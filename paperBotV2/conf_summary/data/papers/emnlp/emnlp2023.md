# EMNLP2023

## 会议论文列表

本会议共有 2241 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Frontmatter](https://aclanthology.org/2023.emnlp-demo.0) |  | 0 |  |  |  |
| 2 |  |  [Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs](https://doi.org/10.18653/v1/2023.emnlp-demo.1) |  | 0 | Most NLP tasks are modeled as supervised learning and thus require labeled training data to train effective models. However, manually producing such data at sufficient quality and quantity is known to be costly and time-intensive. Current research addresses this bottleneck by exploring a novel paradigm called zero-shot learning via dataset generation. Here, a powerful LLM is prompted with a task description to generate labeled data that can be used to train a downstream NLP model. For instance, an LLM might be prompted to “generate 500 movie reviews with positive overall sentiment, and another 500 with negative sentiment.” The generated data could then be used to train a binary sentiment classifier, effectively leveraging an LLM as a teacher to a smaller student model. With this demo, we introduce Fabricator, an open-source Python toolkit for dataset generation. Fabricator implements common dataset generation workflows, supports a wide range of downstream NLP tasks (such as text classification, question answering, and entity recognition), and is integrated with well-known libraries to facilitate quick experimentation. With Fabricator, we aim to support researchers in conducting reproducible dataset generation experiments using LLMs and help practitioners apply this approach to train models for downstream tasks. | Jonas Golde, Patrick Haller, Felix Hamborg, Julian Risch, Alan Akbik |  |
| 3 |  |  [End-to-End Evaluation for Low-Latency Simultaneous Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-demo.2) |  | 0 | The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user. | Christian Huber, Tu Anh Dinh, Carlos Mullov, NgocQuan Pham, Thai Binh Nguyen, Fabian Retkowski, Stefan Constantin, Enes Yavuz Ugan, Danni Liu, Zhaolin Li, Sai Koneru, Jan Niehues, Alexander Waibel |  |
| 4 |  |  [CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools](https://doi.org/10.18653/v1/2023.emnlp-demo.3) |  | 0 | In the face of climate change, are companies really taking substantial steps toward more sustainable operations? A comprehensive answer lies in the dense, information-rich landscape of corporate sustainability reports. However, the sheer volume and complexity of these reports make human analysis very costly. Therefore, only a few entities worldwide have the resources to analyze these reports at scale, which leads to a lack of transparency in sustainability reporting. Empowering stakeholders with LLM-based automatic analysis tools can be a promising way to democratize sustainability report analysis. However, developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop. In this paper, we introduce ChatReport, a novel LLM-based system to automate the analysis of corporate sustainability reports, addressing existing challenges by (1) making the answers traceable to reduce the harm of hallucination and (2) actively involving domain experts in the development loop. We make our methodology, annotated datasets, and generated analyses of 1015 reports publicly available. Video Introduction: https://www.youtube.com/watch?v=Q5AzaKzPE4M Github: https://github.com/EdisonNi-hku/chatreport Live web app: reports.chatclimate.ai | Jingwei Ni, Julia Anna Bingler, Chiara Colesanti Senni, Mathias Kraus, Glen Gostlow, Tobias Schimanski, Dominik Stammbach, Saeid Ashraf Vaghefi, Qian Wang, Nicolas Webersinke, Tobias Wekhof, Tingyu Yu, Markus Leippold |  |
| 5 |  |  [RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.4) |  | 0 | Retrieval-augmented large language models (R-LLMs) combine pre-trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question-answering. However, current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap, we present RaLLe, an open-source framework designed to facilitate the development, evaluation, and optimization of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. By leveraging these features, developers can enhance the performance and accuracy of their R-LLMs in knowledge-intensive generation tasks. | Yasuto Hoshi, Daisuke Miyashita, Youyang Ng, Kento Tatsuno, Yasuhiro Morioka, Osamu Torii, Jun Deguchi |  |
| 6 |  |  [VIST5: An Adaptive, Retrieval-Augmented Language Model for Visualization-oriented Dialog](https://doi.org/10.18653/v1/2023.emnlp-demo.5) |  | 0 | The advent of large language models has brought about new ways of interacting with data intuitively via natural language. In recent years, a variety of visualization systems have explored the use of natural language to create and modify visualizations through visualization-oriented dialog. However, the majority of these systems rely on tailored dialog agents to analyze domain-specific data and operate domain-specific visualization tools and libraries. This is a major challenge when trying to transfer functionalities between dialog interfaces of different visualization applications. To address this issue, we propose VIST5, a visualization-oriented dialog system that focuses on easy adaptability to an application domain as well as easy transferability of language-controllable visualization library functions between applications. Its architecture is based on a retrieval-augmented T5 language model that leverages few-shot learning capabilities to enable a rapid adaptation of the system. | Henrik Voigt, Nuno Carvalhais, Monique Meuschke, Markus Reichstein, Sina Zarrieß, Kai Lawonn |  |
| 7 |  |  [H2O Open Ecosystem for State-of-the-art Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.6) |  | 0 | Large Language Models (LLMs) represent a revolution in AI. However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text. For this reason we need open, transparent and safe solutions. We introduce a complete open-source ecosystem for developing and testing LLMs. The goal of this project is to boost open alternatives to closed-source approaches. We release h2oGPT, a family of fine-tuned LLMs from 7 to 70 Billion parameters. We also introduce H2O LLM Studio, a framework and no-code GUI designed for efficient fine-tuning, evaluation, and deployment of LLMs using the most recent state-of-the-art techniques. Our code and models are licensed under fully permissive Apache 2.0 licenses. We believe open-source language models help to boost AI development and make it more accessible and trustworthy. Our demo is available at: https://gpt.h2o.ai/ | Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian Jeblick, Chun Ming Lee, Marcos V. Conde |  |
| 8 |  |  [Koala: An Index for Quantifying Overlaps with Pre-training Corpora](https://doi.org/10.18653/v1/2023.emnlp-demo.7) |  | 0 | In very recent years more attention has been placed on probing the role of pre-training data in Large Language Models (LLMs) downstream behaviour. Despite the importance, there is no public tool that supports such analysis of pre-training corpora at large scale. To help research in this space, we launch Koala, a searchable index over large pre-training corpora using lossless compressed suffix arrays with highly efficient compression rate and search support. In its first release we index the public proportion of OPT 175B, GPT-3, GPT-Neo, GPT-Neo, LLaMA, BERT, ELECTRA, RoBERTA, XLNet pre-training corpora. Koala provides a framework to do forensic analysis on the current and future benchmarks as well as to assess the degree of memorization in the output from the LLMs. Koala is available for public use at https://koala-index.erc.monash.edu/. | ThuyTrang Vu, Xuanli He, Gholamreza Haffari, Ehsan Shareghi |  |
| 9 |  |  [Sudowoodo: A Chinese Lyric Imitation System with Source Lyrics](https://doi.org/10.18653/v1/2023.emnlp-demo.8) |  | 0 | Lyrics generation is a well-known application in natural language generation research, with several previous studies focusing on generating accurate lyrics using precise control such as keywords, rhymes, etc. However, lyrics imitation, which involves writing new lyrics by imitating the style and content of the source lyrics, remains a challenging task due to the lack of a parallel corpus. In this paper, we introduce Sudowoodo, a Chinese lyrics imitation system that can generate new lyrics based on the text of source lyrics. To address the issue of lacking a parallel training corpus for lyrics imitation, we propose a novel framework to construct a parallel corpus based on a keyword-based lyrics model from source lyrics. Then the pairs (new lyrics, source lyrics) are used to train the lyrics imitation model. During the inference process, we utilize a post-processing module to filter and rank the generated lyrics, selecting the highest-quality ones. We incorporated audio information and aligned the lyrics with the audio to form the songs as a bonus. The human evaluation results show that our framework can perform better lyric imitation. Meanwhile, the Sudowoodo system and demo video of the system is available at Sudowoodo and https://youtu.be/u5BBT\_j1L5M | Yongzhu Chang, Rongsheng Zhang, Lin Jiang, Qihang Chen, Le Zhang, Jiashu Pu |  |
| 10 |  |  [ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data Format](https://doi.org/10.18653/v1/2023.emnlp-demo.9) |  | 0 | Task-oriented dialogue (TOD) systems function as digital assistants, guiding users through various tasks such as booking flights or finding restaurants. Existing toolkits for building TOD systems often fall short in delivering comprehensive arrays of data, model, and experimental environments with a user-friendly experience. We introduce ConvLab-3: a multifaceted dialogue system toolkit crafted to bridge this gap. Our unified data format simplifies the integration of diverse datasets and models, significantly reducing complexity and cost for studying generalization and transfer. Enhanced with robust reinforcement learning (RL) tools, featuring a streamlined training process, in-depth evaluation tools, and a selection of user simulators, ConvLab-3 supports the rapid development and evaluation of robust dialogue policies. Through an extensive study, we demonstrate the efficacy of transfer learning and RL and showcase that ConvLab-3 is not only a powerful tool for seasoned researchers but also an accessible platform for newcomers. | Qi Zhu, Christian Geishauser, HsienChin Lin, Carel van Niekerk, Baolin Peng, Zheng Zhang, Shutong Feng, Michael Heck, Nurul Lubis, Dazhen Wan, Xiaochen Zhu, Jianfeng Gao, Milica Gasic, Minlie Huang |  |
| 11 |  |  [FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge](https://doi.org/10.18653/v1/2023.emnlp-demo.10) |  | 0 | Detecting factual errors of textual information, whether generated by large language models (LLM) or curated by humans, is crucial for making informed decisions. LLMs’ inability to attribute their claims to external knowledge and their tendency to hallucinate makes it difficult to rely on their responses. Humans, too, are prone to factual errors in their writing. Since manual detection and correction of factual er- rors is labor-intensive, developing an automatic approach can greatly reduce human effort. We present a prototype tool that automatically extracts factual claims from text, gathers evidence from external knowledge sources, evaluates the factuality of each claim, and suggests revisions for identified errors using the collected evidence. Initial empirical evaluation on fact error detection (77-85% F1) shows the potential of our tool. | Farima Fatahi Bayat, Kun Qian, Benjamin Han, Yisi Sang, Anton Belyi, Samira Khorshidi, Fei Wu, Ihab F. Ilyas, Yunyao Li |  |
| 12 |  |  [YATO: Yet Another deep learning based Text analysis Open toolkit](https://doi.org/10.18653/v1/2023.emnlp-demo.11) |  | 0 | We introduce YATO, an open-source, easy-to-use toolkit for text analysis with deep learning. Different from existing heavily engineered toolkits and platforms, YATO is lightweight and user-friendly for researchers from cross-disciplinary areas. Designed in a hierarchical structure, YATO supports free combinations of three types of widely used features including 1) traditional neural networks (CNN, RNN, etc.); 2) pre-trained language models (BERT, RoBERTa, ELECTRA, etc.); and 3) user-customized neural features via a simple configurable file. Benefiting from the advantages of flexibility and ease of use, YATO can facilitate fast reproduction and refinement of state-of-the-art NLP models, and promote the cross-disciplinary applications of NLP techniques. The code, examples, and documentation are publicly available at https://github.com/jiesutd/YATO. A demo video is also available at https://www.youtube.com/playlist?list=PLJ0mhzMcRuDUlTkzBfAftOqiJRxYTTjXH. | Zeqiang Wang, Yile Wang, Jiageng Wu, Zhiyang Teng, Jie Yang |  |
| 13 |  |  [Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face](https://doi.org/10.18653/v1/2023.emnlp-demo.12) |  | 0 | We present Spacerini, a tool that integrates the Pyserini toolkit for reproducible information retrieval research with Hugging Face to enable the seamless construction and deployment of interactive search engines. Spacerini makes state-of-the-art sparse and dense retrieval models more accessible to non-IR practitioners while minimizing deployment effort. This is useful for NLP researchers who want to better understand and validate their research by performing qualitative analyses of training corpora, for IR researchers who want to demonstrate new retrieval models integrated into the growing Pyserini ecosystem, and for third parties reproducing the work of other researchers. Spacerini is open source and includes utilities for loading, preprocessing, indexing, and deploying search engines locally and remotely. We demonstrate a portfolio of 13 search engines created with Spacerini for different use cases. | Christopher Akiki, Odunayo Ogundepo, Aleksandra Piktus, Xinyu Zhang, Akintunde Oladipo, Jimmy Lin, Martin Potthast |  |
| 14 |  |  [Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning](https://doi.org/10.18653/v1/2023.emnlp-demo.13) |  | 0 | We introduce Adapters, an open-source library that unifies parameter-efficient and modular transfer learning in large language models. By integrating 10 diverse adapter methods into a unified interface, Adapters offers ease of use and flexible configuration. Our library allows researchers and practitioners to leverage adapter modularity through composition blocks, enabling the design of complex adapter setups. We demonstrate the library’s efficacy by evaluating its performance against full fine-tuning on various NLP tasks. Adapters provides a powerful tool for addressing the challenges of conventional fine-tuning paradigms and promoting more efficient and modular transfer learning. The library is available via https://adapterhub.ml/adapters. | Clifton Poth, Hannah Sterz, Indraneil Paul, Sukannya Purkayastha, Leon Engländer, Timo Imhof, Ivan Vulic, Sebastian Ruder, Iryna Gurevych, Jonas Pfeiffer |  |
| 15 |  |  [INTELMO: Enhancing Models' Adoption of Interactive Interfaces](https://doi.org/10.18653/v1/2023.emnlp-demo.14) |  | 0 | This paper presents INTELMO, an easy-to-use library to help model developers adopt user-faced interactive interfaces and articles from real-time RSS sources for their language models. The library categorizes common NLP tasks and provides default style patterns, streamlining the process of creating interfaces with minimal code modifications while ensuring an intuitive user experience. Moreover, INTELMO employs a multi-granular hierarchical abstraction to provide developers with fine-grained and flexible control over user interfaces. INTELMO is under active development, with document available at https://intelmo.github.io. | Chunxu Yang, ChienSheng Wu, Lidiya Murakhovs'ka, Philippe Laban, Xiang Chen |  |
| 16 |  |  [Humanoid Agents: Platform for Simulating Human-like Generative Agents](https://doi.org/10.18653/v1/2023.emnlp-demo.15) |  | 0 | Just as computational simulations of atoms, molecules and cells have shaped the way we study the sciences, true-to-life simulations of human-like agents can be valuable tools for studying human behavior. We propose Humanoid Agents, a system that guides Generative Agents to behave more like humans by introducing three elements of System 1 processing: Basic needs (e.g. hunger, health and energy), Emotion and Closeness in Relationships. Humanoid Agents are able to use these dynamic elements to adapt their daily activities and conversations with other agents, as supported with empirical experiments. Our system is designed to be extensible to various settings, three of which we demonstrate, as well as to other elements influencing human behavior (e.g. empathy, moral values and cultural background). Our platform also includes a Unity WebGL game interface for visualization and an interactive analytics dashboard to show agent statuses over time. Our platform is available on https://www.humanoidagents.com/ and code is on https://github.com/HumanoidAgents/HumanoidAgents | Zhilin Wang, Yu Ying Chiu, Yu Cheung Chiu |  |
| 17 |  |  [TP-Detector: Detecting Turning Points in the Engineering Process of Large-scale Projects](https://doi.org/10.18653/v1/2023.emnlp-demo.16) |  | 0 | This paper introduces a novel task of detecting turning points in the engineering process of large-scale projects, wherein the turning points signify significant transitions occurring between phases. Given the complexities involving diverse critical events and limited comprehension in individual news reports, we approach the problem by treating the sequence of related news streams as a window with multiple instances. To capture the evolution of changes effectively, we adopt a deep Multiple Instance Learning (MIL) framework and employ the multiple instance ranking loss to discern the transition patterns exhibited in the turning point window. Extensive experiments consistently demonstrate the effectiveness of our proposed approach on the constructed dataset compared to baseline methods. We deployed the proposed mode and provided a demonstration video to illustrate its functionality. The code and dataset are available on GitHub. | Qi Wu, WenHan Chao, Xian Zhou, Zhunchen Luo |  |
| 18 |  |  [CLEVA: Chinese Language Models EVAluation Platform](https://doi.org/10.18653/v1/2023.emnlp-demo.17) |  | 0 | With the continuous emergence of Chinese Large Language Models (LLMs), how to evaluate a model’s capabilities has become an increasingly significant issue. The absence of a comprehensive Chinese benchmark that thoroughly assesses a model’s performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted to holistically evaluate Chinese LLMs. Our platform employs a standardized workflow to assess LLMs’ performance across various dimensions, regularly updating a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round. Empowered by an easy-to-use interface that requires just a few mouse clicks and a model API, users can conduct a thorough evaluation with minimal coding. Large-scale experiments featuring 23 Chinese LLMs have validated CLEVA’s efficacy. | Yanyang Li, Jianqiao Zhao, Duo Zheng, ZiYuan Hu, Zhi Chen, Xiaohui Su, Yongfeng Huang, Shijia Huang, Dahua Lin, Michael R. Lyu, Liwei Wang |  |
| 19 |  |  [DOPA METER - A Tool Suite for Metrical Document Profiling and Aggregation](https://doi.org/10.18653/v1/2023.emnlp-demo.18) |  | 0 | We present DOPA METER, a tool suite for the metrical investigation of written language, that provides diagnostic means for its division into discourse categories, such as registers, genres, and style. The quantitative basis of our system are 120 metrics covering a wide range of lexical, syntactic, and semantic features relevant for language profiling. The scores can be summarized, compared, and aggregated using visualization tools that can be tailored according to the users’ needs. We also showcase an application scenario for DOPA METER. | Christina Lohr, Udo Hahn |  |
| 20 |  |  [Muted: Multilingual Targeted Offensive Speech Identification and Visualization](https://doi.org/10.18653/v1/2023.emnlp-demo.19) |  | 0 | Offensive language such as hate, abuse, and profanity (HAP) occurs in various content on the web. While previous work has mostly dealt with sentence level annotations, there have been a few recent attempts to identify offensive spans as well. We build upon this work and introduce MUTED, a system to identify multilingual HAP content by displaying offensive arguments and their targets using heat maps to indicate their intensity. MUTED can leverage any transformer-based HAP-classification model and its attention mechanism out-of-the-box to identify toxic spans, without further fine-tuning. In addition, we use the spaCy library to identify the specific targets and arguments for the words predicted by the attention heatmaps. We present the model’s performance on identifying offensive spans and their targets in existing datasets and present new annotations on German text. Finally, we demonstrate our proposed visualization tool on multilingual inputs. | Christoph Tillmann, Aashka Trivedi, Sara Rosenthal, Santosh Borse, Rong Zhang, Avirup Sil, Bishwaranjan Bhattacharjee |  |
| 21 |  |  [Gentopia.AI: A Collaborative Platform for Tool-Augmented LLMs](https://doi.org/10.18653/v1/2023.emnlp-demo.20) |  | 0 | Augmented Language Models (ALMs) empower large language models with the ability to use tools, transforming them into intelligent agents for real-world interactions. However, most existing frameworks for ALMs, to varying degrees, are deficient in the following critical features: flexible customization, collaborative democratization, and holistic evaluation. This paper proposes Gentopia, a lightweight and extensible framework for ALMs. Gentopia allows the flexible customization of agents through simple configurations, seamlessly integrating various language models, task formats, prompting modules, and plugins into a unified paradigm. Furthermore, we establish Gentpool, a public platform enabling the registration and sharing of user-customized agents. Agents registered in Gentpool are composable such that they can be assembled together for agent collaboration, advancing the democratization of artificial intelligence. To ensure high-quality agents, Gentbench, an integral component of Gentpool, is designed to thoroughly evaluate user-customized agents across diverse aspects such as safety, robustness, efficiency, etc. We release Gentopia on Github and will continuously move forward. | Binfeng Xu, Xukun Liu, Hua Shen, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng, Yuchen Liu, Ziyu Yao, Dongkuan Xu |  |
| 22 |  |  [MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.21) |  | 0 | AI-empowered music processing is a diverse feld that encompasses dozens of tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension tasks (e.g., music classifcation). For developers and amateurs, it is very diffcult to grasp all of these task to satisfy their requirements in music processing, especially considering the huge differences in the representations of music data and the model applicability across platforms among various tasks. Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements. Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements. More specifically, we build 1) toolset that collects tools from diverse sources, including Hugging Face, GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g., ChatGPT) to organize these tools and automatically decompose user requests into multiple sub-tasks and invoke corresponding music tools. The primary goal of this system is to free users from the intricacies of AI-music tools, enabling them to concentrate on the creative aspect. By granting users the freedom to effortlessly combine tools, the system offers a seamless and enriching music experience. The code is available on GitHub along with a brief instructional video. | Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei Ye, Shikun Zhang, Jiang Bian |  |
| 23 |  |  [SentAlign: Accurate and Scalable Sentence Alignment](https://doi.org/10.18653/v1/2023.emnlp-demo.22) |  | 0 | We present SentAlign, an accurate sentence alignment tool designed to handle very large parallel document pairs. Given user-defined parameters, the alignment algorithm evaluates all possible alignment paths in fairly large documents of thousands of sentences and uses a divide-and-conquer approach to align documents containing tens of thousands of sentences. The scoring function is based on LaBSE bilingual sentence representations. SentAlign outperforms five other sentence alignment tools when evaluated on two different evaluation sets, German-French and English-Icelandic, and on a downstream machine translation task. | Steinþór Steingrímsson, Hrafn Loftsson, Andy Way |  |
| 24 |  |  [QACheck: A Demonstration System for Question-Guided Multi-Hop Fact-Checking](https://doi.org/10.18653/v1/2023.emnlp-demo.23) |  | 0 | Fact-checking real-world claims often requires intricate, multi-step reasoning due to the absence of direct evidence to support or refute them. However, existing fact-checking systems often lack transparency in their decision-making, making it challenging for users to comprehend their reasoning process. To address this, we propose the Question-guided Multi-hop Fact-Checking (QACheck) system, which guides the model’s reasoning process by asking a series of questions critical for verifying a claim. QACheck has five key modules: a claim verifier, a question generator, a question-answering module, a QA validator, and a reasoner. Users can input a claim into QACheck, which then predicts its veracity and provides a comprehensive report detailing its reasoning process, guided by a sequence of (question, answer) pairs. QACheck also provides the source of evidence supporting each question, fostering a transparent, explainable, and user-friendly fact-checking process. | Liangming Pan, Xinyuan Lu, MinYen Kan, Preslav Nakov |  |
| 25 |  |  [RobustQA: A Framework for Adversarial Text Generation Analysis on Question Answering Systems](https://doi.org/10.18653/v1/2023.emnlp-demo.24) |  | 0 | Question answering (QA) systems have reached human-level accuracy; however, these systems are not robust enough and are vulnerable to adversarial examples. Recently, adversarial attacks have been widely investigated in text classification. However, there have been few research efforts on this topic in QA. In this article, we have modified the attack algorithms widely used in text classification to fit those algorithms for QA systems. We have evaluated the impact of various attack methods on QA systems at character, word, and sentence levels. Furthermore, we have developed a new framework, named RobustQA, as the first open-source toolkit for investigating textual adversarial attacks in QA systems. RobustQA consists of seven modules: Tokenizer, Victim Model, Goals, Metrics, Attacker, Attack Selector, and Evaluator. It currently supports six different attack algorithms. Furthermore, the framework simplifies the development of new attack algorithms in QA. The source code and documentation of RobustQA are available at https://github.com/mirbostani/RobustQA. | Yasaman Boreshban, Seyed Morteza Mirbostani, Seyedeh Fatemeh Ahmadi, Gita Shojaee, Fatemeh Kamani, Gholamreza GhassemSani, Seyed Abolghasem Mirroshandel |  |
| 26 |  |  [Kandinsky: An Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion](https://doi.org/10.18653/v1/2023.emnlp-demo.25) |  | 0 | Text-to-image generation is a significant domain in modern computer vision and achieved substantial improvements through the evolution of generative architectures. Among these, diffusion-based models demonstrated essential quality enhancements. These models generally split into two categories: pixel-level and latent-level approaches. We present Kandinsky – a novel exploration of latent diffusion architecture, combining the principles of image prior models with latent diffusion techniques. The image prior model, is trained separately to map CLIP text and image embeddings. Another distinct feature of the proposed model is the modified MoVQ implementation, which serves as the image autoencoder component. Overall the designed model contains 3.3B parameters. We also deployed a user-friendly demo system that supports diverse generative modes such as text-to-image generation, image fusion, text and image fusion, image variations generation and text-guided inpainting/outpainting. Additionally we released the source code and checkpoints for Kandinsky models. Experimental evaluations demonstrate FID score of 8.03 on the COCO-30K dataset, marking our model as the top open source performer in terms of measurable image generation quality. | Anton Razzhigaev, Arseniy Shakhmatov, Anastasia Maltseva, Vladimir Arkhipkin, Igor Pavlov, Ilya Ryabov, Angelina Kuts, Alexander Panchenko, Andrey Kuznetsov, Denis Dimitrov |  |
| 27 |  |  [NewsRecLib: A PyTorch-Lightning Library for Neural News Recommendation](https://doi.org/10.18653/v1/2023.emnlp-demo.26) |  | 0 | NewsRecLib is an open-source library based on Pytorch-Lightning and Hydra developed for training and evaluating neural news recommendation models. The foremost goals of NewsRecLib are to promote reproducible research and rigorous experimental evaluation by (i) providing a unified and highly configurable framework for exhaustive experimental studies and (ii) enabling a thorough analysis of the performance contribution of different model architecture components and training regimes. NewsRecLib is highly modular, allows specifying experiments in a single configuration file, and includes extensive logging facilities. Moreover, NewsRecLib provides out-of-the-box implementations of several prominent neural models, training methods, standard evaluation benchmarks, and evaluation metrics for news recommendation. | Andreea Iana, Goran Glavas, Heiko Paulheim |  |
| 28 |  |  [MiniChain: A Small Library for Coding with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.27) |  | 0 | Programming augmented by large language models (LLMs) opens up many new application areas, but also requires care. LLMs are accurate enough, on average, to replace core functionality, yet make basic mistakes that demonstrate a lack of robustness. An ecosystem of prompting tools, from intelligent agents to new programming languages, have emerged with different solutions for patching LLMs with other tools. In this work, we introduce MiniChain, an opinionated tool for LLM augmented programming, with the design goals of ease-of-use of prototyping, transparency through automatic visualization, and a minimalistic approach to advanced features. The MiniChain library provides core primitives for coding LLM calls, separating out prompt templates, and capturing program structure. The library includes demo implementations of the main applications papers in the area, including chat-bots, code generation, retrieval-based question answering, and complex information extraction. The library is open-source and available at https://github.com/srush/MiniChain, with code demos available at https://srush-minichain.hf.space/, and video demo at https://www.youtube.com/watch?v=VszZ1VnO7sk. | Alexander M. Rush |  |
| 29 |  |  [Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2023.emnlp-demo.28) |  | 0 | A key technology for large language models (LLMs) involves instruction tuning that helps align the models’ responses with human expectations to realize impressive learning abilities. Two major approaches for instruction tuning characterize supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), which are applied to produce the best commercial LLMs. To improve the accessibility of LLMs, various instruction-tuned open-source LLMs have also been introduced recently. However, existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their accessibility to many other languages in the world. In addition, SFT has been used as the only approach to instruction-tune open-source LLMs for multiple languages. This has left a significant gap for fine-tuned LLMs based on RLHF in diverse languages and raised important questions on how RLHF can boost the performance of multilingual instruction tuning. To overcome this issue, we present Okapi, the first system with instruction-tuned LLMs based on RLHF for multiple languages. Okapi introduces instruction and response-ranked data in 26 diverse languages to facilitate the experiments and development of future multilingual LLM research. We also present benchmark datasets to enable the evaluation of generative LLMs in multiple languages. Our experiments demonstrate the advantages of RLHF for multilingual instruction over SFT for different base models and datasets. Our framework with created resources, fine-tuned LLMs, interaction scripts are released at https://github.com/nlp-uoregon/Okapi. A demo video to show our framework can also be found at: https://youtu.be/QFV2fkPwvi0. | Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A. Rossi, Thien Huu Nguyen |  |
| 30 |  |  [SAGEViz: SchemA GEneration and Visualization](https://doi.org/10.18653/v1/2023.emnlp-demo.29) |  | 0 | Schema induction involves creating a graph representation depicting how events unfold in a scenario. We present SAGEViz, an intuitive and modular tool that utilizes human-AI collaboration to create and update complex schema graphs efficiently, where multiple annotators (humans and models) can work simultaneously on a schema graph from any domain. The tool consists of two components: (1) a curation component powered by plug-and-play event language models to create and expand event sequences while human annotators validate and enrich the sequences to build complex hierarchical schemas, and (2) an easy-to-use visualization component to visualize schemas at varying levels of hierarchy. Using supervised and few-shot approaches, our event language models can continually predict relevant events starting from a seed event. We conduct a user study and show that users need less effort in terms of interaction steps with SAGEViz to generate schemas of better quality. We also include a video demonstrating the system. | Sugam Devare, Mahnaz Koupaee, Gautham Gunapati, Sayontan Ghosh, Sai Vallurupalli, Yash Kumar Lal, Francis Ferraro, Nathanael Chambers, Greg Durrett, Raymond J. Mooney, Katrin Erk, Niranjan Balasubramanian |  |
| 31 |  |  [Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation](https://doi.org/10.18653/v1/2023.emnlp-demo.30) |  | 0 | Fine-grained, span-level human evaluation has emerged as a reliable and robust method for evaluating text generation tasks such as summarization, simplification, machine translation and news generation, and the derived annotations have been useful for training automatic metrics and improving language models. However, existing annotation tools implemented for these evaluation frameworks lack the adaptability to be extended to different domains or languages, or modify annotation settings according to user needs; and, the absence of a unified annotated data format inhibits the research in multi-task learning. In this paper, we introduce Thresh, a unified, customizable and deployable platform for fine-grained evaluation. With a single YAML configuration file, users can build and test an annotation interface for any framework within minutes – all in one web browser window. To facilitate collaboration and sharing, Thresh provides a community hub that hosts a collection of fine-grained frameworks and corresponding annotations made and collected by the community, covering a wide range of NLP tasks. For deployment, Thresh offers multiple options for any scale of annotation projects from small manual inspections to large crowdsourcing ones. Additionally, we introduce a Python library to streamline the entire process from typology design and deployment to annotation processing. Thresh is publicly accessible at https://thresh.tools. | David Heineman, Yao Dou, Wei Xu |  |
| 32 |  |  [InsightPilot: An LLM-Empowered Automated Data Exploration System](https://doi.org/10.18653/v1/2023.emnlp-demo.31) |  | 0 | Exploring data is crucial in data analysis, as it helps users understand and interpret the data more effectively. However, performing effective data exploration requires in-depth knowledge of the dataset, the user intent and expertise in data analysis techniques. Not being familiar with either can create obstacles that make the process time-consuming and overwhelming. To address this issue, we introduce InsightPilot, an LLM (Large Language Model)-based, automated data exploration system designed to simplify the data exploration process. InsightPilot features a set of carefully designed analysis actions that streamline the data exploration process. Given a natural language question, InsightPilot collaborates with the LLM to issue a sequence of analysis actions, explore the data and generate insights. We demonstrate the effectiveness of InsightPilot in a user study and a case study, showing how it can help users gain valuable insights from their datasets. | Pingchuan Ma, Rui Ding, Shuai Wang, Shi Han, Dongmei Zhang |  |
| 33 |  |  [SynJax: Structured Probability Distributions for JAX](https://doi.org/10.18653/v1/2023.emnlp-demo.32) |  | 0 | The development of deep learning software libraries enabled significant progress in the field by allowing users to focus on modeling, while letting the library to take care of the tedious and time-consuming task of optimizing execution for modern hardware accelerators. However, this has benefited only particular types of deep learning models, such as Transformers, whose primitives map easily to the vectorized computation. The models that explicitly account for structured objects, such as trees and segmentations, did not benefit equally because they require custom algorithms that are difficult to implement in a vectorized form. SynJax directly addresses this problem by providing an efficient vectorized implementation of inference algorithms for structured distributions covering alignment, tagging, segmentation, constituency trees and spanning trees. This is done by exploiting the connection between algorithms for automatic differentiation and probabilistic inference. With SynJax we can build large-scale differentiable models that explicitly model structure in the data. The code is available at https://github.com/google-deepmind/synjax | Milos Stanojevic, Laurent Sartran |  |
| 34 |  |  [RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and Editor](https://doi.org/10.18653/v1/2023.emnlp-demo.33) |  | 0 | In this paper, we present RESIN-EDITOR, an interactive event graph visualizer and editor designed for analyzing complex events. Our RESIN-EDITOR system allows users to render and freely edit hierarchical event graphs extracted from multimedia and multi-document news clusters with guidance from human-curated event schemas. RESIN-EDITOR’s unique features include hierarchical graph visualization, comprehensive source tracing, and interactive user editing, which significantly outperforms existing Information Extraction (IE) visualization tools in both IE result analysis and general model improvements. In our evaluation of RESIN-EDITOR, we demonstrate ways in which our tool is effective in understanding complex events and enhancing system performances. The source code, a video demonstration, and a live website for RESIN-EDITOR have been made publicly available. | Khanh Duy Nguyen, Zixuan Zhang, Reece Suchocki, Sha Li, Martha Palmer, Susan Windisch Brown, Jiawei Han, Heng Ji |  |
| 35 |  |  [DRGCoder: Explainable Clinical Coding for the Early Prediction of Diagnostic-Related Groups](https://doi.org/10.18653/v1/2023.emnlp-demo.34) |  | 0 | Medical claim coding is the process of transforming medical records, usually presented as free texts written by clinicians, or discharge summaries, into structured codes in a classification system such as ICD-10 (International Classification of Diseases, Tenth Revision) or DRG (Diagnosis-Related Group) codes. This process is essential for medical billing and transitional care; however, manual coding is time-consuming, error-prone, and expensive. To solve these issues, we propose DRGCoder, an explainability-enhanced clinical claim coding system for the early prediction of medical severity DRGs (MS-DRGs), a classification system that categorizes patients’ hospital stays into various DRG groups based on the severity of illness and mortality risk. The DRGCoder framework introduces a novel multi-task Transformer model for MS-DRG prediction, modeling both the DRG labels of the discharge summaries and the important, or salient words within he discharge summaries. We allow users to inspect DRGCoder’s reasoning by visualizing the weights for each word of the input. Additionally, DRGCoder allows users to identify diseases within discharge summaries and compare across multiple discharge summaries. Our demo is available at https://huggingface.co/spaces/danielhajialigol/DRGCoder. A video demonstrating the demo can be found at https://www.youtube.com/watch?v=pcdiG6VwqlA | Daniel Hajialigol, Derek Kaknes, Tanner Barbour, Daphne Yao, Chris North, Jimeng Sun, David Liem, Xuan Wang |  |
| 36 |  |  [CAMRA: Copilot for AMR Annotation](https://doi.org/10.18653/v1/2023.emnlp-demo.35) |  | 0 | In this paper, we introduce CAMRA (Copilot for AMR Annotatations), a cutting-edge web-based tool designed for constructing Abstract Meaning Representation (AMR) from natural language text. CAMRA offers a novel approach to deep lexical semantics annotation such as AMR, treating AMR annotation akin to coding in programming languages. Leveraging the familiarity of programming paradigms, CAMRA encompasses all essential features of existing AMR editors, including example lookup, while going a step further by integrating Propbank roleset lookup as an autocomplete feature within the tool. Notably, CAMRA incorporates AMR parser models as coding co-pilots, greatly enhancing the efficiency and accuracy of AMR annotators. | Jon Z. Cai, Shafiuddin Rehan Ahmed, Julia Bonn, Kristin WrightBettner, Martha Palmer, James H. Martin |  |
| 37 |  |  [Reaction Miner: An Integrated System for Chemical Reaction Extraction from Textual Data](https://doi.org/10.18653/v1/2023.emnlp-demo.36) |  | 0 | Chemical reactions, as a core entity in the realm of chemistry, hold crucial implications in diverse areas ranging from hands-on laboratory research to advanced computational drug design. Despite a burgeoning interest in employing NLP techniques to extract these reactions, aligning this task with the real-world requirements of chemistry practitioners remains an ongoing challenge. In this paper, we present Reaction Miner, a system specifically designed to interact with raw scientific literature, delivering precise and more informative chemical reactions. Going beyond mere extraction, Reaction Miner integrates a holistic workflow: it accepts PDF files as input, bypassing the need for pre-processing and bolstering user accessibility. Subsequently, a text segmentation module ensures that the refined text encapsulates complete chemical reactions, augmenting the accuracy of extraction. Moreover, Reaction Miner broadens the scope of existing pre-defined reaction roles, including vital attributes previously neglected, thereby offering a more comprehensive depiction of chemical reactions. Evaluations conducted by chemistry domain users highlight the efficacy of each module in our system, demonstrating Reaction Miner as a powerful tool in this field. | Ming Zhong, Siru Ouyang, Yizhu Jiao, Priyanka Kargupta, Leo Luo, Yanzhen Shen, Bobby Zhou, Xianrui Zhong, Xuan Liu, Hongxiang Li, Jinfeng Xiao, Minhao Jiang, Vivian Hu, Xuan Wang, Heng Ji, Martin D. Burke, Huimin Zhao, Jiawei Han |  |
| 38 |  |  [CHAMP: Efficient Annotation and Consolidation of Cluster Hierarchies](https://doi.org/10.18653/v1/2023.emnlp-demo.37) |  | 0 | Various NLP tasks require a complex hierarchical structure over nodes, where each node is a cluster of items. Examples include generating entailment graphs, hierarchical cross-document coreference resolution, annotating event and subevent relations, etc. To enable efficient annotation of such hierarchical structures, we release CHAMP, an open source tool allowing to incrementally construct both clusters and hierarchy simultaneously over any type of texts. This incremental approach significantly reduces annotation time compared to the common pairwise annotation approach and also guarantees maintaining transitivity at the cluster and hierarchy levels. Furthermore, CHAMP includes a consolidation mode, where an adjudicator can easily compare multiple cluster hierarchy annotations and resolve disagreements. | Arie Cattan, Tom Hope, Doug Downey, Roy BarHaim, Lilach Eden, Yoav Kantor, Ido Dagan |  |
| 39 |  |  [Prompt2Model: Generating Deployable Models from Natural Language Instructions](https://doi.org/10.18653/v1/2023.emnlp-demo.38) |  | 0 | Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model. Our demo video is posted at youtu.be/LYYQ_EhGd-Q. | Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, Graham Neubig |  |
| 40 |  |  [NewsSense: Reference-free Verification via Cross-document Comparison](https://doi.org/10.18653/v1/2023.emnlp-demo.39) |  | 0 | We present NewsSense, a novel sensemaking tool and reading interface designed to collect and integrate information from multiple news articles on a central topic. NewsSense provides “reference-free verification,” augmenting a central grounding article of the user’s choice by: (1) linking to related articles from different sources; and (2) providing inline highlights on how specific claims are either supported or contradicted by information from other articles. Using NewsSense, users can seamlessly digest and cross-check multiple information sources without disturbing their natural reading flow. Our pilot study shows that NewsSense has the potential to help users identify key information, verify the credibility of news articles, explore different perspectives, and understand what content is supported, contradicted, or missing. | Jeremiah Milbauer, Ziqi Ding, Zhijin Wu, Tongshuang Wu |  |
| 41 |  |  [NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails](https://doi.org/10.18653/v1/2023.emnlp-demo.40) |  | 0 | NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems. Guardrails (or rails for short) are a specific way of controlling the output of an LLM, such as not talking about topics considered harmful, following a predefined dialogue path, using a particular language style, and more. There are several mechanisms that allow LLM providers and developers to add guardrails that are embedded into a specific model at training, e.g. using model alignment. Using a runtime inspired from dialogue management, NeMo Guardrails provides a different approach by allowing developers to add programmable rails to LLM applications - these are user-defined, independent of the underlying LLM, and interpretable. Our initial results show that the proposed approach can be used with several LLM providers to develop controllable and safe LLM applications using programmable rails. | Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien, Jonathan Cohen |  |
| 42 |  |  [LM-Polygraph: Uncertainty Estimation for Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.41) |  | 0 | Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields. However, a significant challenge arises as these models often “hallucinate”, i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements. Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs. However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions. In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses. LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs. | Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun, Artem Vazhentsev, Sergey Petrakov, Kirill Fedyanin, Daniil Vasilev, Elizaveta Goncharova, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Artem Shelmanov |  |
| 43 |  |  [Descriptive Knowledge Graph in Biomedical Domain](https://doi.org/10.18653/v1/2023.emnlp-demo.42) |  | 0 | We present a novel system that automatically extracts and generates informative and descriptive sentences from the biomedical corpus and facilitates the efficient search for relational knowledge. Unlike previous search engines or exploration systems that retrieve unconnected passages, our system organizes descriptive sentences as a relational graph, enabling researchers to explore closely related biomedical entities (e.g., diseases treated by a chemical) or indirectly connected entities (e.g., potential drugs for treating a disease). Our system also uses ChatGPT and a fine-tuned relation synthesis model to generate concise and reliable descriptive sentences from retrieved information, reducing the need for extensive human reading effort. With our system, researchers can easily obtain both high-level knowledge and detailed references and interactively steer to the information of interest. We spotlight the application of our system in COVID-19 research, illustrating its utility in areas such as drug repurposing and literature curation. | Kerui Zhu, Jie Huang, Kevin ChenChuan Chang |  |
| 44 |  |  [Prompterator: Iterate Efficiently towards More Effective Prompts](https://doi.org/10.18653/v1/2023.emnlp-demo.43) |  | 0 | With the advent of Large Language Models (LLMs) the process known as prompting, which entices the LLM to solve an arbitrary language processing task without the need for finetuning, has risen to prominence. Finding well-performing prompts, however, is a non-trivial task which requires experimentation in order to arrive at a prompt that solves a specific task. When a given task does not readily reduce to one that can be easily measured with well established metrics, human evaluation of the results obtained by prompting is often necessary. In this work we present prompterator, a tool that helps the user interactively iterate over various potential prompts and choose the best performing one based on human feedback. It is distributed as an open source package with out-of-the-box support for various LLM providers and was designed to be easily extensible. | Samuel Sucik, Daniel Skala, Andrej Svec, Peter Hraska, Marek Suppa |  |
| 45 |  |  [ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.44) |  | 0 | The unprecedented performance of LLMs requires comprehensive and accurate evaluation. We argue that for LLMs evaluation, benchmarks need to be comprehensive and systematic. To this end, we propose the Zhujiu benchmark, which has the following strengths: (1) Multi-dimensional ability coverage: We comprehensively evaluate LLMs across 7 ability dimensions covering 51 tasks. Especially, we also propose a new benchmark that focus on knowledge ability of LLMs. (2) Multi-faceted evaluation methods collaboration: We use 3 different yet complementary evaluation methods to comprehensively evaluate LLMs, which can ensure the authority and accuracy of the evaluation results. (3) Comprehensive Chinese benchmark: ZhuJiu is the pioneering benchmark that fully assesses LLMs in Chinese, while also providing equally robust evaluation abilities in English. (4) Avoiding potential data leakage: To avoid data leakage, we construct evaluation data specifically for 37 tasks. We evaluate 10 current mainstream LLMs, and conduct an in-depth discussion and analysis of their results. The ZhuJiu benchmark and open-participation leaderboard are publicly released at http://www.zhujiu-benchmark.com and we also provide a demo video at https://youtu.be/qypkJ89L1Ic. | Baoli Zhang, Haining Xie, Pengfan Du, Junhao Chen, Pengfei Cao, Yubo Chen, Shengping Liu, Kang Liu, Jun Zhao |  |
| 46 |  |  [PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-Rich Scientific Documents](https://doi.org/10.18653/v1/2023.emnlp-demo.45) |  | 0 | Despite growing interest in applying natural language processing (NLP) and computer vision (CV) models to the scholarly domain, scientific documents remain challenging to work with. They’re often in difficult-to-use PDF formats, and the ecosystem of models to process them is fragmented and incomplete. We introduce PaperMage, an open-source Python toolkit for analyzing and processing visually-rich, structured scientific documents. PaperMage offers clean and intuitive abstractions for seamlessly representing and manipulating both textual and visual document elements. PaperMage achieves this by integrating disparate state-of-the-art NLP and CV models into a unified framework, and provides turn-key recipes for common scientific document processing use-cases. PaperMage has powered multiple research prototypes of AI applications over scientific documents, along with Semantic Scholar’s large-scale production system for processing millions of PDFs. GitHub: https://github.com/allenai/papermage | Kyle Lo, Zejiang Shen, Benjamin Newman, Joseph Chee Chang, Russell Authur, Erin Bransom, Stefan Candra, Yoganand Chandrasekhar, Regan Huff, Bailey Kuehl, Amanpreet Singh, Chris Wilhelm, Angele Zamarron, Marti A. Hearst, Daniel S. Weld, Doug Downey, Luca Soldaini |  |
| 47 |  |  [OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event Understanding](https://doi.org/10.18653/v1/2023.emnlp-demo.46) |  | 0 | Event understanding aims at understanding the content and relationship of events within texts, which covers multiple complicated information extraction tasks: event detection, event argument extraction, and event relation extraction. To facilitate related research and application, we present an event understanding toolkit OmniEvent, which features three desiderata: (1) Comprehensive. OmniEvent supports mainstream modeling paradigms of all the event understanding tasks and the processing of 15 widely-used English and Chinese datasets. (2) Fair. OmniEvent carefully handles the inconspicuous evaluation pitfalls reported in Peng et al. (2023), which ensures fair comparisons between different models. (3) Easy-to-use. OmniEvent is designed to be easily used by users with varying needs. We provide off-the-shelf models that can be directly deployed as web services. The modular framework also enables users to easily implement and evaluate new event understanding models with OmniEvent. The toolkit is publicly released along with the demonstration website and video. | Hao Peng, Xiaozhi Wang, Feng Yao, Zimu Wang, Chuzhao Zhu, Kaisheng Zeng, Lei Hou, Juanzi Li |  |
| 48 |  |  [CocoSciSum: A Scientific Summarization Toolkit with Compositional Controllability](https://doi.org/10.18653/v1/2023.emnlp-demo.47) |  | 0 | We present a novel toolkit for controlled summarization of scientific documents, designed for the specific needs of the scientific community. Our system generates summaries based on user preferences, adjusting key attributes specifically of length and keyword inclusion. A distinguishing feature is its ability to manage multiple attributes concurrently, demonstrating Compositional Controllability for Scientific Summarization (CocoSciSum). Benchmarked against the strong Flan-T5 baseline, CocoSciSum exhibits superior performance on both the quality of summaries generated and the control over single and multiple attributes. Moreover, CocoSciSum is a user-centric toolkit, supporting user preferences expressed in natural language instructions, and accommodating diverse input document formats. CocoSciSum is available on GitHub (https://github.com/WING-NUS/SciAssist/tree/CocoSciSum) with an introduction video (https://youtu.be/YC1YDeEjAbQ). | Yixi Ding, Yanxia Qin, Qian Liu, MinYen Kan |  |
| 49 |  |  [CoLLiE: Collaborative Training of Large Language Models in an Efficient Way](https://doi.org/10.18653/v1/2023.emnlp-demo.48) |  | 0 | Large language models (LLMs) are increasingly pivotal in a wide range of natural language processing tasks. Access to pre-trained models, courtesy of the open-source community, has made it possible to adapt these models to specific applications for enhanced performance. However, the substantial resources required for training these models necessitate efficient solutions. This paper introduces CoLLiE, an efficient library that facilitates collaborative training of large language models using 3D parallelism, parameter-efficient fine-tuning (PEFT) methods, and optimizers such as Lion, Adan, Sophia, and LOMO. With its modular design and comprehensive functionality, CoLLiE offers a balanced blend of efficiency, ease of use, and customization. CoLLiE has proven superior training efficiency in comparison with prevalent solutions in pre-training and fine-tuning scenarios. Furthermore, we provide an empirical evaluation of the correlation between model size and GPU memory consumption under different optimization methods, as well as an analysis of the throughput. Lastly, we carry out a comprehensive comparison of various optimizers and PEFT methods within the instruction-tuning context. CoLLiE is available at https://github.com/OpenLMLab/collie. | Kai Lv, Shuo Zhang, Tianle Gu, Shuhao Xing, Jiawei Hong, Keyu Chen, Xiaoran Liu, Yuqing Yang, Honglin Guo, Tengxiao Liu, Yu Sun, Qipeng Guo, Hang Yan, Xipeng Qiu |  |
| 50 |  |  [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding](https://doi.org/10.18653/v1/2023.emnlp-demo.49) |  | 0 | We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous works that complement LLMs to process the visual or audio signals only, Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble a pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities, as the pre-trained audio encoder and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for the LLM module. To align the output of both visual & audio encoders with LLM’s embedding space, we first train Video-LLaMA on massive video/image-caption pairs and then tune our model with visual-instruction datasets of moderate amount but higher quality. We found Video-LLaMA shows the ability to perceive and comprehend video content and generate meaningful responses grounded in the visual and auditory information presented in the videos. | Hang Zhang, Xin Li, Lidong Bing |  |
| 51 |  |  [SummHelper: Collaborative Human-Computer Summarization](https://doi.org/10.18653/v1/2023.emnlp-demo.50) |  | 0 | Current approaches for text summarization are predominantly automatic, with rather limited space for human intervention and control over the process. In this paper, we introduce SummHelper, and screencast demo at https://www.youtube.com/watch?v=nGcknJwGhxk a 2-phase summarization assistant designed to foster human-machine collaboration. The initial phase involves content selection, where the system recommends potential content, allowing users to accept, modify, or introduce additional selections. The subsequent phase, content consolidation, involves SummHelper generating a coherent summary from these selections, which users can then refine using visual mappings between the summary and the source text. Small-scale user studies reveal the effectiveness of our application, with participants being especially appreciative of the balance between automated guidance and opportunities for personal input. | Aviv Slobodkin, Niv Nachum, Shmuel Amar, Ori Shapira, Ido Dagan |  |
| 52 |  |  [ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-demo.51) |  | 0 | Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior. To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent frameworks that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs. In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers. It provides a user-friendly system library, with a customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way. To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications. Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope. The ModelScope-Agent online demo, library are now publicly available. | Chenliang Li, He Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji Zhang, Fei Huang, Jingren Zhou |  |
| 53 |  |  [EfficientOCR: An Extensible, Open-Source Package for Efficiently Digitizing World Knowledge](https://doi.org/10.18653/v1/2023.emnlp-demo.52) |  | 0 | Billions of public domain documents remain trapped in hard copy or lack an accurate digitization. Modern natural language processing methods cannot be used to index, retrieve, and summarize their texts; conduct computational textual analyses; or extract information for statistical analyses, and these texts cannot be incorporated into language model training. Given the diversity and sheer quantity of public domain texts, liberating them at scale requires optical character recognition (OCR) that is accurate, extremely cheap to deploy, and sample-efficient to customize to novel collections, languages, and character sets. Existing OCR engines, largely designed for small-scale commercial applications in high resource languages, often fall short of these requirements. EffOCR (EfficientOCR), a novel open-source OCR package, meets both the computational and sample efficiency requirements for liberating texts at scale by abandoning the sequence-to-sequence architecture typically used for OCR, which takes representations from a learned vision model as inputs to a learned language model. Instead, EffOCR models OCR as a character or word-level image retrieval problem. EffOCR is cheap and sample efficient to train, as the model only needs to learn characters’ visual appearance and not how they are used in sequence to form language. Models in the EffOCR model zoo can be deployed off-the-shelf with only a few lines of code and include lightweight models designed for mobile phones that are extremely cheap to deploy. Importantly, EffOCR also allows for easy, sample efficient customization with a simple model training interface and minimal labeling requirements due to its sample efficiency. We illustrate the utility of EffOCR by cheaply and accurately digitizing 20 million historical U.S. newspaper scans, evaluating zero-shot performance on randomly selected documents from the U.S. National Archives, and accurately digitizing a Japanese document collection for which all other OCR solutions failed. | Tom Bryan, Jacob Carlson, Abhishek Arora, Melissa Dell |  |
| 54 |  |  [Frontmatter](https://aclanthology.org/2023.emnlp-industry.0) |  | 0 |  |  |  |
| 55 |  |  [BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis](https://doi.org/10.18653/v1/2023.emnlp-industry.1) |  | 0 | Recently, diffusion-based deep generative models (e.g., Stable Diffusion) have shown impressive results in text-to-image synthesis. However, current text-to-image models often require multiple passes of prompt engineering by humans in order to produce satisfactory results for real-world applications. We propose BeautifulPrompt, a deep generative model to produce high-quality prompts from very simple raw descriptions, which enables diffusion-based models to generate more beautiful images. In our work, we first fine-tuned the BeautifulPrompt model over low-quality and high-quality collecting prompt pairs. Then, to ensure that our generated prompts can generate more beautiful images, we further propose a Reinforcement Learning with Visual AI Feedback technique to fine-tune our model to maximize the reward values of the generated prompts, where the reward values are calculated based on the PickScore and the Aesthetic Scores. Our results demonstrate that learning from visual AI feedback promises the potential to improve the quality of generated prompts and images significantly. We further showcase the integration of BeautifulPrompt to a cloud-native AI platform to provide better text-to-image generation service in the cloud. | Tingfeng Cao, Chengyu Wang, Bingyan Liu, Ziheng Wu, Jinhui Zhu, Jun Huang |  |
| 56 |  |  [Enhancing Language Model with Unit Test Techniques for Efficient Regular Expression Generation](https://doi.org/10.18653/v1/2023.emnlp-industry.2) |  | 0 | Recent research has investigated the use of generative language models to produce regular expressions with semantic-based approaches. However, these approaches have shown shortcomings in practical applications, particularly in terms of functional correctness, which refers to the ability to reproduce the intended function inputs by the user. To address this issue, we present a novel method called Unit-Test Driven Reinforcement Learning (UTD-RL). Our approach differs from previous methods by taking into account the crucial aspect of functional correctness and transforming it into a differentiable gradient feedback using policy gradient techniques. In which functional correctness can be evaluated through Unit Tests, a testing method that ensures regular expressions meets its design and performs as intended. Experiments conducted on three public datasets demonstrate the effectiveness of the proposed method in generating regular expressions. This method has been employed in a regulatory scenario where regular expressions can be utilized to ensure that all online content is free from non-compliant elements, thereby significantly reducing the workload of relevant personnel. | Chenhui Mao, Xiexiong Lin, Xin Jin, Xin Zhang |  |
| 57 |  |  [A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models](https://doi.org/10.18653/v1/2023.emnlp-industry.3) |  | 0 | Large language models have become a vital component in modern NLP, achieving state of the art performance in a variety of tasks. However, they are often inefficient for real-world deployment due to their expensive inference costs. Knowledge distillation is a promising technique to improve their efficiency while retaining most of their effectiveness. In this paper, we reproduce, compare and analyze several representative methods for task-agnostic (general-purpose) distillation of Transformer language models. Our target of study includes Output Distribution (OD) transfer, Hidden State (HS) transfer with various layer mapping strategies, and Multi-Head Attention (MHA) transfer based on MiniLMv2. Through our extensive experiments, we study the effectiveness of each method for various student architectures in both monolingual (English) and multilingual settings. Overall, we show that MHA transfer based on MiniLMv2 is generally the best option for distillation and explain the potential reasons behind its success. Moreover, we show that HS transfer remains as a competitive baseline, especially under a sophisticated layer mapping strategy, while OD transfer consistently lags behind other approaches. Findings from this study helped us deploy efficient yet effective student models for latency-critical applications. | Takuma Udagawa, Aashka Trivedi, Michele Merler, Bishwaranjan Bhattacharjee |  |
| 58 |  |  [Towards Effective Automatic Debt Collection with Persona Awareness](https://doi.org/10.18653/v1/2023.emnlp-industry.4) |  | 0 | Understanding debtor personas is crucial for collectors to empathize with debtors and develop more effective collection strategies. In this paper, we take the first step towards comprehensively investigating the significance of debtor personas and present a successful commercial practice on automatic debt collection agents. Specifically, we organize the debtor personas into a taxonomy and construct a persona-aware conversation dataset. Building upon it, we implement a simple yet effective persona-aware agent called PAD. After two-month online testing, PAD increases the recovery rate by 3.31% and collects an additional ~100K RMB. Our commercial practice brings inspiration to the debt collection industry by providing an effective automatic solution. | Tong Zhang, Junhong Liu, Chen Huang, Jia Liu, Hongru Liang, Zujie Wen, Wenqiang Lei |  |
| 59 |  |  [Gatekeeper to save COGS and improve efficiency of Text Prediction](https://doi.org/10.18653/v1/2023.emnlp-industry.5) |  | 0 | The text prediction (TP) workflow calls a Large Language Model (LLM), almost, after every character to get subsequent sequence of characters, till user accepts a suggestion. The confidence score of the prediction is commonly used for filtering the results to ensure that only correct predictions are shown to user. As LLMs require massive amounts of computation and storage, such an approach incurs network and high execution cost. So, we propose a Model gatekeeper (GK) to stop the LLM calls that will result in incorrect predictions at client application level itself. This way a GK can save cost of model inference and improve user experience by not showing the incorrect predictions. We demonstrate that use of a model gatekeeper saved approx 46.6% of COGS for TP, at the cost of approx 4.5% loss in character saving. Use of GK also improved the efficiency (suggestion rate) of TP model by 73%. | Nidhi Tiwari, Sneha Kola, Milos Milunovic, Siqing Chen, Marjan Slavkovski |  |
| 60 |  |  [Efficient Transformer Knowledge Distillation: A Performance Review](https://doi.org/10.18653/v1/2023.emnlp-industry.6) |  | 0 | As pretrained transformer language models continue to achieve state-of-the-art performance, the Natural Language Processing community has pushed for advances in model compression and efficient attention mechanisms to address high computational requirements and limited input sequence length. Despite these separate efforts, no investigation has been done into the intersection of these two fields. In this work, we provide an evaluation of model compression via knowledge distillation on efficient attention transformers. We provide cost-performance trade-offs for the compression of state-of-the-art efficient attention architectures and the gains made in performance in comparison to their full attention counterparts. Furthermore, we introduce a new long-context Named Entity Recognition dataset, GONERD, to train and test the performance of NER models on long sequences. We find that distilled efficient attention transformers can preserve a significant amount of original model performance, preserving up to 98.6% across short-context tasks (GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context Question-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on long-context Named Entity Recognition (GONERD), while decreasing inference times by up to 57.8%. We find that, for most models on most tasks, performing knowledge distillation is an effective method to yield high-performing efficient attention models with low costs. | Nathan Brown, Ashton Williamson, Tahj Anderson, Logan Lawrence |  |
| 61 |  |  [CDD: A Large Scale Dataset for Legal Intelligence Research](https://doi.org/10.18653/v1/2023.emnlp-industry.7) |  | 0 | As an important application of Artificial Intelligence, legal intelligence has recently attracted the attention of many researchers. Previous works investigated diverse issues like predicting crimes, predicting outcomes of judicial debates, or extracting information/knowledge from various kinds of legal documents. Although many advances have been made, the research on supporting prediction of court judgments remains relatively scarce, while the lack of large-scale data resources limits the development of this research.In this paper, we present a novel, large-size Court Debate Dataset (CDD), which includes 30,481 court cases, totaling 1,144,425 utterances. CDD contains real-world conversations involving judges, plaintiffs and defendants in court trials. To construct this dataset we have invited experienced judges to design appropriate labels for data records. We then asked law school students to provide annotations based on the defined labels. The dataset can be applied to several downstream tasks, such as text summarization, dialogue generation, text classification, etc. We introduce the details of the different tasks in the rapidly developing field of legal intelligence, the research of which can be fostered thanks to our dataset, and we provide the corresponding benchmark performance. | Changzhen Ji, Yating Zhang, Adam Jatowt, Haipang Wu |  |
| 62 |  |  [MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning](https://doi.org/10.18653/v1/2023.emnlp-industry.8) |  | 0 | In this paper, we present a methodology for linguistic feature extraction, focusing particularly on automatically syllabifying words in multiple languages, with a design to be compatible with a forced-alignment tool, the Montreal Forced Aligner (MFA). In both the textual and phonetic domains, our method focuses on the extraction of phonetic transcriptions from text, stress marks, and a unified automatic syllabification (in text and phonetic domains). The system was built with open-source components and resources. Through an ablation study, we demonstrate the efficacy of our approach in automatically syllabifying words from several languages (English, French and Spanish). Additionally, we apply the technique to the transcriptions of the CMU ARCTIC dataset, generating valuable annotations available online (https://github.com/noetits/MUST_P-SRL) that are ideal for speech representation learning, speech unit discovery, and disentanglement of speech factors in several speech-related fields. | Noé Tits |  |
| 63 |  |  [Personalized Dense Retrieval on Global Index for Voice-enabled Conversational Systems](https://doi.org/10.18653/v1/2023.emnlp-industry.9) |  | 0 | Voice-controlled AI dialogue systems are susceptible to noise from phonetic variations and failure to resolve ambiguous entities. Typically, personalized entity resolution (ER) and/or query rewrites (QR) are deployed to recover from these error modes. Previous work in this field achieves personalization by constraining retrieval search space to personalized indices built from user’s historical interactions with the device. While constrained retrieval achieves high precision, predictions are limited to entities in recent user history, which offers low coverage of future requests. Further, maintaining individual indices for millions of users is memory intensive and difficult to scale. In this work, we propose a personalized entity retrieval system that is robust to phonetic noise and ambiguity but is not limited to a personalized index. We achieve this by embedding user listening preferences into a contextual query embedding used in retrieval. We demonstrate our model’s ability to correct multiple error modes and show 91% improvement over baseline on the entity retrieval task. Finally, we optimize the end-to-end approach to fit within online latency constraints while maintaining gains in performance. | Masha Belyi, Charlotte Dzialo, Chaitanya Dwivedi, Prajit Muppidi, Kanna Shimizu |  |
| 64 |  |  [Text2Topic: Multi-Label Text Classification System for Efficient Topic Detection in User Generated Content with Zero-Shot Capabilities](https://doi.org/10.18653/v1/2023.emnlp-industry.10) |  | 0 | Multi-label text classification is a critical task in the industry. It helps to extract structured information from large amount of textual data. We propose Text to Topic (Text2Topic), which achieves high multi-label classification performance by employing a Bi-Encoder Transformer architecture that utilizes concatenation, subtraction, and multiplication of embeddings on both text and topic. Text2Topic also supports zero-shot predictions, produces domain-specific text embeddings, and enables production-scale batch-inference with high throughput. The final model achieves accurate and comprehensive results compared to state-of-the-art baselines, including large language models (LLMs). In this study, a total of 239 topics are defined, and around 1.6 million text-topic pairs annotations (in which 200K are positive) are collected on approximately 120K texts from 3 main data sources on Booking.com. The data is collected with optimized smart sampling and partial labeling. The final Text2Topic model is deployed on a real-world stream processing platform, and it outperforms other models with 92.9% micro mAP, as well as a 75.8% macro mAP score. We summarize the modeling choices which are extensively tested through ablation studies, and share detailed in-production decision-making steps. | Fengjun Wang, Moran Beladev, Ofri Kleinfeld, Elina Frayerman, Tal Shachar, Eran Fainman, Karen Lastmann Assaraf, Sarai Mizrachi, Benjamin Wang |  |
| 65 |  |  [Deep Metric Learning to Hierarchically Rank - An Application in Product Retrieval](https://doi.org/10.18653/v1/2023.emnlp-industry.11) |  | 0 | Most e-commerce search engines use customer behavior signals to augment lexical matching and improve search relevance. Many e-commerce companies like Amazon, Alibaba, Ebay etc. operate in multiple countries with country specific stores. However, customer behavior data is sparse in newer stores. To compensate for sparsity of behavioral data in low traffic stores, search engines often use cross-listed products in some form. However, cross-listing across stores is not uniform and in many cases itself sparse. In this paper, we develop a model to identify duplicate and near-duplicate products across stores. Such a model can be used to unify product catalogs worldwide, improve product meta-data or as in our case, use near-duplicate products across multiple to improve search relevance. To capture the product similarity hierarchy, we develop an approach that integrates retrieval and ranking tasks across multiple languages in a single step based on a novel Hierarchical Ranked Multi Similarity (HRMS) Loss that combines Multi-Similarity (MS) loss and Hierarchical Triplet Loss to learn a hierarchical metric space. Our method outperforms strong baselines in terms of catalog coverage and precision of the mappings. We also show via online A/B tests that the product mappings found by our method are successful at improving search quality in low traffic stores, measured in rate of searches with at least one click, significantly by 0.8% and improving cold start product engagement measured as new product clicks significantly by 1.72% in established stores. | Kee Kiat Koo, Ashutosh Joshi, Nishaanth Reddy, Karim Bouyarmane, Ismail B. Tutar, Vaclav Petricek, Changhe Yuan |  |
| 66 |  |  [A Pretrained Language Model for Cyber Threat Intelligence](https://doi.org/10.18653/v1/2023.emnlp-industry.12) |  | 0 | We present a new BERT model for the cybersecurity domain, CTI-BERT, which can improve the accuracy of cyber threat intelligence (CTI) extraction, enabling organizations to better defend against potential cyber threats. We provide detailed information about the domain corpus collection, the training methodology and its effectiveness for a variety of NLP tasks for the cybersecurity domain. The experiments show that CTI-BERT significantly outperforms several general-domain and security-domain models for these cybersecurity applications indicating that the training data and methodology have a significant impact on the model performance. | Youngja Park, Weiqiu You |  |
| 67 |  |  [SAMP: A Model Inference Toolkit of Post-Training Quantization for Text Processing via Self-Adaptive Mixed-Precision](https://doi.org/10.18653/v1/2023.emnlp-industry.13) |  | 0 | The latest industrial inference engines, such as FasterTransformer and TurboTransformers, have verified that half-precision floating point (FP16) and 8-bit integer (INT8) quantization can greatly improve model inference speed. However, the existing INT8 quantization methods are too complicated, and improper usage will lead to model performance damage greatly. In this paper, we develop a toolkit for users to easily quantize their models for inference, in which Self-Adaptive Mixed-Precision (SAMP) is proposed to automatically control quantization rate by a mixed-precision architecture to balance model accuracy and efficiency. Experimental results show that our SAMP toolkit has a higher speedup than PyTorch and FasterTransformer while ensuring the required accuracy. In addition, SAMP is based on a modular design, decoupling the tokenizer, embedding, encoder and target layers, which allows users to handle various downstream tasks and can be seamlessly integrated into PyTorch. | Rong Tian, Zijing Zhao, Weijie Liu, Haoyan Liu, Weiquan Mao, Zhe Zhao, Kan Zhou |  |
| 68 |  |  [KD-Boost: Boosting Real-Time Semantic Matching in E-commerce with Knowledge Distillation](https://doi.org/10.18653/v1/2023.emnlp-industry.14) |  | 0 | Real-time semantic matching is vital to web and product search. Transformer-based models have shown to be highly effective at encoding queries into an embedding space where semantically similar entities (queries or results) are in close proximity. However, the computational complexity of large transformer models limits their utilization for real-time matching. In this paper, we propose KD-Boost, a novel knowledge distillation algorithm designed for real-time semantic matching. KD-Boost trains low latency accurate student models by leveraging soft labels from a teacher model as well as ground truth via pairwise query-product and query-query signal derived from direct audits, user behavior, and taxonomy-based data using custom loss functions. Experiments on internal and external e-commerce datasets demonstrate an improvement of 2-3% ROC-AUC compared to training student models directly, outperforming teacher and SOTA knowledge distillation benchmarks. Simulated online A/B tests using KD-Boost for automated Query Reformulation (QR) indicate a 6.31% increase in query-to-query matching, 2.76% increase in product coverage, and a 2.19% improvement in relevance. | Sanjay Agrawal, Vivek Sembium, Ankith M. S |  |
| 69 |  |  [Multi-teacher Distillation for Multilingual Spelling Correction](https://doi.org/10.18653/v1/2023.emnlp-industry.15) |  | 0 | Accurate spelling correction is a critical step in modern search interfaces, especially in an era of mobile devices and speech-to-text interfaces. For services that are deployed around the world, this poses a significant challenge for multilingual NLP: spelling errors need to be caught and corrected in all languages, and even in queries that use multiple languages. In this paper, we tackle this challenge using multi-teacher distillation. On our approach, a monolingual teacher model is trained for each language/locale, and these individual models are distilled into a single multilingual student model intended to serve all languages/locales. In experiments using open-source data as well as customer data from a worldwide search service, we show that this leads to highly effective spelling correction models that can meet the tight latency requirements of deployed services. | Jingfen Zhang, Xuan Guo, Sravan Bodapati, Christopher Potts |  |
| 70 |  |  [Does Named Entity Recognition Truly Not Scale Up to Real-world Product Attribute Extraction?](https://doi.org/10.18653/v1/2023.emnlp-industry.16) |  | 0 | The key challenge in the attribute-value extraction (AVE) task from e-commerce sites is the scalability to diverse attributes for a large number of products in real-world e-commerce sites. To make AVE scalable to diverse attributes, recent researchers adopted a question-answering (QA)-based approach that additionally inputs the target attribute as a query to extract its values, and confirmed its advantage over a classical approach based on named-entity recognition (NER) on real-word e-commerce datasets. In this study, we argue the scalability of the NER-based approach compared to the QA-based approach, since researchers have compared BERT-based QA-based models to only a weak BiLSTM-based NER baseline trained from scratch in terms of only accuracy on datasets designed to evaluate the QA-based approach. Experimental results using a publicly available real-word dataset revealed that, under a fair setting, BERT-based NER models rival BERT-based QA models in terms of the accuracy, and their inference is faster than the QA model that processes the same product text several times to handle multiple target attributes. | WeiTe Chen, Keiji Shinzato, Naoki Yoshinaga, Yandi Xia |  |
| 71 |  |  [Investigating Table-to-Text Generation Capabilities of Large Language Models in Real-World Information Seeking Scenarios](https://doi.org/10.18653/v1/2023.emnlp-industry.17) |  | 0 | Tabular data is prevalent across various industries, necessitating significant time and effort for users to understand and manipulate for their information-seeking purposes. The advancements in large language models (LLMs) have shown enormous potential to improve user efficiency. However, the adoption of LLMs in real-world applications for table information seeking remains underexplored. In this paper, we investigate the table-to-text capabilities of different LLMs using four datasets within two real-world information seeking scenarios. These include the LogicNLG and our newly-constructed LoTNLG datasets for data insight generation, along with the FeTaQA and our newly-constructed F2WTQ datasets for query-based generation. We structure our investigation around three research questions, evaluating the performance of LLMs in table-to-text generation, automated evaluation, and feedback generation, respectively. Experimental results indicate that the current high-performing LLM, specifically GPT-4, can effectively serve as a table-to-text generator, evaluator, and feedback generator, facilitating users’ information seeking purposes in real-world scenarios. However, a significant performance gap still exists between other open-sourced LLMs (e.g., Vicuna and LLaMA-2) and GPT-4 models. Our data and code are publicly available at https://github.com/yale-nlp/LLM-T2T. | Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, Arman Cohan |  |
| 72 |  |  [TMID: A Comprehensive Real-world Dataset for Trademark Infringement Detection in E-Commerce](https://doi.org/10.18653/v1/2023.emnlp-industry.18) |  | 0 | Annually, e-commerce platforms incur substantial financial losses due to trademark infringements, making it crucial to identify and mitigate potential legal risks tied to merchant information registered to the platforms. However, the absence of high-quality datasets hampers research in this area. To address this gap, our study introduces TMID, a novel dataset to detect trademark infringement in merchant registrations. This is a real-world dataset sourced directly from Alipay, one of the world’s largest e-commerce and digital payment platforms. As infringement detection is a legal reasoning task requiring an understanding of the contexts and legal rules, we offer a thorough collection of legal rules and merchant and trademark-related contextual information with annotations from legal experts. We ensure the data quality by performing an extensive statistical analysis. Furthermore, we conduct an empirical study on this dataset to highlight its value and the key challenges. Through this study, we aim to contribute valuable resources to advance research into legal compliance related to trademark infringement within the e-commerce sphere. | Tongxin Hu, Zhuang Li, Xin Jin, Lizhen Qu, Xin Zhang |  |
| 73 |  |  [Joint Dialogue Topic Segmentation and Categorization: A Case Study on Clinical Spoken Conversations](https://doi.org/10.18653/v1/2023.emnlp-industry.19) |  | 0 | Utilizing natural language processing techniques in clinical conversations is effective to improve the efficiency of health management workflows for medical staff and patients. Dialogue segmentation and topic categorization are two fundamental steps for processing verbose spoken conversations and highlighting informative spans for downstream tasks. However, in practical use cases, due to the variety of segmentation granularity and topic definition, and the lack of diverse annotated corpora, no generic models are readily applicable for domain-specific applications. In this work, we introduce and adopt a joint model for dialogue segmentation and topic categorization, and conduct a case study on healthcare follow-up calls for diabetes management; we provide insights from both data and model perspectives toward performance and robustness. | Zhengyuan Liu, Siti Umairah Md. Salleh, Hong Choon Oh, Pavitra Krishnaswamy, Nancy F. Chen |  |
| 74 |  |  [AdapterDistillation: Non-Destructive Task Composition with Knowledge Distillation](https://doi.org/10.18653/v1/2023.emnlp-industry.20) |  | 0 | Leveraging knowledge from multiple tasks through introducing a small number of task specific parameters into each transformer layer, also known as adapters, receives much attention recently. However, adding an extra fusion layer to implement knowledge composition not only increases the inference time but also is non-scalable for some applications. To avoid these issues, we propose a two-stage knowledge distillation algorithm called AdapterDistillation. In the first stage, we extract task specific knowledge by using local data to train a student adapter. In the second stage, we distill the knowledge from the existing teacher adapters into the student adapter to help its inference. Extensive experiments on frequently asked question retrieval in task-oriented dialog systems validate the efficiency of AdapterDistillation. We show that AdapterDistillation outperforms existing algorithms in terms of accuracy, resource consumption and inference time. | Junjie Wang, Yicheng Chen, Wangshu Zhang, Sen Hu, Teng Xu, Jing Zheng |  |
| 75 |  |  [PROMINET: Prototype-based Multi-View Network for Interpretable Email Response Prediction](https://doi.org/10.18653/v1/2023.emnlp-industry.21) |  | 0 | Email is a widely used tool for business communication, and email marketing has emerged as a cost-effective strategy for enterprises. While previous studies have examined factors affecting email marketing performance, limited research has focused on understanding email response behavior by considering email content and metadata. This study proposes a Prototype-based Multi-view Network (PROMINET) that incorporates semantic and structural information from email data. By utilizing prototype learning, the PROMINET model generates latent exemplars, enabling interpretable email response prediction. The model maps learned semantic and structural exemplars to observed samples in the training data at different levels of granularity, such as document, sentence, or phrase. The approach is evaluated on two real-world email datasets: the Enron corpus and an in-house Email Marketing corpus. Experimental results demonstrate that the PROMINET model outperforms baseline models, achieving a ~3% improvement in F1 score on both datasets. Additionally, the model provides interpretability through prototypes at different granularity levels while maintaining comparable performance to non-interpretable models. The learned prototypes also show potential for generating suggestions to enhance email text editing and improve the likelihood of effective email responses. This research contributes to enhancing sender-receiver communication and customer engagement in email interactions. | Yuqing Wang, Prashanth Vijayaraghavan, Ehsan Degan |  |
| 76 |  |  [Retrieval-Enhanced Dual Encoder Training for Product Matching](https://doi.org/10.18653/v1/2023.emnlp-industry.22) |  | 0 | Product matching is the task of matching a seller-listed item to an appropriate product. It is a critical task for an e-commerce platform, and the approach needs to be efficient to run in a large-scale setting. A dual encoder approach has been a common practice for product matching recently, due to its high performance and computation efficiency. In this paper, we propose a two-stage training for the dual encoder model. Stage 1 trained a dual encoder to identify the more informative training data. Stage 2 then train on the more informative data to get a better dual encoder model. This technique is a learned approach for building training data. We evaluate the retrieval-enhanced training on two different datasets: a publicly available Large-Scale Product Matching dataset and a real-world e-commerce dataset containing 47 million products. Experiment results show that our approach improved by 2% F1 on the public dataset and 9% F1 on the real-world e-commerce dataset. | Justin Chiu |  |
| 77 |  |  [WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-industry.23) |  | 0 | This paper introduces WordArt Designer, a user-driven framework for artistic typography synthesis, relying on the Large Language Model (LLM). The system incorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo modules. 1) The LLM Engine, empowered by the LLM (e.g. GPT-3.5), interprets user inputs and generates actionable prompts for the other modules, thereby transforming abstract concepts into tangible designs. 2) The SemTypo module optimizes font designs using semantic concepts, striking a balance between artistic transformation and readability. 3) Building on the semantic layout provided by the SemTypo module, the StyTypo module creates smooth, refined images. 4) The TexTypo module further enhances the design’s aesthetics through texture rendering, enabling the generation of inventive textured fonts. Notably, WordArt Designer highlights the fusion of generative AI with artistic typography. Experience its capabilities on ModelScope: https://www.modelscope.cn/studios/WordArt/WordArt. | JunYan He, ZhiQi Cheng, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Yusen Hu, Bin Luo, Yifeng Geng, Xuansong Xie |  |
| 78 |  |  [Lattice Path Edit Distance: A Romanization-aware Edit Distance for Extracting Misspelling-Correction Pairs from Japanese Search Query Logs](https://doi.org/10.18653/v1/2023.emnlp-industry.24) |  | 0 | Edit distance has been successfully used to extract training data, i.e., misspelling-correction pairs, of spelling correction models from search query logs in languages including English. However, the success does not readily apply to Japanese, where misspellings are often dissimilar to correct spellings due to the romanization-based input methods. To address this problem, we introduce lattice path edit distance, which utilizes romanization lattices to efficiently consider all possible romanized forms of input strings. Empirical experiments using Japanese search query logs demonstrated that the lattice path edit distance outperformed baseline methods including the standard edit distance combined with an existing transliterator and morphological analyzer. A training data collection pipeline that uses the lattice path edit distance has been deployed in production at our search engine for over a year. | Nobuhiro Kaji |  |
| 79 |  |  [Learning Multilingual Sentence Representations with Cross-lingual Consistency Regularization](https://doi.org/10.18653/v1/2023.emnlp-industry.25) |  | 0 | Multilingual sentence representations are the foundation for similarity-based bitext mining, which is crucial for scaling multilingual neural machine translation (NMT) system to more languages. In this paper, we introduce MuSR: a one-for-all Multilingual Sentence Representation model that supports 223 languages. Leveraging billions of English-centric parallel corpora, we train a multilingual Transformer encoder, coupled with an auxiliary Transformer decoder, by adopting a multilingual NMT framework with CrossConST, a cross-lingual consistency regularization technique proposed in Gao et al. (2023). Experimental results on multilingual similarity search and bitext mining tasks show the effectiveness of our approach. Specifically, MuSR achieves superior performance over LASER3 (Heffernan et al., 2022) which consists of 148 independent multilingual sentence encoders. | Pengzhi Gao, Liwen Zhang, Zhongjun He, Hua Wu, Haifeng Wang |  |
| 80 |  |  [Unveiling Identity Biases in Toxicity Detection : A Game-Focused Dataset and Reactivity Analysis Approach](https://doi.org/10.18653/v1/2023.emnlp-industry.26) |  | 0 | Identity biases arise commonly from annotated datasets, can be propagated in language models and can cause further harm to marginal groups. Existing bias benchmarking datasets are mainly focused on gender or racial biases and are made to pinpoint which class the model is biased towards. They also are not designed for the gaming industry, a concern for models built for toxicity detection in videogames’ chat. We propose a dataset and a method to highlight oversensitive terms using reactivity analysis and the model’s performance. We test our dataset against ToxBuster, a language model developed by Ubisoft fine-tuned for toxicity detection on multiplayer videogame’s written chat, and Perspective API. We find that these toxicity models often automatically tag terms related to a community’s identity as toxic, which prevents members of already marginalized groups to make their presence known or have a mature / normal conversation. Through this process, we have generated an interesting list of terms that trigger the models to varying degrees, along with insights on establishing a baseline through human annotations. | Josiane Van Dorpe, Zachary Yang, Nicolas GrenonGodbout, Grégoire Winterstein |  |
| 81 |  |  [ORANGE: Text-video Retrieval via Watch-time-aware Heterogeneous Graph Contrastive Learning](https://doi.org/10.18653/v1/2023.emnlp-industry.27) |  | 0 | With the explosive growth of short-video data on industrial video-sharing platforms such as TikTok and YouTube, text-video retrieval techniques have become increasingly important. Most existing works for text-video retrieval focus on designing informative representation learning methods and delicate matching mechanisms, which leverage the content information of queries and videos themselves (i.e., textual information of queries and multimodal information of videos). However, real-world scenarios often involve brief, ambiguous queries and low-quality videos, making content-based retrieval less effective. In order to accommodate various search requirements and enhance user satisfaction, this study introduces a novel Text-video Retrieval method via Watch-time-aware Heterogeneous Graph Contrastive Learning (termed ORANGE). This approach aims to learn informative embeddings for queries and videos by leveraging both content information and the abundant relational information present in video-search scenarios. Specifically, we first construct a heterogeneous information graph where nodes represent domain objects (e.g., query, video, tag) and edges represent rich relations among these objects. Afterwards, a meta-path-guided heterogeneous graph attention encoder with the awareness of video watch time is devised to encode various semantic aspects of query and video nodes. To train our model, we introduce a meta-path-wise contrastive learning paradigm that facilitates capturing dependencies across multiple semantic relations, thereby enhancing the obtained embeddings. Finally, when deployed online, for new queries non-existent in the constructed graph, a bert-based query encoder distilled from our ORANGE is employed. Offline experiments conducted on a real-world dataset demonstrate the effectiveness of our ORANGE. Moreover, it has been implemented in the matching stage of an industrial online video-search service, where it exhibited statistically significant improvements over the online baseline in an A/B test. | Yucheng Lin, Tim Chang, Yaning Chang, Jianqiang Ma, Donghui Li, Ting Peng, Zang Li, Zhiyi Zhou, Feng Wang |  |
| 82 |  |  [Compute-Efficient Churn Reduction for Conversational Agents](https://doi.org/10.18653/v1/2023.emnlp-industry.28) |  | 0 | Model churn occurs when re-training a model yields different predictions despite using the same data and hyper-parameters. Churn reduction is crucial for industry conversational systems where users expect consistent results for the same queries. In this setting, compute resources are often limited due to latency requirements during serving and overall time constraints during re-training. To address this issue, we propose a compute-efficient method that mitigates churn without requiring extra resources for training or inference. Our approach involves a lightweight data pre-processing step that pairs semantic parses based on their “function call signature” and encourages similarity through an additional loss based on Jensen-Shannon Divergence. We validate the effectiveness of our method in three scenarios: academic (+3.93 percent improvement on average in a churn reduction metric), simulated noisy data (+8.09), and industry (+5.28) settings. | Christopher Hidey, Sarthak Sarthak |  |
| 83 |  |  [Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering](https://doi.org/10.18653/v1/2023.emnlp-industry.29) |  | 0 | Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average due to its lack of specific domain knowledge. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, centered around Microsoft products and IT technical problems encountered by customers. This dataset contains industry cloud-specific QA knowledge, an area not extensively covered in general LLMs, making it well-suited for evaluating methods aiming to enhance LLMs’ domain-specific capabilities. In addition, we propose a new model interaction paradigm that can empower LLM to achieve better performance on domain-specific tasks where it is not proficient. Extensive experiments demonstrate that the approach following our method outperforms the commonly used LLM with retrieval methods. We make our source code and sample data available at: https://aka.ms/Microsoft_QA. | Fangkai Yang, Pu Zhao, Zezhong Wang, Lu Wang, Bo Qiao, Jue Zhang, Mohit Garg, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang |  |
| 84 |  |  [Enhancing Extreme Multi-Label Text Classification: Addressing Challenges in Model, Data, and Evaluation](https://doi.org/10.18653/v1/2023.emnlp-industry.30) |  | 0 | Extreme multi-label text classification is a prevalent task in industry, but it frequently encounters challenges in terms of machine learning perspectives, including model limitations, data scarcity, and time-consuming evaluation. This paper aims to mitigate these issues by introducing novel approaches. Firstly, we propose a label ranking model as an alternative to the conventional SciBERT-based classification model, enabling efficient handling of large-scale labels and accommodating new labels. Secondly, we present an active learning-based pipeline that addresses the data scarcity of new labels during the update of a classification system. Finally, we introduce ChatGPT to assist with model evaluation. Our experiments demonstrate the effectiveness of these techniques in enhancing the extreme multi-label text classification task. | Dan Li, Zi Long Zhu, Janneke van de Loo, Agnes Masip Gomez, Vikrant Yadav, Georgios Tsatsaronis, Zubair Afzal |  |
| 85 |  |  [Query-aware Multi-modal based Ranking Relevance in Video Search](https://doi.org/10.18653/v1/2023.emnlp-industry.31) |  | 0 | Relevance ranking system plays a crucial role in video search on streaming platforms. Most relevance ranking methods focus on text modality, incapable of fully exploiting cross-modal cues present in video. Recent multi-modal models have demonstrated promise in various vision-language tasks but provide limited help for downstream query-video relevance tasks due to the discrepency between relevance ranking-agnostic pre-training objectives and the real video search scenarios that demand comprehensive relevance modeling. To address these challenges, we propose a QUery-Aware pre-training model with multi-modaLITY (QUALITY) that incorporates hard-mined query information as alignment targets and utilizes video tag information for guidance. QUALITY is integrated into our relevance ranking model, which leverages multi-modal knowledge and improves ranking optimization method based on ordinal regression. Extensive experiments show our proposed model significantly enhances video search performance. | Chengcan Ye, Ting Peng, Tim Chang, Zhiyi Zhou, Feng Wang |  |
| 86 |  |  [Coordinated Replay Sample Selection for Continual Federated Learning](https://doi.org/10.18653/v1/2023.emnlp-industry.32) |  | 0 | Continual Federated Learning (CFL) combines Federated Learning (FL), the decentralized learning of a central model on a number of client devices that may not communicate their data, and Continual Learning (CL), the learning of a model from a continual stream of data without keeping the entire history. In CL, the main challenge is forgetting what was learned from past data. While replay-based algorithms that keep a small pool of past training data are effective to reduce forgetting, only simple replay sample selection strategies have been applied to CFL in prior work, and no previous work has explored coordination among clients for better sample selection. To bridge this gap, we adapt a replay sample selection objective based on loss gradient diversity to CFL and propose a new relaxation-based selection of samples to optimize the objective. Next, we propose a practical algorithm to coordinate gradient-based replay sample selection across clients without communicating private data. We benchmark our coordinated and uncoordinated replay sample selection algorithms against random sampling-based baselines with language models trained on a large scale de-identified real-world text dataset. We show that gradient-based sample selection methods both boost performance and reduce forgetting compared to random sampling methods, with our coordination method showing gains early in the low replay size regime (when the budget for storing past data is small). | Jack Good, Jimit Majmudar, Christophe Dupuy, Jixuan Wang, Charith Peris, Clement Chung, Richard S. Zemel, Rahul Gupta |  |
| 87 |  |  [Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective](https://doi.org/10.18653/v1/2023.emnlp-industry.33) |  | 0 | This paper studies how to effectively build meeting summarization systems for real-world usage using large language models (LLMs). For this purpose, we conduct an extensive evaluation and comparison of various closed-source and open-source LLMs, namely, GPT-4, GPT-3.5, PaLM-2, and LLaMA-2. Our findings reveal that most closed-source LLMs are generally better in terms of performance. However, much smaller open-source models like LLaMA-2 (7B and 13B) could still achieve performance comparable to the large closed-source models even in zero-shot scenarios. Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models, the opensource models that can achieve competitive performance are more advantageous for industrial use. Balancing performance with associated costs and privacy concerns, the LLaMA-2-7B model looks more promising for industrial usage. In sum, this paper offers practical insights on using LLMs for real-world business meeting summarization, shedding light on the trade-offs between performance and cost. | Md. Tahmid Rahman Laskar, XueYong Fu, Cheng Chen, Shashi Bhushan TN |  |
| 88 |  |  [Creator Context for Tweet Recommendation](https://doi.org/10.18653/v1/2023.emnlp-industry.34) |  | 0 | When discussing a tweet, people usually not only refer to the content it delivers, but also to the person behind the tweet. In other words, grounding the interpretation of the tweet in the context of its creator plays an important role in deciphering the true intent and the importance of the tweet. In this paper, we attempt to answer the question of how creator context should be used to advance tweet understanding. Specifically, we investigate the usefulness of different types of creator context, and examine different model structures for incorporating creator context in tweet modeling. We evaluate our tweet understanding models on a practical use case – recommending relevant tweets to news articles. This use case already exists in popular news apps, and can also serve as a useful assistive tool for journalists. We discover that creator context is essential for tweet understanding, and can improve application metrics by a large margin. However, we also observe that not all creator contexts are equal. Creator context can be time sensitive and noisy. Careful creator context selection and deliberate model structure design play an important role in creator context effectiveness. | Spurthi Amba Hombaiah, Tao Chen, Mingyang Zhang, Michael Bendersky, Marc Najork, Matt Colen, Sergey Levi, Vladimir Ofitserov, Tanvir Amin |  |
| 89 |  |  [AdaBERT-CTC: Leveraging BERT-CTC for Text-Only Domain Adaptation in ASR](https://doi.org/10.18653/v1/2023.emnlp-industry.35) |  | 0 | End-to-end (E2E) automatic speech recognition (ASR) models are becoming increasingly popular in commercial applications, such as virtual assistants, closed captioning, and dictation systems. The accuracy of the ASR is crucial to their success. However, E2E models still struggle to recognize out-of-domain words such as proper nouns and domain-specific terms. In this paper we introduce AdaBERT-CTC, a domain adaptation technique that relies solely on textual data. Our method allows for text-only adaptation by fine-tuning a pre-trained self-supervised text encoder model. Additionally, we show that our method can be made parameter-efficient by adding bottleneck adapters to the pre-trained model. This allows for adaptation with less than a 5% increase in parameters and minimal computational overhead during inference. We demonstrate that our approach outperforms the base BERT-CTC model by up to 14% relative word error rate improvement on several out-of-domain, publicly available datasets. | Tyler Vuong, Karel Mundnich, Dhanush Bekal, Veera Raghavendra Elluru, Srikanth Ronanki, Sravan Bodapati |  |
| 90 |  |  [Conversing with databases: Practical Natural Language Querying](https://doi.org/10.18653/v1/2023.emnlp-industry.36) |  | 0 | In this work, we designed, developed and released in production DataQue – a hybrid NLQ (Natural Language Querying) system for conversational DB querying. We address multiple practical problems that are not accounted for in public Text-to-SQL solutions – numerous complex implied conditions in user questions, jargon and abbreviations, custom calculations, non-SQL operations, a need to inject all those into pipeline fast and to have guaranteed parsing results for demanding users, cold-start problem. The DataQue processing pipeline for Text-to-SQL translation consists of 10-15 model-based and rule-based components that allows to tightly control the processing. | Denis Kochedykov, Fenglin Yin, Sreevidya Khatravath |  |
| 91 |  |  [AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications](https://doi.org/10.18653/v1/2023.emnlp-industry.37) |  | 0 | Adversarially testing large language models (LLMs) is crucial for their safe and responsible deployment in practice. We introduce an AI-assisted approach for automated generation of adversarial evaluation datasets to test the safety of LLM generations on new downstream applications. We call it AART AI-assisted Red-Teaming - an automated alternative to current manual red-teaming efforts. AART offers a data generation and augmentation pipeline of reusable and customizable recipes that reduce significantly human effort and enable integration of adversarial testing earlier in new product development. AART generates evaluation datasets with high diversity of content characteristics critical for effective adversarial testing (e.g. sensitive and harmful concepts, specific to a wide range of cultural and geographic regions and application scenarios). The data generation is steered by AI-assisted recipes to define, scope and prioritize diversity within a new application context. This feeds into a structured LLM-generation process that scales up evaluation priorities. This provides transparency of developers evaluation intentions and enables quick adaptation to new use cases and newly discovered model weaknesses. Compared to some of the state-of-the-art tools AART shows promising results in terms of concept coverage and data quality. | Bhaktipriya Radharapu, Kevin Robinson, Lora Aroyo, Preethi Lahoti |  |
| 92 |  |  [Speakerly: A Voice-based Writing Assistant for Text Composition](https://doi.org/10.18653/v1/2023.emnlp-industry.38) |  | 0 | We present Speakerly, a new real-time voice-based writing assistance system that helps users with text composition across various use cases such as emails, instant messages, and notes. The user can interact with the system through instructions or dictation, and the system generates a well-formatted and coherent document. We describe the system architecture and detail how we address the various challenges while building and deploying such a system at scale. More specifically, our system uses a combination of small, task-specific models as well as pre-trained language models for fast and effective text composition while supporting a variety of input modes for better usability. | Dhruv Kumar, Vipul Raheja, Alice KaiserSchatzlein, Robyn Perry, Apurva Joshi, Justin HuguesNuger, Samuel Lou, Navid Chowdhury |  |
| 93 |  |  [Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks](https://doi.org/10.18653/v1/2023.emnlp-industry.39) |  | 0 | The most recent large language models (LLMs) such as ChatGPT and GPT-4 have shown exceptional capabilities of generalist models, achieving state-of-the-art performance on a wide range of NLP tasks with little or no adaptation. How effective are such models in the finance domain? Understanding this basic question would have a significant impact on many downstream financial analytical tasks. In this paper, we conduct empirical studies and provide experimental evidences of their performance on a wide variety of financial text analytical problems, using eight benchmark datasets from five categories of tasks. We report both the strengths and limitations of the current models by comparing them to the state-of-the-art fine-tuned approaches and the recently released domain-specific pretrained models. We hope our study can help to understand the capability of the existing models in the financial domain and facilitate further improvements. | Xianzhi Li, Samuel Chan, Xiaodan Zhu, Yulong Pei, Zhiqiang Ma, Xiaomo Liu, Sameena Shah |  |
| 94 |  |  [CL-QR: Cross-Lingual Enhanced Query Reformulation for Multi-lingual Conversational AI Agents](https://doi.org/10.18653/v1/2023.emnlp-industry.40) |  | 0 | The growing popularity of conversational AI agents such as Alexa, Google Assistant, and Siri rely on accurate spoken language comprehension. The query reformulation (QR) method, which reformulates defective user queries, has been broadly adopted to mitigate the challenges posed by understanding user’s intent from imperfect spoken recognition result. However, due to the scarcity of non-English QR labels, providing high-quality QR for non-English users still remains a challenge. This work proposes a novel cross-lingual QR framework, CL-QR, to leverage the abundant reformulation resources in English to improve non-English QR performance. The proposed work also proposes a Module-wise Mutually-supervised Feedback learning (MMF) algorithm to enable the continually self-improving of the CL-QR, which alleviates the lack of cross-lingual QR training data and enhances the delivery of high-quality reformulations learned in English for multilingual queries. Both offline evaluation and online A/B testing demonstrates the effectiveness of the proposed method. | Zhongkai Sun, Zhengyang Zhao, Sixing Lu, Chengyuan Ma, Xiaohu Liu, Xing Fan, Wei Shen, Chenlei Guo |  |
| 95 |  |  [Improving Contextual Query Rewrite for Conversational AI Agents through User-preference Feedback Learning](https://doi.org/10.18653/v1/2023.emnlp-industry.41) |  | 0 | Contextual query rewriting (CQR) is a crucial component in Conversational AI agents, leveraging the contextual information from previous user-agent conversations to improve the comprehension of current user intent. However, traditional CQR methods often concentrate on supervised fine-tuning only, neglecting the opportunities to learn from user feedback to align with user preferences. Inspired by recent advances in learning from human feedback (LHF), this paper proposes a novel Preference Aligned Contextual Query Rewriting (PA-CQR) framework to enhance the CQR model’s capability in generating user preference-aligned rewrites. This paper also investigates the efficacy of various state-of-the-art feedback learning algorithms on the CQR task, and proposes a novel Dynamic Direct Preference Optimization (Dynamic DPO) algorithm to better adapt the DPO algorithm to large-scale CQR training. Experiments on large-scale real-world CQR data set demonstrate the superiority of the proposed PA-CQR framework and the Dynamic DPO. | Zhongkai Sun, Yingxue Zhou, Jie Hao, Xing Fan, Yanbin Lu, Chengyuan Ma, Wei Shen, Chenlei Guo |  |
| 96 |  |  [Scaling Neural ITN for Numbers and Temporal Expressions in Tamil: Findings for an Agglutinative Low-resource Language](https://doi.org/10.18653/v1/2023.emnlp-industry.42) |  | 0 | ITN involves rewriting the verbalised form of text from spoken transcripts to its corresponding written form. The task inherently expects challenges in identifying ITN entries due to spelling variations in words arising out of dialects, transcription errors etc. Additionally, in Tamil, word boundaries between adjacent words in a sentence often get obscured due to Punarchi, i.e. phonetic transformation of these boundaries. Being morphologically rich, the words in Tamil show a high degree of agglutination due to inflection and clitics. The combination of such factors leads to a high degree of surface-form variations, making scalability with pure rule-based approaches difficult. Instead, we experiment with fine-tuning three pre-trained neural LMs, consisting of a seq2seq model (s2s), a non-autoregressive text editor (NAR) and a sequence tagger + rules combination (tagger). While the tagger approach works best in a fully-supervised setting, s2s performs the best (98.05 F-Score) when augmented with additional data, via bootstrapping and data augmentation (DA&B). S2S reports a cumulative percentage improvement of 20.1 %, and statistically significant gains for all our models with DA&B. Compared to a fully supervised setup, bootstrapping alone reports a percentage improvement as high as 14.12 %, even with a small seed set of 324 ITN entries. | Bhavuk Singhal, Sindhuja Gopalan, Amrith Krishna, Malolan Chetlur |  |
| 97 |  |  [EELBERT: Tiny Models through Dynamic Embeddings](https://doi.org/10.18653/v1/2023.emnlp-industry.43) |  | 0 | We introduce EELBERT, an approach for compression of transformer-based models (e.g., BERT), with minimal impact on the accuracy of downstream tasks. This is achieved by replacing the input embedding layer of the model with dynamic, i.e. on-the-fly, embedding computations. Since the input embedding layer occupies a large portion of the model size, especially for the smaller BERT variants, replacing this layer with an embedding computation function helps us reduce the model size significantly. Empirical evaluation on the GLUE benchmark shows that our BERT variants (EELBERT) suffer minimal regression compared to the traditional BERT models. Through this approach, we are able to develop our smallest model UNO-EELBERT, which achieves a GLUE score within 4% of fully trained BERT-tiny, while being 15x smaller (1.2 MB) in size. | Gabrielle Cohn, Rishika Agarwal, Deepanshu Gupta, Siddharth Patwardhan |  |
| 98 |  |  [Gold Standard Bangla OCR Dataset: An In-Depth Look at Data Preprocessing and Annotation Processes](https://doi.org/10.18653/v1/2023.emnlp-industry.44) |  | 0 | This research paper focuses on developing an improved Bangla Optical Character Recognition (OCR) system, addressing the challenges posed by the complexity of Bangla text structure, diverse handwriting styles, and the scarcity of comprehensive datasets. Leveraging recent advancements in Deep Learning and OCR techniques, we anticipate a significant enhancement in the performance of Bangla OCR by utilizing a large and diverse collection of labeled Bangla text image datasets. This study introduces the most extensive gold standard corpus for Bangla characters and words, comprising over 4 million human-annotated images. Our dataset encompasses various document types, such as Computer Compose, Letterpress, Typewriters, Outdoor Banner-Poster, and Handwritten documents, gathered from diverse sources. The entire corpus has undergone meticulous human annotation, employing a controlled annotation procedure consisting of three-step annotation and one-step validation, ensuring adherence to gold standard criteria. This paper provides a comprehensive overview of the complete data collection procedure. The ICT Division, Government of the People’s Republic of Bangladesh, will make the dataset publicly available, facilitating further research and development in Bangla OCR and related domains. | Hasmot Ali, AKM Shahariar Azad Rabby, Md. Majedul Islam, A. k. m Mahamud, Nazmul Hasan, Fuad Rahman |  |
| 99 |  |  [PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching](https://doi.org/10.18653/v1/2023.emnlp-industry.45) |  | 0 | Instruction fine-tuning has conventionally been employed to adapt Large Language Models (LLMs) to a variety of diverse tasks. Nonetheless, this technique often necessitates substantial computational resources, making it impractical for deployment by individuals or small-scale entities. Recently, Low-Rank Adaptation (LoRA) has become a promising alternative, offering tuning capabilities with reduced resource overhead. However, attaining satisfactory performance through the fine-tuning of LoRA is a non-trivial challenge. In this paper, we propose PILLOW, which aims to improve LoRA’s performance by leveraging LLM’s in-context learning capability through prompt matching via reinforcement learning in resource-constrained environments. Specifically, PILLOW incorporates a matching network that selects prompts from a user-defined pool, concatenates the optimal prompts given the user instruction, and performs inference using the LoRA-fine-tuned LLMs. Compared with typical instruction fine-tuning methods, PILLOW exhibits commensurate performance on various evaluation metrics, utilizing only consumer-grade GPU resources and exhibiting a large increase in training efficiency. | Zhenting Qi, Xiaoyu Tan, Shaojie Shi, Chao Qu, Yinghui Xu, Yuan Qi |  |
| 100 |  |  [Welcome to the Real World: Efficient, Incremental and Scalable Key Point Analysis](https://doi.org/10.18653/v1/2023.emnlp-industry.46) |  | 0 | Key Point Analysis (KPA) is an emerging summarization framework, which extracts the main points from a collection of opinions, and quantifies their prevalence. It has been successfully applied to diverse types of data, including arguments, user reviews and survey responses. Despite the growing academic interest in KPA, little attention has been given to the practical challenges of implementing a KPA system in production. This work presents a deployed KPA system, which regularly serves multiple teams in our organization. We discuss the main challenges we faced while building a real-world KPA system, as well as the architecture and algorithmic improvements we developed to address these challenges. Specifically, we focus on efficient matching of sentences to key points, incremental processing, scalability and resiliency. The value of our contributions is demonstrated in an extensive set of experiments, over five existing and novel datasets. Finally, we describe several use cases of the deployed system, which illustrate its practical value. | Lilach Eden, Yoav Kantor, Matan Orbach, Yoav Katz, Noam Slonim, Roy BarHaim |  |
| 101 |  |  [Automatic Linking of Judgements to UK Supreme Court Hearings](https://doi.org/10.18653/v1/2023.emnlp-industry.47) |  | 0 | One the most important archived legal material in the UK is the Supreme Court published judgements and video recordings of court sittings for the decided cases. The impact of Supreme Court published material extends far beyond the parties involved in any given case as it provides landmark rulings on arguable points of law of the greatest public and constitutional importance. However, the recordings of a case are usually very long which makes it both time and effort consuming for legal professionals to study the critical arguments in the legal deliberations. In this research, we summarise the second part of a combined research-industrial project for building an automated tool designed specifically to link segments in the text judgement to semantically relevant timespans in the videos of the hearings. The tool is employed as a User-Interface (UI) platform that provides a better access to justice by bookmarking the timespans in the videos which contributed to the final judgement of the case. We explain how we employ AI generative technology to retrieve the relevant links and show that the customisation of the GPT text embeddings to our dataset achieves the best accuracy for our automatic linking system. | Hadeel Saadany, Constantin Orasan |  |
| 102 |  |  [Automatic Marketing Theme and Commodity Construction System for E-commerce](https://doi.org/10.18653/v1/2023.emnlp-industry.48) |  | 0 | When consumers’ shopping needs are concentrated, they are more interested in the collection of commodities under the specific marketing theme. Therefore, mining marketing themes and their commodities collections can help customers save shopping costs and improve user clicks and purchases for recommendation system. However, the current system invites experts to write marketing themes and select the relevant commodities, which suffer from difficulty in mass production, poor timeliness and low online indicators. Therefore, we propose a automatic marketing theme and commodity construction system, which can not only generate popular marketing themes and select the relevant commodities automatically, but also improve the theme online effectiveness in the recommendation system. Specifically, we firstly utilize the pretrained language model to generate the marketing themes. And then, we utilize the theme-commodity consistency module to select the relevant commodities for the above generative theme. What’s more, we also build the indicator simulator to evaluate the effectiveness of the above generative theme. When the indicator is lower, the above selective commodities will be input into the theme-rewriter module to generate more efficient marketing themes. Finally, we utilize the human screening to control the system quality. Both the offline experiments and online A/B test demonstrate the superior performance of our proposed system compared with state-of-the-art methods. | Zhiping Wang, Peng Lin, Hainan Zhang, Hongshen Chen, Tianhao Li, Zhuoye Ding, Sulong Xu, Jinghe Hu |  |
| 103 |  |  [Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures](https://doi.org/10.18653/v1/2023.emnlp-industry.49) |  | 0 | This paper introduces a new IncidentAI dataset for safety prevention. Different from prior corpora that usually contain a single task, our dataset comprises three tasks: named entity recognition, cause-effect extraction, and information retrieval. The dataset is annotated by domain experts who have at least six years of practical experience as high-pressure gas conservation managers. We validate the contribution of the dataset in the scenario of safety prevention. Preliminary results on the three tasks show that NLP techniques are beneficial for analyzing incident reports to prevent future failures. The dataset facilitates future research in NLP and incident management communities. The access to the dataset is also provided (The IncidentAI dataset is available at: https://github.com/Cinnamon/incident-ai-dataset). | Shumpei Inoue, MinhTien Nguyen, Hiroki Mizokuchi, TuanAnh D. Nguyen, HuuHiep Nguyen, Dung Le |  |
| 104 |  |  [An Auxiliary Task Boosted Multi-task Learning Method for Service Account Retrieval with Limited Human Annotation](https://doi.org/10.18653/v1/2023.emnlp-industry.50) |  | 0 | Service accounts, including organizations’ official accounts and mini-programs, provide various convenient services for users, and have become crucial components of a number of applications. Therefore, retrieving service accounts quickly and accurately is vital. However, this task suffers from the problem of limited human annotation, i.e., manually assessing account functionality and assigning ratings based on user experience is both labor-intensive and time-consuming. To this end, this paper proposes a novel approach, the Auxiliary task Boosted Multi-Task Learning method (AuxBoost-MTL). Specifically, the proposed method introduces multiple auxiliary tasks, which is able to utilized the log data from our application as supervision, and enhance the performance of the main task, service account retrieval. Furthermore, we introduce an Adaptive Hierarchical Fusion Module (AHF module) into our approach. This module is designed to adaptively perform hierarchical fusion of embeddings from auxiliary tasks into the main task, thereby enhancing the model efficacy. Experiments on two real-world industrial datasets demonstrate the effectiveness of our proposed approach. | Yuanzhou Yao, Zhao Zhang, Kaijia Yang, Huasheng Liang, Qiang Yan, Yongjun Xu |  |
| 105 |  |  [VKIE: The Application of Key Information Extraction on Video Text](https://doi.org/10.18653/v1/2023.emnlp-industry.51) |  | 0 | Extracting structured information from videos is critical for numerous downstream applications in the industry. In this paper, we define a significant task of extracting hierarchical key information from visual texts on videos. To fulfill this task, we decouple it into four subtasks and introduce two implementation solutions called PipVKIE and UniVKIE. PipVKIE sequentially completes the four subtasks in continuous stages, while UniVKIE is improved by unifying all the subtasks into one backbone. Both PipVKIE and UniVKIE leverage multimodal information from vision, text, and coordinates for feature representation. Extensive experiments on one well-defined dataset demonstrate that our solutions can achieve remarkable performance and efficient inference speed. | Siyu An, Ye Liu, Haoyuan Peng, Di Yin |  |
| 106 |  |  [Investigating the Role and Impact of Disfluency on Summarization](https://doi.org/10.18653/v1/2023.emnlp-industry.52) |  | 0 | Contact centers handle both chat and voice calls for the same domain. As part of their workflow, it is a standard practice to summarize the conversations once they conclude. A significant distinction between chat and voice communication lies in the presence of disfluencies in voice calls, such as repetitions, restarts, and replacements. These disfluencies are generally considered noise for downstream natural language understanding (NLU) tasks. While a separate summarization model for voice calls can be trained in addition to chat specific model for the same domain, it requires manual annotations for both the channels and adds complexity arising due to maintaining two models. Therefore, it’s crucial to investigate if a model trained on fluent data can handle disfluent data effectively. While previous research explored impact of disfluency on question-answering and intent detection, its influence on summarization is inadequately studied. Our experiments reveal up to 6.99-point degradation in Rouge-L score, along with reduced fluency, consistency, and relevance when a fluent-trained model handles disfluent data. Replacement disfluencies have the highest negative impact. To mitigate this, we examine Fused-Fine Tuning by training the model with a combination of fluent and disfluent data, resulting in improved performance on both public and real-life datasets. Our work highlights the significance of incorporating disfluency in training summarization models and its advantages in an industrial setting. | Varun Nathan, Ayush Kumar, Jithendra Vepa |  |
| 107 |  |  [InsightNet : Structured Insight Mining from Customer Feedback](https://doi.org/10.18653/v1/2023.emnlp-industry.53) |  | 0 | We propose InsightNet, a novel approach for the automated extraction of structured insights from customer reviews. Our end-to-end machine learning framework is designed to overcome the limitations of current solutions, including the absence of structure for identified topics, non-standard aspect names, and lack of abundant training data. The proposed solution builds a semi-supervised multi-level taxonomy from raw reviews, a semantic similarity heuristic approach to generate labelled data and employs a multi-task insight extraction architecture by fine-tuning an LLM. InsightNet identifies granular actionable topics with customer sentiments and verbatim for each topic. Evaluations on real-world customer review data show that InsightNet performs better than existing solutions in terms of structure, hierarchy and completeness. We empirically demonstrate that InsightNet outperforms the current state-of-the-art methods in multi-label topic classification, achieving an F1 score of 0.85, which is an improvement of 11% F1-score over the previous best results. Additionally, InsightNet generalises well for unseen aspects and suggests new topics to be added to the taxonomy. | Sandeep Sricharan Mukku, Manan Soni, Chetan Aggarwal, Jitenkumar Rana, Promod Yenigalla, Rashmi Patange, Shyam Mohan |  |
| 108 |  |  [E2E Spoken Entity Extraction for Virtual Agents](https://doi.org/10.18653/v1/2023.emnlp-industry.54) |  | 0 | In human-computer conversations, extracting entities such as names, street addresses and email addresses from speech is a challenging task. In this paper, we study the impact of fine-tuning pre-trained speech encoders on extracting spoken entities in human-readable form directly from speech without the need for text transcription. We illustrate that such a direct approach optimizes the encoder to transcribe only the entity relevant portions of speech ignoring the superfluous portions such as carrier phrases, or spell name entities. In the context of dialog from an enterprise virtual agent, we demonstrate that the 1-step approach outperforms the typical 2-step approach which first generates lexical transcriptions followed by text-based entity extraction for identifying spoken entities. | Karan Singla, YeonJun Kim, Srinivas Bangalore |  |
| 109 |  |  [Generative Models for Product Attribute Extraction](https://doi.org/10.18653/v1/2023.emnlp-industry.55) |  | 0 | Product attribute extraction is an emerging field in information extraction and e-commerce, with applications including knowledge base construction, product recommendation, and enhancing customer experiences. In this work, we explore the use of generative models for product attribute extraction. We analyze their utility with hard and soft prompting methods, and demonstrate their ability to generate implicit attribute values, which state-of-the-art sequence tagging models are unable to extract. We perform a wide range of experiments on Amazon and MAVE product attribute datasets, and are the first to present results on multilingual attribute extraction. Our results show that generative models can outperform state- of-the-art tagging models for explicit product attribute extraction while having greater data efficiency, that they have the unique ability to perform implicit attribute extraction, and that in certain settings large language models can perform competitively with finetuned models with as little as two in-context examples. | Ansel Blume, Nasser Zalmout, Heng Ji, Xian Li |  |
| 110 |  |  [CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering](https://doi.org/10.18653/v1/2023.emnlp-industry.56) |  | 0 | Large language models (LLMs) have demonstrated remarkable performance by following natural language instructions without fine-tuning them on domain-specific tasks and data. However, leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the lack of awareness about the domain and expected output, such LLMs may generate unexpected and unsafe answers that are not tailored to the target domain. In this paper, we propose CarExpert, an in-car retrieval-augmented conversational question-answering system leveraging LLMs for different tasks. Specifically, CarExpert employs LLMs to control the input, provide domain-specific documents to the extractive and generative answering components, and controls the output to ensure safe and domain-specific answers. A comprehensive empirical evaluation exhibits that CarExpert outperforms state-of-the-art LLMs in generating natural, safe and car-specific answers. | Md. Rashad Al Hasan Rony, Christian Suess, Sinchana Ramakanth Bhat, Viju Sudhi, Julia Schneider, Maximilian Vogel, Roman Teucher, Ken E. Friedl, Soumya R. Sahoo |  |
| 111 |  |  [BUSTER: a "BUSiness Transaction Entity Recognition" dataset](https://doi.org/10.18653/v1/2023.emnlp-industry.57) |  | 0 | Albeit Natural Language Processing has seen major breakthroughs in the last few years, transferring such advances into real-world business cases can be challenging. One of the reasons resides in the displacement between popular benchmarks and actual data. Lack of supervision, unbalanced classes, noisy data and long documents often affect real problems in vertical domains such as finance, law and health. To support industry-oriented research, we present BUSTER, a BUSiness Transaction Entity Recognition dataset. The dataset consists of 3779 manually annotated documents on financial transactions. We establish several baselines exploiting both general-purpose and domain-specific language models. The best performing model is also used to automatically annotate 6196 documents, which we release as an additional silver corpus to BUSTER. | Andrea Zugarini, Andrew Zamai, Marco Ernandes, Leonardo Rigutini |  |
| 112 |  |  [Multi-word Tokenization for Sequence Compression](https://doi.org/10.18653/v1/2023.emnlp-industry.58) |  | 0 | Large Language Models have proven highly successful at modelling a variety of tasks. However, this comes at a steep computational cost that hinders wider industrial uptake. In this paper, we present MWT: a Multi-Word Tokenizer that goes beyond word boundaries by representing frequent multi-word expressions as single tokens. MWTs produce a more compact and efficient tokenization that yields two benefits: (1) Increase in performance due to a greater coverage of input data given a fixed sequence length budget; (2) Faster and lighter inference due to the ability to reduce the sequence length with negligible drops in performance. Our results show that MWT is more robust across shorter sequence lengths, thus allowing for major speedups via early sequence truncation. | Leonidas Gee, Leonardo Rigutini, Marco Ernandes, Andrea Zugarini |  |
| 113 |  |  [JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization](https://doi.org/10.18653/v1/2023.emnlp-industry.59) |  | 0 | In this study, we introduce JarviX, a sophisticated data analytics framework. JarviX is designed to employ Large Language Models (LLMs) to facilitate an automated guide and execute high-precision data analyzes on tabular datasets. This framework emphasizes the significance of varying column types, capitalizing on state-of-the-art LLMs to generate concise data insight summaries, propose relevant analysis inquiries, visualize data effectively, and provide comprehensive explanations for results drawn from an extensive data analysis pipeline. Moreover, JarviX incorporates an automated machine learning (AutoML) pipeline for predictive modeling. This integration forms a comprehensive and automated optimization cycle, which proves particularly advantageous for optimizing machine configuration. The efficacy and adaptability of JarviX are substantiated through a series of practical use case studies. | Shangching Liu, Shengkun Wang, Tsungyao Chang, Wenqi Lin, ChungWei Hsiung, YiChen Hsieh, YuPing Cheng, SianHong Luo, Jianwei Zhang |  |
| 114 |  |  [Retrieve and Copy: Scaling ASR Personalization to Large Catalogs](https://doi.org/10.18653/v1/2023.emnlp-industry.60) |  | 0 | Personalization of automatic speech recognition (ASR) models is a widely studied topic because of its many practical applications. Most recently, attention-based contextual biasing techniques are used to improve the recognition of rare words and/or domain specific entities. However, due to performance constraints, the biasing is often limited to a few thousand entities, restricting real-world usability. To address this, we first propose a “Retrieve and Copy” mechanism to improve latency while retaining the accuracy even when scaled to a large catalog. We also propose a training strategy to overcome the degradation in recall at such scale due to an increased number of confusing entities. Overall, our approach achieves up to 6% more Word Error Rate reduction (WERR) and 3.6% absolute improvement in F1 when compared to a strong baseline. Our method also allows for large catalog sizes of up to 20K without significantly affecting WER and F1-scores, while achieving at least 20% inference speedup per acoustic frame. | Sai Muralidhar Jayanthi, Devang Kulshreshtha, Saket Dingliwal, Srikanth Ronanki, Sravan Bodapati |  |
| 115 |  |  [STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants](https://doi.org/10.18653/v1/2023.emnlp-industry.61) |  | 0 | In the context of a voice assistant system, steering refers to the phenomenon in which a user issues a follow-up command attempting to direct or clarify a previous turn. We propose STEER, a steering detection model that predicts whether a follow-up turn is a user’s attempt to steer the previous command. Constructing a training dataset for steering use cases poses challenges due to the cold-start problem. To overcome this, we developed heuristic rules to sample opt-in usage data, approximating positive and negative samples without any annotation. Our experimental results show promising performance in identifying steering intent, with over 95% accuracy on our sampled data. Moreover, STEER, in conjunction with our sampling strategy, aligns effectively with real-world steering scenarios, as evidenced by its strong zero-shot performance on a human-graded evaluation set. In addition to relying solely on user transcripts as input, we introduce STEER+, an enhanced version of the model. STEER+ utilizes a semantic parse tree to provide more context on out-of-vocabulary words, such as named entities that often occur at the sentence boundary. This further improves model performance, reducing error rate in domains where entities frequently appear, such as messaging. Lastly, we present a data analysis that highlights the improvement in user experience when voice assistants support steering use cases. | Leon Liyang Zhang, Jiarui Lu, Joel Ruben Antony Moniz, Aditya Kulkarni, Dhivya Piraviperumal, Tien Dung Tran, Nick Tzou, Hong Yu |  |
| 116 |  |  [Self-Criticism: Aligning Large Language Models with their Understanding of Helpfulness, Honesty, and Harmlessness](https://doi.org/10.18653/v1/2023.emnlp-industry.62) |  | 0 | Recently, there has been a notable surge in the significance of large language models (LLMs) that engage in conversational-style interactions, such as ChatGPT and Claude, as they contribute significantly to the progress of artificial general intelligence (AGI). Typically, these models undergo a two-phase fine-tuning process: instruction fine-tuning (IF) and reinforcement learning from human feedback (RLHF). These methods aim to align the LLMs to be helpful, honest, and harmless (HHH). However, RLHF, which incorporates independent reward models trained on high-quality human feedback datasets, incurs high costs in terms of hardware resources and human efforts. Therefore, we explore the possibility of aligning LLMs with their own understanding of HHH through IF and in-context learning (ICL). In this study, we propose a novel framework called Self-Criticism, which allows LLMs to align themselves with HHH based on the definition they learned from a large-scale text corpus. We begin by employing IF on a given instruction set and learning HHH discrimination through few-shot ICL. Subsequently, the LLMs evaluate their own generated responses and learn to produce “better” responses based on self-judgment. Finally, the model is retrained based on the self-generated responses to distill the whole process. By analyzing our proposed method, we also find interesting connections between Self-Criticism and goal-conditioned reinforcement learning, and pseudo-labeling. Experimental results demonstrate that this method achieves nearly identical performance to RLHF in terms of both human evaluation and evaluation by other LLMs, with only a minimal alignment tax. | Xiaoyu Tan, Shaojie Shi, Xihe Qiu, Chao Qu, Zhenting Qi, Yinghui Xu, Yuan Qi |  |
| 117 |  |  [InstructPTS: Instruction-Tuning LLMs for Product Title Summarization](https://doi.org/10.18653/v1/2023.emnlp-industry.63) |  | 0 | E-commerce product catalogs contain billions of items. Most products have lengthy titles, as sellers pack them with product attributes to improve retrieval, and highlight key product aspects. This results in a gap between such unnatural products titles, and how customers refer to them. It also limits how e-commerce stores can use these seller-provided titles for recommendation, QA, or review summarization. Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a controllable approach for the task of Product Title Summarization (PTS). Trained using a novel instruction fine-tuning strategy, our approach is able to summarize product titles according to various criteria (e.g. number of words in a summary, inclusion of specific phrases, etc.). Extensive evaluation on a real-world e-commerce catalog shows that compared to simple fine-tuning of LLMs, our proposed approach can generate more accurate product name summaries, with an improvement of over 14 and 8 BLEU and ROUGE points, respectively. | Besnik Fetahu, Zhiyu Chen, Oleg Rokhlenko, Shervin Malmasi |  |
| 118 |  |  [LLM4Vis: Explainable Visualization Recommendation using ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-industry.64) |  | 0 | Data visualization is a powerful tool for exploring and communicating insights in various domains. To automate visualization choice for datasets, a task known as visualization recommendation has been proposed. Various machine-learning-based approaches have been developed for this purpose, but they often require a large corpus of dataset-visualization pairs for training and lack natural explanations for their results. To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples. Our approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps. To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint. Evaluations on the VizML dataset show that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP, in both few-shot and zero-shot settings. The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis. | Lei Wang, Songheng Zhang, Yun Wang, EePeng Lim, Yong Wang |  |
| 119 |  |  [DUBLIN: Visual Document Understanding By Language-Image Network](https://doi.org/10.18653/v1/2023.emnlp-industry.65) |  | 0 | In this paper, we present DUBLIN, a pixel-based model for visual document understanding that does not rely on OCR. DUBLIN can process both images and texts in documents just by the pixels and handle diverse document types and tasks. DUBLIN is pretrained on a large corpus of document images with novel tasks that enhance its visual and linguistic abilities. We evaluate DUBLIN on various benchmarks and show that it achieves state-of-the-art performance on extractive tasks such as DocVQA, InfoVQA, AI2D, OCR-VQA, RefExp, and CORD, as well as strong performance on abstraction datasets such as VisualMRC and text captioning. Our model demonstrates the potential of OCR-free document processing and opens new avenues for applications and research. | Kriti Aggarwal, Aditi Khandelwal, Kumar Tanmay, Owais Khan Mohammed, Qiang Liu, Monojit Choudhury, Hardik Hansrajbhai Chauhan, Subhojit Som, Vishrav Chaudhary, Saurabh Tiwary |  |
| 120 |  |  [DocumentNet: Bridging the Data Gap in Document Pre-training](https://doi.org/10.18653/v1/2023.emnlp-industry.66) |  | 0 | Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multimodal capabilities for VDER. | Lijun Yu, Jin Miao, Xiaoyu Sun, Jiayi Chen, Alexander G. Hauptmann, Hanjun Dai, Wei Wei |  |
| 121 |  |  [Relevance-assisted Generation for Robust Zero-shot Retrieval](https://doi.org/10.18653/v1/2023.emnlp-industry.67) |  | 0 | Zero-shot retrieval tasks such as the BEIR benchmark reveal out-of-domain generalization as a key weakness of high-performance dense retrievers. As a solution, domain adaptation for dense retrievers has been actively studied. A notable approach is synthesizing domain-specific data, by generating pseudo queries (PQ), for fine-tuning with domain-specific relevance between PQ and documents. Our contribution is showing that key biases can cause sampled PQ to be irrelevant, negatively contributing to generalization. We propose to preempt their generation, by dividing the generation into simpler subtasks, of generating relevance explanations and guiding the generation to avoid negative generalization. Experiment results show that our proposed approach is more robust to domain shifts, validated on challenging BEIR zero-shot retrieval tasks. | Jihyuk Kim, Minsoo Kim, Joonsuk Park, Seungwon Hwang |  |
| 122 |  |  [Too much of product information : Don't worry, let's look for evidence!](https://doi.org/10.18653/v1/2023.emnlp-industry.68) |  | 0 | Product question answering (PQA) aims to provide an instant response to customer questions posted on shopping message boards, social media, brand websites and retail stores. In this paper, we propose a distantly supervised solution to answer customer questions by using product information. Auto-answering questions using product information poses two main challenges:(i) labelled data is not readily available (ii)lengthy product information requires attending to various parts of the text to answer the question. To this end, we first propose a novel distant supervision based NLI model to prepare training data without any manual efforts. To deal with lengthy context, we factorize answer generation into two sub-problems. First, given product information, model extracts evidence spans relevant to question. Then, model leverages evidence spans to generate answer. Further, we propose two novelties in fine-tuning approach: (i) First, we jointly fine-tune model for both the tasks in end-to-end manner and showcase that it outperforms standard multi-task fine-tuning. (ii) Next, we introduce an auxiliary contrastive loss for evidence extraction. We show that combination of these two ideas achieves an absolute improvement of 6% in accuracy (human evaluation) over baselines. | Aryan Jain, Jitenkumar Rana, Chetan Aggarwal |  |
| 123 |  |  [Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting](https://doi.org/10.18653/v1/2023.emnlp-industry.69) |  | 0 | Applying machine learning to financial time series has been an active area of industrial research enabling innovation in market insights, risk management, strategic decision-making, and policy formation. This paper explores the novel use of Large Language Models (LLMs) for explainable financial time series forecasting, addressing challenges in cross-sequence reasoning, multi-modal data integration, and result interpretation that are inherent in traditional approaches. Focusing on NASDAQ-100 stocks, we utilize public historical stock data, company metadata, and economic/financial news. Our experiments employ GPT-4 for zero-shot/few-shot inference and Open LLaMA for instruction-based fine-tuning. The study demonstrates LLMs’ ability to generate well-reasoned decisions by leveraging cross-sequence information and extracting insights from text and price time series. We show that our LLM-based approach outperforms classic ARMA-GARCH and gradient-boosting tree models. Furthermore, fine-tuned public LLMs, such as Open-LLaMA, can generate reasonable and explainable forecasts, although they underperform compared to GPT-4. | Xinli Yu, Zheng Chen, Yanbin Lu |  |
| 124 |  |  [ViGPTQA - State-of-the-Art LLMs for Vietnamese Question Answering: System Overview, Core Models Training, and Evaluations](https://doi.org/10.18653/v1/2023.emnlp-industry.70) |  | 0 | Large language models (LLMs) and their applications in low-resource languages (such as in Vietnamese) are limited due to lack of training data and benchmarking datasets. This paper introduces a practical real-world implementation of a question answering system for Vietnamese, called ViGPTQA, leveraging the power of LLM. Since there is no effective LLM in Vietnamese to date, we also propose, evaluate, and open-source an instruction-tuned LLM for Vietnamese, named ViGPT. ViGPT demonstrates exceptional performances, especially on real-world scenarios. We curate a new set of benchmark datasets that encompass both AI and human-generated data, providing a comprehensive evaluation framework for Vietnamese LLMs. By achieving state-of-the-art results and approaching other multilingual LLMs, our instruction-tuned LLM underscores the need for dedicated Vietnamese-specific LLMs. Our open-source model supports customized and privacy-fulfilled Vietnamese language processing systems. | Minh Thuan Nguyen, KhanhTung Tran, NhuVan Nguyen, XuanSon Vu |  |
| 125 |  |  [An Integrated Search System for Korea Weather Data](https://doi.org/10.18653/v1/2023.emnlp-industry.71) |  | 0 | We introduce WeatherSearch, an integrated search system deployed at the Korea Meteorological Administration (KMA). WeatherSearch enables users to retrieve all the relevant data for weather forecasting from a massive weather database with simple natural language queries. We carefully design and conduct multiple expert surveys and interviews for template creation and apply data augmentation techniques including template filling to collect 4 million data points with minimal human labors. We then finetune mT5 on the collected dataset and achieve an average MRR of 0.66 and an average Recall of 0.82. We also discuss weather-data-specific characteristics that should be taken into account for creating such a system. We hope our paper serves as a simple and effective guideline for those designing similar systems in other regions of the world. | Jinkyung Jo, Dayeon Ki, Soyoung Yoon, Minjoon Seo |  |
| 126 |  |  [Adaptive Hyper-parameter Learning for Deep Semantic Retrieval](https://doi.org/10.18653/v1/2023.emnlp-industry.72) |  | 0 | Deep semantic retrieval has achieved remarkable success in online E-commerce applications. The majority of methods aim to distinguish positive items and negative items for each query by utilizing margin loss or softmax loss. Despite their decent performance, these methods are highly sensitive to hyper-parameters, i.e., margin and temperature 𝜏, which measure the similarity of negative pairs and affect the distribution of items in metric space. How to design and choose adaptively parameters for different pairs is still an open challenge. Recently several methods have attempted to alleviate the above problem by learning each parameter through trainable/statistical methods in the recommendation. We argue that those are not suitable for retrieval scenarios, due to the agnosticism and diversity of the queries. To fully overcome this limitation, we propose a novel adaptive metric learning method that designs a simple and universal hyper-parameter-free learning method to improve the performance of retrieval. Specifically, we first propose a method that adaptive obtains the hyper-parameters by relying on the batch similarity without fixed or extra-trainable hyper-parameters. Subsequently, we adopt a symmetric metric learning method to mitigate model collapse issues. Furthermore, the proposed method is general and sheds a highlight on other fields. Extensive experiments demonstrate our method significantly outperforms previous methods on a real-world dataset, highlighting the superiority and effectiveness of our method. This method has been successfully deployed on an online E-commerce search platform and brought substantial economic benefits. | Mingming Li, Chunyuan Yuan, Huimu Wang, Peng Wang, Jingwei Zhuo, Binbin Wang, Lin Liu, Sulong Xu |  |
| 127 |  |  [On Sample-Efficient Code Generation](https://doi.org/10.18653/v1/2023.emnlp-industry.73) |  | 0 | Large language models often struggle to predict runtime behavior in code generation tasks, leading to a reliance on rejection sampling (best-of-n) to generate multiple code snippets then select the best. Our distinction is reducing sampling costs, without compromising generation quality. We introduce EFFICODE, a novel framework that prioritizes sampling on test problems that models can solve. We show how EFFICODE estimates solvability to optimize computational costs during multiple sampling. Based on empirical evidence, EFFICODE consistently demonstrates reduced sampling budgets while maintaining comparable code generation performance, especially when problems are challenging. In addition, utilizing EFFICODE to rank sampled code snippets also shows its effectiveness in answer code selection for reducing temporal costs, by not requiring any execution or test case generation. | Hojae Han, Yu Jin Kim, Byoungjip Kim, Youngwon Lee, Kyungjae Lee, Kyungmin Lee, Moontae Lee, Kyunghoon Bae, Seungwon Hwang |  |
| 128 |  |  [Batch Prompting: Efficient Inference with Large Language Model APIs](https://doi.org/10.18653/v1/2023.emnlp-industry.74) |  | 0 | Performing inference on large volumes of samples with large language models (LLMs) can be computationally and financially costly in industry and real-world use. We propose batch prompting, a simple yet effective prompting approach that enables the LLM to run inference in batches, instead of one sample at a time. Our method reduces both token and time costs while retaining downstream performance. We theoretically demonstrate that under a few-shot in-context learning setting, the inference costs decrease almost inverse linearly with the number of samples in each batch. We extensively validate the effectiveness of batch prompting on ten datasets across commonsense QA, arithmetic reasoning, and NLI/NLU: batch prompting significantly (up to 5× with six samples in batch) reduces the LLM (Codex) inference token and time costs while achieving better or comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5 and GPT-4, we show the benefits of batch prompting also hold. Further analysis shows that the number of samples in each batch and the complexity of tasks affect its performance. Moreover, batch prompting can be applied across different reasoning methods using LLMs. Our code is released at the site https://github.com/xlang-ai/batch-prompting. | Zhoujun Cheng, Jungo Kasai, Tao Yu |  |
| 129 |  |  [Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding](https://doi.org/10.18653/v1/2023.emnlp-industry.75) |  | 0 | A Personalized Query Rewriting system strives to minimize defective queries to ensure robust conversational functionality by considering individual user behavior and preferences. It’s designed as a search-based system, maintaining a user index of past successful interactions with the conversational AI. However, this method faces challenges with unseen interactions, which refers to novel user interactions not covered by the user’s historical index. This paper introduces our Collaborative Query Rewriting approach, which utilizes underlying topological information to assist in rewriting defective queries arising from unseen user interactions. This approach begins by constructing a “User Feedback Interaction Graph” (FIG) using historical user-entity interactions. Subsequently, we traverse through the graph edges to establish an enhanced user index, referred to as the “collaborative user index”. This paper then further explores the use of Large Language Models (LLMs) in conjunction with graph traversal, leading to a significant increase in index coverage for unseen interactions. The effectiveness of our proposed approach has been proven through experiments on a large-scale real-world dataset and online A/B experiments. | Zheng Chen, Ziyan Jiang, Fan Yang, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, Aram Galstyan |  |
| 130 |  |  [DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues](https://doi.org/10.18653/v1/2023.emnlp-industry.76) |  | 0 | Controversy is a reflection of our zeitgeist, and an important aspect to any discourse. The rise of large language models (LLMs) as conversational systems has increased public reliance on these systems for answers to their various questions. Consequently, it is crucial to systematically examine how these models respond to questions that pertaining to ongoing debates. However, few such datasets exist in providing human-annotated labels reflecting the contemporary discussions. To foster research in this area, we propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. This dataset presents challenges concerning knowledge recency, safety, fairness, and bias. We evaluate different LLMs using a subset of this dataset, illuminating how they handle controversial issues and the stances they adopt. This research ultimately contributes to our understanding of LLMs’ interaction with controversial issues, paving the way for improvements in their comprehension and handling of complex societal debates. | David Q. Sun, Artem Abzaliev, Hadas Kotek, Christopher Klein, Zidi Xiu, Jason D. Williams |  |
| 131 |  |  [Angel: Enterprise Search System for the Non-Profit Industry](https://doi.org/10.18653/v1/2023.emnlp-industry.77) |  | 0 | Non-profit industry need a system for accurately matching fund-seekers (e.g., AMERICAN NATIONAL RED CROSS) with fund-givers (e.g., BILL AND MELINDA GATES FOUNDATION) aligned in cause (e.g., cancer) and target beneficiary group (e.g., children). In this paper, we create an enterprise search system “ANGEL” for the non-profit industry that takes a fund-giver’s mission description as input and returns a ranked list of fund-seekers as output, and vice-versa. ANGEL employs ColBERT, a neural information retrieval model, which we enhance by exploiting the two techniques of (a) Syntax-aware local attention (SLA) to combine syntactic information in the mission description with multi-head self-attention and (b) Dense Pseudo Relevance Feedback (DPRF) for augmentation of short mission descriptions. We create a mapping dictionary “non-profit-dict” to curate a “non-profit-search database” containing information on 594K fund-givers and 194K fund-seekers from IRS-990 filings for the non-profit industry search engines . We also curate a “non-profit-evaluation” dataset containing scored matching between 463 fund-givers and 100 fund-seekers. The research is in collaboration with a philanthropic startup that identifies itself as an “AI matching platform, fundraising assistant, and philanthropy search base.” Domain experts at the philanthropic startup annotate the non-profit evaluation dataset and continuously evaluate the performance of ANGEL. ANGEL achieves an improvement of 0.14 MAP@10 and 0.16 MRR@10 over the state-of-the-art baseline on the non-profit evaluation dataset. To the best of our knowledge, ours is the first effort at building an enterprise search engine based on neural information retrieval for the non-profit industry. | Saiful Haq, Ashutosh Sharma, Pushpak Bhattacharyya |  |
| 132 |  |  [Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023](https://aclanthology.org/volumes/2023.findings-emnlp/) |  | 0 |  | Houda Bouamor, Juan Pino, Kalika Bali |  |
| 133 |  |  [Frontmatter](https://aclanthology.org/2023.findings-emnlp.0) |  | 0 |  |  |  |
| 134 |  |  [Multi Document Summarization Evaluation in the Presence of Damaging Content](https://doi.org/10.18653/v1/2023.findings-emnlp.1) |  | 0 | In the Multi-document summarization (MDS) task, a summary is produced for a given set of documents. A recent line of research introduced the concept of damaging documents, denoting documents that should not be exposed to readers due to various reasons. In the presence of damaging documents, a summarizer is ideally expected to exclude damaging content in its output. Existing metrics evaluate a summary based on aspects such as relevance and consistency with the source documents. We propose to additionally measure the ability of MDS systems to properly handle damaging documents in their input set. To that end, we offer two novel metrics based on lexical similarity and language model likelihood. A set of experiments demonstrates the effectiveness of our metrics in measuring the ability of MDS systems to summarize a set of documents while eliminating damaging content from their summaries. | Avshalom Manevich, David Carmel, Nachshon Cohen, Elad Kravi, Ori Shapira |  |
| 135 |  |  [Guiding AMR Parsing with Reverse Graph Linearization](https://doi.org/10.18653/v1/2023.findings-emnlp.2) |  | 0 | Abstract Meaning Representation (AMR) parsing aims to extract an abstract semantic graph from a given sentence. The sequence-to-sequence approaches, which linearize the semantic graph into a sequence of nodes and edges and generate the linearized graph directly, have achieved good performance. However, we observed that these approaches suffer from structure loss accumulation during the decoding process, leading to a much lower F1-score for nodes and edges decoded later compared to those decoded earlier. To address this issue, we propose a novel Reverse Graph Linearization (RGL) enhanced framework. RGL defines both default and reverse linearization orders of an AMR graph, where most structures at the back part of the default order appear at the front part of the reversed order and vice versa. RGL incorporates the reversed linearization to the original AMR parser through a two-pass self-distillation mechanism, which guides the model when generating the default linearizations. Our analysis shows that our proposed method significantly mitigates the problem of structure loss accumulation, outperforming the previously best AMR parsing model by 0.8 and 0.5 Smatch scores on the AMR 2.0 and AMR 3.0 dataset, respectively. The code are available at https://github.com/pkunlp-icler/AMR_reverse_graph_linearization. | Bofei Gao, Liang Chen, Peiyi Wang, Zhifang Sui, Baobao Chang |  |
| 136 |  |  [Translate the Beauty in Songs: Jointly Learning to Align Melody and Translate Lyrics](https://doi.org/10.18653/v1/2023.findings-emnlp.3) |  | 0 | Song translation requires both translation of lyrics and alignment of music notes so that the resulting verse can be sung to the accompanying melody, which is a challenging problem that has attracted some interests in different aspects of the translation process. In this paper, we propose Lyrics-Melody Translation with Adaptive Grouping (LTAG), a holistic solution to automatic song translation by jointly modeling lyric translation and lyrics-melody alignment. It is a novel encoder-decoder framework that can simultaneously translate the source lyrics and determine the number of aligned notes at each decoding step through an adaptive note grouping module. To address data scarcity, we commissioned a small amount of training data annotated specifically for this task and used large amounts of automatic training data through back-translation. Experiments conducted on an English-Chinese song translation data set show the effectiveness of our model in both automatic and human evaluations. | Chengxi Li, Kai Fan, Jiajun Bu, Boxing Chen, Zhongqiang Huang, Zhi Yu |  |
| 137 |  |  [Aksharantar: Open Indic-language Transliteration datasets and models for the Next Billion Users](https://doi.org/10.18653/v1/2023.findings-emnlp.4) |  | 0 | Transliteration is very important in the Indian language context due to the usage of multiple scripts and the widespread use of romanized inputs. However, few training and evaluation sets are publicly available. We introduce Aksharantar, the largest publicly available transliteration dataset for Indian languages created by mining from monolingual and parallel corpora, as well as collecting data from human annotators. The dataset contains 26 million transliteration pairs for 21 Indic languages from 3 language families using 12 scripts. Aksharantar is 21 times larger than existing datasets and is the first publicly available dataset for 7 languages and 1 language family. We also introduce a test set of 103k word pairs for 19 languages that enables a fine-grained analysis of transliteration models on native origin words, foreign words, frequent words, and rare words. Using the training set, we trained IndicXlit, a multilingual transliteration model that improves accuracy by 15% on the Dakshina test set, and establishes strong baselines on the Aksharantar testset introduced in this work. The models, mining scripts, transliteration guidelines, and datasets are available at https://github.com/AI4Bharat/IndicXlit under open-source licenses. | Yash Madhani, Sushane Parthan, Priyanka Bedekar, Gokul NC, Ruchi Khapra, Anoop Kunchukuttan, Pratyush Kumar, Mitesh M. Khapra |  |
| 138 |  |  [Pretraining Without Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.5) |  | 0 | Transformers have been essential to pretraining success in NLP. While other architectures have been used, downstream accuracy is either significantly worse, or requires attention layers to match standard benchmarks such as GLUE. This work explores pretraining without attention by using recent advances in sequence routing based on state-space models (SSMs). Our proposed model, Bidirectional Gated SSM (BiGS), combines SSM layers with a multiplicative gating architecture that has been effective in simplified sequence modeling architectures. The model learns static layers that do not consider pair-wise interactions. Even so, BiGS is able to match BERT pretraining accuracy on GLUE and can be extended to long-form pretraining of 4096 tokens without approximation. Analysis shows that while the models have similar average accuracy, the approach has different inductive biases than BERT and scales more efficiently to longer sequences. | Junxiong Wang, Jing Nathan Yan, Albert Gu, Alexander M. Rush |  |
| 139 |  |  [Time-Aware Representation Learning for Time-Sensitive Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.6) |  | 0 | Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as ‘after’ and ‘before’, and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at https://github.com/sonjbin/TCQA | Jungbin Son, Alice Oh |  |
| 140 |  |  [EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation Metrics](https://doi.org/10.18653/v1/2023.findings-emnlp.7) |  | 0 | Efficiency is a key property to foster inclusiveness and reduce environmental costs, especially in an era of LLMs. In this work, we provide a comprehensive evaluation of efficiency for MT evaluation metrics. Our approach involves replacing computation-intensive transformers with lighter alternatives and employing linear and quadratic approximations for alignment algorithms on top of LLM representations. We evaluate six (reference-free and reference-based) metrics across three MT datasets and examine 16 lightweight transformers. In addition, we look into the training efficiency of metrics like COMET by utilizing adapters. Our results indicate that (a) TinyBERT provides the optimal balance between quality and efficiency, (b) CPU speed-ups are more substantial than those on GPU; (c) WMD approximations yield no efficiency gains while reducing quality and (d) adapters enhance training efficiency (regarding backward pass speed and memory requirements) as well as, in some cases, metric quality. These findings can help to strike a balance between evaluation speed and quality, which is essential for effective NLG systems. Furthermore, our research contributes to the ongoing efforts to optimize NLG evaluation metrics with minimal impact on performance. To our knowledge, ours is the most comprehensive analysis of different aspects of efficiency for MT metrics conducted so far. | Daniil Larionov, Jens Grünwald, Christoph Leiter, Steffen Eger |  |
| 141 |  |  [Unsupervised Opinion Summarization Using Approximate Geodesics](https://doi.org/10.18653/v1/2023.findings-emnlp.8) |  | 0 | Opinion summarization is the task of creating summaries capturing popular opinions from user reviews. In this paper, we introduce Geodesic Summarizer (GeoSumm), a novel system to perform unsupervised extractive opinion summarization. GeoSumm consists of an encoder-decoder based representation learning model that generates topical representations of texts. These representations capture the underlying semantics of the text as a distribution over learnable latent units. GeoSumm generates these topical representations by performing dictionary learning over pre-trained text representations at multiple layers of the decoder. We then use these topical representations to quantify the importance of review sentences using a novel approximate geodesic distance-based scoring mechanism. We use the importance scores to identify popular opinions in order to compose general and aspect-specific summaries. Our proposed model, GeoSumm, achieves strong performance on three opinion summarization datasets. We perform additional experiments to analyze the functioning of our model and showcase the generalization ability of GeoSumm across different domains. | Somnath Basu Roy Chowdhury, Nicholas Monath, Avinava Dubey, Amr Ahmed, Snigdha Chaturvedi |  |
| 142 |  |  [Investigating the Frequency Distortion of Word Embeddings and Its Impact on Bias Metrics](https://doi.org/10.18653/v1/2023.findings-emnlp.9) |  | 0 | Recent research has shown that static word embeddings can encode words’ frequencies. However, little has been studied about this behavior. In the present work, we study how frequency and semantic similarity relate to one another in static word embeddings, and we assess the impact of this relationship on embedding-based bias metrics. We find that Skip-gram, GloVe and FastText embeddings tend to produce higher similarity between high-frequency words than between other frequency combinations. We show that the association between frequency and similarity also appears when words are randomly shuffled, and holds for different hyperparameter settings. This proves that the patterns we find are neither due to real semantic associations nor to specific parameters choices, and are an artifact produced by the word embeddings. To illustrate how frequencies can affect the measurement of biases related to gender, ethnicity, and affluence, we carry out a controlled experiment that shows that biases can even change sign or reverse their order when word frequencies change. | Francisco Valentini, Juan Sosa, Diego Fernández Slezak, Edgar Altszyler |  |
| 143 |  |  [Improving Classifier Robustness through Active Generative Counterfactual Data Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.10) |  | 0 | Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned auxiliary classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small amount of human-annotated counterfactual data (10%), we can generate a counterfactual augmentation dataset with learned labels, that provides an 18-20% improvement in robustness and a 14-21% reduction in errors on 6 out-of-domain datasets, comparable to that of a fully human-annotated counterfactual dataset for both sentiment classification and question paraphrase tasks. | Ananth Balashankar, Xuezhi Wang, Yao Qin, Ben Packer, Nithum Thain, Ed H. Chi, Jilin Chen, Alex Beutel |  |
| 144 |  |  [Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study](https://doi.org/10.18653/v1/2023.findings-emnlp.11) |  | 0 | Code-switching (CSW) text generation has been receiving increasing attention as a solution to address data scarcity. In light of this growing interest, we need more comprehensive studies comparing different augmentation approaches. In this work, we compare three popular approaches: lexical replacements, linguistic theories, and back-translation (BT), in the context of Egyptian Arabic-English CSW. We assess the effectiveness of the approaches on machine translation and the quality of augmentations through human evaluation. We show that BT and CSW predictive-based lexical replacement, being trained on CSW parallel data, perform best on both tasks. Linguistic theories and random lexical replacement prove to be effective in the lack of CSW parallel data, where both approaches achieve similar results. | Injy Hamed, Nizar Habash, Thang Vu |  |
| 145 |  |  [On the Relation between Sensitivity and Accuracy in In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.12) |  | 0 | In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose SenSel, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that SenSel consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions. | Yanda Chen, Chen Zhao, Zhou Yu, Kathleen R. McKeown, He He |  |
| 146 |  |  [Self-distilled Transitive Instance Weighting for Denoised Distantly Supervised Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.13) |  | 0 | The widespread existence of wrongly labeled instances is a challenge to distantly supervised relation extraction. Most of the previous works are trained in a bag-level setting to alleviate such noise. However, sentence-level training better utilizes the information than bag-level training, as long as combined with effective noise alleviation. In this work, we propose a novel Transitive Instance Weighting mechanism integrated with the self-distilled BERT backbone, utilizing information in the intermediate outputs to generate dynamic instance weights for denoised sentence-level training. By down-weighting wrongly labeled instances and discounting the weights of easy-to-fit ones, our method can effectively tackle wrongly labeled instances and prevent overfitting. Experiments on both held-out and manual datasets indicate that our method achieves state-of-the-art performance and consistent improvements over the baselines. | Xiangyu Lin, Weijia Jia, Zhiguo Gong |  |
| 147 |  |  [MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation](https://doi.org/10.18653/v1/2023.findings-emnlp.14) |  | 0 | Recent approaches to word sense disambiguation (WSD) utilize encodings of the sense gloss (definition), in addition to the input context, to improve performance. In this work we demonstrate that this approach can be adapted for use in multiword expression (MWE) identification by training models which use gloss and context information to filter MWE candidates produced by a rule-based extraction pipeline. Our approach substantially improves precision, outperforming the state-of-the-art in MWE identification on the DiMSUM dataset by up to 1.9 F1 points and achieving competitive results on the PARSEME 1.1 English dataset. Our models also retain most of their WSD performance, showing that a single model can be used for both tasks. Finally, building on similar approaches using Bi-encoders for WSD, we introduce a novel Poly-encoder architecture which improves MWE identification performance. | Joshua Tanner, Jacob Hoffman |  |
| 148 |  |  [Dual Contrastive Learning Framework for Incremental Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.15) |  | 0 | Incremental learning plays a pivotal role in the context of online knowledge discovery, as it encourages large models (LM) to learn and refresh knowledge continuously. Many approaches have been proposed to simultaneously preserve knowledge from previous tasks while learning new concepts in online NLP applications. In this paper, we primarily focus on learning a more generalized embedding space that could be better transferred to various downstream sequence tasks. The key idea is to learn from both task-agnostic and task-specific embedding aspects so that the inherent challenge of catastrophic forgetting that arises in incremental learning scenarios can be addressed with a more generalized solution. We propose a dual contrastive learning (DCL) based framework to foster the transferability of representations across different tasks, it consists of two key components: firstly, we utilize global contrastive learning that intertwines a task-agnostic strategy for promoting a generalized embedding space; secondly, considering the domain shift from unseen distributions can compromise the quality of learned embeddings. We further incorporate a task-specific attention mechanism to enhance the adaptability of task-specific weight for various emerging tasks and ultimately reduce errors in generic representations. Experiments over various text datasets demonstrate that our work achieves superior performance and outperforms the current state-of-the-art methods. | Yigong Wang, Zhuoyi Wang, Yu Lin, Jinghui Guo, Sadaf Md. Halim, Latifur Khan |  |
| 149 |  |  [Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards](https://doi.org/10.18653/v1/2023.findings-emnlp.16) |  | 0 | Community Question-Answering (CQA) portals serve as a valuable tool for helping users within an organization. However, making them accessible to non-English-speaking users continues to be a challenge. Translating questions can broaden the community’s reach, benefiting individuals with similar inquiries in various languages. Translating questions using Neural Machine Translation (NMT) poses more challenges, especially in noisy environments, where the grammatical correctness of the questions is not monitored. These questions may be phrased as statements by non-native speakers, with incorrect subject-verb order and sometimes even missing question marks. Creating a synthetic parallel corpus from such data is also difficult due to its noisy nature. To address this issue, we propose a training methodology that fine-tunes the NMT system only using source-side data. Our approach balances adequacy and fluency by utilizing a loss function that combines BERTScore and Masked Language Model (MLM) Score. Our method surpasses the conventional Maximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on synthetic target data, by achieving a 1.9 BLEU score improvement. Our model exhibits robustness while we add noise to our baseline, and still achieve 1.1 BLEU improvement and large improvements on TER and BLEURT metrics. Our proposed methodology is model-agnostic and is only necessary during the training phase. We make the codes and datasets publicly available at https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt for facilitating further research. | Baban Gain, Ramakrishna Appicharla, Soumya Chennabasavaraj, Nikesh Garera, Asif Ekbal, Muthusamy Chelliah |  |
| 150 |  |  [Filtered Semi-Markov CRF](https://doi.org/10.18653/v1/2023.findings-emnlp.17) |  | 0 | Semi-Markov CRF has been proposed as an alternative to the traditional Linear Chain CRF for text segmentation tasks such as Named Entity Recognition (NER). Unlike CRF, which treats text segmentation as token-level prediction, Semi-CRF considers segments as the basic unit, making it more expressive. However, Semi-CRF suffers from two major drawbacks: (1) quadratic complexity over sequence length, as it operates on every span of the input sequence, and (2) inferior performance compared to CRF for sequence labeling tasks like NER. In this paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that addresses these issues by incorporating a filtering step to eliminate irrelevant segments, reducing complexity and search space. Our approach is evaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF while being significantly faster. The implementation of our method is available on Github. | Urchade Zaratiana, Nadi Tomeh, Niama El Khbir, Pierre Holat, Thierry Charnois |  |
| 151 |  |  [Data Pruning for Efficient Model Pruning in Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.18) |  | 0 | Model pruning methods reduce memory requirements and inference time of large-scale pre-trained language models after deployment. However, the actual pruning procedure is computationally intensive, involving repeated training and pruning until the required sparsity is achieved. This paper combines data pruning with movement pruning for Neural Machine Translation (NMT) to enable efficient fine-pruning. We design a dataset pruning strategy by leveraging cross-entropy scores of individual training instances. We conduct pruning experiments on the task of machine translation from Romanian-to-English and Turkish-to-English, and demonstrate that selecting hard-to-learn examples (top-k) based on training cross-entropy scores outperforms other dataset pruning methods. We empirically demonstrate that data pruning reduces the overall steps required for convergence and the training time of movement pruning. Finally, we perform a series of experiments to tease apart the role of training data during movement pruning and uncover new insights to understand the interplay between data and model pruning in the context of NMT. | Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza |  |
| 152 |  |  [Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.19) |  | 0 | One challenge in speech translation is that plenty of spoken content is long-form, but short units are necessary for obtaining high-quality translations. To address this mismatch, we adapt large language models (LLMs) to split long ASR transcripts into segments that can be independently translated so as to maximize the overall translation quality. We overcome the tendency of hallucination in LLMs by incorporating finite-state constraints during decoding; these eliminate invalid outputs without requiring additional training. We discover that LLMs are adaptable to transcripts containing ASR errors through prompt-tuning or fine-tuning. Relative to a state-of-the-art automatic punctuation baseline, our best LLM improves the average BLEU by 2.9 points for English–German, English–Spanish, and English–Arabic TED talk translation in 9 test sets, just by improving segmentation. | Arya McCarthy, Hao Zhang, Shankar Kumar, Felix Stahlberg, Ke Wu |  |
| 153 |  |  [Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.findings-emnlp.20) |  | 0 | Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting aims to predict the missing entity from a fact in the future, posing a challenge that aligns more closely with real-world prediction problems. Existing research mostly encodes entities and relations using sequential graph neural networks applied to recent snapshots. However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction. Additionally, we introduce a two-phase forward propagation method to prevent information leakage. Through the evaluation on six TKGC (extrapolation) datasets, we demonstrate that our model outperforms all eight recent state-of-the-art models by a significant margin. | Kunze Wang, Soyeon Caren Han, Josiah Poon |  |
| 154 |  |  [RethinkingTMSC: An Empirical Study for Target-Oriented Multimodal Sentiment Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.21) |  | 0 | Recently, Target-oriented Multimodal Sentiment Classification (TMSC) has gained significant attention among scholars. However, current multimodal models have reached a performance bottleneck. To investigate the causes of this problem, we perform extensive empirical evaluation and in-depth analysis of the datasets to answer the following questions: \*\*Q1\*\*: Are the modalities equally important for TMSC? \*\*Q2\*\*: Which multimodal fusion modules are more effective? \*\*Q3\*\*: Do existing datasets adequately support the research? Our experiments and analyses reveal that the current TMSC systems primarily rely on the textual modality, as most of targets’ sentiments can be determined \*solely\* by text. Consequently, we point out several directions to work on for the TMSC task in terms of model design and dataset construction. The code and data can be found in https://github.com/Junjie-Ye/RethinkingTMSC. | Junjie Ye, Jie Zhou, Junfeng Tian, Rui Wang, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 155 |  |  [Lexical Entrainment for Conversational Systems](https://doi.org/10.18653/v1/2023.findings-emnlp.22) |  | 0 | Conversational agents have become ubiquitous in assisting with daily tasks, and are expected to possess human-like features. One such feature is lexical entrainment (LE), a phenomenon in which speakers in human-human conversations tend to naturally and subconsciously align their lexical choices with those of their interlocutors, leading to more successful and engaging conversations. As an example, if a digital assistant replies “Your appointment for Jinling Noodle Pub is at 7 pm” to the question “When is my reservation for Jinling Noodle Bar today?”, it may feel as though the assistant is trying to correct the speaker, whereas a response of “Your reservation for Jinling Noodle Baris at 7 pm” would likely be perceived as more positive. This highlights the importance of LE in establishing a shared terminology for maximum clarity and reducing ambiguity in conversations. However, we demonstrate in this work that current response generation models do not adequately address this crucial human-like phenomenon. To address this, we propose a new dataset, named MultiWOZ-ENTR, and a measure for LE for conversational systems. Additionally, we suggest a way to explicitly integrate LE into conversational systems with two new tasks, a LE extraction task and a LE generation task. We also present two baseline approaches for the LE extraction task, which aim to detect LE expressions from dialogue contexts | Zhengxiang Shi, Procheta Sen, Aldo Lipani |  |
| 156 |  |  [AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies](https://doi.org/10.18653/v1/2023.findings-emnlp.23) |  | 0 | We show that dialogue models can detect errors in their own messages, by calculating the likelihood of replies that are indicative of poor messages. For example, if an agent believes its partner is likely to respond “I don’t understand” to a candidate message, that message may not make sense, so an alternative message should be chosen. We evaluate our approach on a dataset from the game Diplomacy, which contains long dialogues richly grounded in the game state, on which existing models make many errors. We first show that hand-crafted replies can be effective for the task of detecting nonsense in applications as complex as Diplomacy. We then design AutoReply, an algorithm to search for such discriminative replies automatically, given a small number of annotated dialogue examples. We find that AutoReply-generated replies outperform handcrafted replies and perform on par with supervised learning approaches. | Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis |  |
| 157 |  |  [Follow-on Question Suggestion via Voice Hints for Voice Assistants](https://doi.org/10.18653/v1/2023.findings-emnlp.24) |  | 0 | The adoption of voice assistants like Alexa or Siri has grown rapidly, allowing users to instantly access information via voice search. Query suggestion is a standard feature of screen-based search experiences, allowing users to explore additional topics. However, this is not trivial to implement in voice-based settings. To enable this, we tackle the novel task of suggesting questions with compact and natural voice hints to allow users to ask follow-up questions. We define the task, ground it in syntactic theory and outline linguistic desiderata for spoken hints. We propose baselines and an approach using sequence-to-sequence Transformers to generate spoken hints from a list of questions. Using a new dataset of 6681 input questions and human written hints, we evaluated the models with automatic metrics and human evaluation. Results show that a naive approach of concatenating suggested questions creates poor voice hints. Our approach, which applies a linguistically-motivated pretraining task was strongly preferred by humans for producing the most natural hints. | Besnik Fetahu, Pedro Faustini, Anjie Fang, Giuseppe Castellucci, Oleg Rokhlenko, Shervin Malmasi |  |
| 158 |  |  [Bidirectional Masked Self-attention and N-gram Span Attention for Constituency Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.25) |  | 0 | Attention mechanisms have become a crucial aspect of deep learning, particularly in natural language processing (NLP) tasks. However, in tasks such as constituency parsing, attention mechanisms can lack the directional information needed to form sentence spans. To address this issue, we propose a Bidirectional masked and N-gram span Attention (BNA) model, which is designed by modifying the attention mechanisms to capture the explicit dependencies between each word and enhance the representation of the output span vectors. The proposed model achieves state-of-the-art performance on the Penn Treebank and Chinese Penn Treebank datasets, with F1 scores of 96.47 and 94.15, respectively. Ablation studies and analysis show that our proposed BNA model effectively captures sentence structure by contextualizing each word in a sentence through bidirectional dependencies and enhancing span representation. | Soohyeong Kim, Whanhee Cho, Minji Kim, Yong Choi |  |
| 159 |  |  [CR-COPEC: Causal Rationale of Corporate Performance Changes to learn from Financial Reports](https://doi.org/10.18653/v1/2023.findings-emnlp.26) |  | 0 | In this paper, we introduce CR-COPEC called Causal Rationale of Corporate Performance Changes from financial reports. This is a comprehensive large-scale domain-adaptation causal sentence dataset to detect financial performance changes of corporate. CR-COPEC contributes to two major achievements. First, it detects causal rationale from 10-K annual reports of the U.S. companies, which contain experts’ causal analysis following accounting standards in a formal manner. This dataset can be widely used by both individual investors and analysts as material information resources for investing and decision-making without tremendous effort to read through all the documents. Second, it carefully considers different characteristics which affect the financial performance of companies in twelve industries. As a result, CR-COPEC can distinguish causal sentences in various industries by taking unique narratives in each industry into consideration. We also provide an extensive analysis of how well CR-COPEC dataset is constructed and suited for classifying target sentences as causal ones with respect to industry characteristics. | Ye Eun Chun, Sunjae Kwon, Kyunghwan Sohn, Nakwon Sung, Junyoup Lee, Byoung Seo, Kevin Compher, Seungwon Hwang, Jaesik Choi |  |
| 160 |  |  [Plausibility Processing in Transformer Language Models: Focusing on the Role of Attention Heads in GPT](https://doi.org/10.18653/v1/2023.findings-emnlp.27) |  | 0 | The goal of this paper is to explore how Transformer language models process semantic knowledge, especially regarding the plausibility of noun-verb relations. First, I demonstrate GPT2 exhibits a higher degree of similarity with humans in plausibility processing compared to other Transformer language models. Next, I delve into how knowledge of plausibility is contained within attention heads of GPT2 and how these heads causally contribute to GPT2’s plausibility processing ability. Through several experiments, it was found that: i) GPT2 has a number of attention heads that detect plausible noun-verb relationships; ii) these heads collectively contribute to the Transformer’s ability to process plausibility, albeit to varying degrees; and iii) attention heads’ individual performance in detecting plausibility does not necessarily correlate with how much they contribute to GPT2’s plausibility processing ability. | Soo Ryu |  |
| 161 |  |  [Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis](https://doi.org/10.18653/v1/2023.findings-emnlp.28) |  | 0 | The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics – through the use of Unit Tests to check its functional correctness – lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models’ coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model’s performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL. | Philip John Gorinski, Matthieu Zimmer, Gerasimos Lampouras, DerrickGohXin Deik, Ignacio Iacobacci |  |
| 162 |  |  [Unlocking the Heterogeneous Landscape of Big Data NLP with DUUI](https://doi.org/10.18653/v1/2023.findings-emnlp.29) |  | 0 | Automatic analysis of large corpora is a complex task, especially in terms of time efficiency. This complexity is increased by the fact that flexible, extensible text analysis requires the continuous integration of ever new tools. Since there are no adequate frameworks for these purposes in the field of NLP, and especially in the context of UIMA, that are not outdated or unusable for security reasons, we present a new approach to address the latter task: Docker Unified UIMA Interface (DUUI), a scalable, flexible, lightweight, and feature-rich framework for automatic distributed analysis of text corpora that leverages Big Data experience and virtualization with Docker. We evaluate DUUI’s communication approach against a state-of-the-art approach and demonstrate its outstanding behavior in terms of time efficiency, enabling the analysis of big text data. | Alexander Leonhardt, Giuseppe Abrami, Daniel Baumartz, Alexander Mehler |  |
| 163 |  |  [Towards Agile Text Classifiers for Everyone](https://doi.org/10.18653/v1/2023.findings-emnlp.30) |  | 0 | Text-based safety classifiers are widely used for content moderation and increasingly to tune generative language model behavior - a topic of growing concern for the safety of digital assistants and chatbots. However, different policies require different classifiers, and safety policies themselves improve from iteration and adaptation. This paper introduces and evaluates methods for agile text classification, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy. Experimenting with 7 datasets from three safety-related domains, comprising 15 annotation schemes, led to our key finding: prompt-tuning large language models, like PaLM 62B, with a labeled dataset of as few as 80 examples can achieve state-of-the-art performance. We argue that this enables a paradigm shift for text classification, especially for models supporting safer online discourse. Instead of collecting millions of examples to attempt to create universal safety classifiers over months or years, classifiers could be tuned using small datasets, created by individuals or small organizations, tailored for specific use cases, and iterated on and adapted in the time-span of a day. | Maximilian Mozes, Jessica Hoffmann, Katrin Tomanek, Muhamed Kouate, Nithum Thain, Ann Yuan, Tolga Bolukbasi, Lucas Dixon |  |
| 164 |  |  [Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good](https://doi.org/10.18653/v1/2023.findings-emnlp.31) |  | 0 | With the recent advances in natural language processing (NLP), a vast number of applications have emerged across various use cases. Among the plethora of NLP applications, many academic researchers are motivated to do work that has a positive social impact, in line with the recent initiatives of NLP for Social Good (NLP4SG). However, it is not always obvious to researchers how their research efforts are tackling today’s big social problems. Thus, in this paper, we introduce NLP4SGPapers, a scientific dataset with three associated tasks that can help identify NLP4SG papers and characterize the NLP4SG landscape by: (1) identifying the papers that address a social problem, (2) mapping them to the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying the task they are solving and the methods they are using. Using state-of-the-art NLP models, we address each of these tasks and use them on the entire ACL Anthology, resulting in a visualization workspace that gives researchers a comprehensive overview of the field of NLP4SG. Our website is available at https://nlp4sg.vercel.app . We released our data at https://huggingface.co/datasets/feradauto/NLP4SGPapers and code at https://github.com/feradauto/nlp4sg | Fernando Gonzalez Adauto, Zhijing Jin, Bernhard Schölkopf, Tom Hope, Mrinmaya Sachan, Rada Mihalcea |  |
| 165 |  |  [PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale](https://doi.org/10.18653/v1/2023.findings-emnlp.32) |  | 0 | Existing question answering (QA) systems owe much of their success to large, high-quality training data. Such annotation efforts are costly, and the difficulty compounds in the cross-lingual setting. Therefore, prior cross-lingual QA work has focused on releasing evaluation datasets, and then applying zero-shot methods as baselines. This work proposes a synthetic data generation method for cross-lingual QA which leverages indirect supervision from existing parallel corpora. Our method termed PAXQA (Projecting annotations for cross-lingual (x) QA) decomposes cross-lingual QA into two stages. First, we apply a question generation (QG) model to the English side. Second, we apply annotation projection to translate both the questions and answers. To better translate questions, we propose a novel use of lexically-constrained machine translation, in which constrained entities are extracted from the parallel bitexts. We apply PAXQA to generate cross-lingual QA examples in 4 languages (662K examples total), and perform human evaluation on a subset to create validation and test splits. We then show that models fine-tuned on these datasets outperform prior synthetic data generation models over several extractive QA datasets. The largest performance gains are for directions with non-English questions and English contexts. Ablation studies show that our dataset generation method is relatively robust to noise from automatic word alignments, showing the sufficient quality of our generations. To facilitate follow-up work, we release our code and datasets at https://github.com/manestay/paxqa. | Bryan Li, Chris CallisonBurch |  |
| 166 |  |  [Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for Cross-Lingual Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.33) |  | 0 | In cross-lingual language understanding, machine translation is often utilized to enhance the transferability of models across languages, either by translating the training data from the source language to the target, or from the target to the source to aid inference. However, in cross-lingual machine reading comprehension (MRC), it is difficult to perform a deep level of assistance to enhance cross-lingual transfer because of the variation of answer span positions in different languages. In this paper, we propose X-STA, a new approach for cross-lingual MRC. Specifically, we leverage an attentive teacher to subtly transfer the answer spans of the source language to the answer output space of the target. A Gradient-Disentangled Knowledge Sharing technique is proposed as an improved cross-attention block. In addition, we force the model to learn semantic alignments from multiple granularities and calibrate the model outputs with teacher guidance to enhance cross-lingual transferability. Experiments on three multi-lingual MRC datasets show the effectiveness of our method, outperforming state-of-the-art approaches. | Tingfeng Cao, Chengyu Wang, Chuanqi Tan, Jun Huang, Jinhui Zhu |  |
| 167 |  |  [BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using Genre Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.34) |  | 0 | While performance of many text classification tasks has been recently improved due to Pretrained Language Models (PLMs), in this paper we show that they still suffer from a performance gap when the underlying distribution of topics changes. For example, a genre classifier trained on political topics often fails when tested on documents in the same genre, but about sport or medicine. In this work, we quantify this phenomenon empirically with a large corpus and a large set of topics. Thus, we verify that domain transfer remains challenging both for classic PLMs, such as BERT, and for modern large models (LLMs), such as GPT. We develop a data augmentation approach by generating texts in any desired genre and on any desired topic, even when there are no documents in the training corpus that are both in that particular genre and on that particular topic. When we augment the training dataset with the topically-controlled synthetic texts, F1 improves up to 50% for some topics, approaching on-topic training, while showing no or next to no improvement for other topics. While our empirical results focus on genre classification, our methodology is applicable to other classification tasks such as gender, authorship, or sentiment classification. | Dmitri Roussinov, Serge Sharoff |  |
| 168 |  |  [Toward Stronger Textual Attack Detectors](https://doi.org/10.18653/v1/2023.findings-emnlp.35) |  | 0 | The landscape of available textual adversarial attacks keeps growing, posing severe threats and raising concerns regarding deep NLP systems integrity. However, the crucial problem of defending against malicious attacks has only drawn few attention in the NLP community. The latter is nonetheless instrumental to develop robust and trustworthy systems. This paper makes two important contributions in this line of search: (i) we introduce LAROUSSE, a new framework to detect textual adversarial attacks and (ii) we introduce STAKEOUT, an extended benchmark composed of nine popular attack methods, three datasets and two pre-trained models. LAROUSSE is ready-to-use in production as it is unsupervised, hyperparameter free and non-differentiable, protecting it against gradient-based methods. Our new benchmark STAKEOUT allows for a robust evaluation framework: we conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods, and which allows to identify interesting factor of detection rate variations. | Pierre Colombo, Marine Picot, Nathan Noiry, Guillaume Staerman, Pablo Piantanida |  |
| 169 |  |  [MEAL: Stable and Active Learning for Few-Shot Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.36) |  | 0 | Few-shot classification has made great strides due to foundation models that, through priming and prompting, are highly effective few-shot learners. However, this approach has high variance both across different sets of few shots (\*data selection\*) and across different finetuning runs (\*run variability\*). This is problematic not only because it impedes the fair comparison of different approaches, but especially because it makes few-shot learning too unreliable for many real-world applications. To alleviate these issues, we make two contributions for more stable and effective few-shot learning: First, we propose novel ensembling methods and show that they substantially reduce \*run variability\*. Second, we introduce a new active learning (AL) criterion for \*data selection\* and present the first AL-based approach specifically tailored towards prompt-based learning. In our experiments, we show that our combined method, MEAL (\*\*M\*\*ultiprompt finetuning and prediction \*\*E\*\*nsembling with \*\*A\*\*ctive \*\*L\*\*earning), improves overall performance of prompt-based finetuning by 2.3 points on five diverse tasks. We publicly share our code and data splits in https://github.com/akoksal/MEAL. | Abdullatif Köksal, Timo Schick, Hinrich Schütze |  |
| 170 |  |  [Structure and Label Constrained Data Augmentation for Cross-domain Few-shot NER](https://doi.org/10.18653/v1/2023.findings-emnlp.37) |  | 0 | Cross-domain few-shot named entity recognition (NER) is a challenging task that aims to recognize entities in target domains with limited labeled data by leveraging relevant knowledge from source domains. However, domain gaps limit the effect of knowledge transfer and harm the performance of NER models. In this paper, we analyze those domain gaps from two new perspectives, i.e., entity annotations and entity structures and leverage word-to-tag and word-to-word relations to model them, respectively. Moreover, we propose a novel method called Structure and Label Constrained Data Augmentation (SLC-DA) for Cross-domain Few-shot NER, which novelly design a label constrained pre-train task and a structure constrained optimization objectives in the data augmentation process to generate domain-specific augmented data to help NER models smoothly transition from source to target domains. We evaluate our approach on several standard datasets and achieve state-of-the-art or competitive results, demonstrating the effectiveness of our method in cross-domain few-shot NER. | Jingyi Zhang, Ying Zhang, Yufeng Chen, Jinan Xu |  |
| 171 |  |  [Weakly-supervised Deep Cognate Detection Framework for Low-Resourced Languages Using Morphological Knowledge of Closely-Related Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.38) |  | 0 | Exploiting cognates for transfer learning in under-resourced languages is an exciting opportunity for language understanding tasks, including unsupervised machine translation, named entity recognition and information retrieval. Previous approaches mainly focused on supervised cognate detection tasks based on orthographic, phonetic or state-of-the-art contextual language models, which under-perform for most under-resourced languages. This paper proposes a novel language-agnostic weakly-supervised deep cognate detection framework for under-resourced languages using morphological knowledge from closely related languages. We train an encoder to gain morphological knowledge of a language and transfer the knowledge to perform unsupervised and weakly-supervised cognate detection tasks with and without the pivot language for the closely-related languages. While unsupervised, it overcomes the need for hand-crafted annotation of cognates. We performed experiments on different published cognate detection datasets across language families and observed not only significant improvement over the state-of-the-art but also our method outperformed the state-of-the-art supervised and unsupervised methods. Our model can be extended to a wide range of languages from any language family as it overcomes the requirement of the annotation of the cognate pairs for training. | Koustava Goswami, Priya Rani, Theodorus Fransen, John P. McCrae |  |
| 172 |  |  [SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data](https://doi.org/10.18653/v1/2023.findings-emnlp.39) |  | 0 | Text-to-SQL aims to automate the process of generating SQL queries on a database from natural language text. In this work, we propose “SQLPrompt”, tailored to improve the few-shot prompting capabilities of Text-to-SQL for Large Language Models (LLMs). Our methods include innovative prompt design, execution-based consistency decoding strategy which selects the SQL with the most consistent execution outcome among other SQL proposals, and a method that aims to improve performance by diversifying the SQL proposals during consistency selection with different prompt designs (“MixPrompt”) and foundation models (“MixLLMs”). We show that SQLPrompt outperforms previous approaches for in-context learning with zero labeled data by a large margin, closing the gap with finetuning state-of-the-art with thousands of labeled data. | Ruoxi Sun, Sercan Ö. Arik, Rajarishi Sinha, Hootan Nakhost, Hanjun Dai, Pengcheng Yin, Tomas Pfister |  |
| 173 |  |  [Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.40) |  | 0 | Foundation models or pre-trained models have substantially improved the performance of various language, vision, and vision-language understanding tasks. However, existing foundation models can only perform the best in one type of tasks, namely language, vision, or vision-language. It is still an open question whether it is possible to construct a general foundation model performing the best for all the understanding tasks. In this paper, we propose a new method for training the general foundation model, X-FM (the X-Foundation Model). X-FM has one language encoder, one vision encoder, and one fusion encoder, as well as a new training method. The training method includes two new techniques for learning X-FM from text, image, and image-text pair data. One is to stop gradients from the vision-language training when learning the language encoder. The other is to leverage the vision-language training to guide the learning of the vision encoder. Extensive experiments on benchmark datasets show that X-FM can significantly outperform existing general foundation models and perform better than or comparable to existing foundation models specifically for language, vision, or vision-language understanding. Code and pre-trained models are released at https://github.com/zhangxinsong-nlp/XFM. | Xinsong Zhang, Yan Zeng, Jipeng Zhang, Hang Li |  |
| 174 |  |  [Trigger Warnings: Bootstrapping a Violence Detector for Fan Fiction](https://doi.org/10.18653/v1/2023.findings-emnlp.41) |  | 0 | We present the first dataset and evaluation results on a newly defined task: assigning trigger warnings. We introduce a labeled corpus of narrative fiction from Archive of Our Own (AO3), a popular fan fiction site, and define a document-level classification task to determine whether or not to assign a trigger warning to an English story. We focus on the most commonly assigned trigger type “violence’ using the warning labels provided by AO3 authors as ground-truth labels. We trained SVM, BERT, and Longfomer models on three datasets sampled from the corpus and achieve F1 scores between 0.8 and 0.9, indicating that assigning trigger warnings for violence is feasible. | Magdalena Wolska, Matti Wiegmann, Christopher Schröder, Ole Borchardt, Benno Stein, Martin Potthast |  |
| 175 |  |  [Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.42) |  | 0 | Code pre-trained models (CodePTMs) have recently become the de-facto paradigm for various tasks in the domain of code intelligence. To achieve excellent performance, the widely used strategy is to fine-tune all the parameters of CodePTMs. However, as the model size increases along with the number of downstream tasks, this strategy becomes excessively expensive. There are also some prior works that utilize Parameter-Efficient Learning (PEL) methods for model tuning in natural language processing to mitigate similar problems, but applying them directly to CodePTMs fails to capture the inherent structural characteristics of codes. To address the problem, in this paper, we propose Pass-Tuning for structure-aware Parameter-Efficient code representation learning. Specifically, a plug-and-play graph neural network module that can learn from Abstract Syntax Tree (AST) is employed as a tunable prefix. On the one hand, Pass-Tuning can further exploit the structural information of source code. On the other hand, it could serve as a replacement for full fine-tuning. We evaluate our method on multiple tasks across eight programming languages, including code understanding and generation. These results demonstrate the effectiveness, robustness, and universality of our method. | Nuo Chen, Qiushi Sun, Jianing Wang, Xiang Li, Ming Gao |  |
| 176 |  |  [Counterfactual Augmentation for Multimodal Learning Under Presentation Bias](https://doi.org/10.18653/v1/2023.findings-emnlp.43) |  | 0 | In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a \*presentation bias\* in the labels that compromises the ability to train new models. In this paper, we propose \*counterfactual augmentation\*, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting. | Victoria Lin, LouisPhilippe Morency, Dimitrios Dimitriadis, Srinagesh Sharma |  |
| 177 |  |  [A Table-to-Text Framework with Heterogeneous Multidominance Attention and Self-Evaluated Multi-Pass Deliberation](https://doi.org/10.18653/v1/2023.findings-emnlp.44) |  | 0 | Though big progress in table-to-text works, effectively leveraging table structure signals, e.g., hierarchical structure, remains challenging. Besides, deliberating generated descriptions proves to be effective for table-to-text. However, determining the appropriate outcome when encountering multi-pass candidates is another challenge. To this end, we propose a novel table-to-text approach on top of Self-evaluated multi-pass Generation and Heterogenous Multidominance Attention, namely SG-HMA. Specifically, we formulate the table structure into a multidominance (MD) structure and devise a heterogenous multidominance attention (HMA) to comprehensively explore the complex interactions encoded in the hierarchical structure, which can further deliver rich signals for text generation with the help of pre-trained language models (PLMs). Afterward, a contrastive loss is introduced to align the generation objective with evaluation metrics, so the more faithful generated descriptions can be guaranteed. We conduct extensive experiments on three public datasets, demonstrating that SG-HMA outperforms several SOTA methods quantitatively and qualitatively. | Xi Chen, Xinjiang Lu, Haoran Xin, Wenjun Peng, Haoyang Duan, Feihu Jiang, Jingbo Zhou, Hui Xiong |  |
| 178 |  |  [Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting](https://doi.org/10.18653/v1/2023.findings-emnlp.45) |  | 0 | News media is expected to uphold unbiased reporting. Yet they may still affect public opinion by selectively including or omitting events that support or contradict their ideological positions. Prior work in NLP has only studied media bias via linguistic style and word usage. In this paper, we study to which degree media balances news reporting and affects consumers through event inclusion or omission. We first introduce the task of detecting both partisan and counter-partisan events: events that support or oppose the author’s political ideology. To conduct our study, we annotate a high-quality dataset, PAC, containing 8,511 (counter-)partisan event annotations in 304 news articles from ideologically diverse media outlets. We benchmark PAC to highlight the challenges of this task. Our findings highlight both the ways in which the news subtly shapes opinion and the need for large language models that better understand events within a broader context. Our dataset can be found at https://github.com/launchnlp/Partisan-Event-Dataset. | Kaijian Zou, Xinliang Frederick Zhang, Winston Wu, Nicholas Beauchamp, Lu Wang |  |
| 179 |  |  [Video-Text Retrieval by Supervised Sparse Multi-Grained Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.46) |  | 0 | While recent progress in video-text retrieval has been advanced by the exploration of better representation learning, in this paper, we present a novel multi-grained sparse learning framework, S3MA, to learn an aligned sparse space shared between the video and the text for video-text retrieval. The shared sparse space is initialized with a finite number of sparse concepts, each of which refers to a number of words. With the text data at hand, we learn and update the shared sparse space in a supervised manner using the proposed similarity and alignment losses. Moreover, to enable multi-grained alignment, we incorporate frame representations for better modeling the video modality and calculating fine-grained and coarse-grained similarities. Benefiting from the learned shared sparse space and multi-grained similarities, extensive experiments on several video-text retrieval benchmarks demonstrate the superiority of S3MA over existing methods. | Yimu Wang, Peng Shi |  |
| 180 |  |  [Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.47) |  | 0 | Intent discovery is a crucial task in natural language processing, and it is increasingly relevant for various of industrial applications. Identifying novel, unseen intents from user inputs remains one of the biggest challenges in this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for multilingual intent discovery relying on a Transformer architecture, fine-tuned with Adapters. We train the model for Natural Language Inference (NLI) and later perform unknown intent classification in a zero-shot setting for multiple languages. In our evaluation, we first analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance in casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters can effectively perform intent discovery by generating semantically similar intents, if not equal, to the ground-truth ones. Our experiments show how Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot settings: known intent classification and unseen intent discovery. The proposed pipeline holds the potential for broad application in customer care. It enables automated dynamic triage using a lightweight model that can be easily deployed and scaled in various business scenarios, unlike large language models. Zero-Shot-BERT-Adapters represents an innovative multi-language approach for intent discovery, enabling the online generation of novel intents. A Python package implementing the pipeline and the new datasets we compiled are available at the following link: https://github.com/GT4SD/zero-shot-bert-adapters. | Daniele Comi, Dimitrios Christofidellis, Pier Francesco Piazza, Matteo Manica |  |
| 181 |  |  [ReFSQL: A Retrieval-Augmentation Framework for Text-to-SQL Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.48) |  | 0 | Text-to-SQL is the task that aims at translating natural language questions into SQL queries. Existing methods directly align the natural language with SQL Language and train one encoder-decoder-based model to fit all questions. However, they underestimate the inherent structural characteristics of SQL, as well as the gap between specific structure knowledge and general knowledge. This leads to structure errors in the generated SQL. To address the above challenges, we propose a retrieval-argument framework, namely ReFSQL. It contains two parts, structure-enhanced retriever and the generator. Structure-enhanced retriever is designed to identify samples with comparable specific knowledge in an unsupervised way. Subsequently, we incorporate the retrieved samples’ SQL into the input, enabling the model to acquire prior knowledge of similar SQL grammar. To further bridge the gap between specific and general knowledge, we present a mahalanobis contrastive learning method, which facilitates the transfer of the sample toward the specific knowledge distribution constructed by the retrieved samples. Experimental results on five datasets verify the effectiveness of our approach in improving the accuracy and robustness of Text-to-SQL generation. Our framework has achieved improved performance when combined with many other backbone models (including the 11B flan-T5) and also achieved state-of-the-art performance when compared to existing methods that employ the fine-tuning approach. | Kun Zhang, Xiexiong Lin, Yuanzhuo Wang, Xin Zhang, Fei Sun, Jianhe Cen, Hexiang Tan, Xuhui Jiang, Huawei Shen |  |
| 182 |  |  [Approximating Two-Layer Feedforward Networks for Efficient Transformers](https://doi.org/10.18653/v1/2023.findings-emnlp.49) |  | 0 | How to reduce compute and memory requirements of neural networks (NNs) without sacrificing performance? Many recent works use sparse Mixtures of Experts (MoEs) to build resource-efficient large language models (LMs). Here we introduce several novel perspectives on MoEs, presenting a general framework that \*unifies\* various methods to \*approximate two-layer NNs\* (e.g., feedforward blocks of Transformers), including product-key memories (PKMs). Leveraging insights from this framework, we propose methods to improve both MoEs and PKMs. Unlike prior work that compares MoEs with dense baselines under the \*compute-equal\* condition, our evaluation condition is \*parameter-equal\*, which is crucial to properly evaluate LMs. We show that our MoEs are competitive with the \*dense\* Transformer-XL on both the WikiText-103 and enwiki8 datasets at two different scales, while being much more resource efficient. This demonstrates that MoEs are relevant not only to extremely large LMs but also to any-scale resource-efficient LMs. Our code is public. | Róbert Csordás, Kazuki Irie, Jürgen Schmidhuber |  |
| 183 |  |  [Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.50) |  | 0 | Adapting a large language model for multiple-attribute text style transfer via fine-tuning can be challenging due to the substantial amount of computational resources and labeled data required for the specific downstream task. In this paper, we address this challenge by introducing Adapter-TST, a framework that freezes the pre-trained model’s original parameters and enables the development of a multiple-attribute text style transfer model. Using BART as the backbone model, Adapter-TST utilizes different neural adapters to model different types of attribute information, similar to a plug-in connected to BART. Our method allows control over multiple attributes (e.g. sentiment, tense, active or passive voice) and configures the adapters’ architecture to generate multiple outputs in respect to attributes or compositional editing on the same sentence. We evaluate the proposed model on both traditional sentiment transfer and multiple-attribute transfer tasks. The experiment results demonstrate that Adapter-TST outperforms all the state-of-the-art baselines with significantly less computational resources. We have also empirically shown that each adapter is able to characterize specific stylistic attributes effectively and can be configured to perform compositional editing. | Zhiqiang Hu, Nancy F. Chen, Roy KaWei Lee |  |
| 184 |  |  [Solving the Right Problem is Key for Translational NLP: A Case Study in UMLS Vocabulary Insertion](https://doi.org/10.18653/v1/2023.findings-emnlp.51) |  | 0 | As the immense opportunities enabled by large language models become more apparent, NLP systems will be increasingly expected to excel in real-world settings. However, in many instances, powerful models alone will not yield translational NLP solutions, especially if the formulated problem is not well aligned with the real-world task. In this work, we study the case of UMLS vocabulary insertion, an important real-world task in which hundreds of thousands of new terms, referred to as atoms, are added to the UMLS, one of the most comprehensive open-source biomedical knowledge bases. Previous work aimed to develop an automated NLP system to make this time-consuming, costly, and error-prone task more efficient. Nevertheless, practical progress in this direction has been difficult to achieve due to a problem formulation and evaluation gap between research output and the real-world task. In order to address this gap, we introduce a new formulation for UMLS vocabulary insertion which mirrors the real-world task, datasets which faithfully represent it and several strong baselines we developed through re-purposing existing solutions. Additionally, we propose an effective rule-enhanced biomedical language model which enables important new model behavior, outperforms all strong baselines and provides measurable qualitative improvements to editors who carry out the UVI task. We hope this case study provides insight into the considerable importance of problem formulation for the success of translational NLP solutions. | Bernal Jimenez Gutierrez, Yuqing Mao, Vinh Nguyen, Kin Wah Fung, Yu Su, Olivier Bodenreider |  |
| 185 |  |  [Improving Cross-lingual Transfer through Subtree-aware Word Reordering](https://doi.org/10.18653/v1/2023.findings-emnlp.52) |  | 0 | Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via source- or target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consistently outperforms strong baselines over different language pairs and model architectures. This performance advantage holds true in both zero-shot and few-shot scenarios. | Ofir Arviv, Dmitry Nikolaev, Taelin Karidi, Omri Abend |  |
| 186 |  |  [Novel Slot Detection With an Incremental Setting](https://doi.org/10.18653/v1/2023.findings-emnlp.53) |  | 0 | Current dialogue systems face diverse user requests and rapid change domains, making quickly adapt to scenarios with previous unseen slot types become a major challenge. Recently, researchers have introduced novel slot detection (NSD) to discover potential new types. However, dialogue system with NSD does not bring practical improvements due to the system still cannot handle novel slots in subsequent interactions. In this paper, we define incremental novel slot detection (INSD), which separates the dialogue system to deal with novel types as two major phrases: 1) model discovers unknown slots, 2) training model to possess the capability to handle new classes. We provide an effective model to extract novel slots with set prediction strategy and propose a query-enhanced approach to overcome catastrophic forgetting during the process of INSD. We construct two INSD datasets to evaluate our method and experimental results show that our approach exhibits superior performance. | Chen Liang, Hongliang Li, Changhao Guan, Qingbin Liu, Jian Liu, Jinan Xu, Zhe Zhao |  |
| 187 |  |  [Self-supervised Post-processing Method to Enrich Pretrained Word Vectors](https://doi.org/10.18653/v1/2023.findings-emnlp.54) |  | 0 | Retrofitting techniques, which inject external resources into word representations, have compensated for the weakness of distributed representations in semantic and relational knowledge between words. However, the previous methods require additional external resources and strongly depend on the lexicon. To address the issues, we propose a simple extension of extrofitting, self-supervised extrofitting: extrofitting by its own word vector distribution. Our methods improve the vanilla embeddings on all of word similarity tasks without any external resources. Moreover, the method is also effective in various languages, which implies that our method will be useful in lexicon-scarce languages. As downstream tasks, we show its benefits in dialogue state tracking and text classification tasks, reporting better and generalized results compared to other word vector specialization methods. | Hwiyeol Jo |  |
| 188 |  |  [Automatic Model Selection with Large Language Models for Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.55) |  | 0 | Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two distinct reasoning methods, each with its own strengths. CoT employs natural language, offering flexibility and interpretability, while PAL utilizes programming language, yielding more structured and rigorous logic. We introduce a model selection method to combine the best of both worlds by employing a large language model (LLM) to dynamically select between them. Our theoretical analysis underscores the feasibility of this method, which is further corroborated by empirical results. Our proposed method demonstrates significant performance improvements across eight reasoning datasets with Codex, ChatGPT, and GPT-4. Additionally, our method is complementary to self-consistency; when integrated, it can further enhance performance while significantly reducing computation costs. Moreover, we achieve new state-of-the-art results on GSM8K and SVAMP, with respective accuracies of 96.8% and 93.7%. | James Xu Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, Michael Qizhe Xie |  |
| 189 |  |  [ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes](https://doi.org/10.18653/v1/2023.findings-emnlp.56) |  | 0 | 3D referring expression comprehension is a task to ground text representations onto objects in 3D scenes. It is a crucial task for indoor household robots or augmented reality devices to localize objects referred to in user instructions. However, existing indoor 3D referring expression comprehension datasets typically cover larger object classes that are easy to localize, such as chairs, tables, or doors, and often overlook small objects, such as cooking tools or office supplies. Based on the recently proposed diverse and high-resolution 3D scene dataset of ARKitScenes, we construct the ARKitSceneRefer dataset focusing on small daily-use objects that frequently appear in real-world indoor scenes. ARKitSceneRefer contains 15k objects of 1,605 indoor scenes, which are significantly larger than those of the existing 3D referring datasets, and covers diverse object classes of 583 from the LVIS dataset. In empirical experiments with both 2D and 3D state-of-the-art referring expression comprehension models, we observed the task difficulty of the localization in the diverse small object classes. | Shunya Kato, Shuhei Kurita, Chenhui Chu, Sadao Kurohashi |  |
| 190 |  |  [Improving Question Generation with Multi-level Content Planning](https://doi.org/10.18653/v1/2023.findings-emnlp.57) |  | 0 | This paper addresses the problem of generating questions from a given context and an answer, specifically focusing on questions that require multi-hop reasoning across an extended context. Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context. To mitigate this issue, we propose MultiFactor, a novel QG framework based on multi-level content planning. Specifically, MultiFactor includes two components: FA-Model, which simultaneously selects key phrases and generates full answers, and Q-Model which takes the generated full answer as an additional input to generate questions. Here, full answer generation is introduced to connect the short answer with the selected key phrases, thus forming an answer-aware summary to facilitate QG. Both FA-Model and Q-Model are formalized as simple-yet-effective Phrase-Enhanced Transformers, our joint model for phrase selection and text generation. Experimental results show that our method outperforms strong baselines on two popular QG datasets. Our code is available at https://github.com/zeaver/MultiFactor. | Zehua Xia, Qi Gou, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li, CamTu Nguyen |  |
| 191 |  |  [Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing](https://doi.org/10.18653/v1/2023.findings-emnlp.58) |  | 0 | The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of fine-tuned auto-encoding language models (BERT, RoBERTa, FinBERT) and the LLM ChatGPT. Our findings reveal that while ChatGPT demonstrates notable performance across most financial tasks, it generally lags behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study builds foundation evaluation benchmarks for continuing efforts to build more advanced LLMs in the financial domain. | Yue Guo, Zian Xu, Yi Yang |  |
| 192 |  |  [DelucionQA: Detecting Hallucinations in Domain-specific Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.59) |  | 0 | Hallucination is a well-known phenomenon in text generated by large language models (LLMs). The existence of hallucinatory responses is found in almost all application scenarios e.g., summarization, question-answering (QA) etc. For applications requiring high reliability (e.g., customer-facing assistants), the potential existence of hallucination in LLM-generated text is a critical problem. The amount of hallucination can be reduced by leveraging information retrieval to provide relevant background information to the LLM. However, LLMs can still generate hallucinatory content for various reasons (e.g., prioritizing its parametric knowledge over the context, failure to capture the relevant information from the context, etc.). Detecting hallucinations through automated methods is thus paramount. To facilitate research in this direction, we introduce a sophisticated dataset, DelucionQA, that captures hallucinations made by retrieval-augmented LLMs for a domain-specific QA task. Furthermore, we propose a set of hallucination detection methods to serve as baselines for future works from the research community. Analysis and case study are also provided to share valuable insights on hallucination phenomena in the target scenario. | Mobashir Sadat, Zhengyu Zhou, Lukas Lange, Jun Araki, Arsalan Gundroo, Bingqing Wang, Rakesh R. Menon, Md. Rizwan Parvez, Zhe Feng |  |
| 193 |  |  [InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution](https://doi.org/10.18653/v1/2023.findings-emnlp.60) |  | 0 | Over recent decades, significant advancements in cross-modal retrieval is mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance. | Xiangru Jian, Yimu Wang |  |
| 194 |  |  [Dissecting In-Context Learning of Translations in GPT-3](https://doi.org/10.18653/v1/2023.findings-emnlp.61) |  | 0 | Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting. In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations. We find that asymmetric perturbation of the source-target mappings yield vastly different results. We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations. We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting. We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations. | Vikas Raunak, Arul Menezes, Hany Hassan Awadalla |  |
| 195 |  |  [Social Commonsense-Guided Search Query Generation for Open-Domain Knowledge-Powered Conversations](https://doi.org/10.18653/v1/2023.findings-emnlp.62) |  | 0 | Open-domain dialog involves generating search queries that help obtain relevant knowledge for holding informative conversations. However, it can be challenging to determine what information to retrieve when the user is passive and does not express a clear need or request. To tackle this issue, we present a novel approach that focuses on generating internet search queries that are guided by social commonsense. Specifically, we leverage a commonsense dialog system to establish connections related to the conversation topic, which subsequently guides our query generation. Our proposed framework addresses passive user interactions by integrating topic tracking, commonsense response generation and instruction-driven query generation. Through extensive evaluations, we show that our approach overcomes limitations of existing query generation techniques that rely solely on explicit dialog information, and produces search queries that are more relevant, specific, and compelling, ultimately resulting in more engaging responses. | Revanth Gangi Reddy, Hao Bai, Wentao Yao, Sharath Chandra Etagi Suresh, Heng Ji, ChengXiang Zhai |  |
| 196 |  |  [MixTEA: Semi-supervised Entity Alignment with Mixture Teaching](https://doi.org/10.18653/v1/2023.findings-emnlp.63) |  | 0 | Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method. | Feng Xie, Xin Song, Xiang Zeng, Xuechen Zhao, Lei Tian, Bin Zhou, Yusong Tan |  |
| 197 |  |  [EZ-STANCE: A Large Dataset for Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.64) |  | 0 |  | Chenye Zhao, Cornelia Caragea |  |
| 198 |  |  [Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.65) |  | 0 | Neural ‘dense’ retrieval models are state of the art for many datasets, however these models often exhibit limited domain transfer ability. Existing approaches to adaptation are unwieldy, such as requiring explicit supervision, complex model architectures, or massive external models. We present ABEL, a simple but effective unsupervised method to enhance passage retrieval in zero-shot settings. Our technique follows a straightforward loop: a dense retriever learns from supervision signals provided by a reranker, and subsequently, the reranker is updated based on feedback from the improved retriever. By iterating this loop, the two components mutually enhance one another’s performance. Experimental results demonstrate that our unsupervised ABEL model outperforms both leading supervised and unsupervised retrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation abilities to tasks and domains that were unseen during training. By either fine-tuning ABEL on labelled data or integrating it with existing supervised dense retrievers, we achieve state-of-the-art results. | Fan Jiang, Qiongkai Xu, Tom Drummond, Trevor Cohn |  |
| 199 |  |  [TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.66) |  | 0 | Large-scale video-language pre-training has made remarkable strides in advancing video-language understanding tasks. However, the heavy computational burden of video encoding remains a formidable efficiency bottleneck, particularly for long-form videos. These videos contain massive visual tokens due to their inherent 3D properties and spatiotemporal redundancy, making it challenging to capture complex temporal and spatial relationships. To tackle this issue, we propose an efficient method called TEmporal-Spatial Token Aggregation (TESTA). TESTA condenses video semantics by adaptively aggregating similar frames, as well as similar patches within each frame. TESTA can reduce the number of visual tokens by 75% and thus accelerate video encoding. Building upon TESTA, we introduce a pre-trained video-language model equipped with a divided space-time token aggregation module in each video encoder block. We evaluate our model on five datasets for paragraph-to-video retrieval and long-form VideoQA tasks. Experimental results show that TESTA improves computing efficiency by 1.7 times, and achieves significant performance gains from its scalability in processing longer input frames, e.g., +13.7 R@1 on QuerYD and +6.5 R@1 on Condensed Movie. | Shuhuai Ren, Sishuo Chen, Shicheng Li, Xu Sun, Lu Hou |  |
| 200 |  |  [Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.67) |  | 0 | Answering time-sensitive questions from long documents requires temporal reasoning over the times in questions and documents. An important open question is whether large language models can perform such reasoning solely using a provided text document, or whether they can benefit from additional temporal information extracted using other systems. We address this research question by applying existing temporal information extraction systems to construct temporal graphs of events, times, and temporal relations in questions and documents. We then investigate different approaches for fusing these graphs into Transformer models. Experimental results show that our proposed approach for fusing temporal graphs into input text substantially enhances the temporal reasoning capabilities of Transformer models with or without fine-tuning. Additionally, our proposed method outperforms various graph convolution-based approaches and establishes a new state-of-the-art performance on SituatedQA and three splits of TimeQA. | Xin Su, Phillip Howard, Nagib Hakim, Steven Bethard |  |
| 201 |  |  [The Internal State of an LLM Knows When It's Lying](https://doi.org/10.18653/v1/2023.findings-emnlp.68) |  | 0 | While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM’s internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71% to 83% accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier’s performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios. | Amos Azaria, Tom M. Mitchell |  |
| 202 |  |  [Factual Relation Discrimination for Factuality-oriented Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.69) |  | 0 | Most neural abstractive summarization models are capable of producing high-quality summaries. However, they still frequently contain factual errors. Existing factuality-oriented abstractive summarization models only consider the integration of factual information and ignore the causes of factual errors. To address this issue, we propose a factuality-oriented abstractive summarization model DASum, which is based on a new task factual relation discrimination that is able to identify the causes of factual errors. First, we use data augmentation methods to construct counterfactual summaries (i. e., negative samples), and build a factual summarization dataset. Then, we propose the factual relation discrimination task, which determines the factuality of the dependency relations in summaries during summary generation and guides our DASum to generate factual relations, thereby improving the factuality of summaries. Experimental results on the CNN/DM and XSUM datasets show that our DASum outperforms several state-of-the-art benchmarks in terms of the factual metrics. | Zhiguang Gao, Peifeng Li, Feng Jiang, Xiaomin Chu, Qiaoming Zhu |  |
| 203 |  |  [Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment](https://doi.org/10.18653/v1/2023.findings-emnlp.70) |  | 0 | Multi-Modal Entity Alignment (MMEA) is a critical task that aims to identify equivalent entity pairs across multi-modal knowledge graphs (MMKGs). However, this task faces challenges due to the presence of different types of information, including neighboring entities, multi-modal attributes, and entity types. Directly incorporating the above information (e.g., concatenation or attention) can lead to an unaligned information space. To address these challenges, we propose a novel MMEA transformer, called Meaformer, that hierarchically introduces neighbor features, multi-modal attributes, and entity types to enhance the alignment task. Taking advantage of the transformer’s ability to better integrate multiple information, we design a hierarchical modifiable self-attention block in a transformer encoder to preserve the unique semantics of different information. Furthermore, we design two entity-type prefix injection methods to redintegrate entity-type information using type prefixes, which help to restrict the global information of entities not present in the MMKGs. | Qian Li, Cheng Ji, Shu Guo, Zhaoji Liang, Lihong Wang, Jianxin Li |  |
| 204 |  |  [Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries](https://doi.org/10.18653/v1/2023.findings-emnlp.71) |  | 0 | We study how multilingual sentence representations capture European countries and occupations and how this differs across European languages. We prompt the models with templated sentences that we machine-translate into 12 European languages and analyze the most prominent dimensions in the embeddings. Our analysis reveals that the most prominent feature in the embedding is the political distinction between Eastern and Western Europe and the country’s economic strength in terms of GDP. When prompted specifically for job prestige, the embedding space clearly distinguishes high and low-prestige jobs. The occupational dimension is uncorrelated with the most dominant country dimensions in three out of four studied models. The exception is a small distilled model that exhibits a connection between occupational prestige and country of origin, which is a potential source of nationality-based discrimination. Our findings are consistent across languages. | Jindrich Libovický |  |
| 205 |  |  [Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.72) |  | 0 | Large Language Models (LLMs) have generated considerable interest and debate regarding their potential emergence of Theory of Mind (ToM). Several recent inquiries reveal a lack of robust ToM in these models and pose a pressing demand to develop new benchmarks, as current ones primarily focus on different aspects of ToM and are prone to shortcuts and data leakage. In this position paper, we seek to answer two road-blocking questions: (1) How can we taxonomize a holistic landscape of machine ToM? (2) What is a more effective evaluation protocol for machine ToM? Following psychological studies, we taxonomize machine ToM into 7 mental state categories and delineate existing benchmarks to identify under-explored aspects of ToM. We argue for a holistic and situated evaluation of ToM to break ToM into individual components and treat LLMs as an agent who is physically situated in environments and socially situated in interactions with humans. Such situated evaluation provides a more comprehensive assessment of mental states and potentially mitigates the risk of shortcuts and data leakage. We further present a pilot study in a grid world setup as a proof of concept. We hope this position paper can facilitate future research to integrate ToM with LLMs and offer an intuitive means for researchers to better position their work in the landscape of ToM. | Ziqiao Ma, Jacob Sansom, Run Peng, Joyce Chai |  |
| 206 |  |  [Text Augmented Spatial Aware Zero-shot Referring Image Segmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.73) |  | 0 | In this paper, we study a challenging task of zero-shot referring image segmentation. This task aims to identify the instance mask that is most related to a referring expression without training on pixel-level annotations. Previous research takes advantage of pre-trained cross-modal models, e.g., CLIP, to align instance-level masks with referring expressions. Yet, CLIP only considers the global-level alignment of image-text pairs, neglecting fine-grained matching between the referring sentence and local image regions. To address this challenge, we introduce a Text Augmented Spatial-aware (TAS) zero-shot referring image segmentation framework that is training-free and robust to various visual encoders. TAS incorporates a mask proposal network for instance-level mask extraction, a text-augmented visual-text matching score for mining the image-text correlation, and a spatial rectifier for mask post-processing. Notably, the text-augmented visual-text matching score leverages a P-score and an N-score in addition to the typical visual-text matching score. The P-score is utilized to close the visual-text domain gap through a surrogate captioning model, where the score is computed between the surrogate model-generated texts and the referring expression. The N-score considers the fine-grained alignment of region-text pairs via negative phrase mining, encouraging the masked image to be repelled from the mined distracting phrases. Extensive experiments are conducted on various datasets, including RefCOCO, RefCOCO+, and RefCOCOg. The proposed method clearly outperforms state-of-the-art zero-shot referring image segmentation methods. | Yucheng Suo, Linchao Zhu, Yi Yang |  |
| 207 |  |  [IRFL: Image Recognition of Figurative Language](https://doi.org/10.18653/v1/2023.findings-emnlp.74) |  | 0 | Figures of speech such as metaphors, similes, and idioms are integral parts of human communication. They are ubiquitous in many forms of discourse, allowing people to convey complex, abstract ideas and evoke emotion. As figurative forms are often conveyed through multiple modalities (e.g., both text and images), understanding multimodal figurative language is an important AI challenge, weaving together profound vision, language, commonsense and cultural knowledge. In this work, we develop the Image Recognition of Figurative Language (IRFL) dataset. We leverage human annotation and an automatic pipeline we created to generate a multimodal dataset, and introduce two novel tasks as a benchmark for multimodal figurative language understanding. We experimented with state-of-the-art vision and language models and found that the best (22%) performed substantially worse than humans (97%). We release our dataset, benchmark, and code in hopes of driving the development of models that can better understand figurative language. | Ron Yosef, Yonatan Bitton, Dafna Shahaf |  |
| 208 |  |  [Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization](https://doi.org/10.18653/v1/2023.findings-emnlp.75) |  | 0 | Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily overfit to few-shot training samples, thereby undermining generalizability. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they fail to data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with MEta-gradient Regularization for few-shot generalization (SUPMER). SUPMER leverages self-supervised meta-learning with a diverse set of well-designed meta-tasks to learn a universal prompt initialization for efficient adaptation using only unlabeled data. Additionally, it jointly meta-learns a gradient regularization function to transform raw gradients into a domain-generalizable direction, thus alleviating the problem of overfitting. Extensive experiments show that SUPMER achieves better performance for different few-shot downstream tasks, and also exhibits a stronger domain generalization ability. The code for SUPMER will be available at https://github.com/beepkh/SUPMER. | Kaihang Pan, Juncheng Li, Hongye Song, Jun Lin, Xiaozhong Liu, Siliang Tang |  |
| 209 |  |  [An Adaptive Prompt Generation Framework for Task-oriented Dialogue System](https://doi.org/10.18653/v1/2023.findings-emnlp.76) |  | 0 | The de facto way of utilizing black-box large language models (LLMs) to perform various downstream tasks is prompting. However, obtaining suitable prompts for specific tasks is still a challenging problem. While existing LLM-based methods demonstrate promising performance in task-oriented dialogue (TOD) task, they often require manual adjustment in prompt selection, or focus solely on dialogue understanding or generation. To address these issues, we propose an adaptive prompt generation framework to fully unleash the potential of LLMs for the comprehensive TOD system. Firstly, we design a trainable slot generator (TSG) that can generate domain and slot information in the belief state, which serves as prior knowledge for subsequent prompt generation. Next, we propose an adaptive prompt generator (APG) that utilizes the prior knowledge to generate prompts for the LLM, deriving the belief state and system response of the dialogue for evaluation. Finally, we evaluate our framework on the MultiWOZ 2.0 dataset. Extensive experiments demonstrate that our method outperforms existing methods. Our code and data will be released. | Jun Gao, Liuyu Xiang, Huijia Wu, Han Zhao, Yiqi Tong, Zhaofeng He |  |
| 210 |  |  [Temporal Knowledge Graph Reasoning Based on N-tuple Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.77) |  | 0 | Reasoning over Temporal Knowledge Graphs (TKGs) that predicts temporal facts (e.g., events) in the future is crucial for many applications. The temporal facts in existing TKGs only contain their core entities (i.e., the entities playing core roles therein) and formulate them as quadruples, i.e., (subject entity, predicate, object entity, timestamp). This formulation oversimplifies temporal facts and inevitably causes information loss. Therefore, we propose to describe a temporal fact more accurately as an n-tuple, containing not only its predicate and core entities, but also its auxiliary entities, as well as the roles of all entities. By so doing, TKGs are augmented to N-tuple Temporal Knowledge Graphs (N-TKGs). To conduct reasoning over N-TKGs, we further propose N-tuple Evolutional Network (NE-Net). It recurrently learns the evolutional representations of entities and predicates in temporal facts at different timestamps in the history via modeling the relations among those entities and predicates. Based on the learned representations, reasoning tasks at future timestamps can be realized via task-specific decoders. Experiment results on two newly built datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net. | Zhongni Hou, Xiaolong Jin, Zixuan Li, Long Bai, Saiping Guan, Yutao Zeng, Jiafeng Guo, Xueqi Cheng |  |
| 211 |  |  [Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making](https://doi.org/10.18653/v1/2023.findings-emnlp.78) |  | 0 | Explaining black-box model behavior with natural language has achieved impressive results in various NLP tasks. Recent research has explored the utilization of subsequences from the input text as a rationale, providing users with evidence to support the model decision. Although existing frameworks excel in generating high-quality rationales while achieving high task performance, they neglect to account for the unreliable link between the generated rationale and model decision. In simpler terms, a model may make correct decisions while attributing wrong rationales, or make poor decisions while attributing correct rationales. To mitigate this issue, we propose a unified two-stage framework known as Self-Attribution and Decision-Making (SADM). Through extensive experiments on five reasoning datasets from the ERASER benchmark, we demonstrate that our framework not only establishes a more reliable link between the generated rationale and model decision but also achieves competitive results in task performance and the quality of rationale. Furthermore, we explore the potential of our framework in semi-supervised scenarios. | Yanrui Du, Sendong Zhao, Haochun Wang, Yuhan Chen, Rui Bai, Zewen Qiang, Muzhen Cai, Bing Qin |  |
| 212 |  |  [Adaptive Structure Induction for Aspect-based Sentiment Analysis with Spectral Perspective](https://doi.org/10.18653/v1/2023.findings-emnlp.79) |  | 0 | Recently, incorporating structure information (e.g. dependency syntactic tree) can enhance the performance of aspect-based sentiment analysis (ABSA). However, this structure information is obtained from off-the-shelf parsers, which is often sub-optimal and cumbersome. Thus, automatically learning adaptive structures is conducive to solving this problem. In this work, we concentrate on structure induction from pre-trained language models (PLMs) and throw the structure induction into a spectrum perspective to explore the impact of scale information in language representation on structure induction ability. Concretely, the main architecture of our model is composed of commonly used PLMs (e.g. RoBERTa, etc), and a simple yet effective graph structure learning (GSL) module (graph learner + GNNs). Subsequently, we plug in spectral filters with different bands respectively after the PLMs to produce filtered language representations and feed them into the GSL module to induce latent structures. We conduct extensive experiments on three public benchmarks for ABSA. The results and further analyses demonstrate that introducing this spectral approach can shorten Aspects-sentiment Distance (AsD) and be beneficial to structure induction. Even based on such a simple framework, the effects on three datasets can reach SOTA (state of the art) or near SOTA performance. Additionally, our exploration also has the potential to be generalized to other tasks or to bring inspiration to other similar domains. | Hao Niu, Yun Xiong, Xiaosu Wang, Wenjing Yu, Yao Zhang, Zhonglei Guo |  |
| 213 |  |  [NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.80) |  | 0 | We present NovaCOMET, an open commonsense knowledge model, that combines the best aspects of knowledge and general task models. Compared to previous knowledge models, NovaCOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, it explicitly centers knowledge, enabling superior performance for commonsense reasoning. NovaCOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NovATOMIC, a publicly-releaseddiscrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NovaCOMET on NovATOMIC by fine-tuning an open-source pretrained model. NovaCOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs. The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like Flan-T5 on a range of commonsense generation tasks. NovaCOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well. | Peter West, Ronan Le Bras, Taylor Sorensen, Bill Yuchen Lin, Liwei Jiang, Ximing Lu, Khyathi Raghavi Chandu, Jack Hessel, Ashutosh Baheti, Chandra Bhagavatula, Yejin Choi |  |
| 214 |  |  [In-Context Demonstration Selection with Cross Entropy Difference](https://doi.org/10.18653/v1/2023.findings-emnlp.81) |  | 0 | Large language models (LLMs) can use in-context demonstrations to improve performance on zero-shot tasks. However, selecting the best in-context examples is challenging because model performance can vary widely depending on the selected examples. We present a cross-entropy difference (CED) method for selecting in-context demonstrations. Our method is based on the observation that the effectiveness of in-context demonstrations negatively correlates with the perplexity of the test example by a language model that was finetuned on that demonstration. We utilize parameter efficient finetuning to train small models on training data that are used for computing the cross-entropy difference between a test example and every candidate in-context demonstration. This metric is used to rank and select in-context demonstrations independently for each test input. We evaluate our method on a mix-domain dataset that combines 8 benchmarks, representing 4 text generation tasks, showing that CED for in-context demonstration selection can improve performance for a variety of LLMs over baseline selection methods. | Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu |  |
| 215 |  |  [The Past, Present, and Future of Typological Databases in NLP](https://doi.org/10.18653/v1/2023.findings-emnlp.82) |  | 0 | Typological information has the potential to be beneficial in the development of NLP models, particularly for low-resource languages. Unfortunately, current large-scale typological databases, notably WALS and Grambank, are inconsistent both with each other and with other sources of typological information, such as linguistic grammars. Some of these inconsistencies stem from coding errors or linguistic variation, but many of the disagreements are due to the discrete categorical nature of these databases. We shed light on this issue by systematically exploring disagreements across typological databases and resources, and their uses in NLP, covering the past and present. We next investigate the future of such work, offering an argument that a continuous view of typological features is clearly beneficial, echoing recommendations from linguistics. We propose that such a view of typology has significant potential in the future, including in language modeling in low-resource scenarios. | Emi Baylor, Esther Ploeger, Johannes Bjerva |  |
| 216 |  |  [SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations](https://doi.org/10.18653/v1/2023.findings-emnlp.83) |  | 0 | Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant. | Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu Wang, Qi Liu, Xiangmin Xu |  |
| 217 |  |  [Can ChatGPT Assess Human Personalities? A General Evaluation Framework](https://doi.org/10.18653/v1/2023.findings-emnlp.84) |  | 0 | Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers–Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and GPT-4. Our experiments reveal ChatGPT’s ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT. | Haocong Rao, Cyril Leung, Chunyan Miao |  |
| 218 |  |  [MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model](https://doi.org/10.18653/v1/2023.findings-emnlp.85) |  | 0 | Multi-modal open-domain question answering typically requires evidence retrieval from databases across diverse modalities, such as images, tables, passages, etc. Even Large Language Models (LLMs) like GPT-4 fall short in this task. To enable LLMs to tackle the task in a zero-shot manner, we introduce MoqaGPT, a straightforward and flexible framework. Using a divide-and-conquer strategy that bypasses intricate multi-modality ranking, our framework can accommodate new modalities and seamlessly transition to new models for the task. Built upon LLMs, MoqaGPT retrieves and extracts answers from each modality separately, then fuses this multi-modal information using LLMs to produce a final answer. Our methodology boosts performance on the MMCoQA dataset, improving F1 by +37.91 points and EM by +34.07 points over the supervised baseline. On the MultiModalQA dataset, MoqaGPT surpasses the zero-shot baseline, improving F1 by 9.5 points and EM by 10.1 points, and significantly closes the gap with supervised methods. Our codebase is available at https://github.com/lezhang7/MOQAGPT. | Le Zhang, Yihong Wu, Fengran Mo, JianYun Nie, Aishwarya Agrawal |  |
| 219 |  |  [Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search](https://doi.org/10.18653/v1/2023.findings-emnlp.86) |  | 0 | Precisely understanding users’ contextual search intent has been an important challenge for conversational search. As conversational search sessions are much more diverse and long-tailed, existing methods trained on limited data still show unsatisfactory effectiveness and robustness to handle real conversational search scenarios. Recently, large language models (LLMs) have demonstrated amazing capabilities for text generation and conversation understanding. In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search. Under this framework, we explore three prompting methods to generate multiple query rewrites and hypothetical responses, and propose to aggregate them into an integrated representation that can robustly represent the user’s real contextual search intent. Extensive automatic evaluations and human evaluations on three widely used conversational search benchmarks, including CAsT-19, CAsT-20, and CAsT-21, demonstrate the remarkable performance of our simple LLM4CS framework compared with existing methods and even using human rewrites. Our findings provide important evidence to better understand and leverage LLMs for conversational search. | Kelong Mao, Zhicheng Dou, Fengran Mo, Jiewen Hou, Haonan Chen, Hongjin Qian |  |
| 220 |  |  [DocAsRef: An Empirical Study on Repurposing Reference-based Summary Quality Metrics as Reference-free Metrics](https://doi.org/10.18653/v1/2023.findings-emnlp.87) |  | 0 | Automated summary quality assessment falls into two categories: reference-based and reference-free. Reference-based metrics, historically deemed more accurate due to the additional information provided by human-written references, are limited by their reliance on human input. In this paper, we hypothesize that the comparison methodologies used by some reference-based metrics to evaluate a system summary against its corresponding reference can be effectively adapted to assess it against its source document, thereby transforming these metrics into reference-free ones. Experimental results support this hypothesis. After being repurposed reference-freely, the zero-shot BERTScore using the pretrained DeBERTa-large-MNLI model of <0.5B parameters consistently outperforms its original reference-based version across various aspects on the SummEval and Newsroom datasets. It also excels in comparison to most existing reference-free metrics and closely competes with zero-shot summary evaluators based on GPT-3.5. | Forrest Sheng Bao, Ruixuan Tu, Ge Luo, Yinfei Yang, Hebi Li, Minghui Qiu, Youbiao He, Cen Chen |  |
| 221 |  |  [Toxicity in chatgpt: Analyzing persona-assigned language models](https://doi.org/10.18653/v1/2023.findings-emnlp.88) |  | 0 | Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a “Blueprint For An AI Bill Of Rights” which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6×, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others (3× more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI. | Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan |  |
| 222 |  |  [Execution-Based Evaluation for Open-Domain Code Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.89) |  | 0 | To extend the scope of coding queries to more realistic settings, we propose ODEX, the first Open-Domain EXecution-based natural language (NL) to Python code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries, along with 1,707 human-written test cases for execution. Our NL-Code pairs are harvested from StackOverflow forums to encourage natural and practical coding queries. Moreover, ODEX supports four natural languages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing behavioral differences among top-performing code language models (LM). While CODEX achieves better overall results, CODEGEN improves effectively via scaling – CODEGEN 6.1B performs comparably with CODEX 12B. Both models show substantial gaps between open and closed domains, but CODEGEN gaps tend to decrease with model size while CODEX gaps increase. We release ODEX to facilitate research into open-domain problems for the code generation community. | Zhiruo Wang, Shuyan Zhou, Daniel Fried, Graham Neubig |  |
| 223 |  |  [Syntax-Aware Retrieval Augmented Code Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.90) |  | 0 | Neural code generation models are nowadays widely adopted to generate code from natural language descriptions automatically. Recently, pre-trained neural models equipped with token-level retrieval capabilities have exhibited great potentials in neural machine translation. However, applying them directly to code generation experience challenges: the use of the retrieval-based mechanism inevitably introduces extraneous noise to the generation process, resulting in even syntactically incorrect code. Computationally, such models necessitate frequent searches of the cached datastore, which turns out to be time-consuming. To address these issues, we propose kNN-TRANX, a token-level retrieval augmented code generation method. kNN-TRANX allows for searches in smaller datastores tailored for the code generation task. It leverages syntax constraints for the retrieval of datastores, which reduces the impact of retrieve noise. We evaluate kNN-TRANX on two public datasets and the experimental results confirm the effectiveness of our approach. | Xiangyu Zhang, Yu Zhou, Guang Yang, Taolue Chen |  |
| 224 |  |  [Selecting Key Views for Zero-Shot Entity Linking](https://doi.org/10.18653/v1/2023.findings-emnlp.91) |  | 0 | Entity linking, which aligns mentions in the text to entities in knowledge bases, is essential for many natural language processing tasks. Considering the real-world scenarios, recent research hotspot of entity linking has focused on the zero-shot setting, where mentions need to link to unseen entities and only the description of each entity is provided. This task challenges the language understanding ability of models to capture the coherence evidence between the mention context and entity description. However, entity descriptions often contain rich information from multiple views, and a mention with context only relates to a small part of the information. Other irrelevant information will introduce noise, which interferes with models to make the right judgments. Furthermore, the existence of these information also makes it difficult to synthesize key information. To solve these problems, we select key views from descriptions and propose a KVZEL framework for zero-shot entity linking. Specifically, our KVZEL first adopts unsupervised clustering to form sub views. Then, it employs a mention-aware key views selection module to iteratively accumulate mention-focused views. This puts emphasis on capturing mention-related information and allows long-range key information integration. Finally, we aggregate key views to make the final decision. Experimental results show the effectiveness of our KVZEL and it achieves the new state-of-the-art on the zero-shot entity linking dataset. | Xuhui Sui, Ying Zhang, Kehui Song, Baohang Zhou, Xiaojie Yuan, Wensheng Zhang |  |
| 225 |  |  [Is Explanation the Cure? Misinformation Mitigation in the Short Term and Long Term](https://doi.org/10.18653/v1/2023.findings-emnlp.92) |  | 0 | With advancements in natural language processing (NLP) models, automatic explanation generation has been proposed to mitigate misinformation on social media platforms in addition to adding warning labels to identified fake news. While many researchers have focused on generating good explanations, how these explanations can really help humans combat fake news is under-explored. In this study, we compare the effectiveness of a warning label and the state-of- the-art counterfactual explanations generated by GPT-4 in debunking misinformation. In a two-wave, online human-subject study, participants (N = 215) were randomly assigned to a control group in which false contents are shown without any intervention, a warning tag group in which the false claims were labeled, or an explanation group in which the false contents were accompanied by GPT-4 generated explanations. Our results show that both interventions significantly decrease participants’ self-reported belief in fake claims in an equivalent manner for the short-term and long-term. We discuss the implications of our findings and directions for future NLP-based misinformation debunking strategies. | YiLi Hsu, ShihChieh Dai, Aiping Xiong, LunWei Ku |  |
| 226 |  |  [Improving the Robustness of Summarization Models by Detecting and Removing Input Noise](https://doi.org/10.18653/v1/2023.findings-emnlp.93) |  | 0 | The evaluation of abstractive summarization models typically uses test data that is identically distributed as training data. In real-world practice, documents to be summarized may contain input noise caused by text extraction artifacts or data pipeline bugs. The robustness of model performance under distribution shift caused by such noise is relatively under studied. We present a large empirical study quantifying the sometimes severe loss in performance – up to 12 ROUGE-1 points – from different types of input noise for a range of datasets and model sizes. We then propose a light-weight method for detecting and removing such noise in the input during model inference without requiring any extra training, auxiliary models, or even prior knowledge of the type of noise. Our proposed approach effectively mitigates the loss in performance, recovering a large fraction of the performance drop, sometimes as large as 11 ROUGE-1 points. | Kundan Krishna, Yao Zhao, Jie Ren, Balaji Lakshminarayanan, Jiaming Luo, Mohammad Saleh, Peter J. Liu |  |
| 227 |  |  [How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts](https://doi.org/10.18653/v1/2023.findings-emnlp.94) |  | 0 | In recent years, there has been a rapid proliferation of AI-generated text, primarily driven by the release of powerful pre-trained language models (PLMs). To address the issue of misuse associated with AI-generated text, various high-performing detectors have been developed, including the OpenAI detector and the Stanford DetectGPT. In our study, we ask how reliable these detectors are. We answer the question by designing a novel approach that can prompt any PLM to generate text that evades these high-performing detectors. The proposed approach suggests a universal evasive prompt, a novel type of soft prompt, which guides PLMs in producing “human-like” text that can mislead the detectors. The novel universal evasive prompt is achieved in two steps: First, we create an evasive soft prompt tailored to a specific PLM through prompt tuning; and then, we leverage the transferability of soft prompts to transfer the learned evasive soft prompt from one PLM to another. Employing multiple PLMs in various writing tasks, we conduct extensive experiments to evaluate the efficacy of the evasive soft prompts in their evasion of state-of-the-art detectors. | Tharindu Kumarage, Paras Sheth, Raha Moraffah, Joshua Garland, Huan Liu |  |
| 228 |  |  [Knowledge is a Region in Weight Space for Fine-tuned Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.95) |  | 0 | Research on neural networks has focused on understanding a single model trained on a single dataset. However, relatively little is known about the relationships between different models, particularly those trained or tested on different datasets. We address this by studying how the weight space and the underlying loss landscape of different models are interconnected. Specifically, we demonstrate that finetuned models that were optimized for high performance, reside in well-defined regions in weight space, and vice versa – that any model that resides anywhere in those regions also exhibits high performance. Notably, we show that language models that have been finetuned on the same dataset form a tight cluster in the weight space, while models finetuned on different datasets from the same underlying task form a looser cluster. Moreover, traversing around the region between the models leads to new models that perform comparably or even better than models obtained via finetuning, even on tasks that the original models were not finetuned on. Our findings provide insight into the relationships between models, demonstrating that a model positioned between two similar models can acquire the knowledge of both. We leverage this and design a method for selecting a better model for efficient finetuning. Specifically, we show that starting from the center of the region is as effective, if not more, than using the pretrained model in 11 out of 12 datasets, resulting in an average accuracy improvement of 3.06. | Almog Gueta, Elad Venezian, Colin Raffel, Noam Slonim, Yoav Katz, Leshem Choshen |  |
| 229 |  |  [Unveiling the Multi-Annotation Process: Examining the Influence of Annotation Quantity and Instance Difficulty on Model Performance](https://doi.org/10.18653/v1/2023.findings-emnlp.96) |  | 0 | The NLP community has long advocated for the construction of multi-annotator datasets to better capture the nuances of language interpretation, subjectivity, and ambiguity. This paper conducts a retrospective study to show how performance scores can vary when a dataset expands from a single annotation per instance to multiple annotations. We propose a novel multi-annotator simulation process to generate datasets with varying annotation budgets. We show that similar datasets with the same annotation budget can lead to varying performance gains. Our findings challenge the popular belief that models trained on multi-annotation examples always lead to better performance than models trained on single or few-annotation examples. | Pritam Kadasi, Mayank Singh |  |
| 230 |  |  [On the Risk of Misinformation Pollution with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.97) |  | 0 | We investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation (up to 87%) in the performance of ODQA systems. Moreover, we uncover disparities in the attributes associated with persuading humans and machines, presenting an obstacle to current human-centric approaches to combat misinformation. To mitigate the harm caused by LLM-generated misinformation, we propose three defense strategies: misinformation detection, vigilant prompting, and reader ensemble. These approaches have demonstrated promising results, albeit with certain associated costs. Lastly, we discuss the practicality of utilizing LLMs as automatic misinformation generators and provide relevant resources and code to facilitate future research in this area. | Yikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, MinYen Kan, William Yang Wang |  |
| 231 |  |  [Dolphin: A Challenging and Diverse Benchmark for Arabic NLG](https://doi.org/10.18653/v1/2023.findings-emnlp.98) |  | 0 | We present Dolphin, a novel benchmark that addresses the need for a natural language generation (NLG) evaluation framework dedicated to the wide collection of Arabic languages and varieties. The proposed benchmark encompasses a broad range of 13 different NLG tasks, including dialogue generation, question answering, machine translation, summarization, among others. Dolphin comprises a substantial corpus of 40 diverse and representative public datasets across 50 test splits, carefully curated to reflect real-world scenarios and the linguistic richness of Arabic. It sets a new standard for evaluating the performance and generalization capabilities of Arabic and multilingual models, promising to enable researchers to push the boundaries of current methodologies. We provide an extensive analysis of Dolphin, highlighting its diversity and identifying gaps in current Arabic NLG research. We also offer a public leaderboard that is both interactive and modular and evaluate several Arabic and multilingual models on our benchmark, allowing us to set strong baselines against which researchers can compare. | El Moatez Billah Nagoudi, AbdelRahim A. Elmadany, Ahmed Oumar ElShangiti, Muhammad AbdulMageed |  |
| 232 |  |  [Hierarchical Enhancement Framework for Aspect-based Argument Mining](https://doi.org/10.18653/v1/2023.findings-emnlp.99) |  | 0 | Aspect-Based Argument Mining (ABAM) is a critical task in computational argumentation. Existing methods have primarily treated ABAM as a nested named entity recognition problem, overlooking the need for tailored strategies to effectively address the specific challenges of ABAM tasks. To this end, we propose a layer-based Hierarchical Enhancement Framework (HEF) for ABAM, and introduce three novel components: the Semantic and Syntactic Fusion (SSF) component, the Batch-level Heterogeneous Graph Attention Network (BHGAT) component, and the Span Mask Interactive Attention (SMIA) component. These components serve the purposes of optimizing underlying representations, detecting argument unit stances, and constraining aspect term recognition boundaries, respectively. By incorporating these components, our framework enables better handling of the challenges and improves the performance and accuracy in argument unit and aspect term recognition. Experiments on multiple datasets and various tasks verify the effectiveness of the proposed framework and components. | Yujie Fu, Yang Li, Suge Wang, Xiaoli Li, Deyu Li, Jian Liao, Jianxing Zheng |  |
| 233 |  |  [MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.100) |  | 0 | Large language models (LLMs) have shown nearly saturated performance on many natural language processing (NLP) tasks. As a result, it is natural for people to believe that LLMs have also mastered abilities such as time understanding and reasoning. However, research on the temporal sensitivity of LLMs has been insufficiently emphasized. To fill this gap, this paper constructs Multiple Sensitive Factors Time QA (MenatQA), which encompasses three temporal factors (scope factor, order factor, counterfactual factor) with total 2,853 samples for evaluating the time comprehension and reasoning abilities of LLMs. This paper tests current mainstream LLMs with different parameter sizes, ranging from billions to hundreds of billions. The results show most LLMs fall behind smaller temporal reasoning models with different degree on these factors. In specific, LLMs show a significant vulnerability to temporal biases and depend heavily on the temporal information provided in questions. Furthermore, this paper undertakes a preliminary investigation into potential improvement strategies by devising specific prompts and leveraging external tools. These approaches serve as valuable baselines or references for future research endeavors. | Yifan Wei, Yisong Su, Huanhuan Ma, Xiaoyan Yu, Fangyu Lei, Yuanzhe Zhang, Jun Zhao, Kang Liu |  |
| 234 |  |  [What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study](https://doi.org/10.18653/v1/2023.findings-emnlp.101) |  | 0 | The effectiveness of Chain-of-thought prompting (CoT) has been widely recognized, but the underlying mechanisms behind its success, the reason why it just works for a wide range of tasks, remains an open question. To investigate this, we employ a counterfactual prompting approach, systematically manipulating elements of examples used in a few-shot prompt, and testing the consequences on model behavior. This allows us to understand the relative contributions of prompt elements such as symbols (digits, entities) and patterns (equations, sentence structure) on in-context learning. Our experiments with three different large language models (LLMs) reveal several key findings. First, the specific symbols used in the prompt do not significantly impact the model’s performance. However, consistent patterns in examples and specifying text in style frequently found on the web are crucial. Second, our findings suggest that the necessity of accurate few-shot examples depends on their role in communicating task understanding. We identify tasks where inaccurate few-shot examples hurt and, surprisingly, tasks where they improve performance. Additionally, we find that the intermediate steps in CoT may not necessarily facilitate learning how to solve a task, but instead efficiently convey task understanding (what) to the model. Furthermore, CoT leverages LLMs to fill in missing commonsense information, particularly helping difficult reasoning problems and long-tail questions. | Aman Madaan, Katherine Hermann, Amir Yazdanbakhsh |  |
| 235 |  |  [Perceptual Structure in the absence of grounding: the impact of abstractedness and subjectivity in color language for LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.102) |  | 0 | The need for grounding in language understanding is an active research topic. Previous work has suggested that color perception and color language appear as a suitable test bed to empirically study the problem, given its cognitive significance and showing that there is considerable alignment between a defined color space and the feature space defined by a language model. To further study this issue, we collect a large scale source of colors and their descriptions, containing almost a 1 million examples , and perform an empirical analysis to compare two kinds of alignments: (i) inter-space, by learning a mapping between embedding space and color space, and (ii) intra-space, by means of prompting comparatives between color descriptions. Our results show that while color space alignment holds for monolexemic, highly pragmatic color descriptions, this alignment drops considerably in the presence of examples that exhibit elements of real linguistic usage such as subjectivity and abstractedness, suggesting that grounding may be required in such cases. | Pablo Loyola, Edison MarreseTaylor, Andrés Hoyos Idrobo |  |
| 236 |  |  [A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets](https://doi.org/10.18653/v1/2023.findings-emnlp.103) |  | 0 | Offensive language detection is crucial in natural language processing (NLP). We investigated the importance of context for detecting such language in reply tweets on Twitter, where the use of offensive language is widespread. We collected a Turkish tweet dataset where the target group was unvaccinated people during the Covid period. Tweets in the dataset were enriched with contextual information by adding the original tweet to which a particular tweet was posted as a reply. The dataset, which includes over 28,000 tweet-reply pairs, was manually labeled by human annotators and made publicly available. In addition, we compared the performance of different machine learning models with and without contextual information. Our results show that this type of contextual information was not very useful in improving the performance of the models in general, although it slightly increased the macro-averaged F1-score of certain models. | Musa Ihtiyar, Ömer Özdemir, Mustafa Erengül, Arzucan Özgür |  |
| 237 |  |  [Remember what you did so you know what to do next](https://doi.org/10.18653/v1/2023.findings-emnlp.104) |  | 0 | We explore using the 6B parameter GPT-J language model to create a plan for a simulated robot to achieve 30 classes of goals in ScienceWorld, a text game simulator for elementary science experiments and for which previously published empirical work has shown large language models (LLM)s to be a poor fit (Wang et al., 2022). Using the Markov assumption, the LLM outperforms the state-of-the-art based on reinforcement learning by a factor of 1.4. When we fill the LLM’s input buffer with as many prior steps as will fit, improvement rises to 3.3x. Even when training on only 6.5% of the training data, we observe a 2.3x improvement over the state-of-the-art. Our experiments show that performance varies widely across the 30 classes of actions, indicating that averaging over tasks can hide significant performance issues. | Manuel R. Ciosici, Alex Hedges, Yash Kankanampati, Justin Martin, Marjorie Freedman, Ralph M. Weischedel |  |
| 238 |  |  [An Empirical Study of Multimodal Model Merging](https://doi.org/10.18653/v1/2023.findings-emnlp.105) |  | 0 | Model merging (e.g., via interpolation or task arithmetic) fuses multiple models trained on different tasks to generate a multi-task solution. The technique has been proven successful in previous studies, where the models are trained on similar tasks and with the same initialization. In this paper, we expand on this concept to a multimodal setup by merging transformers trained on different modalities. Furthermore, we conduct our study for a novel goal where we can merge vision, language, and cross-modal transformers of a modality-specific architecture to create a parameter-efficient modality-agnostic architecture. Through comprehensive experiments, we systematically investigate the key factors impacting model performance after merging, including initialization, merging mechanisms, and model architectures. We also propose two metrics that assess the distance between weights to be merged and can serve as an indicator of the merging outcomes. Our analysis leads to an effective training recipe for matching the performance of the modality-agnostic baseline (i.e., pre-trained from scratch) via model merging. Our method also outperforms naive merging significantly on various tasks, with improvements of 3% on VQA, 7% on COCO retrieval, 25% on NLVR2, 14% on Flickr30k and 3% on ADE20k. | YiLin Sung, Linjie Li, Kevin Lin, Zhe Gan, Mohit Bansal, Lijuan Wang |  |
| 239 |  |  [Learning to Abstract with Nonparametric Variational Information Bottleneck](https://doi.org/10.18653/v1/2023.findings-emnlp.106) |  | 0 | Learned representations at the level of characters, sub-words, words, and sentences, have each contributed to advances in understanding different NLP tasks and linguistic phenomena. However, learning textual embeddings is costly as they are tokenization specific and require different models to be trained for each level of abstraction. We introduce a novel language representation model which can learn to compress to different levels of abstraction at different layers of the same model. We apply Nonparametric Variational Information Bottleneck (NVIB) to stacked Transformer self-attention layers in the encoder, which encourages an information-theoretic compression of the representations through the model. We find that the layers within the model correspond to increasing levels of abstraction and that their representations are more linguistically informed. Finally, we show that NVIB compression results in a model which is more robust to adversarial perturbations. | Melika Behjati, Fabio Fehr, James Henderson |  |
| 240 |  |  [Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document](https://doi.org/10.18653/v1/2023.findings-emnlp.107) |  | 0 | Visual Relation Extraction (VRE) is a powerful means of discovering relationships between entities within visually-rich documents. Existing methods often focus on manipulating entity features to find pairwise relations, yet neglect the more fundamental structural information that links disparate entity pairs together. The absence of global structure information may make the model struggle to learn long-range relations and easily predict conflicted results. To alleviate such limitations, we propose a GlObal Structure knowledge-guided relation Extraction (GOSE) framework. GOSE initiates by generating preliminary relation predictions on entity pairs extracted from a scanned image of the document. Subsequently, global structural knowledge is captured from the preceding iterative predictions, which are then incorporated into the representations of the entities. This “generate-capture-incorporate” cycle is repeated multiple times, allowing entity representations and global structure knowledge to be mutually reinforced. Extensive experiments validate that GOSE not only outperforms existing methods in the standard fine-tuning setting but also reveals superior cross-lingual learning capabilities; indeed, even yields stronger data-efficient performance in the low-resource setting. | Xiangnan Chen, Qian Xiao, Juncheng Li, Duo Dong, Jun Lin, Xiaozhong Liu, Siliang Tang |  |
| 241 |  |  [Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization](https://doi.org/10.18653/v1/2023.findings-emnlp.108) |  | 0 | Recent studies have shown that sequence-to-sequence (seq2seq) models struggle with compositional generalization (CG), i.e., the ability to systematically generalize to unseen compositions of seen components. There is mounting evidence that one of the reasons hindering CG is the representation of the encoder uppermost layer is entangled, i.e., the syntactic and semantic representations of sequences are entangled. However, we consider that the previously identified representation entanglement problem is not comprehensive enough. Additionally, we hypothesize that the source keys and values representations passing into different decoder layers are also entangled. Starting from this intuition, we propose CompoSition (Compose Syntactic and Semantic Representations), an extension to seq2seq models which learns to compose representations of different encoder layers dynamically for different tasks, since recent studies reveal that the bottom layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information. Specifically, we introduce a composed layer between the encoder and decoder to compose different encoder layers’ representations to generate specific keys and values passing into different decoder layers. CompoSition achieves competitive results on two comprehensive and realistic benchmarks, which empirically demonstrates the effectiveness of our proposal. Codes are available at https://github.com/thinkaboutzero/COMPOSITION. | Lei Lin, Shuangtao Li, Yafang Zheng, Biao Fu, Shan Liu, Yidong Chen, Xiaodong Shi |  |
| 242 |  |  [SelectNoise: Unsupervised Noise Injection to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.109) |  | 0 | In this work, we focus on the task of machine translation (MT) from extremely low-resource language (ELRLs) to English. The unavailability of parallel data, lack of representation from large multilingual pre-trained models, and limited monolingual data hinder the development of MT systems for ELRLs. However, many ELRLs often share lexical similarities with high-resource languages (HRLs) due to factors such as dialectical variations, geographical proximity, and language structure. We utilize this property to improve cross-lingual signals from closely related HRL to enable MT for ELRLs. Specifically, we propose a novel unsupervised approach, SelectNoise, based on selective candidate extraction and noise injection to generate noisy HRLs training data. The noise injection acts as a regularizer, and the model trained with noisy data learns to handle lexical variations such as spelling, grammar, and vocabulary changes, leading to improved cross-lingual transfer to ELRLs. The selective candidates are extracted using BPE merge operations and edit operations, and noise injection is performed using greedy, top-p, and top-k sampling strategies. We evaluate the proposed model on 12 ELRLs from the FLORES-200 benchmark in a zero-shot setting across two language families. The proposed model outperformed all the strong baselines, demonstrating its efficacy. It has comparable performance with the supervised noise injection model. Our code and model are publicly available. | Maharaj Brahma, Kaushal Maurya, Maunendra Sankar Desarkar |  |
| 243 |  |  [Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning](https://doi.org/10.18653/v1/2023.findings-emnlp.110) |  | 0 | Dense retrieval models have exhibited remarkable effectiveness, but they rely on abundant labeled data and face challenges when applied to different domains. Previous domain adaptation methods have employed generative models to generate pseudo queries, creating pseudo datasets to enhance the performance of dense retrieval models. However, these approaches typically use unadapted rerank models, leading to potentially imprecise labels. In this paper, we demonstrate the significance of adapting the rerank model to the target domain prior to utilizing it for label generation. This adaptation process enables us to obtain more accurate labels, thereby improving the overall performance of the dense retrieval model. Additionally, by combining the adapted retrieval model with the adapted rerank model, we achieve significantly better domain adaptation results across three retrieval datasets. We release our code for future research. | Che Chen, Ching Yang, ChunYi Lin, HungYu Kao |  |
| 244 |  |  [Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach](https://doi.org/10.18653/v1/2023.findings-emnlp.111) |  | 0 | Large Language Models (LLMs) have not only exhibited exceptional performance across various tasks, but also demonstrated sparks of intelligence. Recent studies have focused on assessing their capabilities on human exams and revealed their impressive competence in different domains. However, cognitive research on the overall knowledge structure of LLMs is still lacking. In this paper, based on educational diagnostic assessment method, we conduct an evaluation using MoocRadar, a meticulously annotated human test dataset based on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain insights of their cognitive capabilities. This research emphasizes the significance of investigating LLMs’ knowledge and understanding the disparate cognitive patterns of LLMs. By shedding light on models’ knowledge, researchers can advance development and utilization of LLMs in a more informed and effective manner. | Zheyuan Zhang, Jifan Yu, Juanzi Li, Lei Hou |  |
| 245 |  |  [Simpler neural networks prefer subregular languages](https://doi.org/10.18653/v1/2023.findings-emnlp.112) |  | 0 | We apply a continuous relaxation of L0 regularization (Louizos et al., 2017), which induces sparsity, to study the inductive biases of LSTMs. In particular, we are interested in the patterns of formal languages which are readily learned and expressed by LSTMs. Across a wide range of tests we find sparse LSTMs prefer subregular languages over regular languages and the strength of this preference increases as we increase the pressure for sparsity. Furthermore LSTMs which are trained on subregular languages have fewer non-zero parameters. We conjecture that this subregular bias in LSTMs is related to the cognitive bias for subregular language observed in human phonology which are both downstream of a simplicity bias in a suitable description language. | Charles Torres, Richard Futrell |  |
| 246 |  |  [Simple Hardware-Efficient PCFGs with Independent Left and Right Productions](https://doi.org/10.18653/v1/2023.findings-emnlp.113) |  | 0 | Scaling dense PCFGs to thousands of nonterminals via low-rank parameterizations of the rule probability tensor has been shown to be beneficial for unsupervised parsing. However, PCFGs scaled this way still perform poorly as a language model, and even underperform similarly-sized HMMs. This work introduces SimplePCFG, a simple PCFG formalism with independent left and right productions. Despite imposing a stronger independence assumption than the low-rank approach, we find that this formalism scales more effectively both as a language model and as an unsupervised parser. We further introduce FlashInside, a hardware IO-aware implementation of the inside algorithm for efficiently scaling simple PCFGs. Through extensive experiments on multiple grammar induction benchmarks, we validate the effectiveness of simple PCFGs over low-rank baselines. | Wei Liu, Songlin Yang, Yoon Kim, Kewei Tu |  |
| 247 |  |  [R³ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context](https://doi.org/10.18653/v1/2023.findings-emnlp.114) |  | 0 | With the help of Chain-of-Thought (CoT) prompting, Large Language Models (LLMs) have achieved remarkable performance on various reasoning tasks. However, most of them have been evaluated under noise-free context and the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated. Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction. Inspired by interactive CoT method, where intermediate reasoning steps are promoted by multiple rounds of interaction between users and LLMs, we propose a novel prompting method, namely R3 prompting, for CoT reasoning under noisy context. Specifically, R3 prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction, which corresponds to a thought process of reviewing, rephrasing and resolving. The responses generated at the last interaction will perform as hints to guide toward the responses of the next interaction. Our experiments show that R3 prompting significantly outperforms existing CoT prompting methods on five reasoning tasks under noisy context. With GPT-3.5-turbo, we observe 3.7% accuracy improvement on average on the reasoning tasks under noisy context compared to the most competitive prompting baseline. More analyses and ablation studies show the robustness and generalization of R3 prompting method in solving reasoning tasks in LLMs under noisy context. | Qingyuan Tian, Hanlun Zhu, Lei Wang, Yang Li, Yunshi Lan |  |
| 248 |  |  [Quality Estimation-Assisted Automatic Post-Editing](https://doi.org/10.18653/v1/2023.findings-emnlp.115) |  | 0 | Automatic Post-Editing (APE) systems are prone to over-correction of the Machine Translation (MT) outputs. While Word-level Quality Estimation (QE) system can provide a way to curtail the over-correction, a significant performance gain has not been observed thus far by utilizing existing APE and QE combination strategies. In this paper, we propose joint training of a model on APE and QE tasks to improve the APE. Our proposed approach utilizes a multi-task learning (MTL) methodology, which shows significant improvement while treating both tasks as a ‘bargaining game’ during training. Moreover, we investigate various existing combination strategies and show that our approach achieves state-of-the-art performance for a ‘distant’ language pair, viz., English-Marathi. We observe an improvement of 1.09 TER and 1.37 BLEU points over a baseline QE-Unassisted APE system for English-Marathi, while also observing 0.46 TER and 0.62 BLEU points for English-German. Further, we discuss the results qualitatively and show how our approach helps reduce over-correction, thereby improving the APE performance. We also observe that the degree of integration between QE and APE directly correlates with the APE performance gain. We release our code and models publicly. | Sourabh Dattatray Deoghare, Diptesh Kanojia, Frédéric Blain, Tharindu Ranasinghe, Pushpak Bhattacharyya |  |
| 249 |  |  [Adapter Pruning using Tropical Characterization](https://doi.org/10.18653/v1/2023.findings-emnlp.116) |  | 0 | Adapters are widely popular parameter-efficient transfer learning approaches in natural language processing that insert trainable modules in between layers of a pre-trained language model. Apart from several heuristics, however, there has been a lack of studies analyzing the optimal number of adapter parameters needed for downstream applications. Thus, we propose an adapter pruning approach by studying the tropical characteristics of trainable modules. We cast it as an optimization problem that aims to prune parameters from the adapter layers without changing the orientation of underlying tropical hypersurfaces. Our experiments on five NLP datasets show that tropical geometry tends to identify more relevant parameters to prune when compared with the magnitude-based baseline, while a combined approach works best across the tasks. | Rishabh Bhardwaj, Tushar Vaidya, Soujanya Poria |  |
| 250 |  |  [Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge](https://doi.org/10.18653/v1/2023.findings-emnlp.117) |  | 0 | We present a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems. These rules define natural language text predicates as a weighted mixture of knowledge base paths. The weights learned during training effectively serve the mapping needed to perform relation linking. We use popular masked training strategy to self-learn the rules. A key distinguishing aspect of our work is that the masked training operate over logical forms of the sentence instead of their natural language text form. This offers opportunity to extract extended context information from the structured knowledge source and use that to build robust and human readable rules. We evaluate accuracy and usefulness of such learned rules by utilizing them for prediction of missing kinship relation in CLUTRR dataset and relation linking in a KBQA system using SWQ-WD dataset. Results demonstrate the effectiveness of our approach - its generalizability, interpretability and ability to achieve an average performance gain of 17% on CLUTRR dataset. | Shajith Ikbal, Udit Sharma, Hima Karanam, Sumit Neelam, Ronny Luss, Dheeraj Sreedhar, Pavan Kapanipathi, Naweed Khan, Kyle Erwin, Ndivhuwo Makondo, Ibrahim Abdelaziz, Achille Fokoue, Alexander Gray, Maxwell Crouse, Subhajit Chaudhury, Chitra Subramanian |  |
| 251 |  |  [TaTA: A Multilingual Table-to-Text Dataset for African Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.118) |  | 0 | Existing data-to-text generation datasets are mostly limited to English. To address this lack of data, we create Table-to-Text in African languages (TaTA), the first large multilingual table-to-text dataset with a focus on African languages. We created TaTA by transcribing figures and accompanying text in bilingual reports by the Demographic and Health Surveys Program, followed by professional translation to make the dataset fully parallel. TaTA includes 8,700 examples in nine languages including four African languages (Hausa, Igbo, Swahili, and Yorùbá) and a zero-shot test language (Russian). We additionally release screenshots of the original figures for future research on multilingual multi-modal approaches. Through an in-depth human evaluation, we show that TaTA is challenging for current models and that less than half the outputs from an mT5-XXL-based model are understandable and attributable to the source data. Our results highlight a) the need for validating metrics; and b) the importance of domain-specific metrics. | Sebastian Gehrmann, Sebastian Ruder, Vitaly Nikolaev, Jan A. Botha, Michael Chavinda, Ankur P. Parikh, Clara Rivera |  |
| 252 |  |  [Explain-then-translate: an analysis on improving program translation with self-generated explanations](https://doi.org/10.18653/v1/2023.findings-emnlp.119) |  | 0 | This work explores the use of self-generated natural language explanations as an intermediate step for code-to-code translation with language models. Across three types of explanations and 19 programming languages constructed from the MultiPL-E dataset, we find the explanations to be particularly effective in the zero-shot case, improving performance by 12% on average. Improvements with natural language explanations are particularly pronounced on difficult programs. We release our dataset, code, and canonical solutions in all 19 languages. | Zilu Tang, Mayank Agarwal, Alexander Shypula, Bailin Wang, Derry Wijaya, Jie Chen, Yoon Kim |  |
| 253 |  |  [Can Brain Signals Reveal Inner Alignment with Human Languages?](https://doi.org/10.18653/v1/2023.findings-emnlp.120) |  | 0 | Brain Signals, such as Electroencephalography (EEG), and human languages have been widely explored independently for many downstream tasks, however, the connection between them has not been well explored. In this study, we explore the relationship and dependency between EEG and language. To study at the representation level, we introduced MTAM, a Multimodal Transformer Alignment Model, to observe coordinated representations between the two modalities. We used various relationship alignment-seeking techniques, such as Canonical Correlation Analysis and Wasserstein Distance, as loss functions to transfigure features. On downstream applications, sentiment analysis and relation detection, we achieved new state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method achieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets for sentiment analysis, and 7.4% on ZuCo for relation detection. In addition, we provide interpretations of the performance improvement: (1) feature distribution shows the effectiveness of the alignment module for discovering and encoding the relationship between EEG and language; (2) alignment weights show the influence of different language semantics as well as EEG frequency features; (3) brain topographical maps provide an intuitive demonstration of the connectivity in the brain regions. Our code is available at https://github.com/Jason-Qiu/EEG_Language_Alignment. | Jielin Qiu, William Han, Jiacheng Zhu, Mengdi Xu, Douglas Weber, Bo Li, Ding Zhao |  |
| 254 |  |  [DemoSG: Demonstration-enhanced Schema-guided Generation for Low-resource Event Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.121) |  | 0 | Most current Event Extraction (EE) methods focus on the high-resource scenario, which requires a large amount of annotated data and can hardly be applied to low-resource domains. To address EE more effectively with limited resources, we propose the Demonstration-enhanced Schema-guided Generation (DemoSG) model, which benefits low-resource EE from two aspects: Firstly, we propose the demonstration-based learning paradigm for EE to fully use the annotated data, which transforms them into demonstrations to illustrate the extraction process and help the model learn effectively. Secondly, we formulate EE as a natural language generation task guided by schema-based prompts, thereby leveraging label semantics and promoting knowledge transfer in low-resource scenarios. We conduct extensive experiments under in-domain and domain adaptation low-resource settings on three datasets, and study the robustness of DemoSG. The results show that DemoSG significantly outperforms current methods in low-resource scenarios. | Gang Zhao, Xiaocheng Gong, Xinjie Yang, Guanting Dong, Shudong Lu, Si Li |  |
| 255 |  |  [GLGR: Question-aware Global-to-Local Graph Reasoning for Multi-party Dialogue Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.122) |  | 0 | Graph reasoning contributes to the integration of discretely-distributed attentive information (clues) for Multi-party Dialogue Reading Comprehension (MDRC). This is attributed primarily to multi-hop reasoning over global conversational structures. However, existing approaches barely apply questions for anti-noise graph reasoning. More seriously, the local semantic structures in utterances are neglected, although they are beneficial for bridging across semantically-related clues. In this paper, we propose a question-aware global-to-local graph reasoning approach. It expands the canonical Interlocutor-Utterance graph by introducing a question node, enabling comprehensive global graph reasoning. More importantly, it constructs a semantic-role graph for each utterance, and accordingly performs local graph reasoning conditioned on the semantic relations. We design a two-stage encoder network to implement the progressive reasoning from the global graph to local. The experiments on the benchmark datasets Molweni and FriendsQA show that our approach yields significant improvements, compared to BERT and ELECTRA baselines. It achieves 73.6% and 77.2% F1-scores on Molweni and FriendsQA, respectively, outperforming state-of-the-art methods that employ different pretrained language models as backbones. | Yanling Li, Bowei Zou, Yifan Fan, Xibo Li, Ai Ti Aw, Yu Hong |  |
| 256 |  |  [Towards Mitigating LLM Hallucination via Self Reflection](https://doi.org/10.18653/v1/2023.findings-emnlp.123) |  | 0 | Large language models (LLMs) have shown promise for generative and knowledge-intensive tasks including question-answering (QA) tasks. However, the practical deployment still faces challenges, notably the issue of “hallucination”, where models generate plausible-sounding but unfaithful or nonsensical information. This issue becomes particularly critical in the medical domain due to the uncommon professional concepts and potential social risks involved. This paper analyses the phenomenon of hallucination in medical generative QA systems using widely adopted LLMs and datasets. Our investigation centers on the identification and comprehension of common problematic answers, with a specific emphasis on hallucination. To tackle this challenge, we present an interactive self-reflection methodology that incorporates knowledge acquisition and answer generation. Through this feedback process, our approach steadily enhances the factuality, consistency, and entailment of the generated answers. Consequently, we harness the interactivity and multitasking ability of LLMs and produce progressively more precise and accurate answers. Experimental results on both automatic and human evaluation demonstrate the superiority of our approach in hallucination reduction compared to baselines. | Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, Pascale Fung |  |
| 257 |  |  [Making Body Movement in Sign Language Corpus Accessible for Linguists and Machines with Three-Dimensional Normalization of MediaPipe](https://doi.org/10.18653/v1/2023.findings-emnlp.124) |  | 0 | Linguists can access movement in the sign language video corpus through manual annotation or computational methods. The first relies on a predefinition of features, and the second requires technical knowledge. Methods like MediaPipe and OpenPose are now more often used in sign language processing. MediaPipe detects a two-dimensional (2D) body pose in a single image with a limited approximation of the depth coordinate. Such 2D projection of a three-dimensional (3D) body pose limits the potential application of the resulting models outside the capturing camera settings and position. 2D pose data does not provide linguists with direct and human-readable access to the collected movement data. We propose our four main contributions: A novel 3D normalization method for MediaPipe’s 2D pose, a novel human-readable way of representing the 3D normalized pose data, an analysis of Japanese Sign Language (JSL) sociolinguistic features using the proposed techniques, where we show how an individual signer can be identified based on unique personal movement patterns suggesting a potential threat to anonymity. Our method outperforms the common 2D normalization on a small, diverse JSL dataset. We demonstrate its benefit for deep learning approaches by significantly outperforming the pose-based state-of-the-art models on the open sign language recognition benchmark. | Victor Skobov, Mayumi Bono |  |
| 258 |  |  [XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.125) |  | 0 | Data scarcity is a crucial issue for the development of highly multilingual NLP systems. Yet for many under-represented languages (ULs) — languages for which NLP research is particularly far behind in meeting user needs — it is feasible to annotate small amounts of data. Motivated by this, we propose XTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather than zero-shot; its focus on user-centric tasks — tasks with broad adoption by speakers of high-resource languages; and its focus on under-represented languages where this scarce-data scenario tends to be most realistic. XTREME-UP evaluates the capabilities of language models across 88 under-represented languages over 9 key user-centric technologies including ASR, OCR, MT, and information access tasks that are of general utility. We create new datasets for OCR, autocomplete, semantic parsing, and transliteration, and build on and refine existing datasets for other tasks. XTREME-UP provides methodology for evaluating many modeling scenarios including text only, multi-modal (vision, audio, and text), supervised parameter tuning, and in-context learning. We evaluate commonly used models on the benchmark. We release all code and scripts to train and evaluate models. | Sebastian Ruder, Jonathan H. Clark, Alexander Gutkin, Mihir Kale, Min Ma, Massimo Nicosia, Shruti Rijhwani, Parker Riley, Jean Michel A. Sarr, Xinyi Wang, John Wieting, Nitish Gupta, Anna Katanova, Christo Kirov, Dana L. Dickinson, Brian Roark, Bidisha Samanta, Connie Tao, David Ifeoluwa Adelani, Vera Axelrod, Isaac Caswell, Colin Cherry, Dan Garrette, R. Reeve Ingle, Melvin Johnson, Dmitry Panteleev, Partha Talukdar |  |
| 259 |  |  [DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models](https://doi.org/10.18653/v1/2023.findings-emnlp.126) |  | 0 | Recent advances in image and video creation, especially AI-based image synthesis, have led to the production of numerous visual scenes that exhibit a high level of abstractness and diversity. Consequently, Visual Storytelling (VST), a task that involves generating meaningful and coherent narratives from a collection of images, has become even more challenging and is increasingly desired beyond real-world imagery. While existing VST techniques, which typically use autoregressive decoders, have made significant progress, they suffer from low inference speed and are not well-suited for synthetic scenes. To this end, we propose a novel diffusion-based system DiffuVST, which models the generation of a series of visual descriptions as a single conditional denoising process. The stochastic and non-autoregressive nature of DiffuVST at inference time allows it to generate highly diverse narratives more efficiently. In addition, DiffuVST features a unique design with bi-directional text history guidance and multimodal adapter modules, which effectively improve inter-sentence coherence and image-to-text fidelity. Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed. | Shengguang Wu, Mei Yuan, Qi Su |  |
| 260 |  |  [DiFair: A Benchmark for Disentangled Assessment of Gender Knowledge and Bias](https://doi.org/10.18653/v1/2023.findings-emnlp.127) |  | 0 | Numerous debiasing techniques have been proposed to mitigate the gender bias that is prevalent in pretrained language models. These are often evaluated on datasets that check the extent to which the model is gender-neutral in its predictions. Importantly, this evaluation protocol overlooks the possible adverse impact of bias mitigation on useful gender knowledge. To fill this gap, we propose \*\*DiFair\*\*, a manually curated dataset based on masked language modeling objectives. \*\*DiFair\*\* allows us to introduce a unified metric, \*gender invariance score\*, that not only quantifies a model’s biased behavior, but also checks if useful gender knowledge is preserved. We use \*\*DiFair\*\* as a benchmark for a number of widely-used pretained language models and debiasing techniques. Experimental results corroborate previous findings on the existing gender biases, while also demonstrating that although debiasing techniques ameliorate the issue of gender bias, this improvement usually comes at the price of lowering useful gender knowledge of the model. | Mahdi Zakizadeh, Kaveh Eskandari Miandoab, Mohammad Taher Pilehvar |  |
| 261 |  |  [Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens](https://doi.org/10.18653/v1/2023.findings-emnlp.128) |  | 0 | Recent psycholinguistic studies have drawn conflicting conclusions about the relationship between the quality of a language model and the ability of its surprisal estimates to predict human reading times, which has been speculated to be due to the large gap in both the amount of training data and model capacity across studies. The current work aims to consolidate these findings by evaluating surprisal estimates from Transformer-based language model variants that vary systematically in the amount of training data and model capacity on their ability to predict human reading times. The results show that surprisal estimates from most variants with contemporary model capacities provide the best fit after seeing about two billion training tokens, after which they begin to diverge from humanlike expectations. Additionally, newly-trained smaller model variants reveal a ‘tipping point’ at convergence, after which the decrease in language model perplexity begins to result in poorer fits to human reading times. These results suggest that the massive amount of training data is mainly responsible for the poorer fit achieved by surprisal from larger pre-trained language models, and that a certain degree of model capacity is necessary for Transformer-based language models to capture humanlike expectations. | ByungDoh Oh, William Schuler |  |
| 262 |  |  [ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination](https://doi.org/10.18653/v1/2023.findings-emnlp.129) |  | 0 | In the field of Large Language Models (LLMs), researchers are increasingly exploring their effectiveness across a wide range of tasks. However, a critical area that requires further investigation is the interpretability of these models, particularly the ability to generate rational explanations for their decisions. Most existing explanation datasets are limited to the English language and the general domain, which leads to a scarcity of linguistic diversity and a lack of resources in specialized domains, such as medical. To mitigate this, we propose ExplainCPE, a challenging medical dataset consisting of over 7K problems from Chinese Pharmacist Examination, specifically tailored to assess the model-generated explanations. From the overall results, only GPT-4 passes the pharmacist examination with a 75.7% accuracy, while other models like ChatGPT fail. Further detailed analysis of LLM-generated explanations reveals the limitations of LLMs in understanding medical text and executing computational reasoning. With the increasing importance of AI safety and trustworthiness, ExplainCPE takes a step towards improving and evaluating the interpretability of LLMs in the medical domain. | Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu, Min Zhang |  |
| 263 |  |  [CLASS: A Design Framework for Building Intelligent Tutoring Systems Based on Learning Science principles](https://doi.org/10.18653/v1/2023.findings-emnlp.130) |  | 0 | We present a design framework called Conversational Learning with Analytical Step-by-Step Strategies (CLASS) for building advanced Intelligent Tutoring Systems (ITS) powered by high-performance Large Language Models (LLMs). The CLASS framework empowers ITS with two key capabilities. First, through a carefully curated scaffolding dataset, CLASS equips ITS with essential problem-solving strategies, enabling it to provide tutor-like, step-by-step guidance to students. Second, by using a dynamic conversational dataset, CLASS assists ITS in facilitating natural language interactions, fostering engaging student-tutor conversations. The CLASS framework also provides valuable insights into ITS’s internal decision-making process which allows seamless integration of user feedback, thus enabling continuous refinement and improvement. We also present a proof-of-concept ITS, referred to as SPOCK, which is trained using the CLASS framework with a focus on introductory college level biology content. A carefully constructed protocol was developed for SPOCK’s preliminary evaluation, examining aspects such as the factual accuracy and relevance of its responses. Experts in the field of biology offered favorable remarks, particularly highlighting SPOCK’s capability to break down questions into manageable subproblems and provide encouraging responses to students. | Shashank Sonkar, Naiming Liu, Debshila Basu Mallick, Richard G. Baraniuk |  |
| 264 |  |  [Normal-Abnormal Decoupling Memory for Medical Report Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.131) |  | 0 | The automatic generation of medical reports plays a crucial role in clinical automation. In contrast to natural images, radiological images exhibit a high degree of similarity, while medical data are prone to data bias and complex noise, posing challenges for existing methods in capturing nuanced visual information. To address these challenges, we introduce a novel normal-abnormal semantic decoupling network that utilizes abnormal pattern memory. Different from directly optimizing the network using medical reports, we optimize visual extraction through the extraction of abnormal semantics from the reports. Moreover, we independently learn normal semantics based on abnormal semantics, ensuring that the optimization of the visual network remains unaffected by normal semantics learning. Then, we divided the words in the report into four parts: normal/abnormal sentences and normal/abnormal semantics, optimizing the network with distinct weights for each partition. The two semantic components, along with visual information, are seamlessly integrated to facilitate the generation of precise and coherent reports. This approach mitigates the impact of noisy normal semantics and reports. Moreover, we develop a novel encoder for abnormal pattern memory, which improves the network’s ability to detect anomalies by capturing and embedding the abnormal patterns of images in the visual encoder. This approach demonstrates excellent performance on the benchmark MIMIC-CXR, surpassing the current state-of-the-art methods. | Guosheng Zhao, Yan Yan, Zijian Zhao |  |
| 265 |  |  [mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations](https://doi.org/10.18653/v1/2023.findings-emnlp.132) |  | 0 | Multilingual sequence-to-sequence models perform poorly with increased language coverage and fail to consistently generate text in the correct target language in few-shot settings. To address these challenges, we propose mmT5, a modular multilingual sequence-to-sequence model. mmT5 utilizes language-specific modules during pre-training, which disentangle language-specific information from language-agnostic information. We identify representation drift during fine-tuning as a key limitation of modular generative models and develop strategies that enable effective zero-shot transfer. Our model outperforms mT5 at the same parameter sizes by a large margin on representative natural language understanding and generation tasks in 40+ languages. Compared to mT5, mmT5 raises the rate of generating text in the correct language under zero-shot settings from 7% to 99%, thereby greatly alleviating the source language hallucination problem. | Jonas Pfeiffer, Francesco Piccinno, Massimo Nicosia, Xinyi Wang, Machel Reid, Sebastian Ruder |  |
| 266 |  |  [ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories](https://doi.org/10.18653/v1/2023.findings-emnlp.133) |  | 0 | Recently, Large Language Models (LLMs) have been serving as general-purpose interfaces, posing a significant demand for comprehensive visual knowledge. However, it remains unclear how well current LLMs and their visually augmented counterparts (VaLMs) can master visual commonsense knowledge. To investigate this, we propose ImageNetVC, a human-annotated dataset specifically designed for zero- and few-shot visual commonsense evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we benchmark the fundamental visual commonsense knowledge of both unimodal LLMs and VaLMs. Furthermore, we analyze the factors affecting the visual commonsense knowledge of large-scale models, providing insights into the development of language models enriched with visual commonsense knowledge. Our code and dataset are available at https://github.com/hemingkx/ImageNetVC. | Heming Xia, Qingxiu Dong, Lei Li, Jingjing Xu, Tianyu Liu, Ziwei Qin, Zhifang Sui |  |
| 267 |  |  [MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.134) |  | 0 | We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to context noise. | Besnik Fetahu, Zhiyu Chen, Sudipta Kar, Oleg Rokhlenko, Shervin Malmasi |  |
| 268 |  |  [A Query-Parallel Machine Reading Comprehension Framework for Low-resource NER](https://doi.org/10.18653/v1/2023.findings-emnlp.135) |  | 0 | Named entity recognition (NER) is a fundamental task in natural language processing. Recently, NER has been formulated as a machine reading comprehension (MRC) task, in which manually-crafted queries are used to extract entities of different types. However, current MRC-based NER techniques are limited to extracting a single type of entities at a time and are largely geared towards resource-rich settings. This renders them inefficient during the inference phase, while also leaving their potential untapped for utilization in low-resource settings. We suggest a query-parallel MRC-based approach to address these issues, which is capable of extracting multiple entity types concurrently and is applicable to both resource-rich and resource-limited settings. Specifically, we propose a query-parallel encoder which uses a query-segmented attention mechanism to isolate the semantics of queries and model the query-context interaction with a unidirectional flow. This allows for easier generalization to new entity types or transfer to new domains. After obtaining the query and context representations through the encoder, they are fed into a query-conditioned biaffine predictor to extract multiple entities at once. The model is trained with parameter-efficient tuning technique, making it more data-efficient. We conduct extensive experiments and demonstrate that our model performs competitively against strong baseline methods in resource-rich settings, and achieves state-of-the-art results in low-resource settings, including training-from-scratch, in-domain transfer and cross-domain transfer tasks. | Yuhao Zhang, Yongliang Wang |  |
| 269 |  |  [BiSPN: Generating Entity Set and Relation Set Coherently in One Pass](https://doi.org/10.18653/v1/2023.findings-emnlp.136) |  | 0 | By modeling the interaction among instances and avoiding error propagation, Set Prediction Networks (SPNs) achieve state-of-the-art performance on the tasks of named entity recognition and relation triple extraction respectively. However, how to jointly extract entities and relation triples via SPNs remains an unexplored problem, where the main challenge is the maintenance of coherence between the predicted entity/relation sets during one-pass generation. In this work, we present Bipartite Set Prediction Network (BiSPN), a novel joint entity-relation extraction model that can efficiently generate entity set and relation set in parallel. To overcome the challenge of coherence, BiSPN is equipped with a novel bipartite consistency loss as well as an entity-relation linking loss during training. Experiments on three biomedical/clinical datasets and a general-domain dataset show that BiSPN achieves new state of the art in knowledge-intensive scene and performs competitively in general-domain, while being more efficient than two-stage joint extraction methods. | Yuxin He, Buzhou Tang |  |
| 270 |  |  [MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings](https://doi.org/10.18653/v1/2023.findings-emnlp.137) |  | 0 | As dialogue systems become more popular, evaluation of their response quality gains importance. Engagingness highly correlates with overall quality and creates a sense of connection that gives human participants a more fulfilling experience. Although qualities like coherence and fluency are readily measured with well-worn automatic metrics, evaluating engagingness often relies on human assessment, which is a costly and time-consuming process. Existing automatic engagingness metrics evaluate the response without the conversation history, are designed for one dataset, or have limited correlation with human annotations. Furthermore, they have been tested exclusively on English conversations. Given that dialogue systems are increasingly available in languages beyond English, multilingual evaluation capabilities are essential. We propose that large language models (LLMs) may be used for evaluation of engagingness in dialogue through prompting, and ask how prompt constructs and translated prompts compare in a multilingual setting. We provide a prompt-design taxonomy for engagingness and find that using selected prompt elements with LLMs, including our comprehensive definition of engagingness, outperforms state-of-the-art methods on evaluation of engagingness in dialogue across multiple languages. | Amila Ferron, Amber Shore, Ekata Mitra, Ameeta Agrawal |  |
| 271 |  |  [Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.138) |  | 0 | Over the past few years, various domain-specific pretrained language models (PLMs) have been proposed and have outperformed general-domain PLMs in specialized areas such as biomedical, scientific, and clinical domains. In addition, financial PLMs have been studied because of the high economic impact of financial data analysis. However, we found that financial PLMs were not pretrained on sufficiently diverse financial data. This lack of diverse training data leads to a subpar generalization performance, resulting in general-purpose PLMs, including BERT, often outperforming financial PLMs on many downstream tasks. To address this issue, we collected a broad range of financial corpus and trained the Financial Language Model (FiLM) on these diverse datasets. Our experimental results confirm that FiLM outperforms not only existing financial PLMs but also general domain PLMs. Furthermore, we provide empirical evidence that this improvement can be achieved even for unseen corpus groups. | Jaeyoung Choe, Keonwoong Noh, Nayeon Kim, Seyun Ahn, Woohwan Jung |  |
| 272 |  |  [LLMDet: A Third Party Large Language Models Generated Text Detection Tool](https://doi.org/10.18653/v1/2023.findings-emnlp.139) |  | 0 | Generated texts from large language models (LLMs) are remarkably close to high-quality human-authored text, raising concerns about their potential misuse in spreading false information and academic misconduct. Consequently, there is an urgent need for a highly practical detection tool capable of accurately identifying the source of a given text. However, existing detection tools typically rely on access to LLMs and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of fine-grained tracing, intermediary judgment, and rapid detection. Therefore, we propose LLMDet, a model-specific, secure, efficient, and extendable detection tool, that can source text from specific LLMs, such as GPT-2, OPT, LLaMA, and others. In LLMDet, we record the next-token probabilities of salient n-grams as features to calculate proxy perplexity for each LLM. By jointly analyzing the proxy perplexities of LLMs, we can determine the source of the generated text. Experimental results show that LLMDet yields impressive detection performance while ensuring speed and security, achieving 98.54% precision and about × 5.0 faster for recognizing human-authored text. Additionally, LLMDet can effortlessly extend its detection capabilities to a new open-source model. We will provide an open-source tool at https://github.com/TrustedLLM/LLMDet. | Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, TatSeng Chua |  |
| 273 |  |  [RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.140) |  | 0 | Automating radiology report generation can significantly alleviate radiologists’ workloads. Previous research has primarily focused on realizing highly concise observations while neglecting the precise attributes that determine the severity of diseases (e.g., small pleural effusion). Since incorrect attributes will lead to imprecise radiology reports, strengthening the generation process with precise attribute modeling becomes necessary. Additionally, the temporal information contained in the historical records, which is crucial in evaluating a patient’s current condition (e.g., heart size is unchanged), has also been largely disregarded. To address these issues, we propose RECAP, which generates precise and accurate radiology reports via dynamic disease progression reasoning. Specifically, RECAP first predicts the observations and progressions (i.e., spatiotemporal information) given two consecutive radiographs. It then combines the historical records, spatiotemporal information, and radiographs for report generation, where a disease progression graph and dynamic progression reasoning mechanism are devised to accurately select the attributes of each observation and progression. Extensive experiments on two publicly available datasets demonstrate the effectiveness of our model. | Wenjun Hou, Yi Cheng, Kaishuai Xu, Wenjie Li, Jiang Liu |  |
| 274 |  |  [Causal Intervention for Abstractive Related Work Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.141) |  | 0 | Abstractive related work generation has attracted increasing attention in generating coherent related work that helps readers grasp the current research. However, most existing models ignore the inherent causality during related work generation, leading to spurious correlations which downgrade the models’ generation quality and generalizability. In this study, we argue that causal intervention can address such limitations and improve the quality and coherence of generated related work. To this end, we propose a novel Causal Intervention Module for Related Work Generation (CaM) to effectively capture causalities in the generation process. Specifically, we first model the relations among the sentence order, document (reference) correlations, and transitional content in related work generation using a causal graph. Then, to implement causal interventions and mitigate the negative impact of spurious correlations, we use do-calculus to derive ordinary conditional probabilities and identify causal effects through CaM. Finally, we subtly fuse CaM with Transformer to obtain an end-to-end related work generation framework. Extensive experiments on two real-world datasets show that CaM can effectively promote the model to learn causal relations and thus produce related work of higher quality and coherence. | Jiachang Liu, Qi Zhang, Chongyang Shi, Usman Naseem, Shoujin Wang, Liang Hu, Ivor W. Tsang |  |
| 275 |  |  [G-SPEED: General SParse Efficient Editing MoDel](https://doi.org/10.18653/v1/2023.findings-emnlp.142) |  | 0 | Large Language Models (LLMs) have demonstrated incredible capabilities in understanding, generating, and manipulating languages. Through human-model interactions, LLMs can automatically understand human-issued instructions and output the expected contents, which can significantly increase working efficiency. In various types of real-world demands, editing-oriented tasks account for a considerable proportion, which involves an interactive process that entails the continuous refinement of existing texts to meet specific criteria. Due to the need for multi-round human-model interaction and the generation of complicated editing tasks, there is an emergent need for efficient general editing models. In this paper, we propose General SParse Efficient Editing MoDel (G-SPEED), which can fulfill diverse editing requirements through a single model while maintaining low computational costs. Specifically, we first propose a novel unsupervised text editing data clustering algorithm to deal with the data scarcity problem. Subsequently, we introduce a sparse editing model architecture to mitigate the inherently limited learning capabilities of small language models. The experimental outcomes indicate that G-SPEED, with its 508M parameters, can surpass LLMs equipped with 175B parameters. Our code and model checkpoints are available at https://github.com/Banner-Z/G-SPEED. | Haoke Zhang, Yue Wang, Juntao Li, Xiabing Zhou, Min Zhang |  |
| 276 |  |  [Attack Prompt Generation for Red Teaming and Defending Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.143) |  | 0 | Large language models (LLMs) are susceptible to red teaming attacks, which can induce LLMs to generate harmful content. Previous research constructs attack prompts via manual or automatic methods, which have their own limitations on construction cost and quality. To address these issues, we propose an integrated approach that combines manual and automatic methods to economically generate high-quality attack prompts. Specifically, considering the impressive capabilities of newly emerged LLMs, we propose an attack framework to instruct LLMs to mimic human-generated prompts through in-context learning. Furthermore, we propose a defense framework that fine-tunes victim LLMs through iterative interactions with the attack framework to enhance their safety against red teaming attacks. Extensive experiments on different LLMs validate the effectiveness of our proposed attack and defense frameworks. Additionally, we release a series of attack prompts datasets named SAP with varying sizes, facilitating the safety evaluation and enhancement of more LLMs. | Boyi Deng, Wenjie Wang, Fuli Feng, Yang Deng, Qifan Wang, Xiangnan He |  |
| 277 |  |  [Smart "Chef": Verifying the Effect of Role-based Paraphrasing for Aspect Term Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.144) |  | 0 | We tackle Aspect Term Extraction (ATE), a task of automatically extracting aspect terms from sentences. The current Pretrained Language Model (PLM) based extractors have achieved significant improvements. They primarily benefit from context-aware encoding. However, a considerable number of sentences in ATE corpora contain uninformative or low-quality contexts. Such sentences frequently act as “troublemakers” during test. In this study, we explore the context-oriented quality improvement method. Specifically, we propose to automatically rewrite the sentences from the perspectives of virtual experts with different roles, such as a “chef” in the restaurant domain. On this basis, we perform ATE over the paraphrased sentences during test, using the well-trained extractors without any change. In the experiments, we leverage ChatGPT to determine virtual experts in the considered domains, and induce ChatGPT to generate paraphrases conditioned on the roles of virtual experts. We experiment on the benchmark SemEval datasets, including Laptop-domain L14 and Restaurant-domain R14-16. The experimental results show that our approach effectively recalls the inconspicuous aspect terms like “al di la”, although it reduces the precision. In addition, it is proven that our approach can be substantially improved by redundancy elimination and multi-role voting. More importantly, our approach can be used to expand the predictions obtained on the original sentences. This yields state-of-the-art performance (i.e., F1-scores of 86.2%, 89.3%, 77.7%, 82.7% on L14 and R14-16) without retraining or fine-tuning the baseline extractors. | Jiaxiang Chen, Yu Hong, Qingting Xu, Jianmin Yao |  |
| 278 |  |  [Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.145) |  | 0 | Multiple defendants in a criminal fact description generally exhibit complex interactions, and cannot be well handled by existing Legal Judgment Prediction (LJP) methods which focus on predicting judgment results (e.g., law articles, charges, and terms of penalty) for single-defendant cases. To address this problem, we propose the task of multi-defendant LJP, which aims to automatically predict the judgment results for each defendant of multi-defendant cases. Two challenges arise with the task of multi-defendant LJP: (1) indistinguishable judgment results among various defendants; and (2) the lack of a real-world dataset for training and evaluation. To tackle the first challenge, we formalize the multi-defendant judgment process as hierarchical reasoning chains and introduce a multi-defendant LJP method, named Hierarchical Reasoning Network (HRN), which follows the hierarchical reasoning chains to determine criminal relationships, sentencing circumstances, law articles, charges, and terms of penalty for each defendant. To tackle the second challenge, we collect a real-world multi-defendant LJP dataset, namely MultiLJP, to accelerate the relevant research in the future. Extensive experiments on MultiLJP verify the effectiveness of our proposed HRN. | Yougang Lyu, Jitai Hao, Zihan Wang, Kai Zhao, Shen Gao, Pengjie Ren, Zhumin Chen, Fang Wang, Zhaochun Ren |  |
| 279 |  |  [Interpreting Indirect Answers to Yes-No Questions in Multiple Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.146) |  | 0 | Yes-no questions expect a yes or no for an answer, but people often skip polar keywords. Instead, they answer with long explanations that must be interpreted. In this paper, we focus on this challenging problem and release new benchmarks in eight languages. We present a distant supervision approach to collect training data, and demonstrate that direct answers (i.e., with polar keywords) are useful to train models to interpret indirect answers (i.e., without polar keywords). We show that monolingual fine-tuning is beneficial if training data can be obtained via distant supervision for the language of interest (5 languages). Additionally, we show that cross-lingual fine-tuning is always beneficial (8 languages). | Zijie Wang, Md Mosharaf Hossain, Shivam Mathur, Terry Cruz Melo, Kadir Bulut Özler, Keun Hee Park, Jacob Quintero, MohammadHossein Rezaei, Shreya Nupur Shakya, Md Nayem Uddin, Eduardo Blanco |  |
| 280 |  |  [Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with Type-Related Features](https://doi.org/10.18653/v1/2023.findings-emnlp.147) |  | 0 | Few-shot named entity recognition (NER) has shown remarkable progress in identifying entities in low-resource domains. However, few-shot NER methods still struggle with out-of-domain (OOD) examples due to their reliance on manual labeling for the target domain. To address this limitation, recent studies enable generalization to an unseen target domain with only a few labeled examples using data augmentation techniques. Two important challenges remain: First, augmentation is limited to the training data, resulting in minimal overlap between the generated data and OOD examples. Second, knowledge transfer is implicit and insufficient, severely hindering model generalizability and the integration of knowledge from the source domain. In this paper, we propose a framework, prompt learning with type-related features (PLTR), to address these challenges. To identify useful knowledge in the source domain and enhance knowledge transfer, PLTR automatically extracts entity type-related features (TRFs) based on mutual information criteria. To bridge the gap between training and OOD data, PLTR generates a unique prompt for each unseen example by selecting relevant TRFs. We show that PLTR achieves significant performance improvements on in-domain and cross-domain datasets. The use of PLTR facilitates model adaptation and increases representation similarities between the source and unseen domains. | Zihan Wang, Ziqi Zhao, Zhumin Chen, Pengjie Ren, Maarten de Rijke, Zhaochun Ren |  |
| 281 |  |  [Intervention-Based Alignment of Code Search with Execution Feedback](https://doi.org/10.18653/v1/2023.findings-emnlp.148) |  | 0 | One of the fundamental goals in code search is to retrieve a functionally correct code for a given natural language query. As annotating for correctness requires executing test cases (i.e. obtaining execution feedback), existing code search training datasets approximate text-code co-occurrences as positive execution feedback. However, this approximation may misalign models’ retrieval decisions from ground-truth correctness. To address such limitation, we propose Code Intervention-based Reinforcement Learning (CIRL) that perturbs training code to result in misalignment (i.e. code intervention), then tests models’ decisions and corrects them with the execution feedback by reinforcement learning. The first technical contribution of CIRL is to induce the execution feedback from perturbation, without actual execution. Secondly, CIRL introduces structural perturbations using abstract syntax trees, going beyond simple lexical changes. Experimental results on various datasets demonstrate the effectiveness of CIRL compared to conventional approaches. | Hojae Han, Minsoo Kim, Seungwon Hwang, Nan Duan, Shuai Lu |  |
| 282 |  |  [Enhancing Neural Machine Translation with Semantic Units](https://doi.org/10.18653/v1/2023.findings-emnlp.149) |  | 0 | Conventional neural machine translation (NMT) models typically use subwords and words as the basic units for model input and comprehension. However, complete words and phrases composed of several tokens are often the fundamental units for expressing semantics, referred to as semantic units. To address this issue, we propose a method Semantic Units for Machine Translation (SU4MT) which models the integral meanings of semantic units within a sentence, and then leverages them to provide a new perspective for understanding the sentence. Specifically, we first propose Word Pair Encoding (WPE), a phrase extraction method to help identify the boundaries of semantic units. Next, we design an Attentive Semantic Fusion (ASF) layer to integrate the semantics of multiple subwords into a single vector: the semantic unit representation. Lastly, the semantic-unit-level sentence representation is concatenated to the token-level one, and they are combined as the input of encoder. Experimental results demonstrate that our method effectively models and leverages semantic-unit-level information and outperforms the strong baselines. | Langlin Huang, Shuhao Gu, Zhuocheng Zhang, Yang Feng |  |
| 283 |  |  [DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework](https://doi.org/10.18653/v1/2023.findings-emnlp.150) |  | 0 | With the growing volume of diverse information, the demand for classifying arbitrary topics has become increasingly critical. To address this challenge, we introduce DRAFT, a simple framework designed to train a classifier for few-shot topic classification. DRAFT uses a few examples of a specific topic as queries to construct Customized dataset with a dense retriever model. Multi-query retrieval (MQR) algorithm, which effectively handles multiple queries related to a specific topic, is applied to construct the Customized dataset. Subsequently, we fine-tune a classifier using the Customized dataset to identify the topic. To demonstrate the efficacy of our proposed approach, we conduct evaluations on both widely used classification benchmark datasets and manually constructed datasets with 291 diverse topics, which simulate diverse contents encountered in real-world applications. DRAFT shows competitive or superior performance compared to baselines that use in-context learning, such as GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks despite having 177 times fewer parameters, demonstrating its effectiveness. | Keonwoo Kim, Younggun Lee |  |
| 284 |  |  [A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games](https://doi.org/10.18653/v1/2023.findings-emnlp.151) |  | 0 | The growing capabilities of large language models (LLMs) have inspired recent efforts to integrate LLM-generated dialogue into video games. However, evaluation remains a major challenge: how do we assess the player experience in a commercial game augmented with LLM-generated dialogue? To explore this question, we introduce a dynamic evaluation framework for the dialogue management systems that govern the task-oriented dialogue often found in roleplaying video games. We first extract dialogue from the widely-acclaimed role-playing game \*Disco Elysium: The Final Cut\*, which contains 1.1M words of dialogue spread across a complex graph of utterances where node reachability depends on game state (e.g., whether a certain item is held). Using this dataset, we have GPT-4 perform \*dialogue infilling\* to generate grounded utterances based on game state represented via code. In a statistically robust study of 28 players recruited from the r/DiscoyElysium subreddit, the LLM outputs are evaluated against the game designers’ writing via both preference judgments and free-form feedback using a web interface that recreates the game’s core conversation functionality. Overall, the game designers’ prose is significantly preferred to GPT-4 generations, with participants citing reasons such as improved logical flow and grounding with the game state. To spur more principled future research in this area, we release our web interface and tools to enable researchers to build upon our work. https://pl.aiwright.dev | Nader Akoury, Qian Yang, Mohit Iyyer |  |
| 285 |  |  [Generative Calibration for In-context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.152) |  | 0 | As one of the most exciting features of large language models (LLMs), in-context learning is a mixed blessing. While it allows users to fast-prototype a task solver with only a few training examples, the performance is generally sensitive to various configurations of the prompt such as the choice or order of the training examples. In this paper, we for the first time theoretically and empirically identify that such a paradox is mainly due to the label shift of the in-context model to the data distribution, in which LLMs shift the label marginal p(y) while having a good label conditional p(x\|y). With this understanding, we can simply calibrate the in-context predictive distribution by adjusting the label marginal, which is estimated via Monte-Carlo sampling over the in-context model, i.e., generation of LLMs. We call our approach as generative calibration. We conduct exhaustive experiments with 12 text classification tasks and 12 LLMs scaling from 774M to 33B, generally find that the proposed method greatly and consistently outperforms the ICL as well as state-of-the-art calibration methods, by up to 27% absolute in macro-F1. Meanwhile, the proposed method is also stable under different prompt configurations. | Zhongtao Jiang, Yuanzhe Zhang, Cao Liu, Jun Zhao, Kang Liu |  |
| 286 |  |  [Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.153) |  | 0 | Few-shot relation extraction involves identifying the type of relationship between two specific entities within a text, using a limited number of annotated samples. A variety of solutions to this problem have emerged by applying meta-learning and neural graph techniques which typically necessitate a training process for adaptation. Recently, the strategy of in-context learning has been demonstrating notable results without the need of training. Few studies have already utilized in-context learning for zero-shot information extraction. Unfortunately, the evidence for inference is either not considered or implicitly modeled during the construction of chain-of-thought prompts. In this paper, we propose a novel approach for few-shot relation extraction using large language models, named CoT-ER, chain-of-thought with explicit evidence reasoning. In particular, CoT-ER first induces large language models to generate evidences using task-specific and concept-level knowledge. Then these evidences are explicitly incorporated into chain-of-thought prompting for relation extraction. Experimental results demonstrate that our CoT-ER approach (with 0% training data) achieves competitive performance compared to the fully-supervised (with 100% training data) state-of-the-art approach on the FewRel1.0 and FewRel2.0 datasets. | Xilai Ma, Jing Li, Min Zhang |  |
| 287 |  |  [AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.154) |  | 0 | To alleviate the data scarcity problem in End-to-end speech translation (ST), pre-training on data for speech recognition and machine translation is considered as an important technique. However, the modality gap between speech and text prevents the ST model from efficiently inheriting knowledge from the pre-trained models. In this work, we propose AdaTranS for end-to-end ST. It adapts the speech features with a new shrinking mechanism to mitigate the length mismatch between speech and text features by predicting word boundaries. Experiments on the MUST-C dataset demonstrate that AdaTranS achieves better performance than the other shrinking-based methods, with higher inference speed and lower memory usage. Further experiments also show that AdaTranS can be equipped with additional alignment losses to further improve performance. | Xingshan Zeng, Liangyou Li, Qun Liu |  |
| 288 |  |  [No offence, Bert - I insult only humans! Multilingual sentence-level attack on toxicity detection networks](https://doi.org/10.18653/v1/2023.findings-emnlp.155) |  | 0 | We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations. | Sergey Berezin, Reza Farahbakhsh, Noël Crespi |  |
| 289 |  |  [Manipulating the Perceived Personality Traits of Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.156) |  | 0 | Psychology research has long explored aspects of human personality like extroversion, agreeableness and emotional stability, three of the personality traits that make up the ‘Big Five’. Categorizations like the ‘Big Five’ are commonly used to assess and diagnose personality types. In this work, we explore whether text generated from large language models exhibits consistency in it’s perceived ‘Big Five’ personality traits. For example, is a language model such as GPT2 likely to respond in a consistent way if asked to go out to a party? We also show that when exposed to different types of contexts (such as personality descriptions, or answers to diagnostic questions about personality traits), language models such as BERT and GPT2 consistently identify and mirror personality markers in those contexts. This behavior illustrates an ability to be manipulated in a predictable way (with correlations up to 0.84 between intended and realized changes in personality traits), and frames them as tools for controlling personas in applications such as dialog systems. We contribute two data-sets of personality descriptions of humans subjects. | Graham Caron, Shashank Srivastava |  |
| 290 |  |  [WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia](https://doi.org/10.18653/v1/2023.findings-emnlp.157) |  | 0 | This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus. WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment. Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also significantly more informative and engaging, just like an LLM. WikiChat achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4, while receiving significantly higher user ratings and more favorable comments. | Sina J. Semnani, Violet Z. Yao, Heidi C. Zhang, Monica S. Lam |  |
| 291 |  |  [Automated Few-Shot Classification with Instruction-Finetuned Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.158) |  | 0 | A particularly successful class of approaches for few-shot learning combines language models with prompts - hand-crafted task descriptions that complement data samples. However, designing prompts by hand for each task commonly requires domain knowledge and substantial guesswork. We observe, in the context of classification tasks, that instruction finetuned language models are remarkably robust towards some dimensions of a prompt’s design. We subsequently propose a simple method to eliminate the need for handcrafted prompts, named AuT-Few. This approach consists of (i) a prompt retrieval module that selects suitable task instructions from the instruction-tuning knowledge base, and (ii) the generation of two distinct, semantically meaningful, class descriptions and a selection mechanism via cross-validation. Over 12 datasets, spanning 8 classification tasks, we show that AuT-Few outperforms current state-of-the-art few-shot learning methods. Moreover, AuT-Few is the best ranking method across datasets on the RAFT few-shot benchmark. Notably, these results are achieved without task-specific handcrafted prompts on unseen tasks. | Rami Aly, Xingjian Shi, Kaixiang Lin, Aston Zhang, Andrew Gordon Wilson |  |
| 292 |  |  [Meta-Learning of Prompt Generation for Lightweight Prompt Engineering on Language-Model-as-a-Service](https://doi.org/10.18653/v1/2023.findings-emnlp.159) |  | 0 | Recently, many companies have been providing the capabilities of large language models as services. These Language-Model-as-a-Service (LMaaS) offerings support a variety of user tasks through in-context learning from prompts, which include instructions and demonstrations of the task. However, for users, manually crafting prompts or running automatic prompt tuning methods themselves can be demanding. Despite these challenges, LMaaS providers do not offer automatic prompt engineering methods as part of their services. One of the major obstacles to deploying them on an LMaaS is the heavy computational costs associated with automatic prompt engineering methods. These methods are typically designed to iterate through tens of thousands of examples, which impose unaffordable overheads for LMaaS providers. In this paper, we introduce MetaL-Prompt, a novel lightweight automatic prompt generation method for LMaaS. MetaL-Prompt meta-trains a prompt generation model (PGM) to enable robust learning by the language model from the contexts created by the generated prompts (i.e., in-context learning). Thanks to our meta-learning approach, a PGM can generate prompts for unseen tasks without requiring additional training for those specific tasks. Furthermore, the PGM can generate prompts with a single forward pass, significantly reducing computational costs compared to previous methods. We evaluate MetaL-Prompt on a range of unseen tasks and find that it improves performance by up to 19.4% in terms of mean F1 score on QA datasets compared to the state-of-the-art baseline P-tuning, with limited computational cost. | Hyeonmin Ha, Jihye Lee, Wookje Han, ByungGon Chun |  |
| 293 |  |  [Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction](https://doi.org/10.18653/v1/2023.findings-emnlp.160) |  | 0 | The vital role of analogical reasoning in human cognition allows us to grasp novel concepts by linking them with familiar ones through shared relational structures. Despite the attention previous research has given to word analogies, this work suggests that Large Language Models (LLMs) often overlook the structures that underpin these analogies, raising questions about the efficacy of word analogies as a measure of analogical reasoning skills akin to human cognition. In response to this, our paper introduces a task of analogical structure abduction, grounded in cognitive psychology, designed to abduce structures that form an analogy between two systems. In support of this task, we establish a benchmark called SCAR, containing 400 scientific analogies from 13 distinct fields, tailored for evaluating analogical reasoning with structure abduction. The empirical evidence underlines the continued challenges faced by LLMs, including ChatGPT and GPT-4, in mastering this task, signifying the need for future exploration to enhance their abilities. | Siyu Yuan, Jiangjie Chen, Xuyang Ge, Yanghua Xiao, Deqing Yang |  |
| 294 |  |  [HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings](https://doi.org/10.18653/v1/2023.findings-emnlp.161) |  | 0 | In this paper, we propose a hierarchical contrastive learning framework, HiCL, which considers local segment-level and global sequence-level relationships to improve training efficiency and effectiveness. Traditional methods typically encode a sequence in its entirety for contrast with others, often neglecting local representation learning, leading to challenges in generalizing to shorter texts. Conversely, HiCL improves its effectiveness by dividing the sequence into several segments and employing both local and global contrastive learning to model segment-level and sequence-level relationships. Further, considering the quadratic time complexity of transformers over input tokens, HiCL boosts training efficiency by first encoding short segments and then aggregating them to obtain the sequence representation. Extensive experiments show that HiCL enhances the prior top-performing SNCSE model across seven extensively evaluated STS tasks, with an average increase of +0.2% observed on BERTlarge and +0.44% on RoBERTalarge. | Zhuofeng Wu, Chaowei Xiao, V. G. Vinod Vydiswaran |  |
| 295 |  |  [Density-Aware Prototypical Network for Few-Shot Relation Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.162) |  | 0 | In recent years, few-shot relation classification has evoked many research interests. Yet a more challenging problem, i.e. none-of-the-above (NOTA), is under-explored. Existing works mainly regard NOTA as an extra class and treat it the same as known relations. However, such a solution ignores the overall instance distribution, where NOTA instances are actually outliers and distributed unnaturally compared with known ones. In this paper, we propose a density-aware prototypical network (D-Proto) to treat various instances distinctly. Specifically, we design unique training objectives to separate known instances and isolate NOTA instances, respectively. This produces an ideal instance distribution, where known instances are dense yet NOTAs have a small density. Moreover, we propose a NOTA detection module to further enlarge the density of known samples, and discriminate NOTA and known samples accurately. Experimental results demonstrate that the proposed method outperforms strong baselines with robustness towards various NOTA rates. The code will be made public after the paper is accepted. | Jianfeng Wu, Mengting Hu, Yike Wu, Bingzhe Wu, Yalan Xie, Mingming Liu, Renhong Cheng |  |
| 296 |  |  [Improved Training of Deep Text Clustering](https://doi.org/10.18653/v1/2023.findings-emnlp.163) |  | 0 | The classical deep clustering optimization methods basically leverage information such as clustering centers, mutual information, and distance metrics to construct implicit generalized labels to establish information feedback (weak supervision) and thus optimize the deep model. However, the resulting generalized labels have different degrees of errors in the whole clustering process due to the limitation of clustering accuracy, which greatly interferes with the clustering process. To this end, this paper proposes a general deep clustering optimization method from the perspective of empirical risk minimization, using the correlation relationship between the samples. Experiments on two classical deep clustering methods demonstrate the necessity and effectiveness of the method. Code is available at https://github.com/yangzonghao1024/DCGLU. | Zonghao Yang, Wenpeng Hu, Yushan Tan, Zhunchen Luo |  |
| 297 |  |  [RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.164) |  | 0 | Retrieval-augmented language models show promise in addressing issues like outdated information and hallucinations in language models (LMs). However, current research faces two main problems: 1) determining what information to retrieve, and 2) effectively combining retrieved information during generation. We argue that valuable retrieved information should not only be related to the current source text but also consider the future target text, given the nature of LMs that model future tokens. Moreover, we propose that aggregation using latent variables derived from a compact latent space is more efficient than utilizing explicit raw text, which is limited by context length and susceptible to noise. Therefore, we introduce RegaVAE, a retrieval-augmented language model built upon the variational auto-encoder (VAE). It encodes the text corpus into a latent space, capturing current and future information from both source and target text. Additionally, we leverage the VAE to initialize the latent space and adopt the probabilistic form of the retrieval generation paradigm by expanding the Gaussian prior distribution into a Gaussian mixture distribution. Theoretical analysis provides an optimizable upper bound for RegaVAE. Experimental results on various datasets demonstrate significant improvements in text generation quality and hallucination removal. | Jingcheng Deng, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 298 |  |  [RefGPT: Dialogue Generation of GPT, by GPT, and for GPT](https://doi.org/10.18653/v1/2023.findings-emnlp.165) |  | 0 | Large Language Models (LLMs) have attained the impressive capability to resolve a wide range of NLP tasks by fine-tuning high-quality instruction data. However, collecting human-written data of high quality, especially multi-turn dialogues, is expensive and unattainable for most people. Though previous studies have used powerful LLMs to generate the dialogues automatically, they all suffer from generating untruthful dialogues because of the model hallucination. Therefore, we propose a method called RefGPT to generate enormous truthful and customized dialogues without worrying about factual errors caused by the model hallucination. RefGPT solves the model hallucination in dialogue generation by restricting the LLMs to leverage the given reference instead of reciting their own knowledge to generate dialogues. Additionally, RefGPT adds detailed controls on every utterance to enable high customization capability, which previous studies have ignored. On the basis of RefGPT, we also propose two high-quality dialogue datasets generated by GPT-4, namely \*\*RefGPT-Fact\*\* and \*\*RefGPT-Code\*\*. RefGPT-Fact is a dataset with 100k multi-turn dialogues based on factual knowledge and RefGPT-Code has 76k multi-turn dialogues covering a wide range of coding scenarios. Our code and datasets are released in https://github.com/mutonix/RefGPT. | Dongjie Yang, Ruifeng Yuan, Yuantao Fan, Yifei Yang, Zili Wang, Shusen Wang, Hai Zhao |  |
| 299 |  |  [INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent](https://doi.org/10.18653/v1/2023.findings-emnlp.166) |  | 0 | In this paper, we propose a novel negotiation agent designed for the online marketplace. Our dialogue agent is integrative in nature i.e, it possesses the capability to negotiate on price as well as other factors, such as the addition or removal of items from a deal bundle, thereby offering a more flexible and comprehensive negotiation experience. To enable this functionality, we create a new dataset called Integrative Negotiation Dataset (IND). For this dataset creation, we introduce a new semi-automated data creation method, which combines defining negotiation intents, actions, and intent-action simulation between users and the agent to generate potential dialogue flows. Finally, the prompting of GPT-J, a state-of-the-art language model, is done to generate dialogues for a given intent, with a human-in-the-loop process for post-editing and refining minor errors to ensure high data quality. We first train a maximum likelihood loss based model on IND, and then employ a set of novel rewards specifically tailored for the negotiation task to train our Integrative Negotiation Agent (INA). These rewards incentivize the agent to learn effective negotiation strategies that can adapt to various contextual requirements and price proposals. We train our model and conduct experiments to evaluate the effectiveness of our reward-based dialogue agent for negotiation. Our results demonstrate that the proposed approach and reward functions significantly enhance the negotiation capabilities of the dialogue agent. The INA successfully engages in integrative negotiations, displaying the ability to dynamically adjust prices and negotiate the inclusion or exclusion of items in a deal bundle. | Zishan Ahmad, Suman Saurabh, Vaishakh Sreekanth Menon, Asif Ekbal, Roshni R. Ramnani, Anutosh Maitra |  |
| 300 |  |  [Large Language Models are Better Reasoners with Self-Verification](https://doi.org/10.18653/v1/2023.findings-emnlp.167) |  | 0 | Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification. | Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, Jun Zhao |  |
| 301 |  |  [Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting](https://doi.org/10.18653/v1/2023.findings-emnlp.168) |  | 0 | Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture the source of important words, which is crucial to edit the incomplete utterance, and introduce words from irrelevant utterances. We propose a novel and effective multi-task information interaction framework including context selection, edit matrix construction, and relevance merging to capture the multi-granularity of semantic information. Benefiting from fetching the relevant utterance and figuring out the important words, our approach outperforms existing state-of-the-art models on two benchmark datasets Restoration-200K and CANAND in this field. | Haowei Du, Dinghao Zhang, Chen Li, Yang Li, Dongyan Zhao |  |
| 302 |  |  [Accuracy is not enough: Evaluating Personalization in Summarizers](https://doi.org/10.18653/v1/2023.findings-emnlp.169) |  | 0 | Text summarization models are evaluated in terms of their accuracy and quality using various measures such as ROUGE, BLEU, METEOR, BERTScore, PYRAMID, readability, and several other recently proposed ones. The central objective of all accuracy measures is to evaluate the model’s ability to capture saliency accurately. Since saliency is subjective w.r.t the readers’ preferences, there cannot be a fit-all summary for a given document. This means that in many use-cases, summarization models need to be personalized w.r.t user-profiles. However, to our knowledge, there is no measure to evaluate the degree-of-personalization of a summarization model. In this paper, we first establish that existing accuracy measures cannot evaluate the degree of personalization of any summarization model, and then propose a novel measure, called EGISES, for automatically computing the same. Using the PENS dataset released by Microsoft Research, we analyze the degree of personalization of ten different state-of-the-art summarization models (both extractive and abstractive), five of which are explicitly trained for personalized summarization, and the remaining are appropriated to exhibit personalization. We conclude by proposing a generalized accuracy measure, called P-Accuracy, for designing accuracy measures that should also take personalization into account and demonstrate the robustness and reliability of the measure through meta-evaluation. | Rahul Vansh, Darsh Rank, Sourish Dasgupta, Tanmoy Chakraborty |  |
| 303 |  |  [For Generated Text, Is NLI-Neutral Text the Best Text?](https://doi.org/10.18653/v1/2023.findings-emnlp.170) |  | 0 | We explore incorporating natural language inference (NLI) into the text generative pipeline by using a pre-trained NLI model to assess whether a generated sentence entails, contradicts, or is neutral to the prompt and preceding text. First, we show that the NLI task is predictive of generation errors made by GPT-3. We use these results to develop an NLI-informed generation procedure for GPT-J. Then, we evaluate these generations by obtaining human annotations on error types and overall quality. We find that an NLI strategy of maximizing entailment improves text generation when the nucleus sampling randomness parameter value is high, while one which maximizes contradiction is in fact productive when the parameter value is low. Overall, though, we demonstrate that an NLI strategy of maximizing the neutral class provides the highest quality of generated text (significantly better than the vanilla generations), regardless of parameter value. | Michail Mersinias, Kyle Mahowald |  |
| 304 |  |  [Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review](https://doi.org/10.18653/v1/2023.findings-emnlp.171) |  | 0 | Technology Assisted Review (TAR) stopping rules aim to reduce the cost of manually assessing documents for relevance by minimising the number of documents that need to be examined to ensure a desired level of recall. This paper extends an effective stopping rule using information derived from a text classifier that can be trained without the need for any additional annotation. Experiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal and RCV1) showed that the proposed approach consistently improves performance and outperforms several alternative methods. | Reem Bin Hezam, Mark Stevenson |  |
| 305 |  |  [Complexity-Guided Curriculum Learning for Text Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.172) |  | 0 | Curriculum learning provides a systematic approach to training. It refines training progressively, tailors training to task requirements, and improves generalization through exposure to diverse examples. We present a curriculum learning approach that builds on existing knowledge about text and graph complexity formalisms for training with text graph data. The core part of our approach is a novel data scheduler, which employs “spaced repetition” and complexity formalisms to guide the training process. We demonstrate the effectiveness of the proposed approach on several text graph tasks and graph neural network architectures. The proposed model gains more and uses less data; consistently prefers text over graph complexity indices throughout training, while the best curricula derived from text and graph complexity indices are equally effective; and it learns transferable curricula across GNN models and datasets. In addition, we find that both node-level (local) and graph-level (global) graph complexity indices, as well as shallow and traditional text complexity indices play a crucial role in effective curriculum learning. | Nidhi Vakil, Hadi Amiri |  |
| 306 |  |  [CoVariance-based Causal Debiasing for Entity and Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.173) |  | 0 | Joint entity and relation extraction tasks aim to recognize named entities and extract relations simultaneously. Suffering from a variety of data biases, such as data selection bias, and distribution bias (out of distribution, long-tail distribution), serious concerns can be witnessed to threaten the model’s transferability, robustness, and generalization. In this work, we address the above problems from a causality perspective. We propose a novel causal framework called c ̲ovariance and ̲variance ̲optimization framework (OVO) to optimize feature representations and conduct general debiasing. In particular, the proposed ̲covariance ̲optimizing (COP) minimizes characterizing features’ covariance for alleviating the selection and distribution bias and enhances feature representation in the feature space. Furthermore, based on the causal backdoor adjustment, we propose \\underlinevariance ̲optimizing (VOP) separates samples in terms of label information and minimizes the variance of each dimension in the feature vectors of the same class label for mitigating the distribution bias further. By applying it to three strong baselines in two widely used datasets, the results demonstrate the effectiveness and generalization of OVO for joint entity and relation extraction tasks. Furthermore, a fine-grained analysis reveals that OVO possesses the capability to mitigate the impact of long-tail distribution. | Lin Ren, Yongbin Liu, Yixin Cao, Chunping Ouyang |  |
| 307 |  |  [Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.174) |  | 0 | Data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. However, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. In this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. We empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. We introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. Experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy. | Zhengyuan Liu, Hai Leong Chieu, Nancy F. Chen |  |
| 308 |  |  [In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.175) |  | 0 | Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by culture: formality. We analyze the formality distributions of XGLM and BLOOM’s predictions, two popular generative multilingual language models, in 5 languages. We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that the models generate a significant amount of informal predictions even when prompted with formal text. We release with this work 6,000 annotated samples, paving the way for future work on the formality of generative multilingual LMs. | Asim Ersoy, Gerson Vizcarra, Tasmiah Tahsin Mayeesha, Benjamin Muller |  |
| 309 |  |  [MaXM: Towards Multilingual Visual Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.176) |  | 0 | Visual Question Answering (VQA) has been primarily studied through the lens of the English language. Yet, tackling VQA in other languages in the same manner would require a considerable amount of resources. In this paper, we propose scalable solutions to multilingual visual question answering (mVQA), on both data and modeling fronts. We first propose a translation-based framework to mVQA data generation that requires much less human annotation efforts than the conventional approach of directly collection questions and answers. Then, we apply our framework to the multilingual captions in the Crossmodal-3600 dataset and develop an efficient annotation protocol to create MaXM, a test-only VQA benchmark in 7 diverse languages. Finally, we develop a simple, lightweight, and effective approach as well as benchmark state-of-the-art English and multilingual VQA models. We hope that our benchmark encourages further research on mVQA. | Soravit Changpinyo, Linting Xue, Michal Yarom, Ashish V. Thapliyal, Idan Szpektor, Julien Amelot, Xi Chen, Radu Soricut |  |
| 310 |  |  [Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.177) |  | 0 | Knowledge-grounded dialogue generation requires first retrieving appropriate external knowledge based on a conversational context and then generating a response grounded on the retrieved knowledge. In general, these two sequential modules, a knowledge retriever and a response generator, have been separately trained in a supervised manner. However, obtaining intermediate labels of the ground-truth knowledge is expensive, especially in open-domain conversations. Latent variable modeling avoids this need for the labels. In this paper, we propose an efficient algorithm for this latent variable modeling that is able to leverage a large amount of dialogue data. Rather than directly training the complex retriever, we adapt a query generator with an off-the-shelf retriever, and the query generator and response generator are simultaneously trained over the latent variable of query. Moreover, we employ lower bound of the evidence as a training objective and modify it to robustly perform the joint training. Experimental results on diverse knowledge-grounded dialogue datasets show that the proposed algorithm significantly outperforms the supervised learning algorithm even without the use of the annotated knowledge while maintaining efficiency and scalability. | Gunsoo Han, Daejin Jo, Daniel Wontae Nam, Eunseop Yoon, Taehwan Kwon, Seungeun Rho, KyoungWoon On, Chang Dong Yoo, Sungwoong Kim |  |
| 311 |  |  [Ask To The Point: Open-Domain Entity-Centric Question Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.178) |  | 0 | We introduce a new task called \*entity-centric question generation\* (ECQG), motivated by real-world applications such as topic-specific learning, assisted reading, and fact-checking. The task aims to generate questions from an entity perspective. To solve ECQG, we propose a coherent PLM-based framework GenCONE with two novel modules: content focusing and question verification. The content focusing module first identifies a focus as “what to ask” to form draft questions, and the question verification module refines the questions afterwards by verifying the answerability. We also construct a large-scale open-domain dataset from SQuAD to support this task. Our extensive experiments demonstrate that GenCONE significantly and consistently outperforms various baselines, and two modules are effective and complementary in generating high-quality questions. | Yuxiang Liu, Jie Huang, Kevin ChenChuan Chang |  |
| 312 |  |  [Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.179) |  | 0 | In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT selection and self-prompted inference via in-context learning. Extensive experiments on four multi-hop question-answering benchmarks show that our proposed SP-CoT not only significantly surpasses the previous SOTA methods on large-scale (175B) LLMs, but also nearly doubles the zero-shot performance of small-scale (13B) LLMs. Further analysis reveals the remarkable capability of SP-CoT to elicit direct and concise intermediate reasoning steps by recalling ~50% of intermediate answers on MuSiQue-Ans dataset. | Jinyuan Wang, Junlong Li, Hai Zhao |  |
| 313 |  |  [CASE: Commonsense-Augmented Score with an Expanded Answer Space](https://doi.org/10.18653/v1/2023.findings-emnlp.180) |  | 0 | LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks to the knowledge they acquired in their training. In multiple-choice QA tasks, the LM probabilities are used as an imperfect measure of the plausibility of each answer choice. One of the major limitations of the basic score is that it treats all words as equally important. We propose CASE, a Commonsense-Augmented Score with an Expanded Answer Space. CASE addresses this limitation by assigning importance weights for individual words based on their semantic relations to other words in the input. The dynamic weighting approach outperforms basic LM scores, not only because it reduces noise from unimportant words, but also because it informs the model of implicit commonsense knowledge that may be useful for answering the question. We then also follow prior work in expanding the answer space by generating lexically-divergent answers that are conceptually-similar to the choices. When combined with answer space expansion, our method outperforms strong baselines on 5 commonsense benchmarks. We further show these two approaches are complementary and may be especially beneficial when using smaller LMs. | Wenkai Chen, Sahithya Ravi, Vered Shwartz |  |
| 314 |  |  [GRENADE: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.181) |  | 0 | Self-supervised representation learning on text-attributed graphs, which aims to create expressive and generalizable representations for various downstream tasks, has received increasing research attention lately. However, existing methods either struggle to capture the full extent of structural context information or rely on task-specific training labels, which largely hampers their effectiveness and generalizability in practice. To solve the problem of self-supervised representation learning on text-attributed graphs, we develop a novel Graph-Centric Language model – GRENADE. Specifically, GRENADE harnesses the synergy of both pre-trained language model and graph neural network by optimizing with two specialized self-supervised learning algorithms: graph-centric contrastive learning and graph-centric knowledge alignment. The proposed graph-centric self-supervised learning algorithms effectively help GRENADE to capture informative textual semantics as well as structural context information on text-attributed graphs. Through extensive experiments, GRENADE shows its superiority over state-of-the-art methods. | Yichuan Li, Kaize Ding, Kyumin Lee |  |
| 315 |  |  [Sources of Hallucination by Large Language Models on Inference Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.182) |  | 0 | Large Language Models (LLMs) are claimed to be capable of Natural Language Inference (NLI), necessary for applied tasks like question answering and summarization. We present a series of behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled experiments. We establish two biases originating from pretraining which predict much of their behavior, and show that these are major sources of hallucination in generative LLMs. First, memorization at the level of sentences: we show that, regardless of the premise, models falsely label NLI test samples as entailing when the hypothesis is attested in training data, and that entities are used as “indices’ to access the memorized data. Second, statistical patterns of usage learned at the level of corpora: we further show a similar effect when the premise predicate is less frequent than that of the hypothesis in the training data, a bias following from previous studies. We demonstrate that LLMs perform significantly worse on NLI test samples which do not conform to these biases than those which do, and we offer these as valuable controls for future LLM evaluation. | Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark Johnson, Mark Steedman |  |
| 316 |  |  [Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer](https://doi.org/10.18653/v1/2023.findings-emnlp.183) |  | 0 | Pretrained transformer models have demonstrated remarkable performance across various natural language processing tasks. These models leverage the attention mechanism to capture long- and short-range dependencies in the sequence. However, the (full) attention mechanism incurs high computational cost – quadratic in the sequence length, which is not affordable in tasks with long sequences, e.g., inputs with 8k tokens. Although sparse attention can be used to improve computational efficiency, as suggested in existing work, it has limited modeling capacity and often fails to capture complicated dependencies in long sequences. To tackle this challenge, we propose MASFormer, an easy-to-implement transformer variant with mixed attention spans. Specifically, MASFormer is equipped with full attention to capture long-range dependencies, but only at a small number of layers. For the remaining layers, MASformer only employs sparse attention to capture short-range dependencies. Our experiments on natural language modeling and generation tasks show that a decoder-only MASFormer model of 1.3B parameters can achieve competitive performance to vanilla transformers with full attention while significantly reducing computational cost (up to 75%). Additionally, we investigate the effectiveness of continual training with long sequence data and how sequence length impacts downstream generation performance, which may be of independent interest. | Qingru Zhang, Dhananjay Ram, Cole Hawkins, Sheng Zha, Tuo Zhao |  |
| 317 |  |  [Prompting ChatGPT in MNER: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge](https://doi.org/10.18653/v1/2023.findings-emnlp.184) |  | 0 | Multimodal Named Entity Recognition (MNER) on social media aims to enhance textual entity prediction by incorporating image-based clues. Existing studies mainly focus on maximizing the utilization of pertinent image information or incorporating external knowledge from explicit knowledge bases. However, these methods either neglect the necessity of providing the model with external knowledge, or encounter issues of high redundancy in the retrieved knowledge. In this paper, we present PGIM — a two-stage framework that aims to leverage ChatGPT as an implicit knowledge base and enable it to heuristically generate auxiliary knowledge for more efficient entity prediction. Specifically, PGIM contains a Multimodal Similar Example Awareness module that selects suitable examples from a small number of predefined artificial samples. These examples are then integrated into a formatted prompt template tailored to the MNER and guide ChatGPT to generate auxiliary refined knowledge. Finally, the acquired knowledge is integrated with the original text and fed into a downstream model for further processing. Extensive experiments show that PGIM outperforms state-of-the-art methods on two classic MNER datasets and exhibits a stronger robustness and generalization capability. | Jinyuan Li, Han Li, Zhuo Pan, Di Sun, Jiahao Wang, Wenkun Zhang, Gang Pan |  |
| 318 |  |  [Understanding HTML with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.185) |  | 0 | Large language models (LLMs) have shown exceptional performance on a variety of natural language tasks. Yet, their capabilities for HTML understanding – i.e., parsing the raw HTML of a webpage, with applications to automation of web-based tasks, crawling, and browser-assisted retrieval – have not been fully explored. We contribute HTML understanding models (fine-tuned LLMs) and an in-depth analysis of their capabilities under three tasks: (i) Semantic Classification of HTML elements, (ii) Description Generation for HTML inputs, and (iii) Autonomous Web Navigation of HTML pages. While previous work has developed dedicated architectures and training procedures for HTML understanding, we show that LLMs pretrained on standard natural language corpora transfer remarkably well to HTML understanding tasks. For instance, when fine-tuned on data from the MiniWoB benchmark, LLMs successfully complete 50% more tasks using 192x less data compared to the previous best supervised model. We create and open-source a large-scale HTML dataset distilled and auto-labeled from CommonCrawl | Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin V. Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, Aleksandra Faust |  |
| 319 |  |  [The PEACE-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.186) |  | 0 | Cognitive appraisal plays a pivotal role in deciphering emotions. Recent studies have delved into its significance, yet the interplay between various forms of cognitive appraisal and specific emotions, such as joy and anger, remains an area of exploration in consumption contexts. Our research introduces the PEACE-Reviews dataset, a unique compilation of annotated autobiographical accounts where individuals detail their emotional and appraisal experiences during interactions with personally significant products or services. Focusing on the inherent variability in consumer experiences, this dataset offers an in-depth analysis of participants’ psychological traits, their evaluative feedback on purchases, and the resultant emotions. Notably, the PEACE-Reviews dataset encompasses emotion, cognition, individual traits, and demographic data. We also introduce preliminary models that predict certain features based on the autobiographical narratives. | Gerard Yeo, Kokil Jaidka |  |
| 320 |  |  [UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model](https://doi.org/10.18653/v1/2023.findings-emnlp.187) |  | 0 | Text is ubiquitous in our visual world, conveying crucial information, such as in documents, websites, and everyday photographs. In this work, we propose UReader, a first exploration of universal OCR-free visually-situated language understanding based on the Multimodal Large Language Model (MLLM). By leveraging the shallow text recognition ability of the MLLM, we only finetuned 1.2% parameters and the training cost is much lower than previous work following domain-specific pretraining and finetuning paradigms. Concretely, UReader is jointly finetuned on a wide range of Visually-situated Language Understanding tasks via a unified instruction format. To enhance the visual text and semantic understanding, we further apply two auxiliary tasks with the same format, namely text reading and key points generation tasks. We design a shape-adaptive cropping module before the encoder-decoder architecture of MLLM to leverage the frozen low-resolution vision encoder for processing high-resolution images. Without downstream finetuning, our single model achieves state-of-the-art ocr-free performance in 8 out of 10 visually-situated language understanding tasks, across 5 domains: documents, tables, charts, natural images, and webpage screenshots. Codes and instruction-tuning datasets will be released. | Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Ming Yan, Guohai Xu, Chenliang Li, Junfeng Tian, Qi Qian, Ji Zhang, Qin Jin, Liang He, Xin Lin, Fei Huang |  |
| 321 |  |  [Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2023.findings-emnlp.188) |  | 0 | Reinforcement learning from human feedback serves as a crucial bridge, aligning large language models with human and societal values. This alignment requires a vast corpus of human feedback to learn a reward model, which is subsequently used to finetune language models. However, we have identified that the reward model often finds shortcuts to bypass its intended objectives, misleadingly assuming that humans prefer longer responses. The emergence of length bias often induces the model to favor longer outputs, yet it doesn’t equate to an increase in helpful information within these outputs. In this paper, we propose an innovative solution, applying the Product-of-Experts (PoE) technique to separate reward modeling from the influence of sequence length. In our framework, the main expert concentrates on understanding human intents, while the biased expert targets the identification and capture of length bias. To further enhance the learning of bias, we introduce perturbations into the bias-focused expert, disrupting the flow of semantic information. Experimental results validate the effectiveness of our approach, indicating that language model performance is improved, irrespective of sequence length. | Wei Shen, Rui Zheng, WenYu Zhan, Jun Zhao, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 322 |  |  [Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions](https://doi.org/10.18653/v1/2023.findings-emnlp.189) |  | 0 | Large Language Models (LLMs) demonstrate impressive reasoning ability and the maintenance of world knowledge not only in natural language tasks, but also in some vision-language tasks such as open-domain knowledge-based visual question answering (OK-VQA). As images are invisible to LLMs, researchers convert images to text to engage LLMs into the visual question reasoning procedure. This leads to discrepancies between images and their textual representations presented to LLMs, which consequently impedes final reasoning performance. To fill the information gap and better leverage the reasoning capability, we design a framework that enables LLMs to proactively ask relevant questions to unveil more details in the image, along with filters for refining the generated information. We validate our idea on OK-VQA and A-OKVQA. Our method continuously boosts the performance of baselines methods by an average gain of 2.15% on OK-VQA, and achieves consistent improvements across different LLMs. | Ziyue Wang, Chi Chen, Peng Li, Yang Liu |  |
| 323 |  |  [Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only](https://doi.org/10.18653/v1/2023.findings-emnlp.190) |  | 0 | Recent studies have revealed the remarkable cross-lingual capability of multilingual pre-trained language models (mPLMs), even when pre-trained without parallel corpora (mono-mPLMs). Intuitively, semantic alignments may be the reason behind such capability but remain under-explored. In this work, we investigate the alignment properties from the token perspective in mono-mPLMs and find that the alignments correspond to the geometric similarity of embedding space across different languages. Nevertheless, mono-mPLMs tend to damage this geometric similarity at the higher layers due to the lack of cross-lingual interactions, thus limiting their cross-lingual transfer capabilities. To address this issue, we introduce token-level and semantic-level code-switched masked language modeling, employing the self-induced token alignments to explicitly improve cross-lingual interactions over layers of mono-mPLMs without relying on parallel sentences. We evaluate our method on various natural language understanding tasks and unsupervised machine translation tasks. The results demonstrate that our methods outperform the strong baselines and achieve comparable performance with mPLMs trained with parallel corpora. | Jinliang Lu, Yu Lu, Jiajun Zhang |  |
| 324 |  |  [LogiCoT: Logical Chain-of-Thought Instruction Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.191) |  | 0 | Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive chain-of-thought reasoning ability. Recent work on self-instruction tuning, such as Alpaca, has focused on enhancing the general proficiency of models. These instructions enable the model to achieve performance comparable to GPT-3.5 on general tasks like open-domain text generation and paraphrasing. However, they fall short of helping the model handle complex reasoning tasks. To bridge the gap, this paper presents LogiCoT, a new instruction-tuning dataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the process of harvesting instructions for prompting GPT-4 to generate chain-of-thought rationales. LogiCoT serves as an instruction set for teaching models of logical reasoning and elicits general reasoning skills. | Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji Zhou, Yue Zhang |  |
| 325 |  |  [Hiding in Plain Sight: Tweets with Hate Speech Masked by Homoglyphs](https://doi.org/10.18653/v1/2023.findings-emnlp.192) |  | 0 | To avoid detection by current NLP monitoring applications, progenitors of hate speech often replace one or more letters in offensive words with homoglyphs, visually similar Unicode characters. Harvesting real-world hate speech containing homoglyphs is challenging due to the vast replacement possibilities. We developed a character substitution scraping method and assembled the Offensive Tweets with Homoglyphs (OTH) Dataset (N=90,788) with more than 1.5 million occurrences of 1,281 non-Latin characters (emojis excluded). In an annotated sample (n=700), 40.14% of the tweets were found to contain hate speech. We assessed the performance of seven transformer-based hate speech detection models and found that they performed poorly in a zero-shot setting (F1 scores between 0.04 and 0.52) but normalizing the data dramatically improved detection (F1 scores between 0.59 and 0.71). Training the models using the annotated data further boosted performance (highest micro-averaged F1 score=0.88, using five-fold cross validation). This study indicates that a dataset containing homoglyphs known and unknown to the scraping script can be collected, and that neural models can be trained to recognize camouflaged real-world hate speech. | Portia Cooper, Mihai Surdeanu, Eduardo Blanco |  |
| 326 |  |  [Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.193) |  | 0 | Recently, aspect-based sentiment analysis (ABSA) models have yielded promising results. However, they are susceptible to learning spurious correlations between certain words of the input text and output labels while modeling the sentiment feature of the aspect. This spurious correlation will potentially undermine the performance of ABSA models. One direct solution for this problem is to make the model see and learn an explanation of sentiment expression rather than certain words. Motivated by this, we exploit explanations for the sentiment polarity of each aspect from large language models (LLMs) to reduce spurious correlations in ABSA. First, we formulate a prompt template that wraps the sentence, an aspect, and the sentiment label. This template is utilized to prompt LLMs to generate an appropriate explanation that states the sentiment cause. Then, we propose two straightforward yet effective methods to leverage the explanation for preventing the learning of spurious correlations. We conducted extensive comparative experiments on five datasets by integrating them with some representative ABSA models. Results show that our methods can achieve performance gains and enhance the performance and generalization ability of ABSA models. | Qianlong Wang, Keyang Ding, Bin Liang, Min Yang, Ruifeng Xu |  |
| 327 |  |  [High-quality argumentative information in low resources approaches improve counter-narrative generation](https://doi.org/10.18653/v1/2023.findings-emnlp.194) |  | 0 | It has been shown that high quality fine-tuning boosts the performance of language models, even if the size of the fine-tuning is small. In this work we show how highly targeted fine-tuning improves the task of hate speech counter-narrative generation in user-generated text, even for very small sizes of training (1722 counter-narratives for English and 355 for Spanish). Providing a small subset of examples focusing on single argumentative strategies, together with the argumentative analysis relevant to that strategy, yields counter-narratives that are as satisfactory as providing the whole set of counter-narratives. We also show that a good base model is required for the fine-tuning to have a positive impact. Indeed, for Spanish, the counter-narratives obtained without fine-tuning are mostly unacceptable, and, while fine-tuning improves their overall quality, the performance still remains quite unsatisfactory. | Damián Ariel Furman, Pablo Torres, José A. Rodríguez, Diego Letzen, Maria Vanina Martinez, Laura Alonso Alemany |  |
| 328 |  |  [A Reference-free Segmentation Quality Index (SegReFree)](https://doi.org/10.18653/v1/2023.findings-emnlp.195) |  | 0 | Topic segmentation, in the context of natural language processing, is the process of finding boundaries in a sequence of sentences that separate groups of adjacent sentences at shifts in semantic meaning. Currently, assessing the quality of a segmentation is done by comparing segmentation boundaries selected by a human or algorithm to those selected by a known good reference. This means that it is not possible to quantify the quality of a segmentation without a human annotator, which can be costly and time consuming. This work seeks to improve assessment of segmentation by proposing a reference-free segmentation quality index (SegReFree). The metric takes advantage of the fact that segmentation at a sentence level generally seeks to identify segment boundaries at semantic boundaries within the text. The proposed metric uses a modified cluster validity metric with semantic embeddings of the sentences to determine the quality of the segmentation. Multiple segmentation data sets are used to compare our proposed metric with existing reference-based segmentation metrics by progressively degrading the reference segmentation while computing all possible metrics; through this process, a strong correlation with existing segmentation metrics is shown. A Python library implementing the metric is released under the GNU General Public License and the repository is available at https://github.com/evan-person/reference_free_segmentation_metric. | Evan Lucas, Dylan Kangas, Timothy C. Havens |  |
| 329 |  |  [In-context Learning for Few-shot Multimodal Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.196) |  | 0 | Thanks in part to the availability of copious annotated resources for some entity categories, existing studies have achieved superior performance in multimodal named entity recognition (MNER). However, in the real-world scenario, it is infeasible to enumerate all entity categories in advance. Therefore, in this paper, we formulate a new few-shot multimodal named entity recognition (FewMNER) task, which aims to effectively locate and identify named entities for a text-image pair only using a small number of labeled examples. Further, we explore the merit of in-context learning (ICL) and propose a novel framework to deal with FewMNER, where three points are taken into account: i.e., converting visual modality, selecting useful examples, and designing an effective task demonstration. Specifically, we first employ an image caption model to convert images into textual descriptions, enabling large language models to absorb information from visual modality. Then, we use the ranking of the sum of similarity rankings from both text and image modalities to select k-nearest examples, which form a demonstration context. Finally, we utilize the MNER definition and the meaning of each entity category as effective instruction. Extensive experimental results demonstrate that our framework outperforms baselines under several few-shot settings. | Chenran Cai, Qianlong Wang, Bin Liang, Bing Qin, Min Yang, KamFai Wong, Ruifeng Xu |  |
| 330 |  |  [On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study](https://doi.org/10.18653/v1/2023.findings-emnlp.197) |  | 0 | Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods’ effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty using our newly introduced evaluation protocol. We show that the probabilistic methods consistently improve the model’s generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns of probabilistic methods widely-adopted in NLP community (e.g., Deep Ensemble and Monte Carlo Dropout), cautioning the importance of choosing appropriate method for the data setting. | Polina Zablotskaia, Du Phan, Joshua Maynez, Shashi Narayan, Jie Ren, Jeremiah Z. Liu |  |
| 331 |  |  [Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods](https://doi.org/10.18653/v1/2023.findings-emnlp.198) |  | 0 | The majority of existing work on sign language recognition encodes signed videos without explicitly acknowledging the phonological attributes of signs. Given that handshape is a vital parameter in sign languages, we explore the potential of handshape-aware sign language recognition. We augment the PHOENIX14T dataset with gloss-level handshape labels, resulting in the new PHOENIX14T-HS dataset. Two unique methods are proposed for handshape-inclusive sign language recognition: a single-encoder network and a dual-encoder network, complemented by a training strategy that simultaneously optimizes both the CTC loss and frame-level cross-entropy loss. The proposed methodology consistently outperforms the baseline performance. The dataset and code can be accessed at: www.anonymous.com. | Xuan Zhang, Kevin Duh |  |
| 332 |  |  [SimCKP: Simple Contrastive Learning of Keyphrase Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.199) |  | 0 | Keyphrase generation (KG) aims to generate a set of summarizing words or phrases given a source document, while keyphrase extraction (KE) aims to identify them from the text. Because the search space is much smaller in KE, it is often combined with KG to predict keyphrases that may or may not exist in the corresponding document. However, current unified approaches adopt sequence labeling and maximization-based generation that primarily operate at a token level, falling short in observing and scoring keyphrases as a whole. In this work, we propose SimCKP, a simple contrastive learning framework that consists of two stages: 1) An extractor-generator that extracts keyphrases by learning context-aware phrase-level representations in a contrastive manner while also generating keyphrases that do not appear in the document; 2) A reranker that adapts scores for each generated phrase by likewise aligning their representations with the corresponding document. Experimental results on multiple benchmark datasets demonstrate the effectiveness of our proposed approach, which outperforms the state-of-the-art models by a significant margin. | Minseok Choi, Chaeheon Gwak, Seho Kim, Si Hyeong Kim, Jaegul Choo |  |
| 333 |  |  [LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain](https://doi.org/10.18653/v1/2023.findings-emnlp.200) |  | 0 | Lately, propelled by phenomenal advances around the transformer architecture, the legal NLP field has enjoyed spectacular growth. To measure progress, well-curated and challenging benchmarks are crucial. Previous efforts have produced numerous benchmarks for general NLP models, typically based on news or Wikipedia. However, these may not fit specific domains such as law, with its unique lexicons and intricate sentence structures. Even though there is a rising need to build NLP systems for languages other than English, many benchmarks are available only in English and no multilingual benchmark exists in the legal NLP field. We survey the legal NLP literature and select 11 datasets covering 24 languages, creating LEXTREME. To fairly compare models, we propose two aggregate scores, i.e., dataset aggregate score and language aggregate score. Our results show that even the best baseline only achieves modest results, and also ChatGPT struggles with many tasks. This indicates that LEXTREME remains a challenging task with ample room for improvement. To facilitate easy use for researchers and practitioners, we release LEXTREME on huggingface along with a public leaderboard and the necessary code to evaluate models. We also provide a public Weights and Biases project containing all runs for transparency. | Joel Niklaus, Veton Matoshi, Pooja Rani, Andrea Galassi, Matthias Stürmer, Ilias Chalkidis |  |
| 334 |  |  [Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.201) |  | 0 | Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students’ mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions’ rationales when attempting to correct students’ answers. Three research questions are formulated. | AnZi Yen, WeiLing Hsu |  |
| 335 |  |  [Simultaneous Machine Translation with Tailored Reference](https://doi.org/10.18653/v1/2023.findings-emnlp.202) |  | 0 | Simultaneous machine translation (SiMT) generates translation while reading the whole source sentence. However, existing SiMT models are typically trained using the same reference disregarding the varying amounts of available source information at different latency. Training the model with ground-truth at low latency may introduce forced anticipations, whereas utilizing reference consistent with the source word order at high latency results in performance degradation. Consequently, it is crucial to train the SiMT model with appropriate reference that avoids forced anticipations during training while maintaining high quality. In this paper, we propose a novel method that provides tailored reference for the SiMT models trained at different latency by rephrasing the ground-truth. Specifically, we introduce the tailor, induced by reinforcement learning, to modify ground-truth to the tailored reference. The SiMT model is trained with the tailored reference and jointly optimized with the tailor to enhance performance. Importantly, our method is applicable to a wide range of current SiMT approaches. Experiments on three translation tasks demonstrate that our method achieves state-of-the-art performance in both fixed and adaptive policies. | Shoutao Guo, Shaolei Zhang, Yang Feng |  |
| 336 |  |  [Dynamic Voting for Efficient Reasoning in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.203) |  | 0 | Multi-path voting methods like Self-consistency have been used to mitigate reasoning errors in large language models caused by factual errors and illusion generation. However, these methods require excessive computing resources as they generate numerous reasoning paths for each problem. And our experiments show that on the arithmetic reasoning task, SVAMP, half of the problems fail to obtain noticeable accuracy gains when voting with more than three paths. In this paper, we propose a novel multi-path voting technique called Dynamic Voting, which effectively reduces the number of reasoning paths during multi-path voting while preserving accuracies by applying early exiting for problems that large language models can confidently solve. Experimental evaluations on arithmetic, commonsense, and symbolic reasoning tasks under few-shot and zero-shot settings demonstrate that Dynamic Voting achieves comparable accuracies employing significantly fewer reasoning paths. Notably, one of our Dynamic Voting strategies outperforms Self-consistency using only 24.7% of the number of paths on the LetterConcat task in the few-shot setting. Furthermore, Dynamic Voting showcases strong robustness in threshold selection. It also demonstrates excellent generalizability when combined with other voting techniques, different models, and diverse prompts. | Mingfeng Xue, Dayiheng Liu, Wenqiang Lei, Xingzhang Ren, Baosong Yang, Jun Xie, Yidan Zhang, Dezhong Peng, Jiancheng Lv |  |
| 337 |  |  [On Surgical Fine-tuning for Language Encoders](https://doi.org/10.18653/v1/2023.findings-emnlp.204) |  | 0 | Fine-tuning all the layers of a pre-trained neural language encoder (either using all the parameters or using parameter-efficient methods) is often the de-facto way of adapting it to a new task. We show evidence that for different downstream language tasks, fine-tuning only a subset of layers is sufficient to obtain performance that is close to and often better than fine-tuning all the layers in the language encoder. We propose an efficient metric based on the diagonal of the Fisher information matrix (FIM score), to select the candidate layers for selective fine-tuning. We show, empirically on GLUE and SuperGLUE tasks and across distinct language encoders, that this metric can effectively select layers leading to a strong downstream performance. Our work highlights that task-specific information corresponding to a given downstream task is often localized within a few layers, and tuning only those is sufficient for strong performance. Additionally, we demonstrate the robustness of the FIM score to rank layers in a manner that remains constant during the optimization process. | Abhilasha Lodha, Gayatri Belapurkar, Saloni Chalkapurkar, Yuanming Tao, Reshmi Ghosh, Samyadeep Basu, Dmitrii Petrov, Soundararajan Srinivasan |  |
| 338 |  |  [AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.205) |  | 0 | Recent large language models (LLMs) are promising for making decisions in grounded environments. However, LLMs frequently fail in complex decision-making tasks due to the misalignment between the pre-trained knowledge in LLMs and the actual rules in the environment. Existing methods require either costly gradient computation or lengthy in-context demonstrations. In this paper, we propose AutoPlan, an approach to guide LLM-based agents to accomplish interactive decision-making tasks. AutoPlan augments the LLM prompt with a task-solving plan and optimizes it through iterative experience collection and reflection. Our experiments show that AutoPlan, though using no in-context demonstrations, achieves success rates on par with the baselines using human-written demonstrations on ALFWorld and even outperforms them by 8% on HotpotQA. The code is available at https://github.com/owaski/AutoPlan. | Siqi Ouyang, Lei Li |  |
| 339 |  |  [Measuring Faithful and Plausible Visual Grounding in VQA](https://doi.org/10.18653/v1/2023.findings-emnlp.206) |  | 0 | Metrics for Visual Grounding (VG) in Visual Question Answering (VQA) systems primarily aim to measure a system’s reliance on relevant parts of the image when inferring an answer to the given question. Lack of VG has been a common problem among state-of-the-art VQA systems and can manifest in over-reliance on irrelevant image parts or a disregard for the visual modality entirely. Although inference capabilities of VQA models are often illustrated by a few qualitative illustrations, most systems are not quantitatively assessed for their VG properties. We believe, an easily calculated criterion for meaningfully measuring a system’s VG can help remedy this shortcoming, as well as add another valuable dimension to model evaluations and analysis. To this end, we propose a new VG metric that captures if a model a) identifies question-relevant objects in the scene, and b) actually relies on the information contained in the relevant objects when producing its answer, i.e., if its visual grounding is both “faithful” and “plausible”. Our metric, called Faithful & Plausible Visual Grounding (FPVG), is straightforward to determine for most VQA model designs. We give a detailed description of FPVG and evaluate several reference systems spanning various VQA architectures. Code to support the metric calculations on the GQA data set is available on GitHub. | Daniel Reich, Felix Putze, Tanja Schultz |  |
| 340 |  |  [Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.207) |  | 0 | Large language models (LLMs) enable zero-shot approaches in open-domain question answering (ODQA), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection (DAS) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training. | Sukmin Cho, Jeongyeon Seo, Soyeong Jeong, Jong C. Park |  |
| 341 |  |  [Can you Summarize my learnings? Towards Perspective-based Educational Dialogue Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.208) |  | 0 | The steady increase in the utilization of Virtual Tutors (VT) over recent years has allowed for a more efficient, personalized, and interactive AI-based learning experiences. A vital aspect in these educational chatbots is summarizing the conversations between the VT and the students, as it is critical in consolidating learning points and monitoring progress. However, the approach to summarization should be tailored according to the perspective. Summarization from the VTs perspective should emphasize on its teaching efficiency and potential improvements. Conversely, student-oriented summaries should distill learning points, track progress, and suggest scope for improvements. Based on this hypothesis, in this work, we propose a new task of Multi-modal Perspective based Dialogue Summarization (MM-PerSumm), demonstrated in an educational setting. Towards this aim, we introduce a novel dataset, CIMA-Summ that summarizes educational dialogues from three unique perspectives: the Student, the Tutor, and a Generic viewpoint. In addition, we propose an Image and Perspective-guided Dialogue Summarization (IP-Summ) model which is a Seq2Seq language model incorporating (i) multi-modal learning from images and (ii) a perspective-based encoder that constructs a dialogue graph capturing the intentions and actions of both the VT and the student, enabling the summarization of a dialogue from diverse perspectives. Lastly, we conduct detailed analyses of our model’s performance, highlighting the aspects that could lead to optimal modeling of IP-Summ. | Raghav Jain, Tulika Saha, Jhagrut Lalwani, Sriparna Saha |  |
| 342 |  |  [Adaptive Textual Label Noise Learning based on Pre-trained Models](https://doi.org/10.18653/v1/2023.findings-emnlp.209) |  | 0 | The label noise in real-world scenarios is unpredictable and can even be a mixture of different types of noise. To meet this challenge, we develop an adaptive textual label noise learning framework based on pre-trained models, which consists of an adaptive warm-up stage and a hybrid training stage. Specifically, an early stopping method, relying solely on the training set, is designed to dynamically terminate the warm-up process based on the model’s fit level to different noise scenarios. The hybrid training stage incorporates several generalization strategies to gradually correct mislabeled instances, thereby making better use of noisy data. Experiments on multiple datasets demonstrate that our approach performs comparably or even surpasses the state-of-the-art methods in various noise scenarios, including scenarios with the mixture of multiple types of noise. | Shaohuan Cheng, Wenyu Chen, Mingsheng Fu, Xuanting Xie, Hong Qu |  |
| 343 |  |  [Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples](https://doi.org/10.18653/v1/2023.findings-emnlp.210) |  | 0 | Pretrained language models (PLMs), especially large language models (LLMs) demonstrate impressive capabilities in open-ended text generation. While our statistical results show that LLMs often suffer from over-concentrated information, where the generated texts overly focus on the given prompt and fail to provide sufficient background and detailed information as humans do. To address this issue, we propose a dynamic knowledge-guided informative open-ended text generation approach, that utilizes a knowledge graph to help the model generate more contextually related entities and detailed facts. Specifically, we first employ a local knowledge filter to extract relevant knowledge from the comprehensive knowledge graph for a given topic sentence. Then we introduce a dynamic knowledge selector to predict the entity to be mentioned in the subsequent sentence. Finally, we utilize a knowledge-enhanced text generator to produce a more informative output. To evaluate the effectiveness of our approach, we evaluate the proposed approach in two scenarios: fine-tuning for small PLMs and prompt tuning for LLMs. Experimental results show that our approach could generate more informative texts than baselines. | Zixuan Ren, Yang Zhao, Chengqing Zong |  |
| 344 |  |  [Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.211) |  | 0 | Conventional approaches to relation extraction can only recognize predefined relation types. In the real world, new or out-of-scope relation types may keep challenging the deployed models. In this paper, we formalize such a challenging problem as Novel Relation Detection (NRD), which aims to discover potential new relation types based on training samples of known relations. To this end, we construct two NRD datasets and exhaustively investigate a variety of out-of-scope detection methods. We further propose an effective NRD method that utilizes multi-strategy self-supervised learning to handle the problem of shallow semantic similarity in the NRD task. Experimental results demonstrate the effectiveness of our method, which significantly outperforms previous state-of-the-art methods on both datasets. | Qingbin Liu, Yin Kung, Yanchao Hao, Dianbo Sui, Siyuan Cheng, Xi Chen, Ningyu Zhang, Jiaoyan Chen |  |
| 345 |  |  [Ask Language Model to Clean Your Noisy Translation Data](https://doi.org/10.18653/v1/2023.findings-emnlp.212) |  | 0 | TTransformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise in the target sentences while preserving the semantic integrity of the original sentences. Our human and GPT-4 evaluations also lead to a consistent conclusion that LLM performs well on this task. Lastly, experiments on C-MTNT showcased its effectiveness in evaluating the robustness of NMT models, highlighting the potential of advanced language models for data cleaning and emphasizing C-MTNT as a valuable resource. | Quinten Bolding, Baohao Liao, Brandon James Denis, Jun Luo, Christof Monz |  |
| 346 |  |  [Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users](https://doi.org/10.18653/v1/2023.findings-emnlp.213) |  | 0 | While most task-oriented dialogues assume conversations between the agent and one user at a time, dialogue systems are increasingly expected to communicate with multiple users simultaneously who make decisions collaboratively. To facilitate development of such systems, we release the Multi-User MultiWOZ dataset: task-oriented dialogues among two users and one agent. To collect this dataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat between two users that is semantically and pragmatically consistent with the original user utterance, thus resulting in the same dialogue state and system response. These dialogues reflect interesting dynamics of collaborative decision-making in task-oriented scenarios, e.g., social chatter and deliberation. Supported by this data, we propose the novel task of multi-user contextual query rewriting: to rewrite a task-oriented chat between two users as a concise task-oriented query that retains only task-relevant information and that is directly consumable by the dialogue system. We demonstrate that in multi-user dialogues, using predicted rewrites substantially improves dialogue state tracking without modifying existing dialogue systems that are trained for single-user dialogues. Further, this method surpasses training a medium-sized model directly on multi-user dialogues and generalizes to unseen domains. | Yohan Jo, Xinyan Zhao, Arijit Biswas, Nikoletta Basiou, Vincent Auvray, Nikolaos Malandrakis, Angeliki Metallinou, Alexandros Potamianos |  |
| 347 |  |  [Extractive Summarization via ChatGPT for Faithful Summary Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.214) |  | 0 | Extractive summarization is a crucial task in natural language processing that aims to condense long documents into shorter versions by directly extracting sentences. The recent introduction of large language models has attracted significant interest in the NLP community due to its remarkable performance on a wide range of downstream tasks. This paper first presents a thorough evaluation of ChatGPT’s performance on extractive summarization and compares it with traditional fine-tuning methods on various benchmark datasets. Our experimental analysis reveals that ChatGPT exhibits inferior extractive summarization performance in terms of ROUGE scores compared to existing supervised systems, while achieving higher performance based on LLM-based evaluation metrics. In addition, we explore the effectiveness of in-context learning and chain-of-thought reasoning for enhancing its performance. Furthermore, we find that applying an extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness. These observations highlight potential directions for enhancing ChatGPT’s capabilities in faithful summarization using two-stage approaches. | Haopeng Zhang, Xiao Liu, Jiawei Zhang |  |
| 348 |  |  [MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization](https://doi.org/10.18653/v1/2023.findings-emnlp.215) |  | 0 | Prompt engineering, as an efficient and effective way to leverage Large Language Models (LLM), has drawn a lot of attention from the research community. The existing research primarily emphasizes the importance of adapting prompts to specific tasks, rather than specific LLMs. However, a good prompt is not solely defined by its wording, but also binds to the nature of the LLM in question. In this work, we first quantitatively demonstrate that different prompts should be adapted to different LLMs to enhance their capabilities across various downstream tasks in NLP. Then we novelly propose a model-adaptive prompt optimizer (MAPO) method that optimizes the original prompts for each specific LLM in downstream tasks. Extensive experiments indicate that the proposed method can effectively refine prompts for an LLM, leading to significant improvements over various downstream tasks. | Yuyan Chen, Zhihao Wen, Ge Fan, Zhengyu Chen, Wei Wu, Dayiheng Liu, Zhixu Li, Bang Liu, Yanghua Xiao |  |
| 349 |  |  [PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.216) |  | 0 | Recent advances in large language models (LLMs), such as ChatGPT, have showcased remarkable zero-shot performance across various NLP tasks. However, the potential of LLMs in personality detection, which involves identifying an individual’s personality from their written texts, remains largely unexplored. Drawing inspiration from Psychological Questionnaires, which are carefully designed by psychologists to evaluate individual personality traits through a series of targeted items, we argue that these items can be regarded as a collection of well-structured chain-of-thought (CoT) processes. By incorporating these processes, LLMs can enhance their capabilities to make more reasonable inferences on personality from textual input. In light of this, we propose a novel personality detection method, called PsyCoT, which mimics the way individuals complete psychological questionnaires in a multi-turn dialogue manner. In particular, we employ a LLM as an AI assistant with a specialization in text analysis. We prompt the assistant to rate individual items at each turn and leverage the historical rating results to derive a conclusive personality preference. Our experiments demonstrate that PsyCoT significantly improves the performance and robustness of GPT-3.5 in personality detection, achieving an average F1 score improvement of 4.23/10.63 points on two benchmark datasets compared to the standard prompting method. Our code is available at https://github.com/TaoYang225/PsyCoT. | Tao Yang, Tianyuan Shi, Fanqi Wan, Xiaojun Quan, Qifan Wang, Bingzhe Wu, Jiaxiang Wu |  |
| 350 |  |  [Harnessing the power of LLMs: Evaluating human-AI text co-creation through the lens of news headline generation](https://doi.org/10.18653/v1/2023.findings-emnlp.217) |  | 0 | To explore how humans can best leverage LLMs for writing and how interacting with these models affects feelings of ownership and trust in the writing process, we compared common human-AI interaction types (e.g., guiding system, selecting from system outputs, post-editing outputs) in the context of LLM-assisted news headline generation. While LLMs alone can generate satisfactory news headlines, on average, human control is needed to fix undesirable model outputs. Of the interaction methods, guiding and selecting model output added the most benefit with the lowest cost (in time and effort). Further, AI assistance did not harm participants’ perception of control compared to freeform editing. | Zijian Ding, Alison SmithRenner, Wenjuan Zhang, Joel R. Tetreault, Alejandro Jaimes |  |
| 351 |  |  [NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.218) |  | 0 | Recognizing entities in texts is a central need in many information-seeking scenarios, and indeed, Named Entity Recognition (NER) is arguably one of the most successful examples of a widely adopted NLP task and corresponding NLP technology. Recent advances in large language models (LLMs) appear to provide effective solutions (also) for NER tasks that were traditionally handled with dedicated models, often matching or surpassing the abilities of the dedicated models. Should NER be considered a solved problem? We argue to the contrary: the capabilities provided by LLMs are not the end of NER research, but rather an exciting beginning. They allow taking NER to the next level, tackling increasingly more useful, and increasingly more challenging, variants. We present three variants of the NER task, together with a dataset to support them. The first is a move towards more fine-grained—and intersectional—entity types. The second is a move towards zero-shot recognition and extraction of these fine-grained types based on entity-type labels. The third, and most challenging, is the move from the recognition setup to a novel retrieval setup, where the query is a zero-shot entity type, and the expected result is all the sentences from a large, pre-indexed corpus that contain entities of these types, and their corresponding spans. We show that all of these are far from being solved. We provide a large, silver-annotated corpus of 4 million paragraphs covering 500 entity types, to facilitate research towards all of these three goals. | Uri Katz, Matan Vetzler, Amir David Nissan Cohen, Yoav Goldberg |  |
| 352 |  |  [SWEET - Weakly Supervised Person Name Extraction for Fighting Human Trafficking](https://doi.org/10.18653/v1/2023.findings-emnlp.219) |  | 0 | In this work, we propose a weak supervision pipeline SWEET: Supervise Weakly for Entity Extraction to fight Trafficking for extracting person names from noisy escort advertisements. Our method combines the simplicity of rule-matching (through antirules, i.e., negated rules) and the generalizability of large language models fine-tuned on benchmark, domain-specific and synthetic datasets, treating them as weak labels. One of the major challenges in this domain is limited labeled data. SWEET addresses this by obtaining multiple weak labels through labeling functions and effectively aggregating them. SWEET outperforms the previous supervised SOTA method for this task by 9% F1 score on domain data and better generalizes to common benchmark datasets. Furthermore, we also release HTGEN, a synthetically generated dataset of escort advertisements (built using ChatGPT) to facilitate further research within the community. | Javin Liu, Hao Yu, Vidya Sujaya, Pratheeksha Nair, Kellin Pelrine, Reihaneh Rabbany |  |
| 353 |  |  [Watermarking LLMs with Weight Quantization](https://doi.org/10.18653/v1/2023.findings-emnlp.220) |  | 0 | Abuse of large language models reveals high risks as large language models are being deployed at an astonishing speed. It is important to protect the model weights to avoid malicious usage that violates licenses of open-source large language models. This paper proposes a novel watermarking strategy that plants watermarks in the quantization process of large language models without pre-defined triggers during inference. The watermark works when the model is used in the fp32 mode and remains hidden when the model is quantized to int8, in this way, the users can only inference the model without further supervised fine-tuning of the model. We successfully plant the watermark into open-source large language model weights including GPT-Neo and LLaMA. We hope our proposed method can provide a potential direction for protecting model weights in the era of large language model applications. | Linyang Li, Botian Jiang, Pengyu Wang, Ke Ren, Hang Yan, Xipeng Qiu |  |
| 354 |  |  [Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.221) |  | 0 | Spatial reasoning over text is challenging as the models not only need to extract the direct spatial information from the text but also reason over those and infer implicit spatial relations. Recent studies highlight the struggles even large language models encounter when it comes to performing spatial reasoning over text. In this paper, we explore the potential benefits of disentangling the processes of information extraction and reasoning in models to address this challenge. To explore this, we design various models that disentangle extraction and reasoning(either symbolic or neural) and compare them with state-of-the-art(SOTA) baselines with no explicit design for these parts. Our experimental results consistently demonstrate the efficacy of disentangling, showcasing its ability to enhance models’ generalizability within realistic data domains. | Roshanak Mirzaee, Parisa Kordjamshidi |  |
| 355 |  |  [PsyAttention: Psychological Attention Model for Personality Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.222) |  | 0 | Work on personality detection has tended to incorporate psychological features from different personality models, such as BigFive and MBTI. There are more than 900 psychological features, each of which is helpful for personality detection. However, when used in combination, the application of different calculation standards among these features may result in interference between features calculated using distinct systems, thereby introducing noise and reducing performance. This paper adapts different psychological models in the proposed PsyAttention for personality detection, which can effectively encode psychological features, reducing their number by 85%. In experiments on the BigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and 86.30%, respectively, outperforming state-of-the-art methods, indicating that it is effective at encoding psychological features. | Baohua Zhang, Yongyi Huang, Wenyao Cui, Huaping Zhang, Jianyun Shang |  |
| 356 |  |  [RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training](https://doi.org/10.18653/v1/2023.findings-emnlp.223) |  | 0 | Fine-tuning pre-trained language models (LMs) has become the de facto standard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to robustness issues, such as adversarial robustness and model calibration. Several perspectives of robustness for LMs have been studied independently, but lacking a unified consideration in multiple perspectives. In this paper, we propose Robustifying LMs via Adversarial perturbation with Selective Training (RoAST), a simple yet effective fine-tuning technique to enhance the multi-perspective robustness of LMs in a unified way. RoAST effectively incorporates two important sources for the model robustness, robustness on the perturbed inputs and generalizable knowledge in pre-trained LMs. To be specific, RoAST introduces adversarial perturbation during fine-tuning while the model parameters are selectively updated upon their relative importance to minimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by incorporating four representative perspectives of model robustness, we demonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning methods on six different types of LMs, which indicates its usefulness in practice. | Jaehyung Kim, Yuning Mao, Rui Hou, Hanchao Yu, Davis Liang, Pascale Fung, Qifan Wang, Fuli Feng, Lifu Huang, Madian Khabsa |  |
| 357 |  |  [The Law and NLP: Bridging Disciplinary Disconnects](https://doi.org/10.18653/v1/2023.findings-emnlp.224) |  | 0 | Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored. | Robert Mahari, Dominik Stammbach, Elliott Ash, Alex Pentland |  |
| 358 |  |  [Symbolization, Prompt, and Classification: A Framework for Implicit Speaker Identification in Novels](https://doi.org/10.18653/v1/2023.findings-emnlp.225) |  | 0 | Speaker identification in novel dialogues can be widely applied to various downstream tasks, such as producing multi-speaker audiobooks and converting novels into scripts. However, existing state-of-the-art methods are limited to handling explicit narrative patterns like “Tom said, '...'", unable to thoroughly understand long-range contexts and to deal with complex cases. To this end, we propose a framework named SPC, which identifies implicit speakers in novels via symbolization, prompt, and classification. First, SPC symbolizes the mentions of candidate speakers to construct a unified label set. Then, by inserting a prompt we re-formulate speaker identification as a classification task to minimize the gap between the training objectives of speaker identification and the pre-training task. Two auxiliary tasks are also introduced in SPC to enhance long-range context understanding. Experimental results show that SPC outperforms previous methods by a large margin of 4.8% accuracy on the web novel collection, which reduces 47% of speaker identification errors, and also outperforms the emerging ChatGPT. In addition, SPC is more accurate in implicit speaker identification cases that require long-range context semantic understanding. | Yue Chen, TianWei He, Hongbin Zhou, JiaChen Gu, Heng Lu, ZhenHua Ling |  |
| 359 |  |  [Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.226) |  | 0 | Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot’s visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user’s idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user’s language and action plans, to assist future inferences and personalize them to the user’s language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project’s website: https://helper-agent-llm.github.io. | Gabriel Sarch, Yue Wu, Michael J. Tarr, Katerina Fragkiadaki |  |
| 360 |  |  [ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought](https://doi.org/10.18653/v1/2023.findings-emnlp.227) |  | 0 | Recently Large Language Models (LLMs) have been proven to have strong abilities in various domains and tasks. We study the problem of prompt designing in the text-to-SQL task and attempt to improve the LLMs’ reasoning ability when generating SQL queries. Besides the trivial few-shot in-context learning setting, we design our chain-of-thought (CoT) prompt with a similar method to schema linking. We provide a method named ACT-SQL to automatically generate auto-CoT exemplars and thus the whole process doesn’t need manual labeling. Our approach is cost-saving since we only use the LLMs’ API call once when generating one SQL query. Furthermore, we extend our in-context learning method to the multi-turn text-to-SQL task. The experiment results show that the LLMs’ performance can benefit from our ACT-SQL approach. Our approach achieves SOTA performance on the Spider dev set among existing in-context learning approaches. | Hanchong Zhang, Ruisheng Cao, Lu Chen, Hongshen Xu, Kai Yu |  |
| 361 |  |  [Manifold-Preserving Transformers are Effective for Short-Long Range Encoding](https://doi.org/10.18653/v1/2023.findings-emnlp.228) |  | 0 | Multi-head self-attention-based Transformers have shown promise in different learning tasks. Albeit these models exhibit significant improvement in understanding short-term and long-term contexts from sequences, encoders of Transformers and their variants fail to preserve layer-wise contextual information. Transformers usually project tokens onto sparse manifolds and fail to preserve mathematical equivalence among the token representations. In this work, we propose TransJect, an encoder model that guarantees a theoretical bound for layer-wise distance preservation between a pair of tokens. We propose a simple alternative to dot-product attention to ensure Lipschitz continuity. This allows TransJect to learn injective mappings to transform token representations to different manifolds with similar topology and preserve Euclidean distance between every pair of tokens in subsequent layers. Evaluations across multiple benchmark short- and long-sequence classification tasks show maximum improvements of 6.8% and 5.9%, respectively, over the variants of Transformers. Additionally, TransJect displays 79% better performance than Transformer on the language modeling task. We further highlight the shortcomings of multi-head self-attention from the statistical physics viewpoint. Although multi-head self-attention was incepted to learn different abstraction levels within the networks, our empirical analyses suggest that different attention heads learn randomly and unorderly. In contrast, TransJect adapts a mixture of experts for regularization; these experts are more orderly and balanced and learn different sparse representations from the input sequences. TransJect exhibits very low entropy and can be efficiently scaled to larger depths. | Ayan Sengupta, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 362 |  |  [ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.229) |  | 0 | We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts Large Language Models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pretrained language models. | Martin Vejvar, Yasutaka Fujimoto |  |
| 363 |  |  [Detecting Syntactic Change with Pre-trained Transformer Models](https://doi.org/10.18653/v1/2023.findings-emnlp.230) |  | 0 | We investigate the ability of Transformer-based language models to find syntactic differences between the English of the early 1800s and that of the late 1900s. First, we show that a fine-tuned BERT model can distinguish between text from these two periods using syntactic information only; to show this, we employ a strategy to hide semantic information from the text. Second, we make further use of fine-tuned BERT models to identify specific instances of syntactic change and specific words for which a new part of speech was introduced. To do this, we employ an automatic part-of-speech (POS) tagger and use it to train corpora-specific taggers based only on BERT representations pretrained on different corpora. Notably, our methods of identifying specific candidates for syntactic change avoid using any automatic POS tagger on old text, where its performance may be unreliable; instead, our methods only use untagged old text together with tagged modern text. We examine samples and distributional properties of the model output to validate automatically identified cases of syntactic change. Finally, we use our techniques to confirm the historical rise of the progressive construction, a known example of syntactic change. | Liwen Hou, David Smith |  |
| 364 |  |  [A Word Sense Distribution-based approach for Semantic Change Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.231) |  | 0 | Semantic Change Detection of words is an important task for various NLP applications that must make time-sensitive predictions. Some words are used over time in novel ways to express new meanings, and these new meanings establish themselves as novel senses of existing words. On the other hand, Word Sense Disambiguation (WSD) methods associate ambiguous words with sense ids, depending on the context in which they occur. Given this relationship between WSD and SCD, we explore the possibility of predicting whether a target word has its meaning changed between two corpora collected at different time steps, by comparing the distributions of senses of that word in each corpora. For this purpose, we use pretrained static sense embeddings to automatically annotate each occurrence of the target word in a corpus with a sense id. Next, we compute the distribution of sense ids of a target word in a given corpus. Finally, we use different divergence or distance measures to quantify the semantic change of the target word across the two given corpora. Our experimental results on SemEval 2020 Task 1 dataset show that word sense distributions can be accurately used to predict semantic changes of words in English, German, Swedish and Latin. | Xiaohang Tang, Yi Zhou, Taichi Aida, Procheta Sen, Danushka Bollegala |  |
| 365 |  |  [Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.232) |  | 0 | Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly. As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage. However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs. To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG. Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks. Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task. Our code and data are publicly available at https://github.com/HKUST-KnowComp/GOLD. | Zheye Deng, Weiqi Wang, Zhaowei Wang, Xin Liu, Yangqiu Song |  |
| 366 |  |  [Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.233) |  | 0 | Conversational Recommendation System (CRS) is a rapidly growing research area that has gained significant attention alongside advancements in language modelling techniques. However, the current state of conversational recommendation faces numerous challenges due to its relative novelty and limited existing contributions. In this study, we delve into benchmark datasets for developing CRS models and address potential biases arising from the feedback loop inherent in multi-turn interactions, including selection bias and multiple popularity bias variants. Drawing inspiration from the success of generative data via using language models and data augmentation techniques, we present two novel strategies, ‘Once-Aug’ and ‘PopNudge’, to enhance model performance while mitigating biases. Through extensive experiments on ReDial and TG-ReDial benchmark datasets, we show a consistent improvement of CRS techniques with our data augmentation approaches and offer additional insights on addressing multiple newly formulated biases. | Xi Wang, Hossein A. Rahmani, Jiqun Liu, Emine Yilmaz |  |
| 367 |  |  [Exploring Graph Pre-training for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.234) |  | 0 | Existing studies tend to extract the sentiment elements in a generative manner in order to avoid complex modeling. Despite their effectiveness, they ignore importance of the relationships between sentiment elements that could be crucial, making the large pre-trained generative models sub-optimal for modeling sentiment knowledge. Therefore, we introduce two pre-training paradigms to improve the generation model by exploring graph pre-training that targeting to strengthen the model in capturing the elements’ relationships. Specifically, We first employ an Element-level Graph Pre-training paradigm, which is designed to improve the structure awareness of the generative model. Then, we design a Task Decomposition Pre-training paradigm to make the generative model generalizable and robust against various irregular sentiment quadruples. Extensive experiments show the superiority of our proposed method, validate the correctness of our motivation. | Xiaoyi Bao, Zhongqing Wang, Guodong Zhou |  |
| 368 |  |  [DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding](https://doi.org/10.18653/v1/2023.findings-emnlp.235) |  | 0 | Temporal Language Grounding seeks to localize video moments that semantically correspond to a natural language query. Recent advances employ the attention mechanism to learn the relations between video moments and the text query. However, naive attention might not be able to appropriately capture such relations, resulting in ineffective distributions where target video moments are difficult to separate from the remaining ones. To resolve the issue, we propose an energy-based model framework to explicitly learn moment-query distributions. Moreover, we propose DemaFormer, a novel Transformer-based architecture that utilizes exponential moving average with a learnable damping factor to effectively encode moment-query inputs. Comprehensive experiments on four public temporal language grounding datasets showcase the superiority of our methods over the state-of-the-art baselines. | Thong Nguyen, Xiaobao Wu, Xinshuai Dong, CongDuy Nguyen, SeeKiong Ng, Anh Tuan Luu |  |
| 369 |  |  [Test-time Augmentation for Factual Probing](https://doi.org/10.18653/v1/2023.findings-emnlp.236) |  | 0 | Factual probing is a method that uses prompts to test if a language model “knows” certain world knowledge facts. A problem in factual probing is that small changes to the prompt can lead to large changes in model output. Previous work aimed to alleviate this problem by optimizing prompts via text mining or fine-tuning. However, such approaches are relation-specific and do not generalize to unseen relation types. Here, we propose to use test-time augmentation (TTA) as a relation-agnostic method for reducing sensitivity to prompt variations by automatically augmenting and ensembling prompts at test time. Experiments show improved model calibration, i.e., with TTA, model confidence better reflects prediction accuracy. Improvements in prediction accuracy are observed for some models, but for other models, TTA leads to degradation. Error analysis identifies the difficulty of producing high-quality prompt variations as the main challenge for TTA. | Go Kamoda, Benjamin Heinzerling, Keisuke Sakaguchi, Kentaro Inui |  |
| 370 |  |  [Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.237) |  | 0 | In this paper, we investigate automatic detection of subtle semantic shifts between social communities of different political convictions in Dutch and English. We perform a methodological study comparing methods using static and contextualized language models. We investigate the impact of specializing contextualized models through fine-tuning on target corpora, word sense disambiguation and sentiment. We furthermore propose a new approach using masked token prediction, that relies on behavioral information, specifically the most probable substitutions, instead of geometrical comparison of representations. Our results show that methods using static models and our masked token prediction method can detect differences in connotation of politically loaded terms, whereas methods that rely on measuring the distance between contextualized representations are not providing clear signals, even in synthetic scenarios of extreme shifts. | Sanne Hoeken, Özge Alaçam, Antske Fokkens, Pia Sommerauer |  |
| 371 |  |  [Disfluent Cues for Enhanced Speech Understanding in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.238) |  | 0 | In computational linguistics, the common practice is to “clean” disfluent content from spontaneous speech. However, we hypothesize that these disfluencies might serve as more than mere noise, potentially acting as informative cues. We use a range of pre-trained models for a reading comprehension task involving disfluent queries, specifically featuring different types of speech repairs. The findings indicate that certain disfluencies can indeed improve model performance, particularly those stemming from context-based adjustments. However, large-scale language models struggle to handle repairs involving decision-making or the correction of lexical or syntactic errors, suggesting a crucial area for potential improvement. This paper thus highlights the importance of a nuanced approach to disfluencies, advocating for their potential utility in enhancing model performance rather than their removal. | Morteza Rohanian, Farhad Nooralahzadeh, Omid Rohanian, David A. Clifton, Michael Krauthammer |  |
| 372 |  |  [Watermarking PLMs on Classification Tasks by Combining Contrastive Learning with Weight Perturbation](https://doi.org/10.18653/v1/2023.findings-emnlp.239) |  | 0 | Large pre-trained language models (PLMs) have achieved remarkable success, making them highly valuable intellectual property due to their expensive training costs. Consequently, model watermarking, a method developed to protect the intellectual property of neural models, has emerged as a crucial yet underexplored technique. The problem of watermarking PLMs has remained unsolved since the parameters of PLMs will be updated when fine-tuned on downstream datasets, and then embedded watermarks could be removed easily due to the catastrophic forgetting phenomenon. This study investigates the feasibility of watermarking PLMs by embedding backdoors that can be triggered by specific inputs. We employ contrastive learning during the watermarking phase, allowing the representations of specific inputs to be isolated from others and mapped to a particular label after fine-tuning. Moreover, we demonstrate that by combining weight perturbation with the proposed method, watermarks can be embedded in a flatter region of the loss landscape, thereby increasing their robustness to watermark removal. Extensive experiments on multiple datasets demonstrate that the embedded watermarks can be robustly extracted without any knowledge about downstream tasks, and with a high success rate. | Chenxi Gu, Xiaoqing Zheng, Jianhan Xu, Muling Wu, Cenyuan Zhang, Chengsong Huang, Hua Cai, Xuanjing Huang |  |
| 373 |  |  [BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer](https://doi.org/10.18653/v1/2023.findings-emnlp.240) |  | 0 | Lemmatization holds significance in both natural language processing (NLP) and linguistics, as it effectively decreases data density and aids in comprehending contextual meaning. However, due to the highly inflected nature and morphological richness, lemmatization in Bangla text poses a complex challenge. In this study, we propose linguistic rules for lemmatization and utilize a dictionary along with the rules to design a lemmatizer specifically for Bangla. Our system aims to lemmatize words based on their parts of speech class within a given sentence. Unlike previous rule-based approaches, we analyzed the suffix marker occurrence according to the morpho-syntactic values and then utilized sequences of suffix markers instead of entire suffixes. To develop our rules, we analyze a large corpus of Bangla text from various domains, sources, and time periods to observe the word formation of inflected words. The lemmatizer achieves an accuracy of 96.36% when tested against a manually annotated test dataset by trained linguists and demonstrates competitive performance on three previously published Bangla lemmatization datasets. We are making the code and datasets publicly available at https://github.com/eblict-gigatech/BanLemma in order to contribute to the further advancement of Bangla NLP. | Sadia Afrin, Md. Shahad Mahmud Chowdhury, Md. Ekramul Islam, Faisal Ahamed Khan, Labib Imam Chowdhury, Md. Motahar Mahtab, Nazifa Nuha Chowdhury, Massud Forkan, Neelima Kundu, Hakim Arif, Mohammad Mamun Or Rashid, Mohammad Ruhul Amin, Nabeel Mohammed |  |
| 374 |  |  [Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters](https://doi.org/10.18653/v1/2023.findings-emnlp.241) |  | 0 | The advancement of Large Language Models (LLMs) has led to their widespread use across a broad spectrum of tasks, including decision-making. Prior studies have compared the decision-making abilities of LLMs with those of humans from a psychological perspective. However, these studies have not always properly accounted for the sensitivity of LLMs’ behavior to hyperparameters and variations in the prompt. In this study, we examine LLMs’ performance on the Horizon decision-making task studied by Binz and Schulz (2023), analyzing how LLMs respond to variations in prompts and hyperparameters. By experimenting on three OpenAI language models possessing different capabilities, we observe that the decision-making abilities fluctuate based on the input prompts and temperature settings. Contrary to previous findings, language models display a human-like exploration–exploitation tradeoff after simple adjustments to the prompt. | Manikanta Loya, Divya Sinha, Richard Futrell |  |
| 375 |  |  [Search Augmented Instruction Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.242) |  | 0 | Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing (instruction, grounding information, response) triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking. | Hongyin Luo, Tianhua Zhang, YungSung Chuang, Yuan Gong, Yoon Kim, Xixin Wu, Helen Meng, James R. Glass |  |
| 376 |  |  ["Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters](https://doi.org/10.18653/v1/2023.findings-emnlp.243) |  | 0 | Large Language Models (LLMs) have recently emerged as an effective tool to assist individuals in writing various types of content, including professional documents such as recommendation letters. Though bringing convenience, this application also introduces unprecedented fairness concerns. Model-generated reference letters might be directly used by users in professional scenarios. If underlying biases exist in these model-constructed letters, using them without scrutinization could lead to direct societal harms, such as sabotaging application success rates for female applicants. In light of this pressing issue, it is imminent and necessary to comprehensively study fairness issues and associated harms in this real-world use case. In this paper, we critically examine gender biases in LLM-generated reference letters. Drawing inspiration from social science findings, we design evaluation methods to manifest biases through 2 dimensions: (1) biases in language style and (2) biases in lexical content. We further investigate the extent of bias propagation by analyzing the hallucination bias of models, a term that we define to be bias exacerbation in model-hallucinated contents. Through benchmarking evaluation on 2 popular LLMs- ChatGPT and Alpaca, we reveal significant gender biases in LLM-generated recommendation letters. Our findings not only warn against using LLMs for this application without scrutinization, but also illuminate the importance of thoroughly studying hidden biases and harms in LLM-generated professional documents. | Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, KaiWei Chang, Nanyun Peng |  |
| 377 |  |  [TextMixer: Mixing Multiple Inputs for Privacy-Preserving Inference](https://doi.org/10.18653/v1/2023.findings-emnlp.244) |  | 0 | Pre-trained language models (PLMs) are often deployed as cloud services, enabling users to upload textual data and perform inference remotely. However, users’ personal text often contains sensitive information, and sharing such data directly with the service providers can lead to serious privacy leakage. To address this problem, we introduce a novel privacy-preserving inference framework called MixPi , which prevents plaintext leakage during the inference phase. Inspired by k-anonymity, MixPi aims to obfuscate a user’s private input by mixing it with multiple other inputs, thereby confounding potential privacy attackers. To achieve this, our approach involves: (1) proposing a novel encryption module, Privacy Mixer, which encrypts input from three distinct dimensions: mixing, representation, and position. (2) adopting a pre-trained Multi-input Multi-output network to handle mixed representations and obtain multiple predictions. (3) employing a Privacy Demixer to ensure only the user can decrypt the real output among the multiple predictions. Furthermore, we explore different ways to automatically generate synthetic inputs required for mixing. Experimental results on token and sentence classification tasks demonstrate that MixPi greatly surpasses existing privacy-preserving methods in both performance and privacy. | Xin Zhou, Yi Lu, Ruotian Ma, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 378 |  |  [FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4](https://doi.org/10.18653/v1/2023.findings-emnlp.245) |  | 0 | Compositional reasoning across texts has been a long-standing challenge in natural language processing. With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs. Despite their success, the prompts demand significant human effort to discover and validate them. Our work draws attention to the idea of transferring task-specific inductive biases from finetuned models to prompts, as a way of improving GPT-4’s compositional reasoning capabilities. To leverage these inductive biases, we formulate prompt templates to ease the transfer of inductive biases. The experimental results on multi-hop question answering and numerical reasoning over text show that our proposed prompt scheme shows competitive zero-shot and few-shot performances compared to existing prompts on complicated reasoning tasks, highlighting the importance of adopting the validated biases of the previous paradigm. | Jeonghwan Kim, Giwon Hong, SungHyon Myaeng, Joyce Jiyoung Whang |  |
| 379 |  |  [Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.246) |  | 0 | One of the challenges in language teaching is how best to organize rules regarding syntax, semantics, or phonology in a meaningful manner. This not only requires content creators to have pedagogical skills, but also have that language’s deep understanding. While comprehensive materials to develop such curricula are available in English and some broadly spoken languages, for many other languages, teachers need to manually create them in response to their students’ needs. This is challenging because i) it requires that such experts be accessible and have the necessary resources, and ii) describing all the intricacies of a language is time-consuming and prone to omission. In this work, we aim to facilitate this process by automatically discovering and visualizing grammar descriptions. We extract descriptions from a natural text corpus that answer questions about morphosyntax (learning of word order, agreement, case marking, or word formation) and semantics (learning of vocabulary). We apply this method for teaching two Indian languages, Kannada and Marathi, which, unlike English, do not have well-developed resources for second language learning. To assess the perceived utility of the extracted material, we enlist the help of language educators from schools in North America to perform a manual evaluation, who find the materials have potential to be used for their lesson preparation and learner evaluation. | Aditi Chaudhary, Arun Sampath, Ashwin Sheshadri, Antonios Anastasopoulos, Graham Neubig |  |
| 380 |  |  [Allies: Prompting Large Language Model with Beam Search](https://doi.org/10.18653/v1/2023.findings-emnlp.247) |  | 0 | With the advance of large language models (LLMs), the research field of LLM applications becomes more and more popular and the idea of constructing pipelines to accomplish complex tasks by stacking LLM API calls come true. However, this kind of methods face two limitations: narrow information coverage and low fault tolerance. In this work, we propose a novel method called ALLIES. Given an input query, ALLIES leverages LLMs to iteratively generate new queries related to the original query, enabling an iterative reasoning process. By iteratively refining and expanding the scope of the original query, ALLIES captures and utilizes hidden knowledge that may not be directly obtainable through retrieval. We take zero-shot open-domain question answering (ODQA) as an application scene and evaluate ALLIES on the widely-used benchmarks, such as NQ, WebQ and TriviaQA. The experimental results demonstrate that ALLIES significantly outperforms other zero-shot baselines, indicating its effectiveness in tackling those challenges. Our code is available in https://github.com/microsoft/SimXNS/tree/main/ALLIES. | Hao Sun, Xiao Liu, Yeyun Gong, Yan Zhang, Daxin Jiang, Linjun Yang, Nan Duan |  |
| 381 |  |  [Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.248) |  | 0 | Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver’s error messages to revise symbolic formalizations. We demonstrate Logic-LM’s effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical reasoning. | Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang |  |
| 382 |  |  [SiMFy: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.249) |  | 0 | Temporal Knowledge Graph (TKG) reasoning, which focuses on leveraging temporal information to infer future facts in knowledge graphs, plays a vital role in knowledge graph completion. Typically, existing works for this task design graph neural networks and recurrent neural networks to respectively capture the structural and temporal information in KGs. Despite their effectiveness, in our practice, we find that they tend to suffer the issues of low training efficiency and insufficient generalization ability, which can be attributed to the over design of model architectures. To this end, this paper aims to figure out whether the current complex model architectures are necessary for temporal knowledge graph reasoning. As a result, we put forward a simple yet effective approach (termed SiMFy), which simply utilizes multilayer perceptron (MLP) to model the structural dependencies of events and adopts a fixed-frequency strategy to incorporate historical frequency during inference. Extensive experiments on real-world datasets demonstrate that our SiMFy can reach state-of-the-art performance with the following strengths: 1) faster convergence speed and better generalization ability; 2) a much smaller time consumption in the training process; and 3) better ability to capture the structural dependencies of events in KGs. These results provide evidence that the substitution of complex models with simpler counterparts is a feasible strategy. | Zhengtao Liu, Lei Tan, Mengfan Li, Yao Wan, Hai Jin, Xuanhua Shi |  |
| 383 |  |  [Understanding Translationese in Cross-Lingual Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.250) |  | 0 | Given a document in a source language, cross-lingual summarization (CLS) aims at generating a concise summary in a different target language. Unlike monolingual summarization (MS), naturally occurring source-language documents paired with target-language summaries are rare. To collect large-scale CLS data, existing datasets typically involve translation in their creation. However, the translated text is distinguished from the text originally written in that language, i.e., translationese. In this paper, we first confirm that different approaches of constructing CLS datasets will lead to different degrees of translationese. Then we systematically investigate how translationese affects CLS model evaluation and performance when it appears in source documents or target summaries. In detail, we find that (1) the translationese in documents or summaries of test sets might lead to the discrepancy between human judgment and automatic evaluation; (2) the translationese in training sets would harm model performance in real-world applications; (3) though machine-translated documents involve translationese, they are very useful for building CLS systems on low-resource languages under specific training strategies. Lastly, we give suggestions for future CLS research including dataset and model developments. We hope that our work could let researchers notice the phenomenon of translationese in CLS and take it into account in the future. | Jiaan Wang, Fandong Meng, Yunlong Liang, Tingyi Zhang, Jiarong Xu, Zhixu Li, Jie Zhou |  |
| 384 |  |  [The Truth, The Whole Truth, and Nothing but the Truth: A New Benchmark Dataset for Hebrew Text Credibility Assessment](https://doi.org/10.18653/v1/2023.findings-emnlp.251) |  | 0 | In the age of information overload, it is more important than ever to discern fact from fiction. From the internet to traditional media, we are constantly confronted with a deluge of information, much of which comes from politicians and other public figures who wield significant influence. In this paper, we introduce HeTrue: a new, publicly available dataset for evaluating the credibility of statements made by Israeli public figures and politicians. This dataset consists of 1021 statements, manually annotated by Israeli professional journalists, for their credibility status. Using this corpus, we set out to assess whether the credibility of statements can be predicted based on the text alone. To establish a baseline, we compare text-only methods with others using additional data like metadata, context, and evidence. Furthermore, we develop several credibility assessment models, including a feature-based model that utilizes linguistic features, and state-of-the-art transformer-based models with contextualized embeddings from a pre-trained encoder. Empirical results demonstrate improved performance when models integrate statement and context, outperforming those relying on the statement text alone. Our best model, which also integrates evidence, achieves a 48.3 F1 Score, suggesting that HeTrue is a challenging benchmark, calling for further work on this task. | Ben Hagag, Reut Tsarfaty |  |
| 385 |  |  [IndiSocialFT: Multilingual Word Representation for Indian languages in code-mixed environment](https://doi.org/10.18653/v1/2023.findings-emnlp.252) |  | 0 | The increasing number of Indian language users on the internet necessitates the development of Indian language technologies. In response to this demand, our paper presents a generalized representation vector for diverse text characteristics, including native scripts, transliterated text, multilingual, code-mixed, and social media-related attributes. We gather text from both social media and well-formed sources and utilize the FastText model to create the “IndiSocialFT” embedding. Through intrinsic and extrinsic evaluation methods, we compare IndiSocialFT with three popular pretrained embeddings trained over Indian languages. Our findings show that the proposed embedding surpasses the baselines in most cases and languages, demonstrating its suitability for various NLP applications. | Saurabh Kumar, Sanasam Ranbir Singh, Sukumar Nandi |  |
| 386 |  |  [Adaptive Hinge Balance Loss for Document-Level Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.253) |  | 0 | Document-Level Relation Extraction aims at predicting relations between entities from multiple sentences. A common practice is to select multi-label classification thresholds to decide whether a relation exists between an entity pair. However, in the document-level task, most entity pairs do not express any relations, resulting in a highly imbalanced distribution between positive and negative classes. We argue that the imbalance problem affects threshold selection and may lead to incorrect “no-relation” predictions. In this paper, we propose to down-weight the easy negatives by utilizing a distance between the classification threshold and the predicted score of each relation. Our novel Adaptive Hinge Balance Loss measures the difficulty of each relation class with the distance, putting more focus on hard, misclassified relations, i.e. the minority positive relations. Experiment results on Re-DocRED demonstrate the superiority of our approach over other balancing methods. Source codes are available at https://github.com/Jize-W/HingeABL. | Jize Wang, Xinyi Le, Xiaodi Peng, Cailian Chen |  |
| 387 |  |  [Answer-state Recurrent Relational Network (AsRRN) for Constructed Response Assessment and Feedback Grouping](https://doi.org/10.18653/v1/2023.findings-emnlp.254) |  | 0 | STEM educators must trade off the ease of assessing selected response (SR) questions, like multiple choice, with constructed response (CR) questions, where students articulate their own reasoning. Our work addresses a CR type new to NLP but common in college STEM, consisting of multiple questions per context. To relate the context, the questions, the reference responses, and students’ answers, we developed an Answer-state Recurrent Relational Network (AsRRN). In recurrent time-steps, relation vectors are learned for specific dependencies in a computational graph, where the nodes encode the distinct types of text input. AsRRN incorporates contrastive loss for better representation learning, which improves performance and supports student feedback. AsRRN was developed on a new dataset of 6,532 student responses to three, two-part CR questions. AsRRN outperforms classifiers based on LLMs, a previous relational network for CR questions, and few-shot learning with GPT-3.5. Ablation studies show the distinct contributions of AsRRN’s dependency structure, the number of time steps in the recurrence, and the contrastive loss. | Zhaohui Li, Susan Lloyd, Matthew Beckman, Rebecca J. Passonneau |  |
| 388 |  |  [Low-Resource Comparative Opinion Quintuple Extraction by Data Augmentation with Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.255) |  | 0 | Comparative Opinion Quintuple Extraction (COQE) aims to predict comparative opinion quintuples from comparative sentences. These quintuples include subject, object, shareable aspect, comparative opinion, and preference. The existing pipeline-based COQE method fails in error propagation. In addition, the complexity and insufficient amounts of annotated data hinder the performance of COQE models. In this paper, we introduce a novel approach called low-resource comparative opinion quintuple extraction by Data Augmentation with Prompting (DAP). Firstly, we present an end-to-end model architecture better suited to the data augmentation method from triplets to quintuples and can effectively avoid error propagation. Additionally, we introduce a data-centric augmentation approach that leverages the robust generative abilities of ChatGPT and integrates transfer learning techniques. Experimental results over three datasets (Camera, Car, Ele) demonstrate that our approach yields substantial improvements and achieves state-of-the-art results. The source code and data are publicly released at: https://github.com/qtxu-nlp/COQE-DAP. | Qingting Xu, Yu Hong, Fubang Zhao, Kaisong Song, Yangyang Kang, Jiaxiang Chen, Guodong Zhou |  |
| 389 |  |  [A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.256) |  | 0 | Large Language Models (LLMs) have shown their ability to collaborate effectively with humans in real-world scenarios. However, LLMs are apt to generate hallucinations, i.e., makeup incorrect text and unverified information, which can cause significant damage when deployed for mission-critical tasks. In this paper, we propose a self-check approach based on reverse validation to detect factual errors automatically in a zero-resource fashion. To facilitate future studies and assess different methods, we construct a hallucination detection benchmark named PHD, which is generated by ChatGPT and annotated by human annotators. Contrasting previous studies of zero-resource hallucination detection, our method and benchmark concentrate on passage-level detection instead of sentence-level. We empirically evaluate our method and existing zero-resource detection methods on two datasets. The experimental results demonstrate that the proposed method considerably outperforms the baselines while costing fewer tokens and less time. Furthermore, we manually analyze some hallucination cases that LLM failed to capture, revealing the shared limitation of zero-resource methods. | Shiping Yang, Renliang Sun, Xiaojun Wan |  |
| 390 |  |  [Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.257) |  | 0 | We propose Speculative Decoding (SpecDec), for the first time ever, to formally study exploiting the idea of speculative execution to accelerate autoregressive (AR) decoding. Speculative Decoding has two innovations: Spec-Drafter – an independent model specially optimized for efficient and accurate drafting – and Spec-Verification – a reliable method for verifying the drafted tokens efficiently in the decoding paradigm. Experimental results on various seq2seq tasks including machine translation and abstractive summarization show our approach can achieve around 5x speedup for the popular Transformer architectures with comparable generation quality to beam search decoding, refreshing the impression that the draft-then-verify paradigm introduces only 1.4x~2x speedup. In addition to the remarkable speedup, we also demonstrate 3 additional advantages of SpecDec, revealing its practical value for accelerating generative models in real-world applications. Our models and codes are available at https://github.com/hemingkx/SpecDec. | Heming Xia, Tao Ge, Peiyi Wang, SiQing Chen, Furu Wei, Zhifang Sui |  |
| 391 |  |  [APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.258) |  | 0 | Detecting out-of-domain (OOD) intents from user queries is essential for a task-oriented dialogue system. Previous OOD detection studies generally work on the assumption that plenty of labeled IND intents exist. In this paper, we focus on a more practical few-shot OOD setting where there are only a few labeled IND data and massive unlabeled mixed data that may belong to IND or OOD. The new scenario carries two key challenges: learning discriminative representations using limited IND data and leveraging unlabeled mixed data. Therefore, we propose an adaptive prototypical pseudo-labeling(APP) method for few-shot OOD detection, including a prototypical OOD detection framework (ProtoOOD) to facilitate low-resourceOOD detection using limited IND data, and an adaptive pseudo-labeling method to produce high-quality pseudo OOD and IND labels. Extensive experiments and analysis demonstrate the effectiveness of our method for few-shot OOD detection. | Pei Wang, Keqing He, Yutao Mou, Xiaoshuai Song, Yanan Wu, Jingang Wang, Yunsen Xian, Xunliang Cai, Weiran Xu |  |
| 392 |  |  [2INER: Instructive and In-Context Learning on Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.259) |  | 0 | Prompt-based learning has emerged as a powerful technique in natural language processing (NLP) due to its ability to leverage pre-training knowledge for downstream few-shot tasks. In this paper, we propose 2INER, a novel text-to-text framework for Few-Shot Named Entity Recognition (NER) tasks. Our approach employs instruction finetuning based on InstructionNER to enable the model to effectively comprehend and process task-specific instructions, including both main and auxiliary tasks. We also introduce a new auxiliary task, called Type Extracting, to enhance the model’s understanding of entity types in the overall semantic context of a sentence. To facilitate in-context learning, we concatenate examples to the input, enabling the model to learn from additional contextual information. Experimental results on four datasets demonstrate that our approach outperforms existing Few-Shot NER methods and remains competitive with state-of-the-art standard NER algorithms. | Jiasheng Zhang, Xikai Liu, Xinyi Lai, Yan Gao, Shusen Wang, Yao Hu, Yiqing Lin |  |
| 393 |  |  [Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge](https://doi.org/10.18653/v1/2023.findings-emnlp.260) |  | 0 | Emotion Cause Triplet Extraction in Conversations (ECTEC) aims to simultaneously extract emotion utterances, emotion categories, and cause utterances from conversations. However, existing studies mainly decompose the ECTEC task into multiple subtasks and solve them in a pipeline manner. Moreover, since conversations tend to contain many informal and implicit expressions, it often requires external knowledge and reasoning-based inference to accurately identify emotional and causal clues implicitly mentioned in the context, which are ignored by previous work. To address these limitations, in this paper, we propose a commonSense knowledge-enHanced generAtive fRameworK named SHARK, which formulates the ECTEC task as an index generation problem and generates the emotion-cause-category triplets in an end-to-end manner with a sequence-to-sequence model. Furthermore, we propose to incorporate both retrieved and generated commonsense knowledge into the generative model via a dual-view gate mechanism and a graph attention layer. Experimental results show that our SHARK model consistently outperforms several competitive systems on two benchmark datasets. Our source codes are publicly released at https://github.com/NUSTM/SHARK. | Fanfan Wang, Jianfei Yu, Rui Xia |  |
| 394 |  |  [Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.261) |  | 0 | Large Language Models (LLMs) have significantly advanced the field of Natural Language Processing (NLP), but their lack of interpretability has been a major concern. Current methods for interpreting LLMs are post hoc, applied after inference time, and have limitations such as their focus on low-level features and lack of explainability at higher-level text units. In this work, we introduce proto-lm, a prototypical network-based white-box framework that allows LLMs to learn immediately interpretable embeddings during the fine-tuning stage while maintaining competitive performance. Our method’s applicability and interpretability are demonstrated through experiments on a wide range of NLP tasks, and our results indicate a new possibility of creating interpretable models without sacrificing performance. This novel approach to interpretability in LLMs can pave the way for more interpretable models without the need to sacrifice performance. We release our code at https://github.com/yx131/proto-lm. | Sean Xie, Soroush Vosoughi, Saeed Hassanpour |  |
| 395 |  |  [GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence](https://doi.org/10.18653/v1/2023.findings-emnlp.262) |  | 0 | Conditional story generation is significant in human-machine interaction, particularly in producing stories with complex plots. While Large language models (LLMs) perform well on multiple NLP tasks, including story generation, it is challenging to generate stories with both complex and creative plots. Existing methods often rely on detailed prompts to guide LLMs to meet target conditions, which inadvertently restrict the creative potential of the generated stories. We argue that leveraging information from exemplary human-written stories facilitates generating more diverse plotlines. Delving deeper into story details helps build complex and credible plots. In this paper, we propose a retrieval-auGmented stoRy generation framework with a fOrest of eVidEnce (GROVE) to enhance stories’ complexity. We build a retrieval repository for target conditions to produce few-shot examples to prompt LLMs. Additionally, we design an “asking-why” prompting scheme that extracts a forest of evidence, providing compensation for the ambiguities that may occur in the generated story. This iterative process uncovers underlying story backgrounds. Finally, we select the most fitting chains of evidence from the evidence forest and integrate them into the generated story, thereby enhancing the narrative’s complexity and credibility. Experimental results and numerous examples verify the effectiveness of our method. | Zhihua Wen, Zhiliang Tian, Wei Wu, Yuxin Yang, Yanqi Shi, Zhen Huang, Dongsheng Li |  |
| 396 |  |  [KAPALM: Knowledge grAPh enhAnced Language Models for Fake News Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.263) |  | 0 | Social media has not only facilitated news consumption, but also led to the wide spread of fake news. Because news articles in social media is usually condensed and full of knowledge entities, existing methods of fake news detection use external entity knowledge. However, majority of these methods focus on news entity information and ignore the structured knowledge among news entities. To address this issue, in this work, we propose a Knowledge grAPh enhAnced Language Model (KAPALM) which is a novel model that fuses coarse- and fine-grained representations of entity knowledge from Knowledge Graphs (KGs). Firstly, we identify entities in news content and link them to entities in KGs. Then, a subgraph of KGs is extracted to provide structured knowledge of entities in KGs and fed into a graph neural network to obtain the coarse-grained knowledge representation. This subgraph is pruned to provide fine-grained knowledge and fed into the attentive graph and graph pooling layer. Finally, we integrate the coarse- and fine-grained entity knowledge representations with the textual representation for fake news detection. The experimental results on two benchmark datasets show that our method is superior to state-of-the-art baselines. In addition, it is competitive in the few-shot scenario. | Jing Ma, Chen Chen, Chunyan Hou, Xiaojie Yuan |  |
| 397 |  |  [Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.264) |  | 0 | In law, lore, and everyday life, loopholes are commonplace. When people exploit a loophole, they understand the intended meaning or goal of another person, but choose to go with a different interpretation. Past and current AI research has shown that artificial intelligence engages in what seems superficially like the exploitation of loopholes, but this is likely anthropomorphization. It remains unclear to what extent current models, especially Large Language Models (LLMs), capture the pragmatic understanding required for engaging in loopholes. We examined the performance of LLMs on two metrics developed for studying loophole behavior in humans: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context). We conducted a fine-grained comparison of state-of-the-art LLMs to humans, and find that while many of the models rate loophole behaviors as resulting in less trouble and upset than outright non-compliance (in line with adults), they struggle to recognize the humor in the creative exploitation of loopholes in the way that humans do. Furthermore, only two of the models, GPT 3 and 3.5, are capable of generating loopholes of their own, with GPT3.5 performing closest to the human baseline. | Sonia K. Murthy, Kiera Parece, Sophie Bridgers, Peng Qian, Tomer D. Ullman |  |
| 398 |  |  [InstructExcel: A Benchmark for Natural Language Instruction in Excel](https://doi.org/10.18653/v1/2023.findings-emnlp.265) |  | 0 | With the evolution of Large Language Models (LLMs) we can solve increasingly more complex NLP tasks across various domains, including spreadsheets. This work investigates whether LLMs can generate code (Excel OfficeScripts, a TypeScript API for executing many tasks in Excel) that solves Excel specific tasks provided via natural language user instructions. To do so we introduce a new large-scale benchmark, InstructExcel, created by leveraging the ‘Automate’ feature in Excel to automatically generate OfficeScripts from users’ actions. Our benchmark includes over 10k samples covering 170+ Excel operations across 2,000 publicly available Excel spreadsheets. Experiments across various zero-shot and few-shot settings show that InstructExcel is a hard benchmark for state of the art models like GPT-4. We observe that (1) using GPT-4 over GPT-3.5, (2) providing more in-context examples, and (3) dynamic prompting can help improve performance on this benchmark. | Justin Payan, Swaroop Mishra, Mukul Singh, Carina Negreanu, Christian Pölitz, Chitta Baral, Subhro Roy, Rasika Chakravarthy, Benjamin Van Durme, Elnaz Nouri |  |
| 399 |  |  [Hallucination Detection for Grounded Instruction Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.266) |  | 0 | We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final model outperforms several baselines, including using word probability estimated by the instruction-generation model, and supervised models based on LSTM and Transformer. | Lingjun Zhao, Khanh Nguyen, Hal Daumé III |  |
| 400 |  |  [Definitions Matter: Guiding GPT for Multi-label Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.267) |  | 0 | Large language models have recently risen in popularity due to their ability to perform many natural language tasks without requiring any fine-tuning. In this work, we focus on two novel ideas: (1) generating definitions from examples and using them for zero-shot classification, and (2) investigating how an LLM makes use of the definitions. We thoroughly analyze the performance of GPT-3 model for fine-grained multi-label conspiracy theory classification of tweets using zero-shot labeling. In doing so, we asses how to improve the labeling by providing minimal but meaningful context in the form of the definitions of the labels. We compare descriptive noun phrases, human-crafted definitions, introduce a new method to help the model generate definitions from examples, and propose a method to evaluate GPT-3’s understanding of the definitions. We demonstrate that improving definitions of class labels has a direct consequence on the downstream classification results. | Youri Peskine, Damir Korencic, Ivan Grubisic, Paolo Papotti, Raphaël Troncy, Paolo Rosso |  |
| 401 |  |  [ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.268) |  | 0 | We introduce ECHo (Event Causality Inference via Human-Centric Reasoning), a diagnostic dataset of event causality inference grounded in visio-linguistic social scenarios. ECHo employs real-world human-centric deductive information building on a television crime drama. ECHo requires the Theory-of-Mind (ToM) ability to understand and reason about social interactions based on multimodal information. Using ECHo, we propose a unified Chain-of-Thought (CoT) framework to assess the reasoning capability of current AI systems. Our ToM-enhanced CoT pipeline accommodates various large foundation models in both zero-shot and few-shot visio-linguistic reasoning. We use this framework to scrutinize recent large foundation models such as InstructGPT and MiniGPT-4 on three diagnostic human-centric tasks. Further analysis demonstrates ECHo as a challenging dataset to expose imperfections and inconsistencies in reasoning. Our data and code are publicly available at [https://github.com/YuxiXie/ECHo](https://github.com/YuxiXie/ECHo). | Yuxi Xie, Guanzhen Li, MinYen Kan |  |
| 402 |  |  [An Empirical Study of Instruction-tuning Large Language Models in Chinese](https://doi.org/10.18653/v1/2023.findings-emnlp.269) |  | 0 | The success of ChatGPT validates the potential of large language models (LLMs) in artificial general intelligence (AGI). Subsequently, the release of LLMs has sparked the open-source community’s interest in instruction-tuning, which is deemed to accelerate ChatGPT’s replication process. However, research on instruction-tuning LLMs in Chinese, the world’s most spoken language, is still in its early stages. Therefore, this paper makes an in-depth empirical study of instruction-tuning LLMs in Chinese, which can serve as a cookbook that provides valuable findings for effectively customizing LLMs that can better respond to Chinese instructions. Specifically, we systematically explore the impact of LLM bases, parameter-efficient methods, instruction data types, which are the three most important elements for instruction-tuning. Besides, we also conduct experiment to study the impact of other factors, e.g., chain-of-thought data and human-value alignment. We hope that this empirical study can make a modest contribution to the open Chinese version of ChatGPT. This paper will release a powerful Chinese LLM that is comparable to ChatGLM. The code and data are available at https: //github.com/PhoebusSi/Alpaca-CoT. | Qingyi Si, Tong Wang, Zheng Lin, Xu Zhang, Yanan Cao, Weiping Wang |  |
| 403 |  |  [Debiasing Multimodal Models via Causal Information Minimization](https://doi.org/10.18653/v1/2023.findings-emnlp.270) |  | 0 | Most existing debiasing methods for multimodal models, including causal intervention and inference methods, utilize approximate heuristics to represent the biases, such as shallow features from early stages of training or unimodal features for multimodal tasks like VQA, etc., which may not be accurate. In this paper, we study bias arising from confounders in a causal graph for multimodal data, and examine a novel approach that leverages causally-motivated information minimization to learn the confounder representations. Robust predictive features contain diverse information that helps a model generalize to out-of-distribution data. Hence, minimizing the information content of features obtained from a pretrained biased model helps learn the simplest predictive features that capture the underlying data distribution. We treat these features as confounder representations and use them via methods motivated by causal theory to remove bias from models. We find that the learned confounder representations indeed capture dataset biases and the proposed debiasing methods improve out-of-distribution (OOD) performance on multiple multimodal datasets without sacrificing in-distribution performance. Additionally, we introduce a novel metric to quantify the sufficiency of spurious features in models’ predictions that further demonstrates the effectiveness of our proposed methods. | Vaidehi Patil, Adyasha Maharana, Mohit Bansal |  |
| 404 |  |  [Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.271) |  | 0 | Emotion arcs capture how an individual (or a population) feels over time. They are widely used in industry and research; however, there is little work on evaluating the automatically generated arcs. This is because of the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. By running experiments on 18 diverse datasets in 9 languages, we show that despite being markedly poor at instance level emotion classification, LexO methods are highly accurate at generating emotion arcs when aggregating information from hundreds of instances. We also show, through experiments on six indigenous African languages, as well as Arabic, and Spanish, that automatic translations of English emotion lexicons can be used to generate high-quality emotion arcs in less-resource languages. This opens up avenues for work on emotions in languages from around the world; which is crucial for commerce, public policy, and health research in service of speakers often left behind. Code and resources: https://github.com/dteodore/EmotionArcs | Daniela Teodorescu, Saif M. Mohammad |  |
| 405 |  |  [Multi-step Jailbreaking Privacy Attacks on ChatGPT](https://doi.org/10.18653/v1/2023.findings-emnlp.272) |  | 0 | With the rapid progress of large language models (LLMs), many downstream NLP tasks can be well solved given appropriate prompts. Though model developers and researchers work hard on dialog safety to avoid generating harmful content from LLMs, it is still challenging to steer AI-generated content (AIGC) for the human good. As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring. In this paper, we study the privacy threats from OpenAI’s ChatGPT and the New Bing enhanced by ChatGPT and show that application-integrated LLMs may cause new privacy threats. To this end, we conduct extensive experiments to support our claims and discuss LLMs’ privacy implications. | Haoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Jie Huang, Fanpu Meng, Yangqiu Song |  |
| 406 |  |  [Chain-of-Thought Embeddings for Stance Detection on Social Media](https://doi.org/10.18653/v1/2023.findings-emnlp.273) |  | 0 | Stance detection on social media is challenging for Large Language Models (LLMs), as emerging slang and colloquial language in online conversations often contain deeply implicit stance labels. Chain-of-Thought (COT) prompting has recently been shown to improve performance on stance detection tasks — alleviating some of these issues. However, COT prompting still struggles with implicit stance identification. This challenge arises because many samples are initially challenging to comprehend before a model becomes familiar with the slang and evolving knowledge related to different topics, all of which need to be acquired through the training data. In this study, we address this problem by introducing COT Embeddings which improve COT performance on stance detection tasks by embedding COT reasonings and integrating them into a traditional RoBERTa-based stance detection pipeline. Our analysis demonstrates that 1) text encoders can leverage COT reasonings with minor errors or hallucinations that would otherwise distort the COT output label. 2) Text encoders can overlook misleading COT reasoning when a sample’s prediction heavily depends on domain-specific patterns. Our model achieves SOTA performance on multiple stance detection datasets collected from social media. | Joseph Gatto, Omar Sharif, Sarah Preum |  |
| 407 |  |  [Using LLM for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries](https://doi.org/10.18653/v1/2023.findings-emnlp.274) |  | 0 | Understanding and characterizing the discus- sions around key events in news streams is important for analyzing political discourse. In this work, we study the problem of identification of such key events and the news articles associated with those events from news streams. We propose a generic framework for news stream clustering that analyzes the temporal trend of news articles to automatically extract the underlying key news events that draw significant media attention. We characterize such key events by generating event summaries, based on which we form document clusters in an unsupervised fashion. We evaluate our simple yet effective framework, and show that it produces more coherent event-focused clusters. To demonstrate the utility of our approach, and facilitate future research along the line, we use our framework to construct KeyEvents, a dataset of 40k articles with 611 key events from 11 topics. | Nishanth Sridhar Nakshatri, Siyi Liu, Sihao Chen, Dan Roth, Dan Goldwasser, Daniel Hopkins |  |
| 408 |  |  [Descriptive Prompt Paraphrasing for Target-Oriented Multimodal Sentiment Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.275) |  | 0 | Target-Oriented Multimodal Sentiment Classification (TMSC) aims to perform sentiment polarity on a target jointly considering its corresponding multiple modalities including text, image, and others. Current researches mainly work on either of two types of targets in a decentralized manner. One type is entity, such as a person name, a location name, etc. and the other is aspect, such as ‘food’, ‘service’, etc. We believe that this target type based division in task modelling is not necessary because the sentiment polarity of the specific target is not governed by its type but its context. For this reason, we propose a unified model for target-oriented multimodal sentiment classification, so called UnifiedTMSC. It is prompt-based language modelling and performs well on four datasets spanning the above two target types. Specifically, we design descriptive prompt paraphrasing to reformulate TMSC task via (1) task paraphrasing, which obtains paraphrased prompts based on the task description through a paraphrasing rule, and (2) image prefix tuning, which optimizes a small continuous image vector throughout the multimodal representation space of text and images. Conducted on two entity-level multimodal datasets: Twitter-2015 and Twitter-2017, and two aspect-level multimodal datasets: Multi-ZOL and MASAD, the experimental results show the effectiveness of our UnifiedTMSC. | Dan Liu, Lin Li, Xiaohui Tao, Jian Cui, Qing Xie |  |
| 409 |  |  [Joint Semantic and Strategy Matching for Persuasive Dialogue](https://doi.org/10.18653/v1/2023.findings-emnlp.276) |  | 0 | Persuasive dialogue aims to persuade users to achieve some targets by conversations. While previous persuasion models have achieved notable successes, they mostly base themselves on utterance semantic matching, and an important aspect has been ignored, that is, the strategy of the conversations, for example, the agent can choose an emotional-appeal strategy to impress users. Compared with utterance semantics, conversation strategies are high-level concepts, which can be informative and provide complementary information to achieve effective persuasions. In this paper, we propose to build a persuasion model by jointly modeling the conversation semantics and strategies, where we design a BERT-like module and an auto-regressive predictor to match the semantics and strategies, respectively. Experimental results indicate that our proposed approach can significantly improve the state-of-the-art baseline by 5% on a small dataset and 37% on a large dataset in terms of Recall@1. Detailed analyses show that the auto-regressive predictor contributes most to the final performance. | Chuhao Jin, Yutao Zhu, Lingzhen Kong, Shijie Li, Xiao Zhang, Ruihua Song, Xu Chen, Huan Chen, Yuchong Sun, Yu Chen, Jun Xu |  |
| 410 |  |  [Non-Autoregressive Sentence Ordering](https://doi.org/10.18653/v1/2023.findings-emnlp.277) |  | 0 | Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step. Such an autoregressive manner only leverages unilateral dependencies during decoding and cannot fully explore the semantic dependency between sentences for ordering. To overcome these limitations, in this paper, we propose a novel Non-Autoregressive Ordering Network, dubbed NAON, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel. We claim that the non-autoregressive manner is not just applicable but also particularly suitable to the sentence ordering task because of two peculiar characteristics of the task: 1) each generation target is in deterministic length, and 2) the sentences and positions should match exclusively. Furthermore, to address the repetition issue of the naive non-autoregressive Transformer, we introduce an exclusive loss to constrain the exclusiveness between positions and sentences. To verify the effectiveness of the proposed model, we conduct extensive experiments on several common-used datasets and the experimental results show that our method outperforms all the autoregressive approaches and yields competitive performance compared with the state-of-the-arts. The codes are available at: https://github.com/steven640pixel/nonautoregressive-sentence-ordering. | Yi Bin, Wenhao Shi, Bin Ji, Jipeng Zhang, Yujuan Ding, Yang Yang |  |
| 411 |  |  [Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.278) |  | 0 | With the recent undeniable advancement in reasoning abilities in large language models (LLMs) like ChatGPT and GPT-4, there is a growing trend for using LLMs on various tasks. One area where LLMs can be employed is as an alternative evaluation metric for complex generative tasks, which generally demands expensive human judges to complement the traditional automatic metrics for various evaluation dimensions such as fluency and consistency. In this work, we conduct extensive analysis to investigate the stability and reliability of LLMs as automatic evaluators for abstractive summarization. We found that while ChatGPT and GPT-4 outperform the commonly used automatic metrics, they are not ready as human replacements due to significant limitations. That is, LLM evaluators rate each candidate system inconsistently and are dimension-dependent. They also struggle to compare candidates with close performance and become more unreliable with higher-quality summaries by obtaining a lower correlation with humans. In other words, with better abstractive summarization systems being introduced at a fast pace, LLMs may result in misleading and unreliable evaluations. | Chenhui Shen, Liying Cheng, XuanPhi Nguyen, Yang You, Lidong Bing |  |
| 412 |  |  [Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender](https://doi.org/10.18653/v1/2023.findings-emnlp.279) |  | 0 | In this paper, we investigate the impact of objects on gender bias in image captioning systems. Our results show that only gender-specific objects have a strong gender bias (e.g., women-lipstick). In addition, we propose a visual semantic-based gender score that measures the degree of bias and can be used as a plug-in for any image captioning system. Our experiments demonstrate the utility of the gender score, since we observe that our score can measure the bias relation between a caption and its related gender; therefore, our score can be used as an additional metric to the existing Object Gender Co-Occ approach. | Ahmed Sabir, Lluís Padró |  |
| 413 |  |  [FREDSum: A Dialogue Summarization Corpus for French Political Debates](https://doi.org/10.18653/v1/2023.findings-emnlp.280) |  | 0 | Recent advances in deep learning, and especially the invention of encoder-decoder architectures, have significantly improved the performance of abstractive summarization systems. While the majority of research has focused on written documents, we have observed an increasing interest in the summarization of dialogues and multi-party conversations over the past few years. In this paper, we present a dataset of French political debates for the purpose of enhancing resources for multi-lingual dialogue summarization. Our dataset consists of manually transcribed and annotated political debates, covering a range of topics and perspectives. We highlight the importance of high-quality transcription and annotations for training accurate and effective dialogue summarization models, and emphasize the need for multilingual resources to support dialogue summarization in non-English languages. We also provide baseline experiments using state-of-the-art methods, and encourage further research in this area to advance the field of dialogue summarization. Our dataset will be made publicly available for use by the research community, enabling further advances in multilingual dialogue summarization. | Virgile Rennard, Guokan Shang, Damien Grari, Julie Hunter, Michalis Vazirgiannis |  |
| 414 |  |  [Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path](https://doi.org/10.18653/v1/2023.findings-emnlp.281) |  | 0 | The rapid growth of web pages and the increasing complexity of their structure poses a challenge for web mining models. Web mining models are required to understand semi-structured web pages, particularly when little is known about the subject or template of a new page. Current methods migrate language models to web mining by embedding the XML source code into the transformer or encoding the rendered layout with graph neural networks. However, these approaches do not take into account the relationships between text nodes within and across pages. In this paper, we propose a new approach, ReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the shortest relative paths in the Document Object Model (DOM) tree of the web page which is a more accurate and efficient signal for key-value pair extraction within a web page. It also incorporates the popularity of each text node by counting the occurrence of the same text node across different web pages. We use contrastive learning to address the issue of sparsity in relation extraction. Extensive experiments on public benchmarks show that our method, ReXMiner, outperforms the state-of-the-art baselines in the task of zero-shot relation extraction in web mining. | Zilong Wang, Jingbo Shang |  |
| 415 |  |  [Narrative Style and the Spread of Health Misinformation on Twitter](https://doi.org/10.18653/v1/2023.findings-emnlp.282) |  | 0 | Using a narrative style is an effective way to communicate health information both on and off social media. Given the amount of misinformation being spread online and its potential negative effects, it is crucial to investigate the interplay between narrative communication style and misinformative health content on user engagement on social media platforms. To explore this in the context of Twitter, we start with previously annotated health misinformation tweets (n ≈15,000) and annotate a subset of the data (n=3,000) for the presence of narrative style. We then use these manually assigned labels to train text classifiers, experimenting with supervised fine-tuning and in-context learning for automatic narrative detection. We use our best model to label remaining portion of the dataset, then statistically analyze the relationship between narrative style, misinformation, and user-level features on engagement, finding that narrative use is connected to increased tweet engagement and can, in some cases, lead to increased engagement with misinformation. Finally, we analyze the general categories of language used in narratives and health misinformation in our dataset. | Achyutarama R. Ganti, Eslam Ali Hassan Hussein, Steven R. Wilson, Zexin Ma, Xinyan Zhao |  |
| 416 |  |  [HadSkip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference](https://doi.org/10.18653/v1/2023.findings-emnlp.283) |  | 0 | Pre-trained language models (LMs) have brought remarkable performance on numerous NLP tasks. However, they require significant resources and entail high computational costs for inference, making them challenging to deploy in real-world and real-time systems. Existing early exiting methods aim to reduce computational complexity by selecting the layer at which to exit, but suffer from the limitation that they have to sequentially traverse through all layers prior to the selected exit layer, which lacks flexibility and degrades their performance. To solve this problem, we propose a homotopic and adaptive layer skipping fine-tuning method named HadSkip. HadSkip adaptively selects the layers to skip based on a predefined budget. Specifically, we introduce a learnable gate before each layer of the LM to determine whether the current layer should be skipped. To tackle various challenges in training such as discrete gates and the budget constraint, we propose a fine-grained initialization strategy and homotopic optimization strategy. We conduct extensive experiments on the GLUE benchmark, and experimental results demonstrate the proposed HadSkip outperforms all state-of-the-art baselines significantly. | Haoyu Wang, Yaqing Wang, Tianci Liu, Tuo Zhao, Jing Gao |  |
| 417 |  |  [Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.284) |  | 0 | Mental illness remains one of the most critical public health issues of our time, due to the severe scarcity and accessibility limit of professionals. Psychotherapy requires high-level expertise to conduct deep, complex reasoning and analysis on the cognition modeling of the patients. In the era of Large Language Models, we believe it is the right time to develop AI assistance for computational psychotherapy. We study the task of cognitive distortion detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs diagnosis on the patient’s speech via three stages: subjectivity assessment to separate the facts and the thoughts; contrastive reasoning to elicit the reasoning processes supporting and contradicting the thoughts; and schema analysis to summarize the cognition schemas. The generated diagnosis rationales through the three stages are essential for assisting the professionals. Experiments demonstrate that DoT obtains significant improvements over ChatGPT for cognitive distortion detection, while generating high-quality rationales approved by human experts. | Zhiyu Chen, Yujie Lu, William Yang Wang |  |
| 418 |  |  [Measuring the Knowledge Acquisition-Utilization Gap in Pretrained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.285) |  | 0 | While pre-trained language models (PLMs) have shown evidence of acquiring vast amounts of knowledge, it remains unclear how much of this parametric knowledge is actually usable in performing downstream tasks. We propose a systematic framework to measure parametric knowledge utilization in PLMs. Our framework first extracts knowledge from a PLM’s parameters and subsequently constructs a downstream task around this extracted knowledge. Performance on this task thus depends exclusively on utilizing the model’s possessed knowledge, avoiding confounding factors like insufficient signal. As an instantiation, we study factual knowledge of PLMs and measure utilization across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps - in acquired vs. utilized knowledge, (2) they show limited robustness in utilizing knowledge under distribution shifts, and (3) larger models close the acquired knowledge gap but the utilized knowledge gap remains. Overall, our study provides insights into PLMs’ capabilities beyond their acquired knowledge. | Amirhossein Kazemnejad, Mehdi Rezagholizadeh, Prasanna Parthasarathi, Sarath Chandar |  |
| 419 |  |  [Non-compositional Expression Generation Based on Curriculum Learning and Continual Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.286) |  | 0 | Non-compositional expressions, by virtue of their non-compositionality, are a classic ‘pain in the neck’ for NLP systems. Different from the general language modeling and generation tasks that are primarily compositional, generating non-compositional expressions is more challenging for current neural models, including large pre-trained language models. The main reasons are 1) their non-compositionality, and 2) the limited data resources. Therefore, to make the best use of available data for modeling non-compositionality, we propose a dynamic curriculum learning framework, which learns training examples from easy ones to harder ones thus optimizing the learning step by step but suffers from the forgetting problem. To alleviate the forgetting problem brought by the arrangement of training examples, we also apply a continual learning method into our curriculum learning framework. Our proposed method combined curriculum and continual learning, to gradually improve the model’s performance on the task of non-compositional expression generation. Experiments on idiomatic expression generation and metaphor generation affirm the effectiveness of our proposed curriculum learning framework and the application of continual learning. Our codes are available at https://github.com/zhjjn/CL2Gen.git. | Jianing Zhou, Ziheng Zeng, Hongyu Gong, Suma Bhat |  |
| 420 |  |  [Information Extraction from Legal Wills: How Well Does GPT-4 Do?](https://doi.org/10.18653/v1/2023.findings-emnlp.287) |  | 0 | This work presents a manually annotated dataset for Information Extraction (IE) from legal wills, and relevant in-context learning experiments on the dataset. The dataset consists of entities, binary relations between the entities (e.g., relations between testator and beneficiary), and n-ary events (e.g., bequest) extracted from 45 legal wills from two US states. This dataset can serve as a foundation for downstream tasks in the legal domain. Another use case of this dataset is evaluating the performance of large language models (LLMs) on this IE task. We evaluated GPT-4 with our dataset to investigate its ability to extract information from legal wills. Our evaluation result demonstrates that the model is capable of handling the task reasonably well. When given instructions and examples as a prompt, GPT-4 shows decent performance for both entity extraction and relation extraction tasks. Nevertheless, the evaluation result also reveals that the model is not perfect. We observed inconsistent outputs (given a prompt) as well as prompt over-generalization. | Alice Saebom Kwak, Cheonkam Jeong, Gaetano Forte, Derek E. Bambauer, Clayton T. Morrison, Mihai Surdeanu |  |
| 421 |  |  [Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution](https://doi.org/10.18653/v1/2023.findings-emnlp.288) |  | 0 | We present a setup for training, evaluating and interpreting neural language models, that uses artificial, language-like data. The data is generated using a massive probabilistic grammar (based on state-split PCFGs), that is itself derived from a large natural language corpus, but also provides us complete control over the generative process. We describe and release both grammar and corpus, and test for the naturalness of our generated data. This approach allows us define closed-form expressions to efficiently compute exact lower bounds on obtainable perplexity using both causal and masked language modelling. Our results show striking differences between neural language modelling architectures and training objectives in how closely they allow approximating the lower bound on perplexity. Our approach also allows us to directly compare learned representations to symbolic rules in the underlying source. We experiment with various techniques for interpreting model behaviour and learning dynamics. With access to the underlying true source, our results show striking differences and outcomes in learning dynamics between different classes of words. | Jaap Jumelet, Willem H. Zuidema |  |
| 422 |  |  [Continual Generalized Intent Discovery: Marching Towards Dynamic and Open-world Intent Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.289) |  | 0 | In a practical dialogue system, users may input out-of-domain (OOD) queries. The Generalized Intent Discovery (GID) task aims to discover OOD intents from OOD queries and extend them to the in-domain (IND) classifier. However, GID only considers one stage of OOD learning, and needs to utilize the data in all previous stages for joint training, which limits its wide application in reality. In this paper, we introduce a new task, Continual Generalized Intent Discovery (CGID), which aims to continuously and automatically discover OOD intents from dynamic OOD data streams and then incrementally add them to the classifier with almost no previous data, thus moving towards dynamic intent recognition in an open world. Next, we propose a method called Prototype-guided Learning with Replay and Distillation (PLRD) for CGID, which bootstraps new intent discovery through class prototypes and balances new and old intents through data replay and feature distillation. Finally, we conduct detailed experiments and analysis to verify the effectiveness of PLRD and understand the key challenges of CGID for future research. | Xiaoshuai Song, Yutao Mou, Keqing He, Yueyan Qiu, Jinxu Zhao, Pei Wang, Weiran Xu |  |
| 423 |  |  [Frugal Prompting for Dialog Models](https://doi.org/10.18653/v1/2023.findings-emnlp.290) |  | 0 | The use of large language models (LLMs) in natural language processing (NLP) tasks is rapidly increasing, leading to changes in how researchers approach problems in the field. To fully utilize these models’ abilities, a better understanding of their behavior for different input protocols is required. With LLMs, users can directly interact with the models through a text-based interface to define and solve various tasks. Hence, understanding the conversational abilities of these LLMs, which may not have been specifically trained for dialog modeling, is also important. This study examines different approaches for building dialog systems using LLMs by considering various aspects of the prompt. As part of prompt tuning, we experiment with various ways of providing instructions, exemplars, current query and additional context. The research also analyzes the representations of dialog history that have the optimal usable-information density. Based on the findings, the paper suggests more compact ways of providing dialog history information while ensuring good performance and reducing model’s inference-API costs. The research contributes to a better understanding of how LLMs can be effectively used for building interactive systems. | Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal |  |
| 424 |  |  [The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.291) |  | 0 | End-to-end spoken language understanding (SLU) remains elusive even with current large pretrained language models on text and speech, especially in multilingual cases. Machine translation has been established as a powerful pretraining objective on text as it enables the model to capture high-level semantics of the input utterance and associations between different languages, which is desired for speech models that work on lower-level acoustic frames. Motivated particularly by the task of cross-lingual SLU, we demonstrate that the task of speech translation (ST) is a good means of pretraining speech models for end-to-end SLU on both intra- and cross-lingual scenarios. By introducing ST, our models reach higher performance over baselines on monolingual and multilingual intent classification as well as spoken question answering using SLURP, MINDS-14, and NMSQA benchmarks. To verify the effectiveness of our methods, we also create new benchmark datasets from both synthetic and real sources, for speech summarization and low-resource/zero-shot transfer from English to French or Spanish. We further show the value of preserving knowledge for the ST pretraining task for better downstream performance, possibly using Bayesian transfer regularizers. | Mutian He, Philip N. Garner |  |
| 425 |  |  [MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space](https://doi.org/10.18653/v1/2023.findings-emnlp.292) |  | 0 | Multi-aspect controllable text generation aims to generate fluent sentences that possess multiple desired attributes simultaneously. Traditional methods either require expensive iteration / searching within the discrete text space during the decoding stage, or train separate controllers for each aspect, resulting in a degradation of text quality due to the discrepancy between different aspects. To address these limitations, we introduce a novel approach for Multi-aspect control, namely MacLaSa, that estimates compact Latent space for multiple aspects, and performs efficient Sampling with a fast sampler. To eliminate the domain discrepancies between different aspects, we first utilize a variational autoencoder (VAE) network to map text sequences from various data sources into close latent representations. The estimated latent space enables the formulation of joint energy-based models and the plugging in of arbitrary attribute discriminators to achieve multi-aspect control. Afterwards, we draw latent samples with a fast sampler based on ordinary differential equations and feed sampled examples to the VAE decoder to produce target text sequences. Experimental results demonstrate that MacLaSa outperforms strong baselines on both attribute relevance and textual quality while maintaining a high inference speed. | Hanxing Ding, Liang Pang, Zihao Wei, Huawei Shen, Xueqi Cheng, TatSeng Chua |  |
| 426 |  |  [HPE: Answering Complex Questions over Text by Hybrid Question Parsing and Execution](https://doi.org/10.18653/v1/2023.findings-emnlp.293) |  | 0 | The dominant paradigm of textual question answering systems is based on end-to-end neural networks, which excels at answering natural language questions but falls short on complex ones. This stands in contrast to the broad adaptation of semantic parsing approaches over structured data sources (e.g., relational database, knowledge graphs), that convert natural language questions to logical forms and execute them with query engines. Towards combining the strengths of neural and symbolic methods, we propose a framework of question parsing and execution on textual QA. It comprises two central pillars: (1) We parse the question of varying complexity into an intermediate representation, named H-expression, which is composed of simple questions as the primitives and symbolic operations representing the relationships among them; (2) To execute the resulting H-expressions, we design a hybrid executor, which integrates the deterministic rules to translate the symbolic operations with a drop-in neural reader network to answer each decomposed simple question. Hence, the proposed framework can be viewed as a top-down question parsing followed by a bottom-up answer backtracking. The resulting H-expressions closely guide the execution process, offering higher precision besides better interpretability while still preserving the advantages of the neural readers for resolving its primitive elements. Our extensive experiments on MuSiQue, 2WikiQA, HotpotQA, and NQ show that the proposed parsing and hybrid execution framework outperforms existing approaches in supervised, few-shot, and zero-shot settings, while also effectively exposing its underlying reasoning process. | Ye Liu, Semih Yavuz, Rui Meng, Dragomir Radev, Caiming Xiong, Shafiq Joty, Yingbo Zhou |  |
| 427 |  |  [Length-Adaptive Distillation: Customizing Small Language Model for Dynamic Token Pruning](https://doi.org/10.18653/v1/2023.findings-emnlp.294) |  | 0 | Pre-trained language models greatly improve the performance of various tasks but at a cost of high computation overhead. To facilitate practical applications, there are mainly two lines of research to accelerate model inference: model compression and dynamic computation (e.g., dynamic token pruning). Existing works either adopt these methods individually or simply apply dynamic computation approaches upon a compressed small language model. We argue that they are sub-optimal since the two approaches are separately designed so the compressed model may not be tailored for dynamic computation. To tackle this problem and make compressed small language models faster, we propose Length-Adaptive Distillation, a two-stage knowledge distillation framework that aims to produce a customized small language model for dynamic token pruning. In the general distillation stage, we enforce the student to mimic and reconstruct the teacher’s output based on the dynamically pruned representations. Then in the task-specific distillation stage, the student is further accustomed to token pruning while absorbing the task-specific knowledge. Experimental results on GLUE benchmark demonstrate that our method can make the small language model more customized for dynamic token pruning and achieve better speed-performance trade-off. | Chang Liu, Chongyang Tao, Jianxin Liang, Jiazhan Feng, Tao Shen, Quzhe Huang, Dongyan Zhao |  |
| 428 |  |  [Toxicity, Morality, and Speech Act Guided Stance Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.295) |  | 0 | In this work, we focus on the task of determining the public attitude toward various social issues discussed on social media platforms. Platforms such as Twitter, however, are often used to spread misinformation, fake news through polarizing views. Existing literature suggests that higher levels of toxicity prevalent in Twitter conversations often spread negativity and delay addressing issues. Further, the embedded moral values and speech acts specifying the intention of the tweet correlate with public opinions expressed on various topics. However, previous works, which mainly focus on stance detection, either ignore the speech act, toxic, and moral features of these tweets that can collectively help capture public opinion or lack an efficient architecture that can detect the attitudes across targets. Therefore, in our work, we focus on the main task of stance detection by exploiting the toxicity, morality, and speech act as auxiliary tasks. We propose a multitasking model TWISTED that initially extracts the valence, arousal, and dominance aspects hidden in the tweets and injects the emotional sense into the embedded text followed by an efficient attention framework to correctly detect the tweet’s stance by using the shared features of toxicity, morality, and speech acts present in the tweet. Extensive experiments conducted on 4 benchmark stance detection datasets (SemEval-2016, P-Stance, COVID19-Stance, and ClimateChange) comprising different domains demonstrate the effectiveness and generalizability of our approach. | Apoorva Upadhyaya, Marco Fisichella, Wolfgang Nejdl |  |
| 429 |  |  [Reasoning about Ambiguous Definite Descriptions](https://doi.org/10.18653/v1/2023.findings-emnlp.296) |  | 0 | Natural language reasoning plays an increasingly important role in improving language models’ ability to solve complex language understanding tasks. An interesting use case for reasoning is the resolution of context-dependent ambiguity. But no resources exist to evaluate how well Large Language Models can use explicit reasoning to resolve ambiguity in language. We propose to use ambiguous definite descriptions for this purpose and create and publish the first benchmark dataset consisting of such phrases. Our method includes all information required to resolve the ambiguity in the prompt, which means a model does not require anything but reasoning to do well. We find this to be a challenging task for recent LLMs. Code and data available at: https://github.com/sfschouten/exploiting-ambiguity | Stefan F. Schouten, Peter Bloem, Ilia Markov, Piek Vossen |  |
| 430 |  |  [A Framework for Bidirectional Decoding: Case Study in Morphological Inflection](https://doi.org/10.18653/v1/2023.findings-emnlp.297) |  | 0 | Transformer-based encoder-decoder models that generate outputs in a left-to-right fashion have become standard for sequence-to-sequence tasks. In this paper, we propose a framework for decoding that produces sequences from the “outside-in”: at each step, the model chooses to generate a token on the left, on the right, or join the left and right sequences. We argue that this is more principled than prior bidirectional decoders. Our proposal supports a variety of model architectures and includes several training methods, such as a dynamic programming algorithm that marginalizes out the latent ordering variable. Our model sets state-of-the-art (SOTA) on the 2022 and 2023 shared tasks, beating the next best systems by over 4.7 and 2.7 points in average accuracy respectively. The model performs particularly well on long sequences, can implicitly learn the split point of words composed of stem and affix, and performs better relative to the baseline on datasets that have fewer unique lemmas. | Marc E. Canby, Julia Hockenmaier |  |
| 431 |  |  [Text-guided 3D Human Generation from 2D Collections](https://doi.org/10.18653/v1/2023.findings-emnlp.298) |  | 0 | 3D human modeling has been widely used for engaging interaction in gaming, film, and animation. The customization of these characters is crucial for creativity and scalability, which highlights the importance of controllability. In this work, we introduce Text-guided 3D Human Generation (T3H), where a model is to generate a 3D human, guided by the fashion description. There are two goals: 1) the 3D human should render articulately, and 2) its outfit is controlled by the given text. To address this T3H task, we propose Compositional Cross-modal Human (CCH). CCH adopts cross-modal attention to fuse compositional human rendering with the extracted fashion semantics. Each human body part perceives relevant textual guidance as its visual patterns. We incorporate the human prior and semantic discrimination to enhance 3D geometry transformation and fine-grained consistency, enabling it to learn from 2D collections for data efficiency. We conduct evaluations on DeepFashion and SHHQ with diverse fashion attributes covering the shape, fabric, and color of upper and lower clothing. Extensive experiments demonstrate that CCH achieves superior results for T3H with high efficiency. | TsuJui Fu, Wenhan Xiong, Yixin Nie, Jingyu Liu, Barlas Oguz, William Wang |  |
| 432 |  |  [Statistically Profiling Biases in Natural Language Reasoning Datasets and Models](https://doi.org/10.18653/v1/2023.findings-emnlp.299) |  | 0 | Recent studies have shown that many natural language understanding and reasoning datasets contain statistical cues that can be exploited by NLP models, resulting in an overestimation of their capabilities. Existing methods, such as “hypothesis-only” tests and CheckList, are limited in identifying these cues and evaluating model weaknesses. We introduce ICQ (I-See-Cue), a lightweight, general statistical profiling framework that automatically identifies potential biases in multiple-choice NLU datasets without requiring additional test cases. ICQ assesses the extent to which models exploit these biases through black-box testing, addressing the limitations of current methods. In this work, we conduct a comprehensive evaluation of statistical biases in 10 popular NLU datasets and 4 models, confirming prior findings, revealing new insights, and offering an online demonstration system to encourage users to assess their own datasets and models. Furthermore, we present a case study on investigating ChatGPT’s bias, providing valuable recommendations for practical applications. | Shanshan Huang, Kenny Q. Zhu |  |
| 433 |  |  [Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number](https://doi.org/10.18653/v1/2023.findings-emnlp.300) |  | 0 | Deep architectures such as Transformers are sometimes criticized for having uninterpretable “black-box” representations. We use causal intervention analysis to show that, in fact, some linguistic features are represented in a linear, interpretable format. Specifically, we show that BERT’s ability to conjugate verbs relies on a linear encoding of subject number that can be manipulated with predictable effects on conjugation accuracy. This encoding is found in the subject position at the first layer and the verb position at the last layer, but distributed across positions at middle layers, particularly when there are multiple cues to subject number. | Sophie Hao, Tal Linzen |  |
| 434 |  |  [MUX-PLMs: Data Multiplexing for High-throughput Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.301) |  | 0 | The widespread adoption of large language models such as ChatGPT and Bard has led to unprecedented demand for these technologies. The burgeoning cost of inference for ever-increasing model sizes coupled with hardware shortages has limited affordable access and poses a pressing need for efficiency approaches geared towards high throughput and performance. Multi-input multi-output (MIMO) algorithms such as data multiplexing, offer a promising solution with a many-fold increase in throughput by performing inference for multiple inputs at the cost of a single input. Yet these approaches are not currently performant enough to be deployed in modern systems. We change that by developing MUX-PLMs, a class of high throughput pre-trained language models (PLMs) trained with data multiplexing, that can be fine-tuned for any downstream task to yield high-throughput high-performance. Our novel multiplexing and demultiplexing modules proficiently entangle and disentangle inputs, and enable high-performance high throughput MUX-PLMs that are competitive with vanilla PLMs while achieving 2x/5x inference speedup with only a 1-4 % drop on a broad suite of tasks. | Vishvak Murahari, Ameet Deshpande, Carlos E. Jimenez, Izhak Shafran, Mingqiu Wang, Yuan Cao, Karthik Narasimhan |  |
| 435 |  |  [That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?](https://doi.org/10.18653/v1/2023.findings-emnlp.302) |  | 0 | The translation of ambiguous text presents a challenge for translation systems, as it requires using the surrounding context to disambiguate the intended meaning as much as possible. While prior work has studied ambiguities that result from different grammatical features of the source and target language, we study semantic ambiguities that exist in the source (English in this work) itself. In particular, we focus on idioms that are open to both literal and figurative interpretations (e.g., goose egg), and collect TIDE, a dataset of 512 pairs of English sentences containing idioms with disambiguating context such that one is literal (it laid a goose egg) and another is figurative (they scored a goose egg, as in a score of zero). In experiments, we compare MT-specific models and language models for (i) their preference when given an ambiguous subsentence, (ii) their sensitivity to disambiguating context, and (iii) the performance disparity between figurative and literal source sentences. We find that current MT models consistently translate English idioms literally, even when the context suggests a figurative interpretation. On the other hand, LMs are far more context-aware, although there remain disparities across target languages. Our findings underline the potential of LMs as a strong backbone for context-aware translation. | Jaechan Lee, Alisa Liu, Orevaoghene Ahia, Hila Gonen, Noah A. Smith |  |
| 436 |  |  [MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic](https://doi.org/10.18653/v1/2023.findings-emnlp.303) |  | 0 | Theory of Mind (ToM) is a critical component of intelligence but its assessment remains the subject of heated debates. Prior research applied human ToM assessments to natural language processing models using either human-created standardized tests or rule-based templates. However, these methods primarily focus on simplistic reasoning and require further validation. Here, we leverage dynamic epistemic logic to isolate a particular component of ToM and to generate controlled problems. We also introduce new verbalization techniques to express these problems in English natural language. Our findings indicate that some language model scaling (from 70M to 6B and 350M to 174B) does not consistently yield results better than random chance. While GPT-4 demonstrates superior epistemic reasoning capabilities, there is still room for improvement. Our code and datasets are publicly available. | Damien Sileo, Antoine Lernould |  |
| 437 |  |  [LATENTLOGIC: Learning Logic Rules in Latent Space over Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.304) |  | 0 | Learning logic rules for knowledge graph reasoning is essential as such rules provide interpretable explanations for reasoning and can be generalized to different domains. However, existing methods often face challenges such as searching in a vast search space (e.g., enumeration of relational paths or multiplication of high-dimensional matrices) and inefficient optimization (e.g., techniques based on reinforcement learning or EM algorithm). To address these limitations, this paper proposes a novel framework called LatentLogic to efficiently mine logic rules by controllable generation in the latent space. Specifically, to map the discrete relational paths into the latent space, we leverage a pre-trained VAE and employ a discriminator to establish an energy-based distribution. Additionally, we incorporate a sampler based on ordinary differential equations, enabling the efficient generation of logic rules in our approach. Extensive experiments on benchmark datasets demonstrate the effectiveness and efficiency of our proposed method. | Junnan Liu, Qianren Mao, Chenghua Lin, Yangqiu Song, Jianxin Li |  |
| 438 |  |  [RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training](https://doi.org/10.18653/v1/2023.findings-emnlp.305) |  | 0 | Pre-trained language models (PLMs) have demonstrated their exceptional performance across a wide range of natural language processing tasks. The utilization of PLM-based sentence embeddings enables the generation of contextual representations that capture rich semantic information. However, despite their success with unseen samples, current PLM-based representations suffer from poor robustness in adversarial scenarios. In this paper, we propose RobustEmbed, a self-supervised sentence embedding framework that enhances both generalization and robustness in various text representation tasks and against diverse adversarial attacks. By generating high-risk adversarial perturbations to promote higher invariance in the embedding space and leveraging the perturbation within a novel contrastive objective approach, RobustEmbed effectively learns high-quality sentence embeddings. Our extensive experiments validate the superiority of RobustEmbed over previous state-of-the-art self-supervised representations in adversarial settings, while also showcasing relative improvements in seven semantic textual similarity (STS) tasks and six transfer tasks. Specifically, our framework achieves a significant reduction in attack success rate from 75.51% to 39.62% for the BERTAttack attack technique, along with enhancements of 1.20% and 0.40% in STS tasks and transfer tasks, respectively. | Javad Rafiei Asl, Eduardo Blanco, Daniel Takabi |  |
| 439 |  |  [More than Votes? Voting and Language based Partisanship in the US Supreme Court](https://doi.org/10.18653/v1/2023.findings-emnlp.306) |  | 0 | Understanding the prevalence and dynamics of justice partisanship and ideology in the US Supreme Court is critical in studying jurisdiction. Most research quantifies partisanship based on voting behavior, and oral arguments in the courtroom — the last essential procedure before the final case outcome — have not been well studied for this purpose. To address this gap, we present a framework for analyzing the language of justices in the courtroom for partisan signals, and study how partisanship in speech aligns with voting patterns. Our results show that the affiliated party of justices can be predicted reliably from their oral contributions. We further show a strong correlation between language partisanship and voting ideology. | Biaoyan Fang, Trevor Cohn, Timothy Baldwin, Lea Frermann |  |
| 440 |  |  [Automatic Evaluation of Attribution by Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.307) |  | 0 | A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support its claims. However, evaluating the attribution, i.e., verifying whether the generated statement is fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate automatic evaluation of attribution given by LLMs. We begin by defining different types of attribution errors, and then explore two approaches for automatic evaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is repurposed from related tasks such as question answering, fact-checking, natural language inference, and summarization. We manually curate a set of test examples covering 12 domains from a generative search engine, New Bing. Our results on this curated test set and simulated examples from existing benchmarks highlight both promising signals and challenges. We hope our problem formulation, testbeds, and findings will help lay the foundation for future studies on this important problem. | Xiang Yue, Boshi Wang, Ziru Chen, Kai Zhang, Yu Su, Huan Sun |  |
| 441 |  |  [Modeling Highlighting of Metaphors in Multitask Contrastive Learning Paradigms](https://doi.org/10.18653/v1/2023.findings-emnlp.308) |  | 0 | Metaphorical language, such as “spending time together”, projects meaning from a source domain (here, money) to a target domain (time). Thereby, it highlights certain aspects of the target domain, such as the effort behind the time investment. Highlighting aspects with metaphors (while hiding others) bridges the two domains and is the core of metaphorical meaning construction. For metaphor interpretation, linguistic theories stress that identifying the highlighted aspects is important for a better understanding of metaphors. However, metaphor research in NLP has not yet dealt with the phenomenon of highlighting. In this paper, we introduce the task of identifying the main aspect highlighted in a metaphorical sentence. Given the inherent interaction of source domains and highlighted aspects, we propose two multitask approaches - a joint learning approach and a continual learning approach - based on a finetuned contrastive learning model to jointly predict highlighted aspects and source domains. We further investigate whether (predicted) information about a source domain leads to better performance in predicting the highlighted aspects, and vice versa. Our experiments on an existing corpus suggest that, with the corresponding information, the performance to predict the other improves in terms of model accuracy in predicting highlighted aspects and source domains notably compared to the single-task baselines. | Meghdut Sengupta, Milad Alshomary, Ingrid Scharlau, Henning Wachsmuth |  |
| 442 |  |  [LDM²: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement](https://doi.org/10.18653/v1/2023.findings-emnlp.309) |  | 0 | With the rapid development of large language models (LLMs), it is highly demanded that LLMs can be adopted to make decisions to enable the artificial general intelligence. Most approaches leverage manually crafted examples to prompt the LLMs to imitate the decision process of human. However, designing optimal prompts is difficult and the patterned prompts can hardly be generalized to more complex environments. In this paper, we propose a novel model named Large Decision Model with Memory (LDM2), which leverages a dynamic memory mechanism to construct dynamic prompts, guiding the LLMs in making proper decisions according to the faced state. LDM2 consists of two stages: memory formation and memory refinement. In the former stage, human behaviors are decomposed into state-action tuples utilizing the powerful summarizing ability of LLMs. Then, these tuples are stored in the memory, whose indices are generated by the LLMs, to facilitate the retrieval of the most relevant subset of memorized tuples based on the current state. In the latter stage, our LDM2 employs tree exploration to discover more suitable decision processes and enrich the memory by adding valuable state-action tuples. The dynamic circle of exploration and memory enhancement provides LDM2 a better understanding of the global environment. Extensive experiments conducted in two interactive environments have shown that our LDM2 outperforms the baselines in terms of both score and success rate, which demonstrates its effectiveness. | Xingjin Wang, Linjing Li, Daniel Dajun Zeng |  |
| 443 |  |  [ZARA: Improving Few-Shot Self-Rationalization for Small Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.310) |  | 0 | Language models (LMs) that jointly generate end-task answers as well as free-text rationales are known as self-rationalization models. Recent works demonstrate great performance gain for self-rationalization by few-shot prompting LMs with rationale-augmented exemplars. However, the ability to benefit from explanations only emerges with large-scale LMs, which have poor accessibility. In this work, we explore the less-studied setting of leveraging explanations for small LMs to improve few-shot self-rationalization. We first revisit the relationship between rationales and answers. Inspired by the implicit mental process of how human beings assess explanations, we present a novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to automatically construct pseudo-parallel data for self-training by reducing the problem of plausibility judgement to natural language inference. Experimental results show ZARA achieves SOTA performance on the FEB benchmark, for both the task accuracy and the explanation metric. In addition, we conduct human and quantitative evaluation validating ZARA’s ability to automatically identify plausible and accurate rationale-answer pairs. | WeiLin Chen, AnZi Yen, ChengKuang Wu, HenHsen Huang, HsinHsi Chen |  |
| 444 |  |  [ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation](https://doi.org/10.18653/v1/2023.findings-emnlp.311) |  | 0 | Despite remarkable advances that large language models have achieved in chatbots nowadays, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media contents, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark constructed based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference when compared to social media contents. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, ToxicChat can be a valuable resource to drive further advancements toward building a safe and healthy environment for user-AI interactions. | Zi Lin, Zihan Wang, Yongqi Tong, Yangkun Wang, Yuxin Guo, Yujia Wang, Jingbo Shang |  |
| 445 |  |  [Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments](https://doi.org/10.18653/v1/2023.findings-emnlp.312) |  | 0 | Writing strong arguments can be challenging for learners. It requires to select and arrange multiple argumentative discourse units (ADUs) in a logical and coherent way as well as to decide which ADUs to leave implicit, so called enthymemes. However, when important ADUs are missing, readers might not be able to follow the reasoning or understand the argument’s main point. This paper introduces two new tasks for learner arguments: to identify gaps in arguments (enthymeme detection) and to fill such gaps (enthymeme reconstruction). Approaches to both tasks may help learners improve their argument quality. We study how corpora for these tasks can be created automatically by deleting ADUs from an argumentative text that are central to the argument and its quality, while maintaining the text’s naturalness. Based on the ICLEv3 corpus of argumentative learner essays, we create 40,089 argument instances for enthymeme detection and reconstruction. Through manual studies, we provide evidence that the proposed corpus creation process leads to the desired quality reduction, and results in arguments that are similarly natural to those written by learners. Finally, first baseline approaches to enthymeme detection and reconstruction demonstrate the corpus’ usefulness. | Maja Stahl, Nick Düsterhus, MeiHua Chen, Henning Wachsmuth |  |
| 446 |  |  [Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.313) |  | 0 | Current variational dialog models have employed pre-trained language models (PLMs) to parameterize the likelihood and posterior distributions. However, the Gaussian assumption made on the prior distribution is incompatible with these distributions, thus restricting the diversity of generated responses. These models also suffer from posterior collapse, i.e., the decoder tends to ignore latent variables and directly access information captured in the encoder through the cross-attention mechanism. In this work, we propose Dior-CVAE, a hierarchical conditional variational autoencoder (CVAE) with diffusion priors to address these challenges. We employ a diffusion model to increase the complexity of the prior distribution and its compatibility with the distributions produced by a PLM. Also, we propose memory dropout to the cross-attention mechanism, which actively encourages the use of latent variables for response generation. Overall, experiments across two commonly used open-domain dialog datasets show that our method can generate more diverse responses without large-scale dialog pre-training. Code is available at https://github.com/UKPLab/dior-cvae. | Tianyu Yang, Thy Thy Tran, Iryna Gurevych |  |
| 447 |  |  [Retrieving Multimodal Information for Augmented Generation: A Survey](https://doi.org/10.18653/v1/2023.findings-emnlp.314) |  | 0 | As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs’ generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods’ applications and encourage them to adapt existing techniques to the fast-growing field of LLMs. | Ruochen Zhao, Hailin Chen, Weishi Wang, Fangkai Jiao, Do Xuan Long, Chengwei Qin, Bosheng Ding, Xiaobao Guo, Minzhi Li, Xingxuan Li, Shafiq Joty |  |
| 448 |  |  [Improving Contrastive Learning of Sentence Embeddings with Focal InfoNCE](https://doi.org/10.18653/v1/2023.findings-emnlp.315) |  | 0 | The recent success of SimCSE has greatly advanced state-of-the-art sentence representations. However, the original formulation of SimCSE does not fully exploit the potential of hard negative samples in contrastive learning. This study introduces an unsupervised contrastive learning framework that combines SimCSE with hard negative mining, aiming to enhance the quality of sentence embeddings. The proposed focal-InfoNCE function introduces self-paced modulation terms in the contrastive objective, downweighting the loss associated with easy negatives and encouraging the model focusing on hard negatives. Experimentation on various STS benchmarks shows that our method improves sentence embeddings in terms of Spearman’s correlation and representation alignment and uniformity. | Pengyue Hou, Xingyu Li |  |
| 449 |  |  [The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.316) |  | 0 | We present The Vault, an open-source dataset of high quality code-text pairs in multiple programming languages for training large language models to understand and generate code. We propose methods for thoroughly extracting samples that use both rules and deep learning to ensure that they contain high-quality pairs of code and text, resulting in a dataset of 43 million high-quality code-text pairs. We thoroughly evaluated this dataset and discovered that when used to train common code language models (such as CodeT5, CodeBERT, and CodeGen), it outperforms the same models train on other datasets such as CodeSearchNet. These evaluations included common coding tasks such as code generation, code summarization, and code search. The Vault can be used by researchers and practitioners to train a wide range of big language models that understand code. Alternatively, researchers can use our data cleaning methods and scripts to improve their own datasets. We anticipate that using The Vault to train large language models will improve their ability to understand and generate code, propelling AI research and software development forward. We are releasing our source code and a framework to make it easier for others to replicate our results. | Dung Nguyen Manh, Le Nam Hai, Anh T. V. Dau, Anh Minh Nguyen, Khanh Nghiem, Jin Guo, Nghi D. Q. Bui |  |
| 450 |  |  [SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes](https://doi.org/10.18653/v1/2023.findings-emnlp.317) |  | 0 | Social and behavioral determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients’ information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both “off-the-shelf” entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets. | Ádám D. Lelkes, Eric Loreaux, Tal Schuster, MingJun Chen, Alvin Rajkomar |  |
| 451 |  |  [On the Zero-Shot Generalization of Machine-Generated Text Detectors](https://doi.org/10.18653/v1/2023.findings-emnlp.318) |  | 0 | The rampant proliferation of large language models, fluent enough to generate text indistinguishable from human-written language, gives unprecedented importance to the detection of machine-generated text. This work is motivated by an important research question: How will the detectors of machine-generated text perform on outputs of a new generator, that the detectors were not trained on? We begin by collecting generation data from a wide range of LLMs, and train neural detectors on data from each generator and test its performance on held-out generators. While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version. As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models. | Xiao Pu, Jingyu Zhang, Xiaochuang Han, Yulia Tsvetkov, Tianxing He |  |
| 452 |  |  [Complex Event Schema Induction with Knowledge-Enriched Diffusion Model](https://doi.org/10.18653/v1/2023.findings-emnlp.319) |  | 0 | The concept of a complex event schema pertains to the graph structure that represents real-world knowledge of events and their multi-dimensional relationships. However, previous studies on event schema induction have been hindered by challenges such as error propagation and data quality issues. To tackle these challenges, we propose a knowledge-enriched discrete diffusion model. Specifically, we distill the abundant event scenario knowledge of Large Language Models (LLMs) through an object-oriented Python style prompt. We incorporate this knowledge into the training data, enhancing its quality. Subsequently, we employ a discrete diffusion process to generate all nodes and links simultaneously in a non-auto-regressive manner to tackle the problem of error propagation. Additionally, we devise an entity relationship prediction module to complete entity relationships between event arguments. Experimental results demonstrate that our approach achieves outstanding performance across a range of evaluation metrics. | Yupu Hao, Pengfei Cao, Yubo Chen, Kang Liu, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Jun Zhao |  |
| 453 |  |  [Exploiting Emotion-Semantic Correlations for Empathetic Response Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.320) |  | 0 | Empathetic response generation aims to generate empathetic responses by understanding the speaker’s emotional feelings from the language of dialogue. Recent methods capture emotional words in the language of communicators and construct them as static vectors to perceive nuanced emotions. However, linguistic research has shown that emotional words in language are dynamic and have correlations with other grammar semantic roles, i.e., words with semantic meanings, in grammar. Previous methods overlook these two characteristics, which easily lead to misunderstandings of emotions and neglect of key semantics. To address this issue, we propose a dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks. ESCM constructs dynamic emotion-semantic vectors through the interaction of context and emotions. We introduce dependency trees to reflect the correlations between emotions and semantics. Based on dynamic emotion-semantic vectors and dependency trees, we propose a dynamic correlation graph convolutional network to guide the model in learning context meanings in dialogue and generating empathetic responses. Experimental results on the EMPATHETIC-DIALOGUES dataset show that ESCM understands semantics and emotions more accurately and expresses fluent and informative empathetic responses. Our analysis results also indicate that the correlations between emotions and semantics are frequently used in dialogues, which is of great significance for empathetic perception and expression. | Zhou Yang, Zhaochun Ren, Yufeng Wang, Xiaofei Zhu, Zhihao Chen, Tiecheng Cai, Yunbing Wu, Yisong Su, Sibo Ju, Xiangwen Liao |  |
| 454 |  |  [Long-Range Language Modeling with Selective Cache](https://doi.org/10.18653/v1/2023.findings-emnlp.321) |  | 0 | The computational cost of transformer-based language models grows quadratically with the sequence length. In this paper, we introduce the selective cache, which stores the selected key-value pairs from the previous context. By selecting important key-value pairs the model makes better use of the cache so that in limited cache size, a longer context history can be stored. We design three kinds of selection methods. The first is based on human language processing. The key-value pairs are selected if they correspond to tokens that are fixated longer, as recorded in eye-tracking-while-reading experiments. We also incorporate the cognitively-inspired selection process into the language model as a trainable process, resulting in two additional methods with improved performance. The selection task is converted into a pruning task so they can be trained with differentiable masks. We demonstrate that the proposed selective cache improves the language modeling performance across different datasets. With the same number of stored key-value pairs (cache size), our selective cache outperforms XL cache and compressive cache by considerable margins. | Xinting Huang, Nora Hollenstein |  |
| 455 |  |  [Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding](https://doi.org/10.18653/v1/2023.findings-emnlp.322) |  | 0 | Text simplification has emerged as an increasingly useful application of AI for bridging the communication gap in specialized fields such as medicine, where the lexicon is often dominated by technical jargon and complex constructs. Despite notable progress, methods in medical simplification sometimes result in the generated text having lower quality and diversity. In this work, we explore ways to further improve the readability of text simplification in the medical domain. We propose (1) a new unlikelihood loss that encourages generation of simpler terms and (2) a reranked beam search decoding method that optimizes for simplicity, which achieve better performance on readability metrics on three datasets. This study’s findings offer promising avenues for improving text simplification in the medical field. | Lorenzo Jaime Yu Flores, Heyuan Huang, Kejian Shi, Sophie Chheang, Arman Cohan |  |
| 456 |  |  [FaLA: Fast Linear Adaptation for Replacing Backbone Models on Edge Devices](https://doi.org/10.18653/v1/2023.findings-emnlp.323) |  | 0 | In this work, we study the language model backbone replacement problem for personalized downstream tasks in a non-stationary on-device scenario. In real world, company may periodically update the knowledge and architectures of backbones to keep the competitive in the market, meanwhile, to accommodate the users’ own preference, models are personalized to fit users’ own distribution locally. Traditional full model tuning or transfer learning for such replacements often incur considerable local device training costs and necessitate extensive backpropagation within deep transformer layers. Addressing this issue, we propose a novel, lightweight tuning method for personalized NLP classification tasks post-backbone replacement. Our approach leverages a personalized matrix calculated from documents corresponding to users’ old and new backbones. This matrix facilitates top-layer parameter tuning, drastically reducing backpropagation computation. To further mitigate training costs associated with matrix linear optimization, we employ correlation clustering to curate a few examples from personalized cluster sets for individuals. Our method achieves over 1000 times computation reduction in Flops for backpropagation and brings the user-specific initialization for personal matrix yielding significant performance boost compared with popular transfer learning methods. | Shuo Huang, Lizhen Qu, Xingliang Yuan, Chunyang Chen |  |
| 457 |  |  [Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model](https://doi.org/10.18653/v1/2023.findings-emnlp.324) |  | 0 | We present a novel approach to multilingual audio-visual speech recognition tasks by introducing a single model on a multilingual dataset. Motivated by a human cognitive system where humans can intuitively distinguish different languages without any conscious effort or guidance, we propose a model that can capture which language is given as an input speech by distinguishing the inherent similarities and differences between languages. To do so, we design a prompt fine-tuning technique into the largely pre-trained audio-visual representation model so that the network can recognize the language class as well as the speech with the corresponding language. Our work contributes to developing robust and efficient multilingual audio-visual speech recognition systems, reducing the need for language-specific models. | Joanna Hong, Se Jin Park, Yong Man Ro |  |
| 458 |  |  [Controllable Chest X-Ray Report Generation from Longitudinal Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.325) |  | 0 | Radiology reports are detailed text descriptions of the content of medical scans. Each report describes the presence/absence and location of relevant clinical findings, commonly including comparison with prior exams of the same patient to describe how they evolved. Radiology reporting is a time-consuming process, and scan results are often subject to delays. One strategy to speed up reporting is to integrate automated reporting systems, however clinical deployment requires high accuracy and interpretability. Previous approaches to automated radiology reporting generally do not provide the prior study as input, precluding comparison which is required for clinical accuracy in some types of scans, and offer only unreliable methods of interpretability. Therefore, leveraging an existing visual input format of anatomical tokens, we introduce two novel aspects: (1) longitudinal representation learning – we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout – a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input. We show through in-depth experiments on the MIMIC-CXR dataset how the proposed approach achieves state-of-the-art results while enabling anatomy-wise controllable report generation. | Francesco Dalla Serra, Chaoyang Wang, Fani Deligianni, Jeff Dalton, Alison O'Neil |  |
| 459 |  |  [Is ChatGPT a Good Multi-Party Conversation Solver?](https://doi.org/10.18653/v1/2023.findings-emnlp.326) |  | 0 | Large Language Models (LLMs) have emerged as influential instruments within the realm of natural language processing; nevertheless, their capacity to handle multi-party conversations (MPCs) – a scenario marked by the presence of multiple interlocutors involved in intricate information exchanges – remains uncharted. In this paper, we delve into the potential of generative LLMs such as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by subjecting them to evaluation across three MPC datasets that encompass five representative tasks. The findings reveal that ChatGPT’s performance on a number of evaluated MPC tasks leaves much to be desired, whilst GPT-4’s results portend a promising future. Additionally, we endeavor to bolster performance through the incorporation of MPC structures, encompassing both speaker and addressee architecture. This study provides an exhaustive evaluation and analysis of applying generative LLMs to MPCs, casting a light upon the conception and creation of increasingly effective and robust MPC agents. Concurrently, this work underscores the challenges implicit in the utilization of LLMs for MPCs, such as deciphering graphical information flows and generating stylistically consistent responses. | ChaoHong Tan, JiaChen Gu, ZhenHua Ling |  |
| 460 |  |  [Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis](https://doi.org/10.18653/v1/2023.findings-emnlp.327) |  | 0 | Training a high performance end-to-end speech (E2E) processing model requires an enormous amount of labeled speech data, especially in the era of data-centric artificial intelligence. However, labeled speech data are usually scarcer and more expensive for collection, compared to textual data. We propose Latent Synthesis (LaSyn), an efficient textual data utilization framework for E2E speech processing models. We train a latent synthesizer to convert textual data into an intermediate latent representation of a pre-trained speech model. These pseudo acoustic representations of textual data augment acoustic data for model training. We evaluate LaSyn on low-resource automatic speech recognition (ASR) and spoken language understanding (SLU) tasks. For ASR, LaSyn improves an E2E baseline trained on LibriSpeech train-clean-100, with relative word error rate reductions over 22.3% on different test sets. For SLU, LaSyn improves our E2E baseline by absolute 4.1% for intent classification accuracy and 3.8% for slot filling SLU-F1 on SLURP, and absolute 4.49% and 2.25% for exact match (EM) and EM-Tree accuracies on STOP respectively. With fewer parameters, the results of LaSyn are competitive to published state-of-the-art works. The results demonstrate the quality of the augmented training data. | Jianqiao Lu, Wenyong Huang, Nianzu Zheng, Xingshan Zeng, Yu Ting Yeung, Xiao Chen |  |
| 461 |  |  [Bipartite Graph Pre-training for Unsupervised Extractive Summarization with Graph Convolutional Auto-Encoders](https://doi.org/10.18653/v1/2023.findings-emnlp.328) |  | 0 | Pre-trained sentence representations are crucial for identifying significant sentences in unsupervised document extractive summarization. However, the traditional two-step paradigm of pre-training and sentence-ranking, creates a gap due to differing optimization objectives. To address this issue, we argue that utilizing pre-trained embeddings derived from a process specifically designed to optimize informative and distinctive sentence representations helps rank significant sentences. To do so, we propose a novel graph pre-training auto-encoder to obtain sentence embeddings by explicitly modelling intra-sentential distinctive features and inter-sentential cohesive features through sentence-word bipartite graphs. These fine-tuned sentence embeddings are then utilized in a graph-based ranking algorithm for unsupervised summarization. Our method is a plug-and-play pre-trained model that produces predominant performance for unsupervised summarization frameworks by providing summary-worthy sentence representations. It surpasses heavy BERT- or RoBERTa-based sentence representations in downstream tasks. | Qianren Mao, Shaobo Zhao, Jiarui Li, Xiaolei Gu, Shizhu He, Bo Li, Jianxin Li |  |
| 462 |  |  [Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.329) |  | 0 | Prompt tuning, in which prompts are optimized to adapt large-scale pre-trained language models to downstream tasks instead of fine-tuning the full model parameters, has been shown to be particularly effective when the prompts are trained in the multi-task transfer learning setting. These methods generally involve individually training prompts for each source task and then aggregating them to provide the initialization of the prompt for the target task. However, this approach critically ignores the fact that some of the source tasks could be negatively or positively interfering with each other. We argue that when we extract knowledge from source tasks via training source prompts, we need to consider this correlation among source tasks for better transfer to target tasks. To this end, we propose a Bayesian approach where we work with the posterior distribution of prompts across source tasks. We obtain representative source prompts corresponding to the samples from the posterior utilizing Stein Variational Gradient Descent, which are then aggregated to constitute the initial target prompt. We show extensive experimental results on the standard benchmark NLP tasks, where our Bayesian multi-task transfer learning approach outperforms the state-of-the-art methods in many settings. Furthermore, our approach requires no auxiliary models other than the prompt itself, achieving high degree of parameter-efficiency. | Haeju Lee, Minchan Jeong, SeYoung Yun, KeeEung Kim |  |
| 463 |  |  [CCIM: Cross-modal Cross-lingual Interactive Image Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.330) |  | 0 | Text image machine translation (TIMT) which translates source language text images into target language texts has attracted intensive attention in recent years. Although the end-to-end TIMT model directly generates target translation from encoded text image features with an efficient architecture, it lacks the recognized source language information resulting in a decrease in translation performance. In this paper, we propose a novel Cross-modal Cross-lingual Interactive Model (CCIM) to incorporate source language information by synchronously generating source language and target language results through an interactive attention mechanism between two language decoders. Extensive experimental results have shown the interactive decoder significantly outperforms end-to-end TIMT models and has faster decoding speed with smaller model size than cascade models. | Cong Ma, Yaping Zhang, Mei Tu, Yang Zhao, Yu Zhou, Chengqing Zong |  |
| 464 |  |  [TRAMS: Training-free Memory Selection for Long-range Language Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.331) |  | 0 | The Transformer architecture is crucial for numerous AI models, but it still faces challenges in long-range language modeling. Though several specific transformer architectures have been designed to tackle issues of long-range dependencies, existing methods like Transformer-XL are plagued by a high percentage of ineffective memories. In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric. This strategy allows us to keep tokens that are likely to have a high attention score with the current queries and ignore the other ones. We have tested our approach on the word-level benchmark (WikiText-103) and the character-level benchmark (enwik8), and the results indicate an improvement without having additional training or adding additional parameters. | Haofei Yu, Cunxiang Wang, Yue Zhang, Wei Bi |  |
| 465 |  |  [A Critical Analysis of Document Out-of-Distribution Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.332) |  | 0 | Large-scale pre-training is widely used in recent document understanding tasks. During deployment, one may expect that models should trigger a conservative fallback policy when encountering out-of-distribution (OOD) samples, which highlights the importance of OOD detection. However, most existing OOD detection methods focus on single-modal inputs such as images or texts. While documents are multi-modal in nature, it is underexplored if and how multi-modal information in documents can be exploited for OOD detection. In this work, we first provide a systematic and in-depth analysis on OOD detection for document understanding models. We study the effects of model modality, pre-training, and fine-tuning across various types of OOD inputs. In particular, we find that spatial information is critical for document OOD detection. To better exploit spatial information, we propose a spatial-aware adapter, which serves as a parameter-efficient add-on module to adapt transformer-based language models to the document domain. Extensive experiments show that adding the spatial-aware adapter significantly improves the OOD detection performance compared to directly using the language model and achieves superior performance compared to competitive baselines. | Jiuxiang Gu, Yifei Ming, Yi Zhou, Jason Kuen, Vlad I. Morariu, Handong Zhao, Ruiyi Zhang, Nikolaos Barmpalios, Anqi Liu, Yixuan Li, Tong Sun, Ani Nenkova |  |
| 466 |  |  [Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.333) |  | 0 | Improving neural machine translation (NMT) systems with prompting has achieved significant progress in recent years. In this work, we focus on how to integrate multi-knowledge, multiple types of knowledge, into NMT models to enhance the performance with prompting. We propose a unified framework, which can integrate effectively multiple types of knowledge including sentences, terminologies/phrases and translation templates into NMT models. We utilize multiple types of knowledge as prefix-prompts of input for the encoder and decoder of NMT models to guide the translation process. The approach requires no changes to the model architecture and effectively adapts to domain-specific translation without retraining. The experiments on English-Chinese and English-German translation demonstrate that our approach significantly outperform strong baselines, achieving high translation quality and terminology match accuracy. | Ke Wang, Jun Xie, Yuqi Zhang, Yu Zhao |  |
| 467 |  |  [Active Learning Principles for In-Context Learning with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.334) |  | 0 | The remarkable advancements in large language models (LLMs) have significantly enhanced predictive performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively perform the task at hand through in-context learning. However, the process of selecting demonstrations for maximizing performance has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based Active Learning (AL) problem over a single iteration. We compare standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Our extensive experimentation involving a diverse range of GPT and OPT models across 24 classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates the importance of using demonstrations that are semantically similar to the domain of the test examples. In fact, we show higher average classification performance using “similar” demonstrations with GPT-2 (124M) than random demonstrations with GPT-Neox (20B). Notably, while diversity sampling shows promise, uncertainty sampling, despite its success in conventional supervised learning AL scenarios, performs poorly in in-context learning. | Katerina Margatina, Timo Schick, Nikolaos Aletras, Jane DwivediYu |  |
| 468 |  |  [InteMATs: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.335) |  | 0 | Multilingual language models (MLLMs) have achieved remarkable success in various cross-lingual transfer tasks. However, they suffer poor performance in zero-shot low-resource languages, particularly when dealing with longer contexts. Existing research mainly relies on full-model fine-tuning on large parallel datasets to enhance the cross-lingual alignment of MLLMs, which is computationally expensive. In this paper, we propose InteMATs, a novel approach that integrates multilingual adapters trained on texts of different levels of granularity. To achieve this, we curate a multilingual parallel dataset comprising 42 languages to pre-train sentence-level and document-level adapters under the contrastive learning framework. Extensive experiments demonstrate the effectiveness of InteMATs in improving the cross-lingual transfer performance of MLLMs, especially on low-resource languages. Finally, our comprehensive analyses and ablation studies provide a deep understanding of the high-quality representations derived by InteMATs. | Meizhen Liu, Xu Guo, Jiakai He, Jianye Chen, Fengyu Zhou, Siu Cheung Hui |  |
| 469 |  |  [PlugMed: Improving Specificity in Patient-Centered Medical Dialogue Generation using In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.336) |  | 0 | The patient-centered medical dialogue systems strive to offer diagnostic interpretation services to users who are less knowledgeable about medical knowledge, through emphasizing the importance of providing responses specific to the patients. It is difficult for the large language models (LLMs) to guarantee the specificity of responses in spite of its promising performance even in some tasks in medical field. Inspired by in-context learning, we propose PlugMed, a Plug-and-Play Medical Dialogue System, for addressing this challenge. PlugMed is equipped with two modules, the prompt generation (PG) module and the response ranking (RR) module, to enhances LLMs’ dialogue strategies for improving the specificity of the dialogue. The PG module is designed to stimulate the imitative ability of LLMs by providing them with real dialogues from similar patients as prompts. The RR module incorporates fine-tuned small model as response filter to enable the selection of appropriate responses generated by LLMs. Furthermore, we introduce a new evaluation method based on matching both user’s intent and high-frequency medical term to effectively assess the specificity of the responses. We conduct experimental evaluations on three medical dialogue datasets, and the results, including both automatic and human evaluation, demonstrate the effectiveness of our approach. | Chengfeng Dou, Zhi Jin, Wenpin Jiao, Haiyan Zhao, Yongqiang Zhao, Zhengwei Tao |  |
| 470 |  |  [CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.337) |  | 0 | Recent code translation techniques exploit neural machine translation models to translate source code from one programming language to another to satisfy production compatibility or to improve efficiency of codebase maintenance. Most existing code translation datasets only focus on a single pair of popular programming languages. To advance research on code translation and meet diverse requirements of real-world applications, we construct \*\*CodeTransOcean\*\*, a large-scale comprehensive benchmark that supports the largest variety of programming languages for code translation. CodeTransOcean consists of three novel multilingual datasets, namely, \*\*MultilingualTrans\*\* supporting translations between multiple popular programming languages, \*\*NicheTrans\*\* for translating between niche programming languages and popular ones, and \*\*LLMTrans\*\* for evaluating executability of translated code by large language models (LLMs). CodeTransOcean also includes a novel cross-framework dataset, \*\*DLTrans\*\*, for translating deep learning code across different frameworks. We develop multilingual modeling approaches for code translation and demonstrate their great potential in improving the translation quality of both low-resource and high-resource language pairs and boosting the training efficiency. We also propose a novel evaluation metric \*\*Debugging Success Rate@K\*\* for program-level code translation. Last but not least, we evaluate LLM ChatGPT on our datasets and investigate its potential for fuzzy execution predictions. We build baselines for CodeTransOcean and analyze challenges of code translation for guiding future research. The CodeTransOcean datasets and code are publicly available at https://github.com/WeixiangYAN/CodeTransOcean. | Weixiang Yan, Yuchen Tian, Yunzhe Li, Qian Chen, Wen Wang |  |
| 471 |  |  [impact of sample selection on in-context learning for entity extraction from scientific writing](https://doi.org/10.18653/v1/2023.findings-emnlp.338) |  | 0 | Prompt-based usage of Large Language Models (LLMs) is an increasingly popular way to tackle many well-known natural language problems. This trend is due, in part, to the appeal of the In-Context Learning (ICL) prompt set-up, in which a few selected training examples are provided along with the inference request. ICL, a type of few-shot learning, is especially attractive for natural language processing (NLP) tasks defined for specialised domains, such as entity extraction from scientific documents, where the annotation is very costly due to expertise requirements for the annotators. In this paper, we present a comprehensive analysis of in-context sample selection methods for entity extraction from scientific documents using GPT-3.5 and compare these results against a fully supervised transformer-based baseline. Our results indicate that the effectiveness of the in-context sample selection methods is heavily domain-dependent, but the improvements are more notable for problems with a larger number of entity types. More in-depth analysis shows that ICL is more effective for low-resource set-ups of scientific information extraction | Necva Bölücü, Maciej Rybinski, Stephen Wan |  |
| 472 |  |  [Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models](https://doi.org/10.18653/v1/2023.findings-emnlp.339) |  | 0 | Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language’s evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43% relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild. | Luiza Pozzobon, Beyza Ermis, Patrick Lewis, Sara Hooker |  |
| 473 |  |  [Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks](https://doi.org/10.18653/v1/2023.findings-emnlp.340) |  | 0 | We investigate MT evaluation metric performance on adversarially-synthesized texts, to shed light on metric robustness. We experiment with word- and character-level attacks on three popular machine translation metrics: BERTScore, BLEURT, and COMET. Our human experiments validate that automatic metrics tend to overpenalize adversarially-degraded translations. We also identify inconsistencies in BERTScore ratings, where it judges the original sentence and the adversarially-degraded one as similar, while judging the degraded translation as notably worse than the original with respect to the reference. We identify patterns of brittleness that motivate more robust metric development. | Yichen Huang, Timothy Baldwin |  |
| 474 |  |  [Time-Considerable Dialogue Models via Reranking by Time Dependency](https://doi.org/10.18653/v1/2023.findings-emnlp.341) |  | 0 | In the last few years, generative dialogue models have shown excellent performance and have been used for various applications. As chatbots become more prevalent in our daily lives, more and more people expect them to behave more like humans, but existing dialogue models do not consider the time information that people are constantly aware of. In this paper, we aim to construct a time-considerable dialogue model that actively utilizes time information. First, we categorize responses by their naturalness at different times and introduce a new metric to classify responses into our categories. Then, we propose a new reranking method to make the existing dialogue model time-considerable using the proposed metric and subjectively evaluate the performances of the obtained time-considerable dialogue models by humans. | Yuiko Tsunomori, Masakazu Ishihata, Hiroaki Sugiyama |  |
| 475 |  |  [Non-Compositionality in Sentiment: New Data and Analyses](https://doi.org/10.18653/v1/2023.findings-emnlp.342) |  | 0 | When natural language phrases are combined, their meaning is often more than the sum of their parts. In the context of NLP tasks such as sentiment analysis, where the meaning of a phrase is its sentiment, that still applies. Many NLP studies on sentiment analysis, however, focus on the fact that sentiment computations are largely compositional. We, instead, set out to obtain non-compositionality ratings for phrases with respect to their sentiment. Our contributions are as follows: a) a methodology for obtaining those non-compositionality ratings, b) a resource of ratings for 259 phrases – NonCompSST – along with an analysis of that resource, and c) an evaluation of computational models for sentiment analysis using this new resource. | Verna Dankers, Christopher Lucas |  |
| 476 |  |  [MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.343) |  | 0 | The large language models have achieved superior performance on various natural language tasks. One major drawback of such approaches is they are resource-intensive in fine-tuning new datasets. Soft-prompt tuning presents a resource-efficient solution to fine-tune the pre-trained language models (PLMs) while keeping their weight frozen. Existing soft prompt methods mainly focus on designing the input-independent prompts that steer the model to fit the domain of the new dataset. Those methods often ignore the fine-grained information about the task and context of the text. In this paper, we propose a multi-level prompt tuning (MPrompt) method for machine reading comprehension. It utilizes prompts at task-specific, domain-specific, and context-specific levels to enhance the comprehension of input semantics at different granularities. We also propose an independence constraint to steer each domain-specific prompt to focus on information within its domain to avoid redundancy. Moreover, we present a prompt generator that incorporates context-related knowledge in the prompt generation to enhance contextual relevancy. We conducted extensive experiments on 12 benchmarks of various QA formats and achieved an average improvement of 1.94% over the state-of-the-art methods. | Guoxin Chen, Yiming Qian, Bowen Wang, Liangzhi Li |  |
| 477 |  |  [DocTrack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading](https://doi.org/10.18653/v1/2023.findings-emnlp.344) |  | 0 | The use of visually-rich documents in various fields has created a demand for Document AI models that can read and comprehend documents like humans, which requires the overcoming of technical, linguistic, and cognitive barriers. Unfortunately, the lack of appropriate datasets has significantly hindered advancements in the field. To address this issue, we introduce DocTrack, a visually-rich document dataset really aligned with human eye-movement information using eye-tracking technology. This dataset can be used to investigate the challenges mentioned above. Additionally, we explore the impact of human reading order on document understanding tasks and examine what would happen if a machine reads in the same order as a human. Our results suggest that although Document AI models have made significant progresses, they still have a long way to go before they can read visually richer documents as accurately, continuously, and flexibly as humans do. These findings have potential implications for future research and development of document intelligence. | Hao Wang, Qingxuan Wang, Yue Li, Changqing Wang, Chenhui Chu, Rui Wang |  |
| 478 |  |  [Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.345) |  | 0 | Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. \*Selective prediction\* is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%. | Jiefeng Chen, Jinsung Yoon, Sayna Ebrahimi, Sercan Ö. Arik, Tomas Pfister, Somesh Jha |  |
| 479 |  |  [Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization](https://doi.org/10.18653/v1/2023.findings-emnlp.346) |  | 0 | Pretrained language models have achieved remarkable success in natural language understanding. However, fine-tuning pretrained models on limited training data tends to overfit and thus diminish performance. This paper presents Bi-Drop, a fine-tuning strategy that selectively updates model parameters using gradients from various sub-nets dynamically generated by dropout. The sub-net estimation of Bi-Drop is performed in an in-batch manner, so it overcomes the problem of hysteresis in sub-net updating, which is possessed by previous methods that perform asynchronous sub-net estimation. Also, Bi-Drop needs only one mini-batch to estimate the sub-net so it achieves higher utility of training data. Experiments on the GLUE benchmark demonstrate that Bi-Drop consistently outperforms previous fine-tuning methods. Furthermore, empirical results also show that Bi-Drop exhibits excellent generalization ability and robustness for domain transfer, data imbalance, and low-resource scenarios. | Shoujie Tong, Heming Xia, Damai Dai, Runxin Xu, Tianyu Liu, Binghuai Lin, Yunbo Cao, Zhifang Sui |  |
| 480 |  |  [ClozEx: A Task toward Generation of English Cloze Explanation](https://doi.org/10.18653/v1/2023.findings-emnlp.347) |  | 0 | Providing explanations for cloze questions in language assessment (LA) has been recognized as a valuable approach to enhancing the language proficiency of learners. However, there is a noticeable absence of dedicated tasks and datasets specifically designed for generating language learner explanations. In response to this gap, this paper introduces a novel task ClozEx of generating explanations for cloze questions in LA, with a particular focus on English as a Second Language (ESL) learners. To support this task, we present a meticulously curated dataset comprising cloze questions paired with corresponding explanations. This dataset aims to assess language proficiency and facilitates language learning by offering informative and accurate explanations. To tackle the task, we fine-tuned various baseline models with our training data, including encoder-decoder and decoder-only architectures. We also explored whether large language models (LLMs) are able to generate good explanations without fine-tuning, just using pre-defined prompts. The evaluation results demonstrate that encoder-decoder models have the potential to deliver fluent and valid explanations when trained on our dataset. | Zizheng Zhang, Masato Mita, Mamoru Komachi |  |
| 481 |  |  [Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces](https://doi.org/10.18653/v1/2023.findings-emnlp.348) |  | 0 | The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal. This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space. However, the involvement of a trainable classifier leads to entanglement between the probe’s results and the classifier’s nature. As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space. We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces. We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes. We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations. | Tal Levy, Omer Goldman, Reut Tsarfaty |  |
| 482 |  |  [The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.349) |  | 0 | Compressing large language models (LLMs), often consisting of billions of parameters, provides faster inference, smaller memory footprints, and enables local deployment. The standard compression techniques are pruning and quantization, with the former eliminating redundant connections in model layers and the latter representing model parameters with as little as 4 bits. The key tradeoff is between the degree of compression and the impact on the quality of the compressed model. Existing research on LLM compression primarily focuses on performance in terms of general metrics like perplexity or downstream task accuracy. More fine-grained metrics, such as those measuring parametric knowledge, remain significantly underexplored. To help bridge this gap, we present a comprehensive analysis across multiple model families using the LAMA and LM-Harness benchmarks in order to systematically quantify the effect of commonly employed compression techniques on model performance. A particular focus is on tradeoffs involving parametric knowledge, with the goal of providing practitioners with practical insights to make informed decisions on compression. | Satya Sai Srinath Namburi, Makesh Sreedhar, Srinath Srinivasan, Frederic Sala |  |
| 483 |  |  [CoEdIT: Text Editing by Task-Specific Instruction Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.350) |  | 0 | We introduce CoEdIT, a state-of-the-art text editing system for writing assistance. CoEdIT takes instructions from the user specifying the attributes of the desired text, such as “Make the sentence simpler” or “Write it in a more neutral style,” and outputs the edited text. We present a large language model fine-tuned on a diverse collection of task-specific instructions for text editing (a total of 82K instructions). Our model (1) achieves state-of-the-art performance on various text editing benchmarks, (2) is competitive with publicly available largest-sized LLMs trained on instructions while being ~60x smaller, (3) is capable of generalizing to unseen edit instructions, and (4) exhibits abilities to generalize to composite instructions containing different combinations of edit actions. Through extensive qualitative and quantitative analysis, we show that writers prefer the edits suggested by CoEdIT relative to other state-of-the-art text editing models. Our code, data, and models are publicly available at https://github.com/vipulraheja/coedit. | Vipul Raheja, Dhruv Kumar, Ryan Koo, Dongyeop Kang |  |
| 484 |  |  [Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.351) |  | 0 | Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs’ hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art. | Yi Dai, Hao Lang, Kaisheng Zeng, Fei Huang, Yongbin Li |  |
| 485 |  |  [Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information](https://doi.org/10.18653/v1/2023.findings-emnlp.352) |  | 0 | Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection. | Alla Chepurova, Aydar Bulatov, Yuri Kuratov, Mikhail Burtsev |  |
| 486 |  |  [DeltaScore: Fine-Grained Story Evaluation with Perturbations](https://doi.org/10.18653/v1/2023.findings-emnlp.353) |  | 0 | Numerous evaluation metrics have been developed for natural language generation tasks, but their effectiveness in evaluating stories is limited as they are not specifically tailored to assess intricate aspects of storytelling, such as fluency and interestingness. In this paper, we introduce DeltaScore, a novel methodology that uses perturbation techniques for the evaluation of nuanced story aspects. We posit that the extent to which a story excels in a specific aspect (e.g., fluency) correlates with the magnitude of its susceptibility to particular perturbations (e.g., the introduction of typos). Given this, we measure the quality of an aspect by calculating the likelihood difference between pre- and post-perturbation states using pre-trained language models. We compare DeltaScore with existing metrics on storytelling datasets from two domains in five fine-grained story aspects: fluency, coherence, relatedness, logicality, and interestingness. DeltaScore demonstrates strong performance, revealing a surprising finding that one specific perturbation proves highly effective in capturing multiple aspects. Source code is available on our GitHub repository. | Zhuohan Xie, Miao Li, Trevor Cohn, Jey Han Lau |  |
| 487 |  |  [MuG: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields](https://doi.org/10.18653/v1/2023.findings-emnlp.354) |  | 0 | Previous research has demonstrated the advantages of integrating data from multiple sources over traditional unimodal data, leading to the emergence of numerous novel multimodal applications. We propose a multimodal classification benchmark MuG with eight datasets that allows researchers to evaluate and improve their models. These datasets are collected from four various genres of games that cover tabular, textual, and visual modalities. We conduct multi-aspect data analysis to provide insights into the benchmark, including label balance ratios, percentages of missing features, distributions of data within each modality, and the correlations between labels and input modalities. We further present experimental results obtained by several state-of-the-art unimodal classifiers and multimodal classifiers, which demonstrate the challenging and multimodal-dependent properties of the benchmark. MuG is released at https://github.com/lujiaying/MUG-Bench with the data, tutorials, and implemented baselines. | Jiaying Lu, Yongchen Qian, Shifan Zhao, Yuanzhe Xi, Carl Yang |  |
| 488 |  |  [Don't waste a single annotation: improving single-label classifiers through soft labels](https://doi.org/10.18653/v1/2023.findings-emnlp.355) |  | 0 | In this paper, we address the limitations of the common data annotation and training methods for objective single-label classification tasks. Typically, when annotating such tasks annotators are only asked to provide a single label for each sample and annotator disagreement is discarded when a final hard label is decided through majority voting. We challenge this traditional approach, acknowledging that determining the appropriate label can be difficult due to the ambiguity and lack of context in the data samples. Rather than discarding the information from such ambiguous annotations, our soft label method makes use of them for training. Our findings indicate that additional annotator information, such as confidence, secondary label and disagreement, can be used to effectively generate soft labels. Training classifiers with these soft labels then leads to improved performance and calibration on the hard label test set. | Ben Wu, Yue Li, Yida Mu, Carolina Scarton, Kalina Bontcheva, Xingyi Song |  |
| 489 |  |  [Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation](https://doi.org/10.18653/v1/2023.findings-emnlp.356) |  | 0 | Parameter-efficient fine-tuning (PEFT) methods have provided an effective way for adapting large vision-language models to specific tasks or scenarios. Typically, they learn a very small scale of parameters for pre-trained models in a white-box formulation, which assumes model architectures to be known and parameters to be accessible. However, large models are often not open-source due to considerations of preventing abuse or commercial factors, hence posing a barrier to the deployment of white-box PEFT methods. To alleviate the dependence on model accessibility, we introduce collaborative black-box tuning (CBBT) for both textual prompt optimization and output feature adaptation for black-box models. Specifically, considering that the backpropagation gradients are blocked, we approximate the gradients of textual prompts by analyzing the predictions with perturbed prompts. Secondly, a lightweight adapter is deployed over the output feature of the inaccessible model, further facilitating the model adaptation process. Empowered with these designs, our CBBT is extensively evaluated on eleven downstream benchmarks and achieves remarkable improvements compared to existing black-box VL adaptation methods. Our code will be made publicly available. | Zixian Guo, Yuxiang Wei, Ming Liu, Zhilong Ji, Jinfeng Bai, Yiwen Guo, Wangmeng Zuo |  |
| 490 |  |  [How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey](https://doi.org/10.18653/v1/2023.findings-emnlp.357) |  | 0 | Transferability estimation has been attached to great attention in the computer vision fields. Researchers try to estimate with low computational cost the performance of a model when transferred from a source task to a given target task. Considering the effectiveness of such estimations, the communities of natural language processing also began to study similar problems for the selection of pre-trained language models. However, there is a lack of a comprehensive comparison between these estimation methods yet. Also, the differences between vision and language scenarios make it doubtful whether previous conclusions can be established across fields. In this paper, we first conduct a thorough survey of existing transferability estimation methods being able to find the most suitable model, then we conduct a detailed empirical study for the surveyed methods based on the GLUE benchmark. From qualitative and quantitative analyses, we demonstrate the strengths and weaknesses of existing methods and show that H-Score generally performs well with superiorities in effectiveness and efficiency. We also outline the difficulties of consideration of training details, applicability to text generation, and consistency to certain metrics which shed light on future directions. | Jun Bai, Xiaofeng Zhang, Chen Li, Hanhua Hong, Xi Xu, Chenghua Lin, Wenge Rong |  |
| 491 |  |  [Licon: A Diverse, Controllable and Challenging Linguistic Concept Learning Benchmark](https://doi.org/10.18653/v1/2023.findings-emnlp.358) |  | 0 | Concept Learning requires learning the definition of a general category from given training examples. Most of the existing methods focus on learning concepts from images. However, the visual information cannot present abstract concepts exactly, which struggles the introduction of novel concepts related to known concepts (e.g., ‘Plant’→‘Asteroids’). In this paper, inspired by the fact that humans learn most concepts through linguistic description, we introduce Linguistic Concept Learning benchmark (Licon), where concepts in diverse forms (e.g., plain attributes, images, and text) are defined by linguistic descriptions. The difficulty to learn novel concepts can be controlled by the number of attributes or the hierarchical relationships between concepts. The diverse and controllable concepts are used to support challenging evaluation tasks, including concept classification, attribute prediction, and concept relationship recognition. In addition, we design an entailment-based concept learning method (EnC) to model the relationship among concepts. Extensive experiments demonstrate the effectiveness of EnC. The benchmark will be released to the public soon. | Shenglong Yu, Ying Zhang, Wenya Guo, Zhengkun Zhang, Ru Zhou, Xiaojie Yuan |  |
| 492 |  |  [InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations](https://doi.org/10.18653/v1/2023.findings-emnlp.359) |  | 0 | While recently developed NLP explainability methods let us open the black box in various ways (Madsen et al., 2022), a missing ingredient in this endeavor is an interactive tool offering a conversational interface. Such a dialogue system can help users explore datasets and models with explanations in a contextualized manner, e.g. via clarification or follow-up questions, and through a natural language interface. We adapt the conversational explanation framework TalkToModel (Slack et al., 2022) to the NLP domain, add new NLP-specific operations such as free-text rationalization, and illustrate its generalizability on three NLP tasks (dialogue act classification, question answering, hate speech detection). To recognize user queries for explanations, we evaluate fine-tuned and few-shot prompting models and implement a novel adapter-based approach. We then conduct two user studies on (1) the perceived correctness and helpfulness of the dialogues, and (2) the simulatability, i.e. how objectively helpful dialogical explanations are for humans in figuring out the model’s predicted label when it’s not shown. We found rationalization and feature attribution were helpful in explaining the model behavior. Moreover, users could more reliably predict the model outcome based on an explanation dialogue rather than one-off explanations. | Nils Feldhus, Qianli Wang, Tatiana Anikina, Sahil Chopra, Cennet Oguz, Sebastian Möller |  |
| 493 |  |  [INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations](https://doi.org/10.18653/v1/2023.findings-emnlp.360) |  | 0 | Recent advancements in Large language models (LLMs) have enabled them to hold free form conversations over multiple turns, but they exhibit a tendency to make unfounded and incorrect statements, commonly known as hallucinations. In particular, LLMs hallucinate frequently when given invalid questions, i.e. ones with incorrect assumptions. The most common approach to evaluate LLMs on hallucinations is to test them on Question Answering (QA) test sets such as TruthfulQA. However, LLMs are increasingly pretrained on massive text corpora scraped from the Internet, which may inevitably expose these test sets to the model during training, leading eventually to an overestimation of model performances on these test sets. In this work, we present an alternative framework to address this risk and to foster further research towards making LLMs robust against invalid questions. We name our framework INVITE: a testbed of automatically generated INValId questions to evaluaTE large language models for hallucinations. In each instantiation, our framework is set up to create a fresh batch of invalid questions by distorting valid facts in which subjects or objects are replaced by similar entities. We evaluate several state of the art LLMs against a testset generated by our framework and highlight its capacity to trigger hallucinations in these models. | Anil Ramakrishna, Rahul Gupta, Jens Lehmann, Morteza Ziyadi |  |
| 494 |  |  [Multimodal Automated Fact-Checking: A Survey](https://doi.org/10.18653/v1/2023.findings-emnlp.361) |  | 0 | Misinformation is often conveyed in multiple modalities, e.g. a miscaptioned image. Multimodal misinformation is perceived as more credible by humans, and spreads faster than its text-only counterparts. While an increasing body of research investigates automated fact-checking (AFC), previous surveys mostly focus on text. In this survey, we conceptualise a framework for AFC including subtasks unique to multimodal misinformation. Furthermore, we discuss related terms used in different communities and map them to our framework. We focus on four modalities prevalent in real-world fact-checking: text, image, audio, and video. We survey benchmarks and models, and discuss limitations and promising directions for future research | Mubashara Akhtar, Michael Sejr Schlichtkrull, Zhijiang Guo, Oana Cocarascu, Elena Simperl, Andreas Vlachos |  |
| 495 |  |  [PROTEGE: Prompt-based Diverse Question Generation from Web Articles](https://doi.org/10.18653/v1/2023.findings-emnlp.362) |  | 0 | Rich and diverse knowledge bases (KB) are foundational building blocks for online knowledge sharing communities such as StackOverflow and Quora, and applications such as conversational assistants (aka chatbots). A popular format for knowledge bases is question-answer pairs (or FAQs), where questions are designed to accurately match a multitude of queries. In this paper, we address the problem of automatic creation of such Q&A-based knowledge bases from domain-specific, long-form textual content (e.g., web articles). Specifically, we consider the problem of question generation, which is the task of generating questions given a paragraph of text as input, with a goal to achieve both diversity and fidelity of the generated questions. Towards this goal we propose PROTEGE, a diverse question generation framework which consists of (1) a novel encoder-decoder based Large Language Model (LLM) architecture which can take a variety of prompts and generate a diverse set of candidate questions, and (2) a hill-climbing algorithm that maximizes a sub-modular objective function to balance diversity with fidelity. Through our experiments on three popular public Q&A datasets, we demonstrate that PROTEGE improves diversity by +16% and fidelity by +8% over diverse beam search and prompt-based baselines. | Vinayak Puranik, Anirban Majumder, Vineet Chaoji |  |
| 496 |  |  [GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions](https://doi.org/10.18653/v1/2023.findings-emnlp.363) |  | 0 | There is growing interest in systems that generate captions for scientific figures. However, assessing these systems’ output poses a significant challenge. Human evaluation requires academic expertise and is costly, while automatic evaluation depends on often low-quality author-written captions. This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions. We first constructed SCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600 scientific figure captions, both original and machine-made, for 600 arXiv figures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption based on its potential to aid reader understanding, given relevant context such as figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot evaluator, outperformed all other models and even surpassed assessments made by computer science undergraduates, achieving a Kendall correlation score of 0.401 with Ph.D. students’ rankings. | TingYao Hsu, ChiehYang Huang, Ryan A. Rossi, Sungchul Kim, C. Lee Giles, TingHao Kenneth Huang |  |
| 497 |  |  [Mulan: A Multi-Level Alignment Model for Video Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.364) |  | 0 | Video Question Answering (VideoQA) aims to answer questions about the visual content of a video. Current methods mainly focus on improving joint representations of video and text. However, these methods pay little attention to the fine-grained semantic interaction between video and text. In this paper, we propose Mulan: a Multi-Level Alignment Model for Video Question Answering, which establishes alignment between visual and textual modalities at the object-level, frame-level, and video-level. Specifically, for object-level alignment, we propose a mask-guided visual feature encoding method and a visual-guided text description method to learn fine-grained spatial information. For frame-level alignment, we introduce the use of visual features from individual frames, combined with a caption generator, to learn overall spatial information within the scene. For video-level alignment, we propose an expandable ordinal prompt for textual descriptions, combined with visual features, to learn temporal information. Experimental results show that our method outperforms the state-of-the-art methods, even when utilizing the smallest amount of extra visual-language pre-training data and a reduced number of trainable parameters. | Yu Fu, Cong Cao, Yuling Yang, Yuhai Lu, Fangfang Yuan, Dakui Wang, Yanbing Liu |  |
| 498 |  |  [HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.365) |  | 0 | With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, \*\*HARE\*\*, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git. | Yongjin Yang, Joonkee Kim, Yujin Kim, Namgyu Ho, James Thorne, SeYoung Yun |  |
| 499 |  |  [ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.366) |  | 0 | Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose \*\*ReLM\*\*, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model’s robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at https://github.com/syr-cn/ReLM. | Yaorui Shi, An Zhang, Enzhi Zhang, Zhiyuan Liu, Xiang Wang |  |
| 500 |  |  [Decomposing Complex Queries for Tip-of-the-tongue Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.367) |  | 0 | When re-finding items, users who forget or are uncertain about identifying details often rely on creative strategies for expressing their information needs—complex queries that describe content elements (e.g., book characters or events), information beyond the document text (e.g., descriptions of book covers), or personal context (e.g., when they read a book). Standard retrieval models that rely on lexical or semantic overlap between query and document text are challenged in such retrieval settings, known as tip-of-the-tongue (TOT) retrieval. We introduce a simple but effective framework for handling such complex queries by decomposing the query with an LLM into individual clues routing those as subqueries to specialized retrievers, and ensembling the results. Our approach takes advantage of off-the-shelf retrievers (e.g., CLIP for retrieving images of book covers) or incorporate retriever-specific logic (e.g., date constraints). We show that our framework incorporating query decomposition into retrievers can improve gold book recall up to 6% absolute gain for Recall@5 on a new collection of 14,441 real-world query-book pairs from an online community for resolving TOT inquiries. | Kevin Lin, Kyle Lo, Joseph Gonzalez, Dan Klein |  |
| 501 |  |  [Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research](https://doi.org/10.18653/v1/2023.findings-emnlp.368) |  | 0 | With language technology increasingly affecting individuals’ lives, many recent works have investigated the ethical aspects of NLP. Among other topics, researchers focused on the notion of morality, investigating, for example, which moral judgements language models make. However, there has been little to no discussion of the terminology and the theories underpinning those efforts and their implications. This lack is highly problematic, as it hides the works’ underlying assumptions and hinders a thorough and targeted scientific debate of morality in NLP. In this work, we address this research gap by (a) providing an overview of some important ethical concepts stemming from philosophy and (b) systematically surveying the existing literature on moral NLP w.r.t. their philosophical foundation, terminology, and data basis. For instance, we analyse what ethical theory an approach is based on, how this decision is justified, and what implications it entails. Our findings surveying 92 papers show that, for instance, most papers neither provide a clear definition of the terms they use nor adhere to definitions from philosophy. Finally, (c) we give three recommendations for future research in the field. We hope our work will lead to a more informed, careful, and sound discussion of morality in language technology. | Karina Vida, Judith Simon, Anne Lauscher |  |
| 502 |  |  [Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games](https://doi.org/10.18653/v1/2023.findings-emnlp.369) |  | 0 | In this work, we introduce a self-supervised behavior cloning transformer for text games, which are challenging benchmarks for multi-step reasoning in virtual environments. Traditionally, Behavior Cloning Transformers excel in such tasks but rely on supervised training data. Our approach auto-generates training data by exploring trajectories (defined by common macro-action sequences) that lead to reward within the games, while determining the generality and utility of these trajectories by rapidly training small models then evalauating their performance on unseen development games. Through empirical analysis, we show our method consistently uncovers generalizable training data, achieving about 90% performance of supervised systems across three benchmark text games. | Ruoyao Wang, Peter A. Jansen |  |
| 503 |  |  [Adapting Pretrained Text-to-Text Models for Long Text Sequences](https://doi.org/10.18653/v1/2023.findings-emnlp.370) |  | 0 | We present an empirical study of adapting an existing pretrained text-to-text model for long-sequence inputs. Through a comprehensive study along three axes of the pretraining pipeline – model architecture, optimization objective, and pretraining corpus, we propose an effective recipe to build long-context models from existing short-context models. Specifically, we replace the full attention in transformers with pooling-augmented blockwise attention, and pretrain the model with a masked-span prediction task with spans of varying lengths. In terms of the pretraining corpus, we find that using randomly concatenated short-documents from a large open-domain corpus results in better performance than using existing long document corpora, which are typically limited in their domain coverage. With these findings, we build a long-context model that achieves competitive performance on long-text QA tasks and establishes the new state of the art on five long-text summarization datasets, often outperforming previous methods with larger model sizes. | Wenhan Xiong, Anchit Gupta, Shubham Toshniwal, Yashar Mehdad, Scott Yih |  |
| 504 |  |  [xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark](https://doi.org/10.18653/v1/2023.findings-emnlp.371) |  | 0 | Recent advancements in reference-free learned metrics for open-domain dialogue evaluation have been driven by the progress in pre-trained language models and the availability of dialogue data with high-quality human annotations. However, current studies predominantly concentrate on English dialogues, and the generalization of these metrics to other languages has not been fully examined. This is largely due to the absence of a multilingual dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval, built on top of open-source English dialogue evaluation datasets. xDial-Eval includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930 annotated turns and 8691 annotated dialogues respectively. The English dialogue data are extended to nine other languages with commercial machine translation systems. On xDial-Eval, we conduct comprehensive analyses of previous BERT-based metrics and the recently-emerged large language models. Lastly, we establish strong self-supervised and multilingual baselines. In terms of average Pearson correlations over all datasets and languages, the best baseline outperforms OpenAI’s ChatGPT by absolute improvements of 6.5% and 4.6% at the turn and dialogue levels respectively, albeit with much fewer parameters. The data and code are publicly available at https://github.com/e0397123/xDial-Eval. | Chen Zhang, Luis F. D'Haro, Chengguang Tang, Ke Shi, Guohua Tang, Haizhou Li |  |
| 505 |  |  [MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems](https://doi.org/10.18653/v1/2023.findings-emnlp.372) |  | 0 | While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly. | Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Tanmay Sinha, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan |  |
| 506 |  |  [Towards Making the Most of ChatGPT for Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.373) |  | 0 | ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT’s translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP). We show that: 1) The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; 2) Emphasizing the task information further improves ChatGPT’s performance, particularly in complex MT tasks; 3) Introducing domain information can elicit ChatGPT’s generalization ability and improve its performance in the specific domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community. We also explore the effects of advanced in-context learning strategies and find a (negative but interesting) observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation. | Keqin Peng, Liang Ding, Qihuang Zhong, Li Shen, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao |  |
| 507 |  |  [Enhancing Reasoning Capabilities by Instruction Learning and Chain-of-Thoughts for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.374) |  | 0 | The aim of implicit discourse relation recognition is to comprehend the sense of connection between two arguments. In this work, we present a classification method that is solely based on generative models. Our proposed approach employs a combination of instruction templates and in-context learning to refine the generative model for effectively addressing the implicit discourse relation recognition task. Furthermore, we utilize Chain-of-Thoughts to partition the inference process into a sequence of three successive stages. This strategy enables us to fully utilize the autoregressive generative model’s potential for knowledge acquisition and inference, ultimately leading to enhanced performance on this natural language understanding task. The results of our experiments, evaluated on benchmark datasets PDTB 2.0, PDTB 3.0, and the CoNLL16 shared task, demonstrate superior performance compared to previous state-of-the-art models. | Yuxiang Lu, Yu Hong, Zhipang Wang, Guodong Zhou |  |
| 508 |  |  [Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets](https://doi.org/10.18653/v1/2023.findings-emnlp.375) |  | 0 | Opinion summarization is expected to digest larger review sets and provide summaries from different perspectives. However, most existing solutions are deficient in epitomizing extensive reviews and offering opinion summaries from various angles due to the lack of designs for information selection. To this end, we propose SubSumm, a supervised summarization framework for large-scale multi-perspective opinion summarization. SubSumm consists of a review sampling strategy set and a two-stage training scheme. The sampling strategies take sentiment orientation and contrastive information value into consideration, with which the review subsets from different perspectives and quality levels can be selected. Subsequently, the summarizer is encouraged to learn from the sub-optimal and optimal subsets successively in order to capitalize on the massive input. Experimental results on AmaSum and Rotten Tomatoes datasets demonstrate that SubSumm is adept at generating pros, cons, and verdict summaries from hundreds of input reviews. Furthermore, our in-depth analysis verifies that the advanced selection of review subsets and the two-stage training scheme are vital to boosting the summarization performance. | Han Jiang, Rui Wang, Zhihua Wei, Yu Li, Xinpeng Wang |  |
| 509 |  |  [Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.376) |  | 0 | Dealing with multiple topics should be considered an important issue in dialogue summarization, because dialogues, unlike documents, are prone to topic drift. Thus, we propose a new dialogue summarization model that reflects dialogue topic distribution to consider all topics present in the dialogue. First, the distribution of dialogue topics is estimated by an effective topic discovery model. Then topic-informed prompt transfers estimated topic distribution information to the output of encoder and decoder vectors. Finally, the topic extractor estimates the summary topic distribution from the output context vector of decoder to distinguish its difference from the dialogue topic distribution. To consider the proportion of each topic distribution appeared in the dialogue, the extractor is trained to reduce the difference between the distributions of the dialogue and the summary. The experimental results on SAMSum and DialogSum show that our model outperforms state-of-the-art methods on ROUGE scores. The human evaluation results also show that our framework well generates comprehensive summaries. | Jaeah You, Youngjoong Ko |  |
| 510 |  |  [Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy](https://doi.org/10.18653/v1/2023.findings-emnlp.377) |  | 0 | We address an important gap in detecting political bias in news articles. Previous works that perform document classification can be influenced by the writing style of each news outlet, leading to overfitting and limited generalizability. Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles. We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads. While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet. We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy. Further analysis and human evaluation demonstrate the ability of our model to capture common discourse structures in journalism. | Jiwoo Hong, Yejin Cho, Jiyoung Han, Jaemin Jung, James Thorne |  |
| 511 |  |  [Measuring and Narrowing the Compositionality Gap in Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.378) |  | 0 | We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy. | Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, Mike Lewis |  |
| 512 |  |  [Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model](https://doi.org/10.18653/v1/2023.findings-emnlp.379) |  | 0 | Question generation is a widely used data augmentation approach with extensive applications, and extracting qualified candidate answers from context passages is a critical step for most question generation systems. However, existing methods for candidate answer extraction are reliant on linguistic rules or annotated data that face the partial annotation issue and challenges in generalization. To overcome these limitations, we propose a novel unsupervised candidate answer extraction approach that leverages the inherent structure of context passages through a Differentiable Masker-Reconstructor (DMR) Model with the enforcement of self-consistency for picking up salient information tokens. We curated two datasets with exhaustively-annotated answers and benchmark a comprehensive set of supervised and unsupervised candidate answer extraction methods. We demonstrate the effectiveness of the DMR model by showing its performance is superior among unsupervised methods and comparable to supervised methods. | Zhuoer Wang, Yicheng Wang, Ziwei Zhu, James Caverlee |  |
| 513 |  |  [HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science](https://doi.org/10.18653/v1/2023.findings-emnlp.380) |  | 0 | We propose an instruction-based process for trustworthy data curation in materials science (MatSci-Instruct), which we then apply to finetune a LLaMa-based language model targeted for materials science (HoneyBee). MatSci-Instruct helps alleviate the scarcity of relevant, high-quality materials science textual data available in the open literature, and HoneyBee is the first billion-parameter language model specialized to materials science. In MatSci-Instruct we improve the trustworthiness of generated data by prompting multiple commercially available large language models for generation with an Instructor module (e.g. Chat-GPT) and verification from an independent Verifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset of multiple tasks and measure the quality of our dataset along multiple dimensions, including accuracy against known facts, relevance to materials science, as well as completeness and reasonableness of the data. Moreover, we iteratively generate more targeted instructions and instruction-data in a finetuning-evaluation-feedback loop leading to progressively better performance for our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmark shows HoneyBee’s outperformance of existing language models on materials science tasks and iterative improvement in successive stages of instruction-data refinement. We study the quality of HoneyBee’s language modeling through automatic evaluation and analyze case studies to further understand the model’s capabilities and limitations. Our code and relevant datasets are publicly available at https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee. | Yu Song, Santiago Miret, Huan Zhang, Bang Liu |  |
| 514 |  |  [Prompt-Based Editing for Text Style Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.381) |  | 0 | Prompting approaches have been recently explored in text style transfer, where a textual prompt is used to query a pretrained language model (PLM) to generate style-transferred texts word by word in an autoregressive manner. However, such a generation process is less controllable and early prediction errors may affect future word predictions. In this paper, we propose a prompt-based editing approach to text style transfer. Specifically, we prompt a PLM for style classification and use the classification probability to compute a style score. Then, we perform discrete search with word-level editing to maximize a comprehensive scoring function for the style-transfer task. In this way, we transform a prompt-based generation problem into a classification one, which does not suffer from the error accumulation problem and is more controllable than the autoregressive generation of sentences. In our experiments, we performed both automatic and human evaluation on three style-transfer benchmark datasets, and show that our approach largely outperforms the existing systems that have 20 times more parameters. Additional empirical analyses further demonstrate the effectiveness of our approach. | Guoqing Luo, Yutong Han, Lili Mou, Mauajama Firdaus |  |
| 515 |  |  [Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation](https://doi.org/10.18653/v1/2023.findings-emnlp.382) |  | 0 | Multilingualism is widespread around the world and code-switching (CSW) is a common practice among different language pairs/tuples across locations and regions. However, there is still not much progress in building successful CSW systems, despite the recent advances in Massive Multilingual Language Models (MMLMs). We investigate the reasons behind this setback through a critical study about the existing CSW data sets (68) across language pairs in terms of the collection and preparation (e.g. transcription and annotation) stages. This in-depth analysis reveals that a) most CSW data involves English ignoring other language pairs/tuples b) there are flaws in terms of representativeness in data collection and preparation stages due to ignoring the location based, socio-demographic and register variation in CSW. In addition, lack of clarity on the data selection and filtering stages shadow the representativeness of CSW data sets. We conclude by providing a short check-list to improve the representativeness for forthcoming studies involving CSW data collection and preparation. | A. Seza Dogruöz, Sunayana Sitaram, Zheng Xin Yong |  |
| 516 |  |  [NERvous About My Health: Constructing a Bengali Medical Named Entity Recognition Dataset](https://doi.org/10.18653/v1/2023.findings-emnlp.383) |  | 0 | The ability to identify important entities in a text, known as Named Entity Recognition (NER), is useful in a large variety of downstream tasks in the biomedical domain. This is a considerably difficult task when working with Consumer Health Questions (CHQs), which consist of informal language used in day-to-day life by patients. These difficulties are amplified in the case of Bengali, which allows for a huge amount of flexibility in sentence structures and has significant variances in regional dialects. Unfortunately, the complexity of the language is not accurately reflected in the limited amount of available data, which makes it difficult to build a reliable decision-making system. To address the scarcity of data, this paper presents ‘Bangla-HealthNER’, a comprehensive dataset designed to identify named entities in health-related texts in the Bengali language. It consists of 31,783 samples sourced from a popular online public health platform, which allows it to capture the diverse range of linguistic styles and dialects used by native speakers from various regions in their day-to-day lives. The insight into this diversity in language will prove useful to any medical decision-making systems that are developed for use in real-world applications. To highlight the difficulty of the dataset, it has been benchmarked on state-of-the-art token classification models, where BanglishBERT achieved the highest performance with an F1-score of 56.13 ± 0.75%. The dataset and all relevant code used in this work have been made publicly available. | Alvi Khan, Fida Kamal, Nuzhat Nower, Tasnim Ahmed, Sabbir Ahmed, Tareque Chowdhury |  |
| 517 |  |  [Sparse Black-Box Multimodal Attack for Vision-Language Adversary Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.384) |  | 0 | Deep neural networks have been widely applied in real-world scenarios, such as product restrictions on e-commerce and hate speech monitoring on social media, to ensure secure governance of various platforms. However, illegal merchants often deceive the detection models by adding large-scale perturbations to prohibited products, so as to earn illegal profits. Current adversarial attacks using imperceptible perturbations encounter challenges in simulating such adversarial behavior and evaluating the vulnerabilities of detection models to such perturbations. To address this issue, we propose a novel black-box multimodal attack, termed Sparse Multimodal Attack (SparseMA), which leverages sparse perturbations to simulate the adversarial behavior exhibited by illegal merchants in the black-box scenario. Moreover, SparseMA bridges the gap between images and texts by treating the separated image patches and text words uniformly in the discrete space. Extensive experiments demonstrate that SparseMA can identify the vulnerability of the model to different modalities, outperforming existing multimodal attacks and unimodal attacks. SparseMA, which is the first proposed method for black-box multimodal attacks to our knowledge, would be used as an effective tool for evaluating the robustness of multimodal models to different modalities. | Zhen Yu, Zhou Qin, Zhenhua Chen, Meihui Lian, Haojun Fu, Weigao Wen, Hui Xue, Kun He |  |
| 518 |  |  [Towards a Unified Framework for Reference Retrieval and Related Work Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.385) |  | 0 | The task of related work generation aims to generate a comprehensive survey of related research topics automatically, saving time and effort for authors. Existing methods simplify this task by using human-annotated references in a large-scale scientific corpus as information sources, which is time- and cost-intensive. To this end, we propose a Unified Reference Retrieval and Related Work Generation Model (UR3WG), which combines reference retrieval and related work generation processes in a unified framework based on the large language model (LLM). Specifically, UR3WG first leverages the world knowledge of LLM to extend the abstract and generate the query for the subsequent retrieval stage. Then a lexicon-enhanced dense retrieval is proposed to search relevant references, where an importance-aware representation of the lexicon is introduced. We also propose multi-granularity contrastive learning to optimize our retriever. Since this task is not simply summarizing the main points in references, it should analyze the complex relationships and present them logically. We propose an instruction-tuning method to leverage LLM to generate related work. Extensive experiments on two wide-applied datasets demonstrate that our model outperforms the state-of-the-art baselines in both generation and retrieval metrics. | Zhengliang Shi, Shen Gao, Zhen Zhang, Xiuying Chen, Zhumin Chen, Pengjie Ren, Zhaochun Ren |  |
| 519 |  |  [Visual Storytelling with Question-Answer Plans](https://doi.org/10.18653/v1/2023.findings-emnlp.386) |  | 0 | Visual storytelling aims to generate compelling narratives from image sequences. Existing models often focus on enhancing the representation of the image sequence, e.g., with external knowledge sources or advanced graph structures. Despite recent progress, the stories are often repetitive, illogical, and lacking in detail. To mitigate these issues, we present a novel framework which integrates visual representations with pretrained language models and planning. Our model translates the image sequence into a visual prefix, a sequence of continuous embeddings which language models can interpret. It also leverages a sequence of question-answer pairs as a blueprint plan for selecting salient visual concepts and determining how they should be assembled into a narrative. Automatic and human evaluation on the VIST benchmark demonstrates that blueprint-based models generate stories that are more coherent, interesting, and natural compared to competitive baselines and state-of-the-art systems. | Danyang Liu, Mirella Lapata, Frank Keller |  |
| 520 |  |  [Investigating Online Community Engagement through Stancetaking](https://doi.org/10.18653/v1/2023.findings-emnlp.387) |  | 0 | Much work has explored lexical and semantic variation in online communities, and drawn connections to community identity and user engagement patterns. Communities also express identity through the sociolinguistic concept of stancetaking. Large-scale computational work on stancetaking has explored community similarities in their preferences for stance markers – words that serve to indicate aspects of a speaker’s stance – without considering the stance-relevant properties of the contexts in which stance markers are used. We propose representations of stance contexts for 1798 Reddit communities and show how they capture community identity patterns distinct from textual or marker similarity measures. We also relate our stance context representations to broader inter- and intra-community engagement patterns, including cross-community posting patterns and social network properties of communities. Our findings highlight the strengths of using rich properties of stance as a way of revealing community identity and engagement patterns in online multi-community spaces. | Jai Aggarwal, Brian Diep, Julia Watson, Suzanne Stevenson |  |
| 521 |  |  [ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.388) |  | 0 | As large language models are integrated into society, robustness toward a suite of prompts is increasingly important to maintain reliability in a high-variance environment.Robustness evaluations must comprehensively encapsulate the various settings in which a user may invoke an intelligent system. This paper proposes ASSERT, Automated Safety Scenario Red Teaming, consisting of three methods – semantically aligned augmentation, target bootstrapping, and adversarial knowledge injection. For robust safety evaluation, we apply these methods in the critical domain of AI safety to algorithmically generate a test suite of prompts covering diverse robustness settings – semantic equivalence, related scenarios, and adversarial. We partition our prompts into four safety domains for a fine-grained analysis of how the domain affects model performance. Despite dedicated safeguards in existing state-of-the-art models, we find statistically significant performance differences of up to 11% in absolute classification accuracy among semantically related scenarios and error rates of up to 19% absolute error in zero-shot adversarial settings, raising concerns for users’ physical safety. | Alex Mei, Sharon Levy, William Yang Wang |  |
| 522 |  |  [Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.389) |  | 0 | Fine-grained entity typing (FET) is an essential task in natural language processing that aims to assign semantic types to entities in text. However, FET poses a major challenge known as the noise labeling problem, whereby current methods rely on estimating noise distribution to identify noisy labels but are confused by diverse noise distribution deviation. To address this limitation, we introduce Co-Prediction Prompt Tuning for noise correction in FET, which leverages multiple prediction results to identify and correct noisy labels. Specifically, we integrate prediction results to recall labeled labels and utilize a differentiated margin to identify inaccurate labels. Moreover, we design an optimization objective concerning divergent co-predictions during fine-tuning, ensuring that the model captures sufficient information and maintains robustness in noise identification. Experimental results on three widely-used FET datasets demonstrate that our noise correction approach significantly enhances the quality of various types of training samples, including those annotated using distant supervision, ChatGPT, and crowdsourcing. | Minghao Tang, Yongquan He, Yongxiu Xu, Hongbo Xu, Wenyuan Zhang, Yang Lin |  |
| 523 |  |  [Co²PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.390) |  | 0 | Pre-trained Language Models are widely used in many important real-world applications. However, recent studies show that these models can encode social biases from large pre-training corpora and even amplify biases in downstream applications. To address this challenge, we propose Co2PT, an efficient and effective \*debias-while-prompt tuning\* method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks. Our experiments conducted on three extrinsic bias benchmarks demonstrate the effectiveness of Co2PT on bias mitigation during the prompt tuning process and its adaptability to existing upstream debiased language models. These findings indicate the strength of Co2PT and provide promising avenues for further enhancement in bias mitigation on downstream tasks. | Xiangjue Dong, Ziwei Zhu, Zhuoer Wang, Maria Teleki, James Caverlee |  |
| 524 |  |  [A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.391) |  | 0 | Pre-trained language models (PLMs) have achieved outstanding achievements in abstractive single-document summarization (SDS). However, such benefits may not fully extend to multi-document summarization (MDS), where the handling of cross-document information is more complex. Previous works either design new MDS architectures or apply PLMs bluntly with concatenated source documents as a reformulated SDS task. While the former does not utilize previous pre-training efforts and may not generalize well across different domains, the latter may not sufficiently attend to the intricate cross-document relationships unique to MDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to better utilize a PLM to facilitate multi-document interactions for the MDS task. Across 10 MDS benchmarks from various domains, our method outperforms or is competitive with the previous best models, including those with additional MDS pre-training or with more parameters. It outperforms its corresponding PLM backbone by up to 3 Rouge-L and is favored by humans. | Chenhui Shen, Liying Cheng, XuanPhi Nguyen, Yang You, Lidong Bing |  |
| 525 |  |  [Universal Domain Adaptation for Robust Handling of Distributional Shifts in NLP](https://doi.org/10.18653/v1/2023.findings-emnlp.392) |  | 0 | When deploying machine learning systems to the wild, it is highly desirable for them to effectively leverage prior knowledge to the unfamiliar domain while also firing alarms to anomalous inputs. In order to address these requirements, Universal Domain Adaptation (UniDA) has emerged as a novel research area in computer vision, focusing on achieving both adaptation ability and robustness (i.e., the ability to detect out-of-distribution samples). While UniDA has led significant progress in computer vision, its application on language input still needs to be explored despite its feasibility. In this paper, we propose a comprehensive benchmark for natural language that offers thorough viewpoints of the model’s generalizability and robustness. Our benchmark encompasses multiple datasets with varying difficulty levels and characteristics, including temporal shifts and diverse domains. On top of our testbed, we validate existing UniDA methods from computer vision and state-of-the-art domain adaptation techniques from NLP literature, yielding valuable findings: We observe that UniDA methods originally designed for image input can be effectively transferred to the natural language domain while also underscoring the effect of adaptation difficulty in determining the model’s performance. | Hyuhng Joon Kim, Hyunsoo Cho, SangWoo Lee, Junyeob Kim, Choonghyun Park, Sanggoo Lee, Kang Min Yoo, Taeuk Kim |  |
| 526 |  |  [Aligning Language Models to User Opinions](https://doi.org/10.18653/v1/2023.findings-emnlp.393) |  | 0 | An important aspect of developing LLMs that interact with humans is to align models’ behavior to their users. It is possible to prompt an LLM into behaving as a certain persona, especially a user group or ideological persona the model captured during its pertaining stage. But, how to best align an LLM with a specific user and not a demographic or ideological group remains an open question. Mining public opinion surveys (by PEW research), we find that the opinions of a user and their demographics and ideologies are not mutual predictors. We use this insight to align LLMs by modeling relevant past user opinions in addition to user demographics and ideology, achieving up to 7 points accuracy gains in predicting public opinions from survey questions across a broad set of topics. Our work opens up the research avenues to bring user opinions as an important ingredient in aligning language models. | EunJeong Hwang, Bodhisattwa Prasad Majumder, Niket Tandon |  |
| 527 |  |  [CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.394) |  | 0 | Deep neural networks have demonstrated their capacity in extracting features from speech inputs. However, these features may include non-linguistic speech factors such as timbre and speaker identity, which are not directly related to translation. In this paper, we propose a content-centric speech representation disentanglement learning framework for speech translation, CCSRD, which decomposes speech representations into content representations and non-linguistic representations via representation disentanglement learning. CCSRD consists of a content encoder that encodes linguistic content information from the speech input, a non-content encoder that models non-linguistic speech features, and a disentanglement module that learns disentangled representations with a cyclic reconstructor, feature reconstructor and speaker classifier trained in a multi-task learning way. Experiments on the MuST-C benchmark dataset demonstrate that CCSRD achieves an average improvement of +0.9 BLEU in two settings across five translation directions over the baseline, outperforming state-of-the-art end-to-end speech translation models and cascaded models. | Xiaohu Zhao, Haoran Sun, Yikun Lei, Shaolin Zhu, Deyi Xiong |  |
| 528 |  |  [Miracle: Towards Personalized Dialogue Generation with Latent-Space Multiple Personal Attribute Control](https://doi.org/10.18653/v1/2023.findings-emnlp.395) |  | 0 | Personalized dialogue systems aim to endow the chatbot agent with more anthropomorphic traits for human-like interactions. Previous approaches have explored explicitly user profile modeling using text descriptions, implicit derivation of user embeddings, or utilizing handicraft prompts for ChatGPT-like models. However, textual personas are limited in describing multi-faceted attributes (e.g., language style, inner character nuances), implicit embedding suffers from personality sparsity, and handicraft prompts lack fine-grained and stable controllability. Hence, these approaches may struggle with complex personalized dialogue generation tasks that require generating controllable responses with multiple personal attributes. To this end, we propose Miracle, a novel personalized dialogue generation method through MultIple PeRsonal Attributes Control within Latent-Space Energy-based Models. ttributes Control within Latent-Space Energy-based Models. Specifically, our approach first disentangles complex personality into multi-faceted attributes. Subsequently, we employ a conditional variational auto-encoder to align with the dense personalized responses within a latent joint attribute space. We have also tailored a dedicated energy function and customized the ordinary differential equations sampling method to offer flexible attribute composition and precise attribute control. Extensive experiments demonstrate that Miracle outperforms several strong baselines in terms of personality controllability and response generation quality. Our dataset and code are available at https://github.com/LZY-the-boys/MIRACLE | Zhenyi Lu, Wei Wei, Xiaoye Qu, XianLing Mao, Dangyang Chen, Jixiong Chen |  |
| 529 |  |  [Towards Multilingual Interlinear Morphological Glossing](https://doi.org/10.18653/v1/2023.findings-emnlp.396) |  | 0 | Interlinear Morphological Glosses are annotations produced in the context of language documentation. Their goal is to identify morphs occurring in an L1 sentence and to explicit their function and meaning, with the further support of an associated translation in L2. We study here the task of automatic glossing, aiming to provide linguists with adequate tools to facilitate this process. Our formalisation of glossing uses a latent variable Conditional Random Field (CRF), which labels the L1 morphs while simultaneously aligning them to L2 words. In experiments with several under-resourced languages, we show that this approach is both effective and data-efficient and mitigates the problem of annotating unknown morphs. We also discuss various design choices regarding the alignment process and the selection of features. We finally demonstrate that it can benefit from multilingual (pre-)training, achieving results which outperform very strong baselines. | Shu Okabe, François Yvon |  |
| 530 |  |  [Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation](https://doi.org/10.18653/v1/2023.findings-emnlp.397) |  | 0 | Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation. | TaChung Chi, TingHan Fan, Alexander Rudnicky, Peter J. Ramadge |  |
| 531 |  |  [Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting](https://doi.org/10.18653/v1/2023.findings-emnlp.398) |  | 0 | Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a “rewrite-then-edit” process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers. | Fanghua Ye, Meng Fang, Shenghui Li, Emine Yilmaz |  |
| 532 |  |  [Distilling ChatGPT for Explainable Automated Student Answer Assessment](https://doi.org/10.18653/v1/2023.findings-emnlp.399) |  | 0 | Providing explainable and faithful feedback is crucial for automated student answer assessment. In this paper, we introduce a novel framework that explores using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation. We identify the appropriate instructions by prompting ChatGPT with different templates to collect the rationales, where inconsistent rationales are refined to align with marking standards. The refined ChatGPT outputs enable us to fine-tune a smaller language model that simultaneously assesses student answers and provides rationales. Extensive experiments on the benchmark dataset show that the proposed method improves the overall QWK score by 11% compared to ChatGPT. Furthermore, our thorough analysis and human evaluation demonstrate that the rationales generated by our proposed method are comparable to those of ChatGPT. Our approach provides a viable solution to achieve explainable automated assessment in education | Jiazheng Li, Lin Gui, Yuxiang Zhou, David West, Cesare Aloisi, Yulan He |  |
| 533 |  |  [Grammatical Error Correction via Mixed-Grained Weighted Training](https://doi.org/10.18653/v1/2023.findings-emnlp.400) |  | 0 | The task of Grammatical Error Correction (GEC) aims to automatically correct grammatical errors in natural texts. Almost all previous works treat annotated training data equally, but inherent discrepancies in data are neglected. In this paper, the inherent discrepancies are manifested in two aspects, namely, accuracy of data annotation and diversity of potential annotations. To this end, we propose MainGEC, which designs token-level and sentence-level training weights based on inherent discrepancies therein, and then conducts mixed-grained weighted training to improve the training effect for GEC. Empirical evaluation shows that whether in the Seq2Seq or Seq2Edit manner, MainGEC achieves consistent and significant performance improvements on two benchmark datasets, demonstrating the effectiveness and superiority of the mixed-grained weighted training. Further ablation experiments verify the effectiveness of designed weights for both granularities in MainGEC. | Jiahao Li, Quan Wang, Chiwei Zhu, Zhendong Mao, Yongdong Zhang |  |
| 534 |  |  [A Unified Framework for Synaesthesia Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.401) |  | 0 | Synaesthesia refers to the description of perceptions in one sensory modality through concepts from other modalities. It involves not only a linguistic phenomenon, but also a cognitive phenomenon structuring human thought and action, which makes understanding it challenging. As a means of cognition, synaesthesia is rendered by more than sensory modalities, cue and stimulus can also play an important role in expressing and understanding it. In addition, understanding synaesthesia involves many cognitive efforts, such as identifying the semantic relationship between sensory words and modalities. Therefore, we propose a unified framework focusing on annotating all kinds of synaesthetic elements and fully exploring the relationship among them. In particular, we introduce a new annotation scheme, including sensory modalities as well as their cues and stimuli, which facilitate understanding synaesthetic information collectively. We further design a structure generation model to capture the relations among synaesthetic elements and generate them jointly. Through extensive experiments, the importance of proposed dataset can be verified by the statistics and progressive performances. In addition, our proposed model yields state-of-the-art results, demonstrating its effectiveness. | Kun Sheng, Zhongqing Wang, Qingqing Zhao, Xiaotong Jiang, Guodong Zhou |  |
| 535 |  |  [Domain Private Transformers for Multi-Domain Dialog Systems](https://doi.org/10.18653/v1/2023.findings-emnlp.402) |  | 0 | Large, general purpose language models have demonstrated impressive performance across many different conversational domains. While multi-domain language models achieve low overall perplexity, their outputs are not guaranteed to stay within the domain of a given input prompt. This paper proposes domain privacy as a novel way to quantify how likely a conditional language model will leak across domains. We also develop policy functions based on token-level domain classification, and propose an efficient fine-tuning method to improve the trained model’s domain privacy. Experiments on membership inference attacks show that our proposed method has comparable resiliency to methods adapted from recent literature on differentially private language models. | Anmol Kabra, Ethan R. Elenberg |  |
| 536 |  |  [Visual Elements Mining as Prompts for Instruction Learning for Target-Oriented Multimodal Sentiment Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.403) |  | 0 | Target-oriented Multimodal Sentiment Classification (TMSC) aims to incorporate visual modality with text modality to identify the sentiment polarity towards a specific target within a sentence. To address this task, we propose a Visual Elements Mining as Prompts (VEMP) method, which describes the semantic information of visual elements with Text Symbols Embedded in the Image (TSEI), Target-aware Adjective-Noun Pairs (TANPs) and image scene caption, and then transform them into prompts for instruction learning of the model Tk-Instruct. In our VEMP, the text symbols embedded in the image may contain the textual descriptions of fine-grained visual elements, and are extracted as input TSEI; we extract adjective-noun pairs from the image and align them with the target to obtain TANPs, in which the adjectives provide emotional embellishments for the relevant target; finally, to effectively fuse these visual elements with text modality for sentiment prediction, we integrate them to construct instruction prompts for instruction-tuning Tk-Instruct which possesses powerful learning capabilities under instructions. Extensive experimental results show that our method achieves state-of-the-art performance on two benchmark datasets. And further analysis demonstrates the effectiveness of each component of our method. | Bin Yang, Jinlong Li |  |
| 537 |  |  [NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.404) |  | 0 | Structured pruning methods have proven effective in reducing the model size and accelerating inference speed in various network architectures such as Transformers. Despite the versatility of encoder-decoder models in numerous NLP tasks, the structured pruning methods on such models are relatively less explored compared to encoder-only models. In this study, we investigate the behavior of the structured pruning of the encoder-decoder models in the decoupled pruning perspective of the encoder and decoder component, respectively. Our findings highlight two insights: (1) the number of decoder layers is the dominant factor of inference speed, and (2) low sparsity in the pruned encoder network enhances generation quality. Motivated by these findings, we propose a simple and effective framework, NASH, that narrows the encoder and shortens the decoder networks of encoder-decoder models. Extensive experiments on diverse generation and inference tasks validate the effectiveness of our method in both speedup and output quality. | Jongwoo Ko, Seungjoon Park, Yujin Kim, Sumyeong Ahn, DuSeong Chang, Euijai Ahn, SeYoung Yun |  |
| 538 |  |  [GBT: Generative Boosting Training Approach for Paraphrase Identification](https://doi.org/10.18653/v1/2023.findings-emnlp.405) |  | 0 | Paraphrase Identification (PI), a task of determining whether a pair of sentences express the same meaning, is widely applied in Information Retrieval and Question Answering. Data Augmentation (DA) is proven effective in tackling the PI task. However, the majority of DA methods still suffer from two limitations: inefficiency and poor quality. In this study, we propose the Generative Boosting Training (GBT) approach for PI. GBT designs a boosting learning method for a single model based on the human learning process, utilizing seq2seq model to perform DA on misclassified instances periodically. We conduct experiments on the benchmark corpora QQP and LCQMC, towards both English and Chinese PI tasks. Experimental results show that our method yields significant improvements on a variety of Pre-trained Language Model (PLM) based baselines with good efficiency and effectiveness. It is noteworthy that a single BERT model (with a linear classifier) can outperform the state-of-the-art PI models with the boosting of GBT. | Rui Peng, Zhiling Jin, Yu Hong |  |
| 539 |  |  [DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet Classification via Memory Bank](https://doi.org/10.18653/v1/2023.findings-emnlp.406) |  | 0 | During crisis events, people often use social media platforms such as Twitter to disseminate information about the situation, warnings, advice, and support. Emergency relief organizations leverage such information to acquire timely crisis circumstances and expedite rescue operations. While existing works utilize such information to build models for crisis event analysis, fully-supervised approaches require annotating vast amounts of data and are impractical due to limited response time. On the other hand, semi-supervised models can be biased, performing moderately well for certain classes while performing extremely poorly for others, resulting in substantially negative effects on disaster monitoring and rescue. In this paper, we first study two recent debiasing methods on semi-supervised crisis tweet classification. Then we propose a simple but effective debiasing method, DeCrisisMB, that utilizes a Memory Bank to store and perform equal sampling for generated pseudo-labels from each class at each training iteration. Extensive experiments are conducted to compare different debiasing methods’ performance and generalization ability in both in-distribution and out-of-distribution settings. The results demonstrate the superior performance of our proposed method. Our code is available at https://github.com/HenryPengZou/DeCrisisMB. | Henry Peng Zou, Yue Zhou, Weizhi Zhang, Cornelia Caragea |  |
| 540 |  |  [Probing LLMs for hate speech detection: strengths and vulnerabilities](https://doi.org/10.18653/v1/2023.findings-emnlp.407) |  | 0 | Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select two large language models (GPT-3.5 and text-davinci) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially (∼20-30%) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline (∼10-20%) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute ‘jailbreak’ prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts. | Sarthak Roy, Ashish Harshavardhan, Animesh Mukherjee, Punyajoy Saha |  |
| 541 |  |  [From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.408) |  | 0 | Document-level Event Argument Extraction (EAE) requires the model to extract arguments of multiple events from a single document. Considering the underlying dependencies between these events, recent efforts leverage the idea of “memory”, where the results of already predicted events are cached and can be retrieved to help the prediction of upcoming events. These methods extract events according to their appearance order in the document, however, the event that appears in the first sentence does not mean that it is the easiest to extract. Existing methods might introduce noise to the extraction of upcoming events if they rely on an incorrect prediction of previous events. In order to provide more reliable memory, we propose a simple-to-complex progressive framework for document-level EAE. Specifically, we first calculate the difficulty of each event and then, we conduct the extraction following a simple-to-complex order. In this way, the memory will store the most certain results, and the model could use these reliable sources to help the prediction of more difficult events. Experiments on WikiEvents show that our model outperforms SOTA by 1.4% in F1, indicating the proposed simple-to-complex framework is useful in the EAE task. | Quzhe Huang, Yanxi Zhang, Dongyan Zhao |  |
| 542 |  |  [MultiCMET: A Novel Chinese Benchmark for Understanding Multimodal Metaphor](https://doi.org/10.18653/v1/2023.findings-emnlp.409) |  | 0 | Metaphor is a pervasive aspect of human communication, and its presence in multimodal forms has become more prominent with the progress of mass media. However, there is limited research on multimodal metaphor resources beyond the English language. Furthermore, the existing work in natural language processing does not address the exploration of categorizing the source and target domains in metaphors. This omission is significant considering the extensive research conducted in the fields of cognitive linguistics, which emphasizes that a profound understanding of metaphor relies on recognizing the differences and similarities between domain categories. We, therefore, introduce MultiCMET, a multimodal Chinese metaphor dataset, consisting of 13,820 text-image pairs of advertisements with manual annotations of the occurrence of metaphors, domain categories, and sentiments metaphors convey. We also constructed a domain lexicon that encompasses categorizations of metaphorical source domains and target domains and propose a Cascading Domain Knowledge Integration (CDKI) benchmark to detect metaphors by introducing domain-specific lexical features. Experimental results demonstrate the effectiveness of CDKI. The dataset and code are publicly available. | Dongyu Zhang, Jingwei Yu, Senyuan Jin, Liang Yang, Hongfei Lin |  |
| 543 |  |  [GlotLID: Language Identification for Low-Resource Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.410) |  | 0 | Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance accessibility of NLP technology for low-resource languages and cultures. GlotLID-M model, code, and list of data sources are available: https://github.com/cisnlp/GlotLID. | Amir Hossein Kargaran, Ayyoob Imani, François Yvon, Hinrich Schütze |  |
| 544 |  |  [Finding Support Examples for In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.411) |  | 0 | In-context learning is a new learning paradigm where a language model observes a few examples and directly outputs the test input’s prediction. Previous works have shown that it is sensitive to the provided examples and randomly sampled examples probably cause inferior performance. In this paper, we propose finding “support examples” for in-context learning: Given a training dataset, it aims to select one permutation of a few examples, which can well characterize the task for in-context learning and thus lead to superior performance. Although for traditional gradient-based training, there are extensive methods to find a coreset from the entire dataset, they struggle to find important in-context examples, because in-context learning occurs in the language model’s forward process without gradients or parameter updates and thus has a significant gap with traditional training. Additionally, the strong dependence among in-context examples makes it an NP-hard combinatorial optimization problem and enumerating all permutations is infeasible. Hence we propose \*\*LENS\*\*, a fi\*\*L\*\*ter-th\*\*EN\*\*-\*\*S\*\*earch method to tackle this challenge in two stages: irst we filter the dataset to obtain individually informative in-context examples. Specifically, we propose a novel metric, InfoScore, to evaluate the example’s in-context informativeness based on the language model’s feedback, and further propose a progressive filtering process to filter out uninformative examples. Then we propose diversity-guided example search which iteratively refines and evaluates the selected example permutations, to find examples that fully depict the task. The experimental results show that LENS significantly outperforms a wide range of baselines and further analyses show that each component contribute critically to the improvements and shed light on the principles of supporting examples and in-context learning. | Xiaonan Li, Xipeng Qiu |  |
| 545 |  |  [Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech](https://doi.org/10.18653/v1/2023.findings-emnlp.412) |  | 0 | While many prior studies have applied computational approaches, such as machine learning, to detect and moderate hate speech, only scant attention has been paid to the task of identifying the underlying cause of hate speech. In this study, we introduce the concept of hate instigating speech, which refers to a specific type of textual posts on online platforms that stimulate or provoke others to engage in hate speech. The identification of hate instigating speech carries substantial practical implications for effective hate speech moderation. Rather than targeting individual instances of hate speech, by focusing on their roots, i.e., hate instigating speech, it becomes possible to significantly reduce the volume of content that requires review for moderation. Additionally, targeting hate instigating speech enables early prevention of the spread and propagation of hate speech, further enhancing the effectiveness of moderation efforts. However, several challenges hinder researchers from addressing the identification of hate instigating speech. First, there is a lack of comprehensive datasets specifically annotated for hate instigation, making it difficult to train and evaluate computational models effectively. Second, the subtle and nuanced nature of hate instigating speech (e.g., seemingly non-offensive texts serve as catalysts for triggering hate speech) makes it difficult to apply off-the-shelf machine learning models to the problem. To address these challenges, in this study, we have developed and released a multilingual dataset specifically designed for the task of identifying hate instigating speech. Specifically, it encompasses both English and Korean, allowing for a comprehensive examination of hate instigating speech across different linguistic contexts. We have applied existing machine learning models to our dataset and the results demonstrate that the extant models alone are insufficient for effectively detecting hate instigating speech. This finding highlights the need for further attention from the academic community to address this specific challenge. We expect our study and dataset to inspire researchers to explore innovative methods that can enhance the accuracy of hate instigating speech detection, ultimately contributing to more effective moderation and prevention of hate speech propagation online. | Hyoungjun Park, Ho Shim, Kyuhan Lee |  |
| 546 |  |  [Responsible AI Considerations in Text Summarization Research: A Review of Current Practices](https://doi.org/10.18653/v1/2023.findings-emnlp.413) |  | 0 | AI and NLP publication venues have increasingly encouraged researchers to reflect on possible ethical considerations, adverse impacts, and other responsible AI issues their work might engender. However, for specific NLP tasks our understanding of how prevalent such issues are, or when and why these issues are likely to arise, remains limited. Focusing on text summarization—a common NLP task largely overlooked by the responsible AI community—we examine research and reporting practices in the current literature. We conduct a multi-round qualitative analysis of 333 summarization papers from the ACL Anthology published between 2020–2022. We focus on how, which, and when responsible AI issues are covered, which relevant stakeholders are considered, and mismatches between stated and realized research goals. We also discuss current evaluation practices and consider how authors discuss the limitations of both prior work and their own work. Overall, we find that relatively few papers engage with possible stakeholders or contexts of use, which limits their consideration of potential downstream adverse impacts or other responsible AI issues. Based on our findings, we make recommendations on concrete practices and research directions. | Yu Lu Liu, Meng Cao, Su Lin Blodgett, Jackie Chi Kit Cheung, Alexandra Olteanu, Adam Trischler |  |
| 547 |  |  [Improving Speech Translation by Fusing Speech and Text](https://doi.org/10.18653/v1/2023.findings-emnlp.414) |  | 0 | In speech translation, leveraging multimodal data to improve model performance and address limitations of individual modalities has shown significant effectiveness. In this paper, we harness the complementary strengths of speech and text to improve speech translation. However, speech and text are disparate modalities, we observe three aspects of modality gap that impede their integration in a speech translation model. To tackle these gaps, we propose \*\*Fuse\*\*-\*\*S\*\*peech-\*\*T\*\*ext (\*\*FuseST\*\*), a cross-modal model which supports three distinct input modalities for translation: speech, text and fused speech-text. We leverage multiple techniques for cross-modal alignment and conduct a comprehensive analysis to assess its impact on speech translation, machine translation and fused speech-text translation. We evaluate FuseST on MuST-C, GigaST and newstest benchmark. Experiments show that the proposed FuseST achieves an average 34.0 BLEU on MuST-C En→De/Es/Fr (vs SOTA +1.1 BLEU). Further experiments demonstrate that FuseST does not degrade on MT task, as observed in previous works. Instead, it yields an average improvement of 3.2 BLEU over the pre-trained MT model. Code is available at https://github.com/WenbiaoYin/FuseST. | Wenbiao Yin, Zhicheng Liu, Chengqi Zhao, Tao Wang, Jian Tong, Rong Ye |  |
| 548 |  |  [Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward](https://doi.org/10.18653/v1/2023.findings-emnlp.415) |  | 0 | To create a captivating story, a writer often plans a sequence of logically coherent events and ingeniously manipulates the narrative order to generate flashback in place. However, existing storytelling systems suffer from both insufficient understanding of event correlations and inadequate awareness of event temporal order (e.g., go to hospital <after> get ill), making it challenging to generate high-quality events that balance the logic and narrative order of story. In this paper, we propose a narrative order aware framework BPOT (Bidirectional Pretraining Model with Optimal Transport Reward) for story generation, which presents a bidirectional pretrained model to encode event correlations and pairwise event order. We also design a reinforcement learning algorithm with novel optimal transport reward to further improve the quality of generated events in the fine-tuning stage. Specifically, a narrative order aware event sequence model is pretrained with the joint learning objectives of event blank infilling and pairwise order prediction. Then, reinforcement learning with novel optimal transport reward is designed to further improve the generated event quality in the fine-tuning stage. The novel optimal transport reward captures the mappings between the generated events and the sentences in the story, effectively measuring the quality of generated events. Both automatic and manual evaluation results demonstrate the superiority of our framework in generating logically coherent stories with flashbacks. | Zhicong Lu, Li Jin, Guangluan Xu, Linmei Hu, Nayu Liu, Xiaoyu Li, Xian Sun, Zequn Zhang, Kaiwen Wei |  |
| 549 |  |  [Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.416) |  | 0 | Claim verification plays a crucial role in combating misinformation. While existing works on claim verification have shown promising results, a crucial piece of the puzzle that remains unsolved is to understand how to verify claims without relying on human-annotated data, which is expensive to create at a large scale. Additionally, it is important for models to provide comprehensive explanations that can justify their decisions and assist human fact-checkers. This paper presents First-Order-Logic-Guided Knowledge-Grounded (FOLK) Reasoning that can verify complex claims and generate explanations without the need for annotated evidence using Large Language Models (LLMs). FOLK leverages the in-context learning ability of LLMs to translate the claim into a First-Order-Logic (FOL) clause consisting of predicates, each corresponding to a sub-claim that needs to be verified. Then, FOLK performs FOL-Guided reasoning over a set of knowledge-grounded question-and-answer pairs to make veracity predictions and generate explanations to justify its decision-making process. This process makes our model highly explanatory, providing clear explanations of its reasoning process in human-readable form. Our experiment results indicate that FOLK outperforms strong baselines on three datasets encompassing various claim verification challenges. Our code and data are available. | Haoran Wang, Kai Shu |  |
| 550 |  |  [Strong and Efficient Baselines for Open Domain Conversational Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.417) |  | 0 | Unlike the Open Domain Question Answering (ODQA) setting, the conversational (ODConvQA) domain has received limited attention when it comes to reevaluating baselines for both efficiency and effectiveness. In this paper, we study the State-of-the-Art (SotA) Dense Passage Retrieval (DPR) retriever and Fusion-in-Decoder (FiD) reader pipeline, and show that it significantly underperforms when applied to ODConvQA tasks due to various limitations. We then propose and evaluate strong yet simple and efficient baselines, by introducing a fast reranking component between the retriever and the reader, and by performing targeted finetuning steps. Experiments on two ODConvQA tasks, namely TopiOCQA and OR-QuAC, show that our method improves the SotA results, while reducing reader’s latency by 60%. Finally, we provide new and valuable insights into the development of challenging baselines that serve as a reference for future, more intricate approaches, including those that leverage Large Language Models (LLMs). | Andrei C. Coman, Gianni Barlacchi, Adrià de Gispert |  |
| 551 |  |  [Efficient Continue Training of Temporal Language Model with Structural Information](https://doi.org/10.18653/v1/2023.findings-emnlp.418) |  | 0 | Current language models are mainly trained on snap-shots of data gathered at a particular time, which decreases their capability to generalize over time and model language change. To model the time variable, existing works have explored temporal language models (e.g., TempoBERT) by directly incorporating the timestamp into the training process. While effective to some extent, these methods are limited by the superficial temporal information brought by timestamps, which fails to learn the inherent changes of linguistic components. In this paper, we empirically confirm that the performance of pre-trained language models (PLMs) is closely affiliated with syntactically changed tokens. Based on this observation, we propose a simple yet effective method named Syntax-Guided Temporal Language Model (SG-TLM), which could learn the inherent language changes by capturing an intrinsic relationship between the time prefix and the tokens with salient syntactic change. Experiments on two datasets and three tasks demonstrate that our model outperforms existing temporal language models in both memorization and generalization capabilities. Extensive results further confirm the effectiveness of our approach across different model frameworks, including both encoder-only and decoder-only models (e.g., LLaMA). Our code is available at https://github.com/zhaochen0110/TempoLM. | Zhaochen Su, Juntao Li, Zikang Zhang, Zihan Zhou, Min Zhang |  |
| 552 |  |  [Retrieval-Augmented Parsing for Complex Graphs by Exploiting Structure and Uncertainty](https://doi.org/10.18653/v1/2023.findings-emnlp.419) |  | 0 | Retrieval augmentation enhances generative language models by retrieving informative exemplars relevant for output prediction. However, in realistic graph parsing problems where the output space is large and complex, classic retrieval methods based on input-sentence similarity can fail to identify the most informative exemplars that target graph elements the model is most struggling about, leading to suboptimal retrieval and compromised prediction under limited retrieval budget. In this work, we improve retrieval-augmented parsing for complex graph problems by exploiting two unique sources of information (1) structural similarity and (2) model uncertainty. We propose Structure-aware and Uncertainty-Guided Adaptive Retrieval (SUGAR) that first quantify the model uncertainty in graph prediction and identify its most uncertain subgraphs, and then retrieve exemplars based on their structural similarity with the identified uncertain subgraphs. On a suite of real-world parsing benchmarks with non-trivial graph structure (SMCalflow and E-commerce), SUGAR exhibits a strong advantage over its classic counterparts that do not leverage structure or model uncertainty. | Zi Lin, Quan Yuan, Panupong Pasupat, Jeremiah Z. Liu, Jingbo Shang |  |
| 553 |  |  [When it Rains, it Pours: Modeling Media Storms and the News Ecosystem](https://doi.org/10.18653/v1/2023.findings-emnlp.420) |  | 0 | Most events in the world receive at most brief coverage by the news media. Occasionally, however, an event will trigger a media storm, with voluminous and widespread coverage lasting for weeks instead of days. In this work, we develop and apply a pairwise article similarity model, allowing us to identify story clusters in corpora covering local and national online news, and thereby create a comprehensive corpus of media storms over a nearly two year period. Using this corpus, we investigate media storms at a new level of granularity, allowing us to validate claims about storm evolution and topical distribution, and provide empirical support for previously hypothesized patterns of influence of storms on media coverage and intermedia agenda setting. | Benjamin Litterer, David Jurgens, Dallas Card |  |
| 554 |  |  [Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.421) |  | 0 | Event argument extraction is critical to various natural language processing tasks for providing structured information. Existing works usually extract the event arguments one by one, and mostly neglect to build dependency information among event argument roles, especially from the perspective of event structure. Such an approach hinders the model from learning the interactions between different roles. In this paper, we raise our research question: How to adequately model dependencies between different roles for better performance? To this end, we propose an intra-event and inter-event dependency-aware graph network, which uses the event structure as the fundamental unit to construct dependencies between roles. Specifically, we first utilize the dense intra-event graph to construct role dependencies within events, and then construct dependencies between events by retrieving similar events of the current event through the retrieval module. To further optimize dependency information and event representation, we propose a dependency interaction module and two auxiliary tasks to improve the extraction ability of the model in different scenarios. Experimental results on the ACE05, RAMS, and WikiEvents datasets show the great advantages of our proposed approach. | Hao Li, Yanan Cao, Yubing Ren, Fang Fang, Lanxue Zhang, Yingjie Li, Shi Wang |  |
| 555 |  |  [From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification](https://doi.org/10.18653/v1/2023.findings-emnlp.422) |  | 0 | Retrieval-enhanced methods have become a primary approach in fact verification (FV); it requires reasoning over multiple retrieved pieces of evidence to verify the integrity of a claim. To retrieve evidence, existing work often employs off-the-shelf retrieval models whose design is based on the probability ranking principle. We argue that, rather than relevance, for FV we need to focus on the utility that a claim verifier derives from the retrieved evidence. We introduce the feedback-based evidence retriever (FER) that optimizes the evidence retrieval process by incorporating feedback from the claim verifier. As a feedback signal we use the divergence in utility between how effectively the verifier utilizes the retrieved evidence and the ground-truth evidence to produce the final claim label. Empirical studies demonstrate the superiority of FER over prevailing baselines. | Hengran Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng |  |
| 556 |  |  [How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.423) |  | 0 | Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing model size. In particular, we systematically examine the contrastive learning of DRs, under the framework of Data Augmentation (DA). Our study shows that common DA practices such as query augmentation with generative models and pseudo-relevance label creation using a cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA approach with diverse queries and sources of supervision to progressively train a generalizable DR. As a result, DRAGON, our Dense Retriever trained with diverse AuGmentatiON, is the first BERT-base-sized DR to achieve state-of-the-art effectiveness in both supervised and zero-shot evaluations and even competes with models using more complex late interaction. | ShengChieh Lin, Akari Asai, Minghan Li, Barlas Oguz, Jimmy Lin, Yashar Mehdad, Wentau Yih, Xilun Chen |  |
| 557 |  |  [Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach](https://doi.org/10.18653/v1/2023.findings-emnlp.424) |  | 0 | Shortcut reasoning is an irrational process of inference, which degrades the robustness of an NLP model. While a number of previous work has tackled the identification of shortcut reasoning, there are still two major limitations: (i) a method for quantifying the severity of the discovered shortcut reasoning is not provided; (ii) certain types of shortcut reasoning may be missed. To address these issues, we propose a novel method for identifying shortcut reasoning. The proposed method quantifies the severity of the shortcut reasoning by leveraging out-of-distribution data and does not make any assumptions about the type of tokens triggering the shortcut reasoning. Our experiments on Natural Language Inference and Sentiment Analysis demonstrate that our framework successfully discovers known and unknown shortcut reasoning in the previous work. | Daichi Haraguchi, Kiyoaki Shirai, Naoya Inoue, Natthawut Kertkeidkachorn |  |
| 558 |  |  [Schema-adaptable Knowledge Graph Construction](https://doi.org/10.18653/v1/2023.findings-emnlp.425) |  | 0 | Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schema-adaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We further propose a simple yet effective baseline dubbed AdaKGC, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that AdaKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community. | Hongbin Ye, Honghao Gui, Xin Xu, Xi Chen, Huajun Chen, Ningyu Zhang |  |
| 559 |  |  [Evaluating the Knowledge Base Completion Potential of GPT](https://doi.org/10.18653/v1/2023.findings-emnlp.426) |  | 0 | Structured knowledge bases (KBs) are an asset for search engines and other applications but are inevitably incomplete. Language models (LMs) have been proposed for unsupervised knowledge base completion (KBC), yet, their ability to do this at scale and with high accuracy remains an open question. Prior experimental studies mostly fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we perform a careful evaluation of GPT’s potential to complete the largest public KB: Wikidata. We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task. Nonetheless, it provides solid improvements over earlier approaches with smaller LMs. In particular, we show that it is feasible to extend Wikidata by 27M facts at 90% precision. | Blerta Veseli, Simon Razniewski, JanChristoph Kalo, Gerhard Weikum |  |
| 560 |  |  [Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset](https://doi.org/10.18653/v1/2023.findings-emnlp.427) |  | 0 | Mathematical understanding and reasoning are crucial tasks for assessing the capabilities of artificial intelligence (AI). However, existing benchmarks either require just a few steps of reasoning, or only contain a small amount of data in one specific topic, making it hard to analyse AI’s behaviour with reference to different problems within a specific topic in detail. In this work, we propose Conic10K, a challenging math problem dataset on conic sections in Chinese senior high school education. Our dataset contains various problems with different reasoning depths, while only the knowledge from conic sections is required. Since the dataset only involves a narrow range of knowledge, it is easy to separately analyse the knowledge a model possesses and the reasoning ability it has. For each problem, we provide a high-quality formal representation, the reasoning steps, and the final solution. Experiments show that existing large language models, including GPT-4, exhibit weak performance on complex reasoning. We hope that our findings could inspire more advanced techniques for precise natural language understanding and reasoning. Our dataset and codes are available at https://github.com/whyNLP/Conic10K. | Haoyi Wu, Wenyang Hui, Yezeng Chen, Weiqi Wu, Kewei Tu, Yi Zhou |  |
| 561 |  |  [DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text](https://doi.org/10.18653/v1/2023.findings-emnlp.428) |  | 0 | Spatial reasoning in text plays a crucial role in various real-world applications. Existing approaches for spatial reasoning typically infer spatial relations from pure text, which overlook the gap between natural language and symbolic structures. Graph neural networks (GNNs) have showcased exceptional proficiency in inducing and aggregating symbolic structures. However, classical GNNs face challenges in handling multi-hop spatial reasoning due to the over-smoothing issue, i.e., the performance decreases substantially as the number of graph layers increases. To cope with these challenges, we propose a novel Depth-Wise Graph Neural Network (DepWiGNN). Specifically, we design a novel node memory scheme and aggregate the information over the depth dimension instead of the breadth dimension of the graph, which empowers the ability to collect long dependencies without stacking multiple layers. Experimental results on two challenging multi-hop spatial reasoning datasets show that DepWiGNN outperforms existing spatial reasoning methods. The comparisons with the other three GNNs further demonstrate its superiority in capturing long dependency in the graph. | Shuaiyi Li, Yang Deng, Wai Lam |  |
| 562 |  |  [TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.429) |  | 0 | The ability to detect intent in dialogue systems has become increasingly important in modern technology. These systems often generate a large amount of unlabeled data, and manually labeling this data requires substantial human effort. Semi-supervised methods attempt to remedy this cost by using a model trained on a few labeled examples and then by assigning pseudo-labels to further a subset of unlabeled examples that has a model prediction confidence higher than a certain threshold. However, one particularly perilous consequence of these methods is the risk of picking an imbalanced set of examples across classes, which could lead to poor labels. In the present work, we describe Top-K K-Nearest Neighbor (TK-KNN), which uses a more robust pseudo-labeling approach based on distance in the embedding space while maintaining a balanced set of pseudo-labeled examples across classes through a ranking-based approach. Experiments on several datasets show that TK-KNN outperforms existing models, particularly when labeled data is scarce on popular datasets such as CLINC150 and Banking77. | Nicholas Botzer, David Vasquez, Tim Weninger, Issam H. Laradji |  |
| 563 |  |  [Late Fusion of Transformers for Sentiment Analysis of Code-Switched Data](https://doi.org/10.18653/v1/2023.findings-emnlp.430) |  | 0 | Code-switching is a common phenomenon in multilingual communities and is often used on social media. However, sentiment analysis of code-switched data is a challenging yet less explored area of research. This paper aims to develop a sentiment analysis system for code-switched data. In this paper, we present a novel approach combining two transformers using logits of their output and feeding them to a neural network for classification. We show the efficacy of our approach using two benchmark datasets, viz., English-Hindi (En-Hi), and English-Spanish (En-Es) availed by Microsoft GLUECoS. Our approach results in an F1 score of 73.66% for En-Es and 61.24% for En-Hi, significantly higher than the best model reported for the GLUECoS benchmark dataset. | Gagan Sharma, R. Chinmay, Raksha Sharma |  |
| 564 |  |  [Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information](https://doi.org/10.18653/v1/2023.findings-emnlp.431) |  | 0 | The inductive inference of the knowledge graph aims to complete the potential relations between the new unknown entities in the graph. Most existing methods are based on entity-independent features such as graph structure information and relationship information to inference. However, the neighborhood of these new entities is often too sparse to obtain enough information to build these features effectively. In this work, we propose a knowledge graph inductive inference method that fuses ontology information. Based on the enclosing subgraph, we bring in feature embeddings of concepts corresponding to entities to learn the semantic information implicit in the ontology. Considering that the ontology information of entities may be missing, we build a type constraint regular loss to explicitly model the semantic connections between entities and concepts, and thus capture the missing concepts of entities. Experimental results show that our approach significantly outperforms large language models like ChatGPT on two benchmark datasets, YAGO21K-610 and DB45K-165, and improves the MRR metrics by 15.4% and 44.1%, respectively, when compared with the state-of-the-art methods. | Wentao Zhou, Jun Zhao, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 565 |  |  [Dynamic Stance: Modeling Discussions by Labeling the Interactions](https://doi.org/10.18653/v1/2023.findings-emnlp.432) |  | 0 | Stance detection is an increasingly popular task that has been mainly modeled as a static task, by assigning the expressed attitude of a text toward a given topic. Such a framing presents limitations, with trained systems showing poor generalization capabilities and being strongly topic-dependent. In this work, we propose modeling stance as a dynamic task, by focusing on the interactions between a message and their replies. For this purpose, we present a new annotation scheme that enables the categorization of all kinds of textual interactions. As a result, we have created a new corpus, the Dynamic Stance Corpus (DySC), consisting of three datasets in two middle-resourced languages: Catalan and Dutch. Our data analysis further supports our modeling decisions, empirically showing differences between the annotation of stance in static and dynamic contexts. We fine-tuned a series of monolingual and multilingual models on DySC, showing portability across topics and languages. | Blanca Calvo Figueras, Irene Baucells de la Peña, Tommaso Caselli |  |
| 566 |  |  [Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements](https://doi.org/10.18653/v1/2023.findings-emnlp.433) |  | 0 | Empathetic dialogue is an indispensable part of building harmonious social relationships and contributes to the development of a helpful AI. Previous approaches are mainly based on fine small-scale language models. With the advent of ChatGPT, the application effect of large language models (LLMs) in this field has attracted great attention. This work empirically investigates the performance of LLMs in generating empathetic responses and proposes three improvement methods of semantically similar in-context learning, two-stage interactive generation, and combination with the knowledge base. Extensive experiments show that LLMs can significantly benefit from our proposed methods and is able to achieve state-of-the-art performance in both automatic and human evaluations. Additionally, we explore the possibility of GPT-4 simulating human evaluators. | Yushan Qian, Weinan Zhang, Ting Liu |  |
| 567 |  |  [GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves](https://doi.org/10.18653/v1/2023.findings-emnlp.434) |  | 0 | Markets and policymakers around the world hang on the consequential monetary policy decisions made by the Federal Open Market Committee (FOMC). Publicly available textual documentation of their meetings provides insight into members’ attitudes about the economy. We use GPT-4 to quantify dissent among members on the topic of inflation. We find that transcripts and minutes reflect the diversity of member views about the macroeconomic outlook in a way that is lost or omitted from the public statements. In fact, diverging opinions that shed light upon the committee’s “true” attitudes are almost entirely omitted from the final statements. Hence, we argue that forecasting FOMC sentiment based solely on statements will not sufficiently reflect dissent among the hawks and doves. | Denis Peskoff, Adam Visokay, Sander Schulhoff, Benjamin Wachspress, Alan Blinder, Brandon M. Stewart |  |
| 568 |  |  [DialogQAE: N-to-N Question Answer Pair Extraction from Customer Service Chatlog](https://doi.org/10.18653/v1/2023.findings-emnlp.435) |  | 0 | Harvesting question-answer (QA) pairs from customer service chatlog in the wild is an efficient way to enrich the knowledge base for customer service chatbots in the cold start or continuous integration scenarios. Prior work attempts to obtain 1-to-1 QA pairs from growing customer service chatlog, which fails to integrate the incomplete utterances from the dialog context for composite QA retrieval. In this paper, we propose N-to-N QA extraction task in which the derived questions and corresponding answers might be separated across different utterances. We introduce a suite of generative/discriminative tagging based methods with end-to-end and two-stage variants that perform well on 5 customer service datasets and for the first time setup a benchmark for N-to-N DialogQAE with utterance and session level evaluation metrics. With a deep dive into extracted QA pairs, we find that the relations between and inside the QA pairs can be indicators to analyze the dialogue structure, e.g. information seeking, clarification, barge-in and elaboration. We also show that the proposed models can adapt to different domains and languages, and reduce the labor cost of knowledge accumulation in the real-world product dialogue platform. | Xin Zheng, Tianyu Liu, Haoran Meng, Xu Wang, Yufan Jiang, MengLiang Rao, Binghuai Lin, Yunbo Cao, Zhifang Sui |  |
| 569 |  |  [Inverse Reinforcement Learning for Text Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.436) |  | 0 | We introduce inverse reinforcement learning (IRL) as an effective paradigm for training abstractive summarization models, imitating human summarization behaviors. Our IRL model estimates the reward function using a suite of important sub-rewards for summarization and concurrently optimizes the policy network. Experimental results across datasets in different domains (CNN/DailyMail and WikiHow) and various model sizes (BART-base and BART-large) demonstrate the superiority of our proposed IRL model for summarization over MLE and RL baselines. The resulting summaries exhibit greater similarity to human-crafted gold references, outperforming MLE and RL baselines on metrics such as ROUGE, coverage, novelty, compression ratio, factuality, and human evaluations. | Yu Fu, Deyi Xiong, Yue Dong |  |
| 570 |  |  [MM-Reasoner: A Multi-Modal Knowledge-Aware Framework for Knowledge-Based Visual Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.437) |  | 0 | Thanks to the strong reasoning capabilities of Large Language Models (LLMs), recent approaches to knowledge-based visual question answering (KVQA) utilize LLMs with a global caption of an input image to answer a question. However, these approaches may miss key visual information that is not captured by the caption. Moreover, they cannot fully utilize the visual information required to answer the question. To address these issues, we introduce a new framework called Multi-Modal Knowledge-Aware Reasoner (MM-Reasoner) for KVQA. MM-Reasoner first utilizes a set of vision APIs, such as dense captioners, object detectors, and OCR, to extract detailed information from the image in textual format. Then, it prompts an LLM to extract query-specific knowledge from the extracted textual information to provide a rich representation that contains external knowledge, commonsense, explicit supporting facts, and rationales required for reasoning. Finally, the knowledge, query, and visual input are used to fine-tune a Vision-Language Model (VLM). At test time, MM-Reasoner uses the potential answers predicted by the VLM to iteratively update and optimize the prompt, refining its answer. Empirical studies show that MM-Reasoner achieves state-of-the-art performance on several KVQA datasets. | Mahmoud Khademi, Ziyi Yang, Felipe Frujeri, Chenguang Zhu |  |
| 571 |  |  [Toward Joint Language Modeling for Speech Units and Text](https://doi.org/10.18653/v1/2023.findings-emnlp.438) |  | 0 | Speech and text are two major forms of human language. The research community has been focusing on mapping speech to text or vice versa for many years. However, in the field of language modeling, very little effort has been made to model them jointly. In light of this, we explore joint language modeling for speech units and text. Specifically, we compare different speech tokenizers to transform continuous speech signals into discrete units and use different methods to construct mixed speech-text data. We introduce automatic metrics to evaluate how well the joint LM mixes speech and text. We also fine-tune the LM on downstream spoken language understanding (SLU) tasks with different modalities (speech or text) and test its performance to assess the model’s learning of shared representations. Our results show that by mixing speech units and text with our proposed mixing techniques, the joint LM improves over a speech-only baseline on SLU tasks and shows zero-shot cross-modal transferability. | JuChieh Chou, ChungMing Chien, WeiNing Hsu, Karen Livescu, Arun Babu, Alexis Conneau, Alexei Baevski, Michael Auli |  |
| 572 |  |  [From Chaos to Clarity: Claim Normalization to Empower Fact-Checking](https://doi.org/10.18653/v1/2023.findings-emnlp.439) |  | 0 | With the proliferation of social media platforms, users are exposed to vast information, including posts containing misleading claims. However, the pervasive noise inherent in these posts presents a challenge in identifying precise and prominent claims that require verification. Extracting the core assertions from such posts is arduous and time-consuming. We introduce a novel task, called Claim Normalization (aka ClaimNorm) that aims to decompose complex and noisy social media posts into more straightforward and understandable forms, termed normalized claims. We propose CACN , a pioneering approach that leverages chain-of-thought and claim check-worthiness estimation, mimicking human reasoning processes, to comprehend intricate claims. Moreover, we capitalize on large language models’ powerful in-context learning abilities to provide guidance and improve the claim normalization process. To evaluate the effectiveness of our proposed model, we meticulously compile a comprehensive real-world dataset, CLAN, comprising more than 6k instances of social media posts alongside their respective normalized claims. Experimentation demonstrates that CACN outperforms several baselines across various evaluation measures. A rigorous error analysis validates CACN‘s capabilities and pitfalls. We release our dataset and code at https://github.com/LCS2-IIITD/CACN-EMNLP-2023. | Megha Sundriyal, Tanmoy Chakraborty, Preslav Nakov |  |
| 573 |  |  [Mitigating Biases in Hate Speech Detection from A Causal Perspective](https://doi.org/10.18653/v1/2023.findings-emnlp.440) |  | 0 | Nowadays, many hate speech detectors are built to automatically detect hateful content. However, their training sets are sometimes skewed towards certain stereotypes (e.g., race or religion-related). As a result, the detectors are prone to depend on some shortcuts for predictions. Previous works mainly focus on token-level analysis and heavily rely on human experts’ annotations to identify spurious correlations, which is not only costly but also incapable of discovering higher-level artifacts. In this work, we use grammar induction to find grammar patterns for hate speech and analyze this phenomenon from a causal perspective. Concretely, we categorize and verify different biases based on their spuriousness and influence on the model prediction. Then, we propose two mitigation approaches including Multi-Task Intervention and Data-Specific Intervention based on these confounders. Experiments conducted on 9 hate speech datasets demonstrate the effectiveness of our approaches. | Zhehao Zhang, Jiaao Chen, Diyi Yang |  |
| 574 |  |  [Unmasking the Hidden Meaning: Bridging Implicit and Explicit Hate Speech Embedding Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.441) |  | 0 | Research on automatic hate speech (HS) detection has mainly focused on identifying explicit forms of hateful expressions on user-generated content. Recently, a few works have started to investigate methods to address more implicit and subtle abusive content. However, despite these efforts, automated systems still struggle to correctly recognize implicit and more veiled forms of HS. As these systems heavily rely on proper textual representations for classification, it is crucial to investigate the differences in embedding implicit and explicit messages. Our contribution to address this challenging task is fourfold. First, we present a comparative analysis of transformer-based models, evaluating their performance across five datasets containing implicit HS messages. Second, we examine the embedding representations of implicit messages across different targets, gaining insight into how veiled cases are encoded. Third, we compare and link explicit and implicit hateful messages across these datasets through their targets, enforcing the relation between explicitness and implicitness and obtaining more meaningful embedding representations. Lastly, we show how these newer representation maintains high performance on HS labels, while improving classification in borderline cases. | Nicolás Benjamín Ocampo, Elena Cabrio, Serena Villata |  |
| 575 |  |  [PerturbScore: Connecting Discrete and Continuous Perturbations in NLP](https://doi.org/10.18653/v1/2023.findings-emnlp.442) |  | 0 | With the rapid development of neural network applications in NLP, model robustness problem is gaining more attention. Different from computer vision, the discrete nature of texts makes it more challenging to explore robustness in NLP. Therefore, in this paper, we aim to connect discrete perturbations with continuous perturbations, therefore we can use such connections as a bridge to help understand discrete perturbations in NLP models. Specifically, we first explore how to connect and measure the correlation between discrete perturbations and continuous perturbations. Then we design a regression task as a PerturbScore to learn the correlation automatically. Through experimental results, we find that we can build a connection between discrete and continuous perturbations and use the proposed PerturbScore to learn such correlation, surpassing previous methods used in discrete perturbation measuring. Further, the proposed PerturbScore can be well generalized to different datasets, perturbation methods, indicating that we can use it as a powerful tool to study model robustness in NLP. | Linyang Li, Ke Ren, Yunfan Shao, Pengyu Wang, Xipeng Qiu |  |
| 576 |  |  [InstructoR: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.443) |  | 0 | Compared to traditional single-turn ad-hoc retrieval, conversational retrieval needs to handle the multi-turn conversation and understand the user’s real query intent. However, most existing methods simply fine-tune the pre-trained ad-hoc retriever on limited supervised data, making it challenging for the retriever to fully grasp the entirety of the conversation. In this paper, we find that large language models (LLMs) can accurately discover the user’s query intent from the complex conversation context and provide the supervised signal to instruct the retriever in an unsupervised manner. Therefore, we propose a novel method termed InstructoR to Instruct unsupervised conversational dense Retrieval with LLMs. We design an unsupervised training framework that employs LLMs to estimate the session-passage relevance score as the soft label to guide the retriever’s training. Specially, we devise three instructing strategies from context, query and response perspectives to calculate the relevance score more precisely, including conversational retrieval as conversation generation, question rewrite as latent variable and question response as posterior guide. Experimental results show InstructoR can bring significant improvements across various ad-hoc retrievers, even surpassing the current supervised state-of-the-art method. We also demonstrate the effectiveness of our method under low-resource and zero-shot settings. Our code is publicly available at https://github.com/jinzhuoran/InstructoR/. | Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 577 |  |  [The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.444) |  | 0 | Human evaluation in often considered to be the gold standard method of evaluating a Natural Language Generation system. However, whilst its importance is accepted by the community at large, the quality of its execution is often brought into question. In this position paper, we argue that the generation of more esoteric forms of language - humour, irony and sarcasm - constitutes a subdomain where the characteristics of selected evaluator panels are of utmost importance, and every effort should be made to report demographic characteristics wherever possible, in the interest of transparency and replicability. We support these claims with an overview of each language form and an analysis of examples in terms of how their interpretation is affected by different participant variables. We additionally perform a critical survey of recent works in NLG to assess how well evaluation procedures are reported in this subdomain, and note a severe lack of open reporting of evaluator demographic information, and a significant reliance on crowdsourcing platforms for recruitment. | Tyler Loakman, Aaron Maladry, Chenghua Lin |  |
| 578 |  |  [INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.445) |  | 0 | A salient characteristic of pre-trained language models (PTLMs) is a remarkable improvement in their generalization capability and emergence of new capabilities with increasing model capacity and pre-training dataset size. Consequently, we are witnessing the development of enormous models pushing the state-of-the-art. It is, however, imperative to realize that this inevitably leads to prohibitively long training times, extortionate computing costs, and a detrimental environmental impact. Significant efforts are underway to make PTLM training more efficient through innovations in model architectures, training pipelines, and loss function design, with scant attention being paid to optimizing the utility of training data. The key question that we ask is whether it is possible to train PTLMs by employing only highly informative subsets of the training data while maintaining downstream performance? Building upon the recent progress in informative data subset selection, we show how we can employ submodular optimization to select highly representative subsets of the training corpora and demonstrate that the proposed framework can be applied to efficiently train multiple PTLMs (BERT, BioBERT, GPT-2) using only a fraction of data. Further, we perform a rigorous empirical evaluation to show that the resulting models achieve up to ~99% of the performance of the fully-trained models. We made our framework publicly available at https://github.com/Efficient-AI/ingenious. | H. S. V. N. S. Kowndinya Renduchintala, Krishnateja Killamsetty, Sumit Bhatia, Milan Aggarwal, Ganesh Ramakrishnan, Rishabh K. Iyer, Balaji Krishnamurthy |  |
| 579 |  |  [Towards General Error Diagnosis via Behavioral Testing in Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.446) |  | 0 | Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models. However, applying behavioral testing to machine translation (MT) systems is challenging as it generally requires human efforts to craft references for evaluating the translation quality of such systems on newly generated test cases. Existing works in behavioral testing of MT systems circumvent this by evaluating translation quality without references, but this restricts diagnosis to specific types of errors, such as incorrect translation of single numeric or currency words. In order to diagnose general errors, this paper proposes a new Bilingual Translation Pair Generation based Behavior Testing (BTPGBT) framework for conducting behavioral testing of MT systems. The core idea of BTPGBT is to employ a novel bilingual translation pair generation (BTPG) approach that automates the construction of high-quality test cases and their pseudoreferences. Experimental results on various MT systems demonstrate that BTPGBT could provide comprehensive and accurate behavioral testing results for general error diagnosis, which further leads to several insightful findings. Our code and data are available at https: //github.com/wujunjie1998/BTPGBT. | Junjie Wu, Lemao Liu, DitYan Yeung |  |
| 580 |  |  [Retrieval-Augmented Few-shot Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.447) |  | 0 | Retrieval-augmented methods are successful in the standard scenario where the retrieval space is sufficient; whereas in the few-shot scenario with limited retrieval space, this paper shows it is non-trivial to put them into practice. First, it is impossible to retrieve semantically similar examples by using an off-the-shelf metric and it is crucial to learn a task-specific retrieval metric; Second, our preliminary experiments demonstrate that it is difficult to optimize a plausible metric by minimizing the standard cross-entropy loss. The in-depth analyses quantitatively show minimizing cross-entropy loss suffers from the weak supervision signals and the severe gradient vanishing issue during the optimization. To address these issues, we introduce two novel training objectives, namely EM-L and R-L, which provide more task-specific guidance to the retrieval metric by the EM algorithm and a ranking-based loss, respectively. Extensive experiments on 10 datasets prove the superiority of the proposed retrieval augmented methods on the performance. | Guoxin Yu, Lemao Liu, Haiyun Jiang, Shuming Shi, Xiang Ao |  |
| 581 |  |  [Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.448) |  | 0 | Real-world Temporal Knowledge Graphs keep growing with time and new entities and facts emerge continually, necessitating a model that can extrapolate to future timestamps and transfer knowledge for new components. Therefore, our work first dives into this more realistic issue, lifelong TKG reasoning, where existing methods can only address part of the challenges. Specifically, we formulate lifelong TKG reasoning as a temporal-path-based reinforcement learning (RL) framework. Then, we add temporal displacement into the action space of RL to extrapolate for the future and further propose a temporal-rule-based reward shaping to guide the training. To transfer and update knowledge, we design a new edge-aware message passing module, where the embeddings of new entities and edges are inductive. We conduct extensive experiments on three newly constructed benchmarks for lifelong TKG reasoning. Experimental results show the outperforming effectiveness of our model against all well-adapted baselines. | Zhongwu Chen, Chengjin Xu, Fenglong Su, Zhen Huang, Yong Dou |  |
| 582 |  |  [Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.449) |  | 0 | Recent advancements in natural language processing have demonstrated the efficacy of pre-trained language models for various downstream tasks through prompt-based fine-tuning. In contrast to standard fine-tuning, which relies solely on labeled examples, prompt-based fine-tuning combines a few labeled examples (few shot) with guidance through prompts tailored for the specific language and task. For low-resource languages, where labeled examples are limited, prompt-based fine-tuning appears to be a promising alternative. In this paper, we compare prompt-based and standard fine-tuning for the popular task of text classification in Urdu and Roman Urdu languages. We conduct experiments using five datasets, covering different domains, and pre-trained multilingual transformers. The results reveal that significant improvement of up to 13% in accuracy is achieved by prompt-based fine-tuning over standard fine-tuning approaches. This suggests the potential of prompt-based fine-tuning as a valuable approach for low-resource languages with limited labeled data. | Faizad Ullah, Ubaid Azam, Ali Faheem, Faisal Kamiran, Asim Karim |  |
| 583 |  |  [Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.450) |  | 0 | Cross-document relation extraction (CodRED) task aims to infer the relation between two entities mentioned in different documents within a reasoning path. Previous studies have concentrated on merely capturing implicit relations between the entities. However, humans usually utilize explicit information chains such as hyperlinks or additional searches to find the relations between two entities. Inspired by this, we propose Path wIth expLOraTion (PILOT) that provides the enhanced reasoning path by exploring the explicit clue information within the documents. PILOT finds the bridging entities which directly guide the paths between the entities and then employs them as stepstones to navigate desirable paths. We show that models with PILOT outperform the baselines in the CodRED task. Furthermore, we offer a variety of analyses to verify the validity of the reasoning paths constructed through PILOT, including evaluations using large language models such as ChatGPT. | Junyoung Son, Jinsung Kim, Jungwoo Lim, Yoonna Jang, Heuiseok Lim |  |
| 584 |  |  [The student becomes the master: Outperforming GPT3 on Scientific Factual Error Correction](https://doi.org/10.18653/v1/2023.findings-emnlp.451) |  | 0 | Due to the prohibitively high cost of creating error correction datasets, most Factual Claim Correction methods rely on a powerful verification model to guide the correction process. This leads to a significant drop in performance in domains like Scientific Claim Correction, where good verification models do not always exist. In this work we introduce SciFix, a claim correction system that does not require a verifier but is able to outperform existing methods by a considerable margin — achieving correction accuracy of 84% on the SciFact dataset, 77% on SciFact-Open and 72.75% on the CovidFact dataset, compared to next best accuracies of 7.6%, 5% and 15% on the same datasets respectively. Our method leverages the power of prompting with LLMs during training to create a richly annotated dataset that can be used for fully supervised training and regularization. We additionally use a claim-aware decoding procedure to improve the quality of corrected claims. Our method outperforms the very LLM that was used to generate the annotated dataset — with FewShot Prompting on GPT3.5 achieving 58%, 61% and 64% on the respective datasets, a consistently lower correction accuracy, despite using nearly 800 times as many parameters as our model. | Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnabás Póczos |  |
| 585 |  |  [Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.452) |  | 0 | Neural models, including large language models (LLMs), achieve superior performance on multi-hop question-answering. To elicit reasoning capabilities from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to generate both the reasoning chain and the answer, which enhances the model’s capabilities in conducting multi-hop reasoning. However, several challenges still remain: such as struggling with inaccurate reasoning, hallucinations, and lack of interpretability. On the other hand, information extraction (IE) identifies entities, relations, and events grounded to the text. The extracted structured information can be easily interpreted by humans and machines (Grishman, 2019). In this work, we investigate constructing and leveraging extracted semantic structures (graphs) for multi-hop question answering, especially the reasoning process. Empirical results and human evaluations show that our framework: generates more faithful reasoning chains and substantially improves the QA performance on two benchmark datasets. Moreover, the extracted structures themselves naturally provide grounded explanations that are preferred by humans, as compared to the generated reasoning chains and saliency-based explanations. | Ruosen Li, Xinya Du |  |
| 586 |  |  [Hierarchical Catalogue Generation for Literature Review: A Benchmark](https://doi.org/10.18653/v1/2023.findings-emnlp.453) |  | 0 | Scientific literature review generation aims to extract and organize important information from an abundant collection of reference papers and produces corresponding reviews while lacking a clear and logical hierarchy. We observe that a high-quality catalogue-guided generation process can effectively alleviate this problem. Therefore, we present an atomic and challenging task named Hierarchical Catalogue Generation for Literature Review as the first step for review generation, which aims to produce a hierarchical catalogue of a review paper given various references. We construct a novel English Hierarchical Catalogues of Literature Reviews Dataset with 7.6k literature review catalogues and 389k reference papers. To accurately assess the model performance, we design two evaluation metrics for informativeness and similarity to ground truth from semantics and structure. Our extensive analyses verify the high quality of our dataset and the effectiveness of our evaluation metrics. We further benchmark diverse experiments on state-of-the-art summarization models like BART and large language models like ChatGPT to evaluate their capabilities. We further discuss potential directions for this task to motivate future research. | Kun Zhu, Xiaocheng Feng, Xiachong Feng, Yingsheng Wu, Bing Qin |  |
| 587 |  |  [MCC-KD: Multi-CoT Consistent Knowledge Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.454) |  | 0 | Large language models (LLMs) have showcased remarkable capabilities in complex reasoning through chain of thought (CoT) prompting. Recently, there has been a growing interest in transferring these reasoning abilities from LLMs to smaller models. However, achieving both the diversity and consistency in rationales presents a challenge. In this paper, we focus on enhancing these two aspects and propose Multi-CoT Consistent Knowledge Distillation (MCC-KD) to efficiently distill the reasoning capabilities. In MCC-KD, we generate multiple rationales for each question and enforce consistency among their predictions by minimizing the bidirectional KL-divergence between the answer distributions. We conduct comprehensive experiments to investigate the effectiveness of MCC-KD with different model architectures (LLaMA/FlanT5) and various model scales (3B/7B/11B/13B) on both mathematical reasoning and commonsense reasoning benchmarks. The empirical results demonstrate that MCC-KD achieves superior performance on in-distribution datasets and exhibits a strong generalization ability on out-of-distribution datasets. | Hongzhan Chen, Siyue Wu, Xiaojun Quan, Rui Wang, Ming Yan, Ji Zhang |  |
| 588 |  |  [An Empirical Study of Frame Selection for Text-to-Video Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.455) |  | 0 | Text-to-video retrieval (TVR) aims to find the most relevant video in a large video gallery given a query text. The intricate and abundant context of the video challenges the performance and efficiency of TVR. To handle the serialized video contexts, existing methods typically select a subset of frames within a video to represent the video content for TVR. How to select the most representative frames is a crucial issue, whereby the selected frames are required to not only retain the semantic information of the video but also promote retrieval efficiency by excluding temporally redundant frames. In this paper, we make the first empirical study of frame selection for TVR. We systemically classify existing frame selection methods into text-free and text-guided ones, under which we detailedly analyze six different frame selections in terms of effectiveness and efficiency. Among them, two frame selections are first developed in this paper. According to the comprehensive analysis on multiple TVR benchmarks, we empirically conclude that the TVR with proper frame selections can significantly improve the retrieval efficiency without sacrificing the retrieval performance. | Mengxia Wu, Min Cao, Yang Bai, Ziyin Zeng, Chen Chen, Liqiang Nie, Min Zhang |  |
| 589 |  |  [Conditional Natural Language Inference](https://doi.org/10.18653/v1/2023.findings-emnlp.456) |  | 0 | To properly explain sentence pairs that provide contradictory (different) information for different conditions, we introduce the task of conditional natural language inference (Cond-NLI) and focus on automatically extracting contradictory aspects and their conditions from a sentence pair. Cond-NLI can help to provide a full spectrum of information, such as when there are multiple answers to a question each addressing a specific condition, or reviews with different opinions for different conditions. We show that widely-used feature-attribution explanation models are not suitable for finding conditions, especially when sentences are long and are written independently. We propose a simple yet effective model for the original NLI task that can successfully extract conditions while not requiring token-level annotations. Our model enhances the interpretability of the NLI task while maintaining comparable accuracy. To evaluate models for the Cond-NLI, we build and release a token-level annotated dataset BioClaim which contains potentially contradictory claims from the biomedical domain. Our experiments show that our proposed model outperforms the full cross-encoder and other baselines in extracting conditions. It also performs on-par with GPT-3 which has an order of magnitude more parameters and trained on a huge amount of data. | Youngwoo Kim, Razieh Rahimi, James Allan |  |
| 590 |  |  [Contrastive Distant Supervision for Debiased and Denoised Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.457) |  | 0 | Distant Supervision (DS) is a promising learning approach for MRC by leveraging easily-obtained question-answer pairs. Unfortunately, the heuristically annotated dataset will inevitably lead to mislabeled instances, resulting in answer bias and context noise problems. To learn debiased and denoised MRC models, this paper proposes the Contrastive Distant Supervision algorithm – CDS, which can learn to distinguish confusing and noisy instances via confidence-aware contrastive learning. Specifically, to eliminate answer bias, CDS samples counterfactual negative instances, which ensures that MRC models must take both answer information and question-context interaction into consideration. To denoise distantly annotated contexts, CDS samples confusing negative instances to increase the margin between correct and mislabeled instances. We further propose a confidence-aware contrastive loss to model and leverage the uncertainty of all DS instances during learning. Experimental results show that CDS is effective and can even outperform supervised MRC models without manual annotations. | Ning Bian, Hongyu Lin, Xianpei Han, Ben He, Le Sun |  |
| 591 |  |  [KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness](https://doi.org/10.18653/v1/2023.findings-emnlp.458) |  | 0 | In recent years, Pre-trained Language Models (PLMs) have shown their superiority by pre-training on unstructured text corpus and then fine-tuning on downstream tasks. On entity-rich textual resources like Wikipedia, Knowledge-Enhanced PLMs (KEPLMs) incorporate the interactions between tokens and mentioned entities in pre-training, and are thus more effective on entity-centric tasks such as entity linking and relation classification. Although exploiting Wikipedia’s rich structures to some extent, conventional KEPLMs still neglect a unique layout of the corpus where each Wikipedia page is around a topic entity (identified by the page URL and shown in the page title). In this paper, we demonstrate that KEPLMs without incorporating the topic entities will lead to insufficient entity interaction and biased (relation) word semantics. We thus propose KEPLET, a novel Knowledge-Énhanced Pre-trained LanguagE model with Topic entity awareness. In an end-to-end manner, KEPLET identifies where to add the topic entity’s information in a Wikipedia sentence, fuses such information into token and mentioned entities representations, and supervises the network learning, through which it takes topic entities back into consideration. Experiments demonstrated the generality and superiority of KEPLET which was applied to two representative KEPLMs, achieving significant improvements on four entity-centric tasks. | Yichuan Li, Jialong Han, Kyumin Lee, Chengyuan Ma, Benjamin Z. Yao, Xiaohu Liu |  |
| 592 |  |  [Revisiting Large Language Models as Zero-shot Relation Extractors](https://doi.org/10.18653/v1/2023.findings-emnlp.459) |  | 0 | Relation extraction (RE) consistently involves a certain degree of labeled or unlabeled data even if under zero-shot setting. Recent studies have shown that large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt, which provides the possibility of extracting relations from text without any data and parameter tuning. This work focuses on the study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors. On the one hand, we analyze the drawbacks of existing RE prompts and attempt to incorporate recent prompt techniques such as chain-of-thought (CoT) to improve zero-shot RE. We propose the summarize-and-ask (SumAsk) prompting, a simple prompt recursively using LLMs to transform RE inputs to the effective question answering (QA) format. On the other hand, we conduct comprehensive experiments on various benchmarks and settings to investigate the capabilities of LLMs on zero-shot RE. Specifically, we have the following findings: (i) SumAsk consistently and significantly improves LLMs performance on different model sizes, benchmarks and settings; (ii) Zero-shot prompting with ChatGPT achieves competitive or superior results compared with zero-shot and fully supervised methods; (iii) LLMs deliver promising performance in extracting overlapping relations; (iv) The performance varies greatly regarding different relations. Different from small language models, LLMs are effective in handling challenge none-of-the-above (NoTA) relation. | Guozheng Li, Peng Wang, Wenjun Ke |  |
| 593 |  |  [Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.460) |  | 0 | Dialogue summarization involves a wide range of scenarios and domains. However, existing methods generally only apply to specific scenarios or domains. In this study, we propose a new pre-trained model specifically designed for multi-scenario multi-domain dialogue summarization. It adopts a multi-stage pre-training strategy to reduce the gap between the pre-training objective and fine-tuning objective. Specifically, we first conduct domain-aware pre-training using large-scale multi-scenario multi-domain dialogue data to enhance the adaptability of our pre-trained model. Then, we conduct task-oriented pre-training using large-scale multi-scenario multi-domain “dialogue-summary” parallel data annotated by ChatGPT to enhance the dialogue summarization ability of our pre-trained model. Experimental results on three dialogue summarization datasets from different scenarios and domains indicate that our pre-trained model significantly outperforms previous state-of-the-art models in full fine-tuning, zero-shot, and few-shot settings. | Weixiao Zhou, Gengyao Li, Xianfu Cheng, Xinnian Liang, Junnan Zhu, Feifei Zhai, Zhoujun Li |  |
| 594 |  |  [Towards large language model-based personal agents in the enterprise: Current trends and open problems](https://doi.org/10.18653/v1/2023.findings-emnlp.461) |  | 0 | There is an emerging trend to use large language models (LLMs) to reason about complex goals and orchestrate a set of pluggable tools or APIs to accomplish a goal. This functionality could, among other use cases, be used to build personal assistants for knowledge workers. While there are impressive demos of LLMs being used as autonomous agents or for tool composition, these solutions are not ready mission-critical enterprise settings. For example, they are brittle to input changes, and can produce inconsistent results for the same inputs. These use cases have many open problems in an exciting area of NLP research, such as trust and explainability, consistency and reproducibility, adherence to guardrails and policies, best practices for composable tool design, and the need for new metrics and benchmarks. This vision paper illustrates some examples of LLM-based autonomous agents that reason and compose tools, highlights cases where they fail, surveys some of the recent efforts in this space, and lays out the research challenges to make these solutions viable for enterprises. | Vinod Muthusamy, Yara Rizk, Kiran Kate, Praveen Venkateswaran, Vatche Isahagian, Ashu Gulati, Parijat Dube |  |
| 595 |  |  [CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.462) |  | 0 | Large Language Models (LLMs) have made significant progress in utilizing tools, but their ability is limited by API availability and the instability of implicit reasoning, particularly when both planning and execution are involved. To overcome these limitations, we propose CREATOR, a novel framework that enables LLMs to create their own tools using documentation and code realization. CREATOR disentangles abstract tool creation and concrete decision execution, resulting in improved performance. We evaluate CREATOR on MATH and TabMWP benchmarks, respectively consisting of challenging math competition problems and diverse tabular contents. Remarkably, CREATOR outperforms existing chain-of-thought, program-of-thought, and tool-using baselines. Additionally, we introduce the Creation Challenge dataset, featuring 2K diverse questions, to emphasize the necessity and benefits of LLMs’ tool creation ability. Further research demonstrates that leveraging LLMs as tool creators facilitates knowledge transfer, and LLMs exhibit varying levels of tool creation abilities, enabling them to adapt to diverse situations. The tool creation ability revolutionizes the LLM’s problem-solving paradigm, driving us closer to the next frontier of artificial intelligence. | Cheng Qian, Chi Han, Yi Ren Fung, Yujia Qin, Zhiyuan Liu, Heng Ji |  |
| 596 |  |  [Query-based Image Captioning from Multi-context 360cdegree Images](https://doi.org/10.18653/v1/2023.findings-emnlp.463) |  | 0 | A 360-degree image captures the entire scene without the limitations of a camera’s field of view, which makes it difficult to describe all the contexts in a single caption. We propose a novel task called Query-based Image Captioning (QuIC) for 360-degree images, where a query (words or short phrases) specifies the context to describe. This task is more challenging than the conventional image captioning task, which describes salient objects in images, as it requires fine-grained scene understanding to select the contents consistent with user’s intent based on the query. We construct a dataset for the new task that comprises 3,940 360-degree images and 18,459 pairs of queries and captions annotated manually. Experiments demonstrate that fine-tuning image captioning models further on our dataset can generate more diverse and controllable captions from multiple contexts of 360-degree images. | Koki Maeda, Shuhei Kurita, Taiki Miyanishi, Naoaki Okazaki |  |
| 597 |  |  [Auto Search Indexer for End-to-End Document Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.464) |  | 0 | Generative retrieval, which is a new advanced paradigm for document retrieval, has recently attracted research interests, since it encodes all documents into the model and directly generates the retrieved documents. However, its power is still underutilized since it heavily relies on the “preprocessed” document identifiers (docids), thus limiting its retrieval performance and ability to retrieve new documents. In this paper, we propose a novel fully end-to-end retrieval paradigm. It can not only end-to-end learn the best docids for existing and new documents automatically via a semantic indexing module, but also perform end-to-end document retrieval via an encoder-decoder-based generative model, namely Auto Search Indexer (ASI). Besides, we design a reparameterization mechanism to combine the above two modules into a joint optimization framework. Extensive experimental results demonstrate the superiority of our model over advanced baselines on both public and industrial datasets and also verify the ability to deal with new documents. | Tianchi Yang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 598 |  |  ['Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion](https://doi.org/10.18653/v1/2023.findings-emnlp.465) |  | 0 | We study stereotypes embedded within one of the most popular text-to-image generators: Stable Diffusion. We answer the question: what stereotypes of gender and nationality/continental identity does Stable Diffusion display in the absence of such information i.e. what gender and nationality/continental identity is assigned to ‘a person,’ or to ‘a person from Asia.’ Using CLIP-cosine similarity for zero-shot classification of images generated by CLIP-based Stable Diffusion v2.1 verified by manual examination, we chronicle results from 136 prompts (50 results/prompt) of front-facing images of faces from 6 different continents, 27 countries and 3 genders. We observe how Stable Diffusion results of ‘a person’ without any additional gender/nationality information correspond closest to images of men (avg. similarity 0.64) and least with persons of nonbinary gender (avg. similarity 0.41), and to persons from Europe/North America (avg. similarities 0.71 and 0.68, respectively) over Africa/Asia (avg. similarities 0.43 and 0.41, respectively), pointing towards Stable Diffusion having a concerning representation of personhood to be a European/North American man. We also show continental stereotypes and resultant harms e.g. a person from Oceania is deemed to be Australian/New Zealander (avg. similarities 0.77 and 0.74, respectively) over Papua New Guinean (avg. similarity 0.31), pointing to the erasure of Indigenous Oceanic peoples, who form a majority over descendants of colonizers both in Papua New Guinea and in Oceania overall. Finally, we unexpectedly observe a pattern of sexualization of women, specifically Latin American, Mexican, Indian and Egyptian women, confirmed through an NSFW detector and verified by manual examination. This demonstrates how Stable Diffusion perpetuates Western fetishization of women of color through objectification in media, which if left unchecked will worsen this stereotypical representation. All code and relevant data will be made publicly available. | Sourojit Ghosh, Aylin Caliskan |  |
| 599 |  |  [Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.466) |  | 0 | The size and the computational load of fine-tuning large-scale pre-trained neural network are becoming two major obstacles in adopting machine learning in many applications. Continual learning (CL) can serve as a remedy through enabling knowledge-transfer across sequentially arriving tasks which relaxes the need to fine-tune all network weights from scratch. However, existing CL algorithms primarily consider learning unimodal vision-only or language-only tasks. We develop a transformer-based CL architecture for learning bimodal vision-and-language tasks based on increasing the number of the learnable parameters dynamically and using knowledge distillation. The new additional parameters are used to specialize the network for each task. Our approach enables sharing information between the tasks while addressing the challenge of catastrophic forgetting. Our approach is scalable learning to a large number of tasks because it requires little memory and time overhead. Our model reaches state-of-the-art performance on challenging vision-and-language tasks. | Yuliang Cai, Jesse Thomason, Mohammad Rostami |  |
| 600 |  |  [Evaluating Verifiability in Generative Search Engines](https://doi.org/10.18653/v1/2023.findings-emnlp.467) |  | 0 | Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines—Bing Chat, NeevaAI, perplexity.ai, and YouChat—across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that these results are concerningly low for systems that may serve as a primary tool for information-seeking users, especially given their facade of trustworthiness. We hope that our results further motivate the development of trustworthy generative search engines and help researchers and users better understand the shortcomings of existing commercial systems. | Nelson F. Liu, Tianyi Zhang, Percy Liang |  |
| 601 |  |  [Enhancing Abstractiveness of Summarization Models through Calibrated Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.468) |  | 0 | In this paper, we propose a novel approach named DisCal to enhance the level of abstractiveness (measured by n-gram overlap) without sacrificing the informativeness (measured by ROUGE) of generated summaries. DisCal exposes diverse pseudo summaries with two supervision to the student model. Firstly, the best pseudo summary is identified in terms of abstractiveness and informativeness and used for sequence-level distillation. Secondly, their ranks are used to ensure the student model to assign higher prediction scores to summaries with higher ranks. Our experiments show that DisCal outperforms prior methods in abstractive summarization distillation, producing highly abstractive and informative summaries. | Hwanjun Song, Igor Shalyminov, Hang Su, Siffi Singh, Kaisheng Yao, Saab Mansour |  |
| 602 |  |  [Visually Grounded Continual Language Learning with Selective Specialization](https://doi.org/10.18653/v1/2023.findings-emnlp.469) |  | 0 | A desirable trait of an artificial agent acting in the visual world is to continually learn a sequence of language-informed tasks while striking a balance between sufficiently specializing in each task and building a generalized knowledge for transfer. Selective specialization, i.e., a careful selection of model components to specialize in each task, is a strategy to provide control over this trade-off. However, the design of selection strategies requires insights on the role of each model component in learning rather specialized or generalizable representations, which poses a gap in current research. Thus, our aim with this work is to provide an extensive analysis of selection strategies for visually grounded continual language learning. Due to the lack of suitable benchmarks for this purpose, we introduce two novel diagnostic datasets that provide enough control and flexibility for a thorough model analysis. We assess various heuristics for module specialization strategies as well as quantifiable measures for two different types of model architectures. Finally, we design conceptually simple approaches based on our analysis that outperform common continual learning baselines. Our results demonstrate the need for further efforts towards better aligning continual learning algorithms with the learning behaviors of individual model parts. | Kyra Ahrens, Lennart Bengtson, Jae Hee Lee, Stefan Wermter |  |
| 603 |  |  [RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.470) |  | 0 | We introduce RoMQA, the first benchmark for robust, multi-evidence, multi-answer question answering (QA). RoMQA contains clusters of questions that are derived from related constraints mined from the Wikidata knowledge graph. RoMQA evaluates robustness of QA models to varying constraints by measuring worst-case performance within each question cluster. Compared to prior QA datasets, RoMQA has more human-written questions that require reasoning over more evidence text and have, on average, many more correct answers. In addition, human annotators rate RoMQA questions as more natural or likely to be asked by people. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is challenging: zeroshot and few-shot models perform similarly to naive baselines, while supervised retrieval methods perform well below gold evidence upper bounds. Moreover, existing models are not robust to variations in question constraints, but can be made more robust by tuning on clusters of related questions. Our results show that RoMQA is a challenging benchmark for large language models, and provides a quantifiable test to build more robust QA methods. | Victor Zhong, Weijia Shi, Wentau Yih, Luke Zettlemoyer |  |
| 604 |  |  [Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers](https://doi.org/10.18653/v1/2023.findings-emnlp.471) |  | 0 | Recent approaches have explored language- guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved. Our code is available at: https://github.com/WeiKangda/TALC.git. | Kangda Wei, Sayan Ghosh, Rakesh R. Menon, Shashank Srivastava |  |
| 605 |  |  [Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.472) |  | 0 | We present PeerSum, a novel dataset for generating meta-reviews of scientific papers. The meta-reviews can be interpreted as abstractive summaries of reviews, multi-turn discussions and the paper abstract. These source documents have a rich inter-document relationship with an explicit hierarchical conversational structure, cross-references and (occasionally) conflicting information. To introduce the structural inductive bias into pre-trained language models, we introduce RAMMER (Relationship-aware Multi-task Meta-review Generator), a model that uses sparse attention based on the conversational structure and a multi-task training objective that predicts metadata features (e.g., review ratings). Our experimental results show that RAMMER outperforms other strong baseline models in terms of a suite of automatic evaluation metrics. Further analyses, however, reveal that RAMMER and other models struggle to handle conflicts in source documents, suggesting meta-review generation is a challenging task and a promising avenue for further research. | Miao Li, Eduard H. Hovy, Jey Han Lau |  |
| 606 |  |  [VIPHY: Probing "Visible" Physical Commonsense Knowledge](https://doi.org/10.18653/v1/2023.findings-emnlp.473) |  | 0 | Vision-language models (VLMs) have shown remarkable performance on visual reasoning tasks (e.g. attributes, location). While such tasks measure the requisite knowledge to ground and reason over a given visual instance, they do not, however, measure the ability of VLMs to retain and generalize such knowledge. In this work, we evaluate VLMs’ ability to acquire “visible” physical knowledge – the information that is easily accessible from images of static scenes, particularly along the dimensions of object color, size, and space. We build an automatic pipeline to derive a comprehensive knowledge resource for calibrating and probing these models. Our results indicate a severe gap between model and human performance across all three dimensions. Furthermore, we demonstrate that a caption pretrained LM significantly outperforms VLMs on both size and spatial tasks – highlighting that despite sufficient access to ground language with visual modality, they struggle to retain such knowledge. | Shikhar Singh, Ehsan Qasemi, Muhao Chen |  |
| 607 |  |  [Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data](https://doi.org/10.18653/v1/2023.findings-emnlp.474) |  | 0 | Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is under-explored. We investigate whether LLMs can augment clinical data for detecting Alzheimer’s Disease (AD)-related signs and symptoms from electronic health records (EHRs), a challenging task that requires high expertise. We create a novel pragmatic taxonomy for AD sign and symptom progression based on expert knowledge and generated three datasets: (1) a gold dataset annotated by human experts on longitudinal EHRs of AD patients; (2) a silver dataset created by the data-to-label method, which labels sentences from a public EHR collection with AD-related signs and symptoms; and (3) a bronze dataset created by the label-to-data method which generates sentences with AD-related signs and symptoms based on the label definition. We train a system to detect AD-related signs and symptoms from EHRs. We find that the silver and bronze datasets improves the system performance, outperforming the system using only the gold dataset. This shows that LLMs can generate synthetic clinical data for a complex task by incorporating expert knowledge, and our label-to-data method can produce datasets that are free of sensitive information, while maintaining acceptable quality. | Rumeng Li, Xun Wang, Hong Yu |  |
| 608 |  |  [Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.475) |  | 0 | Stylized dialogue generation systems aim to produce coherent and context-aware dialogues while effectively emulating the desired style. Generating stylized dialogue is valuable yet challenging due to the scarce parallel data. Existing methods often synthesize pseudo data through back translation, yet suffer from noisy and context-agnostic style signals caused by insufficient guidance on target style features. To address this, we propose the knowledge-augmented stylized dialogue generation model, which includes a feature-guided style knowledge selection module that utilizes context and response features. Specifically, we retrieve dialogue-related style sentences from style corpus to explicitly provide clear style signals. We design a feature-guided selection module with response-related contrastive learning and style responsiveness Kullback-Leibler losses to enhance generation at both semantic and stylized levels. Our approach demonstrates satisfactory performance on two public stylized dialogue benchmarks in both automatic and human evaluations. | Jinpeng Li, Zekai Zhang, Xiuying Chen, Dongyan Zhao, Rui Yan |  |
| 609 |  |  [Probing LLMs for Joint Encoding of Linguistic Categories](https://doi.org/10.18653/v1/2023.findings-emnlp.476) |  | 0 | Large Language Models (LLMs) exhibit impressive performance on a range of NLP tasks, due to the general-purpose linguistic knowledge acquired during pretraining. Existing model interpretability research (Tenney et al., 2019) suggests that a linguistic hierarchy emerges in the LLM layers, with lower layers better suited to solving syntactic tasks and higher layers employed for semantic processing. Yet, little is known about how encodings of different linguistic phenomena interact within the models and to what extent processing of linguistically-related categories relies on the same, shared model representations. In this paper, we propose a framework for testing the joint encoding of linguistic categories in LLMs. Focusing on syntax, we find evidence of joint encoding both at the same (related part-of-speech (POS) classes) and different (POS classes and related syntactic dependency relations) levels of linguistic hierarchy. Our cross-lingual experiments show that the same patterns hold across languages in multilingual LLMs. | Giulio Starace, Konstantinos Papakostas, Rochelle Choenni, Apostolos Panagiotopoulos, Matteo Rosati, Alina Leidinger, Ekaterina Shutova |  |
| 610 |  |  [On Robustness of Finetuned Transformer-based NLP Models](https://doi.org/10.18653/v1/2023.findings-emnlp.477) |  | 0 | Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models. In this paper, we characterize changes between pretrained and finetuned language model representations across layers using two metrics: CKA and STIR. Further, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on classification tasks from General Language Understanding Evaluation (GLUE) benchmark, and generation tasks like summarization, free-form generation and question generation. GPT-2 representations are more robust than BERT and T5 across multiple types of input perturbation. Although models exhibit good robustness broadly, dropping nouns, verbs or changing characters are the most impactful. Overall, this study provides valuable insights into perturbation-specific weaknesses of popular Transformer-based models which should be kept in mind when passing inputs. | Pavan Kalyan Reddy Neerudu, Subba Reddy Oota, Mounika Marreddy, Venkateswara Rao Kagita, Manish Gupta |  |
| 611 |  |  [Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.478) |  | 0 | In executable task-oriented semantic parsing, the system aims to translate users’ utterances in natural language to machine-interpretable programs (API calls) that can be executed according to pre-defined API specifications. With the popularity of Large Language Models (LLMs), in-context learning offers a strong baseline for such scenarios, especially in data-limited regimes. However, LLMs are known to hallucinate and therefore pose a formidable challenge in constraining generated content. Thus, it remains uncertain if LLMs can effectively perform task-oriented utterance-to-API generation, where respecting the API’s structural and task-specific constraints is crucial. In this work, we seek to measure, analyze and mitigate such constraints violations. First, we identify the categories of various constraints in obtaining API-semantics from task-oriented utterances, and define fine-grained metrics that complement traditional ones. Second, we leverage these metrics to conduct a detailed error analysis of constraints violations seen in state-of-the-art LLMs, which motivates us to investigate two popular mitigation strategies– Semantic-Retrieval of Demonstrations (SRD) and API-aware Constrained Decoding (API-CD). Our experiments show that these strategies are effective at reducing constraints violations and improving the quality of the generated API calls, but require careful consideration given their implementation complexity and latency. | Shufan Wang, Sébastien Jean, Sailik Sengupta, James Gung, Nikolaos Pappas, Yi Zhang |  |
| 612 |  |  [Entity Disambiguation on a Tight Labeling Budget](https://doi.org/10.18653/v1/2023.findings-emnlp.479) |  | 0 | Many real-world NLP applications face the challenge of training an entity disambiguation model for a specific domain with a small labeling budget. In this setting there is often access to a large unlabeled pool of documents. It is then natural to ask the question: which samples should be selected for annotation? In this paper we propose a solution that combines feature diversity with low rank correction. Our sampling strategy is formulated in the context of bilinear tensor models. Our experiments show that the proposed approach can significantly reduce the amount of labeled data necessary to achieve a given performance. | Audi Primadhanty, Ariadna Quattoni |  |
| 613 |  |  [Topic-DPR: Topic-based Prompts for Dense Passage Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.480) |  | 0 | Prompt-based learning’s efficacy across numerous natural language processing tasks has led to its integration into dense passage retrieval. Prior research has mainly focused on enhancing the semantic understanding of pre-trained language models by optimizing a single vector as a continuous prompt. This approach, however, leads to a semantic space collapse; identical semantic information seeps into all representations, causing their distributions to converge in a restricted region. This hinders differentiation between relevant and irrelevant passages during dense retrieval. To tackle this issue, we present Topic-DPR, a dense passage retrieval model that uses topic-based prompts. Unlike the single prompt method, multiple topic-based prompts are established over a probabilistic simplex and optimized simultaneously through contrastive learning. This encourages representations to align with their topic distributions, improving space uniformity. Furthermore, we introduce a novel positive and negative sampling strategy, leveraging semi-structured data to boost dense retrieval efficiency. Experimental results from two datasets affirm that our method surpasses previous state-of-the-art retrieval techniques. | Qingfa Xiao, Shuangyin Li, Lei Chen |  |
| 614 |  |  [Quantifying the Dialect Gap and its Correlates Across Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.481) |  | 0 | Historically, researchers and consumers have noticed a decrease in quality when applying NLP tools to minority variants of languages (i.e. Puerto Rican Spanish or Swiss German), but studies exploring this have been limited to a select few languages. Additionally, past studies have mainly been conducted in a monolingual context, so cross-linguistic trends have not been identified and tied to external factors. In this work, we conduct a comprehensive evaluation of the most influential, state-of-the-art large language models (LLMs) across two high-use applications, machine translation and automatic speech recognition, to assess their functionality on the regional dialects of several high- and low-resource languages. Additionally, we analyze how the regional dialect gap is correlated with economic, social, and linguistic factors. The impact of training data, including related factors like dataset size and its construction procedure, is shown to be significant but not consistent across models or languages, meaning a one-size-fits-all approach cannot be taken in solving the dialect gap. This work will lay the foundation for furthering the field of dialectal NLP by laying out evident disparities and identifying possible pathways for addressing them through mindful data collection. | Anjali Kantharuban, Ivan Vulic, Anna Korhonen |  |
| 615 |  |  [RECAL: Sample-Relation Guided Confidence Calibration over Tabular Data](https://doi.org/10.18653/v1/2023.findings-emnlp.482) |  | 0 | Tabular-format data is widely adopted in various real-world applications. Various machine learning models have achieved remarkable success in both industrial applications and data-science competitions. Despite these successes, most current machine learning methods for tabular data lack accurate confidence estimation, which is needed by some high-risk sensitive applications such as credit modeling and financial fraud detection. In this paper, we study the confidence estimation of machine learning models applied to tabular data. The key finding of our paper is that a real-world tabular dataset typically contains implicit sample relations, and this can further help to obtain a more accurate estimation. To this end, we introduce a general post-training confidence calibration framework named RECAL to calibrate the predictive confidence of current machine learning models by employing graph neural networks to model the relations between different samples. We perform extensive experiments on tabular datasets with both implicit and explicit graph structures and show that RECAL can significantly improve the calibration quality compared to the conventional method without considering the sample relations. | Haotian Wang, Zhen Zhang, Mengting Hu, Qichao Wang, Liang Chen, Yatao Bian, Bingzhe Wu |  |
| 616 |  |  [Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment](https://doi.org/10.18653/v1/2023.findings-emnlp.483) |  | 0 | Pre-trained vision and language models such as CLIP have witnessed remarkable success in connecting images and texts with a primary focus on English texts. Despite recent efforts to extend CLIP to support other languages, disparities in performance among different languages have been observed due to uneven resource availability. Additionally, current cross-lingual transfer methods of those pre-trained models would consume excessive resources for a large number of languages. Therefore, we propose a new parameter-efficient cross-lingual transfer learning framework that utilizes a translation-based alignment method to mitigate multilingual disparities and explores parameter-efficient fine-tuning methods for parameter-efficient cross-lingual transfer. Extensive experiments on XTD and Multi30K datasets, covering 11 languages under zero-shot, few-shot, and full-dataset learning scenarios, show that our framework significantly reduces the multilingual disparities among languages and improves cross-lingual transfer results, especially in low-resource scenarios, while only keeping and fine-tuning an extremely small number of parameters compared to the full model (e.g., Our framework only requires 0.16% additional parameters of a full-model for each language in the few-shot learning scenario). | Zhen Zhang, Jialu Wang, Xin Eric Wang |  |
| 617 |  |  [Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of Lexical Overlap in Train and Test Reference Summaries](https://doi.org/10.18653/v1/2023.findings-emnlp.484) |  | 0 | Ideal summarization models should generalize to novel summary-worthy content without remembering reference training summaries by rote. However, a single average performance score on the entire test set is inadequate in determining such model competencies. We propose a fine-grained evaluation protocol by partitioning a test set based on the lexical similarity of reference test summaries with training summaries. We observe up to a 5x (1.2x) difference in ROUGE-2 (entity recall) scores between the subsets with the lowest and highest similarity. Next, we show that such training repetitions also make a model vulnerable to rote learning, reproducing data artifacts such as factual errors, especially when reference test summaries are lexically close to training summaries. Consequently, we propose to limit lexical repetitions in training summaries during both supervised fine-tuning and likelihood calibration stages to improve the performance on novel test cases while retaining average performance. Our automatic and human evaluations on novel test subsets and recent news articles show that limiting lexical repetitions in training summaries can prevent rote learning and improve generalization. | Prafulla Kumar Choubey, Alexander R. Fabbri, Caiming Xiong, ChienSheng Wu |  |
| 618 |  |  [Pseudointelligence: A Unifying Lens on Language Model Evaluation](https://doi.org/10.18653/v1/2023.findings-emnlp.485) |  | 0 | With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities. Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that “(perceived) intelligence lies in the eye of the beholder.” That is, that claims of intelligence are meaningful only when their evaluator is taken into account. Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator. We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods. | Shikhar Murty, Orr Paradise, Pratyusha Sharma |  |
| 619 |  |  [GDA: Grammar-based Data Augmentation for Text Classification using Slot Information](https://doi.org/10.18653/v1/2023.findings-emnlp.486) |  | 0 | Recent studies propose various data augmentation approaches to resolve the low-resource problem in natural language processing tasks. Data augmentation is a successful solution to this problem and recent strategies give variation on sentence structures to boost performance. However, these approaches can potentially lead to semantic errors and produce semantically noisy data due to the unregulated variation of sentence structures. In an effort to combat these semantic errors, we leverage slot information, the representation of the context of keywords from a sentence, and form a data augmentation strategy which we propose, called GDA. Our strategy employs algorithms that construct and manipulate rules of context-aware grammar, utilizing this slot information. The algorithms extract recurrent patterns by distinguishing words with slots and form the “rules of grammar”—a set of injective relations between a sentence’s semantics and its syntactical structure—to augment the dataset. The augmentation is done in an automated manner with the constructed rules and thus, GDA is explainable and reliable without any human intervention. We evaluate GDA with state-of-the-art data augmentation techniques, including those using pre-trained language models, and the result illustrates that GDA outperforms all other data augmentation methods by 19.38%. Extensive experiments show that GDA is an effective data augmentation strategy that incorporates word semantics for more accurate and diverse data. | Joonghyuk Hahn, Hyunjoon Cheon, Elizabeth Orwig, SuHyeon Kim, SangKi Ko, YoSub Han |  |
| 620 |  |  [Implicit Sense-labeled Connective Recognition as Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.487) |  | 0 | Implicit Discourse Relation Recognition (IDRR) involves identifying the sense label of an implicit connective between adjacent text spans. This has traditionally been approached as a classification task. However, some downstream tasks require more than just a sense label as well as the specific connective used. This paper presents Implicit Sense-labeled Connective Recognition (ISCR), which identifies the implicit connectives and their sense labels between adjacent text spans. ISCR can be treated as a classification task, but a large number of potential categories, sense labels, and uneven distribution of instances among them make this difficult. Instead, this paper handles the task as a text-generation task, using an encoder-decoder model to generate both connectives and their sense labels. Here, we explore a classification method and three kinds of text-generation methods. From our evaluation results on PDTB-3.0, we found that our method outperforms the conventional classification-based method. | Yui Oka, Tsutomu Hirao |  |
| 621 |  |  [VISTA: Visual-Textual Knowledge Graph Representation Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.488) |  | 0 | Knowledge graphs represent human knowledge using triplets composed of entities and relations. While most existing knowledge graph embedding methods only consider the structure of a knowledge graph, a few recently proposed multimodal methods utilize images or text descriptions of entities in a knowledge graph. In this paper, we propose visual-textual knowledge graphs (VTKGs), where not only entities but also triplets can be explained using images, and both entities and relations can accompany text descriptions. By compiling visually expressible commonsense knowledge, we construct new benchmark datasets where triplets themselves are explained by images, and the meanings of entities and relations are described using text. We propose VISTA, a knowledge graph representation learning method for VTKGs, which incorporates the visual and textual representations of entities and relations using entity encoding, relation encoding, and triplet decoding transformers. Experiments show that VISTA outperforms state-of-the-art knowledge graph completion methods in real-world VTKGs. | Jaejun Lee, Chanyoung Chung, Hochang Lee, Sungho Jo, Joyce Jiyoung Whang |  |
| 622 |  |  [Dynamic Stashing Quantization for Efficient Transformer Training](https://doi.org/10.18653/v1/2023.findings-emnlp.489) |  | 0 | Large Language Models (LLMs) have demonstrated impressive performance on a range of Natural Language Processing (NLP) tasks. Unfortunately, the immense amount of computations and memory accesses required for LLM training makes them prohibitively expensive in terms of hardware cost, and thus challenging to deploy in use cases such as on-device learning. In this paper, motivated by the observation that LLM training is memory-bound, we propose a novel dynamic quantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a special focus on reducing the memory operations, but also enjoys the other benefits of low precision training, such as the reduced arithmetic cost. We conduct a thorough study on two translation tasks (trained-from-scratch) and three classification tasks (fine-tuning). DSQ reduces the amount of arithmetic operations by 20.95× and the number of DRAM operations by 2.55× on IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in on-device learning. | Guo Yang, Daniel Lo, Robert D. Mullins, Yiren Zhao |  |
| 623 |  |  [A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.490) |  | 0 | Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4’s law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such case, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains. Code is available at https://github.com/srhthu/LM-CompEval-Legal | Ruihao Shui, Yixin Cao, Xiang Wang, TatSeng Chua |  |
| 624 |  |  [A Lightweight Method to Generate Unanswerable Questions in English](https://doi.org/10.18653/v1/2023.findings-emnlp.491) |  | 0 | If a question cannot be answered with the available information, robust systems for question answering (QA) should know \*not\* to answer. One way to build QA models that do this is with additional training data comprised of unanswerable questions, created either by employing annotators or through automated methods for unanswerable question generation. To show that the model complexity of existing automated approaches is not justified, we examine a simpler data augmentation method for unanswerable question generation in English: performing antonym and entity swaps on answerable questions. Compared to the prior state-of-the-art, data generated with our training-free and lightweight strategy results in better models (+1.6 F1 points on SQuAD 2.0 data with BERT-large), and has higher human-judged relatedness and readability. We quantify the raw benefits of our approach compared to no augmentation across multiple encoder models, using different amounts of generated data, and also on TydiQA-MinSpan data (+9.3 F1 points with BERT-large). Our results establish swaps as a simple but strong baseline for future work. | Vagrant Gautam, Miaoran Zhang, Dietrich Klakow |  |
| 625 |  |  [Automatic Evaluate Dialogue Appropriateness by Using Dialogue Act](https://doi.org/10.18653/v1/2023.findings-emnlp.492) |  | 0 | Evaluation of dialogue systems requires assessing various aspects, among which appropriateness holds significance as a core element of communicative language competence. However, current evaluations heavily rely on human judgments, which are time-consuming, labor-intensive, prone to biases, and lacking objectivity. In this paper, we introduce Dialogue Act Appropriateness (DAA), a novel method that utilizes the underlying patterns of dialogue act transitions to evaluate the appropriateness of chatbot responses. We learn transition patterns from human-human dialogue corpora, evaluating chatbot appropriateness by measuring the similarity of their transition patterns to those observed in human-human dialogues. To validate DAA, we annotate a test dataset by manually evaluating the appropriateness of dialogues from multiple chatbot systems. The experimental results demonstrate a strong correlation between our evaluation metric and human ratings, establishing the reliability of DAA as a measure of dialogue appropriateness. | Bao Chen, Yuanjie Wang, Zeming Liu, Yuhang Guo |  |
| 626 |  |  [TabPrompt: Graph-based Pre-training and Prompting for Few-shot Table Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.493) |  | 0 | Table Understanding (TU) is a crucial aspect of information extraction that enables machines to comprehend the semantics behind tabular data. However, existing methods of TU cannot deal with the scarcity of labeled tabular data. In addition, these methods primarily focus on the textual content within the table, disregarding the inherent topological information of the table. This can lead to a misunderstanding of the tabular semantics. In this paper, we propose TabPrompt, a new framework to tackle the above challenges. Prompt-based learning has gained popularity due to its exceptional performance in few-shot learning. Thus, we introduce prompt-based learning to handle few-shot TU. Furthermore, Graph Contrastive Learning (Graph CL) demonstrates remarkable capabilities in capturing topological information, making Graph Neural Networks an ideal method for encoding tables. Hence, we develop a novel Graph CL method tailored to tabular data. This method serves as the pretext task during the pre-training phase, allowing the generation of vector representations that incorporate the table’s topological information. The experimental results of outperforming all strong baselines demonstrate the strength of our method in few-shot table understanding tasks. | Rihui Jin, Jianan Wang, Wei Tan, Yongrui Chen, Guilin Qi, Wang Hao |  |
| 627 |  |  [Towards Formality-Aware Neural Machine Translation by Leveraging Context Information](https://doi.org/10.18653/v1/2023.findings-emnlp.494) |  | 0 | Formality is one of the most important linguistic properties to determine the naturalness of translation. Although a target-side context contains formality-related tokens, the sparsity within the context makes it difficult for context-aware neural machine translation (NMT) models to properly discern them. In this paper, we introduce a novel training method to explicitly inform the NMT model by pinpointing key informative tokens using a formality classifier. Given a target context, the formality classifier guides the model to concentrate on the formality-related tokens within the context. Additionally, we modify the standard cross-entropy loss, especially toward the formality-related tokens obtained from the classifier. Experimental results show that our approaches not only improve overall translation quality but also reflect the appropriate formality from the target context. | Dohee Kim, Yujin Baek, Soyoung Yang, Jaegul Choo |  |
| 628 |  |  [Improving Seq2Seq Grammatical Error Correction via Decoding Interventions](https://doi.org/10.18653/v1/2023.findings-emnlp.495) |  | 0 | The sequence-to-sequence (Seq2Seq) approach has recently been widely used in grammatical error correction (GEC) and shows promising performance. However, the Seq2Seq GEC approach still suffers from two issues. First, a Seq2Seq GEC model can only be trained on parallel data, which, in GEC task, is often noisy and limited in quantity. Second, the decoder of a Seq2Seq GEC model lacks an explicit awareness of the correctness of the token being generated. In this paper, we propose a unified decoding intervention framework that employs an external critic to assess the appropriateness of the token to be generated incrementally, and then dynamically influence the choice of the next token. We discover and investigate two types of critics: a pre-trained left-to-right language model critic and an incremental target-side grammatical error detector critic. Through extensive experiments on English and Chinese datasets, our framework consistently outperforms strong baselines and achieves results competitive with state-of-the-art methods. | Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang |  |
| 629 |  |  [Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses](https://doi.org/10.18653/v1/2023.findings-emnlp.496) |  | 0 | In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings. | Aysa Xuemo Fan, Haoran Zhang, Luc Paquette, Rui Zhang |  |
| 630 |  |  [Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefix](https://doi.org/10.18653/v1/2023.findings-emnlp.497) |  | 0 | Many real-world applications require making multiple predictions from the same text. Fine-tuning a large pre-trained language model for each downstream task causes computational burdens in the inference time due to several times of forward passes. To amortize the computational cost, freezing the language model and building lightweight models for downstream tasks based on fixed text representations are common solutions. Accordingly, how to learn fixed but general text representations that can generalize well to unseen downstream tasks becomes a challenge. Previous works have shown that the generalizability of representations can be improved by fine-tuning the pre-trained language model with some source tasks in a multi-tasking way. In this work, we propose a prefix-based method to learn the fixed text representations with source tasks. We learn a task-specific prefix for each source task independently and combine them to get the final representations. Our experimental results show that prefix-based training performs better than multi-tasking training and can update the text representations at a smaller computational cost than multi-tasking training. | KuanHao Huang, Liang Tan, Rui Hou, Sinong Wang, Amjad Almahairi, Ruty Rinott |  |
| 631 |  |  [Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.498) |  | 0 | Model-agnostic meta-learning has garnered attention as a promising technique for enhancing few-shot cross-lingual transfer learning in low-resource scenarios. However, little attention was paid to the impact of data selection strategies on this cross-lingual meta-transfer method, particularly the sampling of cross-lingual meta-training data (i.e. meta-tasks) at the syntactic level to reduce language gaps. In this paper, we propose a Meta-Task Collector-based Cross-lingual Meta-Transfer framework (MeTaCo-XMT) to adapt different data selection strategies to construct meta-tasks for meta-transfer learning. Syntactic differences have an effect on transfer performance, so we consider a syntactic similarity sampling strategy and propose a syntactic distance metric model consisting of a syntactic encoder block based on the pre-trained model and a distance metric block using Word Move’s Distance (WMD). Additionally, we conduct experiments with three different data selection strategies to instantiate our framework and analyze their performance impact. Experimental results on two multilingual NLP datasets, Wikiann and TydiQA, demonstrate the significant superiority of our approach compared to existing strong baselines. | Linjuan Wu, Zongyi Guo, Baoliang Cui, Haihong Tang, Weiming Lu |  |
| 632 |  |  [Reasoning Makes Good Annotators : An Automatic Task-specific Rules Distilling Framework for Low-resource Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.499) |  | 0 | Relation extraction is often challenged by insufficient labeled data. Previous methods exploit knowledge from unlabeled data by generating pseudo labels in a self-training pipeline, which suffers a gradual drift problem. Logic rules, a transferable and explainable form of expert knowledge, have achieved promising success by improving the model with weak labels. But manually writing comprehensive rules set is challenging and tedious. To alleviate the human labor of writing high-quality rules, in this work, we propose ARIA, an Automatic task-specific Rules distilling framework. Specifically, we guide the pre-trained language model to reason rules as experts and compose them into robust compound rules for data labeling. Besides, ARIA could continuously enrich the rules set to power the labeling ability by discovering reliable model-labeled data for distinguishable rules generation. Experiments on two public datasets demonstrate the effectiveness of ARIA in a low-resource scenario. | Yilin Lu, Juncheng Li, Xiaoqiang Wang, Haochen Shi, Tao Chen, Siliang Tang |  |
| 633 |  |  [Co-training and Co-distillation for Quality Improvement and Compression of Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.500) |  | 0 | Knowledge Distillation (KD) compresses computationally expensive pre-trained language models (PLMs) by transferring their knowledge to smaller models, allowing their use in resource-constrained or real-time settings. However, most smaller models fail to surpass the performance of the original larger model, resulting in sacrificing performance to improve inference speed. To address this issue, we propose Co-Training and Co-Distillation (CTCD), a novel framework that improves performance and inference speed together by co-training two models while mutually distilling knowledge. The CTCD framework successfully achieves this based on two significant findings: 1) Distilling knowledge from the smaller model to the larger model during co-training improves the performance of the larger model. 2) The enhanced performance of the larger model further boosts the performance of the smaller model. The CTCD framework shows promise as it can be combined with existing techniques like architecture design or data augmentation, replacing one-way KD methods, to achieve further performance improvement. Extensive ablation studies demonstrate the effectiveness of CTCD, and the small model distilled by CTCD outperforms the original larger model by a significant margin of 1.66 on the GLUE benchmark. | Hayeon Lee, Rui Hou, Jongpil Kim, Davis Liang, Hongbo Zhang, Sung Ju Hwang, Alexander Min |  |
| 634 |  |  [ReadPrompt: A Readable Prompting Method for Reliable Knowledge Probing](https://doi.org/10.18653/v1/2023.findings-emnlp.501) |  | 0 | Knowledge probing is a task to assess the knowledge encoded within pre-trained language models (PLMs) by having the PLM complete prompts such as “Italy is located in __,”. The model’s prediction precision serves as a lower bound for the amount of knowledge it contains. Subsequent works explore training a series of vectors as prompts to guide PLMs towards more accurate predictions. However, these methods compromise the readability of the prompts. We cannot directly understand these prompts from their literal meaning, making it difficult to verify whether they are correct. Consequently, the credibility of probing results derived from these prompts is diminished. To address the issue, we propose a novel method called ReadPrompt, which aims to identify meaningful sentences to serve as prompts. Experiments show that ReadPrompt achieves state-of-the-art performance on the current knowledge probing benchmark. Moreover, since the prompt is readable, we discovered a misalignment between constructed prompts and knowledge, which is also present in current prompting methods verified by an attack experiment. We claim that the probing outcomes of the current prompting methods are unreliable that overestimate the knowledge contained within PLMs. | Zezhong Wang, Luyao Ye, Hongru Wang, WaiChung Kwan, David Ho, KamFai Wong |  |
| 635 |  |  [Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency](https://doi.org/10.18653/v1/2023.findings-emnlp.502) |  | 0 | Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders. However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category). We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions. Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level. We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios. | Zilin Xiao, Linjun Shou, Xingyao Zhang, Jie Wu, Ming Gong, Daxin Jiang |  |
| 636 |  |  [How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench](https://doi.org/10.18653/v1/2023.findings-emnlp.503) |  | 0 | We investigate the predictability of large language model (LLM) capabilities: given records of past experiments using different model families, numbers of parameters, tasks, and numbers of in-context examples, can we accurately predict LLM performance on new experiment configurations? Answering this question has practical implications for LLM users (e.g., deciding which models to try), developers (e.g., prioritizing evaluation on representative tasks), and the research community (e.g., identifying hard-to-predict capabilities that warrant further investigation). We study the performance prediction problem on experiment records from BIG-bench. On a random train-test split, an MLP-based predictor achieves an R2 score greater than 95%, indicating the presence of learnable patterns within the experiment records. We then formulate the problem of searching for “small-bench,” an informative subset of BIG-bench tasks from which the performance on the full set can be maximally recovered. We find a subset as informative as BIG-bench Hard for evaluating new model families, while being 3× smaller. Additionally, we find competitive subsets by clustering task representations learned by our MLP-based predictor and selecting tasks close to cluster centroids, highlighting the importance of task diversity in constructing “small-bench.” | Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, Robin Jia |  |
| 637 |  |  [POSQA: Probe the World Models of LLMs with Size Comparisons](https://doi.org/10.18653/v1/2023.findings-emnlp.504) |  | 0 | Embodied language comprehension emphasizes that language understanding is not solely a matter of mental processing in the brain but also involves interactions with the physical and social environment. With the explosive growth of Large Language Models (LLMs) and their already ubiquitous presence in our daily lives, it is becoming increasingly necessary to verify their real-world understanding. Inspired by cognitive theories, we propose POSQA: a Physical Object Size Question Answering dataset with simple size comparison questions to examine the extremity and analyze the potential mechanisms of the embodied comprehension of the latest LLMs. We show that even the largest LLMs today perform poorly under the zero-shot setting. We then push their limits with advanced prompting techniques and external knowledge augmentation. Furthermore, we investigate whether their real-world comprehension primarily derives from contextual information or internal weights and analyse the impact of prompt formats and report bias of different objects. Our results show that real-world understanding that LLMs shaped from textual data can be vulnerable to deception and confusion by the surface form of prompts, which makes it less aligned with human behaviours. | Chang Shu, Jiuzhou Han, Fangyu Liu, Ehsan Shareghi, Nigel Collier |  |
| 638 |  |  [Hierarchical Fusion for Online Multimodal Dialog Act Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.505) |  | 0 | We propose a framework for online multimodal dialog act (DA) classification based on raw audio and ASR-generated transcriptions of current and past utterances. Existing multimodal DA classification approaches are limited by ineffective audio modeling and late-stage fusion. We showcase significant improvements in multimodal DA classification by integrating modalities at a more granular level and incorporating recent advancements in large language and audio models for audio feature extraction. We further investigate the effectiveness of self-attention and cross-attention mechanisms in modeling utterances and dialogs for DA classification. We achieve a substantial increase of 3 percentage points in the F1 score relative to current state-of-the-art models on two prominent DA classification datasets, MRDA and EMOTyDA. | Md Messal Monem Miah, Adarsh Pyarelal, Ruihong Huang |  |
| 639 |  |  [STEER: Unified Style Transfer with Expert Reinforcement](https://doi.org/10.18653/v1/2023.findings-emnlp.506) |  | 0 | While text style transfer has many applications across natural language processing, the core premise of transferring from a single source style is unrealistic in a real-world setting. In this work, we focus on arbitrary style transfer: rewriting a text from an arbitrary, unknown style to a target style. We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified frame-work developed to overcome the challenge of limited parallel data for style transfer. STEER involves automatically generating a corpus of style-transfer pairs using a product of experts during decoding. The generated offline data is then used to pre-train an initial policy before switching to online, off-policy reinforcement learning for further improvements via fine-grained reward signals. STEER is unified and can transfer to multiple target styles from an arbitrary, unknown source style, making it particularly flexible and efficient. Experimental results on a challenging dataset with text from a diverse set of styles demonstrate state-of-the-art results compared to competitive baselines. Remarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on overall style transfer quality, despite being 226 times smaller in size. We also show STEER is robust, maintaining its style transfer capabilities on out-of-domain data, and surpassing nearly all baselines across various styles. The success of our method highlights the potential of RL algorithms when augmented with controllable decoding to overcome the challenge of limited data supervision. | Skyler Hallinan, Faeze Brahman, Ximing Lu, Jaehun Jung, Sean Welleck, Yejin Choi |  |
| 640 |  |  [Enhancing Argument Structure Extraction with Efficient Leverage of Contextual Information](https://doi.org/10.18653/v1/2023.findings-emnlp.507) |  | 0 | Argument structure extraction (ASE) aims to identify the discourse structure of arguments within documents. Previous research has demonstrated that contextual information is crucial for developing an effective ASE model. However, we observe that merely concatenating sentences in a contextual window does not fully utilize contextual information and can sometimes lead to excessive attention on less informative sentences. To tackle this challenge, we propose an Efficient Context-aware ASE model (ECASE) that fully exploits contextual information by enhancing modeling capacity and augmenting training data. Specifically, we introduce a sequence-attention module and distance-weighted similarity loss to aggregate contextual information and argumentative information. Additionally, we augment the training data by randomly masking discourse markers and sentences, which reduces the model’s reliance on specific words or less informative sentences. Our experiments on five datasets from various domains demonstrate that our model achieves state-of-the-art performance. Furthermore, ablation studies confirm the effectiveness of each module in our model. | Yun Luo, Zhen Yang, Fandong Meng, Yingjie Li, Jie Zhou, Yue Zhang |  |
| 641 |  |  [Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate](https://doi.org/10.18653/v1/2023.findings-emnlp.508) |  | 0 | Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD. | Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, Bing Qin |  |
| 642 |  |  [Culturally Aware Natural Language Inference](https://doi.org/10.18653/v1/2023.findings-emnlp.509) |  | 0 | Humans produce and consume language in a particular cultural context, which includes knowledge about specific norms and practices. A listener’s awareness of the cultural context is critical for interpreting the speaker’s meaning. A simple expression like \*I didn’t leave a tip\* implies a strong sense of dissatisfaction when tipping is assumed to be the norm. As NLP systems reach users from different cultures, achieving culturally aware language understanding becomes increasingly important. However, current research has focused on building cultural knowledge bases without studying how such knowledge leads to contextualized interpretations of texts. In this work, we operationalize cultural variations in language understanding through a natural language inference (NLI) task that surfaces cultural variations as label disagreement between annotators from different cultural groups. We introduce the first Culturally Aware Natural Language Inference (CALI) dataset with 2.7K premise-hypothesis pairs annotated by two cultural groups located in the U.S. and India. With CALI, we categorize how cultural norms affect language understanding and present an evaluation framework to assess at which levels large language models are culturally aware. Our dataset is available at https://github.com/SALT-NLP/CulturallyAwareNLI. | Jing Huang, Diyi Yang |  |
| 643 |  |  [End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply Systems](https://doi.org/10.18653/v1/2023.findings-emnlp.510) |  | 0 | Reply suggestion systems represent a staple component of many instant messaging and email systems. However, the requirement to produce sets of replies, rather than individual replies, makes the task poorly suited for out-of-the-box retrieval architectures, which only consider individual message-reply similarity. As a result, these system often rely on additional post-processing modules to diversify the outputs. However, these approaches are ultimately bottlenecked by the performance of the initial retriever, which in practice struggles to present a sufficiently diverse range of options to the downstream diversification module, leading to the suggestions being less relevant to the user. In this paper, we consider a novel approach that radically simplifies this pipeline through an autoregressive text-to-text retrieval model, that learns the smart reply task end-to-end from a dataset of (message, reply set) pairs obtained via bootstrapping. Empirical results show this method consistently outperforms a range of state-of-the-art baselines across three datasets, corresponding to a 5.1%-17.9% improvement in relevance, and a 0.5%-63.1% improvement in diversity compared to the best baseline approach. We make our code publicly available. | Benjamin Towle, Ke Zhou |  |
| 644 |  |  [Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness](https://doi.org/10.18653/v1/2023.findings-emnlp.511) |  | 0 | The potential of using a large language model (LLM) as a knowledge base (KB) has sparked significant interest. To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge. Existing work on editing LLMs has partially addressed the issue of dependency, when the editing of a fact should apply to its lexical variations without disrupting irrelevant ones. However, they neglect the dependency between a fact and its logical implications. We propose an evaluation protocol with an accompanying question-answering dataset, StandUp, that provides a comprehensive assessment of the editing process considering the above notions of dependency. Our protocol involves setting up a controlled environment in which we edit facts and monitor their impact on LLMs, along with their implications based on If-Then rules. Extensive experiments on StandUp show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts. | Zichao Li, Ines Arous, Siva Reddy, Jackie Chi Kit Cheung |  |
| 645 |  |  [Effects of Human Adversarial and Affable Samples on BERT Generalizability](https://doi.org/10.18653/v1/2023.findings-emnlp.512) |  | 0 | BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training data quality, not quantity, on a model’s generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e. sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e. sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus or even degradation. In contrast, h-affables may not contribute to a model’s generalizability and may even degrade generalization performance. | Aparna Elangovan, Estrid He, Yuan Li, Karin Verspoor |  |
| 646 |  |  [Logic Unveils Truth, While Disguise Obscures It: Transition Logic Augmented Response Selection for Multi-Turn Dialogue](https://doi.org/10.18653/v1/2023.findings-emnlp.513) |  | 0 | Multi-turn response selection aims to retrieve a response for a dialogue context from a candidate pool and negative sampling is the key to its retrieval performance. However, previous methods of negative samples tend to yield false negatives due to the one-to-many property in open-domain dialogue, which is detrimental to the optimization process. To deal with the problem, we propose a sequential variational ladder auto-encoder to capture the diverse one-to-many transition pattern of multiple characteristics in open-domain dialogue. The learned transition logic thus assists in identifying potential positives in disguise. Meanwhile, we propose a TRIGGER framework to adjust negative sampling in the training process such that the scope of false negatives dynamically updates according to the model capacity. Extensive experiments on two benchmarks verify the effectiveness of our approach. | Tingchen Fu, Xueliang Zhao, Lemao Liu, Rui Yan |  |
| 647 |  |  [Are Language Models Worse than Humans at Following Prompts? It's Complicated](https://doi.org/10.18653/v1/2023.findings-emnlp.514) |  | 0 | Prompts have been the center of progress in advancing language models’ zero-shot and few-shot performance. However, recent work finds that models can perform surprisingly well when given intentionally irrelevant or misleading prompts. Such results may be interpreted as evidence that model behavior is not “human like’. In this study, we challenge a central assumption in such work: that humans would perform badly when given pathological instructions. We find that humans are able to reliably ignore irrelevant instructions and thus, like models, perform well on the underlying task despite an apparent lack of signal regarding the task they are being asked to do. However, when given deliberately misleading instructions, humans follow the instructions faithfully, whereas models do not. Thus, our conclusion is mixed with respect to prior work. We argue against the earlier claim that high performance with irrelevant prompts constitutes evidence against models’ instruction understanding, but we reinforce the claim that models’ failure to follow misleading instructions raises concerns. More broadly, we caution that future research should not idealize human behaviors as a monolith and should not train or evaluate models to mimic assumptions about these behaviors without first validating humans’ behaviors empirically. | Albert Webson, Alyssa Marie Loo, Qinan Yu, Ellie Pavlick |  |
| 648 |  |  [A Sequence-to-Structure Approach to Document-level Targeted Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.515) |  | 0 | Most previous studies on aspect-based sentiment analysis (ABSA) were carried out at the sentence level, while the research of document-level ABSA has not received enough attention. In this work, we focus on the document-level targeted sentiment analysis task, which aims to extract the opinion targets consisting of multi-level entities from a review document and predict their sentiments. We propose a Sequence-to-Structure (Seq2Struct) approach to address the task, which is able to explicitly model the hierarchical structure among multiple opinion targets in a document, and capture the long-distance dependencies among affiliated entities across sentences. In addition to the existing Seq2Seq approach, we further construct four strong baselines with different pretrained models. Experimental results on six domains show that our Seq2Struct approach outperforms all the baselines significantly. Aside from the performance advantage in outputting the multi-level target-sentiment pairs, our approach has another significant advantage - it can explicitly display the hierarchical structure of the opinion targets within a document. Our source code is publicly released at https://github.com/NUSTM/Doc-TSA-Seq2Struct. | Nan Song, Hongjie Cai, Rui Xia, Jianfei Yu, Zhen Wu, Xinyu Dai |  |
| 649 |  |  [Generating Extractive Answers: Gated Recurrent Memory Reader for Conversational Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.516) |  | 0 | Conversational question answering (CQA) is a more complicated task than traditional single-turn machine reading comprehension (MRC). Different from large language models (LLMs) like ChatGPT, the models of CQA need to extract answers from given contents to answer follow-up questions according to conversation history. In this paper, we propose a novel architecture, i.e., Gated Recurrent Memory Reader (GRMR), which integrates traditional extractive MRC models into a generalized sequence-to-sequence framework. After the passage is encoded, the decoder will generate the extractive answers turn by turn. Different from previous models that concatenate the previous questions and answers as context superficially and redundantly, our model can use less storage space and consider historical memory deeply and selectively. Experiments on the Conversational Question Answering (CoQA) dataset show that our model achieves comparable results to most models with the least space occupancy. | Xuanyu Zhang, Qing Yang |  |
| 650 |  |  [Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.517) |  | 0 | Deep learning approaches exhibit promising performances on various text tasks. However, they are still struggling on medical text classification since samples are often extremely imbalanced and scarce. Different from existing mainstream approaches that focus on supplementary semantics with external medical information, this paper aims to rethink the data challenges in medical texts and present a novel framework-agnostic algorithm called Text2Tree that only utilizes internal label hierarchy in training deep learning models. We embed the ICD code tree structure of labels into cascade attention modules for learning hierarchy-aware label representations. Two new learning schemes, Similarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are devised to boost text classification by reusing and distinguishing samples of other labels following the label representation hierarchy, respectively. Experiments on authoritative public datasets and real-world medical records show that our approach stably achieves superior performances over classical and advanced imbalanced classification methods. Our code is available at https://github.com/jyansir/Text2Tree. | Jiahuan Yan, Haojun Gao, Kai Zhang, Weize Liu, Danny Chen, Jian Wu, Jintai Chen |  |
| 651 |  |  [Impact of Co-occurrence on Factual Knowledge of Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.518) |  | 0 | Large language models (LLMs) often make factually incorrect responses despite their success in various applications. In this paper, we hypothesize that relying heavily on simple co-occurrence statistics of the pre-training corpora is one of the main factors that cause factual errors. Our results reveal that LLMs are vulnerable to the co-occurrence bias, defined as preferring frequently co-occurred words over the correct answer. Consequently, LLMs struggle to recall facts whose subject and object rarely co-occur in the pre-training dataset although they are seen during finetuning. We show that co-occurrence bias remains despite scaling up model sizes or finetuning. Therefore, we suggest finetuning on a debiased dataset to mitigate the bias by filtering out biased samples whose subject-object co-occurrence count is high. Although debiased finetuning allows LLMs to memorize rare facts in the training set, it is not effective in recalling rare facts unseen during finetuning. Further research in mitigation will help build reliable language models by preventing potential errors. The code is available at https://github.com/CheongWoong/impact_of_cooccurrence. | Cheongwoong Kang, Jaesik Choi |  |
| 652 |  |  [CTQScorer: Combining Multiple Features for In-context Example Selection for Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.519) |  | 0 | Large language models have demonstrated the capability to perform on machine translation when the input is prompted with a few examples (in-context learning). Translation quality depends on various features of the selected examples, such as their quality and relevance, but previous work has predominantly focused on individual features in isolation. In this paper, we propose a general framework for combining different features influencing example selection. We learn a regression model, CTQ Scorer (Contextual Translation Quality), that selects examples based on multiple features in order to maximize the translation quality. On multiple language pairs and language models, we show that CTQ Scorer helps significantly outperform random selection as well as strong single-factor baselines reported in the literature. We also see an improvement of over 2.5 COMET points on average with respect to a strong BM25 retrieval-based baseline. | Aswanth M., Ratish Puduppully, Raj Dabre, Anoop Kunchukuttan |  |
| 653 |  |  [Swap and Predict - Predicting the Semantic Changes in Words across Corpora by Context Swapping](https://doi.org/10.18653/v1/2023.findings-emnlp.520) |  | 0 | Meanings of words change over time and across domains. Detecting the semantic changes of words is an important task for various NLP applications that must make time-sensitive predictions. We consider the problem of predicting whether a given target word, w, changes its meaning between two different text corpora, 𝒞1 and 𝒞2. For this purpose, we propose Swapping-based Semantic Change Detection (SSCD), an unsupervised method that randomly swaps contexts between 𝒞1 and 𝒞2 where w occurs. We then look at the distribution of contextualised word embeddings of w, obtained from a pretrained masked language model (MLM), representing the meaning of w in its occurrence contexts in 𝒞1 and 𝒞2. Intuitively, if the meaning of w does not change between 𝒞1 and 𝒞2, we would expect the distributions of contextualised word embeddings of w to remain the same before and after this random swapping process. Despite its simplicity, we demonstrate that even by using pretrained MLMs without any fine-tuning, our proposed context swapping method accurately predicts the semantic changes of words in four languages (English, German, Swedish, and Latin) and across different time spans (over 50 years and about five years). Moreover, our method achieves significant performance improvements compared to strong baselines for the English semantic change prediction task. Source code is available at https://github.com/a1da4/svp-swap . | Taichi Aida, Danushka Bollegala |  |
| 654 |  |  [Beyond Layout Embedding: Layout Attention with Gaussian Biases for Structured Document Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.521) |  | 0 | Effectively encoding layout information is a central problem in structured document understanding. Most existing methods rely heavily on millions of trainable parameters to learn the layout features of each word from Cartesian coordinates. However, two unresolved questions remain: (1) Is the Cartesian coordinate system the optimal choice for layout modeling? (2) Are massive learnable parameters truly necessary for layout representation? In this paper, we address these questions by proposing Layout Attention with Gaussian Biases (LAGaBi): Firstly, we find that polar coordinates provide a superior choice over Cartesian coordinates as they offer a measurement of both distance and angle between word pairs, capturing relative positions more effectively. Furthermore, by feeding the distances and angles into 2-D Gaussian kernels, we model intuitive inductive layout biases, i.e., the words closer within a document should receive more attention, which will act as the attention biases to revise the textual attention distribution. LAGaBi is model-agnostic and language-independent, which can be applied to a range of transformer-based models, such as the text pre-training models from the BERT series and the LayoutLM series that incorporate visual features. Experimental results on three widely used benchmarks demonstrate that, despite reducing the number of layout parameters from millions to 48, LAGaBi achieves competitive or even superior performance. | Xi Zhu, Xue Han, Shuyuan Peng, Shuo Lei, Chao Deng, Junlan Feng |  |
| 655 |  |  [ESPVR: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.522) |  | 0 | Multimodal Named Entity Recognition (MNER) uses visual information to improve the performance of text-only Named Entity Recognition (NER). However, existing methods for acquiring local visual information suffer from certain limitations: (1) using an attention-based method to extract visual regions related to the text from visual regions obtained through convolutional architectures (e.g., ResNet), attention is distracted by the entire image, rather than being fully focused on the visual regions most relevant to the text; (2) using an object detection-based (e.g., Mask R-CNN) method to detect visual object regions related to the text, object detection has a limited range of recognition categories. Moreover, the visual regions obtained by object detection may not correspond to the entities in the text. In summary, the goal of these methods is not to extract the most relevant visual regions for the entities in the text. The visual regions obtained by these methods may be redundant or insufficient for the entities in the text. In this paper, we propose an Entity Spans Position Visual Regions (ESPVR) module to obtain the most relevant visual regions corresponding to the entities in the text. Experiments show that our proposed approach can achieve the SOTA on Twitter-2017 and competitive results on Twitter-2015. | Xiujiao Li, Guanglu Sun, Xinyu Liu |  |
| 656 |  |  [Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency](https://doi.org/10.18653/v1/2023.findings-emnlp.523) |  | 0 | With growing capabilities of large language models, prompting them has become the dominant way to access them. This has motivated the development of strategies for automatically selecting effective language prompts. In this paper, we introduce \*\*pFlat\*\* (prompt flatness), a new metric to quantify the expected utility of a language prompt. This metric is inspired by \*flatness\* regularization in statistical learning that quantifies the robustness of the model towards its parameter perturbations. We provide theoretical foundations for this metric and its relationship with other prompt selection metrics, providing a comprehensive understanding of existing methods. Empirically, we show that combining \*\*pFlat\*\* with existing metrics improves both performance and sample efficiency. Our metric outperforms the previous prompt selection metrics with an average increase of 10% in Pearson correlation across 6 classification benchmarks, and the prompt selected by our metric gains 5% higher accuracy than previous metrics across the benchmarks. | Lingfeng Shen, Weiting Tan, Boyuan Zheng, Daniel Khashabi |  |
| 657 |  |  [Detecting Erroneously Recognized Handwritten Byzantine Text](https://doi.org/10.18653/v1/2023.findings-emnlp.524) |  | 0 | Handwritten text recognition (HTR) yields textual output that comprises errors, which are considerably more compared to that of recognised printed (OCRed) text. Post-correcting methods can eliminate such errors but may also introduce errors. In this study, we investigate the issues arising from this reality in Byzantine Greek. We investigate the properties of the texts that lead post-correction systems to this adversarial behaviour and we experiment with text classification systems that learn to detect incorrect recognition output. A large masked language model, pre-trained in modern and fine-tuned in Byzantine Greek, achieves an Average Precision score of 95%. The score improves to 97% when using a model that is pre-trained in modern and then in ancient Greek, the two language forms Byzantine Greek combines elements from. A century-based analysis shows that the advantage of the classifier that is further-pre-trained in ancient Greek concerns texts of older centuries. The application of this classifier before a neural post-corrector on HTRed text reduced significantly the post-correction mistakes. | John Pavlopoulos, Vasiliki Kougia, Paraskevi Platanou, Holger Essler |  |
| 658 |  |  [Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment](https://doi.org/10.18653/v1/2023.findings-emnlp.525) |  | 0 | Pretrained language models (PLMs) based knowledge-grounded dialogue systems are prone to generate responses that are factually inconsistent with the provided knowledge source. In such inconsistent responses, the dialogue models fail to accurately express the external factual knowledge they rely upon. Inspired by previous work which identified that feedforward networks (FFNs) within Transformers are responsible for factual knowledge expressions, we investigate two methods to efficiently improve the factual expression capability of FFNs by knowledge enhancement and alignment respectively. We first propose K-Dial, which explicitly introduces extended FFNs in Transformers to enhance factual knowledge expressions given the specific patterns of knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement learning for factual consistency (RLFC) method to implicitly adjust FFNs’ expressions in responses by aligning with gold knowledge for the factual consistency preference. To comprehensively assess the factual consistency and dialogue quality of responses, we employ extensive automatic measures and human evaluations including sophisticated fine-grained NLI-based metrics. Experimental results on WoW and CMU_DoG datasets demonstrate that our methods efficiently enhance the ability of the FFN module to convey factual knowledge, validating the efficacy of improving factual consistency for knowledge-grounded dialogue systems. | Boyang Xue, Weichao Wang, Hongru Wang, Fei Mi, Rui Wang, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, KamFai Wong |  |
| 659 |  |  [TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets](https://doi.org/10.18653/v1/2023.findings-emnlp.526) |  | 0 | Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora, and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Hence, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present Triangular Document-level Pre-training (TRIP) as the first in the field to accelerate the conventional monolingual and bilingual objectives into a trilingual objective with a novel method called Grafting. Experiments show that TRIP achieves several strong state-of-the-art (SOTA) scores on three multilingual document-level machine translation benchmarks and one cross-lingual abstractive summarization benchmark, including consistent improvements by up to 3.11 d-BLEU points and 8.9 ROUGE-L points. | Hongyuan Lu, Haoyang Huang, Shuming Ma, Dongdong Zhang, Wai Lam, Zhaochuan Gao, Anthony Aue, Arul Menezes, Furu Wei |  |
| 660 |  |  [Frequency Balanced Datasets Lead to Better Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.527) |  | 0 | This paper reports on the experiments aimed to improve our understanding of the role of the amount of data required for training attention-based transformer language models. Specifically, we investigate the impact of reducing the immense amounts of required pre-training data through sampling strategies that identify and reduce high-frequency tokens as different studies have indicated that the existence of very high-frequency tokens in pre-training data might bias learning, causing undesired effects. In this light, we describe our sampling algorithm that iteratively assesses token frequencies and removes sentences that contain still high-frequency tokens, eventually delivering a balanced, linguistically correct dataset. We evaluate the results in terms of model perplexity and fine-tuning linguistic probing tasks, NLP downstream tasks as well as more semantic SuperGlue tasks. The results show that pre-training with the resulting balanced dataset allows reducing up to three times the pre-training data. | Rodolfo Zevallos, Mireia Farrús, Núria Bel |  |
| 661 |  |  [Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.528) |  | 0 | The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow optimizes only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET. | Jianing Wang, Qiushi Sun, Nuo Chen, Chengyu Wang, Jun Huang, Ming Gao, Xiang Li |  |
| 662 |  |  [TR-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy](https://doi.org/10.18653/v1/2023.findings-emnlp.529) |  | 0 | Temporal knowledge graph (TKG) has been proved to be an effective way for modeling dynamic facts in real world. Many efforts have been devoted into predicting future events i.e. extrapolation, on TKGs. Recently, rule-based knowledge graph completion methods which are considered to be more interpretable than embedding-based methods, have been transferred to temporal knowledge graph extrapolation. However, rule-based models suffer from temporal redundancy when leveraged under dynamic settings, which results in inaccurate rule confidence calculation. In this paper, we define the problem of temporal redundancy and propose TR-Rules which solves the temporal redundancy issues through a simple but effective strategy. Besides, to capture more information lurking in TKGs, apart from cyclic rules, TR-Rules also mines and properly leverages acyclic rules, which has not been explored by existing models. Experimental results on three benchmarks show that TR-Rules achieves state-of-the-art performance. Ablation study shows the impact of temporal redundancy and demonstrates the performance of acyclic rules is much more promising due to its higher sensitivity to the number of sampled walks during learning stage. | Ningyuan Li, Haihong E, Shi Li, Mingzhi Sun, Tianyu Yao, Meina Song, Yong Wang, Haoran Luo |  |
| 663 |  |  [On the Transferability of Visually Grounded PCFGs](https://doi.org/10.18653/v1/2023.findings-emnlp.530) |  | 0 | There has been a significant surge of interest in visually grounded grammar induction in recent times. While a variety of models have been developed for the task and have demonstrated impressive performance, they have not been evaluated on text domains that are different from the training domain, so it is unclear if the improvements brought by visual groundings are transferable. Our study aims to fill this gap and assess the degree of transferability. We start by extending VC-PCFG (short for Visually-grounded Compound PCFG [[Zhao and Titov, 2020](https://aclanthology.org/2020.emnlp-main.354/)]) in such a way that it can transfer across text domains. We consider a zero-shot transfer learning setting where a model is trained on the source domain and is directly applied to target domains, without any further training. Our experimental results suggest that: the benefits from using visual groundings transfer to text in a domain similar to the training domain but fail to transfer to remote domains. Further, we conduct data and result analysis; we find that the lexicon overlap between the source domain and the target domain is the most important factor in the transferability of VC-PCFG. | Yanpeng Zhao, Ivan Titov |  |
| 664 |  |  [Analysis of Style-Shifting on Social Media: Using Neural Language Model Conditioned by Social Meanings](https://doi.org/10.18653/v1/2023.findings-emnlp.531) |  | 0 | In this paper, we propose a novel framework for evaluating style-shifting in social media conversations. Our proposed framework captures changes in an individual’s conversational style based on surprisals predicted by a personalized neural language model for individuals. Our personalized language model integrates not only the linguistic contents of conversations but also non-linguistic factors, such as social meanings, including group membership, personal attributes, and individual beliefs. We incorporate these factors directly or implicitly into our model, leveraging large, pre-trained language models and feature vectors derived from a relationship graph on social media. Compared to existing models, our personalized language model demonstrated superior performance in predicting an individual’s language in a test set. Furthermore, an analysis of style-shifting utilizing our proposed metric based on our personalized neural language model reveals a correlation between our metric and various conversation factors as well as human evaluation of style-shifting. | Seiya Kawano, Shota Kanezaki, Angel Fernando Garcia Contreras, Akishige Yuguchi, Marie Katsurai, Koichiro Yoshino |  |
| 665 |  |  [Linguistic Compression in Single-Sentence Human-Written Summaries](https://doi.org/10.18653/v1/2023.findings-emnlp.532) |  | 0 | Summarizing texts involves significant cognitive efforts to compress information. While advances in automatic summarization systems have drawn attention from the NLP and linguistics communities to this topic, there is a lack of computational studies of linguistic patterns in human-written summaries. This work presents a large-scale corpus study of human-written single-sentence summaries. We analyzed the linguistic compression patterns from source documents to summaries at different granularities, and we found that summaries are generally written with morphological expansion, increased lexical diversity, and similar positional arrangements of specific words compared to the source across different genres. We also studied how linguistic compressions of different factors affect reader judgments of quality through a human study, with the results showing that the use of morphological and syntactic changes by summary writers matches reader preferences while lexical diversity and word specificity preferences are not aligned between summary writers and readers. | Fangcong Yin, Marten van Schijndel |  |
| 666 |  |  [MCLF: A Multi-grained Contrastive Learning Framework for ASR-robust Spoken Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.533) |  | 0 | Enhancing the robustness towards Automatic Speech Recognition (ASR) errors is of great importance for Spoken Language Understanding (SLU). Trending ASR-robust SLU systems have witnessed impressive improvements through global contrastive learning. However, although most ASR errors occur only at local positions of utterances, they can easily lead to severe semantic changes, and utterance-level classification or comparison is difficult to distinguish such differences. To address the problem, we propose a two-stage multi-grained contrastive learning framework dubbed MCLF. Technically, we first adapt the pre-trained language models to downstream SLU datasets via the proposed multi-grained contrastive learning objective and then fine-tune it on the corresponding dataset. Besides, to facilitate contrastive learning in the pre-training stage, we explore several data augmentation methods to expand the training data. Experimental results and detailed analyses on four datasets and four BERT-like backbone models demonstrate the effectiveness of our approach. | Zhiqi Huang, Dongsheng Chen, Zhihong Zhu, Xuxin Cheng |  |
| 667 |  |  [Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge](https://doi.org/10.18653/v1/2023.findings-emnlp.534) |  | 0 | To build ultimate dialogue agents, previous studies suggest models that ground both persona and knowledge. However, applying the dialogue system directly to the usual conversation is still limited because the system requires a complete sentence-formed persona and knowledge candidate sets from the given dataset. In contrast to the dialogue setting in the dataset, humans utilize semantic concepts in their minds rather than a set of pre-defined candidate sentences. Following this manner of human dialogue, we suggest an adaptive dialogue system that is applicable to situations where complete sentence-formed candidates are not given. Our model generates consistent and relevant persona descriptions and identifies relevant knowledge for engaging and knowledgeable responses, even with fragmentary information. We show that our model outperforms previous baselines that utilize persona and knowledge candidate sentences and conduct the human evaluation on the machine-generated responses. In addition, we conduct ablation studies to demonstrate the effectiveness of each component of our model. Furthermore, we apply our model to other dialogue datasets that only ground knowledge or persona to showcase its adaptability. Our code is available at https://github.com/dlawjddn803/BeCand. | Jungwoo Lim, Myunghoon Kang, Jinsung Kim, Jeongwook Kim, Yuna Hur, Heuiseok Lim |  |
| 668 |  |  [SmartSpanNER: Making SpanNER Robust in Low Resource Scenarios](https://doi.org/10.18653/v1/2023.findings-emnlp.535) |  | 0 | Named Entity Recognition (NER) is one of the most fundamental tasks in natural language processing. Span-level prediction (SpanNER) is more naturally suitable for nested NER than sequence labeling (SeqLab). However, according to our experiments, the SpanNER method is more sensitive to the amount of training data, i.e., the F1 score of SpanNER drops much more than that of SeqLab when the amount of training data drops. In order to improve the robustness of SpanNER in low resource scenarios, we propose a simple and effective method SmartSpanNER, which introduces a Named Entity Head (NEH) prediction task to SpanNER and performs multi-task learning together with the task of span classification. Experimental results demonstrate that the robustness of SpanNER could be greatly improved by SmartSpanNER in low resource scenarios constructed on the CoNLL03, Few-NERD, GENIA and ACE05 standard benchmark datasets. | Min Zhang, Xiaosong Qiao, Yanqing Zhao, Shimin Tao, Hao Yang |  |
| 669 |  |  [ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.536) |  | 0 | We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test and small validation sets, without training data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard. | Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer Levy |  |
| 670 |  |  [Data Selection Curriculum for Abstractive Text Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.537) |  | 0 | Abstractive Text Summarization (ATS) models are commonly trained using large-scale data that is randomly shuffled. However, the impact of data selection and data ordering on ATS models remains a relatively unexplored research area, where a significant challenge lies in accurately assessing the learning difficulty of each training instance. This study introduces a Data Selection Curriculum (DSC) scoring system that incorporates both the difficulty of improving ATS model via an instance and the expected performance on this instance. By selectively excluding excessively simple and overly complex instances, the training efficiency can be optimized. Furthermore, curriculum learning is integrated to accelerate convergence and improve performance by gradually increasing the learning difficulty, inspired by human learners. Experimental results on the CNN/DailyMail dataset demonstrate that our approach surpasses potent baselines, utilizing a mere 20% of the available instances. | Shichao Sun, Ruifeng Yuan, Jianfei He, Ziqiang Cao, Wenjie Li, Xiaohua Jia |  |
| 671 |  |  [Romanization-based Large-scale Adaptation of Multilingual Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.538) |  | 0 | Large multilingual pretrained language models (mPLMs) have become the de facto state of the art for cross-lingual transfer in NLP. However, their large-scale deployment to many languages, besides pretraining data scarcity, is also hindered by the increase in vocabulary size and limitations in their parameter budget. In order to boost the capacity of mPLMs to deal with low-resource and unseen languages, we explore the potential of leveraging transliteration on a massive scale. In particular, we explore the UROMAN transliteration tool, which provides mappings from UTF-8 to Latin characters for all the writing systems, enabling inexpensive romanization for virtually any language. We first focus on establishing how UROMAN compares against other language-specific and manually curated transliterators for adapting multilingual PLMs. We then study and compare a plethora of data- and parameter-efficient strategies for adapting the mPLMs to romanized and non-romanized corpora of 14 diverse low-resource languages. Our results reveal that UROMAN-based transliteration can offer strong performance for many languages, with particular gains achieved in the most challenging setups: on languages with unseen scripts and with limited training data without any vocabulary augmentation. Further analyses reveal that an improved tokenizer based on romanized data can even outperform non-transliteration-based methods in the majority of languages. | Sukannya Purkayastha, Sebastian Ruder, Jonas Pfeiffer, Iryna Gurevych, Ivan Vulic |  |
| 672 |  |  [Measuring bias in Instruction-Following models with P-AT](https://doi.org/10.18653/v1/2023.findings-emnlp.539) |  | 0 | Instruction-Following Language Models (IFLMs) are promising and versatile tools for solving many downstream, information-seeking tasks. Given their success, there is an urgent need to have a shared resource to determine whether existing and new IFLMs are prone to produce biased language interactions. In this paper, we propose Prompt Association Test (P-AT): a new resource for testing the presence of social biases in IFLMs. P-AT stems from WEAT (Caliskan et al., 2017) and generalizes the notion of measuring social biases to IFLMs. Basically, we cast WEAT word tests in promptized classification tasks, and we associate a metric - the bias score. Our resource consists of 2310 prompts. We then experimented with several families of IFLMs discovering gender and race biases in all the analyzed models. We expect P-AT to be an important tool for quantifying bias across different dimensions and, therefore, for encouraging the creation of fairer IFLMs before their distortions have consequences in the real world. | Dario Onorati, Elena Sofia Ruzzetti, Davide Venditti, Leonardo Ranaldi, Fabio Massimo Zanzotto |  |
| 673 |  |  [Open-ended Commonsense Reasoning with Unrestricted Answer Candidates](https://doi.org/10.18653/v1/2023.findings-emnlp.540) |  | 0 | Open-ended Commonsense Reasoning is defined as solving a commonsense question without providing 1) a short list of answer candidates and 2) a pre-defined answer scope. Conventional ways of formulating the commonsense question into a question-answering form or utilizing external knowledge to learn retrieval-based methods are less applicable in the open-ended setting due to an inherent challenge. Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space. Moreover, most questions require implicit multi-hop reasoning, which presents even more challenges to our problem. In this work, we leverage pre-trained language models to iteratively retrieve reasoning paths on the external knowledge base, which does not require task-specific supervision. The reasoning paths can help to identify the most precise answer to the commonsense question. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively. | Chen Ling, Xuchao Zhang, Xujiang Zhao, Yanchi Liu, Wei Cheng, Mika Oishi, Takao Osaki, Katsushi Matsuda, Haifeng Chen, Liang Zhao |  |
| 674 |  |  [Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units](https://doi.org/10.18653/v1/2023.findings-emnlp.541) |  | 0 | We introduce DISSC, a novel, lightweight method that converts the rhythm, pitch contour and timbre of a recording to a target speaker in a textless manner. Unlike DISSC, most voice conversion (VC) methods focus primarily on timbre, and ignore people’s unique speaking style (prosody). The proposed approach uses a pretrained, self-supervised model for encoding speech to discrete units, which makes it simple, effective, and fast to train. All conversion modules are only trained on reconstruction like tasks, thus suitable for any-to-many VC with no paired data. We introduce a suite of quantitative and qualitative evaluation metrics for this setup, and empirically demonstrate that DISSC significantly outperforms the evaluated baselines. Code and samples are available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/. | Gallil Maimon, Yossi Adi |  |
| 675 |  |  [Knowledge-Selective Pretraining for Attribute Value Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.542) |  | 0 | Attribute Value Extraction (AVE) aims to retrieve the values of attributes from the product profiles. The state-of-the-art methods tackle the AVE task through a question-answering (QA) paradigm, where the value is predicted from the context (i.e. product profile) given a query (i.e. attributes). Despite of the substantial advancements that have been made, the performance of existing methods on rare attributes is still far from satisfaction, and they cannot be easily extended to unseen attributes due to the poor generalization ability. In this work, we propose to leverage pretraining and transfer learning to address the aforementioned weaknesses. We first collect the product information from various E-commerce stores and retrieve a large number of (profile, attribute, value) triples, which will be used as the pretraining corpus. To more effectively utilize the retrieved corpus, we further design a Knowledge-Selective Framework (KSelF) based on query expansion that can be closely combined with the pretraining corpus to boost the performance. Meanwhile, considering the public AE-pub dataset contains considerable noise, we construct and contribute a larger benchmark EC-AVE collected from E-commerce websites. We conduct evaluation on both of these datasets. The experimental results demonstrate that our proposed KSelF achieves new state-of-the-art performance without pretraining. When incorporated with the pretraining corpus, the performance of KSelF can be further improved, particularly on the attributes with limited training resources. | Hui Liu, Qingyu Yin, Zhengyang Wang, Chenwei Zhang, Haoming Jiang, Yifan Gao, Zheng Li, Xian Li, Chao Zhang, Bing Yin, William Wang, Xiaodan Zhu |  |
| 676 |  |  [New Datasets and Controllable Iterative Data Augmentation Method for Code-switching ASR Error Correction](https://doi.org/10.18653/v1/2023.findings-emnlp.543) |  | 0 | With the wide use of automatic speech recognition(ASR) systems, researchers pay more attention to the ASR error correction task to improve the quality of recognition results. In particular, ASR in bilingual or multilingual settings, namely code-switching ASR, has greater challenges and research value. In this paper, we first present code-switching ASR correction datasets obtained from solid ASR systems and automatic annotators. The datasets contain Chinese-English code-switching dialogues of bilingual speakers in Singapore, Malaysia, and Hong Kong. Based on this task, we propose a controllable iterative (CI) data augmentation method for improving the performance of mainstream ASR error correction systems. With a small amount of training data, our proposed method has the ability to iteratively produce abundant pseudo parallel data from the monolingual corpus for Chinese-English code-switching ASR correction. Results of experiments show that our method achieves the best performance compared with the rule-based, back-translation-based data augmentation methods and large language model ChatGPT. | Zhaohong Wan, Xiaojun Wan, Wei Peng, Rongjun Li |  |
| 677 |  |  [Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition](https://doi.org/10.18653/v1/2023.findings-emnlp.544) |  | 0 | Cross-encoder models, which jointly encode and score a query-item pair, are prohibitively expensive for direct k-nearest neighbor (k-NN) search. Consequently, k-NN search typically employs a fast approximate retrieval (e.g. using BM25 or dual-encoder vectors), followed by reranking with a cross-encoder; however, the retrieval approximation often has detrimental recall regret. This problem is tackled by ANNCUR (Yadav et al., 2022), a recent work that employs a cross-encoder only, making search efficient using a relatively small number of anchor items, and a CUR matrix factorization. While ANNCUR’s one-time selection of anchors tends to approximate the cross-encoder distances on average, doing so forfeits the capacity to accurately estimate distances to items near the query, leading to regret in the crucial end-task: recall of top-k items. In this paper, we propose ADACUR, a method that adaptively, iteratively, and efficiently minimizes the approximation error for the practically important top-k neighbors. It does so by iteratively performing k-NN search using the anchors available so far, then adding these retrieved nearest neighbors to the anchor set for the next round. Empirically, on multiple datasets, in comparison to previous traditional and state-of-the-art methods such as ANNCUR and dual-encoder-based retrieve-and-rerank, our proposed approach ADACUR consistently reduces recall error—by up to 70% on the important k = 1 setting—while using no more compute than its competitors. | Nishant Yadav, Nicholas Monath, Manzil Zaheer, Andrew McCallum |  |
| 678 |  |  [Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.545) |  | 0 | With the development of multilingual pre-trained language models (mPLMs), zero-shot cross-lingual transfer shows great potential. To further improve the performance of cross-lingual transfer, many studies have explored representation misalignment caused by morphological differences but neglected the misalignment caused by the anisotropic distribution of contextual representations. In this work, we propose enhanced isotropy and constrained code-switching for zero-shot cross-lingual transfer to alleviate the problem of misalignment caused by the anisotropic representations and maintain syntactic structural knowledge. Extensive experiments on three zero-shot cross-lingual transfer tasks demonstrate that our method gains significant improvements over strong mPLM backbones and further improves the state-of-the-art methods. | Yixin Ji, Jikai Wang, Juntao Li, Hai Ye, Min Zhang |  |
| 679 |  |  [Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?](https://doi.org/10.18653/v1/2023.findings-emnlp.546) |  | 0 | How do we evaluate Large Language Models (LLMs) and determine the aspects and limits of their intelligent behaviour? It is currently conjectured that shortcomings of LLMs in multi-linguality and reasoning are due to a lack of ability to generalize. It has been argued that, instead, humans are better at generalization because they have a tendency at extracting rules from complex data. We propose a method to evaluate LLMs ability to rule-based generalization. When exposed to tests of analytic intelligence, for example the visual RAVEN IQ test, human problem-solvers identify the relevant objects in the picture and their relevant attributes and reason based on rules applied to them. Based on the induced rules, they are able to provide a generalisation and a solution to the test. An analogous language task has recently been proposed (called BLM) for LLM. In this paper, we argue that we can use this task to investigate what linguistic reasoning LLM develop, by asking them to solve some simple variants of the BLM task. We find that current state-of-the-art generative models, such as ChatGPT, can handle the task in the sense that they easily understand the instructions and can provide step-by-step reasoning that shows that it can solve two of the main cognitive hurdles: correspondence finding (object and attribute identification) and item novelty. However, overall they cannot find the correct answer, even with considerable help. In particular, they never identify the structure of the problem, exhibiting, we hypothesize, a lack of goal and subgoal management abilities, an ability that has been argued to measure differential abilities in humans. We argue that this finding supports the usefulness of the task as a method to test the limits and specific properties of generalisation ability in Large Language Models, providing an intrinsic evaluation method inspired by tests of human intelligence. | Paola Merlo |  |
| 680 |  |  [DistillCSE: Distilled Contrastive Learning for Sentence Embeddings](https://doi.org/10.18653/v1/2023.findings-emnlp.547) |  | 0 | This paper proposes the DistillCSE framework, which performs contrastive learning under the self-training paradigm with knowledge distillation. The potential advantage of DistillCSE is its self-enhancing feature: using a base model to provide additional supervision signals, a stronger model may be learned through knowledge distillation. However, the vanilla DistillCSE through the standard implementation of knowledge distillation only achieves marginal improvements. The quantitative analyses demonstrate its reason that the standard knowledge distillation exhibits a relatively large variance of the teacher model’s logits due to the essence of contrastive learning. To mitigate the issue induced by high variance, this paper accordingly proposed two simple yet effective solutions for knowledge distillation: a Group-P shuffling strategy as an implicit regularization and the averaging logits from multiple teacher components. Experiments on standard benchmarks demonstrate that the proposed DistillCSE outperforms many strong baseline methods and yields a new state-of-the-art performance. | Jiahao Xu, Wei Shao, Lihui Chen, Lemao Liu |  |
| 681 |  |  [GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets](https://doi.org/10.18653/v1/2023.findings-emnlp.548) |  | 0 | Named Entity Recognition (NER) models play a crucial role in various NLP tasks, including information extraction (IE) and text understanding. In academic writing, references to machine learning models and datasets are fundamental components of various computer science publications and necessitate accurate models for identification. Despite the advancements in NER, existing ground truth datasets do not treat fine-grained types like ML model and model architecture as separate entity types, and consequently, baseline models cannot recognize them as such. In this paper, we release a corpus of 100 manually annotated full-text scientific publications and a first baseline model for 10 entity types centered around ML models and datasets. In order to provide a nuanced understanding of how ML models and datasets are mentioned and utilized, our dataset also contains annotations for informal mentions like “our BERT-based model” or “an image CNN”. You can find the ground truth dataset and code to replicate model training at https://data.gesis.org/gsap/gsap-ner. | Wolfgang Otto, Matthäus Zloch, Lu Gan, Saurav Karmakar, Stefan Dietze |  |
| 682 |  |  [Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.549) |  | 0 | Multi-document summarization (MDS) assumes a set of topic-related documents are provided as input. In practice, this document set is not always available; it would need to be retrieved given an information need, i.e. a question or topic statement, a setting we dub “open-domain’ MDS. We study this more challenging setting by formalizing the task and bootstrapping it using existing datasets, retrievers and summarizers. Via extensive automatic and human evaluation, we determine: (1) state-of-the-art summarizers suffer large reductions in performance when applied to open-domain MDS, (2) additional training in the open-domain setting can reduce this sensitivity to imperfect retrieval, and (3) summarizers are insensitive to the retrieval of duplicate documents and the order of retrieved documents, but highly sensitive to other errors, like the retrieval of irrelevant documents. Based on our results, we provide practical guidelines to enable future work on open-domain MDS, e.g. how to choose the number of retrieved documents to summarize. Our results suggest that new retrieval and summarization methods and annotated resources for training and evaluation are necessary for further progress in the open-domain setting. | John M. Giorgi, Luca Soldaini, Bo Wang, Gary D. Bader, Kyle Lo, Lucy Lu Wang, Arman Cohan |  |
| 683 |  |  [Few-shot Unified Question Answering: Tuning Models or Prompts?](https://doi.org/10.18653/v1/2023.findings-emnlp.550) |  | 0 | Question-answering (QA) tasks often investigate specific question types, knowledge domains, or reasoning skills, leading to specialized models catering to specific categories of QA tasks. While recent research has explored the idea of unified QA models, such models are usually explored for high-resource scenarios and require re-training to extend their capabilities. To overcome these drawbacks, the paper explores the potential of two paradigms of tuning, model, and prompts, for unified QA under a low-resource setting. The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization. The study also shows that parameter-sharing results in superior few-shot performance, simple knowledge transfer techniques for prompt initialization can be effective, and prompt tuning achieves a significant performance boost from pre-training in a low-resource regime. The research offers insights into the advantages and limitations of prompt tuning for unified QA in a few-shot setting, contributing to the development of effective and efficient systems in low-resource scenarios. | Srijan Bansal, Semih Yavuz, Bo Pang, Meghana Bhat, Yingbo Zhou |  |
| 684 |  |  [Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations](https://doi.org/10.18653/v1/2023.findings-emnlp.551) |  | 0 | When we communicate with other humans, we do not simply generate a sequence of words. Rather, we use our cognitive state (beliefs, desires, intentions) and our model of the audience’s cognitive state to create utterances that affect the audience’s cognitive state in the intended manner. An important part of cognitive state is the common ground, which is the content the speaker believes, and the speaker believes the audience believes, and so on. While much attention has been paid to common ground in cognitive science, there has not been much work in natural language processing. In this paper, we introduce a new annotation and corpus to capture common ground. We then describe some initial experiments extracting propositions from dialog and tracking their status in the common ground from the perspective of each speaker. | Magdalena Markowska, Mohammad Taghizadeh, Adil Soubki, Seyed Abolghasem Mirroshandel, Owen Rambow |  |
| 685 |  |  [Getting MoRE out of Mixture of Language Model Reasoning Experts](https://doi.org/10.18653/v1/2023.findings-emnlp.552) |  | 0 | While recent large language models (LLMs) improve on various question answering (QA) datasets, it remains difficult for a single model to generalize across question types that require distinct reasoning abilities. We provide empirical evidence that state-of-the-art LLMs suffer from poor generalizability on reasoning types beyond those seen in the prompt. To remedy this, we propose a Mixture-of-Reasoning-Experts (MORE) framework that ensembles diverse specialized language models. We specialize the backbone language model with prompts optimized for different reasoning categories, including factual, multihop, mathematical, and commonsense reasoning. Our key insight is to leverage agreement among the specialized experts to select the best answer for each question, or to abstain from answering. This gives MORE higher accuracy than any single specialized model on a collection of 12 QA datasets from four reasoning types. Beyond generalizability, the interpretable design of MORE improves selective question answering results compared to baselines without incorporating inter-expert agreement. This framework is also more interpretable and useful to human consumers of QA outputs. Our human study confirms that presenting expert predictions and the answer selection process helps annotators more accurately calibrate when to trust the system’s output. We release all code and data to facilitate future work. | Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, Jordan L. BoydGraber |  |
| 686 |  |  ["You Are An Expert Linguistic Annotator": Limits of LLMs as Analyzers of Abstract Meaning Representation](https://doi.org/10.18653/v1/2023.findings-emnlp.553) |  | 0 | Large language models (LLMs) demonstrate an amazing proficiency and fluency in the use of language. Does that mean that they have also acquired insightful linguistic knowledge about the language, to an extent that they can serve as an “expert linguistic annotator’? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models, focusing on the Abstract Meaning Representation (AMR) parsing formalism (Banarescu et al., 2013), which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models’ analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot examples, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., “Identify the primary event of this sentence, and the predicate corresponding to that event.”). Across these settings, we find that models can reliably reproduce the basic format of AMR, as well as some core event, argument, and modifier structure-however, model outputs are prone to frequent and major errors, and holistic analysis of parse acceptability shows that even with few-shot demonstrations, models have virtually 0% success in producing fully accurate parses. Eliciting responses in natural language produces similar patterns of errors. Overall, our findings indicate that these models out-of-the-box can accurately identify some core aspects of semantic structure, but there remain key limitations in their ability to support fully accurate semantic analyses or parses. | Allyson Ettinger, Jena D. Hwang, Valentina Pyatkin, Chandra Bhagavatula, Yejin Choi |  |
| 687 |  |  [Zero-Shot Data Maps. Efficient Dataset Cartography Without Model Training](https://doi.org/10.18653/v1/2023.findings-emnlp.554) |  | 0 | Data Maps (Swayamdipta, et al. 2020) have emerged as a powerful tool for diagnosing large annotated datasets. Given a model fitted on a dataset, these maps show each data instance from the dataset in a 2-dimensional space defined by a) the model’s confidence in the true class and b) the variability of this confidence. In previous work, confidence and variability are usually computed using training dynamics, which requires the fitting of a strong model to the dataset. In this paper, we introduce a novel approach: Zero-Shot Data Maps based on fast bi-encoder networks. For each data point, confidence on the true label and variability are computed over the members of an ensemble of zero-shot models constructed with different — but semantically equivalent — label descriptions, i.e., textual representations of each class in a given label space. We conduct a comparative analysis of maps compiled using traditional training dynamics and our proposed zero-shot models across various datasets. Our findings reveal that Zero-Shot Data Maps generally match those produced by the traditional method while delivering up to a 14x speedup. The code is available [here](https://github.com/symanto-research/zeroshot-cartography). | Angelo Basile, Marc FrancoSalvador, Paolo Rosso |  |
| 688 |  |  [Isotropy-Enhanced Conditional Masked Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.555) |  | 0 | Non-autoregressive models have been widely used for various text generation tasks to accelerate the inference process but at the cost of generation quality to some extent. To achieve a good balance between inference speedup and generation quality, iterative NAR models like CMLM and Disco are proposed. Researchers have made much follow-up progress based on them, and some recent iterative models can achieve very promising performance while maintaining significant speedup. In this paper, we give more insights into iterative NAR models by exploring the anisotropic problem, i.e., the representations of distinct predicted target tokens are similar and indiscriminative. Upon the confirmation of the anisotropic problem in iterative NAR models, we first analyze the effectiveness of the contrastive learning method and further propose the Look Neighbors strategy to enhance the learning of token representations during training. Experiments on 4 WMT datasets show that our methods consistently improve the performance as well as alleviate the anisotropic problem of the conditional masked language model, even outperforming the current SoTA result on WMT14 EN → DE. | Pei Guo, Yisheng Xiao, Juntao Li, Yixin Ji, Min Zhang |  |
| 689 |  |  [Scaling Law for Document Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.556) |  | 0 | The scaling laws of language models have played a significant role in advancing large language models. In order to promote the development of document translation, we systematically examine the scaling laws in this field. In this paper, we carry out an in-depth analysis of the influence of three factors on translation quality: model scale, data scale, and sequence length. Our findings reveal that increasing sequence length effectively enhances model performance when model size is limited. However, sequence length cannot be infinitely extended; it must be suitably aligned with the model scale and corpus volume. Further research shows that providing adequate context can effectively enhance the translation quality of a document’s initial portion. Nonetheless, exposure bias remains the primary factor hindering further improvement in translation quality for the latter half of the document. | Zhuocheng Zhang, Shuhao Gu, Min Zhang, Yang Feng |  |
| 690 |  |  [Automatic Pronunciation Assessment - A Review](https://doi.org/10.18653/v1/2023.findings-emnlp.557) |  | 0 | Pronunciation assessment and its application in computer-aided pronunciation training (CAPT) have seen impressive progress in recent years. With the rapid growth in language processing and deep learning over the past few years, there is a need for an updated review. In this paper, we review methods employed in pronunciation assessment for both phonemic and prosodic. We categorize the main challenges observed in prominent research trends, and highlight existing limitations, and available resources. This is followed by a discussion of the remaining challenges and possible directions for future work. | Yassine El Kheir, Ahmed Ali, Shammur Absar Chowdhury |  |
| 691 |  |  [Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model](https://doi.org/10.18653/v1/2023.findings-emnlp.558) |  | 0 | Transformers have shown dominant performance across a range of domains including language and vision. However, their computational cost grows quadratically with the sequence length, making their usage prohibitive for resource-constrained applications. To counter this, our approach is to divide the whole sequence into segments and apply attention to the individual segments. We propose a segmented recurrent transformer (SRformer) that combines segmented (local) attention with recurrent attention. The loss caused by reducing the attention window length is compensated by aggregating information across segments with recurrent attention. SRformer leverages Recurrent Accumulate-and-Fire (RAF) neurons’ inherent memory to update the cumulative product of keys and values. The segmented attention and lightweight RAF neurons ensure the efficiency of the proposed transformer. Such an approach leads to models with sequential processing capability at a lower computation/memory cost. We apply the proposed method to T5 and BART transformers. The modified models are tested on summarization datasets including CNN-dailymail, XSUM, ArXiv, and MediaSUM. Notably, using segmented inputs of varied sizes, the proposed model achieves 6-22% higher ROUGE1 scores than a segmented transformer and outperforms other recurrent transformer approaches. Furthermore, compared to full attention, the proposed model reduces the computational complexity of cross attention by around 40%. | Yinghan Long, Sayeed Shafayet Chowdhury, Kaushik Roy |  |
| 692 |  |  [PUNR: Pre-training with User Behavior Modeling for News Recommendation](https://doi.org/10.18653/v1/2023.findings-emnlp.559) |  | 0 | News recommendation aims to predict click behaviors based on user behaviors. How to effectively model the user representations is the key to recommending preferred news. Existing works are mostly focused on improvements in the supervised fine-tuning stage. However, there is still a lack of PLM-based unsupervised pre-training methods optimized for user representations. In this work, we propose an unsupervised pre-training paradigm with two tasks, i.e. user behavior masking and user behavior generation, both towards effective user behavior modeling. Firstly, we introduce the user behavior masking pre-training task to recover the masked user behaviors based on their contextual behaviors. In this way, the model could capture a much stronger and more comprehensive user news reading pattern. Besides, we incorporate a novel auxiliary user behavior generation pre-training task to enhance the user representation vector derived from the user encoder. We use the above pre-trained user modeling encoder to obtain news and user representations in downstream fine-tuning. Evaluations on the real-world news benchmark show significant performance improvements over existing baselines. | Guangyuan Ma, Hongtao Liu, Xing Wu, Wanhui Qian, Zhepeng Lv, Qing Yang, Songlin Hu |  |
| 693 |  |  [Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design](https://doi.org/10.18653/v1/2023.findings-emnlp.560) |  | 0 | Discovering novel catalysts requires complex reasoning involving multiple chemical properties and resultant trade-offs, leading to a combinatorial growth in the search space. While large language models (LLM) have demonstrated novel capabilities for chemistry through complex instruction following capabilities and high quality reasoning, a goal-driven combinatorial search using LLMs has not been explored in detail. In this work, we present a Monte Carlo Tree Search-based approach that improves beyond state-of-the-art chain-of-thought prompting variants to augment scientific reasoning. We introduce two new reasoning datasets: 1) a curation of computational chemistry simulations, and 2) diverse questions written by catalysis researchers for reasoning about novel chemical conversion processes. We improve over the best baseline by 25.8% and find that our approach can augment scientist’s reasoning and discovery process with novel insights. | Henry Sprueill, Carl Edwards, Mariefel V. Olarte, Udishnu Sanyal, Heng Ji, Sutanay Choudhury |  |
| 694 |  |  [Measure Children's Mindreading Ability with Machine Reading](https://doi.org/10.18653/v1/2023.findings-emnlp.561) |  | 0 | Recently, much research in psychology has benefited from the advances in machine learning techniques. Some recent studies showed that it is possible to build automated scoring models for children’s mindreading. These models were trained on a set of manually-labeled question-response pairs, which were collected by asking children to answer one or two questions after a short story is told or a video clip is played. However, existing models did not take the features of the stories and video clips into account when scoring, which obviously will reduce the accuracy of the scoring models. Furthermore, considering that different psychological tests may contain the same questions, this approach cannot be extended to other related psychological test datasets. In this study, we proposed a multi-modal learning framework to leverage the features extracted from the stories and videos related to the questions being asked during the children’s mindreading evaluation. Experimental results show that the scores produced by the proposed models agree well with those graded by human experts, highlighting the potential of the proposed network architecture for practical automated children’s mindreading scoring systems. | Yuliang Yan, Xiaohua Wang, Xiang Zhou, Xiaoqing Zheng, Xuanjing Huang |  |
| 695 |  |  [Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.562) |  | 0 | In comparative linguistics, colexification refers to the phenomenon of a lexical form conveying two or more distinct meanings. Existing work on colexification patterns relies on annotated word lists, limiting scalability and usefulness in NLP. In contrast, we identify colexification patterns of more than 2,000 concepts across 1,335 languages directly from an unannotated parallel corpus. We then propose simple and effective methods to build multilingual graphs from the colexification patterns: ColexNet and ColexNet+. ColexNet’s nodes are concepts and its edges are colexifications. In ColexNet+, concept nodes are additionally linked through intermediate nodes, each representing an ngram in one of 1,334 languages. We use ColexNet+ to train ColexNet+, high-quality multilingual embeddings that are well-suited for transfer learning. In our experiments, we first show that ColexNet achieves high recall on CLICS, a dataset of crosslingual colexifications. We then evaluate ColexNet+ on roundtrip translation, sentence retrieval and sentence classification and show that our embeddings surpass several transfer learning baselines. This demonstrates the benefits of using colexification as a source of information in multilingual NLP. | Yihong Liu, Haotian Ye, Leonie Weissweiler, Renhao Pei, Hinrich Schütze |  |
| 696 |  |  [Injecting structural hints: Using language models to study inductive biases in language learning](https://doi.org/10.18653/v1/2023.findings-emnlp.563) |  | 0 | Both humans and transformer language models are able to learn language without explicit structural supervision. What cognitive inductive biases make this learning possible? Here, we examine the effect of different inductive learning biases by actively controlling the inductive biases of artificial learners: we structurally bias models by pretraining on synthetic formally-structured data, and evaluate these structural biases by fine-tuning on three typologically-distant human languages: English, Japanese, and Basque. We investigate the effect on downstream language perplexity of three types of inductive bias: 1) recursive, hierarchical processing 2) unrestricted token-token dependencies that can’t be modeled by context-free grammars, and 3) a Zipfian power-law vocabulary distribution. We show that complex, non-context-free interactions between tokens form the best inductive biases. Our study leverages the capabilities of transformer models to run controlled language learning experiments that are not possible to run on humans, and surfaces hypotheses about the structures that facilitate language learning in both humans and machines. | Isabel Papadimitriou, Dan Jurafsky |  |
| 697 |  |  [Machine Reading Comprehension using Case-based Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.564) |  | 0 | We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI. Our method (CBR-MRC) builds upon the hypothesis that contextualized answers to similar questions share semantic similarities with each other. Given a test question, CBR-MRC first retrieves a set of similar cases from a nonparametric memory and then predicts an answer by selecting the span in the test context that is most similar to the contextualized representations of answers in the retrieved cases. The semi-parametric nature of our approach allows it to attribute a prediction to the specific set of evidence cases, making it a desirable choice for building reliable and debuggable QA systems. We show that CBR-MRC provides high accuracy comparable with large reader models and outperforms baselines by 11.5 and 8.4 EM on NaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability of CBR-MRC in identifying not just the correct answer tokens but also the span with the most relevant supporting evidence. Lastly, we observe that contexts for certain question types show higher lexical diversity than others and find that CBR-MRC is robust to these variations while performance using fully-parametric methods drops. | Dung Thai, Dhruv Agarwal, Mudit Chaudhary, Wenlong Zhao, Rajarshi Das, JayYoon Lee, Hannaneh Hajishirzi, Manzil Zaheer, Andrew McCallum |  |
| 698 |  |  [Unleashing the Power of Language Models in Text-Attributed Graph](https://doi.org/10.18653/v1/2023.findings-emnlp.565) |  | 0 | Representation learning on graph has been demonstrated to be a powerful tool for solving real-world problems. Text-attributed graph carries both semantic and structural information among different types of graphs. Existing works have paved the way for knowledge extraction of this type of data by leveraging language models or graph neural networks or combination of them. However, these works suffer from issues like underutilization of relationships between nodes or words or unaffordable memory cost. In this paper, we propose a Node Representation Update Pre-training Architecture based on Co-modeling Text and Graph (NRUP). In NRUP, we construct a hierarchical text-attributed graph that incorporates both original nodes and word nodes. Meanwhile, we apply four self-supervised tasks for different level of constructed graph. We further design the pre-training framework to update the features of nodes during training epochs. We conduct the experiment on the benchmark dataset ogbn-arxiv. Our method achieves outperformance compared to baselines, fully demonstrating its validity and generalization. | Haoyu Kuang, Jiarong Xu, Haozhe Zhang, Zuyu Zhao, Qi Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 699 |  |  [Locally Differentially Private Document Generation Using Zero Shot Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.566) |  | 0 | Numerous studies have highlighted the privacy risks associated with large language models. Our research offers a unique perspective by demonstrating that pretrained large language models can effectively contribute to privacy preservation. We propose a locally differentially private mechanism called DP-Prompt, which leverages the power of pretrained large language models and zero-shot prompting to counter author de-anonymization attacks while minimizing the impact on downstream utility. When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5), we observe a notable reduction in the success rate of de-anonymization attacks, showing that it surpasses existing approaches by a considerable margin despite its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt (with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving a 46% reduction in author identification F1 score against static attackers and a 26% reduction against adaptive attackers. We conduct extensive experiments across six open-source large language models, ranging up to 7 billion parameters, to analyze various effects of the privacy-utility tradeoff. | Saiteja Utpala, Sara Hooker, PinYu Chen |  |
| 700 |  |  [Contrastive Deterministic Autoencoders For Language Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.567) |  | 0 | Variational autoencoders (VAEs) are a popular family of generative models with wide applicability. Training VAEs, especially for text, often runs into the issue of posterior collapse, resulting in loss of representation quality. Deterministic autoencoders avoid this issue, and have been explored particularly well for images. It is however unclear how to best modify a deterministic model designed for images into a successful one for text. We show that with suitable adaptations, we can significantly improve on batch-normed VAEs (BN-VAEs), a strong benchmark for language modeling with VAEs, by replacing them with analogous deterministic models. We employ techniques from contrastive learning to control the entropy of the aggregate posterior of these models to make it Gaussian. The resulting models skip reparametrization steps in VAE modeling and avoid posterior collapse, while outperforming a broad range of VAE models on text generation and downstream tasks from representations. These improvements are shown to be consistent across both LSTM and Transformer-based VAE architectures. Appropriate comparisons to BERT/GPT-2 based results are also included. We also qualitatively examine the latent space through interpolation to supplement the quantitative aspects of the model. | Amur Ghose, Pascal Poupart |  |
| 701 |  |  [CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.568) |  | 0 | We propose CHiLL (Crafting High-Level Latents), an approach for natural-language specification of features for linear models. CHiLL prompts LLMs with expert-crafted queries to generate interpretable features from health records. The resulting noisy labels are then used to train a simple linear classifier. Generating features based on queries to an LLM can empower physicians to use their domain expertise to craft features that are clinically meaningful for a downstream task of interest, without having to manually extract these from raw EHR. We are motivated by a real-world risk prediction task, but as a reproducible proxy, we use MIMIC-III and MIMIC-CXR data and standard predictive tasks (e.g., 30-day readmission) to evaluate this approach. We find that linear models using automatically extracted features are comparably performant to models using reference features, and provide greater interpretability than linear models using “Bag-of-Words” features. We verify that learned feature weights align well with clinical expectations. | Denis Jered McInerney, Geoffrey S. Young, JanWillem van de Meent, Byron C. Wallace |  |
| 702 |  |  [Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers](https://doi.org/10.18653/v1/2023.findings-emnlp.569) |  | 0 | Recent applications of LLMs in Machine Reading Comprehension (MRC) systems have shown impressive results, but the use of shortcuts, mechanisms triggered by features spuriously correlated to the true label, has emerged as a potential threat to their reliability. We analyze the problem from two angles: LLMs as editors, guided to edit text to mislead LLMs; and LLMs as readers, who answer questions based on the edited text. We introduce a framework that guides an editor to add potential shortcuts-triggers to samples. Using GPT4 as the editor, we find it can successfully edit trigger shortcut in samples that fool LLMs. Analysing LLMs as readers, we observe that even capable LLMs can be deceived using shortcut knowledge. Strikingly, we discover that GPT4 can be deceived by its own edits (15% drop in F1). Our findings highlight inherent vulnerabilities of LLMs to shortcut manipulations. We publish ShortcutQA, a curated dataset generated by our framework for future research. | Mosh Levy, Shauli Ravfogel, Yoav Goldberg |  |
| 703 |  |  [Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters](https://doi.org/10.18653/v1/2023.findings-emnlp.570) |  | 0 | In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter. | Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, Jia Li |  |
| 704 |  |  [Quick Back-Translation for Unsupervised Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.571) |  | 0 | The field of unsupervised machine translation has seen significant advancement from the marriage of the Transformer and the back-translation algorithm. The Transformer is a powerful generative model, and back-translation leverages Transformer’s high-quality translations for iterative self-improvement. However, the Transformer is encumbered by the run-time of autoregressive inference during back-translation, and back-translation is limited by a lack of synthetic data efficiency. We propose a two-for-one improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT re-purposes the encoder as a generative model, and uses encoder-generated sequences to train the decoder in conjunction with the original autoregressive back-translation step, improving data throughput and utilization. Experiments on various WMT benchmarks demonstrate that a relatively small number of refining steps of QBT improve current unsupervised machine translation models, and that QBT dramatically outperforms standard back-translation only method in terms of training efficiency for comparable translation qualities. | Benjamin Brimacombe, Jiawei Zhou |  |
| 705 |  |  [SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token](https://doi.org/10.18653/v1/2023.findings-emnlp.572) |  | 0 | We present a simple, but effective method to incorporate syntactic dependency information directly into transformer-based language models (e.g. RoBERTa) for tasks such as Aspect-Based Sentiment Classification (ABSC), where the desired output depends on specific input tokens. In contrast to prior approaches to ABSC that capture syntax by combining language models with graph neural networks over dependency trees, our model, Syntax-Integrated RoBERTa for ABSC (SIR-ABSC) incorporates syntax directly into the language model by using a novel aggregator token. Yet, SIR-ABSC outperforms these more complex models, yielding new state-of-the-art results on ABSC. | Ikhyun Cho, Yoonhwa Jung, Julia Hockenmaier |  |
| 706 |  |  [Citance-Contextualized Summarization of Scientific Papers](https://doi.org/10.18653/v1/2023.findings-emnlp.573) |  | 0 | Current approaches to automatic summarization of scientific papers generate informative summaries in the form of abstracts. However, abstracts are not intended to show the relationship between a paper and the references cited in it. We propose a new contextualized summarization approach that can generate an informative summary conditioned on a given sentence containing the citation of a reference (a so-called “citance”). This summary outlines content of the cited paper relevant to the citation location. Thus, our approach extracts and models the citances of a paper, retrieves relevant passages from cited papers, and generates abstractive summaries tailored to each citance. We evaluate our approach using \*\*Webis-Context-SciSumm-2023\*\*, a new dataset containing 540K computer science papers and 4.6M citances therein. | Shahbaz Syed, Ahmad Dawar Hakimi, Khalid Al Khatib, Martin Potthast |  |
| 707 |  |  [SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations](https://doi.org/10.18653/v1/2023.findings-emnlp.574) |  | 0 | End-to-end Speech Translation is hindered by a lack of available data resources. While most of them are based on documents, a sentence-level version is available, which is however single and static, potentially impeding the usefulness of the data. We propose a new data augmentation strategy, SegAugment, to address this issue by generating multiple alternative sentence-level versions of a dataset. Our method utilizes an Audio Segmentation system, which re-segments the speech of each document with different length constraints, after which we obtain the target text via alignment methods. Experiments demonstrate consistent gains across eight language pairs in MuST-C, with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource scenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment obtains state-of-the-art results in MuST-C. Finally, we show that the proposed method can also successfully augment sentence-level datasets, and that it enables Speech Translation models to close the gap between the manual and automatic segmentation at inference time. | Ioannis Tsiamas, José A. R. Fonollosa, Marta R. Costajussà |  |
| 708 |  |  [Intersectional Stereotypes in Large Language Models: Dataset and Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.575) |  | 0 | Despite many stereotypes targeting intersectional demographic groups, prior studies on stereotypes within Large Language Models (LLMs) primarily focus on broader, individual categories. This research bridges this gap by introducing a novel dataset of intersectional stereotypes, curated with the assistance of the ChatGPT model and manually validated. Moreover, this paper offers a comprehensive analysis of intersectional stereotype propagation in three contemporary LLMs by leveraging this dataset. The findings underscore the urgency of focusing on intersectional biases in ongoing efforts to reduce stereotype prevalence in LLMs. | Weicheng Ma, Brian Chiang, Tong Wu, Lili Wang, Soroush Vosoughi |  |
| 709 |  |  [Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond](https://doi.org/10.18653/v1/2023.findings-emnlp.576) |  | 0 | Vision-language (VL) understanding tasks evaluate models’ comprehension of complex visual scenes through multiple-choice questions. However, we have identified two dataset biases that models can exploit as shortcuts to resolve various VL tasks correctly without proper understanding. The first type of dataset bias is Unbalanced Matching bias, where the correct answer overlaps the question and image more than the incorrect answers. The second type of dataset bias is Distractor Similarity bias, where incorrect answers are overly dissimilar to the correct answer but significantly similar to other incorrect answers within the same sample. To address these dataset biases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic training and debiased evaluation data. We then introduce Intra-sample Counterfactual Training (ICT) to assist models in utilizing the synthesized training data, particularly the counterfactual data, via focusing on intra-sample differentiation. Extensive experiments demonstrate the effectiveness of ADS and ICT in consistently improving model performance across different benchmarks, even in domain-shifted scenarios. | Zhecan Wang, Long Chen, Haoxuan You, Keyang Xu, Yicheng He, Wenhao Li, Noel Codella, KaiWei Chang, ShihFu Chang |  |
| 710 |  |  [The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who](https://doi.org/10.18653/v1/2023.findings-emnlp.577) |  | 0 | Automated fact-checking is often presented as an epistemic tool that fact-checkers, social media consumers, and other stakeholders can use to fight misinformation. Nevertheless, few papers thoroughly discuss how. We document this by analysing 100 highly-cited papers, and annotating epistemic elements related to intended use, i.e., means, ends, and stakeholders. We find that narratives leaving out some of these aspects are common, that many papers propose inconsistent means and ends, and that the feasibility of suggested strategies rarely has empirical backing. We argue that this vagueness actively hinders the technology from reaching its goals, as it encourages overclaiming, limits criticism, and prevents stakeholder feedback. Accordingly, we provide several recommendations for thinking and writing about the use of fact-checking artefacts. | Michael Sejr Schlichtkrull, Nedjma Ousidhoum, Andreas Vlachos |  |
| 711 |  |  [Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression](https://doi.org/10.18653/v1/2023.findings-emnlp.578) |  | 0 | Large-scale pre-trained language models (LLMs) have demonstrated exceptional performance in various natural language processing (NLP) tasks. However, the massive size of these models poses huge challenges for their deployment in real-world applications. While numerous model compression techniques have been proposed, most of them are not well-suited for achieving extreme model compression when there is a significant gap in model scale. In this paper, we introduce a novel compression paradigm called Retrieval-based Knowledge Transfer (RetriKT), which effectively transfers the knowledge of LLMs to extremely small-scale models (e.g., 1%). In particular, our approach extracts knowledge from LLMs to construct a knowledge store, from which the small-scale model can retrieve relevant information and leverage it for effective inference. To improve the quality of the model, soft prompt tuning and Proximal Policy Optimization (PPO) reinforcement learning techniques are employed. Extensive experiments are conducted on low-resource tasks from SuperGLUE and GLUE benchmarks. The results demonstrate that the proposed approach significantly enhances the performance of small-scale models by leveraging the knowledge from LLMs. | Jiduan Liu, Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai, Dongyan Zhao, Ran Wang, Rui Yan |  |
| 712 |  |  [COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification](https://doi.org/10.18653/v1/2023.findings-emnlp.579) |  | 0 | Offensive and toxic text on social media platforms can lead to polarization and divisiveness within online communities and hinders constructive dialogue. Text detoxification is a crucial task in natural language processing to ensure the generation of non-toxic and safe text. Text detoxification is a special case of the Text Style Transfer (TST) problem, where an input text is rephrased to an output text that preserves its content while modifying the style (in this case to a more neutral, non-toxic style). State-of-the-art methods for detoxification use supervised training of encoder-decoder models to produce gold-standard outputs with a standard likelihood-based objective. However, it can be hard for these models to deviate from their pretrained auto-encoder identity mapping. While previous methods have used unlikelihood-based losses to penalize input-to-output copying of toxic content, these methods also unfortunately penalize non-toxic content in the input that would be fine to preserve in the output. To address these issues, we introduce a novel contrastive unlikelihood objective (COUNT) that directly contrasts the gold standard rephrasing with the identity input-to-output mapping to effectively isolate and focus learning on non-toxic style transfer. We benchmark COUNT on two parallel datasets, ParaDetox and APPDIA, showing that it achieves significant improvements in jointly combined fluency, content preservation, and detoxification (i.e., the highest “J” score). | Mohammad Mahdi Abdollah Pour, Parsa Farinneya, Manasa Bharadwaj, Nikhil Verma, Ali Pesaranghader, Scott Sanner |  |
| 713 |  |  [KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.findings-emnlp.580) |  | 0 | Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC and they can be categorized into two main classes, including triple-based and test-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced distributions of entities. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate the limitations in the two approaches, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever, to alleviate the long-tail problem without incurring additional training overhead. In the proposed KICGPT model, we propose an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide LLM. Empirical results on benchmark datasets demonstrate the effectiveness of the proposed KICGPT model with lighter training overhead and no finetuning. | Yanbin Wei, Qiushi Huang, Yu Zhang, James T. Kwok |  |
| 714 |  |  [Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.581) |  | 0 | Article comprehension is an important challenge in natural language processing with many applications such as article generation or image-to-article retrieval. Prior work typically encodes all tokens in articles uniformly using pretrained language models. However, in many applications, such as understanding news stories, these articles are based on real-world events and may reference many named entities that are difficult to accurately recognize and predict by language models. To address this challenge, we propose an ENtity-aware article GeneratIoN and rEtrieval (ENGINE) framework, to explicitly incorporate named entities into language models. ENGINE has two main components: a named-entity extraction module to extract named entities from both metadata and embedded images associated with articles, and an entity-aware mechanism that enhances the model’s ability to recognize and predict entity names. We conducted experiments on three public datasets: GoodNews, VisualNews, and WikiText, where our results demonstrate that our model can boost both article generation and article retrieval performance, with a 4-5 perplexity improvement in article generation and a 3-4% boost in recall@1 in article retrieval. We release our implementation at [this http URL](https://github.com/Zhongping-Zhang/ENGINE). | Zhongping Zhang, Yiwen Gu, Bryan A. Plummer |  |
| 715 |  |  [A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing](https://doi.org/10.18653/v1/2023.findings-emnlp.582) |  | 0 | Two of the central factors believed to underpin human sentence processing difficulty are expectations and retrieval from working memory. A recent attempt to create a unified cognitive model integrating these two factors have relied on the parallels between the self-attention mechanism of transformer language models and cue-based retrieval theories of working memory in human sentence processing (Ryu and Lewis 2021). While the authors show that attention patterns in specialized attention heads of GPT-2 are consistent with a key prediction of cue-based retrieval models, similarity-based interference effects, their method requires the identification of syntactically specialized attention heads, and makes an cognitively implausible implicit assumption that hundreds of memory retrieval operations take place in parallel. In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories. We show that our model’s single attention head can capture semantic and syntactic interference effects observed in human experiments. | William Timkey, Tal Linzen |  |
| 716 |  |  [Annotations Are Not All You Need: A Cross-modal Knowledge Transfer Network for Unsupervised Temporal Sentence Grounding](https://doi.org/10.18653/v1/2023.findings-emnlp.583) |  | 0 | This paper addresses the task of temporal sentence grounding (TSG). Although many respectable works have made decent achievements in this important topic, they severely rely on massive expensive video-query paired annotations, which require a tremendous amount of human effort to collect in real-world applications. To this end, in this paper, we target a more practical but challenging TSG setting: unsupervised temporal sentence grounding, where both paired video-query and segment boundary annotations are unavailable during the network training. Considering that some other cross-modal tasks provide many easily available yet cheap labels, we tend to collect and transfer their simple cross-modal alignment knowledge into our complex scenarios: 1) We first explore the entity-aware object-guided appearance knowledge from the paired Image-Noun task, and adapt them into each independent video frame; 2) Then, we extract the event-aware action representation from the paired Video-Verb task, and further refine the action representation into more practical but complicated real-world cases by a newly proposed copy-paste approach; 3) By modulating and transferring both appearance and action knowledge into our challenging unsupervised task, our model can directly utilize this general knowledge to correlate videos and queries, and accurately retrieve the relevant segment without training. Extensive experiments on two challenging datasets (ActivityNet Captions and Charades-STA) show our effectiveness, outperforming existing unsupervised methods and even competitively beating supervised works. | Xiang Fang, Daizong Liu, Wanlong Fang, Pan Zhou, Yu Cheng, Keke Tang, Kai Zou |  |
| 717 |  |  [Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts](https://doi.org/10.18653/v1/2023.findings-emnlp.584) |  | 0 | Prompt tuning has been proven to be successful on various tasks by incorporating a small number of trainable parameters while freezing large pre-trained language models (PLMs). However, it is still unsettled how to generate more proper prompts for any individual examples and how to extend prompt tuning to multi-task learning scenarios by leveraging cross-task features. To address these challenges, we propose a token-wise prompt tuning (TPT), in which a bank of finer-grained soft prompt tokens is built for multi-task learning by memory network. The tokens are retrieved from the bank against an input example and assembled to an instance-dependent prompt. Extensive experimental results on 14 datasets demonstrated that the models enhanced by our TPT performed far better than full parameter fine-tuned models and achieved state-of-the-art by tuning only 0.035% parameters. | Muling Wu, Wenhao Liu, Jianhan Xu, Changze Lv, Zixuan Ling, Tianlong Li, Longtao Huang, Xiaoqing Zheng, Xuanjing Huang |  |
| 718 |  |  [A Rewriting Approach for Gender Inclusivity in Portuguese](https://doi.org/10.18653/v1/2023.findings-emnlp.585) |  | 0 | In recent years, there has been a notable rise in research interest regarding the integration of gender-inclusive and gender-neutral language in natural language processing models. A specific area of focus that has gained practical and academic significant interest is gender-neutral rewriting, which involves converting binary-gendered text to its gender-neutral counterpart. However, current approaches to gender-neutral rewriting for gendered languages tend to rely on large datasets, which may not be an option for languages with fewer resources, such as Portuguese. In this paper, we present a rule-based and a neural-based tool for gender-neutral rewriting for Portuguese, a heavily gendered Romance language whose morphology creates different challenges from the ones tackled by other gender-neutral rewriters. Our neural approach relies on fine-tuning large multilingual machine translation models on examples generated by the rule-based model. We evaluate both models on texts from different sources and contexts. We provide the first Portuguese dataset explicitly containing gender-neutral language and neopronouns, as well as a manually annotated golden collection of 500 sentences that allows for evaluation of future work. | Leonor Veloso, Luísa Coheur, Rui Ribeiro |  |
| 719 |  |  [EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.586) |  | 0 | Measuring Semantic Textual Similarity (STS) is a fundamental task in biomedical text processing, which aims at quantifying the similarity between two input biomedical sentences. Unfortunately, the STS datasets in the biomedical domain are relatively smaller but more complex in semantics than common domain, often leading to overfitting issues and insufficient text representation even based on Pre-trained Language Models (PLMs) due to too many biomedical entities. In this paper, we propose EARA, an entity-aligned, attention-based and retrieval-augmented PLMs. Our proposed EARA first aligns the same type of fine-grained entity information in each sentence pair with an entity alignment matrix. Then, EARA regularizes the attention mechanism with an entity alignment matrix with an auxiliary loss. Finally, we add a retrieval module that retrieves similar instances to expand the scope of entity pairs and improve the model’s generalization. The comprehensive experiments reflect that EARA can achieve state-of-the-art performance on both in-domain and out-of-domain datasets. Source code is available. | Ying Xiong, Xin Yang, Linjing Liu, KaChun Wong, Qingcai Chen, Yang Xiang, Buzhou Tang |  |
| 720 |  |  [Neuro-Symbolic Sentiment Analysis with Dynamic Word Sense Disambiguation](https://doi.org/10.18653/v1/2023.findings-emnlp.587) |  | 0 | Sentiment analysis is a task that highly depends on the understanding of word senses. Traditional neural network models are black boxes that represent word senses as vectors that are uninterpretable for humans. On the other hand, the application of Word Sense Disambiguation (WSD) systems in downstream tasks poses challenges regarding i) which words need to be disambiguated, and ii) how to model explicit word senses into easily understandable terms for a downstream model. This work proposes a neurosymbolic framework that incorporates WSD by identifying and paraphrasing ambiguous words to improve the accuracy of sentiment predictions. The framework allows us to understand which words are paraphrased into which semantically unequivocal words, thus enabling a downstream task model to gain both accuracy and interpretability. To better fine-tune a lexical substitution model for WSD on a downstream task without ground-truth word sense labels, we leverage dynamic rewarding to jointly train sentiment analysis and lexical substitution models. Our framework proves to effectively improve the performance of sentiment analysis on corpora from different domains. | Xulang Zhang, Rui Mao, Kai He, Erik Cambria |  |
| 721 |  |  [Role of Context in Unsupervised Sentence Representation Learning: the Case of Dialog Act Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.588) |  | 0 | Unsupervised learning of word representations involves capturing the contextual information surrounding word occurrences, which can be grounded in the observation that word form is largely disconnected from word meaning. While there are fewer reasons to believe that the same holds for sentences, learning through context has been carried over to learning representations of word sequences. However, this work pays minimal to no attention to the role of context in inferring sentence representations. In this article, we present a dialog act tag probing task designed to explicitly compare content-, and context-oriented sentence representations inferred on utterances of telephone conversations (SwDA). Our results suggest that there is no clear benefit of context-based sentence representations over content-based sentence representations. However, there is a very clear benefit of increasing the dimensionality of the sentence vectors in nearly all approaches. | Rastislav Hronsky, Emmanuel Keuleers |  |
| 722 |  |  [CLMSM: A Multi-Task Learning Framework for Pre-training on Procedural Text](https://doi.org/10.18653/v1/2023.findings-emnlp.589) |  | 0 | In this paper, we propose \*\*\*CLMSM\*\*\*, a domain-specific, continual pre-training framework, that learns from a large set of procedural recipes. \*\*\*CLMSM\*\*\* uses a Multi-Task Learning Framework to optimize two objectives - a) Contrastive Learning using hard triplets to learn fine-grained differences across entities in the procedures, and b) a novel Mask-Step Modelling objective to learn step-wise context of a procedure. We test the performance of \*\*\*CLMSM\*\*\* on the downstream tasks of tracking entities and aligning actions between two procedures on three datasets, one of which is an open-domain dataset not conforming with the pre-training dataset. We show that \*\*\*CLMSM\*\*\* not only outperforms baselines on recipes (in-domain) but is also able to generalize to open-domain procedural NLP tasks. | Abhilash Nandy, Manav Nitin Kapadnis, Pawan Goyal, Niloy Ganguly |  |
| 723 |  |  [Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking](https://doi.org/10.18653/v1/2023.findings-emnlp.590) |  | 0 | In the field of information retrieval, Query Likelihood Models (QLMs) rank documents based on the probability of generating the query given the content of a document. Recently, advanced large language models (LLMs) have emerged as effective QLMs, showcasing promising ranking capabilities. This paper focuses on investigating the genuine zero-shot ranking effectiveness of recent LLMs, which are solely pre-trained on unstructured text data without supervised instruction fine-tuning. Our findings reveal the robust zero-shot ranking ability of such LLMs, highlighting that additional instruction fine-tuning may hinder effectiveness unless a question generation task is present in the fine-tuning dataset. Furthermore, we introduce a novel state-of-the-art ranking system that integrates LLM-based QLMs with a hybrid zero-shot retriever, demonstrating exceptional effectiveness in both zero-shot and few-shot scenarios. We make our codebase publicly available at https://github.com/ielab/llm-qlm. | Shengyao Zhuang, Bing Liu, Bevan Koopman, Guido Zuccon |  |
| 724 |  |  [On General Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.591) |  | 0 | Natural Language Processing prides itself to be an empirically-minded, if not outright empiricist field, and yet lately it seems to get itself into essentialist debates on issues of meaning and measurement (“Do Large Language Models Understand Language, And If So, How Much?”). This is not by accident: Here, as everywhere, the evidence underspecifies the understanding. As a remedy, this paper sketches the outlines of a model of understanding, which can ground questions of the adequacy of current methods of measurement of model quality. The paper makes three claims: A) That different language use situation types have different characteristics, B) That language understanding is a multifaceted phenomenon, bringing together individualistic and social processes, and C) That the choice of Understanding Indicator marks the limits of benchmarking, and the beginnings of considerations of the ethics of NLP use. | David Schlangen |  |
| 725 |  |  [USB: A Unified Summarization Benchmark Across Tasks and Domains](https://doi.org/10.18653/v1/2023.findings-emnlp.592) |  | 0 | While the NLP community has produced numerous summarization benchmarks, none provide the rich annotations required to simultaneously address many important problems related to control and reliability. We introduce a Wikipedia-derived benchmark, complemented by a rich set of crowd-sourced annotations, that supports 8 interrelated tasks: (i) extractive summarization; (ii) abstractive summarization; (iii) topic-based summarization; (iv) compressing selected sentences into a one-line summary; (v) surfacing evidence for a summary sentence; (vi) predicting the factual accuracy of a summary sentence; (vii) identifying unsubstantiated spans in a summary sentence; (viii) correcting factual errors in summaries. We compare various methods on this benchmark and discover that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models. For factuality-related tasks, we also evaluate existing heuristics to create training data and find that training on them results in worse performance than training on 20× less human-labeled data. Our articles draw from 6 domains, facilitating cross-domain analysis. On some tasks, the amount of training data matters more than the domain where it comes from, while for other tasks training specifically on data from the target domain, even if limited, is more beneficial. | Kundan Krishna, Prakhar Gupta, Sanjana Ramprasad, Byron C. Wallace, Jeffrey P. Bigham, Zachary C. Lipton |  |
| 726 |  |  [tagE: Enabling an Embodied Agent to Understand Human Instructions](https://doi.org/10.18653/v1/2023.findings-emnlp.593) |  | 0 | Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and their corresponding arguments from these intricate instructions. These extracted tasks are then mapped (or grounded) to the robot’s established collection of skills, while the arguments find grounding in objects present within the environment. To facilitate the training and evaluation of our system, we have curated a dataset featuring complex instructions. The results of our experiments underscore the prowess of our approach, as it outperforms robust baseline models. | Chayan Sarkar, Avik Mitra, Pradip Pramanick, Tapas Nayak |  |
| 727 |  |  [Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.594) |  | 0 | Hierarchical multi-label text classification (HMTC) aims at utilizing a label hierarchy in multi-label classification. Recent approaches to HMTC deal with the problem of imposing an overconstrained premise on the output space by using contrastive learning on generated samples in a semi-supervised manner to bring text and label embeddings closer. However, the generation of samples tends to introduce noise as it ignores the correlation between similar samples in the same batch. One solution to this issue is supervised contrastive learning, but it remains an underexplored topic in HMTC due to its complex structured labels. To overcome this challenge, we propose \*\*HJCL\*\*, a \*\*H\*\*ierarchy-aware \*\*J\*\*oint Supervised \*\*C\*\*ontrastive \*\*L\*\*earning method that bridges the gap between supervised contrastive learning and HMTC. Specifically, we employ both instance-wise and label-wise contrastive learning techniques and carefully construct batches to fulfill the contrastive learning objective. Extensive experiments on four multi-path HMTC datasets demonstrate that HJCLachieves promising results and the effectiveness of Contrastive Learning on HMTC. Code and data are available at https://github.com/simonucl/HJCL. | Simon Chi Lok U, Jie He, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 728 |  |  [Uncovering Limitations in Text-to-Image Generation: A Contrastive Approach with Structured Semantic Alignment](https://doi.org/10.18653/v1/2023.findings-emnlp.595) |  | 0 | Despite significant advancements in text-to-image generation models, they still face challenges when it comes to producing highly detailed or complex images based on textual descriptions. In order to explore these limitations, we propose a Structured Semantic Alignment (SSA) method for evaluating text-to-image generation models. SSA focuses on learning structured semantic embeddings across different modalities and aligning them in a joint space. The method employs the following steps to achieve its objective: (i) Generating mutated prompts by substituting words with semantically equivalent or nonequivalent alternatives while preserving the original syntax; (ii) Representing the sentence structure through parsing trees obtained via syntax parsing; (iii) Learning fine-grained structured embeddings that project semantic features from different modalities into a shared embedding space; (iv) Evaluating the semantic consistency between the structured text embeddings and the corresponding visual embeddings. Through experiments conducted on various benchmarks, we have demonstrated that SSA offers improved measurement of semantic consistency of text-to-image generation models. Additionally, it unveils a wide range of generation errors including under-generation, incorrect constituency, incorrect dependency, and semantic confusion. By uncovering these biases and limitations embedded within the models, our proposed method provides valuable insights into their shortcomings when applied to real-world scenarios. | Qianyu Feng, Yulei Sui, Hongyu Zhang |  |
| 729 |  |  [An Intent-based and Annotation-free Method for Duplicate Question Detection in CQA Forums](https://doi.org/10.18653/v1/2023.findings-emnlp.596) |  | 0 | With the advent of large language models (LLMs), Community Question Answering (CQA) forums offer well-curated questions and answers that can be utilized for instruction-tuning, effectively training LLMs to be aligned with human intents. However, the issue of duplicate questions arises as the volume of content within CQA continues to grow, posing a threat to content quality. Recent research highlights the benefits of detecting and eliminating duplicate content. It not only enhances the LLMs’ ability to generalize across diverse intents but also improves the efficiency of training data utilization while addressing concerns related to information leakage. However, existing methods for detecting duplicate questions in CQA typically rely on generic text-pair matching models, overlooking the intent behind the questions. In this paper, we propose a novel intent-based duplication detector named Intent-DQD that comprehensively leverages intent information to address the problem of duplicate question detection in CQA. Intent-DQD first leverages the characteristics in CQA forums and extracts training labels to recognize and match intents without human annotation. Intent-DQD then effectively aggregates intent-level relations and establishes question-level relations to enable intent-aware duplication detection. Experimental results on fifteen distinct domains from both CQADupStack and Stack Overflow datasets demonstrate the effectiveness of Intent-DQD. Reproducible codes and datasets will be released upon publication of the paper. | Yubo Shu, Hansu Gu, Peng Zhang, Tun Lu, Ning Gu |  |
| 730 |  |  [Accelerating Multiple Intent Detection and Slot Filling via Targeted Knowledge Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.597) |  | 0 | Recent non-autoregressive Spoken Language Understanding (SLU) models have attracted increasing attention because of their encouraging inference speed. However, most of existing methods (1) suffer from the multi-modality problem since they have little prior knowledge about the reference during inference; (2) fail to achieve a satisfactory inference speed limited by their complex frameworks. To tackle these issues, in this paper, we propose a Targeted Knowledge Distillation Framework (TKDF) for multi-intent SLU, which utilizes the knowledge distillation method to improve the performance. Specifically, we first train an SLU model as the teacher model, which has higher accuracy while slower inference speed. Then we introduce an evaluator and apply a curriculum learning strategy to select proper targets for the student model. Experiment results on two public multi-intent datasets show that our approach can realize a flexible trade-off between inference speed and accuracy, achieving comparable performance to the state-of-the-art models while speeding up by over 4.5 times. More encouragingly, further analysis shows that distilling only 4% of the original data can help the student model outperform its counterpart trained on the original data by about 14.6% in terms of overall accuracy on MixATIS dataset. | Xuxin Cheng, Zhihong Zhu, Wanshi Xu, Yaowei Li, Hongxiang Li, Yuexian Zou |  |
| 731 |  |  [Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.598) |  | 0 | Despite the recent success achieved by several two-stage prototypical networks in few-shot named entity recognition (NER) task, the over-detected false spans at span detection stage and the inaccurate and unstable prototypes at type classification stage remain to be challenging problems. In this paper, we propose a novel Type-Aware Decomposed framework, namely TadNER, to solve these problems. We first present a type-aware span filtering strategy to filter out false spans by removing those semantically far away from type names. We then present a type-aware contrastive learning strategy to construct more accurate and stable prototypes by jointly exploiting support samples and type names as references. Extensive experiments on various benchmarks prove that our proposed TadNER framework yields a new state-of-the-art performance. | Yongqi Li, Yu Yu, Tieyun Qian |  |
| 732 |  |  [A Closer Look into Using Large Language Models for Automatic Evaluation](https://doi.org/10.18653/v1/2023.findings-emnlp.599) |  | 0 | Using large language models (LLMs) to evaluate text quality has recently gained popularity. Some existing prior works explore the idea of using LLMs for evaluation, while they differ in some details of the evaluation process. In this paper, we analyze \*LLM evaluation\* and \*G-Eval\*, and we discuss how those details in the evaluation process change how well the ratings given by LLMs correlate with human ratings. We find that the auto Chain-of-Thought (CoT) used in G-Eval does not always make G-Eval more aligned with human ratings. We also show that forcing the LLM to output only a numeric rating, as in G-Eval, is suboptimal. Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets. | David ChengHan Chiang, Hungyi Lee |  |
| 733 |  |  [Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?](https://doi.org/10.18653/v1/2023.findings-emnlp.600) |  | 0 | Given the success of Graph Neural Networks (GNNs) for structure-aware machine learning, many studies have explored their use for text classification, but mostly in specific domains with limited data characteristics. Moreover, some strategies prior to GNNs relied on graph mining and classical machine learning, making it difficult to assess their effectiveness in modern settings. This work extensively investigates graph representation methods for text classification, identifying practical implications and open challenges. We compare different graph construction schemes using a variety of GNN architectures and setups across five datasets, encompassing short and long documents as well as unbalanced scenarios in diverse domains. Two Transformer-based large language models are also included to complement the study. The results show that i) although the effectiveness of graphs depends on the textual input features and domain, simple graph constructions perform better the longer the documents are, ii) graph representations are especially beneficial for longer documents, outperforming Transformer-based models, iii) graph methods are particularly efficient for solving the task. | Margarita Bugueño, Gerard de Melo |  |
| 734 |  |  [Natural Language Annotations for Reasoning about Program Semantics](https://doi.org/10.18653/v1/2023.findings-emnlp.601) |  | 0 | By grounding natural language inference in code (and vice versa), researchers aim to create programming assistants that explain their work, are “coachable” and can surface any gaps in their reasoning. Can we deduce automatically interesting properties of programs from their syntax and common-sense annotations alone, without resorting to static analysis? How much of program logic and behaviour can be captured in natural language? To stimulate research in this direction and attempt to answer these questions we propose HTL, a dataset and protocol for annotating programs with natural language predicates at a finer granularity than code comments and without relying on internal compiler representations. The dataset is available at the following address: https://doi.org/10.5281/zenodo.7893113 . | Marco Zocca |  |
| 735 |  |  [Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.602) |  | 0 | Previous work has established that a person’s demographics and speech style affect how well speech processing models perform for them. But where does this bias come from? In this work, we present the Speech Embedding Association Test (SpEAT), a method for detecting bias in one type of model used for many speech tasks: pre-trained models. The SpEAT is inspired by word embedding association tests in natural language processing, which quantify intrinsic bias in a model’s representations of different concepts, such as race or valence—something’s pleasantness or unpleasantness—and capture the extent to which a model trained on large-scale socio-cultural data has learned human-like biases. Using the SpEAT, we test for six types of bias in 16 English speech models (including 4 models also trained on multilingual data), which come from the wav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more models reveal positive valence (pleasantness) associations with abled people over disabled people, with European-Americans over African-Americans, with females over males, with U.S. accented speakers over non-U.S. accented speakers, and with younger people over older people. Beyond establishing that pre-trained speech models contain these biases, we also show that they can have real world effects. We compare biases found in pre-trained models to biases in downstream models adapted to the task of Speech Emotion Recognition (SER) and find that in 66 of the 96 tests performed (69%), the group that is more associated with positive valence as indicated by the SpEAT also tends to be predicted as speaking with higher valence by the downstream model. Our work provides evidence that, like text and image-based models, pre-trained speech based-models frequently learn human-like biases when trained on large-scale socio-cultural datasets. Our work also shows that bias found in pre-trained models can propagate to the downstream task of SER. | Isaac Slaughter, Craig Greenberg, Reva Schwartz, Aylin Caliskan |  |
| 736 |  |  [Text Classification via Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.603) |  | 0 | Despite the remarkable success of large-scale Language Models (LLMs) such as GPT-3, their performances still significantly underperform fine-tuned models in the task of text classification.This is due to (1) the lack of reasoning ability in addressing complex linguistic phenomena (e.g., intensification, contrast, irony etc); (2) limited number of tokens allowed in in-context learning. In this paper, we introduce Clue And Reasoning Prompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for kNN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM’s generalization ability and the task-specific evidence provided by the full labeled dataset. Remarkably, CARP yields new SOTA performances on 4 out of 5 widely-used text-classification benchmarks, 97.39 (+1.24) on SST-2, 96.40 (+0.72) on AGNews, 98.78 (+0.25) on R8 and 96.95 (+0.6) on R52, and a performance comparable to SOTA on MR (92.39 v.s. 93.3). More importantly, we find that CARP delivers impressive abilities on low-resource and domain-adaptation setups. Specifically, using 16 examples per class, CARP achieves comparable performances to supervised models with 1,024 examples per class. | Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, Guoyin Wang |  |
| 737 |  |  [On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.604) |  | 0 | Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn’t account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the increased complexity of out-of-distribution (OOD) contents. To tackle this novel task, we present a task-aware meta-learning based framework, with a central focus on achieving effective task personalization that distinguishes between in-task and out-of-task distribution. Specifically, we adopt a hierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to achieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost future research in the field of entity-level few-shot VDER. Experimental results demonstrate our approaches significantly improve the robustness of popular meta-learning baselines. | Jiayi Chen, Hanjun Dai, Bo Dai, Aidong Zhang, Wei Wei |  |
| 738 |  |  [Semi-Structured Object Sequence Encoders](https://doi.org/10.18653/v1/2023.findings-emnlp.605) |  | 0 | In this paper we explore the task of modeling semi-structured object sequences; in particular, we focus our attention on the problem of developing a structure-aware input representation for such sequences. Examples of such data include user activity on websites, machine logs, and many others. This type of data is often represented as a sequence of sets of key-value pairs over time and can present modeling challenges due to an ever-increasing sequence length. We propose a two-part approach, which first considers each key independently and encodes a representation of its values over time; we then self-attend over these value-aware key representations to accomplish a downstream task. This allows us to operate on longer object sequences than existing methods. We introduce a novel shared-attention-head architecture between the two modules and present an innovative training schedule that interleaves the training of both modules with shared weights for some attention heads. Our experiments on multiple prediction tasks using real-world data demonstrate that our approach outperforms a unified network with hierarchical encoding, as well as other methods including a record-centric representation and a flattened representation of the sequence. | Rudra Murthy V, Riyaz A. Bhat, R. Chulaka Gunasekara, Siva Sankalp Patel, Hui Wan, Tejas I. Dhamecha, Danish Contractor, Marina Danilevsky |  |
| 739 |  |  [DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM](https://doi.org/10.18653/v1/2023.findings-emnlp.606) |  | 0 | In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages Encoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME’s potential extends to generating clustered embeddings as well. Notably, our proposed framework proves to be efficient to train and exhibits high adaptability, demonstrating its potential for a wide array of applications. | Weijie Xu, Wenxiang Hu, Fanyou Wu, Srinivasan H. Sengamedu |  |
| 740 |  |  [Energy and Carbon Considerations of Fine-Tuning BERT](https://doi.org/10.18653/v1/2023.findings-emnlp.607) |  | 0 | Despite the popularity of the pre-train then fine-tune paradigm in the NLP community, existing work quantifying energy costs and associated carbon emissions has largely focused on language model pre-training. Although a single pre-training run draws substantially more energy than fine-tuning, fine-tuning is performed more frequently by many more individual actors, and thus must be accounted for when considering the energy and carbon footprint of NLP. In order to better characterize the role of fine-tuning in the landscape of energy and carbon emissions in NLP, we perform a careful empirical study of the computational costs of fine-tuning across tasks, datasets, hardware infrastructure and measurement modalities. Our experimental results allow us to place fine-tuning energy and carbon costs into perspective with respect to pre-training and inference, and outline recommendations to NLP researchers and practitioners who wish to improve their fine-tuning energy efficiency. | Xiaorong Wang, Clara Na, Emma Strubell, Sorelle A. Friedler, Sasha Luccioni |  |
| 741 |  |  [Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models](https://doi.org/10.18653/v1/2023.findings-emnlp.608) |  | 0 | The dominance of proprietary LLMs has led to restricted access and raised information privacy concerns. The SoTA open-source alternatives are crucial for information-sensitive and high-volume applications but often lag behind in performance. To address this gap, we propose (1) A generalized variant of iterative self-critique and self-refinement devoid of external influence. (2) A novel ranking metric - Performance, Refinement, and Inference Cost Score (PeRFICS) - to find the optimal model for a given task considering refined performance and cost. Our experiments show that SoTA open source models of varying sizes from 7B - 65B, on average, improve 8.2% from their baseline performance. Strikingly, even models with extremely small memory footprints, such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39% improvement in high-creativity, open ended tasks on the Vicuna benchmark. Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement. This work has profound implications for resource-constrained and information-sensitive environments seeking to leverage LLMs without incurring prohibitive costs, compromising on performance and privacy. The domain-agnostic self-refinement process coupled with our novel ranking metric facilitates informed decision-making in model selection, thereby reducing costs and democratizing access to high-performing language models, as evidenced by three case studies on personal computing, gaming and enterprise solutions. | Sumuk Shashidhar, Abhinav Chinta, Vaibhav Sahai, Zhenhailong Wang, Heng Ji |  |
| 742 |  |  [Chinese Metaphorical Relation Extraction: Dataset and Models](https://doi.org/10.18653/v1/2023.findings-emnlp.609) |  | 0 | Metaphor identification is usually formulated as a sequence labeling or a syntactically related word-pair classification problem. In this paper, we propose a novel formulation of metaphor identification as a relation extraction problem. We introduce metaphorical relations, which are links between two spans, a target span and a source-related span, which are realized in sentences. Based on spans, we can use more flexible and precise text units beyond single words for capturing the properties of the target and the source. We create a dataset for Chinese metaphorical relation extraction, with more than 4,200 sentences annotated with metaphorical relations, corresponding target/source-related spans, and fine-grained span types. We develop a span-based end-to-end model for metaphorical relation extraction and demonstrate its effectiveness. We expect that metaphorical relation extraction can serve as a bridge for connecting linguistic and conceptual metaphor processing. The dataset is at https://github.com/cnunlp/CMRE. | Guihua Chen, Tiantian Wu, MiaoMiao Cheng, Xu Han, Jiefu Gong, Shijin Wang, Wei Song |  |
| 743 |  |  [Example-based Hypernetworks for Multi-source Adaptation to Unseen Domains](https://doi.org/10.18653/v1/2023.findings-emnlp.610) |  | 0 | As Natural Language Processing (NLP) algorithms continually achieve new milestones, out-of-distribution generalization remains a significant challenge. This paper addresses the issue of multi-source adaptation for unfamiliar domains: We leverage labeled data from multiple source domains to generalize to unknown target domains at training. Our innovative framework employs example-based Hypernetwork adaptation: a T5 encoder-decoder initially generates a unique signature from an input example, embedding it within the source domains’ semantic space. This signature is subsequently utilized by a Hypernetwork to generate the task classifier’s weights. In an advanced version, the signature also enriches the input example’s representation. We evaluated our method across two tasks—sentiment classification and natural language inference—in 29 adaptation scenarios, where it outpaced established algorithms. We also compare our finetuned architecture to few-shot GPT-3, demonstrating its effectiveness in essential use cases. To the best of our knowledge, this marks the first application of Hypernetworks to the adaptation for unknown domains. | Tomer Volk, Eyal BenDavid, Ohad Amosy, Gal Chechik, Roi Reichart |  |
| 744 |  |  [Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.611) |  | 0 | The age of social media is rife with memes. Understanding and detecting harmful memes pose a significant challenge due to their implicit meaning that is not explicitly conveyed through the surface text and image. However, existing harmful meme detection approaches only recognize superficial harm-indicative signals in an end-to-end classification manner but ignore in-depth cognition of the meme text and image. In this paper, we attempt to detect harmful memes based on advanced reasoning over the interplay of multimodal information in memes. Inspired by the success of Large Language Models (LLMs) on complex reasoning, we first conduct abductive reasoning with LLMs. Then we propose a novel generative framework to learn reasonable thoughts from LLMs for better multimodal fusion and lightweight fine-tuning, which consists of two training stages: 1) Distill multimodal reasoning knowledge from LLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive experiments conducted on three meme datasets demonstrate that our proposed approach achieves superior performance than state-of-the-art methods on the harmful meme detection task. | Hongzhan Lin, Ziyang Luo, Jing Ma, Long Chen |  |
| 745 |  |  [Domain Adaptation for Conversational Query Production with the RAG Model Feedback](https://doi.org/10.18653/v1/2023.findings-emnlp.612) |  | 0 | Conversational query production is an emerging fundamental task for the dialogue system, where search queries are generated to explore the vast and continually updating knowledge from a search engine. To accelerate this line of research, previous studies have released several datasets with human-annotated search queries. However, the limited annotations still can not cover conversations of various domains. To solve this challenge, we propose a novel domain adaptation framework. It is inspired by a weakly supervised learning algorithm from previous work that guides a model using reinforcement learning with BM25 scores as feedback. Though effective, it is fragile facing noisy content on webpages from a commercial search engine and variance in conversations because of ignoring deep semantic information of dialogue contexts. Thus, we improve the algorithm by taking the advance of retrieval-augmented generation (RAG) and exploring several practical techniques such as knowledge distillation for stable training. We conduct experiments in multiple settings across different languages. Guided by the RAG model feedback, our model is more robust and performs significantly better especially in a more challenging setting over strong baselines. | Ante Wang, Linfeng Song, Ge Xu, Jinsong Su |  |
| 746 |  |  [LEGO: A Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.613) |  | 0 | Causality Explanation Generation refers to generate an explanation in natural language given an initial cause-effect pair. It demands rigorous explicit rationales to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized, making it challenging for large language models since they are often suffering from spurious causal associations when they encounter the content that does not exist in their memory. In this work, we introduce LEGO, a Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for causality explanation generation. Specifically, we treat LLM as character malleable LEGO block and utilize role-playing to assign specific roles to five LLMs. We firstly devise a Fine-grained World Knowledge Integration Module to augment information about tasks for alleviating the phenomenon of spurious causal associations. Then, we leverage an Iterative Feedback and Refinement Module to improve the generated explanation by multi-aspect feedback. Extensive experiments on widely used WIKIWHY and e-CARE datasets show the superiority of our multi-agent framework in terms of reasoning about the causality among cause and effect. | Zhitao He, Pengfei Cao, Yubo Chen, Kang Liu, Ruopeng Li, Mengshu Sun, Jun Zhao |  |
| 747 |  |  [Ranking LLM-Generated Loop Invariants for Program Verification](https://doi.org/10.18653/v1/2023.findings-emnlp.614) |  | 0 | Synthesizing inductive loop invariants is fundamental to automating program verification. In this work we observe that Large Language Models (such as gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of programs in a 0-shot setting, yet require several samples to generate the correct invariants. This can lead to a large number a calls to a program verifier to establish an invariant. To address this issue, we propose a re-ranking approach for the generated results of LLMs. We have designed a ranker that can distinguish between correct inductive invariants and incorrect attempts based on the problem definition. The ranker is optimized as a contrastive ranker. Experimental results demonstrate that this re-ranking mechanism significantly improves the ranking of correct invariants among the generated candidates, leading to a notable reduction in the number of calls to a verifier. | Saikat Chakraborty, Shuvendu K. Lahiri, Sarah Fakhoury, Akash Lal, Madanlal Musuvathi, Aseem Rastogi, Aditya Senthilnathan, Rahul Sharma, Nikhil Swamy |  |
| 748 |  |  [WordNet Is All You Need: A Surprisingly Effective Unsupervised Method for Graded Lexical Entailment](https://doi.org/10.18653/v1/2023.findings-emnlp.615) |  | 0 | We propose a simple unsupervised approach which exclusively relies on WordNet (Miller,1995) for predicting graded lexical entailment (GLE) in English. Inspired by the seminal work of Resnik (1995), our method models GLE as the sum of two information-theoretic scores: a symmetric semantic similarity score and an asymmetric specificity loss score, both exploiting the hierarchical synset structure of WordNet. Our approach also includes a simple disambiguation mechanism to handle polysemy in a given word pair. Despite its simplicity, our method achieves performance above the state of the art (Spearman 𝜌 = 0.75) on HyperLex (Vulic et al., 2017), the largest GLE dataset, outperforming all previous methods, including specialized word embeddings approaches that use WordNet as weak supervision. | Joseph Renner, Pascal Denis, Rémi Gilleron |  |
| 749 |  |  [Knowledge Corpus Error in Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.616) |  | 0 | Recent works in open-domain question answering (QA) have explored generating context passages from large language models (LLMs), replacing the traditional retrieval step in the QA pipeline. However, it is not well understood why generated passages can be more effective than retrieved ones. This study revisits the conventional formulation of QA and introduces the concept of knowledge corpus error. This error arises when the knowledge corpus used for retrieval is only a subset of the entire string space, potentially excluding more helpful passages that exist outside the corpus. LLMs may mitigate this shortcoming by generating passages in a larger space. We come up with an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically. Our results across three QA benchmarks reveal an increased performance (10% - 13%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error. | Yejoon Lee, Philhoon Oh, James Thorne |  |
| 750 |  |  [Epsilon Sampling Rocks: Investigating Sampling Strategies for Minimum Bayes Risk Decoding for Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.617) |  | 0 | Recent advances in machine translation (MT) have shown that Minimum Bayes Risk (MBR) decoding can be a powerful alternative to beam search decoding, especially when combined with neural-based utility functions. However, the performance of MBR decoding depends heavily on how and how many candidates are sampled from the model. In this paper, we explore how different sampling approaches for generating candidate lists for MBR decoding affect performance. We evaluate popular sampling approaches, such as ancestral, nucleus, and top-k sampling. Based on our insights into their limitations, we experiment with the recently proposed epsilon-sampling approach, which prunes away all tokens with a probability smaller than epsilon, ensuring that each token in a sample receives a fair probability mass. Through extensive human evaluations, we demonstrate that MBR decoding based on epsilon-sampling significantly outperforms not only beam search decoding, but also MBR decoding with all other tested sampling methods across four language pairs. | Markus Freitag, Behrooz Ghorbani, Patrick Fernandes |  |
| 751 |  |  [The language of prompting: What linguistic properties make a prompt successful?](https://doi.org/10.18653/v1/2023.findings-emnlp.618) |  | 0 | The latest generation of LLMs can be prompted to achieve impressive zero-shot or few-shot performance in many NLP tasks. However, since performance is highly sensitive to the choice of prompts, considerable effort has been devoted to crowd-sourcing prompts or designing methods for prompt optimisation. Yet, we still lack a systematic understanding of how linguistic properties of prompts correlate with the task performance. In this work, we investigate how LLMs of different sizes, pre-trained and instruction-tuned, perform on prompts that are semantically equivalent, but vary in linguistic structure. We investigate both grammatical properties such as mood, tense, aspect and modality, as well as lexico-semantic variation through the use of synonyms. Our findings contradict the common assumption that LLMs achieve optimal performance on prompts which reflect language use in pretraining or instruction-tuning data. Prompts transfer poorly between datasets or models, and performance cannot generally be explained by perplexity, word frequency, word sense ambiguity or prompt length. Based on our results, we put forward a proposal for a more robust and comprehensive evaluation standard for prompting research. | Alina Leidinger, Robert van Rooij, Ekaterina Shutova |  |
| 752 |  |  [When and Why Does Bias Mitigation Work?](https://doi.org/10.18653/v1/2023.findings-emnlp.619) |  | 0 | Neural models have been shown to exploit shallow surface features to perform language understanding tasks, rather than learning the deeper language understanding and reasoning skills that practitioners desire. Previous work has developed debiasing techniques to pressure models away from spurious features or artifacts in datasets, with the goal of having models instead learn useful, task-relevant representations. However, what do models actually learn as a result of such debiasing procedures? In this work, we evaluate three model debiasing strategies, and through a set of carefully designed tests we show how debiasing can actually increase the model’s reliance on hidden biases, instead of learning robust features that help it solve a task. Further, we demonstrate how even debiasing models against all shallow features in a dataset may still not help models address NLP tasks. As a result, we suggest that debiasing existing models may not be sufficient for many language understanding tasks, and future work should consider new learning paradigms, to address complex challenges such as commonsense reasoning and inference. | Abhilasha Ravichander, Joe Stacey, Marek Rei |  |
| 753 |  |  [Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy](https://doi.org/10.18653/v1/2023.findings-emnlp.620) |  | 0 | Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner: a model’s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation. | Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, Weizhu Chen |  |
| 754 |  |  [Dynamic Low-rank Estimation for Transformer-based Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.621) |  | 0 | Matrix decomposition methods, such as Singular Value Decomposition (SVD) and its importance-weighted variants, have been widely used for compressing Transformer-based language models. While importance-weighted decomposition methods alleviate the strong assumption of equal importance for each parameter in SVD, they still rely on two fundamental assumptions: 1) unchanged importance distribution during further fine-tuning, 2) equal importance across weight matrices in different layers. Furthermore, these methods necessitate a well-trained task-specific model as the starting point and require additional fine-tuning after compression. In this work, we proposed RankDyna, a matrix decomposition method that enables dynamic rank resource allocation among matrices across different layers during the training process. Starting from a general pre-trained model, RankDyna accomplishes the dual goals of compression and adaptation to the downstream task, all within a single round of fine-tuning. The extensive evaluations demonstrate that RankDyna can outperform current SOTA methods under various parameter budget levels, and the advantage of RankDyna is further enhanced with higher compression rates. | Ting Hua, Xiao Li, Shangqian Gao, YenChang Hsu, Yilin Shen, Hongxia Jin |  |
| 755 |  |  [Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling](https://doi.org/10.18653/v1/2023.findings-emnlp.622) |  | 0 | Existing accent transfer works rely on parallel data or speech recognition models. This paper focuses on the practical application of accent transfer and aims to implement accent transfer using non-parallel datasets. The study has encountered the challenge of speech representation disentanglement and modeling accents. In our accent modeling transfer framework, we manage to solve these problems by two proposed methods. First, we learn the suprasegmental information associated with tone to finely model the accents in terms of tone and rhythm. Second, we propose to use mutual information learning to disentangle the accent features and control the accent of the generated speech during the inference time. Experiments show that the proposed framework attains superior performance to the baseline models in terms of accentedness and audio quality. | Linqin Wang, Zhengtao Yu, Yuanzhang Yang, Shengxiang Gao, Cunli Mao, Yuxin Huang |  |
| 756 |  |  [Compositional Generalization for Data-to-Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.623) |  | 0 | Data-to-text generation involves transforming structured data, often represented as predicate-argument tuples, into coherent textual descriptions. Despite recent advances, systems still struggle when confronted with unseen combinations of predicates, producing unfaithful descriptions (e.g.,hallucinations or omissions). We refer to this issue as compositional generalisation, and it encouraged us to create a benchmark for assessing the performance of different approaches on this specific problem. Furthermore, we propose a novel model that addresses compositional generalization by clustering predicates into groups. Our model generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time. This approach significantly outperforms T5-baselines across all evaluation metrics. Notably, it achieved a 31% improvement over T5 in terms of a metric focused on maintaining faithfulness to the input. | Xinnuo Xu, Ivan Titov, Mirella Lapata |  |
| 757 |  |  [In-Context Learning Creates Task Vectors](https://doi.org/10.18653/v1/2023.findings-emnlp.624) |  | 0 | In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm. However, its underlying mechanism is still not well understood. In particular, it is challenging to map it to the “standard’ machine learning framework, where one uses a training set S to find a best-fitting function f(x) in some hypothesis class. Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query x and a single “task vector’ calculated from the training set. Thus, ICL can be seen as compressing S into a single task vector 𝜃(S) and then using this task vector to modulate the transformer to produce the output. We support the above claim via comprehensive experiments across a range of models and tasks. | Roee Hendel, Mor Geva, Amir Globerson |  |
| 758 |  |  [TalkUp: Paving the Way for Understanding Empowering Language](https://doi.org/10.18653/v1/2023.findings-emnlp.625) |  | 0 | Empowering language is important in many real-world contexts, from education to workplace dynamics to healthcare. Though language technologies are growing more prevalent in these contexts, empowerment has seldom been studied in NLP, and moreover, it is inherently challenging to operationalize because of its implicit nature. This work builds from linguistic and social psychology literature to explore what characterizes empowering language. We then crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers. Our preliminary analyses show that this dataset, which we call TalkUp, can be used to train language models that capture empowering and disempowering language. More broadly, TalkUp provides an avenue to explore implication, presuppositions, and how social context influences the meaning of language. | Lucille Njoo, Chan Young Park, Octavia Stappart, Marvin Thielk, Yi Chu, Yulia Tsvetkov |  |
| 759 |  |  [Unifying Text, Tables, and Images for Multimodal Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.626) |  | 0 | Multimodal question answering (MMQA), which aims to derive the answer from multiple knowledge modalities (e.g., text, tables, and images), has received increasing attention due to its board applications. Current approaches to MMQA often rely on single-modal or bi-modal QA models, which limits their ability to effectively integrate information across all modalities and leverage the power of pre-trained language models. To address these limitations, we propose a novel framework called UniMMQA, which unifies three different input modalities into a text-to-text format by employing position-enhanced table linearization and diversified image captioning techniques. Additionally, we enhance cross-modal reasoning by incorporating a multimodal rationale generator, which produces textual descriptions of cross-modal relations for adaptation into the text-to-text generation process. Experimental results on three MMQA benchmark datasets show the superiority of UniMMQA in both supervised and unsupervised settings. | Haohao Luo, Ying Shen, Yang Deng |  |
| 760 |  |  [Unsupervised Lexical Simplification with Context Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.627) |  | 0 | We propose a new unsupervised lexical simplification method that uses only monolingual data and pre-trained language models. Given a target word and its context, our method generates substitutes based on the target context and also additional contexts sampled from monolingual data. We conduct experiments in English, Portuguese, and Spanish on the TSAR-2022 shared task, and show that our model substantially outperforms other unsupervised systems across all languages. We also establish a new state-of-the-art by ensembling our model with GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution data set, achieving a state-of-the-art result. | Takashi Wada, Timothy Baldwin, Jey Han Lau |  |
| 761 |  |  [mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences](https://doi.org/10.18653/v1/2023.findings-emnlp.628) |  | 0 | We present our work on developing a multilingual, efficient text-to-text transformer that is suitable for handling long inputs. This model, called mLongT5, builds upon the architecture of LongT5, while leveraging the multilingual datasets used for pretraining mT5 and the pretraining tasks of UL2. We evaluate this model on a variety of multilingual summarization and question-answering tasks, and the results show stronger performance for mLongT5 when compared to existing multilingual models such as mBART or M-BERT. | David C. Uthus, Santiago Ontañón, Joshua Ainslie, Mandy Guo |  |
| 762 |  |  [Multilingual Lottery Tickets to Pretrain Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.629) |  | 0 | The curse of multilinguality in training multilingual pretrained language models (mPLMs) refers to the negative interference between languages, especially when the capacity is limited. While increasing the capacity may appear intuitive for overcoming this curse, it negatively affects both training and inference costs. Our distinction is pursuing the competing goals of reducing negative interference, while keeping capacity per each language more or less the same. Specifically, we first scale the model to reduce interference, then search for a per-language subnetwork, or a lottery ticket, with comparable performance to the full model. According to lottery ticket hypothesis, this scale-then-find-ticket approach alleviates interfering signals as in the scaled model, but redistributes parameters to keep the parameters reduced. Finally, to avoid the cost of multiple retraining for searching multilingual tickets, we explore zero-shot neural architecture search (NAS) methods. We investigate the most appropriate zero-shot NAS method to find multilingual tickets. Our proposed multilingual tickets reduce the inference cost of models for each languages, while boosting the performances. The ticket search cost is negligible and tickets found qualitatively preserve linguistic similarity. Our code is publicly available. | Jaeseong Lee, Seungwon Hwang |  |
| 763 |  |  [Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios](https://doi.org/10.18653/v1/2023.findings-emnlp.630) |  | 0 | Audio-visual question answering (AVQA) is a challenging task that requires multistep spatio-temporal reasoning over multimodal contexts. Recent works rely on elaborate target-agnostic parsing of audio-visual scenes for spatial grounding while mistreating audio and video as separate entities for temporal grounding. This paper proposes a new target-aware joint spatio-temporal grounding network for AVQA. It consists of two key components: the target-aware spatial grounding module (TSG) and the single-stream joint audio-visual temporal grounding module (JTG). The TSG can focus on audio-visual cues relevant to the query subject by utilizing explicit semantics from the question. Unlike previous two-stream temporal grounding modules that required an additional audio-visual fusion module, JTG incorporates audio-visual fusion and question-aware temporal grounding into one module with a simpler single-stream architecture. The temporal synchronization between audio and video in the JTG is facilitated by our proposed cross-modal synchrony loss (CSL). Extensive experiments verified the effectiveness of our proposed method over existing state-of-the-art methods. | Yuanyuan Jiang, Jianqin Yin |  |
| 764 |  |  [KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.631) |  | 0 | While large language models (LLMs) have made considerable advancements in understanding and generating unstructured text, their application in structured data remains underexplored. Particularly, using LLMs for complex reasoning tasks on knowledge graphs (KGs) remains largely untouched. To address this, we propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and Inference, each aimed at partitioning sentences, retrieving relevant graph components, and deriving logical conclusions, respectively. We evaluate KG-GPT using KG-based fact verification and KGQA benchmarks, with the model showing competitive and robust performance, even outperforming several fully-supervised models. Our work, therefore, marks a significant step in unifying structured and unstructured data processing within the realm of LLMs. | Jiho Kim, Yeonsu Kwon, Yohan Jo, Edward Choi |  |
| 765 |  |  [Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.632) |  | 0 | In this work, we study whether multilingual language models (MultiLMs) can transfer logical reasoning abilities to other languages when they are fine-tuned for reasoning in a different language. We evaluate the cross-lingual reasoning abilities of MultiLMs in two schemes: (1) where the language of the context and the question remain the same in the new languages that are tested (i.e., the reasoning is still monolingual, but the model must transfer the learned reasoning ability across languages), and (2) where the language of the context and the question is different (which we term code-switched reasoning). On two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate that although MultiLMs can transfer reasoning ability across languages in a monolingual setting, they struggle to transfer reasoning abilities in a code-switched setting. Following this observation, we propose a novel attention mechanism that uses a dedicated set of parameters to encourage cross-lingual attention in code-switched sequences, which improves the reasoning performance by up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively. | Negar Foroutan, Mohammadreza Banaei, Karl Aberer, Antoine Bosselut |  |
| 766 |  |  [CITB: A Benchmark for Continual Instruction Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.633) |  | 0 | Continual learning (CL) is a paradigm that aims to replicate the human ability to learn and accumulate knowledge continually without forgetting previous knowledge and transferring it to new tasks. Recent instruction tuning (IT) involves fine-tuning models to make them more adaptable to solving NLP tasks in general. However, it is still uncertain how instruction tuning works in the context of CL tasks. This challenging yet practical problem is formulated as Continual Instruction Tuning (CIT). In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types, InstrDialog and InstrDialog++, to study various CL methods systematically. Our experiments show that existing CL methods do not effectively leverage the rich natural language instructions, and fine-tuning an instruction-tuned model sequentially can yield similar or better results. We further explore different aspects that might affect the learning of CIT. We hope this benchmark will facilitate more research in this direction. | Zihan Zhang, Meng Fang, Ling Chen, MohammadReza NamaziRad |  |
| 767 |  |  [Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.634) |  | 0 | In this work, we propose a method that combines two popular research areas by injecting linguistic structures into pre-trained language models in the parameter-efficient fine-tuning (PEFT) setting. In our approach, parallel adapter modules encoding different linguistic structures are combined using a novel Mixture-of-Linguistic-Experts architecture, where Gumbel-Softmax gates are used to determine the importance of these modules at each layer of the model. To reduce the number of parameters, we first train the model for a fixed small number of steps before pruning the experts based on their important scores. Our experiment results with three different pre-trained models show that our approach can outperform state-of-the-art PEFT methods with a comparable number of parameters. In addition, we provide additional analysis to examine the experts selected by each model at each layer to provide insights for future studies. | Raymond Li, Gabriel Murray, Giuseppe Carenini |  |
| 768 |  |  [Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information](https://doi.org/10.18653/v1/2023.findings-emnlp.635) |  | 0 | Multi-label text classification (MLTC) aims to assign multiple labels to a given text. Previous works have focused on text representation learning and label correlations modeling using pre-trained language models (PLMs). However, studies have shown that PLMs generate word frequency-oriented text representations, causing texts with different labels to be closely distributed in a narrow region, which is difficult to classify. To address this, we present a novel framework CL( ̲Contrastive ̲Learning)-MIL ( ̲Multi-granularity ̲Information ̲Learning) to refine the text representation for MLTC task. We first use contrastive learning to generate uniform initial text representation and incorporate label frequency implicitly. Then, we design a multi-task learning module to integrate multi-granularity (diverse text-labels correlations, label-label relations and label frequency) information into text representations, enhancing their discriminative ability. Experimental results demonstrate the complementarity of the modules in CL-MIL, improving the quality of text representations and yielding stable and competitive improvements for MLTC. | Fangfang Li, Puzhen Su, Junwen Duan, Weidong Xiao |  |
| 769 |  |  [PCMID: Multi-Intent Detection through Supervised Prototypical Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.636) |  | 0 | Intent detection is a major task in Natural Language Understanding (NLU) and is the component of dialogue systems for interpreting users’ intentions based on their utterances. Many works have explored detecting intents by assuming that each utterance represents only a single intent. Such systems have achieved very good results; however, intent detection is a far more challenging task in typical real-world scenarios, where each user utterance can be highly complex and express multiple intents. Therefore, in this paper, we propose PCMID, a novel Multi-Intent Detection framework enabled by Prototypical Contrastive Learning under a supervised setting. The PCMID model can learn multiple semantic representations of a given user utterance under the context of different intent labels in an optimized semantic space. Our experiments show that PCMID achieves the current state-of-the-art performance on both multiple public benchmark datasets and a private real-world dataset for the multi-intent detection task. | Yurun Song, Junchen Zhao, Spencer Koehler, Amir Abdullah, Ian G. Harris |  |
| 770 |  |  [Is GPT-4 a Good Data Analyst?](https://doi.org/10.18653/v1/2023.findings-emnlp.637) |  | 0 | As large language models (LLMs) have demonstrated their powerful capabilities in plenty of domains and tasks, including context understanding, code generation, language generation, data storytelling, etc., many data analysts may raise concerns if their jobs will be replaced by artificial intelligence (AI). This controversial topic has drawn great attention in public. However, we are still at a stage of divergent opinions without any definitive conclusion. Motivated by this, we raise the research question of “is GPT-4 a good data analyst?” in this work and aim to answer it by conducting head-to-head comparative studies. In detail, we regard GPT-4 as a data analyst to perform end-to-end data analysis with databases from a wide range of domains. We propose a framework to tackle the problems by carefully designing the prompts for GPT-4 to conduct experiments. We also design several task-specific evaluation metrics to systematically compare the performance between several professional human data analysts and GPT-4. Experimental results show that GPT-4 can achieve comparable performance to humans. We also provide in-depth discussions about our results to shed light on further studies before reaching the conclusion that GPT-4 can replace data analysts. | Liying Cheng, Xingxuan Li, Lidong Bing |  |
| 771 |  |  [DiffusionRet: Diffusion-Enhanced Generative Retriever using Constrained Decoding](https://doi.org/10.18653/v1/2023.findings-emnlp.638) |  | 0 | Generative retrieval, which maps from a query to its relevant document identifiers (docids), has recently emerged as a new information retrieval (IR) paradigm, however, having suffered from 1) the lack of the intermediate reasoning step, caused by the manner of merely using a query to perform the hierarchical classification, and 2) the pretrain-finetune discrepancy, which comes from the use of the artificial symbols of docids. To address these limitations, we propose the novel approach of using the document generation from a query as an intermediate step before the retrieval, thus presenting ̲diffusion-enhanced generative ̲retrieval (DiffusionRet), which consists of two processing steps: 1) the diffusion-based document generation, which employs the sequence-to-sequence diffusion model to produce a pseudo document sample from a query, being expected to semantically close to a relevant document; 2) N-gram-based generative retrieval, which use another sequence-to-sequence model to generate n-grams that appear in the collection index for linking a generated sample to an original document. Experiment results on MS MARCO and Natural Questions dataset show that the proposed DiffusionRet significantly outperforms all the existing generative retrieval methods and leads to the state-of-the-art performances, even with much smaller number of parameters. | Shanbao Qiao, Xuebing Liu, SeungHoon Na |  |
| 772 |  |  [Estimating Large Language Model Capabilities without Labeled Test Data](https://doi.org/10.18653/v1/2023.findings-emnlp.639) |  | 0 | Large Language Models (LLMs) have exhibited an impressive ability to perform in-context learning (ICL) from only a few examples, but the success of ICL varies widely from task to task. Thus, it is important to quickly determine whether ICL is applicable to a new task, but directly evaluating ICL accuracy can be expensive in situations where test data is expensive to annotate—the exact situations where ICL is most appealing. In this paper, we propose the task of ICL accuracy estimation, in which we predict the accuracy of an LLM when doing in-context learning on a new task given only unlabeled test data for that task. To perform ICL accuracy estimation, we propose a method that trains a meta-model using LLM confidence scores as features. We compare our method to several strong accuracy estimation baselines on a new benchmark that covers 4 LLMs and 3 task collections. The meta-model improves over all baselines across 7 out of 12 settings and achieves the same estimation performance as directly evaluating on 40 collected labeled test examples per task. At the same time, no existing approach provides an accurate and reliable ICL accuracy estimation in every setting, highlighting the need for better ways to measure the uncertainty of LLM predictions. | Harvey Yiyun Fu, Qinyuan Ye, Albert Xu, Xiang Ren, Robin Jia |  |
| 773 |  |  [A Novel Contrastive Learning Method for Clickbait Detection on RoCliCo: A Romanian Clickbait Corpus of News Articles](https://doi.org/10.18653/v1/2023.findings-emnlp.640) |  | 0 | To increase revenue, news websites often resort to using deceptive news titles, luring users into clicking on the title and reading the full news. Clickbait detection is the task that aims to automatically detect this form of false advertisement and avoid wasting the precious time of online users. Despite the importance of the task, to the best of our knowledge, there is no publicly available clickbait corpus for the Romanian language. To this end, we introduce a novel Romanian Clickbait Corpus (RoCliCo) comprising 8,313 news samples which are manually annotated with clickbait and non-clickbait labels. Furthermore, we conduct experiments with four machine learning methods, ranging from handcrafted models to recurrent and transformer-based neural networks, to establish a line-up of competitive baselines. We also carry out experiments with a weighted voting ensemble. Among the considered baselines, we propose a novel BERT-based contrastive learning model that learns to encode news titles and contents into a deep metric space such that titles and contents of non-clickbait news have high cosine similarity, while titles and contents of clickbait news have low cosine similarity. Our data set and code to reproduce the baselines are publicly available for download at https://github.com/dariabroscoteanu/RoCliCo. | DariaMihaela Broscoteanu, Radu Tudor Ionescu |  |
| 774 |  |  [Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues](https://doi.org/10.18653/v1/2023.findings-emnlp.641) |  | 0 | Open-domain dialogue system usually requires different sources of knowledge to generate more informative and evidential responses. However, existing knowledge-grounded dialogue systems either focus on a single knowledge source or overlook the dependency between multiple sources of knowledge, which may result in generating inconsistent or even paradoxical responses. To incorporate multiple knowledge sources and dependencies between them, we propose SAFARI, a novel framework that leverages the exceptional capabilities of large language models (LLMs) in planning, understanding, and incorporating under both supervised and unsupervised settings. Specifically, SAFARI decouples the knowledge grounding into multiple sources and response generation, which allows easy extension to various knowledge sources including the possibility of not using any sources. To study the problem, we construct a personalized knowledge-grounded dialogue dataset Knowledge Behind Persona (KBP), which is the first to consider the dependency between persona and implicit knowledge. Experimental results on the KBP dataset demonstrate that the SAFARI framework can effectively produce persona-consistent and knowledge-enhanced responses. | Hongru Wang, Minda Hu, Yang Deng, Rui Wang, Fei Mi, Weichao Wang, Yasheng Wang, WaiChung Kwan, Irwin King, KamFai Wong |  |
| 775 |  |  [Toxicity in Multilingual Machine Translation at Scale](https://doi.org/10.18653/v1/2023.findings-emnlp.642) |  | 0 | Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpret what causes toxicity. Making use of the input attributions allows us to explain toxicity, because the source contributions significantly correlate with toxicity for 84% of languages studied. Given our findings, our recommendations to reduce added toxicity are to curate training data to avoid mistranslations, mitigate hallucination and check unstable translations. | Marta R. Costajussà, Eric Michael Smith, Christophe Ropers, Daniel Licht, Jean Maillard, Javier Ferrando, Carlos Escolano |  |
| 776 |  |  [Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue](https://doi.org/10.18653/v1/2023.findings-emnlp.643) |  | 0 | E-commerce pre-sales dialogue aims to understand and elicit user needs and preferences for the items they are seeking so as to provide appropriate recommendations. Conversational recommender systems (CRSs) learn user representation and provide accurate recommendations based on dialogue context, but rely on external knowledge. Large language models (LLMs) generate responses that mimic pre-sales dialogues after fine-tuning, but lack domain-specific knowledge for accurate recommendations. Intuitively, the strengths of LLM and CRS in E-commerce pre-sales dialogues are complementary, yet no previous work has explored this. This paper investigates the effectiveness of combining LLM and CRS in E-commerce pre-sales dialogues, proposing two collaboration methods: CRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a real-world dataset of E-commerce pre-sales dialogues. We analyze the impact of two collaborative approaches with two CRSs and two LLMs on four tasks of E-commerce pre-sales dialogue. We find that collaborations between CRS and LLM can be very effective in some cases. | Yuanxing Liu, Weinan Zhang, Yifan Chen, Yuchi Zhang, Haopeng Bai, Fan Feng, Hengbin Cui, Yongbin Li, Wanxiang Che |  |
| 777 |  |  [VIP5: Towards Multimodal Foundation Models for Recommendation](https://doi.org/10.18653/v1/2023.findings-emnlp.644) |  | 0 | Computer Vision (CV), Natural Language Processing (NLP), and Recommender Systems (RecSys) are three prominent AI applications that have traditionally developed independently, resulting in disparate modeling and engineering methodologies. This has impeded the ability for these fields to directly benefit from each other’s advancements. With the recent development of foundation models, large language models have emerged as a potential general-purpose interface for unifying different modalities and problem formulations. In light of this, we propose the development of a multimodal foundation model (MFM) considering visual, textual, and personalization modalities under the P5 recommendation paradigm, thus named VIP5 (Visual P5), to unify various modalities and recommendation tasks. This will enable the processing of multiple modalities in a shared architecture for improved recommendations. To achieve this, we introduce multimodal personalized prompts to accommodate multiple modalities under a shared format. Additionally, we propose a parameter-efficient training method for foundation models, which involves freezing the P5 backbone and fine-tuning lightweight adapters, resulting in improved recommendation performance and increased efficiency in terms of training time and memory usage. Code and data of VIP5 are available at https://github.com/jeykigung/VIP5. | Shijie Geng, Juntao Tan, Shuchang Liu, Zuohui Fu, Yongfeng Zhang |  |
| 778 |  |  [A Spectral Viewpoint on Continual Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.645) |  | 0 | Continual Relation Extraction (CRE) aims to continuously train a model to learn new relations while preserving its ability on previously learned relations. Similar to other continual learning problems, in CRE, models experience representation shift, where learned deep space changes in the continual learning process, which leads to the downgrade in the performance of the old tasks. In this work, we will provide an insight into this phenomenon under the spectral viewpoint. Our key argument is that, for each class shape, if its eigenvectors (or spectral components) do not change much, the shape is well-preserved. We then conduct a spectral experiment and show that, for the shape of each class, the eigenvectors with larger eigenvalue are more preserved after learning new tasks which means these vectors are good at keeping class shapes. Based on this analysis, we propose a simple yet effective class-wise regularization that improve the eigenvalues in the representation learning. We observe that our proposed regularization leads to an increase in the eigenvalues. Extensive experiments on two benchmark datasets, FewRel and TACRED, show the effectiveness of our proposed method with significant improvement in performance compared to the state-of-the-art models. Further analyses also verify our hypothesis that larger eigenvalues lead to better performance and vice versa. | Huy Nguyen, Chien Nguyen, Linh Ngo Van, Anh Tuan Luu, Thien Huu Nguyen |  |
| 779 |  |  [Learning to Follow Object-Centric Image Editing Instructions Faithfully](https://doi.org/10.18653/v1/2023.findings-emnlp.646) |  | 0 | Natural language instructions are a powerful interface for editing the outputs of text-to-image diffusion models. However, several challenges need to be addressed: 1) underspecification (the need to model the implicit meaning of instructions) 2) grounding (the need to localize where the edit has to be performed), 3) faithfulness (the need to preserve the elements of the image not affected by the edit instruction). Current approaches focusing on image editing with natural language instructions rely on automatically generated paired data, which, as shown in our investigation, is noisy and sometimes nonsensical, exacerbating the above issues. Building on recent advances in segmentation, Chain-of-Thought prompting, and visual question answering, we significantly improve the quality of the paired data. In addition, we enhance the supervision signal by highlighting parts of the image that need to be changed by the instruction. The model fine-tuned on the improved data is capable of performing fine-grained object-centric edits better than state-of-the-art baselines, mitigating the problems outlined above, as shown by automatic and human evaluations. Moreover, our model is capable of generalizing to domains unseen during training, such as visual metaphors. | Tuhin Chakrabarty, Kanishk Singh, Arkadiy Saakyan, Smaranda Muresan |  |
| 780 |  |  [Zero-shot Topical Text Classification with LLMs - an Experimental Study](https://doi.org/10.18653/v1/2023.findings-emnlp.647) |  | 0 | Topical Text Classification (TTC) is an ancient, yet timely research area in natural language processing, with many practical applications. The recent dramatic advancements in large LMs raise the question of how well these models can perform in this task in a zero-shot scenario. Here, we share a first comprehensive study, comparing the zero-shot performance of a variety of LMs over TTC23, a large benchmark collection of 23 publicly available TTC datasets, covering a wide range of domains and styles. In addition, we leverage this new TTC benchmark to create LMs that are specialized in TTC, by fine-tuning these LMs over a subset of the datasets and evaluating their performance over the remaining, held-out datasets. We show that the TTC-specialized LMs obtain the top performance on our benchmark, by a significant margin. Our code and model are made available for the community. We hope that the results presented in this work will serve as a useful guide for practitioners interested in topical text classification. | Shai Gretz, Alon Halfon, Ilya Shnayderman, Orith ToledoRonen, Artem Spector, Lena Dankin, Yannis Katsis, Ofir Arviv, Yoav Katz, Noam Slonim, Liat EinDor |  |
| 781 |  |  [Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems](https://doi.org/10.18653/v1/2023.findings-emnlp.648) |  | 0 | Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. We define generic personas to represent demographic groups, such as “an Asian person”, whereas specific personas may take the form of specific popular Asian names like “Yumi”. While the adoption of personas enriches user experiences by making dialogue systems more engaging and approachable, it also casts a shadow of potential risk by exacerbating social biases within model responses, thereby causing societal harm through interactions with users. In this paper, we systematically study “persona biases”, which we define to be the sensitivity of dialogue models’ harmful behaviors contingent upon the personas they adopt. We categorize persona biases into biases in harmful expression and harmful agreement, and establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to investigate persona biases by experimenting with UNIVERSALPERSONA, a systematically constructed persona dataset encompassing various types of both generic and specific model personas. Through benchmarking on four different models- including Blender, ChatGPT, Alpaca, and Vicuna- our study uncovers significant persona biases in dialogue systems. Our findings also underscore the pressing need to revisit the use of personas in dialogue agents to ensure safe application. | Yixin Wan, Jieyu Zhao, Aman Chadha, Nanyun Peng, KaiWei Chang |  |
| 782 |  |  [A Black-Box Attack on Code Models via Representation Nearest Neighbor Search](https://doi.org/10.18653/v1/2023.findings-emnlp.649) |  | 0 | Existing methods for generating adversarial code examples face several challenges: limted availability of substitute variables, high verification costs for these substitutes, and the creation of adversarial samples with noticeable perturbations. To address these concerns, our proposed approach, RNNS, uses a search seed based on historical attacks to find potential adversarial substitutes. Rather than directly using the discrete substitutes, they are mapped to a continuous vector space using a pre-trained variable name encoder. Based on the vector representation, RNNS predicts and selects better substitutes for attacks. We evaluated the performance of RNNS across six coding tasks encompassing three programming languages: Java, Python, and C. We employed three pre-trained code models (CodeBERT, GraphCodeBERT, and CodeT5) that resulted in a cumulative of 18 victim models. The results demonstrate that RNNS outperforms baselines in terms of ASR and QT. Furthermore, the perturbation of adversarial examples introduced by RNNS is smaller compared to the baselines in terms of the number of replaced variables and the change in variable length. Lastly, our experiments indicate that RNNS is efficient in attacking defended models and can be employed for adversarial training. | Jie Zhang, Wei Ma, Qiang Hu, Shangqing Liu, Xiaofei Xie, Yves Le Traon, Yang Liu |  |
| 783 |  |  [How Well Do Text Embedding Models Understand Syntax?](https://doi.org/10.18653/v1/2023.findings-emnlp.650) |  | 0 | Text embedding models have significantly contributed to advancements in natural language processing by adeptly capturing semantic properties of textual data. However, the ability of these models to generalize across a wide range of syntactic contexts remains under-explored. In this paper, we first develop an evaluation set, named SR, to scrutinize the capability for syntax understanding of text embedding models from two crucial syntactic aspects: Structural heuristics, and Relational understanding among concepts, as revealed by the performance gaps in previous studies. Our findings reveal that existing text embedding models have not sufficiently addressed these syntactic understanding challenges, and such ineffectiveness becomes even more apparent when evaluated against existing benchmark datasets. Furthermore, we conduct rigorous analysis to unearth factors that lead to such limitations and examine why previous evaluations fail to detect such ineffectiveness. Lastly, we propose strategies to augment the generalization ability of text embedding models in diverse syntactic scenarios. This study serves to highlight the hurdles associated with syntactic generalization and provides pragmatic guidance for boosting model performance across varied syntactic contexts. | Yan Zhang, Zhaopeng Feng, Zhiyang Teng, Zuozhu Liu, Haizhou Li |  |
| 784 |  |  [CASSI: Contextual and Semantic Structure-based Interpolation Augmentation for Low-Resource NER](https://doi.org/10.18653/v1/2023.findings-emnlp.651) |  | 0 | While text augmentation methods have been successful in improving performance in the low-resource setting, they suffer from annotation corruption for a token-level task like NER. Moreover, existing methods cannot reliably add context diversity to the dataset, which has been shown to be crucial for low-resource NER. In this work, we propose Contextual and Semantic Structure-based Interpolation (CASSI), a novel augmentation scheme that generates high-quality contextually diverse augmentations while avoiding annotation corruption by structurally combining a pair of semantically similar sentences to generate a new sentence while maintaining semantic correctness and fluency. To accomplish this, we generate candidate augmentations by performing multiple dependency parsing-based exchanges in a pair of semantically similar sentences that are filtered via scoring with a pretrained Masked Language Model and a metric to promote specificity. Experiments show that CASSI consistently outperforms existing methods at multiple low resource levels, in multiple languages, and for noisy and clean text. | Tanmay Surana, ThiNga Ho, Kyaw Zin Tun, Eng Siong Chng |  |
| 785 |  |  [NEWTON: Are Large Language Models Capable of Physical Reasoning?](https://doi.org/10.18653/v1/2023.findings-emnlp.652) |  | 0 | Large Language Models (LLMs), through their contextualized representations, have been empirically proven to encapsulate syntactic, semantic, word sense, and common-sense knowledge. However, there has been limited exploration of their physical reasoning abilities, specifically concerning the crucial attributes for comprehending everyday objects. To address this gap, we introduce NEWTON, a repository and benchmark for evaluating the physics reasoning skills of LLMs. Further, to enable domain-specific adaptation of this benchmark, we present a pipeline to enable researchers to generate a variant of this benchmark that has been customized to the objects and attributes relevant for their application. The NEWTON repository comprises a collection of 2800 object-attribute pairs, providing the foundation for generating infinite-scale assessment templates. The NEWTON benchmark consists of 160K QA questions, curated using the NEWTON repository to investigate the physical reasoning capabilities of several mainstream language models across foundational, explicit, and implicit reasoning tasks. Through extensive empirical analysis, our results highlight the capabilities of LLMs for physical reasoning. We find that LLMs like GPT-4 demonstrate strong reasoning capabilities in scenario-based tasks but exhibit less consistency in object-attribute reasoning compared to humans (50% vs. 84%). Furthermore, the NEWTON platform demonstrates its potential for evaluating and enhancing language models, paving the way for their integration into physically grounded settings, such as robotic manipulation. Project site: https://newtonreasoning.github.io | Yi Ru Wang, Jiafei Duan, Dieter Fox, Siddhartha S. Srinivasa |  |
| 786 |  |  [Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language](https://doi.org/10.18653/v1/2023.findings-emnlp.653) |  | 0 | Counterspeech, i.e., responses to counteract potential harms of hateful speech, has become an increasingly popular solution to address online hate speech without censorship. However, properly countering hateful language requires countering and dispelling the underlying inaccurate stereotypes implied by such language. In this work, we draw from psychology and philosophy literature to craft six psychologically inspired strategies to challenge the underlying stereotypical implications of hateful language. We first examine the convincingness of each of these strategies through a user study, and then compare their usages in both human- and machine-generated counterspeech datasets. Our results show that human-written counterspeech uses countering strategies that are more specific to the implied stereotype (e.g., counter examples to the stereotype, external factors about the stereotype’s origins), whereas machine-generated counterspeech uses less specific strategies (e.g., generally denouncing the hatefulness of speech). Furthermore, machine generated counterspeech often employs strategies that humans deem less convincing compared to human-produced counterspeech. Our findings point to the importance of accounting for the underlying stereotypical implications of speech when generating counterspeech and for better machine reasoning about anti-stereotypical examples. | Jimin Mun, Emily Allaway, Akhila Yerukola, Laura Vianna, SarahJane Leslie, Maarten Sap |  |
| 787 |  |  [On the Calibration of Large Language Models and Alignment](https://doi.org/10.18653/v1/2023.findings-emnlp.654) |  | 0 | As large language models attract increasing attention and find widespread application, concurrent challenges of reliability also arise at the same time. Confidence calibration, an effective analysis method for gauging the reliability of deep models, serves as a crucial tool for assessing and improving their reliability. However, such investigation has been comparatively underexplored. In this work, we conduct a systematic examination of the calibration of aligned language models throughout the entire construction process, including pretraining and alignment training. At each stage, we investigate how different training settings, such as parameter scales and training data, affect model calibration. To thoroughly assess model calibration, we evaluate models on three most concerned aspects: generation, factuality and understanding. Our work sheds light on whether popular LLMs are well-calibrated and how the training process influences model calibration. | Chiwei Zhu, Benfeng Xu, Quan Wang, Yongdong Zhang, Zhendong Mao |  |
| 788 |  |  [TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction](https://doi.org/10.18653/v1/2023.findings-emnlp.655) |  | 0 | Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed methods, we propose and utilize a dataset called Food-Recommendation DB (FRDB) focusing on food recommendation for women around pregnancy period or infants. Our summarization compression can reduce 65% of the retrieval token size with further 0.3% improvement on the accuracy; semantic compression provides a more flexible way to trade-off the token size with performance, for which we can reduce the token size by 20% with only 1.6% of accuracy drop. | Junyi Liu, Liangzhi Li, Tong Xiang, Bowen Wang, Yiming Qian |  |
| 789 |  |  [Identifying Conspiracy Theories News based on Event Relation Graph](https://doi.org/10.18653/v1/2023.findings-emnlp.656) |  | 0 | Conspiracy theories, as a type of misinformation, are narratives that explains an event or situation in an irrational or malicious manner. While most previous work examined conspiracy theory in social media short texts, limited attention was put on such misinformation in long news documents. In this paper, we aim to identify whether a news article contains conspiracy theories. We observe that a conspiracy story can be made up by mixing uncorrelated events together, or by presenting an unusual distribution of relations between events. Achieving a contextualized understanding of events in a story is essential for detecting conspiracy theories. Thus, we propose to incorporate an event relation graph for each article, in which events are nodes, and four common types of event relations, coreference, temporal, causal, and subevent relations, are considered as edges. Then, we integrate the event relation graph into conspiracy theory identification in two ways: an event-aware language model is developed to augment the basic language model with the knowledge of events and event relations via soft labels; further, a heterogeneous graph attention network is designed to derive a graph embedding based on hard labels. Experiments on a large benchmark dataset show that our approach based on event relation graph improves both precision and recall of conspiracy theory identification, and generalizes well for new unseen media sources. | Yuanyuan Lei, Ruihong Huang |  |
| 790 |  |  [Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems](https://doi.org/10.18653/v1/2023.findings-emnlp.657) |  | 0 | Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users’ lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in providing truthful information, highlighting the challenges of ensuring faithfulness in the CRS context. We release our code and make all data available. | Lidiya Murakhovs'ka, Philippe Laban, Tian Xie, Caiming Xiong, ChienSheng Wu |  |
| 791 |  |  [Dynamic Open-book Prompt for Conversational Recommender System](https://doi.org/10.18653/v1/2023.findings-emnlp.658) |  | 0 | Conversational Recommender System (CRS) aims to deliver personalized recommendations through interactive dialogues. Recent advances in prompt learning have shed light on this task. However, the performance of existing methods is confined by the limited context within ongoing conversations. Moreover, these methods utilize training samples only for prompt parameter training. The constructed prompt lacks the ability to refer to the training data during inference, which exacerbates the problem of limited context. To solve this problem, we propose a novel Dynamic Open-book Prompt approach, where the open book stores users’ experiences in historical data, and we dynamically construct the prompt to memorize the user’s current utterance and selectively retrieve relevant contexts from the open book. Specifically, we first build an item-recommendation graph from the open book and convolute on the graph to form a base prompt which contains more information besides the finite dialogue. Then, we enhance the representation learning process of the prompt by tailoring similar contexts in the graph into the prompt to meet the user’s current need. This ensures the prompt provides targeted suggestions that are both informed and contextually relevant. Extensive experimental results on the ReDial dataset demonstrate the significant improvements achieved by our proposed model over the state-of-the-art methods. Our code and data are available at https://github.com/NLPWM-WHU/DOP. | Xuan Ma, Tieyun Qian, Ke Sun |  |
| 792 |  |  [Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.659) |  | 0 | Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process. | Zhihan Zhang, Shuohang Wang, Wenhao Yu, Yichong Xu, Dan Iter, Qingkai Zeng, Yang Liu, Chenguang Zhu, Meng Jiang |  |
| 793 |  |  [DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models](https://doi.org/10.18653/v1/2023.findings-emnlp.660) |  | 0 | Diffusion models have gained prominence in generating high-quality sequences of text. Nevertheless, current approaches predominantly represent discrete text within a continuous diffusion space, which incurs substantial computational overhead during training and results in slower sampling speeds. In this paper, we introduce a soft absorbing state that facilitates the diffusion model in learning to reconstruct discrete mutations based on the underlying Gaussian space, thereby enhancing its capacity to recover conditional signals. During the sampling phase, we employ state-of-the-art ODE solvers within the continuous space to expedite the sampling process. Comprehensive experimental evaluations reveal that our proposed method effectively accelerates the training convergence by 4x and generates samples of similar quality 800x faster, rendering it significantly closer to practical application. | Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, Lingpeng Kong |  |
| 794 |  |  [M2C: Towards Automatic Multimodal Manga Complement](https://doi.org/10.18653/v1/2023.findings-emnlp.661) |  | 0 | Multimodal manga analysis focuses on enhancing manga understanding with visual and textual features, which has attracted considerable attention from both natural language processing and computer vision communities. Currently, most comics are hand-drawn and prone to problems such as missing pages, text contamination, and text aging, resulting in missing comic text content and seriously hindering human comprehension. In other words, the Multimodal Manga Complement (M2C) task has not been investigated, which aims to handle the aforementioned issues by providing a shared semantic space for vision and language understanding. To this end, we first propose the Multimodal Manga Complement task by establishing a new M2C benchmark dataset covering two languages. First, we design a manga argumentation method called MCoT to mine event knowledge in comics with large language models. Then, an effective baseline FVP-M2 using fine-grained visual prompts is proposed to support manga complement. Extensive experimental results show the effectiveness of FVP-M2 method for Multimodal Mange Complement. | Hongcheng Guo, Boyang Wang, Jiaqi Bai, Jiaheng Liu, Jian Yang, Zhoujun Li |  |
| 795 |  |  [Learn Your Tokens: Word-Pooled Tokenization for Language Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.662) |  | 0 | Language models typically tokenize text into subwords, using a deterministic, hand-engineered heuristic of combining characters into longer surface-level strings such as ‘ing’ or whole words. Recent literature has repeatedly shown the limitations of such a tokenization strategy, particularly for documents not written in English and for representing numbers. On the other extreme, byte/character-level language models are much less restricted but suffer from increased sequence description lengths and a subsequent quadratic expansion in self-attention computation. Recent attempts to compress and limit these context lengths with fixed size convolutions is helpful but completely ignores the word boundary. This paper considers an alternative ‘learn your tokens’ scheme which utilizes the word boundary to pool bytes/characters into word representations, which are fed to the primary language model, before again decoding individual characters/bytes per word in parallel. We find that our moderately expressive and moderately fast end-to-end tokenizer outperform by over ‘300%‘ both subwords and byte/character models over the intrinsic language modeling metric of next-word prediction across datasets. It particularly outshines on rare words, outperforming by a factor of 30! We extensively study the language modeling setup for all three categories of tokenizers and theoretically analyze how our end-to-end models can also be a strong trade-off in efficiency and robustness. | Avijit Thawani, Saurabh Ghanekar, Xiaoyuan Zhu, Jay Pujara |  |
| 796 |  |  [Towards Detecting Contextual Real-Time Toxicity for In-Game Chat](https://doi.org/10.18653/v1/2023.findings-emnlp.663) |  | 0 | Real-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster’s transferability across the datasets. Furthermore, we showcase ToxBuster’s efficacy in post-game moderation, successfully flagging 82.1% of chat-reported players at a precision level of 90.0%. Additionally, we show how an additional 6% of unreported toxic players can be proactively moderated. | Zachary Yang, Nicolas GrenonGodbout, Reihaneh Rabbany |  |
| 797 |  |  [JWSign: A Highly Multilingual Corpus of Bible Translations for more Diversity in Sign Language Processing](https://doi.org/10.18653/v1/2023.findings-emnlp.664) |  | 0 | Advancements in sign language processing have been hindered by a lack of sufficient data, impeding progress in recognition, translation, and production tasks. The absence of comprehensive sign language datasets across the world’s sign languages has widened the gap in this field, resulting in a few sign languages being studied more than others, making this research area extremely skewed mostly towards sign languages from high-income countries. In this work we introduce a new large and highly multilingual dataset for sign language translation: JWSign. The dataset consists of 2,530 hours of Bible translations in 98 sign languages, featuring more than 1,500 individual signers. On this dataset, we report neural machine translation experiments. Apart from bilingual baseline systems, we also train multilingual systems, including some that take into account the typological relatedness of signed or spoken languages. Our experiments highlight that multilingual systems are superior to bilingual baselines, and that in higher-resource scenarios, clustering language pairs that are related improves translation quality. | Shester Gueuwou, Sophie Siake, Colin Leong, Mathias Müller |  |
| 798 |  |  [Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.665) |  | 0 | Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth | Alan Cowap, Yvette Graham, Jennifer Foster |  |
| 799 |  |  [Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules](https://doi.org/10.18653/v1/2023.findings-emnlp.666) |  | 0 | Large language models (LLMs) have achieved remarkable results on NLP tasks but at the expense of huge parameter sizes and the consequent computational costs. In this paper, we propose Variator, a parameter-efficient acceleration method that enhances computational efficiency through plug-and-play compression plugins. Compression plugins are designed to reduce the sequence length via compressing multiple hidden vectors into one and trained with original LLMs frozen. Different from traditional model acceleration methods, which compress LLMs to smaller sizes, Variator offers two distinct advantages: (1) In real-world applications, the plug-and-play nature of our compression plugins enables dynamic selection of different compression plugins with varying acceleration ratios based on the current workload. (2) The compression plugin comprises a few compact neural network layers with minimal parameters, significantly saving storage and memory overhead, particularly in scenarios with a growing number of tasks. We validate the effectiveness of Variator on seven datasets. Experimental results show that Variator can save 53% computational costs using only 0.9% additional parameters with a performance drop of less than 2%. Moreover, when the model scales to billions of parameters, Variator matches the strong performance of uncompressed LLMs. Our code and checkpoints will be released to facilitate future work. | Chaojun Xiao, Yuqi Luo, Wenbin Zhang, Pengle Zhang, Xu Han, Yankai Lin, Zhengyan Zhang, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou |  |
| 800 |  |  [PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.667) |  | 0 | Factual Error Correction (FEC) aims to rectify false claims by making minimal revisions to align them more accurately with supporting evidence. However, the lack of datasets containing false claims and their corresponding corrections has impeded progress in this field. Existing distantly supervised models typically employ the mask-then-correct paradigm, where a masker identifies problematic spans in false claims, followed by a corrector to predict the masked portions. Unfortunately, accurately identifying errors in claims is challenging, leading to issues like over-erasure and incorrect masking. To overcome these challenges, we present PivotFEC, a method that enhances few-shot FEC with a pivot task approach using large language models (LLMs). Specifically, we introduce a pivot task called factual error injection, which leverages LLMs (e.g., ChatGPT) to intentionally generate text containing factual errors under few-shot settings; then, the generated text with factual errors can be used to train the FEC corrector. Our experiments on a public dataset demonstrate the effectiveness of PivotFEC in two significant ways: Firstly, it improves the widely-adopted SARI metrics by 11.3 compared to the best-performing distantly supervised methods. Secondly, it outperforms its few-shot counterpart (i.e., LLMs are directly used to solve FEC) by 7.9 points in SARI, validating the efficacy of our proposed pivot task. | Xingwei He, ALong Jin, Jun Ma, Yuan Yuan, Siu Ming Yiu |  |
| 801 |  |  [Semantic Similarity Covariance Matrix Shrinkage](https://doi.org/10.18653/v1/2023.findings-emnlp.668) |  | 0 | An accurate estimation of the covariance matrix is a critical component of many applications in finance, including portfolio optimization. The sample covariance suffers from the curse of dimensionality when the number of observations is in the same order or lower than the number of variables. This tends to be the case in portfolio optimization, where a portfolio manager can choose between thousands of stocks using historical daily returns to guide their investment decisions. To address this issue, past works proposed linear covariance shrinkage to regularize the estimated matrix. While effective, the proposed methods relied solely on historical price data and thus ignored company fundamental data. In this work, we propose to utilise semantic similarity derived from textual descriptions or knowledge graphs to improve the covariance estimation. Rather than using the semantic similarity directly as a biased estimator to the covariance, we employ it as a shrinkage target. The resulting covariance estimators leverage both semantic similarity and recent price history, and can be readily adapted to a broad range of financial securities. The effectiveness of the approach is demonstrated for a period including diverse market conditions and compared with the covariance shrinkage prior art. | Guillaume Becquin, Saher Esmeir |  |
| 802 |  |  [LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.669) |  | 0 | Thematic analysis (TA) has been widely used for analyzing qualitative data in many disciplines and fields. To ensure reliable analysis, the same piece of data is typically assigned to at least two human coders. Moreover, to produce meaningful and useful analysis, human coders develop and deepen their data interpretation and coding over multiple iterations, making TA labor-intensive and time-consuming. Recently the emerging field of large language models (LLMs) research has shown that LLMs have the potential replicate human-like behavior in various tasks: in particular, LLMs outperform crowd workers on text-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We propose a human–LLM collaboration framework (i.e., LLM-in-the-loop) to conduct TA with in-context learning (ICL). This framework provides the prompt to frame discussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA. We demonstrate the utility of this framework using survey datasets on the aspects of the music listening experience and the usage of a password manager. Results of the two case studies show that the proposed framework yields similar coding quality to that of human coders but reduces TA’s labor and time demands. | ShihChieh Dai, Aiping Xiong, LunWei Ku |  |
| 803 |  |  [LLM aided semi-supervision for efficient Extractive Dialog Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.670) |  | 0 | Generating high-quality summaries for chat dialogs often requires large labeled datasets. We propose a method to efficiently use unlabeled data for extractive summarization of customer-agent dialogs. In our method, we frame summarization as a question-answering problem and use state-of-the-art large language models (LLMs) to generate pseudo-labels for a dialog. We then use these pseudo-labels to fine-tune a chat summarization model, effectively transferring knowledge from the large LLM into a smaller specialized model. We demonstrate our method on the TWEETSUMM dataset, and show that using 10% of the original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L, whereas the current state-of-the-art trained on the entire training data set obtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case (i.e., ROUGE-L) we still effectively retain 94.7% of the performance while using only 10% of the data. | Nishant Mishra, Gaurav Sahu, Iacer Calixto, Ameen AbuHanna, Issam H. Laradji |  |
| 804 |  |  [Investigating Multilingual Coreference Resolution by Universal Annotations](https://doi.org/10.18653/v1/2023.findings-emnlp.671) |  | 0 | Multilingual coreference resolution (MCR) has been a long-standing and challenging task. With the newly proposed multilingual coreference dataset, CorefUD (Nedoluzhko et al., 2022), we conduct an investigation into the task by using its harmonized universal morphosyntactic and coreference annotations. First, we study coreference by examining the ground truth data at different linguistic levels, namely mention, entity and document levels, and across different genres, to gain insights into the characteristics of coreference across multiple languages. Second, we perform an error analysis of the most challenging cases that the SotA system fails to resolve in the CRAC 2022 shared task using the universal annotations. Last, based on this analysis, we extract features from universal morphosyntactic annotations and integrate these features into a baseline system to assess their potential benefits for the MCR task. Our results show that our best configuration of features improves the baseline by 0.9% F1 score. | Haixia Chai, Michael Strube |  |
| 805 |  |  [FactSpotter: Evaluating the Factual Faithfulness of Graph-to-Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.672) |  | 0 | Graph-to-text (G2T) generation takes a graph as input and aims to generate a fluent and faith- ful textual representation of the information in the graph. The task has many applications, such as dialogue generation and question an- swering. In this work, we investigate to what extent the G2T generation problem is solved for previously studied datasets, and how pro- posed metrics perform when comparing generated texts. To help address their limitations, we propose a new metric that correctly identifies factual faithfulness, i.e., given a triple (subject, predicate, object), it decides if the triple is present in a generated text. We show that our metric FactSpotter achieves the highest correlation with human annotations on data correct- ness, data coverage, and relevance. In addition, FactSpotter can be used as a plug-in feature to improve the factual faithfulness of existing models. Finally, we investigate if existing G2T datasets are still challenging for state-of-the-art models. Our code is available online: https://github.com/guihuzhang/FactSpotter. | Kun Zhang, Oana Balalau, Ioana Manolescu |  |
| 806 |  |  [LayoutDIT: Layout-Aware End-to-End Document Image Translation with Multi-Step Conductive Decoder](https://doi.org/10.18653/v1/2023.findings-emnlp.673) |  | 0 | Document image translation (DIT) aims to translate text embedded in images from one language to another. It is a challenging task that needs to understand visual layout with text semantics simultaneously. However, existing methods struggle to capture the crucial visual layout in real-world complex document images. In this work, we make the first attempt to incorporate layout knowledge into DIT in an end-to-end way. Specifically, we propose a novel Layout-aware end-to-end Document Image Translation (LayoutDIT) with multi-step conductive decoder. A layout-aware encoder is first introduced to model visual layout relations with raw OCR results. Then a novel multi-step conductive decoder is unified with hidden states conduction across three step-decoders to achieve the document translation step by step. Benefiting from the layout-aware end-to-end joint training, our LayoutDIT outperforms state-of-the-art methods with better parameter efficiency. Besides, we create a new multi-domain document image translation dataset to validate the model’s generalization. Extensive experiments show that LayoutDIT has a good generalization in diverse and complex layout scenes. | Zhiyang Zhang, Yaping Zhang, Yupu Liang, Lu Xiang, Yang Zhao, Yu Zhou, Chengqing Zong |  |
| 807 |  |  [Balaur: Language Model Pretraining with Lexical Semantic Relations](https://doi.org/10.18653/v1/2023.findings-emnlp.674) |  | 0 | Lexical semantic relations (LSRs) characterize meaning relationships between words and play an important role in systematic generalization on lexical inference tasks. Notably, several tasks that require knowledge of hypernymy still pose a challenge for pretrained language models (LMs) such as BERT, underscoring the need to better align their linguistic behavior with our knowledge of LSRs. In this paper, we propose Balaur, a model that addresses this challenge by modeling LSRs directly in the LM’s hidden states throughout pretraining. Motivating our approach is the hypothesis that the internal representations of LMs can provide an interface to their observable linguistic behavior, and that by controlling one we can influence the other. We validate our hypothesis and demonstrate that Balaur generally improves the performance of large transformer-based LMs on a comprehensive set of hypernymy-informed tasks, as well as on the original LM objective. Code and data are made available at https://github.com/mirandrom/balaur | Andrei Mircea, Jackie C. K. Cheung |  |
| 808 |  |  [Exploring In-Context Learning for Knowledge Grounded Dialog Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.675) |  | 0 | Large neural-based dialog generation models have been applied in many real-life scenarios, yet they are prone to hallucination and tend to produce factually inaccurate outputs which raise great concerns. To alleviate this problem, we propose a plug-and-play retrieval-based framework IKA, which leverages in-context learning and retrieval techniques to enhance LLMs on knowledge grounded dialog generation. We design thorough experiments on a large-scale knowledge graph with 1M+ facts to investigate the effectiveness and generalization of our framework. Experiments show that our method surpasses previous training-based SOTA by a large margin, specifically 46.67% in BLEU4, 26.01% in ROUGE-L, 122.90% in BARTScore and 30.50% in Entity Coverage F1. Further analysis show promising abilities of LLMs to perform knowledge-intensive tasks, which is previously considered weak and understudied. | Qinyu Chen, Wenhao Wu, Sujian Li |  |
| 809 |  |  [Towards Enhancing Relational Rules for Knowledge Graph Link Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.676) |  | 0 | Graph neural networks (GNNs) have shown promising performance for knowledge graph reasoning. A recent variant of GNN called progressive relational graph neural network (PRGNN), utilizes relational rules to infer missing knowledge in relational digraphs and achieves notable results. However, during reasoning with PRGNN, two important properties are often overlooked: (1) the sequentiality of relation composition, where the order of combining different relations affects the semantics of the relational rules, and (2) the lagged entity information propagation, where the transmission speed of required information lags behind the appearance speed of new entities. Ignoring these properties leads to incorrect relational rule learning and decreased reasoning accuracy. To address these issues, we propose a novel knowledge graph reasoning approach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN). Specifically, RUN-GNN employs a query related fusion gate unit to model the sequentiality of relation composition and utilizes a buffering update mechanism to alleviate the negative effect of lagged entity information propagation, resulting in higher-quality relational rule learning. Experimental results on multiple datasets demonstrate the superiority of RUN-GNN is superior on both transductive and inductive link prediction tasks. | Shuhan Wu, Huaiyu Wan, Wei Chen, Yuting Wu, Junfeng Shen, Youfang Lin |  |
| 810 |  |  [Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.677) |  | 0 | Narrative understanding involves capturing the author’s cognitive processes, providing insights into their knowledge, intentions, beliefs, and desires. Although large language models (LLMs) excel in generating grammatically coherent text, their ability to comprehend the author’s thoughts remains uncertain. This limitation hinders the practical applications of narrative understanding. In this paper, we conduct a comprehensive survey of narrative understanding tasks, thoroughly examining their key features, definitions, taxonomy, associated datasets, training objectives, evaluation metrics, and limitations. Furthermore, we explore the potential of expanding the capabilities of modularized LLMs to address novel narrative understanding tasks. By framing narrative understanding as the retrieval of the author’s imaginative cues that outline the narrative structure, our study introduces a fresh perspective on enhancing narrative comprehension. | Lixing Zhu, Runcong Zhao, Lin Gui, Yulan He |  |
| 811 |  |  [Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.678) |  | 0 | Utterances do not occur in isolation in dialogues; it is essential to have the information of who the speaker of an utterance is to be able to recover the speaker’s intention with respect to the surrounding context. Beyond simply capturing speaker switches, identifying how speakers interact with each other in a dialogue is crucial to understanding conversational flow. This becomes increasingly important and simultaneously difficult to model when more than two interlocutors take part in a conversation. To overcome this challenge, we propose to explicitly add speaker awareness to each utterance representation. To that end, we use a graph neural network to model how each speaker is behaving within the local context of a conversation. The speaker representations learned this way are then used to update their respective utterance representations. We experiment with both multiparticipant and dyadic conversations on the MRDA and SwDA datasets and show the effectiveness of our approach. | Ayesha Qamar, Adarsh Pyarelal, Ruihong Huang |  |
| 812 |  |  [Demystifying Prompts in Language Models via Perplexity Estimation](https://doi.org/10.18653/v1/2023.findings-emnlp.679) |  | 0 | Language models can be prompted to perform a wide variety of tasks with zero- and few-shot in-context learning. However, performance varies significantly with the choice of prompt, and we do not yet understand why this happens. In this paper, we analyze the factors that contribute to this variance and establish a new empirical hypothesis: the performance of a prompt is predicted by the extent to which the model is familiar with the language it contains. Over a wide range of tasks, we show that the lower the perplexity of the prompt, the better it is able to perform the task, when considering reasonable prompts that are related to it. As part of our analysis, we also devise a method to automatically extend a small seed set of manually written prompts by paraphrasing with GPT3 and backtranslation. This larger set allows us to verify that perplexity is a strong predictor of the success of a prompt and we show that the lowest perplexity prompts are consistently effective. | Hila Gonen, Srini Iyer, Terra Blevins, Noah A. Smith, Luke Zettlemoyer |  |
| 813 |  |  [C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health](https://doi.org/10.18653/v1/2023.findings-emnlp.680) |  | 0 | Cognitive distortions refer to patterns of irrational thinking that can lead to distorted perceptions of reality and mental health problems in individuals. Despite previous attempts to detect cognitive distortion through language, progress has been slow due to the lack of appropriate data. In this paper, we present the C2D2 dataset, the first expert-supervised Chinese Cognitive Distortion Dataset, which contains 7,500 cognitive distortion thoughts in everyday life scenes. Additionally, we examine the presence of cognitive distortions in social media texts shared by individuals diagnosed with mental disorders, providing insights into the association between cognitive distortions and mental health conditions. We propose that incorporating information about users’ cognitive distortions can enhance the performance of existing models mental disorder detection. We contribute to a better understanding of how cognitive distortions appear in individuals’ language and their impact on mental health. | Bichen Wang, Pengfei Deng, Yanyan Zhao, Bing Qin |  |
| 814 |  |  [MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.findings-emnlp.681) |  | 0 | Data Augmentation through generating pseudo data has been proven effective in mitigating the challenge of data scarcity in the field of Grammatical Error Correction (GEC). Various augmentation strategies have been widely explored, most of which are motivated by two heuristics, i.e., increasing the distribution similarity and diversity of pseudo data. However, the underlying mechanism responsible for the effectiveness of these strategies remains poorly understood. In this paper, we aim to clarify how data augmentation improves GEC models. To this end, we introduce two interpretable and computationally efficient measures: Affinity and Diversity. Our findings indicate that an excellent GEC data augmentation strategy characterized by high Affinity and appropriate Diversity can better improve the performance of GEC models. Based on this observation, we propose MixEdit, a data augmentation approach that strategically and dynamically augments realistic data, without requiring extra monolingual corpora. To verify the correctness of our findings and the effectiveness of the proposed MixEdit, we conduct experiments on mainstream English and Chinese GEC datasets. The results show that MixEdit substantially improves GEC models and is complementary to traditional data augmentation methods. All the source codes of MixEdit are released at https://github.com/THUKElab/MixEdit. | Jingheng Ye, Yinghui Li, Yangning Li, HaiTao Zheng |  |
| 815 |  |  [CCEval: A Representative Evaluation Benchmark for the Chinese-centric Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.682) |  | 0 | The Chinese-centric Multilingual Machine Translation (MMT) has gained more importance recently due to increasing demands from international business development and cross-cultural exchanges. However, an important factor that limits the progress of this area is the lack of highly representative and high-quality evaluation benchmarks. To fill this gap, we propose CCEval, an impartial and representative Chinese-centric MMT evaluation dataset. This benchmark dataset consists of 2500 Chinese sentences we meticulously selected and processed, and covers more diverse linguistic features as compared to other MMT evaluation benchmarks. These sentences have been translated into 11 languages of various resource levels by professional translators via a rigorously controlled process pipeline to ensure their high quality. We conduct experiments to demonstrate our sampling methodology’s effectiveness in constructing evaluation datasets strongly correlated with human evaluations. The resulting dataset enables better assessments of the Chinese-centric MMT quality. Our CCEval benchmark dataset is available at https://bright.pcl.ac.cn/en/offlineTasks. | Lianzhang Lou, Xi Yin, Yutao Xie, Yang Xiang |  |
| 816 |  |  [ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense](https://doi.org/10.18653/v1/2023.findings-emnlp.683) |  | 0 | Humans possess a strong capability for reasoning beyond common sense. For example, given an unconventional image of a goldfish laying on the table next to an empty fishbowl, a human would effortlessly determine that the fish is not inside the fishbowl. The case, however, may be different for a vision-language model, whose reasoning could gravitate towards the common scenario that the fish is inside the bowl, despite the visual input. In this paper, we introduce a novel probing dataset named ROME (reasoning beyond commonsense knowledge) to evaluate whether the state-of-the-art pre-trained vision-language models have the reasoning capability to correctly interpret counter-intuitive content. ROME contains images that defy commonsense knowledge with regards to color, shape, material, size and positional relation. Experiments on the state-of-the-art pre-trained vision-language models reveal that most of these models are still largely incapable of interpreting counter-intuitive scenarios. We hope that ROME will spur further investigations on reasoning beyond commonsense knowledge in vision-language research. | Kankan Zhou, Eason Lai, Wei Bin Au Yeong, Kyriakos Mouratidis, Jing Jiang |  |
| 817 |  |  [Automatic Analysis of Substantiation in Scientific Peer Reviews](https://doi.org/10.18653/v1/2023.findings-emnlp.684) |  | 0 | With the increasing amount of problematic peer reviews in top AI conferences, the community is urgently in need of automatic quality control measures. In this paper, we restrict our attention to substantiation — one popular quality aspect indicating whether the claims in a review are sufficiently supported by evidence — and provide a solution automatizing this evaluation process. To achieve this goal, we first formulate the problem as claim-evidence pair extraction in scientific peer reviews, and collect SubstanReview, the first annotated dataset for this task. SubstanReview consists of 550 reviews from NLP conferences annotated by domain experts. On the basis of this dataset, we train an argument mining system to automatically analyze the level of substantiation in peer reviews. We also perform data analysis on the SubstanReview dataset to obtain meaningful insights on peer reviewing quality in NLP conferences over recent years. The dataset is available at https://github.com/YanzhuGuo/SubstanReview. | Yanzhu Guo, Guokan Shang, Virgile Rennard, Michalis Vazirgiannis, Chloé Clavel |  |
| 818 |  |  [Hierarchical Prompting Assists Large Language Model on Web Navigation](https://doi.org/10.18653/v1/2023.findings-emnlp.685) |  | 0 | Large language models (LLMs) struggle on processing complicated observations in interactive decision making. To alleviate this issue, we propose a simple hierarchical prompting approach. Diverging from previous prompting approaches that always put the full observation (a web page) to the prompt, we propose to first construct an action-aware observation which is more condensed and relevant with a dedicated Summarizer prompt. The Actor prompt then predicts the next action based on the summarized history. While our method has broad applicability, we particularly demonstrate its efficacy in the complex domain of web navigation where a full observation often contains redundant and irrelevant information. Our approach outperforms the previous state-of-the-art prompting mechanism with the same LLM by 6.2% on task success rate, demonstrating its potential on interactive decision making tasks with long observation traces. | Robert Lo, Abishek Sridhar, Frank F. Xu, Hao Zhu, Shuyan Zhou |  |
| 819 |  |  [Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.686) |  | 0 | Debatepedia is a publicly available dataset consisting of arguments and counter-arguments on controversial topics that has been widely used for the single-document query-focused abstractive summarization task in recent years. However, it has been recently found that this dataset is limited by noise and even most queries in this dataset do not have any relevance to the respective document. In this paper, we study whether large language models (LLMs) can be utilized to clean the Debatepedia dataset to make it suitable for query-focused abstractive summarization. More specifically, we harness the language generation capabilities of two LLMs, namely, ChatGPT and PaLM to regenerate its queries. Based on our experiments, we find that solely depending on large language models for query correction may not be very useful for data cleaning. However, we observe that leveraging a rule-based approach for data sampling followed by query regeneration using LLMs (especially ChatGPT) for the sampled instances may ensure a higher quality version of this dataset suitable for the development of more generalized query-focused text summarization models. | Md. Tahmid Rahman Laskar, Mizanur Rahman, Israt Jahan, Enamul Hoque, Jimmy Xiangji Huang |  |
| 820 |  |  [TSTR: Target Similarity Tuning Meets the Real World](https://doi.org/10.18653/v1/2023.findings-emnlp.687) |  | 0 | Target similarity tuning (TST) is a method of selecting relevant examples in natural language (NL) to code generation through large language models (LLMs) to improve performance. Its goal is to adapt a sentence embedding model to have the similarity between two NL inputs match the similarity between their associated code outputs. In this paper, we propose different methods to apply and improve TST in the real world. First, we replace the sentence transformer with embeddings from a larger model, which reduces sensitivity to the language distribution and thus provides more flexibility in synthetic generation of examples, and we train a tiny model that transforms these embeddings to a space where embedding similarity matches code similarity, which allows the model to remain a black box and only requires a few matrix multiplications at inference time. Second, we how to efficiently select a smaller number of training examples to train the TST model. Third, we introduce a ranking-based evaluation for TST that does not require end-to-end code generation experiments, which can be expensive to perform. | Anirudh Khatry, Sumit Gulwani, Priyanshu Gupta, Vu Le, Mukul Singh, Ananya Singha, Gust Verbruggen |  |
| 821 |  |  [RealBehavior: A Framework for Faithfully Characterizing Foundation Models' Human-like Behavior Mechanisms](https://doi.org/10.18653/v1/2023.findings-emnlp.688) |  | 0 | Reports of human-like behaviors in foundation models are growing, with psychological theories providing enduring tools to investigate these behaviors. However, current research tends to directly apply these human-oriented tools without verifying the faithfulness of their outcomes. In this paper, we introduce a framework, RealBehavior, which is designed to characterize the humanoid behaviors of models faithfully. Beyond simply measuring behaviors, our framework assesses the faithfulness of results based on reproducibility, internal and external consistency, and generalizability. Our findings suggest that a simple application of psychological tools cannot faithfully characterize all human-like behaviors. Moreover, we discuss the impacts of aligning models with human and social values, arguing for the necessity of diversifying alignment objectives to prevent the creation of models with restricted characteristics. | Enyu Zhou, Rui Zheng, Zhiheng Xi, Songyang Gao, Xiaoran Fan, Zichu Fei, Jingting Ye, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 822 |  |  [Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance](https://doi.org/10.18653/v1/2023.findings-emnlp.689) |  | 0 | Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one in-classroom group with recommender system feature-based suggestions and four groups recruited from Prolific – a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis and Word Embedding Association Tests (WEAT), we evaluate the gender bias at various stages of the pipeline: in reviews written by students, in suggestions generated by the models, and in model embeddings directly. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students’ responses. | Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Parsa Neshaei, Roman Rietsche, Tanja Käser |  |
| 823 |  |  [VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing](https://doi.org/10.18653/v1/2023.findings-emnlp.690) |  | 0 | Reflective listening is a fundamental skill that counselors must acquire to achieve proficiency in motivational interviewing (MI). It involves responding in a manner that acknowledges and explores the meaning of what the client has expressed in the conversation. In this work, we introduce the task of counseling response rewriting, which transforms non-reflective statements into reflective responses. We introduce VERVE, a template-based rewriting system with paraphrase-augmented training and adaptive template updating. VERVE first creates a template by identifying and filtering out tokens that are not relevant to reflections and constructs a reflective response using the template. Paraphrase-augmented training allows the model to learn less-strict fillings of masked spans, and adaptive template updating helps discover effective templates for rewriting without significantly removing the original content. Using both automatic and human evaluations, we compare our method against text rewriting baselines and show that our framework is effective in turning non-reflective statements into more reflective responses while achieving a good content preservation-reflection style trade-off. | Do June Min, Verónica PérezRosas, Ken Resnicow, Rada Mihalcea |  |
| 824 |  |  [Self-Knowledge Guided Retrieval Augmentation for Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.691) |  | 0 | Large language models (LLMs) have shown superior performance without task-specific fine-tuning. Despite the success, the knowledge stored in the parameters of LLMs could still be incomplete and difficult to update due to the computational costs. As complementary, retrieval-based methods can offer non-parametric world knowledge and improve the performance on tasks such as question answering. However, we find that the retrieved knowledge does not always help and even has a negative impact on original responses occasionally. To better make use of both internal knowledge and external world knowledge, we investigate eliciting the model’s ability to recognize what they know and do not know (which is also called “self-knowledge”) and propose Self-Knowledge guided Retrieval augmentation (SKR), a simple yet effective method which can let LLMs refer to the questions they have previously encountered and adaptively call for external resources when dealing with new questions. We evaluate SKR on multiple datasets and demonstrate that it outperforms chain-of-thought based and fully retrieval-based methods by using either InstructGPT or ChatGPT. | Yile Wang, Peng Li, Maosong Sun, Yang Liu |  |
| 825 |  |  [Pretraining Language Models with Text-Attributed Heterogeneous Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.692) |  | 0 | In many real-world scenarios (e.g., academic networks, social platforms), different types of entities are not only associated with texts but also connected by various relationships, which can be abstracted as Text-Attributed Heterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models (LMs) primarily focus on separately learning the textual information of each entity and overlook the crucial aspect of capturing topological connections among entities in TAHGs. In this paper, we present a new pretraining framework for LMs that explicitly considers the topological and heterogeneous information in TAHGs. Firstly, we define a context graph as neighborhoods of a target node within specific orders and propose a topology-aware pretraining task to predict nodes involved in the context graph by jointly optimizing an LM and an auxiliary heterogeneous graph neural network. Secondly, based on the observation that some nodes are text-rich while others have little text, we devise a text augmentation strategy to enrich textless nodes with their neighbors’ texts for handling the imbalance issue. We conduct link prediction and node classification tasks on three datasets from various domains. Experimental results demonstrate the superiority of our approach over existing methods and the rationality of each design. Our code is available at https://github.com/Hope-Rita/THLM. | Tao Zou, Le Yu, Yifei Huang, Leilei Sun, Bowen Du |  |
| 826 |  |  [CReTIHC: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings](https://doi.org/10.18653/v1/2023.findings-emnlp.693) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their ability to establish causal relationships, particularly in the context of temporal interventions and language hallucinations, remains challenging. This paper presents CReTIHC, a novel dataset designed to test and enhance the causal reasoning abilities of LLMs. The dataset is constructed using a unique approach that incorporates elements of verbal hallucinations and temporal interventions through the reengineering of existing causal inference datasets. This transformation creates complex scenarios that push LLMs to critically evaluate the information presented and identify cause-and-effect relationships. The CReTIHC dataset serves as a pioneering tool for improving LLM’s causal inference capabilities, paving the way for a more nuanced understanding of causal relationships in natural language processing (NLP) tasks. The whole dataset is publicly accessible at: (https://github.com/ChangwooChun/CReTIHC) | Changwoo Chun, Songeun Lee, Jaehyung Seo, Heuiseok Lim |  |
| 827 |  |  [On the Dimensionality of Sentence Embeddings](https://doi.org/10.18653/v1/2023.findings-emnlp.694) |  | 0 | Learning sentence embeddings is a fundamental problem in natural language processing. While existing research primarily focuses on enhancing the quality of sentence embeddings, the exploration of sentence embedding dimensions is limited. Here we present a comprehensive and empirical analysis of the dimensionality of sentence embeddings. First, we demonstrate that the optimal dimension of sentence embeddings is usually smaller than the default value. Subsequently, to compress the dimension of sentence embeddings with minimum performance degradation, we identify two components contributing to the overall performance loss: the encoder’s performance loss and the pooler’s performance loss. Therefore, we propose a two-step training method for sentence representation learning models, wherein the encoder and the pooler are optimized separately to mitigate the overall performance loss in low-dimension scenarios. Experimental results on seven STS tasks and seven sentence classification tasks demonstrate that our method significantly improves the performance of low-dimensional sentence embeddings. | Hongwei Wang, Hongming Zhang, Dong Yu |  |
| 828 |  |  [Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.695) |  | 0 | Scaling pre-trained language models has resulted in large performance gains in various natural language processing tasks but comes with a large cost in memory requirements. Inspired by the position embeddings in transformers, we aim to simplify and reduce the memory footprint of the multi-head attention (MHA) mechanism. We propose an alternative module that uses only a single shared projection matrix and multiple head embeddings (MHE), i.e. one per head. We empirically demonstrate that our MHE attention is substantially more memory efficient compared to alternative attention mechanisms while achieving high predictive performance retention ratio to vanilla MHA on several downstream tasks. MHE attention only requires a negligible fraction of additional parameters (3nd, where n is the number of attention heads and d the size of the head embeddings) compared to a single-head attention, while MHA requires (3n2-3n)d2-3nd additional parameters. | Huiyin Xue, Nikolaos Aletras |  |
| 829 |  |  [Entity-Based Evaluation of Political Bias in Automatic Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.696) |  | 0 | Growing literature has shown that NLP systems may encode social biases; however, the \*political\* bias of summarization models remains relatively unknown. In this work, we use an entity replacement method to investigate the portrayal of politicians in automatically generated summaries of news articles. We develop an entity-based computational framework to assess the sensitivities of several extractive and abstractive summarizers to the politicians Donald Trump and Joe Biden. We find consistent differences in these summaries upon entity replacement, such as reduced emphasis of Trump’s presence in the context of the same article and a more individualistic representation of Trump with respect to the collective US government (i.e., administration). These summary dissimilarities are most prominent when the entity is heavily featured in the source article. Our characterization provides a foundation for future studies of bias in summarization and for normative discussions on the ideal qualities of automatic summaries. | Karen Zhou, Chenhao Tan |  |
| 830 |  |  [StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.697) |  | 0 | Stylistic headline generation is the task to generate a headline that not only summarizes the content of an article, but also reflects a desired style that attracts users. As style-specific article-headline pairs are scarce, previous researches focus on unsupervised approaches with a standard headline generation dataset and mono-style corpora. In this work, we follow this line and propose StyleBART, an unsupervised approach for stylistic headline generation. Our method decorates the pretrained BART model with adapters that are responsible for different styles and allows the generation of headlines with diverse styles by simply switching the adapters. Different from previous works, StyleBART separates the task of style learning and headline generation, making it possible to freely combine the base model and the style adapters during inference. We further propose an inverse paraphrasing task to enhance the style adapters. Extensive automatic and human evaluations show that StyleBART achieves new state-of-the-art performance in the unsupervised stylistic headline generation task, producing high-quality headlines with the desired style. | Hanqing Wang, Yajing Luo, Boya Xiong, Guanhua Chen, Yun Chen |  |
| 831 |  |  [RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training](https://doi.org/10.18653/v1/2023.findings-emnlp.698) |  | 0 | The dialogue systems in customer services have been developed with neural models to provide users with precise answers and round-the-clock support in task-oriented conversations by detecting customer intents based on their utterances. Existing intent detection approaches have highly relied on adaptively pre-training language models with large-scale datasets, yet the predominant cost of data collection may hinder their superiority. In addition, they neglect the information within the conversational responses of the agents, which have a lower collection cost, but are significant to customer intent as agents must tailor their replies based on the customers’ intent. In this paper, we propose RSVP, a self-supervised framework dedicated to task-oriented dialogues, which utilizes agent responses for pre-training in a two-stage manner. Specifically, we introduce two pre-training tasks to incorporate the relations of utterance-response pairs: 1) Response Retrieval by selecting a correct response from a batch of candidates, and 2) Response Generation by mimicking agents to generate the response to a given utterance. Our benchmark results for two real-world customer service datasets show that RSVP significantly outperforms the state-of-the-art baselines by 4.95% for accuracy, 3.4% for MRR@3, and 2.75% for MRR@5 on average. Extensive case studies are investigated to show the validity of incorporating agent responses into the pre-training stage. | YuChien Tang, WeiYao Wang, AnZi Yen, WenChih Peng |  |
| 832 |  |  [Improving Low-resource Question Answering by Augmenting Question Information](https://doi.org/10.18653/v1/2023.findings-emnlp.699) |  | 0 | In the era of large models, low-resource question-answering tasks lag, emphasizing the importance of data augmentation - a key research avenue in natural language processing. The main challenges include leveraging the large model’s internal knowledge for data augmentation, determining which QA data component - the question, passage, or answer - benefits most from augmentation, and retaining consistency in the augmented content without inducing excessive noise. To tackle these, we introduce PQQ, an innovative approach for question data augmentation consisting of Prompt Answer, Question Generation, and Question Filter. Our experiments reveal that ChatGPT underperforms on the experimental data, yet our PQQ method excels beyond existing augmentation strategies. Further, its universal applicability is validated through successful tests on high-resource QA tasks like SQUAD1.1 and TriviaQA. | Andong Chen, Yuan Sun, Xiaobing Zhao, Rosella P. Galindo Esparza, Kehai Chen, Yang Xiang, Tiejun Zhao, Min Zhang |  |
| 833 |  |  [InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning](https://doi.org/10.18653/v1/2023.findings-emnlp.700) |  | 0 | Safety detection has been an increasingly important topic in recent years and it has become even more necessary to develop reliable safety detection systems with the rapid development of large language models. However, currently available safety detection systems have limitations in terms of their versatility and interpretability. In this paper, we first introduce InstructSafety, a safety detection framework that unifies 7 common sub-tasks for safety detection. These tasks are unified into a similar form through different instructions. We then conduct a comprehensive survey of existing safety detection datasets and process 39 human-annotated datasets for instruction tuning. We also construct adversarial samples to enhance the model’s robustness. After fine-tuning Flan-T5 on the collected data, we have developed Safety-Flan-T5, a multidimensional and explainable safety detector. We conduct comprehensive experiments on a variety of datasets and tasks, and demonstrate the strong performance of Safety-Flan-T5 in comparison to supervised baselines and served APIs (Perspective API, ChatGPT and InstructGPT). We will release the processed data, fine-tuned Safety-Flan-T5 and related code for public use. | Zhexin Zhang, Jiale Cheng, Hao Sun, Jiawen Deng, Minlie Huang |  |
| 834 |  |  ["A Tale of Two Movements': Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.701) |  | 0 | Social media has become a major driver of social change, by facilitating the formation of online social movements. Automatically understanding the perspectives driving the movement and the voices opposing it, is a challenging task as annotated data is difficult to obtain. We propose a weakly supervised graph-based approach that explicitly models perspectives in #BackLivesMatter-related tweets. Our proposed approach utilizes a social-linguistic representation of the data. We convert the text to a graph by breaking it into structured elements and connect it with the social network of authors, then structured prediction is done over the elements for identifying perspectives. Our approach uses a small seed set of labeled examples. We experiment with large language models for generating artificial training examples, compare them to manual annotation, and find that it achieves comparable performance. We perform quantitative and qualitative analyses using a human-annotated test set. Our model outperforms multitask baselines by a large margin, successfully characterizing the perspectives supporting and opposing #BLM. | Shamik Roy, Dan Goldwasser |  |
| 835 |  |  [ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery](https://doi.org/10.18653/v1/2023.findings-emnlp.702) |  | 0 | The discovery of new intent categories from user utterances is a crucial task in expanding agent skills. The key lies in how to efficiently solicit semantic evidence from utterances and properly transfer knowledge from existing intents to new intents. However, previous methods laid too much emphasis on relations among utterances or clusters for transfer learning, while paying less attention to the usage of semantics. As a result, these methods suffer from in-domain over-fitting and often generate meaningless new intent clusters due to data distortion. In this paper, we present a novel approach called Cluster Semantic Enhanced Prompt Learning (CsePL) for discovering new intents. Our method leverages two-level contrastive learning with label semantic alignment to learn meaningful representations of intent clusters. These learned intent representations are then utilized as soft prompt initializations for discriminating new intents, reducing the dominance of existing intents. Extensive experiments conducted on three public datasets demonstrate the superiority of our proposed method. It not only outperforms existing methods but also suggests meaningful intent labels and enables early detection of new intents. | Jinggui Liang, Lizi Liao |  |
| 836 |  |  [Investigating the Effect of Pre-finetuning BERT Models on NLI Involving Presuppositions](https://doi.org/10.18653/v1/2023.findings-emnlp.703) |  | 0 | We explore the connection between presupposition, discourse and sarcasm and propose to leverage that connection in a transfer learning scenario with the goal of improving the performance of NLI models on cases involving presupposition. We exploit advances in training transformer-based models that show that pre-finetuning—–i.e., finetuning the model on an additional task or dataset before the actual finetuning phase—–can help these models, in some cases, achieve a higher performance on a given downstream task. Building on those advances and that aforementioned connection, we propose pre-finetuning NLI models on carefully chosen tasks in an attempt to improve their performance on NLI cases involving presupposition. We notice that, indeed, pre-finetuning on those tasks leads to performance improvements. Furthermore, we run several diagnostic tests to understand whether these gains are merely a byproduct of additional training data. The results show that, while additional training data seems to be helping on its own in some cases, the choice of the tasks plays a role in the performance improvements. | Jad Kabbara, Jackie Chi Kit Cheung |  |
| 837 |  |  [MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling](https://doi.org/10.18653/v1/2023.findings-emnlp.704) |  | 0 | With the rise of non-autoregressive approach, some non-autoregressive models for joint multiple intent detection and slot filling have obtained the promising inference speed. However, most existing SLU models (1) suffer from the multi-modality problem that leads to reference intents and slots may not be suitable for training; (2) lack of alignment between the correct predictions of the two tasks, which extremely limits the overall accuracy. Therefore, in this paper, we propose Modifying the Reference via Reinforcement Learning (MRRL), a novel method for multiple intent detection and slot filling, which introduces a modifier and employs reinforcement learning. Specifically, we try to provide the better training target for the non-autoregressive SLU model via modifying the reference based on the output of the non-autoregressive SLU model, and propose a suitability reward to ensure that the output of the modifier module could fit well with the output of the non-autoregressive SLU model and does not deviate too far from the reference. In addition, we also propose a compromise reward to realize a flexible trade-off between the two subtasks. Experiments on two multi-intent datasets and non-autoregressive baselines demonstrate that our MRRL could consistently improve the performance of baselines. More encouragingly, our best variant achieves new state-of-the-art results, outperforming the previous best approach by 3.6 overall accuracy on MixATIS dataset. | Xuxin Cheng, Zhihong Zhu, Bowen Cao, Qichen Ye, Yuexian Zou |  |
| 838 |  |  [DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task](https://doi.org/10.18653/v1/2023.findings-emnlp.705) |  | 0 | Recently, prompt-based generative frameworks have shown impressive capabilities in sequence labeling tasks. However, in practical dialogue scenarios, relying solely on simplistic templates and traditional corpora presents a challenge for these methods in generalizing to unknown input perturbations. To address this gap, we propose a multi-task demonstration-based generative framework for noisy slot filling, named DemoNSF. Specifically, we introduce three noisy auxiliary tasks, namely noisy recovery (NR), random mask (RM), and hybrid discrimination (HD), to implicitly capture semantic structural information of input perturbations at different granularities. In the downstream main task, we design a noisy demonstration construction strategy for the generative framework, which explicitly incorporates task-specific information and perturbed distribution during training and inference. Experiments on two benchmarks demonstrate that DemoNSF outperforms all baseline methods and achieves strong generalization. Further analysis provides empirical guidance for the practical application of generative frameworks. Our code is released at https://github.com/dongguanting/Demo-NSF. | Guanting Dong, Tingfeng Hui, Zhuoma Gongque, Jinxu Zhao, Daichi Guo, Gang Zhao, Keqing He, Weiran Xu |  |
| 839 |  |  [SHARCS: Efficient Transformers Through Routing with Dynamic Width Sub-networks](https://doi.org/10.18653/v1/2023.findings-emnlp.706) |  | 0 | We introduce SHARCS for adaptive inference that takes into account the hardness of input samples. SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths. Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy. | Mohammadreza Salehi, Sachin Mehta, Aditya Kusupati, Ali Farhadi, Hannaneh Hajishirzi |  |
| 840 |  |  [Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.707) |  | 0 | Cross-domain Relation Extraction aims to transfer knowledge from a source domain to a different target domain to address low-resource challenges. However, the semantic gap caused by data bias between domains is a major challenge, especially in few-shot scenarios. Previous work has mainly focused on transferring knowledge between domains through shared feature representations without analyzing the impact of each factor that may produce data bias based on the characteristics of each domain. This work takes a causal perspective and proposes a new framework CausalGF. By constructing a unified structural causal model, we estimating the causal effects of factors such as syntactic structure, label distribution,and entities on the outcome. CausalGF calculates the causal effects among the factors and adjusts them dynamically based on domain characteristics, enabling adaptive gap filling. Our experiments show that our approach better fills the domain gap, yielding significantly better results on the cross-domain few-shot relation extraction task. | Ge Bai, Chenji Lu, Jiaxiang Geng, Shilong Li, Yidong Shi, Xiyan Liu, Ying Liu, Zhang Zhang, Ruifang Liu |  |
| 841 |  |  [MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities](https://doi.org/10.18653/v1/2023.findings-emnlp.708) |  | 0 | Text classification is essential for organizing unstructured text. Traditional methods rely on human annotations or, more recently, a set of class seed words for supervision, which can be costly, particularly for specialized or emerging domains. To address this, using class surface names alone as extremely weak supervision has been proposed. However, existing approaches treat different levels of text granularity (documents, sentences, or words) independently, disregarding inter-granularity class disagreements and the context identifiable exclusively through joint extraction. In order to tackle these issues, we introduce MEGClass, an extremely weakly-supervised text classification method that leverages Mutually-Enhancing Text Granularities. MEGClass utilizes coarse- and fine-grained context signals obtained by jointly considering a document’s most class-indicative words and sentences. This approach enables the learning of a contextualized document representation that captures the most discriminative class indicators. By preserving the heterogeneity of potential classes, MEGClass can select the most informative class-indicative documents as iterative feedback to enhance the initial word-based class representations and ultimately fine-tune a pre-trained text classifier. Extensive experiments on seven benchmark datasets demonstrate that MEGClass outperforms other weakly and extremely weakly supervised methods. | Priyanka Kargupta, Tanay Komarlu, Susik Yoon, Xuan Wang, Jiawei Han |  |
| 842 |  |  [Causal Inference from Text: Unveiling Interactions between Variables](https://doi.org/10.18653/v1/2023.findings-emnlp.709) |  | 0 | Adjusting for latent covariates is crucial for estimating causal effects from observational textual data. Most existing methods only account for confounding covariates that affect both treatment and outcome, potentially leading to biased causal effects. This bias arises from insufficient consideration of non-confounding covariates, which are relevant only to either the treatment or the outcome. In this work, we aim to mitigate the bias by unveiling interactions between different variables to disentangle the non-confounding covariates when estimating causal effects from text. The disentangling process ensures covariates only contribute to their respective objectives, enabling independence between variables. Additionally, we impose a constraint to balance representations from the treated group and control group to alleviate selection bias. We conduct experiments on two different treatment factors under various scenarios, and the proposed model significantly outperforms recent strong baselines. Furthermore, our thorough analysis on earnings call transcripts demonstrates that our model can effectively disentangle the variables, and further investigations into real-world scenarios provide guidance for investors to make informed decisions. | Yuxiang Zhou, Yulan He |  |
| 843 |  |  [Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!](https://doi.org/10.18653/v1/2023.findings-emnlp.710) |  | 0 | Large Language Models (LLMs) have made remarkable strides in various tasks. Whether LLMs are competitive few-shot solvers for information extraction (IE) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings. Therefore, we conclude that LLMs are not effective few-shot information extractors in general. Nonetheless, we illustrate that with appropriate prompting strategies, LLMs can effectively complement SLMs and tackle challenging samples that SLMs struggle with. And moreover, we propose an adaptive filter-then-rerank paradigm to combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as filters and LLMs serve as rerankers. By prompting LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.4% F1-gain on average) on various IE tasks, with an acceptable time and cost investment. | Yubo Ma, Yixin Cao, Yong Hong, Aixin Sun |  |
| 844 |  |  [Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration](https://doi.org/10.18653/v1/2023.findings-emnlp.711) |  | 0 | Conversational systems based on Large Language Models (LLMs), such as ChatGPT, show exceptional proficiency in context understanding and response generation. However, they still possess limitations, such as failing to ask clarifying questions to ambiguous queries or refuse users’ unreasonable requests, both of which are considered as key aspects of a conversational agent’s proactivity. This raises the question of whether LLM-based conversational systems are equipped to handle proactive dialogue problems. In this work, we conduct a comprehensive analysis of LLM-based conversational systems, specifically focusing on three key aspects of proactive dialogues: clarification, target-guided, and non-collaborative dialogues. To trigger the proactivity of LLMs, we propose the Proactive Chain-of-Thought prompting scheme, which augments LLMs with the goal planning capability over descriptive reasoning chains. Empirical findings are discussed to promote future studies on LLM-based proactive dialogue systems. | Yang Deng, Lizi Liao, Liang Chen, Hongru Wang, Wenqiang Lei, TatSeng Chua |  |
| 845 |  |  [Ecologically Valid Explanations for Label Variation in NLI](https://doi.org/10.18653/v1/2023.findings-emnlp.712) |  | 0 | Human label variation, or annotation disagreement, exists in many natural language processing (NLP) tasks, including natural language inference (NLI). To gain direct evidence of how NLI label variation arises, we build LiveNLI, an English dataset of 1,415 ecologically valid explanations (annotators explain the NLI labels they chose) for 122 MNLI items (at least 10 explanations per item). The LiveNLI explanations confirm that people can systematically vary on their interpretation and highlight within-label variation: annotators sometimes choose the same label for different reasons. This suggests that explanations are crucial for navigating label interpretations in general. We few-shot prompt large language models to generate explanations but the results are inconsistent: they sometimes produces valid and informative explanations, but it also generates implausible ones that do not support the label, highlighting directions for improvement. | NanJiang Jiang, Chenhao Tan, MarieCatherine de Marneffe |  |
| 846 |  |  [A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.713) |  | 0 | Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of predicting facts for new, previously unseen entities based on context information. Although new entities can be integrated by retraining the model from scratch in principle, such an approach is infeasible for large-scale KGs, where retraining is expensive and new entities may arise frequently. In this paper, we propose and describe a large-scale benchmark to evaluate semi-inductive LP models. The benchmark is based on and extends Wikidata5M: It provides transductive, k-shot, and 0-shot LP tasks, each varying the available information from (i) only KG structure, to (ii) including textual mentions, and (iii) detailed descriptions of the entities. We report on a small study of recent approaches and found that semi-inductive LP performance is far from transductive performance on long-tail entities throughout all experiments. The benchmark provides a test bed for further research into integrating context and textual information in semi-inductive LP models. | Adrian Kochsiek, Rainer Gemulla |  |
| 847 |  |  [SummIt: Iterative Text Summarization via ChatGPT](https://doi.org/10.18653/v1/2023.findings-emnlp.714) |  | 0 | Existing text summarization systems have made significant progress in recent years, but typically generate summaries in a single step. The one-shot summarization setting is sometimes inadequate, however, as the generated summary may contain hallucinations or overlook important details related to the reader’s interests. In this paper, we address this limitation by proposing SummIt, an iterative text summarization framework based on large language models like ChatGPT. Our framework enables the model to refine the generated summary iteratively through self-evaluation and feedback, closely resembling the iterative process humans undertake when drafting and revising summaries. Furthermore, we explore the potential benefits of integrating knowledge and topic extractors into the framework to enhance summary faithfulness and controllability. We evaluate the performance of our framework on three benchmark summarization datasets through empirical and qualitative analyses. We also conduct a human evaluation to validate the effectiveness of the model’s refinements and find a potential issue of over-correction. | Haopeng Zhang, Xiao Liu, Jiawei Zhang |  |
| 848 |  |  [Orthogonal Subspace Learning for Language Model Continual Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.715) |  | 0 | Benefiting from massive corpora and advanced hardware, large language models (LLMs) exhibit remarkable capabilities in language understanding and generation. However, their performance degrades in scenarios where multiple tasks are encountered sequentially, also known as catastrophic forgetting. In this paper, we propose orthogonal low-rank adaptation (O-LoRA), a simple and efficient approach for continual learning in language models, effectively mitigating catastrophic forgetting while learning new tasks. Specifically, O-LoRA learns tasks in different (low-rank) vector subspaces that are kept orthogonal to each other in order to minimize interference. Our method induces only marginal additional parameter costs and requires no user data storage for replay. Experimental results on continual learning benchmarks show that our method outperforms state-of-the-art methods. Furthermore, compared to previous approaches, our method excels in preserving the generalization ability of LLMs on unseen tasks. | Xiao Wang, Tianze Chen, Qiming Ge, Han Xia, Rong Bao, Rui Zheng, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 849 |  |  [Attention-Enhancing Backdoor Attacks Against BERT-based Models](https://doi.org/10.18653/v1/2023.findings-emnlp.716) |  | 0 | Recent studies have revealed that Backdoor Attacks can threaten the safety of natural language processing (NLP) models. Investigating the strategies of backdoor attacks will help to understand the model’s vulnerability. Most existing textual backdoor attacks focus on generating stealthy triggers or modifying model weights. In this paper, we directly target the interior structure of neural networks and the backdoor mechanism. We propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention patterns. Our loss can be applied to different attacking methods to boost their attack efficacy in terms of attack successful rates and poisoning rates. It applies to not only traditional dirty-label attacks, but also the more challenging clean-label attacks. We validate our method on different backbone models (BERT, RoBERTa, and DistilBERT) and various tasks (Sentiment Analysis, Toxic Detection, and Topic Classification). | Weimin Lyu, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen |  |
| 850 |  |  [Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.717) |  | 0 | Theory of Mind (ToM) is the ability to reason about one’s own and others’ mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others’ beliefs. %We also incorporate a new deception mechanism in ToM reasoning. We introduce Hi-ToM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP. | Yufan Wu, Yinghui He, Yilin Jia, Rada Mihalcea, Yulong Chen, Naihao Deng |  |
| 851 |  |  [Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.718) |  | 0 | In this paper, we propose SRL4NLP, a new approach for data augmentation by drawing an analogy between image and text processing: Super-resolution learning. This method is based on using high-resolution images to overcome the problem of low resolution images. While this technique is a common usage in image processing when images have a low resolution or are too noisy, it has never been used in NLP. We therefore propose the first adaptation of this method for text classification and evaluate its effectiveness on urgency detection from tweets posted in crisis situations, a very challenging task where messages are scarce and highly imbalanced. We show that this strategy is efficient when compared to competitive state-of-the-art data augmentation techniques on several benchmarks datasets in two languages. | Romain Meunier, Farah Benamara, Véronique Moriceau, Patricia Stolf |  |
| 852 |  |  [SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank](https://doi.org/10.18653/v1/2023.findings-emnlp.719) |  | 0 | Deep neural classifiers trained with cross-entropy loss (CE loss) often suffer from poor calibration, necessitating the task of out-of-distribution (OOD) detection. Traditional supervised OOD detection methods require expensive manual annotation of in-distribution and OOD samples. To address the annotation bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that requires only in-distribution samples as supervision. We cast OOD detection as an inter-document intra-label (IDIL) ranking problem and train the classifier with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a set of in-distribution documents and their labels, for each label, we train the classifier to rank the softmax scores of documents belonging to that label to be higher than the scores of documents that belong to other labels. Unlike CE loss, our IDIL loss function reaches zero when the desired confidence ranking is achieved and gradients are backpropagated to decrease probabilities associated with incorrect labels rather than continuously increasing the probability of the correct label. Extensive experiments with several classifiers on multiple classification datasets demonstrate the effectiveness of our method in both coarse- and fine-grained settings. | Dheeraj Mekala, Adithya Samavedhi, Chengyu Dong, Jingbo Shang |  |
| 853 |  |  [Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.720) |  | 0 | Knowing how to end and resume conversations over time is a natural part of communication, allowing for discussions to span weeks, months, or years. The duration of gaps between conversations dictates which topics are relevant and which questions to ask, and dialogue systems which do not explicitly model time may generate responses that are unnatural. In this work we explore the idea of making dialogue models aware of time, and present GapChat, a multi-session dialogue dataset in which the time between each session varies. While the dataset is constructed in real-time, progress on events in speakers’ lives is simulated in order to create realistic dialogues occurring across a long timespan. We expose time information to the model and compare different representations of time and event progress. In human evaluation we show that time-aware models perform better in metrics that judge the relevance of the chosen topics and the information gained from the conversation. | Qiang Zhang, Jason Naradowsky, Yusuke Miyao |  |
| 854 |  |  [A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction](https://doi.org/10.18653/v1/2023.findings-emnlp.721) |  | 0 | Bilingual lexicon induction (BLI) is the task of inducing word translations with a learned mapping function that aligns monolingual word embedding spaces in two different languages. However, most previous methods treat word embeddings as isolated entities and fail to jointly consider both the intra-space and inter-space topological relations between words. This limitation makes it challenging to align words from embedding spaces with distinct topological structures, especially when the assumption of isomorphism may not hold. To this end, we propose a novel approach called the Structure-Aware Generative Adversarial Network (SA-GAN) model to explicitly capture multiple topological structure information to achieve accurate BLI. Our model first incorporates two lightweight graph convolutional networks (GCNs) to leverage intra-space topological correlations between words for generating source and target embeddings. We then employ a GAN model to explore inter-space topological structures by learning a global mapping function that initially maps the source embeddings to the target embedding space. To further align the coarse-grained structures, we develop a pair-wised local mapping (PLM) strategy that enables word-specific transformations in an unsupervised manner. Extensive experiments conducted on public datasets, including languages with both distant and close etymological relationships, demonstrate the effectiveness of our proposed SA-GAN model. | Bocheng Han, Qian Tao, Lusi Li, Zhihao Xiong |  |
| 855 |  |  [NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark](https://doi.org/10.18653/v1/2023.findings-emnlp.722) |  | 0 | In this position paper we argue that the classical evaluation on Natural Language Processing (NLP) tasks using annotated benchmarks is in trouble. The worst kind of data contamination happens when a Large Language Model (LLM) is trained on the test split of a benchmark, and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not straightforward to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and argues for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination. | Oscar Sainz, Jon Ander Campos, Iker GarcíaFerrero, Julen Etxaniz, Oier Lopez de Lacalle, Eneko Agirre |  |
| 856 |  |  [Improving Pacing in Long-Form Story Planning](https://doi.org/10.18653/v1/2023.findings-emnlp.723) |  | 0 | Existing LLM-based systems for writing long-form stories or story outlines frequently suffer from unnatural pacing, whether glossing over important events or over-elaborating on insignificant details, resulting in a jarring experience for the reader. We propose a \*\*CONC\*\*rete \*\*O\*\*utline \*\*C\*\*on\*\*T\*\*rol (CONCOCT) system to improve pacing when automatically generating story outlines. We first train a \*concreteness evaluator\* to judge which of two events is more concrete (low-level-detailed). This evaluator can then be used to control pacing in hierarchical outline generation; in this work, we explore a \*vaguest-first\* expansion procedure that aims for uniform pacing. We further use the evaluator to filter new outline items based on predicted concreteness. Compared to a baseline hierarchical outline generator, humans judge CONCOCT’s pacing to be more consistent over 57% of the time across multiple outline lengths; the gains also translate to downstream stories. All code, data, and models are open-sourced. | Yichen Wang, Kevin Yang, Xiaoming Liu, Dan Klein |  |
| 857 |  |  [Argument mining as a multi-hop generative machine reading comprehension task](https://doi.org/10.18653/v1/2023.findings-emnlp.724) |  | 0 | Argument mining (AM) is a natural language processing task that aims to generate an argumentative graph given an unstructured argumentative text. An argumentative graph that consists of argumentative components and argumentative relations contains completed information of an argument and exhibits the logic of an argument. As the argument structure of an argumentative text can be regarded as an answer to a “why” question, the whole argument structure is therefore similar to the “chain of thought” concept, i.e., the sequence of ideas that lead to a specific conclusion for a given argument (Wei et al., 2022). For argumentative texts in the same specific genre, the “chain of thought” of such texts is usually similar, i.e., in a student essay, there is usually a major claim supported by several claims, and then a number of premises which are related to the claims are included (Eger et al., 2017). In this paper, we propose a new perspective which transfers the argument mining task into a multi-hop reading comprehension task, allowing the model to learn the argument structure as a “chain of thought”. We perform a comprehensive evaluation of our approach on two AM benchmarks and find that we surpass SOTA results. A detailed analysis shows that specifically the “chain of thought” information is helpful for the argument mining task. | Boyang Liu, Viktor Schlegel, Riza BatistaNavarro, Sophia Ananiadou |  |
| 858 |  |  [HuatuoGPT, Towards Taming Language Model to Be a Doctor](https://doi.org/10.18653/v1/2023.findings-emnlp.725) |  | 0 | In this paper, we present HuatuoGPT, a Large Language Model (LLM) for medical consultation. The core recipe of HuatuoGPT is to leverage both distilled data from \*\*ChatGPT\*\* and real-world data from \*\*doctors\*\* in the supervised fine-tuning stage. This is not only because purely using \*\*ChatGPT\*\*-distilled data might cause ‘model collapse’, but also because real-world data from \*\*doctors\*\* would be complementary to \*\*ChatGPT\*\*-distilled data. The responses from ChatGPT are usually detailed, well-presented, fluent, and instruction-followed, but it cannot perform like a doctor in many aspects, e.g. for interactive diagnosis. Therefore, the extra doctors’ data could tame a distilled language model to perform like doctors. To synergize the strengths of both data sources, we introduce RLMF (Reinforcement Learning from Mixed Feedback) where a reward model is trained to align the language model with the merits that both sources (ChatGPT and doctors) bring. Experimental results (in GPT-4 evaluation, human evaluation, and medical benchmark datasets) demonstrate that HuatuoGPT achieves state-of-the-art results in performing medical consultation among open-source LLMs. It is worth noting that by using additional real-world data and RLMF, the distilled language model (i.e., HuatuoGPT) outperforms its teacher model (i.e., ChatGPT) in most cases. | Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, Xiang Wan, Benyou Wang, Haizhou Li |  |
| 859 |  |  [Debias NLU Datasets via Training-free Perturbations](https://doi.org/10.18653/v1/2023.findings-emnlp.726) |  | 0 | Several recent studies have shown that advanced models for natural language understanding (NLU) are prone to capture biased features that are independent of the task but spuriously correlated to labels. Such models often perform well on in-distribution (ID) datasets but fail to generalize to out-of-distribution (OOD) datasets. Existing solutions can be separated into two orthogonal approaches: model-centric methods and data-centric methods. Model-centric methods improve OOD performance at the expense of ID performance. Data-centric strategies usually boost both of them via data-level manipulations such as generative data augmentation. However, the high cost of fine-tuning a generator to produce valid samples limits the potential of such approaches. To address this issue, we propose PDD, a framework that conducts training-free Perturbations on samples containing biased features to Debias NLU Datasets. PDD works by iteratively conducting perturbations via pre-trained mask language models (MLM). PDD exhibits the advantage of low cost by adopting a training-free perturbation strategy and further improves the label consistency by utilizing label information during perturbations. Extensive experiments demonstrate that PDD shows competitive performance with previous state-of-the-art debiasing strategies. When combined with the model-centric debiasing methods, PDD establishes a new state-of-the-art. | Qi Guo, Yuanhang Tang, Yawen Ouyang, Zhen Wu, Xinyu Dai |  |
| 860 |  |  [Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.727) |  | 0 | Aspect-based sentiment analysis (ABSA) aims to align aspects and corresponding sentiment expressions, so as to identify the sentiment polarities of specific aspects. Most existing ABSA methods focus on mining syntactic or semantic information, which still suffers from noisy interference introduced by the attention mechanism and dependency tree when multiple aspects exist in a sentence. To address these issues, in this paper, we revisit ABSA from a novel perspective by proposing a novel scope-assisted multi-view graph contrastive learning framework. It not only mitigates noisy interference for better locating aspect and its corresponding sentiment opinion with aspect-specific scope, but also captures the correlation and difference between sentiment polarities and syntactic/semantic information. Extensive experiments on five benchmark datasets show that our proposed approach substantially outperforms state-of-the-art methods and verifies the effectiveness and robustness of our model. | Heyan Chai, Ziyi Yao, Siyu Tang, Ye Wang, Liqiang Nie, Binxing Fang, Qing Liao |  |
| 861 |  |  [Robustness of Named-Entity Replacements for In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.728) |  | 0 | A key feature of modern large language models (LLMs) is their ability to perform in-context learning, a prompting technique where query- answer demonstrations are shown before the final query. This allows for generalization to novel distributions at inference time where the LLM can learn new rules without parameter updates. However, the choice of demonstrations and their relationship to a particular query can have a profound impact on model accuracy, raising concerns about the true in-context generalization capabilities (Zhao et al., 2021). In this work, we explore the robustness of the in-context learning paradigm by focusing on entities. In particular, we seek to understand the robustness of LLM in-context learning with respect to named entity replacements. We discover a significant variance in downstream performance based on the choice of the named entities, across three popular reasoning tasks and two popular LLMs. Specifically, model accuracy on the test sets can fluctuate between -2.7 to +8.0 points depending on the choice of named entity replacements. Our analysis exposes the sensitivity of LLM in-context learning with respect to named entities, and offers a simple recipe to improve test performance by hyper-parameter tuning the named entities for a given dataset. Code and datasets for reproducing the results are publicly available. | Saeed Goodarzi, Nikhil Kagita, Dennis Minn, Shufan Wang, Roberto Dessì, Shubham Toshniwal, Adina Williams, Jack Lanchantin, Koustuv Sinha |  |
| 862 |  |  [Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words](https://doi.org/10.18653/v1/2023.findings-emnlp.729) |  | 0 | The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss. A natural question arises: what characteristics do models acquire during contrastive learning? This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less. The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words. We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information). The results provide empirical evidence that contrastive fine-tuning emphasizes informative words. | Hiroto Kurita, Goro Kobayashi, Sho Yokoi, Kentaro Inui |  |
| 863 |  |  [Legally Enforceable Hate Speech Detection for Public Forums](https://doi.org/10.18653/v1/2023.findings-emnlp.730) |  | 0 | Hate speech causes widespread and deep-seated societal issues. Proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. This research introduces a new perspective and task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums. | Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu |  |
| 864 |  |  [ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.731) |  | 0 | Implicit hate speech detection is a challenging task in text classification since no explicit cues (e.g., swear words) exist in the text. While some pre-trained language models have been developed for hate speech detection, they are not specialized in implicit hate speech. Recently, an implicit hate speech dataset with a massive number of samples has been proposed by controlling machine generation. We propose a pre-training approach, ConPrompt, to fully leverage such machine-generated data. Specifically, given a machine-generated statement, we use example statements of its origin prompt as positive samples for contrastive learning. Through pre-training with ConPrompt, we present ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection. We conduct extensive experiments on several implicit hate speech datasets and show the superior generalization ability of ToxiGen-ConPrompt compared to other pre-trained models. Additionally, we empirically show that ConPrompt is effective in mitigating identity term bias, demonstrating that it not only makes a model more generalizable but also reduces unintended bias. We analyze the representation quality of ToxiGen-ConPrompt and show its ability to consider target group and toxicity, which are desirable features in terms of implicit hate speeches. | Youngwook Kim, Shinwoo Park, Youngsoo Namgoong, YoSub Han |  |
| 865 |  |  [Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting](https://doi.org/10.18653/v1/2023.findings-emnlp.732) |  | 0 | Syntactic knowledge is invaluable information for many tasks which handle complex or long sentences, but typical pre-trained language models do not contain sufficient syntactic knowledge. Thus it results in failures in downstream tasks that require syntactic knowledge. In this paper, we explore additional training to incorporate syntactic knowledge to a language model. We designed four pre-training tasks that learn different syntactic perspectives. For adding new syntactic knowledge and keeping a good balance between the original and additional knowledge, we addressed the problem of catastrophic forgetting that prevents the model from keeping semantic information when the model learns additional syntactic knowledge. We demonstrated that additional syntactic training produced consistent performance gains while clearly avoiding catastrophic forgetting. | Ran Iwamoto, Issei Yoshida, Hiroshi Kanayama, Takuya Ohko, Masayasu Muraoka |  |
| 866 |  |  [Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?](https://doi.org/10.18653/v1/2023.findings-emnlp.733) |  | 0 | Large language models can perform downstream tasks in a zero-shot fashion, given natural language prompts that specify the desired behavior. Such prompts are typically hand engineered, but can also be learned with gradient-based methods from labeled data. However, it is underexplored what factors make the prompts effective, especially when the prompts are in natural language. In this paper, we investigate common attributes shared by effective prompts in classification problems. We first propose a human readable prompt tuning method (FluentPrompt) based on Langevin dynamics that incorporates a fluency constraint to find a distribution of effective and fluent prompts. Our analysis reveals that effective prompts are topically related to the task domain and calibrate the prior probability of output labels. Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks. | Weijia Shi, Xiaochuang Han, Hila Gonen, Ari Holtzman, Yulia Tsvetkov, Luke Zettlemoyer |  |
| 867 |  |  [Chain-of-Thought Reasoning in Tabular Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.734) |  | 0 | Tabular mathematical reasoning task requires models to perform multi-step operations including information look-up and numerical calculation, based on heterogeneous data from tables and questions. Existing solutions tend to extend chain-of-thought (CoT) reasoning into powerful large language models (LLMs) to promote multi-hop mathematical reasoning. However, such LLM-based approaches are not a viable solution in the scenario of privatization deployment or limited resources. To address this problem, we revisit small-scale tabular language models (TaLMs) and extend chain-of-thought reasoning into TaLMs for the first time. Specifically, we propose a novel framework, TaCo, which coordinates two TaLMs responsible for CoT generation and answer inference, respectively. Besides, our framework can be combined with an external calculator to enhance accurate numerical calculation. On the TABMWP dataset, TaCo outperforms the state-of-the-art ChatGPT by 9.55% (82.60%→92.15% in accuracy) with much less parameters (0.8B). The code will be released along with the paper. | Mingyu Zheng, Hao Yang, Wenbin Jiang, Zheng Lin, Yajuan Lyu, Qiaoqiao She, Weiping Wang |  |
| 868 |  |  [Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.735) |  | 0 | Query-Focused Summarization (QFS) aims to generate summaries from source documents that can answer specific queries. Although the QFS task has gained increasing attention recently, its development is constrained by the fact that mainstream QFS models are BART variants, which are autoregressive and suffer from long-term dependencies and exposure bias. To address these problems, we adopt a diffusion language model that performs well in non-autoregressive scenarios to effectively resolve issues related to autoregressive methods. However, QFS requires guidance from queries to generate adequate summaries, while diffusion language models have limited sensitivity to queries. In this paper, we propose QFS-DLM, a non-autoregressive diffusion language model that incorporates query-document fragment relevance and query-document global relevance to enhance the adaptability of QFS tasks. Firstly, we extract key fragments from documents based on queries and assign higher weights to them, thereby emphasizing crucial and continuous information within the document. Secondly, we calculate global relevance scores between queries and documents, and then integrate these scores into the model’s loss function, enabling the model to prefer high-quality data and distance itself from low-quality data. Overall, our method achieves state-of-the-art performance on Debatepedia and PubMedQA datasets in ROUGE scores, GPT-4, and human evaluations. | Shaoyao Huang, Luozheng Qin, Ziqiang Cao |  |
| 869 |  |  [Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding](https://doi.org/10.18653/v1/2023.findings-emnlp.736) |  | 0 | Grounding has been argued to be a crucial component towards the development of more complete and truly semantically competent artificial intelligence systems. Literature has divided into two camps: While some argue that grounding allows for qualitatively different generalizations, others believe it can be compensated by mono-modal data quantity. Limited empirical evidence has emerged for or against either position, which we argue is due to the methodological challenges that come with studying grounding and its effects on NLP systems. In this paper, we establish a methodological framework for studying what the effects are—if any—of providing models with richer input sources than text-only. The crux of it lies in the construction of comparable samples of populations of models trained on different input modalities, so that we can tease apart the qualitative effects of different input sources from quantifiable model performances. Experiments using this framework reveal qualitative differences in model behavior between cross-modally grounded, cross-lingually grounded, and ungrounded models, which we measure both at a global dataset level as well as for specific word representations, depending on how concrete their semantics is. | Timothee Mickus, Elaine Zosa, Denis Paperno |  |
| 870 |  |  [EMO-KNOW: A Large Scale Dataset on Emotion-Cause](https://doi.org/10.18653/v1/2023.findings-emnlp.737) |  | 0 | Emotion-Cause analysis has attracted the attention of researchers in recent years. However, most existing datasets are limited in size and number of emotion categories. They often focus on extracting parts of the document that contain the emotion cause and fail to provide more abstractive, generalizable root cause. To bridge this gap, we introduce a large-scale dataset of emotion causes, derived from 9.8 million cleaned tweets over 15 years. We describe our curation process, which includes a comprehensive pipeline for data gathering, cleaning, labeling, and validation, ensuring the dataset’s reliability and richness. We extract emotion labels and provide abstractive summarization of the events causing emotions. The final dataset comprises over 700,000 tweets with corresponding emotion-cause pairs spanning 48 emotion classes, validated by human evaluators. The novelty of our dataset stems from its broad spectrum of emotion classes and the abstractive emotion cause that facilitates the development of an emotion-cause knowledge graph for nuanced reasoning. Our dataset will enable the design of emotion-aware systems that account for the diverse emotional responses of different people for the same event. | Mia Huong Nguyen, Yasith Samaradivakara, Prasanth Sasikumar, Chitralekha Gupta, Suranga Nanayakkara |  |
| 871 |  |  [Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.738) |  | 0 | Parameter-shared pre-trained language models (PLMs) have emerged as a successful approach in resource-constrained environments, enabling substantial reductions in model storage and memory costs without significant performance compromise. However, it is important to note that parameter sharing does not alleviate computational burdens associated with inference, thus impeding its practicality in situations characterized by limited stringent latency requirements or computational resources. Building upon neural ordinary differential equations (ODEs), we introduce a straightforward technique to enhance the inference efficiency of parameter-shared PLMs. Additionally, we propose a simple pre-training technique that leads to fully or partially shared models capable of achieving even greater inference acceleration. The experimental results demonstrate the effectiveness of our methods on both autoregressive and autoencoding PLMs, providing novel insights into more efficient utilization of parameter-shared models in resource-constrained settings. | Weize Chen, Xiaoyue Xu, Xu Han, Yankai Lin, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou |  |
| 872 |  |  [Natural Response Generation for Chinese Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.739) |  | 0 | Machine reading comprehension (MRC) is an important area of conversation agents and draws a lot of attention. However, there is a notable limitation to current MRC benchmarks: The labeled answers are mostly either spans extracted from the target corpus or the choices of the given candidates, ignoring the natural aspect of high-quality responses. As a result, MRC models trained on these datasets can not generate human-like responses in real QA scenarios. To this end, we construct a new dataset called Penguin to promote the research of MRC, providing a training and test bed for natural response generation to real scenarios. Concretely, Penguin consists of 200k training data with high-quality fluent, and well-informed responses. Penguin is the first benchmark towards natural response generation in Chinese MRC on a relatively large scale. To address the challenges in Penguin, we develop two strong baselines: end-to-end and two-stage frameworks. Following that, we further design Prompt-BART: fine-tuning the pre-trained generative language models with a mixture of prefix prompts in Penguin. Extensive experiments validated the effectiveness of this design. | Nuo Chen, Hongguang Li, Yinan Bao, Baoyuan Wang, Jia Li |  |
| 873 |  |  [Treepiece: Faster Semantic Parsing via Tree Tokenization](https://doi.org/10.18653/v1/2023.findings-emnlp.740) |  | 0 | Autoregressive (AR) encoder-decoder neural networks have proved successful in many NLP problems, including Semantic Parsing – a task that translates natural language to machine-readable parse trees. However, the sequential prediction process of AR models can be slow. To accelerate AR for semantic parsing, we introduce a new technique called TreePiece that tokenizes a parse tree into subtrees and generates one subtree per decoding step. On TOPv2 benchmark, TreePiece shows 4.6 times faster decoding speed than standard AR, and comparable speed but significantly higher accuracy compared to Non-Autoregressive (NAR). | Sid Wang, Akshat Shrivastava, Aleksandr Livshits |  |
| 874 |  |  [Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking](https://doi.org/10.18653/v1/2023.findings-emnlp.741) |  | 0 | Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring and annotating task-oriented dialogues, which can be time-consuming and costly. However, DST extends beyond simple slot-filling and requires effective updating strategies for tracking dialogue state as conversations progress. In this paper, we propose ParsingDST, a new In-Context Learning (ICL) method, to introduce additional intricate updating strategies in zero-shot DST. Our approach reformulates the DST task by leveraging powerful Large Language Models (LLMs) and translating the original dialogue text to JSON through semantic parsing as an intermediate state. We also design a novel framework that includes more modules to ensure the effectiveness of updating strategies in the text-to-JSON process. Experimental results demonstrate that our approach outperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant improvements in Joint Goal Accuracy (JGA) and slot accuracy compared to existing ICL methods. | Yuxiang Wu, Guanting Dong, Weiran Xu |  |
| 875 |  |  [Mitigating Framing Bias with Polarity Minimization Loss](https://doi.org/10.18653/v1/2023.findings-emnlp.742) |  | 0 | Framing bias plays a significant role in exacerbating political polarization by distorting the perception of actual events. Media outlets with divergent political stances often use polarized language in their reporting of the same event. We propose a new loss function that encourages the model to minimize the polarity difference between the polarized input articles to reduce framing bias. Specifically, our loss is designed to jointly optimize the model to map polarity ends bidirectionally. Our experimental results demonstrate that incorporating the proposed polarity minimization loss leads to a substantial reduction in framing bias when compared to a BART-based multi-document summarization model. Notably, we find that the effectiveness of this approach is most pronounced when the model is trained to minimize the polarity loss associated with informational framing bias (i.e., skewed selection of information to report). | Yejin Bang, Nayeon Lee, Pascale Fung |  |
| 876 |  |  [Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation](https://doi.org/10.18653/v1/2023.findings-emnlp.743) |  | 0 | Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT’s causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT’s upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit causality rather than implicit causality, and performs better in sentences with lower event density and smaller lexical distance between events. | Jinglong Gao, Xiao Ding, Bing Qin, Ting Liu |  |
| 877 |  |  [Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.744) |  | 0 | Large language models (LLMs) are a promising avenue for machine translation (MT). However, current LLM-based MT systems are brittle: their effectiveness highly depends on the choice of few-shot examples and they often require extra post-processing due to overgeneration. Alternatives such as finetuning on translation instructions are computationally expensive and may weaken in-context learning capabilities, due to overspecialization. In this paper, we provide a closer look at this problem. We start by showing that adapter-based finetuning with LoRA matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50. This method also outperforms few-shot prompting and eliminates the need for post-processing or in-context examples. However, we show that finetuning generally degrades few-shot performance, hindering adaptation capabilities. Finally, to obtain the best of both worlds, we propose a simple approach that incorporates few-shot examples during finetuning. Experiments on 10 language pairs show that our proposed approach recovers the original few-shot capabilities while keeping the added benefits of finetuning. | Duarte M. Alves, Nuno Miguel Guerreiro, João Alves, José Pombal, Ricardo Rei, José Guilherme Camargo de Souza, Pierre Colombo, André F. T. Martins |  |
| 878 |  |  [How Many Demonstrations Do You Need for In-context Learning?](https://doi.org/10.18653/v1/2023.findings-emnlp.745) |  | 0 | Large language models (LLMs) are capable to perform complex reasoning by in-context learning (ICL) when provided with a few input-output demonstrations (demos) and more powerful when intermediate reasoning steps (chain of thoughts (CoT)) of the demos are given. Is it necessary to use multi-demo in ICL? In this paper, we study ICL using fewer demos for each test query on the tasks in (Wei et al., 2022). Surprisingly, we do not observe significant degradation when using only one randomly chosen demo. To study this phenomenon, for each test query, we categorize demos into “positive demos” leading to the correct answer, and “negative demos” resulting in wrong answers. Our analysis reveals an inherent bias in those widely studied datasets and the redundancy of demos: most demos are positive for a majority of test queries, which explains the good performance of ICL with one random demo. Moreover, ICL (with and w/o CoT) using only one positive demo significantly outperforms multi-demo ICL adopted by most previous works, indicating the weakness of LLMs in finding positive demo(s) for input queries, which is difficult to evaluate on the biased datasets. Furthermore, we observe a counterintuitive behavior of ICL using multi-demo, i.e., its accuracy degrades(improves) when given more positive(negative) demos. This implies that ICL can be easily misguided by interference among demos and their spurious correlations. Our analyses highlight several fundamental challenges that need to be addressed in LLMs training, ICL, and benchmark design. | Jiuhai Chen, Lichang Chen, Chen Zhu, Tianyi Zhou |  |
| 879 |  |  [Improving word mover's distance by leveraging self-attention matrix](https://doi.org/10.18653/v1/2023.findings-emnlp.746) |  | 0 | Measuring the semantic similarity between two sentences is still an important task. The word mover’s distance (WMD) computes the similarity via the optimal alignment between the sets of word embeddings. However, WMD does not utilize word order, making it challenging to distinguish sentences with significant overlaps of similar words, even if they are semantically very different. Here, we attempt to improve WMD by incorporating the sentence structure represented by BERT’s self-attention matrix (SAM). The proposed method is based on the Fused Gromov-Wasserstein distance, which simultaneously considers the similarity of the word embedding and the SAM for calculating the optimal transport between two sentences. Experiments demonstrate the proposed method enhances WMD and its variants in paraphrase identification with near-equivalent performance in semantic textual similarity. | Hiroaki Yamagiwa, Sho Yokoi, Hidetoshi Shimodaira |  |
| 880 |  |  [Improving Span Representation by Efficient Span-Level Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.747) |  | 0 | High-quality span representations are crucial to natural language processing tasks involving span prediction and classification. Most existing methods derive a span representation by aggregation of token representations within the span. In contrast, we aim to improve span representations by considering span-span interactions as well as more comprehensive span-token interactions. Specifically, we introduce layers of span-level attention on top of a normal token-level transformer encoder. Given that attention between all span pairs results in O(n4) complexity (n being the sentence length) and not all span interactions are intuitively meaningful, we restrict the range of spans that a given span could attend to, thereby reducing overall complexity to O(n3). We conduct experiments on various span-related tasks and show superior performance of our model surpassing baseline models. Our code is publicly available at https://github.com/jipy0222/Span-Level-Attention. | Pengyu Ji, Songlin Yang, Kewei Tu |  |
| 881 |  |  [Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.748) |  | 0 | Deception and persuasion play a critical role in long-horizon dialogues between multiple parties, especially when the interests, goals, and motivations of the participants are not aligned. Such complex tasks pose challenges for current Large Language Models (LLM) as deception and persuasion can easily mislead them, especially in long-horizon multi-party dialogues. To this end, we explore the game of Avalon: The Resistance, a social deduction game in which players must determine each other’s hidden identities to complete their team’s objective. We introduce an online testbed and a dataset containing 20 carefully collected and labeled games among human players that exhibit long-horizon deception in a cooperative-competitive setting. We discuss the capabilities of LLMs to utilize deceptive long-horizon conversations between six human players to determine each player’s goal and motivation. Particularly, we discuss the multimodal integration of the chat between the players and the game’s state that grounds the conversation, providing further insights into the true player identities. We find that even current state-of-the-art LLMs do not reach human performance, making our dataset a compelling benchmark to investigate the decision-making and language-processing capabilities of LLMs. Our dataset and online testbed can be found at our project website: https://sstepput.github.io/Avalon-NLU/ | Simon Stepputtis, Joseph Campbell, Yaqi Xie, Zhengyang Qi, Wenxin Sharon Zhang, Ruiyi Wang, Sanketh Rangreji, Charles Lewis, Katia P. Sycara |  |
| 882 |  |  [Improving Sequential Model Editing with Fact Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.749) |  | 0 | The task of sequential model editing is to fix erroneous knowledge in Pre-trained Language Models (PLMs) efficiently, precisely and continuously. Although existing methods can deal with a small number of modifications, these methods experience a performance decline or require additional annotated data, when the number of edits increases. In this paper, we propose a Retrieval Augmented Sequential Model Editing framework (RASE) that leverages factual information to enhance editing generalization and to guide the identification of edits by retrieving related facts from the fact-patch memory we constructed. Our main findings are: (i) State-of-the-art models can hardly correct massive mistakes stably and efficiently; (ii) Even if we scale up to thousands of edits, RASE can significantly enhance editing generalization and maintain consistent performance and efficiency; (iii) RASE can edit large-scale PLMs and increase the performance of different editors. Moreover, it can integrate with ChatGPT and further improve performance. Our code and data are available at: https://github.com/sev777/RASE. | Xiaoqi Han, Ru Li, Hongye Tan, Yuanlong Wang, Qinghua Chai, Jeff Z. Pan |  |
| 883 |  |  [Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison](https://doi.org/10.18653/v1/2023.findings-emnlp.750) |  | 0 | The success of ChatGPT has ignited an AI race, with researchers striving to develop new large language models (LLMs) that can match or surpass the language understanding and generation abilities of commercial ones. In recent times, a number of models have emerged, claiming performance near that of GPT-3.5 or GPT-4 through various instruction-tuning methods. As practitioners of Text-to-SQL parsing, we are grateful for their valuable contributions to open-source research. However, it is important to approach these claims with a sense of scrutiny and ascertain the actual effectiveness of these models. Therefore, we pit six popular large language models against each other, systematically evaluating their Text-to-SQL parsing capability on nine benchmark datasets with five different prompting strategies, covering both zero-shot and few-shot scenarios. Regrettably, the open-sourced models fell significantly short of the performance achieved by closed-source models like GPT-3.5, highlighting the need for further work to bridge the performance gap between these models. | Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin Chen, Jian Su |  |
| 884 |  |  [KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model](https://doi.org/10.18653/v1/2023.findings-emnlp.751) |  | 0 | Most biomedical pretrained language models are monolingual and cannot handle the growing cross-lingual requirements. The scarcity of non-English domain corpora, not to mention parallel data, poses a significant hurdle in training multilingual biomedical models. Since knowledge forms the core of domain-specific corpora and can be translated into various languages accurately, we propose a model called KBioXLM, which transforms the multilingual pretrained model XLM-R into the biomedical domain using a knowledge-anchored approach. We achieve a biomedical multilingual corpus by incorporating three granularity knowledge alignments (entity, fact, and passage levels) into monolingual corpora. Then we design three corresponding training tasks (entity masking, relation masking, and passage relation prediction) and continue training on top of the XLM-R model to enhance its domain cross-lingual ability. To validate the effectiveness of our model, we translate the English benchmarks of multiple tasks into Chinese. Experimental results demonstrate that our model significantly outperforms monolingual and multilingual pretrained models in cross-lingual zero-shot and few-shot scenarios, achieving improvements of up to 10+ points. | Lei Geng, Xu Yan, Ziqiang Cao, Juntao Li, Wenjie Li, Sujian Li, Xinjie Zhou, Yang Yang, Jun Zhang |  |
| 885 |  |  [Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?](https://doi.org/10.18653/v1/2023.findings-emnlp.752) |  | 0 | An important assumption that comes with using LLMs on psycholinguistic data has gone unverified. LLM-based predictions are based on subword tokenization, not decomposition of words into morphemes. Does that matter? We carefully test this by comparing surprisal estimates using orthographic, morphological, and BPE tokenization against reading time data. Our results replicate previous findings and provide evidence that \*in the aggregate\*, predictions using BPE tokenization do not suffer relative to morphological and orthographic segmentation. However, a finer-grained analysis points to potential issues with relying on BPE-based tokenization, as well as providing promising results involving morphologically-aware surprisal estimates and suggesting a new method for evaluating morphological prediction. | Sathvik Nair, Philip Resnik |  |
| 886 |  |  [A Zero-Shot Language Agent for Computer Control with Structured Reflection](https://doi.org/10.18653/v1/2023.findings-emnlp.753) |  | 0 | Large language models (LLMs) have shown increasing capacity at planning and executing a high-level goal in a live computer environment (e.g. MiniWoB++). To perform a task, recent works often require a model to learn from trace examples of the task via either supervised learning or few/many-shot prompting. Without these trace examples, it remains a challenge how an agent can autonomously learn and improve its control on a computer, which limits the ability of an agent to perform a new task. We approach this problem with a zero-shot agent that requires no given expert traces. Our agent plans for executable actions on a partially observed environment, and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management. On the easy tasks of MiniWoB++, we show that our zero-shot agent often outperforms recent SoTAs, with more efficient reasoning. For tasks with more complexity, our reflective agent performs on par with prior best models, even though previous works had the advantages of accessing expert traces or additional screen information. | Tao Li, Gang Li, Zhiwei Deng, Bryan Wang, Yang Li |  |
| 887 |  |  [SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF](https://doi.org/10.18653/v1/2023.findings-emnlp.754) |  | 0 | Model alignment with human preferences is an essential step in making Large Language Models (LLMs) helpful and consistent with human values. It typically consists of supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) stages. However, RLHF faces inherent limitations stemming from a complex training setup and its tendency to align the model with implicit values that end users cannot control at run-time. Moreover, reward models in RLHF stage commonly rely on single-dimensional feedback as opposed to explicit, multifaceted signals that indicate attributes such as helpfulness, humor, and toxicity. To address these limitations, we propose SteerLM, a supervised fine-tuning method that empowers end-users to control responses during inference. SteerLM conditions responses to conform to an explicitly defined multi-dimensional set of attributes, thereby empowering a steerable AI capable of generating helpful and high-quality responses while maintaining customizability. Experiments show that SteerLM trained on open source datasets generates responses that are preferred by human and automatic evaluators to many state-of-the-art baselines trained with RLHF while being much easier to train. Try SteerLM at https://huggingface.co/nvidia/SteerLM-llama2-13B | Yi Dong, Zhilin Wang, Makesh Narsimhan Sreedhar, Xianchao Wu, Oleksii Kuchaiev |  |
| 888 |  |  [IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.755) |  | 0 | The field of vision-and-language (VL) understanding has made unprecedented progress with end-to-end large pre-trained VL models (VLMs). However, they still fall short in zero-shot reasoning tasks that require multi-step inferencing. To achieve this goal, previous works resort to a divide-and-conquer pipeline. In this paper, we argue that previous efforts have several inherent shortcomings: 1) They rely on domain-specific sub-question decomposing models. 2) They force models to predict the final answer even if the sub-questions or sub-answers provide insufficient information. We address these limitations via IdealGPT, a framework that iteratively decomposes VL reasoning using large language models (LLMs). Specifically, IdealGPT utilizes an LLM to generate sub-questions, a VLM to provide corresponding sub-answers, and another LLM to reason to achieve the final answer. These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question. We evaluate IdealGPT on multiple challenging VL reasoning tasks under a zero-shot setting. In particular, our IdealGPT outperforms the best existing GPT-4-like models by an absolute 10% on VCR and 15% on SNLI-VE. Code is available at https://github.com/Hxyou/IdealGPT. | Haoxuan You, Rui Sun, Zhecan Wang, Long Chen, Gengyu Wang, Hammad A. Ayyubi, KaiWei Chang, ShihFu Chang |  |
| 889 |  |  [GRI: Graph-based Relative Isomorphism of Word Embedding Spaces](https://doi.org/10.18653/v1/2023.findings-emnlp.756) |  | 0 | Automated construction of bi-lingual dictionaries using monolingual embedding spaces is a core challenge in machine translation. The end performance of these dictionaries relies on the geometric similarity of individual spaces, i.e., their degree of isomorphism. Existing attempts aimed at controlling the relative isomorphism of different spaces fail to incorporate the impact of lexically different but semantically related words in the training objective. To address this, we propose GRI that combines the distributional training objectives with attentive graph convolutions to unanimously consider the impact of lexical variations of semantically similar words required to define/compute the relative isomorphism of multiple spaces. Exper imental evaluation shows that GRI outperforms the existing research by improving the average P@1 by a relative score of upto 63.6%. | Muhammad Asif Ali, Yan Hu, Jianbin Qin, Di Wang |  |
| 890 |  |  [PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.757) |  | 0 | We introduce PersonaLM - Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation to improve language modeling for Automatic Speech Recognition (ASR) personalization. PersonaLM leverages contextually similar n-gram word frequencies for recognizing rare word patterns associated with unseen domains. It aggregates the next-word probability distribution based on the relative importance of different domains to the input query. To achieve this, we propose a Span Aggregated Group-Contrastive Neural (SCAN) retriever that learns to rank external domains/users by utilizing a group-wise contrastive span loss that pulls together span representations belonging to the same group while pushing away spans from unrelated groups in the semantic space. We propose ASAP benchmark for ASR LM personalization that consists of three user-specific speech-to-text tasks for meetings, TED talks, and financial earnings calls. Extensive experiments show that PersonaLM significantly outperforms strong baselines with a 10-16% improvement in perplexity and a 5-8% reduction in Word Error Rates on popular Wikitext-103, UserLibri, and our ASAP dataset. We further demonstrate the usefulness of the SCAN retriever for improving user-personalized text generation and classification by retrieving relevant context for zero-shot prompting and few-shot fine-tuning of LLMs by 7-12% on the LAMP benchmark. | Puneet Mathur, Zhe Liu, Ke Li, Yingyi Ma, Gil Keren, Zeeshan Ahmed, Dinesh Manocha, Xuedong Zhang |  |
| 891 |  |  [Scaling Vision-Language Models with Sparse Mixture of Experts](https://doi.org/10.18653/v1/2023.findings-emnlp.758) |  | 0 | The field of natural language processing (NLP) has made significant strides in recent years, particularly in the development of large-scale vision-language models (VLMs). These models aim to bridge the gap between text and visual information, enabling a more comprehensive understanding of multimedia data. However, as these models become larger and more complex, they also become more challenging to train and deploy. One approach to addressing this challenge is the use of sparsely-gated mixture-of-experts (MoE) techniques, which divide the model into smaller, specialized sub-models that can jointly solve a task. In this paper, we explore the effectiveness of MoE in scaling vision-language models, demonstrating its potential to achieve state-of-the-art performance on a range of benchmarks over dense models of equivalent computational cost. Our research offers valuable insights into stabilizing the training of MoE models, understanding the impact of MoE on model interpretability, and balancing the trade-offs between compute performance when scaling VLMs. We hope our work will inspire further research into the use of MoE for scaling large-scale vision-language models and other multimodal machine learning applications. | Sheng Shen, Zhewei Yao, Chunyuan Li, Trevor Darrell, Kurt Keutzer, Yuxiong He |  |
| 892 |  |  [Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.759) |  | 0 | Aspect-based sentiment analysis (ABSA) has been widely studied since the explosive growth of social networking services. However, the recognition of implicit sentiments that do not contain obvious opinion words remains less explored. In this paper, we propose aspect-category enhanced learning with a neural coherence model (ELCoM). It captures document-level coherence by using contrastive learning, and sentence-level by a hypergraph to mine opinions from explicit sentences to aid implicit sentiment classification. To address the issue of sentences with different sentiment polarities in the same category, we perform cross-category enhancement to offset the impact of anomalous nodes in the hypergraph and obtain sentence representations with enhanced aspect-category. Extensive experiments on benchmark datasets show that the ELCoM achieves state-of-the-art performance. Our source codes and data are released at https://github.com/cuijin-23/ELCoM. | Jin Cui, Fumiyo Fukumoto, Xinfeng Wang, Yoshimi Suzuki, Jiyi Li, Wanzeng Kong |  |
| 893 |  |  [End-to-end Adversarial Sample Generation for Data Augmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.760) |  | 0 | Adversarial samples pose a significant challenge to neural inference models. In this paper, we propose a novel enhancing approach A3 for the robustness of the neural NLP models, which combines the adversarial training and data augmentation. We propose an adversarial sample generator that consists of a conditioned paraphrasing model and a condition generator. The latter aims to generate conditions which guides the paraphrasing model to generate adversarial samples. A pretrained discriminator is introduced to help the adversarial sample generator adapt to the data characteristics for different tasks. We adopt a weighted loss to incorporate the generated adversarial samples with the original samples for augmented training. Compared to existing methods, our approach is much efficient since the generation process is independent to the target model and the generated samples are reusable for different models. Experimental results on several tasks show that our approach improves the overall performance of the trained model. Specially, the enhanced model is robust for various attacking techniques. | Tianyuan Liu, Yuqing Sun |  |
| 894 |  |  [Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.761) |  | 0 | Complex Query Answering (CQA) is a challenge task of Knowledge Graph (KG). Due to the incompleteness of KGs, query embedding (QE) methods have been proposed to encode queries and entities into the same embedding space, and treat logical operators as neural set operators to obtain answers. However, these methods train KG embeddings and neural set operators concurrently on both simple (one-hop) and complex (multi-hop and logical) queries, which causes performance degradation on simple queries and low training efficiency. In this paper, we propose Query to Triple (Q2T), a novel approach that decouples the training for simple and complex queries. Q2T divides the training into two stages: (1) Pre-training the neural link predictor on simple queries to predict tail entities based on the head entity and relation. (2) Training the query encoder on complex queries to encode diverse complex queries into a unified triple form that can be efficiently solved by the pretrained link predictor. Our proposed Q2T is not only efficient to train, but also modular, thus easily adaptable to various neural link predictors that have been studied well. Extensive experiments demonstrate that, even without explicit modeling for neural set operators, Q2T still achieves state-of-the-art performance on diverse complex queries over three public benchmarks. | Yao Xu, Shizhu He, Cunguang Wang, Li Cai, Kang Liu, Jun Zhao |  |
| 895 |  |  [Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement](https://doi.org/10.18653/v1/2023.findings-emnlp.762) |  | 0 | To enhance the multi-step reasoning capabilities of large language models, researchers have extensively explored prompting methods, notably the Chain-of-Thought (CoT) method which explicitly elicits human-like rationales. However, they have inadvertently overlooked the potential of enhancing model reasoning performance by formulating higher-quality problems. In this work, we start from the problem side and propose Self-Polish (SP), a novel method that facilitates the model’s reasoning by guiding it to progressively refine the given problems to be more comprehensible and solvable. We also explore several automatic prompting varients and propose the Self-Polish prompt bank for the community. SP is orthogonal to all other prompting methods of answer/reasoning side like CoT, allowing for seamless integration with state-of-the-art techniques for further improvement. Thorough experiments show that the proposed method attains notable and consistent effectiveness on five reasoning benchmarks across different models. Furthermore, our method also showcases impressive performance on robustness evaluation. Codes and prompts are available at https://github.com/WooooDyy/Self-Polish. | Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Jia Liu, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 896 |  |  [Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection](https://doi.org/10.18653/v1/2023.findings-emnlp.763) |  | 0 | It is widely acknowledged that large and sparse models have higher accuracy than small and dense models under the same model size constraints. This motivates us to train a large model and then remove its redundant neurons or weights by pruning. Most existing works pruned the networks in a deterministic way, the performance of which solely depends on a single pruning criterion and thus lacks variety. Instead, in this paper, we propose a model pruning strategy that first generates several pruning masks in a designed random way. Subsequently, along with an effective mask-selection rule, the optimal mask is chosen from the pool of mask candidates. To further enhance efficiency, we introduce an early mask evaluation strategy, mitigating the overhead associated with training multiple masks. Our extensive experiments demonstrate that this approach achieves state-of-the-art performance across eight datasets from GLUE, particularly excelling at high levels of sparsity. | Jianwei Li, Weizhi Gao, Qi Lei, Dongkuan Xu |  |
| 897 |  |  [Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.764) |  | 0 | Detecting hallucinations in natural language processing (NLP) is a critical undertaking that demands a deep understanding of both the semantic and pragmatic aspects of languages. Cognitive approaches that leverage users’ behavioural signals, such as gaze, have demonstrated effectiveness in addressing NLP tasks with similar linguistic complexities. However, their potential in the context of hallucination detection remains largely unexplored. In this paper, we propose a novel cognitive approach for hallucination detection that leverages gaze signals from humans. We first collect and introduce an eye tracking corpus (IITB-HGC: IITB-Hallucination Gaze corpus) consisting of 500 instances, annotated by five annotators for hallucination detection. Our analysis reveals that humans selectively attend to relevant parts of the text based on distributional similarity, similar to the attention bias phenomenon in psychology. We identify two attention strategies employed by humans: global attention, which focuses on the most informative sentence, and local attention, which focuses on important words within a sentence. Leveraging these insights, we propose a novel cognitive framework for hallucination detection that incorporates these attention biases. Experimental evaluations on the FactCC dataset demonstrate the efficacy of our approach, obtaining a balanced accuracy of 87.1%. Our study highlights the potential of gaze-based approaches in addressing the task of hallucination detection and sheds light on the cognitive processes employed by humans in identifying inconsistencies. | Kishan Maharaj, Ashita Saxena, Raja Kumar, Abhijit Mishra, Pushpak Bhattacharyya |  |
| 898 |  |  [Noisy Pair Corrector for Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.765) |  | 0 | Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise. | Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu, Daya Guo, Jiancheng Lv, Jian Guo |  |
| 899 |  |  [Enhancing Accessible Communication: from European Portuguese to Portuguese Sign Language](https://doi.org/10.18653/v1/2023.findings-emnlp.766) |  | 0 | Portuguese Sign Language (LGP) is the official language in deaf education in Portugal. Current approaches in developing a translation system between European Portuguese and LGP rely on hand-crafted rules. In this paper, we present a fully automatic corpora-driven rule-based machine translation system between European Portuguese and LGP glosses, and also two neural machine translation models. We also contribute with the LGP-5-Domain corpus, composed of five different text domains, built with the help of our rule-based system, and used to train the neural models. In addition, we provide a gold collection, annotated by LGP experts, that can be used for future evaluations. Compared with the only similar available translation system, PE2LGP, results are always improved with the new rule-based model, which competes for the highest scores with one of the neural models. | Catarina Sousa, Luísa Coheur, Mara Moita |  |
| 900 |  |  [Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean](https://doi.org/10.18653/v1/2023.findings-emnlp.767) |  | 0 | This study investigates the extent to which currently available morpheme parsers/taggers apply to lesser-studied languages and language-usage contexts, with a focus on second language (L2) Korean. We pursue this inquiry by (1) training a neural-network model (pre-trained on first language [L1] Korean data) on varying L2 datasets and (2) measuring its morpheme parsing/POS tagging performance on L2 test sets from both the same and different sources of the L2 train sets. Results show that the L2 trained models generally excel in domain-specific tokenization and POS tagging compared to the L1 pre-trained baseline model. Interestingly, increasing the size of the L2 training data does not lead to improving model performance consistently. | Hakyung Sung, GyuHo Shin |  |
| 901 |  |  [Improving generalization in large langue model by learning prefix subspaces](https://doi.org/10.18653/v1/2023.findings-emnlp.768) |  | 0 | This article focuses on large language models (LLMs) fine-tuning in the scarce data regime (also known as “few-shot learning setting”). We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces. This optimization method, recently introduced in computer vision, aims to improve model generalization by identifying wider local optima through the joint optimization of an entire simplex of models in parameter space. Although this property would be highly beneficial in the context of training large language models in the “few-shot learning” setting, its adaptation to massive, pretrained transformers poses some challenges. First, their considerable number of parameters make it difficult to train several model jointly, and second, their deterministic parameter initialisation schemes make them unfit to the subspace method as originaly proposed. We show in this paper that its application to “Parameter Efficient Fine-Tuning” (PEFT) methods, however, is relatively natural, and we propose to apply it to prefix-tuning, by learning entire simplexes of continous prefixes. We test our method on a variant of the GLUE benchmark adapted to the few-shot learning setting, and show that both our contributions (learning prefix simplexes, and non-deterministic validation metric inference) jointly lead to a gain in average performances compared to state of the art methods. | Louis Falissard, Vincent Guigue, Laure Soulier |  |
| 902 |  |  [Domain Adaptation for Sentiment Analysis Using Robust Internal Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.769) |  | 0 | Sentiment analysis is a costly yet necessary task for enterprises to study the opinions of their customers to improve their products and to determine optimal marketing strategies. Due to the existence of a wide range of domains across different products and services, cross-domain sentiment analysis methods have received significant attention. These methods mitigate the domain gap between different applications by training cross-domain generalizable classifiers which relax the need for data annotation for each domain. We develop a domain adaptation method which induces large margins between data representations that belong to different classes in an embedding space. This embedding space is trained to be domain-agnostic by matching the data distributions across the domains. Large interclass margins in the source domain help to reduce the effect of “domain shift” in the target domain. Theoretical and empirical analysis are provided to demonstrate that the proposed method is effective. | Mohammad Rostami, Digbalay Bose, Shrikanth Narayanan, Aram Galstyan |  |
| 903 |  |  [KeFVP: Knowledge-enhanced Financial Volatility Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.770) |  | 0 | Financial volatility prediction is vital for indicating a company’s risk profile. Transcripts of companies’ earnings calls are important unstructured data sources to be utilized to access companies’ performance and risk profiles. However, current works ignore the role of financial metrics knowledge (such as EBIT, EPS, and ROI) in transcripts, which is crucial for understanding companies’ performance, and little consideration is given to integrating text and price information. In this work, we statistic common financial metrics and make a special dataset based on these metrics. Then, we introduce a knowledge-enhanced financial volatility prediction method (KeFVP) to inject knowledge of financial metrics into text comprehension by knowledge-enhanced adaptive pre-training (KePt) and effectively incorporating text and price information by introducing a conditional time series prediction module. We conduct extensive experiments on three real-world public datasets, and the results indicate that KeFVP is effective and outperforms all the state-of-the-art methods. | Hao Niu, Yun Xiong, Xiaosu Wang, Wenjing Yu, Yao Zhang, Weizu Yang |  |
| 904 |  |  [A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check](https://doi.org/10.18653/v1/2023.findings-emnlp.771) |  | 0 | In recent years, Chinese Spelling Check (CSC) has been greatly improved by designing task-specific pre-training methods or introducing auxiliary tasks, which mostly solve this task in an end-to-end fashion. In this paper, we propose to decompose the CSC workflow into detection, reasoning, and searching subtasks so that the rich external knowledge about the Chinese language can be leveraged more directly and efficiently. Specifically, we design a plug-and-play detection-and-reasoning module that is compatible with existing SOTA non-autoregressive CSC models to further boost their performance. We find that the detection-and-reasoning module trained for one model can also benefit other models. We also study the primary interpretability provided by the task decomposition. Extensive experiments and detailed analyses demonstrate the effectiveness and competitiveness of the proposed module. | Haojing Huang, Jingheng Ye, Qingyu Zhou, Yinghui Li, Yangning Li, Feng Zhou, HaiTao Zheng |  |
| 905 |  |  [Asking Clarification Questions to Handle Ambiguity in Open-Domain QA](https://doi.org/10.18653/v1/2023.findings-emnlp.772) |  | 0 | Ambiguous questions persist in open-domain question answering, because formulating a precise question with a unique answer is often challenging. Previous works have tackled this issue by asking disambiguated questions for all possible interpretations of the ambiguous question. Instead, we propose to ask a clarification question, where the user’s response will help identify the interpretation that best aligns with the user’s intention. We first present CAmbigNQ, a dataset consisting of 5,653 ambiguous questions, each with relevant passages, possible answers, and a clarification question. The clarification questions were efficiently created by generating them using InstructGPT and manually revising them as necessary. We then define a pipeline of three tasks—(1) ambiguity detection, (2) clarification question generation, and (3) clarification-based QA. In the process, we adopt or design appropriate evaluation metrics to facilitate sound research. Lastly, we achieve F1 of 61.3, 25.1, and 40.5 on the three tasks, demonstrating the need for further improvements while providing competitive baselines for future work. | Dongryeol Lee, Segwang Kim, Minwoo Lee, Hwanhee Lee, Joonsuk Park, SangWoo Lee, Kyomin Jung |  |
| 906 |  |  [Addressing the Length Bias Challenge in Document-Level Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.773) |  | 0 | Document-level neural machine translation (DNMT) has shown promising results by incorporating context information through increased maximum lengths of source and target sentences. However, this approach also introduces a length bias problem, whereby DNMT suffers from significant translation quality degradation when decoding sentences that are much shorter or longer than the maximum sentence length during training, i.e., the length bias problem. To prevent the model from neglecting shorter sentences, we sample the training data to ensure a more uniform distribution across different sentence lengths while progressively increasing the maximum sentence length during training. Additionally, we introduce a length-normalized attention mechanism to aid the model in focusing on target information, mitigating the issue of attention divergence when processing longer sentences. Furthermore, during the decoding stage of DNMT, we propose a sliding decoding strategy that limits the length of target sentences to not exceed the maximum length encountered during training. The experimental results indicate that our method can achieve state-of-the-art results on several open datasets, and further analysis shows that our method can significantly alleviate the length bias problem. | Zhuocheng Zhang, Shuhao Gu, Min Zhang, Yang Feng |  |
| 907 |  |  [EconBERTa: Towards Robust Extraction of Named Entities in Economics](https://doi.org/10.18653/v1/2023.findings-emnlp.774) |  | 0 | Adapting general-purpose language models has proven to be effective in tackling downstream tasks within specific domains. In this paper, we address the task of extracting entities from the economics literature on impact evaluation. To this end, we release EconBERTa, a large language model pretrained on scientific publications in economics, and ECON-IE, a new expert-annotated dataset of economics abstracts for Named Entity Recognition (NER). We find that EconBERTa reaches state-of-the-art performance on our downstream NER task. Additionally, we extensively analyze the model’s generalization capacities, finding that most errors correspond to detecting only a subspan of an entity or failure to extrapolate to longer sequences. This limitation is primarily due to an inability to detect part-of-speech sequences unseen during training, and this effect diminishes when the number of unique instances in the training set increases. Examining the generalization abilities of domain-specific language models paves the way towards improving the robustness of NER models for causal knowledge extraction. | Karim Lasri, Pedro Vitor Quinta de Castro, Mona Schirmer, Luis Eduardo San Martin, Linxi Wang, Tomás Dulka, Haaya Naushan, John PouguéBiyong, Arianna Legovini, Samuel Fraiberger |  |
| 908 |  |  [Consonant is all you need: a compact representation of English text for efficient NLP](https://doi.org/10.18653/v1/2023.findings-emnlp.775) |  | 0 | In natural language processing (NLP), the representation of text plays a crucial role in various tasks such as language modeling, sentiment analysis, and machine translation. The standard approach is to represent text in the same way as we, as humans, read and write. In this paper, we propose a novel approach to represent text with only consonants which presents a compact representation of English text that offers improved efficiency without sacrificing performance. We exploit the fact that consonants are more discriminative than vowels and by representing text using consonants, we can significantly reduce the overall memory and compute footprint required for storing and processing textual data. We present two alternative representations: ‘consonants-only’, where we completely remove the vowels from the text, and ‘masked-vowels’, where we mask all the vowels into one special symbol. To evaluate our approaches, we conducted experiments on various NLP tasks, including text classification, part-of-speech (POS) tagging, named-entity recognition (NER), and neural machine translation (NMT), in addition to language modeling. Our results demonstrate that the proposed consonant-based representation achieves comparable performance compared to the standard text representation while requiring significantly fewer computational resources. Furthermore, we show that our representation can be seamlessly integrated with existing NLP models and frameworks, providing a practical solution for efficient text processing. Last but not the least, we present a technique to retrieve the vowel information from our processed text representation keeping in mind the need to reproduce text in human readable form in some NLP applications. | Maged Saeed AlShaibani, Irfan Ahmad |  |
| 909 |  |  [Detrimental Contexts in Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.776) |  | 0 | For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model’s end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the detrimental passages. First, even with the correct context, the model can make an incorrect prediction, posing a challenge in determining which passages are most influential. Second, evaluation typically considers lexical matching, which is not robust to variations of correct answers. Despite these limitations, our experimental results underscore the pivotal role of identifying and removing these detrimental passages for the context-efficient retrieve-then-read pipeline. | Philhoon Oh, James Thorne |  |
| 910 |  |  [PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India](https://doi.org/10.18653/v1/2023.findings-emnlp.777) |  | 0 | This paper introduces PMIndiaSum, a multilingual and massively parallel summarization corpus focused on languages in India. Our corpus provides a training and testing ground for four language families, 14 languages, and the largest to date with 196 language pairs. We detail our construction workflow including data acquisition, processing, and quality assurance. Furthermore, we publish benchmarks for monolingual, cross-lingual, and multilingual summarization by fine-tuning, prompting, as well as translate-and-summarize. Experimental results confirm the crucial role of our data in aiding summarization between Indian languages. Our dataset is publicly available and can be freely modified and re-distributed. | Ashok Urlana, Pinzhen Chen, Zheng Zhao, Shay B. Cohen, Manish Shrivastava, Barry Haddow |  |
| 911 |  |  [Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture](https://doi.org/10.18653/v1/2023.findings-emnlp.778) |  | 0 | Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as Active Learning (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts’ real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Additional ablation studies illustrate the potential of our AL architecture for transfer learning, generalizability, and integration with large language models (LLMs). While LLMs exhibit exceptional explanation-generation capabilities for relatively simple tasks, their effectiveness in complex real-world tasks warrants further in-depth study. | Bingsheng Yao, Ishan Jindal, Lucian Popa, Yannis Katsis, Sayan Ghosh, Lihong He, Yuxuan Lu, Shashank Srivastava, Yunyao Li, James A. Hendler, Dakuo Wang |  |
| 912 |  |  [Decoding Stumpers: Large Language Models vs. Human Problem-Solvers](https://doi.org/10.18653/v1/2023.findings-emnlp.779) |  | 0 | This paper investigates the problem-solving capabilities of Large Language Models (LLMs) by evaluating their performance on stumpers, unique single-step intuition problems that pose challenges for human solvers but are easily verifiable. We compare the performance of four state-of-the-art LLMs (Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our findings reveal that the new-generation LLMs excel in solving stumpers and surpass human performance. However, humans exhibit superior skills in verifying solutions to the same problems. This research enhances our understanding of LLMs’ cognitive abilities and provides insights for enhancing their problem-solving potential across various domains. | Alon Goldstein, Miriam Havin, Roi Reichart, Ariel Goldstein |  |
| 913 |  |  [Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.780) |  | 0 | Emotion Recognition in Conversation (ERC) has been widely studied due to its importance in developing emotion-aware empathetic machines. The rise of pre-trained language models (PLMs) has further pushed the limit of ERC performance. However, most recent works on ERC using PLMs are heavily data-driven, and requires fine-tuning the entire PLMs. To improve both sample and computational efficiency, we propose a derivative-free optimization method called Cross-Task Prompt Tuning (CTPT) for few-shot conversational emotion recognition. Unlike existing methods that learn independent knowledge from individual tasks, CTPT leverages sharable cross-task knowledge by exploiting external knowledge from other source tasks to improve learning performance under the few-shot setting. Moreover, CTPT only needs to optimize a vector under the low intrinsic dimensionality without gradient, which is highly parameter-efficient compared with existing approaches. Experiments on five different contextual conversation datasets demonstrate that our CTPT method has superior results on both few-shot scenarios and zero-shot transfers. | Yige Xu, Zhiwei Zeng, Zhiqi Shen |  |
| 914 |  |  [SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting](https://doi.org/10.18653/v1/2023.findings-emnlp.781) |  | 0 | Given the high-stakes nature of healthcare decision-making, we aim to improve the efficiency of human annotators rather than replacing them with fully automated solutions. We introduce a new comprehensive resource, SYMPTOMIFY, a dataset of annotated vaccine adverse reaction reports detailing individual vaccine reactions. The dataset, consisting of over 800k reports, surpasses previous datasets in size. Notably, it features reasoning-based explanations alongside background knowledge obtained via language model knowledge harvesting. We evaluate performance across various methods and learning paradigms, paving the way for future comparisons and benchmarking. | Bosung Kim, Ndapa Nakashole |  |
| 915 |  |  [TokenDrop + BucketSampler: Towards Efficient Padding-free Fine-tuning of Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.782) |  | 0 | The great success of Language Models (LMs) for various Natural Language Processing (NLP) tasks is accompanied by computational challenges during both pre-training and fine-tuning. Pre-training has attracted significant attention due to its huge computational footprint. We focus on the fine-tuning of pre-trained LMs, which is expected to be performed much more frequently as the pre-trained models are adapted to downstream tasks. During fine-tuning, the presence of variable-length input sequences necessitates the use of padding tokens when batching sequences. These padding tokens lead to ineffectual computations, adversely impacting the efficiency of fine-tuning. We also observe that LMs memorize the limited task-specific training data despite the use of known regularization methods. Based on these insights, we present TokenDrop + BucketSampler, a framework that simultaneously improves efficiency and accuracy of LM fine-tuning. BucketSampler generates batches of samples with lower variance in sequence lengths to reduce the number of padding tokens, but does so without the accompanying accuracy drop seen in previous approaches. TokenDrop is a new regularizer that prunes a random subset of insignificant tokens from each input sequence in every epoch to prevent overfitting. TokenDrop drops more tokens from the longer sequences in each batch to further reduce variance in input lengths and the need for padding. TokenDrop + BucketSampler accelerates fine-tuning on diverse downstream tasks by up to 10.61X, while also producing models that are up to 1.17% more accurate compared to conventional fine-tuning. Code is available at https://github.com/amrnag/TokenDrop-BucketSampler. . | Amrit Nagarajan, Anand Raghunathan |  |
| 916 |  |  [Unified Representation for Non-compositional and Compositional Expressions](https://doi.org/10.18653/v1/2023.findings-emnlp.783) |  | 0 | Accurate processing of non-compositional language relies on generating good representations for such expressions. In this work, we study the representation of language non-compositionality by proposing a language model, PIER+, that builds on BART and can create semantically meaningful and contextually appropriate representations for English potentially idiomatic expressions (PIEs). PIEs are characterized by their non-compositionality and contextual ambiguity in their literal and idiomatic interpretations. Via intrinsic evaluation on embedding quality and extrinsic evaluation on PIE processing and NLU tasks, we show that representations generated by PIER+ result in 33% higher homogeneity score for embedding clustering than BART, whereas 3.12% and 3.29% gains in accuracy and sequence accuracy for PIE sense classification and span detection compared to the state-of-the-art IE representation model, GIEA. These gains are achieved without sacrificing PIER+’s performance on NLU tasks (+/- 1% accuracy) compared to BART. | Ziheng Zeng, Suma Bhat |  |
| 917 |  |  [Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.784) |  | 0 | Retrieval-augmented generation models augment knowledge encoded in a language model by providing additional relevant external knowledge (context) during generation. Although it has been shown that the quantity and quality of context impact the performance of retrieval-augmented generation models during inference, limited research explores how these characteristics affect model training. This paper explores how context quantity and quality during model training affect the performance of Fusion-in-Decoder (FiD), the state-of-the-art retrieval-augmented generation model, in extractive open-domain question answering tasks. Experimental results suggest that FiD models overfit to context quality during training and show suboptimal performance when evaluated on different context quality. Through the experimental results, we also reveal FiD models trained with different context quality have different cross-attention distribution patterns. Specifically, as context quality during training increases, FiD models tend to attend more uniformly to each passage in context. Finally, based on these observations, we propose a method to mitigate overfitting to specific context quality by introducing bias to the cross-attention distribution, which we demonstrate to be effective in improving the performance of FiD models on different context quality. | Kosuke Akimoto, Kunihiro Takeoka, Masafumi Oyamada |  |
| 918 |  |  [Error Detection for Text-to-SQL Semantic Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.785) |  | 0 | Despite remarkable progress in text-to-SQL semantic parsing in recent years, the performance of existing parsers is still far from perfect. Specifically, modern text-to-SQL parsers based on deep learning are often over-confident, thus casting doubt on their trustworthiness when deployed for real use. In this paper, we propose a parser-independent error detection model for text-to-SQL semantic parsing. Using a language model of code as its bedrock, we enhance our error detection model with graph neural networks that learn structural features of both natural language questions and SQL queries. We train our model on realistic parsing errors collected from a cross-domain setting, which leads to stronger generalization ability. Experiments with three strong text-to-SQL parsers featuring different decoding mechanisms show that our approach outperforms parser-dependent uncertainty metrics. Our model could also effectively improve the performance and usability of text-to-SQL semantic parsers regardless of their architectures. | Shijie Chen, Ziru Chen, Huan Sun, Yu Su |  |
| 919 |  |  [Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy](https://doi.org/10.18653/v1/2023.findings-emnlp.786) |  | 0 | Ultra-fine entity typing (UFET) is the task of inferring the semantic types from a large set of fine-grained candidates that apply to a given entity mention. This task is especially challenging because we only have a small number of training examples for many types, even with distant supervision strategies. State-of-the-art models, therefore, have to rely on prior knowledge about the type labels in some way. In this paper, we show that the performance of existing methods can be improved using a simple technique: we use pre-trained label embeddings to cluster the labels into semantic domains and then treat these domains as additional types. We show that this strategy consistently leads to improved results as long as high-quality label embeddings are used. Furthermore, we use the label clusters as part of a simple post-processing technique, which results in further performance gains. Both strategies treat the UFET model as a black box and can thus straightforwardly be used to improve a wide range of existing models. | Na Li, Zied Bouraoui, Steven Schockaert |  |
| 920 |  |  [Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper](https://doi.org/10.18653/v1/2023.findings-emnlp.787) |  | 0 | Neutrality is difficult to achieve and, in politics, subjective. Traditional media typically adopt an editorial line that can be used by their potential readers as an indicator of the media bias. Several platforms currently rate news outlets according to their political bias. The editorial line and the ratings help readers in gathering a balanced view of news. But in the advent of instruction-following language models, tasks such as writing a newspaper article can be delegated to computers. Without imposing a biased persona, where would an AI-based news outlet lie within the bias ratings? In this work, we use the ratings of authentic news outlets to create a multilingual corpus of news with coarse stance annotations (Left and Right) along with automatically extracted topic annotations. We show that classifiers trained on this data are able to identify the editorial line of most unseen newspapers in English, German, Spanish and Catalan. We then apply the classifiers to 101 newspaper-like articles written by ChatGPT and Bard in the 4 languages at different time periods. We observe that, similarly to traditional newspapers, ChatGPT editorial line evolves with time and, being a data-driven system, the stance of the generated articles differs among languages. | Cristina EspañaBonet |  |
| 921 |  |  [Do "English" Named Entity Recognizers Work Well on Global Englishes?](https://doi.org/10.18653/v1/2023.findings-emnlp.788) |  | 0 | The vast majority of the popular English named entity recognition (NER) datasets contain American or British English data, despite the existence of many global varieties of English. As such, it is unclear whether they generalize for analyzing use of English globally. To test this, we build a newswire dataset, the Worldwide English NER Dataset, to analyze NER model performance on low-resource English variants from around the world. We test widely used NER toolkits and transformer models, including models using the pre-trained contextual models RoBERTa and ELECTRA, on three datasets: a commonly used British English newswire dataset, CoNLL 2003, a more American focused dataset OntoNotes, and our global dataset. All models trained on the CoNLL or OntoNotes datasets experienced significant performance drops—over 10 F1 in some cases—when tested on the Worldwide English dataset. Upon examination of region-specific errors, we observe the greatest performance drops for Oceania and Africa, while Asia and the Middle East had comparatively strong performance. Lastly, we find that a combined model trained on the Worldwide dataset and either CoNLL or OntoNotes lost only 1-2 F1 on both test sets. | Alexander Shan, John Bauer, Riley Carlson, Christopher D. Manning |  |
| 922 |  |  [Affective and Dynamic Beam Search for Story Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.789) |  | 0 | Storytelling’s captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies. In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives. AffGen introduces ‘intriguing twists’ in narratives by employing two novel techniques—Dynamic Beam Sizing and Affective Reranking. Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model. Affective Reranking prioritizes sentence candidates based on affect intensity. Our empirical evaluations, both automatic and human, demonstrate AffGen’s superior performance over existing baselines in generating affectively charged and interesting narratives. Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen. | Tenghao Huang, Ehsan Qasemi, Bangzheng Li, He Wang, Faeze Brahman, Muhao Chen, Snigdha Chaturvedi |  |
| 923 |  |  [Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference](https://doi.org/10.18653/v1/2023.findings-emnlp.790) |  | 0 | Clickbait posts tend to spread inaccurate or misleading information to manipulate people’s attention and emotions, which greatly harms the credibility of social media. Existing clickbait detection models rely on analyzing the objective semantics in posts or correlating posts with article content only. However, these models fail to identify and exploit the manipulation intention of clickbait from a user’s subjective perspective, leading to limited capability to explore comprehensive clues of clickbait. To address such a issue, we propose a multiview clickbait detection model, named MCDM, to model subjective and objective preferences simultaneously. MCDM introduces two novel complementary modules for modeling subjective feeling and objective content relevance, respectively. The subjective feeling module adopts a user-centric approach to capture subjective features of posts, such as language patterns and emotional inclinations. The objective module explores news elements from posts and models article content correlations to capture objective clues for clickbait detection. Extensive experimental results on two real-world datasets show that our proposed MCDM outperforms state-of-the-art approaches for clickbait detection, verifying the effectiveness of integrating subjective and objective preferences for detecting clickbait. | Chongyang Shi, Yijun Yin, Qi Zhang, Liang Xiao, Usman Naseem, Shoujin Wang, Liang Hu |  |
| 924 |  |  [Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models](https://doi.org/10.18653/v1/2023.findings-emnlp.791) |  | 0 | \*Data Synthesis\* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the \*real task\* data distribution. Thus, in this paper, we propose \*Synthesis Step by Step\* (\*\*S3\*\*), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data. | Ruida Wang, Wangchunshu Zhou, Mrinmaya Sachan |  |
| 925 |  |  [Identifying Early Maladaptive Schemas from Mental Health Question Texts](https://doi.org/10.18653/v1/2023.findings-emnlp.792) |  | 0 | In Psychotherapy, maladaptive schemas– negative perceptions that an individual has of the self, others, or the world that endure despite objective reality–often lead to resistance to treatments and relapse of mental health issues such as depression, anxiety, panic attacks etc. Identification of early maladaptive schemas (EMS) is thus a crucial step during Schema Therapy-based counseling sessions, where patients go through a detailed and lengthy EMS questionnaire. However, such an approach is not practical in ‘offline’ counseling scenarios, such as community QA forums which are gaining popularity for people seeking mental health support. In this paper, we investigate both LLM (Large Language Models) and non-LLM approaches for identifying EMS labels using resources from Schema Therapy. Our evaluation indicates that recent LLMs can be effective for identifying EMS but their predictions lack explainability and are too sensitive to precise ‘prompts’. Both LLM and non-LLM methods are unable to reliably address the null cases, i.e. cases with no EMS labels. However, we posit that the two approaches show complementary properties and together, they can be used to further devise techniques for EMS identification. | Sujatha Das Gollapalli, Beng Heng Ang, SeeKiong Ng |  |
| 926 |  |  [Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning](https://doi.org/10.18653/v1/2023.findings-emnlp.793) |  | 0 | Augmenting pretrained language models (LMs) with a vision encoder (e.g., Flamingo) has obtained state-of-the-art results in image-to-text generation. However, these models store all the knowledge within their parameters, thus often requiring enormous model parameters to model the abundant visual concepts and very rich text descriptions. Additionally, they are inefficient in incorporating new data, requiring a computational-expensive fine-tuning process. In this work, we introduce a Retrieval-augmented Visual Language Model, Re-ViLM, built upon the Flamingo, that supports retrieving the relevant knowledge from the external database for zero and in-context few-shot image-to-text generations. By storing certain knowledge explicitly in the external database, our approach reduces the number of model parameters and can easily accommodate new data during evaluation by simply updating the database. We also construct an interleaved image and text data that facilitates in-context few-shot learning capabilities.We demonstrate that Re-ViLM significantly boosts performance for image-to-text generation tasks, especially for zero-shot and few-shot generation in out-of-domain settings with 4x less parameters compared with baseline methods. | Zhuolin Yang, Wei Ping, Zihan Liu, Vijay Korthikanti, Weili Nie, DeAn Huang, Linxi Fan, Zhiding Yu, Shiyi Lan, Bo Li, Mohammad Shoeybi, MingYu Liu, Yuke Zhu, Bryan Catanzaro, Chaowei Xiao, Anima Anandkumar |  |
| 927 |  |  [Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.794) |  | 0 | Spoken Language Understanding (SLU), a crucial component of task-oriented dialogue systems, has consistently garnered attention from both academic and industrial communities. Although incorporating syntactic information into models has the potential to enhance the comprehension of user utterances and yield impressive results, its application in SLU systems remains largely unexplored. In this paper, we propose a carefully designed model termed Syntax-aware attention (SAT) to enhance SLU, where attention scopes are constrained based on relationships within the syntactic structure. Experimental results on three datasets show that our model achieves substantial improvements and excellent performance. Moreover, SAT can be integrated into other BERT-based language models to further boost their performance. | Yifeng Xie, Zhihong Zhu, Xuxin Cheng, Zhiqi Huang, Dongsheng Chen |  |
| 928 |  |  [Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate](https://doi.org/10.18653/v1/2023.findings-emnlp.795) |  | 0 | Large language models (LLMs) such as ChatGPT and GPT-4 have shown impressive performance in complex reasoning tasks. However, it is difficult to know whether the models are reasoning based on deep understandings of truth and logic, or leveraging their memorized patterns in a relatively superficial way. In this work, we explore testing LLMs’ reasoning by engaging with them in a debate-like conversation, where given a question, the LLM and the user need to discuss to make the correct decision starting from opposing arguments. Upon mitigating the Clever Hans effect, our task requires the LLM to not only achieve the correct answer on its own, but also be able to hold and defend its belief instead of blindly believing or getting misled by the user’s (invalid) arguments and critiques, thus testing in greater depth whether the LLM grasps the essence of the reasoning required to solve the problem. Across a range of complex reasoning benchmarks spanning math, commonsense, logic and BIG-Bench tasks, we find that despite their impressive performance as reported in existing work on generating correct step-by-step solutions in the beginning, LLMs like ChatGPT cannot maintain their beliefs in truth for a significant portion of examples when challenged by oftentimes absurdly invalid arguments. Our work points to danger zones of model alignment, and also suggests more careful treatments and interpretations of the recent findings that LLMs can improve their responses based on feedback. | Boshi Wang, Xiang Yue, Huan Sun |  |
| 929 |  |  [Using In-Context Learning to Improve Dialogue Safety](https://doi.org/10.18653/v1/2023.findings-emnlp.796) |  | 0 | While large neural-based conversational models have become increasingly proficient dialogue agents, recent work has highlighted safety issues with these systems. For example, these systems can be goaded into generating toxic content, often perpetuating social biases or stereotypes. We investigate a retrieval-based approach for reducing bias and toxicity in responses from chatbots. It uses in-context learning to steer a model towards safer generations. Concretely, to generate a response to an unsafe dialogue context, we retrieve demonstrations of safe responses to similar dialogue contexts. We find our method performs competitively with existing approaches to dialogue safety without requiring training. We also show, using automatic and human evaluation, that reductions in toxicity obtained using our approach are not at the cost engagingness or coherency. Finally, we note our method can be used in compliment to existing dialogue safety approaches, such as RLHF. | Nicholas Meade, Spandana Gella, Devamanyu Hazarika, Prakhar Gupta, Di Jin, Siva Reddy, Yang Liu, Dilek HakkaniTur |  |
| 930 |  |  [HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue](https://doi.org/10.18653/v1/2023.findings-emnlp.797) |  | 0 | Video-grounded Dialogue (VGD) aims to answer questions regarding a given multi-modal input comprising video, audio, and dialogue history. Although there have been numerous efforts in developing VGD systems to improve the quality of their responses, existing systems are competent only to incorporate the information in the video and text and tend to struggle in extracting the necessary information from the audio when generating appropriate responses to the question. The VGD system seems to be deaf, and thus, we coin this symptom of current systems’ ignoring audio data as a deaf response. To overcome the deaf response problem, Hearing Enhanced Audio Response (HEAR) framework is proposed to perform sensible listening by selectively attending to audio whenever the question requires it. The HEAR framework enhances the accuracy and audibility of VGD systems in a model-agnostic manner. HEAR is validated on VGD datasets (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows effectiveness with various VGD systems. | Sunjae Yoon, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, Chang Dong Yoo |  |
| 931 |  |  [Improving Consistency for Text Summarization with Energy Functions](https://doi.org/10.18653/v1/2023.findings-emnlp.798) |  | 0 | Current abstractive summarization models often generate inconsistent content, i.e. texts that are not directly inferable from the source document, are not consistent with respect to world knowledge, or are self-contradictory. These inconsistencies motivate a new consistency taxonomy that we define as faithfulness, factuality, and self-supportiveness. However, most recent work on reducing inconsistency in document summarization only focuses on faithfulness detection and correction while ignoring other inconsistency phenomena, which limits the model’s scalability. To improve the general consistency we introduce EnergySum, where we apply the Residual Energy-based Model by designing energy scorers that reflect each type of consistency. These energy scores are utilized in candidate re-ranking during the sampling process. Experiments on XSUM and CNN/DM datasets show that EnergySum mitigates the trade-off between accuracy and consistency. | Qi Zeng, Qingyu Yin, Zheng Li, Yifan Gao, Sreyashi Nag, Zhengyang Wang, Bing Yin, Heng Ji, Chao Zhang |  |
| 932 |  |  [Defining a New NLP Playground](https://doi.org/10.18653/v1/2023.findings-emnlp.799) |  | 0 | The recent explosion of performance of large language models (LLMs) has changed the field of Natural Language Processing (NLP) more abruptly and seismically than any other shift in the field’s 80 year history. This has resulted in concerns that the field will become homogenized and resource-intensive. This new status quo has put many academic researchers, especially PhD students, at a disadvantage. This paper aims to define a new NLP playground by proposing 20+ PhD-dissertation-worthy research directions, covering theoretical analysis, new and challenging problems, learning paradigms and interdisciplinary applications. | Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li, Xingyao Wang, Yi Ren Fung, Charles Yu, Joel R. Tetreault, Eduard H. Hovy, Heng Ji |  |
| 933 |  |  [UPTON: Preventing Authorship Leakage from Public Text Release via Data Poisoning](https://doi.org/10.18653/v1/2023.findings-emnlp.800) |  | 0 | Consider a scenario where an author (e.g., activist, whistle-blower) with many public writings wishes to write “anonymously” when attackers may have already built an authorship attribution (AA) model based off of public writings including those of the author. To enable her wish, we ask a question “can one make the publicly released writings, T , unattributable so that AA models trained on T cannot attribute its authorship well?” Toward this question, we present a novel solution, UPTON, that exploits black-box data poisoning methods to weaken the authorship features in training samples and make released texts unlearnable. It is different from previous obfuscation works (e.g., adversarial attacks that modify test samples or backdoor works that only change the model outputs when triggering words occur). Using four authorship datasets (IMDb10, IMDb64, Enron and WJO), we present empirical validation where UPTON successfully downgrades the accuracy of AA models to the impractical level (e.g., ~ 35%) while keeping texts still readable (e.g., > 0.9 in BERTScore). UPTON remains effective to AA models that are already trained on available clean writings of authors. | Ziyao Wang, Thai Le, Dongwon Lee |  |
| 934 |  |  [IAEval: A Comprehensive Evaluation of Instance Attribution on Natural Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.801) |  | 0 | Instance attribution (IA) aims to identify the training instances leading to the prediction of a test example, helping researchers understand the dataset better and optimize data processing. While many IA methods have been proposed recently, how to evaluate them still remains open. Previous evaluations of IA only focus on one or two dimensions and are not comprehensive. In this work, we introduce IAEval for IA methods, a systematic and comprehensive evaluation scheme covering four significant requirements: sufficiency, completeness, stability and plausibility. We elaborately design novel metrics to measure these requirements for the first time. Three representative IA methods are evaluated under IAEval on four natural language understanding datasets. Extensive experiments confirmed the effectiveness of IAEval and exhibited its ability to provide comprehensive comparison among IA methods. With IAEval, researchers can choose the most suitable IA methods for applications like model debugging. | Peijian Gu, Yaozong Shen, Lijie Wang, Quan Wang, Hua Wu, Zhendong Mao |  |
| 935 |  |  [Scene Graph Enhanced Pseudo-Labeling for Referring Expression Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.802) |  | 0 | Referring Expression Comprehension (ReC) is a task that involves localizing objects in images based on natural language expressions. Most ReC methods typically approach the task as a supervised learning problem. However, the need for costly annotations, such as clear image-text pairs or region-text pairs, hinders the scalability of existing approaches. In this work, we propose a novel scene graph-based framework that automatically generates high-quality pseudo region-query pairs. Our method harnesses scene graphs to capture the relationships between objects in images and generate expressions enriched with relation information. To ensure accurate mapping between visual regions and text, we introduce an external module that employs a calibration algorithm to filter out ambiguous queries. Additionally, we employ a rewriter module to enhance the diversity of our generated pseudo queries through rewriting. Extensive experiments demonstrate that our method outperforms previous pseudo-labeling methods by about 10%, 12%, and 11% on RefCOCO, RefCOCO+, and RefCOCOg, respectively. Furthermore, it surpasses the state-of-the-art unsupervised approach by more than 15% on the RefCOCO dataset. | Cantao Wu, Yi Cai, Liuwu Li, Jiexin Wang |  |
| 936 |  |  [Noisy Self-Training with Synthetic Queries for Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.803) |  | 0 | Although existing neural retrieval models reveal promising results when training data is abundant and the performance keeps improving as training data increases, collecting high-quality annotated data is prohibitively costly. To this end, we introduce a novel noisy self-training framework combined with synthetic queries, showing that neural retrievers can be improved in a self-evolution manner with no reliance on any external models. Experimental results show that our method improves consistently over existing methods on both general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval benchmarks. Extra analysis on low-resource settings reveals that our method is data efficient and outperforms competitive baselines, with as little as 30% of labelled training data. Further extending the framework for reranker training demonstrates that the proposed method is general and yields additional gains on tasks of diverse domains. | Fan Jiang, Tom Drummond, Trevor Cohn |  |
| 937 |  |  [Leveraging GPT-4 for Automatic Translation Post-Editing](https://doi.org/10.18653/v1/2023.findings-emnlp.804) |  | 0 | While Neural Machine Translation (NMT) represents the leading approach to Machine Translation (MT), the outputs of NMT models still require translation post-editing to rectify errors and enhance quality under critical settings. In this work, we formalize the task of direct translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs. Our results demonstrate that GPT-4 is adept at translation post-editing, producing meaningful and trustworthy edits to translations that help improve its general quality as well as remove different classes of major errors in translations. In particular, human evaluations on assessing edit trustworthiness show that GPT-4 exhibits a large improvement over the prior state-of-the-art LLM. Notably, we improve upon state-of-the-art performance on WMT-22 English-Chinese, English-German, Chinese-English and German-English language pairs using GPT-4 based post-editing, as evaluated by state-of-the-art MT quality metrics. However, we also show that GPT-4 could produce hallucinated edits, thereby urging caution in its use as an expert translation post-editor. | Vikas Raunak, Amr Sharaf, Yiren Wang, Hany Hassan Awadalla, Arul Menezes |  |
| 938 |  |  [Uniform Complexity for Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.805) |  | 0 | Large language models (LLMs) have shown promising results in a wide array of generative NLP tasks, such as summarization and machine translation. In the context of narrative generation, however, existing models still do not capture factors that contribute to producing consistent text. For instance, it is logical that a piece of text or a story should be uniformly readable throughout and that this form of complexity should be controllable. As such, if the complexity of an input text prompt is rated first-grade reading level in the Flesch Reading Ease test, then the generated text continuing the plot should also be within this range of complexity. With this in mind, we introduce Uniform Complexity for Text Generation (UCTG), a new benchmark test which raises the challenge of making generative models observe uniform linguistic properties with respect to prompts. We experiment with over 150+ linguistically and cognitively motivated features for evaluating text complexity in humans and generative models. From our results, we find that models such as GPT-2 struggle to preserve the complexity of input prompts used in its generations, even if finetuned with professionally written texts. | Joseph Marvin Imperial, Harish Tayyar Madabushi |  |
| 939 |  |  [Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.806) |  | 0 | Large Language Models (LLMs), such as ChatGPT, greatly empower dialogue systems with strong language understanding and generation capabilities. However, most of the previous works prompt the LLMs to directly generate a response based on the dialogue context, overlooking the underlying linguistic cues about the user status exhibited in the context. Such in-depth dialogue scenarios are challenging for existing LLMs to figure out the user’s hidden needs and respond satisfactorily through a single-step inference. To this end, we propose a novel linguistic cue-based chain-of-thoughts (Cue-CoT), which enhances the LLMs inference with an intermediate reasoning step to find cues exhibited in the dialogue, aiming to provide a more personalized and engaging response. To evaluate the approach, we build a benchmark with in-depth dialogue questions, consisting of 6 datasets in both Chinese and English, targeting 3 major linguistic cues during the conversation: personality, emotion, and psychology. We conducted experiments on the proposed benchmark with 5 LLMs under both zero-shot and one-shot settings. Empirical results demonstrate our proposed Cue-CoT method outperforms standard prompting methods in terms of both helpfulness and acceptability on all datasets. | Hongru Wang, Rui Wang, Fei Mi, Yang Deng, Zezhong Wang, Bin Liang, Ruifeng Xu, KamFai Wong |  |
| 940 |  |  [CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.807) |  | 0 | Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus on developing more efficient fine-tuning techniques for the task. Instead, our motivation is to come up with a generic approach that can improve the downstream performances of multiple ABSA tasks simultaneously. Towards this, we present CONTRASTE, a novel pre-training strategy using CONTRastive learning to enhance the ASTE performance. While we primarily focus on ASTE, we also demonstrate the advantage of our proposed technique on other ABSA tasks such as ACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion, sentiment) triplets, first, we design aspect-based prompts with corresponding sentiments masked. We then (pre)train an encoder-decoder model by applying contrastive learning on the decoder-generated aspect-aware sentiment representations of the masked terms. For fine-tuning the model weights thus obtained, we then propose a novel multi-task approach where the base encoder-decoder model is combined with two complementary modules, a tagging-based Opinion Term Detector, and a regression-based Triplet Count Estimator. Exhaustive experiments on four benchmark datasets and a detailed ablation study establish the importance of each of our proposed components as we achieve new state-of-the-art ASTE results. | Rajdeep Mukherjee, Nithish Kannen, Saurabh Kumar Pandey, Pawan Goyal |  |
| 941 |  |  [Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts](https://doi.org/10.18653/v1/2023.findings-emnlp.808) |  | 0 | Continual pre-training has been urgent for adapting a pre-trained model to a multitude of domains and tasks in the fast-evolving world. In practice, a continually pre-trained model is expected to demonstrate not only greater capacity when fine-tuned on pre-trained domains but also a non-decreasing performance on unseen ones. In this work, we first investigate such anytime fine-tuning effectiveness of existing continual pre-training approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. The agreement loss maximally preserves the generalization of a pre-trained model to new domains, and the disagreement one guards the exclusiveness of the generated hidden states for each domain. Remarkably, prompts by the hypernetwork alleviate the domain identity when fine-tuning and promote knowledge transfer across domains. Our method achieved improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively, demonstrating its efficacy. | Gangwei Jiang, Caigao Jiang, Siqiao Xue, James Zhang, Jun Zhou, Defu Lian, Ying Wei |  |
| 942 |  |  [Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts](https://doi.org/10.18653/v1/2023.findings-emnlp.809) |  | 0 | Visual question answering (VQA) is the task of answering questions about an image. The task assumes an understanding of both the image and the question to provide a natural language answer. VQA has gained popularity in recent years due to its potential applications in a wide range of fields, including robotics, education, and healthcare. In this paper, we focus on knowledge-augmented VQA, where answering the question requires commonsense knowledge, world knowledge, and reasoning about ideas and concepts not present in the image. We propose a multimodal framework that uses language guidance (LG) in the form of rationales, image captions, scene graphs, etc to answer questions more accurately. We benchmark our method on the multi-choice question-answering task of the A-OKVQA, Science-QA, VSR, and IconQA datasets using CLIP and BLIP models. We show that the use of language guidance is a simple but powerful and effective strategy for visual question answering. Our language guidance improves the performance of CLIP by 7.6% and BLIP-2 by 4.8% in the challenging A-OKVQA dataset. We also observe consistent improvement in performance on the Science-QA, VSR, and IconQA datasets when using the proposed language guidances. The implementation of LG-VQA is publicly available at https://github.com/declare-lab/LG-VQA. | Deepanway Ghosal, Navonil Majumder, Roy KaWei Lee, Rada Mihalcea, Soujanya Poria |  |
| 943 |  |  [XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words](https://doi.org/10.18653/v1/2023.findings-emnlp.810) |  | 0 | Due to the absence of explicit word boundaries in the speech stream, the task of segmenting spoken sentences into word units without text supervision is particularly challenging. In this work, we leverage the most recent self-supervised speech models that have proved to quickly adapt to new tasks through fine-tuning, even in low resource conditions. Taking inspiration from semi-supervised learning, we fine-tune an XLS-R model to predict word boundaries themselves produced by top-tier speech segmentation systems: DPDP, VG-HuBERT and DP-Parse. Once XLS-R is fine-tuned, it is used to infer new word boundary labels that are used in turn for another fine-tuning step. Our method consistently improves the performance of each system and set a new state-of-the-art that is, on average 130% higher than the previous one as measured by the F1 score on correctly discovered word tokens on five corpora featuring different languages. Finally, our system can segment speech from languages unseen during fine-tuning in a zero-shot fashion. | Robin Algayres, Pablo DiegoSimon, Benoît Sagot, Emmanuel Dupoux |  |
| 944 |  |  [Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data](https://doi.org/10.18653/v1/2023.findings-emnlp.811) |  | 0 | Chain-of-thought (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in complex reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt LLMs, posing challenges for real-world applications where labeled data is available without rational chains. This paper proposes a new strategy, AutomateCoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoT by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machinegenerated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where competitive results are achieved on arithmetic reasoning (+2.7%), commonsense reasoning (+3.4%), symbolic reasoning (+3.2%), and non-reasoning tasks (+2.5%). | Kashun Shum, Shizhe Diao, Tong Zhang |  |
| 945 |  |  [What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations](https://doi.org/10.18653/v1/2023.findings-emnlp.812) |  | 0 | Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios. We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a student model that produces defeasible contexts with improved validity, diversity, and defeasibility. From this model we distill a high-quality dataset, 𝛿-Rules-of-Thumb, of 1.2M entries of contextualizations and rationales for 115K defeasible moral actions rated highly by human annotators 85.9% to 99.8% of the time. Using 𝛿-RoT we obtain a final student model that wins over all intermediate student models by a notable margin. | Kavel Rao, Liwei Jiang, Valentina Pyatkin, Yuling Gu, Niket Tandon, Nouha Dziri, Faeze Brahman, Yejin Choi |  |
| 946 |  |  [An Empirical Study on Multiple Knowledge from ChatGPT for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2023.findings-emnlp.813) |  | 0 | Multiple knowledge (e.g., co-reference, topics, emotional causes, etc) has been demonstrated effective for emotion detection. However, exploring this knowledge in Emotion Recognition in Conversations (ERC) is currently a blank slate due to the lack of annotated data and the high cost involved in obtaining such knowledge. Fortunately, the emergence of Large Language Models (LLMs) holds promise in filling this void. Therefore, we propose a Multiple Knowledge Fusion Model (MKFM) to effectively integrate such knowledge generated by LLMs for ERC and empirically study its impact on the model. Experimental results on three public datasets have demonstrated the effectiveness of multiple knowledge for ERC. Furthermore, we conduct a detailed analysis of the contribution and complementarity of this knowledge. | Geng Tu, Bin Liang, Bing Qin, KamFai Wong, Ruifeng Xu |  |
| 947 |  |  [Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction](https://doi.org/10.18653/v1/2023.findings-emnlp.814) |  | 0 | Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case’s charge, applicable law article, and term of penalty. A core problem of LJP is distinguishing confusing legal cases where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, in order to exploit the numbers in legal cases for predicting the term of penalty of certain charges, we enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Second, we propose a moco-based supervised contrastive learning to learn distinguishable representations and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Extensive experiments on real-world datasets show that the proposed method achieves new state-of-the-art results, particularly for confusing legal cases. Ablation studies also demonstrate the effectiveness of each component. | Leilei Gan, Baokui Li, Kun Kuang, Yating Zhang, Lei Wang, Anh Tuan Luu, Yi Yang, Fei Wu |  |
| 948 |  |  [One For All & All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.815) |  | 0 | Multilingual language models enable zero-shot cross-lingual transfer (ZS-XLT): fine-tuned on sizable source-language task data, they perform the task in target languages without labeled instances. The effectiveness of ZS-XLT hinges on the linguistic proximity between languages and the amount of pretraining data for a language. Because of this, model selection based on source-language validation is unreliable: it picks model snapshots with suboptimal target-language performance. As a remedy, some work optimizes ZS-XLT by extensively tuning hyperparameters: the follow-up work then routinely struggles to replicate the original results. Other work searches over narrower hyperparameter grids, reporting substantially lower performance. In this work, we therefore propose an unsupervised evaluation protocol for ZS-XLT that decouples performance maximization from hyperparameter tuning. As a robust and more transparent alternative to extensive hyperparameter tuning, we propose to accumulatively average snapshots from different runs into a single model. We run broad ZS-XLT experiments on both higher-level semantic tasks (NLI, extractive QA) and a lower-level token classification task (NER) and find that conventional model selection based on source-language validation quickly plateaus to suboptimal ZS-XLT performance. On the other hand, our accumulative run-by-run averaging of models trained with different hyperparameters boosts ZS-XLT performance and closely correlates with “oracle” ZS-XLT, i.e., model selection based on target-language validation performance. | Fabian David Schmidt, Ivan Vulic, Goran Glavas |  |
| 949 |  |  [Dimensions of Online Conflict: Towards Modeling Agonism](https://doi.org/10.18653/v1/2023.findings-emnlp.816) |  | 0 | Agonism plays a vital role in democratic dialogue by fostering diverse perspectives and robust discussions. Within the realm of online conflict there is another type: hateful antagonism, which undermines constructive dialogue. Detecting conflict online is central to platform moderation and monetization. It is also vital for democratic dialogue, but only when it takes the form of agonism. To model these two types of conflict, we collected Twitter conversations related to trending controversial topics. We introduce a comprehensive annotation schema for labelling different dimensions of conflict in the conversations, such as the source of conflict, the target, and the rhetorical strategies deployed. Using this schema, we annotated approximately 4,000 conversations with multiple labels. We then train both logistic regression and transformer-based models on the dataset, incorporating context from the conversation, including the number of participants and the structure of the interactions. Results show that contextual labels are helpful in identifying conflict and make the models robust to variations in topic. Our research contributes a conceptualization of different dimensions of conflict, a richly annotated dataset, and promising results that can contribute to content moderation. | Matt Canute, Mali Jin, hannah holtzclaw, Alberto Lusoli, Philippa R. Adams, Mugdha Pandya, Maite Taboada, Diana Maynard, Wendy Hui Kyong Chun |  |
| 950 |  |  [Learning under Label Proportions for Text Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.817) |  | 0 | We present one of the preliminary NLP works under the challenging setup of Learning from Label Proportions (LLP), where the data is provided in an aggregate form called bags and only the proportion of samples in each class as the ground truth. This setup is inline with the desired characteristics of training models under Privacy settings and Weakly supervision. By characterizing some irregularities of the most widely used baseline technique DLLP, we propose a novel formulation that is also robust. This is accompanied with a learnability result that provides a generalization bound under LLP. Combining this formulation with a self-supervised objective, our method achieves better results as compared to the baselines in almost 87% of the experimental configurations which include large scale models for both long and short range texts across multiple metrics. | Jatin Chauhan, Xiaoxuan Wang, Wei Wang |  |
| 951 |  |  [MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition](https://doi.org/10.18653/v1/2023.findings-emnlp.818) |  | 0 | Humans have the ability to learn novel compositional concepts by recalling primitive concepts acquired from past experience and generalizing these primitive concepts to novel compositions. Inspired by the above human’s compositional learning procedure, in this paper, we propose MetaReVision, a retrievalenhanced meta-learning model to solve the visually grounded compositional concept learning problem. The proposed MetaReVision consists of a retrieval module and a meta-learning module which are designed to incorporate retrieved primitive concepts as supporting set to meta-train visual-language models for grounded compositional concept recognition. Through meta-learning from episodes constructed by the retriever, MetaReVision learns a generic compositional representation that can be fast updated to recognize novel composi tional concepts. We create CompCOCO and CompFlickr to benchmark the grounded compositional concept learning. Our experimental results show MetaReVision outperforms other competitive baselines and the retrieval module does plays an important role in this compositional learning process. | Guangyue Xu, Parisa Kordjamshidi, Joyce Chai |  |
| 952 |  |  [PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning](https://doi.org/10.18653/v1/2023.findings-emnlp.819) |  | 0 | Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning. This paper proposes Perturbation Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages. To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text. To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for 3,000 images in five languages. In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, while maintaining a strong correlation with human judgments. | Yongil Kim, Yerin Hwang, Hyeongu Yun, Seunghyun Yoon, Trung Bui, Kyomin Jung |  |
| 953 |  |  [Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.820) |  | 0 | Scientific literature understanding tasks have gained significant attention due to their potential to accelerate scientific discovery. Pre-trained language models (LMs) have shown effectiveness in these tasks, especially when tuned via contrastive learning. However, jointly utilizing pre-training data across multiple heterogeneous tasks (e.g., extreme multi-label paper classification, citation prediction, and literature search) remains largely unexplored. To bridge this gap, we propose a multi-task contrastive learning framework, SciMult, with a focus on facilitating common knowledge sharing across different scientific literature understanding tasks while preventing task-specific skills from interfering with each other. To be specific, we explore two techniques – task-aware specialization and instruction tuning. The former adopts a Mixture-of-Experts Transformer architecture with task-aware sub-layers; the latter prepends task-specific instructions to the input text so as to produce task-aware outputs. Extensive experiments on a comprehensive collection of benchmark datasets verify the effectiveness of our task-aware specialization strategy, where we outperform state-of-the-art scientific pre-trained LMs. Code, datasets, and pre-trained models can be found at https://scimult.github.io/. | Yu Zhang, Hao Cheng, Zhihong Shen, Xiaodong Liu, YeYi Wang, Jianfeng Gao |  |
| 954 |  |  [BLM-s/lE: A structured dataset of English spray-load verb alternations for testing generalization in LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.821) |  | 0 | Current NLP models appear to be achieving performance comparable to human capabilities on well-established benchmarks. New benchmarks are now necessary to test deeper layers of understanding of natural languages by these models. Blackbird’s Language Matrices are a recently developed framework that draws inspiration from tests of human analytic intelligence. The BLM task has revealed that successful performances in previously studied linguistic problems do not yet stem from a deep understanding of the generative factors that define these problems. In this study, we define a new BLM task for predicate-argument structure, and develop a structured dataset for its investigation, concentrating on the spray-load verb alternations in English, as a case study. The context sentences include one alternant from the spray-load alternation and the target sentence is the other alternant, to be chosen among a minimally contrastive and adversarial set of answers. We describe the generation process of the dataset and the reasoning behind the generating rules. The dataset aims to facilitate investigations into how verb information is encoded in sentence embeddings and how models generalize to the complex properties of argument structures. Benchmarking experiments conducted on the dataset and qualitative error analysis on the answer set reveal the inherent challenges associated with the problem even for current high-performing representations. | Giuseppe Samo, Vivi Nastase, Chunyang Jiang, Paola Merlo |  |
| 955 |  |  [Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt](https://doi.org/10.18653/v1/2023.findings-emnlp.822) |  | 0 | Enhancing the zero-shot performance of instruction-following models requires heavy computation, either by scaling the total number of training datasets or the model size. In this work, we explore how retrieval of soft prompts obtained through prompt tuning can efficiently assist hard prompts in zero-shot task generalization. Specifically, we train soft prompt embeddings for each prompt through prompt tuning, store the samples of the training instances mapped with the prompt embeddings, and retrieve the corresponding prompt embedding of the training instance closest to the query instance during inference. While only adding 0.007% additional parameters, retrieval of soft prompt enhances the performance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets as well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39% points. Also, we report an interesting finding that retrieving source embeddings trained on similar answer choice formats is more important than those on similar task types. | Seonghyeon Ye, Joel Jang, Doyoung Kim, Yongrae Jo, Minjoon Seo |  |
| 956 |  |  [Geographical Erasure in Language Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.823) |  | 0 | Large language models (LLMs) encode vast amounts of world knowledge. However, since these models are trained on large swaths of internet data, they are at risk of inordinately capturing information about dominant groups. This imbalance can propagate into generated language. In this work, we study and operationalise a form of geographical erasure wherein language models underpredict certain countries. We demonstrate consistent instances of erasure across a range of LLMs. We discover that erasure strongly correlates with low frequencies of country mentions in the training corpus. Lastly, we mitigate erasure by finetuning using a custom objective. | Pola Schwöbel, Jacek Golebiowski, Michele Donini, Cédric Archambeau, Danish Pruthi |  |
| 957 |  |  [Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?](https://doi.org/10.18653/v1/2023.findings-emnlp.824) |  | 0 | Despite tremendous advances in AI, it remains a significant challenge to develop interactive task guidance systems that can offer situated, personalized guidance and assist humans in various tasks. These systems need to have a sophisticated understanding of the user as well as the environment, and make timely accurate decisions on when and what to say. To address this issue, we created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based on natural interaction between a human user and a human instructor. We further proposed two tasks: User and Environment Understanding, and Instructor Decision Making. We leveraged several foundation models to study to what extent these models can be quickly adapted to perceptually enabled task guidance. Our quantitative, qualitative, and human evaluation results show that these models can demonstrate fair performances in some cases with no task-specific training, but a fast and reliable adaptation remains a significant challenge. Our benchmark and baselines will provide a stepping stone for future work on situated task guidance. | Yuwei Bao, Keunwoo Peter Yu, Yichi Zhang, Shane Storks, Itamar BarYossef, Alexander De La Iglesia, Megan Su, XiaoLin Zheng, Joyce Chai |  |
| 958 |  |  [Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?](https://doi.org/10.18653/v1/2023.findings-emnlp.825) |  | 0 | There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour? How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community. | Yi Tay, Mostafa Dehghani, Samira Abnar, Hyung Won Chung, William Fedus, Jinfeng Rao, Sharan Narang, Vinh Q. Tran, Dani Yogatama, Donald Metzler |  |
| 959 |  |  [Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.826) |  | 0 | Large language models (LLMs) demonstrate impressive multilingual capability, but their performance varies substantially across different languages. In this work, we introduce a simple yet effective method, called cross-lingual-thought prompting (XLT), to systematically improve the multilingual capability of LLMs. Specifically, XLT is a generic template prompt that stimulates cross-lingual and logical reasoning skills to enhance task performance across languages. We conduct comprehensive evaluations on 7 typical benchmarks related to reasoning, understanding, and generation tasks, covering both high-resource and low-resource languages. Experimental results show that XLT not only remarkably enhances the performance of various multilingual tasks but also significantly reduces the gap between the average performance and the best performance of each task in different languages. Notably, XLT brings over 10 points of average improvement in arithmetic reasoning and open-domain question-answering tasks. | Haoyang Huang, Tianyi Tang, Dongdong Zhang, Xin Zhao, Ting Song, Yan Xia, Furu Wei |  |
| 960 |  |  [DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text](https://doi.org/10.18653/v1/2023.findings-emnlp.827) |  | 0 | With the rapid progress of Large language models (LLMs) and the huge amount of text they generate, it becomes impractical to manually distinguish whether a text is machine-generated. The growing use of LLMs in social media and education, prompts us to develop methods to detect machine-generated text, preventing malicious use such as plagiarism, misinformation, and propaganda. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the Log-Rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover, DetectLLM-NPR needs fewer perturbations than previous work to achieve the same level of performance, which makes it more practical for real-world use. We also investigate the efficiency-performance trade-off based on users’ preference for these two measures and provide intuition for using them in practice effectively. We release the data and the code of both methods in https://github.com/mbzuai-nlp/DetectLLM. | Jinyan Su, Terry Yue Zhuo, Di Wang, Preslav Nakov |  |
| 961 |  |  [From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.828) |  | 0 | Reasoning is a distinctive human capacity, enabling us to address complex problems by breaking them down into a series of manageable cognitive steps. Yet, complex logical reasoning is still cumbersome for language models. Based on the dual process theory in cognitive science, we are the first to unravel the cognitive reasoning abilities of language models. Our framework employs an iterative methodology to construct a Cognitive Tree (CogTree). The root node of this tree represents the initial query, while the leaf nodes consist of straightforward questions that can be answered directly. This construction involves two main components: the implicit extraction module (referred to as the intuitive system) and the explicit reasoning module (referred to as the reflective system). The intuitive system rapidly generates multiple responses by utilizing in-context examples, while the reflective system scores these responses using comparative learning. The scores guide the intuitive system in its subsequent generation step.Our experimental results on two popular and challenging reasoning tasks indicate that it is possible to achieve a performance level comparable to that of GPT-3.5 (with 175B parameters), using a significantly smaller language model that contains fewer parameters (<=7B) than 5% of GPT-3.5. | Junbing Yan, Chengyu Wang, Taolin Zhang, Xiaofeng He, Jun Huang, Wei Zhang |  |
| 962 |  |  [Macedon: Minimizing Representation Coding Rate Reduction for Cross-Lingual Natural Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.829) |  | 0 | Cross-lingual natural language understanding(NLU) is one of the fundamental tasks of NLP. The goal is to learn a model which can generalize well on both high-resource and low-resource language data. Recent pre-trained multilingual language models, e.g., multilingual BERT, XLM, have shown impressive performance on cross-lingual NLU tasks. However, such promising results request the use of sufficient training data, which is a difficult condition to satisfy for low-resource language. When the data is limited in those low resource languages, the accuracy of existing models will drop. In light of this challenge, we investigate the important task of how to train the cross-lingual model with abundant high-source language data and limited low-resource language data. Existing methods typically learn language-agnostic representation via adversarial training and mutual information estimation. Existing approaches may suffer When data is very limited (e.g., low-resource language) because it is challenging to estimate data distribution accurately. To tackle this issue, we propose a conceptually innovative approach to remove language-associated information via minimizing representation coding rate reduction(Macedon). Specifically, Macedon avoids using extra codes to encode language-related information, which is measured by the rate-distortion function. To validate the effectiveness of Macedon, we conduct extensive experiments on three tasks, including paraphrase identification, natural language inference, and query advertisement matching. The experiment results show that the proposed Macedon outperforms state-of-the-art cross-lingual NLU approaches. | Haoyu Wang, Yaqing Wang, Huaxiu Yao, Jing Gao |  |
| 963 |  |  [Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions](https://doi.org/10.18653/v1/2023.findings-emnlp.830) |  | 0 | Large language models (LLM’s) have been widely used for several applications such as question answering, text classification and clustering. While the preliminary results across the aforementioned tasks looks promising, recent work has dived deep into LLM’s performing poorly for complex Named Entity Recognition (NER) tasks in comparison to fine-tuned pre-trained language models (PLM’s). To enhance wider adoption of LLM’s, our paper investigates the robustness of such LLM NER models and its instruction fine-tuned variants to adversarial attacks. In particular, we propose a novel attack which relies on disentanglement and word attribution techniques where the former aids in learning an embedding capturing both entity and non-entity influences separately, and the latter aids in identifying important words across both components. This is in stark contrast to most techniques which primarily leverage non-entity words for perturbations limiting the space being explored to synthesize effective adversarial examples. Adversarial training results based on our method improves the F1 score over original LLM NER model by 8% and 18% on CoNLL-2003 and Ontonotes 5.0 datasets respectively. | Xiaomeng Jin, Bhanukiran Vinzamuri, Sriram Venkatapathy, Heng Ji, Pradeep Natarajan |  |
| 964 |  |  [LLMs - the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on Indian Court Cases](https://doi.org/10.18653/v1/2023.findings-emnlp.831) |  | 0 | The Large Language Models (LLMs) have impacted many real-life tasks. To examine the efficacy of LLMs in a high-stake domain like law, we have applied state-of-the-art LLMs for two popular tasks: Statute Prediction and Judgment Prediction, on Indian Supreme Court cases. We see that while LLMs exhibit excellent predictive performance in Statute Prediction, their performance dips in Judgment Prediction when compared with many standard models. The explanations generated by LLMs (along with prediction) are of moderate to decent quality. We also see evidence of gender and religious bias in the LLM-predicted results. In addition, we present a note from a senior legal expert on the ethical concerns of deploying LLMs in these critical legal tasks. | Shaurya Vats, Atharva Zope, Somsubhra De, Anurag Sharma, Upal Bhattacharya, Shubham Kumar Nigam, Shouvik Kumar Guha, Koustav Rudra, Kripabandhu Ghosh |  |
| 965 |  |  [You Are What You Annotate: Towards Better Models through Annotator Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.832) |  | 0 | Annotator disagreement is ubiquitous in natural language processing (NLP) tasks. There are multiple reasons for such disagreements, including the subjectivity of the task, difficult cases, unclear guidelines, and so on. Rather than simply aggregating labels to obtain data annotations, we instead try to directly model the diverse perspectives of the annotators, and explicitly account for annotators’ idiosyncrasies in the modeling process by creating representations for each annotator (\*annotator embeddings\*) and also their annotations (\*annotation embeddings\*). In addition, we propose \*\*TID-8\*\*, \*\*T\*\*he \*\*I\*\*nherent \*\*D\*\*isagreement - \*\*8\*\* dataset, a benchmark that consists of eight existing language understanding datasets that have inherent annotator disagreement. We test our approach on TID-8 and show that our approach helps models learn significantly better from disagreements on six different datasets in TID-8 while increasing model size by fewer than 1% parameters. By capturing the unique tendencies and subjectivity of individual annotators through embeddings, our representations prime AI models to be inclusive of diverse viewpoints. | Naihao Deng, Xinliang Frederick Zhang, Siyang Liu, Winston Wu, Lu Wang, Rada Mihalcea |  |
| 966 |  |  [Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers](https://doi.org/10.18653/v1/2023.findings-emnlp.833) |  | 0 | Backdoor attacks manipulate model predictions by inserting innocuous triggers into training and test data. We focus on more realistic and more challenging clean-label attacks where the adversarial training examples are correctly labeled. Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts. We also propose a poison selection technique to improve the effectiveness of both LLMBkd as well as existing textual backdoor attacks. Lastly, we describe REACT, a baseline defense to mitigate backdoor attacks via antidote training examples. Our evaluations demonstrate LLMBkd’s effectiveness and efficiency, where we consistently achieve high attack success rates across a wide range of styles with little effort and no model training. | Wencong You, Zayd Hammoudeh, Daniel Lowd |  |
| 967 |  |  [Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance](https://doi.org/10.18653/v1/2023.findings-emnlp.834) |  | 0 | Adopting a two-stage paradigm of pretraining followed by fine-tuning, Pretrained Language Models (PLMs) have achieved substantial advancements in the field of natural language processing. However, in real-world scenarios, data labels are often noisy due to the complex annotation process, making it essential to develop strategies for fine-tuning PLMs with such noisy labels. To this end, we introduce an innovative approach for fine-tuning PLMs using noisy labels, which incorporates the guidance of Large Language Models (LLMs) like ChatGPT. This guidance assists in accurately distinguishing between clean and noisy samples and provides supplementary information beyond the noisy labels, thereby boosting the learning process during fine-tuning PLMs. Extensive experiments on synthetic and real-world noisy datasets further demonstrate the superior advantages of our framework over the state-of-the-art baselines. | Song Wang, Zhen Tan, Ruocheng Guo, Jundong Li |  |
| 968 |  |  [Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions](https://doi.org/10.18653/v1/2023.findings-emnlp.835) |  | 0 | Large language models (LLMs) are capable of answering knowledge-intensive complex questions with chain-of-thought (CoT) reasoning. However, they tend to generate factually incorrect reasoning steps when the required knowledge is not available or up-to-date in models’ parameters. Recent works turn to retrieving external knowledge to augment CoT reasoning. Despite being promising, these chain-based methods suffer from: 1) Negative retrieval. Unnecessary or incorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the ability to look backward or forward, a local error in one step will propagate along the chain. In this paper, we propose a novel approach: Probabilistic Tree-of-thought Reasoning (ProbTree). First, LLMs translate a complex question into a query tree, in which each non-root node denotes a sub-question of its parent node. Then, probabilistic reasoning is conducted over the tree, by solving questions from leaf to root considering the confidence of both question decomposing and answering. During reasoning, for leaf nodes, LLMs choose a more confident answer from Closed-book QA that employs parametric knowledge and Open-book QA that employs retrieved external knowledge, thus eliminating the negative retrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs have broader sights and are able to globally reason with the information from child nodes, thus recovering from local errors. The experiments on three Complex QA datasets under the open-domain setting show that our approach outperforms SOTA methods significantly, demonstrating the effect of probabilistic tree-of-thought reasoning. | Shulin Cao, Jiajie Zhang, Jiaxin Shi, Xin Lv, Zijun Yao, Qi Tian, Lei Hou, Juanzi Li |  |
| 969 |  |  [Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of LMs](https://doi.org/10.18653/v1/2023.findings-emnlp.836) |  | 0 | Using in-context learning (ICL) for data generation, techniques such as Self-Instruct (Wang et al., 2023) or the follow-up Alpaca (Taori et al., 2023) can train strong conversational agents with only a small amount of human supervision. One limitation of these approaches is that they resort to very large language models (around 175B parameters) that are also proprietary and non-public. Here we explore the application of such techniques to language models that are much smaller (around 10B–40B parameters) and have permissive licenses. We find the Self-Instruct approach to be less effective at these sizes and propose new ICL methods that draw on two main ideas: (a) categorization and simplification of the ICL templates to make prompt learning easier for the LM, and (b) ensembling over multiple LM outputs to help select high-quality synthetic examples. Our algorithm leverages the 175 Self-Instruct seed tasks and employs separate pipelines for instructions that require an input and instructions that do not. Empirical investigations with different LMs show that: (1) Our proposed method yields higher-quality instruction tuning data than Self-Instruct, (2) It improves performances of both vanilla and instruction-tuned LMs by significant margins, and (3) Smaller instruction-tuned LMs generate more useful examples than their larger un-tuned counterparts. | YoungSuk Lee, Md. Arafat Sultan, Yousef ElKurdi, Tahira Naseem, Asim Munawar, Radu Florian, Salim Roukos, Ramón Fernandez Astudillo |  |
| 970 |  |  [The Less the Merrier? Investigating Language Representation in Multilingual Models](https://doi.org/10.18653/v1/2023.findings-emnlp.837) |  | 0 | Multilingual Language Models offer a way to incorporate multiple languages in one model and utilize cross-language transfer learning to improve performance for different Natural Language Processing (NLP) tasks. Despite progress in multilingual models, not all languages are supported as well, particularly in low-resource settings. In this work, we investigate the linguistic representation of different languages in multilingual models. We start by asking the question which languages are supported in popular multilingual models and which languages are left behind. Then, for included languages, we look at models’ learned representations based on language family and dialect and try to understand how models’ learned representations for (1) seen and (2) unseen languages vary across different language groups. In addition, we test and analyze performance on downstream tasks such as text generation and Named Entity Recognition. We observe from our experiments that community-centered models—models that focus on languages of a given family or geographical location and are built by communities who speak them—perform better at distinguishing between languages in the same family for low-resource languages. Our paper contributes to the literature in understanding multilingual models and their shortcomings and offers insights on potential ways to improve them. | Hellina Nigatu, Atnafu Lambebo Tonja, Jugal Kalita |  |
| 971 |  |  [SuperTweetEval: A Challenging, Unified and Heterogeneous Benchmark for Social Media NLP Research](https://doi.org/10.18653/v1/2023.findings-emnlp.838) |  | 0 | Despite its relevance, the maturity of NLP for social media pales in comparison with general-purpose models, metrics and benchmarks. This fragmented landscape makes it hard for the community to know, for instance, given a task, which is the best performing model and how it compares with others. To alleviate this issue, we introduce a unified benchmark for NLP evaluation in social media, SuperTweetEval, which includes a heterogeneous set of tasks and datasets combined, adapted and constructed from scratch. We benchmarked the performance of a wide range of models on SuperTweetEval and our results suggest that, despite the recent advances in language modelling, social media remains challenging. | Dimosthenis Antypas, Asahi Ushio, Francesco Barbieri, Leonardo Neves, Kiamehr Rezaee, Luis Espinosa Anke, Jiaxin Pei, José CamachoCollados |  |
| 972 |  |  [Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.839) |  | 0 | Unsupervised neural machine translation has recently made remarkable strides, achieving impressive results with the exclusive use of monolingual corpora. Nonetheless, these methods still exhibit fundamental flaws, such as confusing similar words. A straightforward remedy to rectify this drawback is to employ bilingual dictionaries, however, high-quality bilingual dictionaries can be costly to obtain. To overcome this limitation, we propose a method that incorporates images at the word level to augment the lexical mappings. Specifically, our method inserts visual representations into the model, modifying the corresponding embedding layer information. Besides, a visible matrix is adopted to isolate the impact of images on other unrelated words. Experiments on the Multi30k dataset with over 300,000 self-collected images validate the effectiveness in generating more accurate word translation, achieving an improvement of up to +2.81 BLEU score, which is comparable or even superior to using bilingual dictionaries. | Chengpeng Fu, Xiaocheng Feng, Yichong Huang, Wenshuai Huo, Hui Wang, Bing Qin, Ting Liu |  |
| 973 |  |  [Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches](https://doi.org/10.18653/v1/2023.findings-emnlp.840) |  | 0 | People rely heavily on context to enrich meaning beyond what is literally said, enabling concise but effective communication. To interact successfully and naturally with people, user-facing artificial intelligence systems will require similar skills in pragmatics: relying on various types of context — from shared linguistic goals and conventions, to the visual and embodied world — to use language effectively. We survey existing grounded settings and pragmatic modeling approaches and analyze how the task goals, environmental contexts, and communicative affordances in each work enrich linguistic meaning. We present recommendations for future grounded task design to naturally elicit pragmatic phenomena, and suggest directions that focus on a broader range of communicative contexts and affordances. | Daniel Fried, Nicholas Tomlin, Jennifer Hu, Roma Patel, Aida Nematzadeh |  |
| 974 |  |  [MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.841) |  | 0 | The research study of detecting multiple intents and filling slots is becoming more popular because of its relevance to complicated real-world situations. Recent advanced approaches, which are joint models based on graphs, might still face two potential issues: (i) the uncertainty introduced by constructing graphs based on preliminary intents and slots, which may transfer intent-slot correlation information to incorrect label node destinations, and (ii) direct incorporation of multiple intent labels for each token w.r.t. token-level intent voting might potentially lead to incorrect slot predictions, thereby hurting the overall performance. To address these two issues, we propose a joint model named MISCA. Our MISCA introduces an intent-slot co-attention mechanism and an underlying layer of label attention mechanism. These mechanisms enable MISCA to effectively capture correlations between intents and slot labels, eliminating the need for graph construction. They also facilitate the transfer of correlation information in both directions: from intents to slots and from slots to intents, through multiple levels of label-specific representations, without relying on token-level intent information. Experimental results show that MISCA outperforms previous models, achieving new state-of-the-art overall accuracy performances on two benchmark datasets MixATIS and MixSNIPS. This highlights the effectiveness of our attention mechanisms. | Thinh Pham, Tran Chi, Dat Quoc Nguyen |  |
| 975 |  |  [Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization](https://doi.org/10.18653/v1/2023.findings-emnlp.842) |  | 0 | Emotion recognition in conversation (ERC) has attracted increasing attention in natural language processing community. Previous work commonly first extract semantic-view features via fine-tuning PLMs, then models context-view features based on the obtained semantic-view features by various graph neural networks. However, it is difficult to fully model interaction between utterances simply through a graph neural network and the features at semantic-view and context-view are not well aligned. Moreover, the previous parametric learning paradigm struggle to learn the patterns of tail class given fewer instances. To this end, we treat the pre-trained conversation model as a prior knowledge base and from which we elicit correlations between utterances by a probing procedure. And we adopt supervised contrastive learning to align semantic-view and context-view features, these two views of features work together in a complementary manner, contributing to ERC from distinct perspectives. Meanwhile, we propose a new semi-parametric paradigm of inferencing through memorization to solve the recognition problem of tail class samples. We consistently achieve state-of-the-art results on four widely used benchmarks. Extensive experiments demonstrate the effectiveness of our proposed multi-view feature alignment and memorization. | Guiyang Hou, Yongliang Shen, Wenqi Zhang, Wei Xue, Weiming Lu |  |
| 976 |  |  [Mandarin classifier systems optimize to accommodate communicative pressures](https://doi.org/10.18653/v1/2023.findings-emnlp.843) |  | 0 | Previous work on noun classification implies that gender systems are inherently optimized to accommodate communicative pressures on human language learning and processing (Dye. et al 2017, 2018). They state that languages make use of either grammatical (e.g., gender) or probabilistic (pre-nominal modifiers) to smoothe the entropy of nouns in context. We show that even languages that are considered genderless, like Mandarin Chinese, possess a noun classification device that plays the same functional role as gender markers. Based on close to 1M Mandarin noun phrases extracted from the Leipzig Corpora Collection (Goldhahn et al. 2012) and their corresponding fastText embeddings (Bojanowski et al. 2016), we show that noun-classifier combinations are sensitive to same frequency, similarity, and co-occurrence interactions that structure gender systems. We also present the first study of the effects of the interaction between grammatical and probabilisitic noun classification. | Yamei Wang, Géraldine Walther |  |
| 977 |  |  [Probing Representations for Document-level Event Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.844) |  | 0 | The probing classifiers framework has been employed for interpreting deep neural network models for a variety of natural language processing (NLP) applications. Studies, however, have largely focused on sentencelevel NLP tasks. This work is the first to apply the probing paradigm to representations learned for document-level information extraction (IE). We designed eight embedding probes to analyze surface, semantic, and event-understanding capabilities relevant to document-level event extraction. We apply them to the representations acquired by learning models from three different LLM-based document-level IE approaches on a standard dataset. We found that trained encoders from these models yield embeddings that can modestly improve argument detections and labeling but only slightly enhance event-level tasks, albeit trade-offs in information helpful for coherence and event-type prediction. We further found that encoder models struggle with document length and cross-sentence discourse. | Barry Wang, Xinya Du, Claire Cardie |  |
| 978 |  |  [Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features](https://doi.org/10.18653/v1/2023.findings-emnlp.845) |  | 0 | The increasing ubiquity of language technology necessitates a shift towards considering cultural diversity in the machine learning realm, particularly for subjective tasks that rely heavily on cultural nuances, such as Offensive Language Detection (OLD). Current understanding underscores that these tasks are substantially influenced by cultural values, however, a notable gap exists in determining if cultural features can accurately predict the success of cross-cultural transfer learning for such subjective tasks. Addressing this, our study delves into the intersection of cultural features and transfer learning effectiveness. The findings reveal that cultural value surveys indeed possess a predictive power for cross-cultural transfer learning success in OLD tasks, and that it can be further improved using offensive word distance. Based on these results, we advocate for the integration of cultural information into datasets. Additionally, we recommend leveraging data sources rich in cultural information, such as surveys, to enhance cultural adaptability. Our research signifies a step forward in the quest for more inclusive, culturally sensitive language technologies. | Li Zhou, Antonia Karamolegkou, Wenyu Chen, Daniel Hershcovich |  |
| 979 |  |  [Linguistically Motivated Sign Language Segmentation](https://doi.org/10.18653/v1/2023.findings-emnlp.846) |  | 0 | Sign language segmentation is a crucial task in sign language processing systems. It enables downstream tasks such as sign recognition, transcription, and machine translation. In this work, we consider two kinds of segmentation: segmentation into individual signs and segmentation into phrases, larger units comprising several signs. We propose a novel approach to jointly model these two tasks. Our method is motivated by linguistic cues observed in sign language corpora. We replace the predominant IO tagging scheme with BIO tagging to account for continuous signing. Given that prosody plays a significant role in phrase boundaries, we explore the use of optical flow features. We also provide an extensive analysis of hand shapes and 3D hand normalization. We find that introducing BIO tagging is necessary to model sign boundaries. Explicitly encoding prosody by optical flow improves segmentation in shallow models, but its contribution is negligible in deeper models. Careful tuning of the decoding algorithm atop the models further improves the segmentation quality. We demonstrate that our final models generalize to out-of-domain video content in a different signed language, even under a zero-shot setting. We observe that including optical flow and 3D hand normalization enhances the robustness of the model in this context. | Amit Moryossef, Zifan Jiang, Mathias Müller, Sarah Ebling, Yoav Goldberg |  |
| 980 |  |  [Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.847) |  | 0 | Active learning, a widely adopted technique for enhancing machine learning models in text and image classification tasks with limited annotation resources, has received relatively little attention in the domain of Named Entity Recognition (NER). The challenge of data imbalance in NER has hindered the effectiveness of active learning, as sequence labellers lack sufficient learning signals. To address these challenges, this paper presents a novel re-weighting-based active learning strategy that assigns dynamic smoothing weights to individual tokens. This adaptable strategy is compatible with various token-level acquisition functions and contributes to the development of robust active learners. Experimental results on multiple corpora demonstrate the substantial performance improvement achieved by incorporating our re-weighting strategy into existing acquisition functions, validating its practical efficacy. We will release our implementation upon the publication of this paper. | Haocheng Luo, Wei Tan, Ngoc Dang Nguyen, Lan Du |  |
| 981 |  |  [Language-Agnostic Bias Detection in Language Models with Bias Probing](https://doi.org/10.18653/v1/2023.findings-emnlp.848) |  | 0 | Pretrained language models (PLMs) are key components in NLP, but they contain strong social biases. Quantifying these biases is challenging because current methods focusing on fill-the-mask objectives are sensitive to slight changes in input. To address this, we propose a bias probing technique called LABDet, for evaluating social bias in PLMs with a robust and language-agnostic method. For nationality as a case study, we show that LABDet “surfaces” nationality bias by training a classifier on top of a frozen PLM on non-nationality sentiment detection. We find consistent patterns of nationality bias across monolingual PLMs in six languages that align with historical and political context. We also show for English BERT that bias surfaced by LABDet correlates well with bias in the pretraining data; thus, our work is one of the few studies that directly links pretraining data to PLM behavior. Finally, we verify LABDet’s reliability and applicability to different templates and languages through an extensive set of robustness checks. We publicly share our code and dataset in https://github.com/akoksal/LABDet. | Abdullatif Köksal, Omer Faruk Yalcin, Ahmet Akbiyik, M. Tahir Kilavuz, Anna Korhonen, Hinrich Schütze |  |
| 982 |  |  [CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.849) |  | 0 | How much success in Knowledge Graph Completion (KGC) would translate into the performance enhancement in downstream tasks is an important question that has not been studied in depth. In this paper, we introduce a novel benchmark, namely CompleQA, to comprehensively assess the influence of representative KGC methods on Knowledge Graph Question Answering (KGQA), one of the most important downstream applications. This benchmark includes a knowledge graph with 3 million triplets across 5 distinct domains, coupled with over 5000 question-answering pairs and a completion dataset that is well-aligned with these questions. Our evaluation of four well-known KGC methods in combination with two state-of-the-art KGQA systems shows that effective KGC can significantly mitigate the impact of knowledge graph incompleteness on question-answering performance. Surprisingly, we also find that the best-performing KGC method(s) does not necessarily lead to the best QA results, underscoring the need to consider downstream applications when doing KGC. | Donghan Yu, Yu Gu, Chenyan Xiong, Yiming Yang |  |
| 983 |  |  [Improving Multi-Criteria Chinese Word Segmentation through Learning Sentence Representation](https://doi.org/10.18653/v1/2023.findings-emnlp.850) |  | 0 | Recent Chinese word segmentation (CWS) models have shown competitive performance with pre-trained language models’ knowledge. However, these models tend to learn the segmentation knowledge through in-vocabulary words rather than understanding the meaning of the entire context. To address this issue, we introduce a context-aware approach that incorporates unsupervised sentence representation learning over different dropout masks into the multi-criteria training framework. We demonstrate that our approach reaches state-of-the-art (SoTA) performance on F1 scores for six of the nine CWS benchmark datasets and out-of-vocabulary (OOV) recalls for eight of nine. Further experiments discover that substantial improvements can be brought with various sentence representation objectives. | Chun Lin, YingJia Lin, ChiaJen Yeh, YiTing Li, Ching Yang, HungYu Kao |  |
| 984 |  |  [A Joint Matrix Factorization Analysis of Multilingual Representations](https://doi.org/10.18653/v1/2023.findings-emnlp.851) |  | 0 | We present an analysis tool based on joint matrix factorization for comparing latent representations of multilingual and monolingual models. An alternative to probing, this tool allows us to analyze multiple sets of representations in a joint manner. Using this tool, we study to what extent and how morphosyntactic features are reflected in the representations learned by multilingual pre-trained models. We conduct a large-scale empirical study of over 33 languages and 17 morphosyntactic categories. Our findings demonstrate variations in the encoding of morphosyntactic information across upper and lower layers, with category-specific differences influenced by language properties. Hierarchical clustering of the factorization outputs yields a tree structure that is related to phylogenetic trees manually crafted by linguists. Moreover, we find the factorization outputs exhibit strong associations with performance observed across different cross-lingual tasks. We release our code to facilitate future research. | Zheng Zhao, Yftah Ziser, Bonnie Webber, Shay B. Cohen |  |
| 985 |  |  [Don't Add, don't Miss: Effective Content Preserving Generation from Pre-Selected Text Spans](https://doi.org/10.18653/v1/2023.findings-emnlp.852) |  | 0 | The recently introduced Controlled Text Reduction (CTR) task isolates the text generation step within typical summarization-style tasks. It does so by challenging models to generate coherent text conforming to pre-selected content within the input text (“highlights”). This framing enables increased modularity in summarization-like tasks, allowing to couple a single CTR model with various content-selection setups and modules. However, there are currently no reliable CTR models, while the performance of the existing baseline for the task is mediocre, falling short of practical utility. Here, we address this gap by introducing a high-quality, open-source CTR model that tackles two prior key limitations: inadequate enforcement of the content-preservation constraint, and suboptimal silver training data. Addressing these, we amplify the content-preservation constraint in both training, via RL, and inference, via a controlled decoding strategy. Further, we substantially improve the silver training data quality via GPT-4 distillation. Overall, pairing the distilled dataset with the highlight-adherence strategies yields marked gains over the current baseline, of up to 30 ROUGE-L points, providing a reliable CTR model for downstream use. | Aviv Slobodkin, Avi Caciularu, Eran Hirsch, Ido Dagan |  |
| 986 |  |  [A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting](https://doi.org/10.18653/v1/2023.findings-emnlp.853) |  | 0 | Many real-world tasks involve a mixed-initiative setup, wherein humans and AI systems collaboratively perform a task. While significant work has been conducted towards enabling humans to specify, through language, exactly how an agent should complete a task (i.e., low-level specification), prior work lacks on interpreting the high-level strategic intent of the human commanders. Parsing strategic intent from language will allow autonomous systems to independently operate according to the user’s plan without frequent guidance or instruction. In this paper, we build a computational interface capable of translating unstructured language strategies into actionable intent in the form of goals and constraints. Leveraging a game environment, we collect a dataset of over 1000 examples, mapping language strategies to the corresponding goals and constraints, and show that our model, trained on this dataset, significantly outperforms human interpreters in inferring strategic intent (i.e., goals and constraints) from language (p < 0.05). Furthermore, we show that our model (125M parameters) significantly outperforms ChatGPT for this task (p < 0.05) in a low-data setting. | Pradyumna Tambwekar, Lakshita Dodeja, Nathan Vaska, Wei Xu, Matthew C. Gombolay |  |
| 987 |  |  [HFMRE: Constructing Huffman Tree in Bags to Find Excellent Instances for Distantly Supervised Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.854) |  | 0 | Since the introduction of distantly supervised relation extraction methods, numerous approaches have been developed, the most representative of which is multi-instance learning (MIL). To find reliable features that are most representative of multi-instance bags, aggregation strategies such as AVG (average), ONE (at least one), and ATT (sentence-level attention) are commonly used. These strategies tend to train third-party vectors to select sentence-level features, leaving it to the third party to decide/identify what is noise, ignoring the intrinsic associations that naturally exist from sentence to sentence. In this paper, we propose the concept of circular cosine similarity, which is used to explicitly show the intrinsic associations between sentences within a bag. We also consider the previous methods to be a crude denoising process as they are interrupted and do not have a continuous noise detection procedure. Following this consideration, we implement a relation extraction framework (HFMRE) that relies on the Huffman tree, where sentences are considered as leaf nodes and circular cosine similarity are considered as node weights. HFMRE can continuously and iteratively discriminate noise and aggregated features during the construction of the Huffman tree, eventually finding an excellent instance that is representative of a bag-level feature. The experiments demonstrate the remarkable effectiveness of our method, outperforming previously advanced baselines on the popular DSRE datasets. | Min Li, Cong Shao, Gang Li, Mingle Zhou |  |
| 988 |  |  [DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in Indo-European Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.855) |  | 0 | Disfluency correction (DC) is the process of removing disfluent elements like fillers, repetitions and corrections from spoken utterances to create readable and interpretable text. DC is a vital post-processing step applied to Automatic Speech Recognition (ASR) outputs, before subsequent processing by downstream language understanding tasks. Existing DC research has primarily focused on English due to the unavailability of large-scale open-source datasets. Towards the goal of multilingual disfluency correction, we present a high-quality human-annotated DC corpus covering four important Indo-European languages: English, Hindi, German and French. We provide extensive analysis of results of state-of-the-art DC models across all four languages obtaining F1 scores of 97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French). To demonstrate the benefits of DC on downstream tasks, we show that DC leads to 5.65 points increase in BLEU scores on average when used in conjunction with a state-of-the-art Machine Translation (MT) system. We release code to run our experiments along with our annotated dataset here. | Vineet Bhat, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 989 |  |  [Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity](https://doi.org/10.18653/v1/2023.findings-emnlp.856) |  | 0 | Mixture-of-experts (MoE) models that employ sparse activation have demonstrated effectiveness in significantly increasing the number of parameters while maintaining low computational requirements per token. However, recent studies have established that MoE models are inherently parameter-inefficient as the improvement in performance diminishes with an increasing number of experts. We hypothesize this parameter inefficiency is a result of all experts having equal capacity, which may not adequately meet the varying complexity requirements of different tokens or tasks. In light of this, we propose Stratified Mixture of Experts (SMoE) models, which feature a stratified structure and can assign dynamic capacity to different tokens. We demonstrate the effectiveness of SMoE on three multilingual machine translation benchmarks, containing 4, 15, and 94 language pairs, respectively. We show that SMoE outperforms multiple state-of-the-art MoE models with the same or fewer parameters. | Haoran Xu, Maha Elbayad, Kenton Murray, Jean Maillard, Vedanuj Goswami |  |
| 990 |  |  [Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.857) |  | 0 | Given the omnipresence of social media in our society, thoughts and opinions are being shared online in an unprecedented manner. This means that both positive and negative emotions can be equally and freely expressed. However, the negativity bias posits that human beings are inherently drawn to and more moved by negativity and, as a consequence, negative emotions get more traffic. Correspondingly, when writing about emotions this negativity bias could lead to expressions of negative emotions that are linguistically more complex. In this paper, we attempt to use readability and linguistic complexity metrics to better understand the manifestation of emotions on social media platforms like Reddit based on the widely-used GoEmotions dataset. We demonstrate that according to most metrics, negative emotions indeed tend to generate more complex text than positive emotions. In addition, we examine whether a higher complexity hampers the automatic identification of emotions. To answer this question, we fine-tuned three state-of-the-art transformers (BERT, RoBERTa, and SpanBERT) on the same emotion detection dataset. We demonstrate that these models often fail to predict emotions for the more complex texts. More advanced LLMs like RoBERTa and SpanBERT also fail to improve by significant margins on complex samples. This calls for a more nuanced interpretation of the emotion detection performance of transformer models. We make the automatically annotated data available for further research at: https://huggingface.co/datasets/pranaydeeps/CAMEO | Pranaydeep Singh, Luna De Bruyne, Orphée De Clercq, Els Lefever |  |
| 991 |  |  [Probing the "Creativity" of Large Language Models: Can models produce divergent semantic association?](https://doi.org/10.18653/v1/2023.findings-emnlp.858) |  | 0 | Large language models possess remarkable capacity for processing language, but it remains unclear whether these models can further generate creative content. The present study aims to investigate the creative thinking of large language models through a cognitive perspective. We utilize the divergent association task (DAT), an objective measurement of creativity that asks models to generate unrelated words and calculates the semantic distance between them. We compare the results across different models and decoding strategies. Our findings indicate that: (1) When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level. (2) Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability. These results imply that advanced large language models have divergent semantic associations, which is a fundamental process underlying creativity. | Honghua Chen, Nai Ding |  |
| 992 |  |  [Code-Switching with Word Senses for Pretraining in Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.859) |  | 0 | Lexical ambiguity is a significant and pervasive challenge in Neural Machine Translation (NMT), with many state-of-the-art (SOTA) NMT systems struggling to handle polysemous words (Campolungo et al., 2022). The same holds for the NMT pretraining paradigm of denoising synthetic “code-switched” text (Pan et al., 2021; Iyer et al., 2023), where word senses are ignored in the noising stage – leading to harmful sense biases in the pretraining data that are subsequently inherited by the resulting models. In this work, we introduce Word Sense Pretraining for Neural Machine Translation (WSP-NMT) - an end-to-end approach for pretraining multilingual NMT models leveraging word sense-specific information from Knowledge Bases. Our experiments show significant improvements in overall translation quality. Then, we show the robustness of our approach to scale to various challenging data and resource-scarce scenarios and, finally, report fine-grained accuracy improvements on the DiBiMT disambiguation benchmark. Our studies yield interesting and novel insights into the merits and challenges of integrating word sense information and structured knowledge in multilingual pretraining for NMT. | Vivek Iyer, Edoardo Barba, Alexandra Birch, Jeff Z. Pan, Roberto Navigli |  |
| 993 |  |  [DiffusionSL: Sequence Labeling via Tag Diffusion Process](https://doi.org/10.18653/v1/2023.findings-emnlp.860) |  | 0 | Sequence Labeling (SL) is long-standing in Natural Language Processing (NLP). Traditionally, discriminative models have been widely used to capture the conditional distribution of sequence tags, rather than generative models. In this paper, we present DiffusionSL, a framework that utilizes a conditional discrete diffusion model for generating discrete tag data, resulting in a Tag Diffusion Process. We treat the natural language sequence as the conditional signal and the sequence tags as the generation target, iteratively refining the noisy tags to obtain clean ones. To address the discreteness issue, we propose the Bit-Tag Converter (BTConverter) to model the target in continuous data space. Furthermore, we introduce the Bit Diffusion Transformer (BitDiT) to model the process of noise elimination. Leveraging the powerful iterative refinement capability of the diffusion model, DiffusionSL achieves superior performance against previous state-of-the-art (SOTA) baselines and outperforms gpt-3.5-turbo significantly across multiple benchmark datasets and various tasks. | Ziyang Huang, Pengfei Cao, Jun Zhao, Kang Liu |  |
| 994 |  |  [COMET-M: Reasoning about Multiple Events in Complex Sentences](https://doi.org/10.18653/v1/2023.findings-emnlp.861) |  | 0 | Understanding the speaker’s intended meaning often involves drawing commonsense inferences to reason about what is not stated explicitly. In multi-event sentences, it requires understanding the relationships between events based on contextual knowledge. We propose COMET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence. COMET-M builds upon COMET (Bosselut et al., 2019), which excels at generating event-centric inferences for simple sentences, but struggles with the complexity of multi-event sentences prevalent in natural text. To overcome this limitation, we curate a Multi-Event Inference (MEI) dataset of 35K human-written inferences. We train COMET-M on the human-written inferences and also create baselines using automatically labeled examples. Experimental results demonstrate the significant performance improvement of COMET-M over COMET in generating multi-event inferences. Moreover, COMET-M successfully produces distinct inferences for each target event, taking the complete context into consideration. COMET-M holds promise for downstream tasks involving natural text such as coreference resolution, dialogue, and story understanding. | Sahithya Ravi, Raymond T. Ng, Vered Shwartz |  |
| 995 |  |  [On Event Individuation for Document-Level Information Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.862) |  | 0 | As information extraction (IE) systems have grown more adept at processing whole documents, the classic task of \*template filling\* has seen renewed interest as a benchmark for document-level IE. In this position paper, we call into question the suitability of template filling for this purpose. We argue that the task demands definitive answers to thorny questions of \*event individuation\* — the problem of distinguishing distinct events — about which even human experts disagree. Through an annotation study and error analysis, we show that this raises concerns about the usefulness of template filling metrics, the quality of datasets for the task, and the ability of models to learn it. Finally, we consider possible solutions. | William Gantt, Reno Kriz, Yunmo Chen, Siddharth Vashishtha, Aaron Steven White |  |
| 996 |  |  [AniEE: A Dataset of Animal Experimental Literature for Event Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.863) |  | 0 | Event extraction (EE), as a crucial information extraction (IE) task, aims to identify event triggers and their associated arguments from unstructured text, subsequently classifying them into pre-defined types and roles. In the biomedical domain, EE is widely used to extract complex structures representing biological events from literature. Due to the complicated semantics and specialized domain knowledge, it is challenging to construct biomedical event extraction datasets. Additionally, most existing biomedical EE datasets primarily focus on cell experiments or the overall experimental procedures. Therefore, we introduce AniEE, an event extraction dataset concentrated on the animal experiment stage. We establish a novel animal experiment customized entity and event scheme in collaboration with domain experts. We then create an expert-annotated high-quality dataset containing discontinuous entities and nested events and evaluate our dataset on the recent outstanding NER and EE models. | Dohee Kim, Ra Yoo, Soyoung Yang, Hee Yang, Jaegul Choo |  |
| 997 |  |  [From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions](https://doi.org/10.18653/v1/2023.findings-emnlp.864) |  | 0 | In this work, we show that contemporary language models have a previously unknown skill – the capacity for electronic circuit design from high-level textual descriptions, akin to code generation. We introduce two benchmarks: PINS100, assessing model knowledge of electrical components, and MICRO25, evaluating a model’s capability to design common microcontroller circuits and code in the Arduino ecosystem that involve input, output, sensors, motors, protocols, and logic – with models such as GPT-4 and Claude-V1 achieving between 60% to 96% Pass@1 on generating full devices. We include six case studies of using language models as a design assistant for moderately complex devices, such as a radiation-powered random number generator, an emoji keyboard, a visible spectrometer, and several assistive devices, while offering a qualitative analysis performance, outlining evaluation challenges, and suggesting areas of development to improve complex circuit design and practical utility. With this work, we aim to spur research at the juncture of natural language processing and electronic design. | Peter Jansen |  |
| 998 |  |  [Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training](https://doi.org/10.18653/v1/2023.findings-emnlp.865) |  | 0 | In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model’s automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model’s capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration. | Zhisong Zhang, Emma Strubell, Eduard H. Hovy |  |
| 999 |  |  [Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading](https://doi.org/10.18653/v1/2023.findings-emnlp.866) |  | 0 | Conversational Machine Reading (CMR) requires answering a user’s initial question through multi-turn dialogue interactions based on a given document. Although there exist many effective methods, they largely neglected the alignment between the document and the user-provided information, which significantly affects the intermediate decision-making and subsequent follow-up question generation. To address this issue, we propose a pipeline framework that (1) aligns the aforementioned two sides in an explicit way, (2) makes decisions using a lightweight many-to-many entailment reasoning module, and (3) directly generates follow-up questions based on the document and previously asked questions. Our proposed method achieves state-of-the-art in micro-accuracy and ranks the first place on the public leaderboard of the CMR benchmark dataset ShARC. | Yangyang Luo, Shiyu Tian, Caixia Yuan, Xiaojie Wang |  |
| 1000 |  |  [Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers](https://doi.org/10.18653/v1/2023.findings-emnlp.867) |  | 0 | Neural networks have revolutionized language modeling and excelled in various downstream tasks. However, the extent to which these models achieve compositional generalization comparable to human cognitive abilities remains a topic of debate. While existing approaches in the field have mainly focused on novel architectures and alternative learning paradigms, we introduce a pioneering method harnessing the power of dataset cartography (Swayamdipta et al., 2020). By strategically identifying a subset of compositional generalization data using this approach, we achieve a remarkable improvement in model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets. Notably, our technique incorporates dataset cartography as a curriculum learning criterion, eliminating the need for hyperparameter tuning while consistently achieving superior performance. Our findings highlight the untapped potential of dataset cartography in unleashing the full capabilities of compositional generalization within Transformer models. | Osman Batur Ince, Tanin Zeraati, Semih Yagcioglu, Yadollah Yaghoobzadeh, Erkut Erdem, Aykut Erdem |  |
| 1001 |  |  [Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention](https://doi.org/10.18653/v1/2023.findings-emnlp.868) |  | 0 | Recent large language models (LLMs) have revealed strong abilities to understand natural language. Since most of them share the same basic structure, i.e. the transformer block, possible contributors to their success in the training process are scaling and instruction tuning. However, how these factors affect the models’ language perception is unclear. This work compares the self-attention of several existing LLMs (LLaMA, Alpaca and Vicuna) in different sizes (7B, 13B, 30B, 65B), together with eye saccade, an aspect of human reading attention, to assess the effect of scaling and instruction tuning on language perception. Results show that scaling enhances the human resemblance and improves the effective attention by reducing the trivial pattern reliance, while instruction tuning does not. However, instruction tuning significantly enhances the models’ sensitivity to instructions. We also find that current LLMs are consistently closer to non-native than native speakers in attention, suggesting a sub-optimal language perception of all models. Our code and data used in the analysis is available on GitHub. | Changjiang Gao, Shujian Huang, Jixing Li, Jiajun Chen |  |
| 1002 |  |  [Efficient Data Learning for Open Information Extraction with Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.869) |  | 0 | Open Information Extraction (OpenIE) is a fundamental yet challenging task in Natural Language Processing, which involves extracting all triples (subject, predicate, object) from a given sentence. While labelling-based methods have their merits, generation-based techniques offer unique advantages, such as the ability to generate tokens not present in the original sentence. However, these generation-based methods often require a significant amount of training data to learn the task form of OpenIE and substantial training time to overcome slow model convergence due to the order penalty. In this paper, we introduce a novel framework, OK-IE, that ingeniously transforms the task form of OpenIE into the pre-training task form of the T5 model, thereby reducing the need for extensive training data. Furthermore, we introduce an innovative concept of ‘anchors’ to control the sequence of model outputs, effectively eliminating the impact of order penalty on model convergence and significantly reducing training time. Experimental results indicate that, compared to previous SOTA methods, OK-IE requires only 1/100 of the training data (900 instances) and 1/120 of the training time (3 minutes) to achieve comparable results. | Zhiyuan Fan, Shizhu He |  |
| 1003 |  |  [Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning](https://doi.org/10.18653/v1/2023.findings-emnlp.870) |  | 0 | Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusively on influential prompt tokens. By employing even simple search methods within the pruned search space, ClaPS achieves state-of-the-art performance across various tasks and LLMs, surpassing the performance of complex approaches while significantly reducing search costs. Our findings underscore the critical role of search space design and optimization in enhancing both the usefulness and the efficiency of black-box prompt-based learning. | Han Zhou, Xingchen Wan, Ivan Vulic, Anna Korhonen |  |
| 1004 |  |  [Towards Zero-shot Learning for End-to-end Cross-modal Translation Models](https://doi.org/10.18653/v1/2023.findings-emnlp.871) |  | 0 | One of the main problems in speech translation is the mismatches between different modalities. The second problem, scarcity of parallel data covering multiple modalities, means that the end-to-end multi-modal models tend to perform worse than cascade models, although there are exceptions under favorable conditions. To address these problems, we propose an end-to-end zero-shot speech translation model, connecting two pre-trained uni-modality modules via word rotator’s distance. The model retains the ability of zero-shot, which is like cascade models, and also can be trained in an end-to-end style to avoid error propagation. Our comprehensive experiments on the MuST-C benchmarks show that our end-to-end zero-shot approach performs better than or as well as those of the CTC-based cascade models and that our end-to-end model with supervised training also matches the latest baselines. | Jichen Yang, Kai Fan, Minpeng Liao, Boxing Chen, Zhongqiang Huang |  |
| 1005 |  |  [LLMaAA: Making Large Language Models as Active Annotators](https://doi.org/10.18653/v1/2023.findings-emnlp.872) |  | 0 | Prevalent supervised learning methods in natural language processing (NLP) are notoriously data-hungry, which demand large amounts of high-quality annotated data. In practice, acquiring such data is a costly endeavor. Recently, the superior few-shot performance of large language models (LLMs) has propelled the development of dataset generation, where the training data are solely synthesized from LLMs. However, such an approach usually suffers from low-quality issues, and requires orders of magnitude more labeled data to achieve satisfactory performance. To fully exploit the potential of LLMs and make use of massive unlabeled data, we propose LLMaAA, which takes LLMs as annotators and puts them into an active learning loop to determine what to annotate efficiently. To learn robustly with pseudo labels, we optimize both the annotation and training processes: (1) we draw k-NN examples from a small demonstration pool as in-context examples, and (2) we adopt the example reweighting technique to assign training samples with learnable weights. Compared with previous approaches, LLMaAA features both efficiency and reliability. We conduct experiments and analysis on two classic NLP tasks, named entity recognition and relation extraction. With LLMaAA, task-specific models trained from LLM-generated labels can outperform the teacher within only hundreds of annotated examples, which is much more cost-effective than other baselines. | Ruoyu Zhang, Yanzeng Li, Yongliang Ma, Ming Zhou, Lei Zou |  |
| 1006 |  |  [NLMs: Augmenting Negation in Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.873) |  | 0 | Negation is the fundamental component in a natural language that reverses the semantic meaning of a sentence. It plays an extremely important role across a wide range of applications, yet they are underrepresented in pre-trained language models (LMs), resulting often in wrong inferences. In this work, we try to improve the underlying understanding of the negation in the pre-trained LMs. To augment negation understanding, we propose a language model objective with a weighted cross-entropy loss and elastic weight consolidation regularization. We reduce the mean top 1 error rate for BERT-base to 1.1%, BERT-large to 0.78%, RoBERTA-base to 3.74%, RoBERTA-large to 0.01% on the negated LAMA dataset. It minimizes the BERT error rate by a margin of 8% and also outperform the existing negation models. We also provide empirical evidences that negated augmented models outperform the classical models on original as well as negation benchmarks on natural language inference tasks. | Rituraj Singh, Rahul Kumar, Vivek Sridhar |  |
| 1007 |  |  [Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers](https://doi.org/10.18653/v1/2023.findings-emnlp.874) |  | 0 | Prompt tuning attempts to update few task-specific parameters in pre-trained models. It has achieved comparable performance to fine-tuning of the full parameter set on both language understanding and generation tasks. In this work, we study the problem of prompt tuning for neural text retrievers. We introduce parameter-efficient prompt tuning for text retrieval across in-domain, cross-domain, and cross-topic settings. Through an extensive analysis, we show that the strategy can mitigate the two issues—parameter-inefficiency and weak generalizability—faced by fine-tuning based retrieval methods. Notably, it can significantly improve the out-of-domain zero-shot generalization of the retrieval models. By updating only 0.1% of the model parameters, the prompt tuning strategy can help retrieval models achieve better generalization performance than traditional methods in which all parameters are updated. Finally, to facilitate research on retrievers’ cross-topic generalizability, we curate and release an academic retrieval dataset with 18K query-results pairs in 87 topics, making it the largest topic-specific one to date. | Weng Tam, Xiao Liu, Kaixuan Ji, Lilong Xue, Jiahua Liu, Tao Li, Yuxiao Dong, Jie Tang |  |
| 1008 |  |  [X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity](https://doi.org/10.18653/v1/2023.findings-emnlp.875) |  | 0 | Cross-lingual transfer (XLT) is an emergent ability of multilingual language models that preserves their performance on a task to a significant extent when evaluated in languages that were not included in the fine-tuning process. While English, due to its widespread usage, is typically regarded as the primary language for model adaption in various tasks, recent studies have revealed that the efficacy of XLT can be amplified by selecting the most appropriate source languages based on specific conditions. In this work, we propose the utilization of sub-network similarity between two languages as a proxy for predicting the compatibility of the languages in the context of XLT. Our approach is model-oriented, better reflecting the inner workings of foundation models. In addition, it requires only a moderate amount of raw text from candidate languages, distinguishing it from the majority of previous methods that rely on external resources. In experiments, we demonstrate that our method is more effective than baselines across diverse tasks. Specifically, it shows proficiency in ranking candidates for zero-shot XLT, achieving an improvement of 4.6% on average in terms of NDCG@3. We also provide extensive analyses that confirm the utility of sub-networks for XLT prediction. | Taejun Yun, Jinhyeon Kim, Deokyeong Kang, Seong Hoon Lim, Jihoon Kim, Taeuk Kim |  |
| 1009 |  |  [Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.876) |  | 0 | Distantly supervised relation extraction (DSRE) aims to extract relational facts from texts but suffers from noisy instances. To mitigate the influence of noisy labels, current methods typically use the Multi-Instance-Learning framework to extract relations for each bag. However, these approaches are not capable of extracting relation labels for individual sentences. Several studies have focused on sentence-level DSRE to solve the above problem. These studies primarily aim to develop methods for identifying noisy samples and filtering them out to mitigate the impact of noise. However, discarding noisy samples directly leads to the loss of useful information. To this end, we propose SSLRE, a novel Semi-Supervised-Learning Relation Extraction framework for sentence-level DSRE. We discard only the labels of the noisy samples and utilize these instances without labels as unlabeled samples. Our SSLRE framework utilizes a weighted K-NN graph to select confident samples as labeled data and the rest as unlabeled. We then design a robust semi-supervised learning framework that can efficiently handle remaining label noise present in the labeled dataset, while also making effective use of unlabeled samples. Based on our experiments on two real-world datasets, the SSLRE framework we proposed has achieved significant enhancements in sentence-level relation extraction performance compared to the existing state-of-the-art methods. Moreover, it has also attained a state-of-the-art level of performance in bag-level relation extraction with ONE aggregation strategy. | Xin Sun, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang |  |
| 1010 |  |  [Towards Concept-Aware Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.877) |  | 0 | Concepts play a pivotal role in various human cognitive functions, including learning, reasoning and communication. However, there is very little work on endowing machines with the ability to form and reason with concepts. In particular, state-of-the-art large language models (LLMs) work at the level of tokens, not concepts. In this work, we analyze how well contemporary LLMs capture human concepts and their structure. We then discuss ways to develop concept-aware LLMs, taking place at different stages of the pipeline. We sketch a method for pretraining LLMs using concepts, and also explore the simpler approach that uses the output of existing LLMs. Despite its simplicity, our proof-of-concept is shown to better match human intuition, as well as improve the robustness of predictions. These preliminary results underscore the promise of concept-aware LLMs. | Chen Shani, Jilles Vreeken, Dafna Shahaf |  |
| 1011 |  |  [ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.878) |  | 0 | Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. In particular, we evaluate ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. Compared to the performance of previous models, our extensive experiments demonstrate the worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning. | Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, Thien Huu Nguyen |  |
| 1012 |  |  [Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training](https://doi.org/10.18653/v1/2023.findings-emnlp.879) |  | 0 | Representational spaces learned via language modeling are fundamental to Natural Language Processing (NLP), however there has been limited understanding regarding how and when during training various types of linguistic information emerge and interact. Leveraging a novel information theoretic probing suite, which enables direct comparisons of not just task performance, but their representational subspaces, we analyze nine tasks covering syntax, semantics and reasoning, across 2M pre-training steps and five seeds. We identify critical learning phases across tasks and time, during which subspaces emerge, share information, and later disentangle to specialize. Across these phases, syntactic knowledge is acquired rapidly after 0.5% of full training. Continued performance improvements primarily stem from the acquisition of open-domain knowledge, while semantics and reasoning tasks benefit from later boosts to long-range contextualization and higher specialization. Measuring cross-task similarity further reveals that linguistically related tasks share information throughout training, and do so more during the critical phase of learning than before or after. Our findings have implications for model interpretability, multi-task learning, and learning from limited data. | Max MüllerEberstein, Rob van der Goot, Barbara Plank, Ivan Titov |  |
| 1013 |  |  [Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.880) |  | 0 | Large Language Models (LLMs) have recently gained the In-Context Learning (ICL) ability with the models scaling up, allowing them to quickly adapt to downstream tasks with only a few demonstration examples prepended in the input sequence. Nonetheless, the current practice of ICL treats all demonstration examples equally, which still warrants improvement, as the quality of examples is usually uneven. In this paper, we investigate how to determine approximately optimal weights for demonstration examples and how to apply them during ICL. To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance. To expedite the weight-searching process, we discretize the continuous weight space and adopt beam search. With approximately optimal weights obtained, we further propose two strategies to apply them to demonstrations at different model positions. Experimental results on 8 text classification tasks show that our approach outperforms conventional ICL by a large margin. Our code are publicly available at https:github.com/Zhe-Young/WICL. | Zhe Yang, Damai Dai, Peiyi Wang, Zhifang Sui |  |
| 1014 |  |  [Difference-Masking: Choosing What to Mask in Continued Pretraining](https://doi.org/10.18653/v1/2023.findings-emnlp.881) |  | 0 | The self-supervised objective of masked prediction has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks. | Alex Wilf, Syeda Nahida Akter, Leena Mathur, Paul Pu Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, LouisPhilippe Morency |  |
| 1015 |  |  [Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation](https://doi.org/10.18653/v1/2023.findings-emnlp.882) |  | 0 | Knowledge distillation is known as an effective technique for compressing over-parameterized language models. In this work, we propose to break down the global feature distillation task into N local sub-tasks. In this new framework, we consider each neuron in the last hidden layer of the teacher network as a specialized sub-teacher. We also consider each neuron in the last hidden layer of the student network as a focused sub-student. We make each focused sub-student learn from one corresponding specialized sub-teacher and ignore the others. This will facilitate the task for the sub-student and keep it focused. Our proposed method is novel and can be combined with other distillation techniques. Empirical results show that our proposed approach outperforms the state-of-the-art methods by maintaining higher performance on most benchmark datasets. Furthermore, we propose a randomized variant of our approach, called Masked One-to-One Mapping. Rather than learning all the N sub-tasks simultaneously, we focus on learning a subset of these sub-tasks at each optimization step. This variant enables the student to digest the received flow of knowledge more effectively and yields superior results. | Khouloud Saadi, Jelena Mitrovic, Michael Granitzer |  |
| 1016 |  |  [IMU2CLIP: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.883) |  | 0 | We present IMU2CLIP, a novel pre-training approach to align Inertial Measurement Unit (IMU) motion sensor recordings with text and video, by projecting them into the joint representation space of Contrastive Language-Image Pre-training (CLIP). The proposed approach allows IMU2CLIP to translate human motions (as measured by IMU sensors) into their corresponding textual descriptions and videos – while preserving the transitivity across these modalities. We introduce several new IMU-based Wearable AI applications such as motion-based media search, or an LM-based multimodal reasoning with motion sensor data – all using text as the grounding platform. In addition, we show that IMU2CLIP significantly improves downstream performances when fine-tuned for each application, demonstrating its universal usage as a new pre-trained resource. Our code and models will be released publicly. | Seungwhan Moon, Andrea Madotto, Zhaojiang Lin, Aparajita Saraf, Amy Bearman, Babak Damavandi |  |
| 1017 |  |  [Conditioning on Dialog Acts improves Empathy Style Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.884) |  | 0 | We explore the role of dialog acts in style transfer, specifically empathy style transfer – rewriting a sentence to make it more empathetic without changing its meaning. Specifically, we use two novel few-shot prompting strategies: target prompting, which only uses examples of the target style (unlike traditional prompting with source/target pairs), and dialog-act-conditioned prompting, which first estimates the dialog act of the source sentence and then makes it more empathetic using few-shot examples of the same dialog act. Our study yields two key findings: (1) Target prompting typically improves empathy more effectively while maintaining the same level of semantic similarity; (2) Dialog acts matter. Dialog-act-conditioned prompting enhances empathy while preserving both semantics and the dialog-act type. Different dialog acts benefit differently from different prompting methods, highlighting the need for further investigation of the role of dialog acts in style transfer. | Renyi Qu, Lyle H. Ungar, João Sedoc |  |
| 1018 |  |  [Systematic Assessment of Factual Knowledge in Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.885) |  | 0 | Previous studies have relied on existing question-answering benchmarks to evaluate the knowledge stored in large language models (LLMs). However, this approach has limitations regarding factual knowledge coverage, as it mostly focuses on generic domains which may overlap with the pretraining data. This paper proposes a framework to systematically assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions and expected answers from the facts stored in a given KG, and then evaluates the accuracy of LLMs in answering these questions. We systematically evaluate the state-of-the-art LLMs with KGs in generic and specific domains. The experiment shows that ChatGPT is consistently the top performer across all domains. We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context. | Linhao Luo, ThuyTrang Vu, Dinh Q. Phung, Gholamreza Haffari |  |
| 1019 |  |  [From Speculation Detection to Trustworthy Relational Tuples in Information Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.886) |  | 0 | Speculation detection is an important NLP task to identify text factuality. However, the extracted speculative information (e.g., speculative polarity, cue, and scope) lacks structure and poses challenges for direct utilization in downstream tasks. Open Information Extraction (OIE), on the other hand, extracts structured tuples as facts, without examining the certainty of these tuples. Bridging this gap between speculation detection and information extraction becomes imperative to generate structured speculative information and trustworthy relational tuples. Existing studies on speculation detection are defined at sentence level; but even if a sentence is determined to be speculative, not all factual tuples extracted from it are speculative. In this paper, we propose to study speculations in OIE tuples and determine whether a tuple is speculative. We formally define the research problem of tuple-level speculation detection. We then conduct detailed analysis on the LSOIE dataset which provides labels for speculative tuples. Lastly, we propose a baseline model SpecTup for this new research task. | Kuicai Dong, Aixin Sun, JungJae Kim, Xiaoli Li |  |
| 1020 |  |  [Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.887) |  | 0 | Generative models have been widely applied to solve extractive tasks, where parts of the input is extracted to form the desired output, and achieved significant success. For example, in extractive question answering (QA), generative models have constantly yielded state-of-the-art results. In this work, we study the issue of tokenization inconsistency that is commonly neglected in training these models. This issue damages the extractive nature of these tasks after the input and output are tokenized inconsistently by the tokenizer, and thus leads to performance drop as well as hallucination. We propose a simple yet effective fix to this issue and conduct a case study on extractive QA. We show that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F1 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets. Further, the model converges faster, and becomes less likely to generate out-of-context answers. Our results demonstrate the need for increased scrutiny regarding how tokenization is done in extractive tasks and the benefits of consistent tokenization during training. | Kaiser Sun, Peng Qi, Yuhao Zhang, Lan Liu, William Yang Wang, Zhiheng Huang |  |
| 1021 |  |  [Dialogue Medical Information Extraction with Medical-Item Graph and Dialogue-Status Enriched Representation](https://doi.org/10.18653/v1/2023.findings-emnlp.888) |  | 0 | The multi-turn doctor-patient dialogue includes rich medical knowledge, like the symptoms of the patient, the diagnosis and medication suggested by the doctor. If mined and represented properly, such medical knowledge can benefit a large range of clinical applications, including diagnosis assistance and medication recommendation. To derive structured knowledge from free text dialogues, we target a critical task: the Dialogue Medical Information Extraction (DMIE). DMIE aims to detect pre-defined clinical meaningful medical items (symptoms, surgery, etc.) as well as their statuses (positive, negative, etc.) from the dialogue. Existing approaches mainly formulate DMIE as a multi-label classification problem and ignore the relationships among medical items and statuses. Different from previous approaches, we propose a heterogeneous graph to model the relationship between items. We further propose two consecutive attention based modules to enrich the item representation with the dialogue and status. In this manner, we are able to model the relationships among medical items and statuses in the DMIE task. Experimental results on the public benchmark data set show that the proposed model outperforms previous works and achieves the state-of-the-art performance. | Lei Gao, Xinnan Zhang, Xian Wu, Shen Ge, Yefeng Zheng |  |
| 1022 |  |  [LogicAttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference](https://doi.org/10.18653/v1/2023.findings-emnlp.889) |  | 0 | Recently Large Language Models (LLMs) such as GPT-3, ChatGPT, and FLAN have led to impressive progress in Natural Language Inference (NLI) tasks. However, these models may rely on simple heuristics or artifacts in the evaluation data to achieve their high performance, which suggests that they still suffer from logical inconsistency. To assess the logical consistency of these models, we propose a LogicAttack, a method to attack NLI models using diverse logical forms of premise and hypothesis, providing a more robust evaluation of their performance. Our approach leverages a range of inference rules from propositional logic, such as Modus Tollens and Bidirectional Dilemma, to generate effective adversarial attacks and identify common vulnerabilities across multiple NLI models. We achieve an average ~53% Attack Success Rate (ASR) across multiple logic-based attacks. Moreover, we demonstrate that incorporating generated attack samples into training enhances the logical reasoning ability of the target model and decreases its vulnerability to logic-based attacks. Data and source code are available at https://github.com/msantoshmadhav/LogicAttack. | Mutsumi Nakamura, Santosh Mashetty, Mihir Parmar, Neeraj Varshney, Chitta Baral |  |
| 1023 |  |  [Decomposed Prompt Tuning via Low-Rank Reparameterization](https://doi.org/10.18653/v1/2023.findings-emnlp.890) |  | 0 | While prompt tuning approaches have achieved competitive performance with high efficiency, we observe that they invariably employ the same initialization process, wherein the soft prompt is either randomly initialized or derived from an existing embedding vocabulary. In contrast to these conventional methods, this study aims to investigate an alternative way to derive soft prompt. Our empirical studies show that the soft prompt typically exhibits a low “intrinsic rank” characteristic. With such observations, we propose decomposed prompt tuning, a novel approach that utilizes low-rank matrices to initialize the soft prompt. Through the low-rank reparameterization, our method significantly reduces the number of trainable parameters while maintaining effectiveness. Experimental results on the SuperGLUE benchmark in both high-resource and low-resource scenarios demonstrate the effectiveness of the proposed method. | Yao Xiao, Lu Xu, Jiaxi Li, Wei Lu, Xiaoli Li |  |
| 1024 |  |  [SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.891) |  | 0 | Building and maintaining end-to-end task bots using minimal human effort is a long-standing challenge in dialog research. In this work, we introduce SGP-TOD, Schema-Guided Prompting for building Task-Oriented Dialog systems effortlessly based on large language models (LLMs). Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct fixed LLMs to generate appropriate responses on novel tasks, without the need for training data. Specifically, SGP-TOD comprises three components: an LLM for interacting with users, a Dialog State Tracking (DST) Prompter to aid the LLM in tracking dialog states with the given belief instruction, and a Policy Prompter to direct the LLM to generate proper responses adhering to the provided dialog policy. Experimental results on Multiwoz, RADDLE, and STAR datasets show that our training-free strategy, SGP-TOD, yields state-of-the-art (SOTA) zero-shot performance, significantly surpassing the few-shot approaches. In a domain-extension setting, SGP-TOD aptly adapts to new functionalities by merely adding supplementary schema rules. We make our code and data publicly available. | Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, Helen Meng |  |
| 1025 |  |  [Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.892) |  | 0 | In this position paper, we argue that instead of morally aligning LLMs to specific set of ethical principles, we should infuse generic ethical reasoning capabilities into them so that they can handle value pluralism at a global scale. When provided with an ethical policy, an LLM should be capable of making decisions that are ethically consistent to the policy. We develop a framework that integrates moral dilemmas with moral principles pertaining to different foramlisms of normative ethics, and at different levels of abstractions. Initial experiments with GPT-x models shows that while GPT-4 is a nearly perfect ethical reasoner, the models still have bias towards the moral values of Western and English speaking societies. | Abhinav Rao, Aditi Khandelwal, Kumar Tanmay, Utkarsh Agarwal, Monojit Choudhury |  |
| 1026 |  |  [Vector-Quantized Prompt Learning for Paraphrase Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.893) |  | 0 | Deep generative modeling of natural languages has achieved many successes, such as producing fluent sentences and translating from one language into another. However, the development of generative modeling techniques for paraphrase generation still lags behind largely due to the challenges in addressing the complex conflicts between expression diversity and semantic preservation. This paper proposes to generate diverse and high-quality paraphrases by exploiting the pre-trained models with instance-dependent prompts. To learn generalizable prompts, we assume that the number of abstract transforming patterns of paraphrase generation (governed by prompts) is finite and usually not large. Therefore, we present vector-quantized prompts as the cues to control the generation of pre-trained models. Extensive experiments demonstrate that the proposed method achieves new state-of-art results on three benchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release all the code upon acceptance. | Haotian Luo, Yixin Liu, Peidong Liu, Xianggen Liu |  |
| 1027 |  |  [Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.894) |  | 0 | Pretrained language models are expected to effectively map input text to a set of vectors while preserving the inherent relationships within the text. Consequently, designing a white-box model to compute metrics that reflect the presence of specific internal relations in these vectors has become a common approach for post-hoc interpretability analysis of pretrained language models. However, achieving interpretability in white-box models and ensuring the rigor of metric computation becomes challenging when the source model lacks inherent interpretability. Therefore, in this paper, we discuss striking a balance in this trade-off and propose a novel line to constructing metrics for understanding the mechanisms of pretrained language models. We have specifically designed a family of metrics along this line of investigation, and the model used to compute these metrics is referred to as the tree topological probe. We conducted measurements on BERT-large by using these metrics. Based on the experimental results, we propose a speculation regarding the working mechanism of BERT-like pretrained language models, as well as a strategy for enhancing fine-tuning performance by leveraging the topological probe to improve specific submodules. | You Li, Jinhui Yin, Yuming Lin |  |
| 1028 |  |  [PARROT: Zero-Shot Narrative Reading Comprehension via Parallel Reading](https://doi.org/10.18653/v1/2023.findings-emnlp.895) |  | 0 | Narrative comprehension is a challenging task that requires a deep understanding of the foundational elements of narratives. Acquiring this skill requires extensive annotated data. To mitigate the burden of data annotation, we present Parrot, a zero-shot approach for narrative reading comprehension through parallel reading, which involves two parallel narratives that tell the same story. By leveraging one narrative as a source of supervision signal to guide the understanding of the other, Parrot abstracts the textual content and develops genuine narrative understanding. Evaluation conducted on two narrative comprehension benchmarks demonstrates that Parrot surpasses previous zero-shot approaches and achieves comparable performance to fully supervised models. The code will be available at https://github.com/zhaochaocs/Parrot. | Chao Zhao, Anvesh Rao Vijjini, Snigdha Chaturvedi |  |
| 1029 |  |  [BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance](https://doi.org/10.18653/v1/2023.findings-emnlp.896) |  | 0 | Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical literature is paramount for public safety, but involves slow and costly manual labor. We set out to improve drug safety monitoring (pharmacovigilance, PV) through the use of Natural Language Processing (NLP). We introduce BioDEX, a large-scale resource for Biomedical adverse Drug Event eXtraction, rooted in the historical output of drug safety reporting in the U.S. BioDEX consists of 65k abstracts and 19k full-text biomedical papers with 256k associated document-level safety reports created by medical experts. The core features of these reports include the reported weight, age, and biological sex of a patient, a set of drugs taken by the patient, the drug dosages, the reactions experienced, and whether the reaction was life threatening. In this work, we consider the task of predicting the core information of the report given its originating paper. We estimate human performance to be 72.0% F1, whereas our best model achieves 59.1% F1 (62.3 validation), indicating significant headroom. We also begin to explore ways in which these models could help professional PV reviewers. Our code and data are available at https://github.com/KarelDO/BioDEX. | Karel D'Oosterlinck, François Remy, Johannes Deleu, Thomas Demeester, Chris Develder, Klim Zaporojets, Aneiss Ghodsi, Simon Ellershaw, Jack Collins, Christopher Potts |  |
| 1030 |  |  [Coarse-to-Fine Dual Encoders are Better Frame Identification Learners](https://doi.org/10.18653/v1/2023.findings-emnlp.897) |  | 0 | Frame identification aims to find semantic frames associated with target words in a sentence. Recent researches measure the similarity or matching score between targets and candidate frames by modeling frame definitions. However, they either lack sufficient representation learning of the definitions or face challenges in efficiently selecting the most suitable frame from over 1000 candidate frames. Moreover, commonly used lexicon filtering (lf) to obtain candidate frames for the target may ignore out-of-vocabulary targets and cause inadequate frame modeling. In this paper, we propose CoFFTEA, a ̲Coarse-to- ̲Fine ̲Frame and ̲Target ̲Encoders ̲Architecture. With contrastive learning and dual encoders, CoFFTEA efficiently and effectively models the alignment between frames and targets. By employing a coarse-to-fine curriculum learning procedure, CoFFTEA gradually learns to differentiate frames with varying degrees of similarity. Experimental results demonstrate that CoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without lf. Further analysis suggests that CoFFTEA can better model the relationships between frame and frame, as well as target and target. The code for our approach is available at https://github.com/pkunlp-icler/COFFTEA. | Kaikai An, Ce Zheng, Bofei Gao, Haozhe Zhao, Baobao Chang |  |
| 1031 |  |  [Sound of Story: Multi-modal Storytelling with Audio](https://doi.org/10.18653/v1/2023.findings-emnlp.898) |  | 0 | Storytelling is multi-modal in the real world. When one tells a story, one may use all of the visualizations and sounds along with the story itself. However, prior studies on storytelling datasets and tasks have paid little attention to sound even though sound also conveys meaningful semantics of the story. Therefore, we propose to extend story understanding and telling areas by establishing a new component called background sound which is story context-based audio without any linguistic information. For this purpose, we introduce a new dataset, called Sound of Story (SoS), which has paired image and text sequences with corresponding sound or background music for a story. To the best of our knowledge, this is the largest well-curated dataset for storytelling with sound. Our SoS dataset consists of 27,354 stories with 19.6 images per story and 984 hours of speech-decoupled audio such as background music and other sounds. As benchmark tasks for storytelling with sound and the dataset, we propose retrieval tasks between modalities, and audio generation tasks from image-text sequences, introducing strong baselines for them. We believe the proposed dataset and tasks may shed light on the multi-modal understanding of storytelling in terms of sound. | Jaeyeon Bae, Seokhoon Jeong, Seokun Kang, Namgi Han, JaeYon Lee, Hyounghun Kim, Taehwan Kim |  |
| 1032 |  |  [Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce](https://doi.org/10.18653/v1/2023.findings-emnlp.899) |  | 0 | In e-commerce, opinion summarization is the process of condensing the opinions presented in product reviews. However, the absence of large amounts of supervised datasets presents challenges in generating both aspect-specific and general opinion summaries. Existing approaches have attempted to address these challenges through synthetic dataset creation (SDC). However, general opinion summarization models struggle to generate summaries faithful to the input reviews whereas aspect-specific opinion summarization models are limited due to their reliance on human-specified aspects and seed words. To address this, we propose SDC strategies tailored for general and aspect-specific opinion summarization. We experimented on three e-commerce test sets: Oposum+, Amazon, and Flipkart. For general opinion summarization, pre-trained language model (PLM) fine-tuned on our general synthetic dataset surpass the SOTA on average by 2.3 R1 points. Faithfulness evaluation metrics and human evaluations indicate that our model-generated summaries are more faithful to the input compared to others. For aspect-specific opinion summarization, PLM fine-tuned on our aspect-specific synthetic dataset surpass SOTA by ~ 1 R1 point without the aid of any human-specified aspects or seed words. | Tejpalsingh Siledar, Suman Banerjee, Amey Patil, Sudhanshu Singh, Muthusamy Chelliah, Nikesh Garera, Pushpak Bhattacharyya |  |
| 1033 |  |  [Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection](https://doi.org/10.18653/v1/2023.findings-emnlp.900) |  | 0 | Rumors spread rapidly through online social microblogs at a relatively low cost, causing substantial economic losses and negative consequences in our daily lives. Existing rumor detection models often neglect the underlying semantic coherence between text and image components in multimodal posts, as well as the challenges posed by incomplete modalities in single modal posts, such as missing text or images. This paper presents CLKD-IMRD, a novel framework for Incomplete Modality Rumor Detection. CLKD-IMRD employs Contrastive Learning and Knowledge Distillation to capture the semantic consistency between text and image pairs, while also enhancing model generalization to incomplete modalities within individual posts. Extensive experimental results demonstrate that our CLKD-IMRD outperforms state-of-the-art methods on two English and two Chinese benchmark datasets for rumor detection in social media. | Fan Xu, Pinyun Fu, Qi Huang, Bowei Zou, AiTi Aw, Mingwen Wang |  |
| 1034 |  |  [Beyond Testers' Biases: Guiding Model Testing with Knowledge Bases using LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.901) |  | 0 | Current model testing work has mostly focused on creating test cases. Identifying what to test is a step that is largely ignored and poorly supported. We propose Weaver, an interactive tool that supports requirements elicitation for guiding model testing. Weaver uses large language models to generate knowledge bases and recommends concepts from them interactively, allowing testers to elicit requirements for further testing. Weaver provides rich external knowledge to testers and encourages testers to systematically explore diverse concepts beyond their own biases. In a user study, we show that both NLP experts and non-experts identified more, as well as more diverse concepts worth testing when using Weaver. Collectively, they found more than 200 failing test cases for stance detection with zero-shot ChatGPT. Our case studies further show that Weaver can help practitioners test models in real-world settings, where developers define more nuanced application scenarios (e.g., code understanding and transcript summarization) using LLMs. | Chenyang Yang, Rishabh Rustogi, Rachel A. BrowerSinning, Grace A. Lewis, Christian Kästner, Tongshuang Wu |  |
| 1035 |  |  [CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.902) |  | 0 | The task of zero-shot commonsense question answering evaluates models on their capacity to reason about general scenarios beyond those presented in specific datasets. Existing approaches for tackling this task leverage external knowledge from CommonSense Knowledge Bases (CSKBs) by pre-training the model on synthetic QA pairs constructed from CSKBs. In these approaches, negative examples (distractors) are formulated by randomly sampling from CSKBs using fairly primitive keyword constraints. However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. To tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization. Specifically, CAR abstracts a commonsense knowledge triple to many higher-level instances, which increases the coverage of the CSKB and expands the ground-truth answer space, reducing the likelihood of selecting false negative distractors. Extensive experiments demonstrate that CAR more robustly generalizes to answering questions about zero-shot commonsense scenarios than existing methods, including large language models, such as GPT3.5 and ChatGPT. Our code, data, and model checkpoints are available at https://github.com/HKUST-KnowComp/CAR. | Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, Yangqiu Song, Antoine Bosselut |  |
| 1036 |  |  [kNN-CM: A Non-parametric Inference-Phase Adaptation of Parametric Text Classifiers](https://doi.org/10.18653/v1/2023.findings-emnlp.903) |  | 0 | Semi-parametric models exhibit the properties of both parametric and non-parametric modeling and have been shown to be effective in the next-word prediction language modeling task. However, there is a lack of studies on the text-discriminating properties of such models. We propose an inference-phase approach—k-Nearest Neighbor Classification Model (kNN-CM)—that enhances the capacity of a pre-trained parametric text classifier by incorporating a simple neighborhood search through the representation space of (memorized) training samples. The final class prediction of kNN-CM is based on the convex combination of probabilities obtained from kNN search and prediction of the classifier. Our experiments show consistent performance improvements on eight SuperGLUE tasks, three adversarial natural language inference (ANLI) datasets, 11 question-answering (QA) datasets, and two sentiment classification datasets. | Rishabh Bhardwaj, Yingting Li, Navonil Majumder, Bo Cheng, Soujanya Poria |  |
| 1037 |  |  [Cross-modality Data Augmentation for End-to-End Sign Language Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.904) |  | 0 | End-to-end sign language translation (SLT) aims to directly convert sign language videos into spoken language texts without intermediate representations. It has been challenging due to the data scarcity of labeled data and the modality gap between sign videos and texts. To tackle these challenges, we propose a novel Cross-modality Data Augmentation (XmDA) framework to transfer the powerful gloss-to-text translation capabilities to end-to-end sign language translation (i.e., video-to-text). Specifically, XmDA consists of two key components: cross-modality mix-up and cross-modality knowledge distillation. The former one explicitly encourages the alignment between sign video features and gloss embeddings to bridge the modality gap. The latter one utilizes the generation knowledge from gloss-to-text teacher models to guide the spoken language text generation. Experimental results on two widely used SLT datasets, i.e., PHOENIX-2014T and CSL-Daily, demonstrate that the proposed XmDA framework significantly and consistently outperforms the baseline models. Extensive analyses confirm our claim that XmDA enhances end-to-end sign language translation by reducing the representation distance between sign videos and glosses, as well as improving the translation of low-frequency words and long sentences. | Jinhui Ye, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Hui Xiong |  |
| 1038 |  |  [Consistency is Key: On Data-Efficient Modality Transfer in Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.905) |  | 0 | End-to-end approaches have shown promising results for speech translation (ST), but they suffer from its data scarcity compared to machine translation (MT). To address this, progressive training has become a common practice, of using external MT data during the fine-tuning phase. Despite of its prevalence and computational overhead, its validity is not extensively corroborated yet. This paper conducts an empirical investigation and finds that progressive training is ineffective. We identify learning-forgetting trade-off as a critical obstacle, then hypothesize and verify that consistency learning (CL) breaks the dilemma of learning-forgetting. The proposed method, which combines knowledge distillation (KD) and CL, outperforms the previous methods on MuST-C dataset even without additional data, and our proposed consistency-informed KD achieves additional improvements against KD+CL. Code and models are availble at https://github.com/hjlee1371/consistency-s2tt. | Hojin Lee, Changmin Lee, Seungwon Hwang |  |
| 1039 |  |  [Relation-Aware Question Answering for Heterogeneous Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.906) |  | 0 | Multi-hop Knowledge Base Question Answering(KBQA) aims to find the answer entity in a knowledge graph (KG), which requires multiple steps of reasoning. Existing retrieval-based approaches solve this task by concentrating on the specific relation at different hops and predicting the intermediate entity within the reasoning path. However, these models fail to utilize information from head-tail entities and the semantic connection between relations to enhance the current relation representation, which undermines the information capturing of relations in KGs. To address this issue, we construct a dual relation graph where each node denotes a relation in the original KG (primal entity graph) and edges are constructed between relations sharing same head or tail entities. Then we iteratively do primal entity graph reasoning, dual relation graph information propagation, and interaction between these two graphs. In this way, the interaction between entity and relation is enhanced, and we derive better entity and relation representations. Experiments on two public datasets, WebQSP and CWQ, show that our approach achieves a significant performance gain over the prior state-of-the-art. | Haowei Du, Quzhe Huang, Chen Li, Chen Zhang, Yang Li, Dongyan Zhao |  |
| 1040 |  |  [InstOptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators](https://doi.org/10.18653/v1/2023.findings-emnlp.907) |  | 0 | Instruction-based language modeling has received significant attention in pretrained language models. However, the efficiency of instruction engineering remains low and hinders the development of instruction studies. Recent studies have focused on automating instruction generation, but they primarily aim to improve performance without considering other crucial objectives that impact instruction quality, such as instruction length and perplexity. Therefore, we propose a novel approach (i.e., InstOptima) that treats instruction generation as an evolutionary multi-objective optimization problem. In contrast to text edition-based methods, our approach utilizes a large language model (LLM) to simulate instruction operators, including mutation and crossover. Furthermore, we introduce an objective-guided mechanism for these operators, allowing the LLM to comprehend the objectives and enhance the quality of the generated instructions. Experimental results demonstrate improved fine-tuning performance and the generation of a diverse set of high-quality instructions. | Heng Yang, Ke Li |  |
| 1041 |  |  [Less than One-shot: Named Entity Recognition via Extremely Weak Supervision](https://doi.org/10.18653/v1/2023.findings-emnlp.908) |  | 0 | We study the named entity recognition (NER) problem under the extremely weak supervision (XWS) setting, where only one example entity per type is given in a context-free way. While one can see that XWS is lighter than one-shot in terms of the amount of supervision, we propose a novel method X-NER that can outperform the state-of-the-art one-shot NER methods. We first mine entity spans that are similar to the example entities from an unlabelled training corpus. Instead of utilizing entity span representations from language models, we find it more effective to compare the context distributions before and after the span is replaced by the entity example. We then leverage the top-ranked spans as pseudo-labels to train an NER tagger. Extensive experiments and analyses on 4 NER datasets show the superior end-to-end NER performance of X-NER, outperforming the state-of-the-art few-shot methods with 1-shot supervision and ChatGPT annotations significantly. Finally, our X-NER possesses several notable properties, such as inheriting the cross-lingual abilities of the underlying language models. | Letian Peng, Zihan Wang, Jingbo Shang |  |
| 1042 |  |  [Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.909) |  | 0 | Transformer-based models have achieved dominant performance in numerous NLP tasks. Despite their remarkable successes, pre-trained transformers such as BERT suffer from a computationally expensive self-attention mechanism that interacts with all tokens, including the ones unfavorable to classification performance. To overcome these challenges, we propose integrating two strategies: token pruning and token combining. Token pruning eliminates less important tokens in the attention mechanism’s key and value as they pass through the layers. Additionally, we adopt fuzzy logic to handle uncertainty and alleviate potential mispruning risks arising from an imbalanced distribution of each token’s importance. Token combining, on the other hand, condenses input sequences into smaller sizes in order to further compress the model. By integrating these two approaches, we not only improve the model’s performance but also reduce its computational demands. Experiments with various datasets demonstrate superior performance compared to baseline models, especially with the best improvement over the existing BERT model, achieving +5%p in accuracy and +5.6%p in F1 score. Additionally, memory cost is reduced to 0.61x, and a speedup of 1.64x is achieved. | Jungmin Yun, Mihyeon Kim, Youngbin Kim |  |
| 1043 |  |  [Semantic Decomposition of Question and SQL for Text-to-SQL Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.910) |  | 0 | Text-to-SQL semantic parsing faces challenges in generalizing to cross-domain and complex queries. Recent research has employed a question decomposition strategy to enhance the parsing of complex SQL queries.However, this strategy encounters two major obstacles: (1) existing datasets lack question decomposition; (2) due to the syntactic complexity of SQL, most complex queries cannot be disentangled into sub-queries that can be readily recomposed. To address these challenges, we propose a new modular Query Plan Language (QPL) that systematically decomposes SQL queries into simple and regular sub-queries. We develop a translator from SQL to QPL by leveraging analysis of SQL server query optimization plans, and we augment the Spider dataset with QPL programs. Experimental results demonstrate that the modular nature of QPL benefits existing semantic-parsing architectures, and training text-to-QPL parsers is more effective than text-to-SQL parsing for semantically equivalent queries. The QPL approach offers two additional advantages: (1) QPL programs can be paraphrased as simple questions, which allows us to create a dataset of (complex question, decomposed questions). Training on this dataset, we obtain a Question Decomposer for data retrieval that is sensitive to database schemas. (2) QPL is more accessible to non-experts for complex queries, leading to more interpretable output from the semantic parser. | Ben Eyal, Moran Mahabi, Ophir Haroche, Amir Bachar, Michael Elhadad |  |
| 1044 |  |  [Time-Aware Language Modeling for Historical Text Dating](https://doi.org/10.18653/v1/2023.findings-emnlp.911) |  | 0 | Automatic text dating(ATD) is a challenging task since explicit temporal mentions usually do not appear in texts. Existing state-of-the-art approaches learn word representations via language models, whereas most of them ignore diachronic change of words, which may affect the efforts of text modeling. Meanwhile, few of them consider text modeling for long diachronic documents. In this paper, we present a time-aware language model named TALM, to learn temporal word representations by transferring language models of general domains to those of time-specific ones. We also build a hierarchical modeling approach to represent diachronic documents by encoding them with temporal word representations. Experiments on a Chinese diachronic corpus show that our model effectively captures implicit temporal information of words, and outperforms state-of-the-art approaches in historical text dating as well. | Han Ren, Hai Wang, Yajie Zhao, Yafeng Ren |  |
| 1045 |  |  [A Read-and-Select Framework for Zero-shot Entity Linking](https://doi.org/10.18653/v1/2023.findings-emnlp.912) |  | 0 | Zero-shot entity linking (EL) aims at aligning entity mentions to unseen entities to challenge the generalization ability. Previous methods largely focus on the candidate retrieval stage and ignore the essential candidate ranking stage, which disambiguates among entities and makes the final linking prediction. In this paper, we propose a read-and-select (ReS) framework by modeling the main components of entity disambiguation, i.e., mention-entity matching and cross-entity comparison. First, for each candidate, the reading module leverages mention context to output mention-aware entity representations, enabling mention-entity matching. Then, in the selecting module, we frame the choice of candidates as a sequence labeling problem, and all candidate representations are fused together to enable cross-entity comparison. Our method achieves the state-of-the-art performance on the established zero-shot EL dataset ZESHEL with a 2.55% micro-average accuracy gain, with no need for laborious multi-phase pre-training used in most of the previous work, showing the effectiveness of both mention-entity and cross-entity interaction. | Zhenran Xu, Yulin Chen, Baotian Hu, Min Zhang |  |
| 1046 |  |  [Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting](https://doi.org/10.18653/v1/2023.findings-emnlp.913) |  | 0 | In conversational search settings, users ask questions and receive answers as part of a conversation. The ambiguity in the questions is a common challenge, which can be effectively addressed by leveraging contextual information from the conversation history. In this context, determining topic continuity and reformulating questions into well-defined queries are crucial tasks. Previous approaches have typically addressed these tasks either as a classification task in the case of topic continuity or as a text generation task for question reformulation. However, no prior work has combined both tasks to effectively identify ambiguous questions as part of a conversation. In this paper, we propose a Multi-Task Learning (MTL) approach that uses a text generation model for both question rewriting and classification. Our models, based on BART and T5, are trained to rewrite conversational questions and identify follow-up questions simultaneously. We evaluate our approach on multiple test sets and demonstrate that it outperforms single-task learning baselines on the three LIF test sets, with statistically significant improvements ranging from +3.5% to +10.5% in terms of F1 and Micro-F1 scores. We also show that our approach outperforms single-task question rewriting models in passage retrieval on a large OR-QuAC test set. | Sarawoot Kongyoung, Craig MacDonald, Iadh Ounis |  |
| 1047 |  |  [DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit](https://doi.org/10.18653/v1/2023.findings-emnlp.914) |  | 0 | Multi-component compounding is a prevalent phenomenon in Sanskrit, and understanding the implicit structure of a compound’s components is crucial for deciphering its meaning. Earlier approaches in Sanskrit have focused on binary compounds and neglected the multi-component compound setting. This work introduces the novel task of nested compound type identification (NeCTI), which aims to identify nested spans of a multi-component compound and decode the implicit semantic relations between them. To the best of our knowledge, this is the first attempt in the field of lexical semantics to propose this task. We present 2 newly annotated datasets including an out-of-domain dataset for this task. We also benchmark these datasets by exploring the efficacy of the standard problem formulations such as nested named entity recognition, constituency parsing and seq2seq, etc. We present a novel framework named DepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the performance of the best baseline with an average absolute improvement of 13.1 points F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement in inference efficiency. In line with the previous findings in the binary Sanskrit compound identification task, context provides benefits for the NeCTI task. The codebase and datasets are publicly available at: https://github.com/yaswanth-iitkgp/DepNeCTI | Jivnesh Sandhan, Yaswanth Narsupalli, Sreevatsa Muppirala, Sriram Krishnan, Pavankumar Satuluri, Amba P. Kulkarni, Pawan Goyal |  |
| 1048 |  |  [HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark](https://doi.org/10.18653/v1/2023.findings-emnlp.915) |  | 0 | Current benchmarks for Hebrew Natural Language Processing (NLP) focus mainly on morpho-syntactic tasks, neglecting the semantic dimension of language understanding. To bridge this gap, we set out to deliver a Hebrew Machine Reading Comprehension (MRC) dataset, where MRC is to be realized as extractive Question Answering. The morphologically-rich nature of Hebrew poses a challenge to this endeavor: the indeterminacy and non-transparency of span boundaries in morphologically complex forms lead to annotation inconsistencies, disagreements, and flaws of standard evaluation metrics. To remedy this, we devise a novel set of guidelines, a controlled crowdsourcing protocol, and revised evaluation metrics, that are suitable for the morphologically rich nature of the language. Our resulting benchmark, HeQ (Hebrew QA), features 30,147 diverse question-answer pairs derived from both Hebrew Wikipedia articles and Israeli tech news. Our empirical investigation reveals that standard evaluation metrics such as F1 Scores and Exact Match (EM) are not appropriate for Hebrew (and other MRLs), and we propose a relevant enhancement. In addition, our experiments show low correlation between models’ performance on morpho-syntactic tasks and on MRC, which suggests that models that are designed for the former might underperform on semantic-heavy tasks. The development and exploration of HeQ illustrate some of the challenges MRLs pose in natural language understanding (NLU), fostering progression towards more and better NLU models for Hebrew and other MRLs. | Amir David Nissan Cohen, Hilla Merhav, Yoav Goldberg, Reut Tsarfaty |  |
| 1049 |  |  [HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis](https://doi.org/10.18653/v1/2023.findings-emnlp.916) |  | 0 | Authorship Analysis, also known as stylometry, has been an essential aspect of Natural Language Processing (NLP) for a long time. Likewise, the recent advancement of Large Language Models (LLMs) has made authorship analysis increasingly crucial for distinguishing between human-written and AI-generated texts. However, these authorship analysis tasks have primarily been focused on written texts, not considering spoken texts. Thus, we introduce the largest benchmark for spoken texts - HANSEN( ̲Human ̲ANd ai ̲Spoken t ̲Ext be ̲Nchmark). HANSEN encompasses meticulous curation of existing speech datasets accompanied by transcripts, alongside the creation of novel AI-generated spoken text datasets. Together, it comprises 17 human datasets, and AI-generated spoken texts created using 3 prominent LLMs: ChatGPT, PaLM2, and Vicuna13B. To evaluate and demonstrate the utility of HANSEN, we perform Authorship Attribution (AA) & Author Verification (AV) on human-spoken datasets and conducted Human vs. AI text detection using state-of-the-art (SOTA) models. While SOTA methods, such as, character n-gram or Transformer-based model, exhibit similar AA & AV performance in human-spoken datasets compared to written ones, there is much room for improvement in AI-generated spoken text detection. The HANSEN benchmark is available at: https://huggingface.co/datasets/HANSEN-REPO/HANSEN | Nafis Irtiza Tripto, Adaku Uchendu, Thai Le, Mattia Setzu, Fosca Giannotti, Dongwon Lee |  |
| 1050 |  |  [Data Augmentation for Code Translation with Comparable Corpora and Multiple References](https://doi.org/10.18653/v1/2023.findings-emnlp.917) |  | 0 | One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of translations by execution. The code is available at https://github.com/Veronicium/CMTrans. | Yiqing Xie, Atharva Naik, Daniel Fried, Carolyn P. Rosé |  |
| 1051 |  |  [Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-emnlp.918) |  | 0 | The ability to bridge Question Generation (QG) and Question Answering (QA) across structured and unstructured modalities has the potential for aiding different NLP applications. One key application is in QA-based methods that have recently been shown to be useful for automatically evaluating Natural Language (NL) texts generated from Knowledge Graphs (KG). While methods have been proposed for QG-QA across these modalities, these efforts have been in English only; in this work, we bring multilinguality (Brazilian Portuguese and Russian) to multimodal (KG and NL) QG-QA. Using synthetic data generation and machine translation to produce QG-QA data that is aligned between graph and text, we are able to train multimodal, multi-task models that can perform multimodal QG and QA in Portuguese and Russian. We show that our approach outperforms a baseline which is derived from previous work on English and adapted to handle these two languages. | Kelvin Han, Claire Gardent |  |
| 1052 |  |  [InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.919) |  | 0 | Diffusion models have garnered considerable interest in the field of text generation. Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization. However, there exists a notable disparity between the “easy-first” text generation process of current diffusion models and the “keyword-first” natural text generation process of humans, which has received limited attention. To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model. Our approach introduces a “keyinfo-first” generation strategy and incorporates a noise schedule based on the amount of text information. In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure. Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency. | Renzhi Wang, Jing Li, Piji Li |  |
| 1053 |  |  [Enhancing Scalability of Pre-trained Language Models via Efficient Parameter Sharing](https://doi.org/10.18653/v1/2023.findings-emnlp.920) |  | 0 | In this paper, we propose a highly parameter-efficient approach to scaling pre-trained language models (PLMs) to a deeper model depth. Unlike prior work that shares all parameters or uses extra blocks, we design a more capable parameter-sharing architecture based on matrix product operator (MPO), an efficient tensor decomposition method to factorize the parameter matrix into a set of local tensors. Based on such a decomposition, we share the important local tensor across all layers for reducing the model size and meanwhile keep layer-specific tensors (also using Adapters) for enhancing the adaptation flexibility. To improve the model training, we further propose a stable initialization algorithm tailored for the MPO-based architecture. Extensive experiments have demonstrated the effectiveness of our proposed model in enhancing scalability and achieving higher performance (i.e., with fewer parameters than BERT-base, we successfully scale the model depth by a factor of 4x and even achieve 0.1 points higher than BERT-large for GLUE score). The code to reproduce the results of this paper can be found at https://github.com/RUCAIBox/MPOBERT-code. | Peiyu Liu, ZeFeng Gao, Yushuo Chen, Xin Zhao, JiRong Wen |  |
| 1054 |  |  [Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.921) |  | 0 | Recently, prompt-based fine-tuning has garnered considerable interest as a core technique for few-shot text classification task. This approach reformulates the fine-tuning objective to align with the Masked Language Modeling (MLM) objective. Leveraging unlabeled data, prompt-based self-training has shown greater effectiveness in binary and three-class classification. However, prompt-based self-training for multi-class classification has not been adequately investigated, despite its significant applicability to real-world scenarios. Moreover, extending current methods to multi-class classification suffers from the verbalizer that extracts the predicted value of manually pre-defined single label word for each class from MLM predictions. Consequently, we introduce a novel, efficient verbalizer structure, named Mapping-free Automatic Verbalizer (MAV). Comprising two fully connected layers, MAV serves as a trainable verbalizer that automatically extracts the requisite word features for classification by capitalizing on all available information from MLM predictions. Experimental results on five multi-class classification datasets indicate MAV’s superior self-training efficacy. | Yookyung Kho, Jaehee Kim, Pilsung Kang |  |
| 1055 |  |  [On the Impact of Cross-Domain Data on German Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.922) |  | 0 | Traditionally, large language models have been either trained on general web crawls or domain-specific data. However, recent successes of generative large language models, have shed light on the benefits of cross-domain datasets. To examine the significance of prioritizing data diversity over quality, we present a German dataset comprising texts from five domains, along with another dataset aimed at containing high-quality data. Through training a series of models ranging between 122M and 750M parameters on both datasets, we conduct a comprehensive benchmark on multiple downstream tasks. Our findings demonstrate that the models trained on the cross-domain dataset outperform those trained on quality data alone, leading to improvements up to 4.45% over the previous state-of-the-art. | Amin Dada, Aokun Chen, Cheng Peng, Kaleb E. Smith, Ahmad IdrissiYaghir, Constantin Seibold, Jianning Li, Lars Heiliger, Christoph M. Friedrich, Daniel Truhn, Jan Egger, Jiang Bian, Jens Kleesiek, Yonghui Wu |  |
| 1056 |  |  [Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation](https://doi.org/10.18653/v1/2023.findings-emnlp.923) |  | 0 | Text normalization methods have been commonly applied to historical language or user-generated content, but less often to dialectal transcriptions. In this paper, we introduce dialect-to-standard normalization – i.e., mapping phonetic transcriptions from different dialects to the orthographic norm of the standard variety – as a distinct sentence-level character transduction task and provide a large-scale analysis of dialect-to-standard normalization methods. To this end, we compile a multilingual dataset covering four languages: Finnish, Norwegian, Swiss German and Slovene. For the two biggest corpora, we provide three different data splits corresponding to different use cases for automatic normalization. We evaluate the most successful sequence-to-sequence model architectures proposed for text normalization tasks using different tokenization approaches and context sizes. We find that a character-level Transformer trained on sliding windows of three words works best for Finnish, Swiss German and Slovene, whereas the pre-trained byT5 model using full sentences obtains the best results for Norwegian. Finally, we perform an error analysis to evaluate the effect of different data splits on model performance. | Olli Kuparinen, Aleksandra Miletic, Yves Scherrer |  |
| 1057 |  |  [Re-Examining Summarization Evaluation across Multiple Quality Criteria](https://doi.org/10.18653/v1/2023.findings-emnlp.924) |  | 0 | The common practice for assessing automatic evaluation metrics is to measure the correlation between their induced system rankings and those obtained by reliable human evaluation, where a higher correlation indicates a better metric. Yet, an intricate setting arises when an NLP task is evaluated by multiple Quality Criteria (QCs), like for text summarization where prominent criteria including relevance, consistency, fluency and coherence. In this paper, we challenge the soundness of this methodology when multiple QCs are involved, concretely for the summarization case. First, we show that the allegedly best metrics for certain QCs actually do not perform well, failing to detect even drastic summary corruptions with respect to the considered QC. To explain this, we show that some of the high correlations obtained in the multi-QC setup are spurious. Finally, we propose a procedure that may help detecting this effect. Overall, our findings highlight the need for further investigating metric evaluation methodologies for the multiple-QC case. | Ori Ernst, Ori Shapira, Ido Dagan, Ran Levy |  |
| 1058 |  |  [A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.925) |  | 0 | The Vietnamese language embodies dialectal variants closely attached to the nation’s three macro-regions: the Northern, Central and Southern regions. As the northern dialect forms the basis of the standard language, it’s considered the prestige dialect. While the northern dialect differs from the remaining two in certain aspects, it almost shares an identical lexicon with the southern dialect, making the textual attributes nearly interchangeable. In contrast, the central dialect possesses a number of unique vocabularies and is less mutually intelligible to the standard dialect. Through preliminary experiments, we observe that current NLP models do not possess understandings of the Vietnamese central dialect text, which most likely originates from the lack of resources. To facilitate research on this domain, we introduce a new parallel corpus for Vietnamese central-northern dialect text transfer. Via exhaustive benchmarking, we discover monolingual language models’ superiority over their multilingual counterparts on the dialect transfer task. We further demonstrate that fine-tuned transfer models can seamlessly improve the performance of existing NLP systems on the central dialect domain with dedicated results in translation and text-image retrieval tasks. | Thang Le, Anh Tuan Luu |  |
| 1059 |  |  [A Comprehensive Evaluation of Tool-Assisted Generation Strategies](https://doi.org/10.18653/v1/2023.findings-emnlp.926) |  | 0 | A growing area of research investigates augmenting language models with tools (e.g., search engines, calculators) to overcome their shortcomings (e.g., missing or incorrect knowledge, incorrect logical inferences). Various few-shot tool-usage strategies have been proposed. However, there is no systematic and fair comparison across different strategies, or between these strategies and strong baselines that do not leverage tools. We conduct an extensive empirical analysis, finding that (1) across various datasets, example difficulty levels, and models, strong no-tool baselines are competitive to tool-assisted strategies, implying that effectively using tools with in-context demonstrations is a difficult unsolved problem; (2) for knowledge-retrieval tasks, strategies that \*refine\* incorrect outputs with tools outperform strategies that retrieve relevant information \*ahead of\* or \*during generation\*; (3) tool-assisted strategies are expensive in the number of tokens they require to work—incurring additional costs by orders of magnitude—which does not translate into significant improvement in performance. Overall, our findings suggest that few-shot tool integration is still an open challenge, emphasizing the need for comprehensive evaluations of future strategies to accurately assess their \*benefits\* and \*costs\*. | Alon Jacovi, Avi Caciularu, Jonathan Herzig, Roee Aharoni, Bernd Bohnet, Mor Geva |  |
| 1060 |  |  [InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT](https://doi.org/10.18653/v1/2023.findings-emnlp.927) |  | 0 | While large models such as GPT-3 demonstrate exceptional performance in zeroshot and fewshot summarization tasks, their extensive serving and fine-tuning costs hinder their utilization in various applications. Conversely, previous studies have found that although automatic metrics tend to favor smaller fine-tuned models, the quality of the summaries they generate is inferior to that of larger models like GPT-3 when assessed by human evaluators. To address this issue, we propose InheritSumm, a versatile and compact summarization model derived from GPT-3.5 through distillation. InheritSumm not only exhibits comparable zeroshot and fewshot summarization capabilities to GPT-3.5 but is also sufficiently compact for fine-tuning purposes. Experimental results demonstrate that InheritSumm achieves similar or superior performance to GPT-3.5 in zeroshot and fewshot settings. Furthermore, it outperforms the previously established best small models in both prefix-tuning and full-data fine-tuning scenarios. | Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuohang Wang, Chenguang Zhu, Michael Zeng |  |
| 1061 |  |  [Learning to love diligent trolls: Accounting for rater effects in the dialogue safety task](https://doi.org/10.18653/v1/2023.findings-emnlp.928) |  | 0 | Chatbots have the risk of generating offensive utterances, which must be avoided. Post-deployment, one way for a chatbot to continuously improve is to source utterance/label pairs from feedback by live users. However, among users are trolls, who provide training examples with incorrect labels. To de-troll training data, previous work removed training examples that have high user-aggregated cross-validation (CV) error. However, CV is expensive; and in a coordinated attack, CV may be overwhelmed by trolls in number and in consistency among themselves. In the present work, I address both limitations by proposing a solution inspired by methodology in automated essay scoring (AES): have multiple users rate each utterance, then perform latent class analysis (LCA) to infer correct labels. As it does not require GPU computations, LCA is inexpensive. In experiments, I found that the AES-like solution can infer training labels with high accuracy when trolls are consistent, even when trolls are the majority. | Michael John Ilagan |  |
| 1062 |  |  [Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal Scenarios Like a Lawyer?](https://doi.org/10.18653/v1/2023.findings-emnlp.929) |  | 0 | Large Language Models (LLMs), such as ChatGPT, have drawn a lot of attentions recently in the legal domain due to its emergent ability to tackle a variety of legal tasks. However, it is still unknown if LLMs are able to analyze a legal case and perform reasoning in the same manner as lawyers. Therefore, we constructed a novel corpus consisting of scenarios pertain to Contract Acts Malaysia and Australian Social Act for Dependent Child. ChatGPT is applied to perform analysis on the corpus using the IRAC method, which is a framework widely used by legal professionals for organizing legal analysis. Each scenario in the corpus is annotated with a complete IRAC analysis in a semi-structured format so that both machines and legal professionals are able to interpret and understand the annotations. In addition, we conducted the first empirical assessment of ChatGPT for IRAC analysis in order to understand how well it aligns with the analysis of legal professionals. Our experimental results shed lights on possible future research directions to improve alignments between LLMs and legal experts in terms of legal reasoning. | Xiaoxi Kang, Lizhen Qu, LayKi Soon, Adnan Trakic, Terry Yue Zhuo, Patrick Charles Emerton, Genevieve Grant |  |
| 1063 |  |  [Coverage-based Example Selection for In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.930) |  | 0 | In-context learning (ICL), the ability of large language models to perform novel tasks by conditioning on a prompt with a few task examples, requires these examples to be informative about the test instance. The standard approach of independently ranking and selecting the most similar examples selects redundant examples while omitting important information. In this work, we show that BERTScore-Recall (BSR) selects better examples that demonstrate more of the salient aspects, e.g. reasoning patterns, of the test input. We further extend BSR and many standard metrics to easily optimizable set-level metrics, giving still better coverage of those salient aspects. On 15 datasets spanning 6 tasks and with 7 diverse LLMs, we show that (1) BSR is the superior metric for in-context example selection across the board, and (2) for compositional tasks, set selection using Set-BSR outperforms independent ranking by up to 17 points on average and, despite being training-free, surpasses methods that leverage task or LLM-specific training. | Shivanshu Gupta, Matt Gardner, Sameer Singh |  |
| 1064 |  |  [Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization](https://doi.org/10.18653/v1/2023.findings-emnlp.931) |  | 0 | Large language models (LLMs) have exhibited considerable cross-lingual generalization abilities, whereby they implicitly transfer knowledge across languages. However, the transfer is not equally successful for all languages, especially for low-resource ones, which poses an ongoing challenge. It is unclear whether we have reached the limits of implicit cross-lingual generalization and if explicit knowledge transfer is viable. In this paper, we investigate the potential for explicitly aligning conceptual correspondence between languages to enhance cross-lingual generalization. Using the syntactic aspect of language as a testbed, our analyses of 43 languages reveal a high degree of alignability among the spaces of structural concepts within each language for both encoder-only and decoder-only LLMs. We then propose a meta-learning-based method to learn to align conceptual spaces of different languages, which facilitates zero-shot and few-shot generalization in concept classification and also offers insights into the cross-lingual in-context learning phenomenon. Experiments on syntactic analysis tasks show that our approach achieves competitive results with state-of-the-art methods and narrows the performance gap between languages, particularly benefiting those with limited resources. | Ningyu Xu, Qi Zhang, Jingting Ye, Menghan Zhang, Xuanjing Huang |  |
| 1065 |  |  [Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing](https://doi.org/10.18653/v1/2023.findings-emnlp.932) |  | 0 | Dual use, the intentional, harmful reuse of technology and scientific artefacts, is an ill-defined problem within the context of Natural Language Processing (NLP). As large language models (LLMs) have advanced in their capabilities and become more accessible, the risk of their intentional misuse becomes more prevalent. To prevent such intentional malicious use, it is necessary for NLP researchers and practitioners to understand and mitigate the risks of their research. Hence, we present an NLP-specific definition of dual use informed by researchers and practitioners in the field. Further, we propose a checklist focusing on dual-use in NLP, that can be integrated into existing conference ethics-frameworks. The definition and checklist are created based on a survey of NLP researchers and practitioners. | LucieAimée Kaffee, Arnav Arora, Zeerak Talat, Isabelle Augenstein |  |
| 1066 |  |  [BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions](https://doi.org/10.18653/v1/2023.findings-emnlp.933) |  | 0 | Text classification is a well-studied and versatile building block for many NLP applications. Yet, existing approaches require either large annotated corpora to train a model with or, when using large language models as a base, require carefully crafting the prompt as well as using a long context that can fit many examples. As a result, it is not possible for end-users to build classifiers for themselves. To address this issue, we propose a novel approach to few-shot text classification using an LLM. Rather than few-shot examples, the LLM is prompted with descriptions of the salient features of each class. These descriptions are coauthored by the user and the LLM interactively: while the user annotates each few-shot example, the LLM asks relevant questions that the user answers. Examples, questions, and answers are summarized to form the classification prompt. Our experiments show that our approach yields high accuracy classifiers, within 79% of the performance of models trained with significantly larger datasets while using only 1% of their training sets. Additionally, in a study with 30 participants, we show that end-users are able to build classifiers to suit their specific needs. The personalized classifiers show an average accuracy of 90%, which is 15% higher than the state-of-the-art approach. | Arth Bohra, Govert Verkes, Artem Harutyunyan, Pascal Weinberger, Giovanni Campagna |  |
| 1067 |  |  [Approximating CKY with Transformers](https://doi.org/10.18653/v1/2023.findings-emnlp.934) |  | 0 | We investigate the ability of transformer models to approximate the CKY algorithm, using them to directly predict a sentence’s parse and thus avoid the CKY algorithm’s cubic dependence on sentence length. We find that on standard constituency parsing benchmarks this approach achieves competitive or better performance than comparable parsers that make use of CKY, while being faster. We also evaluate the viability of this approach for parsing under random PCFGs. Here we find that performance declines as the grammar becomes more ambiguous, suggesting that the transformer is not fully capturing the CKY computation. However, we also find that incorporating additional inductive bias is helpful, and we propose a novel approach that makes use of gradients with respect to chart representations in predicting the parse, in analogy with the CKY algorithm being a subgradient of a partition function variant with respect to the chart. | Ghazal Khalighinejad, Ollie Liu, Sam Wiseman |  |
| 1068 |  |  [DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines](https://doi.org/10.18653/v1/2023.findings-emnlp.935) |  | 0 | Dialogue models are able to generate coherent and fluent responses, but they can still be challenging to control and may produce non-engaging, unsafe results. This unpredictability diminishes user trust and can hinder the use of the models in the real world. To address this, we introduce DialGuide, a novel framework for controlling dialogue model behavior using natural language rules, or guidelines. These guidelines provide information about the context they are applicable to and what should be included in the response, allowing the models to generate responses that are more closely aligned with the developer’s expectations and intent. We evaluate DialGuide on three tasks in open-domain dialogue response generation: guideline selection, response generation, and response entailment verification. Our dataset contains 10,737 positive and 15,467 negative dialogue context-response-guideline triplets across two domains - chit-chat and safety. We provide baseline models for the tasks and benchmark their performance. We also demonstrate that DialGuide is effective in the dialogue safety domain, producing safe and engaging responses that follow developer guidelines. | Prakhar Gupta, Yang Liu, Di Jin, Behnam Hedayatnia, Spandana Gella, Sijia Liu, Patrick Lange, Julia Hirschberg, Dilek HakkaniTur |  |
| 1069 |  |  [RWKV: Reinventing RNNs for the Transformer Era](https://doi.org/10.18653/v1/2023.findings-emnlp.936) |  | 0 | Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit linear scaling in memory and computational requirements but struggle to match the same performance as Transformers due to limitations in parallelization and scalability. We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of transformers with the efficient inference of RNNs. Our approach leverages a linear attention mechanism and allows us to formulate the model as either a Transformer or an RNN, thus parallelizing computations during training and maintains constant computational and memory complexity during inference. We scale our models as large as 14 billion parameters, by far the largest dense RNN ever trained, and find RWKV performs on par with similarly sized Transformers, suggesting future work can leverage this architecture to create more efficient models. This work presents a significant step towards reconciling trade-offs between computational efficiency and model performance in sequence processing tasks. | Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Chung, Leon Derczynski, Xingjian Du, Matteo Grella, Kranthi Kiran GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartlomiej Koptyra, Hayden Lau, Jiaju Lin, Krishna Sri Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Johan S. Wind, Stanislaw Wozniak, Zhenyuan Zhang, Qinghua Zhou, Jian Zhu, RuiJie Zhu |  |
| 1070 |  |  [Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification](https://doi.org/10.18653/v1/2023.findings-emnlp.937) |  | 0 | Authorship verification (AV) is a fundamental task in natural language processing (NLP) and computational linguistics, with applications in forensic analysis, plagiarism detection, and identification of deceptive content. Existing AV techniques, including traditional stylometric and deep learning approaches, face limitations in terms of data requirements and lack of explainability. To address these limitations, this paper proposes PromptAV, a novel technique that leverages Large-Language Models (LLMs) for AV by providing step-by-step stylometric explanation prompts. PromptAV outperforms state-of-the-art baselines, operates effectively with limited training data, and enhances interpretability through intuitive explanations, showcasing its potential as an effective and interpretable solution for the AV task. | ChiaYu Hung, Zhiqiang Hu, Yujia Hu, Roy KaWei Lee |  |
| 1071 |  |  [Transitioning Representations between Languages for Cross-lingual Event Detection via Langevin Dynamics](https://doi.org/10.18653/v1/2023.findings-emnlp.938) |  | 0 | Cross-lingual transfer learning (CLTL) for event detection (ED) aims to develop models in high-resource source languages that can be directly applied to produce effective performance for lower-resource target languages. Previous research in this area has focused on representation matching methods to develop a language-universal representation space into which source- and target-language example representations can be mapped to achieve cross-lingual transfer. However, as this approach modifies the representations for the source-language examples, the models might lose discriminative features for ED that are learned over training data of the source language to prevent effective predictions. To this end, our work introduces a novel approach for cross-lingual ED where we only aim to transition the representations for the target-language examples into the source-language space, thus preserving the representations in the source language and their discriminative information. Our method introduces Langevin Dynamics to perform representation transition and a semantic preservation framework to retain event type features during the transition process. Extensive experiments over three languages demonstrate the state-of-the-art performance for ED in CLTL. | Chien Nguyen, Huy Nguyen, Franck Dernoncourt, Thien Huu Nguyen |  |
| 1072 |  |  [VISIT: Visualizing and Interpreting the Semantic Information Flow of Transformers](https://doi.org/10.18653/v1/2023.findings-emnlp.939) |  | 0 | Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them more human interpretable. In this paper, we investigate LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through this projection, we identify patterns in the information flow inside the attention mechanism. Based on our discoveries, we create a tool to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph, with nodes representing neurons or hidden states and edges representing the interactions between them. Our visualization simplifies huge amounts of data into easy-to-read plots that can reflect the models’ internal processing, uncovering the contribution of each component to the models’ final prediction. Our visualization also unveils new insights about the role of layer norms as semantic filters that influence the models’ output, and about neurons that are always activated during forward passes and act as regularization vectors. | Shahar Katz, Yonatan Belinkov |  |
| 1073 |  |  [Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?](https://doi.org/10.18653/v1/2023.findings-emnlp.940) |  | 0 | Robustness, the ability of models to maintain performance in the face of perturbations, is critical for developing reliable NLP systems. Recent studies have shown promising results in improving the robustness of models through adversarial training and data augmentation. However, in machine translation, most of these studies have focused on bilingual machine translation with a single translation direction. In this paper, we investigate the transferability of robustness across different languages in multilingual neural machine translation. We propose a robustness transfer analysis protocol and conduct a series of experiments. In particular, we use character-, word-, and multi-level noises to attack the specific translation direction of the multilingual neural machine translation model and evaluate the robustness of other translation directions. Our findings demonstrate that the robustness gained in one translation direction can indeed transfer to other translation directions. Additionally, we empirically find scenarios where robustness to character-level noise and word-level noise is more likely to transfer. | Leiyu Pan, Supryadi, Deyi Xiong |  |
| 1074 |  |  [Arabic Mini-ClimateGPT : A Climate Change and Sustainability Tailored Arabic LLM](https://doi.org/10.18653/v1/2023.findings-emnlp.941) |  | 0 | Climate change is one of the most significant challenges we face together as a society. Creating awareness and educating policy makers the wide-ranging impact of climate change is an essential step towards a sustainable future. Recently, Large Language Models (LLMs) like ChatGPT and Bard have shown impressive conversational abilities and excel in a wide variety of NLP tasks. While these models are close-source, recently alternative open-source LLMs such as Stanford Alpaca and Vicuna have shown promising results. However, these open-source models are not specifically tailored for climate related domain specific information and also struggle to generate meaningful responses in other languages such as, Arabic. To this end, we propose a light-weight Arabic Mini-ClimateGPT that is built on an open-source LLM and is specifically fine-tuned on a conversational-style instruction tuning curated Arabic dataset Clima500-Instruct with over 500k instructions about climate change and sustainability. Further, our model also utilizes a vector embedding based retrieval mechanism during inference. We validate our proposed model through quantitative and qualitative evaluations on climate-related queries. Our model surpasses the baseline LLM in 88.3% of cases during ChatGPT-based evaluation. Furthermore, our human expert evaluation reveals an 81.6% preference for our model’s responses over multiple popular open-source models. Our open-source demos, models and curated instruction sets are available here : https://github.com/mbzuai-oryx/ClimateGPT | Sahal Shaji Mullappilly, Abdelrahman M. Shaker, Omkar Thawakar, Hisham Cholakkal, Rao Muhammad Anwer, Salman H. Khan, Fahad Shahbaz Khan |  |
| 1075 |  |  [Interpreting Answers to Yes-No Questions in User-Generated Content](https://doi.org/10.18653/v1/2023.findings-emnlp.942) |  | 0 | Interpreting answers to yes-no questions in social media is difficult. Yes and no keywords are uncommon, and the few answers that include them are rarely to be interpreted what the keywords suggest. In this paper, we present a new corpus of 4,442 yes-no question-answer pairs from Twitter. We discuss linguistic characteristics of answers whose interpretation is yes or no, as well as answers whose interpretation is unknown. We show that large language models are far from solving this problem, even after fine-tuning and blending other corpora for the same problem but outside social media. | Shivam Mathur, Keun Hee Park, Dhivya Chinnappa, Saketh Kotamraju, Eduardo Blanco |  |
| 1076 |  |  [Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.943) |  | 0 | Dialogue discourse parsing is a fundamental natural language processing task. It can benefit a series of conversation-related downstream tasks including dialogue summarization and emotion recognition in conversations. However, existing parsing approaches are constrained by predefined relation types, which can impede the adaptability of the parser for downstream tasks. To this end, we propose to introduce a task-aware paradigm to improve the versatility of the parser in this paper. Moreover, to alleviate error propagation and learning bias, we design a graph-based discourse parsing model termed DialogDP. Building upon the symmetrical property of matrix-embedded parsing graphs, we have developed an innovative self-supervised mechanism that leverages both bottom-up and top-down parsing strategies. This approach allows the parsing graphs to mutually regularize and enhance each other. Empirical studies on dialogue discourse parsing datasets and a downstream task demonstrate the effectiveness and flexibility of our framework. | Wei Li, Luyao Zhu, Wei Shao, Zonglin Yang, Erik Cambria |  |
| 1077 |  |  [Selective Demonstrations for Cross-domain Text-to-SQL](https://doi.org/10.18653/v1/2023.findings-emnlp.944) |  | 0 | Large language models (LLMs) with in-context learning have demonstrated impressive generalization capabilities in the cross-domain text-to-SQL task, without the use of in-domain annotations. However, incorporating in-domain demonstration examples has been found to greatly enhance LLMs’ performance. In this paper, we delve into the key factors within in-domain examples that contribute to the improvement and explore whether we can harness these benefits without relying on in-domain annotations. Based on our findings, we propose a demonstration selection framework, ODIS, which utilizes both out-of-domain examples and synthetically generated in-domain examples to construct demonstrations. By retrieving demonstrations from hybrid sources, ODIS leverages the advantages of both, showcasing its effectiveness compared to baseline methods that rely on a single data source. Furthermore, ODIS outperforms state-of-the-art approaches on two cross-domain text-to-SQL datasets, with improvements of 1.1 and 11.8 points in execution accuracy, respectively. | Shuaichen Chang, Eric FoslerLussier |  |
| 1078 |  |  [DocSplit: Simple Contrastive Pretraining for Large Document Embeddings](https://doi.org/10.18653/v1/2023.findings-emnlp.945) |  | 0 | Existing model pretraining methods only consider local information. For example, in the popular token masking strategy, the words closer to the masked token are more important for prediction than words far away. This results in pretrained models that generate high-quality sentence embeddings, but low-quality embeddings for large documents. We propose a new pretraining method called DocSplit which forces models to consider the entire global context of a large document. Our method uses a contrastive loss where the positive examples are randomly sampled sections of the input document, and negative examples are randomly sampled sections of unrelated documents. Like previous pretraining methods, DocSplit is fully unsupervised, easy to implement, and can be used to pretrain any model architecture. Our experiments show that DocSplit outperforms other pretraining methods for document classification, few shot learning, and information retrieval tasks. | Yujie Wang, Mike Izbicki |  |
| 1079 |  |  [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.946) |  | 0 | While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied and yet to be benchmarked. However, conducting such benchmarking studies is challenging because of the large variations in LLMs’ performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, this paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw more accurate conclusions about LLMs’ performance on a specific complex task. | Shubhra Kanti Karmaker Santu, Dongji Feng |  |
| 1080 |  |  [IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery](https://doi.org/10.18653/v1/2023.findings-emnlp.947) |  | 0 | Identifying intents from dialogue utterances forms an integral component of task-oriented dialogue systems. Intent-related tasks are typically formulated either as a classification task, where the utterances are classified into predefined categories or as a clustering task when new and previously unknown intent categories need to be discovered from these utterances. Further, the intent classification may be modeled in a multiclass (MC) or multilabel (ML) setup. While typically these tasks are modeled as separate tasks, we propose IntenDD a unified approach leveraging a shared utterance encoding backbone. IntenDD uses an entirely unsupervised contrastive learning strategy for representation learning, where pseudo-labels for the unlabeled utterances are generated based on their lexical features. Additionally, we introduce a two-step post-processing setup for the classification tasks using modified adsorption. Here, first, the residuals in the training data are propagated followed by smoothing the labels both modeled in a transductive setting. Through extensive evaluations on various benchmark datasets, we find that our approach consistently outperforms competitive baselines across all three tasks. On average, IntenDD reports percentage improvements of 2.32 %, 1.26 %, and 1.52 % in their respective metrics for few-shot MC, few-shot ML, and the intent discovery tasks respectively. | Bhavuk Singhal, Ashim Gupta, Shivasankaran V. P, Amrith Krishna |  |
| 1081 |  |  [INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion](https://doi.org/10.18653/v1/2023.findings-emnlp.948) |  | 0 | Computer-aided translation (CAT) aims to enhance human translation efficiency and is still important in scenarios where machine translation cannot meet quality requirements. One fundamental task within this field is Word-Level Auto Completion (WLAC). WLAC predicts a target word given a source sentence, translation context, and a human typed character sequence. Previous works either employ word classification models to exploit contextual information from both sides of the target word or directly disregarded the dependencies from the right-side context. Furthermore, the key information, i.e. human typed sequences, is only used as prefix constraints in the decoding module. In this paper, we propose the INarIG (Iterative Non-autoregressive Instruct Generation) model, which constructs the human typed sequence into Instruction Unit and employs iterative decoding with subwords to fully utilize input information given in the task. Our model is more competent in dealing with low-frequency words (core scenario of this task), and achieves state-of-the-art results on the WMT22 and benchmark datasets, with a maximum increase of over 10% prediction accuracy. | Hengchao Shang, Zongyao Li, Daimeng Wei, Jiaxin Guo, Minghan Wang, Xiaoyu Chen, Lizhi Lei, Hao Yang |  |
| 1082 |  |  [Is the Answer in the Text? Challenging ChatGPT with Evidence Retrieval from Instructive Text](https://doi.org/10.18653/v1/2023.findings-emnlp.949) |  | 0 | Generative language models have recently shown remarkable success in generating answers to questions in a given textual context. However, these answers may suffer from hallucination, wrongly cite evidence, and spread misleading information. In this work, we address this problem by employing ChatGPT, a state-of-the-art generative model, as a machine-reading system. We ask it to retrieve answers to lexically varied and open-ended questions from trustworthy instructive texts. We introduce WHERE (WikiHow Evidence REtrieval), a new high-quality evaluation benchmark of a set of WikiHow articles exhaustively annotated with evidence sentences to questions that comes with a special challenge: All questions are about the article’s topic, but not all can be answered using the provided context. We interestingly find that when using a regular question-answering prompt, ChatGPT neglects to detect the unanswerable cases. When provided with a few examples, it learns to better judge whether a text provides answer evidence or not. Alongside this important finding, our dataset defines a new benchmark for evidence retrieval in question answering, which we argue is one of the necessary next steps for making large language models more trustworthy. | Sophie Henning, Talita Anthonio, Wei Zhou, Heike Adel, Mohsen Mesgar, Annemarie Friedrich |  |
| 1083 |  |  [PaRaDe: Passage Ranking using Demonstrations with LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.950) |  | 0 | Recent studies show that large language models (LLMs) can be instructed to effectively perform zero-shot passage re-ranking, in which the results of a first stage retrieval method, such as BM25, are rated and reordered to improve relevance. In this work, we improve LLM-based re-ranking by algorithmically selecting few-shot demonstrations to include in the prompt. Our analysis investigates the conditions where demonstrations are most helpful, and shows that adding even one demonstration is significantly beneficial. We propose a novel demonstration selection strategy based on difficulty rather than the commonly used semantic similarity. Furthermore, we find that demonstrations helpful for ranking are also effective at question generation. We hope our work will spur more principled research into question generation and passage ranking. | Andrew Drozdov, Honglei Zhuang, Zhuyun Dai, Zhen Qin, Razieh Rahimi, Xuanhui Wang, Dana Alon, Mohit Iyyer, Andrew McCallum, Donald Metzler, Kai Hui |  |
| 1084 |  |  [Learning Dynamic Representations for Discourse Dependency Parsing](https://doi.org/10.18653/v1/2023.findings-emnlp.951) |  | 0 | Transition systems have been widely used for the discourse dependency parsing task. Existing works often characterize transition states by examining a certain number of elementary discourse units (EDUs), while neglecting the arcs obtained from the transition history. In this paper, we propose to employ GAT-based encoder to learn dynamic representations for sub-trees constructed in previous transition steps. By incorporating these representations, our model is able to retain accessibility to all parsed EDUs through the obtained arcs, thus better utilizing the structural information of the document, particularly when handling lengthy text spans with complex structures. For the discourse relation recognition task, we employ edge-featured GATs to derive better representations for EDU pairs. Experimental results show that our model can achieve state-of-the-art performance on widely adopted datasets including RST-DT, SciDTB and CDTB. Our code is available at https://github.com/lty-lty/Discourse-Dependency-Parsing. | Tianyi Liu, Yansong Feng, Dongyan Zhao |  |
| 1085 |  |  [K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings](https://doi.org/10.18653/v1/2023.findings-emnlp.952) |  | 0 | Numerous datasets have been proposed to combat the spread of online hate. Despite these efforts, a majority of these resources are English-centric, primarily focusing on overt forms of hate. This research gap calls for developing high-quality corpora in diverse languages that also encapsulate more subtle hate expressions. This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings. This resource is the largest offensive language corpus in Korean and is the first to offer target-specific ratings on a three-point Likert scale, enabling the detection of hate expressions in Korean across varying degrees of offensiveness. We conduct experiments showing the effectiveness of the proposed corpus, including a comparison with existing datasets. Additionally, to address potential noise and bias in human annotations, we explore a novel idea of adopting the Cognitive Reflection Test, which is widely used in social science for assessing an individual’s cognitive ability, as a proxy of labeling quality. Findings indicate that annotations from individuals with the lowest test scores tend to yield detection models that make biased predictions toward specific target groups and are less accurate. This study contributes to the NLP research on hate speech detection and resource construction. The code and dataset can be accessed at https://github.com/ssu-humane/K-HATERS. | Chaewon Park, Soohwan Kim, Kyubyong Park, Kunwoo Park |  |
| 1086 |  |  [Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.953) |  | 0 | Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework which only requires target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective than strong baselines both in long-tail languages and in high-resource languages. We also demonstrate that our approach is capable of transferring knowledge between domains and languages in zero-shot scenarios. | Wen Lai, Alexandra Chronopoulou, Alexander Fraser |  |
| 1087 |  |  [BotPercent: Estimating Bot Populations in Twitter Communities](https://doi.org/10.18653/v1/2023.findings-emnlp.954) |  | 0 | Twitter bot detection is vital in combating misinformation and safeguarding the integrity of social media discourse. While malicious bots are becoming more and more sophisticated and personalized, standard bot detection approaches are still agnostic to social environments (henceforth, communities) the bots operate at. In this work, we introduce community-specific bot detection, estimating the percentage of bots given the context of a community. Our method—BotPercent—is an amalgamation of Twitter bot detection datasets and feature-, text-, and graph-based models, adjusted to a particular community on Twitter. We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations. Experiments demonstrate that BotPercent achieves state-of-the-art performance in community-level Twitter bot detection across both balanced and imbalanced class distribution settings, presenting a less biased estimator of Twitter bot populations within the communities we analyze. We then analyze bot rates in several Twitter groups, including users who engage with partisan news media, political communities in different countries, and more. Our results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making. The implementation of BotPercent is available at https://github.com/TamSiuhin/BotPercent. | Zhaoxuan Tan, Shangbin Feng, Melanie Sclar, Herun Wan, Minnan Luo, Yejin Choi, Yulia Tsvetkov |  |
| 1088 |  |  [The Locality and Symmetry of Positional Encodings](https://doi.org/10.18653/v1/2023.findings-emnlp.955) |  | 0 | Positional Encodings (PEs) are used to inject word-order information into transformer-based language models. While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order. In this work, we conduct a systematic study of positional encodings in Bidirectional Masked Language Models (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly. We believe that these results are the basis for developing better PEs for transformer-based language models. | Lihu Chen, Gaël Varoquaux, Fabian M. Suchanek |  |
| 1089 |  |  [Towards a Deep Understanding of Multilingual End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.956) |  | 0 | In this paper, we employ Singular Value Canonical Correlation Analysis (SVCCA) to analyze representations learnt in a multilingual end-to-end speech translation model trained over 22 languages. SVCCA enables us to estimate representational similarity across languages and layers, enhancing our understanding of the functionality of multilingual speech translation and its potential connection to multilingual neural machine translation. The multilingual speech translation model is trained on the CoVoST 2 dataset in all possible directions, and we utilize LASER to extract parallel bitext data for SVCCA analysis. We derive three major findings from our analysis: (I) Linguistic similarity loses its efficacy in multilingual speech translation when the training data for a specific language is limited. (II) Enhanced encoder representations and well-aligned audio-text data significantly improve translation quality, surpassing the bilingual counterparts when the training data is not compromised. (III) The encoder representations of multilingual speech translation demonstrate superior performance in predicting phonetic features in linguistic typology prediction. With these findings, we propose that releasing the constraint of limited data for low-resource languages and subsequently combining them with linguistically related high-resource languages could offer a more effective approach for multilingual end-to-end speech translation. | Haoran Sun, Xiaohu Zhao, Yikun Lei, Shaolin Zhu, Deyi Xiong |  |
| 1090 |  |  [An Empirical Investigation of Implicit and Explicit Knowledge-Enhanced Methods for Ad Hoc Dataset Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.957) |  | 0 | Ad hoc dataset retrieval has become an important way of finding data on the Web, where the underlying problem is how to measure the relevance of a dataset to a query. State-of-the-art solutions for this task are still lexical methods, which cannot capture semantic similarity. Semantics-aware knowledge-enhanced retrieval methods, which achieved promising results on other tasks, have yet to be systematically studied on this specialized task. To fill the gap, in this paper, we present an empirical investigation of the task where we implement and evaluate, on two test collections, a set of implicit and explicit knowledge-enhancement retrieval methods in various settings. Our results reveal the unique features of the task and suggest an interpolation of different kinds of methods as the current best practice. | Weiqing Luo, Qiaosheng Chen, Zhiyang Zhang, Zixian Huang, Gong Cheng |  |
| 1091 |  |  [A Multi-Modal Multilingual Benchmark for Document Image Classification](https://doi.org/10.18653/v1/2023.findings-emnlp.958) |  | 0 | Document image classification is different from plain-text document classification and consists of classifying a document by understanding the content and structure of documents such as forms, emails, and other such documents. We show that the only existing dataset for this task (Lewis et al., 2006) has several limitations and we introduce two newly curated multilingual datasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We further undertake a comprehensive study of popular visually-rich document understanding or Document AI models in previously untested setting in document image classification such as 1) multi-label classification, and 2) zero-shot cross-lingual transfer setup. Experimental results show limitations of multilingual Document AI models on cross-lingual transfer across typologically distant languages. Our datasets and findings open the door for future research into improving Document AI models. | Yoshinari Fujinuma, Siddharth Varia, Nishant Sankaran, Srikar Appalaraju, Bonan Min, Yogarshi Vyas |  |
| 1092 |  |  [Unnatural language processing: How do language models handle machine-generated prompts?](https://doi.org/10.18653/v1/2023.findings-emnlp.959) |  | 0 | Language model prompt optimization research has shown that semantically and grammatically well-formed manually crafted prompts are routinely outperformed by automatically generated token sequences with no apparent meaning or syntactic structure, including sequences of vectors from a model’s embedding space. We use machine-generated prompts to probe how models respond to input that is not composed of natural language expressions. We study the behavior of models of different sizes in multiple semantic tasks in response to both continuous and discrete machine-generated prompts, and compare it to the behavior in response to human-generated natural-language prompts. Even when producing a similar output, machine-generated and human prompts trigger different response patterns through the network processing pathways, including different perplexities, different attention and output entropy distributions, and different unit activation profiles. We provide preliminary insight into the nature of the units activated by different prompt types, suggesting that only natural language prompts recruit a genuinely linguistic circuit. | Corentin Kervadec, Francesca Franzon, Marco Baroni |  |
| 1093 |  |  [Investigating the Effectiveness of Multiple Expert Models Collaboration](https://doi.org/10.18653/v1/2023.findings-emnlp.960) |  | 0 | This paper aims to investigate the effectiveness of several machine translation (MT) models and aggregation methods in a multi-domain setting under fair conditions and explore a direction for tackling multi-domain MT. We mainly compare the performance of the single model approach by jointly training all domains and the multi-expert models approach with a particular aggregation strategy. We conduct experiments on multiple domain datasets and demonstrate that a combination of smaller domain expert models can outperform a larger model trained for all domain data. | Ikumi Ito, Takumi Ito, Jun Suzuki, Kentaro Inui |  |
| 1094 |  |  [Gradually Excavating External Knowledge for Implicit Complex Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.961) |  | 0 | Recently, large language models (LLMs) have gained much attention for the emergence of human-comparable capabilities and huge potential. However, for open-domain implicit question-answering problems, LLMs may not be the ultimate solution due to the reasons of: 1) uncovered or out-of-date domain knowledge, 2) one-shot generation and hence restricted comprehensiveness. To this end, this work proposes a gradual knowledge excavation framework for open-domain complex question answering, where LLMs iteratively and actively acquire extrinsic information, then reason based on acquired historical knowledge. Specifically, during each step of the solving process, the model selects an action to execute, such as querying external knowledge or performing a single logical reasoning step, to gradually progress toward a final answer. Our method can effectively leverage plug-and-play external knowledge and dynamically adjust the strategy for solving complex questions. Evaluated on the StrategyQA dataset, our method achieves 78.17% accuracy with less than 6% parameters of its competitors, setting new SOTA in the ~10B LLM class. | Chang Liu, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, Edmund Y. Lam, Ngai Wong |  |
| 1095 |  |  [Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.962) |  | 0 | The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting CovidET-Appraisals, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. CovidET-Appraisals presents an ideal testbed to evaluate the ability of large language models — excelling at a wide range of NLP tasks — to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public. | Hongli Zhan, Desmond C. Ong, Junyi Jessy Li |  |
| 1096 |  |  [Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.963) |  | 0 | The impressive achievements of transformers force NLP researchers to delve into how these models represent the underlying structure of natural language. In this paper, we propose a novel standpoint to investigate the above issue: using typological similarities among languages to observe how their respective monolingual models encode structural information. We aim to layer-wise compare transformers for typologically similar languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered Kernel Alignment to measure similarity among weight matrices. We found that syntactic typological similarity is consistent with the similarity between the weights in the middle layers, which are the pretrained BERT layers to which syntax encoding is generally attributed. Moreover, we observe that a domain adaptation on semantically equivalent texts enhances this similarity among weight matrices. | Elena Sofia Ruzzetti, Federico Ranaldi, Felicia Logozzo, Michele Mastromattei, Leonardo Ranaldi, Fabio Massimo Zanzotto |  |
| 1097 |  |  [Discourse Sense Flows: Modelling the Rhetorical Style of Documents across Various Domains](https://doi.org/10.18653/v1/2023.findings-emnlp.964) |  | 0 | Recent research on shallow discourse parsing has given renewed attention to the role of discourse relation signals, in particular explicit connectives and so-called alternative lexicalizations. In our work, we first develop new models for extracting signals and classifying their senses, both for explicit connectives and alternative lexicalizations, based on the Penn Discourse Treebank v3 corpus. Thereafter, we apply these models to various raw corpora, and we introduce ‘discourse sense flows’, a new way of modeling the rhetorical style of a document by the linear order of coherence relations, as captured by the PDTB senses. The corpora span several genres and domains, and we undertake comparative analyses of the sense flows, as well as experiments on automatic genre/domain discrimination using discourse sense flow patterns as features. We find that n-gram patterns are indeed stronger predictors than simple sense (unigram) distributions. | René Knaebel, Manfred Stede |  |
| 1098 |  |  [HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling](https://doi.org/10.18653/v1/2023.findings-emnlp.965) |  | 0 | In task-oriented dialogue scenarios, cross-domain zero-shot slot filling plays a vital role in leveraging source domain knowledge to learn a model with high generalization ability in unknown target domain where annotated data is unavailable. However, the existing state-of-the-art zero-shot slot filling methods have limited generalization ability in target domain, they only show effective knowledge transfer on seen slots and perform poorly on unseen slots. To alleviate this issue, we present a novel Hierarchical Contrastive Learning Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse- to fine-grained contrastive learning based on Gaussian-distributed embedding to learn the generalized deep semantic relations between utterance-tokens, by optimizing inter- and intra-token distribution distance. This encourages HiCL to generalize to the slot types unseen at training phase. Furthermore, we present a new iterative label set semantics inference method to unbiasedly and separately evaluate the performance of unseen slot types which entangled with their counterparts (i.e., seen slot types) in the previous zero-shot slot filling evaluation methods. The extensive empirical experiments on four datasets demonstrate that the proposed method achieves comparable or even better performance than the current state-of-the-art zero-shot slot filling approaches. | Junwen Zhang, Yin Zhang |  |
| 1099 |  |  [A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing](https://doi.org/10.18653/v1/2023.findings-emnlp.966) |  | 0 | We evaluate a range of recent LLMs on English creative writing, a challenging and complex task that requires imagination, coherence, and style. We use a difficult, open-ended scenario chosen to avoid training data reuse: an epic narration of a single combat between Ignatius J. Reilly, the protagonist of the Pulitzer Prize-winning novel A Confederacy of Dunces (1980), and a pterodactyl, a prehistoric flying reptile. We ask several LLMs and humans to write such a story and conduct a human evalution involving various criteria such as fluency, coherence, originality, humor, and style. Our results show that some state-of-the-art commercial LLMs match or slightly outperform our writers in most dimensions; whereas open-source LLMs lag behind. Humans retain an edge in creativity, while humor shows a binary divide between LLMs that can handle it comparably to humans and those that fail at it. We discuss the implications and limitations of our study and suggest directions for future research. | Carlos GómezRodríguez, Paul Williams |  |
| 1100 |  |  [1-PAGER: One Pass Answer Generation and Evidence Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.967) |  | 0 | We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent ‘closed-book’ question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval. | Palak Jain, Livio Soares, Tom Kwiatkowski |  |
| 1101 |  |  [Context-faithful Prompting for Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.968) |  | 0 | Large language models (LLMs) encode parametric knowledge about world facts and have shown remarkable performance in knowledge-driven NLP tasks. However, their reliance on parametric knowledge may cause them to overlook contextual cues, leading to incorrect predictions in context-sensitive NLP tasks (e.g., knowledge acquisition tasks). In this paper, we seek to assess and enhance LLMs’ contextual faithfulness in two aspects: knowledge conflict and prediction with abstention. We demonstrate that LLMs’ faithfulness can be significantly improved using carefully designed prompting strategies. In particular, we identify opinion-based prompts and counterfactual demonstrations as the most effective methods. Opinion-based prompts reframe the context as a narrator’s statement and inquire about the narrator’s opinions, while counterfactual demonstrations use instances containing false facts to improve faithfulness in knowledge conflict situations. Neither technique requires additional training. We conduct experiments on three datasets of two standard NLP tasks, machine reading comprehension and relation extraction, and the results demonstrate significant improvement in faithfulness to contexts. Code and data are released at https://github.com/wzhouad/context-faithful-llm. | Wenxuan Zhou, Sheng Zhang, Hoifung Poon, Muhao Chen |  |
| 1102 |  |  [InfoCL: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective](https://doi.org/10.18653/v1/2023.findings-emnlp.969) |  | 0 | Continual learning (CL) aims to constantly learn new knowledge over time while avoiding catastrophic forgetting on old tasks. We focus on continual text classification under the class-incremental setting. Recent CL studies have identified the severe performance decrease on analogous classes as a key factor for catastrophic forgetting. In this paper, through an in-depth exploration of the representation learning process in CL, we discover that the compression effect of the information bottleneck leads to confusion on analogous classes. To enable the model learn more sufficient representations, we propose a novel replay-based continual text classification method, InfoCL. Our approach utilizes fast-slow and current-past contrastive learning to perform mutual information maximization and better recover the previously learned representations. In addition, InfoCL incorporates an adversarial memory augmentation strategy to alleviate the overfitting problem of replay. Experimental results demonstrate that InfoCL effectively mitigates forgetting and achieves state-of-the-art performance on three text classification tasks. | Yifan Song, Peiyi Wang, Weimin Xiong, Dawei Zhu, Tianyu Liu, Zhifang Sui, Sujian Li |  |
| 1103 |  |  [Sparse Frame Grouping Network with Action Centered for Untrimmed Video Paragraph Captioning](https://doi.org/10.18653/v1/2023.findings-emnlp.970) |  | 0 | Generating paragraph captions for untrimmed videos without event annotations is challenging, especially when aiming to enhance precision and minimize repetition at the same time. To address this challenge, we propose a module called Sparse Frame Grouping (SFG). It dynamically groups event information with the help of action information for the entire video and excludes redundant frames within pre-defined clips. To enhance the performance, an Intra Contrastive Learning technique is designed to align the SFG module with the core event content in the paragraph, and an Inter Contrastive Learning technique is employed to learn action-guided context with reduced static noise simultaneously. Extensive experiments are conducted on two benchmark datasets (ActivityNet Captions and YouCook2). Results demonstrate that SFG outperforms the state-of-the-art methods on all metrics. | Guorui Yu, Yimin Hu, Yuejie Zhang, Rui Feng, Tao Zhang, Shang Gao |  |
| 1104 |  |  [Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery](https://doi.org/10.18653/v1/2023.findings-emnlp.971) |  | 0 | Binary code analysis has immense importance in the research domain of software security. Today, software is very often compiled for various Instruction Set Architectures (ISAs). As a result, cross-architecture binary code analysis has become an emerging problem. Recently, deep learning-based binary analysis has shown promising success. It is widely known that training a deep learning model requires a massive amount of data. However, for some low-resource ISAs, an adequate amount of data is hard to find, preventing deep learning from being widely adopted for binary analysis. To overcome the data scarcity problem and facilitate cross-architecture binary code analysis, we propose to apply the ideas and techniques in Neural Machine Translation (NMT) to binary code analysis. Our insight is that a binary, after disassembly, is represented in some assembly language. Given a binary in a low-resource ISA, we translate it to a binary in a high-resource ISA (e.g., x86). Then we can use a model that has been trained on the high-resource ISA to test the translated binary. We have implemented the model called UNSUPERBINTRANS, and conducted experiments to evaluate its performance. Specifically, we conducted two downstream tasks, including code similarity detection and vulnerability discovery. In both tasks, we achieved high accuracies. | Iftakhar Ahmad, Lannan Luo |  |
| 1105 |  |  [Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.972) |  | 0 | We address the task of evidence retrieval for long document question answering, which involves locating relevant paragraphs within a document to answer a question. We aim to assess the applicability of large language models (LLMs) in the task of zero-shot long document evidence retrieval, owing to their unprecedented performance across various NLP tasks. However, currently the LLMs can consume limited context lengths as input, thus providing document chunks as inputs might overlook the global context while missing out on capturing the inter-segment dependencies. Moreover, directly feeding the large input sets can incur significant computational costs, particularly when processing the entire document (and potentially incurring monetary expenses with enterprise APIs like OpenAI’s GPT variants). To address these challenges, we propose a suite of techniques that exploit the discourse structure commonly found in documents. By utilizing this structure, we create a condensed representation of the document, enabling a more comprehensive understanding and analysis of relationships between different parts. We retain 99.6% of the best zero-shot approach’s performance, while processing only 26% of the total tokens used by the best approach in the information seeking evidence retrieval setup. We also show how our approach can be combined with \*self-ask\* reasoning agent to achieve best zero-shot performance in complex multi-hop question answering, just ≈ 4% short of zero-shot performance using gold evidence. | Inderjeet Nair, Shwetha Somasundaram, Apoorv Saxena, Koustava Goswami |  |
| 1106 |  |  [Emergent Inabilities? Inverse Scaling Over the Course of Pretraining](https://doi.org/10.18653/v1/2023.findings-emnlp.973) |  | 0 | Does inverse scaling only occur as a function of model size, or can it also occur over the course of training? We carry out an exploratory study investigating whether the performance of language models on specific tasks can decrease (while general performance remains high) during training on the language modeling task. We find 8 tasks on which Pythia 12B (Biderman et al., 2023) shows decreased performance over the course of training. Five of these tasks (TruthfulQA-MC1, TruthfulQA-MC2, Hindsight Neglect, Memo Trap, and Pattern Match Suppression) additionally show a consistent relationship whereby larger language models show a greater decrease in performance the more they are trained, despite showing standard (positive) scaling overall. This highlights the importance of testing performance at all relevant benchmarks any time models are trained on additional data, even if their overall performance improves. | James A. Michaelov, Ben Bergen |  |
| 1107 |  |  [Alignment Precedes Fusion: Open-Vocabulary Named Entity Recognition as Context-Type Semantic Matching](https://doi.org/10.18653/v1/2023.findings-emnlp.974) |  | 0 | Despite the significant progress in developing named entity recognition models, scaling to novel-emerging types still remains challenging in real-world scenarios. Continual learning and zero-shot learning approaches have been explored to handle novel-emerging types with less human supervision, but they have not been as successfully adopted as supervised approaches. Meanwhile, humans possess a much larger vocabulary size than these approaches and have the ability to learn the alignment between entities and concepts effortlessly through natural supervision. In this paper, we consider a more realistic and challenging setting called open-vocabulary named entity recognition (OVNER) to imitate human-level ability. OVNER aims to recognize entities in novel types by their textual names or descriptions. Specifically, we formulate OVNER as a semantic matching task and propose a novel and scalable two-stage method called Context-Type SemAntiC Alignment and FusiOn (CACAO). In the pre-training stage, we adopt Dual-Encoder for context-type semantic alignment and pre-train Dual-Encoder on 80M context-type pairs which are easily accessible through natural supervision. In the fine-tuning stage, we use Cross-Encoder for context-type semantic fusion and fine-tune Cross-Encoder on base types with human supervision. Experimental results show that our method outperforms the previous state-of-the-art methods on three challenging OVNER benchmarks by 9.7%, 9.5%, and 1.8% F1-score of novel types. Moreover, CACAO also demonstrates its flexible transfer ability in cross-domain NER. | Zhuoran Jin, Pengfei Cao, Zhitao He, Yubo Chen, Kang Liu, Jun Zhao |  |
| 1108 |  |  [Representation Projection Invariance Mitigates Representation Collapse](https://doi.org/10.18653/v1/2023.findings-emnlp.975) |  | 0 | Fine-tuning contextualized representations learned by pre-trained language models remains a prevalent practice in NLP. However, fine-tuning can lead to representation degradation (also known as representation collapse), which may result in instability, sub-optimal performance, and weak generalization. In this paper, we propose Representation Projection Invariance (REPINA), a novel regularization method to maintain the information content of representation and reduce representation collapse during fine-tuning by discouraging undesirable changes in the representations. We study the empirical behavior of the proposed regularization in comparison to 5 comparable baselines across 13 language understanding tasks (GLUE benchmark and six additional datasets). When evaluating in-domain performance, REPINA consistently outperforms other baselines on most tasks (10 out of 13). Additionally, REPINA improves out-of-distribution performance. We also demonstrate its effectiveness in few-shot settings and robustness to label perturbation. As a by-product, we extend previous studies of representation collapse and propose several metrics to quantify it. Our empirical findings show that our approach is significantly more effective at mitigating representation collapse. | Anastasia Razdaibiedina, Ashish Khetan, Zohar Karnin, Daniel Khashabi, Vivek Madan |  |
| 1109 |  |  [Tunable Soft Prompts are Messengers in Federated Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.976) |  | 0 | Federated learning (FL) enables multiple participants to collaboratively train machine learning models using decentralized data sources, alleviating privacy concerns that arise from directly sharing local data. However, the lack of model privacy protection in FL becomes an unneglectable challenge, especially when people want to federally finetune models based on a proprietary large language model. In this study, we propose a novel FL training approach that accomplishes information exchange among participants via tunable soft prompts. These soft prompts, updated and transmitted between the server and clients, assume the role of the global model parameters and serve as messengers to deliver useful knowledge from the local data and global model. As the global model itself is not required to be shared and the local training is conducted based on an auxiliary model with fewer parameters than the global model, the proposed approach provides protection for the global model while reducing communication and computation costs in FL. Extensive experiments show the effectiveness of the proposed approach compared to several baselines. We have released the source code at https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp. | Chenhe Dong, Yuexiang Xie, Bolin Ding, Ying Shen, Yaliang Li |  |
| 1110 |  |  [Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting](https://doi.org/10.18653/v1/2023.findings-emnlp.977) |  | 0 | Automatically generated reports from medical images promise to improve the workflow of radiologists. Existing methods consider an image-to-report modeling task by directly generating a fully-fledged report from an image. However, this conflates the content of the report (e.g., findings and their attributes) with its style (e.g., format and choice of words), which can lead to clinically inaccurate reports. To address this, we propose a two-step approach for radiology report generation. First, we extract the content from an image; then, we verbalize the extracted content into a report that matches the style of a specific radiologist. For this, we leverage RadGraph—a graph representation of reports—together with large language models (LLMs). In our quantitative evaluations, we find that our approach leads to beneficial performance. Our human evaluation with clinical raters highlights that the AI-generated reports are indistinguishably tailored to the style of individual radiologist despite leveraging only a few examples as context. | Benjamin Yan, Ruochen Liu, David E. Kuo, Subathra Adithan, Eduardo Pontes Reis, Stephen Kwak, Vasantha Kumar Venugopal, Chloe O'Connell, Agustina Saenz, Pranav Rajpurkar, Michael Moor |  |
| 1111 |  |  [Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs](https://doi.org/10.18653/v1/2023.findings-emnlp.978) |  | 0 | This paper presents an in-depth study of multimodal machine translation (MMT), examining the prevailing understanding that MMT systems exhibit decreased sensitivity to visual information when text inputs are complete. Instead, we attribute this phenomenon to insufficient cross-modal interaction, rather than image information redundancy. A novel approach is proposed to generate parallel Visual Question-Answering (VQA) style pairs from the source text, fostering more robust cross-modal interaction. Using Large Language Models (LLMs), we explicitly model the probing signal in MMT to convert it into VQA-style data to create the Multi30K-VQA dataset. An MMT-VQA multitask learning framework is introduced to incorporate explicit probing signals from the dataset into the MMT training process. Experimental results on two widely-used benchmarks demonstrate the effectiveness of this novel approach. Our code and data would be available at: https://github.com/libeineu/MMT-VQA. | Yuxin Zuo, Bei Li, Chuanhao Lv, Tong Zheng, Tong Xiao, JingBo Zhu |  |
| 1112 |  |  [GenKIE: Robust Generative Multimodal Document Key Information Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.979) |  | 0 | Key information extraction (KIE) from scanned documents has gained increasing attention because of its applications in various domains. Although promising results have been achieved by some recent KIE approaches, they are usually built based on discriminative models, which lack the ability to handle optical character recognition (OCR) errors and require laborious token-level labeling. In this paper, we propose a novel generative end-to-end model, named GenKIE, to address the KIE task. GenKIE is a sequence-to-sequence multimodal generative model that utilizes multimodal encoders to embed visual, layout and textual features and a decoder to generate the desired output. Well-designed prompts are leveraged to incorporate the label semantics as the weakly supervised signals and entice the generation of the key information. One notable advantage of the generative model is that it enables automatic correction of OCR errors. Besides, token-level granular annotation is not required. Extensive experiments on multiple public real-world datasets show that GenKIE effectively generalizes over different types of documents and achieves state-of-the-art results. Our experiments also validate the model’s robustness against OCR errors, making GenKIE highly applicable in real-world scenarios. | Panfeng Cao, Ye Wang, Qiang Zhang, Zaiqiao Meng |  |
| 1113 |  |  [Improving Multimodal Sentiment Analysis: Supervised Angular margin-based Contrastive Learning for Enhanced Fusion Representation](https://doi.org/10.18653/v1/2023.findings-emnlp.980) |  | 0 | The effectiveness of a model is heavily reliant on the quality of the fusion representation of multiple modalities in multimodal sentiment analysis. Moreover, each modality is extracted from raw input and integrated with the rest to construct a multimodal representation. Although previous methods have proposed multimodal representations and achieved promising results, most of them focus on forming positive and negative pairs, neglecting the variation in sentiment scores within the same class. Additionally, they fail to capture the significance of unimodal representations in the fusion vector. To address these limitations, we introduce a framework called Supervised Angular-based Contrastive Learning for Multimodal Sentiment Analysis. This framework aims to enhance discrimination and generalizability of the multimodal representation and overcome biases in the fusion vector’s modality. Our experimental results, along with visualizations on two widely used datasets, demonstrate the effectiveness of our approach. | CongDuy Nguyen, Thong Nguyen, Duc Anh Vu, Anh Tuan Luu |  |
| 1114 |  |  [Efficient Multilingual Language Model Compression through Vocabulary Trimming](https://doi.org/10.18653/v1/2023.findings-emnlp.981) |  | 0 | Multilingual language models (LMs) have become a powerful tool in NLP, especially for non-English languages. Nevertheless, model parameters of multilingual LMs remain large due to the larger embedding matrix of the vocabulary covering tokens in different languages. Instead, monolingual LMs can be trained in a target language with the language-specific vocabulary only. In this paper, we propose vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a target language by deleting potentially irrelevant tokens from its vocabulary. In theory, VT can compress any existing multilingual LM to any language covered by the original model. In our experiments, we show that VT can retain the original performance of the multilingual LM, while being considerably smaller in size than the original multilingual LM. The evaluation is performed over four NLP tasks (two generative and two classification tasks) among four widely used multilingual LMs in seven languages. The results show that this methodology can keep the best of both monolingual and multilingual worlds by keeping a small size as monolingual models without the need for specifically retraining them, and can even help limit potentially harmful social biases. | Asahi Ushio, Yi Zhou, José CamachoCollados |  |
| 1115 |  |  [ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding](https://doi.org/10.18653/v1/2023.findings-emnlp.982) |  | 0 | Most multilingual vision-and-language (V&L) research aims to accomplish multilingual and multimodal capabilities within one model. However, the scarcity of multilingual captions for images has hindered the development. To overcome this obstacle, we propose ICU, Image Caption Understanding, which divides a V&L task into two stages: a V&L model performs image captioning in English, and a multilingual language model (mLM), in turn, takes the caption as the alt text and performs cross-lingual language understanding. The burden of multilingual processing is lifted off V&L model and placed on mLM. Since the multilingual text data is relatively of higher abundance and quality, ICU can facilitate the conquering of language barriers for V&L models. In experiments on two tasks across 9 languages in the IGLUE benchmark, we show that ICU can achieve new state-of-the-art results for five languages, and comparable results for the rest. | Guojun Wu |  |
| 1116 |  |  [GTA: Gated Toxicity Avoidance for LM Performance Preservation](https://doi.org/10.18653/v1/2023.findings-emnlp.983) |  | 0 | Caution: This paper includes offensive words that could potentially cause unpleasantness. The fast-paced evolution of generative language models such as GPT-4 has demonstrated outstanding results in various NLP generation tasks. However, due to the potential generation of offensive words related to race or gender, various Controllable Text Generation (CTG) methods have been proposed to mitigate the occurrence of harmful words. However, existing CTG methods not only reduce toxicity but also negatively impact several aspects of the language model’s generation performance, including topic consistency, grammar, and perplexity. This paper explores the limitations of previous methods and introduces a novel solution in the form of a simple Gated Toxicity Avoidance (GTA) that can be applied to any CTG method. We also evaluate the effectiveness of the proposed GTA by comparing it with state-of-the-art CTG methods across various datasets. Our findings reveal that gated toxicity avoidance efficiently achieves comparable levels of toxicity reduction to the original CTG methods while preserving the generation performance of the language model. | Heegyu Kim, Hyunsouk Cho |  |
| 1117 |  |  [LMGQS: A Large-scale Dataset for Query-focused Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.984) |  | 0 | Query-focused summarization (QFS) aims to extract or generate a summary of an input document that directly answers or is relevant to a given query. The lack of large-scale datasets in the form of documents, queries, and summaries has hindered model development in this area. In contrast, multiple large-scale high-quality datasets for generic summarization exist. We hypothesize that there is a hidden query for each summary sentence in a generic summarization annotation, and we utilize a large-scale pretrained language model to recover it. In this way, we convert four generic summarization benchmarks into a new QFS benchmark dataset, LMGQS, which consists of over 1 million document-query-summary samples. We thoroughly investigate the properties of our proposed dataset and establish baselines with state-of-the-art summarization models. By fine-tuning a language model on LMGQS, we achieve state-of-the-art zero-shot and supervised performance on multiple existing QFS benchmarks, demonstrating the high quality and diversity of LMGQS. | Ruochen Xu, Song Wang, Yang Liu, Shuohang Wang, Yichong Xu, Dan Iter, Pengcheng He, Chenguang Zhu, Michael Zeng |  |
| 1118 |  |  [ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.985) |  | 0 | Although large language models (LLMs) have achieved excellent performance in a variety of evaluation benchmarks, they still struggle in complex reasoning tasks which require specific knowledge and multi-hop reasoning. To improve the reasoning abilities, we propose ChatCoT, a tool-augmented chain-of-thought reasoning framework for chat-based LLMs (e.g., ChatGPT). In ChatCoT, we model the chain-of-thought (CoT) reasoning as multi-turn conversations, to utilize tools in a more natural way through chatting. At each turn, LLMs can either interact with tools or perform the reasoning. Our approach can effectively leverage the multi-turn conversation ability of chat-based LLMs, and integrate the thought chain following and tools manipulation in a unified way. Specially, we initialize the early turns of the conversation by the knowledge about tools, tasks, and reasoning format, and propose an iterative tool-augmented reasoning step to perform step-by-step tool-augmented reasoning. The experiment results on two complex reasoning datasets (MATH and HotpotQA) have shown the effectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relative improvement over the state-of-the-art baseline. | Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Xin Zhao, JiRong Wen |  |
| 1119 |  |  [Non-Autoregressive Document-Level Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.986) |  | 0 | Non-autoregressive translation (NAT) models achieve comparable performance and superior speed compared to auto-regressive translation (AT) models in the context of sentence-level machine translation (MT). However, their abilities are unexplored in document-level MT, hindering their usage in real scenarios. In this paper, we conduct a comprehensive examination of typical NAT models in the context of document-level MT and further propose a simple but effective design of sentence alignment between source and target. Experiments show that NAT models achieve high acceleration on documents, and sentence alignment significantly enhances their performance. However, current NAT models still have a significant performance gap compared to their AT counterparts. Further investigation reveals that NAT models suffer more from the multi-modality and misalignment issues in the context of document-level MT, and current NAT models struggle with exploiting document context and handling discourse phenomena. We delve into these challenges and provide our code at https://github.com/baoguangsheng/nat-on-doc. | Guangsheng Bao, Zhiyang Teng, Hao Zhou, Jianhao Yan, Yue Zhang |  |
| 1120 |  |  [Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.987) |  | 0 | Prior works have shown the promising results of commonsense knowledge-aware models in improving informativeness while reducing the hallucination issue. Nonetheless, prior works often can only use monolingual knowledge whose language is consistent with the dialogue context. Except for a few high-resource languages, such as English and Chinese, most languages suffer from insufficient knowledge issues, especially minority languages. To this end, this work proposes a new task, Multi-Lingual Commonsense Knowledge-Aware Response Generation (MCKRG), which tries to use commonsense knowledge in other languages to enhance the current dialogue generation. Then, we construct a MCKRG dataset MCK-Dialog of seven languages with multiple alignment methods. Finally, we verify the effectiveness of using multi-lingual commonsense knowledge with a proposed MCK-T5 model. Extensive experimental results demonstrate the great potential of using multi-lingual commonsense knowledge in high-resource and low-resource languages. To the best of our knowledge, this work is the first to explore Multi-Lingual Commonsense Knowledge-Aware Response Generation. | Sixing Wu, Jiong Yu, Tianshi Che, Yang Zhou, Wei Zhou |  |
| 1121 |  |  [Mixture of Soft Prompts for Controllable Data Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.988) |  | 0 | Large language models (LLMs) effectively generate fluent text when the target output follows natural language patterns. However, structured prediction tasks confine the output format to a limited ontology, causing even very large models to struggle since they were never trained with such restrictions in mind. The difficulty of using LLMs for direct prediction is exacerbated in few-shot learning scenarios, which commonly arise due to domain shift and resource limitations. We flip the problem on its head by leveraging the LLM as a tool for data augmentation rather than direct prediction. Our proposed Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating multi-attribute data in a controlled manner. Denoising mechanisms are further applied to improve the quality of synthesized data. Automatic metrics show our method is capable of producing diverse and natural text, while preserving label semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks when compared against strong baselines. Our method offers an alternate data-centric approach for applying LLMs to complex prediction tasks. | Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, Zhou Yu |  |
| 1122 |  |  [A Boundary Offset Prediction Network for Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.989) |  | 0 | Named entity recognition (NER) is a fundamental task in natural language processing that aims to identify and classify named entities in text. However, span-based methods for NER typically assign entity types to text spans, resulting in an imbalanced sample space and neglecting the connections between non-entity and entity spans. To address these issues, we propose a novel approach for NER, named the Boundary Offset Prediction Network (BOPN), which predicts the boundary offsets between candidate spans and their nearest entity spans. By leveraging the guiding semantics of boundary offsets, BOPN establishes connections between non-entity and entity spans, enabling non-entity spans to function as additional positive samples for entity detection. Furthermore, our method integrates entity type and span representations to generate type-aware boundary offsets instead of using entity types as detection targets. We conduct experiments on eight widely-used NER datasets, and the results demonstrate that our proposed BOPN outperforms previous state-of-the-art methods. | Minghao Tang, Yongquan He, Yongxiu Xu, Hongbo Xu, Wenyuan Zhang, Yang Lin |  |
| 1123 |  |  [Prefix-Tuning Based Unsupervised Text Style Transfer](https://doi.org/10.18653/v1/2023.findings-emnlp.990) |  | 0 | Unsupervised text style transfer aims at training a generative model that can alter the style of the input sentence while preserving its content without using any parallel data. In this paper, we employ powerful pre-trained large language models and present a new prefix-tuning-based method for unsupervised text style transfer. We construct three different kinds of prefixes, i.e., shared prefix, style prefix, and content prefix, to encode task-specific information, target style, and the content information of the input sentence, respectively. Compared to embeddings used by previous works, the proposed prefixes can provide richer information for the model. Furthermore, we adopt a recursive way of using language models in the process of style transfer. This strategy provides a more effective way for the interactions between the input sentence and GPT-2, helps the model construct more informative prefixes, and thus, helps improve the performance. Evaluations on the well-known datasets show that our method outperforms the state-of-the-art baselines. Results, analysis of ablation studies, and subjective evaluations from humans are also provided for a deeper understanding of the proposed method. | Huiyu Mai, Wenhao Jiang, ZhiHong Deng |  |
| 1124 |  |  [Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation](https://doi.org/10.18653/v1/2023.findings-emnlp.991) |  | 0 | Code pre-trained models (CodePTMs) have significantly advanced the field of neural code intelligence. Despite their capabilities, these models are susceptible to adversarial attacks that subtly modify the model inputs, resulting in incorrect outputs or predictions. Previous methods of robustness evaluation for CodePTMs primarily stem from a textual perspective, without explicitly taking into account the structure of the code. Furthermore, prior studies fail to encompass a broad enough spectrum of tasks and models. In this paper, we propose a set of novel robustness evaluation methods based on the intrinsic structure of the code. Specifically, we first launch adversarial attacks on crucial identifier tokens and sub-tree structures to explore the impact of imperceptible perturbation. Then, we perform global restructuring of the code using different traversal methods for abstract syntax trees, aiming to explore the model’s sensitivity to input samples with equivalent information. Moreover, for each scenario, we employ adversarial training methods to explore the possibility of restoring the performance of perturbed models. For both code understanding and generation, our proposed method has demonstrated its effectiveness across a wide range of models and tasks, thereby allowing us to make one step forward in our understanding of the inner mechanisms of CodePTMs. | Nuo Chen, Qiushi Sun, Jianing Wang, Ming Gao, Xiaoli Li, Xiang Li |  |
| 1125 |  |  [Annotation Sensitivity: Training Data Collection Methods Affect Model Performance](https://doi.org/10.18653/v1/2023.findings-emnlp.992) |  | 0 | When training data are collected from human annotators, the design of the annotation instrument, the instructions given to annotators, the characteristics of the annotators, and their interactions can impact training data. This study demonstrates that design choices made when creating an annotation instrument also impact the models trained on the resulting annotations. We introduce the term annotation sensitivity to refer to the impact of annotation data collection methods on the annotations themselves and on downstream model performance and predictions. We collect annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, randomly assigning annotators to conditions. We then fine-tune BERT models on each of the five resulting datasets and evaluate model performance on a holdout portion of each condition. We find considerable differences between the conditions for 1) the share of hate speech/offensive language annotations, 2) model performance, 3) model predictions, and 4) model learning curves. Our results emphasize the crucial role played by the annotation instrument which has received little attention in the machine learning literature. We call for additional research into how and why the instrument impacts the annotations to inform the development of best practices in instrument design. | Christoph Kern, Stephanie Eckman, Jacob Beck, Rob Chew, Bolei Ma, Frauke Kreuter |  |
| 1126 |  |  [Qualitative Code Suggestion: A Human-Centric Approach to Qualitative Coding](https://doi.org/10.18653/v1/2023.findings-emnlp.993) |  | 0 | Qualitative coding is a content analysis method in which researchers read through a text corpus and assign descriptive labels or qualitative codes to passages. It is an arduous and manual process which human-computer interaction (HCI) studies have shown could greatly benefit from NLP techniques to assist qualitative coders. Yet, previous attempts at leveraging language technologies have set up qualitative coding as a fully automatable classification problem. In this work, we take a more assistive approach by defining the task of qualitative code suggestion (QCS) in which a ranked list of previously assigned qualitative codes is suggested from an identified passage. In addition to being user-motivated, QCS integrates previously ignored properties of qualitative coding such as the sequence in which passages are annotated, the importance of rare codes and the differences in annotation styles between coders. We investigate the QCS task by releasing the first publicly available qualitative coding dataset, CVDQuoding, consisting of interviews conducted with women at risk of cardiovascular disease. In addition, we conduct a human evaluation which shows that our systems consistently make relevant code suggestions. | Cesare Spinoso Di Piano, Samira Abbasgholizadeh Rahimi, Jackie Chi Kit Cheung |  |
| 1127 |  |  [D²TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.994) |  | 0 | Many-to-many multimodal summarization (M3S) task aims to generate summaries in any language with document inputs in any language and the corresponding image sequence, which essentially comprises of multimodal monolingual summarization (MMS) and multimodal cross-lingual summarization (MXLS) tasks. Although much work has been devoted to either MMS or MXLS, little research pays attention to the M3S task. Besides, existing studies mainly focus on 1) utilizing MMS to enhance MXLS via knowledge distillation without considering the performance of MMS or 2) improving MMS models by filtering summary-unrelated visual features with implicit learning or explicitly complex training objectives. In this paper, we first introduce a general and practical task, i.e., M3S. Further, we propose a dual knowledge distillation and target-oriented vision modeling framework for the M3S task. Specifically, the dual knowledge distillation method guarantees that the knowledge of MMS and MXLS can be transferred to each other and thus mutually prompt both of them. To offer target-oriented visual features, a simple yet effective target-oriented contrastive objective is designed and responsible for discarding needless visual information. Extensive experiments on the many-to-many setting show the effectiveness of the proposed approach. Additionally, we contribute a many-to-many multimodal summarization (lmttM3Sum) dataset with 44 languages to facilitate future research. | Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 1128 |  |  [Improving Input-label Mapping with Demonstration Replay for In-context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.995) |  | 0 | In-context learning (ICL) is an emerging capability of large autoregressive language models where a few input-label demonstrations are appended to the input to enhance the model’s understanding of downstream NLP tasks, without directly adjusting the model parameters. The effectiveness of ICL can be attributed to the strong language modeling capabilities of large language models (LLMs), which enable them to learn the mapping between input and labels based on in-context demonstrations. Despite achieving promising results, the causal nature of language modeling in ICL restricts the attention to be backward only, i.e., a token only attends to its previous tokens, failing to capture the full input-label information and limiting the model’s performance. In this paper, we propose a novel ICL method called Repeated Demonstration with Sliding Causal Attention, (RdSca). Specifically, we duplicate later demonstrations and concatenate them to the front, allowing the model to ‘observe’ the later information even under the causal restriction. Besides, we introduce sliding causal attention, which customizes causal attention to avoid information leakage. Experimental results show that our method significantly improves the input-label mapping in ICL demonstrations. We also conduct an in-depth analysis of how to customize the causal attention without training, which has been an unexplored area in previous research. | Zhuocheng Gong, Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan |  |
| 1129 |  |  [Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies](https://doi.org/10.18653/v1/2023.findings-emnlp.996) |  | 0 | In-context learning (ICL) has emerged as a new approach to various natural language processing tasks, utilizing large language models (LLMs) to make predictions based on context that has been supplemented with a few examples or task-specific instructions. In this paper, we aim to extend this method to question answering tasks that utilize structured knowledge sources, and improve Text-to-SQL systems by exploring various prompt design strategies for employing LLMs. We conduct a systematic investigation into different demonstration selection methods and optimal instruction formats for prompting LLMs in the Text-to-SQL task. Our approach involves leveraging the syntactic structure of an example’s SQL query to retrieve demonstrations, and we demonstrate that pursuing both diversity and similarity in demonstration selection leads to enhanced performance. Furthermore, we show that LLMs benefit from database-related knowledge augmentations. Our most effective strategy outperforms the state-of-the-art system by 2.5 points (Execution Accuracy) and the best fine-tuned system by 5.1 points on the Spider dataset. These results highlight the effectiveness of our approach in adapting LLMs to the Text-to-SQL task, and we present an analysis of the factors contributing to the success of our strategy. | Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen Zhang, Arman Cohan, Dragomir Radev |  |
| 1130 |  |  [Cross-lingual Open-Retrieval Question Answering for African Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.997) |  | 0 | African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems – those that retrieve answer content from other languages while serving people in their native language—offer a means of filling this gap. To this end, we create Our Dataset, the first cross-lingual QA dataset with a focus on African languages. Our Dataset includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, Our Dataset focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retrieval methods. Overall, Our Dataset proves challenging for state-of-the-art QA models. We hope that the dataset enables the development of more equitable QA technology. | Odunayo Ogundepo, Tajuddeen Gwadabe, Clara Rivera, Jonathan H. Clark, Sebastian Ruder, David Ifeoluwa Adelani, Bonaventure Dossou, Abdou Aziz Diop, Claytone Sikasote, Gilles Hacheme, Happy Buzaaba, Ignatius Ezeani, Rooweither Mabuya, Salomey Osei, Chris Emezue, Albert Kahira, Shamsuddeen Hassan Muhammad, Akintunde Oladipo, Abraham Toluwase Owodunni, Atnafu Lambebo Tonja, Iyanuoluwa Shode, Akari Asai, Aremu Anuoluwapo, Ayodele Awokoya, Bernard Opoku, Chiamaka Chukwuneke, Christine Mwase, Clemencia Siro, Stephen Arthur, Tunde Ajayi, Verrah Otiende, Andre Niyongabo Rubungo, Boyd Sinkala, Daniel A. Ajisafe, Emeka Onwuegbuzia, Falalu Ibrahim Lawan, Ibrahim Said Ahmad, Jesujoba O. Alabi, Chinedu E. Mbonu, Mofetoluwa Adeyemi, Mofya Phiri, Orevaoghene Ahia, Ruqayya Nasir Iro, Sonia Adhiambo |  |
| 1131 |  |  [Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens](https://doi.org/10.18653/v1/2023.findings-emnlp.998) |  | 0 | We argue that translation quality alone is not a sufficient metric for measuring knowledge transfer in multilingual neural machine translation. To support this claim, we introduce Representational Transfer Potential (RTP), which measures representational similarities between languages. We show that RTP can measure both positive and negative transfer (interference), and find that RTP is strongly correlated with changes in translation quality, indicating that transfer does occur. Furthermore, we investigate data and language characteristics that are relevant for transfer, and find that multi-parallel overlap is an important yet under-explored feature. Based on this, we develop a novel training scheme, which uses an auxiliary similarity loss that encourages representations to be more invariant across languages by taking advantage of multi-parallel data. We show that our method yields increased translation quality for low- and mid-resource languages across multiple data and model setups. | David Stap, Vlad Niculae, Christof Monz |  |
| 1132 |  |  [Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog](https://doi.org/10.18653/v1/2023.findings-emnlp.999) |  | 0 | Asking for clarification is fundamental to effective collaboration. An interactive artificial agent must know when to ask a human instructor for more information in order to ascertain their goals. Previous work bases the timing of questions on supervised models learned from interactions between humans. Instead of a supervised classification task, we wish to ground the need for questions in the acting agent’s predictive uncertainty. In this work, we investigate if ambiguous linguistic instructions can be aligned with uncertainty in neural models. We train an agent using the T5 encoder-decoder architecture to solve the Minecraft Collaborative Building Task and identify uncertainty metrics that achieve better distributional separation between clear and ambiguous instructions. We further show that well-calibrated prediction probabilities benefit the detection of ambiguous instructions. Lastly, we provide a novel empirical analysis on the relationship between uncertainty and dialog history length and highlight an important property that poses a difficulty for detection. | Kata Naszádi, Putra Manggala, Christof Monz |  |
| 1133 |  |  [Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.1000) |  | 0 | Prompting Large Language Models (LLMs) performs impressively in zero- and few-shot settings. Hence, small and medium-sized enterprises (SMEs) that cannot afford the cost of creating large task-specific training datasets, but also the cost of pretraining their own LLMs, are increasingly turning to third-party services that allow them to prompt LLMs. However, such services currently require a payment per call, which becomes a significant operating expense (OpEx). Furthermore, customer inputs are often very similar over time, hence SMEs end-up prompting LLMs with very similar instances. We propose a framework that allows reducing the calls to LLMs by caching previous LLM responses and using them to train a local inexpensive model on the SME side. The framework includes criteria for deciding when to trust the local model or call the LLM, and a methodology to tune the criteria and measure the tradeoff between performance and cost. For experimental purposes, we instantiate our framework with two LLMs, GPT-3.5 or GPT-4, and two inexpensive students, a k-NN classifier or a Multi-Layer Perceptron, using two common business tasks, intent recognition and sentiment analysis. Experimental results indicate that significant OpEx savings can be obtained with only slightly lower performance. | Ilias Stogiannidis, Stavros Vassos, Prodromos Malakasiotis, Ion Androutsopoulos |  |
| 1134 |  |  [ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback](https://doi.org/10.18653/v1/2023.findings-emnlp.1001) |  | 0 | Large language models (LLMs) like ChatGPT have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose ParroT, a framework to enhance and regulate the translation abilities during chat based on open-source LLMs (e.g., LLaMA), human-written translation and feedback data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a “Hint” field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to further improvement, which demonstrates the importance of learning from low-quality translations annotated by humans. We also demonstrate the potential of automatic evaluation tools in providing quality information of translations, when constructing error-guided instructions for directions that lack human annotation data. Please refer to our Github project for more implementation details: https://github.com/wxjiao/ParroT. | Wenxiang Jiao, Jentse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang, Shuming Shi, Zhaopeng Tu |  |
| 1135 |  |  [Dense Retrieval as Indirect Supervision for Large-space Decision Making](https://doi.org/10.18653/v1/2023.findings-emnlp.1002) |  | 0 | Many discriminative natural language understanding (NLU) tasks have large label spaces. Learning such a process of large-space decision making is particularly challenging due to the lack of training instances per label and the difficulty of selection among many fine-grained labels. Inspired by dense retrieval methods for passage finding in open-domain QA, we propose a reformulation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR). Instead of predicting fine-grained decisions as logits, DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus. This approach not only leverages rich indirect supervision signals from easy-to-consume learning resources for dense retrieval, it also leads to enhanced prediction generalizability with a semantically meaningful representation of the large decision space. When evaluated on tasks with decision spaces ranging from hundreds to hundred-thousand scales, DDR outperforms strong baselines greatly by 27.54% in P @1 on two extreme multi-label classification tasks, 1.17% in F1 score ultra-fine entity typing, and 1.26% in accuracy on three few-shot intent classification tasks on average. | Nan Xu, Fei Wang, Mingtao Dong, Muhao Chen |  |
| 1136 |  |  [One-Model-Connects-All: A Unified Graph Pre-Training Model for Online Community Modeling](https://doi.org/10.18653/v1/2023.findings-emnlp.1003) |  | 0 | Online community is composed of communities, users, and user-generated textual content, with rich information that can help us solve social problems. Previous research hasn’t fully utilized these three components and the relationship among them. What’s more, they can’t adapt to a wide range of downstream tasks. To solve these problems, we focus on a framework that simultaneously considers communities, users, and texts. And it can easily connect with a variety of downstream tasks related to social media. Specifically, we use a ternary heterogeneous graph to model online communities. Text reconstruction and edge generation are used to learn structural and semantic knowledge among communities, users, and texts. By leveraging this pre-trained model, we achieve promising results across multiple downstream tasks, such as violation detection, sentiment analysis, and community recommendation. Our exploration will improve online community modeling. | Ruoxue Ma, Jiarong Xu, Xinnong Zhang, Haozhe Zhang, Zuyu Zhao, Qi Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 1137 |  |  [In-Image Neural Machine Translation with Segmented Pixel Sequence-to-Sequence Model](https://doi.org/10.18653/v1/2023.findings-emnlp.1004) |  | 0 | In-Image Machine Translation (IIMT) aims to convert images containing texts from one language to another. Traditional approaches for this task are cascade methods, which utilize optical character recognition (OCR) followed by neural machine translation (NMT) and text rendering. However, the cascade methods suffer from compounding errors of OCR and NMT, leading to a decrease in translation quality. In this paper, we propose an end-to-end model instead of the OCR, NMT and text rendering pipeline. Our neural architecture adopts encoder-decoder paradigm with segmented pixel sequences as inputs and outputs. Through end-to-end training, our model yields improvements across various dimensions, (i) it achieves higher translation quality by avoiding error propagation, (ii) it demonstrates robustness for out domain data, and (iii) it displays insensitivity to incomplete words. To validate the effectiveness of our method and support for future research, we construct our dataset containing 4M pairs of De-En images and train our end-to-end model. The experimental results show that our approach outperforms both cascade method and current end-to-end model. | Yanzhi Tian, Xiang Li, Zeming Liu, Yuhang Guo, Bin Wang |  |
| 1138 |  |  [NarrativeXL: a Large-scale Dataset for Long-Term Memory Models](https://doi.org/10.18653/v1/2023.findings-emnlp.1005) |  | 0 | We propose a new large-scale (nearly a million questions) ultra-long-context (more than 50,000 words average document length) reading comprehension dataset. Using GPT 3.5, we summarized each scene in 1,500 hand-curated fiction books from Project Gutenberg, which resulted in approximately 150 scene-level summaries per book. After that, we created a number of reading comprehension questions based on these summaries, including three types of multiple-choice scene recognition questions, as well as free-form narrative reconstruction questions. With 990,595 total questions, our dataset is an order of magnitude larger than the closest alternatives. Crucially, most questions have a known “retention demand”, indicating how long-term of a memory is needed to answer them, which should aid long-term memory performance evaluation. We validate our data in four small-scale experiments: one with human labelers, and three with existing language models. We show that our questions 1) adequately represent the source material 2) can be used to diagnose a model’s memory capacity 3) are not trivial for modern language models even when the memory demand does not exceed those models’ context lengths. Lastly, we provide our code which can be used to further expand the dataset with minimal human labor. | Arsenii Moskvichev, KyVinh Mai |  |
| 1139 |  |  [Dialogue Act-Aided Backchannel Prediction Using Multi-Task Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.1006) |  | 0 | Produced in the form of small injections such as “Yeah!” or “Uh-Huh” by listeners in a conversation, supportive verbal feedback (i.e., backchanneling) is essential for natural dialogue. Highlighting its tight relation to speaker intent and utterance type, we propose a multi-task learning approach that learns textual representations for the task of backchannel prediction in tandem with dialogue act classification. We demonstrate the effectiveness of our approach by improving the prediction of specific backchannels like “Yeah” or “Really?” by up to 2.0% in F1. Additionally, whereas previous models relied on well-established methods to extract audio features, we further pre-train the audio encoder in a self-supervised fashion using voice activity projection. This leads to additional gains of 1.4% in weighted F1. | Wencke Liermann, YoHan Park, YongSeok Choi, KongJoo Lee |  |
| 1140 |  |  [mReFinED: An Efficient End-to-End Multilingual Entity Linking System](https://doi.org/10.18653/v1/2023.findings-emnlp.1007) |  | 0 | End-to-end multilingual entity linking (MEL) is concerned with identifying multilingual entity mentions and their corresponding entity IDs in a knowledge base. Existing works assumed that entity mentions were given and skipped the entity mention detection step due to a lack of high-quality multilingual training corpora. To overcome this limitation, we propose mReFinED, the first end-to-end multilingual entity linking. Additionally, we propose a bootstrapping mention detection framework that enhances the quality of training corpora. Our experimental results demonstrated that mReFinED outperformed the best existing work in the end-to-end MEL task while being 44 times faster. | Peerat Limkonchotiwat, Weiwei Cheng, Christos Christodoulopoulos, Amir Saffari, Jens Lehmann |  |
| 1141 |  |  [Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.1008) |  | 0 | Continual learning (CL) has two main objectives: preventing catastrophic forgetting (CF) and encouraging knowledge transfer (KT). The existing literature mainly focused on overcoming CF. Some work has also been done on KT when the tasks are similar. To our knowledge, only one method has been proposed to learn a sequence of mixed tasks. However, these techniques still suffer from CF and/or limited KT. This paper proposes a new CL method to achieve both. It overcomes CF by isolating the knowledge of each task via discovering a sub-network for it. A soft-masking mechanism is also proposed to preserve the previous knowledge and to enable the new task to leverage the past knowledge to achieve KT. Experiments using classification, generation, information extraction, and their mixture (i.e., heterogeneous tasks) show that the proposed method consistently outperforms strong baselines. | Zixuan Ke, Bing Liu, Wenhan Xiong, Asli Celikyilmaz, Haoran Li |  |
| 1142 |  |  [PIVOINE: Instruction Tuning for Open-world Entity Profiling](https://doi.org/10.18653/v1/2023.findings-emnlp.1009) |  | 0 | This work considers the problem of Open-world Entity Profiling, a sub-domain of Open-world Information Extraction (Open-world IE). Unlike the conventional closed-world IE, Open-world IE is considered a more general situation where entities and relations could be beyond a predefined ontology. We seek to develop a large language model (LLM) that can perform Open-world Entity Profiling with instruction tuning to extract desirable entity profiles characterized by (possibly fine-grained) natural language instructions. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction-tuning dataset for Open-world Entity Profiling enriched with a comprehensive corpus, extensive annotations, and diverse instructions. We finetune pretrained BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world Entity Profiling with strong instruction-following capabilities. Our experiments demonstrate that PIVOINE significantly outperforms traditional methods and ChatGPT-based baselines, displaying impressive generalization capabilities on both unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as a promising solution to tackle the open-world challenge of entity profiling. | Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu, Jianshu Chen |  |
| 1143 |  |  [DiQAD: A Benchmark Dataset for Open-domain Dialogue Quality Assessment](https://doi.org/10.18653/v1/2023.findings-emnlp.1010) |  | 0 | Dialogue assessment plays a critical role in the development of open-domain dialogue systems. Existing work are uncapable of providing an end-to-end and human-epistemic assessment dataset, while they only provide sub-metrics like coherence or the dialogues are conversed between annotators far from real user settings. In this paper, we release a large-scale dialogue quality assessment dataset (DiQAD), for automatically assessing open-domain dialogue quality. Specifically, we (1) establish the assessment criteria based on the dimensions conforming to human judgements on dialogue qualities, and (2) annotate large-scale dialogues that conversed between real users based on these annotation criteria, which contains around 100,000 dialogues. We conduct several experiments and report the performances of the baselines as the benchmark on DiQAD. The dataset is openly accessible at https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation. | Yukun Zhao, Lingyong Yan, Weiwei Sun, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, Dawei Yin |  |
| 1144 |  |  [Tuna: Instruction Tuning using Feedback from Large Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.1011) |  | 0 | Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a cost-effective way to align model behaviors with human preferences. However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses. In this paper, we propose finetuning an instruction-tuned LLM using our novel probabilistic ranking and contextual ranking approaches to increase the likelihood of generating better responses. Probabilistic ranking enables the instruction-tuned model to inherit the relative rankings of high-quality and low-quality responses from the teacher LLM. On the other hand, learning with contextual ranking allows the model to refine its own response distribution using the contextual understanding ability of stronger LLMs. Furthermore, we apply probabilistic ranking and contextual ranking sequentially to the instruction-tuned LLM. The resulting model, which we call Tuna, consistently improves the performance on Super Natural Instructions (119 test tasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results than several strong reinforcement learning baselines. Our code and data are available at https://github.com/microsoft/LMOps. | Haoran Li, Yiran Liu, Xingxing Zhang, Wei Lu, Furu Wei |  |
| 1145 |  |  [Emptying the Ocean with a Spoon: Should We Edit Models?](https://doi.org/10.18653/v1/2023.findings-emnlp.1012) |  | 0 | We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations. We contrast model editing with three similar but distinct approaches that pursue better defined objectives: (1) retrieval-based architectures, which decouple factual memory from inference and linguistic capabilities embodied in LLMs; (2) concept erasure methods, which aim at preventing systemic bias in generated text; and (3) attribution methods, which aim at grounding generations into identified textual sources. We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability, it opens risks by reinforcing the notion that models can be trusted for factuality. We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component. | Yuval Pinter, Michael Elhadad |  |
| 1146 |  |  [A Causal View of Entity Bias in (Large) Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.1013) |  | 0 | Entity bias widely affects pretrained (large) language models, causing them to rely on (biased) parametric knowledge to make unfaithful predictions. Although causality-inspired methods have shown great potential to mitigate entity bias, it is hard to precisely estimate the parameters of underlying causal models in practice. The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate. Building upon this SCM, we propose causal intervention techniques to mitigate entity bias for both white-box and black-box settings. The proposed causal intervention perturbs the original entity with neighboring entities. This intervention reduces specific biasing information pertaining to the original entity while still preserving sufficient semantic information from similar entities. Under the white-box setting, our training-time intervention improves OOD performance of PLMs on relation extraction (RE) and machine reading comprehension (MRC) by 5.7 points and by 9.1 points, respectively. Under the black-box setting, our in-context intervention effectively reduces the entity-based knowledge conflicts of GPT-3.5, achieving up to 20.5 points of improvement of exact match accuracy on MRC and up to 17.6 points of reduction in memorization ratio on RE. | Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen |  |
| 1147 |  |  [T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics](https://doi.org/10.18653/v1/2023.findings-emnlp.1014) |  | 0 | Modern embedding-based metrics for evaluation of generated text generally fall into one of two paradigms: discriminative metrics that are trained to directly predict which outputs are of higher quality according to supervised human annotations, and generative metrics that are trained to evaluate text based on the probabilities of a generative model. Both have their advantages; discriminative metrics are able to directly optimize for the problem of distinguishing between good and bad outputs, while generative metrics can be trained using abundant raw text. In this paper, we present a framework that combines the best of both worlds, using both supervised and unsupervised signals from whatever data we have available. We operationalize this idea by training T5Score, a metric that uses these training signals with mT5 as backbone. We perform an extensive empirical comparison with other existing metrics on 5 datasets, 19 languages and 280 systems, demonstrating the utility of our method. Experimental results show that: T5Score achieves the best performance on all datasets against existing top-scoring metrics at the segment level. | Yiwei Qin, Weizhe Yuan, Graham Neubig, Pengfei Liu |  |
| 1148 |  |  [T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.1015) |  | 0 | In the absence of readily available labeled data for a given sequence labeling task and language, annotation projection has been proposed as one of the possible strategies to automatically generate annotated data. Annotation projection has often been formulated as the task of transporting, on parallel corpora, the labels pertaining to a given span in the source language into its corresponding span in the target language. In this paper we present T-Projection, a novel approach for annotation projection that leverages large pretrained text2text language models and state-of-the-art machine translation technology. T-Projection decomposes the label projection task into two subtasks: (i) A candidate generation step, in which a set of projection candidates using a multilingual T5 model is generated and, (ii) a candidate selection step, in which the generated candidates are ranked based on translation probabilities. We conducted experiments on intrinsic and extrinsic tasks in 5 Indo-European and 8 low-resource African languages. We demostrate that T-projection outperforms previous annotation projection methods by a wide margin. We believe that T-Projection can help to automatically alleviate the lack of high-quality training data for sequence labeling tasks. Code and data are publicly available. | Iker GarcíaFerrero, Rodrigo Agerri, German Rigau |  |
| 1149 |  |  [MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document](https://doi.org/10.18653/v1/2023.findings-emnlp.1016) |  | 0 | The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging. Previous work models time implicitly, making it difficult to handle such complex relationships. To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Reasoning framework for temporal reasoning over time-involved documents. Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs. On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective. Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under question perturbations. | Zheng Chu, Zekun Wang, Jiafeng Liang, Ming Liu, Bing Qin |  |
| 1150 |  |  [MSCFFN: A New FFN with Multi-Space Cross to Accelerate Transformer](https://doi.org/10.18653/v1/2023.findings-emnlp.1017) |  | 0 | Transformer models have achieved impressive success in various natural language processing tasks. But it is also limited used in some areas and the heavy computation complexity is one of the main limitations. Many model structures have been proposed to reduce the computation complexity and some are really effective. The previous research can be divided into two categories. One is to use more effective training and inference strategies and the other is focused on how to replace the standard self-attention mechanism with linear attention method. Differently, we revisit the design in Transformer and find that the feed forward network (FFN) is also computationally expensive, especially when the hidden dimension is large. In this paper, we propose a new FFN structure, named MSCFFN, which splits the large matrix space to several small space to reduce the computation complexity and uses the Multi-Space Cross method to ensure the accurate result. To the best of our knowledge, this is the first time to redesign FFN to accelerate Transformers. We experimentally validate the effectiveness of the proposed method on the Long-Range Arena benchmark. And the results show MSCFFN can achieve a faster speed with a similar or even better accuracy. | Tang Dongge, Qing Yang |  |
| 1151 |  |  [Dialect Transfer for Swiss German Speech Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.1018) |  | 0 | This paper investigates the challenges in building Swiss German speech translation systems, specifically focusing on the impact of dialect diversity and differences between Swiss German and Standard German. Swiss German is a spoken language with no formal writing system, it comprises many diverse dialects and is a low-resource language with only around 5 million speakers. The study is guided by two key research questions: how does the inclusion and exclusion of dialects during the training of speech translation models for Swiss German impact the performance on specific dialects, and how do the differences between Swiss German and Standard German impact the performance of the systems? We show that dialect diversity and linguistic differences pose significant challenges to Swiss German speech translation, which is in line with linguistic hypotheses derived from empirical investigations. | Claudio Paonessa, Yanick Schraner, Jan Deriu, Manuela Hürlimann, Manfred Vogel, Mark Cieliebak |  |
| 1152 |  |  [Masked Path Modeling for Vision-and-Language Navigation](https://doi.org/10.18653/v1/2023.findings-emnlp.1019) |  | 0 | Vision-and-language navigation (VLN) agents are trained to navigate in real-world environments based on natural language instructions. A major challenge in VLN is the limited available training data, which hinders the models’ ability to generalize effectively. Previous approaches have attempted to alleviate this issue by using external tools to generate pseudo-labeled data or integrating web-scaled image-text pairs during training. However, these methods often rely on automatically-generated or out-of-domain data, leading to challenges such as suboptimal data quality and domain mismatch. In this paper, we introduce a masked path modeling (MPM) objective. MPM pretrains an agent using self-collected data for subsequent navigation tasks, eliminating the need for external tools. Specifically, our method allows the agent to explore navigation environments and record the paths it traverses alongside the corresponding agent actions. Subsequently, we train the agent on this collected data to reconstruct the original action sequence when given a randomly masked subsequence of the original path. This approach enables the agent to accumulate a diverse and substantial dataset, facilitating the connection between visual observations of paths and the agent’s actions, which is the foundation of the VLN task. Importantly, the collected data are in-domain, and the training process avoids synthetic data with uncertain quality, addressing previous issues. We conduct experiments on various VLN datasets and demonstrate the applications of MPM across different levels of instruction complexity. Our results exhibit significant improvements in success rates, with enhancements of 1.3%, 1.1%, and 1.2% on the val-unseen split of the Room-to-Room, Room-for-Room, and Room-across-Room datasets, respectively. Additionally, we underscore the adaptability of MPM as well as the potential for additional improvements when the agent is allowed to explore unseen environments prior to testing. | ZiYi Dou, Feng Gao, Nanyun Peng |  |
| 1153 |  |  [Learning Interpretable Style Embeddings via Prompting LLMs](https://doi.org/10.18653/v1/2023.findings-emnlp.1020) |  | 0 | Style representation learning builds content-independent representations of author style in text. To date, no large dataset of texts with stylometric annotations on a wide range of style dimensions has been compiled, perhaps because the linguistic expertise to perform such annotation would be prohibitively expensive. Therefore, current style representation approaches make use of unsupervised neural methods to disentangle style from content to create style vectors. These approaches, however, result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to generate a synthetic stylometry dataset. We use this synthetic data to then train human-interpretable style representations we call LISA embeddings. We release our synthetic dataset (StyleGenome) and our interpretable style embedding model (LISA) as resources. | Ajay Patel, Delip Rao, Ansh Kothary, Kathleen R. McKeown, Chris CallisonBurch |  |
| 1154 |  |  [Exploring Context-Aware Evaluation Metrics for Machine Translation](https://doi.org/10.18653/v1/2023.findings-emnlp.1021) |  | 0 | Previous studies on machine translation evaluation mostly focused on the quality of individual sentences, while overlooking the important role of contextual information. Although WMT Metrics Shared Tasks have introduced context content into the human annotations of translation evaluation since 2019, the relevant metrics and methods still did not take advantage of the corresponding context. In this paper, we propose a context-aware machine translation evaluation metric called Cont-COMET, built upon the effective COMET framework. Our approach simultaneously considers the preceding and subsequent contexts of the sentence to be evaluated and trains our metric to be aligned with the setting during human annotation. We also introduce a content selection method to extract and utilize the most relevant information. The experiments and evaluation of Cont-COMET on the official test framework from WMT show improvements in both system-level and segment-level assessments. | Xinyu Hu, Xunjian Yin, Xiaojun Wan |  |
| 1155 |  |  [GRACE: Discriminator-Guided Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2023.findings-emnlp.1022) |  | 0 | In the context of multi-step reasoning, e.g., with chain-of-thought, language models (LMs) can easily assign a high likelihood to incorrect steps. As a result, decoding strategies that optimize for solution likelihood often yield incorrect solutions. To address this issue, we propose Guiding chain-of-thought ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding approach that steers the decoding process towards producing correct reasoning steps. GRACE employs a discriminator trained with a contrastive loss over correct and incorrect steps, which is used during decoding to score next-step candidates based on their correctness. Importantly, GRACE only requires sampling from the LM, without the need for LM training or fine-tuning. Using models from FLAN-T5 and LLaMA families, we evaluate GRACE over four math and two symbolic reasoning tasks, where it exhibits substantial performance gains compared to greedy decoding, verifiers, and self-consistency in most settings. When further combined with self-consistency, GRACE outperforms all the baselines by sizeable margins. Human and LLM evaluations over GSM8K show that GRACE not only improves the final answer accuracy but also the correctness of the intermediate reasoning. | Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang |  |
| 1156 |  |  [QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.1023) |  | 0 | Zero-shot commonsense Question-Answering (QA) requires models to reason about general situations beyond specific benchmarks. State-of-the-art approaches fine-tune language models on QA pairs constructed from CommonSense Knowledge Bases (CSKBs) to equip the models with more commonsense knowledge in a QA context. However, current QA synthesis protocols may introduce noise from the CSKBs and generate ungrammatical questions and false negative options, which impede the model’s ability to generalize. To address these issues, we propose QADYNAMICS, a training dynamics-driven framework for QA diagnostics and refinement. Our approach analyzes the training dynamics of each QA pair at both the question level and option level, discarding machine-detectable artifacts by removing uninformative QA pairs and mislabeled or false-negative options. Extensive experiments demonstrate the effectiveness of our approach, which outperforms all baselines while using only 33% of the synthetic data, even including LLMs such as ChatGPT. Moreover, expert evaluations confirm that our framework significantly improves the quality of QA synthesis. Our code and model checkpoints are available at https://github.com/HKUST-KnowComp/QaDynamics. | Haochen Shi, Weiqi Wang, Tianqing Fang, Baixuan Xu, Wenxuan Ding, Xin Liu, Yangqiu Song |  |
| 1157 |  |  [RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction](https://doi.org/10.18653/v1/2023.findings-emnlp.1024) |  | 0 | Universal Information Extraction (UIE) is an area of interest due to the challenges posed by varying targets, heterogeneous structures, and demand-specific schemas. Previous works have achieved success by unifying a few tasks, such as Named Entity Recognition (NER) and Relation Extraction (RE), while they fall short of being true UIE models particularly when extracting other general schemas such as quadruples and quintuples. Additionally, these models used an implicit structural schema instructor, which could lead to incorrect links between types, hindering the model’s generalization and performance in low-resource scenarios. In this paper, we redefine the true UIE with a formal formulation that covers almost all extraction schemas. To the best of our knowledge, we are the first to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which is a Recursive Method with Explicit Schema Instructor for UIE. To avoid interference between different types, we reset the position ids and attention mask matrices. RexUIE shows strong performance under both full-shot and few-shot settings and achieves state-of-the-art results on the tasks of extracting complex schemas. | Chengyuan Liu, Fubang Zhao, Yangyang Kang, Jingyuan Zhang, Xiang Zhou, Changlong Sun, Kun Kuang, Fei Wu |  |
| 1158 |  |  [PromptARA: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection](https://doi.org/10.18653/v1/2023.findings-emnlp.1025) |  | 0 | Readability assessment aims to automatically classify texts based on readers’ reading levels. The hybrid automatic readability assessment (ARA) models using both deep and linguistic features have attracted rising attention in recent years due to their impressive performance. However, deep features are not fully explored due to the scarcity of training data, and the fusion of deep and linguistic features is not very effective in existing hybrid ARA models. In this paper, we propose a novel hybrid ARA model called PromptARA through employing prompts to improve deep feature representations and an orthogonal projection layer to fuse both deep and linguistic features. A series of experiments are conducted over four English and two Chinese corpora to show the effectiveness of the proposed model. Experimental results demonstrate that the proposed model is superior to state-of-the-art models. | Jinshan Zeng, Xianglong Yu, Xianchao Tong, Wenyan Xiao |  |
| 1159 |  |  [Does Listener Gaze in Face-to-Face Interaction Follow the Entropy Rate Constancy Principle: An Empirical Study](https://doi.org/10.18653/v1/2023.findings-emnlp.1026) |  | 0 | It is generally assumed that language (written and spoken) follows the entropy rate constancy (ERC) principle, which states that the information density of a text is constant over time. Recently, this has also been found for nonverbal gestures used in monologue, but it is still unclear whether the ERC principle also applies to listeners’ nonverbal signals. We focus on listeners’ gaze behaviour extracted from video-recorded conversations and trained a transformer-based neural sequence model to process the gaze data of the dialogues and compute its information density. We also compute the information density of the corresponding speech using a pre-trained language model. Our results show (1) that listeners’ gaze behaviour in dialogues roughly follows the ERC principle, as well as (2) a congruence between information density of speech and listeners’ gaze behaviour. | Yu Wang, Hendrik Buschmeier |  |
| 1160 |  |  [Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing](https://doi.org/10.18653/v1/2023.findings-emnlp.1027) |  | 0 | Fine-grained entity typing (FGET) aims to assign appropriate fine-grained types to entity mentions within their context, which is an important foundational task in natural language processing. Previous approaches for FGET only utilized textual context information. However, in the form of short text, the contextual semantic information is often insufficient for FGET. In many real-world scenarios, text is often accompanied by images, and the visual context is valuable for FGET. To this end, we firstly propose a new task called multimodal fine-grained entity typing (MFGET). Then we construct a large-scale dataset for multimodal fine-grained entity typing called MFIGER based on FIGER. To fully leverage both textual and visual information, we propose a novel Multimodal Object-Level Visual Context Network (MOVCNet). MOVCNet can capture fine-grained semantic information by detecting objects in images, and effectively merge both textual and visual context. Experimental results demonstrate that our approach achieves superior classification performance compared to previous text-based approaches. | Ying Zhang, Wenbo Fan, Kehui Song, Yu Zhao, Xuhui Sui, Xiaojie Yuan |  |
| 1161 |  |  [Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data](https://doi.org/10.18653/v1/2023.findings-emnlp.1028) |  | 0 | Numerical data plays a crucial role in various real-world domains like finance, economics, and science. Thus, understanding and reasoning with numbers are essential in these fields. Recent benchmarks have assessed the numerical reasoning abilities of language models, revealing their limitations in limited and specific numerical aspects. In this paper, we propose a complete hierarchical taxonomy for numerical reasoning skills, encompassing over ten reasoning types across four levels: representation, number sense, manipulation, and complex reasoning. We conduct a comprehensive evaluation of state-of-the-art models on all reasoning types. To identify challenging reasoning types for different model types, we develop a diverse and extensive set of numerical probes and measure performance shifts. By employing a semi-automated approach, we focus on the tabular Natural Language Inference (TNLI) task as a case study. While no single model excels in all reasoning types, FlanT5 (few-/zero-shot) and GPT3.5 (few-shot) demonstrate strong overall numerical reasoning skills compared to other models in our probes. | Mubashara Akhtar, Abhilash Reddy Shankarampeta, Vivek Gupta, Arpit Patil, Oana Cocarascu, Elena Simperl |  |
| 1162 |  |  [Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks](https://doi.org/10.18653/v1/2023.findings-emnlp.1029) |  | 0 | Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model’s API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model’s resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility. | Ruixiang Tang, Gord Lueck, Rodolfo Quispe, Huseyin A. Inan, Janardhan Kulkarni, Xia Hu |  |
| 1163 |  |  [BERT Has More to Offer: BERT Layers Combination Yields Better Sentence Embeddings](https://doi.org/10.18653/v1/2023.findings-emnlp.1030) |  | 0 | Obtaining sentence representations from BERT-based models as feature extractors is invaluable as it takes much less time to pre-compute a one-time representation of the data and then use it for the downstream tasks, rather than fine-tune the whole BERT. Most previous works acquire a sentence’s representation by passing it to BERT and averaging its last layer. In this paper, we propose that the combination of certain layers of a BERT-based model rested on the data set and model can achieve substantially better results. We empirically show the effectiveness of our method for different BERT-based models on different tasks and data sets. Specifically, on seven standard semantic textual similarity data sets, we outperform the baseline BERT by improving the Spearman’s correlation by up to 25.75% and on average 16.32% without any further training. We also achieved state-of-the-art results on eight transfer data sets by reducing the relative error by up to 37.41% and on average 17.92%. | Seyyed MohammadSaleh Hosseini, Munawara Munia, Latifur Khan |  |
| 1164 |  |  [Extrapolating Multilingual Understanding Models as Multilingual Generators](https://doi.org/10.18653/v1/2023.findings-emnlp.1031) |  | 0 | Multilingual understanding models (or encoder-based), pre-trained via masked language modeling, have achieved promising results on many language understanding tasks (e.g., mBERT). However, these models are not capable of generating high-quality text compared with decoder-based causal language models. Can we transform a pre-trained language understanding model into an effective language generation model? We propose a Semantic-Guided Alignment-then-Denoising (SGA) approach to adapt a multilingual encoder to a multilingual generator with a small number of additional parameters. Experiments show that the proposed approach is an effective adaption method, outperforming widely-used initialization-based methods with gains of 9.4 BLEU on machine translation, 8.1 Rouge-L on question generation, and 5.5 METEOR on story generation on XLM-Rlarge. On the other hand, we observe that XLM-R is still inferior to mBART in supervised settings despite better results on zero-shot settings, indicating that more exploration is required to make understanding models strong generators. Our code is available at https://github.com/chengzhipanpan/XLMR4MT. | Bohong Wu, Fei Yuan, Hai Zhao, Lei Li, Jingjing Xu |  |
| 1165 |  |  [SAC³: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency](https://doi.org/10.18653/v1/2023.findings-emnlp.1032) |  | 0 | Hallucination detection is a critical step toward understanding the trustworthiness of modern language models (LMs). To achieve this goal, we re-examine existing detection approaches based on the self-consistency of LMs and uncover two types of hallucinations resulting from 1) question-level and 2) model-level, which cannot be effectively identified through self-consistency check alone. Building upon this discovery, we propose a novel sampling-based method, i.e., semantic-aware cross-check consistency (SAC3) that expands on the principle of self-consistency checking. Our SAC3 approach incorporates additional mechanisms to detect both question-level and model-level hallucinations by leveraging advances including semantically equivalent question perturbation and cross-model response consistency checking. Through extensive and systematic empirical analysis, we demonstrate that SAC3 outperforms the state of the art in detecting both non-factual and factual statements across multiple question-answering and open-domain generation benchmarks. | Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A. Malin, Kumar Sricharan |  |
| 1166 |  |  [Test-Time Self-Adaptive Small Language Models for Question Answering](https://doi.org/10.18653/v1/2023.findings-emnlp.1033) |  | 0 | Recent instruction-finetuned large language models (LMs) have achieved notable performances in various tasks, such as question-answering (QA). However, despite their ability to memorize a vast amount of general knowledge across diverse tasks, they might be suboptimal on specific tasks due to their limited capacity to transfer and adapt knowledge to target tasks. Moreover, further finetuning LMs with labeled datasets is often infeasible due to their absence, but it is also questionable if we can transfer smaller LMs having limited knowledge only with unlabeled test data. In this work, we show and investigate the capabilities of smaller self-adaptive LMs, only with unlabeled test data. In particular, we first stochastically generate multiple answers, and then ensemble them while filtering out low-quality samples to mitigate noise from inaccurate labels. Our proposed self-adaption strategy demonstrates significant performance improvements on benchmark QA datasets with higher robustness across diverse prompts, enabling LMs to stay stable. Code is available at: https://github.com/starsuzi/T-SAS. | Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong Park |  |
| 1167 |  |  [ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook](https://doi.org/10.18653/v1/2023.findings-emnlp.1034) |  | 0 | Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote. | Wangtao Sun, Xuanqing Yu, Shizhu He, Jun Zhao, Kang Liu |  |
| 1168 |  |  [Evaluating Parameter-Efficient Finetuning Approaches for Pre-trained Models on the Financial Domain](https://doi.org/10.18653/v1/2023.findings-emnlp.1035) |  | 0 | Large-scale language models with millions, billions, or trillions of trainable parameters are becoming increasingly popular. However, they risk becoming rapidly over-parameterized and the adaptation cost of fully fine-tuning them increases significantly. Storing them becomes progressively impractical as it requires keeping a separate copy of all the fine-tuned weights for each task. By freezing all pre-trained weights during fine-tuning, parameter-efficient tuning approaches have become an appealing alternative to traditional fine-tuning. The performance of these approaches has been evaluated on common NLP tasks of the GLUE benchmark and shown to match full fine-tuning performance, however, their impact is less researched in domain-specific fields such as finance. This work compares the performance of a set of financial BERT-like models to their fully fine-tuned counterparts by leveraging different parameter-efficient tuning methods. We see that results are comparable to traditional fine-tuning while gaining in time and resource efficiency. | Isabella Olariu, Cedric Lothritz, Jacques Klein, Tegawendé F. Bissyandé, Siwen Guo, Shohreh Haddadan |  |
| 1169 |  |  [Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model](https://doi.org/10.18653/v1/2023.findings-emnlp.1036) |  | 0 | Augmenting pretrained language models with retrievers has shown promise in effectively solving common NLP problems, such as language modeling and question answering. In this paper, we evaluate the strengths and weaknesses of popular retriever-augmented language models, namely kNN-LM, REALM, DPR + FiD, Contriever + ATLAS, and Contriever + Flan-T5, in reasoning over retrieved statements across different tasks. Our findings indicate that the simple similarity metric employed by retrievers is insufficient for retrieving all the necessary statements for reasoning. Additionally, the language models do not exhibit strong reasoning even when provided with only the required statements. Furthermore, when combined with imperfect retrievers, the performance of the language models becomes even worse, e.g., Flan-T5’s performance drops by 28.6% when retrieving 5 statements using Contriever. While larger language models improve performance, there is still a substantial room for enhancement. Our further analysis indicates that multihop retrieve-and-read is promising for large language models like GPT-3.5, but does not generalize to other language models like Flan-T5-xxl. The code is available at https://github.com/McGill-NLP/retriever-lm-reasoning. | Parishad BehnamGhader, Santiago Miret, Siva Reddy |  |
| 1170 |  |  [BERTwich: Extending BERT's Capabilities to Model Dialectal and Noisy Text](https://doi.org/10.18653/v1/2023.findings-emnlp.1037) |  | 0 | Real-world NLP applications often deal with nonstandard text (e.g., dialectal, informal, or misspelled text). However, language models like BERT deteriorate in the face of dialect variation or noise. How do we push BERT’s modeling capabilities to encompass nonstandard text? Fine-tuning helps, but it is designed for specializing a model to a task and does not seem to bring about the deeper, more pervasive changes needed to adapt a model to nonstandard language. In this paper, we introduce the novel idea of sandwiching BERT’s encoder stack between additional encoder layers trained to perform masked language modeling on noisy text. We find that our approach, paired with recent work on including character-level noise in fine-tuning data, can promote zero-shot transfer to dialectal text, as well as reduce the distance in the embedding space between words and their noisy counterparts. | Aarohi Srivastava, David Chiang |  |
| 1171 |  |  [Closed Boundary Learning for Classification Tasks with the Universum Class](https://doi.org/10.18653/v1/2023.findings-emnlp.1038) |  | 0 | The Universum class, often known as the \*other\* class or the\*miscellaneous\* class, is defined as a collection of samples that do not belong to any class of interest. It is a typical class that exists in many classification-based tasks in NLP, such as relation extraction, named entity recognition, sentiment analysis, etc. The Universum class exhibits very different properties, namely heterogeneity and lack of representativeness in training data; however, existing methods often treat the Universum class equally with the classes of interest, leading to problems such as overfitting, misclassification, and diminished model robustness. In this work, we propose a closed boundary learning method that applies closed decision boundaries to classes of interest and designates the area outside all closed boundaries in the feature space as the space of the Universum class. Specifically, we formulate closed boundaries as arbitrary shapes, propose the inter-class rule-based probability estimation for the Universum class to cater to its unique properties, and propose a boundary learning loss to adjust decision boundaries based on the balance of misclassified samples inside and outside the boundary. In adherence to the natural properties of the Universum class, our method enhances both accuracy and robustness of classification models, demonstrated by improvements on six state-of-the-art works across three different tasks. Our code is available at https://github.com/hzzhou01/Closed-Boundary-Learning. | Hanzhang Zhou, Zijian Feng, Kezhi Mao |  |
| 1172 |  |  [Revisiting Entropy Rate Constancy in Text](https://doi.org/10.18653/v1/2023.findings-emnlp.1039) |  | 0 | The uniform information density (UID) hypothesis states that humans tend to distribute information roughly evenly across an utterance or discourse. Early evidence in support of the UID hypothesis came from Genzel and Charniak (2002), which proposed an entropy rate constancy principle based on the probability of English text under n-gram language models. We re-evaluate the claims of Genzel and Charniak (2002) with neural language models, failing to find clear evidence in support of entropy rate constancy. We conduct a range of experiments across datasets, model sizes, and languages and discuss implications for the uniform information density hypothesis and linguistic theories of efficient communication more broadly. | Vivek Verma, Nicholas Tomlin, Dan Klein |  |
| 1173 |  |  [Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing](https://doi.org/10.18653/v1/2023.findings-emnlp.1040) |  | 0 | Ultra-fine entity typing plays a crucial role in information extraction by predicting fine-grained semantic types for entity mentions in text. However, this task poses significant challenges due to the massive number of entity types in the output space. The current state-of-the-art approaches, based on standard multi-label classifiers or cross-encoder models, suffer from poor generalization performance or inefficient inference speed. In this paper, we present CASENT, a seq2seq model designed for ultra-fine entity typing that predicts ultra-fine types with calibrated confidence scores. Our model takes an entity mention as input and employs constrained beam search to generate multiple types autoregressively. The raw sequence probabilities associated with the predicted types are then transformed into confidence scores using a novel calibration method. We conduct extensive experiments on the UFET dataset which contains over 10k types. Our method outperforms the previous state-of-the-art in terms of F1 score and calibration error, while achieving an inference speedup of over 50 times. Additionally, we demonstrate the generalization capabilities of our model by evaluating it in zero-shot and few-shot settings on five specialized domain entity typing datasets that are unseen during training. Remarkably, our model outperforms large language models with 10 times more parameters in the zero-shot setting, and when fine-tuned on 50 examples, it significantly outperforms ChatGPT on all datasets. | Yanlin Feng, Adithya Pratapa, David R. Mortensen |  |
| 1174 |  |  [Learning Semantic Role Labeling from Compatible Label Sequences](https://doi.org/10.18653/v1/2023.findings-emnlp.1041) |  | 0 | Semantic role labeling (SRL) has multiple disjoint label sets, e.g., VerbNet and PropBank. Creating these datasets is challenging, therefore a natural question is how to use each one to help the other. Prior work has shown that cross-task interaction helps, but only explored multitask learning so far. A common issue with multi-task setup is that argument sequences are still separately decoded, running the risk of generating structurally inconsistent label sequences (as per lexicons like Semlink). In this paper, we eliminate such issue with a framework that jointly models VerbNet and PropBank labels as one sequence. In this setup, we show that enforcing Semlink constraints during decoding constantly improves the overall F1. With special input constructions, our joint model infers VerbNet arguments from given PropBank arguments with over 99 F1. For learning, we propose a constrained marginal model that learns with knowledge defined in Semlink to further benefit from the large amounts of PropBank-only data. On the joint benchmark based on CoNLL05, our models achieve state-of-the-art F1’s, outperforming the prior best in-domain model by 3.5 (VerbNet) and 0.8 (PropBank). For out-of-domain generalization, our models surpass the prior best by 3.4 (VerbNet) and 0.2 (PropBank). | Tao Li, Ghazaleh Kazeminejad, Susan Windisch Brown, Vivek Srikumar, Martha Palmer |  |
| 1175 |  |  [QUADRo: Dataset and Models for QUestion-Answer Database Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.1042) |  | 0 | An effective approach to design automated Question Answering (QA) systems is to efficiently retrieve answers from pre-computed databases containing question/answer pairs. One of the main challenges to this design is the lack of training/testing data. Existing resources are limited in size and topics and either do not consider answers (question-question similarity only) or their quality in the annotation process. To fill this gap, we introduce a novel open-domain annotated resource to train and evaluate models for this task. The resource consists of 15,211 input questions. Each question is paired with 30 similar question/answer pairs, resulting in a total of 443,000 annotated examples. The binary label associated with each pair indicates the relevance with respect to the input question. Furthermore, we report extensive experimentation to test the quality and properties of our resource with respect to various key aspects of QA systems, including answer relevance, training strategies, and models input configuration. | Stefano Campese, Ivano Lauriola, Alessandro Moschitti |  |
| 1176 |  |  [Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-emnlp.1043) |  | 0 | Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich in world knowledge. This fact has sparked the interest of the community in quantifying the amount of factual knowledge present in PLMs, as this explains their performance on downstream tasks, and potentially justifies their use as knowledge bases. In this work, we survey methods and datasets that are used to probe PLMs for factual knowledge. Our contributions are: (1) We propose a categorization scheme for factual probing methods that is based on how their inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of the datasets used for factual probing; (3) We synthesize insights about knowledge retention and prompt optimization in PLMs, analyze obstacles to adopting PLMs as knowledge bases and outline directions for future work. | Paul Youssef, Osman Alperen Koras, Meijie Li, Jörg Schlötterer, Christin Seifert |  |
| 1177 |  |  [Is ChatGPT the ultimate Data Augmentation Algorithm?](https://doi.org/10.18653/v1/2023.findings-emnlp.1044) |  | 0 | In the aftermath of GPT-3.5, commonly known as ChatGPT, research have attempted to assess its capacity for lowering annotation cost, either by doing zero-shot learning, generating new data, or replacing human annotators. Some studies have also investigated its use for data augmentation (DA), but only in limited contexts, which still leaves the question of how ChatGPT performs compared to state-of-the-art algorithms. In this paper, we use ChatGPT to create new data both with paraphrasing and with zero-shot generation, and compare it to seven other algorithms. We show that while ChatGPT performs exceptionally well on some simpler data, it overall does not perform better than the other algorithms, yet demands a much larger implication from the practitioner due to the ChatGPT often refusing to answer due to sensitive content in the datasets. | Frédéric Piedboeuf, Philippe Langlais |  |
| 1178 |  |  [Enhanced Simultaneous Machine Translation with Word-level Policies](https://doi.org/10.18653/v1/2023.findings-emnlp.1045) |  | 0 | Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT. | Kang Kim, Hankyu Cho |  |
| 1179 |  |  [Causal Intervention-based Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-emnlp.1046) |  | 0 |  | Zhen Yang, Yongbin Liu, Chunping Ouyang |  |
| 1180 |  |  [TADI: Topic-aware Attention and Powerful Dual-encoder Interaction for Recall in News Recommendation](https://doi.org/10.18653/v1/2023.findings-emnlp.1047) |  | 0 |  | Junxiang Jiang |  |
| 1181 |  |  [Unveiling the Power of Argument Arrangement in Online Persuasive Discussions](https://doi.org/10.18653/v1/2023.findings-emnlp.1048) |  | 0 |  | Nailia Mirzakhmedova, Johannes Kiesel, Khalid Al Khatib, Benno Stein |  |
| 1182 |  |  [FFAEval: Evaluating Dialogue System via Free-For-All Ranking](https://doi.org/10.18653/v1/2023.findings-emnlp.1049) |  | 0 |  | Zeyao Ma, Zijun Yao, Jing Zhang, Jifan Yu, Xiaohan Zhang, Juanzi Li, Jie Tang |  |
| 1183 |  |  [Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-emnlp.1050) |  | 0 |  | Nuo Chen, Hongguang Li, Junqing He, Yinan Bao, Xinshi Lin, Qi Yang, Jianfeng Liu, Ruyi Gan, Jiaxing Zhang, Baoyuan Wang, Jia Li |  |
| 1184 |  |  [VER: Unifying Verbalizing Entities and Relations](https://doi.org/10.18653/v1/2023.findings-emnlp.1051) |  | 0 |  | Jie Huang, Kevin Chang |  |
| 1185 |  |  [The Linearity of the Effect of Surprisal on Reading Times across Languages](https://doi.org/10.18653/v1/2023.findings-emnlp.1052) |  | 0 |  | Weijie Xu, Jason Chon, Tianran Liu, Richard Futrell |  |
| 1186 |  |  [Adversarial Text Generation by Search and Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.1053) |  | 0 |  | Guoyi Li, Bingkang Shi, Zongzhen Liu, Dehan Kong, Yulei Wu, Xiaodan Zhang, Longtao Huang, Honglei Lyu |  |
| 1187 |  |  [Measuring Pointwise \mathcalV-Usable Information In-Context-ly](https://doi.org/10.18653/v1/2023.findings-emnlp.1054) |  | 0 |  | Sheng Lu, Shan Chen, Yingya Li, Danielle S. Bitterman, Guergana Savova, Iryna Gurevych |  |
| 1188 |  |  [SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://doi.org/10.18653/v1/2023.findings-emnlp.1055) |  | 0 |  | Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, Xipeng Qiu |  |
| 1189 |  |  [Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration](https://doi.org/10.18653/v1/2023.findings-emnlp.1056) |  | 0 |  | Ercong Nie, Helmut Schmid, Hinrich Schütze |  |
| 1190 |  |  [A Thorough Examination on Zero-shot Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-emnlp.1057) |  | 0 |  | Ruiyang Ren, Yingqi Qu, Jing Liu, Xin Zhao, Qifei Wu, Yuchen Ding, Hua Wu, Haifeng Wang, JiRong Wen |  |
| 1191 |  |  [Contrastive Pre-training for Personalized Expert Finding](https://doi.org/10.18653/v1/2023.findings-emnlp.1058) |  | 0 |  | Qiyao Peng, Hongtao Liu, Zhepeng Lv, Qing Yang, Wenjun Wang |  |
| 1192 |  |  [Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.1059) |  | 0 |  | Jianbin Shen, Junyu Xuan, Christy Jie Liang |  |
| 1193 |  |  [Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning](https://doi.org/10.18653/v1/2023.findings-emnlp.1060) |  | 0 |  | Hongfu Liu, Ye Wang |  |
| 1194 |  |  [Frontmatter](https://aclanthology.org/2023.emnlp-main.0) |  | 0 |  |  |  |
| 1195 |  |  [IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions](https://doi.org/10.18653/v1/2023.emnlp-main.1) |  | 0 |  | Zhebin Zhang, Xinyu Zhang, Yuanhang Ren, Saijiang Shi, Meng Han, Yongkang Wu, Ruofei Lai, Zhao Cao |  |
| 1196 |  |  [Absolute Position Embedding Learns Sinusoid-like Waves for Attention Based on Relative Position](https://doi.org/10.18653/v1/2023.emnlp-main.2) |  | 0 |  | Yuji Yamamoto, Takuya Matsuzaki |  |
| 1197 |  |  [Chinese Lexical Substitution: Dataset and Method](https://doi.org/10.18653/v1/2023.emnlp-main.3) |  | 0 |  | Jipeng Qiang, Kang Liu, Ying Li, Yun Li, Yi Zhu, YunHao Yuan, Xiaocheng Hu, Xiaoye Ouyang |  |
| 1198 |  |  [Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting](https://doi.org/10.18653/v1/2023.emnlp-main.4) |  | 0 |  | Chenkai Sun, Jinning Li, Yi Ren Fung, Hou Pong Chan, Tarek F. Abdelzaher, ChengXiang Zhai, Heng Ji |  |
| 1199 |  |  [Fine-grained Conversational Decoding via Isotropic and Proximal Search](https://doi.org/10.18653/v1/2023.emnlp-main.5) |  | 0 |  | Yuxuan Yao, Han Wu, Qiling Xu, Linqi Song |  |
| 1200 |  |  [Holistic Inter-Annotator Agreement and Corpus Coherence Estimation in a Large-scale Multilingual Annotation Campaign](https://doi.org/10.18653/v1/2023.emnlp-main.6) |  | 0 |  | Nicolas Stefanovitch, Jakub Piskorski |  |
| 1201 |  |  [PHD: Pixel-Based Language Modeling of Historical Documents](https://doi.org/10.18653/v1/2023.emnlp-main.7) |  | 0 |  | Nadav Borenstein, Phillip Rust, Desmond Elliott, Isabelle Augenstein |  |
| 1202 |  |  [Primacy Effect of ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.8) |  | 0 |  | Yiwei Wang, Yujun Cai, Muhao Chen, Yuxuan Liang, Bryan Hooi |  |
| 1203 |  |  [Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension](https://doi.org/10.18653/v1/2023.emnlp-main.9) |  | 0 |  | Akira Kawabata, Saku Sugawara |  |
| 1204 |  |  [Evaluating and Modeling Attribution for Cross-Lingual Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.10) |  | 0 |  | Benjamin Muller, John Wieting, Jonathan H. Clark, Tom Kwiatkowski, Sebastian Ruder, Livio Soares, Roee Aharoni, Jonathan Herzig, Xinyi Wang |  |
| 1205 |  |  [Better Quality Pre-training Data and T5 Models for African Languages](https://doi.org/10.18653/v1/2023.emnlp-main.11) |  | 0 |  | Akintunde Oladipo, Mofetoluwa Adeyemi, Orevaoghene Ahia, Abraham Toluwase Owodunni, Odunayo Ogundepo, David Ifeoluwa Adelani, Jimmy Lin |  |
| 1206 |  |  [Sparse Universal Transformer](https://doi.org/10.18653/v1/2023.emnlp-main.12) |  | 0 |  | Shawn Tan, Yikang Shen, Zhenfang Chen, Aaron C. Courville, Chuang Gan |  |
| 1207 |  |  [Theory of Mind for Multi-Agent Collaboration via Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.13) |  | 0 |  | Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Charles Lewis, Katia P. Sycara |  |
| 1208 |  |  [Establishing Trustworthiness: Rethinking Tasks and Model Evaluation](https://doi.org/10.18653/v1/2023.emnlp-main.14) |  | 0 |  | Robert Litschko, Max MüllerEberstein, Rob van der Goot, Leon WeberGenzel, Barbara Plank |  |
| 1209 |  |  [Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought](https://doi.org/10.18653/v1/2023.emnlp-main.15) |  | 0 |  | Vaishnavi Himakunthala, Andy Ouyang, Daniel Rose, Ryan He, Alex Mei, Yujie Lu, Chinmay Sonar, Michael Saxon, William Yang Wang |  |
| 1210 |  |  [GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP](https://doi.org/10.18653/v1/2023.emnlp-main.16) |  | 0 |  | Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi, Muhammad AbdulMageed |  |
| 1211 |  |  [Dual-Channel Span for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.17) |  | 0 |  | Pan Li, Ping Li, Kai Zhang |  |
| 1212 |  |  [Cultural Concept Adaptation on Multimodal Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.18) |  | 0 |  | Zhi Li, Yin Zhang |  |
| 1213 |  |  [Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection](https://doi.org/10.18653/v1/2023.emnlp-main.19) |  | 0 |  | Farhan Samir, Miikka Silfverberg |  |
| 1214 |  |  [Evaluating Object Hallucination in Large Vision-Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.20) |  | 0 |  | Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao, JiRong Wen |  |
| 1215 |  |  [Event Ontology Completion with Hierarchical Structure Evolution Networks](https://doi.org/10.18653/v1/2023.emnlp-main.21) |  | 0 |  | Pengfei Cao, Yupu Hao, Yubo Chen, Kang Liu, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Jun Zhao |  |
| 1216 |  |  [Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients](https://doi.org/10.18653/v1/2023.emnlp-main.22) |  | 0 |  | Feihu Jin, Jiajun Zhang, Chengqing Zong |  |
| 1217 |  |  [Discourse Structures Guided Fine-grained Propaganda Identification](https://doi.org/10.18653/v1/2023.emnlp-main.23) |  | 0 |  | Yuanyuan Lei, Ruihong Huang |  |
| 1218 |  |  [CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.24) |  | 0 |  | Benjamin Minixhofer, Jonas Pfeiffer, Ivan Vulic |  |
| 1219 |  |  [Improving Image Captioning via Predicting Structured Concepts](https://doi.org/10.18653/v1/2023.emnlp-main.25) |  | 0 |  | Ting Wang, Weidong Chen, Yuanhe Tian, Yan Song, Zhendong Mao |  |
| 1220 |  |  [GATITOS: Using a New Multilingual Lexicon for Low-resource Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.26) |  | 0 |  | Alexander Jones, Isaac Caswell, Orhan Firat, Ishank Saxena |  |
| 1221 |  |  [Continually Improving Extractive QA via Human Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.27) |  | 0 |  | Ge Gao, HungTing Chen, Yoav Artzi, Eunsol Choi |  |
| 1222 |  |  [Using Interpretation Methods for Model Enhancement](https://doi.org/10.18653/v1/2023.emnlp-main.28) |  | 0 |  | Zhuo Chen, Chengyue Jiang, Kewei Tu |  |
| 1223 |  |  [An Expression Tree Decoding Strategy for Mathematical Equation Generation](https://doi.org/10.18653/v1/2023.emnlp-main.29) |  | 0 |  | Wenqi Zhang, Yongliang Shen, Qingpeng Nong, Zeqi Tan, Yanna Ma, Weiming Lu |  |
| 1224 |  |  [Bootstrapping Small & High Performance Language Models with Unmasking-Removal Training Policy](https://doi.org/10.18653/v1/2023.emnlp-main.30) |  | 0 |  | Yahan Yang, Elior Sulem, Insup Lee, Dan Roth |  |
| 1225 |  |  [Diversity Enhanced Narrative Question Generation for Storybooks](https://doi.org/10.18653/v1/2023.emnlp-main.31) |  | 0 |  | Hokeun Yoon, JinYeong Bak |  |
| 1226 |  |  [Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification](https://doi.org/10.18653/v1/2023.emnlp-main.32) |  | 0 |  | Chengyu Dong, Zihan Wang, Jingbo Shang |  |
| 1227 |  |  [How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.33) |  | 0 |  | Hang Chen, Xinyu Yang, Jing Luo, Wenjing Zhu |  |
| 1228 |  |  [Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.34) |  | 0 |  | Qingyi Si, Yuanxin Liu, Zheng Lin, Peng Fu, Yanan Cao, Weiping Wang |  |
| 1229 |  |  [Selectively Answering Ambiguous Questions](https://doi.org/10.18653/v1/2023.emnlp-main.35) |  | 0 |  | Jeremy R. Cole, Michael J. Q. Zhang, Daniel Gillick, Julian Eisenschlos, Bhuwan Dhingra, Jacob Eisenstein |  |
| 1230 |  |  [Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.36) |  | 0 |  | DongHo Lee, Kian Ahrabian, Woojeong Jin, Fred Morstatter, Jay Pujara |  |
| 1231 |  |  [Knowledge Graph Compression Enhances Diverse Commonsense Generation](https://doi.org/10.18653/v1/2023.emnlp-main.37) |  | 0 |  | Eunjeong Hwang, Veronika Thost, Vered Shwartz, Tengfei Ma |  |
| 1232 |  |  [Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models](https://doi.org/10.18653/v1/2023.emnlp-main.38) |  | 0 |  | Yiyuan Li, Rakesh R. Menon, Sayan Ghosh, Shashank Srivastava |  |
| 1233 |  |  [LLM-FP4: 4-Bit Floating-Point Quantized Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.39) |  | 0 |  | ShihYang Liu, Zechun Liu, Xijie Huang, Pingcheng Dong, KwangTing Cheng |  |
| 1234 |  |  [Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers](https://doi.org/10.18653/v1/2023.emnlp-main.40) |  | 0 |  | Chen Tang, Shun Wang, Tomas Goldsack, Chenghua Lin |  |
| 1235 |  |  [Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting](https://doi.org/10.18653/v1/2023.emnlp-main.41) |  | 0 |  | Xi Ye, Greg Durrett |  |
| 1236 |  |  [HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.42) |  | 0 |  | David Dale, Elena Voita, Janice Lam, Prangthip Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Loïc Barrault, Marta R. Costajussà |  |
| 1237 |  |  [Gradient-based Gradual Pruning for Language-Specific Multilingual Neural Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.43) |  | 0 |  | Dan He, MinhQuang Pham, ThanhLe Ha, Marco Turchi |  |
| 1238 |  |  [LLM-powered Data Augmentation for Enhanced Cross-lingual Performance](https://doi.org/10.18653/v1/2023.emnlp-main.44) |  | 0 |  | Chenxi Whitehouse, Monojit Choudhury, Alham Fikri Aji |  |
| 1239 |  |  [Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.45) |  | 0 |  | Chenxu Wang, Ping Jian, Mu Huang |  |
| 1240 |  |  [VLIS: Unimodal Language Models Guide Multimodal Language Generation](https://doi.org/10.18653/v1/2023.emnlp-main.46) |  | 0 |  | Jiwan Chung, Youngjae Yu |  |
| 1241 |  |  [Conceptual structure coheres in human cognition but not in large language models](https://doi.org/10.18653/v1/2023.emnlp-main.47) |  | 0 |  | Siddharth Suresh, Kushin Mukherjee, Xizheng Yu, WeiChun Huang, Lisa Padua, Timothy T. Rogers |  |
| 1242 |  |  [Towards LLM-driven Dialogue State Tracking](https://doi.org/10.18653/v1/2023.emnlp-main.48) |  | 0 |  | Yujie Feng, Zexin Lu, Bo Liu, Liming Zhan, XiaoMing Wu |  |
| 1243 |  |  [Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.49) |  | 0 |  | Haoyu Zhang, Yu Wang, Guanghao Yin, Kejun Liu, Yuanyuan Liu, Tianshu Yu |  |
| 1244 |  |  [Multitask Multimodal Prompted Training for Interactive Embodied Task Completion](https://doi.org/10.18653/v1/2023.emnlp-main.50) |  | 0 |  | Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia |  |
| 1245 |  |  [We're Afraid Language Models Aren't Modeling Ambiguity](https://doi.org/10.18653/v1/2023.emnlp-main.51) |  | 0 |  | Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi |  |
| 1246 |  |  [Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective](https://doi.org/10.18653/v1/2023.emnlp-main.52) |  | 0 |  | Tianyu Liu, Afra Amini, Mrinmaya Sachan, Ryan Cotterell |  |
| 1247 |  |  [GEMINI: Controlling The Sentence-Level Summary Style in Abstractive Text Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.53) |  | 0 |  | Guangsheng Bao, Zebin Ou, Yue Zhang |  |
| 1248 |  |  [Fidelity-Enriched Contrastive Search: Reconciling the Faithfulness-Diversity Trade-Off in Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.54) |  | 0 |  | WeiLin Chen, ChengKuang Wu, HsinHsi Chen, ChungChi Chen |  |
| 1249 |  |  [Analyzing Norm Violations in Live-Stream Chat](https://doi.org/10.18653/v1/2023.emnlp-main.55) |  | 0 |  | Jihyung Moon, DongHo Lee, Hyundong Cho, Woojeong Jin, Chan Young Park, Minwoo Kim, Jonathan May, Jay Pujara, Sungjoon Park |  |
| 1250 |  |  [Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality](https://doi.org/10.18653/v1/2023.emnlp-main.56) |  | 0 |  | Harman Singh, Pengchuan Zhang, Qifan Wang, Mengjiao Wang, Wenhan Xiong, Jingfei Du, Yu Chen |  |
| 1251 |  |  [Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms](https://doi.org/10.18653/v1/2023.emnlp-main.57) |  | 0 |  | Seungju Han, Junhyeok Kim, Jack Hessel, Liwei Jiang, Jiwan Chung, Yejin Son, Yejin Choi, Youngjae Yu |  |
| 1252 |  |  [Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus](https://doi.org/10.18653/v1/2023.emnlp-main.58) |  | 0 |  | Tianhang Zhang, Lin Qiu, Qipeng Guo, Cheng Deng, Yue Zhang, Zheng Zhang, Chenghu Zhou, Xinbing Wang, Luoyi Fu |  |
| 1253 |  |  [FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.59) |  | 0 |  | Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, Yulia Tsvetkov |  |
| 1254 |  |  [Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation](https://doi.org/10.18653/v1/2023.emnlp-main.60) |  | 0 |  | Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn |  |
| 1255 |  |  [Symbol tuning improves in-context learning in language models](https://doi.org/10.18653/v1/2023.emnlp-main.61) |  | 0 |  | Jerry W. Wei, Le Hou, Andrew K. Lampinen, Xiangning Chen, Da Huang, Yi Tay, Xinyun Chen, Yifeng Lu, Denny Zhou, Tengyu Ma, Quoc V. Le |  |
| 1256 |  |  [The neural dynamics of word recognition and integration](https://doi.org/10.18653/v1/2023.emnlp-main.62) |  | 0 |  | Jon Gauthier, Roger Levy |  |
| 1257 |  |  [Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.63) |  | 0 |  | Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joonsuk Park, Jaewoo Kang |  |
| 1258 |  |  [Incorporating Worker Perspectives into MTurk Annotation Practices for NLP](https://doi.org/10.18653/v1/2023.emnlp-main.64) |  | 0 |  | Olivia Huang, Eve Fleisig, Dan Klein |  |
| 1259 |  |  [Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications](https://doi.org/10.18653/v1/2023.emnlp-main.65) |  | 0 |  | Yue Guo, Chenxi Hu, Yi Yang |  |
| 1260 |  |  [Look-back Decoding for Open-Ended Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.66) |  | 0 |  | Nan Xu, Chunting Zhou, Asli Celikyilmaz, Xuezhe Ma |  |
| 1261 |  |  [Large Language Models Can Self-Improve](https://doi.org/10.18653/v1/2023.emnlp-main.67) |  | 0 |  | Jiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, Jiawei Han |  |
| 1262 |  |  [CodeT5+: Open Code Large Language Models for Code Understanding and Generation](https://doi.org/10.18653/v1/2023.emnlp-main.68) |  | 0 |  | Yue Wang, Hung Le, Akhilesh Gotmare, Nghi D. Q. Bui, Junnan Li, Steven C. H. Hoi |  |
| 1263 |  |  [Structural generalization in COGS: Supertagging is (almost) all you need](https://doi.org/10.18653/v1/2023.emnlp-main.69) |  | 0 |  | Alban Petit, Caio F. Corro, François Yvon |  |
| 1264 |  |  [BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations](https://doi.org/10.18653/v1/2023.emnlp-main.70) |  | 0 |  | Qizhi Pei, Wei Zhang, Jinhua Zhu, Kehan Wu, Kaiyuan Gao, Lijun Wu, Yingce Xia, Rui Yan |  |
| 1265 |  |  [Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings](https://doi.org/10.18653/v1/2023.emnlp-main.71) |  | 0 |  | Andrea W. WenYi, David Mimno |  |
| 1266 |  |  [Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation](https://doi.org/10.18653/v1/2023.emnlp-main.72) |  | 0 |  | Jian Wang, Yi Cheng, Dongding Lin, Chak Tou Leong, Wenjie Li |  |
| 1267 |  |  [SeqXGPT: Sentence-Level AI-Generated Text Detection](https://doi.org/10.18653/v1/2023.emnlp-main.73) |  | 0 |  | Pengyu Wang, Linyang Li, Ke Ren, Botian Jiang, Dong Zhang, Xipeng Qiu |  |
| 1268 |  |  [QTSumm: Query-Focused Summarization over Tabular Data](https://doi.org/10.18653/v1/2023.emnlp-main.74) |  | 0 |  | Yilun Zhao, Zhenting Qi, Linyong Nan, Boyu Mi, Yixin Liu, Weijin Zou, Simeng Han, Ruizhe Chen, Xiangru Tang, Yumo Xu, Dragomir Radev, Arman Cohan |  |
| 1269 |  |  [From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation](https://doi.org/10.18653/v1/2023.emnlp-main.75) |  | 0 |  | Jiaxin Ge, Sanjay Subramanian, Trevor Darrell, Boyi Li |  |
| 1270 |  |  ['Don't Get Too Technical with Me': A Discourse Structure-Based Framework for Automatic Science Journalism](https://doi.org/10.18653/v1/2023.emnlp-main.76) |  | 0 |  | Ronald Cardenas, Bingsheng Yao, Dakuo Wang, Yufang Hou |  |
| 1271 |  |  [LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following](https://doi.org/10.18653/v1/2023.emnlp-main.77) |  | 0 |  | ChengFu Yang, YenChun Chen, Jianwei Yang, Xiyang Dai, Lu Yuan, YuChiang Frank Wang, KaiWei Chang |  |
| 1272 |  |  [Penalty Decoding: Well Suppress the Self-Reinforcement Effect in Open-Ended Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.78) |  | 0 |  | Wenhong Zhu, Hongkun Hao, Rui Wang |  |
| 1273 |  |  [Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.79) |  | 0 |  | Jianwei Li, Qi Lei, Wei Cheng, Dongkuan Xu |  |
| 1274 |  |  [Clinical Contradiction Detection](https://doi.org/10.18653/v1/2023.emnlp-main.80) |  | 0 |  | Dave Makhervaks, Plia Gillis, Kira Radinsky |  |
| 1275 |  |  [Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements](https://doi.org/10.18653/v1/2023.emnlp-main.81) |  | 0 |  | Jiacheng Liu, Wenya Wang, Dianzhuo Wang, Noah A. Smith, Yejin Choi, Hannaneh Hajishirzi |  |
| 1276 |  |  [Text-Transport: Toward Learning Causal Effects of Natural Language](https://doi.org/10.18653/v1/2023.emnlp-main.82) |  | 0 |  | Victoria Lin, LouisPhilippe Morency, Eli BenMichael |  |
| 1277 |  |  [How Does Generative Retrieval Scale to Millions of Passages?](https://doi.org/10.18653/v1/2023.emnlp-main.83) |  | 0 |  | Ronak Pradeep, Kai Hui, Jai Gupta, Ádám D. Lelkes, Honglei Zhuang, Jimmy Lin, Donald Metzler, Vinh Q. Tran |  |
| 1278 |  |  [Unveiling the Implicit Toxicity in Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.84) |  | 0 |  | Jiaxin Wen, Pei Ke, Hao Sun, Zhexin Zhang, Chengfei Li, Jinfeng Bai, Minlie Huang |  |
| 1279 |  |  [Is ChatGPT a General-Purpose Natural Language Processing Task Solver?](https://doi.org/10.18653/v1/2023.emnlp-main.85) |  | 0 |  | Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang |  |
| 1280 |  |  [Length is a Curse and a Blessing for Document-level Semantics](https://doi.org/10.18653/v1/2023.emnlp-main.86) |  | 0 |  | Chenghao Xiao, Yizhi Li, G. Thomas Hudson, Chenghua Lin, Noura Al Moubayed |  |
| 1281 |  |  [ALCUNA: Large Language Models Meet New Knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.87) |  | 0 |  | Xunjian Yin, Baizhou Huang, Xiaojun Wan |  |
| 1282 |  |  [Location-Aware Visual Question Generation with Lightweight Models](https://doi.org/10.18653/v1/2023.emnlp-main.88) |  | 0 |  | Nicholas Collin Suwono, Justin ChihYao Chen, TunMin Hung, TingHao (Kenneth) Huang, IBin Liao, YungHui Li, LunWei Ku, ShaoHua Sun |  |
| 1283 |  |  [MemeCap: A Dataset for Captioning and Interpreting Memes](https://doi.org/10.18653/v1/2023.emnlp-main.89) |  | 0 |  | Eunjeong Hwang, Vered Shwartz |  |
| 1284 |  |  [Where to start? Analyzing the potential value of intermediate models](https://doi.org/10.18653/v1/2023.emnlp-main.90) |  | 0 |  | Leshem Choshen, Elad Venezian, Shachar DonYehiya, Noam Slonim, Yoav Katz |  |
| 1285 |  |  [Transcending Scaling Laws with 0.1% Extra Compute](https://doi.org/10.18653/v1/2023.emnlp-main.91) |  | 0 |  | Yi Tay, Jason Wei, Hyung Won Chung, Vinh Q. Tran, David R. So, Siamak Shakeri, Xavier Garcia, Huaixiu Steven Zheng, Jinfeng Rao, Aakanksha Chowdhery, Denny Zhou, Donald Metzler, Slav Petrov, Neil Houlsby, Quoc V. Le, Mostafa Dehghani |  |
| 1286 |  |  [CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation](https://doi.org/10.18653/v1/2023.emnlp-main.92) |  | 0 |  | Minzhi Li, Taiwei Shi, Caleb Ziems, MinYen Kan, Nancy F. Chen, Zhengyuan Liu, Diyi Yang |  |
| 1287 |  |  [Optimizing Retrieval-augmented Reader Models via Token Elimination](https://doi.org/10.18653/v1/2023.emnlp-main.93) |  | 0 |  | Moshe Berchansky, Peter Izsak, Avi Caciularu, Ido Dagan, Moshe Wasserblat |  |
| 1288 |  |  [WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom](https://doi.org/10.18653/v1/2023.emnlp-main.94) |  | 0 |  | Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, Zhiwei Yang |  |
| 1289 |  |  [Robust Prompt Optimization for Large Language Models Against Distribution Shifts](https://doi.org/10.18653/v1/2023.emnlp-main.95) |  | 0 |  | Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi Zhang, TatSeng Chua |  |
| 1290 |  |  [Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.96) |  | 0 |  | Martin Josifoski, Marija Sakota, Maxime Peyrard, Robert West |  |
| 1291 |  |  [Condensing Multilingual Knowledge with Lightweight Language-Specific Modules](https://doi.org/10.18653/v1/2023.emnlp-main.97) |  | 0 |  | Haoran Xu, Weiting Tan, Shuyue Stella Li, Yunmo Chen, Benjamin Van Durme, Philipp Koehn, Kenton Murray |  |
| 1292 |  |  [The Framework Tax: Disparities Between Inference Efficiency in NLP Research and Deployment](https://doi.org/10.18653/v1/2023.emnlp-main.98) |  | 0 |  | Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell |  |
| 1293 |  |  [Evaluating Cross-Domain Text-to-SQL Models and Benchmarks](https://doi.org/10.18653/v1/2023.emnlp-main.99) |  | 0 |  | Mohammadreza Pourreza, Davood Rafiei |  |
| 1294 |  |  [Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.100) |  | 0 |  | Simone Conia, Min Li, Daniel Lee, Umar Farooq Minhas, Ihab F. Ilyas, Yunyao Li |  |
| 1295 |  |  [Memory-Based Invariance Learning for Out-of-Domain Text Classification](https://doi.org/10.18653/v1/2023.emnlp-main.101) |  | 0 |  | Chen Jia, Yue Zhang |  |
| 1296 |  |  [Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling](https://doi.org/10.18653/v1/2023.emnlp-main.102) |  | 0 |  | Xiuying Wei, Yunchen Zhang, Yuhang Li, Xiangguo Zhang, Ruihao Gong, Jinyang Guo, Xianglong Liu |  |
| 1297 |  |  [Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.103) |  | 0 |  | Jiaqi Li, Chuanyi Zhang, Miaozeng Du, Dehai Min, Yongrui Chen, Guilin Qi |  |
| 1298 |  |  [Diversify Question Generation with Retrieval-Augmented Style Transfer](https://doi.org/10.18653/v1/2023.emnlp-main.104) |  | 0 |  | Qi Gou, Zehua Xia, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li, CamTu Nguyen |  |
| 1299 |  |  [Fast and Accurate Factual Inconsistency Detection Over Long Documents](https://doi.org/10.18653/v1/2023.emnlp-main.105) |  | 0 |  | Barrett Martin Lattimer, Patrick Chen, Xinyuan Zhang, Yi Yang |  |
| 1300 |  |  [Interpreting Embedding Spaces by Conceptualization](https://doi.org/10.18653/v1/2023.emnlp-main.106) |  | 0 |  | Adi Simhi, Shaul Markovitch |  |
| 1301 |  |  [Knowledge-Augmented Language Model Verification](https://doi.org/10.18653/v1/2023.emnlp-main.107) |  | 0 |  | Jinheon Baek, Soyeong Jeong, Minki Kang, Jong C. Park, Sung Ju Hwang |  |
| 1302 |  |  [A Generation-based Deductive Method for Math Word Problems](https://doi.org/10.18653/v1/2023.emnlp-main.108) |  | 0 |  | Yuxuan Hu, Jing Zhang, Haoyang Li, Cuiping Li, Hong Chen |  |
| 1303 |  |  [Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation](https://doi.org/10.18653/v1/2023.emnlp-main.109) |  | 0 |  | Zeyuan Yang, Peng Li, Yang Liu |  |
| 1304 |  |  [Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning](https://doi.org/10.18653/v1/2023.emnlp-main.110) |  | 0 |  | Ryan Shea, Zhou Yu |  |
| 1305 |  |  [Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories](https://doi.org/10.18653/v1/2023.emnlp-main.111) |  | 0 |  | Suyu Ge, Chenyan Xiong, Corby Rosset, Arnold Overwijk, Jiawei Han, Paul Bennett |  |
| 1306 |  |  [Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.112) |  | 0 |  | PoNien Kung, Fan Yin, Di Wu, KaiWei Chang, Nanyun Peng |  |
| 1307 |  |  [Towards Example-Based NMT with Multi-Levenshtein Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.113) |  | 0 |  | Maxime Bouthors, Josep Maria Crego, François Yvon |  |
| 1308 |  |  [DUnE: Dataset for Unified Editing](https://doi.org/10.18653/v1/2023.emnlp-main.114) |  | 0 |  | Afra Feyza Akyürek, Eric Pan, Garry Kuwanto, Derry Wijaya |  |
| 1309 |  |  ["Fifty Shades of Bias": Normative Ratings of Gender Bias in GPT Generated English Text](https://doi.org/10.18653/v1/2023.emnlp-main.115) |  | 0 |  | Rishav Hada, Agrima Seth, Harshita Diddee, Kalika Bali |  |
| 1310 |  |  [Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.116) |  | 0 |  | Peitian Zhang, Zheng Liu, Shitao Xiao, Zhicheng Dou, Jing Yao |  |
| 1311 |  |  [ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness](https://doi.org/10.18653/v1/2023.emnlp-main.117) |  | 0 |  | Ján Cegin, Jakub Simko, Peter Brusilovsky |  |
| 1312 |  |  [Query-as-context Pre-training for Dense Passage Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.118) |  | 0 |  | Xing Wu, Guangyuan Ma, Wanhui Qian, Zijia Lin, Songlin Hu |  |
| 1313 |  |  [A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.119) |  | 0 |  | Andrea Burns, Krishna Srinivasan, Joshua Ainslie, Geoff Brown, Bryan A. Plummer, Kate Saenko, Jianmo Ni, Mandy Guo |  |
| 1314 |  |  [Democratizing Reasoning Ability: Tailored Learning from Large Language Model](https://doi.org/10.18653/v1/2023.emnlp-main.120) |  | 0 |  | Zhaoyang Wang, Shaohan Huang, Yuxuan Liu, Jiahai Wang, Minghui Song, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 1315 |  |  [OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.121) |  | 0 |  | Shmuel Amar, Liat Schiff, Ori Ernst, Asi Shefer, Ori Shapira, Ido Dagan |  |
| 1316 |  |  [PEFTDebias : Capturing debiasing information using PEFTs](https://doi.org/10.18653/v1/2023.emnlp-main.122) |  | 0 |  | Sumit Agarwal, Aditya Srikanth Veerubhotla, Srijan Bansal |  |
| 1317 |  |  [Byte Pair Encoding for Symbolic Music](https://doi.org/10.18653/v1/2023.emnlp-main.123) |  | 0 |  | Nathan Fradet, Nicolas Gutowski, Fabien Chhel, JeanPierre Briot |  |
| 1318 |  |  [Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models](https://doi.org/10.18653/v1/2023.emnlp-main.124) |  | 0 |  | Alejo LopezAvila, Víctor SuárezPaniagua |  |
| 1319 |  |  [Self-Influence Guided Data Reweighting for Language Model Pre-training](https://doi.org/10.18653/v1/2023.emnlp-main.125) |  | 0 |  | Megh Thakkar, Tolga Bolukbasi, Sriram Ganapathy, Shikhar Vashishth, Sarath Chandar, Partha Talukdar |  |
| 1320 |  |  [ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation](https://doi.org/10.18653/v1/2023.emnlp-main.126) |  | 0 |  | Xinpeng Wang, Barbara Plank |  |
| 1321 |  |  [TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.127) |  | 0 |  | Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor |  |
| 1322 |  |  [VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining](https://doi.org/10.18653/v1/2023.emnlp-main.128) |  | 0 |  | Ramon RuizDolz, Javier Sanchez |  |
| 1323 |  |  [Tagging-Assisted Generation Model with Encoder and Decoder Supervision for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.129) |  | 0 |  | Xianlong Luo, Meng Yang, Yihao Wang |  |
| 1324 |  |  [Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.130) |  | 0 |  | Namrata Shivagunde, Vladislav Lialin, Anna Rumshisky |  |
| 1325 |  |  [Norm of Word Embedding Encodes Information Gain](https://doi.org/10.18653/v1/2023.emnlp-main.131) |  | 0 |  | Momose Oyama, Sho Yokoi, Hidetoshi Shimodaira |  |
| 1326 |  |  [CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data](https://doi.org/10.18653/v1/2023.emnlp-main.132) |  | 0 |  | Zhehao Zhang, Xitao Li, Yan Gao, JianGuang Lou |  |
| 1327 |  |  [Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph](https://doi.org/10.18653/v1/2023.emnlp-main.133) |  | 0 |  | Yash Kumar Atri, Arun Iyer, Tanmoy Chakraborty, Vikram Goyal |  |
| 1328 |  |  [MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations](https://doi.org/10.18653/v1/2023.emnlp-main.134) |  | 0 |  | Arkil Patel, Satwik Bhattamishra, Siva Reddy, Dzmitry Bahdanau |  |
| 1329 |  |  [Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency](https://doi.org/10.18653/v1/2023.emnlp-main.135) |  | 0 |  | Eric Zelikman, Wanjing Anya Ma, Jasmine E. Tran, Diyi Yang, Jason D. Yeatman, Nick Haber |  |
| 1330 |  |  [Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI)](https://doi.org/10.18653/v1/2023.emnlp-main.136) |  | 0 |  | Megha Chakraborty, S. M. Towhidul Islam Tonmoy, S. M. Mehedi Zaman, Shreya Gautam, Tanay Kumar, Krish Sharma, Niyar R. Barman, Chandan Gupta, Vinija Jain, Aman Chadha, Amit P. Sheth, Amitava Das |  |
| 1331 |  |  [Revisiting the Optimality of Word Lengths](https://doi.org/10.18653/v1/2023.emnlp-main.137) |  | 0 |  | Tiago Pimentel, Clara Meister, Ethan Wilcox, Kyle Mahowald, Ryan Cotterell |  |
| 1332 |  |  [Document-level Relationship Extraction by Bidirectional Constraints of Beta Rules](https://doi.org/10.18653/v1/2023.emnlp-main.138) |  | 0 |  | Yichun Liu, Zizhong Zhu, Xiaowang Zhang, Zhiyong Feng, Daoqi Chen, Yaxin Li |  |
| 1333 |  |  [Instructed Language Models with Retrievers Are Powerful Entity Linkers](https://doi.org/10.18653/v1/2023.emnlp-main.139) |  | 0 |  | Zilin Xiao, Ming Gong, Jie Wu, Xingyao Zhang, Linjun Shou, Daxin Jiang |  |
| 1334 |  |  [Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text](https://doi.org/10.18653/v1/2023.emnlp-main.140) |  | 0 |  | Xiang Li, Jinglu Wang, Xiaohao Xu, Muqiao Yang, Fan Yang, Yizhou Zhao, Rita Singh, Bhiksha Raj |  |
| 1335 |  |  [PROSE: A Pronoun Omission Solution for Chinese-English Spoken Language Translation](https://doi.org/10.18653/v1/2023.emnlp-main.141) |  | 0 |  | Ke Wang, Xiutian Zhao, Yanghui Li, Wei Peng |  |
| 1336 |  |  [A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?](https://doi.org/10.18653/v1/2023.emnlp-main.142) |  | 0 |  | Aniket Pramanick, Yufang Hou, Saif M. Mohammad, Iryna Gurevych |  |
| 1337 |  |  [Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?](https://doi.org/10.18653/v1/2023.emnlp-main.143) |  | 0 |  | Boxi Cao, Qiaoyu Tang, Hongyu Lin, Xianpei Han, Le Sun |  |
| 1338 |  |  [Syntactic Substitutability as Unsupervised Dependency Syntax](https://doi.org/10.18653/v1/2023.emnlp-main.144) |  | 0 |  | Jasper Jian, Siva Reddy |  |
| 1339 |  |  [MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.145) |  | 0 |  | Shuhui Wu, Yongliang Shen, Zeqi Tan, Wenqi Ren, Jietian Guo, Shiliang Pu, Weiming Lu |  |
| 1340 |  |  [The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions](https://doi.org/10.18653/v1/2023.emnlp-main.146) |  | 0 |  | Siru Ouyang, Shuohang Wang, Yang Liu, Ming Zhong, Yizhu Jiao, Dan Iter, Reid Pryzant, Chenguang Zhu, Heng Ji, Jiawei Han |  |
| 1341 |  |  [Learning the Visualness of Text Using Large Vision-Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.147) |  | 0 |  | Gaurav Verma, Ryan A. Rossi, Christopher Tensmeyer, Jiuxiang Gu, Ani Nenkova |  |
| 1342 |  |  [The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values](https://doi.org/10.18653/v1/2023.emnlp-main.148) |  | 0 |  | Hannah Kirk, Andrew M. Bean, Bertie Vidgen, Paul Röttger, Scott Hale |  |
| 1343 |  |  [TempTabQA: Temporal Question Answering for Semi-Structured Tables](https://doi.org/10.18653/v1/2023.emnlp-main.149) |  | 0 |  | Vivek Gupta, Pranshu Kandoi, Mahek Bhavesh Vora, Shuo Zhang, Yujie He, Ridho Reinanda, Vivek Srikumar |  |
| 1344 |  |  [Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task](https://doi.org/10.18653/v1/2023.emnlp-main.150) |  | 0 |  | Chunhui Du, Jidong Tian, Haoran Liao, Jindou Chen, Hao He, Yaohui Jin |  |
| 1345 |  |  [RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation](https://doi.org/10.18653/v1/2023.emnlp-main.151) |  | 0 |  | Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang Zan, Yi Mao, JianGuang Lou, Weizhu Chen |  |
| 1346 |  |  [Influence Scores at Scale for Efficient Language Data Sampling](https://doi.org/10.18653/v1/2023.emnlp-main.152) |  | 0 |  | Nikhil Anand, Joshua Tan, Maria Minakova |  |
| 1347 |  |  [G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment](https://doi.org/10.18653/v1/2023.emnlp-main.153) |  | 0 |  | Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, Chenguang Zhu |  |
| 1348 |  |  [Learning Retrieval Augmentation for Personalized Dialogue Generation](https://doi.org/10.18653/v1/2023.emnlp-main.154) |  | 0 |  | Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang, Lilian Tang |  |
| 1349 |  |  [The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations](https://doi.org/10.18653/v1/2023.emnlp-main.155) |  | 0 |  | Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S. M. Towhidul Islam Tonmoy, Aman Chadha, Amit P. Sheth, Amitava Das |  |
| 1350 |  |  [NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders](https://doi.org/10.18653/v1/2023.emnlp-main.156) |  | 0 |  | Livio Soares, Daniel Gillick, Jeremy R. Cole, Tom Kwiatkowski |  |
| 1351 |  |  [Analyzing Modular Approaches for Visual Question Decomposition](https://doi.org/10.18653/v1/2023.emnlp-main.157) |  | 0 |  | Apoorv Khandelwal, Ellie Pavlick, Chen Sun |  |
| 1352 |  |  [Improving Summarization with Human Edits](https://doi.org/10.18653/v1/2023.emnlp-main.158) |  | 0 |  | Zonghai Yao, Benjamin J. Schloss, Sai P. Selvaraj |  |
| 1353 |  |  [Did You Mean...? Confidence-based Trade-offs in Semantic Parsing](https://doi.org/10.18653/v1/2023.emnlp-main.159) |  | 0 |  | Elias StengelEskin, Benjamin Van Durme |  |
| 1354 |  |  [The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages](https://doi.org/10.18653/v1/2023.emnlp-main.160) |  | 0 |  | Chiyu Zhang, Khai Duy Doan, Qisheng Liao, Muhammad AbdulMageed |  |
| 1355 |  |  [Understanding the Effect of Model Compression on Social Bias in Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.161) |  | 0 |  | Gustavo Gonçalves, Emma Strubell |  |
| 1356 |  |  [BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology](https://doi.org/10.18653/v1/2023.emnlp-main.162) |  | 0 |  | Odhran O'Donoghue, Aleksandar Shtedritski, John Ginger, Ralph Abboud, Ali Essa Ghareeb, Samuel G. Rodriques |  |
| 1357 |  |  [Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages](https://doi.org/10.18653/v1/2023.emnlp-main.163) |  | 0 |  | Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, Wanxiang Che |  |
| 1358 |  |  [FinGPT: Large Generative Models for a Small Language](https://doi.org/10.18653/v1/2023.emnlp-main.164) |  | 0 |  | Risto Luukkonen, Ville Komulainen, Jouni Luoma, Anni Eskelinen, Jenna Kanerva, HannaMari Kupari, Filip Ginter, Veronika Laippala, Niklas Muennighoff, Aleksandra Piktus, Thomas Wang, Nouamane Tazi, Teven Le Scao, Thomas Wolf, Osma Suominen, Samuli Sairanen, Mikko Merioksa, Jyrki Heinonen, Aija Vahtola, Samuel Antao, Sampo Pyysalo |  |
| 1359 |  |  [Boosting Summarization with Normalizing Flows and Aggressive Training](https://doi.org/10.18653/v1/2023.emnlp-main.165) |  | 0 |  | Yu Yang, Xiaotong Shen |  |
| 1360 |  |  [Indicative Summarization of Long Discussions](https://doi.org/10.18653/v1/2023.emnlp-main.166) |  | 0 |  | Shahbaz Syed, Dominik Schwabe, Khalid Al Khatib, Martin Potthast |  |
| 1361 |  |  [A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models](https://doi.org/10.18653/v1/2023.emnlp-main.167) |  | 0 |  | Jaewook Lee, Seongsik Park, SeongHeum Park, Hongjin Kim, Harksoo Kim |  |
| 1362 |  |  [Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling](https://doi.org/10.18653/v1/2023.emnlp-main.168) |  | 0 |  | Yuanhang Yang, Shiyi Qi, Chuanyi Liu, Qifan Wang, Cuiyun Gao, Zenglin Xu |  |
| 1363 |  |  [Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts](https://doi.org/10.18653/v1/2023.emnlp-main.169) |  | 0 |  | Tengxiao Liu, Qipeng Guo, Yuqing Yang, Xiangkun Hu, Yue Zhang, Xipeng Qiu, Zheng Zhang |  |
| 1364 |  |  [GLEN: General-Purpose Event Detection for Thousands of Types](https://doi.org/10.18653/v1/2023.emnlp-main.170) |  | 0 |  | Sha Li, Qiusi Zhan, Kathryn Conger, Martha Palmer, Heng Ji, Jiawei Han |  |
| 1365 |  |  [Hierarchical Pretraining on Multimodal Electronic Health Records](https://doi.org/10.18653/v1/2023.emnlp-main.171) |  | 0 |  | Xiaochen Wang, Junyu Luo, Jiaqi Wang, Ziyi Yin, Suhan Cui, Yuan Zhong, Yaqing Wang, Fenglong Ma |  |
| 1366 |  |  [Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.172) |  | 0 |  | Mateusz Lango, Ondrej Dusek |  |
| 1367 |  |  [Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.173) |  | 0 |  | Wenyu Guo, Qingkai Fang, Dong Yu, Yang Feng |  |
| 1368 |  |  [DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.174) |  | 0 |  | Xinwei Wu, Junzhuo Li, Minghui Xu, Weilong Dong, Shuangzhi Wu, Chao Bian, Deyi Xiong |  |
| 1369 |  |  [Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques](https://doi.org/10.18653/v1/2023.emnlp-main.175) |  | 0 |  | Manon Reusens, Philipp Borchert, Margot Mieskes, Jochen De Weerdt, Bart Baesens |  |
| 1370 |  |  [Can Language Models Laugh at YouTube Short-form Videos?](https://doi.org/10.18653/v1/2023.emnlp-main.176) |  | 0 |  | Dayoon Ko, Sangho Lee, Gunhee Kim |  |
| 1371 |  |  [Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation](https://doi.org/10.18653/v1/2023.emnlp-main.177) |  | 0 |  | Jiaang Li, Quan Wang, Yi Liu, Licheng Zhang, Zhendong Mao |  |
| 1372 |  |  [Exploring All-In-One Knowledge Distillation Framework for Neural Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.178) |  | 0 |  | Zhongjian Miao, Wen Zhang, Jinsong Su, Xiang Li, Jian Luan, Yidong Chen, Bin Wang, Min Zhang |  |
| 1373 |  |  [HistAlign: Improving Context Dependency in Language Generation by Aligning with History](https://doi.org/10.18653/v1/2023.emnlp-main.179) |  | 0 |  | David Wan, Shiyue Zhang, Mohit Bansal |  |
| 1374 |  |  [CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models](https://doi.org/10.18653/v1/2023.emnlp-main.180) |  | 0 |  | Aitor Ormazabal, Mikel Artetxe, Eneko Agirre |  |
| 1375 |  |  [Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach](https://doi.org/10.18653/v1/2023.emnlp-main.181) |  | 0 |  | Harman Singh, Poorva Garg, Mohit Gupta, Kevin Shah, Ashish Goswami, Satyam Modi, Arnab Kumar Mondal, Dinesh Khandelwal, Dinesh Garg, Parag Singla |  |
| 1376 |  |  [Generative Spoken Language Model based on continuous word-sized audio tokens](https://doi.org/10.18653/v1/2023.emnlp-main.182) |  | 0 |  | Robin Algayres, Yossi Adi, Tu Anh Nguyen, Jade Copet, Gabriel Synnaeve, Benoît Sagot, Emmanuel Dupoux |  |
| 1377 |  |  [Enhancing Chat Language Models by Scaling High-quality Instructional Conversations](https://doi.org/10.18653/v1/2023.emnlp-main.183) |  | 0 |  | Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, Bowen Zhou |  |
| 1378 |  |  [Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining](https://doi.org/10.18653/v1/2023.emnlp-main.184) |  | 0 |  | Emanuele Bugliarello, Aida Nematzadeh, Lisa Anne Hendricks |  |
| 1379 |  |  [Unsupervised Grammatical Error Correction Rivaling Supervised Methods](https://doi.org/10.18653/v1/2023.emnlp-main.185) |  | 0 |  | Hannan Cao, Liping Yuan, Yuchen Zhang, Hwee Tou Ng |  |
| 1380 |  |  [S2abEL: A Dataset for Entity Linking from Scientific Tables](https://doi.org/10.18653/v1/2023.emnlp-main.186) |  | 0 |  | Yuze Lou, Bailey Kuehl, Erin Bransom, Sergey Feldman, Aakanksha Naik, Doug Downey |  |
| 1381 |  |  [API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.187) |  | 0 |  | Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, Yongbin Li |  |
| 1382 |  |  [Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers](https://doi.org/10.18653/v1/2023.emnlp-main.188) |  | 0 |  | Daniela Teodorescu, Tiffany Cheng, Alona Fyshe, Saif M. Mohammad |  |
| 1383 |  |  [Lion: Adversarial Distillation of Proprietary Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.189) |  | 0 |  | Yuxin Jiang, Chunkit Chan, Mingyang Chen, Wei Wang |  |
| 1384 |  |  [Evaluating Large Language Models on Controlled Generation Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.190) |  | 0 |  | Jiao Sun, Yufei Tian, Wangchunshu Zhou, Nan Xu, Qian Hu, Rahul Gupta, John Frederick Wieting, Nanyun Peng, Xuezhe Ma |  |
| 1385 |  |  [DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.191) |  | 0 |  | Xiaoyu Guo, YuanFang Li, Gholamreza Haffari |  |
| 1386 |  |  [Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation](https://doi.org/10.18653/v1/2023.emnlp-main.192) |  | 0 |  | Adam Bouyamourn |  |
| 1387 |  |  [A Question Answering Framework for Decontextualizing User-facing Snippets from Scientific Documents](https://doi.org/10.18653/v1/2023.emnlp-main.193) |  | 0 |  | Benjamin Newman, Luca Soldaini, Raymond Fok, Arman Cohan, Kyle Lo |  |
| 1388 |  |  [SLOG: A Structural Generalization Benchmark for Semantic Parsing](https://doi.org/10.18653/v1/2023.emnlp-main.194) |  | 0 |  | Bingzhi Li, Lucia Donatelli, Alexander Koller, Tal Linzen, Yuekun Yao, Najoung Kim |  |
| 1389 |  |  [Pushdown Layers: Encoding Recursive Structure in Transformer Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.195) |  | 0 |  | Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher D. Manning |  |
| 1390 |  |  [Can LLMs Facilitate Interpretation of Pre-trained Language Models?](https://doi.org/10.18653/v1/2023.emnlp-main.196) |  | 0 |  | Basel Mousi, Nadir Durrani, Fahim Dalvi |  |
| 1391 |  |  [Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets](https://doi.org/10.18653/v1/2023.emnlp-main.197) |  | 0 |  | Su Ah Lee, Seokjin Oh, Woohwan Jung |  |
| 1392 |  |  [Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies](https://doi.org/10.18653/v1/2023.emnlp-main.198) |  | 0 |  | Zhengxuan Wu, Alex Tamkin, Isabel Papadimitriou |  |
| 1393 |  |  [Non-Autoregressive Math Word Problem Solver with Unified Tree Structure](https://doi.org/10.18653/v1/2023.emnlp-main.199) |  | 0 |  | Yi Bin, Mengqun Han, Wenhao Shi, Lei Wang, Yang Yang, SeeKiong Ng, Heng Tao Shen |  |
| 1394 |  |  [Improving Chinese Pop Song and Hokkien Gezi Opera Singing Voice Synthesis by Enhancing Local Modeling](https://doi.org/10.18653/v1/2023.emnlp-main.200) |  | 0 |  | Peng Bai, Yue Zhou, Meizhen Zheng, Wujin Sun, Xiaodong Shi |  |
| 1395 |  |  [What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on QA Systems](https://doi.org/10.18653/v1/2023.emnlp-main.201) |  | 0 |  | Navita Goyal, Eleftheria Briakou, Amanda Liu, Connor Baumler, Claire Bonial, Jeffrey Micher, Clare R. Voss, Marine Carpuat, Hal Daumé III |  |
| 1396 |  |  [GROOViST: A Metric for Grounding Objects in Visual Storytelling](https://doi.org/10.18653/v1/2023.emnlp-main.202) |  | 0 |  | Aditya K. Surikuchi, Sandro Pezzelle, Raquel Fernández |  |
| 1397 |  |  [VIBE: Topic-Driven Temporal Adaptation for Twitter Classification](https://doi.org/10.18653/v1/2023.emnlp-main.203) |  | 0 |  | Yuji Zhang, Jing Li, Wenjie Li |  |
| 1398 |  |  [TOD-Flow: Modeling the Structure of Task-Oriented Dialogues](https://doi.org/10.18653/v1/2023.emnlp-main.204) |  | 0 |  | Sungryull Sohn, Yiwei Lyu, Anthony Z. Liu, Lajanugen Logeswaran, DongKi Kim, Dongsub Shim, Honglak Lee |  |
| 1399 |  |  [TopWORDS-Poetry: Simultaneous Text Segmentation and Word Discovery for Classical Chinese Poetry via Bayesian Inference](https://doi.org/10.18653/v1/2023.emnlp-main.205) |  | 0 |  | Changzai Pan, Feiyue Li, Ke Deng |  |
| 1400 |  |  [Knowledge Rumination for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.206) |  | 0 |  | Yunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan, Fei Huang, Huajun Chen, Ningyu Zhang |  |
| 1401 |  |  [Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning](https://doi.org/10.18653/v1/2023.emnlp-main.207) |  | 0 |  | Linjuan Wu, Weiming Lu |  |
| 1402 |  |  [AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification](https://doi.org/10.18653/v1/2023.emnlp-main.208) |  | 0 |  | Yongxin Huang, Kexin Wang, Sourav Dutta, Raj Nath Patel, Goran Glavas, Iryna Gurevych |  |
| 1403 |  |  [Interview Evaluation: A Novel Approach for Automatic Evaluation of Conversational Question Answering Models](https://doi.org/10.18653/v1/2023.emnlp-main.209) |  | 0 |  | Xibo Li, Bowei Zou, Yifan Fan, Yanling Li, Ai Ti Aw, Yu Hong |  |
| 1404 |  |  [TCFLE-8: a Corpus of Learner Written Productions for French as a Foreign Language and its Application to Automated Essay Scoring](https://doi.org/10.18653/v1/2023.emnlp-main.210) |  | 0 |  | Rodrigo Wilkens, Alice Pintard, David Alfter, Vincent Folny, Thomas François |  |
| 1405 |  |  [Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA](https://doi.org/10.18653/v1/2023.emnlp-main.211) |  | 0 |  | David Heineman, Yao Dou, Mounica Maddela, Wei Xu |  |
| 1406 |  |  [Confidence-based Ensembling of Perspective-aware Models](https://doi.org/10.18653/v1/2023.emnlp-main.212) |  | 0 |  | Silvia Casola, Soda Marem Lo, Valerio Basile, Simona Frenda, Alessandra Teresa Cignarella, Viviana Patti, Cristina Bosco |  |
| 1407 |  |  [ToViLaG: Your Visual-Language Generative Model is Also An Evildoer](https://doi.org/10.18653/v1/2023.emnlp-main.213) |  | 0 |  | Xinpeng Wang, Xiaoyuan Yi, Han Jiang, Shanlin Zhou, Zhihua Wei, Xing Xie |  |
| 1408 |  |  [GPT-RE: In-context Learning for Relation Extraction using Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.214) |  | 0 |  | Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, Sadao Kurohashi |  |
| 1409 |  |  [Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment](https://doi.org/10.18653/v1/2023.emnlp-main.215) |  | 0 |  | Sky CHWang, Arkadiy Saakyan, Oliver Li, Zhou Yu, Smaranda Muresan |  |
| 1410 |  |  [INFORM : Information eNtropy based multi-step reasoning FOR large language Models](https://doi.org/10.18653/v1/2023.emnlp-main.216) |  | 0 |  | Chuyue Zhou, Wangjie You, Juntao Li, Jing Ye, Kehai Chen, Min Zhang |  |
| 1411 |  |  [Adaptive Gating in Mixture-of-Experts based Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.217) |  | 0 |  | Jiamin Li, Qiang Su, Yitao Yang, Yimin Jiang, Cong Wang, Hong Xu |  |
| 1412 |  |  [On the Automatic Generation and Simplification of Children's Stories](https://doi.org/10.18653/v1/2023.emnlp-main.218) |  | 0 |  | Maria R. Valentini, Jennifer Weber, Jesus Salcido, Téa Wright, Eliana Colunga, Katharina von der Wense |  |
| 1413 |  |  [When Do Decompositions Help for Machine Reading?](https://doi.org/10.18653/v1/2023.emnlp-main.219) |  | 0 |  | Kangda Wei, Dawn J. Lawrie, Benjamin Van Durme, Yunmo Chen, Orion Weller |  |
| 1414 |  |  [The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.220) |  | 0 |  | Aviv Slobodkin, Omer Goldman, Avi Caciularu, Ido Dagan, Shauli Ravfogel |  |
| 1415 |  |  [Identifying Informational Sources in News Articles](https://doi.org/10.18653/v1/2023.emnlp-main.221) |  | 0 |  | Alexander Spangher, Nanyun Peng, Emilio Ferrara, Jonathan May |  |
| 1416 |  |  [Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning](https://doi.org/10.18653/v1/2023.emnlp-main.222) |  | 0 |  | Sapan Shah, Sreedhar Reddy, Pushpak Bhattacharyya |  |
| 1417 |  |  [Longtriever: a Pre-trained Long Text Encoder for Dense Document Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.223) |  | 0 |  | Junhan Yang, Zheng Liu, Chaozhuo Li, Guangzhong Sun, Xing Xie |  |
| 1418 |  |  [Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization](https://doi.org/10.18653/v1/2023.emnlp-main.224) |  | 0 |  | Yiyang Liu, Jinpeng Li, Enwei Zhu |  |
| 1419 |  |  [Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.225) |  | 0 |  | Gurusha Juneja, Subhabrata Dutta, Soumen Chakrabarti, Sunny Manchanda, Tanmoy Chakraborty |  |
| 1420 |  |  [Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?](https://doi.org/10.18653/v1/2023.emnlp-main.226) |  | 0 |  | Shaoyang Xu, Junzhuo Li, Deyi Xiong |  |
| 1421 |  |  [Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.227) |  | 0 |  | James A. Michaelov, Catherine Arnett, Tyler A. Chang, Ben Bergen |  |
| 1422 |  |  [ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph](https://doi.org/10.18653/v1/2023.emnlp-main.228) |  | 0 |  | Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yaliang Li, JiRong Wen |  |
| 1423 |  |  [Deep Natural Language Feature Learning for Interpretable Prediction](https://doi.org/10.18653/v1/2023.emnlp-main.229) |  | 0 |  | Felipe Urrutia, Cristian Buc Calderon, Valentin Barrière |  |
| 1424 |  |  [ROBBIE: Robust Bias Evaluation of Large Generative Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.230) |  | 0 |  | David Esiobu, Xiaoqing Ellen Tan, Saghar Hosseini, Megan Ung, Yuchen Zhang, Jude Fernandes, Jane DwivediYu, Eleonora Presani, Adina Williams, Eric Michael Smith |  |
| 1425 |  |  [Enhancing Task-oriented Dialogue Systems with Generative Post-processing Networks](https://doi.org/10.18653/v1/2023.emnlp-main.231) |  | 0 |  | Atsumoto Ohashi, Ryuichiro Higashinaka |  |
| 1426 |  |  [Adapting Language Models to Compress Contexts](https://doi.org/10.18653/v1/2023.emnlp-main.232) |  | 0 |  | Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen |  |
| 1427 |  |  [Selective Labeling: How to Radically Lower Data-Labeling Costs for Document Extraction Models](https://doi.org/10.18653/v1/2023.emnlp-main.233) |  | 0 |  | Yichao Zhou, James B. Wendt, Navneet Potti, Jing Xie, Sandeep Tata |  |
| 1428 |  |  [TRAVEL: Tag-Aware Conversational FAQ Retrieval via Reinforcement Learning](https://doi.org/10.18653/v1/2023.emnlp-main.234) |  | 0 |  | Yue Chen, Dingnan Jin, Chen Huang, Jia Liu, Wenqiang Lei |  |
| 1429 |  |  [Continual Dialogue State Tracking via Example-Guided Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.235) |  | 0 |  | Hyundong Cho, Andrea Madotto, Zhaojiang Lin, Khyathi Raghavi Chandu, Satwik Kottur, Jing Xu, Jonathan May, Chinnadhurai Sankar |  |
| 1430 |  |  [Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media](https://doi.org/10.18653/v1/2023.emnlp-main.236) |  | 0 |  | Shubham Mittal, Megha Sundriyal, Preslav Nakov |  |
| 1431 |  |  [COVID-19 Vaccine Misinformation in Middle Income Countries](https://doi.org/10.18653/v1/2023.emnlp-main.237) |  | 0 |  | Jongin Kim, Byeo Bak, Aditya Agrawal, Jiaxi Wu, Veronika J. Wirtz, Traci Hong, Derry Wijaya |  |
| 1432 |  |  [Contrastive Learning of Sentence Embeddings from Scratch](https://doi.org/10.18653/v1/2023.emnlp-main.238) |  | 0 |  | Junlei Zhang, Zhenzhong Lan, Junxian He |  |
| 1433 |  |  [A Rose by Any Other Name would not Smell as Sweet: Social Bias in Names Mistranslation](https://doi.org/10.18653/v1/2023.emnlp-main.239) |  | 0 |  | Sandra Sandoval, Jieyu Zhao, Marine Carpuat, Hal Daumé III |  |
| 1434 |  |  [Investigating Efficiently Extending Transformers for Long Input Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.240) |  | 0 |  | Jason Phang, Yao Zhao, Peter J. Liu |  |
| 1435 |  |  [CS2W: A Chinese Spoken-to-Written Style Conversion Dataset with Multiple Conversion Types](https://doi.org/10.18653/v1/2023.emnlp-main.241) |  | 0 |  | Zishan Guo, Linhao Yu, Minghui Xu, Renren Jin, Deyi Xiong |  |
| 1436 |  |  [Unifying Cross-Lingual Transfer across Scenarios of Resource Scarcity](https://doi.org/10.18653/v1/2023.emnlp-main.242) |  | 0 |  | Alan Ansell, Marinela Parovic, Ivan Vulic, Anna Korhonen, Edoardo M. Ponti |  |
| 1437 |  |  [A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.243) |  | 0 |  | Giuseppe Attanasio, Flor Miriam Plaza del Arco, Debora Nozza, Anne Lauscher |  |
| 1438 |  |  [DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining](https://doi.org/10.18653/v1/2023.emnlp-main.244) |  | 0 |  | Weifeng Jiang, Qianren Mao, Chenghua Lin, Jianxin Li, Ting Deng, Weiyi Yang, Zheng Wang |  |
| 1439 |  |  [Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation](https://doi.org/10.18653/v1/2023.emnlp-main.245) |  | 0 |  | Da Yin, Xiao Liu, Fan Yin, Ming Zhong, Hritik Bansal, Jiawei Han, KaiWei Chang |  |
| 1440 |  |  [Are All Steps Equally Important? Benchmarking Essentiality Detection in Event Processes](https://doi.org/10.18653/v1/2023.emnlp-main.246) |  | 0 |  | Haoyu Wang, Hongming Zhang, Yueguan Wang, Yuqian Deng, Muhao Chen, Dan Roth |  |
| 1441 |  |  [Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.247) |  | 0 |  | Zui Chen, Jiaqi Han, Chaofan Yang, Yi Zhou |  |
| 1442 |  |  [Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection](https://doi.org/10.18653/v1/2023.emnlp-main.248) |  | 0 |  | Gretel Liz De la Peña Sarracén, Paolo Rosso, Robert Litschko, Goran Glavas, Simone Paolo Ponzetto |  |
| 1443 |  |  [SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation](https://doi.org/10.18653/v1/2023.emnlp-main.249) |  | 0 |  | Junfeng Jiang, Chengzhang Dong, Sadao Kurohashi, Akiko Aizawa |  |
| 1444 |  |  [ATFormer: A Learned Performance Model with Transfer Learning Across Devices for Deep Learning Tensor Programs](https://doi.org/10.18653/v1/2023.emnlp-main.250) |  | 0 |  | Yang Bai, Wenqian Zhao, Shuo Yin, Zixiao Wang, Bei Yu |  |
| 1445 |  |  [mRedditSum: A Multimodal Abstractive Summarization Dataset of Reddit Threads with Images](https://doi.org/10.18653/v1/2023.emnlp-main.251) |  | 0 |  | Keighley Overbay, Jaewoo Ahn, Fatemeh Pesaran Zadeh, Joonsuk Park, Gunhee Kim |  |
| 1446 |  |  [Sparse Low-rank Adaptation of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.252) |  | 0 |  | Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun |  |
| 1447 |  |  [Human Learning by Model Feedback: The Dynamics of Iterative Prompting with Midjourney](https://doi.org/10.18653/v1/2023.emnlp-main.253) |  | 0 |  | Shachar DonYehiya, Leshem Choshen, Omri Abend |  |
| 1448 |  |  [ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision](https://doi.org/10.18653/v1/2023.emnlp-main.254) |  | 0 |  | Anastasiia Sedova, Benjamin Roth |  |
| 1449 |  |  [The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.255) |  | 0 |  | Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, Qifan Wang, Lifu Huang |  |
| 1450 |  |  [Ideology Takes Multiple Looks: A High-Quality Dataset for Multifaceted Ideology Detection](https://doi.org/10.18653/v1/2023.emnlp-main.256) |  | 0 |  | Songtao Liu, Ziling Luo, Minghua Xu, Lixiao Wei, Ziyao Wei, Han Yu, Wei Xiang, Bang Wang |  |
| 1451 |  |  [Transductive Learning for Textual Few-Shot Classification in API-based Embedding Models](https://doi.org/10.18653/v1/2023.emnlp-main.257) |  | 0 |  | Pierre Colombo, Victor Pellegrain, Malik Boudiaf, Myriam Tami, Victor Storchan, Ismail Ben Ayed, Pablo Piantanida |  |
| 1452 |  |  [MEGA: Multilingual Evaluation of Generative AI](https://doi.org/10.18653/v1/2023.emnlp-main.258) |  | 0 |  | Kabir Ahuja, Harshita Diddee, Rishav Hada, Millicent Ochieng, Krithika Ramesh, Prachi Jain, Akshay Uttama Nambi, Tanuja Ganu, Sameer Segal, Mohamed Ahmed, Kalika Bali, Sunayana Sitaram |  |
| 1453 |  |  [Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation](https://doi.org/10.18653/v1/2023.emnlp-main.259) |  | 0 |  | Xin Yuan, Jie Guo, Weidong Qiu, Zheng Huang, Shujun Li |  |
| 1454 |  |  [Video-Helpful Multimodal Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.260) |  | 0 |  | Yihang Li, Shuichiro Shimizu, Chenhui Chu, Sadao Kurohashi, Wei Li |  |
| 1455 |  |  [Large Language Models are Temporal and Causal Reasoners for Video Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.261) |  | 0 |  | Dohwan Ko, Ji Soo Lee, WooYoung Kang, Byungseok Roh, Hyunwoo Kim |  |
| 1456 |  |  [Uncertainty Guided Global Memory Improves Multi-Hop Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.262) |  | 0 |  | Alsu Sagirova, Mikhail Burtsev |  |
| 1457 |  |  [Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation](https://doi.org/10.18653/v1/2023.emnlp-main.263) |  | 0 |  | Yuanyuan Liang, Jianing Wang, Hanlun Zhu, Lei Wang, Weining Qian, Yunshi Lan |  |
| 1458 |  |  [TrojanSQL: SQL Injection against Natural Language Interface to Database](https://doi.org/10.18653/v1/2023.emnlp-main.264) |  | 0 |  | Jinchuan Zhang, Yan Zhou, Binyuan Hui, Yaxin Liu, Ziming Li, Songlin Hu |  |
| 1459 |  |  [Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.265) |  | 0 |  | Aly M. Kassem, Omar Mahmoud, Sherif Saad |  |
| 1460 |  |  [MingOfficial: A Ming Official Career Dataset and a Historical Context-Aware Representation Learning Framework](https://doi.org/10.18653/v1/2023.emnlp-main.266) |  | 0 |  | YouJun Chen, HsinYi Hsieh, Yu Lin, Yingtao Tian, Bert Chan, YuSin Liu, YiHsuan Lin, Richard TzongHan Tsai |  |
| 1461 |  |  [DPP-TTS: Diversifying prosodic features of speech via determinantal point processes](https://doi.org/10.18653/v1/2023.emnlp-main.267) |  | 0 |  | Seongho Joo, Hyukhun Koh, Kyomin Jung |  |
| 1462 |  |  [Meta-Learning Online Adaptation of Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.268) |  | 0 |  | Nathan Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn |  |
| 1463 |  |  [Self-Detoxifying Language Models via Toxification Reversal](https://doi.org/10.18653/v1/2023.emnlp-main.269) |  | 0 |  | Chak Tou Leong, Yi Cheng, Jiashuo Wang, Jian Wang, Wenjie Li |  |
| 1464 |  |  [Interactive Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.270) |  | 0 |  | Felix Faltings, Michel Galley, Kianté Brantley, Baolin Peng, Weixin Cai, Yizhe Zhang, Jianfeng Gao, Bill Dolan |  |
| 1465 |  |  [Knowledge Distillation \approx Label Smoothing: Fact or Fallacy?](https://doi.org/10.18653/v1/2023.emnlp-main.271) |  | 0 |  | Md. Sultan |  |
| 1466 |  |  [Analyzing Cognitive Plausibility of Subword Tokenization](https://doi.org/10.18653/v1/2023.emnlp-main.272) |  | 0 |  | Lisa Beinborn, Yuval Pinter |  |
| 1467 |  |  [POE: Process of Elimination for Multiple Choice Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.273) |  | 0 |  | Chenkai Ma, Xinya Du |  |
| 1468 |  |  [NeuSTIP: A Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.274) |  | 0 |  | Ishaan Singh, Navdeep Kaur, Garima Gaur, Mausam |  |
| 1469 |  |  [Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts](https://doi.org/10.18653/v1/2023.emnlp-main.275) |  | 0 |  | Gopendra Vikram Singh, Soumitra Ghosh, Atul Verma, Chetna Painkra, Asif Ekbal |  |
| 1470 |  |  [Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future](https://doi.org/10.18653/v1/2023.emnlp-main.276) |  | 0 |  | Linyi Yang, Yaoxian Song, Xuan Ren, Chenyang Lyu, Yidong Wang, Jingming Zhuo, Lingqiao Liu, Jindong Wang, Jennifer Foster, Yue Zhang |  |
| 1471 |  |  [Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.277) |  | 0 |  | Hongyi Zheng, Abulhair Saparov |  |
| 1472 |  |  [Can Large Language Models Capture Dissenting Human Voices?](https://doi.org/10.18653/v1/2023.emnlp-main.278) |  | 0 |  | Noah Lee, Na An, James Thorne |  |
| 1473 |  |  [DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.279) |  | 0 |  | Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre, Ai Ti Aw, Nancy Chen |  |
| 1474 |  |  [Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.280) |  | 0 |  | Hao Zhao, Jie Fu, Zhaofeng He |  |
| 1475 |  |  [Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View](https://doi.org/10.18653/v1/2023.emnlp-main.281) |  | 0 |  | Ruotian Ma, Xiaolei Wang, Xin Zhou, Qi Zhang, Xuanjing Huang |  |
| 1476 |  |  [GradSim: Gradient-Based Language Grouping for Effective Multilingual Training](https://doi.org/10.18653/v1/2023.emnlp-main.282) |  | 0 |  | Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze |  |
| 1477 |  |  [Discovering Universal Geometry in Embeddings with ICA](https://doi.org/10.18653/v1/2023.emnlp-main.283) |  | 0 |  | Hiroaki Yamagiwa, Momose Oyama, Hidetoshi Shimodaira |  |
| 1478 |  |  [Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City](https://doi.org/10.18653/v1/2023.emnlp-main.284) |  | 0 |  | Mikael Brunila, Jack LaViolette, Sky CHWang, Priyanka Verma, Clara Féré, Grant McKenzie |  |
| 1479 |  |  [Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.285) |  | 0 |  | Lang Qin, Yao Zhang, Hongru Liang, Jun Wang, Zhenglu Yang |  |
| 1480 |  |  [Merging Generated and Retrieved Knowledge for Open-Domain QA](https://doi.org/10.18653/v1/2023.emnlp-main.286) |  | 0 |  | Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang |  |
| 1481 |  |  [Best of Both Worlds: Towards Improving Temporal Knowledge Base Question Answering via Targeted Fact Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.287) |  | 0 |  | Nithish Kannen, Udit Sharma, Sumit Neelam, Dinesh Khandelwal, Shajith Ikbal, Hima Karanam, L. Venkata Subramaniam |  |
| 1482 |  |  [Text Fact Transfer](https://doi.org/10.18653/v1/2023.emnlp-main.288) |  | 0 |  | Nishant Balepur, Jie Huang, Kevin ChenChuan Chang |  |
| 1483 |  |  [A Cheaper and Better Diffusion Language Model with Soft-Masked Noise](https://doi.org/10.18653/v1/2023.emnlp-main.289) |  | 0 |  | Jiaao Chen, Aston Zhang, Mu Li, Alex Smola, Diyi Yang |  |
| 1484 |  |  [Mirages. On Anthropomorphism in Dialogue Systems](https://doi.org/10.18653/v1/2023.emnlp-main.290) |  | 0 |  | Gavin Abercrombie, Amanda Cercas Curry, Tanvi Dinkar, Verena Rieser, Zeerak Talat |  |
| 1485 |  |  [Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?](https://doi.org/10.18653/v1/2023.emnlp-main.291) |  | 0 |  | Kevin Liu, Stephen Casper, Dylan HadfieldMenell, Jacob Andreas |  |
| 1486 |  |  [KEBAP: Korean Error Explainable Benchmark Dataset for ASR and Post-processing](https://doi.org/10.18653/v1/2023.emnlp-main.292) |  | 0 |  | Seonmin Koo, Chanjun Park, Jinsung Kim, Jaehyung Seo, Sugyeong Eo, Hyeonseok Moon, Heuiseok Lim |  |
| 1487 |  |  [Adaptive Policy with Wait-k Model for Simultaneous Translation](https://doi.org/10.18653/v1/2023.emnlp-main.293) |  | 0 |  | Libo Zhao, Kai Fan, Wei Luo, Jing Wu, Shushu Wang, Ziqian Zeng, Zhongqiang Huang |  |
| 1488 |  |  [Cross-Document Event Coreference Resolution on Discourse Structure](https://doi.org/10.18653/v1/2023.emnlp-main.294) |  | 0 |  | Xinyu Chen, Sheng Xu, Peifeng Li, Qiaoming Zhu |  |
| 1489 |  |  [Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations](https://doi.org/10.18653/v1/2023.emnlp-main.295) |  | 0 |  | Yoonna Jang, Suhyune Son, Jeongwoo Lee, Junyoung Son, Yuna Hur, Jungwoo Lim, Hyeonseok Moon, Kisu Yang, Heuiseok Lim |  |
| 1490 |  |  [Can We Edit Factual Knowledge by In-Context Learning?](https://doi.org/10.18653/v1/2023.emnlp-main.296) |  | 0 |  | Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, Jingjing Xu, Baobao Chang |  |
| 1491 |  |  [EDIS: Entity-Driven Image Search over Multimodal Web Content](https://doi.org/10.18653/v1/2023.emnlp-main.297) |  | 0 |  | Siqi Liu, Weixi Feng, TsuJui Fu, Wenhu Chen, William Wang |  |
| 1492 |  |  [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://doi.org/10.18653/v1/2023.emnlp-main.298) |  | 0 |  | Joshua Ainslie, James LeeThorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, Sumit Sanghai |  |
| 1493 |  |  [Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.299) |  | 0 |  | Yifan Hou, Jiaoda Li, Yu Fei, Alessandro Stolfo, Wangchunshu Zhou, Guangtao Zeng, Antoine Bosselut, Mrinmaya Sachan |  |
| 1494 |  |  [BiasX: "Thinking Slow" in Toxic Content Moderation with Explanations of Implied Social Biases](https://doi.org/10.18653/v1/2023.emnlp-main.300) |  | 0 |  | Yiming Zhang, Sravani Nanduri, Liwei Jiang, Tongshuang Wu, Maarten Sap |  |
| 1495 |  |  [Text encoders bottleneck compositionality in contrastive vision-language models](https://doi.org/10.18653/v1/2023.emnlp-main.301) |  | 0 |  | Amita Kamath, Jack Hessel, KaiWei Chang |  |
| 1496 |  |  [Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition](https://doi.org/10.18653/v1/2023.emnlp-main.302) |  | 0 |  | Sander Schulhoff, Jeremy Pinto, Anaum Khan, LouisFrançois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Liu Kost, Christopher Carnahan, Jordan L. BoydGraber |  |
| 1497 |  |  [MMNMT: Modularizing Multilingual Neural Machine Translation with Flexibly Assembled MoE and Dense Blocks](https://doi.org/10.18653/v1/2023.emnlp-main.303) |  | 0 |  | Shangjie Li, Xiangpeng Wei, Shaolin Zhu, Jun Xie, Baosong Yang, Deyi Xiong |  |
| 1498 |  |  [Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.304) |  | 0 |  | TeLin Wu, Yu Zhou, Nanyun Peng |  |
| 1499 |  |  [Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines](https://doi.org/10.18653/v1/2023.emnlp-main.305) |  | 0 |  | Stephen Bothwell, Justin DeBenedetto, Theresa Crnkovich, Hildegund Müller, David Chiang |  |
| 1500 |  |  [Prompting is not a substitute for probability measurements in large language models](https://doi.org/10.18653/v1/2023.emnlp-main.306) |  | 0 |  | Jennifer Hu, Roger Levy |  |
| 1501 |  |  [Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings](https://doi.org/10.18653/v1/2023.emnlp-main.307) |  | 0 |  | Josip Jukic, Jan Snajder |  |
| 1502 |  |  [Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks](https://doi.org/10.18653/v1/2023.emnlp-main.308) |  | 0 |  | Alon Jacovi, Avi Caciularu, Omer Goldman, Yoav Goldberg |  |
| 1503 |  |  [CoLT5: Faster Long-Range Transformers with Conditional Computation](https://doi.org/10.18653/v1/2023.emnlp-main.309) |  | 0 |  | Joshua Ainslie, Tao Lei, Michiel de Jong, Santiago Ontañón, Siddhartha Brahma, Yury Zemlyanskiy, David C. Uthus, Mandy Guo, James LeeThorp, Yi Tay, YunHsuan Sung, Sumit Sanghai |  |
| 1504 |  |  [DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.310) |  | 0 |  | Praveen Venkateswaran, Evelyn Duesterwald, Vatche Isahagian |  |
| 1505 |  |  [Cross-Cultural Analysis of Human Values, Morals, and Biases in Folk Tales](https://doi.org/10.18653/v1/2023.emnlp-main.311) |  | 0 |  | Winston Wu, Lu Wang, Rada Mihalcea |  |
| 1506 |  |  [Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL](https://doi.org/10.18653/v1/2023.emnlp-main.312) |  | 0 |  | Ruiqi Zhong, Charlie Snell, Dan Klein, Jason Eisner |  |
| 1507 |  |  [LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers](https://doi.org/10.18653/v1/2023.emnlp-main.313) |  | 0 |  | Theo Olausson, Alex Gu, Benjamin Lipkin, Cedegao E. Zhang, Armando SolarLezama, Joshua B. Tenenbaum, Roger Levy |  |
| 1508 |  |  [Non-autoregressive Streaming Transformer for Simultaneous Translation](https://doi.org/10.18653/v1/2023.emnlp-main.314) |  | 0 |  | Zhengrui Ma, Shaolei Zhang, Shoutao Guo, Chenze Shao, Min Zhang, Yang Feng |  |
| 1509 |  |  [ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing](https://doi.org/10.18653/v1/2023.emnlp-main.315) |  | 0 |  | Nam Nguyen, Thang Phan, DucVu Nguyen, Kiet Van Nguyen |  |
| 1510 |  |  [RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.316) |  | 0 |  | Shiao Meng, Xuming Hu, Aiwei Liu, Shuang Li, Fukun Ma, Yawen Yang, Lijie Wen |  |
| 1511 |  |  [GeoLM: Empowering Language Models for Geospatially Grounded Language Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.317) |  | 0 |  | Zekun Li, Wenxuan Zhou, YaoYi Chiang, Muhao Chen |  |
| 1512 |  |  [Cross-Modal Conceptualization in Bottleneck Models](https://doi.org/10.18653/v1/2023.emnlp-main.318) |  | 0 |  | Danis Alukaev, Semen Kiselev, Ilya Pershin, Bulat Ibragimov, Vladimir Ivanov, Alexey Kornaev, Ivan Titov |  |
| 1513 |  |  [LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.319) |  | 0 |  | Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, EePeng Lim, Lidong Bing, Xing Xu, Soujanya Poria, Roy KaWei Lee |  |
| 1514 |  |  [DREAM: Deployment of Recombination and Ensembles in Argument Mining](https://doi.org/10.18653/v1/2023.emnlp-main.320) |  | 0 |  | Florian Ruosch, Cristina Sarasua, Abraham Bernstein |  |
| 1515 |  |  [MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments](https://doi.org/10.18653/v1/2023.emnlp-main.321) |  | 0 |  | Debtanu Datta, Shubham Soni, Rajdeep Mukherjee, Saptarshi Ghosh |  |
| 1516 |  |  [Query Rewriting in Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.322) |  | 0 |  | Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan |  |
| 1517 |  |  [PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation](https://doi.org/10.18653/v1/2023.emnlp-main.323) |  | 0 |  | Gaurav Sahu, Olga Vechtomova, Dzmitry Bahdanau, Issam H. Laradji |  |
| 1518 |  |  [COHESENTIA: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts](https://doi.org/10.18653/v1/2023.emnlp-main.324) |  | 0 |  | Aviya Maimon, Reut Tsarfaty |  |
| 1519 |  |  [QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing](https://doi.org/10.18653/v1/2023.emnlp-main.325) |  | 0 |  | Yating Wu, Ritika Mangla, Greg Durrett, Junyi Jessy Li |  |
| 1520 |  |  [PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter](https://doi.org/10.18653/v1/2023.emnlp-main.326) |  | 0 |  | Haoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang, Ning Cheng, Ming Li, Jing Xiao |  |
| 1521 |  |  [Exploring Chain of Thought Style Prompting for Text-to-SQL](https://doi.org/10.18653/v1/2023.emnlp-main.327) |  | 0 |  | ChangYu Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, Huan Sun |  |
| 1522 |  |  [Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages](https://doi.org/10.18653/v1/2023.emnlp-main.328) |  | 0 |  | Alexandra Butoi, Tim Vieira, Ryan Cotterell, David Chiang |  |
| 1523 |  |  [Harnessing Black-Box Control to Boost Commonsense in LM's Generation](https://doi.org/10.18653/v1/2023.emnlp-main.329) |  | 0 |  | Yufei Tian, Felix Zhang, Nanyun Peng |  |
| 1524 |  |  [Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.330) |  | 0 |  | Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, Christopher D. Manning |  |
| 1525 |  |  [Representative Demonstration Selection for In-Context Learning with Two-Stage Determinantal Point Process](https://doi.org/10.18653/v1/2023.emnlp-main.331) |  | 0 |  | Zhao Yang, Yuanzhe Zhang, Dianbo Sui, Cao Liu, Jun Zhao, Kang Liu |  |
| 1526 |  |  [The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.332) |  | 0 |  | Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, Richard Johansson |  |
| 1527 |  |  [ViPE: Visualise Pretty-much Everything](https://doi.org/10.18653/v1/2023.emnlp-main.333) |  | 0 |  | Hassan Shahmohammadi, Adhiraj Ghosh, Hendrik P. A. Lensch |  |
| 1528 |  |  [Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.334) |  | 0 |  | Junpeng Li, Zixia Jia, Zilong Zheng |  |
| 1529 |  |  [Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.335) |  | 0 |  | Kaitlyn Zhou, Dan Jurafsky, Tatsunori Hashimoto |  |
| 1530 |  |  [Elaborative Simplification as Implicit Questions Under Discussion](https://doi.org/10.18653/v1/2023.emnlp-main.336) |  | 0 |  | Yating Wu, William Sheffield, Kyle Mahowald, Junyi Jessy Li |  |
| 1531 |  |  [EntSUMv2: Dataset, Models and Evaluation for More Abstractive Entity-Centric Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.337) |  | 0 |  | Dhruv Mehra, Lingjue Xie, Ella HofmannCoyle, Mayank Kulkarni, Daniel PreotiucPietro |  |
| 1532 |  |  [SciRepEval: A Multi-Format Benchmark for Scientific Document Representations](https://doi.org/10.18653/v1/2023.emnlp-main.338) |  | 0 |  | Amanpreet Singh, Mike D'Arcy, Arman Cohan, Doug Downey, Sergey Feldman |  |
| 1533 |  |  [A Diachronic Perspective on User Trust in AI under Uncertainty](https://doi.org/10.18653/v1/2023.emnlp-main.339) |  | 0 |  | Shehzaad Dhuliawala, Vilém Zouhar, Mennatallah ElAssady, Mrinmaya Sachan |  |
| 1534 |  |  [CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability](https://doi.org/10.18653/v1/2023.emnlp-main.340) |  | 0 |  | Minxuan Lv, Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu |  |
| 1535 |  |  [Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling](https://doi.org/10.18653/v1/2023.emnlp-main.341) |  | 0 |  | Hai Yu, Chong Deng, Qinglin Zhang, Jiaqing Liu, Qian Chen, Wen Wang |  |
| 1536 |  |  [Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents](https://doi.org/10.18653/v1/2023.emnlp-main.342) |  | 0 |  | Hyungjoo Chae, Yongho Song, Kai Tzuiunn Ong, Taeyoon Kwon, Minjin Kim, Youngjae Yu, Dongha Lee, Dongyeop Kang, Jinyoung Yeo |  |
| 1537 |  |  [Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives](https://doi.org/10.18653/v1/2023.emnlp-main.343) |  | 0 |  | Mario Giulianelli, Sarenne Wallbridge, Raquel Fernández |  |
| 1538 |  |  [Generating Commonsense Counterfactuals for Stable Relation Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.344) |  | 0 |  | Xin Miao, Yongqi Li, Tieyun Qian |  |
| 1539 |  |  [C-STS: Conditional Semantic Textual Similarity](https://doi.org/10.18653/v1/2023.emnlp-main.345) |  | 0 |  | Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak Murahari, Victoria Graf, Tanmay Rajpurohit, Ashwin Kalyan, Danqi Chen, Karthik Narasimhan |  |
| 1540 |  |  [Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.346) |  | 0 |  | Seraphina GoldfarbTarrant, Björn Ross, Adam Lopez |  |
| 1541 |  |  [Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks](https://doi.org/10.18653/v1/2023.emnlp-main.347) |  | 0 |  | Chang Yang, Peng Zhang, Wenbo Qiao, Hui Gao, Jiaming Zhao |  |
| 1542 |  |  [Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?](https://doi.org/10.18653/v1/2023.emnlp-main.348) |  | 0 |  | Yichi Zhang, Jiayi Pan, Yuchen Zhou, Rui Pan, Joyce Chai |  |
| 1543 |  |  [Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic Study](https://doi.org/10.18653/v1/2023.emnlp-main.349) |  | 0 |  | Freddy Heppell, Kalina Bontcheva, Carolina Scarton |  |
| 1544 |  |  [Controllable Contrastive Generation for Multilingual Biomedical Entity Linking](https://doi.org/10.18653/v1/2023.emnlp-main.350) |  | 0 |  | Tiantian Zhu, Yang Qin, Qingcai Chen, Xin Mu, Changlong Yu, Yang Xiang |  |
| 1545 |  |  [HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts](https://doi.org/10.18653/v1/2023.emnlp-main.351) |  | 0 |  | Truong Do, Le Khiem, Quang Pham, TrungTin Nguyen, ThanhNam Doan, Binh Nguyen, Chenghao Liu, Savitha Ramasamy, Xiaoli Li, Steven C. H. Hoi |  |
| 1546 |  |  [MediaHG: Rethinking Eye-catchy Features in Social Media Headline Generation](https://doi.org/10.18653/v1/2023.emnlp-main.352) |  | 0 |  | Boning Zhang, Yang Yang |  |
| 1547 |  |  [Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata](https://doi.org/10.18653/v1/2023.emnlp-main.353) |  | 0 |  | Silei Xu, Shicheng Liu, Theo Culhane, Elizaveta Pertseva, MengHsi Wu, Sina J. Semnani, Monica S. Lam |  |
| 1548 |  |  [ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.354) |  | 0 |  | Dheeraj Mekala, Jason Andrew Wolfe, Subhro Roy |  |
| 1549 |  |  [Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule](https://doi.org/10.18653/v1/2023.emnlp-main.355) |  | 0 |  | Andrey Bout, Alexander Podolskiy, Sergey I. Nikolenko, Irina Piontkovskaya |  |
| 1550 |  |  [The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models](https://doi.org/10.18653/v1/2023.emnlp-main.356) |  | 0 |  | Xinyi Chen, Raquel Fernández, Sandro Pezzelle |  |
| 1551 |  |  [RainProof: An Umbrella to Shield Text Generator from Out-Of-Distribution Data](https://doi.org/10.18653/v1/2023.emnlp-main.357) |  | 0 |  | Maxime Darrin, Pablo Piantanida, Pierre Colombo |  |
| 1552 |  |  [KEPL: Knowledge Enhanced Prompt Learning for Chinese Hypernym-Hyponym Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.358) |  | 0 |  | Ningchen Ma, Dong Wang, Hongyun Bao, Lei He, Suncong Zheng |  |
| 1553 |  |  [Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings](https://doi.org/10.18653/v1/2023.emnlp-main.359) |  | 0 |  | Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Chong Deng, Hai Yu, Jiaqing Liu, Yukun Ma, Chong Zhang |  |
| 1554 |  |  [Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.360) |  | 0 |  | Ji Qi, Chuchun Zhang, Xiaozhi Wang, Kaisheng Zeng, Jifan Yu, Jinxin Liu, Lei Hou, Juanzi Li, Xu Bin |  |
| 1555 |  |  [Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions](https://doi.org/10.18653/v1/2023.emnlp-main.361) |  | 0 |  | LucieAimée Kaffee, Arnav Arora, Isabelle Augenstein |  |
| 1556 |  |  [Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding](https://doi.org/10.18653/v1/2023.emnlp-main.362) |  | 0 |  | Sangmin Bae, Jongwoo Ko, Hwanjun Song, SeYoung Yun |  |
| 1557 |  |  [End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions](https://doi.org/10.18653/v1/2023.emnlp-main.363) |  | 0 |  | Libo Qin, Wenbo Pan, Qiguang Chen, Lizi Liao, Zhou Yu, Yue Zhang, Wanxiang Che, Min Li |  |
| 1558 |  |  [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://doi.org/10.18653/v1/2023.emnlp-main.364) |  | 0 |  | Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, Jonathan Berant |  |
| 1559 |  |  [INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.365) |  | 0 |  | Wenda Xu, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag, William Wang, Lei Li |  |
| 1560 |  |  [Multi-level Contrastive Learning for Script-based Character Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.366) |  | 0 |  | Dawei Li, Hengyuan Zhang, Yanran Li, Shiping Yang |  |
| 1561 |  |  [CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients](https://doi.org/10.18653/v1/2023.emnlp-main.367) |  | 0 |  | Jaehyung Seo, Hyeonseok Moon, Jaewook Lee, Sugyeong Eo, Chanjun Park, Heuiseok Lim |  |
| 1562 |  |  [Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks](https://doi.org/10.18653/v1/2023.emnlp-main.368) |  | 0 |  | Ramon RuizDolz, Stella Heras, Ana GarcíaFornes |  |
| 1563 |  |  [Transfer-Free Data-Efficient Multilingual Slot Labeling](https://doi.org/10.18653/v1/2023.emnlp-main.369) |  | 0 |  | Evgeniia Razumovskaia, Ivan Vulic, Anna Korhonen |  |
| 1564 |  |  [Towards Interpretable Mental Health Analysis with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.370) |  | 0 |  | Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, Ziyan Kuang, Sophia Ananiadou |  |
| 1565 |  |  [Learning to Rank Generation with Pairwise Partial Rewards](https://doi.org/10.18653/v1/2023.emnlp-main.371) |  | 0 |  | Youngwon Lee, Jinu Lee, Seungwon Hwang |  |
| 1566 |  |  [GreedyCAS: Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information](https://doi.org/10.18653/v1/2023.emnlp-main.372) |  | 0 |  | Yingqiang Gao, Jessica Lam, Nianlong Gu, Richard H. R. Hahnloser |  |
| 1567 |  |  [Spoiler Detection as Semantic Text Matching](https://doi.org/10.18653/v1/2023.emnlp-main.373) |  | 0 |  | Ryan Tran, Canwen Xu, Julian J. McAuley |  |
| 1568 |  |  [Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.374) |  | 0 |  | Aishwarya Padmakumar, Mert Inan, Spandana Gella, Patrick Lange, Dilek HakkaniTur |  |
| 1569 |  |  [GEM: Gestalt Enhanced Markup Language Model for Web Understanding via Render Tree](https://doi.org/10.18653/v1/2023.emnlp-main.375) |  | 0 |  | Zirui Shao, Feiyu Gao, Zhongda Qi, Hangdi Xing, Jiajun Bu, Zhi Yu, Qi Zheng, Xiaozhong Liu |  |
| 1570 |  |  [Abstractive Open Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.376) |  | 0 |  | Kevin Pei, Ishan Jindal, Kevin ChenChuan Chang |  |
| 1571 |  |  [CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network](https://doi.org/10.18653/v1/2023.emnlp-main.377) |  | 0 |  | Sreyan Ghosh, Manan Suri, Purva Chiniya, Utkarsh Tyagi, Sonal Kumar, Dinesh Manocha |  |
| 1572 |  |  [CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.emnlp-main.378) |  | 0 |  | Jingheng Ye, Yinghui Li, Qingyu Zhou, Yangning Li, Shirong Ma, HaiTao Zheng, Ying Shen |  |
| 1573 |  |  [Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution Methods](https://doi.org/10.18653/v1/2023.emnlp-main.379) |  | 0 |  | Jonathan Kamp, Lisa Beinborn, Antske Fokkens |  |
| 1574 |  |  [SentiStream: A Co-Training Framework for Adaptive Online Sentiment Analysis in Evolving Data Streams](https://doi.org/10.18653/v1/2023.emnlp-main.380) |  | 0 |  | Yuhao Wu, Karthick Sharma, Chun Seah, Shuhao Zhang |  |
| 1575 |  |  [HyperNetwork-based Decoupling to Improve Model Generalization for Few-Shot Relation Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.381) |  | 0 |  | Liang Zhang, Chulun Zhou, Fandong Meng, Jinsong Su, Yidong Chen, Jie Zhou |  |
| 1576 |  |  [Solving Hard Analogy Questions with Relation Embedding Chains](https://doi.org/10.18653/v1/2023.emnlp-main.382) |  | 0 |  | Nitesh Kumar, Steven Schockaert |  |
| 1577 |  |  [Modeling Empathic Similarity in Personal Narratives](https://doi.org/10.18653/v1/2023.emnlp-main.383) |  | 0 |  | Jocelyn Shen, Maarten Sap, Pedro ColonHernandez, Hae Park, Cynthia Breazeal |  |
| 1578 |  |  [Tree Prompting: Efficient Task Adaptation without Fine-Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.384) |  | 0 |  | Chandan Singh, John X. Morris, Alexander M. Rush, Jianfeng Gao, Yuntian Deng |  |
| 1579 |  |  [Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data](https://doi.org/10.18653/v1/2023.emnlp-main.385) |  | 0 |  | Canwen Xu, Daya Guo, Nan Duan, Julian J. McAuley |  |
| 1580 |  |  [Empathy Intent Drives Empathy Detection](https://doi.org/10.18653/v1/2023.emnlp-main.386) |  | 0 |  | Liting Jiang, Di Wu, Bohui Mao, Yanbing Li, Wushour Slamu |  |
| 1581 |  |  [Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling](https://doi.org/10.18653/v1/2023.emnlp-main.387) |  | 0 |  | Yuanjun Shi, Linzhi Wu, Minglai Shao |  |
| 1582 |  |  [BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages](https://doi.org/10.18653/v1/2023.emnlp-main.388) |  | 0 |  | Joseph Marvin Imperial, Ekaterina Kochmar |  |
| 1583 |  |  [ReTAG: Reasoning Aware Table to Analytic Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.389) |  | 0 |  | Deepanway Ghosal, Preksha Nema, Aravindan Raghuveer |  |
| 1584 |  |  [Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators](https://doi.org/10.18653/v1/2023.emnlp-main.390) |  | 0 |  | Liang Chen, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe Wu, TatSeng Chua, KamFai Wong |  |
| 1585 |  |  [Compressing Context to Enhance Inference Efficiency of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.391) |  | 0 |  | Yucheng Li, Bo Dong, Frank Guerin, Chenghua Lin |  |
| 1586 |  |  [MoT: Memory-of-Thought Enables ChatGPT to Self-Improve](https://doi.org/10.18653/v1/2023.emnlp-main.392) |  | 0 |  | Xiaonan Li, Xipeng Qiu |  |
| 1587 |  |  [4 and 7-bit Labeling for Projective and Non-Projective Dependency Trees](https://doi.org/10.18653/v1/2023.emnlp-main.393) |  | 0 |  | Carlos GómezRodríguez, Diego Roca, David Vilares |  |
| 1588 |  |  [Can You Follow Me? Testing Situational Understanding for ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.394) |  | 0 |  | Chenghao Yang, Allyson Ettinger |  |
| 1589 |  |  [Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4](https://doi.org/10.18653/v1/2023.emnlp-main.395) |  | 0 |  | Kellin Pelrine, Anne Imouza, Camille Thibault, Meilina Reksoprodjo, Caleb Gupta, Joel Christoph, JeanFrançois Godbout, Reihaneh Rabbany |  |
| 1590 |  |  [Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation](https://doi.org/10.18653/v1/2023.emnlp-main.396) |  | 0 |  | Bashar Alhafni, Go Inoue, Christian Khairallah, Nizar Habash |  |
| 1591 |  |  [HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.397) |  | 0 |  | Junyi Li, Xiaoxue Cheng, Xin Zhao, JianYun Nie, JiRong Wen |  |
| 1592 |  |  [Enabling Large Language Models to Generate Text with Citations](https://doi.org/10.18653/v1/2023.emnlp-main.398) |  | 0 |  | Tianyu Gao, Howard Yen, Jiatong Yu, Danqi Chen |  |
| 1593 |  |  [Revisiting Machine Translation for Cross-lingual Classification](https://doi.org/10.18653/v1/2023.emnlp-main.399) |  | 0 |  | Mikel Artetxe, Vedanuj Goswami, Shruti Bhosale, Angela Fan, Luke Zettlemoyer |  |
| 1594 |  |  [Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.400) |  | 0 |  | Shuwen Deng, Paul Prasse, David R. Reich, Tobias Scheffer, Lena A. Jäger |  |
| 1595 |  |  [Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model](https://doi.org/10.18653/v1/2023.emnlp-main.401) |  | 0 |  | Leonie Weissweiler, Valentin Hofmann, Anjali Kantharuban, Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkarni, Abhishek Vijayakumar, Haofei Yu, Hinrich Schütze, Kemal Oflazer, David R. Mortensen |  |
| 1596 |  |  [Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.402) |  | 0 |  | Quanyu Long, Wenya Wang, Sinno Jialin Pan |  |
| 1597 |  |  [Understanding the Inner-workings of Language Models Through Representation Dissimilarity](https://doi.org/10.18653/v1/2023.emnlp-main.403) |  | 0 |  | Davis Brown, Charles Godfrey, Nicholas Konz, Jonathan H. Tu, Henry Kvinge |  |
| 1598 |  |  [Efficient Classification of Long Documents via State-Space Models](https://doi.org/10.18653/v1/2023.emnlp-main.404) |  | 0 |  | Peng Lu, Suyuchen Wang, Mehdi Rezagholizadeh, Bang Liu, Ivan Kobyzev |  |
| 1599 |  |  [Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2023.emnlp-main.405) |  | 0 |  | Tianyuan Shi, Liangzhi Li, Zijian Lin, Tao Yang, Xiaojun Quan, Qifan Wang |  |
| 1600 |  |  [Construction Artifacts in Metaphor Identification Datasets](https://doi.org/10.18653/v1/2023.emnlp-main.406) |  | 0 |  | Joanne Boisson, Luis Espinosa Anke, José CamachoCollados |  |
| 1601 |  |  [MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.407) |  | 0 |  | Deepak Nathani, David Wang, Liangming Pan, William Yang Wang |  |
| 1602 |  |  [Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation](https://doi.org/10.18653/v1/2023.emnlp-main.408) |  | 0 |  | Yanzhao Shi, Junzhong Ji, Xiaodan Zhang, Liangqiong Qu, Ying Liu |  |
| 1603 |  |  [Enhancing Structured Evidence Extraction for Fact Verification](https://doi.org/10.18653/v1/2023.emnlp-main.409) |  | 0 |  | Zirui Wu, Nan Hu, Yansong Feng |  |
| 1604 |  |  [Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models](https://doi.org/10.18653/v1/2023.emnlp-main.410) |  | 0 |  | Di Wu, Wasi Uddin Ahmad, KaiWei Chang |  |
| 1605 |  |  [A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems](https://doi.org/10.18653/v1/2023.emnlp-main.411) |  | 0 |  | Hannah Bast, Matthias Hertel, Natalie Prange |  |
| 1606 |  |  [A Multi-Task Dataset for Assessing Discourse Coherence in Chinese Essays: Structure, Theme, and Logic Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.412) |  | 0 |  | Hongyi Wu, Xinshu Shen, Man Lan, Shaoguang Mao, Xiaopeng Bai, Yuanbin Wu |  |
| 1607 |  |  [SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning](https://doi.org/10.18653/v1/2023.emnlp-main.413) |  | 0 |  | Yi Chen, Liang He |  |
| 1608 |  |  [Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation](https://doi.org/10.18653/v1/2023.emnlp-main.414) |  | 0 |  | Chengwei Qin, Chen Chen, Shafiq Joty |  |
| 1609 |  |  [When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.415) |  | 0 |  | Eve Fleisig, Rediet Abebe, Dan Klein |  |
| 1610 |  |  [Lazy-k Decoding: Constrained Decoding for Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.416) |  | 0 |  | Arthur Hemmer, Mickaël Coustaty, Nicola Bartolo, Jérôme Brachat, JeanMarc Ogier |  |
| 1611 |  |  [Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation](https://doi.org/10.18653/v1/2023.emnlp-main.417) |  | 0 |  | Hailin Chen, Amrita Saha, Steven ChuHong Hoi, Shafiq Joty |  |
| 1612 |  |  [Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.418) |  | 0 |  | Raghav Jain, Daivik Sojitra, Arkadeep Acharya, Sriparna Saha, Adam Jatowt, Sandipan Dandapat |  |
| 1613 |  |  [Comparing Styles across Languages](https://doi.org/10.18653/v1/2023.emnlp-main.419) |  | 0 |  | Shreya Havaldar, Matthew Pressimone, Eric Wong, Lyle H. Ungar |  |
| 1614 |  |  [Event Causality Extraction via Implicit Cause-Effect Interactions](https://doi.org/10.18653/v1/2023.emnlp-main.420) |  | 0 |  | Jintao Liu, Zequn Zhang, Kaiwen Wei, Zhi Guo, Xian Sun, Li Jin, Xiaoyu Li |  |
| 1615 |  |  [Evaluation of African American Language Bias in Natural Language Generation](https://doi.org/10.18653/v1/2023.emnlp-main.421) |  | 0 |  | Nicholas Deas, Jessica Grieser, Shana Kleiner, Desmond Patton, Elsbeth Turcan, Kathleen R. McKeown |  |
| 1616 |  |  [A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2023.emnlp-main.422) |  | 0 |  | Songbo Hu, Han Zhou, Moy Yuan, Milan Gritta, Guchun Zhang, Ignacio Iacobacci, Anna Korhonen, Ivan Vulic |  |
| 1617 |  |  [Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction](https://doi.org/10.18653/v1/2023.emnlp-main.423) |  | 0 |  | V. S. D. S. Mahesh Akavarapu, Arnab Bhattacharya |  |
| 1618 |  |  [Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning](https://doi.org/10.18653/v1/2023.emnlp-main.424) |  | 0 |  | Ximing Lu, Faeze Brahman, Peter West, Jaehun Jung, Khyathi Raghavi Chandu, Abhilasha Ravichander, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Y. Lin, Skyler Hallinan, Lianhui Qin, Xiang Ren, Sean Welleck, Yejin Choi |  |
| 1619 |  |  [Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering](https://doi.org/10.18653/v1/2023.emnlp-main.425) |  | 0 |  | Kangil Lee, Segwang Kim, Kyomin Jung |  |
| 1620 |  |  [Taxonomy Expansion for Named Entity Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.426) |  | 0 |  | Karthikeyan K, Yogarshi Vyas, Jie Ma, Giovanni Paolini, Neha Anna John, Shuai Wang, Yassine Benajiba, Vittorio Castelli, Dan Roth, Miguel Ballesteros |  |
| 1621 |  |  [Rather a Nurse than a Physician - Contrastive Explanations under Investigation](https://doi.org/10.18653/v1/2023.emnlp-main.427) |  | 0 |  | Oliver Eberle, Ilias Chalkidis, Laura Cabello, Stephanie Brandl |  |
| 1622 |  |  [EtiCor: Corpus for Analyzing LLMs for Etiquettes](https://doi.org/10.18653/v1/2023.emnlp-main.428) |  | 0 |  | Ashutosh Dwivedi, Pradhyumna Lavania, Ashutosh Modi |  |
| 1623 |  |  [An Investigation of LLMs' Inefficacy in Understanding Converse Relations](https://doi.org/10.18653/v1/2023.emnlp-main.429) |  | 0 |  | Chengwen Qi, Bowen Li, Binyuan Hui, Bailin Wang, Jinyang Li, Jinwang Wu, Yuanjun Laili |  |
| 1624 |  |  [Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.430) |  | 0 |  | Weishi Wang, Yue Wang, Steven C. H. Hoi, Shafiq Joty |  |
| 1625 |  |  [ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters](https://doi.org/10.18653/v1/2023.emnlp-main.431) |  | 0 |  | Vipul Rathore, Rajdeep Dhingra, Parag Singla, Mausam |  |
| 1626 |  |  [Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.432) |  | 0 |  | Xue Han, Yitong Wang, Qian Hu, Pengwei Hu, Chao Deng, Junlan Feng |  |
| 1627 |  |  [Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning](https://doi.org/10.18653/v1/2023.emnlp-main.433) |  | 0 |  | Sarkar Snigdha Sarathi Das, Haoran Zhang, Peng Shi, Wenpeng Yin, Rui Zhang |  |
| 1628 |  |  [On the Representational Capacity of Recurrent Neural Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.434) |  | 0 |  | Franz Nowak, Anej Svete, Li Du, Ryan Cotterell |  |
| 1629 |  |  [A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.435) |  | 0 |  | Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan |  |
| 1630 |  |  [Benchmarking and Improving Text-to-SQL Generation under Ambiguity](https://doi.org/10.18653/v1/2023.emnlp-main.436) |  | 0 |  | Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, Sunita Sarawagi |  |
| 1631 |  |  [Non-autoregressive Text Editing with Copy-aware Latent Alignments](https://doi.org/10.18653/v1/2023.emnlp-main.437) |  | 0 |  | Yu Zhang, Yue Zhang, Leyang Cui, Guohong Fu |  |
| 1632 |  |  [Translating away Translationese without Parallel Data](https://doi.org/10.18653/v1/2023.emnlp-main.438) |  | 0 |  | Rricha Jalota, Koel Dutta Chowdhury, Cristina EspañaBonet, Josef van Genabith |  |
| 1633 |  |  [Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning](https://doi.org/10.18653/v1/2023.emnlp-main.439) |  | 0 |  | Xiao Yu, Maximillian Chen, Zhou Yu |  |
| 1634 |  |  [UniMath: A Foundational and Multimodal Mathematical Reasoner](https://doi.org/10.18653/v1/2023.emnlp-main.440) |  | 0 |  | Zhenwen Liang, Tianyu Yang, Jipeng Zhang, Xiangliang Zhang |  |
| 1635 |  |  [CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding](https://doi.org/10.18653/v1/2023.emnlp-main.441) |  | 0 |  | Yixiao Ma, Yueyue Wu, Weihang Su, Qingyao Ai, Yiqun Liu |  |
| 1636 |  |  [HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies](https://doi.org/10.18653/v1/2023.emnlp-main.442) |  | 0 |  | William Watson, Nicole Cho, Tucker Balch, Manuela Veloso |  |
| 1637 |  |  [Causal Document-Grounded Dialogue Pre-training](https://doi.org/10.18653/v1/2023.emnlp-main.443) |  | 0 |  | Yingxiu Zhao, Bowen Yu, Bowen Li, Haiyang Yu, Jinyang Li, Chao Wang, Fei Huang, Yongbin Li, Nevin L. Zhang |  |
| 1638 |  |  [Accented Speech Recognition With Accent-specific Codebooks](https://doi.org/10.18653/v1/2023.emnlp-main.444) |  | 0 |  | Darshan Prabhu, Preethi Jyothi, Sriram Ganapathy, Vinit Unni |  |
| 1639 |  |  [Linking Surface Facts to Large-Scale Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.445) |  | 0 |  | Gorjan Radevski, Kiril Gashteovski, ChiaChien Hung, Carolin Lawrence, Goran Glavas |  |
| 1640 |  |  [Sentiment Analysis on Streaming User Reviews via Dual-Channel Dynamic Graph Neural Network](https://doi.org/10.18653/v1/2023.emnlp-main.446) |  | 0 |  | Xin Zhang, Linhai Zhang, Deyu Zhou |  |
| 1641 |  |  [DUMB: A Dutch Model Benchmark](https://doi.org/10.18653/v1/2023.emnlp-main.447) |  | 0 |  | Wietse de Vries, Martijn Wieling, Malvina Nissim |  |
| 1642 |  |  [OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding](https://doi.org/10.18653/v1/2023.emnlp-main.448) |  | 0 |  | Zhan Shi, Guoyin Wang, Ke Bai, Jiwei Li, Xiang Li, Qingjun Cui, Belinda Zeng, Trishul Chilimbi, Xiaodan Zhu |  |
| 1643 |  |  [End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-main.449) |  | 0 |  | Juan Pablo ZuluagaGomez, Zhaocheng Huang, Xing Niu, Rohit Paturi, Sundararajan Srinivasan, Prashant Mathur, Brian Thompson, Marcello Federico |  |
| 1644 |  |  [A Fine-Grained Taxonomy of Replies to Hate Speech](https://doi.org/10.18653/v1/2023.emnlp-main.450) |  | 0 |  | Xinchen Yu, Ashley Zhao, Eduardo Blanco, Lingzi Hong |  |
| 1645 |  |  [JointMatch: A Unified Approach for Diverse and Collaborative Pseudo-Labeling to Semi-Supervised Text Classification](https://doi.org/10.18653/v1/2023.emnlp-main.451) |  | 0 |  | Henry Peng Zou, Cornelia Caragea |  |
| 1646 |  |  [Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN](https://doi.org/10.18653/v1/2023.emnlp-main.452) |  | 0 |  | Niloofar Mireshghallah, Nikolai Vogler, Junxian He, Omar Florez, Ahmed ElKishky, Taylor BergKirkpatrick |  |
| 1647 |  |  [Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4](https://doi.org/10.18653/v1/2023.emnlp-main.453) |  | 0 |  | Kent K. Chang, Mackenzie Cramer, Sandeep Soni, David Bamman |  |
| 1648 |  |  [A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts](https://doi.org/10.18653/v1/2023.emnlp-main.454) |  | 0 |  | Marion Di Marco, Katharina Hämmerl, Alexander Fraser |  |
| 1649 |  |  [CiteBench: A Benchmark for Scientific Citation Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.455) |  | 0 |  | Martin Funkquist, Ilia Kuznetsov, Yufang Hou, Iryna Gurevych |  |
| 1650 |  |  [From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.456) |  | 0 |  | Zheyuan Zhang, Shane Storks, Fengyuan Hu, Sungryull Sohn, Moontae Lee, Honglak Lee, Joyce Chai |  |
| 1651 |  |  [A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video](https://doi.org/10.18653/v1/2023.emnlp-main.457) |  | 0 |  | Keito Kudo, Haruki Nagasawa, Jun Suzuki, Nobuyuki Shimizu |  |
| 1652 |  |  [Copyright Violations and Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.458) |  | 0 |  | Antonia Karamolegkou, Jiaang Li, Li Zhou, Anders Søgaard |  |
| 1653 |  |  [Effects of sub-word segmentation on performance of transformer language models](https://doi.org/10.18653/v1/2023.emnlp-main.459) |  | 0 |  | Jue Hou, Anisia Katinskaia, AnhDuc Vu, Roman Yangarber |  |
| 1654 |  |  [Symbolic Planning and Code Generation for Grounded Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.460) |  | 0 |  | Justin T. Chiu, Wenting Zhao, Derek Chen, Saujas Vaduguru, Alexander M. Rush, Daniel Fried |  |
| 1655 |  |  [Universal Self-Adaptive Prompting](https://doi.org/10.18653/v1/2023.emnlp-main.461) |  | 0 |  | Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Eisenschlos, Sercan Ö. Arik, Tomas Pfister |  |
| 1656 |  |  [Somali Information Retrieval Corpus: Bridging the Gap between Query Translation and Dedicated Language Resources](https://doi.org/10.18653/v1/2023.emnlp-main.462) |  | 0 |  | Abdisalam Badel, Ting Zhong, Wenxin Tai, Fan Zhou |  |
| 1657 |  |  [Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.463) |  | 0 |  | Biru Zhu, Lifan Yuan, Ganqu Cui, Yangyi Chen, Chong Fu, Bingxiang He, Yangdong Deng, Zhiyuan Liu, Maosong Sun, Ming Gu |  |
| 1658 |  |  [Faithful Model Evaluation for Model-Based Metrics](https://doi.org/10.18653/v1/2023.emnlp-main.464) |  | 0 |  | Qian Hu, Palash Goyal, Rahul Gupta |  |
| 1659 |  |  [Content- and Topology-Aware Representation Learning for Scientific Multi-Literature](https://doi.org/10.18653/v1/2023.emnlp-main.465) |  | 0 |  | Kai Zhang, Kaisong Song, Yangyang Kang, Xiaozhong Liu |  |
| 1660 |  |  [Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages](https://doi.org/10.18653/v1/2023.emnlp-main.466) |  | 0 |  | Ethan Wilcox, Clara Meister, Ryan Cotterell, Tiago Pimentel |  |
| 1661 |  |  [Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks](https://doi.org/10.18653/v1/2023.emnlp-main.467) |  | 0 |  | Zhaohui Yan, Songlin Yang, Wei Liu, Kewei Tu |  |
| 1662 |  |  [Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.468) |  | 0 |  | Daman Arora, Himanshu Gaurav Singh, Mausam |  |
| 1663 |  |  [StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure](https://doi.org/10.18653/v1/2023.emnlp-main.469) |  | 0 |  | Mattia Opper, Victor Prokhorov, Siddharth Narayanaswamy |  |
| 1664 |  |  [WiCE: Real-World Entailment for Claims in Wikipedia](https://doi.org/10.18653/v1/2023.emnlp-main.470) |  | 0 |  | Ryo Kamoi, Tanya Goyal, Juan Diego Rodriguez, Greg Durrett |  |
| 1665 |  |  [Natural Disaster Tweets Classification Using Multimodal Data](https://doi.org/10.18653/v1/2023.emnlp-main.471) |  | 0 |  | Mohammad Basit, Bashir Alam, Zubaida Fatima, Salman Shaikh |  |
| 1666 |  |  [On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research](https://doi.org/10.18653/v1/2023.emnlp-main.472) |  | 0 |  | Luiza Pozzobon, Beyza Ermis, Patrick Lewis, Sara Hooker |  |
| 1667 |  |  [RoBoCoP: A Comprehensive ROmance BOrrowing COgnate Package and Benchmark for Multilingual Cognate Identification](https://doi.org/10.18653/v1/2023.emnlp-main.473) |  | 0 |  | Liviu P. Dinu, Ana Sabina Uban, Alina Maria Cristea, Anca Dinu, IoanBogdan Iordache, Simona Georgescu, Laurentiu Zoicas |  |
| 1668 |  |  [Instructive Dialogue Summarization with Query Aggregations](https://doi.org/10.18653/v1/2023.emnlp-main.474) |  | 0 |  | Bin Wang, Zhengyuan Liu, Nancy F. Chen |  |
| 1669 |  |  [Semantic matching for text classification with complex class descriptions](https://doi.org/10.18653/v1/2023.emnlp-main.475) |  | 0 |  | Brian de Silva, KuanWen Huang, Gwang Lee, Karen Hovsepian, Yan Xu, Mingwei Shen |  |
| 1670 |  |  [MADNet: Maximizing Addressee Deduction Expectation for Multi-Party Conversation Generation](https://doi.org/10.18653/v1/2023.emnlp-main.476) |  | 0 |  | JiaChen Gu, ChaoHong Tan, Caiyuan Chu, ZhenHua Ling, Chongyang Tao, Quan Liu, Cong Liu |  |
| 1671 |  |  [GLEN: Generative Retrieval via Lexical Index Learning](https://doi.org/10.18653/v1/2023.emnlp-main.477) |  | 0 |  | Sunkyung Lee, Minjin Choi, Jongwuk Lee |  |
| 1672 |  |  [Turn-Level Active Learning for Dialogue State Tracking](https://doi.org/10.18653/v1/2023.emnlp-main.478) |  | 0 |  | Zihan Zhang, Meng Fang, Fanghua Ye, Ling Chen, MohammadReza NamaziRad |  |
| 1673 |  |  [ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.479) |  | 0 |  | Haoqin Tu, Yitong Li, Fei Mi, Zhongliang Yang |  |
| 1674 |  |  [Modeling Conceptual Attribute Likeness and Domain Inconsistency for Metaphor Detection](https://doi.org/10.18653/v1/2023.emnlp-main.480) |  | 0 |  | Yuan Tian, Nan Xu, Wenji Mao, Daniel Zeng |  |
| 1675 |  |  [Referring Image Segmentation via Joint Mask Contextual Embedding Learning and Progressive Alignment Network](https://doi.org/10.18653/v1/2023.emnlp-main.481) |  | 0 |  | Ziling Huang, Shin'ichi Satoh |  |
| 1676 |  |  [Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study](https://doi.org/10.18653/v1/2023.emnlp-main.482) |  | 0 |  | Boxin Wang, Wei Ping, Peng Xu, Lawrence McAfee, Zihan Liu, Mohammad Shoeybi, Yi Dong, Oleksii Kuchaiev, Bo Li, Chaowei Xiao, Anima Anandkumar, Bryan Catanzaro |  |
| 1677 |  |  [SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables](https://doi.org/10.18653/v1/2023.emnlp-main.483) |  | 0 |  | Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, MinYen Kan |  |
| 1678 |  |  [Training Simultaneous Speech Translation with Robust and Random Wait-k-Tokens Strategy](https://doi.org/10.18653/v1/2023.emnlp-main.484) |  | 0 |  | Linlin Zhang, Kai Fan, Jiajun Bu, Zhongqiang Huang |  |
| 1679 |  |  [SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples](https://doi.org/10.18653/v1/2023.emnlp-main.485) |  | 0 |  | Deqing Fu, Ameya Godbole, Robin Jia |  |
| 1680 |  |  [Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence](https://doi.org/10.18653/v1/2023.emnlp-main.486) |  | 0 |  | Zhihong Zhu, Xuxin Cheng, Zhiqi Huang, Dongsheng Chen, Yuexian Zou |  |
| 1681 |  |  [Task-Agnostic Low-Rank Adapters for Unseen English Dialects](https://doi.org/10.18653/v1/2023.emnlp-main.487) |  | 0 |  | Zedian Xiao, William Held, Yanchen Liu, Diyi Yang |  |
| 1682 |  |  [Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization](https://doi.org/10.18653/v1/2023.emnlp-main.488) |  | 0 |  | Tianshi Che, Ji Liu, Yang Zhou, Jiaxiang Ren, Jiwen Zhou, Victor S. Sheng, Huaiyu Dai, Dejing Dou |  |
| 1683 |  |  [TheoremQA: A Theorem-driven Question Answering Dataset](https://doi.org/10.18653/v1/2023.emnlp-main.489) |  | 0 |  | Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, Tony Xia |  |
| 1684 |  |  [Scalable-DSC: A Structural Template Prompt Approach to Scalable Dialogue State Correction](https://doi.org/10.18653/v1/2023.emnlp-main.490) |  | 0 |  | Haoxiang Su, Hongyan Xie, Hao Huang, Shuangyong Song, Ruiyu Fang, Xiaomeng Huang, Sijie Feng |  |
| 1685 |  |  [Don't Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.491) |  | 0 |  | Xiang Zhang, Senyu Li, Bradley Hauer, Ning Shi, Grzegorz Kondrak |  |
| 1686 |  |  [M³Seg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in ASR Transcripts](https://doi.org/10.18653/v1/2023.emnlp-main.492) |  | 0 |  | Ke Wang, Xiutian Zhao, Yanghui Li, Wei Peng |  |
| 1687 |  |  [Empirical Study of Zero-Shot NER with ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.493) |  | 0 |  | Tingyu Xie, Qi Li, Jian Zhang, Yan Zhang, Zuozhu Liu, Hongwei Wang |  |
| 1688 |  |  [Automatic Prompt Optimization with "Gradient Descent" and Beam Search](https://doi.org/10.18653/v1/2023.emnlp-main.494) |  | 0 |  | Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael Zeng |  |
| 1689 |  |  [Active Retrieval Augmented Generation](https://doi.org/10.18653/v1/2023.emnlp-main.495) |  | 0 |  | Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane DwivediYu, Yiming Yang, Jamie Callan, Graham Neubig |  |
| 1690 |  |  [GD-COMET: A Geo-Diverse Commonsense Inference Model](https://doi.org/10.18653/v1/2023.emnlp-main.496) |  | 0 |  | Mehar Bhatia, Vered Shwartz |  |
| 1691 |  |  [Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation](https://doi.org/10.18653/v1/2023.emnlp-main.497) |  | 0 |  | Chenxu Yang, Zheng Lin, Lanrui Wang, Chong Tian, Liang Pang, Jiangnan Li, Qirong Ho, Yanan Cao, Weiping Wang |  |
| 1692 |  |  [Enhancing Biomedical Lay Summarisation with External Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.498) |  | 0 |  | Tomas Goldsack, Zhihao Zhang, Chen Tang, Carolina Scarton, Chenghua Lin |  |
| 1693 |  |  [A Diffusion Weighted Graph Framework for New Intent Discovery](https://doi.org/10.18653/v1/2023.emnlp-main.499) |  | 0 |  | Wenkai Shi, Wenbin An, Feng Tian, Qinghua Zheng, Qianying Wang, Ping Chen |  |
| 1694 |  |  [A Self-enhancement Multitask Framework for Unsupervised Aspect Category Detection](https://doi.org/10.18653/v1/2023.emnlp-main.500) |  | 0 |  | ThiNhung Nguyen, Hoang Ngo, KiemHieu Nguyen, TuanDung Cao |  |
| 1695 |  |  [DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.501) |  | 0 |  | Chengcheng Han, Xiaowei Du, Che Zhang, Yixin Lian, Xiang Li, Ming Gao, Baoyuan Wang |  |
| 1696 |  |  [Recurrent Neural Language Models as Probabilistic Finite-state Automata](https://doi.org/10.18653/v1/2023.emnlp-main.502) |  | 0 |  | Anej Svete, Ryan Cotterell |  |
| 1697 |  |  [Revisiting Source Context in Nearest Neighbor Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.503) |  | 0 |  | Xuanhong Li, Peng Li, Po Hu |  |
| 1698 |  |  [Find-2-Find: Multitask Learning for Anaphora Resolution and Object Localization](https://doi.org/10.18653/v1/2023.emnlp-main.504) |  | 0 |  | Cennet Oguz, Pascal Denis, Emmanuel Vincent, Simon Ostermann, Josef van Genabith |  |
| 1699 |  |  [Background Summarization of Event Timelines](https://doi.org/10.18653/v1/2023.emnlp-main.505) |  | 0 |  | Adithya Pratapa, Kevin Small, Markus Dreyer |  |
| 1700 |  |  [Superlim: A Swedish Language Understanding Evaluation Benchmark](https://doi.org/10.18653/v1/2023.emnlp-main.506) |  | 0 |  | Aleksandrs Berdicevskis, Gerlof Bouma, Robin Kurtz, Felix Morger, Joey Öhman, Yvonne Adesam, Lars Borin, Dana Dannélls, Markus Forsberg, Tim Isbister, Anna Lindahl, Martin Malmsten, Faton Rekathati, Magnus Sahlgren, Elena Volodina, Love Börjeson, Simon Hengchen, Nina Tahmasebi |  |
| 1701 |  |  [Reasoning with Language Model is Planning with World Model](https://doi.org/10.18653/v1/2023.emnlp-main.507) |  | 0 |  | Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu |  |
| 1702 |  |  [LLM-enhanced Self-training for Cross-domain Constituency Parsing](https://doi.org/10.18653/v1/2023.emnlp-main.508) |  | 0 |  | Jianling Li, Meishan Zhang, Peiming Guo, Min Zhang, Yue Zhang |  |
| 1703 |  |  [Continual Named Entity Recognition without Catastrophic Forgetting](https://doi.org/10.18653/v1/2023.emnlp-main.509) |  | 0 |  | Duzhen Zhang, Wei Cong, Jiahua Dong, Yahan Yu, Xiuyi Chen, Yonggang Zhang, Zhen Fang |  |
| 1704 |  |  [DSI++: Updating Transformer Memory with New Documents](https://doi.org/10.18653/v1/2023.emnlp-main.510) |  | 0 |  | Sanket Vaibhav Mehta, Jai Gupta, Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Jinfeng Rao, Marc Najork, Emma Strubell, Donald Metzler |  |
| 1705 |  |  [Editing Common Sense in Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.511) |  | 0 |  | Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong Zhao, Xiang Li, Sarah Wiegreffe, Niket Tandon |  |
| 1706 |  |  [Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.512) |  | 0 |  | Tianqi Zhong, Quan Wang, Jingxuan Han, Yongdong Zhang, Zhendong Mao |  |
| 1707 |  |  [Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.513) |  | 0 |  | Hosein Mohebbi, Grzegorz Chrupala, Willem H. Zuidema, Afra Alishahi |  |
| 1708 |  |  [Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System](https://doi.org/10.18653/v1/2023.emnlp-main.514) |  | 0 |  | Weizhou Shen, Yingqi Gao, Canbin Huang, Fanqi Wan, Xiaojun Quan, Wei Bi |  |
| 1709 |  |  [IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions](https://doi.org/10.18653/v1/2023.emnlp-main.515) |  | 0 |  | Wenhao Yu, Meng Jiang, Peter Clark, Ashish Sabharwal |  |
| 1710 |  |  [How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances](https://doi.org/10.18653/v1/2023.emnlp-main.516) |  | 0 |  | Zihan Zhang, Meng Fang, Ling Chen, MohammadReza NamaziRad, Jun Wang |  |
| 1711 |  |  [PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.517) |  | 0 |  | Wookje Han, Jinsol Park, Kyungjae Lee |  |
| 1712 |  |  [Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.518) |  | 0 |  | Verna Dankers, Ivan Titov, Dieuwke Hupkes |  |
| 1713 |  |  [DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4](https://doi.org/10.18653/v1/2023.emnlp-main.519) |  | 0 |  | Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, Fei Liu |  |
| 1714 |  |  [Gender Biases in Automatic Evaluation Metrics for Image Captioning](https://doi.org/10.18653/v1/2023.emnlp-main.520) |  | 0 |  | Haoyi Qiu, ZiYi Dou, Tianlu Wang, Asli Celikyilmaz, Nanyun Peng |  |
| 1715 |  |  [QA-NatVer: Question Answering for Natural Logic-based Fact Verification](https://doi.org/10.18653/v1/2023.emnlp-main.521) |  | 0 |  | Rami Aly, Marek Strong, Andreas Vlachos |  |
| 1716 |  |  [Increasing Probability Mass on Answer Choices Does Not Always Improve Accuracy](https://doi.org/10.18653/v1/2023.emnlp-main.522) |  | 0 |  | Sarah Wiegreffe, Matthew Finlayson, Oyvind Tafjord, Peter Clark, Ashish Sabharwal |  |
| 1717 |  |  [Generating Data for Symbolic Language with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.523) |  | 0 |  | Jiacheng Ye, Chengzu Li, Lingpeng Kong, Tao Yu |  |
| 1718 |  |  [IDTraffickers: An Authorship Attribution Dataset to link and connect Potential Human-Trafficking Operations on Text Escort Advertisements](https://doi.org/10.18653/v1/2023.emnlp-main.524) |  | 0 |  | Vageesh Saxena, Benjamin Bashpole, Gijs van Dijck, Gerasimos Spanakis |  |
| 1719 |  |  [Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.525) |  | 0 |  | Laura Cabello, Emanuele Bugliarello, Stephanie Brandl, Desmond Elliott |  |
| 1720 |  |  [Improving Dialogue Discourse Parsing via Reply-to Structures of Addressee Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.526) |  | 0 |  | Yaxin Fan, Feng Jiang, Peifeng Li, Fang Kong, Qiaoming Zhu |  |
| 1721 |  |  [Improving Language Models' Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary](https://doi.org/10.18653/v1/2023.emnlp-main.527) |  | 0 |  | Myeongjun Jang, Thomas Lukasiewicz |  |
| 1722 |  |  [DALE: Generative Data Augmentation for Low-Resource Legal NLP](https://doi.org/10.18653/v1/2023.emnlp-main.528) |  | 0 |  | Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Ramaneswaran S., Sakshi Singh, Utkarsh Tyagi, Dinesh Manocha |  |
| 1723 |  |  [FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.529) |  | 0 |  | Xinge Ma, Jiangming Liu, Jin Wang, Xuejie Zhang |  |
| 1724 |  |  [trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.530) |  | 0 |  | Alexander Havrilla, Maksym Zhuravinskyi, Duy Phung, Aman Tiwari, Jonathan Tow, Stella Biderman, Quentin Anthony, Louis Castricato |  |
| 1725 |  |  [This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.531) |  | 0 |  | Iker GarcíaFerrero, Begoña Altuna, Javier Álvez, Itziar GonzalezDios, German Rigau |  |
| 1726 |  |  [MT2: Towards a Multi-Task Machine Translation Model with Translation-Specific In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.532) |  | 0 |  | Chunyou Li, Mingtong Liu, Hongxiao Zhang, Yufeng Chen, Jinan Xu, Ming Zhou |  |
| 1727 |  |  [CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset](https://doi.org/10.18653/v1/2023.emnlp-main.533) |  | 0 |  | Susanna Rücker, Alan Akbik |  |
| 1728 |  |  [Disentangling Transformer Language Models as Superposed Topic Models](https://doi.org/10.18653/v1/2023.emnlp-main.534) |  | 0 |  | Jia Peng Lim, Hady W. Lauw |  |
| 1729 |  |  [Conversational Semantic Parsing using Dynamic Context Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.535) |  | 0 |  | Parag Jain, Mirella Lapata |  |
| 1730 |  |  [Not all quantifiers are equal: Probing Transformer-based language models' understanding of generalised quantifiers](https://doi.org/10.18653/v1/2023.emnlp-main.536) |  | 0 |  | Tharindu Madusanka, Iqra Zahid, Hao Li, Ian PrattHartmann, Riza BatistaNavarro |  |
| 1731 |  |  [Structure-aware Knowledge Graph-to-text Generation with Planning Selection and Similarity Distinction](https://doi.org/10.18653/v1/2023.emnlp-main.537) |  | 0 |  | Feng Zhao, Hongzhi Zou, Cheng Yan |  |
| 1732 |  |  [SOUL: Towards Sentiment and Opinion Understanding of Language](https://doi.org/10.18653/v1/2023.emnlp-main.538) |  | 0 |  | Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing |  |
| 1733 |  |  [Regulation and NLP (RegNLP): Taming Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.539) |  | 0 |  | Catalina Goanta, Nikolaos Aletras, Ilias Chalkidis, Sofia Ranchordás, Gerasimos Spanakis |  |
| 1734 |  |  [MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation](https://doi.org/10.18653/v1/2023.emnlp-main.540) |  | 0 |  | Zexue He, Yu Wang, An Yan, Yao Liu, Eric Y. Chang, Amilcare Gentili, Julian J. McAuley, ChunNan Hsu |  |
| 1735 |  |  [Seeing through the mess: evolutionary dynamics of lexical polysemy](https://doi.org/10.18653/v1/2023.emnlp-main.541) |  | 0 |  | Andreas Baumann, Andreas Stephan, Benjamin Roth |  |
| 1736 |  |  [Are Embedded Potatoes Still Vegetables? On the Limitations of WordNet Embeddings for Lexical Semantics](https://doi.org/10.18653/v1/2023.emnlp-main.542) |  | 0 |  | Xuyou Cheng, Michael Sejr Schlichtkrull, Guy Emerson |  |
| 1737 |  |  [Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.543) |  | 0 |  | Andrea Sottana, Bin Liang, Kai Zou, Zheng Yuan |  |
| 1738 |  |  [Event-Location Tracking in Narratives: A Case Study on Holocaust Testimonies](https://doi.org/10.18653/v1/2023.emnlp-main.544) |  | 0 |  | Eitan Wagner, Renana Keydar, Omri Abend |  |
| 1739 |  |  [Dialogizer: Context-aware Conversational-QA Dataset Generation from Textual Sources](https://doi.org/10.18653/v1/2023.emnlp-main.545) |  | 0 |  | Yerin Hwang, Yongil Kim, Hyunkyung Bae, Hwanhee Lee, Jeesoo Bang, Kyomin Jung |  |
| 1740 |  |  [Learning to Predict Task Transferability via Soft Prompt](https://doi.org/10.18653/v1/2023.emnlp-main.546) |  | 0 |  | Lingyun Feng |  |
| 1741 |  |  [Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.547) |  | 0 |  | Wang Zhu, Jesse Thomason, Robin Jia |  |
| 1742 |  |  [Mirror: A Universal Framework for Various Information Extraction Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.548) |  | 0 |  | Tong Zhu, Junfei Ren, Zijian Yu, Mengsong Wu, Guoliang Zhang, Xiaoye Qu, Wenliang Chen, Zhefeng Wang, Baoxing Huai, Min Zhang |  |
| 1743 |  |  ["Mistakes Help Us Grow": Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms](https://doi.org/10.18653/v1/2023.emnlp-main.549) |  | 0 |  | Kunal Handa, Margaret Clapper, Jessica Boyle, Rose E. Wang, Diyi Yang, David S. Yeager, Dorottya Demszky |  |
| 1744 |  |  [Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text](https://doi.org/10.18653/v1/2023.emnlp-main.550) |  | 0 |  | Qi Cao, Takeshi Kojima, Yutaka Matsuo, Yusuke Iwasawa |  |
| 1745 |  |  [Detecting and Mitigating Hallucinations in Multilingual Summarisation](https://doi.org/10.18653/v1/2023.emnlp-main.551) |  | 0 |  | Yifu Qiu, Yftah Ziser, Anna Korhonen, Edoardo Maria Ponti, Shay B. Cohen |  |
| 1746 |  |  [Exploring Linguistic Probes for Morphological Inflection](https://doi.org/10.18653/v1/2023.emnlp-main.552) |  | 0 |  | Jordan Kodner, Salam Khalifa, Sarah Ruth Brogden Payne |  |
| 1747 |  |  [AMR Parsing with Causal Hierarchical Attention and Pointers](https://doi.org/10.18653/v1/2023.emnlp-main.553) |  | 0 |  | Chao Lou, Kewei Tu |  |
| 1748 |  |  [FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score](https://doi.org/10.18653/v1/2023.emnlp-main.554) |  | 0 |  | Haowei Lin, Yuntian Gu |  |
| 1749 |  |  [Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.555) |  | 0 |  | Haoqi Zheng, Qihuang Zhong, Liang Ding, Zhiliang Tian, Xin Niu, Changjian Wang, Dongsheng Li, Dacheng Tao |  |
| 1750 |  |  [IC3: Image Captioning by Committee Consensus](https://doi.org/10.18653/v1/2023.emnlp-main.556) |  | 0 |  | David Chan, Austin Myers, Sudheendra Vijayanarasimhan, David A. Ross, John F. Canny |  |
| 1751 |  |  [SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.557) |  | 0 |  | Potsawee Manakul, Adian Liusie, Mark J. F. Gales |  |
| 1752 |  |  [Fair Without Leveling Down: A New Intersectional Fairness Definition](https://doi.org/10.18653/v1/2023.emnlp-main.558) |  | 0 |  | Gaurav Maheshwari, Aurélien Bellet, Pascal Denis, Mikaela Keller |  |
| 1753 |  |  [Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications](https://doi.org/10.18653/v1/2023.emnlp-main.559) |  | 0 |  | Manuel Faysse, Gautier Viaud, Céline Hudelot, Pierre Colombo |  |
| 1754 |  |  [CLAD-ST: Contrastive Learning with Adversarial Data for Robust Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-main.560) |  | 0 |  | Sathish Indurthi, Shamil Chollampatt, Ravi Agrawal, Marco Turchi |  |
| 1755 |  |  [M2DF: Multi-grained Multi-curriculum Denoising Framework for Multimodal Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.561) |  | 0 |  | Fei Zhao, Chunhui Li, Zhen Wu, Yawen Ouyang, Jianbing Zhang, Xinyu Dai |  |
| 1756 |  |  [Detection of Multiple Mental Disorders from Social Media with Two-Stream Psychiatric Experts](https://doi.org/10.18653/v1/2023.emnlp-main.562) |  | 0 |  | Siyuan Chen, Zhiling Zhang, Mengyue Wu, Kenny Q. Zhu |  |
| 1757 |  |  [Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?](https://doi.org/10.18653/v1/2023.emnlp-main.563) |  | 0 |  | Ahmed Alajrami, Katerina Margatina, Nikolaos Aletras |  |
| 1758 |  |  [Improved Unsupervised Chinese Word Segmentation Using Pre-trained Knowledge and Pseudo-labeling Transfer](https://doi.org/10.18653/v1/2023.emnlp-main.564) |  | 0 |  | HsiuWen Li, YingJia Lin, YiTing Li, Chun Lin, HungYu Kao |  |
| 1759 |  |  [EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.565) |  | 0 |  | Hanlin Tang, Yifu Sun, Decheng Wu, Kai Liu, Jianchen Zhu, Zhanhui Kang |  |
| 1760 |  |  [Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings](https://doi.org/10.18653/v1/2023.emnlp-main.566) |  | 0 |  | Mattia Atzeni, Mikhail Plekhanov, Frédéric A. Dreyer, Nora Kassner, Simone Merello, Louis Martin, Nicola Cancedda |  |
| 1761 |  |  [APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.567) |  | 0 |  | Qifan Wang, Yuning Mao, Jingang Wang, Hanchao Yu, Shaoliang Nie, Sinong Wang, Fuli Feng, Lifu Huang, Xiaojun Quan, Zenglin Xu, Dongfang Liu |  |
| 1762 |  |  [What's "up" with vision-language models? Investigating their struggle with spatial reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.568) |  | 0 |  | Amita Kamath, Jack Hessel, KaiWei Chang |  |
| 1763 |  |  [IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models](https://doi.org/10.18653/v1/2023.emnlp-main.569) |  | 0 |  | Xiaoyue Wang, Xin Liu, Lijie Wang, Yaoxiang Wang, Jinsong Su, Hua Wu |  |
| 1764 |  |  [Learning Preference Model for LLMs via Automatic Preference Data Generation](https://doi.org/10.18653/v1/2023.emnlp-main.570) |  | 0 |  | Shijia Huang, Jianqiao Zhao, Yanyang Li, Liwei Wang |  |
| 1765 |  |  [Multilingual k-Nearest-Neighbor Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.571) |  | 0 |  | David Stap, Christof Monz |  |
| 1766 |  |  [Understanding Computational Models of Semantic Change: New Insights from the Speech Community](https://doi.org/10.18653/v1/2023.emnlp-main.572) |  | 0 |  | Filip Miletic, Anne PrzewoznyDesriaux, Ludovic Tanguy |  |
| 1767 |  |  [Causal Reasoning through Two Cognition Layers for Improving Generalization in Visual Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.573) |  | 0 |  | Trang Nguyen, Naoaki Okazaki |  |
| 1768 |  |  [StructGPT: A General Framework for Large Language Model to Reason over Structured Data](https://doi.org/10.18653/v1/2023.emnlp-main.574) |  | 0 |  | Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Xin Zhao, JiRong Wen |  |
| 1769 |  |  [Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement](https://doi.org/10.18653/v1/2023.emnlp-main.575) |  | 0 |  | Rosamond Elizabeth Thalken, Edward H. Stiglitz, David Mimno, Matthew Wilkens |  |
| 1770 |  |  [Model-tuning Via Prompts Makes NLP Models Adversarially Robust](https://doi.org/10.18653/v1/2023.emnlp-main.576) |  | 0 |  | Mrigank Raman, Pratyush Maini, J. Zico Kolter, Zachary C. Lipton, Danish Pruthi |  |
| 1771 |  |  [Learning Co-Speech Gesture for Multimodal Aphasia Type Detection](https://doi.org/10.18653/v1/2023.emnlp-main.577) |  | 0 |  | Daeun Lee, Sejung Son, Hyolim Jeon, Seungbae Kim, Jinyoung Han |  |
| 1772 |  |  [STINMatch: Semi-Supervised Semantic-Topological Iteration Network for Financial Risk Detection via News Label Diffusion](https://doi.org/10.18653/v1/2023.emnlp-main.578) |  | 0 |  | Xurui Li, Yue Qin, Rui Zhu, Tianqianjin Lin, Yongming Fan, Yangyang Kang, Kaisong Song, Fubang Zhao, Changlong Sun, Haixu Tang, Xiaozhong Liu |  |
| 1773 |  |  [Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection](https://doi.org/10.18653/v1/2023.emnlp-main.579) |  | 0 |  | Vyoma Raman, Eve Fleisig, Dan Klein |  |
| 1774 |  |  [Describe Me an Auklet: Generating Grounded Perceptual Category Descriptions](https://doi.org/10.18653/v1/2023.emnlp-main.580) |  | 0 |  | Bill Noble, Nikolai Ilinykh |  |
| 1775 |  |  [Revisiting Automated Topic Model Evaluation with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.581) |  | 0 |  | Dominik Stammbach, Vilém Zouhar, Alexander Miserlis Hoyle, Mrinmaya Sachan, Elliott Ash |  |
| 1776 |  |  [ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.582) |  | 0 |  | Xiutian Zhao, Ke Wang, Wei Peng |  |
| 1777 |  |  [On the Benefits of Learning to Route in Mixture-of-Experts Models](https://doi.org/10.18653/v1/2023.emnlp-main.583) |  | 0 |  | Nishanth Dikkala, Nikhil Ghosh, Raghu Meka, Rina Panigrahy, Nikhil Vyas, Xin Wang |  |
| 1778 |  |  [SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation](https://doi.org/10.18653/v1/2023.emnlp-main.584) |  | 0 |  | Elizabeth Clark, Shruti Rijhwani, Sebastian Gehrmann, Joshua Maynez, Roee Aharoni, Vitaly Nikolaev, Thibault Sellam, Aditya Siddhant, Dipanjan Das, Ankur P. Parikh |  |
| 1779 |  |  [Query2doc: Query Expansion with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.585) |  | 0 |  | Liang Wang, Nan Yang, Furu Wei |  |
| 1780 |  |  [We Need to Talk About Reproducibility in NLP Model Comparison](https://doi.org/10.18653/v1/2023.emnlp-main.586) |  | 0 |  | Yan Xue, Xuefei Cao, Xingli Yang, Yu Wang, Ruibo Wang, Jihong Li |  |
| 1781 |  |  [Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration](https://doi.org/10.18653/v1/2023.emnlp-main.587) |  | 0 |  | Fanqi Wan, Xinting Huang, Tao Yang, Xiaojun Quan, Wei Bi, Shuming Shi |  |
| 1782 |  |  [Practical Computational Power of Linear Transformers and Their Recurrent and Self-Referential Extensions](https://doi.org/10.18653/v1/2023.emnlp-main.588) |  | 0 |  | Kazuki Irie, Róbert Csordás, Jürgen Schmidhuber |  |
| 1783 |  |  [InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions](https://doi.org/10.18653/v1/2023.emnlp-main.589) |  | 0 |  | Bodhisattwa Prasad Majumder, Zexue He, Julian J. McAuley |  |
| 1784 |  |  [Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts](https://doi.org/10.18653/v1/2023.emnlp-main.590) |  | 0 |  | Jiashu Pu, Ling Cheng, Lu Fan, Tangjie Lv, Rongsheng Zhang |  |
| 1785 |  |  [Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.591) |  | 0 |  | Dmitry Nikolaev, Tanise Ceron, Sebastian Padó |  |
| 1786 |  |  [ART: rule bAsed futuRe-inference deducTion](https://doi.org/10.18653/v1/2023.emnlp-main.592) |  | 0 |  | Mengze Li, Tianqi Zhao, Jionghao Bai, Baoyi He, Jiaxu Miao, Wei Ji, Zheqi Lv, Zhou Zhao, Shengyu Zhang, Wenqiao Zhang, Fei Wu |  |
| 1787 |  |  [EpiK-Eval: Evaluation for Language Models as Epistemic Models](https://doi.org/10.18653/v1/2023.emnlp-main.593) |  | 0 |  | Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar |  |
| 1788 |  |  [From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification](https://doi.org/10.18653/v1/2023.emnlp-main.594) |  | 0 |  | Shanshan Xu, T. Y. S. S. Santosh, Oana Ichim, Isabella Risini, Barbara Plank, Matthias Grabmair |  |
| 1789 |  |  [On Bilingual Lexicon Induction with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.595) |  | 0 |  | Yaoyiran Li, Anna Korhonen, Ivan Vulic |  |
| 1790 |  |  [Statistical Depth for Ranking and Characterizing Transformer-Based Text Embeddings](https://doi.org/10.18653/v1/2023.emnlp-main.596) |  | 0 |  | Parker Seegmiller, Sarah Preum |  |
| 1791 |  |  [CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model](https://doi.org/10.18653/v1/2023.emnlp-main.597) |  | 0 |  | Kaiyan Zhang, Ning Ding, Biqing Qi, Xuekai Zhu, Xinwei Long, Bowen Zhou |  |
| 1792 |  |  [From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues](https://doi.org/10.18653/v1/2023.emnlp-main.598) |  | 0 |  | Shivani Kumar, Ramaneswaran S., Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 1793 |  |  [Large Language Models are biased to overestimate profoundness](https://doi.org/10.18653/v1/2023.emnlp-main.599) |  | 0 |  | Eugenio HerreraBerg, Tomás Vergara Browne, Pablo LeónVillagrá, MarcLluís Vives, Cristian Buc Calderon |  |
| 1794 |  |  [SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.600) |  | 0 |  | Philippe Laban, Wojciech Kryscinski, Divyansh Agarwal, Alexander R. Fabbri, Caiming Xiong, Shafiq Joty, ChienSheng Wu |  |
| 1795 |  |  [DIVE: Towards Descriptive and Diverse Visual Commonsense Generation](https://doi.org/10.18653/v1/2023.emnlp-main.601) |  | 0 |  | JunHyung Park, Hyuntae Park, Youjin Kang, Eojin Jeon, SangKeun Lee |  |
| 1796 |  |  [Towards Conceptualization of "Fair Explanation": Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators](https://doi.org/10.18653/v1/2023.emnlp-main.602) |  | 0 |  | Tin Nguyen, Jiannan Xu, Aayushi Roy, Hal Daumé III, Marine Carpuat |  |
| 1797 |  |  [Bridging Background Knowledge Gaps in Translation with Automatic Explicitation](https://doi.org/10.18653/v1/2023.emnlp-main.603) |  | 0 |  | HyoJung Han, Jordan L. BoydGraber, Marine Carpuat |  |
| 1798 |  |  [A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation](https://doi.org/10.18653/v1/2023.emnlp-main.604) |  | 0 |  | Xue Zhang, Songming Zhang, Yunlong Liang, Yufeng Chen, Jian Liu, Wenjuan Han, Jinan Xu |  |
| 1799 |  |  [Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.605) |  | 0 |  | Di Wu, Christof Monz |  |
| 1800 |  |  [Quantifying the redundancy between prosody and text](https://doi.org/10.18653/v1/2023.emnlp-main.606) |  | 0 |  | Lukas Wolf, Tiago Pimentel, Evelina Fedorenko, Ryan Cotterell, Alex Warstadt, Ethan Wilcox, Tamar Regev |  |
| 1801 |  |  [CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.607) |  | 0 |  | Mete Ismayilzada, Debjit Paul, Syrielle Montariol, Mor Geva, Antoine Bosselut |  |
| 1802 |  |  [A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot](https://doi.org/10.18653/v1/2023.emnlp-main.608) |  | 0 |  | Aanisha Bhattacharyya, Yaman Singla, Balaji Krishnamurthy, Rajiv Ratn Shah, Changyou Chen |  |
| 1803 |  |  [Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.609) |  | 0 |  | Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun |  |
| 1804 |  |  [Prompting Scientific Names for Zero-Shot Species Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.610) |  | 0 |  | Shubham Parashar, Zhiqiu Lin, Yanan Li, Shu Kong |  |
| 1805 |  |  [Active Learning for Natural Language Generation](https://doi.org/10.18653/v1/2023.emnlp-main.611) |  | 0 |  | Yotam Perlitz, Ariel Gera, Michal ShmueliScheuer, Dafna Sheinwald, Noam Slonim, Liat EinDor |  |
| 1806 |  |  [Re³Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training](https://doi.org/10.18653/v1/2023.emnlp-main.612) |  | 0 |  | Jiaxin Wen, Hao Zhou, Jian Guan, Jie Zhou, Minlie Huang |  |
| 1807 |  |  [MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup](https://doi.org/10.18653/v1/2023.emnlp-main.613) |  | 0 |  | Hua Shen, Vicky Zayats, Johann C. Rocholl, Daniel D. Walker, Dirk Padfield |  |
| 1808 |  |  [Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.614) |  | 0 |  | Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov |  |
| 1809 |  |  [Characterizing Mechanisms for Factual Recall in Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.615) |  | 0 |  | Qinan Yu, Jack Merullo, Ellie Pavlick |  |
| 1810 |  |  [MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark](https://doi.org/10.18653/v1/2023.emnlp-main.616) |  | 0 |  | Dominik Macko, Róbert Móro, Adaku Uchendu, Jason Samuel Lucas, Michiharu Yamashita, Matús Pikuliak, Ivan Srba, Thai Le, Dongwon Lee, Jakub Simko, Mária Bieliková |  |
| 1811 |  |  [Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?](https://doi.org/10.18653/v1/2023.emnlp-main.617) |  | 0 |  | Cheng Zhang, Jianyi Cheng, Ilia Shumailov, George A. Constantinides, Yiren Zhao |  |
| 1812 |  |  [Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.618) |  | 0 |  | Srijith Radhakrishnan, ChaoHan Huck Yang, Sumeer Ahmad Khan, Rohit Kumar, Narsis A. Kiani, David GomezCabrero, Jesper Tegnér |  |
| 1813 |  |  [Reducing Sequence Length by Predicting Edit Spans with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.619) |  | 0 |  | Masahiro Kaneko, Naoaki Okazaki |  |
| 1814 |  |  [Instruct and Extract: Instruction Tuning for On-Demand Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.620) |  | 0 |  | Yizhu Jiao, Ming Zhong, Sha Li, Ruining Zhao, Siru Ouyang, Heng Ji, Jiawei Han |  |
| 1815 |  |  [Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.621) |  | 0 |  | Xiaolei Wang, Xinyu Tang, Xin Zhao, Jingyuan Wang, JiRong Wen |  |
| 1816 |  |  [ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness](https://doi.org/10.18653/v1/2023.emnlp-main.622) |  | 0 |  | Archiki Prasad, Swarnadeep Saha, Xiang Zhou, Mohit Bansal |  |
| 1817 |  |  [Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking](https://doi.org/10.18653/v1/2023.emnlp-main.623) |  | 0 |  | Arian Askari, Mohammad Aliannejadi, Chuan Meng, Evangelos Kanoulas, Suzan Verberne |  |
| 1818 |  |  [Transformer-based Live Update Generation for Soccer Matches from Microblog Posts](https://doi.org/10.18653/v1/2023.emnlp-main.624) |  | 0 |  | Masashi Oshika, Kosuke Yamada, Ryohei Sasano, Koichi Takeda |  |
| 1819 |  |  [Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets](https://doi.org/10.18653/v1/2023.emnlp-main.625) |  | 0 |  | Irina Bejan, Artem Sokolov, Katja Filippova |  |
| 1820 |  |  [Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews](https://doi.org/10.18653/v1/2023.emnlp-main.626) |  | 0 |  | Hye Sun Yun, Iain James Marshall, Thomas A. Trikalinos, Byron C. Wallace |  |
| 1821 |  |  [PromptST: Abstract Prompt Learning for End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-main.627) |  | 0 |  | Tengfei Yu, Liang Ding, Xuebo Liu, Kehai Chen, Meishan Zhang, Dacheng Tao, Min Zhang |  |
| 1822 |  |  [Text Rendering Strategies for Pixel Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.628) |  | 0 |  | Jonas F. Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott |  |
| 1823 |  |  [APoLLo : Unified Adapter and Prompt Learning for Vision Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.629) |  | 0 |  | Sanjoy Chowdhury, Sayan Nag, Dinesh Manocha |  |
| 1824 |  |  [SAMRank: Unsupervised Keyphrase Extraction using Self-Attention Map in BERT and GPT-2](https://doi.org/10.18653/v1/2023.emnlp-main.630) |  | 0 |  | Byungha Kang, Youhyun Shin |  |
| 1825 |  |  [Contrastive Learning for Inference in Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.631) |  | 0 |  | Etsuko Ishii, Yan Xu, Bryan Wilie, Ziwei Ji, Holy Lovenia, Willy Chung, Pascale Fung |  |
| 1826 |  |  [Editing Large Language Models: Problems, Methods, and Opportunities](https://doi.org/10.18653/v1/2023.emnlp-main.632) |  | 0 |  | Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, Ningyu Zhang |  |
| 1827 |  |  [MarkQA: A large scale KBQA dataset with numerical reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.633) |  | 0 |  | Xiang Huang, Sitao Cheng, Yuheng Bao, Shanshan Huang, Yuzhong Qu |  |
| 1828 |  |  [Comparing Biases and the Impact of Multilingual Training across Multiple Languages](https://doi.org/10.18653/v1/2023.emnlp-main.634) |  | 0 |  | Sharon Levy, Neha Anna John, Ling Liu, Yogarshi Vyas, Jie Ma, Yoshinari Fujinuma, Miguel Ballesteros, Vittorio Castelli, Dan Roth |  |
| 1829 |  |  [HutCRS: Hierarchical User-Interest Tracking for Conversational Recommender System](https://doi.org/10.18653/v1/2023.emnlp-main.635) |  | 0 |  | Mingjie Qian, Yongsen Zheng, Jinghui Qin, Liang Lin |  |
| 1830 |  |  [Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.636) |  | 0 |  | Xiaoshuai Song, Keqing He, Pei Wang, Guanting Dong, Yutao Mou, Jingang Wang, Yunsen Xian, Xunliang Cai, Weiran Xu |  |
| 1831 |  |  [The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining](https://doi.org/10.18653/v1/2023.emnlp-main.637) |  | 0 |  | TingRui Chiang, Dani Yogatama |  |
| 1832 |  |  [Simple and Effective Input Reformulations for Translation](https://doi.org/10.18653/v1/2023.emnlp-main.638) |  | 0 |  | Brian Yu, Hansen Lillemark, Kurt Keutzer |  |
| 1833 |  |  [Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs](https://doi.org/10.18653/v1/2023.emnlp-main.639) |  | 0 |  | Yatin Nandwani, Vineet Kumar, Dinesh Raghu, Sachindra Joshi, Luis A. Lastras |  |
| 1834 |  |  [The ACL OCL Corpus: Advancing Open Science in Computational Linguistics](https://doi.org/10.18653/v1/2023.emnlp-main.640) |  | 0 |  | Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, MinYen Kan |  |
| 1835 |  |  [Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.641) |  | 0 |  | Lina Conti, Guillaume Wisniewski |  |
| 1836 |  |  [Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset](https://doi.org/10.18653/v1/2023.emnlp-main.642) |  | 0 |  | Arthur Amalvy, Vincent Labatut, Richard Dufour |  |
| 1837 |  |  [Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting](https://doi.org/10.18653/v1/2023.emnlp-main.643) |  | 0 |  | Preethi Lahoti, Nicholas Blumm, Xiao Ma, Raghavendra Kotikalapudi, Sahitya Potluri, Qijun Tan, Hansa Srinivasan, Ben Packer, Ahmad Beirami, Alex Beutel, Jilin Chen |  |
| 1838 |  |  [Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection](https://doi.org/10.18653/v1/2023.emnlp-main.644) |  | 0 |  | Xinlin Peng, Ying Zhou, Ben He, Le Sun, Yingfei Sun |  |
| 1839 |  |  [Contextual Interaction for Argument Post Quality Assessment](https://doi.org/10.18653/v1/2023.emnlp-main.645) |  | 0 |  | Yiran Wang, Xuanang Chen, Ben He, Le Sun |  |
| 1840 |  |  [Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification](https://doi.org/10.18653/v1/2023.emnlp-main.646) |  | 0 |  | Mujeen Sung, James Gung, Elman Mansimov, Nikolaos Pappas, Raphael Shu, Salvatore Romeo, Yi Zhang, Vittorio Castelli |  |
| 1841 |  |  [Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations](https://doi.org/10.18653/v1/2023.emnlp-main.647) |  | 0 |  | Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, Ming Yin |  |
| 1842 |  |  [GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations](https://doi.org/10.18653/v1/2023.emnlp-main.648) |  | 0 |  | Muhammet Furkan Ilaslan, Chenan Song, Joya Chen, Difei Gao, Weixian Lei, Qianli Xu, Joo Lim, Mike Zheng Shou |  |
| 1843 |  |  [People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection](https://doi.org/10.18653/v1/2023.emnlp-main.649) |  | 0 |  | Indira Sen, Dennis Assenmacher, Mattia Samory, Isabelle Augenstein, Wil M. P. van der Aalst, Claudia Wagner |  |
| 1844 |  |  [Unraveling Feature Extraction Mechanisms in Neural Networks](https://doi.org/10.18653/v1/2023.emnlp-main.650) |  | 0 |  | Xiaobing Sun, Jiaxi Li, Wei Lu |  |
| 1845 |  |  [CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion](https://doi.org/10.18653/v1/2023.emnlp-main.651) |  | 0 |  | Xingwei He, Yeyun Gong, ALong Jin, Hang Zhang, Anlei Dong, Jian Jiao, SiuMing Yiu, Nan Duan |  |
| 1846 |  |  [Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and Gallery Banks](https://doi.org/10.18653/v1/2023.emnlp-main.652) |  | 0 |  | Yimu Wang, Xiangru Jian, Bo Xue |  |
| 1847 |  |  [E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation](https://doi.org/10.18653/v1/2023.emnlp-main.653) |  | 0 |  | Fengyi Fu, Lei Zhang, Quan Wang, Zhendong Mao |  |
| 1848 |  |  [What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies](https://doi.org/10.18653/v1/2023.emnlp-main.654) |  | 0 |  | Amit Gajbhiye, Zied Bouraoui, Na Li, Usashi Chatterjee, Luis Espinosa Anke, Steven Schockaert |  |
| 1849 |  |  [ALDi: Quantifying the Arabic Level of Dialectness of Text](https://doi.org/10.18653/v1/2023.emnlp-main.655) |  | 0 |  | Amr Keleg, Sharon Goldwater, Walid Magdy |  |
| 1850 |  |  [3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding](https://doi.org/10.18653/v1/2023.emnlp-main.656) |  | 0 |  | Zehan Wang, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu, Aoxiong Yin, Zhou Zhao |  |
| 1851 |  |  [Goal-Driven Explainable Clustering via Language Descriptions](https://doi.org/10.18653/v1/2023.emnlp-main.657) |  | 0 |  | Zihan Wang, Jingbo Shang, Ruiqi Zhong |  |
| 1852 |  |  [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.658) |  | 0 |  | Jirui Qi, Raquel Fernández, Arianna Bisazza |  |
| 1853 |  |  [Learning from Mistakes via Cooperative Study Assistant for Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.659) |  | 0 |  | Danqing Wang, Lei Li |  |
| 1854 |  |  [Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.660) |  | 0 |  | Joan Nwatu, Oana Ignat, Rada Mihalcea |  |
| 1855 |  |  [Conceptor-Aided Debiasing of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.661) |  | 0 |  | Yifei Li, Lyle H. Ungar, João Sedoc |  |
| 1856 |  |  [AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing Evaluation Suite](https://doi.org/10.18653/v1/2023.emnlp-main.662) |  | 0 |  | Jonas Groschwitz, Shay B. Cohen, Lucia Donatelli, Meaghan Fowlie |  |
| 1857 |  |  [Rethinking and Improving Multi-task Learning for End-to-end Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-main.663) |  | 0 |  | Yuhao Zhang, Chen Xu, Bei Li, Hao Chen, Tong Xiao, Chunliang Zhang, Jingbo Zhu |  |
| 1858 |  |  [AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing](https://doi.org/10.18653/v1/2023.emnlp-main.664) |  | 0 |  | Matei Bejan, Andrei Manolache, Marius Popescu |  |
| 1859 |  |  [Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors](https://doi.org/10.18653/v1/2023.emnlp-main.665) |  | 0 |  | George Zerveas, Navid Rekabsaz, Carsten Eickhoff |  |
| 1860 |  |  [Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework](https://doi.org/10.18653/v1/2023.emnlp-main.666) |  | 0 |  | Ruike Zhang, Hanxuan Yang, Wenji Mao |  |
| 1861 |  |  [PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs](https://doi.org/10.18653/v1/2023.emnlp-main.667) |  | 0 |  | Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang, HyunJeong Choe, David Greene, Chuan He, Rattima Nitisaroj, Anna Trukhina, Shachi Paul, Pararth Shah, Rushin Shah, Zhou Yu |  |
| 1862 |  |  [An Iteratively Parallel Generation Method with the Pre-Filling Strategy for Document-level Event Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.668) |  | 0 |  | Guanhua Huang, Runxin Xu, Ying Zeng, Jiaze Chen, Zhouwang Yang, Weinan E |  |
| 1863 |  |  [CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations](https://doi.org/10.18653/v1/2023.emnlp-main.669) |  | 0 |  | Myra Cheng, Tiziano Piccardi, Diyi Yang |  |
| 1864 |  |  [Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach](https://doi.org/10.18653/v1/2023.emnlp-main.670) |  | 0 |  | Chen Huang, Peixin Qin, Wenqiang Lei, Jiancheng Lv |  |
| 1865 |  |  [BERTie Bott's Every Flavor Labels: A Tasty Introduction to Semantic Role Labeling for Galician](https://doi.org/10.18653/v1/2023.emnlp-main.671) |  | 0 |  | Micaella Bruton, Meriem Beloucif |  |
| 1866 |  |  [Program Translation via Code Distillation](https://doi.org/10.18653/v1/2023.emnlp-main.672) |  | 0 |  | Yufan Huang, Mengnan Qi, Yongqiang Yao, Maoquan Wang, Bin Gu, Colin B. Clement, Neel Sundaresan |  |
| 1867 |  |  [FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.673) |  | 0 |  | Nan Zhang, Yusen Zhang, Wu Guo, Prasenjit Mitra, Rui Zhang |  |
| 1868 |  |  [Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning](https://doi.org/10.18653/v1/2023.emnlp-main.674) |  | 0 |  | Saibo Geng, Martin Josifoski, Maxime Peyrard, Robert West |  |
| 1869 |  |  [Systematic word meta-sense extension](https://doi.org/10.18653/v1/2023.emnlp-main.675) |  | 0 |  | Lei Yu |  |
| 1870 |  |  [Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory](https://doi.org/10.18653/v1/2023.emnlp-main.676) |  | 0 |  | Ziang Xiao, Susu Zhang, Vivian Lai, Q. Vera Liao |  |
| 1871 |  |  [Revisiting the Knowledge Injection Frameworks](https://doi.org/10.18653/v1/2023.emnlp-main.677) |  | 0 |  | Peng Fu, Yiming Zhang, Haobo Wang, Weikang Qiu, Junbo Zhao |  |
| 1872 |  |  [We Are What We Repeatedly Do: Inducing and Deploying Habitual Schemas in Persona-Based Responses](https://doi.org/10.18653/v1/2023.emnlp-main.678) |  | 0 |  | Benjamin Kane, Lenhart K. Schubert |  |
| 1873 |  |  [Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model](https://doi.org/10.18653/v1/2023.emnlp-main.679) |  | 0 |  | Qi Jia, Siyu Ren, Yizhu Liu, Kenny Q. Zhu |  |
| 1874 |  |  [TaskWeb: Selecting Better Source Tasks for Multi-task NLP](https://doi.org/10.18653/v1/2023.emnlp-main.680) |  | 0 |  | Joongwon Kim, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi |  |
| 1875 |  |  [Improving Bias Mitigation through Bias Experts in Natural Language Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.681) |  | 0 |  | Eojin Jeon, Mingyu Lee, Juhyeong Park, Yeachan Kim, WingLam Mok, SangKeun Lee |  |
| 1876 |  |  [Semi-supervised multimodal coreference resolution in image narrations](https://doi.org/10.18653/v1/2023.emnlp-main.682) |  | 0 |  | Arushi Goel, Basura Fernando, Frank Keller, Hakan Bilen |  |
| 1877 |  |  [A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.683) |  | 0 |  | Yi Zhou, José CamachoCollados, Danushka Bollegala |  |
| 1878 |  |  [Argument-based Detection and Classification of Fallacies in Political Debates](https://doi.org/10.18653/v1/2023.emnlp-main.684) |  | 0 |  | Pierpaolo Goffredo, Mariana Espinoza, Serena Villata, Elena Cabrio |  |
| 1879 |  |  [Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation](https://doi.org/10.18653/v1/2023.emnlp-main.685) |  | 0 |  | Wanrong Zhu, Xinyi Wang, Yujie Lu, TsuJui Fu, Xin Wang, Miguel P. Eckstein, William Wang |  |
| 1880 |  |  [SpEL: Structured Prediction for Entity Linking](https://doi.org/10.18653/v1/2023.emnlp-main.686) |  | 0 |  | Hassan Shavarani, Anoop Sarkar |  |
| 1881 |  |  [Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It's Best to Relate Perspectives!](https://doi.org/10.18653/v1/2023.emnlp-main.687) |  | 0 |  | Philipp Heinisch, Matthias Orlikowski, Julia Romberg, Philipp Cimiano |  |
| 1882 |  |  [Explicit Planning Helps Language Models in Logical Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.688) |  | 0 |  | Hongyu Zhao, Kangrui Wang, Mo Yu, Hongyuan Mei |  |
| 1883 |  |  [clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents](https://doi.org/10.18653/v1/2023.emnlp-main.689) |  | 0 |  | Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov, Brielen Madureira, Philipp Sadler, David Schlangen |  |
| 1884 |  |  [Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences](https://doi.org/10.18653/v1/2023.emnlp-main.690) |  | 0 |  | Eleftheria Briakou, Navita Goyal, Marine Carpuat |  |
| 1885 |  |  [Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models](https://doi.org/10.18653/v1/2023.emnlp-main.691) |  | 0 |  | Tim Schott, Daniel Furman, Shreshta Bhat |  |
| 1886 |  |  [Anchoring Fine-tuning of Sentence Transformer with Semantic Label Information for Efficient Truly Few-shot Classification](https://doi.org/10.18653/v1/2023.emnlp-main.692) |  | 0 |  | Amalie Brogaard Pauli, Leon Derczynski, Ira Assent |  |
| 1887 |  |  [UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers](https://doi.org/10.18653/v1/2023.emnlp-main.693) |  | 0 |  | Jon SaadFalcon, Omar Khattab, Keshav Santhanam, Radu Florian, Martin Franz, Salim Roukos, Avirup Sil, Md. Arafat Sultan, Christopher Potts |  |
| 1888 |  |  [TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings](https://doi.org/10.18653/v1/2023.emnlp-main.694) |  | 0 |  | Hans W. A. Hanley, Zakir Durumeric |  |
| 1889 |  |  [Data Similarity is Not Enough to Explain Language Model Performance](https://doi.org/10.18653/v1/2023.emnlp-main.695) |  | 0 |  | Gregory Yauney, Emily Reif, David Mimno |  |
| 1890 |  |  [Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.696) |  | 0 |  | Miaoxi Zhu, Qihuang Zhong, Li Shen, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao |  |
| 1891 |  |  [Deciphering Stereotypes in Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.697) |  | 0 |  | Weicheng Ma, Henry Scheible, Brian Wang, Goutham Veeramachaneni, Pratim Chowdhary, Alan Sun, Andrew Koulogeorge, Lili Wang, Diyi Yang, Soroush Vosoughi |  |
| 1892 |  |  [An "Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives"](https://doi.org/10.18653/v1/2023.emnlp-main.698) |  | 0 |  | Young Min Cho, Sunny Rai, Lyle H. Ungar, João Sedoc, Sharath Chandra Guntuku |  |
| 1893 |  |  [Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark](https://doi.org/10.18653/v1/2023.emnlp-main.699) |  | 0 |  | Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, David Jurgens |  |
| 1894 |  |  [Interventional Rationalization](https://doi.org/10.18653/v1/2023.emnlp-main.700) |  | 0 |  | Linan Yue, Qi Liu, Li Wang, Yanqing An, Yichao Du, Zhenya Huang |  |
| 1895 |  |  [Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting](https://doi.org/10.18653/v1/2023.emnlp-main.701) |  | 0 |  | Akhila Yerukola, Xuhui Zhou, Elizabeth Clark, Maarten Sap |  |
| 1896 |  |  [Axiomatic Preference Modeling for Longform Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.702) |  | 0 |  | Corby Rosset, Guoqing Zheng, Victor Dibia, Ahmed Awadallah, Paul N. Bennett |  |
| 1897 |  |  [Countering Misinformation via Emotional Response Generation](https://doi.org/10.18653/v1/2023.emnlp-main.703) |  | 0 |  | Daniel Russo, Shane P. KaszefskiYaschuk, Jacopo Staiano, Marco Guerini |  |
| 1898 |  |  [Seq2seq is All You Need for Coreference Resolution](https://doi.org/10.18653/v1/2023.emnlp-main.704) |  | 0 |  | Wenzheng Zhang, Sam Wiseman, Karl Stratos |  |
| 1899 |  |  [Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection](https://doi.org/10.18653/v1/2023.emnlp-main.705) |  | 0 |  | Dennis Fucci, Marco Gaido, Sara Papi, Mauro Cettolo, Matteo Negri, Luisa Bentivogli |  |
| 1900 |  |  [StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.706) |  | 0 |  | Cheng Jiayang, Lin Qiu, Tsz Ho Chan, Tianqing Fang, Weiqi Wang, Chunkit Chan, Dongyu Ru, Qipeng Guo, Hongming Zhang, Yangqiu Song, Yue Zhang, Zheng Zhang |  |
| 1901 |  |  [Beyond Detection: A Defend-and-Summarize Strategy for Robust and Interpretable Rumor Analysis on Social Media](https://doi.org/10.18653/v1/2023.emnlp-main.707) |  | 0 |  | YiTing Chang, YunZhu Song, YiSyuan Chen, HongHan Shuai |  |
| 1902 |  |  [Crystal: Introspective Reasoners Reinforced with Self-Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.708) |  | 0 |  | Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, Asli Celikyilmaz |  |
| 1903 |  |  [DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation](https://doi.org/10.18653/v1/2023.emnlp-main.709) |  | 0 |  | Yongxin Zhu, Zhujin Gao, Xinyuan Zhou, Zhongyi Ye, Linli Xu |  |
| 1904 |  |  [BioFEG: Generate Latent Features for Biomedical Entity Linking](https://doi.org/10.18653/v1/2023.emnlp-main.710) |  | 0 |  | Xuhui Sui, Ying Zhang, Xiangrui Cai, Kehui Song, Baohang Zhou, Xiaojie Yuan, Wensheng Zhang |  |
| 1905 |  |  [TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.711) |  | 0 |  | Jing Xiong, Jianhao Shen, Ye Yuan, Haiming Wang, Yichun Yin, Zhengying Liu, Lin Li, Zhijiang Guo, Qingxing Cao, Yinya Huang, Chuanyang Zheng, Xiaodan Liang, Ming Zhang, Qun Liu |  |
| 1906 |  |  [Physician Detection of Clinical Harm in Machine Translation: Quality Estimation Aids in Reliance and Backtranslation Identifies Critical Errors](https://doi.org/10.18653/v1/2023.emnlp-main.712) |  | 0 |  | Nikita Mehandru, Sweta Agrawal, Yimin Xiao, Ge Gao, Elaine C. Khoong, Marine Carpuat, Niloufar Salehi |  |
| 1907 |  |  [Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive](https://doi.org/10.18653/v1/2023.emnlp-main.713) |  | 0 |  | Tharindu Cyril Weerasooriya, Sujan Dutta, Tharindu Ranasinghe, Marcos Zampieri, Christopher Homan, Ashiqur R. KhudaBukhsh |  |
| 1908 |  |  [Generating Summaries with Controllable Readability Levels](https://doi.org/10.18653/v1/2023.emnlp-main.714) |  | 0 |  | Leonardo F. R. Ribeiro, Mohit Bansal, Markus Dreyer |  |
| 1909 |  |  [mAggretriever: A Simple yet Effective Approach to Zero-Shot Multilingual Dense Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.715) |  | 0 |  | ShengChieh Lin, Amin Ahmad, Jimmy Lin |  |
| 1910 |  |  [CodeFusion: A Pre-trained Diffusion Model for Code Generation](https://doi.org/10.18653/v1/2023.emnlp-main.716) |  | 0 |  | Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, Gust Verbruggen |  |
| 1911 |  |  [CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs](https://doi.org/10.18653/v1/2023.emnlp-main.717) |  | 0 |  | Taha Aksu, Devamanyu Hazarika, Shikib Mehri, Seokhwan Kim, Dilek HakkaniTur, Yang Liu, Mahdi Namazifar |  |
| 1912 |  |  [VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights](https://doi.org/10.18653/v1/2023.emnlp-main.718) |  | 0 |  | Shanshan Xu, Leon Staufer, T. Y. S. S. Santosh, Oana Ichim, Corina Heri, Matthias Grabmair |  |
| 1913 |  |  [ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos](https://doi.org/10.18653/v1/2023.emnlp-main.719) |  | 0 |  | TeLin Wu, ZiYi Dou, Qingyuan Hu, Yu Hou, Nischal Reddy Chandra, Marjorie Freedman, Ralph M. Weischedel, Nanyun Peng |  |
| 1914 |  |  [From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base](https://doi.org/10.18653/v1/2023.emnlp-main.720) |  | 0 |  | Wangzhen Guo, Linyin Luo, Hanjiang Lai, Jian Yin |  |
| 1915 |  |  [Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model](https://doi.org/10.18653/v1/2023.emnlp-main.721) |  | 0 |  | Haikang Deng, Colin Raffel |  |
| 1916 |  |  [CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation](https://doi.org/10.18653/v1/2023.emnlp-main.722) |  | 0 |  | Philipp Borchert, Jochen De Weerdt, Kristof Coussement, Arno De Caigny, MarieFrancine Moens |  |
| 1917 |  |  [Models See Hallucinations: Evaluating the Factuality in Video Captioning](https://doi.org/10.18653/v1/2023.emnlp-main.723) |  | 0 |  | Hui Liu, Xiaojun Wan |  |
| 1918 |  |  [Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors](https://doi.org/10.18653/v1/2023.emnlp-main.724) |  | 0 |  | Marek Kubis, Pawel Skórzewski, Marcin Sowanski, Tomasz Zietkiewicz |  |
| 1919 |  |  [Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces](https://doi.org/10.18653/v1/2023.emnlp-main.725) |  | 0 |  | Usashi Chatterjee, Amit Gajbhiye, Steven Schockaert |  |
| 1920 |  |  [Can Language Models Understand Physical Concepts?](https://doi.org/10.18653/v1/2023.emnlp-main.726) |  | 0 |  | Lei Li, Jingjing Xu, Qingxiu Dong, Ce Zheng, Xu Sun, Lingpeng Kong, Qi Liu |  |
| 1921 |  |  [SPT: Learning to Selectively Insert Prompts for Better Prompt Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.727) |  | 0 |  | Wei Zhu, Ming Tan |  |
| 1922 |  |  [Once Upon a Time in Graph: Relative-Time Pretraining for Complex Temporal Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.728) |  | 0 |  | Sen Yang, Xin Li, Lidong Bing, Wai Lam |  |
| 1923 |  |  [Expository Text Generation: Imitate, Retrieve, Paraphrase](https://doi.org/10.18653/v1/2023.emnlp-main.729) |  | 0 |  | Nishant Balepur, Jie Huang, Kevin ChenChuan Chang |  |
| 1924 |  |  [Large-scale similarity search with Optimal Transport](https://doi.org/10.18653/v1/2023.emnlp-main.730) |  | 0 |  | Cléa Laouar, Yuki Takezawa, Makoto Yamada |  |
| 1925 |  |  [Enhancing Textbooks with Visuals from the Web for Improved Learning](https://doi.org/10.18653/v1/2023.emnlp-main.731) |  | 0 |  | Janvijay Singh, Vilém Zouhar, Mrinmaya Sachan |  |
| 1926 |  |  [Continual Event Extraction with Semantic Confusion Rectification](https://doi.org/10.18653/v1/2023.emnlp-main.732) |  | 0 |  | Zitao Wang, Xinyi Wang, Wei Hu |  |
| 1927 |  |  [An Empirical Study of Translation Hypothesis Ensembling with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.733) |  | 0 |  | António Farinhas, José Guilherme Camargo de Souza, André F. T. Martins |  |
| 1928 |  |  [FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning](https://doi.org/10.18653/v1/2023.emnlp-main.734) |  | 0 |  | Jaemin Shin, Hyungjun Yoon, Seungjoo Lee, Sungjoon Park, Yunxin Liu, Jinho D. Choi, SungJu Lee |  |
| 1929 |  |  [Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.735) |  | 0 |  | Geewook Kim, Hodong Lee, Daehee Kim, Haeji Jung, Sanghee Park, Yoonsik Kim, Sangdoo Yun, Taeho Kil, Bado Lee, Seunghyun Park |  |
| 1930 |  |  [Continual Learning for Multilingual Neural Machine Translation via Dual Importance-based Model Division](https://doi.org/10.18653/v1/2023.emnlp-main.736) |  | 0 |  | Junpeng Liu, Kaiyu Huang, Hao Yu, Jiuyi Li, Jinsong Su, Degen Huang |  |
| 1931 |  |  [SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives](https://doi.org/10.18653/v1/2023.emnlp-main.737) |  | 0 |  | Jiahao Xu, Wei Shao, Lihui Chen, Lemao Liu |  |
| 1932 |  |  [Unlearn What You Want to Forget: Efficient Unlearning for LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.738) |  | 0 |  | Jiaao Chen, Diyi Yang |  |
| 1933 |  |  [Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification](https://doi.org/10.18653/v1/2023.emnlp-main.739) |  | 0 |  | Liam Cripwell, Joël Legrand, Claire Gardent |  |
| 1934 |  |  [Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration](https://doi.org/10.18653/v1/2023.emnlp-main.740) |  | 0 |  | Yiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, Kun Kuang |  |
| 1935 |  |  [FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.741) |  | 0 |  | Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wentau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, Hannaneh Hajishirzi |  |
| 1936 |  |  [Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems](https://doi.org/10.18653/v1/2023.emnlp-main.742) |  | 0 |  | Marek Kadlcík, Michal Stefánik, Ondrej Sotolár, Vlastimil Martinek |  |
| 1937 |  |  [CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.743) |  | 0 |  | Hoang Nguyen, Ye Liu, Chenwei Zhang, Tao Zhang, Philip S. Yu |  |
| 1938 |  |  [When Language Models Fall in Love: Animacy Processing in Transformer Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.744) |  | 0 |  | Michael Hanna, Yonatan Belinkov, Sandro Pezzelle |  |
| 1939 |  |  [Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs](https://doi.org/10.18653/v1/2023.emnlp-main.745) |  | 0 |  | Qing Wang, Kang Zhou, Qiao Qiao, Yuepei Li, Qi Li |  |
| 1940 |  |  [Paraphrase Types for Generation and Detection](https://doi.org/10.18653/v1/2023.emnlp-main.746) |  | 0 |  | Jan Philip Wahle, Bela Gipp, Terry Ruas |  |
| 1941 |  |  [Target-to-Source Augmentation for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.747) |  | 0 |  | Yice Zhang, Yifan Yang, Meng Li, Bin Liang, Shiwei Chen, Ruifeng Xu |  |
| 1942 |  |  [PAC-tuning: Fine-tuning Pre-trained Language Models with PAC-driven Perturbed Gradient Descent](https://doi.org/10.18653/v1/2023.emnlp-main.748) |  | 0 |  | Guangliang Liu, Zhiyu Xue, Xitong Zhang, Kristen Marie Johnson, Rongrong Wang |  |
| 1943 |  |  [Emergence of Abstract State Representations in Embodied Sequence Modeling](https://doi.org/10.18653/v1/2023.emnlp-main.749) |  | 0 |  | Tian Yun, Zilai Zeng, Kunal Handa, Ashish V. Thapliyal, Bo Pang, Ellie Pavlick, Chen Sun |  |
| 1944 |  |  [Accelerating Toeplitz Neural Network with Constant-time Inference Complexity](https://doi.org/10.18653/v1/2023.emnlp-main.750) |  | 0 |  | Zhen Qin, Yiran Zhong |  |
| 1945 |  |  [Dissecting Recall of Factual Associations in Auto-Regressive Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.751) |  | 0 |  | Mor Geva, Jasmijn Bastings, Katja Filippova, Amir Globerson |  |
| 1946 |  |  [StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.752) |  | 0 |  | Sullam Jeoung, Yubin Ge, Jana Diesner |  |
| 1947 |  |  [Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations](https://doi.org/10.18653/v1/2023.emnlp-main.753) |  | 0 |  | MinhQuang Pham, Sathish Indurthi, Shamil Chollampatt, Marco Turchi |  |
| 1948 |  |  [Human Raters Cannot Distinguish English Translations from Original English Texts](https://doi.org/10.18653/v1/2023.emnlp-main.754) |  | 0 |  | Shira Wein |  |
| 1949 |  |  [Impressions: Visual Semiotics and Aesthetic Impact Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.755) |  | 0 |  | Julia Kruk, Caleb Ziems, Diyi Yang |  |
| 1950 |  |  [DNA: Denoised Neighborhood Aggregation for Fine-grained Category Discovery](https://doi.org/10.18653/v1/2023.emnlp-main.756) |  | 0 |  | Wenbin An, Feng Tian, Wenkai Shi, Yan Chen, Qinghua Zheng, Qianying Wang, Ping Chen |  |
| 1951 |  |  [Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.757) |  | 0 |  | Shuai Zhao, Jinming Wen, Anh Tuan Luu, Junbo Zhao, Jie Fu |  |
| 1952 |  |  [UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation](https://doi.org/10.18653/v1/2023.emnlp-main.758) |  | 0 |  | Daixuan Cheng, Shaohan Huang, Junyu Bi, Yuefeng Zhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu Wei, Weiwei Deng, Qi Zhang |  |
| 1953 |  |  [KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning](https://doi.org/10.18653/v1/2023.emnlp-main.759) |  | 0 |  | Xiao Yu, Qingyang Wu, Kun Qian, Zhou Yu |  |
| 1954 |  |  [Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU](https://doi.org/10.18653/v1/2023.emnlp-main.760) |  | 0 |  | Fajri Koto, Nurul Aisyah, Haonan Li, Timothy Baldwin |  |
| 1955 |  |  [Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.761) |  | 0 |  | Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam |  |
| 1956 |  |  [Bridging Information-Theoretic and Geometric Compression in Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.762) |  | 0 |  | Emily Cheng, Corentin Kervadec, Marco Baroni |  |
| 1957 |  |  [Pre-training Language Models for Comparative Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.763) |  | 0 |  | Mengxia Yu, Zhihan Zhang, Wenhao Yu, Meng Jiang |  |
| 1958 |  |  [Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search](https://doi.org/10.18653/v1/2023.emnlp-main.764) |  | 0 |  | Xiang Geng, Yu Zhang, Zhejian Lai, Shuaijie She, Wei Zou, Shimin Tao, Hao Yang, Jiajun Chen, Shujian Huang |  |
| 1959 |  |  [Text Embeddings Reveal (Almost) As Much As Text](https://doi.org/10.18653/v1/2023.emnlp-main.765) |  | 0 |  | John X. Morris, Volodymyr Kuleshov, Vitaly Shmatikov, Alexander M. Rush |  |
| 1960 |  |  [AutoTrial: Prompting Language Models for Clinical Trial Design](https://doi.org/10.18653/v1/2023.emnlp-main.766) |  | 0 |  | Zifeng Wang, Cao Xiao, Jimeng Sun |  |
| 1961 |  |  [Faster Minimum Bayes Risk Decoding with Confidence-based Pruning](https://doi.org/10.18653/v1/2023.emnlp-main.767) |  | 0 |  | Julius Cheng, Andreas Vlachos |  |
| 1962 |  |  [Enhancing Generative Retrieval with Reinforcement Learning from Relevance Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.768) |  | 0 |  | Yujia Zhou, Zhicheng Dou, JiRong Wen |  |
| 1963 |  |  [Multi-Source Probing for Open-Domain Conversational Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.769) |  | 0 |  | Yuanxi Li, Hao Zhou, Jie Zhou, Minlie Huang |  |
| 1964 |  |  [Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.770) |  | 0 |  | Xiao Shi, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li |  |
| 1965 |  |  [Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation](https://doi.org/10.18653/v1/2023.emnlp-main.771) |  | 0 |  | Xuanfan Ni, Hongliang Dai, Zhaochun Ren, Piji Li |  |
| 1966 |  |  [Focus Your Attention (with Adaptive IIR Filters)](https://doi.org/10.18653/v1/2023.emnlp-main.772) |  | 0 |  | Shahar Lutati, Itamar Zimerman, Lior Wolf |  |
| 1967 |  |  [Identifying Statements Crucial for Awareness of Interpretive Nonsense to Prevent Communication Breakdowns](https://doi.org/10.18653/v1/2023.emnlp-main.773) |  | 0 |  | Tomoyuki Maekawa, Michita Imai |  |
| 1968 |  |  [Multilingual Large Language Models Are Not (Yet) Code-Switchers](https://doi.org/10.18653/v1/2023.emnlp-main.774) |  | 0 |  | Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz, Genta Indra Winata, Alham Fikri Aji |  |
| 1969 |  |  [Reinforced Target-driven Conversational Promotion](https://doi.org/10.18653/v1/2023.emnlp-main.775) |  | 0 |  | Huy Dao, Lizi Liao, Dung D. Le, Yuxiang Nie |  |
| 1970 |  |  [Identification of Multimodal Stance Towards Frames of Communication](https://doi.org/10.18653/v1/2023.emnlp-main.776) |  | 0 |  | Maxwell A. Weinzierl, Sanda M. Harabagiu |  |
| 1971 |  |  [Unsupervised Sounding Pixel Learning](https://doi.org/10.18653/v1/2023.emnlp-main.777) |  | 0 |  | Yining Zhang, Yanli Ji, Yang Yang |  |
| 1972 |  |  [LM vs LM: Detecting Factual Errors via Cross Examination](https://doi.org/10.18653/v1/2023.emnlp-main.778) |  | 0 |  | Roi Cohen, May Hamri, Mor Geva, Amir Globerson |  |
| 1973 |  |  [Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.779) |  | 0 |  | Bram van Dijk, Tom Kouwenhoven, Marco Spruit, Max Johannes van Duijn |  |
| 1974 |  |  [PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training](https://doi.org/10.18653/v1/2023.emnlp-main.780) |  | 0 |  | Yunyi Zhang, Minhao Jiang, Yu Meng, Yu Zhang, Jiawei Han |  |
| 1975 |  |  [MeaeQ: Mount Model Extraction Attacks with Efficient Queries](https://doi.org/10.18653/v1/2023.emnlp-main.781) |  | 0 |  | Chengwei Dai, Minxuan Lv, Kun Li, Wei Zhou |  |
| 1976 |  |  [The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.782) |  | 0 |  | Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, Jamin Shin, Minjoon Seo |  |
| 1977 |  |  [Explaining Interactions Between Text Spans](https://doi.org/10.18653/v1/2023.emnlp-main.783) |  | 0 |  | Sagnik Ray Choudhury, Pepa Atanasova, Isabelle Augenstein |  |
| 1978 |  |  [Predictive Chemistry Augmented with Text Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.784) |  | 0 |  | Yujie Qian, Zhening Li, Zhengkai Tu, Connor W. Coley, Regina Barzilay |  |
| 1979 |  |  [System Combination via Quality Estimation for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.emnlp-main.785) |  | 0 |  | Muhammad Reza Qorib, Hwee Tou Ng |  |
| 1980 |  |  [Rethinking Negative Pairs in Code Search](https://doi.org/10.18653/v1/2023.emnlp-main.786) |  | 0 |  | Haochen Li, Xin Zhou, Anh Tuan Luu, Chunyan Miao |  |
| 1981 |  |  [Question Answering as Programming for Solving Time-Sensitive Questions](https://doi.org/10.18653/v1/2023.emnlp-main.787) |  | 0 |  | Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, JianGuang Lou, Yujiu Yang |  |
| 1982 |  |  [Joint Geometrical and Statistical Domain Adaptation for Cross-domain Code Vulnerability Detection](https://doi.org/10.18653/v1/2023.emnlp-main.788) |  | 0 |  | Qianjin Du, Shiji Zhou, Xiaohui Kuang, Gang Zhao, Jidong Zhai |  |
| 1983 |  |  [Revisiting Sparse Retrieval for Few-shot Entity Linking](https://doi.org/10.18653/v1/2023.emnlp-main.789) |  | 0 |  | Yulin Chen, Zhenran Xu, Baotian Hu, Min Zhang |  |
| 1984 |  |  [Controlling Pre-trained Language Models for Grade-Specific Text Simplification](https://doi.org/10.18653/v1/2023.emnlp-main.790) |  | 0 |  | Sweta Agrawal, Marine Carpuat |  |
| 1985 |  |  [CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension](https://doi.org/10.18653/v1/2023.emnlp-main.791) |  | 0 |  | Jingwei Zhang, Xin Wu, Yi Cai |  |
| 1986 |  |  ["Are Your Explanations Reliable?" Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack](https://doi.org/10.18653/v1/2023.emnlp-main.792) |  | 0 |  | Christopher Burger, Lingwei Chen, Thai Le |  |
| 1987 |  |  [CQE: A Comprehensive Quantity Extractor](https://doi.org/10.18653/v1/2023.emnlp-main.793) |  | 0 |  | Satya Almasian, Vivian Kazakova, Philip Göldner, Michael Gertz |  |
| 1988 |  |  [Context Compression for Auto-regressive Transformers with Sentinel Tokens](https://doi.org/10.18653/v1/2023.emnlp-main.794) |  | 0 |  | Siyu Ren, Qi Jia, Kenny Q. Zhu |  |
| 1989 |  |  [A Unified View of Evaluation Metrics for Structured Prediction](https://doi.org/10.18653/v1/2023.emnlp-main.795) |  | 0 |  | Yunmo Chen, William Gantt, Tongfei Chen, Aaron Steven White, Benjamin Van Durme |  |
| 1990 |  |  [A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing](https://doi.org/10.18653/v1/2023.emnlp-main.796) |  | 0 |  | Oren Tsur, Yoav Tulpan |  |
| 1991 |  |  [We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields](https://doi.org/10.18653/v1/2023.emnlp-main.797) |  | 0 |  | Jan Philip Wahle, Terry Ruas, Mohamed Abdalla, Bela Gipp, Saif M. Mohammad |  |
| 1992 |  |  [Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and Tie Calibration](https://doi.org/10.18653/v1/2023.emnlp-main.798) |  | 0 |  | Daniel Deutsch, George F. Foster, Markus Freitag |  |
| 1993 |  |  [SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization](https://doi.org/10.18653/v1/2023.emnlp-main.799) |  | 0 |  | Hyunwoo Kim, Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras, Malihe Alikhani, Gunhee Kim, Maarten Sap, Yejin Choi |  |
| 1994 |  |  [Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.800) |  | 0 |  | Zhiwei Hu, Víctor GutiérrezBasulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan |  |
| 1995 |  |  [MailEx: Email Event and Argument Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.801) |  | 0 |  | Saurabh Srivastava, Gaurav Singh, Shou Matsumoto, Ali K. Raz, Paulo C. G. Costa, Joshua Poore, Ziyu Yao |  |
| 1996 |  |  [Optimized Tokenization for Transcribed Error Correction](https://doi.org/10.18653/v1/2023.emnlp-main.802) |  | 0 |  | Tomer Wullach, Shlomo E. Chazan |  |
| 1997 |  |  [Beware of Model Collapse! Fast and Stable Test-time Adaptation for Robust Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.803) |  | 0 |  | Yi Su, Yixin Ji, Juntao Li, Hai Ye, Min Zhang |  |
| 1998 |  |  [Generative Adversarial Training with Perturbed Token Detection for Model Robustness](https://doi.org/10.18653/v1/2023.emnlp-main.804) |  | 0 |  | Jiahao Zhao, Wenji Mao |  |
| 1999 |  |  [Multi-Task Knowledge Distillation with Embedding Constraints for Scholarly Keyphrase Boundary Classification](https://doi.org/10.18653/v1/2023.emnlp-main.805) |  | 0 |  | Seo Park, Cornelia Caragea |  |
| 2000 |  |  [Set Learning for Generative Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.806) |  | 0 |  | Jiangnan Li, Yice Zhang, Bin Liang, KamFai Wong, Ruifeng Xu |  |
| 2001 |  |  [Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation](https://doi.org/10.18653/v1/2023.emnlp-main.807) |  | 0 |  | Anastasia Kritharoula, Maria Lymperaiou, Giorgos Stamou |  |
| 2002 |  |  [Be Selfish, But Wisely: Investigating the Impact of Agent Personality in Mixed-Motive Human-Agent Interactions](https://doi.org/10.18653/v1/2023.emnlp-main.808) |  | 0 |  | Kushal Chawla, Ian Wu, Yu Rong, Gale M. Lucas, Jonathan Gratch |  |
| 2003 |  |  [Doolittle: Benchmarks and Corpora for Academic Writing Formalization](https://doi.org/10.18653/v1/2023.emnlp-main.809) |  | 0 |  | Shizhe Diao, Yongyu Lei, Liangming Pan, Tianqing Fang, Wangchunshu Zhou, Sedrick Scott Keh, MinYen Kan, Tong Zhang |  |
| 2004 |  |  [Token Prediction as Implicit Classification to Identify LLM-Generated Text](https://doi.org/10.18653/v1/2023.emnlp-main.810) |  | 0 |  | Yutian Chen, Hao Kang, Vivian Zhai, Liangze Li, Rita Singh, Bhiksha Raj |  |
| 2005 |  |  [On Evaluation of Bangla Word Analogies](https://doi.org/10.18653/v1/2023.emnlp-main.811) |  | 0 |  | Mousumi Akter, Souvika Sarkar, Shubhra Kanti Karmaker Santu |  |
| 2006 |  |  [Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts](https://doi.org/10.18653/v1/2023.emnlp-main.812) |  | 0 |  | Haochen Tan, Han Wu, Wei Shao, Xinyun Zhang, Mingjie Zhan, Zhaohui Hou, Ding Liang, Linqi Song |  |
| 2007 |  |  [XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.813) |  | 0 |  | Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa |  |
| 2008 |  |  [Character-LLM: A Trainable Agent for Role-Playing](https://doi.org/10.18653/v1/2023.emnlp-main.814) |  | 0 |  | Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu |  |
| 2009 |  |  [Natural Language Decompositions of Implicit Content Enable Better Text Representations](https://doi.org/10.18653/v1/2023.emnlp-main.815) |  | 0 |  | Alexander Miserlis Hoyle, Rupak Sarkar, Pranav Goel, Philip Resnik |  |
| 2010 |  |  [A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports](https://doi.org/10.18653/v1/2023.emnlp-main.816) |  | 0 |  | Xinyu Wang, Lin Gui, Yulan He |  |
| 2011 |  |  [Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation](https://doi.org/10.18653/v1/2023.emnlp-main.817) |  | 0 |  | Zhiling Zhang, Mengyue Wu, Kenny Q. Zhu |  |
| 2012 |  |  [How do languages influence each other? Studying cross-lingual data sharing during LM fine-tuning](https://doi.org/10.18653/v1/2023.emnlp-main.818) |  | 0 |  | Rochelle Choenni, Dan Garrette, Ekaterina Shutova |  |
| 2013 |  |  [COFFEE: Counterfactual Fairness for Personalized Text Generation in Explainable Recommendation](https://doi.org/10.18653/v1/2023.emnlp-main.819) |  | 0 |  | Nan Wang, Qifan Wang, YiChia Wang, Maziar Sanjabi, Jingzhou Liu, Hamed Firooz, Hongning Wang, Shaoliang Nie |  |
| 2014 |  |  [NameGuess: Column Name Expansion for Tabular Data](https://doi.org/10.18653/v1/2023.emnlp-main.820) |  | 0 |  | Jiani Zhang, Zhengyuan Shen, Balasubramaniam Srinivasan, Shen Wang, Huzefa Rangwala, George Karypis |  |
| 2015 |  |  [BLESS: Benchmarking Large Language Models on Sentence Simplification](https://doi.org/10.18653/v1/2023.emnlp-main.821) |  | 0 |  | Tannon Kew, Alison Chi, Laura VásquezRodríguez, Sweta Agrawal, Dennis Aumiller, Fernando AlvaManchego, Matthew Shardlow |  |
| 2016 |  |  [To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing](https://doi.org/10.18653/v1/2023.emnlp-main.822) |  | 0 |  | Sireesh Gururaja, Amanda Bertsch, Clara Na, David Gray Widder, Emma Strubell |  |
| 2017 |  |  [PALS: Personalized Active Learning for Subjective Tasks in NLP](https://doi.org/10.18653/v1/2023.emnlp-main.823) |  | 0 |  | Kamil Kanclerz, Konrad Karanowski, Julita Bielaniewicz, Marcin Gruza, Piotr Milkowski, Jan Kocon, Przemyslaw Kazienko |  |
| 2018 |  |  [ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation](https://doi.org/10.18653/v1/2023.emnlp-main.824) |  | 0 |  | Yangyi Chen, Xingyao Wang, Manling Li, Derek Hoiem, Heng Ji |  |
| 2019 |  |  [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.825) |  | 0 |  | Huiqiang Jiang, Qianhui Wu, ChinYew Lin, Yuqing Yang, Lili Qiu |  |
| 2020 |  |  [EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data Augmentation for Multi-hop Fact Verification](https://doi.org/10.18653/v1/2023.emnlp-main.826) |  | 0 |  | Yingjie Zhu, Jiasheng Si, Yibo Zhao, Haiyang Zhu, Deyu Zhou, Yulan He |  |
| 2021 |  |  [An Exploration of Left-Corner Transformations](https://doi.org/10.18653/v1/2023.emnlp-main.827) |  | 0 |  | Andreas Opedal, Eleftheria Tsipidi, Tiago Pimentel, Ryan Cotterell, Tim Vieira |  |
| 2022 |  |  [Characterizing and Verifying Scientific Claims: Qualitative Causal Structure is All You Need](https://doi.org/10.18653/v1/2023.emnlp-main.828) |  | 0 |  | Jinxuan Wu, Wenhan Chao, Xian Zhou, Zhunchen Luo |  |
| 2023 |  |  [FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models](https://doi.org/10.18653/v1/2023.emnlp-main.829) |  | 0 |  | Konstantin Dobler, Gerard de Melo |  |
| 2024 |  |  [ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games](https://doi.org/10.18653/v1/2023.emnlp-main.830) |  | 0 |  | Ruoyao Wang, Graham Todd, Xingdi Yuan, Ziang Xiao, MarcAlexandre Côté, Peter A. Jansen |  |
| 2025 |  |  [Skill-Based Few-Shot Selection for In-Context Learning](https://doi.org/10.18653/v1/2023.emnlp-main.831) |  | 0 |  | Shengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Weizhu Chen, JianGuang Lou |  |
| 2026 |  |  [MaNtLE: Model-agnostic Natural Language Explainer](https://doi.org/10.18653/v1/2023.emnlp-main.832) |  | 0 |  | Rakesh R. Menon, Kerem Zaman, Shashank Srivastava |  |
| 2027 |  |  [PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer](https://doi.org/10.18653/v1/2023.emnlp-main.833) |  | 0 |  | Lichang Chen, Jiuhai Chen, Heng Huang, Minhao Cheng |  |
| 2028 |  |  [Ling-CL: Understanding NLP Models through Linguistic Curricula](https://doi.org/10.18653/v1/2023.emnlp-main.834) |  | 0 |  | Mohamed Elgaar, Hadi Amiri |  |
| 2029 |  |  [Towards Unsupervised Recognition of Token-level Semantic Differences in Related Documents](https://doi.org/10.18653/v1/2023.emnlp-main.835) |  | 0 |  | Jannis Vamvas, Rico Sennrich |  |
| 2030 |  |  [Towards a Better Understanding of Variations in Zero-Shot Neural Machine Translation Performance](https://doi.org/10.18653/v1/2023.emnlp-main.836) |  | 0 |  | Shaomu Tan, Christof Monz |  |
| 2031 |  |  [SEER : A Knapsack approach to Exemplar Selection for In-Context HybridQA](https://doi.org/10.18653/v1/2023.emnlp-main.837) |  | 0 |  | Jonathan Tonglet, Manon Reusens, Philipp Borchert, Bart Baesens |  |
| 2032 |  |  [Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations](https://doi.org/10.18653/v1/2023.emnlp-main.838) |  | 0 |  | Jihyoung Jang, Minseong Boo, Hyounghun Kim |  |
| 2033 |  |  [DueT: Image-Text Contrastive Transfer Learning with Dual-adapter Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.839) |  | 0 |  | Taku Hasegawa, Kyosuke Nishida, Koki Maeda, Kuniko Saito |  |
| 2034 |  |  [Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation](https://doi.org/10.18653/v1/2023.emnlp-main.840) |  | 0 |  | Yeongseo Jung, Eunseo Jung, Lei Chen |  |
| 2035 |  |  [CLAIR: Evaluating Image Captions with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.841) |  | 0 |  | David M. Chan, Suzanne Petryk, Joseph Gonzalez, Trevor Darrell, John F. Canny |  |
| 2036 |  |  [MoPe: Model Perturbation based Privacy Attacks on Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.842) |  | 0 |  | Marvin Li, Jason Wang, Jeffrey G. Wang, Seth Neel |  |
| 2037 |  |  [q2d: Turning Questions into Dialogs to Teach Models How to Search](https://doi.org/10.18653/v1/2023.emnlp-main.843) |  | 0 |  | Yonatan Bitton, Shlomi CohenGanor, Ido Hakimi, Yoad Lewenberg, Roee Aharoni, Enav Weinreb |  |
| 2038 |  |  [Aligning Large Language Models through Synthetic Feedback](https://doi.org/10.18653/v1/2023.emnlp-main.844) |  | 0 |  | Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, Kang Min Yoo, Minjoon Seo |  |
| 2039 |  |  [You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models](https://doi.org/10.18653/v1/2023.emnlp-main.845) |  | 0 |  | Alexander Baranov, Vladimir Kniazhevsky, Pavel Braslavski |  |
| 2040 |  |  [Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction](https://doi.org/10.18653/v1/2023.emnlp-main.846) |  | 0 |  | Chong Zhang, Ya Guo, Yi Tu, Huan Chen, Jinyang Tang, Huijia Zhu, Qi Zhang, Tao Gui |  |
| 2041 |  |  [Empower Nested Boolean Logic via Self-Supervised Curriculum Learning](https://doi.org/10.18653/v1/2023.emnlp-main.847) |  | 0 |  | Hongqiu Wu, Linfeng Liu, Hai Zhao, Min Zhang |  |
| 2042 |  |  [The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.848) |  | 0 |  | Pranav Venkit, Mukund Srinath, Sanjana Gautam, Saranya Venkatraman, Vipul Gupta, Rebecca J. Passonneau, Shomir Wilson |  |
| 2043 |  |  [Poisoning Retrieval Corpora by Injecting Adversarial Passages](https://doi.org/10.18653/v1/2023.emnlp-main.849) |  | 0 |  | Zexuan Zhong, Ziqing Huang, Alexander Wettig, Danqi Chen |  |
| 2044 |  |  [DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules](https://doi.org/10.18653/v1/2023.emnlp-main.850) |  | 0 |  | Yanchen Liu, William Held, Diyi Yang |  |
| 2045 |  |  [Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix](https://doi.org/10.18653/v1/2023.emnlp-main.851) |  | 0 |  | Xinyu Ma, Xuebo Liu, Min Zhang |  |
| 2046 |  |  [Unifying Discrete and Continuous Representations for Unsupervised Paraphrase Generation](https://doi.org/10.18653/v1/2023.emnlp-main.852) |  | 0 |  | Mingfeng Xue, Dayiheng Liu, Wenqiang Lei, Jie Fu, Jian Lan, Mei Li, Baosong Yang, Jun Xie, Yidan Zhang, Dezhong Peng, Jiancheng Lv |  |
| 2047 |  |  [The Benefits of Label-Description Training for Zero-Shot Text Classification](https://doi.org/10.18653/v1/2023.emnlp-main.853) |  | 0 |  | Lingyu Gao, Debanjan Ghosh, Kevin Gimpel |  |
| 2048 |  |  [Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer](https://doi.org/10.18653/v1/2023.emnlp-main.854) |  | 0 |  | Elizabeth Salesky, Neha Verma, Philipp Koehn, Matt Post |  |
| 2049 |  |  [Finding Authentic Counterhate Arguments: A Case Study with Public Figures](https://doi.org/10.18653/v1/2023.emnlp-main.855) |  | 0 |  | Abdullah Albanyan, Ahmed Hassan, Eduardo Blanco |  |
| 2050 |  |  [Can We Edit Multimodal Large Language Models?](https://doi.org/10.18653/v1/2023.emnlp-main.856) |  | 0 |  | Siyuan Cheng, Bozhong Tian, Qingbin Liu, Xi Chen, Yongheng Wang, Huajun Chen, Ningyu Zhang |  |
| 2051 |  |  [Exploring Discourse Structure in Document-level Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.857) |  | 0 |  | Xinyu Hu, Xiaojun Wan |  |
| 2052 |  |  [ClusterLLM: Large Language Models as a Guide for Text Clustering](https://doi.org/10.18653/v1/2023.emnlp-main.858) |  | 0 |  | Yuwei Zhang, Zihan Wang, Jingbo Shang |  |
| 2053 |  |  [CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code](https://doi.org/10.18653/v1/2023.emnlp-main.859) |  | 0 |  | Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig |  |
| 2054 |  |  [Learn and Consolidate: Continual Adaptation for Zero-Shot and Multilingual Neural Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.860) |  | 0 |  | Kaiyu Huang, Peng Li, Junpeng Liu, Maosong Sun, Yang Liu |  |
| 2055 |  |  [e-THERAPIST: I suggest you to cultivate a mindset of positivity and nurture uplifting thoughts](https://doi.org/10.18653/v1/2023.emnlp-main.861) |  | 0 |  | Kshitij Mishra, Priyanshu Priya, Manisha Burja, Asif Ekbal |  |
| 2056 |  |  [AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages](https://doi.org/10.18653/v1/2023.emnlp-main.862) |  | 0 |  | Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, Nedjma Ousidhoum, David Ifeoluwa Adelani, Seid Muhie Yimam, Ibrahim Said Ahmad, Meriem Beloucif, Saif M. Mohammad, Sebastian Ruder, Oumaima Hourrane, Alípio Jorge, Pavel Brazdil, Felermino Dário Mário António Ali, Davis David, Salomey Osei, Bello Shehu Bello, Falalu Ibrahim Lawan, Tajuddeen Gwadabe, Samuel Rutunda, Tadesse Destaw Belay, Wendimu Baye Messelle, Hailu Beshada Balcha, Sisay Adugna Chala, Hagos Tesfahun Gebremichael, Bernard Opoku, Stephen Arthur |  |
| 2057 |  |  [Quantifying Character Similarity with Vision Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.863) |  | 0 |  | Xinmei Yang, Abhishek Arora, ShaoYu Jheng, Melissa Dell |  |
| 2058 |  |  [Syllogistic Reasoning for Legal Judgment Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.864) |  | 0 |  | Wentao Deng, Jiahuan Pei, Keyi Kong, Zhe Chen, Furu Wei, Yujun Li, Zhaochun Ren, Zhumin Chen, Pengjie Ren |  |
| 2059 |  |  [Improving Transformer-based Program Repair Model through False Behavior Diagnosis](https://doi.org/10.18653/v1/2023.emnlp-main.865) |  | 0 |  | Youngkyoung Kim, Misoo Kim, Eunseok Lee |  |
| 2060 |  |  [SUT: Active Defects Probing for Transcompiler Models](https://doi.org/10.18653/v1/2023.emnlp-main.866) |  | 0 |  | Mengnan Qi, Yufan Huang, Maoquan Wang, Yongqiang Yao, Zihan Liu, Bin Gu, Colin B. Clement, Neel Sundaresan |  |
| 2061 |  |  [KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection](https://doi.org/10.18653/v1/2023.emnlp-main.867) |  | 0 |  | Sehyun Choi, Tianqing Fang, Zhaowei Wang, Yangqiu Song |  |
| 2062 |  |  [CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL](https://doi.org/10.18653/v1/2023.emnlp-main.868) |  | 0 |  | Mayank Kothyari, Dhruva Dhingra, Sunita Sarawagi, Soumen Chakrabarti |  |
| 2063 |  |  [This Reads Like That: Deep Learning for Interpretable Natural Language Processing](https://doi.org/10.18653/v1/2023.emnlp-main.869) |  | 0 |  | Claudio Fanconi, Moritz Vandenhirtz, Severin Husmann, Julia E. Vogt |  |
| 2064 |  |  [Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs](https://doi.org/10.18653/v1/2023.emnlp-main.870) |  | 0 |  | Roei Herzig, Alon Mendelson, Leonid Karlinsky, Assaf Arbelle, Rogério Feris, Trevor Darrell, Amir Globerson |  |
| 2065 |  |  [TLM: Token-Level Masking for Transformers](https://doi.org/10.18653/v1/2023.emnlp-main.871) |  | 0 |  | Yangjun Wu, Kebin Fang, Dongxiang Zhang, Han Wang, Hao Zhang, Gang Chen |  |
| 2066 |  |  [Addressing NER Annotation Noises with Uncertainty-Guided Tree-Structured CRFs](https://doi.org/10.18653/v1/2023.emnlp-main.872) |  | 0 |  | Jian Liu, Weichang Liu, Yufeng Chen, Jinan Xu, Zhe Zhao |  |
| 2067 |  |  [Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus](https://doi.org/10.18653/v1/2023.emnlp-main.873) |  | 0 |  | Andrea Piergentili, Beatrice Savoldi, Dennis Fucci, Matteo Negri, Luisa Bentivogli |  |
| 2068 |  |  [Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale](https://doi.org/10.18653/v1/2023.emnlp-main.874) |  | 0 |  | Marta R. Costajussà, Pierre Andrews, Eric Michael Smith, Prangthip Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Daniel Licht, Carleigh Wood |  |
| 2069 |  |  [GlobalBench: A Benchmark for Global Progress in Natural Language Processing](https://doi.org/10.18653/v1/2023.emnlp-main.875) |  | 0 |  | Yueqi Song, Simran Khanuja, Pengfei Liu, Fahim Faisal, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig |  |
| 2070 |  |  [DetGPT: Detect What You Need via Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.876) |  | 0 |  | Renjie Pi, Jiahui Gao, Shizhe Diao, Rui Pan, Hanze Dong, Jipeng Zhang, Lewei Yao, Jianhua Han, Hang Xu, Lingpeng Kong, Tong Zhang |  |
| 2071 |  |  [Language Models with Rationality](https://doi.org/10.18653/v1/2023.emnlp-main.877) |  | 0 |  | Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Schütze, Peter Clark |  |
| 2072 |  |  [Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation](https://doi.org/10.18653/v1/2023.emnlp-main.878) |  | 0 |  | Yusheng Liao, Shuyang Jiang, Yiqi Li, Yu Wang, Yanfeng Wang |  |
| 2073 |  |  [Mitigating Temporal Misalignment by Discarding Outdated Facts](https://doi.org/10.18653/v1/2023.emnlp-main.879) |  | 0 |  | Michael J. Q. Zhang, Eunsol Choi |  |
| 2074 |  |  [Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting](https://doi.org/10.18653/v1/2023.emnlp-main.880) |  | 0 |  | William Hogan, Jiacheng Li, Jingbo Shang |  |
| 2075 |  |  [IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions](https://doi.org/10.18653/v1/2023.emnlp-main.881) |  | 0 |  | Ziheng Zeng, Kellen Tan Cheng, Srihari Venkat Nanniyur, Jianing Zhou, Suma Bhat |  |
| 2076 |  |  [Bias Neutralization in Non-Parallel Texts: A Cyclic Approach with Auxiliary Guidance](https://doi.org/10.18653/v1/2023.emnlp-main.882) |  | 0 |  | Karthic Madanagopal, James Caverlee |  |
| 2077 |  |  [Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation](https://doi.org/10.18653/v1/2023.emnlp-main.883) |  | 0 |  | Jason Samuel Lucas, Adaku Uchendu, Michiharu Yamashita, Jooyoung Lee, Shaurya Rohatgi, Dongwon Lee |  |
| 2078 |  |  [SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts](https://doi.org/10.18653/v1/2023.emnlp-main.884) |  | 0 |  | JoonYoung Choi, Junho Kim, JunHyung Park, WingLam Mok, SangKeun Lee |  |
| 2079 |  |  [BRAINTEASER: Lateral Thinking Puzzles for Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.885) |  | 0 |  | Yifan Jiang, Filip Ilievski, Kaixin Ma, Zhivar Sourati |  |
| 2080 |  |  [When are Lemons Purple? The Concept Association Bias of Vision-Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.886) |  | 0 |  | Yingtian Tang, Yutaro Yamada, Yoyo Zhang, Ilker Yildirim |  |
| 2081 |  |  [What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability](https://doi.org/10.18653/v1/2023.emnlp-main.887) |  | 0 |  | Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fernández, Barbara Plank |  |
| 2082 |  |  [Text Representation Distillation via Information Bottleneck Principle](https://doi.org/10.18653/v1/2023.emnlp-main.888) |  | 0 |  | Yanzhao Zhang, Dingkun Long, Zehan Li, Pengjun Xie |  |
| 2083 |  |  [Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation](https://doi.org/10.18653/v1/2023.emnlp-main.889) |  | 0 |  | Zhenwen Liang, Wenhao Yu, Tanmay Rajpurohit, Peter Clark, Xiangliang Zhang, Ashwin Kalyan |  |
| 2084 |  |  [FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions](https://doi.org/10.18653/v1/2023.emnlp-main.890) |  | 0 |  | Hyunwoo Kim, Melanie Sclar, Xuhui Zhou, Ronan Le Bras, Gunhee Kim, Yejin Choi, Maarten Sap |  |
| 2085 |  |  [Exploring the Boundaries of GPT-4 in Radiology](https://doi.org/10.18653/v1/2023.emnlp-main.891) |  | 0 |  | Qianchu Liu, Stephanie L. Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Maria Wetscherek, Robert Tinn, Harshita Sharma, Fernando PérezGarcía, Anton Schwaighofer, Pranav Rajpurkar, Sameer Tajdin Khanna, Hoifung Poon, Naoto Usuyama, Anja Thieme, Aditya V. Nori, Matthew P. Lungren, Ozan Oktay, Javier AlvarezValle |  |
| 2086 |  |  [A Frustratingly Easy Post-Training Quantization Scheme for LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.892) |  | 0 |  | Yongkweon Jeon, Chungman Lee, Kyungphil Park, HoYoung Kim |  |
| 2087 |  |  [A Comprehensive Evaluation of Biomedical Entity Linking Models](https://doi.org/10.18653/v1/2023.emnlp-main.893) |  | 0 |  | David Kartchner, Jennifer Deng, Shubham Lohiya, Tejasri Kopparthi, Prasanth Bathala, Daniel DomingoFernández, Cassie S. Mitchell |  |
| 2088 |  |  [Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals](https://doi.org/10.18653/v1/2023.emnlp-main.894) |  | 0 |  | Sukannya Purkayastha, Anne Lauscher, Iryna Gurevych |  |
| 2089 |  |  [LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages](https://doi.org/10.18653/v1/2023.emnlp-main.895) |  | 0 |  | Milind Agarwal, Md Mahfuz Ibn Alam, Antonios Anastasopoulos |  |
| 2090 |  |  [FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.896) |  | 0 |  | Ruixuan Xiao, Yiwen Dong, Junbo Zhao, Runze Wu, Minmin Lin, Gang Chen, Haobo Wang |  |
| 2091 |  |  [API-Assisted Code Generation for Question Answering on Varied Table Structures](https://doi.org/10.18653/v1/2023.emnlp-main.897) |  | 0 |  | Yihan Cao, Shuyi Chen, Ryan Liu, Zhiruo Wang, Daniel Fried |  |
| 2092 |  |  [Data Factors for Better Compositional Generalization](https://doi.org/10.18653/v1/2023.emnlp-main.898) |  | 0 |  | Xiang Zhou, Yichen Jiang, Mohit Bansal |  |
| 2093 |  |  [ChatEdit: Towards Multi-turn Interactive Facial Image Editing via Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.899) |  | 0 |  | Xing Cui, Zekun Li, Pei Li, Yibo Hu, Hailin Shi, Chunshui Cao, Zhaofeng He |  |
| 2094 |  |  [Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations](https://doi.org/10.18653/v1/2023.emnlp-main.900) |  | 0 |  | James Y. Huang, Wenlin Yao, Kaiqiang Song, Hongming Zhang, Muhao Chen, Dong Yu |  |
| 2095 |  |  [Outlier Dimensions Encode Task Specific Knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.901) |  | 0 |  | William Rudman, Catherine Chen, Carsten Eickhoff |  |
| 2096 |  |  [Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining](https://doi.org/10.18653/v1/2023.emnlp-main.902) |  | 0 |  | Jingcong Liang, Rong Ye, Meng Han, Qi Zhang, Ruofei Lai, Xinyu Zhang, Zhao Cao, Xuanjing Huang, Zhongyu Wei |  |
| 2097 |  |  [Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization](https://doi.org/10.18653/v1/2023.emnlp-main.903) |  | 0 |  | Zihao Fu, Yixuan Su, Zaiqiao Meng, Nigel Collier |  |
| 2098 |  |  [GNAT: A General Narrative Alignment Tool](https://doi.org/10.18653/v1/2023.emnlp-main.904) |  | 0 |  | Tanzir Pial, Steven Skiena |  |
| 2099 |  |  [Self-Ensemble of N-best Generation Hypotheses by Lexically Constrained Decoding](https://doi.org/10.18653/v1/2023.emnlp-main.905) |  | 0 |  | Ryota Miyano, Tomoyuki Kajiwara, Yuki Arase |  |
| 2100 |  |  [UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.906) |  | 0 |  | Ahmed Masry, Parsa Kavehzadeh, Do Xuan Long, Enamul Hoque, Shafiq Joty |  |
| 2101 |  |  [Merging Experts into One: Improving Computational Efficiency of Mixture of Experts](https://doi.org/10.18653/v1/2023.emnlp-main.907) |  | 0 |  | Shwai He, RunZe Fan, Liang Ding, Li Shen, Tianyi Zhou, Dacheng Tao |  |
| 2102 |  |  [Distance-Based Propagation for Efficient Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2023.emnlp-main.908) |  | 0 |  | Harry Shomer, Yao Ma, Juanhui Li, Bo Wu, Charu C. Aggarwal, Jiliang Tang |  |
| 2103 |  |  [What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions](https://doi.org/10.18653/v1/2023.emnlp-main.909) |  | 0 |  | Abhilasha Sancheti, Aparna Garimella, Balaji Vasan Srinivasan, Rachel Rudinger |  |
| 2104 |  |  [Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization](https://doi.org/10.18653/v1/2023.emnlp-main.910) |  | 0 |  | Janghwan Lee, Minsoo Kim, Seungcheol Baek, Seok Joong Hwang, Wonyong Sung, Jungwook Choi |  |
| 2105 |  |  [CP-BCS: Binary Code Summarization Guided by Control Flow Graph and Pseudo Code](https://doi.org/10.18653/v1/2023.emnlp-main.911) |  | 0 |  | Tong Ye, Lingfei Wu, Tengfei Ma, Xuhong Zhang, Yangkai Du, Peiyu Liu, Shouling Ji, Wenhai Wang |  |
| 2106 |  |  [Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism](https://doi.org/10.18653/v1/2023.emnlp-main.912) |  | 0 |  | Mengyu Ye, Tatsuki Kuribayashi, Jun Suzuki, Goro Kobayashi, Hiroaki Funayama |  |
| 2107 |  |  [Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.913) |  | 0 |  | Caoyun Fan, Jidong Tian, Yitian Li, Wenqing Chen, Hao He, Yaohui Jin |  |
| 2108 |  |  [Large Language Models are Complex Table Parsers](https://doi.org/10.18653/v1/2023.emnlp-main.914) |  | 0 |  | Bowen Zhao, Changkai Ji, Yuejie Zhang, Wen He, Yingwen Wang, Qing Wang, Rui Feng, Xiaobo Zhang |  |
| 2109 |  |  [R2H: Building Multimodal Navigation Helpers that Respond to Help Requests](https://doi.org/10.18653/v1/2023.emnlp-main.915) |  | 0 |  | Yue Fan, Jing Gu, Kaizhi Zheng, Xin Wang |  |
| 2110 |  |  [Speech-enriched Memory for Inference-time Adaptation of ASR Models to Word Dictionaries](https://doi.org/10.18653/v1/2023.emnlp-main.916) |  | 0 |  | Ashish R. Mittal, Sunita Sarawagi, Preethi Jyothi, George Saon, Gakuto Kurata |  |
| 2111 |  |  [Generative Table Pre-training Empowers Models for Tabular Prediction](https://doi.org/10.18653/v1/2023.emnlp-main.917) |  | 0 |  | Tianping Zhang, Shaowen Wang, Shuicheng Yan, Li Jian, Qian Liu |  |
| 2112 |  |  [Learning to Describe for Predicting Zero-shot Drug-Drug Interactions](https://doi.org/10.18653/v1/2023.emnlp-main.918) |  | 0 |  | Fangqi Zhu, Yongqi Zhang, Lei Chen, Bing Qin, Ruifeng Xu |  |
| 2113 |  |  [A Simple Baseline for Knowledge-Based Visual Question Answering](https://doi.org/10.18653/v1/2023.emnlp-main.919) |  | 0 |  | Alexandros Xenos, Themos Stafylakis, Ioannis Patras, Georgios Tzimiropoulos |  |
| 2114 |  |  [Unveiling the Essence of Poetry: Introducing a Comprehensive Dataset and Benchmark for Poem Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.920) |  | 0 |  | Ridwan Mahbub, Ifrad Khan, Samiha Anuva, Md Shahriar, Md. Tahmid Rahman Laskar, Sabbir Ahmed |  |
| 2115 |  |  [Privacy Implications of Retrieval-Based Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.921) |  | 0 |  | Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen |  |
| 2116 |  |  [IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems](https://doi.org/10.18653/v1/2023.emnlp-main.922) |  | 0 |  | Xu Huang, Zhirui Zhang, Ruize Gao, Yichao Du, Lemao Liu, Guoping Huang, Shuming Shi, Jiajun Chen, Shujian Huang |  |
| 2117 |  |  [Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents](https://doi.org/10.18653/v1/2023.emnlp-main.923) |  | 0 |  | Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, Zhaochun Ren |  |
| 2118 |  |  [DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization](https://doi.org/10.18653/v1/2023.emnlp-main.924) |  | 0 |  | Chengang Hu, Xiao Liu, Yansong Feng |  |
| 2119 |  |  [Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?](https://doi.org/10.18653/v1/2023.emnlp-main.925) |  | 0 |  | Yang Chen, Hexiang Hu, Yi Luan, Haitian Sun, Soravit Changpinyo, Alan Ritter, MingWei Chang |  |
| 2120 |  |  [EDeR: Towards Understanding Dependency Relations Between Events](https://doi.org/10.18653/v1/2023.emnlp-main.926) |  | 0 |  | Ruiqi Li, Patrik Haslum, Leyang Cui |  |
| 2121 |  |  [It Ain't Over: A Multi-aspect Diverse Math Word Problem Dataset](https://doi.org/10.18653/v1/2023.emnlp-main.927) |  | 0 |  | Jiwoo Kim, Youngbin Kim, Ilwoong Baek, JinYeong Bak, Jongwuk Lee |  |
| 2122 |  |  [Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness](https://doi.org/10.18653/v1/2023.emnlp-main.928) |  | 0 |  | Bevan Koopman, Guido Zuccon |  |
| 2123 |  |  [kNN-LM Does Not Improve Open-ended Text Generation](https://doi.org/10.18653/v1/2023.emnlp-main.929) |  | 0 |  | Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, Mohit Iyyer |  |
| 2124 |  |  [Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model](https://doi.org/10.18653/v1/2023.emnlp-main.930) |  | 0 |  | Zeyu Liu, Tim Dettmers, Xi Lin, Veselin Stoyanov, Xian Li |  |
| 2125 |  |  [Exploring the Impact of Model Scaling on Parameter-Efficient Tuning](https://doi.org/10.18653/v1/2023.emnlp-main.931) |  | 0 |  | Yusheng Su, ChiMin Chan, Jiali Cheng, Yujia Qin, Yankai Lin, Shengding Hu, Zonghan Yang, Ning Ding, Xingzhi Sun, Guotong Xie, Zhiyuan Liu, Maosong Sun |  |
| 2126 |  |  [STAIR: Learning Sparse Text and Image Representation in Grounded Tokens](https://doi.org/10.18653/v1/2023.emnlp-main.932) |  | 0 |  | Chen Chen, Bowen Zhang, Liangliang Cao, Jiguang Shen, Tom Gunter, Albin Madappally Jose, Alexander Toshev, Yantao Zheng, Ruoming Pang, Yinfei Yang |  |
| 2127 |  |  [Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting](https://doi.org/10.18653/v1/2023.emnlp-main.933) |  | 0 |  | Emmy Liu, Aditi Chaudhary, Graham Neubig |  |
| 2128 |  |  [CoRec: An Easy Approach for Coordination Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.934) |  | 0 |  | Qing Wang, Haojie Jia, Wenfei Song, Qi Li |  |
| 2129 |  |  [A linear time approximation of Wasserstein distance with word embedding selection](https://doi.org/10.18653/v1/2023.emnlp-main.935) |  | 0 |  | Sho Otao, Makoto Yamada |  |
| 2130 |  |  [Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication](https://doi.org/10.18653/v1/2023.emnlp-main.936) |  | 0 |  | Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, Xuanjing Huang, Xipeng Qiu |  |
| 2131 |  |  [Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction](https://doi.org/10.18653/v1/2023.emnlp-main.937) |  | 0 |  | CamVan Thi Nguyen, AnhTuan Mai, TheSon Le, HaiDang Kieu, DucTrong Le |  |
| 2132 |  |  [Connecting degree and polarity: An artificial language learning study](https://doi.org/10.18653/v1/2023.emnlp-main.938) |  | 0 |  | Lisa Bylinina, Alexey Tikhonov, Ekaterina Garmash |  |
| 2133 |  |  [Prompting with Pseudo-Code Instructions](https://doi.org/10.18653/v1/2023.emnlp-main.939) |  | 0 |  | Mayank Mishra, Prince Kumar, Riyaz A. Bhat, Rudra Murthy V, Danish Contractor, Srikanth Tamilselvam |  |
| 2134 |  |  [CRAB: Assessing the Strength of Causal Relationships Between Real-world Events](https://doi.org/10.18653/v1/2023.emnlp-main.940) |  | 0 |  | Angelika Romanou, Syrielle Montariol, Debjit Paul, Léo Laugier, Karl Aberer, Antoine Bosselut |  |
| 2135 |  |  [NORMSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly](https://doi.org/10.18653/v1/2023.emnlp-main.941) |  | 0 |  | Yi Fung, Tuhin Chakrabarty, Hao Guo, Owen Rambow, Smaranda Muresan, Heng Ji |  |
| 2136 |  |  [A State-Vector Framework for Dataset Effects](https://doi.org/10.18653/v1/2023.emnlp-main.942) |  | 0 |  | Esmat Sahak, Zining Zhu, Frank Rudzicz |  |
| 2137 |  |  [Challenges in Context-Aware Neural Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.943) |  | 0 |  | Linghao Jin, Jacqueline He, Jonathan May, Xuezhe Ma |  |
| 2138 |  |  [Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond](https://doi.org/10.18653/v1/2023.emnlp-main.944) |  | 0 |  | Siyang Liu, Naihao Deng, Sahand Sabour, Yilin Jia, Minlie Huang, Rada Mihalcea |  |
| 2139 |  |  [FACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering](https://doi.org/10.18653/v1/2023.emnlp-main.945) |  | 0 |  | Megha Chakraborty, Khushbu Pahwa, Anku Rani, Shreyas Chatterjee, Dwip Dalal, Harshit Dave, Ritvik G, Preethi Gurumurthy, Adarsh Mahor, Samahriti Mukherjee, Aditya Pakala, Ishan Paul, Janvita Reddy, Arghya Sarkar, Kinjal Sensharma, Aman Chadha, Amit P. Sheth, Amitava Das |  |
| 2140 |  |  [Building Multi-domain Dialog State Trackers from Single-domain Dialogs](https://doi.org/10.18653/v1/2023.emnlp-main.946) |  | 0 |  | Qi Zhu, Zheng Zhang, Xiaoyan Zhu, Minlie Huang |  |
| 2141 |  |  [Specialist or Generalist? Instruction Tuning for Specific NLP Tasks](https://doi.org/10.18653/v1/2023.emnlp-main.947) |  | 0 |  | Chufan Shi, Yixuan Su, Cheng Yang, Yujiu Yang, Deng Cai |  |
| 2142 |  |  [Making Large Language Models Better Data Creators](https://doi.org/10.18653/v1/2023.emnlp-main.948) |  | 0 |  | DongHo Lee, Jay Pujara, Mohit Sewak, Ryen White, Sujay Kumar Jauhar |  |
| 2143 |  |  [Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation](https://doi.org/10.18653/v1/2023.emnlp-main.949) |  | 0 |  | Xiaohua Wang, Yuliang Yan, Longtao Huang, Xiaoqing Zheng, Xuanjing Huang |  |
| 2144 |  |  [Guideline Learning for In-Context Information Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.950) |  | 0 |  | Chaoxu Pang, Yixuan Cao, Qiang Ding, Ping Luo |  |
| 2145 |  |  [Open Information Extraction via Chunks](https://doi.org/10.18653/v1/2023.emnlp-main.951) |  | 0 |  | Kuicai Dong, Aixin Sun, JungJae Kim, Xiaoli Li |  |
| 2146 |  |  [Rethinking Word-Level Auto-Completion in Computer-Aided Translation](https://doi.org/10.18653/v1/2023.emnlp-main.952) |  | 0 |  | Xingyu Chen, Lemao Liu, Guoping Huang, Zhirui Zhang, Mingming Yang, Shuming Shi, Rui Wang |  |
| 2147 |  |  [Automatic Transcription of Handwritten Old Occitan Language](https://doi.org/10.18653/v1/2023.emnlp-main.953) |  | 0 |  | Esteban Garces Arias, Vallari Pai, Matthias Schöffel, Christian Heumann, Matthias Aßenmacher |  |
| 2148 |  |  [CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities](https://doi.org/10.18653/v1/2023.emnlp-main.954) |  | 0 |  | Sheng Xu, Peifeng Li, Qiaoming Zhu |  |
| 2149 |  |  [Anaphor Assisted Document-Level Relation Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.955) |  | 0 |  | Chonggang Lu, Richong Zhang, Kai Sun, Jaein Kim, Cunwang Zhang, Yongyi Mao |  |
| 2150 |  |  [FinEntity: Entity-level Sentiment Classification for Financial Texts](https://doi.org/10.18653/v1/2023.emnlp-main.956) |  | 0 |  | Yixuan Tang, Yi Yang, Allen Huang, Andy Tam, Justin Z. Tang |  |
| 2151 |  |  [All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison](https://doi.org/10.18653/v1/2023.emnlp-main.957) |  | 0 |  | Yujian Liu, Xinliang Frederick Zhang, Kaijian Zou, Ruihong Huang, Nicholas Beauchamp, Lu Wang |  |
| 2152 |  |  [Rationale-Enhanced Language Models are Better Continual Relation Learners](https://doi.org/10.18653/v1/2023.emnlp-main.958) |  | 0 |  | Weimin Xiong, Yifan Song, Peiyi Wang, Sujian Li |  |
| 2153 |  |  [BanglaAbuseMeme: A Dataset for Bengali Abusive Meme Classification](https://doi.org/10.18653/v1/2023.emnlp-main.959) |  | 0 |  | Mithun Das, Animesh Mukherjee |  |
| 2154 |  |  [ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts](https://doi.org/10.18653/v1/2023.emnlp-main.960) |  | 0 |  | Lena S. Bolliger, David R. Reich, Patrick Haller, Deborah N. Jakobi, Paul Prasse, Lena A. Jäger |  |
| 2155 |  |  [From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.961) |  | 0 |  | Dongjun Kang, Joonsuk Park, Yohan Jo, JinYeong Bak |  |
| 2156 |  |  [Analyzing Film Adaptation through Narrative Alignment](https://doi.org/10.18653/v1/2023.emnlp-main.962) |  | 0 |  | Tanzir Pial, Shahreen Salim Aunti, Charuta Pethe, Allen Kim, Steven Skiena |  |
| 2157 |  |  [Inverse Scaling Can Become U-Shaped](https://doi.org/10.18653/v1/2023.emnlp-main.963) |  | 0 |  | Jason Wei, Najoung Kim, Yi Tay, Quoc V. Le |  |
| 2158 |  |  [Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer](https://doi.org/10.18653/v1/2023.emnlp-main.964) |  | 0 |  | Ruize Gao, Zhirui Zhang, Yichao Du, Lemao Liu, Rui Wang |  |
| 2159 |  |  [Variance Matters: Detecting Semantic Differences without Corpus/Word Alignment](https://doi.org/10.18653/v1/2023.emnlp-main.965) |  | 0 |  | Ryo Nagata, Hiroya Takamura, Naoki Otani, Yoshifumi Kawasaki |  |
| 2160 |  |  [MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter](https://doi.org/10.18653/v1/2023.emnlp-main.966) |  | 0 |  | Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, TatSeng Chua |  |
| 2161 |  |  [A Training-Free Debiasing Framework with Counterfactual Reasoning for Conversational Emotion Detection](https://doi.org/10.18653/v1/2023.emnlp-main.967) |  | 0 |  | Geng Tu, Ran Jing, Bin Liang, Min Yang, KamFai Wong, Ruifeng Xu |  |
| 2162 |  |  [Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations](https://doi.org/10.18653/v1/2023.emnlp-main.968) |  | 0 |  | WeiLin Chen, ChengKuang Wu, YunNung Chen, HsinHsi Chen |  |
| 2163 |  |  [Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.969) |  | 0 |  | Taolin Zhang, Ruyao Xu, Chengyu Wang, Zhongjie Duan, Cen Chen, Minghui Qiu, Dawei Cheng, Xiaofeng He, Weining Qian |  |
| 2164 |  |  [ScdNER: Span-Based Consistency-Aware Document-Level Named Entity Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.970) |  | 0 |  | Ying Wei, Qi Li |  |
| 2165 |  |  [MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions](https://doi.org/10.18653/v1/2023.emnlp-main.971) |  | 0 |  | Zexuan Zhong, Zhengxuan Wu, Christopher D. Manning, Christopher Potts, Danqi Chen |  |
| 2166 |  |  [Stance Detection on Social Media with Background Knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.972) |  | 0 |  | Ang Li, Bin Liang, Jingqian Zhao, Bowen Zhang, Min Yang, Ruifeng Xu |  |
| 2167 |  |  [Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning](https://doi.org/10.18653/v1/2023.emnlp-main.973) |  | 0 |  | Hao Wang, Xiahua Chen, Rui Wang, Chenhui Chu |  |
| 2168 |  |  [NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation](https://doi.org/10.18653/v1/2023.emnlp-main.974) |  | 0 |  | Oliver Li, Mallika Subramanian, Arkadiy Saakyan, Sky CHWang, Smaranda Muresan |  |
| 2169 |  |  [ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets](https://doi.org/10.18653/v1/2023.emnlp-main.975) |  | 0 |  | Tobias Schimanski, Julia Anna Bingler, Mathias Kraus, Camilla Hyslop, Markus Leippold |  |
| 2170 |  |  [Leap-of-Thought: Accelerating Transformers via Dynamic Token Routing](https://doi.org/10.18653/v1/2023.emnlp-main.976) |  | 0 |  | Yeachan Kim, Junho Kim, JunHyung Park, Mingyu Lee, SangKeun Lee |  |
| 2171 |  |  [Reinforcement Replaces Supervision: Query focused Summarization using Deep Reinforcement Learning](https://doi.org/10.18653/v1/2023.emnlp-main.977) |  | 0 |  | Swaroop Nath, Pushpak Bhattacharyya, Harshad Khadilkar |  |
| 2172 |  |  [Fair Text Classification with Wasserstein Independence](https://doi.org/10.18653/v1/2023.emnlp-main.978) |  | 0 |  | Thibaud Leteno, Antoine Gourru, Charlotte Laclau, Rémi Emonet, Christophe Gravier |  |
| 2173 |  |  [TacoPrompt: A Collaborative Multi-Task Prompt Learning Method for Self-Supervised Taxonomy Completion](https://doi.org/10.18653/v1/2023.emnlp-main.979) |  | 0 |  | Hongyuan Xu, Ciyi Liu, Yuhang Niu, Yunong Chen, Xiangrui Cai, Yanlong Wen, Xiaojie Yuan |  |
| 2174 |  |  [An Attribution Method for Siamese Encoders](https://doi.org/10.18653/v1/2023.emnlp-main.980) |  | 0 |  | Lucas Möller, Dmitry Nikolaev, Sebastian Padó |  |
| 2175 |  |  [Global Voices, Local Biases: Socio-Cultural Prejudices across Languages](https://doi.org/10.18653/v1/2023.emnlp-main.981) |  | 0 |  | Anjishnu Mukherjee, Chahat Raj, Ziwei Zhu, Antonios Anastasopoulos |  |
| 2176 |  |  [Graph vs. Sequence: An Empirical Study on Knowledge Forms for Knowledge-Grounded Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.982) |  | 0 |  | Yizhe Yang, Heyan Huang, Yuhang Liu, Yang Gao |  |
| 2177 |  |  [Are Compressed Language Models Less Subgroup Robust?](https://doi.org/10.18653/v1/2023.emnlp-main.983) |  | 0 |  | Leonidas Gee, Andrea Zugarini, Novi Quadrianto |  |
| 2178 |  |  [Length Does Matter: Summary Length can Bias Summarization Metrics](https://doi.org/10.18653/v1/2023.emnlp-main.984) |  | 0 |  | Xiaobo Guo, Soroush Vosoughi |  |
| 2179 |  |  [NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.985) |  | 0 |  | Yongchao Chen, Rujul Gandhi, Yang Zhang, Chuchu Fan |  |
| 2180 |  |  [Reformulating NLP tasks to Capture Longitudinal Manifestation of Language Disorders in People with Dementia](https://doi.org/10.18653/v1/2023.emnlp-main.986) |  | 0 |  | Dimitris Gkoumas, Matthew Purver, Maria Liakata |  |
| 2181 |  |  [Elevating Code-mixed Text Handling through Auditory Information of Words](https://doi.org/10.18653/v1/2023.emnlp-main.987) |  | 0 |  | Mamta, Zishan Ahmad, Asif Ekbal |  |
| 2182 |  |  [Predict and Use: Harnessing Predicted Gaze to Improve Multimodal Sarcasm Detection](https://doi.org/10.18653/v1/2023.emnlp-main.988) |  | 0 |  | Divyank Tiwari, Diptesh Kanojia, Anupama Ray, Apoorva Nunna, Pushpak Bhattacharyya |  |
| 2183 |  |  [Fine-grained Medical Vision-Language Representation Learning for Radiology Report Generation](https://doi.org/10.18653/v1/2023.emnlp-main.989) |  | 0 |  | Siyuan Wang, Bo Peng, Yichao Liu, Qi Peng |  |
| 2184 |  |  [ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer](https://doi.org/10.18653/v1/2023.emnlp-main.990) |  | 0 |  | Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, Hong Chen, Jinzheng He, Zhou Zhao |  |
| 2185 |  |  [Consistency Analysis of ChatGPT](https://doi.org/10.18653/v1/2023.emnlp-main.991) |  | 0 |  | Myeongjun Jang, Thomas Lukasiewicz |  |
| 2186 |  |  [Do Differences in Values Influence Disagreements in Online Discussions?](https://doi.org/10.18653/v1/2023.emnlp-main.992) |  | 0 |  | Michiel van der Meer, Piek Vossen, Catholijn M. Jonker, Pradeep K. Murukannaiah |  |
| 2187 |  |  [Automated Fact-Checking in Dialogue: Are Specialized Models Needed?](https://doi.org/10.18653/v1/2023.emnlp-main.993) |  | 0 |  | Eric Chamoun, Marzieh Saeidi, Andreas Vlachos |  |
| 2188 |  |  [A Digital Language Coherence Marker for Monitoring Dementia](https://doi.org/10.18653/v1/2023.emnlp-main.994) |  | 0 |  | Dimitris Gkoumas, Adam Tsakalidis, Maria Liakata |  |
| 2189 |  |  [Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks](https://doi.org/10.18653/v1/2023.emnlp-main.995) |  | 0 |  | Heng Wang, Wenqian Zhang, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Qinghua Zheng, Minnan Luo |  |
| 2190 |  |  [Joyful: Joint Modality Fusion and Graph Contrastive Learning for Multimoda Emotion Recognition](https://doi.org/10.18653/v1/2023.emnlp-main.996) |  | 0 |  | Dongyuan Li, Yusong Wang, Kotaro Funakoshi, Manabu Okumura |  |
| 2191 |  |  [HyperRank: Hyperbolic Ranking Model for Unsupervised Keyphrase Extraction](https://doi.org/10.18653/v1/2023.emnlp-main.997) |  | 0 |  | Mingyang Song, Huafeng Liu, Liping Jing |  |
| 2192 |  |  [Assessing the influence of attractor-verb distance on grammatical agreement in humans and language models](https://doi.org/10.18653/v1/2023.emnlp-main.998) |  | 0 |  | ChristosNikolaos Zacharopoulos, Théo Desbordes, Mathias SabléMeyer |  |
| 2193 |  |  [Federated Meta-Learning for Emotion and Sentiment Aware Multi-modal Complaint Identification](https://doi.org/10.18653/v1/2023.emnlp-main.999) |  | 0 |  | Apoorva Singh, Siddarth Chandrasekar, Sriparna Saha, Tanmay Sen |  |
| 2194 |  |  [Semantic Similarity Models for Depression Severity Estimation](https://doi.org/10.18653/v1/2023.emnlp-main.1000) |  | 0 |  | Anxo Pérez, Neha Warikoo, Kexin Wang, Javier Parapar, Iryna Gurevych |  |
| 2195 |  |  [Hop, Union, Generate: Explainable Multi-hop Reasoning without Rationale Supervision](https://doi.org/10.18653/v1/2023.emnlp-main.1001) |  | 0 |  | Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush |  |
| 2196 |  |  [To Split or Not to Split: Composing Compounds in Contextual Vector Spaces](https://doi.org/10.18653/v1/2023.emnlp-main.1002) |  | 0 |  | Christopher Jenkins, Filip Miletic, Sabine Schulte im Walde |  |
| 2197 |  |  [ToolWriter: Question Specific Tool Synthesis for Tabular Data](https://doi.org/10.18653/v1/2023.emnlp-main.1003) |  | 0 |  | Carlos Gemmell, Jeff Dalton |  |
| 2198 |  |  [Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations](https://doi.org/10.18653/v1/2023.emnlp-main.1004) |  | 0 |  | Yuan Tian, Zheng Zhang, Zheng Ning, Toby JiaJun Li, Jonathan K. Kummerfeld, Tianyi Zhang |  |
| 2199 |  |  [CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Low Resource With Contrastive Learning](https://doi.org/10.18653/v1/2023.emnlp-main.1005) |  | 0 |  | Xiaoming Liu, Zhaohan Zhang, Yichen Wang, Hang Pu, Yu Lan, Chao Shen |  |
| 2200 |  |  [AnyTOD: A Programmable Task-Oriented Dialog System](https://doi.org/10.18653/v1/2023.emnlp-main.1006) |  | 0 |  | Jeffrey Zhao, Yuan Cao, Raghav Gupta, Harrison Lee, Abhinav Rastogi, Mingqiu Wang, Hagen Soltau, Izhak Shafran, Yonghui Wu |  |
| 2201 |  |  [Can LMs Generalize to Future Data? An Empirical Analysis on Text Summarization](https://doi.org/10.18653/v1/2023.emnlp-main.1007) |  | 0 |  | Chi Seng Cheang, Hou Pong Chan, Derek F. Wong, Xuebo Liu, Zhaocong Li, Yanming Sun, Shudong Liu, Lidia S. Chao |  |
| 2202 |  |  [Zero-Shot Multi-Label Topic Inference with Sentence Encoders and LLMs](https://doi.org/10.18653/v1/2023.emnlp-main.1008) |  | 0 |  | Souvika Sarkar, Dongji Feng, Shubhra Kanti Karmaker Santu |  |
| 2203 |  |  [TaskDiff: A Similarity Metric for Task-Oriented Conversations](https://doi.org/10.18653/v1/2023.emnlp-main.1009) |  | 0 |  | Ankita Bhaumik, Praveen Venkateswaran, Yara Rizk, Vatche Isahagian |  |
| 2204 |  |  [Not all Fake News is Written: A Dataset and Analysis of Misleading Video Headlines](https://doi.org/10.18653/v1/2023.emnlp-main.1010) |  | 0 |  | Yoo Yeon Sung, Jordan L. BoydGraber, Naeemul Hassan |  |
| 2205 |  |  [Learning From Free-Text Human Feedback - Collect New Datasets Or Extend Existing Ones?](https://doi.org/10.18653/v1/2023.emnlp-main.1011) |  | 0 |  | Dominic Petrak, Nafise Sadat Moosavi, Ye Tian, Nikolai Rozanov, Iryna Gurevych |  |
| 2206 |  |  [Euphemistic Abuse - A New Dataset and Classification Experiments for Implicitly Abusive Language](https://doi.org/10.18653/v1/2023.emnlp-main.1012) |  | 0 |  | Michael Wiegand, Jana Kampfmeier, Elisabeth Eder, Josef Ruppenhofer |  |
| 2207 |  |  [Exploring Distributional Shifts in Large Language Models for Code Analysis](https://doi.org/10.18653/v1/2023.emnlp-main.1013) |  | 0 |  | Shushan Arakelyan, Rocktim Jyoti Das, Yi Mao, Xiang Ren |  |
| 2208 |  |  [ATHENA: Mathematical Reasoning with Thought Expansion](https://doi.org/10.18653/v1/2023.emnlp-main.1014) |  | 0 |  | JB. Kim, Hazel Kim, Joonghyuk Hahn, YoSub Han |  |
| 2209 |  |  [A Benchmark for Reasoning with Spatial Prepositions](https://doi.org/10.18653/v1/2023.emnlp-main.1015) |  | 0 |  | Iulia M. Comsa, Srini Narayanan |  |
| 2210 |  |  [TIMELINE: Exhaustive Annotation of Temporal Relations Supporting the Automatic Ordering of Events in News Articles](https://doi.org/10.18653/v1/2023.emnlp-main.1016) |  | 0 |  | Sarah Alsayyahi, Riza BatistaNavarro |  |
| 2211 |  |  [Mitigating Over-Generation for Unsupervised Keyphrase Extraction with Heterogeneous Centrality Detection](https://doi.org/10.18653/v1/2023.emnlp-main.1017) |  | 0 |  | Mingyang Song, Pengyu Xu, Yi Feng, Huafeng Liu, Liping Jing |  |
| 2212 |  |  [Towards Interpretable and Efficient Automatic Reference-Based Summarization Evaluation](https://doi.org/10.18653/v1/2023.emnlp-main.1018) |  | 0 |  | Yixin Liu, Alexander R. Fabbri, Yilun Zhao, Pengfei Liu, Shafiq Joty, ChienSheng Wu, Caiming Xiong, Dragomir Radev |  |
| 2213 |  |  [MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding](https://doi.org/10.18653/v1/2023.emnlp-main.1019) |  | 0 |  | Steven H. Wang, Antoine Scardigli, Leonard Tang, Wei Chen, Dimitry Levkin, Anya Chen, Spencer Ball, Thomas Woodside, Oliver Zhang, Dan Hendrycks |  |
| 2214 |  |  [PK-ICR: Persona-Knowledge Interactive Multi-Context Retrieval for Grounded Dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.1020) |  | 0 |  | Minsik Oh, Joosung Lee, Jiwei Li, Guoyin Wang |  |
| 2215 |  |  [More Than Spoken Words: Nonverbal Message Extraction and Generation](https://doi.org/10.18653/v1/2023.emnlp-main.1021) |  | 0 |  | Dian Yu, Xiaoyang Wang, Wanshun Chen, Nan Du, Longyue Wang, Haitao Mi, Dong Yu |  |
| 2216 |  |  [Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance](https://doi.org/10.18653/v1/2023.emnlp-main.1022) |  | 0 |  | Molly R. Petersen, Lonneke van der Plas |  |
| 2217 |  |  [FAME: Flexible, Scalable Analogy Mappings Engine](https://doi.org/10.18653/v1/2023.emnlp-main.1023) |  | 0 |  | Shahar Jacob, Chen Shani, Dafna Shahaf |  |
| 2218 |  |  [A Self-training Framework for Automated Medical Report Generation](https://doi.org/10.18653/v1/2023.emnlp-main.1024) |  | 0 |  | Siyuan Wang, Zheng Liu, Bo Peng |  |
| 2219 |  |  [A Picture is Worth a Thousand Words: Language Models Plan from Pixels](https://doi.org/10.18653/v1/2023.emnlp-main.1025) |  | 0 |  | Anthony Z. Liu, Lajanugen Logeswaran, Sungryull Sohn, Honglak Lee |  |
| 2220 |  |  [Interpreting and Exploiting Functional Specialization in Multi-Head Attention under Multi-task Learning](https://doi.org/10.18653/v1/2023.emnlp-main.1026) |  | 0 |  | Chong Li, Shaonan Wang, Yunhao Zhang, Jiajun Zhang, Chengqing Zong |  |
| 2221 |  |  [Multilingual Previously Fact-Checked Claim Retrieval](https://doi.org/10.18653/v1/2023.emnlp-main.1027) |  | 0 |  | Matús Pikuliak, Ivan Srba, Róbert Móro, Timo Hromadka, Timotej Smolen, Martin Melisek, Ivan Vykopal, Jakub Simko, Juraj Podrouzek, Mária Bieliková |  |
| 2222 |  |  [ALCAP: Alignment-Augmented Music Captioner](https://doi.org/10.18653/v1/2023.emnlp-main.1028) |  | 0 |  | Zihao He, Weituo Hao, Wei Tsung Lu, Changyou Chen, Kristina Lerman, Xuchen Song |  |
| 2223 |  |  [Do Transformers Parse while Predicting the Masked Word?](https://doi.org/10.18653/v1/2023.emnlp-main.1029) |  | 0 |  | Haoyu Zhao, Abhishek Panigrahi, Rong Ge, Sanjeev Arora |  |
| 2224 |  |  [Composable Text Controls in Latent Space with ODEs](https://doi.org/10.18653/v1/2023.emnlp-main.1030) |  | 0 |  | Guangyi Liu, Zeyu Feng, Yuan Gao, Zichao Yang, Xiaodan Liang, Junwei Bao, Xiaodong He, Shuguang Cui, Zhen Li, Zhiting Hu |  |
| 2225 |  |  [P5: Plug-and-Play Persona Prompting for Personalized Response Selection](https://doi.org/10.18653/v1/2023.emnlp-main.1031) |  | 0 |  | Joosung Lee, Minsik Oh, Donghun Lee |  |
| 2226 |  |  [Reader: Model-based language-instructed reinforcement learning](https://doi.org/10.18653/v1/2023.emnlp-main.1032) |  | 0 |  | Nicola Dainese, Pekka Marttinen, Alexander Ilin |  |
| 2227 |  |  [Adapting Offline Speech Translation Models for Streaming with Future-Aware Distillation and Inference](https://doi.org/10.18653/v1/2023.emnlp-main.1033) |  | 0 |  | Biao Fu, Minpeng Liao, Kai Fan, Zhongqiang Huang, Boxing Chen, Yidong Chen, Xiaodong Shi |  |
| 2228 |  |  [Relation-aware Ensemble Learning for Knowledge Graph Embedding](https://doi.org/10.18653/v1/2023.emnlp-main.1034) |  | 0 |  | Ling Yue, Yongqi Zhang, Quanming Yao, Yong Li, Xian Wu, Ziheng Zhang, Zhenxi Lin, Yefeng Zheng |  |
| 2229 |  |  [GenEx: A Commonsense-aware Unified Generative Framework for Explainable Cyberbullying Detection](https://doi.org/10.18653/v1/2023.emnlp-main.1035) |  | 0 |  | Krishanu Maity, Raghav Jain, Prince Jha, Sriparna Saha, Pushpak Bhattacharyya |  |
| 2230 |  |  [Document-Level Machine Translation with Large Language Models](https://doi.org/10.18653/v1/2023.emnlp-main.1036) |  | 0 |  | Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, Zhaopeng Tu |  |
| 2231 |  |  [Multilingual Simplification of Medical Texts](https://doi.org/10.18653/v1/2023.emnlp-main.1037) |  | 0 |  | Sebastian Joseph, Kathryn Kazanas, Keziah Reina, Vishnesh J. Ramanathan, Wei Xu, Byron C. Wallace, Junyi Jessy Li |  |
| 2232 |  |  [When Reviewers Lock Horns: Finding Disagreements in Scientific Peer Reviews](https://doi.org/10.18653/v1/2023.emnlp-main.1038) |  | 0 |  | Sandeep Kumar, Tirthankar Ghosal, Asif Ekbal |  |
| 2233 |  |  [Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation](https://doi.org/10.18653/v1/2023.emnlp-main.1039) |  | 0 |  | Jiayu Lin, Rong Ye, Meng Han, Qi Zhang, Ruofei Lai, Xinyu Zhang, Zhao Cao, Xuanjing Huang, Zhongyu Wei |  |
| 2234 |  |  [JASMINE: Arabic GPT Models for Few-Shot Learning](https://doi.org/10.18653/v1/2023.emnlp-main.1040) |  | 0 |  | El Moatez Billah Nagoudi, Muhammad AbdulMageed, AbdelRahim A. Elmadany, Alcides Alcoba Inciarte, Md Tawkat Islam Khondaker |  |
| 2235 |  |  [NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports](https://doi.org/10.18653/v1/2023.emnlp-main.1041) |  | 0 |  | Maël Jullien, Marco Valentino, Hannah Frost, Paul O'Regan, Dónal Landers, André Freitas |  |
| 2236 |  |  [Addressing Linguistic Bias through a Contrastive Analysis of Academic Writing in the NLP Domain](https://doi.org/10.18653/v1/2023.emnlp-main.1042) |  | 0 |  | Robert Ridley, Zhen Wu, Jianbing Zhang, Shujian Huang, Xinyu Dai |  |
| 2237 |  |  [RobustGEC: Robust Grammatical Error Correction Against Subtle Context Perturbation](https://doi.org/10.18653/v1/2023.emnlp-main.1043) |  | 0 |  | Yue Zhang, Leyang Cui, Enbo Zhao, Wei Bi, Shuming Shi |  |
| 2238 |  |  [Detecting Propaganda Techniques in Code-Switched Social Media Text](https://doi.org/10.18653/v1/2023.emnlp-main.1044) |  | 0 |  | Muhammad Umar Salman, Asif Hanif, Shady Shehata, Preslav Nakov |  |
| 2239 |  |  [Speech Recognition and Meaning Interpretation: Towards Disambiguation of Structurally Ambiguous Spoken Utterances in Indonesian](https://doi.org/10.18653/v1/2023.emnlp-main.1045) |  | 0 |  | Ruhiyah Widiaputri, Ayu Purwarianti, Dessi Puji Lestari, Kurniawati Azizah, Dipta Tanaya, Sakriani Sakti |  |
| 2240 |  |  [Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.emnlp-main.1046) |  | 0 |  | Minwoo Lee, Hyukhun Koh, Kangil Lee, Dongdong Zhang, Minsung Kim, Kyomin Jung |  |
| 2241 |  |  [Code-Switching Metrics Using Intonation Units](https://doi.org/10.18653/v1/2023.emnlp-main.1047) |  | 0 |  | Rebecca Pattichis, Dora LaCasse, Sonya Trawick, Rena Cacoullos |  |

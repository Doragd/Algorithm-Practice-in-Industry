# EMNLP2024

## 会议论文列表

本会议共有 2396 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.emnlp-industry.0) |  | 0 |  |  |  |
| 2 |  |  [Optimizing Entity Resolution in Voice Interfaces: An ASR-Aware Entity Reference Expansion Approach](https://doi.org/10.18653/v1/2024.emnlp-industry.1) |  | 0 | This paper tackles the challenges presented by Automatic Speech Recognition (ASR) errors in voice-based dialog systems, specifically, their adverse impact on Entity Resolution (ER) as a downstream task. Navigating the equilibrium between accuracy and online retrieval’s speed requirement proves... | Jiangning Chen, Ziyun Zhang, Qianli Hu |  |
| 3 |  |  [Two-tiered Encoder-based Hallucination Detection for Retrieval-Augmented Generation in the Wild](https://doi.org/10.18653/v1/2024.emnlp-industry.2) |  | 0 | Detecting hallucinations, where Large Language Models (LLMs) are not factually consistent with a Knowledge Base (KB), is a challenge for Retrieval-Augmented Generation (RAG) systems. Current solutions rely on public datasets to develop prompts or fine-tune a Natural Language Inference (NLI) model.... | Ilana Zimmerman, Jadin Tredup, Ethan Selfridge, Joseph Bradley |  |
| 4 |  |  [The Program Testing Ability of Large Language Models for Code](https://doi.org/10.18653/v1/2024.emnlp-industry.3) |  | 0 | Recent development of large language models (LLMs) for code like CodeX and CodeT5+ shows promise in achieving code intelligence. Their ability of synthesizing program targeting a pre-defined algorithmic coding task has been intensively tested and verified on datasets including HumanEval and MBPP.... | Weimin Xiong, Yiwen Guo, Hao Chen |  |
| 5 |  |  [Salient Information Prompting to Steer Content in Prompt-based Abstractive Summarization](https://doi.org/10.18653/v1/2024.emnlp-industry.4) |  | 0 | Large language models (LLMs) can generate fluent summaries across domains using prompting techniques, reducing the effort required for summarization applications. However, crafting effective prompts that guide LLMs to generate summaries with the appropriate level of detail and writing style remains... | Lei Xu, Mohammed Asad Karim, Saket Dingliwal, Aparna Elangovan |  |
| 6 |  |  [Predicting Entity Salience in Extremely Short Documents](https://doi.org/10.18653/v1/2024.emnlp-industry.5) |  | 0 | A frequent challenge in applications that use entities extracted from text documents is selecting the most salient entities when only a small number can be used by the application (e.g., displayed to a user). Solving this challenge is particularly difficult in the setting of extremely short... | Benjamin L. Bullough, Harrison Lundberg, Chen Hu, Weihang Xiao |  |
| 7 |  |  [Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention](https://doi.org/10.18653/v1/2024.emnlp-industry.6) |  | 0 | Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resources. In this paper, we present a topic... | ShuTing Pi, Pradeep Bagavan, Yejia Li, Disha Disha, Qun Liu |  |
| 8 |  |  [Retrieval Augmented Spelling Correction for E-Commerce Applications](https://doi.org/10.18653/v1/2024.emnlp-industry.7) |  | 0 | The rapid introduction of new brand names into everyday language poses a unique challenge for e-commerce spelling correction services, which must distinguish genuine misspellings from novel brand names that use unconventional spelling. We seek to address this challenge via Retrieval Augmented... | Xuan Guo, Rohit Patki, Dante Everaert, Christopher Potts |  |
| 9 |  |  [Scaling Parameter-Constrained Language Models with Quality Data](https://doi.org/10.18653/v1/2024.emnlp-industry.8) |  | 0 | Scaling laws in language modeling traditionally quantify training loss as a function of dataset size and model parameters, providing compute-optimal estimates but often neglecting the impact of data quality on model generalization.In this paper, we extend the conventional understanding of scaling... | Ernie Chang, Matteo Paltenghi, Yang Li, PinJie Lin, Changsheng Zhao, Patrick Huber, Zechun Liu, Rastislav Rabatin, Yangyang Shi, Vikas Chandra |  |
| 10 |  |  [INDUS: Effective and Efficient Language Models for Scientific Applications](https://doi.org/10.18653/v1/2024.emnlp-industry.9) |  | 0 | Large language models (LLMs) trained on general domain corpora showed remarkable results on natural language processing (NLP) tasks. However, previous research demonstrated LLMs trained using domain-focused corpora perform better on specialized tasks. Inspired by this insight, we developed INDUS, a... | Bishwaranjan Bhattacharjee, Aashka Trivedi, Masayasu Muraoka, Muthukumaran Ramasubramanian, Takuma Udagawa, Iksha Gurung, Nishan Pantha, Rong Zhang, Bharath Dandala, Rahul Ramachandran, Manil Maskey, Kaylin M. Bugbee, Michael Little, Elizabeth Fancher, Irina Gerasimov, Armin Mehrabian, Lauren M. Sanders, Sylvain Costes, Sergi BlancoCuaresma, Kelly E. Lockhart, Thomas Allen, Félix Grèzes, Megan Ansdell, Alberto Accomazzi, Yousef ElKurdi, Davis Wertheimer, Birgit Pfitzmann, Cesar Berrospi Ramis, Michele Dolfi, Rafael Teixeira de Lima, Panagiotis Vagenas, S. Karthik Mukkavilli, Peter W. J. Staar, Sanaz Vahidinia, Ryan McGranaghan, Tsengdar J. Lee |  |
| 11 |  |  [DL-QAT: Weight-Decomposed Low-Rank Quantization-Aware Training for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.10) |  | 0 | Improving the efficiency of inference in Large Language Models (LLMs) is a critical area of research. Post-training Quantization (PTQ) is a popular technique, but it often faces challenges at low-bit levels, particularly in downstream tasks. Quantization-aware Training (QAT) can alleviate this... | Wenjing Ke, Zhe Li, Dong Li, Lu Tian, Emad Barsoum |  |
| 12 |  |  [Hybrid-RACA: Hybrid Retrieval-Augmented Composition Assistance for Real-time Text Prediction](https://doi.org/10.18653/v1/2024.emnlp-industry.11) |  | 0 | Large language models (LLMs) enhanced with retrieval augmentation has shown great performance in many applications. However, the computational demands for these models pose a challenge when applying them to real-time tasks, such as composition assistance. To address this, we propose Hybrid... | Menglin Xia, Xuchao Zhang, Camille Couturier, Guoqing Zheng, Saravan Rajmohan, Victor Rühle |  |
| 13 |  |  [LLMC: Benchmarking Large Language Model Quantization with a Versatile Compression Toolkit](https://doi.org/10.18653/v1/2024.emnlp-industry.12) |  | 0 | Recent advancements in large language models (LLMs) are propelling us toward artificial general intelligence with their remarkable emergent abilities and reasoning capabilities. However, the substantial computational and memory requirements limit the widespread adoption. Quantization, a key... | Ruihao Gong, Yang Yong, Shiqiao Gu, Yushi Huang, Chengtao Lv, Yunchen Zhang, Dacheng Tao, Xianglong Liu |  |
| 14 |  |  [PDFTriage: Question Answering over Long, Structured Documents](https://doi.org/10.18653/v1/2024.emnlp-industry.13) |  | 0 | Large Language Models (LLMs) have issues with document question answering (QA) in situations where the document is unable to fit in the small context length of an LLM. To overcome this issue, most existing works focus on retrieving the relevant context from the document, representing them as plain... | Jon SaadFalcon, Joe Barrow, Alexa F. Siu, Ani Nenkova, Seunghyun Yoon, Ryan A. Rossi, Franck Dernoncourt |  |
| 15 |  |  [Fairness-Aware Online Positive-Unlabeled Learning](https://doi.org/10.18653/v1/2024.emnlp-industry.14) |  | 0 | Machine learning applications for text classification are increasingly used in domains such as toxicity and misinformation detection in online settings. However, obtaining precisely labeled data for training remains challenging, particularly because not all problematic instances are reported.... | Hoin Jung, Xiaoqian Wang |  |
| 16 |  |  [SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.15) |  | 0 | This study presents a novel learning approach designed to enhance both mathematical reasoning and problem-solving abilities of Large Language Models (LLMs). We focus on integrating the Chain-of-Thought (CoT) and the Program-of-Thought (PoT) learning, hypothesizing that prioritizing the learning of... | Hyeonwoo Kim, Gyoungjin Gim, Yungi Kim, Jihoo Kim, Byungju Kim, Wonseok Lee, Chanjun Park |  |
| 17 |  |  [Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble](https://doi.org/10.18653/v1/2024.emnlp-industry.16) |  | 0 | Increasing use of large language models (LLMs) demand performant guardrails to ensure the safety of inputs and outputs of LLMs. When these safeguards are trained on imbalanced data, they can learn the societal biases. We present a light-weight, post-processing method for mitigating counterfactual... | Olivia Sturman, Aparna Joshi, Bhaktipriya Radharapu, Piyush Kumar, Renee Shelby |  |
| 18 |  |  [Centrality-aware Product Retrieval and Ranking](https://doi.org/10.18653/v1/2024.emnlp-industry.17) |  | 0 | This paper addresses the challenge of improving user experience on e-commerce platforms by enhancing product ranking relevant to user’s search queries. Ambiguity and complexity of user queries often lead to a mismatch between user’s intent and retrieved product titles or documents. Recent... | Hadeel Saadany, Swapnil Bhosale, Samarth Agrawal, Diptesh Kanojia, Constantin Orasan, Zhe Wu |  |
| 19 |  |  [Fusion-Eval: Integrating Assistant Evaluators with LLMs](https://doi.org/10.18653/v1/2024.emnlp-industry.18) |  | 0 | Evaluating natural language generation (NLG) systems automatically poses significant challenges.Recent studies have employed large language models (LLMs) as reference-free metrics for NLG evaluation, enhancing adaptability to new tasks tasks. However, these methods still show lower correspondence... | Lei Shu, Nevan Wichers, Liangchen Luo, Yun Zhu, Yinxiao Liu, Jindong Chen, Lei Meng |  |
| 20 |  |  [Investigating the Personality Consistency in Quantized Role-Playing Dialogue Agents](https://doi.org/10.18653/v1/2024.emnlp-industry.19) |  | 0 | This study explores the consistency of personality traits in quantized large language models (LLMs) for edge device role-playing scenarios. Using the Big Five personality traits model, we evaluate how stable assigned personalities are for Quantized Role-Playing Dialog Agents (QRPDA) during... | Yixiao Wang, Homa Fashandi, Kevin Ferreira |  |
| 21 |  |  [Robust ASR Error Correction with Conservative Data Filtering](https://doi.org/10.18653/v1/2024.emnlp-industry.20) |  | 0 | Error correction (EC) based on large language models is an emerging technology to enhance the performance of automatic speech recognition (ASR) systems.Generally, training data for EC are collected by automatically pairing a large set of ASR hypotheses (as sources) and their gold references (as... | Takuma Udagawa, Masayuki Suzuki, Masayasu Muraoka, Gakuto Kurata |  |
| 22 |  |  [Code Representation Pre-training with Complements from Program Executions](https://doi.org/10.18653/v1/2024.emnlp-industry.21) |  | 0 | Language models for natural language processing have been grafted onto programming language modeling for advancing code intelligence. Although it can be represented in the text format, code is syntactically more rigorous, as it is designed to be properly compiled or interpreted to perform a set of... | Jiabo Huang, Jianyu Zhao, Yuyang Rong, Yiwen Guo, Yifeng He, Hao Chen |  |
| 23 |  |  [ScaleLLM: A Resource-Frugal LLM Serving Framework by Optimizing End-to-End Efficiency](https://doi.org/10.18653/v1/2024.emnlp-industry.22) |  | 0 | Large language models (LLMs) have surged in popularity and are extensively used in commercial applications, where the efficiency of model serving is crucial for the user experience. Most current research focuses on optimizing individual sub-procedures, e.g. local inference and communication,... | Yuhang Yao, Han Jin, Alay Dilipbhai Shah, Shanshan Han, Zijian Hu, Dimitris Stripelis, Yide Ran, Zhaozhuo Xu, Salman Avestimehr, Chaoyang He |  |
| 24 |  |  [Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context](https://doi.org/10.18653/v1/2024.emnlp-industry.23) |  | 0 | This paper introduces a novel framework that combines graph-driven context retrieval in conjunction to knowledge graphs based enhancement, honing the proficiency of LLMs, especially in domain specific community question answering platforms like AskUbuntu, Unix, and ServerFault. We conduct... | Somnath Banerjee, Amruit Sahoo, Sayan Layek, Avik Dutta, Rima Hazra, Animesh Mukherjee |  |
| 25 |  |  [SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions](https://doi.org/10.18653/v1/2024.emnlp-industry.24) |  | 0 | The electric vehicle (EV) battery supply chain’s vulnerability to disruptions necessitates advanced predictive analytics. We present SHIELD (Schema-based Hierarchical Induction for EV supply chain Disruption), a system integrating Large Language Models (LLMs) with domain expertise for EV battery... | ZhiQi Cheng, Yifei Dong, Aike Shi, Wei Liu, Yuzhi Hu, Jason O'Connor, Alexander G. Hauptmann, Kate Whitefoot |  |
| 26 |  |  [Divide-Conquer-Reasoning for Consistency Evaluation and Automatic Improvement of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.25) |  | 0 | Evaluating the quality and consistency of text generated by Large Language Models (LLMs) poses a significant, yet unresolved challenge for industry research. We propose , an automated framework for evaluating and improving the consistency of LLM-generated texts using a divide-conquer-reasoning... | Wendi Cui, Zhuohang Li, Damien Lopez, Kamalika Das, Bradley A. Malin, Kumar Sricharan, Jiaxin Zhang |  |
| 27 |  |  [Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt](https://doi.org/10.18653/v1/2024.emnlp-industry.26) |  | 0 | Financial documents are filled with specialized terminology, arcane jargon, and curious acronyms that pose challenges for general-purpose text embeddings. Yet, few text embeddings specialized for finance have been reported in the literature, perhaps in part due to a lack of public datasets and... | Peter Anderson, Mano Vikash Janardhanan, Jason He, Wei Cheng, Charlie Flanagan |  |
| 28 |  |  [TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Industry Systems](https://doi.org/10.18653/v1/2024.emnlp-industry.27) |  | 0 | Large Language Models (LLMs) have demonstrated proficiency in addressing tasks that necessitate a combination of task planning and the usage of external tools, such as weather and calculator APIs. However, real-world industrial systems present prevalent challenges in task planning and tool usage:... | Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Du Qing, Xiaoru Hu, Hangyu Mao, Ziyue Li, Xingyu Zeng, Rui Zhao, Xueqian Wang |  |
| 29 |  |  [Detecting Ambiguous Utterances in an Intelligent Assistant](https://doi.org/10.18653/v1/2024.emnlp-industry.28) |  | 0 | In intelligent assistants that perform both chatting and tasks through dialogue, like Siri and Alexa, users often make ambiguous utterances such as “I’m hungry” or “I have a headache,” which can be interpreted as either chat or task intents. Naively determining these intents can lead to mismatched... | Satoshi Akasaki, Manabu Sassano |  |
| 30 |  |  [GeoIndia: A Seq2Seq Geocoding Approach for Indian Addresses](https://doi.org/10.18653/v1/2024.emnlp-industry.29) |  | 0 | Geocoding, the conversion of unstructured geographic text into structured spatial data, is essential for logistics, urban planning, and location-based services. Indian addresses with their diverse languages, scripts, and formats present significant challenges that existing geocoding methods often... | Bhavuk Singhal, Anshu Aditya, Lokesh Todwal, Shubham Jain, Debashis Mukherjee |  |
| 31 |  |  [Moleco: Molecular Contrastive Learning with Chemical Language Models for Molecular Property Prediction](https://doi.org/10.18653/v1/2024.emnlp-industry.30) |  | 0 | Pre-trained chemical language models (CLMs) excel in the field of molecular property prediction, utilizing string-based molecular descriptors such as SMILES for learning universal representations. However, such string-based descriptors implicitly contain limited structural information, which is... | JunHyung Park, Hyuntae Park, Yeachan Kim, Woosang Lim, SangKeun Lee |  |
| 32 |  |  [SEED: Semantic Knowledge Transfer for Language Model Adaptation to Materials Science](https://doi.org/10.18653/v1/2024.emnlp-industry.31) |  | 0 | Materials science is an interdisciplinary field focused on studying and discovering materials around us. However, due to the vast space of materials, datasets in this field are typically scarce and have limited coverage. This inherent limitation makes current adaptation methods less effective when... | Yeachan Kim, JunHyung Park, SungHo Kim, Juhyeong Park, Sangyun Kim, SangKeun Lee |  |
| 33 |  |  [News Risk Alerting System (NRAS): A Data-Driven LLM Approach to Proactive Credit Risk Monitoring](https://doi.org/10.18653/v1/2024.emnlp-industry.32) |  | 0 | Credit risk monitoring is an essential process for financial institutions to evaluate the creditworthiness of borrowing entities and minimize potential losses. Traditionally, this involves the periodic assessment of news regarding client companies to identify events which can impact their financial... | Adil Nygaard, Ashish Upadhyay, Lauren Hinkle, Xenia Skotti, Joe Halliwell, Ian Brown, Glen Noronha |  |
| 34 |  |  [FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech Language Model](https://doi.org/10.18653/v1/2024.emnlp-industry.33) |  | 0 | In this study, we aim to explore Multitask Speech Language Model (SpeechLM) efficient inference via token reduction. Unlike other modalities such as vision or text, speech has unique temporal dependencies, making previous efficient inference works on other modalities not directly applicable.... | Yichen Lu, Jiaqi Song, ChaoHan Huck Yang, Shinji Watanabe |  |
| 35 |  |  [TensorOpera Router: A Multi-Model Router for Efficient LLM Inference](https://doi.org/10.18653/v1/2024.emnlp-industry.34) |  | 0 | With the rapid growth of Large Language Models (LLMs) across various domains, numerous new LLMs have emerged, each possessing domain-specific expertise. This proliferation has highlighted the need for quick, high-quality, and cost-effective LLM query response methods. Yet, no single LLM exists to... | Dimitris Stripelis, Zhaozhuo Xu, Zijian Hu, Alay Dilipbhai Shah, Han Jin, Yuhang Yao, Jipeng Zhang, Tong Zhang, Salman Avestimehr, Chaoyang He |  |
| 36 |  |  [Prompt-Tuned Muti-Task Taxonomic Transformer (PTMTTaxoFormer)](https://doi.org/10.18653/v1/2024.emnlp-industry.35) |  | 0 | Hierarchical Text Classification (HTC) is a subclass of multi-label classification, it is challenging because the hierarchy typically has a large number of diverse topics. Existing methods for HTC fall within two categories, local methods (a classifier for each level, node, or parent) or global... | Rajashekar Vasantha, Nhan Nguyen, Yue Zhang |  |
| 37 |  |  [Arcee's MergeKit: A Toolkit for Merging Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.36) |  | 0 | The rapid growth of open-source language models provides the opportunity to merge model checkpoints, combining their parameters to improve performance and versatility. Advances in transfer learning have led to numerous task-specific models, which model merging can integrate into powerful multitask... | Charles Goddard, Shamane Siriwardhana, Malikeh Ehghaghi, Luke Meyers, Vladimir Karpukhin, Brian Benedict, Mark McQuade, Jacob Solawetz |  |
| 38 |  |  [Personal Large Language Model Agents: A Case Study on Tailored Travel Planning](https://doi.org/10.18653/v1/2024.emnlp-industry.37) |  | 0 | Large Language Models (LLMs) have made significant progress, becoming more autonomous and capable of handling real-world tasks through their access to tools, various planning strategies, and memory, referred to as LLM agents. One emerging area of focus is customizing these models to cater to... | Harmanpreet Singh, Nikhil Verma, Yixiao Wang, Manasa Bharadwaj, Homa Fashandi, Kevin Ferreira, Chul Lee |  |
| 39 |  |  [FanLoRA: Fantastic LoRAs and Where to Find Them in Large Language Model Fine-tuning](https://doi.org/10.18653/v1/2024.emnlp-industry.38) |  | 0 | Full-parameter fine-tuning is computationally prohibitive for large language models (LLMs), making parameter-efficient fine-tuning (PEFT) methods like low-rank adaptation (LoRA) increasingly popular. However, LoRA and its existing variants introduce significant latency in multi-tenant settings,... | Aaron Xuxiang Tian, Yi Zhao, Congrui Yin, Wei Zhu, Xing Tian, Yi Ge |  |
| 40 |  |  [ReportGPT: Human-in-the-loop Verifiable Table-to-Text Generation](https://doi.org/10.18653/v1/2024.emnlp-industry.39) |  | 0 | Recent developments in the quality and accessibility of large language models have precipitated a surge in user-facing tools for content generation. Motivated by a necessity for human quality control of these systems, we introduce ReportGPT: a pipeline framework for verifiable human-in-the-loop... | Lucas Cecchi, Petr Babkin |  |
| 41 |  |  [BPID: A Benchmark for Personal Identity Deduplication](https://doi.org/10.18653/v1/2024.emnlp-industry.40) |  | 0 | Data deduplication is a critical task in data management and mining, focused on consolidating duplicate records that refer to the same entity. Personally Identifiable Information (PII) is a critical class of data for deduplication across various industries. Consumer data, stored and generated... | Runhui Wang, Yefan Tao, Adit Krishnan, Luyang Kong, Xuanqing Liu, Yuqian Deng, Yunzhao Yang, Henrik Johnson, Andrew Borthwick, Shobhit Gupta, Aditi Gundlapalli, Davor Golac |  |
| 42 |  |  [MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline](https://doi.org/10.18653/v1/2024.emnlp-industry.41) |  | 0 | The rapid expansion of multimedia content has made accurately retrieving relevant videos from large collections increasingly challenging. Recent advancements in text-video retrieval have focused on cross-modal interactions, large-scale foundation model training, and probabilistic modeling, yet... | Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak |  |
| 43 |  |  [Identifying High Consideration E-Commerce Search Queries](https://doi.org/10.18653/v1/2024.emnlp-industry.42) |  | 0 | In e-commerce, high consideration search missions typically require careful and elaborate decision making, and involve a substantial research investment from customers. We consider the task of identifying High Consideration (HC) queries. Identifying such queries enables e-commerce sites to better... | Zhiyu Chen, Jason Ingyu Choi, Besnik Fetahu, Shervin Malmasi |  |
| 44 |  |  [Sample Design Engineering: An Empirical Study on Designing Better Fine-Tuning Samples for Information Extraction with LLMs](https://doi.org/10.18653/v1/2024.emnlp-industry.43) |  | 0 | Large language models (LLMs) have achieved significant leadership in many NLP tasks, but aligning structured output with generative models in information extraction (IE) tasks remains a challenge. Prompt Engineering (PE) is renowned for improving IE performance through prompt modifications.... | Biyang Guo, He Wang, Wenyilin Xiao, Hong Chen, Zhuxin Lee, Songqiao Han, Hailiang Huang |  |
| 45 |  |  [Refining App Reviews: Dataset, Methodology, and Evaluation](https://doi.org/10.18653/v1/2024.emnlp-industry.44) |  | 0 | With the growing number of mobile users, app development has become increasingly lucrative. Reviews on platforms such as Google Play and Apple App Store provide valuable insights to developers, highlighting bugs, suggesting new features, and offering feedback. However, many reviews contain typos,... | Amrita Singh, Chirag Jain, Mohit Chaudhary, Preethu Anish |  |
| 46 |  |  [TelBench: A Benchmark for Evaluating Telco-Specific Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.45) |  | 0 | The telecommunications industry, characterized by its vast customer base and complex service offerings, necessitates a high level of domain expertise and proficiency in customer service center operations. Consequently, there is a growing demand for Large Language Models (LLMs) to augment the... | Sunwoo Lee, Dhammiko Arya, SeungMo Cho, Gyoungeun Han, Seokyoung Hong, Wonbeom Jang, Seojin Lee, Sohee Park, Sereimony Sek, Injee Song, Sungbin Yoon, Eric Davis |  |
| 47 |  |  [RRADistill: Distilling LLMs' Passage Ranking Ability for Long-Tail Queries Document Re-Ranking on a Search Engine](https://doi.org/10.18653/v1/2024.emnlp-industry.46) |  | 0 | Large Language Models (LLMs) excel at understanding the semantic relationships between queries and documents, even with lengthy and complex long-tail queries. These queries are challenging for feedback-based rankings due to sparse user engagement and limited feedback, making LLMs’ ranking ability... | Nayoung Choi, Youngjune Lee, GyuHwung Cho, Haeyu Jeong, Jungmin Kong, Saehun Kim, Keunchan Park, Sarah Cho, Inchang Jeong, Gyohee Nam, Sunghoon Han, Wonil Yang, Jaeho Choi |  |
| 48 |  |  [KorSmishing Explainer: A Korean-centric LLM-based Framework for Smishing Detection and Explanation Generation](https://doi.org/10.18653/v1/2024.emnlp-industry.47) |  | 0 | To mitigate the annual financial losses caused by SMS phishing (smishing) in South Korea, we propose an explainable smishing detection framework that adapts to a Korean-centric large language model (LLM). Our framework not only classifies smishing attempts but also provides clear explanations,... | Yunseung Lee, Daehee Han |  |
| 49 |  |  [Time Matters: An End-to-End Solution for Temporal Claim Verification](https://doi.org/10.18653/v1/2024.emnlp-industry.48) |  | 0 | Automated claim verification plays an essential role in fostering trust in the digital space. Despite the growing interest, the verification of temporal claims has not received much attention in the community. Temporal claim verification brings new challenges where cues of the temporal information... | Anab Maulana Barik, Wynne Hsu, MongLi Lee |  |
| 50 |  |  [MILD Bot: Multidisciplinary Childhood Cancer Survivor Question-Answering Bot](https://doi.org/10.18653/v1/2024.emnlp-industry.49) |  | 0 | This study introduces a Multidisciplinary chILDhood cancer survivor question-answering (MILD) bot designed to support childhood cancer survivors facing diverse challenges in their survivorship journey. In South Korea, a shortage of experts equipped to address these unique concerns comprehensively... | Mirae Kim, Kyubum Hwang, Hayoung Oh, Min Kim, Chaerim Park, Yehwi Park, Chungyeon Lee |  |
| 51 |  |  [Breaking the Hourglass Phenomenon of Residual Quantization: Enhancing the Upper Bound of Generative Retrieval](https://doi.org/10.18653/v1/2024.emnlp-industry.50) |  | 0 | Generative retrieval (GR) has emerged as a transformative paradigm in search and recommender systems, leveraging numeric-based identifier representations to enhance efficiency and generalization. Notably, methods like TIGER, which employ Residual Quantization-based Semantic Identifiers (RQ-SID),... | Zhirui Kuai, Zuxu Chen, Huimu Wang, Mingming Li, Dadong Miao, Binbin Wang, Xusong Chen, Li Kuang, Yuxing Han, Jiaxing Wang, Guoyu Tang, Lin Liu, Songlin Wang, Jingwei Zhuo |  |
| 52 |  |  [Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction Tuning a Word-Embedding based Retrieval Augmented Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-industry.51) |  | 0 | Few-Shot Cross-Domain NER is the process of leveraging knowledge from data-rich source domains to perform entity recognition on data-scarce target domains. Most previous state-of-the-art (SOTA) approaches use pre-trained language models (PLMs) for cross-domain NER. However, these models are often... | Subhadip Nandi, Neeraj Agrawal |  |
| 53 |  |  [IPL: Leveraging Multimodal Large Language Models for Intelligent Product Listing](https://doi.org/10.18653/v1/2024.emnlp-industry.52) |  | 0 | Unlike professional Business-to-Consumer (B2C) e-commerce platforms (e.g., Amazon), Consumer-to-Consumer (C2C) platforms (e.g., Facebook marketplace) are mainly targeting individual sellers who usually lack sufficient experience in e-commerce. Individual sellers often struggle to compose proper... | Kang Chen, Qingheng Zhang, Chengbao Lian, Yixin Ji, Xuwei Liu, Shuguang Han, Guoqiang Wu, Fei Huang, Jufeng Chen |  |
| 54 |  |  [QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large Language Model Tuning](https://doi.org/10.18653/v1/2024.emnlp-industry.53) |  | 0 | Finetuning large language models requires huge GPU memory, restricting the choice to acquire Larger models. While the quantized version of the Low-Rank Adaptation technique, named QLoRA, significantly alleviates this issue, finding the efficient LoRA rank is still challenging. Moreover, QLoRA is... | Hossein Rajabzadeh, Mojtaba Valipour, Tianshu Zhu, Marzieh S. Tahaei, Hyock Ju Kwon, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh |  |
| 55 |  |  [Improving Hierarchical Text Clustering with LLM-guided Multi-view Cluster Representation](https://doi.org/10.18653/v1/2024.emnlp-industry.54) |  | 0 | In this work, we present an approach that introduces different perspectives or views to improve the quality of hierarchical clustering of interaction drivers in a contact center. Specifically, we present a multi-stage approach that introduces LLM-guided multi-view cluster representation that... | Anup Pattnaik, Cijo George, Rishabh Kumar Tripathi, Sasanka Vutla, Jithendra Vepa |  |
| 56 |  |  [PARA: Parameter-Efficient Fine-tuning with Prompt-Aware Representation Adjustment](https://doi.org/10.18653/v1/2024.emnlp-industry.55) |  | 0 | In the realm of parameter-efficient fine-tuning (PEFT) methods, while options like LoRA are available, there is a persistent demand in the industry for a PEFT approach that excels in both efficiency and performance within the context of single-backbone multi-tenant applications. This paper... | Zequan Liu, Yi Zhao, Ming Tan, Wei Zhu, Aaron Xuxiang Tian |  |
| 57 |  |  [RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance](https://doi.org/10.18653/v1/2024.emnlp-industry.56) |  | 0 | With the ever-increasing demands on Question Answering (QA) systems for IT operations and maintenance, an efficient and supervised fine-tunable framework is necessary to ensure the data security, private deployment and continuous upgrading. Although Large Language Models (LLMs) have notably... | Tianyang Zhang, Zhuoxuan Jiang, Shengguang Bai, Tianrui Zhang, Lin Lin, Yang Liu, Jiawei Ren |  |
| 58 |  |  [ULMR: Unlearning Large Language Models via Negative Response and Model Parameter Average](https://doi.org/10.18653/v1/2024.emnlp-industry.57) |  | 0 | In recent years, large language models (LLMs) have attracted significant interest from the research community due to their broad applicability in many language-oriented tasks, and are now widely used in numerous areas of production and daily life. One source of the powerful capabilities of LLMs is... | Shaojie Shi, Xiaoyu Tan, Xihe Qiu, Chao Qu, Kexin Nie, Yuan Cheng, Wei Chu, Yinghui Xu, Yuan Qi |  |
| 59 |  |  [Pretraining and Finetuning Language Models on Geospatial Networks for Accurate Address Matching](https://doi.org/10.18653/v1/2024.emnlp-industry.58) |  | 0 | We propose a novel framework for pretraining and fine-tuning language models with the goal of determining whether two addresses represent the same physical building. Address matching and building authoritative address catalogues are important to many applications and businesses, such as delivery... | Saket Maheshwary, Arpan Paul, Saurabh Sohoney |  |
| 60 |  |  [SMARTCAL: An Approach to Self-Aware Tool-Use Evaluation and Calibration](https://doi.org/10.18653/v1/2024.emnlp-industry.59) |  | 0 | The tool-use ability of Large Language Models (LLMs) has a profound impact on a wide range of applications. However, LLMs’ self-awareness and self-control capability in appropriately using tools remains understudied. The problem is consequential as it alarms a potential risk of degraded performance... | Yuanhao Shen, Xiaodan Zhu, Lei Chen |  |
| 61 |  |  [Probing the Depths of Language Models' Contact-Center Knowledge for Quality Assurance](https://doi.org/10.18653/v1/2024.emnlp-industry.60) |  | 0 | Recent advancements in large Language Models (LMs) have significantly enhanced their capabilities across various domains, including natural language understanding and generation. In this paper, we investigate the application of LMs to the specialized task of contact-center Quality Assurance (QA),... | Digvijay Ingle, Aashraya Sachdeva, Surya Prakash Sahu, Mayank Sati, Cijo George, Jithendra Vepa |  |
| 62 |  |  [Intelligent Predictive Maintenance RAG framework for Power Plants: Enhancing QA with StyleDFS and Domain Specific Instruction Tuning](https://doi.org/10.18653/v1/2024.emnlp-industry.61) |  | 0 |  | Seongtae Hong, Joong Shin, Jaehyung Seo, Taemin Lee, Jeongbae Park, Cho Young, Byeongho Choi, Heuiseok Lim |  |
| 63 |  |  [Structured Object Language Modeling (SO-LM): Native Structured Objects Generation Conforming to Complex Schemas with Self-Supervised Denoising](https://doi.org/10.18653/v1/2024.emnlp-industry.62) |  | 0 | In this paper, we study the problem of generating structured objects that conform to a complex schema, with intricate dependencies between the different components (facets) of the object. The facets of the object (attributes, fields, columns, properties) can be a mix of short, structured facts, or... | Amir Tavanaei, Kee Kiat Koo, Hayreddin Çeker, Shaobai Jiang, Qi Li, Julien Han, Karim Bouyarmane |  |
| 64 |  |  [Assisting Breastfeeding and Maternity Experts in Responding to User Queries with an AI-in-the-loop Approach](https://doi.org/10.18653/v1/2024.emnlp-industry.63) |  | 0 | Breastfeeding and Maternity experts are a scarce resource and engaging in a conversation with mothers on such a sensitive topic is a time-consuming effort. We present our journey and rationale in assisting experts to answer queries about Breastfeeding and Maternity topics from users, mainly... | Nadjet BouayadAgha, Ignasi GómezSebastià, Alba PadróArocas, Enric Roura, David Castelló, Rocío Tovar |  |
| 65 |  |  [A Hassle-free Algorithm for Strong Differential Privacy in Federated Learning Systems](https://doi.org/10.18653/v1/2024.emnlp-industry.64) |  | 0 | Differential privacy (DP) and federated learning (FL) are combined as advanced privacy-preserving methods when training on-device language models in production mobile keyboard applications. DP-Follow-the-Regularized-Leader (DP-FTRL) algorithms, leveraging correlated noise mechanisms such as tree... | Hugh McMahan, Zheng Xu, Yanxiang Zhang |  |
| 66 |  |  [ProConSuL: Project Context for Code Summarization with LLMs](https://doi.org/10.18653/v1/2024.emnlp-industry.65) |  | 0 | We propose Project Context for Code Summarization with LLMs (ProConSuL), a new framework to provide a large language model (LLM) with precise information about the code structure from program analysis methods such as a compiler or IDE language services and use task decomposition derived from the... | Vadim Lomshakov, Andrey Podivilov, Sergey Savin, Oleg Baryshnikov, Alena Lisevych, Sergey I. Nikolenko |  |
| 67 |  |  [Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach](https://doi.org/10.18653/v1/2024.emnlp-industry.66) |  | 0 | Retrieval Augmented Generation (RAG) has been a powerful tool for Large Language Models (LLMs) to efficiently process overly lengthy contexts. However, recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to understand long contexts directly. We conduct a comprehensive comparison... | Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky |  |
| 68 |  |  [MARS: Multilingual Aspect-centric Review Summarisation](https://doi.org/10.18653/v1/2024.emnlp-industry.67) |  | 0 |  | Sandeep Sricharan Mukku, Abinesh Kanagarajan, Chetan Aggarwal, Promod Yenigalla |  |
| 69 |  |  [A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks](https://doi.org/10.18653/v1/2024.emnlp-industry.68) |  | 0 | In virtual assistant (VA) systems it is important to reject or redirect user queries that fall outside the scope of the system. One of the most accurate approaches for out-of-scope (OOS) rejection is to combine it with the task of intent classification on in-scope queries, and to use methods based... | Tianyi Zhang, Atta Norouzian, Aanchan Mohan, Frederick Ducatelle |  |
| 70 |  |  [Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization](https://doi.org/10.18653/v1/2024.emnlp-industry.69) |  | 0 | Meeting summarization is crucial in digital communication, but existing solutions struggle with salience identification to generate personalized, workable summaries, and context understanding to fully comprehend the meetings’ content.Previous attempts to address these issues by considering related... | Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp |  |
| 71 |  |  [Detecting LLM-Assisted Cheating on Open-Ended Writing Tasks on Language Proficiency Tests](https://doi.org/10.18653/v1/2024.emnlp-industry.70) |  | 0 | The high capability of recent Large Language Models (LLMs) has led to concerns about possible misuse as cheating assistants in open-ended writing tasks in assessments. Although various detecting methods have been proposed, most of them have not been evaluated on or optimized for real-world samples... | Chenhao Niu, Kevin P. Yancey, Ruidong Liu, Mirza Basim Baig, André Horie, James Sharpnack |  |
| 72 |  |  [Can Machine Unlearning Reduce Social Bias in Language Models?](https://doi.org/10.18653/v1/2024.emnlp-industry.71) |  | 0 | Mitigating bias in language models (LMs) has become a critical problem due to the widespread deployment of LMs in the industry and customer-facing applications. Numerous approaches revolve around data pre-processing and subsequent fine-tuning of language models, tasks that can be both... | Omkar Dige, Diljot Arneja, Tsz Fung Yau, Qixuan Zhang, Mohammad Bolandraftar, Xiaodan Zhu, Faiza Khan Khattak |  |
| 73 |  |  [Don't be my Doctor! Recognizing Healthcare Advice in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.72) |  | 0 | Large language models (LLMs) have seen increasing popularity in daily use, with their widespread adoption by many corporations as virtual assistants, chatbots, predictors, and many more. Their growing influence raises the need for safeguards and guardrails to ensure that the outputs from LLMs do... | Kellen Cheng, Anna Lisa Gentile, Pengyuan Li, Chad DeLuca, GuangJie Ren |  |
| 74 |  |  [Building an Efficient Multilingual Non-Profit IR System for the Islamic Domain Leveraging Multiprocessing Design in Rust](https://doi.org/10.18653/v1/2024.emnlp-industry.73) |  | 0 | The widespread use of large language models (LLMs) has dramatically improved many applications of Natural Language Processing (NLP), including Information Retrieval (IR). However, domains that are not driven by commercial interest often lag behind in benefiting from AI-powered solutions. One such... | Vera Pavlova, Mohammed Makhlouf |  |
| 75 |  |  [Adapting LLMs for Structured Natural Language API Integration](https://doi.org/10.18653/v1/2024.emnlp-industry.74) |  | 0 | API integration is crucial for enterprise systems, as it enables seamless interaction between applications within workflows. However, the diversity and complexity of the API landscape present significant challenges in combining API calls based on user intent.Existing methods rely on named entity... | Robin Chan, Katsiaryna Mirylenka, Thomas Gschwind, Christoph Miksovic, Paolo Scotton, Enrico Toniato, Abdel Labbi |  |
| 76 |  |  [OMG-QA: Building Open-Domain Multi-Modal Generative Question Answering Systems](https://doi.org/10.18653/v1/2024.emnlp-industry.75) |  | 0 | We introduce OMG-QA, a new resource for question answering that is designed to evaluate the effectiveness of question answering systems that perform retrieval augmented generation (RAG) in scenarios that demand reasoning on multi-modal, multi-document contexts. These systems, given a user query,... | Linyong Nan, Weining Fang, Aylin Rasteh, Pouya Lahabi, Weijin Zou, Yilun Zhao, Arman Cohan |  |
| 77 |  |  [Survival of the Safest: Towards Secure Prompt Optimization through Interleaved Multi-Objective Evolution](https://doi.org/10.18653/v1/2024.emnlp-industry.76) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities; however, the optimization of their prompts has historically prioritized performance metrics at the expense of crucial safety and security considerations. To overcome this shortcoming, we introduce “Survival of the Safest” (),... | Ankita Sinha, Wendi Cui, Kamalika Das, Jiaxin Zhang |  |
| 78 |  |  [Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow](https://doi.org/10.18653/v1/2024.emnlp-industry.77) |  | 0 | Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks.This paper explores fine-tuning LLMs for predicting stock returns with financial newsflow.Return prediction is fundamental for subsequent tasks... | Tian Guo, Emmanuel Hauptmann |  |
| 79 |  |  [AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset](https://doi.org/10.18653/v1/2024.emnlp-industry.78) |  | 0 | Query Autocomplete (QAC) is a critical feature in modern search engines, facilitating user interaction by predicting search queries based on input prefixes. Despite its widespread adoption, the absence of large-scale, realistic datasets has hindered advancements in QAC system development. This... | Dante Everaert, Rohit Patki, Tianqi Zheng, Christopher Potts |  |
| 80 |  |  [Language, OCR, Form Independent (LOFI) pipeline for Industrial Document Information Extraction](https://doi.org/10.18653/v1/2024.emnlp-industry.79) |  | 0 | This paper presents LOFI (Language, OCR, Form Independent), a pipeline for Document Information Extraction (DIE) in Low-Resource Language (LRL) business documents. LOFI pipeline solves language, Optical Character Recognition (OCR), and form dependencies through flexible model architecture, a... | Chang Yoon, Wonbeen Lee, Seokhwan Jang, Kyuwon Choi, Minsung Jung, Daewoo Choi |  |
| 81 |  |  [The State of the Art of Large Language Models on Chartered Financial Analyst Exams](https://doi.org/10.18653/v1/2024.emnlp-industry.80) |  | 0 | The Chartered Financial Analyst (CFA) program is one of the most widely recognized financial certifications globally. In this work, we test a variety of state-of-the-art large language models (LLMs) on mock CFA exams to provide an overview of their financial analysis capabilities using the same... | Mahmoud Mahfouz, Ethan Callanan, Mathieu Sibue, Antony Papadimitriou, Zhiqiang Ma, Xiaomo Liu, Xiaodan Zhu |  |
| 82 |  |  [Value Alignment from Unstructured Text](https://doi.org/10.18653/v1/2024.emnlp-industry.81) |  | 0 | Aligning large language models (LLMs) to value systems has emerged as a significant area of research within the fields of AI and NLP. Currently, this alignment process relies on the availability of high-quality supervised and preference data, which can be both time-consuming and expensive to curate... | Inkit Padhi, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Manish Nagireddy, Pierre L. Dognin, Kush R. Varshney |  |
| 83 |  |  [LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification](https://doi.org/10.18653/v1/2024.emnlp-industry.82) |  | 0 | Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts. This paper introduces LARA, a Linguistic-Adaptive Retrieval-Augmentation framework to enhance accuracy in multi-turn classification tasks across six languages, accommodating... | Junhua Liu, Tan Yong Keat, Fu Bin, Kwan Hui Lim |  |
| 84 |  |  [Generating Vehicular Icon Descriptions and Indications Using Large Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.83) |  | 0 | To enhance a question-answering system for automotive drivers, we tackle the problem of automatic generation of icon image descriptions. The descriptions can match the driver’s query about the icon appearing on the dashboard and tell the driver what is happening so that they may take an appropriate... | James Fletcher, Nicholas Dehnen, Seyed Nima Tayarani Bathaie, Aijun An, Heidar Davoudi, Ron DiCarlantonio, Gary Farmaner |  |
| 85 |  |  [Athena: Safe Autonomous Agents with Verbal Contrastive Learning](https://doi.org/10.18653/v1/2024.emnlp-industry.84) |  | 0 | Due to emergent capabilities, large language models (LLMs) have been utilized as language-based agents to perform a variety of tasks and make decisions with an increasing degree of autonomy. These autonomous agents can understand high-level instructions, interact with their environments, and... | Tanmana Sadhu, Ali Pesaranghader, Yanan Chen, Dong Hoon Yi |  |
| 86 |  |  [Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks](https://doi.org/10.18653/v1/2024.emnlp-industry.85) |  | 0 | An emergent research trend explores the use of Large Language Models (LLMs) as the backbone of agentic systems (e.g., SWE-Bench, Agent-Bench). To fulfill LLMs’ potential as autonomous agents, they must be able to identify, call, and interact with a variety of external tools and application program... | Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Sadhana Kumaravel, Matthew Stallone, Rameswar Panda, Yara Rizk, G. P. Shrivatsa Bhargav, Maxwell Crouse, R. Chulaka Gunasekara, Shajith Ikbal, Sachindra Joshi, Hima Karanam, Vineet Kumar, Asim Munawar, Sumit Neelam, Dinesh Raghu, Udit Sharma, Adriana Meza Soria, Dheeraj Sreedhar, Praveen Venkateswaran, Merve Unuvar, David Cox, Salim Roukos, Luis A. Lastras, Pavan Kapanipathi |  |
| 87 |  |  [Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization](https://doi.org/10.18653/v1/2024.emnlp-industry.86) |  | 0 | This work focuses on the task of query-based meeting summarization in which the summary of a context (meeting transcript) is generated in response to a specific query. When using Large Language Models (LLMs) for this task, a new call to the LLM inference endpoint/API is required for each new query... | Md. Tahmid Rahman Laskar, Elena Khasanova, XueYong Fu, Cheng Chen, Shashi Bhushan TN |  |
| 88 |  |  [DiAL : Diversity Aware Listwise Ranking for Query Auto-Complete](https://doi.org/10.18653/v1/2024.emnlp-industry.87) |  | 0 | Query Auto-Complete (QAC) is an essential search feature that suggests users with a list of potential search keyword completions as they type, enabling them to complete their queries faster. While the QAC systems in eCommerce stores generally use the Learning to Rank (LTR) approach optimized based... | Sonali Singh, Sachin Farfade, Prakash Mandayam Comar |  |
| 89 |  |  [Systematic Evaluation of Long-Context LLMs on Financial Concepts](https://doi.org/10.18653/v1/2024.emnlp-industry.88) |  | 0 | Long-context large language models (LC LLMs) promise to increase reliability of LLMs in real-world tasks requiring processing and understanding of long input documents. However, this ability of LC LLMs to reliably utilize their growing context windows remains under investigation. In this work, we... | Lavanya Gupta, Saket Sharma, Yiyun Zhao |  |
| 90 |  |  [ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA Datasets with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.89) |  | 0 | The rapid evolution of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation.These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique... | Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeffrey Pound, Yisi Sang, Jimmy Lin, Ihab F. Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li |  |
| 91 |  |  [Knowledge-augmented Financial Market Analysis and Report Generation](https://doi.org/10.18653/v1/2024.emnlp-industry.90) |  | 0 | Crafting a convincing financial market analysis report necessitates a wealth of market information and the expertise of financial analysts, posing a highly challenging task. While large language models (LLMs) have enabled the automated generation of financial market analysis text, they still face... | Yuemin Chen, Feifan Wu, Jingwei Wang, Hao Qian, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Meng Wang |  |
| 92 |  |  [Let Me Speak Freely? A Study On The Impact Of Format Restrictions On Large Language Model Performance](https://doi.org/10.18653/v1/2024.emnlp-industry.91) |  | 0 | Structured generation, the process of producing content in standardized formats like JSON and XML, is widely utilized in real-world applications to extract key output information from large language models (LLMs).This study investigates whether such constraints on generation space impact LLMs’... | Zhi Rui Tam, ChengKuang Wu, YiLin Tsai, ChiehYen Lin, Hungyi Lee, YunNung Chen |  |
| 93 |  |  [ASTRA: Automatic Schema Matching using Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-industry.92) |  | 0 | Many eCommerce platforms source product information from millions of sellers and manufactures, each having their own proprietary schemas, and employ schema matching solutions to structure it to enable informative shopping experiences. Meanwhile, state-of-the-art machine translation techniques have... | Tarang Chugh, Deepak Zambre |  |
| 94 |  |  [Neural Search Space in Gboard Decoder](https://doi.org/10.18653/v1/2024.emnlp-industry.93) |  | 0 | Gboard Decoder produces suggestions by looking for paths that best match input touch points on the context aware search space, which is backed by the language Finite State Transducers (FST). The language FST is currently an N-gram language model (LM). However, N-gram LMs, limited in context length,... | Yanxiang Zhang, Yuanbo Zhang, Haicheng Sun, Yun Wang, Gary Sivek, Shumin Zhai |  |
| 95 |  |  [Prompt Leakage effect and mitigation strategies for multi-turn LLM Applications](https://doi.org/10.18653/v1/2024.emnlp-industry.94) |  | 0 | Prompt leakage poses a compelling security and privacy threat in LLM applications. Leakage of system prompts may compromise intellectual property, and act as adversarial reconnaissance for an attacker. A systematic evaluation of prompt leakage threats and mitigation strategies is lacking,... | Divyansh Agarwal, Alexander R. Fabbri, Ben Risher, Philippe Laban, Shafiq Joty, ChienSheng Wu |  |
| 96 |  |  [Sequential LLM Framework for Fashion Recommendation](https://doi.org/10.18653/v1/2024.emnlp-industry.95) |  | 0 | The fashion industry is one of the leading domains in the global e-commerce sector, prompting major online retailers to employ recommendation systems for product suggestions and customer convenience. While recommendation systems have been widely studied, most are designed for general e-commerce... | Han Liu, Xianfeng Tang, Tianlang Chen, Jiapeng Liu, Indu Indu, Henry Peng Zou, Peng Dai, Roberto F. Galán, Michael D. Porter, Dongmei Jia, Ning Zhang, Lian Xiong |  |
| 97 |  |  [Visual Editing with LLM-based Tool Chaining: An Efficient Distillation Approach for Real-Time Applications](https://doi.org/10.18653/v1/2024.emnlp-industry.96) |  | 0 | We present a practical distillation approach to fine-tune LLMs for invoking tools in real-time applications. We focus on visual editing tasks; specifically, we modify images and videos by interpreting user stylistic requests, specified in natural language (“golden hour”), using an LLM to select the... | Oren Sultan, Alexander Khasin, Guy Shiran, Asnat GreensteinMessica, Dafna Shahaf |  |
| 98 |  |  [Provenance: A Light-weight Fact-checker for Retrieval Augmented LLM Generation Output](https://doi.org/10.18653/v1/2024.emnlp-industry.97) |  | 0 | We present a light-weight approach for detecting nonfactual outputs from retrieval-augemented generation (RAG). Given a context and putative output, we compute a factuality score that can be thresholded to yield a binary decision to check the results of LLM-based question-answering, summarization,... | Hithesh Sankararaman, Mohammed Yasin, Tanner Sorensen, Alessandro Di Bari, Andreas Stolcke |  |
| 99 |  |  [AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model](https://doi.org/10.18653/v1/2024.emnlp-industry.98) |  | 0 | We present Any-Modality Augmented Language Model (AnyMAL), a unified model that reasons over diverse input modality signals (i.e. text, image, video, audio, IMU motion sensor), and generates textual responses. AnyMAL inherits the powerful text-based reasoning abilities of the state-of-the-art LLMs... | Seungwhan Moon, Andrea Madotto, Zhaojiang Lin, Tushar Nagarajan, Matt Smith, Shashank Jain, ChunFu Yeh, Prakash Murugesan, Peyman Heidari, Yue Liu, Kavya Srinet, Babak Damavandi, Anuj Kumar |  |
| 100 |  |  [SLM as Guardian: Pioneering AI Safety with Small Language Model](https://doi.org/10.18653/v1/2024.emnlp-industry.99) |  | 0 | Most prior safety research of large language models (LLMs) has focused on enhancing the alignment of LLMs to better suit the safety requirements of their use cases. However, internalizing such safeguard features into larger models brought challenges of higher training cost and unintended... | Ohjoon Kwon, Donghyeon Jeon, Nayoung Choi, GyuHwung Cho, Hwiyeol Jo, Changbong Kim, Hyunwoo Lee, Inho Kang, Sun Kim, Taiwoo Park |  |
| 101 |  |  [Hyper-QKSG: Framework for Automating Query Generation and Knowledge-Snippet Extraction from Tables and Lists](https://doi.org/10.18653/v1/2024.emnlp-industry.100) |  | 0 | These days, there is an increasing necessity to provide a user with a short knowledge-snippet for a query in commercial information retrieval services such as the featured snippet of Google. In this paper, we focus on how to automatically extract the candidates of query-knowledge snippet pairs from... | Dooyoung Kim, Yoonjin Jang, Dongwook Shin, Chanhoon Park, Youngjoong Ko |  |
| 102 |  |  [Patentformer: A Novel Method to Automate the Generation of Patent Applications](https://doi.org/10.18653/v1/2024.emnlp-industry.101) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated impressive performances across various NLP tasks. However, their potential for automating the task of writing patent documents remains relatively unexplored. To address this gap, in this work, we propose a novel method, Patentformer,... | Juanyan Wang, Sai Mudhiganti, Manali Sharma |  |
| 103 |  |  [MARCO: Multi-Agent Real-time Chat Orchestration](https://doi.org/10.18653/v1/2024.emnlp-industry.102) |  | 0 | Large language model advancements have enabled the development of multi-agent frameworks to tackle complex, real-world problems such as to automate workflows that require interactions with diverse tools, reasoning, and human collaboration. We present MARCO, a Multi-Agent Real-time Chat... | Anubhav Shrimal, Stanley Kanagaraj, Kriti Biswas, Swarnalatha Raghuraman, Anish Nediyanchath, Yi Zhang, Promod Yenigalla |  |
| 104 |  |  [mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval](https://doi.org/10.18653/v1/2024.emnlp-industry.103) |  | 0 | We present systematic efforts in building long-context multilingual text representation model (TRM) and reranker from scratch for text retrieval. We first introduce a text encoder (base size) enhanced with RoPE and unpadding, pre-trained in a native 8192-token context (longer than 512 of previous... | Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie, Ziqi Dai, Jialong Tang, Huan Lin, Baosong Yang, Pengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li, Min Zhang |  |
| 105 |  |  [ItiNera: Integrating Spatial Optimization with Large Language Models for Open-domain Urban Itinerary Planning](https://doi.org/10.18653/v1/2024.emnlp-industry.104) |  | 0 | Citywalk, a recently popular form of urban travel, requires genuine personalization and understanding of fine-grained requests compared to traditional itinerary planning. In this paper, we introduce the novel task of Open-domain Urban Itinerary Planning (OUIP), which generates personalized urban... | Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma |  |
| 106 |  |  [RESTful-Llama: Connecting User Queries to RESTful APIs](https://doi.org/10.18653/v1/2024.emnlp-industry.105) |  | 0 | Recent advancements in Large Language Models (LLMs) have showcased exceptional performance in zero-shot learning and reasoning tasks. However, integrating these models with external tools - a crucial need for real-world applications - remains a significant challenge. We propose RESTful-Llama, a... | Han Xu, Ruining Zhao, Jindong Wang, Haipeng Chen |  |
| 107 |  |  [A Cost-Efficient Modular Sieve for Extracting Product Information from Company Websites](https://doi.org/10.18653/v1/2024.emnlp-industry.106) |  | 0 | Extracting product information is crucial for informed business decisions and strategic planning across multiple industries. However, recent methods relying only on large language models (LLMs) are resource-intensive and computationally prohibitive due to website structure differences and numerous... | Anna Hätty, Dragan Milchevski, Kersten Döring, Marko Putnikovic, Mohsen Mesgar, Filip Novovic, Maximilian Braun, Karina Borimann, Igor Stranjanac |  |
| 108 |  |  [CharacterGLM: Customizing Social Characters with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-industry.107) |  | 0 | Character-based dialogue (CharacterDial) has become essential in the industry (e.g., Character.AI), enabling users to freely customize social characters for social interactions. However, the generalizability and adaptability across various conversational scenarios inherent in customizing social... | Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Pei Ke, Guanqun Bi, Libiao Peng, Jiaming Yang, Xiyao Xiao, Sahand Sabour, Xiaohan Zhang, Wenjing Hou, Yijia Zhang, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang |  |
| 109 |  |  [RAC: Retrieval-augmented Conversation Dataset for Open-domain Question Answering in Conversational Settings](https://doi.org/10.18653/v1/2024.emnlp-industry.108) |  | 0 | In recent years, significant advancements in conversational question and answering (CQA) have been driven by the exponential growth of large language models and the integration of retrieval mechanisms that leverage external knowledge to generate accurate and contextually relevant responses.... | Bonggeun Choi, JeongJae Park, Yoonsung Kim, Jaehyun Park, Youngjoong Ko |  |
| 110 |  |  [Improving Retrieval in Sponsored Search by Leveraging Query Context Signals](https://doi.org/10.18653/v1/2024.emnlp-industry.109) |  | 0 | Accurately retrieving relevant bid keywords for user queries is critical in Sponsored Search but remains challenging, particularly for short, ambiguous queries. Existing dense and generative retrieval models often fail to capture the nuanced user intent in these cases. To address this, we propose... | Akash Kumar Mohankumar, Gururaj K, Gagan Madan, Amit Singh |  |
| 111 |  |  [FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data](https://doi.org/10.18653/v1/2024.emnlp-industry.110) |  | 0 | Large language models (LLMs) have demonstrated prowess in a wide range of tasks. However, many LLMs exhibit significant performance discrepancies between high- and low-resource languages. To mitigate this challenge, we present FuxiTranyu, an open-source multilingual LLM, which is designed to... | Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong |  |
| 112 |  |  [QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis](https://doi.org/10.18653/v1/2024.emnlp-industry.111) |  | 0 | Discovering meaningful insights from a large dataset, known as Exploratory Data Analysis (EDA), is a challenging task that requires thorough exploration and analysis of the data. Automated Data Exploration (ADE) systems use goal-oriented methods with Large Language Models and Reinforcement Learning... | Abhijit Manatkar, Ashlesha Akella, Parthivi Gupta, Krishnasuri Narayanam |  |
| 113 |  |  [PEARL: Preference Extraction with Exemplar Augmentation and Retrieval with LLM Agents](https://doi.org/10.18653/v1/2024.emnlp-industry.112) |  | 0 | Identifying preferences of customers in their shopping journey is a pivotal aspect in providing product recommendations. The task becomes increasingly challenging when there is a multi-turn conversation between the user and a shopping assistant chatbot. In this paper, we tackle a novel and complex... | Vijit Malik, Akshay Jagatap, Vinayak Puranik, Anirban Majumder |  |
| 114 |  |  [RAG-HAT: A Hallucination-Aware Tuning Pipeline for LLM in Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-industry.113) |  | 0 | Retrieval-augmented generation (RAG) has emerged as a significant advancement in the field of large language models (LLMs). By integrating up-to-date information not available during their initial training, RAG greatly enhances the practical utility of LLMs in real-world applications. However, even... | Juntong Song, Xingguang Wang, Juno Zhu, Yuanhao Wu, Xuxin Cheng, Randy Zhong, Cheng Niu |  |
| 115 |  |  [Intent Detection in the Age of LLMs](https://doi.org/10.18653/v1/2024.emnlp-industry.114) |  | 0 | Intent detection is a critical component of task-oriented dialogue systems (TODS) which enables the identification of suitable actions to address user utterances at each dialog turn. Traditional approaches relied on computationally efficient supervised sentence transformer encoder models, which... | Gaurav Arora, Shreya Jain, Srujana Merugu |  |
| 116 |  |  [Aegis: An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering](https://doi.org/10.18653/v1/2024.emnlp-industry.115) |  | 0 | Functional safety is a critical aspect of automotive engineering, encompassing all phases of a vehicle’s lifecycle, including design, development, production, operation, and decommissioning. This domain involves highly knowledge-intensive tasks. This paper introduces Aegis: An Advanced LLM-Based... | Lu Shi, Bin Qi, Jiarui Luo, Yang Zhang, Zhanzhao Liang, Zhaowei Gao, Wenke Deng, Lin Sun |  |
| 117 |  |  [Efficient Answer Retrieval System (EARS): Combining Local DB Search and Web Search for Generative QA](https://doi.org/10.18653/v1/2024.emnlp-industry.116) |  | 0 | In this work, we propose an efficient answer retrieval system \*\*EARS\*\*: a production-ready, factual question answering (QA) system that combines local knowledge base search with generative, context-based QA. To assess the quality of the generated content, we devise comprehensive metrics for... | Nikita Krayko, Ivan Sidorov, Fedor Laputin, Daria Galimzianova, Vasily Konovalov |  |
| 118 |  |  [GraphQL Query Generation: A Large Training and Benchmarking Dataset](https://doi.org/10.18653/v1/2024.emnlp-industry.117) |  | 0 | GraphQL is a powerful query language for APIs that allows clients to fetch precise data efficiently and flexibly, querying multiple resources with a single request. However, crafting complex GraphQL query operations can be challenging. Large Language Models (LLMs) offer an alternative by generating... | Manish Kesarwani, Sambit Ghosh, Nitin Gupta, Shramona Chakraborty, Renuka Sindhgatta, Sameep Mehta, Carlos Eberhardt, Dan Debrunner |  |
| 119 |  |  [Mixture of Diverse Size Experts](https://doi.org/10.18653/v1/2024.emnlp-industry.118) |  | 0 | The Sparsely-Activated Mixture-of-Experts (MoE) architecture has gained popularity for scaling large language models (LLMs) due to the sub-linearly increasing computational costs. Despite its success, most of the current structure designs face the challenge that the experts share the same size such... | Manxi Sun, Wei Liu, Jian Luan, Pengzhi Gao, Bin Wang |  |
| 120 |  |  [Course-Correction: Safety Alignment Using Synthetic Preferences](https://doi.org/10.18653/v1/2024.emnlp-industry.119) |  | 0 | The risk of harmful contents generated by large language models (LLMs) becomes a critical concern. This paper systematically evaluates and enhances LLMs’ capability to perform course-correction, , the model can steer away from generating harmful content autonomously. First, we introduce the C2-Eval... | Rongwu Xu, Yishuo Cai, Zhenhong Zhou, Renjie Gu, Haiqin Weng, Liu Yan, Tianwei Zhang, Wei Xu, Han Qiu |  |
| 121 |  |  [GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced Distillation](https://doi.org/10.18653/v1/2024.emnlp-industry.120) |  | 0 | Pre-trained language models have become an integral component of question-answering systems, achieving remarkable performance. However, for practical deployment, it is crucial to perform knowledge distillation to maintain high performance while operating under computational constraints. In this... | Wenjie Zhou, Zhenxin Ding, Xiaodong Zhang, Haibo Shi, Junfeng Wang, Dawei Yin |  |
| 122 |  |  [PRISM: A New Lens for Improved Color Understanding](https://doi.org/10.18653/v1/2024.emnlp-industry.121) |  | 0 | While image-text pre-trained models, such as CLIP, have demonstrated impressive capabilities in learning robust text and image representations, a critical area for substantial improvement remains—precise color understanding. In this paper, we address this limitation by introducing PRISM, a simple... | Arjun R. Akula, Garima Pruthi, Inderjit S. Dhillon, Pradyumna Narayana, Sugato Basu, Varun Jampani |  |
| 123 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.emnlp-main.0) |  | 0 |  |  |  |
| 124 |  |  [UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1) |  | 0 | Although pre-trained language models have exhibited great flexibility and versatility with prompt-based few-shot learning, they suffer from the extensive parameter size and limited applicability for inference. Recent studies have suggested that PLMs be used as dataset generators and a tiny... | Juhwan Choi, Yeonghwa Kim, Seunguk Yu, Jungmin Yun, Youngbin Kim |  |
| 125 |  |  [Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation](https://doi.org/10.18653/v1/2024.emnlp-main.2) |  | 0 | The quality of the dataset is crucial for ensuring optimal performance and reliability of downstream task models. However, datasets often contain noisy data inadvertently included during the construction process. Numerous attempts have been made to correct this issue through human annotators.... | Juhwan Choi, Jungmin Yun, Kyohoon Jin, Youngbin Kim |  |
| 126 |  |  [FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document](https://doi.org/10.18653/v1/2024.emnlp-main.3) |  | 0 | Through the advent of pre-trained language models, there have been notable advancements in abstractive summarization systems. Simultaneously, a considerable number of novel methods for evaluating factual consistency in abstractive summarization systems has been developed. But these evaluation... | Joonho Yang, Seunghyun Yoon, Byeongjeong Kim, Hwanhee Lee |  |
| 127 |  |  [Prompts have evil twins](https://doi.org/10.18653/v1/2024.emnlp-main.4) |  | 0 | We discover that many natural-language prompts can be replaced by corresponding prompts that are unintelligible to humans but that provably elicit similar behavior in language models. We call these prompts “evil twins” because they are obfuscated and uninterpretable (evil), but at the same time... | Rimon Melamed, Lucas H. McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, Enric BoixAdserà |  |
| 128 |  |  [Table Question Answering for Low-resourced Indic Languages](https://doi.org/10.18653/v1/2024.emnlp-main.5) |  | 0 | TableQA is the task of answering questions over tables of structured information, returning individual cells or tables as output. TableQA research has focused primarily on high-resource languages, leaving medium- and low-resource languages with little progress due to scarcity of annotated data and... | Vaishali Pal, Evangelos Kanoulas, Andrew Yates, Maarten de Rijke |  |
| 129 |  |  [ImageInWords: Unlocking Hyper-Detailed Image Descriptions](https://doi.org/10.18653/v1/2024.emnlp-main.6) |  | 0 | Despite the longstanding adage ”an image is worth a thousand words,” generating accurate hyper-detailed image descriptions remains unsolved. Trained on short web-scraped image-text, vision-language models often generate incomplete descriptions with visual inconsistencies. We address this via a... | Roopal Garg, Andrea Burns, Burcu Karagol Ayan, Yonatan Bitton, Ceslee Montgomery, Yasumasa Onoe, Andrew Bunner, Ranjay Krishna, Jason Baldridge, Radu Soricut |  |
| 130 |  |  [LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay](https://doi.org/10.18653/v1/2024.emnlp-main.7) |  | 0 | This paper explores the open research problem of understanding the social behaviors of LLM-based agents. Using Avalon as a testbed, we employ system prompts to guide LLM agents in gameplay. While previous studies have touched on gameplay with LLM agents, research on their social behaviors is... | Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye, Peilin Zhao, EePeng Lim, Hui Xiong, Hao Wang |  |
| 131 |  |  [When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection](https://doi.org/10.18653/v1/2024.emnlp-main.8) |  | 0 | Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in healthcare applications. However, the application of LLMs in the identification and... | Xiangyu Zhang, Hexin Liu, Kaishuai Xu, Qiquan Zhang, Daijiao Liu, Beena Ahmed, Julien Epps |  |
| 132 |  |  [Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model](https://doi.org/10.18653/v1/2024.emnlp-main.9) |  | 0 | Recently, Denoising Diffusion Probabilistic Models (DDPMs) have attained leading performances across a diverse range of generative tasks. However, in the field of speech synthesis, although DDPMs exhibit impressive performance, their prolonged training duration and substantial inference costs... | Xiangyu Zhang, Daijiao Liu, Hexin Liu, Qiquan Zhang, Hanyu Meng, Leibny Paola GarcíaPerera, Engsiong Chng, Lina Yao |  |
| 133 |  |  [Hateful Word in Context Classification](https://doi.org/10.18653/v1/2024.emnlp-main.10) |  | 0 | Hate speech detection is a prevalent research field, yet it remains underexplored at the level of word meaning. This is significant, as terms used to convey hate often involve non-standard or novel usages which might be overlooked by commonly leveraged LMs trained on general language use. In this... | Sanne Hoeken, Sina Zarrieß, Özge Alaçam |  |
| 134 |  |  [Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze](https://doi.org/10.18653/v1/2024.emnlp-main.11) |  | 0 | Hate speech is a complex and subjective phenomenon. In this paper, we present a dataset (GAZE4HATE) that provides gaze data collected in a hate speech annotation experiment. We study whether the gaze of an annotator provides predictors of their subjective hatefulness rating, and how gaze features... | Özge Alaçam, Sanne Hoeken, Sina Zarrieß |  |
| 135 |  |  [NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.12) |  | 0 | Language models struggle with handling numerical data and performing arithmetic operations. We hypothesize that this limitation can be partially attributed to non-intuitive textual numbers representation. When a digit is read or generated by a causal language model it does not know its place value... | Eli Schwartz, Leshem Choshen, Joseph Shtok, Sivan Doveh, Leonid Karlinsky, Assaf Arbelle |  |
| 136 |  |  ["Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.13) |  | 0 | Existing debiasing techniques are typically training-based or require access to the model’s internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine whether structured prompting techniques can offer... | Shaz Furniturewala, Surgan Jandial, Abhinav Java, Pragyan Banerjee, Simra Shahid, Sumit Bhatia, Kokil Jaidka |  |
| 137 |  |  [A Usage-centric Take on Intent Understanding in E-Commerce](https://doi.org/10.18653/v1/2024.emnlp-main.14) |  | 0 | Identifying and understanding user intents is a pivotal task for E-Commerce. Despite its essential role in product recommendation and business user profiling analysis, intent understanding has not been consistently defined or accurately benchmarked. In this paper, we focus on predicative user... | Wendi Zhou, Tianyi Li, Pavlos Vougiouklis, Mark Steedman, Jeff Z. Pan |  |
| 138 |  |  [Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.15) |  | 0 | Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training... | Oded Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha |  |
| 139 |  |  [Systematic Biases in LLM Simulations of Debates](https://doi.org/10.18653/v1/2024.emnlp-main.16) |  | 0 | The emergence of Large Language Models (LLMs), has opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. Current research suggests that LLM-based agents become increasingly human-like in their performance, sparking interest in... | Amir Taubenfeld, Yaniv Dover, Roi Reichart, Ariel Goldstein |  |
| 140 |  |  [Studying and Mitigating Biases in Sign Language Understanding Models](https://doi.org/10.18653/v1/2024.emnlp-main.17) |  | 0 | Ensuring that the benefits of sign language technologies are distributed equitably among all community members is crucial. Thus, it is important to address potential biases and inequities that may arise from the design or use of these resources. Crowd-sourced sign language datasets, such as the ASL... | Katherine Atwell, Danielle Bragg, Malihe Alikhani |  |
| 141 |  |  [Uncertainty in Language Models: Assessment through Rank-Calibration](https://doi.org/10.18653/v1/2024.emnlp-main.18) |  | 0 | Language Models (LMs) have shown promising performance in natural language generation. However, as LMs often generate incorrect or hallucinated responses, it is crucial to correctly quantify their uncertainty in responding to given inputs. In addition to verbalized confidence elicited via... | Xinmeng Huang, Shuo Li, Mengxin Yu, Matteo Sesia, Hamed Hassani, Insup Lee, Osbert Bastani, Edgar Dobriban |  |
| 142 |  |  [RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning](https://doi.org/10.18653/v1/2024.emnlp-main.19) |  | 0 | Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world. Current research predominantly emphasizes LLMs’ capacity to utilize tools in well-structured environments while overlooking their stability when confronted... | Junjie Ye, Yilong Wu, Songyang Gao, Caishuang Huang, Sixian Li, Guanyu Li, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 143 |  |  [Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing](https://doi.org/10.18653/v1/2024.emnlp-main.20) |  | 0 | Large Language Models (LLMs) have demonstrated significant potential in handling complex reasoning tasks through step-by-step rationale generation. However, recent studies have raised concerns regarding the hallucination and flaws in their reasoning process. Substantial efforts are being made to... | Fangkai Jiao, Chengwei Qin, Zhengyuan Liu, Nancy F. Chen, Shafiq Joty |  |
| 144 |  |  [Scaling Properties of Speech Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.21) |  | 0 | Speech Language Models (SLMs) aim to learn language from raw audio, without textual resources. Despite significant advances, our current models exhibit weak syntax and semantic abilities. However, if the scaling properties of neural language models hold for the speech modality, these abilities will... | Santiago Cuervo, Ricard Marxer |  |
| 145 |  |  ["We Demand Justice!": Towards Social Context Grounding of Political Texts](https://doi.org/10.18653/v1/2024.emnlp-main.22) |  | 0 | Political discourse on social media often contains similar language with opposing intended meanings. For example, the phrase thoughts and prayers, is used to express sympathy for mass shooting victims, as well as satirically criticize the lack of legislative action on gun control. Understanding... | Rajkumar Pujari, Chengfei Wu, Dan Goldwasser |  |
| 146 |  |  [An Experimental Analysis on Evaluating Patent Citations](https://doi.org/10.18653/v1/2024.emnlp-main.23) |  | 0 | The patent citation count is a good indicator of patent quality. This often generates monetary value for the inventors and organizations. However, the factors that influence a patent receiving high citations over the year are still not well understood. With the patents over the past two decades, we... | Rabindra Nath Nandi, Suman Kalyan Maity, Brian Uzzi, Sourav Medya |  |
| 147 |  |  [Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?](https://doi.org/10.18653/v1/2024.emnlp-main.24) |  | 0 | Traditionally, success in multilingual machine translation can be attributed to three key factors in training data: large volume, diverse translation directions, and high quality. In the current practice of fine-tuning large language models (LLMs) for translation, we revisit the importance of these... | Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, Dietrich Klakow |  |
| 148 |  |  [Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing](https://doi.org/10.18653/v1/2024.emnlp-main.25) |  | 0 | The powerful generative abilities of large language models (LLMs) show potential in generating relevance labels for search applications. Previous work has found that directly asking about relevancy, such as "\*How relevant is document A to query Q?\*”, results in suboptimal ranking. Instead, the... | Le Yan, Zhen Qin, Honglei Zhuang, Rolf Jagerman, Xuanhui Wang, Michael Bendersky, Harrie Oosterhuis |  |
| 149 |  |  [Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation](https://doi.org/10.18653/v1/2024.emnlp-main.26) |  | 0 | We investigate non-collaborative dialogue agents, which are expected to engage in strategic conversations with diverse users, for securing a mutual agreement that leans favorably towards the system’s objectives. This poses two main challenges for existing dialogue agents: 1) The inability to... | Tong Zhang, Chen Huang, Yang Deng, Hongru Liang, Jia Liu, Zujie Wen, Wenqiang Lei, TatSeng Chua |  |
| 150 |  |  [Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation](https://doi.org/10.18653/v1/2024.emnlp-main.27) |  | 0 | While Large language model (LLM)-based programming assistants such as CoPilot and ChatGPT can help improve the productivity of professional software developers, they can also facilitate cheating in introductory computer programming courses. Assuming instructors have limited control over the... | Saiful Islam Salim, Rubin Yuchan Yang, Alexander Cooper, Suryashree Ray, Saumya Debray, Sazzadur Rahaman |  |
| 151 |  |  [Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation](https://doi.org/10.18653/v1/2024.emnlp-main.28) |  | 0 | With contributions from the open-source community, a vast amount of instruction tuning (IT) data has emerged. Given the significant resource allocation required by training and evaluating models, it is advantageous to have an efficient method for selecting high-quality IT data. However, existing... | Yuan Ge, Yilun Liu, Chi Hu, Weibin Meng, Shimin Tao, Xiaofeng Zhao, Mahong Xia, Zhang Li, Boxing Chen, Hao Yang, Bei Li, Tong Xiao, JingBo Zhu |  |
| 152 |  |  [On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.29) |  | 0 | We study the presence of heteronormative biases and prejudice against interracial romantic relationships in large language models by performing controlled name-replacement experiments for the task of relationship prediction. We show that models are less likely to predict romantic relationships for... | Abhilasha Sancheti, Haozhe An, Rachel Rudinger |  |
| 153 |  |  [EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models](https://doi.org/10.18653/v1/2024.emnlp-main.30) |  | 0 | We introduce EmphAssess, a prosodic benchmark designed to evaluate the capability of speech-to-speech models to encode and reproduce prosodic emphasis. We apply this to two tasks: speech resynthesis and speech-to-speech translation. In both cases, the benchmark evaluates the ability of the model to... | Maureen de Seyssel, Antony D'Avirro, Adina Williams, Emmanuel Dupoux |  |
| 154 |  |  [On Fake News Detection with LLM Enhanced Semantics Mining](https://doi.org/10.18653/v1/2024.emnlp-main.31) |  | 0 | Large language models (LLMs) have emerged as valuable tools for enhancing textual features in various text-related tasks. Despite their superiority in capturing the lexical semantics between tokens for text analysis, our preliminary study on two popular LLMs, i.e., ChatGPT and Llama2, showcases... | Xiaoxiao Ma, Yuchen Zhang, Kaize Ding, Jian Yang, Jia Wu, Hao Fan |  |
| 155 |  |  [On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices](https://doi.org/10.18653/v1/2024.emnlp-main.32) |  | 0 | While learning with limited labelled data can effectively deal with a lack of labels, it is also sensitive to the effects of uncontrolled randomness introduced by so-called randomness factors (i.e., non-deterministic decisions such as choice or order of samples). We propose and formalise a method... | Branislav Pecher, Ivan Srba, Mária Bieliková |  |
| 156 |  |  [Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection](https://doi.org/10.18653/v1/2024.emnlp-main.33) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional proficiency in instruction-following, making them increasingly integral to various applications. However, this capability introduces the risk of prompt injection attacks, where malicious instructions are embedded in the input to trigger... | Zekun Li, Baolin Peng, Pengcheng He, Xifeng Yan |  |
| 157 |  |  [A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers](https://doi.org/10.18653/v1/2024.emnlp-main.34) |  | 0 | In this paper, we apply a method to quantify biases associated with named entities from various countries. We create counterfactual examples with small perturbations on target-domain data instead of relying on templates or specific datasets for bias detection. On widely used classifiers for... | Valentin Barrière, Sebastian Cifuentes |  |
| 158 |  |  [Mitigating the Alignment Tax of RLHF](https://doi.org/10.18653/v1/2024.emnlp-main.35) |  | 0 | LLMs acquire a wide range of abilities during pre-training, but aligning LLMs under Reinforcement Learning with Human Feedback (RLHF) can lead to forgetting pretrained abilities, which is also known as the alignment tax. To investigate alignment tax, we conducted experiments with existing RLHF... | Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, Tong Zhang |  |
| 159 |  |  [Evaluating Readability and Faithfulness of Concept-based Explanations](https://doi.org/10.18653/v1/2024.emnlp-main.36) |  | 0 | With the growing popularity of general-purpose Large Language Models (LLMs), comes a need for more global explanations of model behaviors. Concept-based explanations arise as a promising avenue for explaining high-level patterns learned by LLMs. Yet their evaluation poses unique challenges,... | Meng Li, Haoran Jin, Ruixuan Huang, Zhihao Xu, Defu Lian, Zijia Lin, Di Zhang, Xiting Wang |  |
| 160 |  |  [Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems](https://doi.org/10.18653/v1/2024.emnlp-main.37) |  | 0 | Intelligent Tutoring Systems (ITSs) can provide personalized and self-paced learning experience. The emergence of large language models (LLMs) further enables better human-machine interaction, and facilitates the development of conversational ITSs in various disciplines such as math and language... | Zhengyuan Liu, Stella Xin Yin, Geyu Lin, Nancy F. Chen |  |
| 161 |  |  [MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making](https://doi.org/10.18653/v1/2024.emnlp-main.38) |  | 0 | Insight gradually becomes a crucial form of long-term memory for an agent. However, the emergence of irrelevant insight and the lack of general insight can greatly undermine the effectiveness of insight. To solve this problem, in this paper, we introduce \*\*M\*\*ulti-\*\*S\*\*cale \*\*I\*\*nsight... | Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou |  |
| 162 |  |  [CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds](https://doi.org/10.18653/v1/2024.emnlp-main.39) |  | 0 | Detecting logical fallacies in texts can help users spot argument flaws, but automating this detection is not easy. Manually annotating fallacies in large-scale, real-world text data to create datasets for developing and validating detection models is costly. This paper introduces CoCoLoFa, the... | MinHsuan Yeh, Ruyuan Wan, TingHao Huang |  |
| 163 |  |  [Tokenization Is More Than Compression](https://doi.org/10.18653/v1/2024.emnlp-main.40) |  | 0 | Tokenization is a foundational step in natural language processing (NLP) tasks, bridging raw text and language models. Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its... | Craig W. Schmidt, Varshini Reddy, Haoran Zhang, Alec Alameddine, Omri Uzan, Yuval Pinter, Chris Tanner |  |
| 164 |  |  [FLIRT: Feedback Loop In-context Red Teaming](https://doi.org/10.18653/v1/2024.emnlp-main.41) |  | 0 | Warning: this paper contains content that may be inappropriate or offensive.As generative models become available for public use in various applications, testing and analyzing vulnerabilities of these models has become a priority. In this work, we propose an automatic red teaming framework that... | Ninareh Mehrabi, Palash Goyal, Christophe Dupuy, Qian Hu, Shalini Ghosh, Richard S. Zemel, KaiWei Chang, Aram Galstyan, Rahul Gupta |  |
| 165 |  |  [Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections](https://doi.org/10.18653/v1/2024.emnlp-main.42) |  | 0 | Language models will inevitably err in situations with which they are unfamiliar. However, by effectively communicating uncertainties, they can still guide humans toward making sound decisions in those contexts. We demonstrate this idea by developing HEAR, a system that can successfully guide... | Lingjun Zhao, Khanh Nguyen, Hal Daumé III |  |
| 166 |  |  [Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks](https://doi.org/10.18653/v1/2024.emnlp-main.43) |  | 0 | Large language models (LLMs) have demonstrated considerable proficiency in general natural language processing (NLP) tasks. Instruction tuning, a successful paradigm, enhances the ability of LLMs to follow natural language instructions and exhibit robust generalization across general tasks.... | Haoyuan Wu, Haisheng Zheng, Zhuolun He, Bei Yu |  |
| 167 |  |  [GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation](https://doi.org/10.18653/v1/2024.emnlp-main.44) |  | 0 | Large language models have seen widespread adoption in math problem-solving, yet for geometry problems, which often necessitate visual aids even for humans, the most advanced multi-modal models still struggle to effectively utilize image information. High-quality data is crucial for enhancing the... | Shihao Cai, Keqin Bao, Hangyu Guo, Jizhi Zhang, Jun Song, Bo Zheng |  |
| 168 |  |  [DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities](https://doi.org/10.18653/v1/2024.emnlp-main.45) |  | 0 | Learned Sparse Retrieval (LSR) models use vocabularies from pre-trained transformers, which often split entities into nonsensical fragments. Splitting entities diminishes retrieval accuracy and limits the model’s ability to incorporate up-to-date world knowledge not included in the training data.... | Thong Nguyen, Shubham Chatterjee, Sean MacAvaney, Iain Mackie, Jeff Dalton, Andrew Yates |  |
| 169 |  |  [Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.46) |  | 0 | Parameter-efficient fine-tuning (PEFT) is crucial for customizing Large Language Models (LLMs) with constrained resource. Although there have been various PEFT methods for dense-architecture LLMs, PEFT for sparse-architecture LLMs is still underexplored. In this work, we study the PEFT method for... | Zihan Wang, Deli Chen, Damai Dai, Runxin Xu, Zhuoshu Li, Yu Wu |  |
| 170 |  |  [LongEmbed: Extending Embedding Models for Long Context Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.47) |  | 0 | Embedding models play a pivotal role in modern NLP applications such as document retrieval. However, existing embedding models are limited to encoding short documents of typically 512 tokens, restrained from application scenarios requiring long inputs. This paper explores context window extension... | Dawei Zhu, Liang Wang, Nan Yang, Yifan Song, Wenhao Wu, Furu Wei, Sujian Li |  |
| 171 |  |  [Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences](https://doi.org/10.18653/v1/2024.emnlp-main.48) |  | 0 | Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning steps using chain-of-thought prompting under zero-shot or few-shot settings. However, zero-shot prompting always encounters low performance, and the superior performance of few-shot prompting hinges on... | Xiangyang Liu, Junliang He, Xipeng Qiu |  |
| 172 |  |  [Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue](https://doi.org/10.18653/v1/2024.emnlp-main.49) |  | 0 | Dialogue Aspect-based Sentiment Quadruple analysis (DiaASQ) extends ABSA to more complex real-world scenarios (i.e., dialogues), which makes existing generation methods encounter heightened noise and order bias challenges, leading to decreased robustness and accuracy.To address these, we propose... | Xianlong Luo, Meng Yang, Yihao Wang |  |
| 173 |  |  [Integrating Plutchik's Theory with Mixture of Experts for Enhancing Emotion Classification](https://doi.org/10.18653/v1/2024.emnlp-main.50) |  | 0 | Emotion significantly influences human behavior and decision-making processes. We propose a labeling methodology grounded in Plutchik’s Wheel of Emotions theory for emotion classification. Furthermore, we employ a Mixture of Experts (MoE) architecture to evaluate the efficacy of this labeling... | Dongjun Lim, YunGyung Cheong |  |
| 174 |  |  [In-context Contrastive Learning for Event Causality Identification](https://doi.org/10.18653/v1/2024.emnlp-main.51) |  | 0 | Event Causality Identification (ECI) aims at determining the existence of a causal relation between two events. Although recent prompt learning-based approaches have shown promising improvements on the ECI task, their performance are often subject to the delicate design of multiple prompts and the... | Chao Liang, Wei Xiang, Bang Wang |  |
| 175 |  |  [What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs](https://doi.org/10.18653/v1/2024.emnlp-main.52) |  | 0 | Best practices for high conflict conversations like counseling or customer support almost always include recommendations to paraphrase the previous speaker. Although paraphrase classification has received widespread attention in NLP, paraphrases are usually considered independent from context, and... | Anna Wegmann, Tijs A. van den Broek, Dong Nguyen |  |
| 176 |  |  [Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs](https://doi.org/10.18653/v1/2024.emnlp-main.53) |  | 0 | Language models learn rare syntactic phenomena, but the extent to which this is attributable to generalization vs. memorization is a major open question. To that end, we iteratively trained transformer language models on systematically manipulated corpora which were human-scale in size, and then... | Kanishka Misra, Kyle Mahowald |  |
| 177 |  |  [Large Language Models for Data Annotation and Synthesis: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.54) |  | 0 | Data annotation and synthesis generally refers to the labeling or generating of raw data with relevant information, which could be used for improving the efficacy of machine learning models. The process, however, is labor-intensive and costly. The emergence of advanced Large Language Models (LLMs),... | Zhen Tan, Dawei Li, Song Wang, Alimohammad Beigi, Bohan Jiang, Amrita Bhattacharjee, Mansooreh Karami, Jundong Li, Lu Cheng, Huan Liu |  |
| 178 |  |  [Chain-of-Dictionary Prompting Elicits Translation in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.55) |  | 0 | Large language models (LLMs) have shown surprisingly good performance in multilingual neural machine translation (MNMT) even if not being trained explicitly for translation. Yet, they still struggle with translating low-resource languages. As supported by our experiments, a bilingual dictionary... | Hongyuan Lu, Haoran Yang, Haoyang Huang, Dongdong Zhang, Wai Lam, Furu Wei |  |
| 179 |  |  [AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.56) |  | 0 | Fine-tuning large language models (LLMs) has achieved remarkable performance across various natural language processing tasks, yet it demands more and more memory as model sizes keep growing. To address this issue, the recently proposed Memory-efficient Zeroth-order (MeZO) methods attempt to... | Yifan Yang, Kai Zhen, Ershad Banijamali, Athanasios Mouchtaris, Zheng Zhang |  |
| 180 |  |  [RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning](https://doi.org/10.18653/v1/2024.emnlp-main.57) |  | 0 | Pre-trained language models, trained on large-scale corpora, demonstrate strong generalizability across various NLP tasks. Fine-tuning these models for specific tasks typically involves updating all parameters, which is resource-intensive. Parameter-efficient fine-tuning (PEFT) methods, such as the... | Haoyu Wang, Tianci Liu, Ruirui Li, Monica Xiao Cheng, Tuo Zhao, Jing Gao |  |
| 181 |  |  [BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering](https://doi.org/10.18653/v1/2024.emnlp-main.58) |  | 0 | Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often struggle with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To... | Haoyu Wang, Ruirui Li, Haoming Jiang, Jinjin Tian, Zhengyang Wang, Chen Luo, Xianfeng Tang, Monica Xiao Cheng, Tuo Zhao, Jing Gao |  |
| 182 |  |  [HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.59) |  | 0 | Empathy serves as a cornerstone in enabling prosocial behaviors, and can be evoked through sharing of personal experiences in stories. While empathy is influenced by narrative content, intuitively, people respond to the way a story is told as well, through narrative style. Yet the relationship... | Jocelyn Shen, Joel Mire, Hae Park, Cynthia Breazeal, Maarten Sap |  |
| 183 |  |  [Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence](https://doi.org/10.18653/v1/2024.emnlp-main.60) |  | 0 | Direct Preference Optimization (DPO) has emerged as a prominent algorithm for the direct and robust alignment of Large Language Models (LLMs) with human preferences, offering a more straightforward alternative to the complex Reinforcement Learning from Human Feedback (RLHF). Despite its promising... | Junru Lu, Jiazheng Li, Siyu An, Meng Zhao, Yulan He, Di Yin, Xing Sun |  |
| 184 |  |  [Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.61) |  | 0 | The cross-cultural adaptation of recipes is an important application of identifying and bridging cultural differences in language. The challenge lies in retaining the essence of the original recipe while also aligning with the writing and dietary habits of the target culture. Information Retrieval... | Tianyi Hu, Maria Maistro, Daniel Hershcovich |  |
| 185 |  |  [RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.62) |  | 0 | The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has enhanced medical diagnosis. However, current Med-LVLMs frequently encounter factual issues, often generating responses that do not align with established medical facts. Retrieval-Augmented Generation (RAG), which utilizes... | Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao |  |
| 186 |  |  [CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading](https://doi.org/10.18653/v1/2024.emnlp-main.63) |  | 0 | The utilization of Large Language Models (LLMs) in financial trading has primarily been concentrated within the stock market, aiding in economic and financial decisions. Yet, the unique opportunities presented by the cryptocurrency market, noted for its on-chain data’s transparency and the critical... | Yuan Li, Bingqiao Luo, Qian Wang, Nuo Chen, Xu Liu, Bingsheng He |  |
| 187 |  |  [A Survey on In-context Learning](https://doi.org/10.18653/v1/2024.emnlp-main.64) |  | 0 | With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate... | Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Baobao Chang, Xu Sun, Lei Li, Zhifang Sui |  |
| 188 |  |  [DocHieNet: A Large and Diverse Dataset for Document Hierarchy Parsing](https://doi.org/10.18653/v1/2024.emnlp-main.65) |  | 0 | Parsing documents from pixels, such as pictures and scanned PDFs, into hierarchical structures is extensively demanded in the daily routines of data storage, retrieval and understanding. However, previously the research on this topic has been largely hindered since most existing datasets are... | Hangdi Xing, Changxu Cheng, Feiyu Gao, Zirui Shao, Zhi Yu, Jiajun Bu, Qi Zheng, Cong Yao |  |
| 189 |  |  [AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation](https://doi.org/10.18653/v1/2024.emnlp-main.66) |  | 0 | The impressive performance of proprietary LLMs like GPT4 in code generation has led to a trend to replicate these capabilities in open-source models through knowledge distillation (e.g. Code Evol-Instruct). However, these efforts often neglect the crucial aspect of response quality, relying heavily... | Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, Lidong Bing |  |
| 190 |  |  [EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.67) |  | 0 | Multimodal large language models (MLLMs) have attracted increasing attention in the past few years, but they may still generate descriptions that include objects not present in the corresponding images, a phenomenon known as object hallucination. To eliminate hallucinations, existing methods... | Shangyu Xing, Fei Zhao, Zhen Wu, Tuo An, Weihao Chen, Chunhui Li, Jianbing Zhang, Xinyu Dai |  |
| 191 |  |  [Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization](https://doi.org/10.18653/v1/2024.emnlp-main.68) |  | 0 | This work suggests fundamentally rethinking the current practice of pruning large language models (LLMs). The way it is done is by divide and conquer: split the model into submodels, sequentially prune them, and reconstruct predictions of the dense counterparts on small calibration data one at a... | Sungbin Shin, Wonpyo Park, Jaeho Lee, Namhoon Lee |  |
| 192 |  |  [LLMs Are Zero-Shot Context-Aware Simultaneous Translators](https://doi.org/10.18653/v1/2024.emnlp-main.69) |  | 0 | The advent of transformers has fueled progress in machine translation. More recently large language models (LLMs) have come to the spotlight thanks to their generality and strong performance in a wide range of language tasks, including translation. Here we show that open-source LLMs perform on par... | Roman Koshkin, Katsuhito Sudoh, Satoshi Nakamura |  |
| 193 |  |  [AgentReview: Exploring Peer Review Dynamics with LLM Agents](https://doi.org/10.18653/v1/2024.emnlp-main.70) |  | 0 | Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent... | Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia Xiao, Jindong Wang |  |
| 194 |  |  [ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.71) |  | 0 | Conversational search requires accurate interpretation of user intent from complex multi-turn contexts. This paper presents ChatRetriever, which inherits the strong generalization capability of large language models to robustly represent complex conversational sessions for dense retrieval. To... | Kelong Mao, Chenlong Deng, Haonan Chen, Fengran Mo, Zheng Liu, Tetsuya Sakai, Zhicheng Dou |  |
| 195 |  |  [Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments](https://doi.org/10.18653/v1/2024.emnlp-main.72) |  | 0 | Large language models (LLMs) have shown promising abilities as cost-effective and reference-free evaluators for assessing language generation quality. In particular, pairwise LLM evaluators, which compare two generated texts and determine the preferred one, have been employed in a wide range of... | Han Zhou, Xingchen Wan, Yinhong Liu, Nigel Collier, Ivan Vulic, Anna Korhonen |  |
| 196 |  |  [Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation](https://doi.org/10.18653/v1/2024.emnlp-main.73) |  | 0 | Legal case retrieval for sourcing similar cases is critical in upholding judicial fairness. Different from general web search, legal case retrieval involves processing lengthy, complex, and highly specialized legal documents. Existing methods in this domain often overlook the incorporation of legal... | Chenlong Deng, Kelong Mao, Zhicheng Dou |  |
| 197 |  |  [Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process](https://doi.org/10.18653/v1/2024.emnlp-main.74) |  | 0 | In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language Models (LLMs), existing works are highly dependent on... | Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong Jiang |  |
| 198 |  |  [Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation](https://doi.org/10.18653/v1/2024.emnlp-main.75) |  | 0 | Recent advances in image tokenizers, such as VQ-VAE, have enabled text-to-image generation using auto-regressive methods, similar to language modeling. However, these methods have yet to leverage pre-trained language models, despite their adaptability to various downstream tasks. In this work, we... | Yuhui Zhang, Brandon McKinzie, Zhe Gan, Vaishaal Shankar, Alexander Toshev |  |
| 199 |  |  [QUDSELECT: Selective Decoding for Questions Under Discussion Parsing](https://doi.org/10.18653/v1/2024.emnlp-main.76) |  | 0 | Question Under Discussion (QUD) is a discourse framework that uses implicit questions to reveal discourse relationships between sentences. In QUD parsing, each sentence is viewed as an answer to a question triggered by an anchor sentence in prior context. The resulting QUD structure is required to... | Ashima Suvarna, Xiao Liu, Tanmay Parekh, KaiWei Chang, Nanyun Peng |  |
| 200 |  |  [Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration](https://doi.org/10.18653/v1/2024.emnlp-main.77) |  | 0 |  | Peng Chen, XiaoYu Guo, YuanFang Li, Xiaowang Zhang, Zhiyong Feng |  |
| 201 |  |  [Model Balancing Helps Low-data Training and Fine-tuning](https://doi.org/10.18653/v1/2024.emnlp-main.78) |  | 0 | Recent advances in foundation models have emphasized the need to align pre-trained models with specialized domains using small, curated datasets. Studies on these foundation models underscore the importance of low-data training and fine-tuning. This topic, well-known in natural language processing... | Zihang Liu, Yuanzhe Hu, Tianyu Pang, Yefan Zhou, Pu Ren, Yaoqing Yang |  |
| 202 |  |  [Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.79) |  | 0 | Aligning language models (LMs) based on human-annotated preference data is a crucial step in obtaining practical and performant LM-based systems. However, multilingual human preference data are difficult to obtain at scale, making it challenging to extend this framework to diverse languages. In... | Zhaofeng Wu, Ananth Balashankar, Yoon Kim, Jacob Eisenstein, Ahmad Beirami |  |
| 203 |  |  [Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment](https://doi.org/10.18653/v1/2024.emnlp-main.80) |  | 0 | Pre-trained language models like BERT and T5 serve as crucial backbone encoders for dense retrieval. However, these models often exhibit limited generalization capabilities and face challenges in improving in-domain accuracy. Recent research has explored using large language models (LLMs) as... | Kun Luo, Minghao Qin, Zheng Liu, Shitao Xiao, Jun Zhao, Kang Liu |  |
| 204 |  |  [A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.81) |  | 0 | Conventional Knowledge Graph Reasoning (KGR) models learn the embeddings of KG components over the structure of KGs, but their performances are limited when the KGs are severely incomplete. Recent LLM-enhanced KGR models input KG structural information into LLMs. However, they require fine-tuning... | Zhongwu Chen, Long Bai, Zixuan Li, Zhen Huang, Xiaolong Jin, Yong Dou |  |
| 205 |  |  [Towards Tool Use Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.82) |  | 0 | Recently, tool use with LLMs has become one of the primary research topics as it can help LLM generate truthful and helpful responses. Existing studies on tool use with LLMs primarily focus on enhancing the tool-calling ability of LLMs. In practice, like chat assistants, LLMs are also required to... | Zhiyuan Chen, Shiqi Shen, Guangyao Shen, Gong Zhi, Xu Chen, Yankai Lin |  |
| 206 |  |  [DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.83) |  | 0 | The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the quality of this data is challenging due to its sheer... | Ranchi Zhao, Zhen Leng Thai, Yifan Zhang, Shengding Hu, Jie Zhou, Yunqi Ba, Jie Cai, Zhiyuan Liu, Maosong Sun |  |
| 207 |  |  [Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps](https://doi.org/10.18653/v1/2024.emnlp-main.84) |  | 0 | When asked to summarize articles or answer questions given a passage, large language models (LLMs) can hallucinate details and respond with unsubstantiated answers that are inaccurate with respect to the input context. This paper describes a simple approach for detecting such \*\*contextual... | YungSung Chuang, Linlu Qiu, ChengYu Hsieh, Ranjay Krishna, Yoon Kim, James R. Glass |  |
| 208 |  |  [Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.85) |  | 0 | Alignment in artificial intelligence pursues the consistency between model responses and human preferences as well as values. In practice, the multifaceted nature of human preferences inadvertently introduces what is known as the ”alignment tax”–a compromise where enhancements in alignment within... | Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Zexu Sun, Bowen Sun, Huimin Chen, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 209 |  |  [Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation](https://doi.org/10.18653/v1/2024.emnlp-main.86) |  | 0 | The Matthew effect is a big challenge in Recommender Systems (RSs), where popular items tend to receive increasing attention, while less popular ones are often overlooked, perpetuating existing disparities. Although many existing methods attempt to mitigate Matthew effect in the static or... | Yongsen Zheng, Ruilin Xu, Guohua Wang, Liang Lin, KwokYan Lam |  |
| 210 |  |  [Advancing Event Causality Identification via Heuristic Semantic Dependency Inquiry Network](https://doi.org/10.18653/v1/2024.emnlp-main.87) |  | 0 |  | Haoran Li, Qiang Gao, Hongmei Wu, Li Huang |  |
| 211 |  |  [Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors](https://doi.org/10.18653/v1/2024.emnlp-main.88) |  | 0 | Multiple-choice visual question answering (VQA) is to automatically choose a correct answer from a set of choices after reading an image. Existing efforts have been devoted to a separate generation of an image-related question, a correct answer, or challenge distractors. By contrast, we turn to a... | Wenjian Ding, Yao Zhang, Jun Wang, Adam Jatowt, Zhenglu Yang |  |
| 212 |  |  [UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation](https://doi.org/10.18653/v1/2024.emnlp-main.89) |  | 0 | The fashion domain encompasses a variety of real-world multimodal tasks, including multimodal retrieval and multimodal generation. The rapid advancements in artificial intelligence generated content, particularly in technologies like large language models for text generation and diffusion models... | Xiangyu Zhao, Yuehan Zhang, Wenlong Zhang, XiaoMing Wu |  |
| 213 |  |  [Tracking the perspectives of interacting language models](https://doi.org/10.18653/v1/2024.emnlp-main.90) |  | 0 | Large language models (LLMs) are capable of producing high quality information at unprecedented rates. As these models continue to entrench themselves in society, the content they produce will become increasingly pervasive in databases that are, in turn, incorporated into the pre-training data,... | Hayden S. Helm, Brandon Duderstadt, Youngser Park, Carey E. Priebe |  |
| 214 |  |  [MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.91) |  | 0 | A multimodal large language model MLLMs may struggle with answering visual-based (personal) entity questions (VEQA), such as ”who is A?” or ”who is A that B is talking to?” for various reasons, e.g., the absence of the name of A in the caption or the inability of MLLMs to recognize A, particularly... | Zhengxuan Zhang, Yin Wu, Yuyu Luo, Nan Tang |  |
| 215 |  |  [Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?](https://doi.org/10.18653/v1/2024.emnlp-main.92) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities, but still suffer from inconsistency issues (e.g. LLMs can react differently to disturbances like rephrasing or inconsequential order change). In addition to these inconsistencies, we also observe that LLMs, while capable of... | Zhe Yang, Yichang Zhang, Tianyu Liu, Jian Yang, Junyang Lin, Chang Zhou, Zhifang Sui |  |
| 216 |  |  [Watch Every Step! LLM Agent Learning via Iterative Step-level Process Refinement](https://doi.org/10.18653/v1/2024.emnlp-main.93) |  | 0 | Large language model agents have exhibited exceptional performance across a range of complex interactive tasks. Recent approaches have utilized tuning with expert trajectories to enhance agent performance, yet they primarily concentrate on outcome rewards, which may lead to errors or suboptimal... | Weimin Xiong, Yifan Song, Xiutian Zhao, Wenhao Wu, Xun Wang, Ke Wang, Cheng Li, Wei Peng, Sujian Li |  |
| 217 |  |  [Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation](https://doi.org/10.18653/v1/2024.emnlp-main.94) |  | 0 | Domain experts across engineering, healthcare, and education follow strict standards for producing quality content such as technical manuals, medication instructions, and children’s reading materials. However, current works in controllable text generation have yet to explore using these standards... | Joseph Marvin Imperial, Gail Forey, Harish Tayyar Madabushi |  |
| 218 |  |  [Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.95) |  | 0 | Cross-domain Named Entity Recognition (CDNER) is crucial for Knowledge Graph (KG) construction and natural language processing (NLP), enabling learning from source to target domains with limited data. Previous studies often rely on manually collected entity-relevant sentences from the web or... | Zhihao Zhang, Sophia Yat Mei Lee, Junshuang Wu, Dong Zhang, Shoushan Li, Erik Cambria, Guodong Zhou |  |
| 219 |  |  [Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models](https://doi.org/10.18653/v1/2024.emnlp-main.96) |  | 0 | Retrieval-Augmented Generative (RAG) models enhance Large Language Models (LLMs) by integrating external knowledge bases, improving their performance in applications like fact-checking and information searching. In this paper, we demonstrate a security threat where adversaries can exploit the... | Zhen Tan, Chengshuai Zhao, Raha Moraffah, Yifan Li, Song Wang, Jundong Li, Tianlong Chen, Huan Liu |  |
| 220 |  |  [Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement](https://doi.org/10.18653/v1/2024.emnlp-main.97) |  | 0 | Scene Graph Generation (SGG) provides basic language representation of visual scenes, requiring models to grasp complex and diverse semantics between objects. This complexity and diversity in SGG leads to underrepresentation, where parts of triplet labels are rare or even unseen during training,... | Yuxuan Wang, Xiaoyuan Liu |  |
| 221 |  |  [SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation](https://doi.org/10.18653/v1/2024.emnlp-main.98) |  | 0 | Large Language Models (LLMs) have transformed machine learning but raised significant legal concerns due to their potential to produce text that infringes on copyrights, resulting in several high-profile lawsuits. The legal landscape is struggling to keep pace with these rapid advancements, with... | Xiaoze Liu, Ting Sun, Tianyang Xu, Feijie Wu, Cunxiang Wang, Xiaoqian Wang, Jing Gao |  |
| 222 |  |  [MatchTime: Towards Automatic Soccer Game Commentary Generation](https://doi.org/10.18653/v1/2024.emnlp-main.99) |  | 0 | Soccer is a globally popular sport with a vast audience, in this paper, we consider constructing an automatic soccer game commentary model to improve the audiences’ viewing experience. In general, we make the following contributions: \*First\*, observing the prevalent video-text misalignment in... | Jiayuan Rao, Haoning Wu, Chang Liu, Yanfeng Wang, Weidi Xie |  |
| 223 |  |  [Rethinking Token Reduction for State Space Models](https://doi.org/10.18653/v1/2024.emnlp-main.100) |  | 0 | Recent advancements in State Space Models (SSMs) have attracted significant interest, particularly in models optimized for parallel training and handling long-range dependencies. Architectures like Mamba have scaled to billions of parameters with selective SSM. To facilitate broader applications... | Zheng Zhan, Yushu Wu, Zhenglun Kong, Changdi Yang, Yifan Gong, Xuan Shen, Xue Lin, Pu Zhao, Yanzhi Wang |  |
| 224 |  |  [Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.101) |  | 0 | Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data... | Chang Zong, Yuchen Yan, Weiming Lu, Jian Shao, Yongfeng Huang, Heng Chang, Yueting Zhuang |  |
| 225 |  |  [MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic](https://doi.org/10.18653/v1/2024.emnlp-main.102) |  | 0 | The advent of large language models (LLMs) like GPT-4 has catalyzed the exploration of multi-task learning (MTL), in which a single model demonstrates proficiency across diverse tasks. Task arithmetic has emerged as a cost-effective approach for MTL. It enables performance enhancement across... | Yuyan Zhou, Liang Song, Bingning Wang, Weipeng Chen |  |
| 226 |  |  [Event Causality Identification with Synthetic Control](https://doi.org/10.18653/v1/2024.emnlp-main.103) |  | 0 | Event causality identification (ECI), a process that extracts causal relations between events from text, is crucial for distinguishing causation from correlation. Traditional approaches to ECI have primarily utilized linguistic patterns and multi-hop relational inference, risking false causality... | Haoyu Wang, Fengze Liu, Jiayao Zhang, Dan Roth, Kyle Richardson |  |
| 227 |  |  [Retrieved Sequence Augmentation for Protein Representation Learning](https://doi.org/10.18653/v1/2024.emnlp-main.104) |  | 0 | Protein Language Models traditionally depend on Multiple Sequence Alignments (MSA) to incorporate evolutionary knowledge. However, MSA-based approaches suffer from substantial computational overhead and generally underperform in generalizing to de novo proteins. This study reevaluates the role of... | Chang Ma, Haiteng Zhao, Lin Zheng, Jiayi Xin, Qintong Li, Lijun Wu, Zhihong Deng, Yang Lu, Qi Liu, Sheng Wang, Lingpeng Kong |  |
| 228 |  |  [HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.105) |  | 0 | Large Vision-Language Models (LVLMs) have shown remarkable performance on many visual-language tasks. However, these models still suffer from multimodal hallucination, which means the generation of objects or content that violates the images. Many existing work detects hallucination by directly... | Fan Yuan, Chi Qin, Xiaogang Xu, Piji Li |  |
| 229 |  |  [TopViewRS: Vision-Language Models as Top-View Spatial Reasoners](https://doi.org/10.18653/v1/2024.emnlp-main.106) |  | 0 | Top-view perspective denotes a typical way in which humans read and reason over different types of maps, and it is vital for localization and navigation of humans as well as of ‘non-human’ agents, such as the ones backed by large Vision-Language Models (VLMs). Nonetheless, spatial reasoning... | Chengzu Li, Caiqi Zhang, Han Zhou, Nigel Collier, Anna Korhonen, Ivan Vulic |  |
| 230 |  |  [DA³: A Distribution-Aware Adversarial Attack against Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.107) |  | 0 | Language models can be manipulated by adversarial attacks, which introduce subtle perturbations to input data. While recent attack methods can achieve a relatively high attack success rate (ASR), we’ve observed that the generated adversarial examples have a different data distribution compared with... | Yibo Wang, Xiangjue Dong, James Caverlee, Philip S. Yu |  |
| 231 |  |  [Evaluating Psychological Safety of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.108) |  | 0 | In this work, we designed unbiased prompts to systematically evaluate the psychological safety of large language models (LLMs). First, we tested five different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average... | Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, Lidong Bing |  |
| 232 |  |  [An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification](https://doi.org/10.18653/v1/2024.emnlp-main.109) |  | 0 | Sentiment classification (SC) often suffers from low-resource challenges such as domain-specific contexts, imbalanced label distributions, and few-shot scenarios. The potential of the diffusion language model (LM) for textual data augmentation (DA) remains unexplored, moreover, textual DA methods... | Zhuowei Chen, Lianxi Wang, Yuben Wu, Xinfeng Liao, Yujia Tian, Junyang Zhong |  |
| 233 |  |  [Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.110) |  | 0 | While large pre-trained visual-language models have shown promising results on traditional visual question answering benchmarks, it is still challenging for them to answer complex VQA problems which requires diverse world knowledge. Motivated by the research of retrieval-augmented generation in the... | Dongze Hao, Qunbo Wang, Longteng Guo, Jie Jiang, Jing Liu |  |
| 234 |  |  [PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.111) |  | 0 | Simultaneous Machine Translation (SiMT) requires target tokens to be generated in real-time as streaming source tokens are consumed. Traditional approaches to SiMT typically require sophisticated architectures and extensive parameter configurations for training adaptive read/write policies, which... | Libo Zhao, Jing Li, Ziqian Zeng |  |
| 235 |  |  [TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging](https://doi.org/10.18653/v1/2024.emnlp-main.112) |  | 0 | Charts are important for presenting and explaining complex data relationships. Recently, multimodal large language models (MLLMs) have shown remarkable capabilities in chart understanding. However, the sheer size of these models limits their use in resource-constrained environments. In this paper,... | Liang Zhang, Anwen Hu, Haiyang Xu, Ming Yan, Yichen Xu, Qin Jin, Ji Zhang, Fei Huang |  |
| 236 |  |  [Do We Need Language-Specific Fact-Checking Models? The Case of Chinese](https://doi.org/10.18653/v1/2024.emnlp-main.113) |  | 0 | This paper investigates the potential benefits of language-specific fact-checking models, focusing on the case of Chinese using CHEF dataset. To better reflect real-world fact-checking, we first develop a novel Chinese document-level evidence retriever, achieving state-of-the-art performance. We... | Caiqi Zhang, Zhijiang Guo, Andreas Vlachos |  |
| 237 |  |  [Enhancing Advanced Visual Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.114) |  | 0 | Recent advancements in Vision-Language (VL) research have sparked new benchmarks for complex visual reasoning, challenging models’ advanced reasoning ability. Traditional Vision-Language models (VLMs) perform well in visual perception tasks while struggling with complex reasoning scenarios.... | Zhiyuan Li, Dongnan Liu, Chaoyi Zhang, Heng Wang, Tengfei Xue, Weidong Cai |  |
| 238 |  |  [CMD: a framework for Context-aware Model self-Detoxification](https://doi.org/10.18653/v1/2024.emnlp-main.115) |  | 0 | Text detoxification aims to minimize the risk of language models producing toxic content. Existing detoxification methods of directly constraining the model output or further training the model on the non-toxic corpus fail to achieve a decent balance between detoxification effectiveness and... | Zecheng Tang, Keyan Zhou, Juntao Li, Yuyang Ding, Pinzheng Wang, Yan Bowen, Renjie Hua, Min Zhang |  |
| 239 |  |  [Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection](https://doi.org/10.18653/v1/2024.emnlp-main.116) |  | 0 | In recent years, large language models (LLMs) have achieved remarkable success in the field of natural language generation. Compared to previous small-scale models, they are capable of generating fluent output based on the provided prefix or prompt. However, one critical challenge — the... | Xiaomeng Hu, Yiming Zhang, Ru Peng, Haozhe Zhang, Chenwei Wu, Gang Chen, Junbo Zhao |  |
| 240 |  |  [TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control](https://doi.org/10.18653/v1/2024.emnlp-main.117) |  | 0 | Zero-shot singing voice synthesis (SVS) with style transfer and style control aims to generate high-quality singing voices with unseen timbres and styles (including singing method, emotion, rhythm, technique, and pronunciation) from audio and text prompts. However, the multifaceted nature of... | Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao |  |
| 241 |  |  [Be Helpful but Don't Talk too Much - Enhancing Helpfulness in Conversations through Relevance in Multi-Turn Emotional Support](https://doi.org/10.18653/v1/2024.emnlp-main.118) |  | 0 | For a conversation to help and support, speakers should maintain an “effect-effort” tradeoff. As outlined in the gist of “Cognitive Relevance Principle”, helpful speakers should optimize the “cognitive relevance” through maximizing the “cognitive effects” and minimizing the “processing effort”... | Junlin Li, Bo Peng, YuYin Hsu, ChuRen Huang |  |
| 242 |  |  [Aligning Language Models to Explicitly Handle Ambiguity](https://doi.org/10.18653/v1/2024.emnlp-main.119) |  | 0 | In interactions between users and language model agents, user utterances frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack of exactness) to prioritize efficiency. This can lead to varying interpretations of the same input based on different assumptions or background... | Hyuhng Joon Kim, Youna Kim, Cheonbok Park, Junyeob Kim, Choonghyun Park, Kang Min Yoo, Sanggoo Lee, Taeuk Kim |  |
| 243 |  |  [Tag-grounded Visual Instruction Tuning with Retrieval Augmentation](https://doi.org/10.18653/v1/2024.emnlp-main.120) |  | 0 | Despite recent advances in the general visual instruction-following ability of Multimodal Large Language Models (MLLMs), they still struggle with critical problems when required to provide a precise and detailed response to a visual instruction: (1) failure to identify novel objects or entities,... | Daiqing Qi, Handong Zhao, Zijun Wei, Sheng Li |  |
| 244 |  |  [GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.121) |  | 0 | Despite the rapid progress of large language models (LLMs), their task performance remains sensitive to prompt design. Recent studies have explored leveraging the LLM itself as an optimizer to identify optimal prompts that maximize task accuracy. However, when evaluating prompts, such approaches... | Xuanchang Zhang, Zhuosheng Zhang, Hai Zhao |  |
| 245 |  |  [Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information](https://doi.org/10.18653/v1/2024.emnlp-main.122) |  | 0 |  | Runze Xia, Congchi Yin, Piji Li |  |
| 246 |  |  [Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.123) |  | 0 | Code retrieval aims to identify code from extensive codebases that semantically aligns with a given query code snippet. Collecting a broad and high-quality set of query and code pairs is crucial to the success of this task. However, existing data collection methods struggle to effectively balance... | Rui Li, Qi Liu, Liyang He, Zheng Zhang, Hao Zhang, Shengyu Ye, Junyu Lu, Zhenya Huang |  |
| 247 |  |  [Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.124) |  | 0 | Vision-language models (VLMs) like CLIP have demonstrated remarkable applicability across a variety of downstream tasks, including zero-shot image classification. Recently, the use of prompts or adapters for efficient transfer learning (ETL) has gained significant attention for effectively adapting... | Yongjin Yang, Jongwoo Ko, SeYoung Yun |  |
| 248 |  |  [Advancing Process Verification for Large Language Models via Tree-Based Preference Learning](https://doi.org/10.18653/v1/2024.emnlp-main.125) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable potential in handling complex reasoning tasks by generating step-by-step rationales. Some methods have proven effective in boosting accuracy by introducing extra verifiers to assess these paths. However, existing verifiers, typically trained... | Mingqian He, Yongliang Shen, Wenqi Zhang, Zeqi Tan, Weiming Lu |  |
| 249 |  |  [An Inversion Attack Against Obfuscated Embedding Matrix in Language Model Inference](https://doi.org/10.18653/v1/2024.emnlp-main.126) |  | 0 | With the rapidly-growing deployment of large language model (LLM) inference services, privacy concerns have arisen regarding to the user input data. Recent studies are exploring transforming user inputs to obfuscated embedded vectors, so that the data will not be eavesdropped by service provides.... | Yu Lin, Qizhi Zhang, Quanwei Cai, Jue Hong, Wu Ye, Huiqi Liu, Bing Duan |  |
| 250 |  |  [VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation](https://doi.org/10.18653/v1/2024.emnlp-main.127) |  | 0 | The recent years have witnessed great advances in video generation. However, the development of automatic video metrics is lagging significantly behind. None of the existing metric is able to provide reliable scores over generated videos. The main barrier is the lack of large-scale human-annotated... | Xuan He, Dongfu Jiang, Ge Zhang, Max Ku, Achint Soni, Sherman Siu, Haonan Chen, Abhranil Chandra, Ziyan Jiang, Aaran Arulraj, Kai Wang, Quy Duc Do, Yuansheng Ni, Bohan Lyu, Yaswanth Narsupalli, Rongqi Fan, Zhiheng Lyu, Bill Yuchen Lin, Wenhu Chen |  |
| 251 |  |  [LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.128) |  | 0 | We introduce LogicAsker, a novel approach for evaluating and enhancing the logical reasoning capabilities of large language models (LLMs) such as ChatGPT and GPT-4. Despite LLMs’ prowess in tasks like writing assistance, code generation, and machine translation, assessing their ability to reason... | Yuxuan Wan, Wenxuan Wang, Yiliu Yang, Youliang Yuan, Jentse Huang, Pinjia He, Wenxiang Jiao, Michael R. Lyu |  |
| 252 |  |  [Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training](https://doi.org/10.18653/v1/2024.emnlp-main.129) |  | 0 | Information Extraction (IE), aiming to extract structured information from unstructured natural language texts, can significantly benefit from pre-trained language models. However, existing pre-training methods solely focus on exploiting the textual knowledge, relying extensively on annotated... | Xiaoyang Yi, Yuru Bao, Jian Zhang, Yifang Qin, Faxin Lin |  |
| 253 |  |  [FuseGen: PLM Fusion for Data-generation based Zero-shot Learning](https://doi.org/10.18653/v1/2024.emnlp-main.130) |  | 0 | Data-generation based zero-shot learning, although effective in training Small Task-specific Models (STMs) via synthetic datasets generated by Pre-trained Language Models (PLMs), is often limited by the low quality of such synthetic datasets. Previous solutions have primarily focused on single PLM... | Tianyuan Zou, Yang Liu, Peng Li, Jianqing Zhang, Jingjing Liu, YaQin Zhang |  |
| 254 |  |  [I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case Study on Text-to-SQL Generation](https://doi.org/10.18653/v1/2024.emnlp-main.131) |  | 0 | This study explores the proactive ability of LLMs to seek user support. We propose metrics to evaluate the trade-off between performance improvements and user burden, and investigate whether LLMs can determine when to request help under varying information availability. Our experiments show that... | ChengKuang Wu, Zhi Rui Tam, ChaoChung Wu, ChiehYen Lin, Hungyi Lee, YunNung Chen |  |
| 255 |  |  [Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm](https://doi.org/10.18653/v1/2024.emnlp-main.132) |  | 0 | We address the task of detecting abusive sentences in which identity groups are depicted as deviating from the norm (e.g. Gays sprinkle flour over their gardens for good luck). These abusive utterances need not be stereotypes or negative in sentiment. We introduce the first dataset for this task.... | Michael Wiegand, Josef Ruppenhofer |  |
| 256 |  |  [By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.133) |  | 0 | Large language models (LLMs) have demonstrated exceptional abilities across various domains. However, utilizing LLMs for ubiquitous sensing applications remains challenging as existing text-prompt methods show significant performance degradation when handling long sensor data sequences. In this... | Hyungjun Yoon, Biniyam Aschalew Tolera, Taesik Gong, Kimin Lee, SungJu Lee |  |
| 257 |  |  [Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization](https://doi.org/10.18653/v1/2024.emnlp-main.134) |  | 0 | Despite recent advances in LLM quantization, activation quantization remains to be challenging due to the activation outliers. Conventional remedies, e.g., mixing precisions for different channels, introduce extra overhead and reduce the speedup. In this work, we develop a simple yet effective... | Seungwoo Son, Wonpyo Park, Woohyun Han, Kyuyeun Kim, Jaeho Lee |  |
| 258 |  |  [CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search](https://doi.org/10.18653/v1/2024.emnlp-main.135) |  | 0 | In this paper, we study how open-source large language models (LLMs) can be effectively deployed for improving query rewriting in conversational search, especially for ambiguous queries. We introduce CHIQ, a two-step method that leverages the capabilities of LLMs to resolve ambiguities in the... | Fengran Mo, Abbas Ghaddar, Kelong Mao, Mehdi Rezagholizadeh, Boxing Chen, Qun Liu, JianYun Nie |  |
| 259 |  |  [Towards Low-Resource Harmful Meme Detection with LMM Agents](https://doi.org/10.18653/v1/2024.emnlp-main.136) |  | 0 | The proliferation of Internet memes in the age of social media necessitates effective identification of harmful ones. Due to the dynamic nature of memes, existing data-driven models may struggle in low-resource scenarios where only a few labeled examples are available. In this paper, we propose an... | Jianzhao Huang, Hongzhan Lin, Ziyan Liu, Ziyang Luo, Guang Chen, Jing Ma |  |
| 260 |  |  [VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values](https://doi.org/10.18653/v1/2024.emnlp-main.137) |  | 0 | This paper introduces VIVA, a benchmark for VIsion-grounded decision-making driven by human VAlues. While most large vision-language models (VLMs) focus on physical-level skills, our work is the first to examine their multimodal capabilities in leveraging human values to make decisions under a... | Zhe Hu, Yixiao Ren, Jing Li, Yu Yin |  |
| 261 |  |  [Direct Multi-Turn Preference Optimization for Language Agents](https://doi.org/10.18653/v1/2024.emnlp-main.138) |  | 0 | Adapting Large Language Models (LLMs) for agent tasks is critical in developing language agents. Direct Preference Optimization (DPO) is a promising technique for this adaptation with the alleviation of compounding errors, offering a means to directly optimize Reinforcement Learning (RL)... | Wentao Shi, Mengqi Yuan, Junkang Wu, Qifan Wang, Fuli Feng |  |
| 262 |  |  [Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.139) |  | 0 | The alignment of reasoning abilities between smaller and larger Language Models are largely conducted via supervised fine-tuning using demonstrations generated from robust Large Language Models (LLMs). Although these approaches deliver more performant models, they do not show sufficiently strong... | Leonardo Ranaldi, André Freitas |  |
| 263 |  |  [In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search](https://doi.org/10.18653/v1/2024.emnlp-main.140) |  | 0 | To effectively use large language models (LLMs) for real-world queries, it is imperative that they generalize to the long-tail distribution, i.e. rare examples where models exhibit low confidence. In this work, we take the first step towards evaluating LLMs in the long-tail distribution of... | Huihan Li, Yuting Ning, Zeyi Liao, Siyuan Wang, Xiang Li, Ximing Lu, Wenting Zhao, Faeze Brahman, Yejin Choi, Xiang Ren |  |
| 264 |  |  [AutoScraper: A Progressive Understanding Web Agent for Web Scraper Generation](https://doi.org/10.18653/v1/2024.emnlp-main.141) |  | 0 | Web scraping is a powerful technique that extracts data from websites, enabling automated data collection, enhancing data analysis capabilities, and minimizing manual data entry efforts. Existing methods, wrappers-based methods suffer from limited adaptability and scalability when faced with a new... | Wenhao Huang, Zhouhong Gu, Chenghao Peng, Jiaqing Liang, Zhixu Li, Yanghua Xiao, Liqian Wen, Zulong Chen |  |
| 265 |  |  [Backward Lens: Projecting Language Model Gradients into the Vocabulary Space](https://doi.org/10.18653/v1/2024.emnlp-main.142) |  | 0 | Understanding how Transformer-based Language Models (LMs) learn and recall information is a key goal of the deep learning community. Recent interpretability methods project weights and hidden states obtained from the forward pass to the models’ vocabularies, helping to uncover how information flows... | Shahar Katz, Yonatan Belinkov, Mor Geva, Lior Wolf |  |
| 266 |  |  [Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.143) |  | 0 | Visual arguments, often used in advertising or social causes, rely on images to persuade viewers to do or believe something. Understanding these arguments requires selective vision: only specific visual stimuli within an image are relevant to the argument, and relevance can only be understood... | Jiwan Chung, Sungjae Lee, Minseo Kim, Seungju Han, Ashkan Yousefpour, Jack Hessel, Youngjae Yu |  |
| 267 |  |  [Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!](https://doi.org/10.18653/v1/2024.emnlp-main.144) |  | 0 | Humans possess multimodal literacy, allowing them to actively integrate information from various modalities to form reasoning. Faced with challenges like lexical ambiguity in text, we supplement this with other modalities, such as thumbnail images or textbook illustrations. Is it possible for... | Jiwan Chung, Seungwon Lim, Jaehyun Jeon, Seungbeen Lee, Youngjae Yu |  |
| 268 |  |  [Reusing Transferable Weight Increments for Low-resource Style Generation](https://doi.org/10.18653/v1/2024.emnlp-main.145) |  | 0 | Text style transfer (TST) is crucial in natural language processing, aiming to endow text with a new style without altering its meaning. In real-world scenarios, not all styles have abundant resources. This work introduces TWIST (reusing Transferable Weight Increments for Style Text generation), a... | Chunzhen Jin, Eliot Huang, Heng Chang, Yaqi Wang, Peng Cao, Osmar R. Zaïane |  |
| 269 |  |  [Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course](https://doi.org/10.18653/v1/2024.emnlp-main.146) |  | 0 | Using large language models (LLMs) for automatic evaluation has become an important evaluation method in NLP research. However, it is unclear whether these LLM-based evaluators can be effectively applied in real-world classrooms to assess student assignments. This empirical report shares how we use... | ChengHan Chiang, WeiChih Chen, ChunYi Kuan, Chienchou Yang, Hungyi Lee |  |
| 270 |  |  [Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?](https://doi.org/10.18653/v1/2024.emnlp-main.147) |  | 0 | State-of-the-art Large Language Models (LLMs) are accredited with an increasing number of different capabilities, ranging from reading comprehension over advanced mathematical and reasoning skills to possessing scientific knowledge. In this paper we focus on multi-hop reasoning—the ability to... | Neeladri Bhuiya, Viktor Schlegel, Stefan Winkler |  |
| 271 |  |  [Instruction Pre-Training: Language Models are Supervised Multitask Learners](https://doi.org/10.18653/v1/2024.emnlp-main.148) |  | 0 | Unsupervised multitask pre-training has been the critical method behind the recent success of language models (LMs). However, supervised multitask learning still holds significant promise, as scaling it in the post-training stage trends towards better generalization. In this paper, we explore... | Daixuan Cheng, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei |  |
| 272 |  |  [LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.149) |  | 0 | Large language models (LLMs) require continual knowledge updates to stay abreast of the ever-changing world facts, prompting the formulation of lifelong model editing task. While recent years have witnessed the development of various techniques for single and batch editing, these methods either... | Renzhi Wang, Piji Li |  |
| 273 |  |  [Collaborative Performance Prediction for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.150) |  | 0 | Comprehensively understanding and accurately predicting the performance of large language models across diverse downstream tasks has emerged as a pivotal challenge in NLP research. The pioneering scaling law on downstream works demonstrated intrinsic similarities within model families and utilized... | Qiyuan Zhang, Fuyuan Lyu, Xue Liu, Chen Ma |  |
| 274 |  |  [Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese](https://doi.org/10.18653/v1/2024.emnlp-main.151) |  | 0 | In this work, we develop a pipeline for historical-psychological text analysis in classical Chinese. Humans have produced texts in various languages for thousands of years; however, most of the computational literature is focused on contemporary languages and corpora. The emerging field of... | Yuqi Chen, Sixuan Li, Ying Li, Mohammad Atari |  |
| 275 |  |  [Knowledge Verification to Nip Hallucination in the Bud](https://doi.org/10.18653/v1/2024.emnlp-main.152) |  | 0 | While large language models (LLMs) have demonstrated exceptional performance across various tasks following human alignment, they may still generate responses that sound plausible but contradict factual knowledge, a phenomenon known as hallucination. In this paper, we demonstrate the feasibility of... | Fanqi Wan, Xinting Huang, Leyang Cui, Xiaojun Quan, Wei Bi, Shuming Shi |  |
| 276 |  |  [QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios](https://doi.org/10.18653/v1/2024.emnlp-main.153) |  | 0 | Reasoning is key to many decision making processes. It requires consolidating a set of rule-like premises that are often associated with degrees of uncertainty and observations to draw conclusions. In this work, we address both the case where premises are specified as numeric probabilistic rules... | Timo Pierre Schrader, Lukas Lange, Simon Razniewski, Annemarie Friedrich |  |
| 277 |  |  [African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification](https://doi.org/10.18653/v1/2024.emnlp-main.154) |  | 0 | Recent Large Vision-Language Models (LVLMs) demonstrate impressive abilities on numerous image understanding and reasoning tasks. The task of fine-grained object classification (e.g., distinction between animal species), however, has been probed insufficiently, despite its downstream importance. We... | Gregor Geigle, Radu Timofte, Goran Glavas |  |
| 278 |  |  [Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.155) |  | 0 | Large Language Models (LLMs) have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when LLMs generate hallucinated text when confronted with false premise... | Hongbang Yuan, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao |  |
| 279 |  |  [To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.156) |  | 0 | Polysemy and synonymy are two crucial interrelated facets of lexicalambiguity. While both phenomena are widely documented in lexical resources and have been studied extensively in NLP,leading to dedicated systems, they are often being consideredindependently in practictal problems. While many tasks... | Bastien Liétard, Pascal Denis, Mikaela Keller |  |
| 280 |  |  [ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings](https://doi.org/10.18653/v1/2024.emnlp-main.157) |  | 0 | The safety defense methods of Large language models (LLMs) stays limited because the dangerous prompts are manually curated to just few known attack types, which fails to keep pace with emerging varieties. Recent studies found that attaching suffixes to harmful instructions can hack the defense of... | Hao Wang, Hao Li, Minlie Huang, Lei Sha |  |
| 281 |  |  [An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making](https://doi.org/10.18653/v1/2024.emnlp-main.158) |  | 0 | Modern large language models (LLMs) have exhibited cooperative synergy on complex task-solving, and collective decision-making (CDM) is a pivotal component in LLM-based multi-agent collaboration frameworks. Our survey on 52 recent such systems uncovers a severe lack of diversity, with a heavy... | Xiutian Zhao, Ke Wang, Wei Peng |  |
| 282 |  |  [Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?](https://doi.org/10.18653/v1/2024.emnlp-main.159) |  | 0 | Large vision-language models (LVLMs) have recently dramatically pushed the state of the art in image captioning and many image understanding tasks (e.g., visual question answering). LVLMs, however, often hallucinate and produce captions that mention concepts that cannot be found in the image. These... | Gregor Geigle, Radu Timofte, Goran Glavas |  |
| 283 |  |  [Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.160) |  | 0 | Recent studies have explored the working mechanisms of In-Context Learning (ICL). However, they mainly focus on classification and simple generation tasks, limiting their broader application to more complex generation tasks in practice. To address this gap, we investigate the impact of... | Zhenyu Liu, Dongfang Li, Xinshuo Hu, Xinping Zhao, Yibin Chen, Baotian Hu, Min Zhang |  |
| 284 |  |  [MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning](https://doi.org/10.18653/v1/2024.emnlp-main.161) |  | 0 | The growing demand for larger-scale models in the development of Large Language Models (LLMs) poses challenges for efficient training within limited computational resources. Traditional fine-tuning methods often exhibit instability in multi-task learning and rely heavily on extensive training... | Yufei Ma, Zihan Liang, Huangyu Dai, Ben Chen, Dehong Gao, Zhuoran Ran, Zihan Wang, Linbo Jin, Wen Jiang, Guannan Zhang, Xiaoyan Cai, Libin Yang |  |
| 285 |  |  [Message Passing on Semantic-Anchor-Graphs for Fine-grained Emotion Representation Learning and Classification](https://doi.org/10.18653/v1/2024.emnlp-main.162) |  | 0 | Emotion classification has wide applications in education, robotics, virtual reality, etc. However, identifying subtle differences between fine-grained emotion categories remains challenging. Current methods typically aggregate numerous token embeddings of a sentence into a single vector, which,... | Pinyi Zhang, Jingyang Chen, Junchen Shen, Zijie Zhai, Ping Li, Jie Zhang, Kai Zhang |  |
| 286 |  |  [PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study](https://doi.org/10.18653/v1/2024.emnlp-main.163) |  | 0 | Philology, the study of ancient manuscripts, demands years of professional training in ex-tensive knowledge memorization and manual textual retrieval. Despite these requirements align closely with strengths of recent successful Large Language Models (LLMs), the scarcity of high-quality, specialized... | Yuqing Zhang, Baoyi He, Yihan Chen, Hangqi Li, Han Yue, Shengyu Zhang, Huaiyong Dou, Junchi Yan, Zemin Liu, Yongquan Zhang, Fei Wu |  |
| 287 |  |  [Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions](https://doi.org/10.18653/v1/2024.emnlp-main.164) |  | 0 | Large language models are susceptible to jailbreak attacks, which can result in the generation of harmful content. While prior defenses mitigate these risks by perturbing or inspecting inputs, they ignore competing objectives, the underlying cause of alignment failures. In this paper, we propose... | Quan Liu, Zhenhong Zhou, Longzhu He, Yi Liu, Wei Zhang, Sen Su |  |
| 288 |  |  [MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.165) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) aims to co-extract the sentiment triplets in a given corpus. Existing approaches within the pretraining-finetuning paradigm tend to either meticulously craft complex tagging schemes and classification heads, or incorporate external semantic augmentation to... | Qiao Sun, Liujia Yang, Minghao Ma, Nanyang Ye, Qinying Gu |  |
| 289 |  |  [Evaluating Large Language Models via Linguistic Profiling](https://doi.org/10.18653/v1/2024.emnlp-main.166) |  | 0 | Large Language Models (LLMs) undergo extensive evaluation against various benchmarks collected in established leaderboards to assess their performance across multiple tasks. However, to the best of our knowledge, there is a lack of comprehensive studies evaluating these models’ linguistic abilities... | Alessio Miaschi, Felice Dell'Orletta, Giulia Venturi |  |
| 290 |  |  [With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.167) |  | 0 | Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have demonstrated aptitude as potential substitutes for human participants in experiments testing psycholinguistic phenomena. However, an understudied question is to what extent models that only have access to vision and text... | Tyler Loakman, Yucheng Li, Chenghua Lin |  |
| 291 |  |  [KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases](https://doi.org/10.18653/v1/2024.emnlp-main.168) |  | 0 | Program induction (PI) has become a promising paradigm for using knowledge bases (KBs) to help large language models (LLMs) answer complex knowledge-intensive questions. Nonetheless, PI typically relies on a large number of parallel question-program pairs to make the LLM aware of the schema of a... | Jiajie Zhang, Shulin Cao, Linmei Hu, Ling Feng, Lei Hou, Juanzi Li |  |
| 292 |  |  [Understanding Higher-Order Correlations Among Semantic Components in Embeddings](https://doi.org/10.18653/v1/2024.emnlp-main.169) |  | 0 | Independent Component Analysis (ICA) offers interpretable semantic components of embeddings.While ICA theory assumes that embeddings can be linearly decomposed into independent components, real-world data often do not satisfy this assumption. Consequently, non-independencies remain between the... | Momose Oyama, Hiroaki Yamagiwa, Hidetoshi Shimodaira |  |
| 293 |  |  [DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection](https://doi.org/10.18653/v1/2024.emnlp-main.170) |  | 0 |  | Zhihong Zhu, Kefan Shen, Zhaorun Chen, Yunyan Zhang, Yuyan Chen, Xiaoqi Jiao, Zhongwei Wan, Shaorong Xie, Wei Liu, Xian Wu, Yefeng Zheng |  |
| 294 |  |  [Evaluating D-MERIT of Partial-annotation on Information Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.171) |  | 0 |  | Royi Rassin, Yaron Fairstein, Oren Kalinsky, Guy Kushilevitz, Nachshon Cohen, Alexander Libov, Yoav Goldberg |  |
| 295 |  |  [Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving](https://doi.org/10.18653/v1/2024.emnlp-main.172) |  | 0 | Natural language explanations represent a proxy for evaluating explanation-based and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is... | Xin Quan, Marco Valentino, Louise A. Dennis, André Freitas |  |
| 296 |  |  [Calibrating the Confidence of Large Language Models by Eliciting Fidelity](https://doi.org/10.18653/v1/2024.emnlp-main.173) |  | 0 | Large language models optimized with techniques like RLHF have achieved good alignment in being helpful and harmless. However, post-alignment, these language models often exhibit overconfidence, where the expressed confidence does not accurately calibrate with their correctness rate. In this paper,... | Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian Zhou, Xipeng Qiu |  |
| 297 |  |  [The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.174) |  | 0 | Reinforcement Learning from Human Feedback significantly enhances Natural Language Processing by aligning language models with human expectations. A critical factor in this alignment is the strength of reward models used during training. This study explores whether stronger reward models invariably... | Yanjun Chen, Dawei Zhu, Yirong Sun, Xinghao Chen, Wei Zhang, Xiaoyu Shen |  |
| 298 |  |  [How Hard is this Test Set? NLI Characterization by Exploiting Training Dynamics](https://doi.org/10.18653/v1/2024.emnlp-main.175) |  | 0 | Natural Language Inference (NLI) evaluation is crucial for assessing language understanding models; however, popular datasets suffer from systematic spurious correlations that artificially inflate actual model performance. To address this, we propose a method for the automated creation of a... | Adrian Cosma, Stefan Ruseti, Mihai Dascalu, Cornelia Caragea |  |
| 299 |  |  [Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection](https://doi.org/10.18653/v1/2024.emnlp-main.176) |  | 0 | Grammatical Error Detection (GED) methods rely heavily on human annotated error corpora. However, these annotations are unavailable in many low-resource languages. In this paper, we investigate GED in this context. Leveraging the zero-shot cross-lingual transfer capabilities of multilingual... | Gaetan Latouche, MarcAndré Carbonneau, Benjamin Swanson |  |
| 300 |  |  [CUTE: Measuring LLMs' Understanding of Their Tokens](https://doi.org/10.18653/v1/2024.emnlp-main.177) |  | 0 | Large Language Models (LLMs) show remarkable performance on a wide variety of tasks. Most LLMs split text into multi-character tokens and process them as atomic units without direct access to individual characters. This raises the question: To what extent can LLMs learn orthographic information? To... | Lukas Edman, Helmut Schmid, Alexander Fraser |  |
| 301 |  |  [SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.178) |  | 0 | Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved passages to reduce computational costs and enhance the final RAG performance, yet it remains challenging. Existing methods heavily rely on heuristic-based augmentation, encountering several... | Xinping Zhao, Dongfang Li, Yan Zhong, Boren Hu, Yibin Chen, Baotian Hu, Min Zhang |  |
| 302 |  |  [On the Role of Context in Reading Time Prediction](https://doi.org/10.18653/v1/2024.emnlp-main.179) |  | 0 | We present a new perspective on how readers integrate context during real-time language comprehension. Our proposals build on surprisal theory, which posits that the processing effort of a linguistic unit (e.g., a word) is an affine function of its in-context information content. We first observe... | Andreas Opedal, Eleanor Chodroff, Ryan Cotterell, Ethan Wilcox |  |
| 303 |  |  [BC-Prover: Backward Chaining Prover for Formal Theorem Proving](https://doi.org/10.18653/v1/2024.emnlp-main.180) |  | 0 | Despite the remarkable progress made by large language models in mathematical reasoning, interactive theorem proving in formal logic still remains a prominent challenge. Previous methods resort to neural models for proofstep generation and search. However, they suffer from exploring possible... | Yuhang He, Jihai Zhang, Jianzhu Bao, Fangquan Lin, Cheng Yang, Bing Qin, Ruifeng Xu, Wotao Yin |  |
| 304 |  |  [From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP](https://doi.org/10.18653/v1/2024.emnlp-main.181) |  | 0 | Interpretability and analysis (IA) research is a growing subfield within NLP with the goal of developing a deeper understanding of the behavior or inner workings of NLP systems and methods. Despite growing interest in the subfield, a criticism of this work is that it lacks actionable insights and... | Marius Mosbach, Vagrant Gautam, Tomás Vergara Browne, Dietrich Klakow, Mor Geva |  |
| 305 |  |  [Autoregressive Pre-Training on Pixels and Texts](https://doi.org/10.18653/v1/2024.emnlp-main.182) |  | 0 | The integration of visual and textual information represents a promising direction in the advancement of language models. In this paper, we explore the dual modality of language—both visual and textual—within an autoregressive framework, pre-trained on both document images and texts. Our method... | Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, Hua Wu |  |
| 306 |  |  [On Training Data Influence of GPT Models](https://doi.org/10.18653/v1/2024.emnlp-main.183) |  | 0 | Amidst the rapid advancements in generative language models, the investigation of how training data shapes the performance of GPT models is still emerging. This paper presents GPTfluence, a novel approach that leverages a featurized simulation to assess the impact of training examples on the... | Yekun Chai, Qingyi Liu, Shuohuan Wang, Yu Sun, Qiwei Peng, Hua Wu |  |
| 307 |  |  [Understanding "Democratization" in NLP and ML Research](https://doi.org/10.18653/v1/2024.emnlp-main.184) |  | 0 | Recent improvements in natural language processing (NLP) and machine learning (ML) and increased mainstream adoption have led to researchers frequently discussing the “democratization” of artificial intelligence. In this paper, we seek to clarify how democratization is understood in NLP and ML... | Arjun Subramonian, Vagrant Gautam, Dietrich Klakow, Zeerak Talat |  |
| 308 |  |  [DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models](https://doi.org/10.18653/v1/2024.emnlp-main.185) |  | 0 | Visual document understanding (VDU) is a challenging task that involves understanding documents across various modalities (text and image) and layouts (forms, tables, etc.). This study aims to enhance generalizability of small VDU models by distilling knowledge from LLMs. We identify that directly... | Sungnyun Kim, Haofu Liao, Srikar Appalaraju, Peng Tang, Zhuowen Tu, Ravi Kumar Satzoda, R. Manmatha, Vijay Mahadevan, Stefano Soatto |  |
| 309 |  |  [Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages](https://doi.org/10.18653/v1/2024.emnlp-main.186) |  | 0 | Automatic question generation (QG) serves a wide range of purposes, such as augmenting question-answering (QA) corpora, enhancing chatbot systems, and developing educational materials. Despite its importance, most existing datasets predominantly focus on English, resulting in a considerable gap in... | Seonjeong Hwang, Yunsu Kim, Gary Geunbae Lee |  |
| 310 |  |  [ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws](https://doi.org/10.18653/v1/2024.emnlp-main.187) |  | 0 | High-quality data is crucial for the pre-training performance of large language models. Unfortunately, existing quality filtering methods rely on a known high-quality dataset as reference, which can introduce potential bias and compromise diversity. In this paper, we propose ScalingFilter, a novel... | Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng |  |
| 311 |  |  [Word Alignment as Preference for Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.188) |  | 0 | The problem of hallucination and omission, a long-standing problem in machine translation (MT), is more pronounced when a large language model (LLM) is used in MT because an LLM itself is susceptible to these phenomena. In this work, we mitigate the problem in an LLM-based MT model by guiding it to... | Qiyu Wu, Masaaki Nagata, Zhongtao Miao, Yoshimasa Tsuruoka |  |
| 312 |  |  [Improving Multi-party Dialogue Generation via Topic and Rhetorical Coherence](https://doi.org/10.18653/v1/2024.emnlp-main.189) |  | 0 | Previous studies on multi-party dialogue generation predominantly concentrated on modeling the reply-to structure of dialogue histories, always overlooking the coherence between generated responses and target utterances. To address this issue, we propose a Reinforcement Learning approach... | Yaxin Fan, Peifeng Li, Qiaoming Zhu |  |
| 313 |  |  [SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.190) |  | 0 | Continual learning (CL) is crucial for language models to dynamically adapt to the evolving real-world demands. To mitigate the catastrophic forgetting problem in CL, data replay has been proven a simple and effective strategy, and the subsequent data-replay-based distillation can further enhance... | Jinghan He, Haiyun Guo, Kuan Zhu, Zihan Zhao, Ming Tang, Jinqiao Wang |  |
| 314 |  |  [Neuron-Level Knowledge Attribution in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.191) |  | 0 | Identifying important neurons for final predictions is essential for understanding the mechanisms of large language models. Due to computational constraints, current attribution techniques struggle to operate at neuron level. In this paper, we propose a static method for pinpointing significant... | Zeping Yu, Sophia Ananiadou |  |
| 315 |  |  [How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning](https://doi.org/10.18653/v1/2024.emnlp-main.192) |  | 0 | We investigate the mechanism of in-context learning (ICL) on sentence classification tasks with semantically-unrelated labels (“foo”/“bar”). We find intervening in only 1% heads (named “in-context heads”) significantly affects ICL accuracy from 87.6% to 24.4%. To understand this phenomenon, we... | Zeping Yu, Sophia Ananiadou |  |
| 316 |  |  [Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.193) |  | 0 | We find arithmetic ability resides within a limited number of attention heads, with each head specializing in distinct operations. To delve into the reason, we introduce the Comparative Neuron Analysis (CNA) method, which identifies an internal logic chain consisting of four distinct stages from... | Zeping Yu, Sophia Ananiadou |  |
| 317 |  |  [Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.194) |  | 0 | Pixel-based language models have emerged as a compelling alternative to subword-based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has been pre-trained on rendered text. While PIXEL has... | Kushal Tatariya, Vladimir Araujo, Thomas Bauwens, Miryam de Lhoneux |  |
| 318 |  |  [GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory](https://doi.org/10.18653/v1/2024.emnlp-main.195) |  | 0 | Privacy issues arise prominently during the inappropriate transmission of information between entities. Existing research primarily studies privacy by exploring various privacy attacks, defenses, and evaluations within narrowly predefined patterns, while neglecting that privacy is not an isolated,... | Wei Fan, Haoran Li, Zheye Deng, Weiqi Wang, Yangqiu Song |  |
| 319 |  |  [Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature](https://doi.org/10.18653/v1/2024.emnlp-main.196) |  | 0 | We present a framework for detecting and categorizing noise in literary texts, demonstrated through its application to Danish and Norwegian literature from the late 19-th century. Noise, understood as “aberrant sonic behaviour,” is not only an auditory phenomenon but also a cultural construct tied... | Ali AlLaith, Daniel Hershcovich, Jens BjerringHansen, Jakob Parby, Alexander Conroy, Timothy Tangherlini |  |
| 320 |  |  [QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.197) |  | 0 | Large Language Models (LLMs) from the GPT family have become extremely popular, leading to a race towards reducing their inference costs to allow for efficient local computation. However, the vast majority of existing work focuses on weight-only quantization, which can reduce runtime costs in the... | Saleh Ashkboos, Ilia Markov, Elias Frantar, Tingxuan Zhong, Xincheng Wang, Jie Ren, Torsten Hoefler, Dan Alistarh |  |
| 321 |  |  [Fine-Grained Prediction of Reading Comprehension from Eye Movements](https://doi.org/10.18653/v1/2024.emnlp-main.198) |  | 0 | Can human reading comprehension be assessed from eye movements in reading? In this work, we address this longstanding question using large-scale eyetracking data. We focus on a cardinal and largely unaddressed variant of this question: predicting reading comprehension of a single participant for a... | Omer Shubi, Yoav Meiri, Cfir Avraham Hadar, Yevgeni Berzak |  |
| 322 |  |  [EfficientRAG: Efficient Retriever for Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.199) |  | 0 | Retrieval-augmented generation (RAG) methods encounter difficulties when addressing complex questions like multi-hop queries.While iterative retrieval methods improve performance by gathering additional information, current approaches often rely on multiple calls of large language models (LLMs).In... | Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu, Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang |  |
| 323 |  |  [Unsupervised Human Preference Learning](https://doi.org/10.18653/v1/2024.emnlp-main.200) |  | 0 | Large language models demonstrate impressive reasoning abilities but struggle to provide personalized content due to their lack of individual user preference information. Existing methods, such as in-context learning and parameter-efficient fine-tuning, fall short in capturing the complexity of... | Sumuk Shashidhar, Abhinav Chinta, Vaibhav Sahai, Dilek HakanniTür |  |
| 324 |  |  [Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering](https://doi.org/10.18653/v1/2024.emnlp-main.201) |  | 0 | The potential effectiveness of counterspeech as a hate speech mitigation strategy is attracting increasing interest in the NLG research community, particularly towards the task of automatically producing it. However, automatically generated responses often lack the argumentative richness which... | Helena Bonaldi, Greta Damo, Nicolás Benjamín Ocampo, Elena Cabrio, Serena Villata, Marco Guerini |  |
| 325 |  |  [Leading Whitespaces of Language Models' Subword Vocabulary Pose a Confound for Calculating Word Probabilities](https://doi.org/10.18653/v1/2024.emnlp-main.202) |  | 0 |  | ByungDoh Oh, William Schuler |  |
| 326 |  |  [LLM4Decompile: Decompiling Binary Code with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.203) |  | 0 | Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute. Motivated by the advancements in Large Language Models (LLMs), we propose LLM4Decompile, the first and largest open-source LLM series... | Hanzhuo Tan, Qi Luo, Jing Li, Yuqun Zhang |  |
| 327 |  |  [From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.204) |  | 0 | With the proliferation of large language models, Parameter Efficient Fine-Tuning (PEFT) method, which freeze pre-trained parameters and only fine-tune a few task-specific parameters, are playing an increasingly important role. However, previous work primarily applied uniform operations across all... | Jihao Gu, Zelin Wang, Yibo Zhang, Ziji Zhang, Ping Gong |  |
| 328 |  |  [CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.205) |  | 0 | Recent studies have explored the use of Large Language Models (LLMs) with Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering (KGQA). They typically require rewriting retrieved subgraphs into natural language formats comprehensible to LLMs. However, when tackling complex... | Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan |  |
| 329 |  |  [MTLS: Making Texts into Linguistic Symbols](https://doi.org/10.18653/v1/2024.emnlp-main.206) |  | 0 | In linguistics, all languages can be considered as symbolic systems, with each language relying on symbolic processes to associate specific symbols with meanings. In the same language, there is a fixed correspondence between linguistic symbol and meaning. In different languages, universal meanings... | Wenlong Fei, Xiaohua Wang, Min Hu, Qingyu Zhang, Hongbo Li |  |
| 330 |  |  [D2R: Dual-Branch Dynamic Routing Network for Multimodal Sentiment Detection](https://doi.org/10.18653/v1/2024.emnlp-main.207) |  | 0 |  | Yifan Chen, Kuntao Li, Weixing Mai, Qiaofeng Wu, Yun Xue, Fenghuan Li |  |
| 331 |  |  [A Generic Method for Fine-grained Category Discovery in Natural Language Texts](https://doi.org/10.18653/v1/2024.emnlp-main.208) |  | 0 | Fine-grained category discovery using only coarse-grained supervision is a cost-effective yet challenging task. Previous training methods focus on aligning query samples with positive samples and distancing them from negatives. They often neglect intra-category and inter-category semantic... | Chang Tian, Matthew B. Blaschko, Wenpeng Yin, Mingzhe Xing, Yinliang Yue, MarieFrancine Moens |  |
| 332 |  |  [Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method](https://doi.org/10.18653/v1/2024.emnlp-main.209) |  | 0 | Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed... | Yang Trista Cao, LovelyFrances Domingo, Sarah A. Gilbert, Michelle L. Mazurek, Katie Shilton, Hal Daumé III |  |
| 333 |  |  [A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.210) |  | 0 | Large language models (LLMs) are essential tools that users employ across various scenarios, so evaluating their performance and guiding users in selecting the suitable service is important. Although many benchmarks exist, they mainly focus on specific predefined model abilities, such as world... | Jiayin Wang, Fengran Mo, Weizhi Ma, Peijie Sun, Min Zhang, JianYun Nie |  |
| 334 |  |  [Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison](https://doi.org/10.18653/v1/2024.emnlp-main.211) |  | 0 | Despite tremendous advancements, current state-of-the-art Vision-Language Models (VLMs) are still far from perfect. They tend to hallucinate and may generate biased responses. In such circumstances, having a way to assess the reliability of a given response generated by a VLM is quite useful.... | Qian Yang, Weixiang Yan, Aishwarya Agrawal |  |
| 335 |  |  [Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism](https://doi.org/10.18653/v1/2024.emnlp-main.212) |  | 0 | Large language models (LLMs) have demonstrated impressive language understanding and generation capabilities, enabling them to answer a wide range of questions across various domains. However, these models are not flawless and often produce responses that contain errors or misinformation. These... | Lang Cao |  |
| 336 |  |  [VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation](https://doi.org/10.18653/v1/2024.emnlp-main.213) |  | 0 | In the realm of vision models, the primary mode of representation is using pixels to rasterize the visual world. Yet this is not always the best or unique way to represent visual content, especially for designers and artists who depict the world using geometry primitives such as polygons. Vector... | Bocheng Zou, Mu Cai, Jianrui Zhang, Yong Jae Lee |  |
| 337 |  |  [What do Large Language Models Need for Machine Translation Evaluation?](https://doi.org/10.18653/v1/2024.emnlp-main.214) |  | 0 | Leveraging large language models (LLMs) for various natural language processing tasks has led to superlative claims about their performance. For the evaluation of machine translation (MT), existing research shows that LLMs are able to achieve results comparable to fine-tuned multilingual... | Shenbin Qian, Archchana Sindhujan, Minnie Kabra, Diptesh Kanojia, Constantin Orasan, Tharindu Ranasinghe, Frédéric Blain |  |
| 338 |  |  [Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale](https://doi.org/10.18653/v1/2024.emnlp-main.215) |  | 0 | Large Language Models (LLMs) face significant challenges at inference time due to their high computational demands. To address this, we present Performance-Guided Knowledge Distillation (PGKD), a cost-effective and high-throughput solution for production text classification applications. PGKD... | Flavio Palo, Prateek Singhi, Bilal Fadlallah |  |
| 339 |  |  [External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models](https://doi.org/10.18653/v1/2024.emnlp-main.216) |  | 0 | Argument mining (AM) involves the identification of argument relations (AR) between Argumentative Discourse Units (ADUs). The essence of ARs among ADUs is context-dependent and lies in maintaining a coherent flow of ideas, often centered around the relations between discussed entities, topics,... | Debela Gemechu, Chris Reed |  |
| 340 |  |  [C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits](https://doi.org/10.18653/v1/2024.emnlp-main.217) |  | 0 | The development of tools and techniques to analyze and extract organizations’ data habits from privacy policies are critical for scalable regulatory compliance audits. Unfortunately, these tools are becoming increasingly limited in their ability to identify compliance issues and fixes. After all,... | Maaz Bin Musa, Steven M. Winston, Garrison Allen, Jacob Schiller, Kevin Moore, Sean Quick, Johnathan Melvin, Padmini Srinivasan, Mihailis Diamantis, Rishab Nithyanand |  |
| 341 |  |  [M²PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning](https://doi.org/10.18653/v1/2024.emnlp-main.218) |  | 0 | Multimodal Large Language Models (MLLMs) demonstrate remarkable performance across a wide range of domains, with increasing emphasis on enhancing their zero-shot generalization capabilities for unseen tasks across various modalities. Instruction tuning has emerged as an effective strategy for... | Taowen Wang, Yiyang Liu, James Liang, Junhan Zhao, Yiming Cui, Yuning Mao, Shaoliang Nie, Jiahao Liu, Fuli Feng, Zenglin Xu, Cheng Han, Lifu Huang, Qifan Wang, Dongfang Liu |  |
| 342 |  |  [Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification](https://doi.org/10.18653/v1/2024.emnlp-main.219) |  | 0 | For extremely weak-supervised text classification, pioneer research generates pseudo labels by mining texts similar to the class names from the raw corpus, which may end up with very limited or even no samples for the minority classes. Recent works have started to generate the relevant texts by... | Letian Peng, Yi Gu, Chengyu Dong, Zihan Wang, Jingbo Shang |  |
| 343 |  |  [Incubating Text Classifiers Following User Instruction with Nothing but LLM](https://doi.org/10.18653/v1/2024.emnlp-main.220) |  | 0 | In this paper, we aim to generate text classification data given arbitrary class definitions (i.e., user instruction), so one can train a text classifier without any human annotation or raw corpus. Recent advances in large language models (LLMs) lead to pioneer attempts to individually generate... | Letian Peng, Zilong Wang, Jingbo Shang |  |
| 344 |  |  [PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL](https://doi.org/10.18653/v1/2024.emnlp-main.221) |  | 0 | Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL tasks, exhibiting remarkable reasoning capabilities. Different from tasks such as math word problem and commonsense reasoning, SQL solutions have a relatively fixed pattern. This facilitates the investigation of whether... | Ruilin Luo, Liyuan Wang, Binghuai Lin, Zicheng Lin, Yujiu Yang |  |
| 345 |  |  [Conditional and Modal Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.222) |  | 0 | The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in AI and cognitive science. In this paper, we probe the extent to which twenty-nine LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference... | Wesley H. Holliday, Matthew Mandelkern, Cedegao Zhang |  |
| 346 |  |  [Advancing Large Language Model Attribution through Self-Improving](https://doi.org/10.18653/v1/2024.emnlp-main.223) |  | 0 | Teaching large language models (LLMs) to generate text with citations to evidence sources can mitigate hallucinations and enhance verifiability in information-seeking systems. However, improving this capability requires high-quality attribution data, which is costly and labor-intensive. Inspired by... | Lei Huang, Xiaocheng Feng, Weitao Ma, Liang Zhao, Yuchun Fan, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin |  |
| 347 |  |  [AlignCap: Aligning Speech Emotion Captioning to Human Preferences](https://doi.org/10.18653/v1/2024.emnlp-main.224) |  | 0 | Speech Emotion Captioning (SEC) has gradually become an active research task. The emotional content conveyed through human speech are often complex, and classifying them into fixed categories may not be enough to fully capture speech emotions. Describing speech emotions through natural language may... | Ziqi Liang, Haoxiang Shi, Hanhui Chen |  |
| 348 |  |  [Interpretability-based Tailored Knowledge Editing in Transformers](https://doi.org/10.18653/v1/2024.emnlp-main.225) |  | 0 | Language models recognized as a new form of knowledge bases, face challenges of outdated, erroneous, and privacy-sensitive information, necessitating knowledge editing to rectify errors without costly retraining. Existing methods, spanning model’s parameters modification, external knowledge... | Yihuai Hong, Aldo Lipani |  |
| 349 |  |  [PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling](https://doi.org/10.18653/v1/2024.emnlp-main.226) |  | 0 | Prompt optimization aims to find the best prompt to a large language model (LLM) for a given task. LLMs have been successfully used to help find and improve prompt candidates for single-step tasks. However, realistic tasks for agents are multi-step and introduce new challenges: (1) Prompt content... | Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, Chuchu Fan |  |
| 350 |  |  [Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.227) |  | 0 | In recent years, the rapid increase in online video content has underscored the limitations of static Video Question Answering (VideoQA) models trained on fixed datasets, as they struggle to adapt to new questions or tasks posed by newly available content. In this paper, we explore the novel... | Chen Cai, Zheng Wang, Jianjun Gao, Wenyang Liu, Ye Lu, Runzhong Zhang, KimHui Yap |  |
| 351 |  |  [Dissecting Fine-Tuning Unlearning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.228) |  | 0 | Fine-tuning-based unlearning methods prevail for erasing targeted harmful, sensitive, or copyrighted information within large language models while preserving overall capabilities. However, the true effectiveness of the methods is unclear. In this paper, we delve into the limitations of... | Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang |  |
| 352 |  |  [Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.229) |  | 0 | Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (i.e., follow open-ended instructions) and faithfulness (i.e., ground responses in given... | Zhengxuan Wu, Yuhao Zhang, Peng Qi, Yumo Xu, Rujun Han, Yian Zhang, Jifan Chen, Bonan Min, Zhiheng Huang |  |
| 353 |  |  [Where is the signal in tokenization space?](https://doi.org/10.18653/v1/2024.emnlp-main.230) |  | 0 | Large Language Models (LLMs) are typically shipped with tokenizers that \*deterministically\* encode text into so-called \*canonical\* token sequences, to which the LLMs assign probability values.One common assumption is that the probability of a piece of text is the probability of its canonical... | Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck |  |
| 354 |  |  [Private Language Models via Truncated Laplacian Mechanism](https://doi.org/10.18653/v1/2024.emnlp-main.231) |  | 0 | Recently it has been shown that deep learning models for NLP tasks are prone to attacks that can even reconstruct the verbatim training texts. To prevent privacy leakage, researchers have investigated word-level perturbations, relying on the formal guarantees of differential privacy (DP) in the... | Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang |  |
| 355 |  |  [Estimating Knowledge in Large Language Models Without Generating a Single Token](https://doi.org/10.18653/v1/2024.emnlp-main.232) |  | 0 |  | Daniela Gottesman, Mor Geva |  |
| 356 |  |  [Consistent Autoformalization for Constructing Mathematical Libraries](https://doi.org/10.18653/v1/2024.emnlp-main.233) |  | 0 | Autoformalization is the task of automatically translating mathematical content written in natural language to a formal language expression. The growing language interpretation capabilities of Large Language Models (LLMs), including in formal languages, are lowering the barriers for... | Lan Zhang, Xin Quan, André Freitas |  |
| 357 |  |  [When Context Leads but Parametric Memory Follows in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.234) |  | 0 | Large language models (LLMs) have demonstrated remarkable progress in leveraging diverse knowledge sources. This study investigates how nine widely used LLMs allocate knowledge between local context and global parameters when answering open-ended questions in knowledge-consistent scenarios. We... | Yufei Tao, Adam Hiatt, Erik Haake, Antonie J. Jetter, Ameeta Agrawal |  |
| 358 |  |  [Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers](https://doi.org/10.18653/v1/2024.emnlp-main.235) |  | 0 | Neural networks without hierarchical biases often struggle to learn linguistic rules that come naturally to humans. However, neural networks are trained primarily on form alone, while children acquiring language additionally receive data about meaning. Would neural networks generalize more like... | Aditya Yedetore, Najoung Kim |  |
| 359 |  |  [When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages](https://doi.org/10.18653/v1/2024.emnlp-main.236) |  | 0 | Multilingual language models are widely used to extend NLP systems to low-resource languages. However, concrete evidence for the effects of multilinguality on language modeling performance in individual languages remains scarce. Here, we pre-train over 10,000 monolingual and multilingual language... | Tyler A. Chang, Catherine Arnett, Zhuowen Tu, Ben Bergen |  |
| 360 |  |  [Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use](https://doi.org/10.18653/v1/2024.emnlp-main.237) |  | 0 | In real-world scenarios, it is desirable for embodied agents to have the ability to leverage human language to gain explicit or implicit knowledge for learning tasks. Despite recent progress, most previous approaches adopt simple low-level instructions as language inputs, which may not reflect... | Jiajun Xi, Yinong He, Jianing Yang, Yinpei Dai, Joyce Chai |  |
| 361 |  |  [MiTTenS: A Dataset for Evaluating Gender Mistranslation](https://doi.org/10.18653/v1/2024.emnlp-main.238) |  | 0 | Translation systems, including foundation models capable of translation, can produce errors that result in gender mistranslation, and such errors can be especially harmful. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS,... | Kevin Robinson, Sneha Kudugunta, Romina Stella, Sunipa Dev, Jasmijn Bastings |  |
| 362 |  |  [Teaching LLMs to Abstain across Languages via Multilingual Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.239) |  | 0 | Multilingual LLMs often have knowledge disparities across languages, with larger gaps in under-resourced languages. Teaching LLMs to abstain in the face of knowledge gaps is thus a promising strategy to mitigate hallucinations in multilingual settings. However, previous studies on LLM abstention... | Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Orevaoghene Ahia, Shuyue Stella Li, Vidhisha Balachandran, Sunayana Sitaram, Yulia Tsvetkov |  |
| 363 |  |  [Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration](https://doi.org/10.18653/v1/2024.emnlp-main.240) |  | 0 | While existing alignment paradigms have been integral in developing large language models (LLMs), LLMs often learn an averaged human preference and struggle to model diverse preferences across cultures, demographics, and communities. We propose Modular Pluralism, a modular framework based on... | Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, Yulia Tsvetkov |  |
| 364 |  |  [StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements](https://doi.org/10.18653/v1/2024.emnlp-main.241) |  | 0 | Authorship obfuscation, rewriting a text to intentionally obscure the identity of the author, is important yet challenging. Current methods using large language models (LLMs) lack interpretability and controllability, often ignoring author-specific stylistic features, resulting in less robust... | Jillian Fisher, Skyler Hallinan, Ximing Lu, Mitchell L. Gordon, Zaïd Harchaoui, Yejin Choi |  |
| 365 |  |  [I Could've Asked That: Reformulating Unanswerable Questions](https://doi.org/10.18653/v1/2024.emnlp-main.242) |  | 0 | When seeking information from unfamiliar documents, users frequently pose questions that cannot be answered by the documents. While existing large language models (LLMs) identify these unanswerable questions, they do not assist users in reformulating their questions, thereby reducing their overall... | Wenting Zhao, Ge Gao, Claire Cardie, Alexander M. Rush |  |
| 366 |  |  [STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions](https://doi.org/10.18653/v1/2024.emnlp-main.243) |  | 0 | Mitigating explicit and implicit biases in Large Language Models (LLMs) has become a critical focus in the field of natural language processing. However, many current methodologies evaluate scenarios in isolation, without considering the broader context or the spectrum of potential biases within... | Robert Morabito, Sangmitra Madhusudan, Tyler McDonald, Ali Emami |  |
| 367 |  |  [Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters](https://doi.org/10.18653/v1/2024.emnlp-main.244) |  | 0 | Do LLMs have political leanings and are LLMs able to shift our political views? This paper explores these questions in the context of the 2024 U.S. presidential election. Through a voting simulation, we demonstrate 18 open-weight and closed-source LLMs’ political preference for Biden over Trump. We... | Yujin Potter, Shiyang Lai, Junsol Kim, James Evans, Dawn Song |  |
| 368 |  |  [SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning](https://doi.org/10.18653/v1/2024.emnlp-main.245) |  | 0 | Large Language Models (LLMs) have highlighted the necessity of effective unlearning mechanisms to comply with data regulations and ethical AI practices. LLM unlearning aims at removing undesired data influences and associated model capabilities without compromising utility beyond the scope of... | Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu |  |
| 369 |  |  [When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives](https://doi.org/10.18653/v1/2024.emnlp-main.246) |  | 0 | Reasoning is most powerful when an LLM accurately aggregates relevant information. We examine the critical role of information aggregation in reasoning by requiring the LLM to analyze sports narratives. To succeed at this task, an LLM must infer points from actions, identify related entities,... | Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Wenlin Yao, Hassan Foroosh, Dong Yu, Fei Liu |  |
| 370 |  |  [An Analysis of Multilingual FActScore](https://doi.org/10.18653/v1/2024.emnlp-main.247) |  | 0 | FActScore has gained popularity as a metric to estimate the factuality of long-form texts generated by Large Language Models (LLMs) in English. However, there has not been any work in studying the behavior of FActScore in other languages. This paper studies the limitations of each component in the... | Vu Trong Kim, Michael Krumdick, Varshini Reddy, Franck Dernoncourt, Viet Dac Lai |  |
| 371 |  |  [Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.248) |  | 0 | Proprietary LMs such as GPT-4 are often employed to assess the quality of responses from various LMs. However, concerns including transparency, controllability, and affordability strongly motivate the development of open-source LMs specialized in evaluations. On the other hand, existing open... | Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, Minjoon Seo |  |
| 372 |  |  [RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.249) |  | 0 | Question answering based on retrieval augmented generation (RAG-QA) is an important research topic in NLP and has a wide range of real-world applications. However, most existing datasets for this task are either constructed using a single source corpus or consist of short extractive answers, which... | Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William Yang Wang, Bonan Min, Vittorio Castelli |  |
| 373 |  |  [PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.250) |  | 0 | Utilizing large language models (LLMs) for zero-shot document ranking is done in one of two ways: (1) prompt-based re-ranking methods, which require no further training but are only feasible for re-ranking a handful of candidate documents due to computational costs; and (2) unsupervised contrastive... | Shengyao Zhuang, Xueguang Ma, Bevan Koopman, Jimmy Lin, Guido Zuccon |  |
| 374 |  |  [Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects](https://doi.org/10.18653/v1/2024.emnlp-main.251) |  | 0 | Yoruba—an African language with roughly 47 million speakers—encompasses a continuum with several dialects. Recent efforts to develop NLP technologies for African languages have focused on their standard dialects, resulting in disparities for dialects and varieties for which there are little to no... | Orevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith, Yulia Tsvetkov |  |
| 375 |  |  [ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.252) |  | 0 | Large Multimodal Models (LMMs) excel at comprehending human instructions and demonstrate remarkable results across a broad spectrum of tasks. Reinforcement Learning from Human Feedback (RLHF) and AI Feedback (RLAIF) further refine LLMs by aligning them with specific preferences. These methods... | JuSeung Byun, Jiyun Chun, Jihyung Kil, Andrew Perrault |  |
| 376 |  |  [Order of Magnitude Speedups for LLM Membership Inference](https://doi.org/10.18653/v1/2024.emnlp-main.253) |  | 0 | Large Language Models (LLMs) have the promise to revolutionize computing broadly, but their complexity and extensive training data also expose significant privacy vulnerabilities. One of the simplest privacy risks associated with LLMs is their susceptibility to membership inference attacks (MIAs),... | Rongting Zhang, Martín Bertrán, Aaron Roth |  |
| 377 |  |  [VIMI: Grounding Video Generation through Multi-modal Instruction](https://doi.org/10.18653/v1/2024.emnlp-main.254) |  | 0 | Existing text-to-video diffusion models rely solely on text-only encoders for their pretraining. This limitation stems from the absence of large-scale multimodal prompt video datasets, resulting in a lack of visual grounding and restricting their versatility and application in multimodal... | Yuwei Fang, Willi Menapace, Aliaksandr Siarohin, TsaiShien Chen, KuanChieh Wang, Ivan Skorokhodov, Graham Neubig, Sergey Tulyakov |  |
| 378 |  |  [F²RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation](https://doi.org/10.18653/v1/2024.emnlp-main.255) |  | 0 | Hate speech (HS) on social media exacerbates misinformation and baseless prejudices. Evidence-supported counterspeech (CS) is crucial for correcting misinformation and reducing prejudices through facts. Existing methods for generating evidence-supported CS often lack clear guidance with a core... | Haiyang Wang, Yuchen Pan, Xin Song, Xuechen Zhao, Minghao Hu, Bin Zhou |  |
| 379 |  |  [Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning](https://doi.org/10.18653/v1/2024.emnlp-main.256) |  | 0 | Social networks are rife with noise and misleading information, presenting multifaceted challenges for rumor detection. In this paper, from the perspective of human cognitive subjectivity, we introduce the mining of individual latent intentions and propose a novel multi-task learning framework, the... | Chang Yang, Peng Zhang, Hui Gao, Jing Zhang |  |
| 380 |  |  [Visual Prompting in LLMs for Enhancing Emotion Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.257) |  | 0 | Vision Large Language Models (VLLMs) are transforming the intersection of computer vision and natural language processing; however, the potential of using visual prompts for emotion recognition in these models remains largely unexplored and untapped. Traditional methods in VLLMs struggle with... | Qixuan Zhang, Zhifeng Wang, Dylan Zhang, Wenjia Niu, Sabrina B. Caldwell, Tom Gedeon, Yang Liu, Zhenyue Qin |  |
| 381 |  |  [IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding](https://doi.org/10.18653/v1/2024.emnlp-main.258) |  | 0 | The audio watermarking technique embeds messages into audio and accurately extracts messages from the watermarked audio. Traditional methods develop algorithms based on expert experience to embed watermarks into the time-domain or transform-domain of signals. With the development of deep neural... | Pengcheng Li, Xulong Zhang, Jing Xiao, Jianzong Wang |  |
| 382 |  |  [Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset](https://doi.org/10.18653/v1/2024.emnlp-main.259) |  | 0 | In multi-person communications, conflicts often arise. Each individual may have their own perspective, which can differ. Additionally, commonly referenced offensive datasets frequently neglect contextual information and are primarily constructed with a focus on intended offenses. This study... | CheWei Tsai, YenHao Huang, TsuKeng Liao, Didier Estrada, Retnani Latifah, YiShin Chen |  |
| 383 |  |  [Outcome-Constrained Large Language Models for Countering Hate Speech](https://doi.org/10.18653/v1/2024.emnlp-main.260) |  | 0 | Automatic counterspeech generation methods have been developed to assist efforts in combating hate speech. Existing research focuses on generating counterspeech with linguistic attributes such as being polite, informative, and intent-driven. However, the real impact of counterspeech in online... | Lingzi Hong, Pengcheng Luo, Eduardo Blanco, Xiaoying Song |  |
| 384 |  |  [Multiple Sources are Better Than One: Incorporating External Knowledge in Low-Resource Glossing](https://doi.org/10.18653/v1/2024.emnlp-main.261) |  | 0 | In this paper, we address the data scarcity problem in automatic data-driven glossing for low-resource languages by coordinating multiple sources of linguistic expertise. We enhance models by incorporating both token-level and sentence-level translations, utilizing the extensive linguistic... | Changbing Yang, Garrett Nicolai, Miikka Silfverberg |  |
| 385 |  |  [Adaptive Immune-based Sound-Shape Code Substitution for Adversarial Chinese Text Attacks](https://doi.org/10.18653/v1/2024.emnlp-main.262) |  | 0 | Adversarial textual examples reveal the vulnerability of natural language processing (NLP) models. Most existing text attack methods are designed for English text, while the robust implementation of the second popular language, i.e., Chinese with 1 billion users, is greatly underestimated. Although... | Ao Wang, Xinghao Yang, Chen Li, Baodi Liu, Weifeng Liu |  |
| 386 |  |  [Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping](https://doi.org/10.18653/v1/2024.emnlp-main.263) |  | 0 | Reinforcement learning shows promise in optimizing dialogue policies, but addressing the challenge of reward sparsity remains crucial. While curriculum learning offers a practical solution by strategically training policies from simple to complex, it hinges on the assumption of a gradual increase... | Yangyang Zhao, Ben Niu, Mehdi Dastani, Shihan Wang |  |
| 387 |  |  [PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling](https://doi.org/10.18653/v1/2024.emnlp-main.264) |  | 0 | As awareness of mental health issues grows, online counseling support services are becoming increasingly prevalent worldwide. Detecting whether users express suicidal ideation in text-based counseling services is crucial for identifying and prioritizing at-risk individuals. However, the lack of... | Huachuan Qiu, Lizhi Ma, Zhenzhong Lan |  |
| 388 |  |  [World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering](https://doi.org/10.18653/v1/2024.emnlp-main.265) |  | 0 | Recent advances in Vision-Language Models (VLMs) and the scarcity of high-quality multi-modal alignment data have inspired numerous researches on synthetic VLM data generation. The conventional norm in VLM data construction uses a mixture of specialists in caption and OCR, or stronger VLM APIs and... | Jiacong Wang, Bohong Wu, Haiyong Jiang, Xun Zhou, Xin Xiao, Haoyuan Guo, Jun Xiao |  |
| 389 |  |  [DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.266) |  | 0 | Large language models (LLMs) are widely used in question-answering (QA) systems but often generate information with hallucinations. Retrieval-augmented generation (RAG) offers a potential remedy, yet the uneven retrieval quality and irrelevant contents may distract LLMs.In this work, we address... | Jing Jin, Houfeng Wang, Hao Zhang, Xiaoguang Li, Zhijiang Guo |  |
| 390 |  |  [How Do Humans Write Code? Large Models Do It the Same Way Too](https://doi.org/10.18653/v1/2024.emnlp-main.267) |  | 0 | Program-of-Thought (PoT) replaces natural language-based Chain-of-Thought (CoT) as the most popular method in Large Language Models (LLMs) mathematical reasoning tasks by utilizing external tool calls to circumvent computational errors. However, our evaluation of the GPT-4 and Llama series reveals... | Long Li, Xuzheng He, Haozhe Wang, Linlin Wang, Liang He |  |
| 391 |  |  [Retrospex: Language Agent Meets Offline Reinforcement Learning Critic](https://doi.org/10.18653/v1/2024.emnlp-main.268) |  | 0 | Large language models (LLMs) possess extensive knowledge and commonsense reasoning capabilities, making them valuable for creating powerful agents. However, existing LLM agent frameworks have not fully utilized past experiences for improvement. This work introduces a new LLM-based agent framework... | Yufei Xiang, Yiqun Shen, Yeqin Zhang, CamTu Nguyen |  |
| 392 |  |  [Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-Context Models](https://doi.org/10.18653/v1/2024.emnlp-main.269) |  | 0 | Numerous recent works target to extend effective context length for language models and various methods, tasks and benchmarks exist to measure model’s effective memory length. However, through thorough investigations, we find limitations for currently existing evaluations on model’s memory. We... | Xinyu Liu, Runsong Zhao, Pengcheng Huang, Chunyang Xiao, Bei Li, Jingang Wang, Tong Xiao, JingBo Zhu |  |
| 393 |  |  [Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation](https://doi.org/10.18653/v1/2024.emnlp-main.270) |  | 0 | Despite the significant progress of large language models (LLMs) in various tasks, they often produce factual errors due to their limited internal knowledge. Retrieval-Augmented Generation (RAG), which enhances LLMs with external knowledge sources, offers a promising solution. However, these... | Yuanjie Lyu, Zihan Niu, Zheyong Xie, Chao Zhang, Tong Xu, Yang Wang, Enhong Chen |  |
| 394 |  |  [CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation](https://doi.org/10.18653/v1/2024.emnlp-main.271) |  | 0 | In recent years, instruction fine-tuning (IFT) on large language models (LLMs) has garnered considerable attention to enhance model performance on unseen tasks. Attempts have been made on automatic construction and effective selection for IFT data. However, we posit that previous methods have not... | Renhao Li, Minghuan Tan, Derek F. Wong, Min Yang |  |
| 395 |  |  [A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners](https://doi.org/10.18653/v1/2024.emnlp-main.272) |  | 0 | This study introduces a hypothesis-testing framework to assess whether large language models (LLMs) possess genuine reasoning abilities or primarily depend on token bias. We go beyond evaluating LLMs on accuracy; rather, we aim to investigate their token bias in solving logical reasoning tasks.... | Bowen Jiang, Yangxinyu Xie, Zhuoqun Hao, Xiaomeng Wang, Tanwi Mallick, Weijie Su, Camillo J. Taylor, Dan Roth |  |
| 396 |  |  [Bayesian Calibration of Win Rate Estimation with LLM Evaluators](https://doi.org/10.18653/v1/2024.emnlp-main.273) |  | 0 | Recent advances in large language models (LLMs) show the potential of using LLMs as evaluators for assessing the quality of text generations from LLMs. However, applying LLM evaluators naively to compare different systems can lead to unreliable results due to the inaccuracy and intrinsic bias of... | Yicheng Gao, Gonghan Xu, Zhe Wang, Arman Cohan |  |
| 397 |  |  [MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.274) |  | 0 | The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math reasoning data. However, a great method to integrate the... | Shuo Yin, Weihao You, Zhilong Ji, Guoqiang Zhong, Jinfeng Bai |  |
| 398 |  |  [Seeing the Forest through the Trees: Data Leakage from Partial Transformer Gradients](https://doi.org/10.18653/v1/2024.emnlp-main.275) |  | 0 | Recent studies have shown that distributed machine learning is vulnerable to gradient inversion attacks, where private training data can be reconstructed by analyzing the gradients of the models shared in training. Previous attacks established that such reconstructions are possible using gradients... | Weijun Li, Qiongkai Xu, Mark Dras |  |
| 399 |  |  [RWKV-CLIP: A Robust Vision-Language Representation Learner](https://doi.org/10.18653/v1/2024.emnlp-main.276) |  | 0 | Contrastive Language-Image Pre-training (CLIP) has significantly improved performance in various vision-language tasks by expanding the dataset with image-text pairs obtained from the web. This paper further explores CLIP from the perspectives of data and model architecture. To mitigate the impact... | Tiancheng Gu, Kaicheng Yang, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng |  |
| 400 |  |  [KidLM: Advancing Language Models for Children - Early Insights and Future Directions](https://doi.org/10.18653/v1/2024.emnlp-main.277) |  | 0 | Recent studies highlight the potential of large language models in creating educational tools for children, yet significant challenges remain in maintaining key child-specific properties such as linguistic nuances, cognitive needs, and safety standards. In this paper, we explore foundational steps... | Mir Tafseer Nayeem, Davood Rafiei |  |
| 401 |  |  [Using Language Models to Disambiguate Lexical Choices in Translation](https://doi.org/10.18653/v1/2024.emnlp-main.278) |  | 0 | In translation, a concept represented by a single word in a source language can have multiple variations in a target language. The task of lexical selection requires using context to identify which variation is most appropriate for a source text. We work with native speakers of nine languages to... | Josh Barua, Sanjay Subramanian, Kayo Yin, Alane Suhr |  |
| 402 |  |  [How Does the Disclosure of AI Assistance Affect the Perceptions of Writing?](https://doi.org/10.18653/v1/2024.emnlp-main.279) |  | 0 | Recent advances in generative AI technologies like large language models have boosted the incorporation of AI assistance in writing workflows, leading to the rise of a new paradigm of human-AI co-creation in writing. To understand how people perceive writings that are produced under this paradigm,... | Zhuoyan Li, Chen Liang, Jing Peng, Ming Yin |  |
| 403 |  |  [An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records](https://doi.org/10.18653/v1/2024.emnlp-main.280) |  | 0 | Electronic healthcare records are vital for patient safety as they document conditions, plans, and procedures in both free text and medical codes. Language models have significantly enhanced the processing of such records, streamlining workflows and reducing manual data entry, thereby saving... | Joakim Edin, Maria Maistro, Lars Maaløe, Lasse Borgholt, Jakob D. Havtorn, Tuukka Ruotsalo |  |
| 404 |  |  [Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.281) |  | 0 | In the age of mobile internet, user data, often referred to as memories, is continuously generated on personal devices. Effectively managing and utilizing this data to deliver services to users is a compelling research topic. In this paper, we introduce a novel task of crafting personalized agents... | Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, Wei Shi |  |
| 405 |  |  [EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation](https://doi.org/10.18653/v1/2024.emnlp-main.282) |  | 0 | The dynamic nature of real-world information necessitates knowledge editing (KE) in large language models (LLMs). The edited knowledge should propagate and facilitate the deduction of new information based on existing model knowledge. We term the existing related knowledge in LLM serving as the... | Jiateng Liu, Pengfei Yu, Yuji Zhang, Sha Li, Zixuan Zhang, Ruhi Sarikaya, Kevin Small, Heng Ji |  |
| 406 |  |  [Modeling Nonnative Sentence Processing with L2 Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.283) |  | 0 | We study LMs pretrained sequentially on two languages (“L2LMs”) for modeling nonnative sentence processing. In particular, we pretrain GPT2 on 6 different first languages (L1s), followed by English as the second language (L2). We examine the effect of the choice of pretraining L1 on the model’s... | Tatsuya Aoyama, Nathan Schneider |  |
| 407 |  |  [From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis](https://doi.org/10.18653/v1/2024.emnlp-main.284) |  | 0 | We explore multi-step reasoning in vision-language models (VLMs). The problem is challenging, as reasoning data consisting of multiple steps of visual and language processing are barely available. To overcome the challenge, we first introduce a least-to-most visual reasoning paradigm, which... | Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan |  |
| 408 |  |  [Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.285) |  | 0 | Training large language models (LLMs) for external tool usage is a rapidly expanding field, with recent research focusing on generating synthetic data to address the shortage of available data. However, the absence of systematic data quality checks poses complications for properly training and... | Shadi Iskander, Sofia Tolmach, Ori Shapira, Nachshon Cohen, Zohar Karnin |  |
| 409 |  |  [Cross-Domain Audio Deepfake Detection: Dataset and Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.286) |  | 0 | Audio deepfake detection (ADD) is essential for preventing the misuse of synthetic voices that may infringe on personal rights and privacy. Recent zero-shot text-to-speech (TTS) models pose higher risks as they can clone voices with a single utterance. However, the existing ADD datasets are... | Yuang Li, Min Zhang, Mengxin Ren, Xiaosong Qiao, Miaomiao Ma, Daimeng Wei, Hao Yang |  |
| 410 |  |  [MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension](https://doi.org/10.18653/v1/2024.emnlp-main.287) |  | 0 | Referring Expression Comprehension (REC), which aims to ground a local visual region via natural language, is a task that heavily relies on multimodal alignment. Most existing methods utilize powerful pre-trained models to transfer visual/linguistic knowledge by full fine-tuning. However, full... | Ting Liu, Zunnan Xu, Yue Hu, Liangtao Shi, Zhiqiang Wang, Quanjun Yin |  |
| 411 |  |  [Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization](https://doi.org/10.18653/v1/2024.emnlp-main.288) |  | 0 | Despite the advances in large language models (LLMs), how they use their knowledge for reasoning is not yet well understood.In this study, we propose a method that deconstructs complex real-world questions into a graph, representing each question as a node with predecessors of background knowledge... | Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo |  |
| 412 |  |  [Aligning Translation-Specific Understanding to General Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.289) |  | 0 | Large Language models (LLMs) have exhibited remarkable abilities in understanding complex texts, offering a promising path towards human-like translation performance. However, this study reveals the misalignment between the translation-specific understanding and the general understanding inside... | Yichong Huang, Baohang Li, Xiaocheng Feng, Wenshuai Huo, Chengpeng Fu, Ting Liu, Bing Qin |  |
| 413 |  |  [FOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation](https://doi.org/10.18653/v1/2024.emnlp-main.290) |  | 0 | Word sense disambiguation (WSD) is a key task in natural language processing and lexical semantics. Pre-trained language models with contextualized word embeddings have significantly improved performance in regular WSD tasks. However, these models still struggle with recognizing semantic boundaries... | Mohamad Ballout, Anne Dedert, Nohayr Abdelmoneim, Ulf Krumnack, Gunther Heidemann, KaiUwe Kühnberger |  |
| 414 |  |  [Concept-skill Transferability-based Data Selection for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.291) |  | 0 | Instruction tuning, or supervised finetuning on extensive task-specific data, is necessary for Large Vision-Language Models (LVLMs) to generalize well across a broad range of vision-language (VL) tasks. However, training on large VL datasets can become prohibitively expensive. In this work, we... | Jaewoo Lee, Boyang Li, Sung Ju Hwang |  |
| 415 |  |  [LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing](https://doi.org/10.18653/v1/2024.emnlp-main.292) |  | 0 | Claim: This work is not advocating the use of LLMs for paper (meta-)reviewing. Instead, wepresent a comparative analysis to identify and distinguish LLM activities from human activities. Two research goals: i) Enable better recognition of instances when someone implicitly uses LLMs for reviewing... | Jiangshu Du, Yibo Wang, Wenting Zhao, Zhongfen Deng, Shuaiqi Liu, Renze Lou, Henry Peng Zou, Pranav Narayanan Venkit, Nan Zhang, Mukund Srinath, Haoran Zhang, Vipul Gupta, Yinghui Li, Tao Li, Fei Wang, Qin Liu, Tianlin Liu, Pengzhi Gao, Congying Xia, Chen Xing, Cheng Jiayang, Zhaowei Wang, Ying Su, Raj Sanjay Shah, Ruohao Guo, Jing Gu, Haoran Li, Kangda Wei, Zihao Wang, Lu Cheng, Surangika Ranathunga, Meng Fang, Jie Fu, Fei Liu, Ruihong Huang, Eduardo Blanco, Yixin Cao, Rui Zhang, Philip S. Yu, Wenpeng Yin |  |
| 416 |  |  [Academics Can Contribute to Domain-Specialized Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.293) |  | 0 | Commercially available models dominate academic leaderboards. While impressive, this has concentrated research on creating and adapting general-purpose models to improve NLP leaderboard standings for large language models. However, leaderboards collect many individual tasks and general-purpose... | Mark Dredze, Genta Indra Winata, Prabhanjan Kambadur, Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, David S. Rosenberg, Sebastian Gehrmann |  |
| 417 |  |  [Beyond Reference: Evaluating High Quality Translations Better than Human References](https://doi.org/10.18653/v1/2024.emnlp-main.294) |  | 0 | In Machine Translation (MT) evaluations, the conventional approach is to compare a translated sentence against its human-created reference sentence. MT metrics provide an absolute score (e.g., from 0 to 1) to a candidate sentence based on the similarity with the reference sentence. Thus, existing... | Keonwoong Noh, Seokjin Oh, Woohwan Jung |  |
| 418 |  |  [Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement](https://doi.org/10.18653/v1/2024.emnlp-main.295) |  | 0 | Large language models (LLMs) demonstrate exceptional instruct-following ability to complete various downstream tasks. Although this impressive ability makes LLMs flexible task solvers, their performance in solving tasks also heavily relies on instructions. In this paper, we reveal that LLMs are... | Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, Ru Xie |  |
| 419 |  |  [SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages](https://doi.org/10.18653/v1/2024.emnlp-main.296) |  | 0 | Southeast Asia (SEA) is a region rich in linguistic diversity and cultural variety, with over 1,300 indigenous languages and a population of 671 million people. However, prevailing AI models suffer from a significant lack of representation of texts, images, and audio datasets from SEA, compromising... | Holy Lovenia, Rahmad Mahendra, Salsabil Maulana Akbar, Lester James V. Miranda, Jennifer Santoso, Elyanah Aco, Akhdan Fadhilah, Jonibek Mansurov, Joseph Marvin Imperial, Onno Kampman, Joel Ruben Antony Moniz, Muhammad Ravi Shulthan Habibi, Frederikus Hudi, Jann Railey Montalan, Ryan Hadiwijaya, Joanito Agili Lopo, William Nixon, Börje Karlsson, James Jaya, Ryandito Diandaru, Yuze Gao, Patrick Amadeus Irawan, Bin Wang, Jan Christian Blaise Cruz, Chenxi Whitehouse, Ivan Halim Parmonangan, Maria Khelli, Wenyu Zhang, Lucky Susanto, Reynard Adha Ryanda, Sonny Lazuardi Hermawan, Dan John Velasco, Muhammad Dehan Al Kautsar, Willy Fitra Hendria, Yasmin Moslem, Noah Flynn, Muhammad Farid Adilazuarda, Haochen Li, Johanes Lee, R. Damanhuri, Shuo Sun, Muhammad Reza Qorib, Amirbek Djanibekov, Wei Qi Leong, Quyet V. Do, Niklas Muennighoff, Tanrada Pansuwan, Ilham Firdausi Putra, Yan Xu, Ngee Tai Chia, Ayu Purwarianti, Sebastian Ruder, WilliamChandra Tjhi, Peerat Limkonchotiwat, Alham Fikri Aji, Sedrick Keh, Genta Indra Winata, Ruochen Zhang, Fajri Koto, Zheng Xin Yong, Samuel Cahyawijaya |  |
| 420 |  |  [Induct-Learn: Short Phrase Prompting with Instruction Induction](https://doi.org/10.18653/v1/2024.emnlp-main.297) |  | 0 | Large Language Models (LLMs) have demonstrated capability in “instruction induction,” generating instructions from demonstrations (input-output pairs). However, existing methods often rely on large datasets or numerous examples, which is impractical and costly in real-world scenarios. In this work,... | PoChun Chen, ShengLun Wei, HenHsen Huang, HsinHsi Chen |  |
| 421 |  |  [Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.298) |  | 0 |  | Shi Mingcong, Chunjiang Zhu, Detian Zhang, Shiting Wen, Qing Li |  |
| 422 |  |  [LUQ: Long-text Uncertainty Quantification for LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.299) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capability in a variety of NLP tasks. However, LLMs are also prone to generate nonfactual content. Uncertainty Quantification (UQ) is pivotal in enhancing our understanding of a model’s confidence on its generation, thereby aiding in the... | Caiqi Zhang, Fangyu Liu, Marco Basaldella, Nigel Collier |  |
| 423 |  |  [Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method](https://doi.org/10.18653/v1/2024.emnlp-main.300) |  | 0 | As the scale of training corpora for large language models (LLMs) grows, model developers become increasingly reluctant to disclose details on their data. This lack of transparency poses challenges to scientific evaluation and ethical deployment. Recently, pretraining data detection approaches,... | Weichao Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng |  |
| 424 |  |  [Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars](https://doi.org/10.18653/v1/2024.emnlp-main.301) |  | 0 | Logical reasoning remains a challenge for natural language processing, but it can be improved by training language models to mimic theorem provers on procedurally generated problems. Previous work used domain-specific proof generation algorithms, which biases reasoning toward specific proof traces... | Damien Sileo |  |
| 425 |  |  [Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach](https://doi.org/10.18653/v1/2024.emnlp-main.302) |  | 0 | Recent progress in Spoken Language Modeling has shown that learning language directly from speech is feasible. Generating speech through a pipeline that operates at the text level typically loses nuances, intonations, and non-verbal vocalizations. Modeling directly from speech opens up the path to... | Maxime Poli, Emmanuel Chemla, Emmanuel Dupoux |  |
| 426 |  |  [Safely Learning with Private Data: A Federated Learning Framework for Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.303) |  | 0 | Private data, being larger and quality-higher than public data, can greatly improve large language models (LLM). However, due to privacy concerns, this data is often dispersed in multiple silos, making its secure utilization for LLM training a challenge. Federated learning (FL) is an ideal solution... | Jiaying Zheng, Hainan Zhang, Lingxiang Wang, Wangjie Qiu, HongWei Zheng, Zhi Ming Zheng |  |
| 427 |  |  [Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge](https://doi.org/10.18653/v1/2024.emnlp-main.304) |  | 0 | Having been trained on massive pretraining data, large language models have shown excellent performance on many knowledge-intensive tasks. However, pretraining data tends to contain misleading and even conflicting information, and it is intriguing to understand how LLMs handle these noisy data... | Jiahuan Li, Yiqing Cao, Shujian Huang, Jiajun Chen |  |
| 428 |  |  [How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?](https://doi.org/10.18653/v1/2024.emnlp-main.305) |  | 0 | The increase in parameter size of multimodal large language models (MLLMs) introduces significant capabilities, particularly multimodal in-context learning, where MLLMs enhance task performance without updating pre-trained parameters. However, this effectiveness hinges on the appropriate selection... | Yang Luo, Zangwei Zheng, Zirui Zhu, Yang You |  |
| 429 |  |  [How Far Can We Extract Diverse Perspectives from Large Language Models?](https://doi.org/10.18653/v1/2024.emnlp-main.306) |  | 0 | Collecting diverse human opinions is costly and challenging. This leads to a recent trend in exploiting large language models (LLMs) for generating diverse data for potential scalable and efficient solutions. However, the extent to which LLMs can generate diverse perspectives on subjective topics... | Shirley Anugrah Hayati, Minhwa Lee, Dheeraj Rajagopal, Dongyeop Kang |  |
| 430 |  |  [EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.307) |  | 0 | Answering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task. Recent advances in large language models (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire proficiency in a specific task using only a few demonstration samples... | Kiran Purohit, Venktesh V, Raghuram Devalla, Krishna Yerragorla, Sourangshu Bhattacharya, Avishek Anand |  |
| 431 |  |  [An LLM Feature-based Framework for Dialogue Constructiveness Assessment](https://doi.org/10.18653/v1/2024.emnlp-main.308) |  | 0 | Research on dialogue constructiveness assessment focuses on (i) analysing conversational factors that influence individuals to take specific actions, win debates, change their perspectives or broaden their open-mindedness and (ii) predicting constructiveness outcomes following dialogues for such... | Lexin Zhou, Youmna Farag, Andreas Vlachos |  |
| 432 |  |  [Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System](https://doi.org/10.18653/v1/2024.emnlp-main.309) |  | 0 | Retrieving accurate domain knowledge and providing helpful information are crucial in developing an effective end-to-end task-oriented dialogue system (E2ETOD). The field has witnessed numerous methods following the retrieve-then-generate paradigm and training their systems on one specific domain.... | Zhanpeng Chen, Zhihong Zhu, Wanshi Xu, Xianwei Zhuang, Yuexian Zou |  |
| 433 |  |  [Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.310) |  | 0 | Efficiently deriving structured workflows from unannotated dialogs remains an underexplored and formidable challenge in computational linguistics. Automating this process could significantly accelerate the manual design of workflows in new domains and enable the grounding of large language models... | Sergio Burdisso, Srikanth R. Madikeri, Petr Motlícek |  |
| 434 |  |  [Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.emnlp-main.311) |  | 0 | Diffusion models are the state of the art in text-to-image generation, but their perceptual variability remains understudied. In this paper, we examine how prompts affect image variability in black-box diffusion-based models. We propose W1KP, a human-calibrated measure of variability in a set of... | Raphael Tang, Xinyu Zhang, Lixinyu Xu, Yao Lu, Wenyan Li, Pontus Stenetorp, Jimmy Lin, Ferhan Ture |  |
| 435 |  |  [Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024](https://doi.org/10.18653/v1/2024.emnlp-main.312) |  | 0 | In light of the recent 2024 European Parliament elections, we are investigating if LLMs can be used as Voting Advice Applications (VAAs). We audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the stance of political parties based on the latest “EU and I” voting assistance... | Ilias Chalkidis |  |
| 436 |  |  [Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.313) |  | 0 | Large language models (LLMs) have shown excellent capability for solving reasoning problems. Existing approaches do not differentiate the question difficulty when designing prompting methods for them. Clearly, a simple method cannot elicit sufficient knowledge from LLMs to answer a hard question.... | Mayi Xu, Yongqi Li, Ke Sun, Tieyun Qian |  |
| 437 |  |  [LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations](https://doi.org/10.18653/v1/2024.emnlp-main.314) |  | 0 | Document-level relation extraction (DocRE) aims to identify relationships between entities within a document. Due to the vast number of entity pairs, fully annotating all fact triplets is challenging, resulting in datasets with numerous false negative samples. Recently, self-training-based methods... | Shengda Fan, Yanting Wang, Shasha Mo, Jianwei Niu |  |
| 438 |  |  [Concept Space Alignment in Multilingual LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.315) |  | 0 | Multilingual large language models (LLMs) seem to generalize somewhat across languages. We hypothesize this is a result of implicit vector space alignment. Evaluating such alignment, we see that larger models exhibit very high-quality linear alignments between corresponding concepts in different... | Qiwei Peng, Anders Søgaard |  |
| 439 |  |  [Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.316) |  | 0 | Transformer-based large language models (LLMs) exhibit limitations such as generating unsafe responses, unreliable reasoning, etc. Existing inference intervention approaches attempt to mitigate these issues by finetuning additional models to produce calibration signals (such as rewards) that guide... | Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou |  |
| 440 |  |  [NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian](https://doi.org/10.18653/v1/2024.emnlp-main.317) |  | 0 | Norwegian, spoken by only 5 million population, is under-representative within the most impressive breakthroughs in NLP tasks. To the best of our knowledge, there has not yet been a comprehensive evaluation of the existing language models (LMs) on Norwegian generation tasks during the article... | Peng Liu, Lemei Zhang, Terje Nissen Farup, Even W. Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, Zhirong Yang |  |
| 441 |  |  [RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework](https://doi.org/10.18653/v1/2024.emnlp-main.318) |  | 0 | Despite significant advancements in natural language generation, controlling language models to produce texts with desired attributes remains a formidable challenge. In this work, we introduce RSA-Control, a training-free controllable text generation framework grounded in pragmatics. RSA-Control... | Yifan Wang, Vera Demberg |  |
| 442 |  |  [Scaling Laws Across Model Architectures: A Comparative Analysis of Dense and MoE Models in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.319) |  | 0 | The scaling of large language models (LLMs) is a critical research area for the efficiency and effectiveness of model training and deployment. Our work investigates the transferability and discrepancies of scaling laws between Dense Models and Mixture of Experts (MoE) models. Through a combination... | Siqi Wang, Zhengyu Chen, Bei Li, Keqing He, Min Zhang, Jingang Wang |  |
| 443 |  |  [Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems](https://doi.org/10.18653/v1/2024.emnlp-main.320) |  | 0 | End-to-end Task-Oriented Dialog (TOD) systems typically require extensive training datasets to perform well. In contrast, large language model (LLM) based TOD systems can excel even with limited data due to their ability to learn tasks through in-context exemplars. However, these models lack... | Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu, Mausam |  |
| 444 |  |  [REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.321) |  | 0 | Considering the limited internal parametric knowledge, retrieval-augmented generation (RAG) has been widely used to extend the knowledge scope of large language models (LLMs). Despite the extensive efforts on RAG research, in existing methods, LLMs cannot precisely assess the relevance of retrieved... | Yuhao Wang, Ruiyang Ren, Junyi Li, Xin Zhao, Jing Liu, JiRong Wen |  |
| 445 |  |  [Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA](https://doi.org/10.18653/v1/2024.emnlp-main.322) |  | 0 | Long-context modeling capabilities of Large Language Models (LLMs) have garnered widespread attention, leading to the emergence of LLMs with ultra-context windows. Meanwhile, benchmarks for evaluating long-context language models are gradually catching up. However, existing benchmarks employ... | Minzheng Wang, Longze Chen, Fu Cheng, Shengyi Liao, Xinghua Zhang, Bingli Wu, Haiyang Yu, Nan Xu, Lei Zhang, Run Luo, Yunshui Li, Min Yang, Fei Huang, Yongbin Li |  |
| 446 |  |  [On Mitigating Performance Disparities in Multilingual Speech Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.323) |  | 0 | How far have we come in mitigating performance disparities across genders in multilingual speech recognition? We compare the impact on gender disparity of different fine-tuning algorithms for automated speech recognition across model sizes, languages and gender. We look at both performance-focused... | Monorama Swain, Anna Zee, Anders Søgaard |  |
| 447 |  |  [Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.324) |  | 0 | The field of privacy-preserving Natural Language Processing has risen in popularity, particularly at a time when concerns about privacy grow with the proliferation of large language models. One solution consistently appearing in recent literature has been the integration of Differential Privacy... | Stephen Meisenbacher, Florian Matthes |  |
| 448 |  |  [To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.325) |  | 0 | In recent years, multimodal large language models (MLLMs) have attracted widespread attention from both industry and academia. Based on the integration position, MLLMs can be categorized into external and internal fusion architectures, with the former being more predominant. However, there remains... | Junyan Lin, Haoran Chen, Dawei Zhu, Xiaoyu Shen |  |
| 449 |  |  [What is "Typological Diversity" in NLP?](https://doi.org/10.18653/v1/2024.emnlp-main.326) |  | 0 | The NLP research community has devoted increased attention to languages beyond English, resulting in considerable improvements for multilingual NLP. However, these improvements only apply to a small subset of the world’s languages. An increasing number of papers aspires to enhance generalizable... | Esther Ploeger, Wessel Poelman, Miryam de Lhoneux, Johannes Bjerva |  |
| 450 |  |  [The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse](https://doi.org/10.18653/v1/2024.emnlp-main.327) |  | 0 | The ability for individuals to constructively engage with one another across lines of difference is a critical feature of a healthy pluralistic society. This is also true in online discussion spaces like social media platforms. To date, much social media research has focused on preventing ills—like... | Xiaobo Guo, Neil Potnis, Melody Yu, Nabeel Gillani, Soroush Vosoughi |  |
| 451 |  |  [Consistent Bidirectional Language Modelling: Expressive Power and Representational Conciseness](https://doi.org/10.18653/v1/2024.emnlp-main.328) |  | 0 | The inability to utilise future contexts and the pre-determined left-to-right generation order are major limitations of unidirectional language models. Bidirectionality has been introduced to address those deficiencies. However, a crucial shortcoming of bidirectional language models is the... | Georgi Shopov, Stefan Gerdjikov |  |
| 452 |  |  [Benchmarking Vision Language Models for Cultural Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.329) |  | 0 | Foundation models and vision-language pre-training have notably advanced Vision Language Models (VLMs), enabling multimodal processing of visual and linguistic data. However, their performance has been typically assessed on general scene understanding - recognizing objects, attributes, and actions... | Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Stanczak, Aishwarya Agrawal |  |
| 453 |  |  [Methods of Automatic Matrix Language Determination for Code-Switched Speech](https://doi.org/10.18653/v1/2024.emnlp-main.330) |  | 0 | Code-switching (CS) is the process of speakers interchanging between two or more languages which in the modern world becomes increasingly common. In order to better describe CS speech the Matrix Language Frame (MLF) theory introduces the concept of a Matrix Language, which is the language that... | Olga Iakovenko, Thomas Hain |  |
| 454 |  |  [Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts](https://doi.org/10.18653/v1/2024.emnlp-main.331) |  | 0 | Emotional intelligence (EI) in artificial intelligence (AI), which refers to the ability of an AI to understand and respond appropriately to human emotions, has emerged as a crucial research topic. Recent studies have shown that large language models (LLMs) and vision large language models (VLLMs)... | Jaewook Lee, Yeajin Jang, Hongjin Kim, Woojin Lee, Harksoo Kim |  |
| 455 |  |  [Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.332) |  | 0 | Despite their widespread adoption, large language models (LLMs) remain prohibitive to use under resource constraints, with their ever growing sizes only increasing the barrier for use. One particular issue stems from the high latency associated with auto-regressive generation in LLMs, rendering the... | Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar |  |
| 456 |  |  [Teaching Small Language Models Reasoning through Counterfactual Distillation](https://doi.org/10.18653/v1/2024.emnlp-main.333) |  | 0 | With the rise of large language models (LLMs), many studies are interested in transferring the reasoning capabilities of LLMs to small language models (SLMs). Previous distillation methods usually utilize the capabilities of LLMs to generate chain-of-thought (CoT) samples and teach SLMs via... | Tao Feng, Yicheng Li, Chenglin Li, Hao Chen, Fei Yu, Yin Zhang |  |
| 457 |  |  [Pretraining Language Models Using Translationese](https://doi.org/10.18653/v1/2024.emnlp-main.334) |  | 0 | In this paper, we explore the utility of Translationese as synthetic data created using machine translation for pre-training language models (LMs) for low-resource languages (LRLs). Our simple methodology consists of translating large amounts of web-crawled monolingual documents (clean) into the... | Meet Doshi, Raj Dabre, Pushpak Bhattacharyya |  |
| 458 |  |  [Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.335) |  | 0 | There is a scarcity of multilingual vision-language models that properly account for the perceptual differences that are reflected in image captions across languages and cultures. In this work, through a multimodal, multilingual retrieval case study, we quantify the existing lack of model... | Kyle Buettner, Adriana Kovashka |  |
| 459 |  |  [MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.336) |  | 0 | Although Dense Passage Retrieval (DPR) models have achieved significantly enhanced performance, their widespread application is still hindered by the demanding inference efficiency and high deployment costs. Knowledge distillation is an efficient method to compress models, which transfers knowledge... | Qixi Lu, Endong Xun, Gongbo Tang |  |
| 460 |  |  [Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates](https://doi.org/10.18653/v1/2024.emnlp-main.337) |  | 0 | Solidarity is a crucial concept to understand social relations in societies. In this study, we investigate the frequency of (anti-)solidarity towards women and migrants in German parliamentary debates between 1867 and 2022. Using 2,864 manually annotated text snippets, we evaluate large language... | Aida Kostikova, Dominik Beese, Benjamin Paassen, Ole Pütz, Gregor Wiedemann, Steffen Eger |  |
| 461 |  |  [CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling](https://doi.org/10.18653/v1/2024.emnlp-main.338) |  | 0 | Long sequence modeling has gained broad interest as large language models (LLMs) continue to advance. Recent research has identified that a large portion of hidden states within the key-value caches of Transformer models can be discarded (also termed evicted) withoutaffecting the perplexity... | Yu Bai, Xiyuan Zou, Heyan Huang, Sanxing Chen, MarcAntoine Rondeau, Yang Gao, Jackie C. K. Cheung |  |
| 462 |  |  [Story Embeddings - Narrative-Focused Representations of Fictional Stories](https://doi.org/10.18653/v1/2024.emnlp-main.339) |  | 0 | We present a novel approach to modeling fictional narratives. The proposed model creates embeddings that represent a story such that similar narratives, that is, reformulations of the same story, will result in similar embeddings. We showcase the prowess of our narrative-focused embeddings on... | Hans Ole Hatzel, Chris Biemann |  |
| 463 |  |  [C-LLM: Learn to Check Chinese Spelling Errors Character by Character](https://doi.org/10.18653/v1/2024.emnlp-main.340) |  | 0 | Chinese Spell Checking (CSC) aims to detect and correct spelling errors in sentences. Despite Large Language Models (LLMs) exhibit robust capabilities and are widely applied in various tasks, their performance on CSC is often unsatisfactory. We find that LLMs fail to meet the Chinese... | Kunting Li, Yong Hu, Liang He, Fandong Meng, Jie Zhou |  |
| 464 |  |  [PSC: Extending Context Window of Large Language Models via Phase Shift Calibration](https://doi.org/10.18653/v1/2024.emnlp-main.341) |  | 0 | Rotary Position Embedding (RoPE) is an efficient position encoding approach and is widely utilized in numerous large language models (LLMs). Recently, a lot of methods have been put forward to further expand the context window based on RoPE. The core concept of those methods is to predefine or... | Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu |  |
| 465 |  |  [Video-LLaVA: Learning United Visual Representation by Alignment Before Projection](https://doi.org/10.18653/v1/2024.emnlp-main.342) |  | 0 | Large Vision-Language Model (LVLM) has enhanced the performance of various downstream tasks in visual-language understanding. Most existing approaches encode images and videos into separate feature spaces, which are then fed as inputs to large language models. However, due to the lack of unified... | Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning, Peng Jin, Li Yuan |  |
| 466 |  |  [SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales](https://doi.org/10.18653/v1/2024.emnlp-main.343) |  | 0 | Large language models (LLMs) often generate inaccurate or fabricated information and generally fail to indicate their confidence, which limits their broader applications. Previous work has elicited confidence from LLMs by direct or self-consistency prompting, or constructing specific datasets for... | Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao |  |
| 467 |  |  [Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing](https://doi.org/10.18653/v1/2024.emnlp-main.344) |  | 0 | Language models strongly rely on frequency information because they maximize the likelihood of tokens during pre-training. As a consequence, language models tend to not generalize well to tokens that are seldom seen during training. Moreover, maximum likelihood training has been discovered to give... | Richard Diehl Martinez, Zébulon Goriely, Andrew Caines, Paula Buttery, Lisa Beinborn |  |
| 468 |  |  [ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations](https://doi.org/10.18653/v1/2024.emnlp-main.345) |  | 0 | Detecting hate speech and offensive language is essential for maintaining a safe and respectful digital environment. This study examines the limitations of state-of-the-art large language models (LLMs) in identifying offensive content within systematically perturbed data, with a focus on Chinese, a... | Yunze Xiao, Yujia Hu, Kenny T. W. Choo, Roy KaWei Lee |  |
| 469 |  |  [Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?](https://doi.org/10.18653/v1/2024.emnlp-main.346) |  | 0 | Analogical reasoning plays a critical role in human cognition, enabling us to understand new concepts by associating them with familiar ones. Previous research in the AI community has mainly focused on identifying and generating analogies and then examining their quality under human evaluation,... | Siyu Yuan, Cheng Jiayang, Lin Qiu, Deqing Yang |  |
| 470 |  |  [Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.347) |  | 0 | Ensuring the verifiability of model answers is a fundamental challenge for retrieval-augmented generation (RAG) in the question answering (QA) domain. Recently, self-citation prompting was proposed to make large language models (LLMs) generate citations to supporting documents along with their... | Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza |  |
| 471 |  |  [Do Large Language Models Know How Much They Know?](https://doi.org/10.18653/v1/2024.emnlp-main.348) |  | 0 | Large Language Models (LLMs) have emerged as highly capable systems and are increasingly being integrated into various uses. Nevertheless, the rapid advancement in their deployment trails a comprehensive understanding of their internal mechanisms, as well as a delineation of their capabilities and... | Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar |  |
| 472 |  |  [Investigating Mysteries of CoT-Augmented Distillation](https://doi.org/10.18653/v1/2024.emnlp-main.349) |  | 0 | Eliciting chain of thought (CoT) rationales - sequences of token that convey a “reasoning” process has been shown to consistently improve LLM performance on tasks like question answering. More recent efforts have shown that such rationales can also be used for model distillation: Including CoT... | Somin Wadhwa, Silvio Amir, Byron C. Wallace |  |
| 473 |  |  [SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics](https://doi.org/10.18653/v1/2024.emnlp-main.350) |  | 0 | Prompt-based fine-tuning has become an essential method for eliciting information encoded in pre-trained language models for a variety of tasks, including text classification. For multi-class classification tasks, prompt-based fine-tuning under low-resource scenarios has resulted in performance... | Zhiwen You, Kanyao Han, Haotian Zhu, Bertram Ludäscher, Jana Diesner |  |
| 474 |  |  [Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP](https://doi.org/10.18653/v1/2024.emnlp-main.351) |  | 0 | Image-text contrastive models like CLIP have wide applications in zero-shot classification, image-text retrieval, and transfer learning. However, they often struggle on compositional visio-linguistic tasks (e.g., attribute-binding or object-relationships) where their performance is no better than... | Samyadeep Basu, Shell Xu Hu, Maziar Sanjabi, Daniela Massiceti, Soheil Feizi |  |
| 475 |  |  [Learning from Natural Language Explanations for Generalizable Entity Matching](https://doi.org/10.18653/v1/2024.emnlp-main.352) |  | 0 | Entity matching is the task of linking records from different sources that refer to the same real-world entity. Past work has primarily treated entity linking as a standard supervised learning problem. However, supervised entity matching models often do not generalize well to new data, and... | Somin Wadhwa, Adit Krishnan, Runhui Wang, Byron C. Wallace, Luyang Kong |  |
| 476 |  |  [Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.353) |  | 0 | Language models (LMs) are known to suffer from hallucinations and misinformation. Retrieval augmented generation (RAG) that retrieves verifiable information from an external knowledge corpus to complement the parametric knowledge in LMs provides a tangible solution to these problems. However, the... | Zhuohang Li, Jiaxin Zhang, Chao Yan, Kamalika Das, Kumar Sricharan, Murat Kantarcioglu, Bradley A. Malin |  |
| 477 |  |  [On the Reliability of Psychological Scales on Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.354) |  | 0 | Recent research has focused on examining Large Language Models’ (LLMs) characteristics from a psychological standpoint, acknowledging the necessity of understanding their behavioral characteristics. The administration of personality tests to LLMs has emerged as a noteworthy area in this context.... | Jentse Huang, Wenxiang Jiao, Man Ho Lam, Eric John Li, Wenxuan Wang, Michael R. Lyu |  |
| 478 |  |  [Contrastive Entity Coreference and Disambiguation for Historical Texts](https://doi.org/10.18653/v1/2024.emnlp-main.355) |  | 0 | Massive-scale historical document collections are crucial for social science research. Despite increasing digitization, these documents typically lack unique cross-document identifiers for individuals mentioned within the texts, as well as individual identifiers from external knowledge bases like... | Abhishek Arora, Emily Silcock, Melissa Dell, Leander Heldring |  |
| 479 |  |  [Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.356) |  | 0 | Recent advances in instruction-tuned Large Vision-Language Models (LVLMs) have imbued the models with the ability to generate high-level, image-grounded explanations with ease. While such capability is largely attributed to the rich world knowledge contained within the Large Language Models (LLMs),... | Jeonghwan Kim, Heng Ji |  |
| 480 |  |  [Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts](https://doi.org/10.18653/v1/2024.emnlp-main.357) |  | 0 | One useful application of NLP models is to support people in reading complex text from unfamiliar domains (e.g., scientific articles). Simplifying the entire text makes it understandable but sometimes removes important details. On the contrary, helping adult readers understand difficult concepts in... | Sumit Asthana, Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata |  |
| 481 |  |  [VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.358) |  | 0 | As large vision-language models (LVLMs) evolve rapidly, the demand for high-quality and diverse data to align these models becomes increasingly crucial. However, the creation of such data with human supervision proves costly and time-intensive. In this paper, we investigate the efficacy of AI... | Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, Qi Liu |  |
| 482 |  |  [Focused Large Language Models are Stable Many-Shot Learners](https://doi.org/10.18653/v1/2024.emnlp-main.359) |  | 0 | In-Context Learning (ICL) enables large language models (LLMs) to achieve rapid task adaptation by learning from demonstrations. With the increase in available context length of LLMs, recent experiments have shown that the performance of ICL does not necessarily scale well in many-shot... | Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 483 |  |  [Reconsidering Sentence-Level Sign Language Translation](https://doi.org/10.18653/v1/2024.emnlp-main.360) |  | 0 | Historically, sign language machine translation has been posed as a sentence-level task: datasets consisting of continuous narratives are chopped up and presented to the model as isolated clips. In this work, we explore the limitations of this task framing. First, we survey a number of linguistic... | Garrett Tanzer, Maximus Shengelia, Ken Harrenstien, David Uthus |  |
| 484 |  |  [GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities](https://doi.org/10.18653/v1/2024.emnlp-main.361) |  | 0 | Perceiving and understanding non-speech sounds and non-verbal speech is essential to making decisions that help us interact with our surroundings. In this paper, we propose GAMA, a novel General-purpose Large Audio-Language Model (LALM) with Advanced Audio Understanding and Complex Reasoning... | Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S. Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha |  |
| 485 |  |  [Verba volant, scripta volant? Don't worry! There are computational solutions for protoword reconstruction](https://doi.org/10.18653/v1/2024.emnlp-main.362) |  | 0 | We introduce a new database of cognate words and etymons for the five main Romance languages, the most comprehensive one to date. We propose a strong benchmark for the automatic reconstruction of protowords for Romance languages, by applying a set of machine learning models and features on these... | Liviu P. Dinu, Ana Sabina Uban, Alina Maria Cristea, IoanBogdan Iordache, TeodorGeorge Marchitan, Simona Georgescu, Laurentiu Zoicas |  |
| 486 |  |  [ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context](https://doi.org/10.18653/v1/2024.emnlp-main.363) |  | 0 | While the biases of language models in production are extensively documented, the biases of their guardrails have been neglected. This paper studies how contextual information about the user influences the likelihood of an LLM to refuse to execute a request. By generating user biographies that... | Victoria R. Li, Yida Chen, Naomi Saphra |  |
| 487 |  |  [Personas as a Way to Model Truthfulness in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.364) |  | 0 | Large language models (LLMs) are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. While unintuitive from a classic view of LMs, recent work has shown that the truth value of a statement can be elicited from the model’s... | Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung Kim, He He |  |
| 488 |  |  [Satyrn: A Platform for Analytics Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.365) |  | 0 | Large language models (LLMs) are capable of producing documents, and retrieval augmented generation (RAG) has shown itself to be a powerful method for improving accuracy without sacrificing fluency. However, not all information can be retrieved from text. We propose an approach that uses the... | Marko Sterbentz, Cameron Barrie, Shubham Shahi, Abhratanu Dutta, Donna Hooshmand, Harper Pack, Kristian J. Hammond |  |
| 489 |  |  [EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning](https://doi.org/10.18653/v1/2024.emnlp-main.366) |  | 0 | In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked Acoustic Modeling), a novel self-supervised learning approach for speech representation learning. In contrast to the prior methods that use random masking schemes for Masked Acoustic Modeling (MAM), we introduce a novel selective and... | Ashish Seth, Ramaneswaran Selvakumar, S. Sakshi, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha |  |
| 490 |  |  [EPO: Hierarchical LLM Agents with Environment Preference Optimization](https://doi.org/10.18653/v1/2024.emnlp-main.367) |  | 0 | Long-horizon decision-making tasks present significant challenges for LLM-based agents due to the need for extensive planning over multiple steps. In this paper, we propose a hierarchical framework that decomposes complex tasks into manageable subgoals, utilizing separate LLMs for subgoal... | Qi Zhao, Haotian Fu, Chen Sun, George Konidaris |  |
| 491 |  |  [Detection and Measurement of Syntactic Templates in Generated Text](https://doi.org/10.18653/v1/2024.emnlp-main.368) |  | 0 | The diversity of text can be measured beyond word-level features, however existing diversity evaluation focuses primarily on word-level features. Here we propose a method for evaluating diversity over syntactic features to characterize general repetition in models, beyond frequent n-grams.... | Chantal Shaib, Yanai Elazar, Junyi Jessy Li, Byron C. Wallace |  |
| 492 |  |  [UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.369) |  | 0 | Smaller-scale Vision-Language Models (VLMs) often claim to perform on par with larger models in general-domain visual grounding and question-answering benchmarks while offering advantages in computational efficiency and storage. However, their ability to handle rare objects, which fall into the... | Xinyu Pi, Mingyuan Wu, Jize Jiang, Haozhen Zheng, Beitong Tian, ChengXiang Zhai, Klara Nahrstedt, Zhiting Hu |  |
| 493 |  |  [Optimized Speculative Sampling for GPU Hardware Accelerators](https://doi.org/10.18653/v1/2024.emnlp-main.370) |  | 0 | In this work, we optimize speculative sampling for parallel hardware accelerators to improve sampling speed. We notice that substantial portions of the intermediate matrices necessary for speculative sampling can be computed concurrently. This allows us to distribute the workload across multiple... | Dominik Wagner, Seanie Lee, Ilja Baumann, Philipp Seeberger, Korbinian Riedhammer, Tobias Bocklet |  |
| 494 |  |  [Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts](https://doi.org/10.18653/v1/2024.emnlp-main.371) |  | 0 | Personalized large language models (LLMs) aim to tailor interactions, content, and recommendations to individual user preferences. While parameter-efficient fine-tuning (PEFT) methods excel in performance and generalization, they are costly and limit communal benefits when used individually. To... | Zhaoxuan Tan, Zheyuan Liu, Meng Jiang |  |
| 495 |  |  [Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning](https://doi.org/10.18653/v1/2024.emnlp-main.372) |  | 0 | Personalization in large language models (LLMs) is increasingly important, aiming to align the LLMs’ interactions, content, and recommendations with individual user preferences. Recent advances have highlighted effective prompt design by enriching user queries with non-parametric knowledge through... | Zhaoxuan Tan, Qingkai Zeng, Yijun Tian, Zheyuan Liu, Bing Yin, Meng Jiang |  |
| 496 |  |  [Unifying Multimodal Retrieval via Document Screenshot Embedding](https://doi.org/10.18653/v1/2024.emnlp-main.373) |  | 0 | In the real world, documents are organized in different formats and varied modalities. Traditional retrieval pipelines require tailored document parsing techniques and content extraction modules to prepare input for indexing. This process is tedious, prone to errors, and has information loss. To... | Xueguang Ma, ShengChieh Lin, Minghan Li, Wenhu Chen, Jimmy Lin |  |
| 497 |  |  [Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.374) |  | 0 | Training a unified multilingual model promotes knowledge transfer but inevitably introduces negative interference. Language-specific modeling methods show promise in reducing interference. However, they often rely on heuristics to distribute capacity and struggle to foster cross-lingual transfer... | Shaomu Tan, Di Wu, Christof Monz |  |
| 498 |  |  [An Audit on the Perspectives and Challenges of Hallucinations in NLP](https://doi.org/10.18653/v1/2024.emnlp-main.375) |  | 0 | We audit how hallucination in large language models (LLMs) is characterized in peer-reviewed literature, using a critical examination of 103 publications across NLP research. Through the examination of the literature, we identify a lack of agreement with the term ‘hallucination’ in the field of... | Pranav Narayanan Venkit, Tatiana Chakravorti, Vipul Gupta, Heidi Biggs, Mukund Srinath, Koustava Goswami, Sarah Rajtmajer, Shomir Wilson |  |
| 499 |  |  [Discovering Knowledge-Critical Subnetworks in Pretrained Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.376) |  | 0 | Pretrained language models (LMs) encode implicit representations of knowledge in their parameters. However, localizing these representations and disentangling them from each other remains an open problem. In this work, we investigate whether pretrained language models contain various... | Deniz Bayazit, Negar Foroutan, Zeming Chen, Gail Weiss, Antoine Bosselut |  |
| 500 |  |  [Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models](https://doi.org/10.18653/v1/2024.emnlp-main.377) |  | 0 | Significant advancements have recently been made in large language models, represented by GPT models.Users frequently have multi-round private conversations with cloud-hosted GPT models for task optimization.Yet, this operational paradigm introduces additional attack surfaces, particularly in... | Junjie Chu, Zeyang Sha, Michael Backes, Yang Zhang |  |
| 501 |  |  [Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.378) |  | 0 | Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage... | Armin Toroghi, Willis Guo, Mohammad Mahdi Abdollah Pour, Scott Sanner |  |
| 502 |  |  [Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution](https://doi.org/10.18653/v1/2024.emnlp-main.379) |  | 0 | Recent advances in Large Language Models (LLM) have led to substantial interest in their application to commonsense reasoning tasks. Despite their potential, LLMs are susceptible to reasoning errors and hallucinations that may be harmful in use cases where accurate reasoning is critical. This... | Armin Toroghi, Willis Guo, Ali Pesaranghader, Scott Sanner |  |
| 503 |  |  [Understanding and Mitigating Language Confusion in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.380) |  | 0 | We investigate a surprising limitation of LLMs: their inability to consistently generate text in a user’s desired language. We create the Language Confusion Benchmark (LCB) to evaluate such failures, covering 15 typologically diverse languages with existing and newly-created English and... | Kelly Marchisio, WeiYin Ko, Alexandre Berard, Théo Dehaze, Sebastian Ruder |  |
| 504 |  |  [Can Large Language Models Learn Independent Causal Mechanisms?](https://doi.org/10.18653/v1/2024.emnlp-main.381) |  | 0 | Despite impressive performance on language modelling and complex reasoning tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon settings or with distribution shifts, exhibiting a lack of generalisation ability. By contrast, systems such as causal models, that learn abstract... | Gaël Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael J. Witbrock, Gillian Dobbie |  |
| 505 |  |  [MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.382) |  | 0 | This study explores the effectiveness of Large Language Models (LLMs) in creating personalized “mirror stories” that reflect and resonate with individual readers’ identities, addressing the significant lack of diversity in literature. We present MirrorStories, a corpus of 1,500 personalized short... | Sarfaroz Yunusov, Hamza Sidat, Ali Emami |  |
| 506 |  |  [InterIntent: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context](https://doi.org/10.18653/v1/2024.emnlp-main.383) |  | 0 | Large language models (LLMs) have demonstrated the potential to mimic human social intelligence. However, most studies focus on simplistic and static self-report or performance-based tests, which limits the depth and validity of the analysis. In this paper, we developed a novel framework,... | Ziyi Liu, Abhishek Anand, Pei Zhou, Jentse Huang, Jieyu Zhao |  |
| 507 |  |  [Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia](https://doi.org/10.18653/v1/2024.emnlp-main.384) |  | 0 | To explain social phenomena and identify systematic biases, much research in computational social science focuses on comparative text analyses. These studies often rely on coarse corpus-level statistics or local word-level analyses, mainly in English. We introduce the InfoGap method—an efficient... | Farhan Samir, Chan Young Park, Anjalie Field, Vered Shwartz, Yulia Tsvetkov |  |
| 508 |  |  [From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.385) |  | 0 | Despite recent advancements in vision-language models, their performance remains suboptimal on images from non-western cultures due to underrepresentation in training datasets. Various benchmarks have been proposed to test models’ cultural inclusivity. Still, they have limited coverage of cultures... | Mehar Bhatia, Sahithya Ravi, Aditya Chinchure, Eunjeong Hwang, Vered Shwartz |  |
| 509 |  |  [Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation](https://doi.org/10.18653/v1/2024.emnlp-main.386) |  | 0 | Textual style expresses a diverse set of information, including interpersonal dynamics (e.g., formality) and the author’s emotions or attitudes (e.g., disgust). An open question is how language models can be explicitly controlled so that they weave together target styles when generating text: for... | Karin de Langis, Ryan Koo, Dongyeop Kang |  |
| 510 |  |  [MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.387) |  | 0 | Projecting visual features into word embedding space has become a significant fusion strategy adopted by Multimodal Large Language Models (MLLMs). However, its internal mechanisms have yet to be explored. Inspired by multilingual research, we identify domain-specific neurons in multimodal large... | Jiahao Huo, Yibo Yan, Boren Hu, Yutao Yue, Xuming Hu |  |
| 511 |  |  [Learning to Extract Structured Entities Using Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.388) |  | 0 | Recent advances in machine learning have significantly impacted the field of information extraction, with Language Models (LMs) playing a pivotal role in extracting structured information from unstructured text. Prior works typically represent information extraction as triplet-centric and use... | Haolun Wu, Ye Yuan, Liana Mikaelyan, Alexander Meulemans, Xue Liu, James Hensman, Bhaskar Mitra |  |
| 512 |  |  [Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons](https://doi.org/10.18653/v1/2024.emnlp-main.389) |  | 0 | LLM-as-a-judge approaches are a practical and effective way of assessing a range of text tasks. However, when using pairwise comparisons to rank a set of candidates, the computational cost scales quadratically with the number of candidates, which has practical limitations. This paper introduces a... | Adian Liusie, Vatsal Raina, Yassir Fathullah, Mark J. F. Gales |  |
| 513 |  |  [A Survey of AMR Applications](https://doi.org/10.18653/v1/2024.emnlp-main.390) |  | 0 | In the ten years since the development of the Abstract Meaning Representation (AMR) formalism, substantial progress has been made on AMR-related tasks such as parsing and alignment. Still, the engineering applications of AMR are not fully understood. In this survey, we categorize and characterize... | Shira Wein, Juri Opitz |  |
| 514 |  |  [Beyond Embeddings: The Promise of Visual Table in Visual Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.391) |  | 0 | Visual representation learning has been a cornerstone in computer vision, involving typical forms such as visual embeddings, structural symbols, and text-based representations. Despite the success of CLIP-type visual embeddings, they often lack access to world knowledge critical for visual... | Yiwu Zhong, ZiYuan Hu, Michael R. Lyu, Liwei Wang |  |
| 515 |  |  [CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation](https://doi.org/10.18653/v1/2024.emnlp-main.392) |  | 0 | Caregiver strategy classification in pediatric rehabilitation contexts is strongly motivated by real-world clinical constraints but highly under-resourced and seldom studied in natural language processing settings. We introduce a large dataset of 4,037 caregiver strategies in this setting, a... | Shahla Farzana, Ivana Lucero, Vivian Villegas, Vera C. Kaelin, Mary A. Khetani, Natalie Parde |  |
| 516 |  |  [Taylor Unswift: Secured Weight Release for Large Language Models via Taylor Expansion](https://doi.org/10.18653/v1/2024.emnlp-main.393) |  | 0 | Ensuring the security of released large language models (LLMs) poses a significant dilemma, as existing mechanisms either compromise ownership rights or raise data privacy concerns. To address this dilemma, we introduce TaylorMLP to protect the ownership of released LLMs and prevent their abuse.... | Guanchu Wang, YuNeng Chuang, Ruixiang Tang, Shaochen Zhong, Jiayi Yuan, Hongye Jin, Zirui Liu, Vipin Chaudhary, Shuai Xu, James Caverlee, Xia Ben Hu |  |
| 517 |  |  [TimeR⁴ : Time-aware Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.394) |  | 0 | Temporal Knowledge Graph Question Answering (TKGQA) aims to answer temporal questions using knowledge in Temporal Knowledge Graphs (TKGs). Previous works employ pre-trained TKG embeddings or graph neural networks to incorporate the knowledge of TKGs. However, these methods fail to fully understand... | Xinying Qian, Ying Zhang, Yu Zhao, Baohang Zhou, Xuhui Sui, Li Zhang, Kehui Song |  |
| 518 |  |  [Knowledge-Centric Hallucination Detection](https://doi.org/10.18653/v1/2024.emnlp-main.395) |  | 0 | Large Language Models (LLMs) have shown impressive capabilities but also a concerning tendency to hallucinate. This paper presents RefChecker, a framework that introduces claim-triplets to represent claims in LLM responses, aiming to detect fine-grained hallucinations. In RefChecker, an extractor... | Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, Zheng Zhang |  |
| 519 |  |  [Revealing the Parallel Multilingual Learning within Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.396) |  | 0 | Large language models (LLMs) can handle multilingual and cross-lingual text within a single input; however, previous works leveraging multilingualism in LLMs primarily focus on using English as the pivot language to enhance language understanding and reasoning. Given that multiple languages are a... | Yongyu Mu, Peinan Feng, Zhiquan Cao, Yuzhang Wu, Bei Li, Chenglong Wang, Tong Xiao, Kai Song, Tongran Liu, Chunliang Zhang, JingBo Zhu |  |
| 520 |  |  [Automatic Instruction Evolving for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.397) |  | 0 | Fine-tuning large pre-trained language models with Evol-Instruct has achieved encouraging results across a wide range of tasks. However, designing effective evolving methods for instruction evolution requires substantial human expertise. This paper proposes Auto Evol-Instruct, an end-to-end... | Weihao Zeng, Can Xu, Yingxiu Zhao, JianGuang Lou, Weizhu Chen |  |
| 521 |  |  [RepEval: Effective Text Evaluation with LLM Representation](https://doi.org/10.18653/v1/2024.emnlp-main.398) |  | 0 | The era of Large Language Models (LLMs) raises new demands for automatic evaluation metrics, which should be adaptable to various application scenarios while maintaining low cost and effectiveness. Traditional metrics for automatic text evaluation are often tailored to specific scenarios, while... | Shuqian Sheng, Yi Xu, Tianhang Zhang, Zanwei Shen, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xiaoying Gan, Xinbing Wang, Chenghu Zhou |  |
| 522 |  |  [Generative Models for Automatic Medical Decision Rule Extraction from Text](https://doi.org/10.18653/v1/2024.emnlp-main.399) |  | 0 | Medical decision rules play a key role in many clinical decision support systems (CDSS). However, these rules are conventionally constructed by medical experts, which is expensive and hard to scale up. In this study, we explore the automatic extraction of medical decision rules from text, leading... | Yuxin He, Buzhou Tang, Xiaoling Wang |  |
| 523 |  |  [Encoding and Controlling Global Semantics for Long-form Video Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.400) |  | 0 | Seeking answers effectively for long videos is essential to build video question answering (videoQA) systems. Previous methods adaptively select frames and regions from long videos to save computations. However, this fails to reason over the whole sequence of video, leading to sub-optimal... | Thong Nguyen, Zhiyuan Hu, Xiaobao Wu, CongDuy Nguyen, SeeKiong Ng, Anh Tuan Luu |  |
| 524 |  |  [Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.401) |  | 0 | Large language models (LLMs) are susceptible to a type of attack known as jailbreaking, which misleads LLMs to output harmful contents. Although there are diverse jailbreak attack strategies, there is no unified understanding on why some methods succeed and others fail. This paper explores the... | Yuping Lin, Pengfei He, Han Xu, Yue Xing, Makoto Yamada, Hui Liu, Jiliang Tang |  |
| 525 |  |  [Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs](https://doi.org/10.18653/v1/2024.emnlp-main.402) |  | 0 | Legal case retrieval (LCR) aims to provide similar cases as references for a given fact description. This task is crucial for promoting consistent judgments in similar cases, effectively enhancing judicial fairness and improving work efficiency for judges. However, existing works face two main... | Cheng Gao, Chaojun Xiao, Zhenghao Liu, Huimin Chen, Zhiyuan Liu, Maosong Sun |  |
| 526 |  |  [Does Large Language Model Contain Task-Specific Neurons?](https://doi.org/10.18653/v1/2024.emnlp-main.403) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities in comprehensively handling various types of natural language processing (NLP) tasks. However, there are significant differences in the knowledge and abilities required for different tasks. Therefore, it is important to... | Ran Song, Shizhu He, Shuting Jiang, Yantuan Xian, Shengxiang Gao, Kang Liu, Zhengtao Yu |  |
| 527 |  |  [Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.404) |  | 0 |  | Philipp Mondorf, Barbara Plank |  |
| 528 |  |  [Advancing Test-Time Adaptation in Wild Acoustic Test Settings](https://doi.org/10.18653/v1/2024.emnlp-main.405) |  | 0 | Acoustic foundation models, fine-tuned for Automatic Speech Recognition (ASR), suffer from performance degradation in wild acoustic test settings when deployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA) under these conditions remains an open and unexplored question.... | Hongfu Liu, Hengguan Huang, Ye Wang |  |
| 529 |  |  [Learning to Retrieve Iteratively for In-Context Learning](https://doi.org/10.18653/v1/2024.emnlp-main.406) |  | 0 | We introduce iterative retrieval, a novel framework that empowers retrievers to make iterative decisions through policy optimization. Finding an optimal portfolio of retrieved items is a combinatorial optimization problem, generally considered NP-hard. This approach provides a learned approximation... | Yunmo Chen, Tongfei Chen, Harsh Jhamtani, Patrick Xia, Richard Shin, Jason Eisner, Benjamin Van Durme |  |
| 530 |  |  [Taxonomy-guided Semantic Indexing for Academic Paper Search](https://doi.org/10.18653/v1/2024.emnlp-main.407) |  | 0 | Academic paper search is an essential task for efficient literature discovery and scientific advancement. While dense retrieval has advanced various ad-hoc searches, it often struggles to match the underlying academic concepts between queries and documents, which is critical for paper search. To... | SeongKu Kang, Yunyi Zhang, Pengcheng Jiang, Dongha Lee, Jiawei Han, Hwanjo Yu |  |
| 531 |  |  [Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts](https://doi.org/10.18653/v1/2024.emnlp-main.408) |  | 0 | Program of Thoughts (PoT) is an approach characterized by its executable intermediate steps, which ensure the accuracy of the logical calculations in the reasoning process. Currently, PoT primarily uses Python. However, relying solely on a single language may result in suboptimal solutions and... | Xianzhen Luo, Qingfu Zhu, Zhiming Zhang, Libo Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che |  |
| 532 |  |  [Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.409) |  | 0 | Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG). However, GCG struggles with... | Hongfu Liu, Yuxi Xie, Ye Wang, Michael Shieh |  |
| 533 |  |  [Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation](https://doi.org/10.18653/v1/2024.emnlp-main.410) |  | 0 | Although existing fashionable generation methods on Incomplete Utterance Rewriting (IUR) can generate coherent utterances, they often result in the inclusion of irrelevant and redundant tokens in rewritten utterances due to their inability to focus on critical tokens in dialogue context.... | Zhiyu Cao, Peifeng Li, Yaxin Fan, Qiaoming Zhu |  |
| 534 |  |  [FRoG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.411) |  | 0 | Fuzzy reasoning is vital due to the frequent use of imprecise information in daily contexts. However, the ability of current large language models (LLMs) to handle such reasoning remains largely uncharted. In this paper, we introduce a new benchmark, FRoG, for fuzzy reasoning, featuring real-world... | Yiyuan Li, Shichao Sun, Pengfei Liu |  |
| 535 |  |  [Aligning Large Language Models with Diverse Political Viewpoints](https://doi.org/10.18653/v1/2024.emnlp-main.412) |  | 0 | Large language models such as ChatGPT exhibit striking political biases. If users query them about political information, they often take a normative stance. To overcome this, we align LLMs with diverse political viewpoints from 100,000 comments written by candidates running for national parliament... | Dominik Stammbach, Philine Widmer, Eunjung Cho, Caglar Gulcehre, Elliott Ash |  |
| 536 |  |  ["You Gotta be a Doctor, Lin" : An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations](https://doi.org/10.18653/v1/2024.emnlp-main.413) |  | 0 | Social science research has shown that candidates with names indicative of certain races or genders often face discrimination in employment practices. Similarly, Large Language Models (LLMs) have demonstrated racial and gender biases in various applications. In this study, we utilize GPT-3.5-Turbo... | Huy Nghiem, John Prindle, Jieyu Zhao, Hal Daumé III |  |
| 537 |  |  [Extending Context Window of Large Language Models from a Distributional Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.414) |  | 0 | Scaling the rotary position embedding (RoPE) has become a common method for extending the context window of RoPE-based large language models (LLMs). However, existing scaling methods often rely on empirical approaches and lack a profound understanding of the internal distribution within RoPE,... | Yingsheng Wu, Yuxuan Gu, Xiaocheng Feng, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin |  |
| 538 |  |  [Leveraging pre-trained language models for linguistic analysis: A case of argument structure constructions](https://doi.org/10.18653/v1/2024.emnlp-main.415) |  | 0 | This study evaluates the effectiveness of pre-trained language models in identifying argument structure constructions, important for modeling both first and second language learning. We examine three methodologies: (1) supervised training with RoBERTa using a gold-standard ASC treebank, including... | Hakyung Sung, Kristopher Kyle |  |
| 539 |  |  [MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration](https://doi.org/10.18653/v1/2024.emnlp-main.416) |  | 0 | Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating exceptional reasoning, tool usage, and memory capabilities. As their applications expand into multi-agent environments, there arises a need for a comprehensive evaluation framework that captures... | Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, SeeKiong Ng, Jiashi Feng |  |
| 540 |  |  [Position Engineering: Boosting Large Language Models through Positional Information Manipulation](https://doi.org/10.18653/v1/2024.emnlp-main.417) |  | 0 | The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel... | Zhiyuan He, Huiqiang Jiang, Zilong Wang, Yuqing Yang, Luna Qiu, Lili Qiu |  |
| 541 |  |  [Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale](https://doi.org/10.18653/v1/2024.emnlp-main.418) |  | 0 | The rapid development of multimodal large language models (MLLMs), such as GPT-4V, has led to significant advancements. However, these models still face challenges in medical multimodal capabilities due to limitations in the quantity and quality of medical vision-text data, stemming from data... | Junying Chen, Chi Gui, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Chen, Xidong Wang, Zhenyang Cai, Ke Ji, Xiang Wan, Benyou Wang |  |
| 542 |  |  [ADELIE: Aligning Large Language Models on Information Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.419) |  | 0 |  | Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li |  |
| 543 |  |  [Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons](https://doi.org/10.18653/v1/2024.emnlp-main.420) |  | 0 | In this paper, we investigate whether Large Language Models (LLMs) actively recall or retrieve their internal repositories of factual knowledge when faced with reasoning tasks. Through an analysis of LLMs’ internal factual recall at each reasoning step via Knowledge Neurons, we reveal that LLMs... | Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Zeng |  |
| 544 |  |  [Lexically Grounded Subword Segmentation](https://doi.org/10.18653/v1/2024.emnlp-main.421) |  | 0 | We present three innovations in tokenization and subword segmentation. First, we propose to use unsupervised morphological analysis with Morfessor as pre-tokenization. Second, we present an algebraic method for obtaining subword embeddings grounded in a word embedding space. Based on that, we... | Jindrich Libovický, Jindrich Helcl |  |
| 545 |  |  [EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees](https://doi.org/10.18653/v1/2024.emnlp-main.422) |  | 0 | Inference with modern Large Language Models (LLMs) is expensive and time-consuming, and speculative sampling has proven to be an effective solution. Most speculative sampling methods such as EAGLE use a static draft tree, implicitly assuming that the acceptance rate of draft tokens depends only on... | Yuhui Li, Fangyun Wei, Chao Zhang, Hongyang Zhang |  |
| 546 |  |  [Do Text-to-Vis Benchmarks Test Real Use of Visualisations?](https://doi.org/10.18653/v1/2024.emnlp-main.423) |  | 0 | Large language models are able to generate code for visualisations in response to simple user requests.This is a useful application and an appealing one for NLP research because plots of data provide grounding for language.However, there are relatively few benchmarks, and those that exist may not... | Hy Nguyen, Xuefei He, Andrew Reeson, Cécile Paris, Josiah Poon, Jonathan K. Kummerfeld |  |
| 547 |  |  [Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.424) |  | 0 | While Large Language Models (LLMs) demonstrate impressive generation abilities, they frequently struggle when it comes to specialized domains due to their limited domain-specific knowledge. Studies on domain-specific LLMs resort to expanding the vocabulary before fine-tuning on domain-specific... | Chengyuan Liu, Shihang Wang, Lizhi Qing, Kun Kuang, Yangyang Kang, Changlong Sun, Fei Wu |  |
| 548 |  |  [Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning](https://doi.org/10.18653/v1/2024.emnlp-main.425) |  | 0 | Recent studies highlight the effectiveness of using in-context learning (ICL) to steer large language models (LLMs) in processing tabular data, a challenging task given the structured nature of such data. Despite advancements in performance, the fairness implications of these methods are less... | Jingyu Hu, Weiru Liu, Mengnan Du |  |
| 549 |  |  [Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges](https://doi.org/10.18653/v1/2024.emnlp-main.426) |  | 0 | Vietnamese, a low-resource language, is typically categorized into three primary dialect groups that belong to Northern, Central, and Southern Vietnam. However, each province within these regions exhibits its own distinct pronunciation variations. Despite the existence of various speech recognition... | Nguyen Dinh, Thanh Dang, Luan Thanh Nguyen, Kiet Van Nguyen |  |
| 550 |  |  [Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment](https://doi.org/10.18653/v1/2024.emnlp-main.427) |  | 0 | Large Language Models (LLMs) are powerful zero-shot assessors used in real-world situations such as assessing written exams and benchmarking systems. Despite these critical applications, no existing work has analyzed the vulnerability of judge-LLMs to adversarial manipulation. This work presents... | Vyas Raina, Adian Liusie, Mark J. F. Gales |  |
| 551 |  |  [Rethinking the Reversal Curse of LLMs: a Prescription from Human Knowledge Reversal](https://doi.org/10.18653/v1/2024.emnlp-main.428) |  | 0 | Large Language Models (LLMs) have exhibited exceptional performance across diverse domains. However, recent studies reveal that LLMs are plagued by the “reversal curse”. Most existing methods rely on aggressive sample permutation and pay little attention to delving into the underlying reasons for... | Zhicong Lu, Li Jin, Peiguang Li, Yu Tian, Linhao Zhang, Sirui Wang, Guangluan Xu, Changyuan Tian, Xunliang Cai |  |
| 552 |  |  [More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.429) |  | 0 | The performance on general tasks decreases after Large Language Models (LLMs) are fine-tuned on domain-specific tasks, the phenomenon is known as Catastrophic Forgetting (CF). However, this paper presents a further challenge for real application of domain-specific LLMs beyond CF, called General... | Chengyuan Liu, Yangyang Kang, Shihang Wang, Lizhi Qing, Fubang Zhao, Chao Wu, Changlong Sun, Kun Kuang, Fei Wu |  |
| 553 |  |  [Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models](https://doi.org/10.18653/v1/2024.emnlp-main.430) |  | 0 |  | Vyas Raina, Rao Ma, Charles McGhee, Kate M. Knill, Mark J. F. Gales |  |
| 554 |  |  [GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation](https://doi.org/10.18653/v1/2024.emnlp-main.431) |  | 0 | Large Language Models (LLMs) have been shown to effectively perform zero-shot document retrieval, a process that typically consists of two steps: i) retrieving relevant documents, and ii) re-ranking them based on their relevance to the query. This paper presents GENRA, a new approach to zero-shot... | Georgios Katsimpras, Georgios Paliouras |  |
| 555 |  |  [XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.432) |  | 0 | Large Language Models (LLMs) have achieved remarkable success in natural language tasks, yet understanding their reasoning processes remains a significant challenge. We address this by introducing XplainLLM, a dataset accompanying an explanation framework designed to enhance LLM transparency and... | Zichen Chen, Jianda Chen, Ambuj K. Singh, Misha Sra |  |
| 556 |  |  [Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.433) |  | 0 | The automation of radiology report generation (RRG) holds immense potential to alleviate radiologists’ workloads and improve diagnostic accuracy. Despite advancements in image captioning and vision-language pretraining, RRG remains challenging due to the lengthy and complex nature of radiology... | Yuanpin Zhou, Huogen Wang |  |
| 557 |  |  [SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information](https://doi.org/10.18653/v1/2024.emnlp-main.434) |  | 0 | Large Vision-Language Models (LVLMs) have become pivotal at the intersection of computer vision and natural language processing. However, the full potential of LVLMs’ Retrieval-Augmented Generation (RAG) capabilities remains underutilized. Existing works either focus solely on the text modality or... | Jiashuo Sun, Jihai Zhang, Yucheng Zhou, Zhaochen Su, Xiaoye Qu, Yu Cheng |  |
| 558 |  |  [UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.435) |  | 0 | Sequential decision-making refers to algorithms that take into account the dynamics of the environment, where early decisions affect subsequent decisions. With large language models (LLMs) demonstrating powerful capabilities between tasks, we can’t help but ask: Can Current LLMs Effectively Make... | Zhanyue Qin, Haochuan Wang, Deyuan Liu, Ziyang Song, Cunhang Fan, Zhao Lv, Jinlin Wu, Zhen Lei, Zhiying Tu, Dianhui Chu, Xiaoyan Yu, Dianbo Sui |  |
| 559 |  |  [Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments](https://doi.org/10.18653/v1/2024.emnlp-main.436) |  | 0 | The applications of large language models (LLMs) have expanded well beyond the confines of text processing, signaling a new era where LLMs are envisioned as generalist agents capable of operating within complex environments. These environments are often highly expansive, making it impossible for... | Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su |  |
| 560 |  |  [MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space](https://doi.org/10.18653/v1/2024.emnlp-main.437) |  | 0 | Personalized Dialogue Generation (PDG) aims to create coherent responses according to roles or personas. Traditional PDG relies on external role data, which can be scarce and raise privacy concerns. Approaches address these issues by extracting role information from dialogue history, which often... | Yihong Tang, Bo Wang, Dongming Zhao, Jinxiaojia Jinxiaojia, Zhangjijun Zhangjijun, Ruifang He, Yuexian Hou |  |
| 561 |  |  [KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server](https://doi.org/10.18653/v1/2024.emnlp-main.438) |  | 0 | The success of large language models (LLMs) facilitate many parties to fine-tune LLMs on their own private data. However, this practice raises privacy concerns due to the memorization of LLMs. Existing solutions, such as utilizing synthetic data for substitution, struggle to simultaneously improve... | Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang |  |
| 562 |  |  [DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination](https://doi.org/10.18653/v1/2024.emnlp-main.439) |  | 0 | Despite the great success of Large Vision-Language Models (LVLMs), they inevitably suffer from hallucination. As we know, both the visual encoder and the Large Language Model (LLM) decoder in LVLMs are Transformer-based, allowing the model to extract visual information and generate text outputs via... | Xuan Gong, Tianshi Ming, Xinpeng Wang, Zhihua Wei |  |
| 563 |  |  [Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.440) |  | 0 | Planning, as the core module of agents, is crucial in various fields such as embodied agents, web navigation, and tool using. With the development of large language models (LLMs), some researchers treat large language models as intelligent agents to stimulate and evaluate their planning... | Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao |  |
| 564 |  |  [Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale](https://doi.org/10.18653/v1/2024.emnlp-main.441) |  | 0 | In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this paper, we explores an alternative approach to... | Wenzhen Zheng, Wenbo Pan, Xu Xu, Libo Qin, Li Yue, Ming Zhou |  |
| 565 |  |  [An Empirical Study of Multilingual Reasoning Distillation for Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.442) |  | 0 | Reasoning is one crucial capability in Large Language Models (LLMs), allowing them to perform complex tasks such as solving math problems and multi-step planning. While reasoning capability can emerge in larger models, smaller ones usually have to rely on distillation to transfer this capability... | Patomporn Payoungkhamdee, Peerat Limkonchotiwat, Jinheon Baek, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 566 |  |  [Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?](https://doi.org/10.18653/v1/2024.emnlp-main.443) |  | 0 | We posit that large language models (LLMs) should be capable of expressing their intrinsic uncertainty in natural language. For example, if the LLM is equally likely to output two contradicting answers to the same question, then its generated response should reflect this uncertainty by hedging its... | Gal Yona, Roee Aharoni, Mor Geva |  |
| 567 |  |  [Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?](https://doi.org/10.18653/v1/2024.emnlp-main.444) |  | 0 | When large language models are aligned via supervised fine-tuning, they may encounter new factual information that was not acquired through pre-training. It is often conjectured that this can teach the model the behavior of hallucinating factually incorrect responses, as the model is trained to... | Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig |  |
| 568 |  |  [Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning](https://doi.org/10.18653/v1/2024.emnlp-main.445) |  | 0 | The widespread presence of hate speech on the internet, including formats such as text-based tweets and multimodal memes, poses a significant challenge to digital platform safety. Recent research has developed detection models tailored to specific modalities; however, there is a notable gap in... | Ming Shan Hee, Aditi Kumaresan, Roy KaWei Lee |  |
| 569 |  |  [MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.446) |  | 0 | Improving user experience and providing personalized search results in E-commerce platforms heavily rely on understanding purchase intention. However, existing methods for acquiring large-scale intentions bank on distilling large language models with human annotation for verification. Such an... | Baixuan Xu, Weiqi Wang, Haochen Shi, Wenxuan Ding, Huihao Jing, Tianqing Fang, Jiaxin Bai, Xin Liu, Changlong Yu, Zheng Li, Chen Luo, Qingyu Yin, Bing Yin, Long Chen, Yangqiu Song |  |
| 570 |  |  [ECON: On the Detection and Resolution of Evidence Conflicts](https://doi.org/10.18653/v1/2024.emnlp-main.447) |  | 0 | The rise of large language models (LLMs) has significantly influenced the quality of information in decision-making systems, leading to the prevalence of AI-generated content and challenges in detecting misinformation and managing conflicting information, or “inter-evidence conflicts.” This study... | Cheng Jiayang, Chunkit Chan, Qianqian Zhuang, Lin Qiu, Tianhang Zhang, Tengxiao Liu, Yangqiu Song, Yue Zhang, Pengfei Liu, Zheng Zhang |  |
| 571 |  |  ["Image, Tell me your story!" Predicting the original meta-context of visual misinformation](https://doi.org/10.18653/v1/2024.emnlp-main.448) |  | 0 | To assist human fact-checkers, researchers have developed automated approaches for visual misinformation detection. These methods assign veracity scores by identifying inconsistencies between the image and its caption, or by detecting forgeries in the image. However, they neglect a crucial point of... | Jonathan Tonglet, MarieFrancine Moens, Iryna Gurevych |  |
| 572 |  |  [Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning](https://doi.org/10.18653/v1/2024.emnlp-main.449) |  | 0 |  | Zhili Shen, Pavlos Vougiouklis, Chenxin Diao, Kaustubh Vyas, Yuanyi Ji, Jeff Z. Pan |  |
| 573 |  |  [Mixture-of-Subspaces in Low-Rank Adaptation](https://doi.org/10.18653/v1/2024.emnlp-main.450) |  | 0 | In this paper, we introduce a subspace-inspired Low-Rank Adaptation (LoRA) method, which is computationally efficient, easy to implement, and readily applicable to large language, multimodal, and diffusion models. Initially, we equivalently decompose the weights of LoRA into two subspaces, and find... | Taiqiang Wu, Jiahao Wang, Zhe Zhao, Ngai Wong |  |
| 574 |  |  [PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data](https://doi.org/10.18653/v1/2024.emnlp-main.451) |  | 0 | Evaluation of multilingual Large Language Models (LLMs) is challenging due to a variety of factors – the lack of benchmarks with sufficient linguistic diversity, contamination of popular benchmarks into LLM pre-training data and the lack of local, cultural nuances in translated benchmarks. In this... | Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri, Manohar Swaminathan, Sunayana Sitaram |  |
| 575 |  |  [LawBench: Benchmarking Legal Knowledge of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.452) |  | 0 | We present LawBench, the first evaluation benchmark composed of 20 tasks aimed to assess the ability of Large Language Models (LLMs) to perform Chinese legal-related tasks. LawBench is meticulously crafted to enable precise assessment of LLMs’ legal capabilities from three cognitive levels that... | Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Alan Huang, Songyang Zhang, Kai Chen, Zhixin Yin, Zongwen Shen, Jidong Ge, Vincent Ng |  |
| 576 |  |  [Efficient Performance Tracking: Leveraging Large Language Models for Automated Construction of Scientific Leaderboards](https://doi.org/10.18653/v1/2024.emnlp-main.453) |  | 0 | Scientific leaderboards are standardized ranking systems that facilitate evaluating and comparing competitive methods. Typically, a leaderboard is defined by a task, dataset, and evaluation metric (TDM) triple, allowing objective performance assessment and fostering innovation through benchmarking.... | Furkan Sahinuç, Thy Thy Tran, Yulia Grishina, Yufang Hou, Bei Chen, Iryna Gurevych |  |
| 577 |  |  [Efficient Vision-Language pre-training via domain-specific learning for human activities](https://doi.org/10.18653/v1/2024.emnlp-main.454) |  | 0 | Current Vision-Language (VL) models owe their success to large-scale pre-training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are known in advance, which is in practice common, the... | Adrian Bulat, Yassine Ouali, Ricardo Guerrero, Brais Martínez, Georgios Tzimiropoulos |  |
| 578 |  |  [Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training](https://doi.org/10.18653/v1/2024.emnlp-main.455) |  | 0 | Diffusion-based text-to-image models have demonstrated impressive achievements in diversity and aesthetics but struggle to generate images with legible visual texts. Existing backbone models have limitations such as misspelling, failing to generate texts, and lack of support for Chinese texts, but... | Wenbo Li, Guohao Li, Zhibin Lan, Xue Xu, Wanru Zhuang, Jiachen Liu, Xinyan Xiao, Jinsong Su |  |
| 579 |  |  [Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works](https://doi.org/10.18653/v1/2024.emnlp-main.456) |  | 0 | Large language models (LLMs) have demonstrated impressive performance and spurred numerous AI applications, in which role-playing agents (RPAs) are particularly popular, especially for fictional characters. The prerequisite for these RPAs lies in the capability of LLMs to understand characters from... | Xinfeng Yuan, Siyu Yuan, Yuhan Cui, Tianhe Lin, Xintao Wang, Rui Xu, Jiangjie Chen, Deqing Yang |  |
| 580 |  |  [Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners](https://doi.org/10.18653/v1/2024.emnlp-main.457) |  | 0 | Recently, Large Language Models (LLMs) have shown impressive language capabilities, while most of them have very unbalanced performance across different languages. Multilingual alignment based on the translation parallel data is an effective method to enhance LLMs’ multilingual capabilities. In... | Shimao Zhang, Changjiang Gao, Wenhao Zhu, Jiajun Chen, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang |  |
| 581 |  |  [AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning](https://doi.org/10.18653/v1/2024.emnlp-main.458) |  | 0 | Recent advancements in large language models (LLMs) have been remarkable. Users face a choice between using cloud-based LLMs for generation quality and deploying local-based LLMs for lower computational cost. The former option is typically costly and inefficient, while the latter usually fails to... | Hao Sun, Jiayi Wu, Hengyi Cai, Xiaochi Wei, Yue Feng, Bo Wang, Shuaiqiang Wang, Yan Zhang, Dawei Yin |  |
| 582 |  |  [CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.459) |  | 0 | Multi-task learning (MTL) benefits the fine-tuning of large language models (LLMs) by providing a single model with improved performance and generalization ability across tasks, presenting a resource-efficient alternative to developing separate models for each task. Yet, existing MTL strategies for... | Zi Gong, Hang Yu, Cong Liao, Bingchang Liu, Chaoyu Chen, Jianguo Li |  |
| 583 |  |  [mDPO: Conditional Preference Optimization for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.460) |  | 0 | Direct preference optimization (DPO) has shown to be an effective method for large language model (LLM) alignment. Recent works have attempted to apply DPO to multimodal scenarios but have found it challenging to achieve consistent improvement. Through a comparative experiment, we identify the... | Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen |  |
| 584 |  |  [Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.461) |  | 0 | Data are crucial element in large language model (LLM) alignment. Recent studies have explored using LLMs for efficient data collection. However, LLM-generated data often suffers from quality issues, with underrepresented or absent aspects and low-quality datapoints. To address these problems, we... | Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, KaiWei Chang, Aram Galstyan |  |
| 585 |  |  [Language-to-Code Translation with a Single Labeled Example](https://doi.org/10.18653/v1/2024.emnlp-main.462) |  | 0 | Tools for translating natural language into code promise natural, open-ended interaction with databases, web APIs, and other software systems. However, this promise is complicated by the diversity and continual development of these systems, each with its own interface and distinct set of features.... | Kaj Bostrom, Harsh Jhamtani, Hao Fang, Sam Thomson, Richard Shin, Patrick Xia, Benjamin Van Durme, Jason Eisner, Jacob Andreas |  |
| 586 |  |  [Attribute or Abstain: Large Language Models as Long Document Assistants](https://doi.org/10.18653/v1/2024.emnlp-main.463) |  | 0 | LLMs can help humans working with long documents, but are known to hallucinate. \*Attribution\* can increase trust in LLM responses: The LLM provides evidence that supports its response, which enhances verifiability. Existing approaches to attribution have only been evaluated in RAG settings, where... | Jan Buchmann, Xiao Liu, Iryna Gurevych |  |
| 587 |  |  [FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models](https://doi.org/10.18653/v1/2024.emnlp-main.464) |  | 0 | Foundation models have demonstrated remarkable capabilities in handling diverse modalities and tasks, outperforming conventional artificial intelligence (AI) approaches that are highly task-specific and modality-reliant. In the medical domain, however, the development of comprehensive foundation... | Xiaochen Wang, Jiaqi Wang, Houping Xiao, Jinghui Chen, Fenglong Ma |  |
| 588 |  |  [Retrieved In-Context Principles from Previous Mistakes](https://doi.org/10.18653/v1/2024.emnlp-main.465) |  | 0 | In-context learning (ICL) has been instrumental in adapting large language models (LLMs) to downstream tasks using correct input-output examples. Recent advances have attempted to improve model performance through principles derived from mistakes, yet these approaches suffer from lack of... | Hao Sun, Yong Jiang, Bo Wang, Yingyan Hou, Yan Zhang, Pengjun Xie, Fei Huang |  |
| 589 |  |  [EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control](https://doi.org/10.18653/v1/2024.emnlp-main.466) |  | 0 | While recent advances in Text-to-Speech (TTS) technology produce natural and expressive speech, they lack the option for users to select emotion and control intensity. We propose EmoKnob, a framework that allows fine-grained emotion control in speech synthesis with few-shot demonstrative samples of... | Haozhe Chen, Run Chen, Julia Hirschberg |  |
| 590 |  |  [VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.467) |  | 0 | Scaling model size significantly challenges the deployment and inference of Large Language Models (LLMs). Due to the redundancy in LLM weights, recent research has focused on pushing weight-only quantization to extremely low-bit (even down to 2 bits). It reduces memory requirements, optimizes... | Yifei Liu, Jicheng Wen, Yang Wang, Shengyu Ye, Li Lyna Zhang, Ting Cao, Cheng Li, Mao Yang |  |
| 591 |  |  [An L\* Algorithm for Deterministic Weighted Regular Languages](https://doi.org/10.18653/v1/2024.emnlp-main.468) |  | 0 | Extracting finite state automata (FSAs) fromblack-box models offers a powerful approachto gaining interpretable insights into complexmodel behaviors. To support this pursuit, wepresent a weighted variant of Angluin’s (1987)L\* algorithm for learning FSAs. We stay faithful to the original... | Clemente Pasti, Talu Karagöz, Franz Nowak, Anej Svete, Reda Boumasmoud, Ryan Cotterell |  |
| 592 |  |  [Towards Verifiable Text Generation with Evolving Memory and Self-Reflection](https://doi.org/10.18653/v1/2024.emnlp-main.469) |  | 0 | Despite the remarkable ability of large language models (LLMs) in language comprehension and generation, they often suffer from producing factually incorrect information, also known as hallucination. A promising solution to this issue is verifiable text generation, which prompts LLMs to generate... | Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin |  |
| 593 |  |  [Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification](https://doi.org/10.18653/v1/2024.emnlp-main.470) |  | 0 | Large Visual Language Models (LVLMs) struggle with hallucinations in visual instruction following task(s). These issues hinder their trustworthiness and real-world applicability. We propose Pelican – a novel framework designed to detect and mitigate hallucinations through claim verification.... | Pritish Sahu, Karan Sikka, Ajay Divakaran |  |
| 594 |  |  [Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes](https://doi.org/10.18653/v1/2024.emnlp-main.471) |  | 0 | We tackle societal bias in image-text datasets by removing spurious correlations between protected groups and image attributes. Traditional methods only target labeled attributes, ignoring biases from unlabeled ones. Using text-guided inpainting models, our approach ensures protected group... | Yusuke Hirota, Jerone Theodore Alexander Andrews, Dora Zhao, Orestis Papakyriakopoulos, Apostolos Modas, Yuta Nakashima, Alice Xiang |  |
| 595 |  |  [RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?](https://doi.org/10.18653/v1/2024.emnlp-main.472) |  | 0 | The latest advancements in large language models (LLMs) have sparked interest in their potential for software vulnerability detection. However, there is currently a lack of research specifically focused on vulnerabilities in the PHP language, and challenges in data sampling and processing persist,... | Di Cao, Yong Liao, Xiuwei Shang |  |
| 596 |  |  [Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel](https://doi.org/10.18653/v1/2024.emnlp-main.473) |  | 0 | Training task-oriented dialogue systems typically requires turn-level annotations for interacting with their APIs: e.g. a dialogue state and the system actions taken at each step. These annotations can be costly to produce, error-prone, and require both domain and annotation expertise. With... | Brendan King, Jeffrey Flanigan |  |
| 597 |  |  [Humans or LLMs as the Judge? A Study on Judgement Bias](https://doi.org/10.18653/v1/2024.emnlp-main.474) |  | 0 | Adopting human and large language models (LLM) as judges (\*a.k.a\* human- and LLM-as-a-judge) for evaluating the performance of LLMs has recently gained attention. Nonetheless, this approach concurrently introduces potential biases from human and LLMs, questioning the reliability of the evaluation... | Guiming Chen, Shunian Chen, Ziche Liu, Feng Jiang, Benyou Wang |  |
| 598 |  |  [WPO: Enhancing RLHF with Weighted Preference Optimization](https://doi.org/10.18653/v1/2024.emnlp-main.475) |  | 0 | Reinforcement learning from human feedback (RLHF) is a promising solution to align large language models (LLMs) more closely with human values. Off-policy preference optimization, where the preference data is obtained from other models, is widely adopted due to its cost efficiency and scalability.... | Wenxuan Zhou, Ravi Agrawal, Shujian Zhang, Sathish Reddy Indurthi, Sanqiang Zhao, Kaiqiang Song, Silei Xu, Chenguang Zhu |  |
| 599 |  |  [Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias](https://doi.org/10.18653/v1/2024.emnlp-main.476) |  | 0 | The common toxicity and societal bias in contents generated by large language models (LLMs) necessitate strategies to reduce harm. Present solutions often demand white-box access to the model or substantial training, which is impractical for cutting-edge commercial LLMs. Moreover, prevailing... | Rongwu Xu, Zi'an Zhou, Tianwei Zhang, Zehan Qi, Su Yao, Ke Xu, Wei Xu, Han Qiu |  |
| 600 |  |  [MetaReflection: Learning Instructions for Language Agents using Past Reflections](https://doi.org/10.18653/v1/2024.emnlp-main.477) |  | 0 | The popularity of Large Language Models (LLMs) have unleashed a new age of Language Agents for solving a diverse range of tasks. While contemporary frontier LLMs are capable enough to power reasonably good Language agents, the closed-API model makes it hard to improve in cases they perform... | Priyanshu Gupta, Shashank Kirtania, Ananya Singha, Sumit Gulwani, Arjun Radhakrishna, Gustavo Soares, Sherry Shi |  |
| 601 |  |  [Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors](https://doi.org/10.18653/v1/2024.emnlp-main.478) |  | 0 | Large language models (LLMs) offer many opportunities to scale high-quality personalized tutoring. A promising approach is to build dialog tutoring models to scaffold students’ problem-solving. However, even though existing models perform well in solving reasoning questions, they can struggle to... | Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan |  |
| 602 |  |  [On Eliciting Syntax from Language Models via Hashing](https://doi.org/10.18653/v1/2024.emnlp-main.479) |  | 0 | Unsupervised parsing, also known as grammar induction, aims to infer syntactic structure from raw text. Recently, binary representation has exhibited remarkable information-preserving capabilities at both lexicon and syntax levels. In this paper, we explore the possibility of leveraging this... | Yiran Wang, Masao Utiyama |  |
| 603 |  |  [CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios](https://doi.org/10.18653/v1/2024.emnlp-main.480) |  | 0 | With the proliferation of Large Language Models (LLMs) in diverse domains, there is a particular need for unified evaluation standards in clinical medical scenarios, where models need to be examined very thoroughly. We present CliMedBench, a comprehensive benchmark with 14 expert-guided core... | Zetian Ouyang, Yishuai Qiu, Linlin Wang, Gerard de Melo, Ya Zhang, Yanfeng Wang, Liang He |  |
| 604 |  |  [The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples](https://doi.org/10.18653/v1/2024.emnlp-main.481) |  | 0 | Recent studies have revealed the vulnerability of pre-trained language models to adversarial attacks. Adversarial defense techniques have been proposed to reconstruct adversarial examples within feature or text spaces. However, these methods struggle to effectively repair the semantics in... | Heng Yang, Ke Li |  |
| 605 |  |  [CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages](https://doi.org/10.18653/v1/2024.emnlp-main.482) |  | 0 | Neural dependency parsing has achieved remarkable performance for low resource morphologically rich languages. It has also been well-studied that morphologically rich languages exhibit relatively free word order. This prompts a fundamental investigation: Is there a way to enhance dependency parsing... | Pretam Ray, Jivnesh Sandhan, Amrith Krishna, Pawan Goyal |  |
| 606 |  |  [Perceptions of Linguistic Uncertainty by Language Models and Humans](https://doi.org/10.18653/v1/2024.emnlp-main.483) |  | 0 | \*Uncertainty expressions\* such as ‘probably’ or ‘highly unlikely’ are pervasive in human language. While prior work has established that there is population-level agreement in terms of how humans quantitatively interpret these expressions, there has been little inquiry into the abilities of... | Catarina G. Belém, Markelle Kelly, Mark Steyvers, Sameer Singh, Padhraic Smyth |  |
| 607 |  |  [Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM](https://doi.org/10.18653/v1/2024.emnlp-main.484) |  | 0 | Contrastive decoding (CD) (Li et al., 2022) improves the next-token distribution of a large expert language model (LM) using a small amateur LM. Although CD is applied to various LMs and domains to enhance open-ended text generation, it is still unclear why CD often works well, when it could fail,... | HawShiuan Chang, Nanyun Peng, Mohit Bansal, Anil Ramakrishna, Tagyoung Chung |  |
| 608 |  |  [Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.485) |  | 0 | Zero-shot cross-domain dialogue state tracking (DST) enables us to manage task-oriented dialogues in new, unseen domains without the cost of collecting in-domain data. Previous studies have implemented slot-based input improvements, such as schema-driven descriptions and question-answering formats,... | Xiaoyu Dong, Yujie Feng, Zexin Lu, Guangyuan Shi, XiaoMing Wu |  |
| 609 |  |  [Knowledge Conflicts for LLMs: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.486) |  | 0 | This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and... | Rongwu Xu, Zehan Qi, Zhijiang Guo, Cunxiang Wang, Hongru Wang, Yue Zhang, Wei Xu |  |
| 610 |  |  [MisinfoEval: Generative AI in the Era of "Alternative Facts"](https://doi.org/10.18653/v1/2024.emnlp-main.487) |  | 0 | The spread of misinformation on social media platforms threatens democratic processes, contributes to massive economic losses, and endangers public health. Many efforts to address misinformation focus on a knowledge deficit model and propose interventions for improving users’ critical thinking... | Saadia Gabriel, Liang Lyu, James Siderius, Marzyeh Ghassemi, Jacob Andreas, Asuman E. Ozdaglar |  |
| 611 |  |  [MEANT: Multimodal Encoder for Antecedent Information](https://doi.org/10.18653/v1/2024.emnlp-main.488) |  | 0 | The stock market provides a rich well of information that can be split across modalities, making it an ideal candidate for multimodal evaluation. Multimodal data plays an increasingly important role in the development of machine learning and has shown to positively impact performance. But... | Benjamin Irving, Annika Marie Schoene |  |
| 612 |  |  [A Thorough Examination of Decoding Methods in the Era of LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.489) |  | 0 | Decoding methods play an indispensable role in converting language models from next-token predictors into practical task solvers. Prior research on decoding methods, primarily focusing on task-specific models, may not extend to the current era of general-purpose large language models (LLMs).... | Chufan Shi, Haoran Yang, Deng Cai, Zhisong Zhang, Yifan Wang, Yujiu Yang, Wai Lam |  |
| 613 |  |  [AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings](https://doi.org/10.18653/v1/2024.emnlp-main.490) |  | 0 | Ranking is a fundamental problem in search, however, existing ranking algorithms usually restrict the granularity of ranking to full passages or require a specific dense index for each desired level of granularity. Such lack of flexibility in granularity negatively affects many applications that... | Revanth Gangi Reddy, Omar Attia, Yunyao Li, Heng Ji, Saloni Potdar |  |
| 614 |  |  [FIRST: Faster Improved Listwise Reranking with Single Token Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.491) |  | 0 | Large Language Models (LLMs) have significantly advanced the field of information retrieval, particularly for reranking. Listwise LLM rerankers have showcased superior performance and generalizability compared to existing supervised approaches. However, conventional listwise LLM reranking methods... | Revanth Gangi Reddy, JaeHyeok Doo, Yifei Xu, Md. Arafat Sultan, Deevya Swain, Avirup Sil, Heng Ji |  |
| 615 |  |  [Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights](https://doi.org/10.18653/v1/2024.emnlp-main.492) |  | 0 | Nested Named Entity Recognition (NER) poses a significant challenge in Natural Language Processing (NLP), demanding sophisticated techniques to identify entities within entities. This research investigates the application of Large Language Models (LLMs) to nested NER, exploring methodologies from... | Hongjin Kim, JaiEun Kim, Harksoo Kim |  |
| 616 |  |  [ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods](https://doi.org/10.18653/v1/2024.emnlp-main.493) |  | 0 | The rapid scaling of large language models (LLMs) has raised concerns about the transparency and fair use of the data used in their pretraining. Detecting such content is challenging due to the scale of the data and limited exposure of each instance during training. We propose ReCaLL (Relative... | Roy Xie, Junlin Wang, Ruomin Huang, Minxing Zhang, Rong Ge, Jian Pei, Neil Gong, Bhuwan Dhingra |  |
| 617 |  |  ["Flex Tape Can't Fix That": Bias and Misinformation in Edited Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.494) |  | 0 | Weight-based model editing methods update the parametric knowledge of language models post-training. However, these methods can unintentionally alter unrelated parametric knowledge representations, potentially increasing the risk of harm. In this work, we investigate how weight editing methods... | Karina Halevy, Anna Sotnikova, Badr AlKhamissi, Syrielle Montariol, Antoine Bosselut |  |
| 618 |  |  [Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.495) |  | 0 | This paper investigates Who’s Harry Potter (WHP), a pioneering yet insufficiently understood method for LLM unlearning. We explore it in two steps. First, we introduce a new task of LLM targeted unlearning, where given an unlearning target (e.g., a person) and some unlearning documents, we aim to... | Yujian Liu, Yang Zhang, Tommi S. Jaakkola, Shiyu Chang |  |
| 619 |  |  [LIONs: An Empirically Optimized Approach to Align Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.496) |  | 0 | Alignment is a crucial step to enhance the instruction-following and conversational abilities of language models. Despite many recent works proposing new algorithms, datasets, and training pipelines, there is a lack of comprehensive studies measuring the impact of various design choices throughout... | Xiao Yu, Qingyang Wu, Yu Li, Zhou Yu |  |
| 620 |  |  [Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing](https://doi.org/10.18653/v1/2024.emnlp-main.497) |  | 0 | This paper explores the utilization of LLMs for data preprocessing (DP), a crucial step in the data mining pipeline that transforms raw data into a clean format. We instruction-tune local LLMs as universal DP task solvers that operate on a local, single, and low-priced GPU, ensuring data security... | Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada |  |
| 621 |  |  [A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery](https://doi.org/10.18653/v1/2024.emnlp-main.498) |  | 0 | In many scientific fields, large language models (LLMs) have revolutionized the way text and other modalities of data (e.g., molecules and proteins) are handled, achieving superior performance in various applications and augmenting the scientific discovery process. Nevertheless, previous surveys on... | Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han |  |
| 622 |  |  [MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents](https://doi.org/10.18653/v1/2024.emnlp-main.499) |  | 0 | Recognizing if LLM output can be grounded in evidence is central to many tasks in NLP: retrieval-augmented generation, summarization, document-grounded dialogue, and more. Current approaches to this kind of fact-checking are based on verifying each piece of a model generation against potential... | Liyan Tang, Philippe Laban, Greg Durrett |  |
| 623 |  |  [Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning](https://doi.org/10.18653/v1/2024.emnlp-main.500) |  | 0 | Medical coding, the translation of unstructured clinical text into standardized medical codes, is a crucial but time-consuming healthcare practice. Though large language models (LLM) could automate the coding process and improve the efficiency of such tasks, interpretability remains paramount for... | John Wu, David Wu, Jimeng Sun |  |
| 624 |  |  [MOSEL: Inference Serving Using Dynamic Modality Selection](https://doi.org/10.18653/v1/2024.emnlp-main.501) |  | 0 | Rapid advancements over the years have helped machine learning models reach previously hard-to-achieve goals, sometimes even exceeding human capabilities. However, achieving desired accuracy comes at the cost of larger model sizes and increased computational demands. Thus, serving predictions from... | Bodun Hu, Le Xu, Jeongyoon Moon, Neeraja J. Yadwadkar, Aditya Akella |  |
| 625 |  |  [From RAG to Riches: Retrieval Interlaced with Sequence Generation](https://doi.org/10.18653/v1/2024.emnlp-main.502) |  | 0 | We present RICHES, a novel approach that interleaves retrieval with sequence generation tasks. RICHES offers an alternative to conventional RAG systems by eliminating the need for separate retriever and generator. It retrieves documents by directly decoding their contents, constrained on the... | Palak Jain, Livio Baldini Soares, Tom Kwiatkowski |  |
| 626 |  |  [Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.503) |  | 0 | Synthetic data is widely used in speech recognition due to the availability of text-to-speech models, which facilitate adapting models to previously unseen text domains. However, existing methods suffer in performance when they fine-tune an automatic speech recognition (ASR) model on synthetic data... | Hsuan Su, Hua Farn, FanYun Sun, ShangTse Chen, Hungyi Lee |  |
| 627 |  |  [Learning to Correct for QA Reasoning with Black-box LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.504) |  | 0 | An open challenge in recent machine learning is about how to improve the reasoning capability of large language models (LLMs) in a black-box setting, i.e., without access to detailed information such as output token probabilities. Existing approaches either rely on accessibility (which is often... | Jaehyung Kim, Dongyoung Kim, Yiming Yang |  |
| 628 |  |  [AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?](https://doi.org/10.18653/v1/2024.emnlp-main.505) |  | 0 | Language agents, built on top of language models (LMs), are systems that can interact with complex environments, such as the open web. In this work, we examine whether such agents can perform realistic and time-consuming tasks on the web, e.g., monitoring real-estate markets or locating relevant... | Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, Jonathan Berant |  |
| 629 |  |  [PostMark: A Robust Blackbox Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.506) |  | 0 | The most effective techniques to detect LLM-generated text rely on inserting a detectable signature—or watermark—during the model’s decoding process. Most existing watermarking methods require access to the underlying LLM’s logits, which LLM API providers are loath to share due to fears of model... | Yapei Chang, Kalpesh Krishna, Amir Houmansadr, John Wieting, Mohit Iyyer |  |
| 630 |  |  [Assessing "Implicit" Retrieval Robustness of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.507) |  | 0 | Retrieval-augmented generation has gained popularity as a framework to enhance large language models with external knowledge. However, its effectiveness hinges on the retrieval robustness of the model. If the model lacks retrieval robustness, its performance is constrained by the accuracy of the... | Xiaoyu Shen, Rexhina Blloshmi, Dawei Zhu, Jiahuan Pei, Wei Zhang |  |
| 631 |  |  [On the Relationship between Truth and Political Bias in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.508) |  | 0 | Language model alignment research often attempts to ensure that models are not only helpful and harmless, but also truthful and unbiased. However, optimizing these objectives simultaneously can obscure how improving one aspect might impact the others. In this work, we focus on analyzing the... | Suyash Fulay, William Brannon, Shrestha Mohanty, Cassandra Overney, Elinor PooleDayan, Deb Roy, Jad Kabbara |  |
| 632 |  |  [Can Active Label Correction Improve LLM-based Modular AI Systems?](https://doi.org/10.18653/v1/2024.emnlp-main.509) |  | 0 | Modular AI systems can be developed using LLM-prompts-based modules to minimize deployment time even for complex tasks. However, these systems do not always perform well and improving them using the data traces collected from a deployment remains an open challenge. The data traces contain LLM... | Karan Taneja, Ashok K. Goel |  |
| 633 |  |  [Statistical Uncertainty in Word Embeddings: GloVe-V](https://doi.org/10.18653/v1/2024.emnlp-main.510) |  | 0 | Static word embeddings are ubiquitous in computational social science applications and contribute to practical decision-making in a variety of fields including law and healthcare. However, assessing the statistical uncertainty in downstream conclusions drawn from word embedding statistics has... | Andrea Vallebueno, Cassandra HandanNader, Christopher D. Manning, Daniel E. Ho |  |
| 634 |  |  [Annotation alignment: Comparing LLM and human annotations of conversational safety](https://doi.org/10.18653/v1/2024.emnlp-main.511) |  | 0 | Do LLMs align with human perceptions of safety? We study this question via \*annotation alignment\*, the extent to which LLMs and humans agree when annotating the safety of user-chatbot conversations. We leverage the recent DICES dataset (Aroyo et al. 2023), in which 350 conversations are each... | Rajiv Movva, Pang Wei Koh, Emma Pierson |  |
| 635 |  |  [DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions](https://doi.org/10.18653/v1/2024.emnlp-main.512) |  | 0 | High-quality distractors are crucial to both the assessment and pedagogical value of multiple-choice questions (MCQs), where manually crafting ones that anticipate knowledge deficiencies or misconceptions among real students is difficult. Meanwhile, automated distractor generation, even with the... | Nigel Fernandez, Alexander Scarlatos, Wanyong Feng, Simon Woodhead, Andrew S. Lan |  |
| 636 |  |  [The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention](https://doi.org/10.18653/v1/2024.emnlp-main.513) |  | 0 | Prompt-based “diversity interventions” are commonly adopted to improve the diversity of Text-to-Image (T2I) models depicting individuals with various racial or gender traits. However, will this strategy result in nonfactual demographic distribution, especially when generating real historical... | Yixin Wan, Di Wu, Haoran Wang, KaiWei Chang |  |
| 637 |  |  [CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.514) |  | 0 | The remarkable performance of large language models (LLMs) in generation tasks has enabled practitioners to leverage publicly available models to power custom applications, such as chatbots and virtual assistants. However, the data used to train or fine-tune these LLMs is often undisclosed,... | Yuetai Li, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Dinuka Sahabandu, Bhaskar Ramasubramanian, Radha Poovendran |  |
| 638 |  |  [Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic](https://doi.org/10.18653/v1/2024.emnlp-main.515) |  | 0 | Reinforcement learning (RL) can align language models with non-differentiable reward signals, such as human preferences. However, a major challenge arises from the sparsity of these reward signals - typically, there is only a single reward for an entire output. This sparsity of rewards can lead to... | Meng Cao, Lei Shu, Lei Yu, Yun Zhu, Nevan Wichers, Yinxiao Liu, Lei Meng |  |
| 639 |  |  [Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.516) |  | 0 | Stigma is a barrier to treatment for individuals struggling with substance use disorders (SUD), which leads to significantly lower treatment engagement rates. With only 7% of those affected receiving any form of help, societal stigma not only discourages individuals with SUD from seeking help but... | Layla Bouzoubaa, Elham Aghakhani, Rezvaneh Rezapour |  |
| 640 |  |  [Efficient Sequential Decision Making with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.517) |  | 0 | This paper focuses on extending the success of large language models (LLMs) to sequential decision making. Existing efforts either (i) re-train or finetune LLMs for decision making, or (ii) design prompts for pretrained LLMs. The former approach suffers from the computational burden of gradient... | Dingyang Chen, Qi Zhang, Yinglun Zhu |  |
| 641 |  |  [SignCLIP: Connecting Text and Sign Language by Contrastive Learning](https://doi.org/10.18653/v1/2024.emnlp-main.518) |  | 0 | We present SignCLIP, which re-purposes CLIP (Contrastive Language-Image Pretraining) to project spoken language text and sign language videos, two classes of natural languages of distinct modalities, into the same space. SignCLIP is an efficient method of learning useful visual representations for... | Zifan Jiang, Gerard Sant, Amit Moryossef, Mathias Müller, Rico Sennrich, Sarah Ebling |  |
| 642 |  |  [APPLS: Evaluating Evaluation Metrics for Plain Language Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.519) |  | 0 | While there has been significant development of models for Plain Language Summarization (PLS), evaluation remains a challenge. PLS lacks a dedicated assessment metric, and the suitability of text generation evaluation metrics is unclear due to the unique transformations involved (e.g., adding... | Yue Guo, Tal August, Gondy Leroy, Trevor Cohen, Lucy Lu Wang |  |
| 643 |  |  [Ontologically Faithful Generation of Non-Player Character Dialogues](https://doi.org/10.18653/v1/2024.emnlp-main.520) |  | 0 | We introduce a language generation dataset grounded in a popular video game. KNUDGE (\*\*KN\*\*owledge Constrained \*\*U\*\*ser-NPC \*\*D\*\*ialogue \*\*GE\*\*neration) requires models to produce trees of dialogue between video game characters that accurately reflect quest and entity specifications... | Nathaniel Weir, Ryan Thomas, Randolph D'Amore, Kellie Hill, Benjamin Van Durme, Harsh Jhamtani |  |
| 644 |  |  [LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives](https://doi.org/10.18653/v1/2024.emnlp-main.521) |  | 0 | The widespread adoption of synthetic data raises new questions about how models generating the data can influence other large language models (LLMs). To start, our work exhaustively characterizes the impact of passive inheritance of model properties by systematically studying how the source of... | Luísa Shimabucoro, Sebastian Ruder, Julia Kreutzer, Marzieh Fadaee, Sara Hooker |  |
| 645 |  |  [RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs](https://doi.org/10.18653/v1/2024.emnlp-main.522) |  | 0 | Minimal pairs are a well-established approach to evaluating the grammatical knowledge of language models. However, existing resources for minimal pairs address a limited number of languages and lack diversity of language-specific grammatical phenomena. This paper introduces the Russian Benchmark of... | Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova, Vladislav Mikhailov |  |
| 646 |  |  [Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.523) |  | 0 | The task of condensing large chunks of textual information into concise and structured tables has gained attention recently due to the emergence of Large Language Models (LLMs) and their potential benefit for downstream tasks, such as text summarization and text mining. Previous approaches often... | Zheye Deng, Chunkit Chan, Weiqi Wang, Yuxi Sun, Wei Fan, Tianshi Zheng, Yauwai Yim, Yangqiu Song |  |
| 647 |  |  [Toward Compositional Behavior in Neural Models: A Survey of Current Views](https://doi.org/10.18653/v1/2024.emnlp-main.524) |  | 0 | Compositionality is a core property of natural language, and compositional behavior (CB) is a crucial goal for modern NLP systems. The research literature, however, includes conflicting perspectives on how CB should be defined, evaluated, and achieved. We propose a conceptual framework to address... | Kate McCurdy, Paul Soulos, Paul Smolensky, Roland Fernandez, Jianfeng Gao |  |
| 648 |  |  [Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs](https://doi.org/10.18653/v1/2024.emnlp-main.525) |  | 0 | Language Model Programs, i.e. sophisticated pipelines of modular language model (LM) calls, are increasingly advancing NLP tasks, but they require crafting prompts that are jointly effective for all modules. We study prompt optimization for LM programs, i.e. how to update these prompts to maximize... | Krista OpsahlOng, Michael J. Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, Omar Khattab |  |
| 649 |  |  [Reverse-Engineering the Reader](https://doi.org/10.18653/v1/2024.emnlp-main.526) |  | 0 | Numerous previous studies have sought to determine to what extent language models, pretrained on natural language text, can serve as useful models of human cognition.In this paper, we are interested in the opposite question: whether we can directly optimize a language model to be a useful cognitive... | Samuel Kiegeland, Ethan Wilcox, Afra Amini, David Robert Reich, Ryan Cotterell |  |
| 650 |  |  [Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.527) |  | 0 | Retrieval-augmented language models (RALMs) have shown strong performance and wide applicability in knowledge-intensive tasks. However, there are significant trustworthiness concerns as RALMs are prone to generating unfaithful outputs, including baseless information or contradictions with the... | Di Wu, JiaChen Gu, Fan Yin, Nanyun Peng, KaiWei Chang |  |
| 651 |  |  [Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text](https://doi.org/10.18653/v1/2024.emnlp-main.528) |  | 0 | Although Large Language Models (LLMs) excel at addressing straightforward reasoning tasks, they frequently struggle with difficulties when confronted by more complex multi-step reasoning due to a range of factors. Firstly, natural language often encompasses complex relationships among entities,... | Kewei Cheng, Nesreen K. Ahmed, Theodore L. Willke, Yizhou Sun |  |
| 652 |  |  [Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning](https://doi.org/10.18653/v1/2024.emnlp-main.529) |  | 0 | Intermediate task transfer learning can greatly improve model performance. If, for example, one has little training data for emotion detection, first fine-tuning a language model on a sentiment classification dataset may improve performance strongly. But which task to choose for transfer learning?... | David Schulte, Felix Hamborg, Alan Akbik |  |
| 653 |  |  [The effects of distance on NPI illusive effects in BERT](https://doi.org/10.18653/v1/2024.emnlp-main.530) |  | 0 | Previous studies have examined the syntactic capabilities of large pre-trained language models, such as BERT, by using stimuli from psycholinguistic studies. Studying well-known processing errors, such as NPI illusive effects can reveal whether a model prioritizes linear or hierarchical information... | So Lee, Mai Vu |  |
| 654 |  |  [Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic](https://doi.org/10.18653/v1/2024.emnlp-main.531) |  | 0 | Recent language models enable new opportunities for structured reasoning with text, such as the construction of intuitive, proof-like textual entailment trees without relying on brittle formal logic. However, progress in this direction has been hampered by a long-standing lack of a clear protocol... | Nathaniel Weir, Kate Sanders, Orion Weller, Shreya Sharma, Dongwei Jiang, Zhengping Jiang, Bhavana Dalvi Mishra, Oyvind Tafjord, Peter A. Jansen, Peter Clark, Benjamin Van Durme |  |
| 655 |  |  [Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the US](https://doi.org/10.18653/v1/2024.emnlp-main.532) |  | 0 | Recent work has highlighted the culturally-contingent nature of commonsense knowledge. We introduce AMAMMERε, a test set of 525 multiple-choice questions designed to evaluate the commonsense knowledge of English LLMs, relative to the cultural contexts of Ghana and the United States. To create... | Christabel Acquaye, Haozhe An, Rachel Rudinger |  |
| 656 |  |  [Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding](https://doi.org/10.18653/v1/2024.emnlp-main.533) |  | 0 | Graphical User Interfaces (GUIs) are central to our interaction with digital devices and growing efforts have been made to build models for various GUI understanding tasks. However, these efforts largely overlook an important GUI-referring task: screen reading based on user-indicated points, which... | Yue Fan, Lei Ding, ChingChen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Wang |  |
| 657 |  |  [Ranking Manipulation for Conversational Search Engines](https://doi.org/10.18653/v1/2024.emnlp-main.534) |  | 0 | Major search engine providers are rapidly incorporating Large Language Model (LLM)-generated content in response to user queries. These \*conversational search engines\* operate by loading retrieved website text into the LLM context for summarization and interpretation. Recent research demonstrates... | Samuel Pfrommer, Yatong Bai, Tanmay Gautam, Somayeh Sojoudi |  |
| 658 |  |  [Fast Forwarding Low-Rank Training](https://doi.org/10.18653/v1/2024.emnlp-main.535) |  | 0 | Parameter efficient finetuning methods like low-rank adaptation (LoRA) aim to reduce the computational costs of finetuning pretrained Language Models (LMs). Enabled by these low-rank settings, we propose an even more efficient optimization strategy: Fast Forward, a simple and effective approach to... | Adir Rahamim, Naomi Saphra, Sara Kangaslahti, Yonatan Belinkov |  |
| 659 |  |  [Precise Model Benchmarking with Only a Few Observations](https://doi.org/10.18653/v1/2024.emnlp-main.536) |  | 0 | How can we precisely estimate a large language model’s (LLM) accuracy on questions belonging to a specific topic within a larger question-answering dataset? The standard direct estimator, which averages the model’s accuracy on the questions in each subgroup, may exhibit high variance for subgroups... | Riccardo Fogliato, Pratik Patil, NilJana Akpinar, Mathew Monfort |  |
| 660 |  |  [Attribute Diversity Determines the Systematicity Gap in VQA](https://doi.org/10.18653/v1/2024.emnlp-main.537) |  | 0 | Although modern neural networks often generalize to new combinations of familiar concepts, the conditions that enable such compositionality have long been an open question. In this work, we study the systematicity gap in visual question answering: the performance difference between reasoning on... | Ian BerlotAttwell, Kumar Krishna Agrawal, Annabelle Michael Carrell, Yash Sharma, Naomi Saphra |  |
| 661 |  |  [ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.538) |  | 0 | When conducting literature reviews, scientists often create literature review tables—tables whose rows are publications and whose columns constitute a schema, a set of aspects used to compare and contrast the papers. Can we automatically generate these tables using language models (LMs)? In this... | Benjamin Newman, Yoonjoo Lee, Aakanksha Naik, Pao Siangliulue, Raymond Fok, Juho Kim, Daniel S. Weld, Joseph Chee Chang, Kyle Lo |  |
| 662 |  |  [Development of Cognitive Intelligence in Pre-trained Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.539) |  | 0 | Recent studies show evidence for emergent cognitive abilities in Large Pre-trained Language Models (PLMs). The increasing cognitive alignment of these models has made them candidates for cognitive science theories. Prior research into the emergent cognitive abilities of PLMs has been... | Raj Sanjay Shah, Khushi Bhardwaj, Sashank Varma |  |
| 663 |  |  [Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.540) |  | 0 | Modeling and leveraging layout reading order in visually-rich documents (VrDs) is critical in document intelligence as it captures the rich structure semantics within documents.Previous works typically formulated layout reading order as a permutation of layout elements, i.e. a sequence containing... | Chong Zhang, Yi Tu, Yixi Zhao, Chenshu Yuan, Huan Chen, Yue Zhang, Mingxu Chai, Ya Guo, Huijia Zhu, Qi Zhang, Tao Gui |  |
| 664 |  |  [Birdie: Advancing State Space Language Modeling with Dynamic Mixtures of Training Objectives](https://doi.org/10.18653/v1/2024.emnlp-main.541) |  | 0 | Efficient state space models (SSMs), including linear recurrent neural networks and linear attention variants, have emerged as potential alternative language models to Transformers. While efficient, SSMs struggle with tasks requiring in-context retrieval, such as text copying and associative... | Sam Blouir, Jimmy T. H. Smith, Antonios Anastasopoulos, Amarda Shehu |  |
| 665 |  |  [Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?](https://doi.org/10.18653/v1/2024.emnlp-main.542) |  | 0 | Multilingual large language models are designed, claimed, and expected to cater to speakers of varied languages. We hypothesise that the current practices of fine-tuning and evaluating these models may not perfectly align with this objective owing to a heavy reliance on translation, which cannot... | Pinzhen Chen, Simon Yu, Zhicheng Guo, Barry Haddow |  |
| 666 |  |  [Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.543) |  | 0 | LLMs process text as sequences of tokens that roughly correspond to words, where less common words are represented by multiple tokens. However, individual tokens are often semantically unrelated to the meanings of the words/concepts they comprise. For example, Llama-2-7b’s tokenizer splits the word... | Sheridan Feucht, David Atkinson, Byron C. Wallace, David Bau |  |
| 667 |  |  [TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering](https://doi.org/10.18653/v1/2024.emnlp-main.544) |  | 0 | Recently, image-based Large Multimodal Models (LMMs) have made significant progress in video question-answering (VideoQA) using a frame-wise approach by leveraging large-scale pretraining in a zero-shot manner. Nevertheless, these models need to be capable of finding relevant information,... | Chuyi Shang, Amos You, Sanjay Subramanian, Trevor Darrell, Roei Herzig |  |
| 668 |  |  [Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding](https://doi.org/10.18653/v1/2024.emnlp-main.545) |  | 0 | Conversational grounding, vital for building dependable dialog systems, involves ensuring a mutual understanding of shared information. Despite its importance, there has been limited research on this aspect of conversation in recent years, especially after the advent of Large Language Models... | Biswesh Mohapatra, Manav Nitin Kapadnis, Laurent Romary, Justine Cassell |  |
| 669 |  |  [Unlocking Memorization in Large Language Models with Dynamic Soft Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.546) |  | 0 | Pretrained large language models (LLMs) have excelled in a variety of natural language processing (NLP) tasks, including summarization, question answering, and translation. However, LLMs pose significant security risks due to their tendency to memorize training data, leading to potential privacy... | Zhepeng Wang, Runxue Bao, Yawen Wu, Jackson Taylor, Cao Xiao, Feng Zheng, Weiwen Jiang, Shangqian Gao, Yanfu Zhang |  |
| 670 |  |  [If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions](https://doi.org/10.18653/v1/2024.emnlp-main.547) |  | 0 | Recent works often assume that Vision-Language Model (VLM) representations are based on visual attributes like shape. However, it is unclear to what extent VLMs prioritize this information to represent concepts. We propose Extract and Explore (EX2), a novel approach to characterize textual features... | Reza Esfandiarpoor, Cristina Menghini, Stephen H. Bach |  |
| 671 |  |  [Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction](https://doi.org/10.18653/v1/2024.emnlp-main.548) |  | 0 | In this work, we are interested in automated methods for knowledge graph creation (KGC) from input text. Progress on large language models (LLMs) has prompted a series of recent works applying them to KGC, e.g., via zero/few-shot prompting. Despite successes on small domain-specific datasets, these... | Bowen Zhang, Harold Soh |  |
| 672 |  |  [MQuinE: a Cure for "Z-paradox" in Knowledge Graph Embedding](https://doi.org/10.18653/v1/2024.emnlp-main.549) |  | 0 | Knowledge graph embedding (KGE) models achieved state-of-the-art results on many knowledge graph tasks including link prediction and information retrieval. Despite the superior performance of KGE models in practice, we discover a deficiency in the expressiveness of some popular existing KGE models... | Yang Liu, Huang Fang, Yunfeng Cai, Mingming Sun |  |
| 673 |  |  [Can Transformers Learn n-gram Language Models?](https://doi.org/10.18653/v1/2024.emnlp-main.550) |  | 0 | Much theoretical work has described the ability of transformers to represent formal languages. However, linking theoretical results to empirical performance is not straightforward due to the complex interplay between the architecture, the learning algorithm, and training data. To test whether... | Anej Svete, Nadav Borenstein, Mike Zhou, Isabelle Augenstein, Ryan Cotterell |  |
| 674 |  |  [StablePrompt : Automatic Prompt Tuning using Reinforcement Learning for Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.551) |  | 0 | Finding appropriate prompts for the specific task has become an important issue as the usage of Large Language Models (LLM) have expanded. However, the variety of input-output formats complicate finding the prompts. Reinforcement Learning (RL) is a promising for prompt tuning due to its ability to... | Minchan Kwon, Gaeun Kim, Jongsuk Kim, Haeil Lee, Junmo Kim |  |
| 675 |  |  [Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems](https://doi.org/10.18653/v1/2024.emnlp-main.552) |  | 0 | LLMs and RAG systems are now capable of handling millions of input tokens or more. However, evaluating the output quality of such systems on long-context tasks remains challenging, as tasks like Needle-in-a-Haystack lack complexity. In this work, we argue that summarization can play a central role... | Philippe Laban, Alexander R. Fabbri, Caiming Xiong, ChienSheng Wu |  |
| 676 |  |  [Multi-pass Decoding for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.emnlp-main.553) |  | 0 | Sequence-to-sequence (seq2seq) models achieve comparable or better grammatical error correction performance compared to sequence-to-edit (seq2edit) models. Seq2edit models normally iteratively refine the correction result, while seq2seq models decode only once without aware of subsequent tokens.... | Xiaoying Wang, Lingling Mu, Jingyi Zhang, Hongfei Xu |  |
| 677 |  |  [Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations](https://doi.org/10.18653/v1/2024.emnlp-main.554) |  | 0 | While language model (LM)-powered chatbots and generative search engines excel at answering concrete queries, discovering information in the terrain of unknown unknowns remains challenging for users. To emulate the common educational scenario where children/students learn by listening to and... | Yucheng Jiang, Yijia Shao, Dekun Ma, Sina J. Semnani, Monica S. Lam |  |
| 678 |  |  [SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.555) |  | 0 | In-context learning (ICL) greatly improves the performance of large language models (LLMs) on various down-stream tasks, where the improvement highly depends on the quality of demonstrations. In this work, we introduce syntactic knowledge to select better in-context examples for machine translation... | Chenming Tang, Zhixiang Wang, Yunfang Wu |  |
| 679 |  |  [Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge](https://doi.org/10.18653/v1/2024.emnlp-main.556) |  | 0 | Despite progress in multimodal large language models (MLLMs), the challenge of interpreting long-form videos in response to linguistic queries persists, largely due to the inefficiency in temporal grounding and limited pre-trained context window size. In this work, we introduce Temporal Grounding... | Yuxuan Wang, Yueqian Wang, Pengfei Wu, Jianxin Liang, Dongyan Zhao, Yang Liu, Zilong Zheng |  |
| 680 |  |  [STORYSUMM: Evaluating Faithfulness in Story Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.557) |  | 0 | Human evaluation has been the gold standard for checking faithfulness in abstractive summarization. However, with a challenging source domain like narrative, multiple annotators can agree a summary is faithful, while missing details that are obvious errors only once pointed out. We therefore... | Melanie Subbiah, Faisal Ladhak, Akankshya Mishra, Griffin Adams, Lydia B. Chilton, Kathleen R. McKeown |  |
| 681 |  |  [MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts](https://doi.org/10.18653/v1/2024.emnlp-main.558) |  | 0 | Advances in multimodal models have greatly improved how interactions relevant to various tasks are modeled. Today’s multimodal models mainly focus on the correspondence between images and text, using this for tasks like image-text matching. However, this covers only a subset of real-world... | Haofei Yu, Zhengyang Qi, Lawrence Jang, Russ Salakhutdinov, LouisPhilippe Morency, Paul Pu Liang |  |
| 682 |  |  [OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer](https://doi.org/10.18653/v1/2024.emnlp-main.559) |  | 0 | Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding. However, processing extensive videos such as 24-hour CCTV footage or full-length films presents significant challenges due to the vast data and... | Lu Zhang, Tiancheng Zhao, Heting Ying, Yibo Ma, Kyusong Lee |  |
| 683 |  |  [Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension](https://doi.org/10.18653/v1/2024.emnlp-main.560) |  | 0 |  | Lin Ai, Zheng Hui, Zizhou Liu, Julia Hirschberg |  |
| 684 |  |  [CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions](https://doi.org/10.18653/v1/2024.emnlp-main.561) |  | 0 | With instruction tuning, Large Language Models (LLMs) can enhance their ability to adhere to commands. Diverging from most works focusing on data mixing, our study concentrates on enhancing the model’s capabilities from the perspective of data sampling during training. Drawing inspiration from the... | Jun Rao, Xuebo Liu, Lian Lian, Shengjun Cheng, Yunjie Liao, Min Zhang |  |
| 685 |  |  [ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers](https://doi.org/10.18653/v1/2024.emnlp-main.562) |  | 0 | Neural speech codecs aim to compress input signals into minimal bits while maintaining content quality in a low-latency manner. However, existing neural codecs often trade model complexity for reconstruction performance. These codecs primarily use convolutional blocks for feature transformation,... | Yuzhe Gu, Enmao Diao |  |
| 686 |  |  [Breaking ReLU Barrier: Generalized MoEfication for Dense Pretrained Models](https://doi.org/10.18653/v1/2024.emnlp-main.563) |  | 0 | As the scale of language models (LMs) continues to grow, there is a heightened interest in reducing the inference cost associated with these models. Mixture-of-Experts (MoEs) present an efficient alternative to dense models, while the existing methods to convert pretrained dense models to MoEs is... | Jaeseong Lee, Seungwon Hwang, Wonpyo Park, Mingi Ji |  |
| 687 |  |  [Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood](https://doi.org/10.18653/v1/2024.emnlp-main.564) |  | 0 | Human and model-generated texts can be distinguished by examining the magnitude of likelihood in language. However, it is becoming increasingly difficult as language model’s capabilities of generating human-like texts keep evolving. This study provides a new perspective by using the relative... | Yang Xu, Yu Wang, Hao An, Zhichen Liu, Yongyuan Li |  |
| 688 |  |  [Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning](https://doi.org/10.18653/v1/2024.emnlp-main.565) |  | 0 | Reinforcement learning from human feedback (RLHF) and AI-generated feedback (RLAIF) have become prominent techniques that significantly enhance the functionality of pre-trained language models (LMs). These methods harness feedback, sourced either from humans or AI, as direct rewards or to shape... | Jiahui Li, Hanlin Zhang, Fengda Zhang, TaiWei Chang, Kun Kuang, Long Chen, Jun Zhou |  |
| 689 |  |  [Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.566) |  | 0 | Pre-trained language models acquire knowledge from vast amounts of text data, which can inadvertently contain sensitive information. To mitigate the presence of undesirable knowledge, the task of knowledge unlearning becomes crucial for language models. Previous research relies on gradient ascent... | Xiaohua Feng, Chaochao Chen, Yuyuan Li, Zibin Lin |  |
| 690 |  |  [ARM: An Alignment-and-Replacement Module for Chinese Spelling Check Based on LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.567) |  | 0 | Chinese Spelling Check (CSC) aims to identify and correct spelling errors in Chinese texts, where enhanced semantic understanding of a sentence can significantly improve correction accuracy. Recently, Large Language Models (LLMs) have demonstrated exceptional mastery of world knowledge and semantic... | Changchun Liu, Kai Zhang, Junzhe Jiang, Zirui Liu, Hanqing Tao, Min Gao, Enhong Chen |  |
| 691 |  |  [On the In-context Generation of Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.568) |  | 0 | Large language models (LLMs) are found to have the ability of in-context generation (ICG): when they are fed with an in-context prompt concatenating a few somehow similar examples, they can implicitly recognize the pattern of them and then complete the prompt in the same pattern. ICG is curious,... | Zhongtao Jiang, Yuanzhe Zhang, Kun Luo, Xiaowei Yuan, Jun Zhao, Kang Liu |  |
| 692 |  |  [Atomic Inference for NLI with Generated Facts as Atoms](https://doi.org/10.18653/v1/2024.emnlp-main.569) |  | 0 | With recent advances, neural models can achieve human-level performance on various natural language tasks. However, there are no guarantees that any explanations from these models are faithful, i.e. that they reflect the inner workings of the model. Atomic inference overcomes this issue, providing... | Joe Stacey, Pasquale Minervini, Haim Dubossarsky, OanaMaria Camburu, Marek Rei |  |
| 693 |  |  [Towards Robust Speech Representation Learning for Thousands of Languages](https://doi.org/10.18653/v1/2024.emnlp-main.570) |  | 0 | Self-supervised learning (SSL) has helped extend speech technologies to more languages by reducing the need for labeled data. However, models are still far from supporting the world’s 7000+ languages. We propose XEUS, a Cross-lingual Encoder for Universal Speech, trained on over 1 million hours of... | William Chen, Wangyou Zhang, Yifan Peng, Xinjian Li, Jinchuan Tian, Jiatong Shi, Xuankai Chang, Soumi Maiti, Karen Livescu, Shinji Watanabe |  |
| 694 |  |  [I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses](https://doi.org/10.18653/v1/2024.emnlp-main.571) |  | 0 | This paper explores an intriguing observation: fine-tuning a large language model (LLM) with responses generated by a LLM often yields better results than using responses generated by humans, particularly in reasoning tasks. We conduct an in-depth investigation to understand why this occurs.... | Xuan Ren, Biao Wu, Lingqiao Liu |  |
| 695 |  |  [PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.572) |  | 0 | Large language models demonstrate reasonable multilingual abilities, despite predominantly English-centric pretraining. However, the spontaneous multilingual alignment in these models is shown to be weak, leading to unsatisfactory cross-lingual transfer and knowledge sharing. Previous works attempt... | Jiahuan Li, Shujian Huang, Aarron Ching, Xinyu Dai, Jiajun Chen |  |
| 696 |  |  [An image speaks a thousand words, but can everyone listen? On image transcreation for cultural relevance](https://doi.org/10.18653/v1/2024.emnlp-main.573) |  | 0 | Given the rise of multimedia content, human translators increasingly focus on culturally adapting not only words but also other modalities such as images to convey the same meaning. While several applications stand to benefit from this, machine translation systems remain confined to dealing with... | Simran Khanuja, Sathyanarayanan Ramamoorthy, Yueqi Song, Graham Neubig |  |
| 697 |  |  [When Parts Are Greater Than Sums: Individual LLM Components Can Outperform Full Models](https://doi.org/10.18653/v1/2024.emnlp-main.574) |  | 0 | This paper studies in-context learning by decomposing the output of large language models into the individual contributions of attention heads and MLPs (components). We observe curious components: good-performing ones that individually do well on a classification task, even when the model performs... | TingYun Chang, Jesse Thomason, Robin Jia |  |
| 698 |  |  [Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference](https://doi.org/10.18653/v1/2024.emnlp-main.575) |  | 0 | This paper focuses on detecting clickbait posts on the Web. These posts often use eye-catching disinformation in mixed modalities to mislead users to click for profit. That affects the user experience and thus would be blocked by content provider. To escape detection, malicious creators use tricks... | Jianxing Yu, Shiqi Wang, Han Yin, Zhenlong Sun, Ruobing Xie, Bo Zhang, Yanghui Rao |  |
| 699 |  |  [Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions](https://doi.org/10.18653/v1/2024.emnlp-main.576) |  | 0 | Embeddings from Large Language Models (LLMs) have emerged as critical components in various applications, particularly for information retrieval. While high-dimensional embeddings generally demonstrate superior performance as they contain more salient information, their practical application is... | Jinsung Yoon, Rajarishi Sinha, Sercan Ömer Arik, Tomas Pfister |  |
| 700 |  |  [KNN-Instruct: Automatic Instruction Construction with K Nearest Neighbor Deduction](https://doi.org/10.18653/v1/2024.emnlp-main.577) |  | 0 | Supervised fine-tuning (SFT) is a critical procedure for aligning large language models. Despite its efficiency, the construction of SFT data often struggles with issues of quality, diversity, and scalability. Many existing methods, inspired by the Self-Instruct framework, typically generate... | Jianshang Kou, Benfeng Xu, Chiwei Zhu, Zhendong Mao |  |
| 701 |  |  [Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation](https://doi.org/10.18653/v1/2024.emnlp-main.578) |  | 0 | The advent of large language models (LLMs) has dramatically advanced the state-of-the-art in numerous natural language generation tasks. For LLMs to be applied reliably, it is essential to have an accurate measure of their confidence. Currently, the most commonly used confidence score function is... | Zhen Lin, Shubhendu Trivedi, Jimeng Sun |  |
| 702 |  |  [MixGR: Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity](https://doi.org/10.18653/v1/2024.emnlp-main.579) |  | 0 |  | Fengyu Cai, Xinran Zhao, Tong Chen, Sihao Chen, Hongming Zhang, Iryna Gurevych, Heinz Koeppl |  |
| 703 |  |  [CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction](https://doi.org/10.18653/v1/2024.emnlp-main.580) |  | 0 | The increasing availability of multimodal data from electronic health records (EHR) has paved the way for deep learning methods to improve diagnosis accuracy. However, deep learning models are data-driven, requiring large-scale datasets to achieve high generalizability. Inspired by how human... | Tuan Nguyen, Thanh Trung Huynh, Minh Hieu Phan, Quoc Viet Hung Nguyen, Phi Le Nguyen |  |
| 704 |  |  ["In-Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](https://doi.org/10.18653/v1/2024.emnlp-main.581) |  | 0 | Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but... | Chuanqi Cheng, Quan Tu, Wei Wu, Shuo Shang, Cunli Mao, Zhengtao Yu, Rui Yan |  |
| 705 |  |  [Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.582) |  | 0 | To better interpret the intrinsic mechanism of large language models (LLMs), recent studies focus on monosemanticity on its basic units. A monosemantic neuron is dedicated to a single and specific concept, which forms a one-to-one correlation between neurons and concepts. Despite extensive research... | Hanqi Yan, Yanzheng Xiang, Guangyi Chen, Yifei Wang, Lin Gui, Yulan He |  |
| 706 |  |  [Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.583) |  | 0 | Calibrating language models (LMs) aligns their generation confidence with the actual likelihood of answer correctness, which can inform users about LMs’ reliability and mitigate hallucinated content. However, prior calibration methods, such as self-consistency-based and logit-based approaches, are... | Xin Liu, Farima Fatahi Bayat, Lu Wang |  |
| 707 |  |  [Reasoning Robustness of LLMs to Adversarial Typographical Errors](https://doi.org/10.18653/v1/2024.emnlp-main.584) |  | 0 |  | Esther Gan, Yiran Zhao, Liying Cheng, Yancan Mao, Anirudh Goyal, Kenji Kawaguchi, MinYen Kan, Michael Shieh |  |
| 708 |  |  [InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance](https://doi.org/10.18653/v1/2024.emnlp-main.585) |  | 0 | As large language models (LLMs) rapidly evolve, they are increasingly being customized through fine-tuning to suit the specific needs of various applications. A critical aspect of this advancement is the alignment process, which ensures that these models perform tasks in ways that align with human... | Pengyu Wang, Dong Zhang, Linyang Li, Chenkun Tan, Xinghao Wang, Mozhi Zhang, Ke Ren, Botian Jiang, Xipeng Qiu |  |
| 709 |  |  [Belief Revision: The Adaptability of Large Language Models Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.586) |  | 0 | The capability to reason from text is crucial for real-world NLP applications. Real-world scenarios often involve incomplete or evolving data. In response, individuals update their beliefs and understandings accordingly. However, most existing evaluations assume that language models (LMs) operate... | Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, Junxian He, Pascale Fung |  |
| 710 |  |  [Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.587) |  | 0 | As a promising paradigm to collaboratively train models with decentralized data, Federated Learning (FL) can be exploited to fine-tune Large Language Models (LLMs). While LLMs correspond to huge size, the scale of the training data significantly increases, which leads to tremendous amounts of... | Ji Liu, Jiaxiang Ren, Ruoming Jin, Zijie Zhang, Yang Zhou, Patrick Valduriez, Dejing Dou |  |
| 711 |  |  [Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints](https://doi.org/10.18653/v1/2024.emnlp-main.588) |  | 0 | The ever-growing biomedical publications magnify the challenge of extracting structured data from unstructured texts. This task involves two components: biomedical entity identification (Named Entity Recognition, NER) and their interrelation determination (Relation Extraction, RE). However,... | Minjia Wang, Fangzhou Liu, Xiuxing Li, Bowen Dong, Zhenyu Li, Tengyu Pan, Jianyong Wang |  |
| 712 |  |  [Decoding Matters: Addressing Amplification Bias and Homogeneity Issue in Recommendations for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.589) |  | 0 | Adapting Large Language Models (LLMs) for recommendation requires careful consideration of the decoding process, given the inherent differences between generating items and natural language. Existing approaches often directly apply LLMs’ original decoding methods. However, we find these methods... | Keqin Bao, Jizhi Zhang, Yang Zhang, Xinyue Huo, Chong Chen, Fuli Feng |  |
| 713 |  |  [LLMs Are Prone to Fallacies in Causal Inference](https://doi.org/10.18653/v1/2024.emnlp-main.590) |  | 0 | Recent work shows that causal facts can be effectively extracted from LLMs through prompting, facilitating the creation of causal graphs for causal inference tasks. However, it is unclear if this success is limited to explicitly-mentioned causal facts in the pretraining data which the model can... | Nitish Joshi, Abulhair Saparov, Yixin Wang, He He |  |
| 714 |  |  [Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles](https://doi.org/10.18653/v1/2024.emnlp-main.591) |  | 0 | Recent works leverage LLMs to roleplay realistic social scenarios, aiding novices in practicing their social skills. However, simulating sensitive interactions, such as in the domain of mental health, is challenging. Privacy concerns restrict data access, and collecting expert feedback, although... | Ryan Louie, Ananjan Nandi, William Fang, Cheng Chang, Emma Brunskill, Diyi Yang |  |
| 715 |  |  [The Lou Dataset - Exploring the Impact of Gender-Fair Language in German Text Classification](https://doi.org/10.18653/v1/2024.emnlp-main.592) |  | 0 | Gender-fair language, an evolving linguistic variation in German, fosters inclusion by addressing all genders or using neutral forms. However, there is a notable lack of resources to assess the impact of this language shift on language models (LMs) might not been trained on examples of this... | Andreas Waldis, Joel Birrer, Anne Lauscher, Iryna Gurevych |  |
| 716 |  |  [When Generative Adversarial Networks Meet Sequence Labeling Challenges](https://doi.org/10.18653/v1/2024.emnlp-main.593) |  | 0 | The current framework for sequence labeling encompasses a feature extractor and a sequence tagger. This study introduces a unified framework named SLGAN, which harnesses the capabilities of Generative Adversarial Networks to address the challenges associated with Sequence Labeling tasks. SLGAN not... | Yu Tong, Ge Chen, Guokai Zheng, Rui Li, Jiang Dazhi |  |
| 717 |  |  [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.594) |  | 0 | Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance Quesetion Answering (QA) performance of Large Language Models (LLMs), yet structured KG verbalization remains challenging. Existing methods, like concatenation or free-form textual conversion of triples, have limitations,... | Sungho Ko, Hyunjin Cho, Hyungjoo Chae, Jinyoung Yeo, Dongha Lee |  |
| 718 |  |  [Speechworthy Instruction-tuned Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.595) |  | 0 | Current instruction-tuned language models are exclusively trained with textual preference data and thus may not be aligned to the unique requirements of other modalities, such as speech. To better align language models with the speech domain, we explore i) prompting strategies based on... | Hyundong Cho, Nicolaas Paul Jedema, Leonardo F. R. Ribeiro, Karishma Sharma, Pedro A. Szekely, Alessandro Moschitti, Ruben Janssen, Jonathan May |  |
| 719 |  |  [Data, Data Everywhere: A Guide for Pretraining Dataset Construction](https://doi.org/10.18653/v1/2024.emnlp-main.596) |  | 0 | The impressive capabilities of recent language models can be largely attributed to the multi-trillion token pretraining datasets that they are trained on. However, model developers fail to disclose their construction methodology which has lead to a lack of open information on how to develop... | Jupinder Parmar, Shrimai Prabhumoye, Joseph Jennings, Bo Liu, Aastha Jhunjhunwala, Zhilin Wang, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro |  |
| 720 |  |  [Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together](https://doi.org/10.18653/v1/2024.emnlp-main.597) |  | 0 | Natural Language Processing (NLP) systems are increasingly taking the form of sophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG), where each module may involve a distinct Language Model (LM) and an associated prompt template. These compound systems often lack intermediate... | Dilara Soylu, Christopher Potts, Omar Khattab |  |
| 721 |  |  [Demystifying Verbatim Memorization in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.598) |  | 0 | Large Language Models (LLMs) frequently memorize long sequences verbatim, often with serious legal and privacy implications. Much prior work has studied such verbatim memorization using observational data. To complement such work, we develop a framework to study verbatim memorization in a... | Jing Huang, Diyi Yang, Christopher Potts |  |
| 722 |  |  [AmbigNLG: Addressing Task Ambiguity in Instruction for NLG](https://doi.org/10.18653/v1/2024.emnlp-main.599) |  | 0 |  | Ayana Niwa, Hayate Iso |  |
| 723 |  |  [Distributional Properties of Subword Regularization](https://doi.org/10.18653/v1/2024.emnlp-main.600) |  | 0 | Subword regularization, used widely in NLP, improves model performance by reducing the dependency on exact tokenizations, augmenting the training corpus, and exposing the model to more unique contexts during training. BPE and MaxMatch, two popular subword tokenization schemes, have stochastic... | Marco Cognetta, Vilém Zouhar, Naoaki Okazaki |  |
| 724 |  |  [DataTales: A Benchmark for Real-World Intelligent Data Narration](https://doi.org/10.18653/v1/2024.emnlp-main.601) |  | 0 | We introduce DataTales, a novel benchmark designed to assess the proficiency of language models in data narration, a task crucial for transforming complex tabular data into accessible narratives. Existing benchmarks often fall short in capturing the requisite analytical complexity for practical... | Yajing Yang, Qian Liu, MinYen Kan |  |
| 725 |  |  [Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters](https://doi.org/10.18653/v1/2024.emnlp-main.602) |  | 0 | Large language models (LLMs) have revolutionized natural language processing and broadened their applicability across diverse commercial applications. However, the deployment of these models is constrained by high inference time in multilingual settings. To mitigate this challenge, this paper... | Euiin Yi, Taehyeon Kim, Hongseok Jeung, DuSeong Chang, SeYoung Yun |  |
| 726 |  |  [GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.603) |  | 0 | News summarization in today’s global scene can be daunting with its flood of multilingual content and varied viewpoints from different sources. However, current studies often neglect such real-world scenarios as they tend to focus solely on either single-language or single-document tasks. To bridge... | Yangfan Ye, Xiachong Feng, Xiaocheng Feng, Weitao Ma, Libo Qin, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin |  |
| 727 |  |  [Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.604) |  | 0 | Despite their popularity in non-English NLP, multilingual language models often underperform monolingual ones due to inter-language competition for model parameters. We propose Cross-lingual Expert Language Models (X-ELM), which mitigate this competition by independently training language models on... | Terra Blevins, Tomasz Limisiewicz, Suchin Gururangan, Margaret Li, Hila Gonen, Noah A. Smith, Luke Zettlemoyer |  |
| 728 |  |  [More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.605) |  | 0 | Incorrect student answers can become valuable learning opportunities, provided that the student understands where they went wrong and why. To this end, rather than being given the correct answer, students should receive elaborated feedback on how to correct a mistake on their own. Highlighting the... | Wencke Liermann, JinXia Huang, Yohan Lee, Kong Joo Lee |  |
| 729 |  |  [Stable Language Model Pre-training by Reducing Embedding Variability](https://doi.org/10.18653/v1/2024.emnlp-main.606) |  | 0 | Stable pre-training is essential for achieving better-performing language models. However, tracking pre-training stability is impractical due to high computational costs. We study Token Embedding Variability as a simple proxy to estimate pre-training stability. We theoretically and empirically... | Woojin Chung, Jiwoo Hong, Na Min An, James Thorne, SeYoung Yun |  |
| 730 |  |  [What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations](https://doi.org/10.18653/v1/2024.emnlp-main.607) |  | 0 | This paper explores the pitfalls in evaluating multilingual automatic speech recognition (ASR) models, with a particular focus on Indic language scripts. We investigate the text normalization routine employed by leading ASR models, including OpenAI Whisper, Meta’s MMS, Seamless, and Assembly AI’s... | Kavya Manohar, Leena G. Pillai |  |
| 731 |  |  [Diversity Over Size: On the Effect of Sample and Topic Sizes for Topic-Dependent Argument Mining Datasets](https://doi.org/10.18653/v1/2024.emnlp-main.608) |  | 0 | Topic-Dependent Argument Mining (TDAM), that is extracting and classifying argument components for a specific topic from large document sources, is an inherently difficult task for machine learning models and humans alike, as large TDAM datasets are rare and recognition of argument components... | Benjamin Schiller, Johannes Daxenberger, Andreas Waldis, Iryna Gurevych |  |
| 732 |  |  [Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas](https://doi.org/10.18653/v1/2024.emnlp-main.609) |  | 0 | This study is the first to explore whether multi-modal large language models (LLMs) can align their behaviors with visual personas, addressing a significant gap in the literature that predominantly focuses on text-based personas. We developed a novel dataset of 5K fictional avatar images for... | Seungjong Sun, Eungu Lee, Seo Yeon Baek, Seunghyun Hwang, Wonbyung Lee, Dongyan Nan, Bernard J. Jansen, JangHyun Kim |  |
| 733 |  |  [ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented Generator](https://doi.org/10.18653/v1/2024.emnlp-main.610) |  | 0 | Large language models (LLMs) are proven to benefit a lot from retrieval-augmented generation (RAG) in alleviating hallucinations confronted with knowledge-intensive questions. RAG adopts information retrieval techniques to inject external knowledge from semantic-relevant documents as input... | Junda Zhu, Lingyong Yan, Haibo Shi, Dawei Yin, Lei Sha |  |
| 734 |  |  [Dynamic Multi-granularity Attribution Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.611) |  | 0 | Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity of a specific aspect within a given sentence. Most existing methods predominantly leverage semantic or syntactic information based on attention scores, which are susceptible to interference caused by irrelevant contexts... | Yanjiang Chen, Kai Zhang, Feng Hu, Xianquan Wang, Ruikang Li, Qi Liu |  |
| 735 |  |  [Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization](https://doi.org/10.18653/v1/2024.emnlp-main.612) |  | 0 | Language models frequently inherit societal biases from their training data. Numerous techniques have been proposed to mitigate these biases during both the pre-training and fine-tuning stages. However, fine-tuning a pre-trained debiased language model on a downstream task can reintroduce biases... | Shahed Masoudian, Markus Frohmann, Navid Rekabsaz, Markus Schedl |  |
| 736 |  |  [Large Language Models Know What is Key Visual Entity: An LLM-assisted Multimodal Retrieval for VQA](https://doi.org/10.18653/v1/2024.emnlp-main.613) |  | 0 | Visual question answering (VQA) tasks, often performed by visual language model (VLM), face challenges with long-tail knowledge. Recent retrieval-augmented VQA (RA-VQA) systems address this by retrieving and integrating external knowledge sources. However, these systems still suffer from redundant... | Pu Jian, Donglei Yu, Jiajun Zhang |  |
| 737 |  |  [Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights](https://doi.org/10.18653/v1/2024.emnlp-main.614) |  | 0 | Large Multimodal Models (LMMs) have achieved great success recently, demonstrating a strong capability to understand multimodal information and to interact with human users. Despite the progress made, the challenge of detecting high-risk interactions in multimodal settings, and in particular in... | Hao Yang, Lizhen Qu, Ehsan Shareghi, Reza Haf |  |
| 738 |  |  [Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations](https://doi.org/10.18653/v1/2024.emnlp-main.615) |  | 0 | Incorporating natural language rationales in the prompt and In-Context Learning (ICL) have led to a significant improvement of Large Language Models (LLMs) performance. However, generating high-quality rationales require human-annotation or the use of auxiliary proxy models. In this work, we... | Milan Bhan, JeanNoël Vittaut, Nicolas Chesneau, MarieJeanne Lesot |  |
| 739 |  |  [What are the Generator Preferences for End-to-end Task-Oriented Dialog System?](https://doi.org/10.18653/v1/2024.emnlp-main.616) |  | 0 | Fully end-to-end task-oriented dialogue (EToD) systems have shown excellent performance, which requires the ability to retrieve entities accurately for generation. Existing methods improve the accuracy of entity retrieval and construct data flows between retrieval results and response generator,... | Wanshi Xu, Xianwei Zhuang, Zhanpeng Chen, Zhihong Zhu, Xuxin Cheng, Yuexian Zou |  |
| 740 |  |  [Paraphrase Types Elicit Prompt Engineering Capabilities](https://doi.org/10.18653/v1/2024.emnlp-main.617) |  | 0 | Much of the success of modern language models depends on finding a suitable prompt to instruct the model. Until now, it has been largely unknown how variations in the linguistic expression of prompts affect these models. This study systematically and empirically evaluates which linguistic features... | Jan Philip Wahle, Terry Ruas, Yang Xu, Bela Gipp |  |
| 741 |  |  [VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models](https://doi.org/10.18653/v1/2024.emnlp-main.618) |  | 0 | Progress in Text-to-Image (T2I) models has significantly advanced the generation of images from textual descriptions. Existing metrics, such as CLIP, effectively measure the semantic alignment between single prompts and their corresponding images. However, they fall short in evaluating a model’s... | Jingtao Cao, Zhang Zheng, Hongru Wang, KamFai Wong |  |
| 742 |  |  [Towards Online Continuous Sign Language Recognition and Translation](https://doi.org/10.18653/v1/2024.emnlp-main.619) |  | 0 | Research on continuous sign language recognition (CSLR) is essential to bridge the communication gap between deaf and hearing individuals. Numerous previous studies have trained their models using the connectionist temporal classification (CTC) loss. During inference, these CTC-based models... | Ronglai Zuo, Fangyun Wei, Brian Mak |  |
| 743 |  |  [Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment](https://doi.org/10.18653/v1/2024.emnlp-main.620) |  | 0 | Although pre-trained language models (PLMs) have been widely used in natural language understandings (NLU), they are still exposed to fairness issues. Most existing extrinsic debiasing methods rely on manually curated word lists for each sensitive groups to modify training data or to add regular... | Yiwei Dai, Hengrui Gu, Ying Wang, Xin Wang |  |
| 744 |  |  [Split and Merge: Aligning Position Biases in LLM-based Evaluators](https://doi.org/10.18653/v1/2024.emnlp-main.621) |  | 0 | Large language models (LLMs) have shown promise as automated evaluators for assessing the quality of answers generated by AI systems. However, LLM-based evaluators exhibit position bias, or inconsistency, when used to evaluate candidate answers in pairwise comparisons, favoring either the first or... | Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai Wang, Cuiyun Gao, Yang Liu |  |
| 745 |  |  [Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation](https://doi.org/10.18653/v1/2024.emnlp-main.622) |  | 0 | The proliferation of online misinformation presents a significant challenge, requiring scalable strategies for effective mitigation. While detection methods exist, current reactive approaches, like content flagging and banning, are short-term and insufficient. Additionally, advancements like large... | Sougata Saha, Rohini K. Srihari |  |
| 746 |  |  [BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.623) |  | 0 | Direct alignment from preferences (DAP) has emerged as a promising paradigm for aligning large language models (LLMs) to human desiderata from pre-collected, offline preference datasets. While recent studies indicate that existing offline DAP methods can directly benefit from online training... | Wenda Xu, Jiachen Li, William Yang Wang, Lei Li |  |
| 747 |  |  [One2Set + Large Language Model: Best Partners for Keyphrase Generation](https://doi.org/10.18653/v1/2024.emnlp-main.624) |  | 0 | Keyphrase generation (KPG) aims to automatically generate a collection of phrases representing the core concepts of a given document. The dominant paradigms in KPG include one2seq and one2set. Recently, there has been increasing interest in applying large language models (LLMs) to KPG. Our... | Liangying Shao, Liang Zhang, Minlong Peng, Guoqi Ma, Hao Yue, Mingming Sun, Jinsong Su |  |
| 748 |  |  [Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.625) |  | 0 | Users post numerous product-related questions on e-commerce platforms, affecting their purchase decisions. Product-related question answering (PQA) entails utilizing product-related resources to provide precise responses to users. We propose a novel task of Multilingual Cross-market Product-based... | Yifei Yuan, Yang Deng, Anders Søgaard, Mohammad Aliannejadi |  |
| 749 |  |  [ORPO: Monolithic Preference Optimization without Reference Model](https://doi.org/10.18653/v1/2024.emnlp-main.626) |  | 0 | While recent preference alignment algorithms for language models have demonstrated promising results, supervised fine-tuning (SFT) remains imperative for achieving successful convergence. In this paper, we revisit SFT in the context of preference alignment, emphasizing that a minor penalty for the... | Jiwoo Hong, Noah Lee, James Thorne |  |
| 750 |  |  [A Multi-Perspective Analysis of Memorization in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.627) |  | 0 | Large Language Models (LLMs) can generate the same sequences contained in the pre-train corpora, known as memorization.Previous research studied it at a macro level, leaving micro yet important questions under-explored, e.g., what makes sentences memorized, the dynamics when generating memorized... | Bowen Chen, Namgi Han, Yusuke Miyao |  |
| 751 |  |  [Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations](https://doi.org/10.18653/v1/2024.emnlp-main.628) |  | 0 | Assessing the performance of systems to classify Multi-Party Conversations (MPC) is challenging due to the interconnection between linguistic and structural characteristics of conversations. Conventional evaluation methods often overlook variances in model behavior across different levels of... | Nicolò Penzo, Maryam Sajedinia, Bruno Lepri, Sara Tonelli, Marco Guerini |  |
| 752 |  |  [Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.629) |  | 0 | Reasoning is a fundamental component of language understanding. Recent prompting techniques, such as chain of thought, have consistently improved LLMs’ performance on various reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs in the... | Haritz Puerto, Martin Tutek, Somak Aditya, Xiaodan Zhu, Iryna Gurevych |  |
| 753 |  |  [Unveiling the Role of Pretraining in Direct Speech Translation](https://doi.org/10.18653/v1/2024.emnlp-main.630) |  | 0 | Direct speech-to-text translation systems encounter an important drawback in data scarcity. A common solution consists on pretraining the encoder on automatic speech recognition, hence losing efficiency in the training process. In this study, we compare the training dynamics of a system using a... | Belen Alastruey, Gerard I. Gállego, Marta R. Costajussà |  |
| 754 |  |  [PCQPR: Proactive Conversational Question Planning with Reflection](https://doi.org/10.18653/v1/2024.emnlp-main.631) |  | 0 | Conversational Question Generation (CQG) enhances the interactivity of conversational question-answering systems in fields such as education, customer service, and entertainment. However, traditional CQG, focusing primarily on the immediate context, lacks the conversational foresight necessary to... | Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen |  |
| 755 |  |  [CodeAgent: Autonomous Communicative Agents for Code Review](https://doi.org/10.18653/v1/2024.emnlp-main.632) |  | 0 | Code review, which aims at ensuring the overall quality and reliability of software, is a cornerstone of software development. Unfortunately, while crucial, Code review is a labor-intensive process that the research community is looking to automate. Existing automated methods rely on single... | Xunzhu Tang, Kisub Kim, Yewei Song, Cedric Lothritz, Bei Li, Saad Ezzini, Haoye Tian, Jacques Klein, Tegawendé F. Bissyandé |  |
| 756 |  |  [TroL: Traversal of Layers for Large Language and Vision Models](https://doi.org/10.18653/v1/2024.emnlp-main.633) |  | 0 | Large language and vision models (LLVMs) have been driven by the generalization power of large language models (LLMs) and the advent of visual instruction tuning. Along with scaling them up directly, these models enable LLVMs to showcase powerful vision language (VL) performances by covering... | ByungKwan Lee, Sangyun Chung, Chae Won Kim, Beomchan Park, Yong Man Ro |  |
| 757 |  |  [MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language](https://doi.org/10.18653/v1/2024.emnlp-main.634) |  | 0 | Machine Translation (MT) has developed rapidly since the release of Large Language Models and current MT evaluation is performed through comparison with reference human translations or by predicting quality scores from human-labeled data. However, these mainstream evaluation methods mainly focus on... | Shun Wang, Ge Zhang, Han Wu, Tyler Loakman, Wenhao Huang, Chenghua Lin |  |
| 758 |  |  [Revisiting Supertagging for faster HPSG parsing](https://doi.org/10.18653/v1/2024.emnlp-main.635) |  | 0 | We present new supertaggers trained on English HPSG-based treebanks and test the effects of the best tagger on parsing speed and accuracy. HPSG treebanks are produced automatically by large manually built grammars and feature high-quality annotation based on a well-developed linguistic theory. The... | Olga Zamaraeva, Carlos GómezRodríguez |  |
| 759 |  |  [Improve Dense Passage Retrieval with Entailment Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.636) |  | 0 | Retrieval module can be plugged into many downstream NLP tasks to improve their performance, such as open-domain question answering and retrieval-augmented generation. The key to a retrieval system is to calculate relevance scores to query and passage pairs. However, the definition of relevance is... | Lu Dai, Hao Liu, Hui Xiong |  |
| 760 |  |  [ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.637) |  | 0 | Tool-augmented large language models (LLMs) are rapidly being integrated into real-world applications. Due to the lack of benchmarks, the community has yet to fully understand the hallucination issues within these models. To address this challenge, we introduce a comprehensive diagnostic benchmark,... | Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana |  |
| 761 |  |  [TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.638) |  | 0 | The objective of the research we present is to remedy the problem of the low quality of language models for low-resource languages. We introduce an algorithm, the Token Embedding Mapping Algorithm (TEMA), that maps the token embeddings of a richly pre-trained model L1 to a poorly trained model L2,... | Rodolfo Zevallos, Núria Bel, Mireia Farrús |  |
| 762 |  |  [DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting](https://doi.org/10.18653/v1/2024.emnlp-main.639) |  | 0 | Coherence in writing, an aspect that L2 English learners often struggle with, is crucial in assessing L2 English writing. Existing automated writing evaluation systems primarily use basic surface linguistic features to detect coherence in writing. However, little effort has been made to correct the... | Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu |  |
| 763 |  |  [Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.640) |  | 0 | Large language models (LLMs) have demonstrated strong capabilities across various language tasks, notably through instruction-tuning methods. However, LLMs face challenges in visualizing complex, real-world data through charts and plots. Firstly, existing datasets rarely cover a full range of chart... | Fatemeh Pesaran Zadeh, Juyeon Kim, JinHwa Kim, Gunhee Kim |  |
| 764 |  |  [PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.641) |  | 0 | Large language models (LLMs) have revolutionized NLP research. Notably, in-context learning enables their use as evaluation metrics for natural language generation, making them particularly advantageous in low-resource scenarios and time-restricted applications. In this work, we introduce PrExMe, a... | Christoph Leiter, Steffen Eger |  |
| 765 |  |  [Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning](https://doi.org/10.18653/v1/2024.emnlp-main.642) |  | 0 | In-context learning, a paradigm bridging the gap between pre-training and fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in few-shot settings. Despite being widely applied, in-context learning is vulnerable to malicious attacks. In this work, we raise security concerns... | Shuai Zhao, Meihuizi Jia, Anh Tuan Luu, Fengjun Pan, Jinming Wen |  |
| 766 |  |  [Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.643) |  | 0 | In dialogue, the addressee may initially misunderstand the speaker and respond erroneously, often prompting the speaker to correct the misunderstanding in the next turn with a Third Position Repair (TPR). The ability to process and respond appropriately to such repair sequences is thus crucial in... | Francisco Javier Chiyah Garcia, Alessandro Suglia, Arash Eshghi |  |
| 767 |  |  [Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models](https://doi.org/10.18653/v1/2024.emnlp-main.644) |  | 0 | As large language models (LLMs) increasingly permeate daily lives, there is a growing demand for real-time interactions that mirror human conversations. Traditional turn-based chat systems driven by LLMs prevent users from verbally interacting with the system while generating responses.To overcome... | Xinrong Zhang, Yingfa Chen, Shengding Hu, Xu Han, Zihang Xu, Yuanwei Xu, Weilin Zhao, Maosong Sun, Zhiyuan Liu |  |
| 768 |  |  [Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations](https://doi.org/10.18653/v1/2024.emnlp-main.645) |  | 0 | Models need appropriate inductive biases to effectively learn from small amounts of data and generalize systematically outside of the training distribution. While Transformers are highly versatile and powerful, they can still benefit from enhanced structural inductive biases for seq2seq tasks,... | Matthias Lindemann, Alexander Koller, Ivan Titov |  |
| 769 |  |  [Puzzle Solving using Reasoning of Large Language Models: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.646) |  | 0 | Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy—dividing puzzles... | Panagiotis Giadikiaroglou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou |  |
| 770 |  |  [SciEx: Benchmarking Large Language Models on Scientific Exams with Human Expert Grading and Automatic Grading](https://doi.org/10.18653/v1/2024.emnlp-main.647) |  | 0 | With the rapid development of Large Language Models (LLMs), it is crucial to have benchmarks which can evaluate the ability of LLMs on different domains. One common use of LLMs is performing tasks on scientific topics, such as writing algorithms, querying databases or giving mathematical proofs.... | Tu Anh Dinh, Carlos Mullov, Leonard Bärmann, Zhaolin Li, Danni Liu, Simon Reiß, Jueun Lee, Nathan Lerzer, Jianfeng Gao, Fabian PellerKonrad, Tobias Röddiger, Alexander Waibel, Tamim Asfour, Michael Beigl, Rainer Stiefelhagen, Carsten Dachsbacher, Klemens Böhm, Jan Niehues |  |
| 771 |  |  [Red Teaming Language Models for Processing Contradictory Dialogues](https://doi.org/10.18653/v1/2024.emnlp-main.648) |  | 0 | Most language models currently available are prone to self-contradiction during dialogues. To mitigate this issue, this study explores a novel contradictory dialogue processing task that aims to detect and modify contradictory statements in a conversation. This task is inspired by research on... | Xiaofei Wen, Bangzheng Li, Tenghao Huang, Muhao Chen |  |
| 772 |  |  [Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.649) |  | 0 | The disconnect between tokenizer creation and model training in language models allows for specific inputs, such as the infamous SolidGoldMagikarp token, to induce unwanted model behaviour. Although such ‘glitch tokens’, tokens present in the tokenizer vocabulary but that are nearly or entirely... | Sander Land, Max Bartolo |  |
| 773 |  |  [Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.650) |  | 0 | Evaluating Large Language Models (LLMs) on reasoning benchmarks demonstrates their ability to solve compositional questions. However, little is known of whether these models engage in genuine logical reasoning or simply rely on implicit cues to generate answers. In this paper, we investigate the... | Houman Mehrafarin, Arash Eshghi, Ioannis Konstas |  |
| 774 |  |  [Pragmatic Norms Are All You Need - Why The Symbol Grounding Problem Does Not Apply to LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.651) |  | 0 | Do LLMs fall prey to Harnad’s symbol grounding problem (SGP), as it has recently been claimed? We argue that this is not the case. Starting out with countering the arguments of Bender and Koller (2020), we trace the origins of the SGP to the computational theory of mind (CTM), and we show that it... | Reto Gubelmann |  |
| 775 |  |  [Major Entity Identification: A Generalizable Alternative to Coreference Resolution](https://doi.org/10.18653/v1/2024.emnlp-main.652) |  | 0 | The limited generalization of coreference resolution (CR) models has been a major bottleneck in the task’s broad application. Prior work has identified annotation differences, especially for mention detection, as one of the main reasons for the generalization gap and proposed using additional... | Kawshik Sundar, Shubham Toshniwal, Makarand Tapaswi, Vineet Gandhi |  |
| 776 |  |  [Enhancing High-order Interaction Awareness in LLM-based Recommender Model](https://doi.org/10.18653/v1/2024.emnlp-main.653) |  | 0 | Large language models (LLMs) have demonstrated prominent reasoning capabilities in recommendation tasks by transforming them into text-generation tasks. However, existing approaches either disregard or ineffectively model the user-item high-order interactions. To this end, this paper presents an... | Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki |  |
| 777 |  |  [What Are the Odds? Language Models Are Capable of Probabilistic Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.654) |  | 0 | Language models (LM) are capable of remarkably complex linguistic tasks; however, numerical reasoning is an area in which they frequently struggle. An important but rarely evaluated form of reasoning is understanding probability distributions. In this paper, we focus on evaluating the probabilistic... | Akshay Paruchuri, Jake Garrison, Shun Liao, John Hernandez, Jacob E. Sunshine, Tim Althoff, Xin Liu, Daniel McDuff |  |
| 778 |  |  [MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.655) |  | 0 | Unsupervised rationale extraction aims to extract text snippets to support model predictions without explicit rationale annotation.Researchers have made many efforts to solve this task. Previous works often encode each aspect independently, which may limit their ability to capture meaningful... | Han Jiang, Junwen Duan, Zhe Qu, Jianxin Wang |  |
| 779 |  |  [LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.656) |  | 0 | Guardrails have emerged as an alternative to safety alignment for content moderation of large language models (LLMs). Existing model-based guardrails have not been designed for resource-constrained computational portable devices, such as mobile phones, more and more of which are running LLM-based... | Hayder Elesedy, Pedro M. Esperança, Silviu Vlad Oprea, Mete Ozay |  |
| 780 |  |  ["A good pun is its own reword": Can Large Language Models Understand Puns?](https://doi.org/10.18653/v1/2024.emnlp-main.657) |  | 0 | Puns play a vital role in academic research due to their distinct structure and clear definition, which aid in the comprehensive analysis of linguistic humor. However, the understanding of puns in large language models (LLMs) has not been thoroughly examined, limiting their use in creative writing... | Zhijun Xu, Siyu Yuan, Lingjie Chen, Deqing Yang |  |
| 781 |  |  [QGEval: Benchmarking Multi-dimensional Evaluation for Question Generation](https://doi.org/10.18653/v1/2024.emnlp-main.658) |  | 0 | Automatically generated questions often suffer from problems such as unclear expression or factual inaccuracies, requiring a reliable and comprehensive evaluation of their quality. Human evaluation is widely used in the field of question generation (QG) and serves as the gold standard for automatic... | Weiping Fu, Bifan Wei, Jianxiang Hu, Zhongmin Cai, Jun Liu |  |
| 782 |  |  [Dependency Graph Parsing as Sequence Labeling](https://doi.org/10.18653/v1/2024.emnlp-main.659) |  | 0 | Various linearizations have been proposed to cast syntactic dependency parsing as sequence labeling. However, these approaches do not support more complex graph-based representations, such as semantic dependencies or enhanced universal dependencies, as they cannot handle reentrancy or cycles. By... | Ana Ezquerro, David Vilares, Carlos GómezRodríguez |  |
| 783 |  |  [NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data](https://doi.org/10.18653/v1/2024.emnlp-main.660) |  | 0 | Large Language Models (LLMs) have shown impressive abilities in data annotation, opening the way for new approaches to solve classic NLP problems. In this paper, we show how to use LLMs to create NuNER, a compact language representation model specialized in the Named Entity Recognition (NER) task.... | Sergei Bogdanov, Alexandre Constantin, Timothée Bernard, Benoît Crabbé, Etienne Bernard |  |
| 784 |  |  [Towards a Greek Proverb Atlas: Computational Spatial Exploration and Attribution of Greek Proverbs](https://doi.org/10.18653/v1/2024.emnlp-main.661) |  | 0 | Proverbs carry wisdom transferred orally from generation to generation. Based on the place they were recorded, this study introduces a publicly-available and machine-actionable dataset of more than one hundred thousand Greek proverb variants. By quantifying the spatial distribution of proverbs, we... | John Pavlopoulos, Panos Louridas, Panagiotis Filos |  |
| 785 |  |  [Unraveling Babel: Exploring Multilingual Activation Patterns of LLMs and Their Applications](https://doi.org/10.18653/v1/2024.emnlp-main.662) |  | 0 | Recently, large language models (LLMs) have achieved tremendous breakthroughs in the field of NLP, but still lack understanding of their internal neuron activities when processing different languages. We designed a method to convert dense LLMs into fine-grained MoE architectures, and then visually... | Weize Liu, Yinlong Xu, Hongxia Xu, Jintai Chen, Xuming Hu, Jian Wu |  |
| 786 |  |  [Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss](https://doi.org/10.18653/v1/2024.emnlp-main.663) |  | 0 | Since the introduction of BERT and RoBERTa, research on Semantic Textual Similarity (STS) has made groundbreaking progress. Particularly, the adoption of contrastive learning has substantially elevated state-of-the-art performance across various STS benchmarks. However, contrastive learning... | Bowen Zhang, Chunping Li |  |
| 787 |  |  [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://doi.org/10.18653/v1/2024.emnlp-main.664) |  | 0 | We propose an end-to-end differentiable training paradigm for stable training of a rationalized transformer classifier. Our approach results in a single model that simultaneously classifies a sample and scores input tokens based on their relevance to the classification. To this end, we build on the... | Marc Felix Brinner, Sina Zarrieß |  |
| 788 |  |  [Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation](https://doi.org/10.18653/v1/2024.emnlp-main.665) |  | 0 | Segmenting text into sentences plays an early and crucial role in many NLP systems. This is commonly achieved by using rule-based or statistical methods relying on lexical features such as punctuation. Although some recent works no longer exclusively rely on punctuation, we find that no prior... | Markus Frohmann, Igor Sterner, Ivan Vulic, Benjamin Minixhofer, Markus Schedl |  |
| 789 |  |  [Applying Contrastive Learning to Code Vulnerability Type Classification](https://doi.org/10.18653/v1/2024.emnlp-main.666) |  | 0 | Vulnerability classification is a crucial task in software security analysis, essential for identifying and mitigating potential security risks. Learning-based methods often perform poorly due to the long-tail distribution of vulnerability classification datasets. Recent approaches try to address... | Chen Ji, Su Yang, Hongyu Sun, Yuqing Zhang |  |
| 790 |  |  [TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts](https://doi.org/10.18653/v1/2024.emnlp-main.667) |  | 0 | Proving mathematical theorems using computer-verifiable formal languages like Lean significantly impacts mathematical reasoning. One approach to formal theorem proving involves generating complete proofs using Large Language Models (LLMs) based on Natural Language (NL) proofs. However, due to the... | Ruida Wang, Jipeng Zhang, Yizhen Jia, Rui Pan, Shizhe Diao, Renjie Pi, Tong Zhang |  |
| 791 |  |  [Multi-Level Cross-Modal Alignment for Speech Relation Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.668) |  | 0 | Speech Relation Extraction (SpeechRE) aims to extract relation triplets from speech data. However, existing studies usually use synthetic speech to train and evaluate SpeechRE models, hindering the further development of SpeechRE due to the disparity between synthetic and real speech. Meanwhile,... | Liang Zhang, Zhen Yang, Biao Fu, Ziyao Lu, Liangying Shao, Shiyu Liu, Fandong Meng, Jie Zhou, Xiaoli Wang, Jinsong Su |  |
| 792 |  |  [Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.669) |  | 0 | Active learning is an iterative labeling process that is used to obtain a small labeled subset, despite the absence of labeled data, thereby enabling to train a model for supervised tasks such as text classification.While active learning has made considerable progress in recent years due to... | Christopher Schröder, Gerhard Heyer |  |
| 793 |  |  [PANDA: Persona Attributes Navigation for Detecting and Alleviating Overuse Problem in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.670) |  | 0 | In the persona-grounded dialogue (PGD) task, it is required not only to respond fluently, but also to ground the attributes according to the current conversation topic properly. However, due to their tendency to overly ground given attributes, LLMs often generate unnatural responses provoked by... | Jinsung Kim, Seonmin Koo, Heuiseok Lim |  |
| 794 |  |  [The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm](https://doi.org/10.18653/v1/2024.emnlp-main.671) |  | 0 | A key concern with the concept of \*“alignment”\* is the implicit question of \*“alignment to what?”\*. AI systems are increasingly used across the world, yet safety alignment is often focused on homogeneous monolingual settings. Additionally, preference training and safety measures often overfit... | Aakanksha, Arash Ahmadian, Beyza Ermis, Seraphina GoldfarbTarrant, Julia Kreutzer, Marzieh Fadaee, Sara Hooker |  |
| 795 |  |  [Subword Segmentation in LLMs: Looking at Inflection and Consistency](https://doi.org/10.18653/v1/2024.emnlp-main.672) |  | 0 | The role of subword segmentation in relation to capturing morphological patterns in LLMs is currently not well explored. Ideally, one would train models like GPT using various segmentations and evaluate how well word meanings are captured. Since this is not computationally feasible, we group words... | Marion Di Marco, Alexander Fraser |  |
| 796 |  |  [Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments](https://doi.org/10.18653/v1/2024.emnlp-main.673) |  | 0 | Prior works formulate the extraction of event-specific arguments as a span extraction problem, where event arguments are explicit — i.e. assumed to be contiguous spans of text in a document. In this study, we revisit this definition of Event Extraction (EE) by introducing two key argument types... | Omar Sharif, Joseph Gatto, Madhusudan Basak, Sarah Masud Preum |  |
| 797 |  |  [Let Me Teach You: Pedagogical Foundations of Feedback for Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.674) |  | 0 | Natural Language Feedback (NLF) is an increasingly popular mechanism for aligning Large Language Models (LLMs) to human preferences. Despite the diversity of the information it can convey, NLF methods are often hand-designed and arbitrary, with little systematic grounding. At the same time,... | Beatriz Borges, Niket Tandon, Tanja Käser, Antoine Bosselut |  |
| 798 |  |  [Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data](https://doi.org/10.18653/v1/2024.emnlp-main.675) |  | 0 | Computational fact-checking (FC) relies on supervised models to verify claims based on given evidence, requiring a resource-intensive process to annotate large volumes of training data. We introduce Unown, a novel framework that generates training instances for FC systems automatically using both... | JeanFlavien Bussotti, Luca Ragazzi, Giacomo Frisoni, Gianluca Moro, Paolo Papotti |  |
| 799 |  |  [TL-CL: Task And Language Incremental Continual Learning](https://doi.org/10.18653/v1/2024.emnlp-main.676) |  | 0 | This paper introduces and investigates the problem of Task and Language Incremental Continual Learning (TLCL), wherein a multilingual model is systematically updated to accommodate new tasks in previously learned languages or new languages for established tasks. This significant yet previously... | Shrey Satapara, P. K. Srijith |  |
| 800 |  |  [Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?](https://doi.org/10.18653/v1/2024.emnlp-main.677) |  | 0 | Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such... | Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst |  |
| 801 |  |  [Empowering Multi-step Reasoning across Languages via Program-Aided Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.678) |  | 0 | In-context learning methods are popular inference strategies where Large Language Models (LLMs) are elicited to solve a task using provided demonstrations without parameter updates. Among these approaches are the reasoning methods, best exemplified by Chain-of-Thought (CoT) and Program-Aided... | Leonardo Ranaldi, Giulia Pucci, Barry Haddow, Alexandra Birch |  |
| 802 |  |  [Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.679) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in various natural language processing tasks. However, LLMs may rely on dataset biases as shortcuts for prediction, which can significantly impair their robustness and generalization capabilities. This paper presents Shortcut Suite, a... | Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu |  |
| 803 |  |  [ControlMath: Controllable Data Generation Promotes Math Generalist Models](https://doi.org/10.18653/v1/2024.emnlp-main.680) |  | 0 | Utilizing large language models (LLMs) for data augmentation has yielded encouraging results in mathematical reasoning. However, these approaches face constraints in problem diversity, potentially restricting them to in-domain/distribution data generation. To this end, we propose... | Nuo Chen, Ning Wu, Jianhui Chang, Linjun Shou, Jia Li |  |
| 804 |  |  [Where Am I From? Identifying Origin of LLM-generated Content](https://doi.org/10.18653/v1/2024.emnlp-main.681) |  | 0 | Generative models, particularly large language models (LLMs), have achieved remarkable success in producing natural and high-quality content. However, their widespread adoption raises concerns regarding copyright infringement, privacy violations, and security risks associated with AI-generated... | Liying Li, Yihan Bai, Minhao Cheng |  |
| 805 |  |  [ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment](https://doi.org/10.18653/v1/2024.emnlp-main.682) |  | 0 | We present a comprehensive evaluation of large language models for multilingual readability assessment. Existing evaluation resources lack domain and language diversity, limiting the ability for cross-domain and cross-lingual analyses. This paper introduces ReadMe++, a multilingual multi-domain... | Tarek Naous, Michael J. Ryan, Anton Lavrouk, Mohit Chandra, Wei Xu |  |
| 806 |  |  [GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text](https://doi.org/10.18653/v1/2024.emnlp-main.683) |  | 0 | Language documentation projects often involve the creation of annotated text in a format such as interlinear glossed text (IGT), which captures fine-grained morphosyntactic analyses in a morpheme-by-morpheme format. However, there are few existing resources providing large amounts of standardized,... | Michael Ginn, Lindia Tjuatja, Taiqi He, Enora Rice, Graham Neubig, Alexis Palmer, Lori S. Levin |  |
| 807 |  |  [GDTB: Genre Diverse Data for English Shallow Discourse Parsing across Modalities, Text Types, and Domains](https://doi.org/10.18653/v1/2024.emnlp-main.684) |  | 0 | Work on shallow discourse parsing in English has focused on the Wall Street Journal corpus, the only large-scale dataset for the language in the PDTB framework. However, the data is not openly available, is restricted to the news domain, and is by now 35 years old. In this paper, we present and... | Yang Janet Liu, Tatsuya Aoyama, Wesley Scivetti, Yilun Zhu, Shabnam Behzad, Lauren Levine, Jessica Lin, Devika Tiwari, Amir Zeldes |  |
| 808 |  |  [RA2FD: Distilling Faithfulness into Efficient Dialogue Systems](https://doi.org/10.18653/v1/2024.emnlp-main.685) |  | 0 | Generating faithful and fast responses is crucial in the knowledge-grounded dialogue. Retrieval Augmented Generation (RAG) strategies are effective but are inference inefficient, while previous Retrieval Free Generations (RFG) are more efficient but sacrifice faithfulness. To solve this... | Zhiyuan Zhu, Yusheng Liao, Chenxin Xu, Yunfeng Guan, Yanfeng Wang, Yu Wang |  |
| 809 |  |  [Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation](https://doi.org/10.18653/v1/2024.emnlp-main.686) |  | 0 | Large language models (LLMs) exhibit powerful reasoning capacity, as evidenced by prior studies focusing on objective topics that with unique standard answers such as arithmetic and commonsense reasoning. However, the reasoning to definite answers emphasizes more on logical thinking, and falls... | Fangrui Lv, Kaixiong Gong, Jian Liang, Xinyu Pang, Changshui Zhang |  |
| 810 |  |  [Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently](https://doi.org/10.18653/v1/2024.emnlp-main.687) |  | 0 | Recent zero-shot evaluations have highlighted important limitations in the abilities of language models (LMs) to perform meaning extraction. However, it is now well known that LMs can demonstrate radical improvements in the presence of experimental contexts such as in-context examples and... | Kanishka Misra, Allyson Ettinger, Kyle Mahowald |  |
| 811 |  |  [Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking](https://doi.org/10.18653/v1/2024.emnlp-main.688) |  | 0 | Text ranking has witnessed significant advancements, attributed to the utilization of dual-encoder enhanced by Pre-trained Language Models (PLMs). Given the proliferation of available PLMs, selecting the most effective one for a given dataset has become a non-trivial challenge. As a promising... | Jun Bai, Zhuofan Chen, Zhenzi Li, Hanhua Hong, Jianfei Zhang, Chen Li, Chenghua Lin, Wenge Rong |  |
| 812 |  |  [Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism](https://doi.org/10.18653/v1/2024.emnlp-main.689) |  | 0 | Large language models (LLMs) exhibit remarkable in-context learning (ICL) capabilities. However, the underlying working mechanism of ICL remains poorly understood. Recent research presents two conflicting views on ICL: One emphasizes the impact of similar examples in the demonstrations, stressing... | Anhao Zhao, Fanghua Ye, Jinlan Fu, Xiaoyu Shen |  |
| 813 |  |  [Self-Powered LLM Modality Expansion for Large Speech-Text Models](https://doi.org/10.18653/v1/2024.emnlp-main.690) |  | 0 | Large language models (LLMs) exhibit remarkable performance across diverse tasks, indicating their potential for expansion into large speech-text models (LSMs) by integrating speech capabilities. Although unified speech-text pre-training and multimodal data instruction-tuning offer considerable... | Tengfei Yu, Xuebo Liu, Zhiyi Hou, Liang Ding, Dacheng Tao, Min Zhang |  |
| 814 |  |  [ABSEval: An Agent-based Framework for Script Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.691) |  | 0 | Recent research indicates that large language models (LLMs) possess a certain degree of script planning capability. However, there is still a lack of focused work on evaluating scripts generated by LLMs. The evaluation of scripts poses challenges due to their logical structure, sequential... | Sirui Liang, Baoli Zhang, Jun Zhao, Kang Liu |  |
| 815 |  |  [Latent Concept-based Explanation of NLP Models](https://doi.org/10.18653/v1/2024.emnlp-main.692) |  | 0 | Interpreting and understanding the predictions made by deep learning models poses a formidable challenge due to their inherently opaque nature. Many previous efforts aimed at explaining these predictions rely on input features, specifically, the words within NLP models. However, such explanations... | Xuemin Yu, Fahim Dalvi, Nadir Durrani, Marzia Nouri, Hassan Sajjad |  |
| 816 |  |  [Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher](https://doi.org/10.18653/v1/2024.emnlp-main.693) |  | 0 |  | Hyunjong Ok, Jegwang Ryu, Jaeho Lee |  |
| 817 |  |  [Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research](https://doi.org/10.18653/v1/2024.emnlp-main.694) |  | 0 | Research in natural language processing (NLP) for Computational Social Science (CSS) heavily relies on data from social media platforms. This data plays a crucial role in the development of models for analysing socio-linguistic phenomena within online communities. In this work, we conduct an... | Yida Mu, Mali Jin, Xingyi Song, Nikolaos Aletras |  |
| 818 |  |  [The Mystery of the Pathological Path-star Task for Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.695) |  | 0 | The recently introduced path-star task is a minimal task designed to exemplify limitations to the abilities of language models (Bachmann and Nagarajan, 2024). It involves a path-star graph where multiple arms radiate from a single starting node and each node is unique. Given the start node and a... | Arvid Frydenlund |  |
| 819 |  |  [Voices in a Crowd: Searching for clusters of unique perspectives](https://doi.org/10.18653/v1/2024.emnlp-main.696) |  | 0 | Language models have been shown to reproduce underlying biases existing in their training data, which is the majority perspective by default. Proposed solutions aim to capture minority perspectives by either modelling annotator disagreements or grouping annotators based on shared metadata, both of... | Nikolas Vitsakis, Amit Parekh, Ioannis Konstas |  |
| 820 |  |  [Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent](https://doi.org/10.18653/v1/2024.emnlp-main.697) |  | 0 | Large Language Models (LLMs) have revolutionized open-domain dialogue agents but encounter challenges in multi-character role-playing (MCRP) scenarios. To address the issue, we present Neeko, an innovative framework designed for efficient multiple characters imitation. Neeko employs a dynamic... | Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang, Hao Peng, Liehuang Zhu |  |
| 821 |  |  [SLANG: New Concept Comprehension of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.698) |  | 0 | The dynamic nature of language, particularly evident in the realm of slang and memes on the Internet, poses serious challenges to the adaptability of Large Language Models (LLMs). Traditionally anchored to static datasets, these models often struggle to keep up with the rapid linguistic evolution... | Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Xueqi Cheng |  |
| 822 |  |  [Towards Interpretable Sequence Continuation: Analyzing Shared Circuits in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.699) |  | 0 | While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend... | Michael Lan, Philip Torr, Fazl Barez |  |
| 823 |  |  [Why Does New Knowledge Create Messy Ripple Effects in LLMs?](https://doi.org/10.18653/v1/2024.emnlp-main.700) |  | 0 | Extensive previous research has focused on post-training knowledge editing (KE) for language models (LMs) to ensure that knowledge remains accurate and up-to-date. One desired property and open question in KE is to let edited LMs correctly handle ripple effects, where LM is expected to answer its... | Jiaxin Qin, Zixuan Zhang, Chi Han, Pengfei Yu, Manling Li, Heng Ji |  |
| 824 |  |  [Lifelong Event Detection via Optimal Transport](https://doi.org/10.18653/v1/2024.emnlp-main.701) |  | 0 | Continual Event Detection (CED) poses a formidable challenge due to the catastrophic forgetting phenomenon, where learning new tasks (with new coming event types) hampers performance on previous ones. In this paper, we introduce a novel approach, Lifelong Event Detection via Optimal Transport... | Viet Dao, VanCuong Pham, Quyen Tran, ThanhThien Le, Linh Ngo Van, Thien Huu Nguyen |  |
| 825 |  |  [SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories](https://doi.org/10.18653/v1/2024.emnlp-main.702) |  | 0 | Given that Large Language Models (LLMs) have made significant progress in writing code, can they now be used to autonomously reproduce results from research repositories? Such a capability would be a boon to the research community, helping researchers validate, understand, and extend prior work. To... | Ben Bogin, Kejuan Yang, Shashank Gupta, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot |  |
| 826 |  |  [FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation](https://doi.org/10.18653/v1/2024.emnlp-main.703) |  | 0 | Large language models (LLMs) have become increasingly prevalent in our daily lives, leading to an expectation for LLMs to be trustworthy —- both accurate and well-calibrated (the prediction confidence should align with its ground truth correctness likelihood). Nowadays, fine-tuning has become the... | KaShun Shum, Minrui Xu, Jianshu Zhang, Zixin Chen, Shizhe Diao, Hanze Dong, Jipeng Zhang, Muhammad Omer Raza |  |
| 827 |  |  [Domain adapted machine translation: What does catastrophic forgetting forget and why?](https://doi.org/10.18653/v1/2024.emnlp-main.704) |  | 0 | Neural Machine Translation (NMT) models can be specialized by domain adaptation, often involving fine-tuning on a dataset of interest. This process risks catastrophic forgetting: rapid loss of generic translation quality. Forgetting has been widely observed, with many mitigation methods proposed.... | Danielle Saunders, Steve DeNeefe |  |
| 828 |  |  [Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.705) |  | 0 | AI-mediated communication enables users to communicate more quickly and efficiently. Various systems have been proposed such as smart reply and AI-assisted writing. Yet, the heterogeneity of the forms of inputs and architectures often renders it challenging to combine insights from user behaviour... | Benjamin Towle, Ke Zhou |  |
| 829 |  |  [Atomic Self-Consistency for Better Long Form Generations](https://doi.org/10.18653/v1/2024.emnlp-main.706) |  | 0 | Recent work has aimed to improve LLM generations by filtering out hallucinations, thereby improving the precision of the information in responses. Correctness of a long-form response, however, also depends on the recall of multiple pieces of information relevant to the question. In this paper, we... | Raghuveer Thirukovalluru, Yukun Huang, Bhuwan Dhingra |  |
| 830 |  |  ["Global is Good, Local is Bad?": Understanding Brand Bias in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.707) |  | 0 | Many recent studies have investigated social biases in LLMs but brand bias has received little attention. This research examines the biases exhibited by LLMs towards different brands, a significant concern given the widespread use of LLMs in affected use cases such as product recommendation and... | Mahammed Kamruzzaman, Hieu Nguyen, Gene Louis Kim |  |
| 831 |  |  [Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach](https://doi.org/10.18653/v1/2024.emnlp-main.708) |  | 0 | Direct speech translation (ST) models often struggle with rare words. Incorrect translation of these words can have severe consequences, impacting translation quality and user trust. While rare word translation is inherently challenging for neural models due to sparse learning signals, real-world... | Siqi Li, Danni Liu, Jan Niehues |  |
| 832 |  |  [ACE: A LLM-based Negotiation Coaching System](https://doi.org/10.18653/v1/2024.emnlp-main.709) |  | 0 | The growing prominence of LLMs has led to an increase in the development of AI tutoring systems. These systems are crucial in providing underrepresented populations with improved access to valuable education. One important area of education that is unavailable to many learners is strategic... | Ryan Shea, Aymen Kallala, Xin Liu, Michael W. Morris, Zhou Yu |  |
| 833 |  |  [TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities](https://doi.org/10.18653/v1/2024.emnlp-main.710) |  | 0 | Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented conversations, including information collection. How to utilize TOD accurately, efficiently and effectively for information collection has always been a critical and challenging task. Recent studies have demonstrated that... | Ming Zhang, Caishuang Huang, Yilong Wu, Shichun Liu, Huiyuan Zheng, Yurui Dong, Yujiong Shen, Shihan Dou, Jun Zhao, Junjie Ye, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 834 |  |  [PATIENT-ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals](https://doi.org/10.18653/v1/2024.emnlp-main.711) |  | 0 | Mental illness remains one of the most critical public health issues. Despite its importance, many mental health professionals highlight a disconnect between their training and actual real-world patient practice. To help bridge this gap, we propose PATIENT-𝜓, a novel patient simulation framework... | Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin Zhi, Shaun M. Eack, Travis Labrum, Samuel M. Murphy, Nev Jones, Kate Hardy, Hong Shen, Fei Fang, Zhiyu Chen |  |
| 835 |  |  [DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis Prediction](https://doi.org/10.18653/v1/2024.emnlp-main.712) |  | 0 | Multi-label text classification (MLTC) tasks in the medical domain often face the long-tail label distribution problem. Prior works have explored hierarchical label structures to find relevant information for few-shot classes, but mostly neglected to incorporate external knowledge from medical... | Xueren Ge, Abhishek Satpathy, Ronald D. Williams, John A. Stankovic, Homa Alemzadeh |  |
| 836 |  |  [ModSCAN: Measuring Stereotypical Bias in Large Vision-Language Models from Vision and Language Modalities](https://doi.org/10.18653/v1/2024.emnlp-main.713) |  | 0 |  | Yukun Jiang, Zheng Li, Xinyue Shen, Yugeng Liu, Michael Backes, Yang Zhang |  |
| 837 |  |  [Large Language Models Can Self-Correct with Key Condition Verification](https://doi.org/10.18653/v1/2024.emnlp-main.714) |  | 0 | Intrinsic self-correct was a method that instructed large language models (LLMs) to verify and correct their responses without external feedback. Unfortunately, the study concluded that the LLMs could not self-correct reasoning yet. We find that a simple yet effective prompting method enhances LLM... | Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang |  |
| 838 |  |  [Learning to Write Rationally: How Information Is Distributed in Non-native Speakers' Essays](https://doi.org/10.18653/v1/2024.emnlp-main.715) |  | 0 | People tend to distribute information evenly in language production for better and clearer communication. In this study, we compared essays written by second language (L2) learners with various native language (L1) backgrounds to investigate how they distribute information in their non-native L2... | Zixin Tang, Janet G. van Hell |  |
| 839 |  |  [Defending Against Social Engineering Attacks in the Age of LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.716) |  | 0 |  | Lin Ai, Tharindu Kumarage, Amrita Bhattacharjee, Zizhou Liu, Zheng Hui, Michael Davinroy, James Cook, Laura Cassani, Kirill Trapeznikov, Matthias Kirchner, Arslan Basharat, Anthony Hoogs, Joshua Garland, Huan Liu, Julia Hirschberg |  |
| 840 |  |  [Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models](https://doi.org/10.18653/v1/2024.emnlp-main.717) |  | 0 | Foundation models (FMs) adapt surprisingly well to downstream tasks with fine-tuning. However, their colossal parameter space prohibits their training on resource-constrained edge-devices. For federated fine-tuning, we need to consider the smaller FMs of few billion parameters at most, namely... | Yae Jee Cho, Luyang Liu, Zheng Xu, Aldi Fahrezi, Gauri Joshi |  |
| 841 |  |  [Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training](https://doi.org/10.18653/v1/2024.emnlp-main.718) |  | 0 | Existing speculative decoding methods typically require additional model structure and training processes to assist the model for draft token generation. This makes the migration of acceleration methods to the new model more costly and more demanding on device memory. To address this problem, we... | Yixuan Wang, Xianzhen Luo, Fuxuan Wei, Yijun Liu, Qingfu Zhu, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che |  |
| 842 |  |  [Target-Aware Language Modeling via Granular Data Sampling](https://doi.org/10.18653/v1/2024.emnlp-main.719) |  | 0 | Language model pretraining generally targets a broad range of use cases and incorporates data from diverse sources. However, there are instances where we desire a model that excels in specific areas without markedly compromising performance in other areas. A cost-effective and straightforward... | Ernie Chang, PinJie Lin, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabatin, Zechun Liu, Yangyang Shi, Vikas Chandra |  |
| 843 |  |  [SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness](https://doi.org/10.18653/v1/2024.emnlp-main.720) |  | 0 | Social media is often the first place where communities discuss the latest societal trends. Prior works have utilized this platform to extract epidemic-related information (e.g. infections, preventive measures) to provide early warnings for epidemic prediction. However, these works only focused on... | Tanmay Parekh, Jeffrey Kwan, Jiarui Yu, Sparsh Johri, Hyosang Ahn, Sreya Muppalla, KaiWei Chang, Wei Wang, Nanyun Peng |  |
| 844 |  |  [CoGen: Learning from Feedback with Coupled Comprehension and Generation](https://doi.org/10.18653/v1/2024.emnlp-main.721) |  | 0 | Systems with both language comprehension and generation capabilities can benefit from the tight connection between the two. This work studies coupling comprehension and generation with focus on continually learning from interaction with users. We propose techniques to tightly integrate the two... | Mustafa Omer Gul, Yoav Artzi |  |
| 845 |  |  [UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks](https://doi.org/10.18653/v1/2024.emnlp-main.722) |  | 0 | The great success of large language models has encouraged the development of large multimodal models, with a focus on image-language interaction. Despite promising results in various image-language downstream tasks, it is still challenging and unclear how to extend the capabilities of these models... | Yuanhao Xiong, Yixin Nie, Haotian Liu, Boxin Wang, Jun Chen, Rong Jin, ChoJui Hsieh, Lorenzo Torresani, Jie Lei |  |
| 846 |  |  [Story Morals: Surfacing value-driven narrative schemas using large language models](https://doi.org/10.18653/v1/2024.emnlp-main.723) |  | 0 | Stories are not only designed to entertain but encode lessons reflecting their authors’ beliefs about the world. In this paper, we propose a new task of narrative schema labelling based on the concept of “story morals” to identify the values and lessons conveyed in stories. Using large language... | David Hobson, Haiqi Zhou, Derek Ruths, Andrew Piper |  |
| 847 |  |  [OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants](https://doi.org/10.18653/v1/2024.emnlp-main.724) |  | 0 | Warning: Contents of this paper may be upsetting.Public attitudes towards key societal issues, expressed on online media, are of immense value in policy and reform efforts, yet challenging to understand at scale. We study one such social issue: homelessness in the U.S., by leveraging the remarkable... | Jaspreet Ranjit, Brihi Joshi, Rebecca Dorn, Laura Petry, Olga Koumoundouros, Jayne Bottarini, Peichen Liu, Eric Rice, Swabha Swayamdipta |  |
| 848 |  |  [AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies](https://doi.org/10.18653/v1/2024.emnlp-main.725) |  | 0 | Humans regularly engage in analogical thinking, relating personal experiences to current situations (X is analogous to Y because of Z). Analogical thinking allows humans to solve problems in creative ways, grasp difficult concepts, and articulate ideas more effectively. Can language models (LMs) do... | Xiao Ye, Andrew Wang, Jacob Choi, Yining Lu, Shreya Sharma, Lingfeng Shen, Vijay Murari Tiyyala, Nicholas Andrews, Daniel Khashabi |  |
| 849 |  |  [SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents](https://doi.org/10.18653/v1/2024.emnlp-main.726) |  | 0 | Scientific information extraction (SciIE) is critical for converting unstructured knowledge from scholarly articles into structured data (entities and relations). Several datasets have been proposed for training and validating SciIE models. However, due to the high complexity and cost of annotating... | Qi Zhang, Zhijia Chen, Huitong Pan, Cornelia Caragea, Longin Jan Latecki, Eduard C. Dragut |  |
| 850 |  |  [Analysis of Plan-based Retrieval for Grounded Text Generation](https://doi.org/10.18653/v1/2024.emnlp-main.727) |  | 0 | In text generation, hallucinations refer to the generation of seemingly coherent text that contradicts established knowledge. One compelling hypothesis is that hallucinations occur when a language model is given a generation task outside its parametric knowledge (due to rarity, recency, domain,... | Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat, Andrew McCallum, Manzil Zaheer |  |
| 851 |  |  [Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors](https://doi.org/10.18653/v1/2024.emnlp-main.728) |  | 0 | Accurate text summarization is one of the most common and important tasks performed by Large Language Models, where the costs of human review for an entire document may be high, but the costs of errors in summarization may be even greater. We propose Detecting Errors through Ensembling Prompts... | Alex Chandler, Devesh Surve, Hui Su |  |
| 852 |  |  [RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.729) |  | 0 | Preference optimization techniques have become a standard final stage for training state-of-art large language models (LLMs). However, despite widespread adoption, the vast majority of work to-date has focused on a small set of high-resource languages like English and Chinese. This captures a small... | John Dang, Arash Ahmadian, Kelly Marchisio, Julia Kreutzer, Ahmet Üstün, Sara Hooker |  |
| 853 |  |  [Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree](https://doi.org/10.18653/v1/2024.emnlp-main.730) |  | 0 | Logical fallacy uses invalid or faulty reasoning in the construction of a statement. Despite the prevalence and harmfulness of logical fallacies, detecting and classifying logical fallacies still remains a challenging task. We observe that logical fallacies often use connective words to indicate an... | Yuanyuan Lei, Ruihong Huang |  |
| 854 |  |  [Chain and Causal Attention for Efficient Entity Tracking](https://doi.org/10.18653/v1/2024.emnlp-main.731) |  | 0 | This paper investigates the limitations of transformers for entity-tracking tasks in large language models. We identify a theoretical constraint, showing that transformers require at least log2 (n+1) layers to handle entity tracking with n state changes. To address this issue, we propose an... | Erwan Fagnou, Paul Caillon, Blaise Delattre, Alexandre Allauzen |  |
| 855 |  |  [BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.732) |  | 0 | Safety backdoor attacks in large language models (LLMs) enable harmful behaviors to be stealthily triggered while evading detection during normal interactions. The high dimensionality of the trigger search space and the diverse range of potential malicious behaviors in LLMs make this a critical... | Yi Zeng, Weiyu Sun, Tran Ngoc Huynh, Dawn Song, Bo Li, Ruoxi Jia |  |
| 856 |  |  [A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution](https://doi.org/10.18653/v1/2024.emnlp-main.733) |  | 0 | Authorship attribution aims to identify the origin or author of a document. Traditional approaches have heavily relied on manual features and fail to capture long-range correlations, limiting their effectiveness. Recent advancements leverage text embeddings from pre-trained language models, which... | Zhengmian Hu, Tong Zheng, Heng Huang |  |
| 857 |  |  [FAC²E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition](https://doi.org/10.18653/v1/2024.emnlp-main.734) |  | 0 | Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs’... | Xiaoqiang Wang, Lingfei Wu, Tengfei Ma, Bang Liu |  |
| 858 |  |  [OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation](https://doi.org/10.18653/v1/2024.emnlp-main.735) |  | 0 | Audio separation in real-world scenarios, where mixtures contain a variable number of sources, presents significant challenges due to limitations of existing models, such as over-separation, under-separation, and dependence on predefined training sources. We propose OpenSep, a novel framework that... | Tanvir Mahmud, Diana Marculescu |  |
| 859 |  |  [Language Concept Erasure for Language-invariant Dense Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.736) |  | 0 | Multilingual models aim for language-invariant representations but still prominently encode language identity. This, along with the scarcity of high-quality parallel retrieval data, limits their performance in retrieval. We introduce LANCER, a multi-task learning framework that improves... | Zhiqi Huang, Puxuan Yu, Shauli Ravfogel, James Allan |  |
| 860 |  |  [Learning Personalized Alignment for Evaluating Open-ended Text Generation](https://doi.org/10.18653/v1/2024.emnlp-main.737) |  | 0 | Recent research has increasingly focused on evaluating large language models’ (LLMs) alignment with diverse human values and preferences, particularly for open-ended tasks like story generation. Traditional evaluation metrics rely heavily on lexical similarity with human-written references, often... | Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian |  |
| 861 |  |  [Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks](https://doi.org/10.18653/v1/2024.emnlp-main.738) |  | 0 | We find that language models have difficulties generating fallacious and deceptive reasoning. When asked to generate deceptive outputs, language models tend to leak honest counterparts but believe them to be false. Exploiting this deficiency, we propose a jailbreak attack method that elicits an... | Yue Zhou, Henry Peng Zou, Barbara Di Eugenio, Yang Zhang |  |
| 862 |  |  [Turn Waste into Worth: Rectifying Top-k Router of MoE](https://doi.org/10.18653/v1/2024.emnlp-main.739) |  | 0 | Sparse Mixture of Experts (MoE) models are popular for training large language models due to their computational efficiency. However, the commonly used top-k routing mechanism suffers from redundancy computation and memory costs due to the unbalanced routing. Some experts are overflow, where the... | Zhiyuan Zeng, Qipeng Guo, Zhaoye Fei, Zhangyue Yin, Yunhua Zhou, Linyang Li, Tianxiang Sun, Hang Yan, Dahua Lin, Xipeng Qiu |  |
| 863 |  |  [Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination](https://doi.org/10.18653/v1/2024.emnlp-main.740) |  | 0 | This paper presents a series of investigations into an interesting phenomenon where we observe performance increases in large language models (LLMs) when providing a prompt that causes and exploits hallucination. We propose null-shot prompting, a counter-intuitive approach where we intentionally... | Pittawat Taveekitworachai, Febri Abdullah, Ruck Thawonmas |  |
| 864 |  |  [CommVQA: Situating Visual Question Answering in Communicative Contexts](https://doi.org/10.18653/v1/2024.emnlp-main.741) |  | 0 | Current visual question answering (VQA) models tend to be trained and evaluated on image-question pairs in isolation. However, the questions people ask are dependent on their informational needs and prior knowledge about the image content. To evaluate how situating images within naturalistic... | Nandita Naik, Christopher Potts, Elisa Kreiss |  |
| 865 |  |  [Ouroboros: Generating Longer Drafts Phrase by Phrase for Faster Speculative Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.742) |  | 0 | Speculative decoding is a widely used method that accelerates the generation process of large language models (LLMs) with no compromise in model performance. It achieves this goal by using an existing smaller model for drafting and then employing the target LLM to verify the draft in a low-cost... | Weilin Zhao, Yuxiang Huang, Xu Han, Wang Xu, Chaojun Xiao, Xinrong Zhang, Yewei Fang, Kaihuo Zhang, Zhiyuan Liu, Maosong Sun |  |
| 866 |  |  [1+1\textgreater2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?](https://doi.org/10.18653/v1/2024.emnlp-main.743) |  | 0 | Large Language Models (LLMs) have garnered significant attention due to their remarkable ability to process information across various languages. Despite their capabilities, they exhibit inconsistencies in handling identical queries in different languages, presenting challenges for further... | Yue Huang, Chenrui Fan, Yuan Li, Siyuan Wu, Tianyi Zhou, Xiangliang Zhang, Lichao Sun |  |
| 867 |  |  [How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.744) |  | 0 | This paper introduces a novel generalized self-imitation learning GSIL framework, which effectively and efficiently aligns large language models with offline demonstration data. We develop GSIL by deriving a surrogate objective of imitation learning with density ratio estimates, facilitating the... | Teng Xiao, Mingxiao Li, Yige Yuan, Huaisheng Zhu, Chao Cui, Vasant G. Honavar |  |
| 868 |  |  [Style-Specific Neurons for Steering LLMs in Text Style Transfer](https://doi.org/10.18653/v1/2024.emnlp-main.745) |  | 0 | Text style transfer (TST) aims to modify the style of a text without altering its original meaning. Large language models (LLMs) demonstrate superior performance across multiple tasks, including TST. However, in zero-shot setups, they tend to directly copy a significant portion of the input text to... | Wen Lai, Viktor Hangya, Alexander Fraser |  |
| 869 |  |  [Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers](https://doi.org/10.18653/v1/2024.emnlp-main.746) |  | 0 | Query rewriting is a crucial technique for passage retrieval in open-domain conversational question answering (CQA). It decontexualizes conversational queries into self-contained questions suitable for off-the-shelf retrievers. Existing methods attempt to incorporate retriever’s preference during... | Tianhua Zhang, Kun Li, Hongyin Luo, Xixin Wu, James R. Glass, Helen Meng |  |
| 870 |  |  [Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.747) |  | 0 | Relation extraction (RE) aims to identify semantic relationships between entities within text. Despite considerable advancements, existing models predominantly require extensive annotated training data, which is both costly and labor-intensive to collect. Moreover, these models often struggle to... | Sizhe Zhou, Yu Meng, Bowen Jin, Jiawei Han |  |
| 871 |  |  [DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.748) |  | 0 | We introduce DA-Code, a code generation benchmark specifically designed to assess LLMs on agent-based data science tasks. This benchmark features three core elements: First, the tasks within DA-Code are inherently challenging, setting them apart from traditional code generation tasks and demanding... | Yiming Huang, Jianwen Luo, Yan Yu, Yitong Zhang, Fangyu Lei, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, Kang Liu |  |
| 872 |  |  [Leveraging Context-Aware Prompting for Commit Message Generation](https://doi.org/10.18653/v1/2024.emnlp-main.749) |  | 0 | Writing comprehensive commit messages is tedious yet important, because these messages describe changes of code, such as fixing bugs or adding new features. However, most existing methods focus on either only the changed lines or nearest context lines, without considering the effectiveness of... | Zhihua Jiang, Jianwei Chen, Dongning Rao, Guanghui Ye |  |
| 873 |  |  [Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination](https://doi.org/10.18653/v1/2024.emnlp-main.750) |  | 0 | We present a large-scale study of linguistic bias exhibited by ChatGPT covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-”standard” varieties from around the world). We prompted GPT-3.5 Turbo and GPT-4 with text by native speakers of... | Eve Fleisig, Genevieve Smith, Madeline Bossi, Ishita Rustagi, Xavier Yin, Dan Klein |  |
| 874 |  |  [Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning](https://doi.org/10.18653/v1/2024.emnlp-main.751) |  | 0 | Model editing aims to correct outdated or erroneous knowledge in large language models (LLMs) without the need for costly retraining. Lifelong model editing is the most challenging task that caters to the continuous editing requirements of LLMs. Prior works primarily focus on single or batch... | Qizhou Chen, Taolin Zhang, Xiaofeng He, Dongyang Li, Chengyu Wang, Longtao Huang, Hui Xue' |  |
| 875 |  |  [A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.752) |  | 0 | Due to the continuous emergence of new data, version updates have become an indispensable requirement for Large Language Models (LLMs). The training paradigms for version updates of LLMs include pre-training from scratch (PTFS) and continual pre-training (CPT). Preliminary experiments demonstrate... | Zhihao Wang, Shiyu Liu, Jianheng Huang, Wang Zheng, Yixuan Liao, Xiaoxin Chen, Junfeng Yao, Jinsong Su |  |
| 876 |  |  [Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages](https://doi.org/10.18653/v1/2024.emnlp-main.753) |  | 0 | Existing zero-shot cross-lingual NER approaches require substantial prior knowledge of the target language, which is impractical for low-resource languages.In this paper, we propose a novel approach to NER using phonemic representation based on the International Phonetic Alphabet (IPA) to bridge... | Jimin Sohn, Haeji Jung, Alex Cheng, Jooeon Kang, Yilin Du, David R. Mortensen |  |
| 877 |  |  [An Analysis and Mitigation of the Reversal Curse](https://doi.org/10.18653/v1/2024.emnlp-main.754) |  | 0 |  | Ang Lv, Kaiyi Zhang, Shufang Xie, Quan Tu, Yuhan Chen, JiRong Wen, Rui Yan |  |
| 878 |  |  [Exploring the Practicality of Generative Retrieval on Dynamic Corpora](https://doi.org/10.18653/v1/2024.emnlp-main.755) |  | 0 | Benchmarking the performance of information retrieval (IR) is mostly conducted with a fixed set of documents (static corpora). However, in realistic scenarios, this is rarely the case and the documents to be retrieved are constantly updated and added. In this paper, we focus on Generative... | Chaeeun Kim, Soyoung Yoon, Hyunji Lee, Joel Jang, Sohee Yang, Minjoon Seo |  |
| 879 |  |  [OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.756) |  | 0 | Entity Linking (EL) is the process of associating ambiguous textual mentions to specific entities in a knowledge base.Traditional EL methods heavily rely on large datasets to enhance their performance, a dependency that becomes problematic in the context of few-shot entity linking, where only a... | Xukai Liu, Ye Liu, Kai Zhang, Kehang Wang, Qi Liu, Enhong Chen |  |
| 880 |  |  [Don't Just Say "I don't know"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations](https://doi.org/10.18653/v1/2024.emnlp-main.757) |  | 0 | Despite the remarkable abilities of Large Language Models (LLMs) to answer questions, they often display a considerable level of overconfidence even when the question does not have a definitive answer. To avoid providing hallucinated answers to these unknown questions, existing studies typically... | Yang Deng, Yong Zhao, Moxin Li, SeeKiong Ng, TatSeng Chua |  |
| 881 |  |  [Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning](https://doi.org/10.18653/v1/2024.emnlp-main.758) |  | 0 | Large Language Models (LLMs) have shown impressive capabilities, yet they still struggle with math reasoning. In this work, we propose CoT-Influx, a novel approach that pushes the boundary of few-shot Chain-of-Thoughts (CoT) learning to improve LLM mathematical reasoning. Motivated by the... | Xijie Huang, Li Lyna Zhang, KwangTing Cheng, Fan Yang, Mao Yang |  |
| 882 |  |  [Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark](https://doi.org/10.18653/v1/2024.emnlp-main.759) |  | 0 | The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the close-ended question-answering (QA) task with answer options for evaluation. However, many clinical decisions involve answering open-ended questions without pre-set... | Fenglin Liu, Zheng Li, Hongjian Zhou, Qingyu Yin, Jingfeng Yang, Xianfeng Tang, Chen Luo, Ming Zeng, Haoming Jiang, Yifan Gao, Priyanka Nigam, Sreyashi Nag, Bing Yin, Yining Hua, Xuan Zhou, Omid Rohanian, Anshul Thakur, Lei A. Clifton, David A. Clifton |  |
| 883 |  |  [Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction](https://doi.org/10.18653/v1/2024.emnlp-main.760) |  | 0 | Automated red teaming is an effective method for identifying misaligned behaviors in large language models (LLMs). Existing approaches, however, often focus primarily on improving attack success rates while overlooking the need for comprehensive test case coverage. Additionally, most of these... | Jinchuan Zhang, Yan Zhou, Yaxin Liu, Ziming Li, Songlin Hu |  |
| 884 |  |  [Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.761) |  | 0 | Activation Editing, which involves directly editting the internal representations of large language models (LLMs) to alter their behavior and achieve desired properties, has emerged as a promising area of research. Existing works primarily treat LLMs’ activations as points in space and modify them... | VanCuong Pham, Thien Nguyen |  |
| 885 |  |  [DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG](https://doi.org/10.18653/v1/2024.emnlp-main.762) |  | 0 | In the rapidly evolving landscape of language, resolving new linguistic expressions in continuously updating knowledge bases remains a formidable challenge. This challenge becomes critical in retrieval-augmented generation (RAG) with knowledge bases, as emerging expressions hinder the retrieval of... | Jinyoung Kim, Dayoon Ko, Gunhee Kim |  |
| 886 |  |  [Preserving Generalization of Language models in Few-shot Continual Relation Extraction](https://doi.org/10.18653/v1/2024.emnlp-main.763) |  | 0 | Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic area of study where models can sequentially integrate knowledge from new relations with limited labeled data while circumventing catastrophic forgetting and preserving prior knowledge from pre-trained backbones. In this work,... | Quyen Tran, Nguyen Xuan Thanh, Nguyen Hoang Anh, Nam Le Hai, Trung Le, Linh Van Ngo, Thien Huu Nguyen |  |
| 887 |  |  [A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations](https://doi.org/10.18653/v1/2024.emnlp-main.764) |  | 0 | Large Language Models (LLMs) have recently gained significant attention due to their remarkable capabilities in performing diverse tasks across various domains. However, a thorough evaluation of these models is crucial before deploying them in real-world applications to ensure they produce reliable... | Md. Tahmid Rahman Laskar, Sawsan Alqahtani, M. Saiful Bari, Mizanur Rahman, Mohammad Abdullah Matin Khan, Haidar Khan, Israt Jahan, Amran Bhuiyan, CheeWei Tan, Md. Rizwan Parvez, Enamul Hoque, Shafiq Joty, Jimmy Huang |  |
| 888 |  |  [Consecutive Batch Model Editing with HooK Layers](https://doi.org/10.18653/v1/2024.emnlp-main.765) |  | 0 | As the typical retraining paradigm is unacceptably time- and resource-consuming, researchers are turning to model editing to find an effective way that supports both consecutive and batch scenarios to edit the model behavior directly. Despite all these practical expectations, existing model editing... | Shuaiyi Li, Yang Deng, Deng Cai, Hongyuan Lu, Liang Chen, Wai Lam |  |
| 889 |  |  [Topic-Oriented Open Relation Extraction with A Priori Seed Generation](https://doi.org/10.18653/v1/2024.emnlp-main.766) |  | 0 | The field of open relation extraction (ORE) has recently observed significant advancement thanks to the growing capability of large language models (LLMs). Nevertheless, challenges persist when ORE is performed on specific topics. Existing methods give sub-optimal results in five dimensions:... | Linyi Ding, Jinfeng Xiao, Sizhe Zhou, Chaoqi Yang, Jiawei Han |  |
| 890 |  |  [Related Work and Citation Text Generation: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.767) |  | 0 | To convince readers of the novelty of their research paper, authors must perform a literature review and compose a coherent story that connects and relates prior works to the current work. This challenging nature of literature review writing makes automatic related work generation (RWG)... | Xiangci Li, Jessica Ouyang |  |
| 891 |  |  [Curriculum Consistency Learning for Conditional Sentence Generation](https://doi.org/10.18653/v1/2024.emnlp-main.768) |  | 0 | Consistency learning (CL) has proven to be a valuable technique for improving the robustness of models in conditional sentence generation (CSG) tasks by ensuring stable predictions across various input data forms. However, models augmented with CL often face challenges in optimizing consistency... | Liangxin Liu, Xuebo Liu, Lian Lian, Shengjun Cheng, Jun Rao, Tengfei Yu, Hexuan Deng, Min Zhang |  |
| 892 |  |  [A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences](https://doi.org/10.18653/v1/2024.emnlp-main.769) |  | 0 | The reasoning abilities of Large Language Models (LLMs) are becoming a central focus of study in NLP. In this paper, we consider the case of syllogistic reasoning, an area of deductive reasoning studied extensively in logic and cognitive psychology. Previous research has shown that pre-trained LLMs... | Leonardo Bertolazzi, Albert Gatt, Raffaella Bernardi |  |
| 893 |  |  [Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision](https://doi.org/10.18653/v1/2024.emnlp-main.770) |  | 0 |  | Fan Jiang, Tom Drummond, Trevor Cohn |  |
| 894 |  |  [MOSEL: 950, 000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages](https://doi.org/10.18653/v1/2024.emnlp-main.771) |  | 0 | The rise of foundation models (FMs), coupled with regulatory efforts addressing their risks and impacts, has sparked significant interest in open-source models. However, existing speech FMs (SFMs) fall short of full compliance with the open-source principles, even if claimed otherwise, as no... | Marco Gaido, Sara Papi, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri |  |
| 895 |  |  [Improving Knowledge Graph Completion with Structure-Aware Supervised Contrastive Learning](https://doi.org/10.18653/v1/2024.emnlp-main.772) |  | 0 | Knowledge Graphs (KGs) often suffer from incomplete knowledge, which restricts their utility. Recently, Contrastive Learning (CL) has been introduced to Knowledge Graph Completion (KGC), significantly improving the discriminative capabilities of KGC models and setting new benchmarks in performance.... | Jiashi Lin, Lifang Wang, Xinyu Lu, Zhongtian Hu, Wei Zhang, Wenxuan Lu |  |
| 896 |  |  [Contribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation](https://doi.org/10.18653/v1/2024.emnlp-main.773) |  | 0 | Universal Dependencies (UD) is a global initiative to create a standard annotation for the dependency syntax of human languages. Addressing its deviation from typological principles, this study presents an empirical investigation of a typologically motivated transformation of UD proposed by William... | Ali Basirat, Navid Hemmati |  |
| 897 |  |  [TRoTR: A Framework for Evaluating the Re-contextualization of Text Reuse](https://doi.org/10.18653/v1/2024.emnlp-main.774) |  | 0 | Current approaches for detecting text reuse do not focus on recontextualization, i.e., how the new context(s) of a reused text differs from its original context(s). In this paper, we propose a novel framework called TRoTR that relies on the notion of topic relatedness for evaluating the diachronic... | Francesco Periti, Pierluigi Cassotti, Stefano Montanelli, Nina Tahmasebi, Dominik Schlechtweg |  |
| 898 |  |  [Structured Optimal Brain Pruning for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.775) |  | 0 | The massive parameters and computational demands hinder the widespread application of Large Language Models (LLMs). Network pruning provides a practical solution to this problem. However, existing pruning works for LLMs mainly focus on unstructured pruning or necessitate post-pruning fine-tuning.... | Jiateng Wei, Quan Lu, Ning Jiang, Siqi Li, Jingyang Xiang, Jun Chen, Yong Liu |  |
| 899 |  |  [Automatically Generated Definitions and their utility for Modeling Word Meaning](https://doi.org/10.18653/v1/2024.emnlp-main.776) |  | 0 | Modeling lexical semantics is a challenging task, often suffering from interpretability pitfalls. In this paper, we delve into the generation of dictionary-like sense definitions and explore their utility for modeling word meaning. We fine-tuned two Llama models and include an existing T5-based... | Francesco Periti, David Alfter, Nina Tahmasebi |  |
| 900 |  |  [How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data](https://doi.org/10.18653/v1/2024.emnlp-main.777) |  | 0 | Recently, there has been a growing interest in studying how to construct better code instruction tuning data. However, we observe Code models trained with these datasets exhibit high performance on HumanEval but perform worse on other benchmarks such as LiveCodeBench. Upon further investigation, we... | Yejie Wang, Keqing He, Dayuan Fu, Zhuoma Gongque, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, Guanting Dong, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu |  |
| 901 |  |  [MAIR: A Massive Benchmark for Evaluating Instructed Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.778) |  | 0 | Recent information retrieval (IR) models are pre-trained and instruction-tuned on massive datasets and tasks, enabling them to perform well on a wide range of tasks and potentially generalize to unseen tasks with instructions. However, existing IR benchmarks focus on a limited scope of tasks,... | Weiwei Sun, Zhengliang Shi, Wu Long, Lingyong Yan, Xinyu Ma, Yiding Liu, Min Cao, Dawei Yin, Zhaochun Ren |  |
| 902 |  |  [Rethinking the Evaluation of In-Context Learning for LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.779) |  | 0 | In-context learning (ICL) has demonstrated excellent performance across various downstream NLP tasks, especially when synergized with powerful large language models (LLMs). Existing studies evaluate ICL methods primarily based on downstream task performance. This evaluation protocol overlooks the... | Guoxin Yu, Lemao Liu, Mo Yu, Yue Yu, Xiang Ao |  |
| 903 |  |  [Cluster-Norm for Unsupervised Probing of Knowledge](https://doi.org/10.18653/v1/2024.emnlp-main.780) |  | 0 | The deployment of language models brings challenges in generating reliable text, especially when these models are fine-tuned with human preferences. To extract the encoded knowledge in these models without (potentially) biased human labels, unsupervised probing techniques like Contrast-Consistent... | Walter Laurito, Sharan Maiya, Grégoire Dhimoïla, Owen Yeung, Kaarel Hänni |  |
| 904 |  |  [Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries](https://doi.org/10.18653/v1/2024.emnlp-main.781) |  | 0 | Large language models (LLMs) can solve complex multi-step problems, but little is known about how these computations are implemented internally. Motivated by this, we study how LLMs answer multi-hop queries such as “The spouse of the performer of Imagine is”. These queries require two information... | Eden Biran, Daniela Gottesman, Sohee Yang, Mor Geva, Amir Globerson |  |
| 905 |  |  [Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration](https://doi.org/10.18653/v1/2024.emnlp-main.782) |  | 0 | The black-box nature of large language models (LLMs) poses challenges in interpreting results, impacting issues such as data intellectual property protection and hallucination tracing. Training data attribution (TDA) methods are considered effective solutions to address these challenges.Most recent... | Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 906 |  |  [Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts](https://doi.org/10.18653/v1/2024.emnlp-main.783) |  | 0 | As the utilization of Large Language Models (LLMs) becomes more widespread, there is a growing demand for their ability to handle more complex and longer external knowledge across various use cases. Most existing evaluations of the open-ended question answering (ODQA) task, which necessitates the... | Seonmin Koo, Jinsung Kim, YoungJoon Jang, Chanjun Park, Heuiseok Lim |  |
| 907 |  |  [KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students](https://doi.org/10.18653/v1/2024.emnlp-main.784) |  | 0 | Flashcard schedulers rely on 1) \*student models\* to predict the flashcards a student knows; and 2) \*teaching policies\* to pick which cards to show next via these predictions.Prior student models, however, just use study data like the student’s past responses, ignoring the text on cards. We... | Matthew Shu, Nishant Balepur, Shi Feng, Jordan L. BoydGraber |  |
| 908 |  |  [Large Language Models Can Be Contextual Privacy Protection Learners](https://doi.org/10.18653/v1/2024.emnlp-main.785) |  | 0 | The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data often contains contextually sensitive personally identifiable information... | Yijia Xiao, Yiqiao Jin, Yushi Bai, Yue Wu, Xianjun Yang, Xiao Luo, Wenchao Yu, Xujiang Zhao, Yanchi Liu, Quanquan Gu, Haifeng Chen, Wei Wang, Wei Cheng |  |
| 909 |  |  [A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick](https://doi.org/10.18653/v1/2024.emnlp-main.786) |  | 0 | Keyword mnemonics are memorable explanations that link new terms to simpler keywords.Prior work generates mnemonics for students, but they do not train models using mnemonics students prefer and aid learning.We build SMART, a mnemonic generator trained on feedback from real students learning new... | Nishant Balepur, Matthew Shu, Alexander Miserlis Hoyle, Alison Robey, Shi Feng, Seraphina GoldfarbTarrant, Jordan L. BoydGraber |  |
| 910 |  |  [Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.787) |  | 0 | Large language models (LLMs) are typically fine-tuned on diverse and extensive datasets sourced from various origins to develop a comprehensive range of skills, such as writing, reasoning, chatting, coding, and more. Each skill has unique characteristics, and these datasets are often heterogeneous... | Minghao Wu, ThuyTrang Vu, Lizhen Qu, Reza Haf |  |
| 911 |  |  [MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction](https://doi.org/10.18653/v1/2024.emnlp-main.788) |  | 0 | Chemical representation learning has gained increasing interest due to the limited availability of supervised data in fields such as drug and materials design. This interest particularly extends to chemical language representation learning, which involves pre-training Transformers on SMILES... | JunHyung Park, Yeachan Kim, Mingyu Lee, Hyuntae Park, SangKeun Lee |  |
| 912 |  |  [First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.789) |  | 0 | Explicit multi-step reasoning, such as chain-of-thought, is widely adopted in the community to explore the better performance of language models (LMs). We report on the systematic strategy that LMs use in this process.Our controlled experiments reveal that LMs rely more heavily on heuristics, such... | Yoichi Aoki, Keito Kudo, Tatsuki Kuribayashi, Shusaku Sone, Masaya Taniguchi, Keisuke Sakaguchi, Kentaro Inui |  |
| 913 |  |  [Tools Fail: Detecting Silent Errors in Faulty Tools](https://doi.org/10.18653/v1/2024.emnlp-main.790) |  | 0 | Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework... | Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk |  |
| 914 |  |  [Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.emnlp-main.791) |  | 0 | Semantic Textual Similarity (STS) constitutes a critical research direction in computational linguistics and serves as a key indicator of the encoding capabilities of embedding models. Driven by advances in pre-trained language models and contrastive learning, leading sentence representation... | Bowen Zhang, Chunping Li |  |
| 915 |  |  [Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing](https://doi.org/10.18653/v1/2024.emnlp-main.792) |  | 0 | Recent efforts have aimed to utilize multilingual pretrained language models (mPLMs) to extend semantic parsing (SP) across multiple languages without requiring extensive annotations. However, achieving zero-shot cross-lingual transfer for SP remains challenging, leading to a performance gap... | Deokhyung Kang, Seonjeong Hwang, Yunsu Kim, Gary Geunbae Lee |  |
| 916 |  |  [Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling](https://doi.org/10.18653/v1/2024.emnlp-main.793) |  | 0 | This study explores replacing Transformers in Visual Language Models (VLMs) with Mamba, a recent structured state space model (SSM) that demonstrates promising performance in sequence modeling. We test models up to 3B parameters under controlled conditions, showing that Mamba-based VLMs outperforms... | Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi |  |
| 917 |  |  [Are LLMs Good Zero-Shot Fallacy Classifiers?](https://doi.org/10.18653/v1/2024.emnlp-main.794) |  | 0 | Fallacies are defective arguments with faulty reasoning. Detecting and classifying them is a crucial NLP task to prevent misinformation, manipulative claims, and biased decisions. However, existing fallacy classifiers are limited by the requirement for sufficient labeled data for training, which... | Fengjun Pan, Xiaobao Wu, Zongrui Li, Anh Tuan Luu |  |
| 918 |  |  [The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.795) |  | 0 | Understanding in-context learning (ICL) capability that enables large language models (LLMs) to excel in proficiency through demonstration examples is of utmost importance. This importance stems not only from the better utilization of this capability across various tasks, but also from the... | Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He |  |
| 919 |  |  [More DWUGs: Extending and Evaluating Word Usage Graph Datasets in Multiple Languages](https://doi.org/10.18653/v1/2024.emnlp-main.796) |  | 0 | Word Usage Graphs (WUGs) represent human semantic proximity judgments for pairs of word uses in a weighted graph, which can be clustered to infer word sense clusters from simple pairwise word use judgments, avoiding the need for word sense definitions. SemEval-2020 Task 1 provided the first and to... | Dominik Schlechtweg, Pierluigi Cassotti, Bill Noble, David Alfter, Sabine Schulte im Walde, Nina Tahmasebi |  |
| 920 |  |  [Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification](https://doi.org/10.18653/v1/2024.emnlp-main.797) |  | 0 | Recent advances in fine-tuning Vision-Language Models (VLMs) have witnessed the success of prompt tuning and adapter tuning, while the classic model fine-tuning on inherent parameters seems to be overlooked. It is believed that fine-tuning the parameters of VLMs with few-shot samples corrupts the... | Ming Li, Jike Zhong, Chenxin Li, Liuzhuozheng Li, Nie Lin, Masashi Sugiyama |  |
| 921 |  |  [ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos](https://doi.org/10.18653/v1/2024.emnlp-main.798) |  | 0 | Previous studies on question generation from videos have mostly focused on generating questions about common objects and attributes and hence are not entity-centric. In this work, we focus on the generation of entity-centric information-seeking questions from videos. Such a system could be useful... | Arpan Phukan, Manish Gupta, Asif Ekbal |  |
| 922 |  |  [Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.799) |  | 0 | The distractor generation task focuses on generating incorrect but plausible options for objective questions such as fill-in-the-blank and multiple-choice questions. This task is widely utilized in educational settings across various domains and subjects. The effectiveness of these questions in... | Elaf Alhazmi, Quan Sheng, Wei Emma Zhang, Munazza Zaib, Ahoud Alhazmi |  |
| 923 |  |  [Evaluating n-Gram Novelty of Language Models Using Rusty-DAWG](https://doi.org/10.18653/v1/2024.emnlp-main.800) |  | 0 | How novel are texts generated by language models (LMs) relative to their training corpora? In this work, we investigate the extent to which modern LMs generate n-grams from their training data, evaluating both (i) the probability LMs assign to complete training n-grams and (ii) n-novelty, the... | William Merrill, Noah A. Smith, Yanai Elazar |  |
| 924 |  |  [ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles](https://doi.org/10.18653/v1/2024.emnlp-main.801) |  | 0 | Deaf and hard-of-hearing (DHH) students face significant barriers in accessing science, technology, engineering, and mathematics (STEM) education, notably due to the scarcity of STEM resources in signed languages. To help address this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia... | Kayo Yin, Chinmay Singh, Fyodor Minakov, Vanessa Milan, Hal Daumé III, Cyril Zhang, Alex Lu, Danielle Bragg |  |
| 925 |  |  [Can Automatic Metrics Assess High-Quality Translations?](https://doi.org/10.18653/v1/2024.emnlp-main.802) |  | 0 | Automatic metrics for evaluating translation quality are typically validated by measuring how well they correlate with human assessments. However, correlation methods tend to capture only the ability of metrics to differentiate between good and bad source-translation pairs, overlooking their... | Sweta Agrawal, António Farinhas, Ricardo Rei, André F. T. Martins |  |
| 926 |  |  [Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.803) |  | 0 | Alignment with human preferences is an important step in developing accurate and safe large language models. This is no exception in machine translation (MT), where better handling of language nuances and context-specific variations leads to improved quality. However, preference data based on human... | Sweta Agrawal, José Guilherme Camargo de Souza, Ricardo Rei, António Farinhas, Gonçalo Rui Alves Faria, Patrick Fernandes, Nuno Miguel Guerreiro, André F. T. Martins |  |
| 927 |  |  [DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.804) |  | 0 | In the realm of multi-intent spoken language understanding, recent advancements have leveraged the potential of prompt learning frameworks. However, critical gaps exist in these frameworks: the lack of explicit modeling of dual-task dependencies and the oversight of task-specific semantic... | Bowen Xing, Lizi Liao, Minlie Huang, Ivor W. Tsang |  |
| 928 |  |  [KnowTuning: Knowledge-aware Fine-tuning for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.805) |  | 0 | Despite their success at many natural language processing (NLP) tasks, large language models still struggle to effectively leverage knowledge for knowledge-intensive tasks, manifesting limitations such as generating incomplete, non-factual, or illogical answers. These limitations stem from... | Yougang Lyu, Lingyong Yan, Shuaiqiang Wang, Haibo Shi, Dawei Yin, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren |  |
| 929 |  |  [SecCoder: Towards Generalizable and Robust Secure Code Generation](https://doi.org/10.18653/v1/2024.emnlp-main.806) |  | 0 | After large models (LMs) have gained widespread acceptance in code-related tasks, their superior generative capacity has greatly promoted the application of the code LM. Nevertheless, the security of the generated code has raised attention to its potential damage. Existing secure code generation... | Boyu Zhang, Tianyu Du, Junkai Tong, Xuhong Zhang, Kingsum Chow, Sheng Cheng, Xun Wang, Jianwei Yin |  |
| 930 |  |  [Nash CoT: Multi-Path Inference with Preference Equilibrium](https://doi.org/10.18653/v1/2024.emnlp-main.807) |  | 0 | Chain of thought (CoT) is a reasoning framework that can enhance the performance of large language models (LLMs) on complex inference tasks. In particular, among various studies related to CoT, multi-path inference stands out as a simple yet effective improvement. However, there is no optimal... | Ziqi Zhang, Cunxiang Wang, Xiao Xiong, Yue Zhang, Donglin Wang |  |
| 931 |  |  [Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention](https://doi.org/10.18653/v1/2024.emnlp-main.808) |  | 0 | Improving the effectiveness and efficiency of large language models (LLMs) simultaneously is a critical yet challenging research goal. In this paper, we find that low-rank pre-training, normally considered as efficient methods that will compromise performance, can be scalably effective when reduced... | Xingtai Lv, Ning Ding, Kaiyan Zhang, Ermo Hua, Ganqu Cui, Bowen Zhou |  |
| 932 |  |  [Small Agent Can Also Rock! Empowering Small Language Models as Hallucination Detector](https://doi.org/10.18653/v1/2024.emnlp-main.809) |  | 0 | Hallucination detection is a challenging task for large language models (LLMs), and existing studies heavily rely on powerful closed-source LLMs such as GPT-4. In this paper, we propose an autonomous LLM-based agent framework, called HaluAgent, which enables relatively smaller LLMs (e.g.... | Xiaoxue Cheng, Junyi Li, Xin Zhao, Hongzhi Zhang, Fuzheng Zhang, Di Zhang, Kun Gai, JiRong Wen |  |
| 933 |  |  [Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.810) |  | 0 | Contrastively trained vision-language models such as CLIP have achieved remarkable progress in vision and language representation learning. Despite the promising progress, their proficiency in compositional reasoning over attributes and relations (e.g., distinguishing between “the car is underneath... | Wei Li, Zhen Huang, Xinmei Tian, Le Lu, Houqiang Li, Xu Shen, Jieping Ye |  |
| 934 |  |  [LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History](https://doi.org/10.18653/v1/2024.emnlp-main.811) |  | 0 | With the recent emergence of powerful instruction-tuned large language models (LLMs), various helpful conversational Artificial Intelligence (AI) systems have been deployed across many applications. When prompted by users, these AI systems successfully perform a wide range of tasks as part of a... | Akash Gupta, Ivaxi Sheth, Vyas Raina, Mark J. F. Gales, Mario Fritz |  |
| 935 |  |  [Social Bias Probing: Fairness Benchmarking for Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.812) |  | 0 | While the impact of social biases in language models has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, limiting our understanding of bias complexities. This paper proposes a novel framework for probing language models for social... | Marta Marchiori Manerba, Karolina Stanczak, Riccardo Guidotti, Isabelle Augenstein |  |
| 936 |  |  [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.813) |  | 0 | Retrieval-augmented language model (RALM) represents a significant advancement in mitigating factual hallucination by leveraging external knowledge sources. However, the reliability of the retrieved information is not always guaranteed, and the retrieval of irrelevant data can mislead the response... | Wenhao Yu, Hongming Zhang, Xiaoman Pan, Peixin Cao, Kaixin Ma, Jian Li, Hongwei Wang, Dong Yu |  |
| 937 |  |  [DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.814) |  | 0 | Large language models (LLMs) have demonstrated emergent capabilities across diverse reasoning tasks via popular Chains-of-Thought (COT) prompting. However, such a simple and fast COT approach often encounters limitations in dealing with complicated problems, while a thorough method, which considers... | Jiabao Pan, Yan Zhang, Chen Zhang, Zuozhu Liu, Hongwei Wang, Haizhou Li |  |
| 938 |  |  [Revisiting Automated Evaluation for Long-form Table Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.815) |  | 0 | In the era of data-driven decision-making, Long-Form Table Question Answering (LFTQA) is essential for integrating structured data with complex reasoning. Despite recent advancements in Large Language Models (LLMs) for LFTQA, evaluating their effectiveness remains a significant challenge. We... | Yuqi Wang, Lyuhao Chen, Songcheng Cai, Zhijian Xu, Yilun Zhao |  |
| 939 |  |  [Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems](https://doi.org/10.18653/v1/2024.emnlp-main.816) |  | 0 | The inherent ambiguity of cause and effect boundaries poses a challenge in evaluating causal event extraction tasks. Traditional metrics like Exact Match and BertScore poorly reflect model performance, so we trained evaluation models to approximate human evaluation, achieving high agreement. We... | Italo Luis da Silva, Hanqi Yan, Lin Gui, Yulan He |  |
| 940 |  |  [Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.817) |  | 0 | Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on \*broadening\* the training set with various data augmentation techniques, which is effective for standard... | Zhihan Zhang, Tao Ge, Zhenwen Liang, Wenhao Yu, Dian Yu, Mengzhao Jia, Dong Yu, Meng Jiang |  |
| 941 |  |  [FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents](https://doi.org/10.18653/v1/2024.emnlp-main.818) |  | 0 | We introduce FinDVer, a comprehensive benchmark specifically designed to evaluate the explainable claim verification capabilities of LLMs in the context of understanding and analyzing long, hybrid-content financial documents. FinDVer contains 4,000 expert-annotated examples across four subsets,... | Yilun Zhao, Yitao Long, Tintin Jiang, Chengye Wang, Weiyuan Chen, Hongjun Liu, Xiangru Tang, Yiming Zhang, Chen Zhao, Arman Cohan |  |
| 942 |  |  [Extracting Prompts by Inverting LLM Outputs](https://doi.org/10.18653/v1/2024.emnlp-main.819) |  | 0 | We consider the problem of language model inversion: given outputs of a language model, we seek to extract the prompt that generated these outputs. We develop a new black-box method, output2prompt, that extracts prompts without access to the model’s logits and without adversarial or jailbreaking... | Collin Zhang, John X. Morris, Vitaly Shmatikov |  |
| 943 |  |  [BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.820) |  | 0 | Evaluating the bias of LLMs becomes more crucial with their rapid development. However, existing evaluation approaches rely on fixed-form outputs and cannot adapt to the flexible open-text generation scenarios of LLMs (e.g., sentence completion and question answering). To address this, we introduce... | Zhiting Fan, Ruizhe Chen, Ruiling Xu, Zuozhu Liu |  |
| 944 |  |  [VHASR: A Multimodal Speech Recognition System With Vision Hotwords](https://doi.org/10.18653/v1/2024.emnlp-main.821) |  | 0 | The image-based multimodal automatic speech recognition (ASR) model enhances speech recognition performance by incorporating audio-related image. However, some works suggest that introducing image information to model does not help improving ASR performance. In this paper, we propose a novel... | Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, Hai Zhao |  |
| 945 |  |  [A Probability-Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors](https://doi.org/10.18653/v1/2024.emnlp-main.822) |  | 0 |  | Naaman Tan, Josef Valvoda, Tianyu Liu, Anej Svete, Yanxia Qin, MinYen Kan, Ryan Cotterell |  |
| 946 |  |  [Bridging Local Details and Global Context in Text-Attributed Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.823) |  | 0 | Representation learning on text-attributed graphs (TAGs) is vital for real-world applications, as they combine semantic textual and contextual structural information. Research in this field generally consist of two main perspectives: local-level encoding and global-level aggregating, respectively... | Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, Liyunfei Liyunfei, Siliang Tang |  |
| 947 |  |  [Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks](https://doi.org/10.18653/v1/2024.emnlp-main.824) |  | 0 | This paper introduces a comprehensive collection of NLP resources for Emakhuwa, Mozambique’s most widely spoken language. The resources include the first manually translated news bitext corpus between Portuguese and Emakhuwa, news topic classification datasets, and monolingual data. We detail the... | Felermino Dário Mário António Ali, Henrique Lopes Cardoso, Rui SousaSilva |  |
| 948 |  |  [RepMatch: Quantifying Cross-Instance Similarities in Representation Space](https://doi.org/10.18653/v1/2024.emnlp-main.825) |  | 0 | Advances in dataset analysis techniques have enabled more sophisticated approaches to analyzing and characterizing training data instances, often categorizing data based on attributes such as “difficulty”. In this work, we introduce RepMatch, a novel method that characterizes data through the lens... | Mohammad Modarres, Sina Abbasi, Mohammad Taher Pilehvar |  |
| 949 |  |  [Commonsense Knowledge Editing Based on Free-Text in LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.826) |  | 0 | Knowledge editing technology is crucial for maintaining the accuracy and timeliness of large language models (LLMs) . However, the setting of this task overlooks a significant portion of commonsense knowledge based on free-text in the real world, characterized by broad knowledge scope, long content... | Xiusheng Huang, Yequan Wang, Jun Zhao, Kang Liu |  |
| 950 |  |  [A Closer Look at Multidimensional Online Political Incivility](https://doi.org/10.18653/v1/2024.emnlp-main.827) |  | 0 | Toxic online political discourse has become prevalent, where scholars debate about its impact to Democratic processes. This work presents a large-scale study of political incivility on Twitter. In line with theories of political communication, we differentiate between harsh ‘impolite’ style and... | Sagi Pendzel, Nir Lotan, Alon Zoizner, Einat Minkov |  |
| 951 |  |  [Leveraging BERT and TFIDF Features for Short Text Clustering via Alignment-Promoting Co-Training](https://doi.org/10.18653/v1/2024.emnlp-main.828) |  | 0 | BERT and TFIDF features excel in capturing rich semantics and important words, respectively. Since most existing clustering methods are solely based on the BERT model, they often fall short in utilizing keyword information, which, however, is very useful in clustering short texts. In this paper, we... | Zetong Li, Qinliang Su, Shijing Si, Jianxing Yu |  |
| 952 |  |  [Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.829) |  | 0 | Most works on gender bias focus on intrinsic bias — removing traces of information about a protected group from the model’s internal representation. However, these works are often disconnected from the impact of such debiasing on downstream applications, which is the main motivation for debiasing... | Bar Iluz, Yanai Elazar, Asaf Yehudai, Gabriel Stanovsky |  |
| 953 |  |  [Unsupervised Named Entity Disambiguation for Low Resource Domains](https://doi.org/10.18653/v1/2024.emnlp-main.830) |  | 0 | In the ever-evolving landscape of natural language processing and information retrieval, the need for robust and domain-specific entity linking algorithms has become increasingly apparent. It is crucial in a considerable number of fields such as humanities, technical writing and biomedical sciences... | Debarghya Datta, Soumajit Pramanik |  |
| 954 |  |  [SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers](https://doi.org/10.18653/v1/2024.emnlp-main.831) |  | 0 | The performance of Transformer models has been enhanced by increasing the number of parameters and the length of the processed text. Consequently, fine-tuning the entire model becomes a memory-intensive process. High-performance methods for parameter-efficient fine-tuning (PEFT) typically work with... | Viktoria Chekalina, Anna Rudenko, Gleb Mezentsev, Aleksandr Mikhalev, Alexander Panchenko, Ivan V. Oseledets |  |
| 955 |  |  [MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.emnlp-main.832) |  | 0 | In recent years, numerous studies have sought to enhance the capabilities of pretrained language models (PLMs) for Knowledge Graph Completion (KGC) tasks by integrating structural information from knowledge graphs. However, existing approaches have not effectively combined the structural attributes... | Qingyang Li, Yanru Zhong, Yuchu Qin |  |
| 956 |  |  [ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual Language Models in Household Activities](https://doi.org/10.18653/v1/2024.emnlp-main.833) |  | 0 | Large language models(LLMs) have been adopted to process textual task description and accomplish procedural planning in embodied AI tasks because of their powerful reasoning ability. However, there is still lack of study on how vision language models(VLMs) behave when multi-modal task inputs are... | Ying Su, Zhan Ling, Haochen Shi, Cheng Jiayang, Yauwai Yim, Yangqiu Song |  |
| 957 |  |  [Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning](https://doi.org/10.18653/v1/2024.emnlp-main.834) |  | 0 | Prompt-based learning paradigm has been shown to be vulnerable to backdoor attacks. Current clean-label attack, employing a specific prompt as trigger, can achieve success without the need for external triggers and ensuring correct labeling of poisoned samples, which are more stealthy compared to... | Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Zhou |  |
| 958 |  |  [GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients](https://doi.org/10.18653/v1/2024.emnlp-main.835) |  | 0 |  | Aashiq Muhamed, Oscar Li, David P. Woodruff, Mona T. Diab, Virginia Smith |  |
| 959 |  |  [RaTEScore: A Metric for Radiology Report Generation](https://doi.org/10.18653/v1/2024.emnlp-main.836) |  | 0 | This paper introduces a novel, entity-aware metric, termed as Radiological Report (Text) Evaluation (RaTEScore), to assess the quality of medical reports generated by AI models. RaTEScore emphasizes crucial medical entities such as diagnostic outcomes and anatomical details, and is robust against... | Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie |  |
| 960 |  |  [HalluMeasure: Fine-grained Hallucination Measurement Using Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.837) |  | 0 | Automating the measurement of hallucinations in LLM generated responses is a challenging task as it requires careful investigation of each factual claim in a response. In this paper, we introduce HalluMeasure, a new LLM-based hallucination detection mechanism that decomposes an LLM response into... | Shayan Ali Akbar, Md Mosharaf Hossain, Tess Wood, SiChi Chin, Erica Salinas, Victor Alvarez, Erwin Cornejo |  |
| 961 |  |  [Learning to Rank Salient Content for Query-focused Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.838) |  | 0 | This study examines the potential of integrating Learning-to-Rank (LTR) with Query-focused Summarization (QFS) to enhance the summary relevance via content prioritization. Using a shared secondary decoder with the summarization decoder, we carry out the LTR task at the segment level. Compared to... | Sajad Sotudeh, Nazli Goharian |  |
| 962 |  |  [Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions](https://doi.org/10.18653/v1/2024.emnlp-main.839) |  | 0 | Classification is a core NLP task architecture with many potential applications. While large language models (LLMs) have brought substantial advancements in text generation, their potential for enhancing classification tasks remains underexplored. To address this gap, we propose a framework for... | Qian Ruan, Ilia Kuznetsov, Iryna Gurevych |  |
| 963 |  |  [LitSearch: A Retrieval Benchmark for Scientific Literature Search](https://doi.org/10.18653/v1/2024.emnlp-main.840) |  | 0 | Literature search questions, such as “where can I find research on the evaluation of consistency in generated summaries?” pose significant challenges for modern search engines and retrieval systems. These questions often require a deep understanding of research concepts and the ability to reason... | Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, Tianyu Gao |  |
| 964 |  |  [Open-world Multi-label Text Classification with Extremely Weak Supervision](https://doi.org/10.18653/v1/2024.emnlp-main.841) |  | 0 | We study open-world multi-label text classification under extremely weak supervision (XWS), where the user only provides a brief description for classification objectives without any labels or ground-truth label space. Similar single-label XWS settings have been explored recently, however, these... | Xintong Li, Jinya Jiang, Ria Dharmani, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang |  |
| 965 |  |  [LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law](https://doi.org/10.18653/v1/2024.emnlp-main.842) |  | 0 | We study LLMs’ ability to extrapolate the behavior of various dynamical systems, including stochastic, chaotic, continuous, and discrete systems, whose evolution is governed by principles of physical interest. Our results show that LLaMA-2, a language model trained on text, achieves accurate... | Toni J. B. Liu, Nicolas Boullé, Raphaël Sarfati, Christopher J. Earls |  |
| 966 |  |  [AKEW: Assessing Knowledge Editing in the Wild](https://doi.org/10.18653/v1/2024.emnlp-main.843) |  | 0 | Knowledge editing injects knowledge updates into language models to keep them correct and up-to-date. However, its current evaluations deviate significantly from practice: their knowledge updates solely consist of structured facts derived from meticulously crafted datasets, instead of practical... | Xiaobao Wu, Liangming Pan, William Yang Wang, Anh Tuan Luu |  |
| 967 |  |  [CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation](https://doi.org/10.18653/v1/2024.emnlp-main.844) |  | 0 | Evaluating the degree of reproduction of copyright-protected content by language models (LMs) is of significant interest to the AI and legal communities. Although both literal and non-literal similarities are considered by courts when assessing the degree of reproduction, prior research has focused... | Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh |  |
| 968 |  |  [Dense X Retrieval: What Retrieval Granularity Should We Use?](https://doi.org/10.18653/v1/2024.emnlp-main.845) |  | 0 | Dense retrieval has become a prominent method to obtain relevant context or world knowledge in open-domain NLP tasks. When we use a learned dense retriever on a retrieval corpus at inference time, an often-overlooked design choice is the retrieval unit in which the corpus is indexed, e.g. document,... | Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao, Hongming Zhang, Dong Yu |  |
| 969 |  |  [Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach](https://doi.org/10.18653/v1/2024.emnlp-main.846) |  | 0 | Susceptibility to misinformation describes the degree of belief in unverifiable claims, a latent aspect of individuals’ mental processes that is not observable. Existing susceptibility studies heavily rely on self-reported beliefs, which can be subject to bias, expensive to collect, and challenging... | Yanchen Liu, Mingyu Derek Ma, Wenna Qin, Azure Zhou, Jiaao Chen, Weiyan Shi, Wei Wang, Diyi Yang |  |
| 970 |  |  [Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.847) |  | 0 | Fine-tuning pre-trained large language models (LLMs) on a diverse array of tasks has become a common approach for building models that can solve various natural language processing (NLP) tasks. However, where and to what extent these models retain task-specific knowledge remains largely unexplored.... | Zheng Zhao, Yftah Ziser, Shay B. Cohen |  |
| 971 |  |  [XDetox: Text Detoxification with Token-Level Toxicity Explanations](https://doi.org/10.18653/v1/2024.emnlp-main.848) |  | 0 | Methods for mitigating toxic content through masking and infilling often overlook the decision-making process, leading to either insufficient or excessive modifications of toxic tokens. To address this challenge, we propose XDetox, a novel method that integrates token-level toxicity explanations... | Beomseok Lee, Hyunwoo Kim, Keon Kim, Yong Suk Choi |  |
| 972 |  |  [Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach](https://doi.org/10.18653/v1/2024.emnlp-main.849) |  | 0 | This paper addresses the task of Chinese Lexical Simplification (CLS). A key challenge in CLS is the scarcity of data resources. We begin by evaluating the performance of various language models at different scales in unsupervised and few-shot settings, finding that their effectiveness is sensitive... | Zihao Xiao, Jiefu Gong, Shijin Wang, Wei Song |  |
| 973 |  |  [Control Large Language Models via Divide and Conquer](https://doi.org/10.18653/v1/2024.emnlp-main.850) |  | 0 | This paper investigates the capability of LLMs on controllable generation with prompt-based controlling, focusing on Lexically Constrained Generation (LCG). We systematically evaluate the performance of LLMs on satisfying lexical constraints with prompt-based controlling, as well as their efficacy... | Bingxuan Li, Yiwei Wang, Tao Meng, KaiWei Chang, Nanyun Peng |  |
| 974 |  |  [Joint Pre-Encoding Representation and Structure Embedding for Efficient and Low-Resource Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.emnlp-main.851) |  | 0 | Knowledge graph completion (KGC) aims to infer missing or incomplete parts in knowledge graph. The existing models are generally divided into structure-based and description-based models, among description-based models often require longer training and inference times as well as increased memory... | Chenyu Qiu, Pengjiang Qian, Chuang Wang, Jian Yao, Li Liu, Wei Fang, Eddie Eddie |  |
| 975 |  |  [Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning](https://doi.org/10.18653/v1/2024.emnlp-main.852) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) is a crucial approach to aligning language models with human values and intentions. A fundamental challenge in this method lies in ensuring that the reward model accurately understands and evaluates human preferences. Current methods rely on ranking... | Lu Chen, Rui Zheng, Binghai Wang, Senjie Jin, Caishuang Huang, Junjie Ye, Zhihao Zhang, Yuhao Zhou, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 976 |  |  [RoCEL: Advancing Table Entity Linking through Distinctive Row and Column Contexts](https://doi.org/10.18653/v1/2024.emnlp-main.853) |  | 0 | Table entity linking (TEL) aims to map entity mentions in the table to their corresponding entities in a knowledge base (KB). The core of this task is to leverage structured contexts, specifically row and column contexts, to enhance the semantics of mentions in entity disambiguation. Most entity... | Yuanzheng Wang, Yixing Fan, Jiafeng Guo, Ruqing Zhang, Xueqi Cheng |  |
| 977 |  |  [Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.854) |  | 0 | When performing complex multi-step reasoning tasks, the ability of Large Language Models (LLMs) to derive structured intermediate proof steps is important for ensuring that the models truly perform the desired reasoning and for improving models’ explainability. This paper is centred around a... | Zi'ou Zheng, Christopher Malon, Martin Renqiang Min, Xiaodan Zhu |  |
| 978 |  |  [Efficient Overshadowed Entity Disambiguation by Mitigating Shortcut Learning](https://doi.org/10.18653/v1/2024.emnlp-main.855) |  | 0 | Entity disambiguation (ED) is crucial in natural language processing (NLP) for tasks such as question-answering and information extraction. A major challenge in ED is handling overshadowed entities—uncommon entities sharing mention surfaces with common entities. The current approach to enhance... | Panuthep Tasawong, Peerat Limkonchotiwat, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 979 |  |  [AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction](https://doi.org/10.18653/v1/2024.emnlp-main.856) |  | 0 | Large Language Models (LLMs) can interact with the real world by connecting with versatile external APIs, resulting in better problem-solving and task automation capabilities. Previous research primarily either focuses on APIs with limited arguments from a single source or overlooks the complex... | Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, KamFai Wong |  |
| 980 |  |  [Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.857) |  | 0 | Large language models (LLMs) are still struggling in aligning with human preference in complex tasks and scenarios. They are prone to overfit into the unexpected patterns or superficial styles in the training data. We conduct an empirical study that only selects the top-10% most updated parameters... | Zhipeng Chen, Kun Zhou, Xin Zhao, Jingyuan Wang, JiRong Wen |  |
| 981 |  |  [AudioVSR: Enhancing Video Speech Recognition with Audio Data](https://doi.org/10.18653/v1/2024.emnlp-main.858) |  | 0 | Visual Speech Recognition (VSR) aims to predict spoken content by analyzing lip movements in videos. Recently reported state-of-the-art results in VSR often rely on increasingly large amounts of video data, while the publicly available transcribed video datasets are insufficient compared to the... | Xiaoda Yang, Xize Cheng, Jiaqi Duan, Hongshun Qiu, Minjie Hong, Minghui Fang, Shengpeng Ji, Jialong Zuo, Zhiqing Hong, Zhimeng Zhang, Tao Jin |  |
| 982 |  |  [ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?](https://doi.org/10.18653/v1/2024.emnlp-main.859) |  | 0 | Although large language models (LLMs) have been largely successful in generating functionally correct programs, conditioning models to produce efficient solutions while ensuring correctness remains a challenge. Further, unreliability in benchmarking code efficiency is a hurdle across varying... | Siddhant Waghjale, Vishruth Veerendranath, Zhiruo Wang, Daniel Fried |  |
| 983 |  |  [Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level](https://doi.org/10.18653/v1/2024.emnlp-main.860) |  | 0 | General-purpose Large Language Models (LLMs) like GPT-4 have achieved remarkable advancements in machine translation (MT) by leveraging extensive web content. On the other hand, translation-specific LLMs are built by pre-training on domain-specific monolingual corpora and fine-tuning with... | Zhaopeng Feng, Ruizhe Chen, Yan Zhang, Zijie Meng, Zuozhu Liu |  |
| 984 |  |  [Re-ReST: Reflection-Reinforced Self-Training for Language Agents](https://doi.org/10.18653/v1/2024.emnlp-main.861) |  | 0 | Finetuning language agents with reasoning-action trajectories is effective, but obtaining these trajectories from human annotations or stronger models is costly and sometimes impractical. In this paper, we investigate the use of self-training in language agents, which can generate supervision from... | ZiYi Dou, ChengFu Yang, Xueqing Wu, KaiWei Chang, Nanyun Peng |  |
| 985 |  |  [Effective Synthetic Data and Test-Time Adaptation for OCR Correction](https://doi.org/10.18653/v1/2024.emnlp-main.862) |  | 0 | Post-OCR technology is used to correct errors in the text produced by OCR systems. This study introduces a method for constructing post-OCR synthetic data with different noise levels using weak supervision. We define Character Error Rate (CER) thresholds for “effective” and “ineffective” synthetic... | Shuhao Guan, Cheng Xu, Moule Lin, Derek Greene |  |
| 986 |  |  [SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework](https://doi.org/10.18653/v1/2024.emnlp-main.863) |  | 0 | Document-level Relation Extraction (DocRE) aims to extract relations between entity pairs in a document and poses many challenges as it involves multiple mentions of entities and cross-sentence inference. However, several aspects that are important for DocRE have not been considered and explored.... | Fu Zhang, Qi Miao, Jingwei Cheng, Hongsen Yu, Yi Yan, Xin Li, Yongxue Wu |  |
| 987 |  |  [FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension](https://doi.org/10.18653/v1/2024.emnlp-main.864) |  | 0 | Referring Expression Comprehension (REC) is a crucial cross-modal task that objectively evaluates the capabilities of language understanding, image comprehension, and language-to-image grounding. Consequently, it serves as an ideal testing ground for Multi-modal Large Language Models (MLLMs). In... | Junzhuo Liu, Xuzheng Yang, Weiwei Li, Peng Wang |  |
| 988 |  |  [Exploring the Learning Capabilities of Language Models using LEVERWORLDS](https://doi.org/10.18653/v1/2024.emnlp-main.865) |  | 0 | Learning a model of a stochastic setting often involves learning both general structure rules and specific properties of the instance. This paper investigates the interplay between learning the general and the specific in various learning methods, with emphasis on sample efficiency. We design a... | Eitan Wagner, Amir Feder, Omri Abend |  |
| 989 |  |  [CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.866) |  | 0 | Although language model scores are often treated as probabilities, their reliability as probability estimators has mainly been studied through calibration, overlooking other aspects. In particular, it is unclear whether language models produce the same value for different ways of assigning joint... | Eitan Wagner, Yuli Slavutsky, Omri Abend |  |
| 990 |  |  [DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding](https://doi.org/10.18653/v1/2024.emnlp-main.867) |  | 0 | Document structure editing involves manipulating localized textual, visual, and layout components in document images based on the user’s requests. Past works have shown that multimodal grounding of user requests in the document image and identifying the accurate structural components and their... | Manan Suri, Puneet Mathur, Franck Dernoncourt, Rajiv Jain, Vlad I. Morariu, Ramit Sawhney, Preslav Nakov, Dinesh Manocha |  |
| 991 |  |  [DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging](https://doi.org/10.18653/v1/2024.emnlp-main.868) |  | 0 | Reinforcement learning from human feedback (RLHF) is a popular strategy for aligning large language models (LLMs) with desired behaviors. Reward modeling is a crucial step in RLHF. However, collecting paired preference data for training reward models is often costly and time-consuming, especially... | TzuHan Lin, ChenAn Li, Hungyi Lee, YunNung Chen |  |
| 992 |  |  [Understanding Slang with LLMs: Modelling Cross-Cultural Nuances through Paraphrasing](https://doi.org/10.18653/v1/2024.emnlp-main.869) |  | 0 | In the realm of social media discourse, the integration of slang enriches communication, reflecting the sociocultural identities of users. This study investigates the capability of large language models (LLMs) to paraphrase slang within climate-related tweets from Nigeria and the UK, with a focus... | Ifeoluwa Wuraola, Nina Dethlefs, Daniel Marciniak |  |
| 993 |  |  [Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.870) |  | 0 | Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest.... | Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, Yingbo Zhou |  |
| 994 |  |  [Re-Reading Improves Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.871) |  | 0 | To enhance the reasoning capabilities of off-the-shelf Large Language Models (LLMs), we introduce a simple, yet general and effective prompting method, RE2, i.e., Re-Reading the question as input. Unlike most thought-eliciting prompting methods, such as Chain-of-Thought (CoT), which aim to elicit... | Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, JianGuang Lou, Shuai Ma |  |
| 995 |  |  [Adaptive Axes: A Pipeline for In-domain Social Stereotype Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.872) |  | 0 | Prior work has explored the possibility of using the semantic information obtained from embedding representations to quantify social stereotypes, leveraging techniques such as word embeddings combined with a list of traits (Garg et al., 2018; Charlesworth et al., 2022) or semantic axes (An et al.,... | Qingcheng Zeng, Mingyu Jin, Rob Voigt |  |
| 996 |  |  [ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments](https://doi.org/10.18653/v1/2024.emnlp-main.873) |  | 0 | The global shortage of healthcare workers has demanded the development of smart healthcare assistants, which can help monitor and alert healthcare workers when necessary. We examine the healthcare knowledge of existing Large Vision Language Models (LVLMs) via the Visual Question Answering (VQA)... | Sourjyadip Ray, Kushal Gupta, Soumi Kundu, Payal Arvind Kasat, Somak Aditya, Pawan Goyal |  |
| 997 |  |  [Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations](https://doi.org/10.18653/v1/2024.emnlp-main.874) |  | 0 | The quality is a crucial issue for crowd annotations. Answer aggregation is an important type of solution. The aggregated answers estimated from multiple crowd answers to the same instance are the eventually collected annotations, rather than the individual crowd answers themselves. Recently, the... | Jiyi Li |  |
| 998 |  |  [Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation](https://doi.org/10.18653/v1/2024.emnlp-main.875) |  | 0 | Large language models (LLMs) exhibit enhanced reasoning at larger scales, driving efforts to distill these capabilities into smaller models via teacher-student learning.Previous works simply fine-tune student models on teachers’ generated Chain-of-Thoughts (CoTs) data. Although these methods... | Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu |  |
| 999 |  |  [Revisiting Supervised Contrastive Learning for Microblog Classification](https://doi.org/10.18653/v1/2024.emnlp-main.876) |  | 0 | Microblog content (e.g., Tweets) is noisy due to its informal use of language and its lack of contextual information within each post. To tackle these challenges, state-of-the-art microblog classification models rely on pre-training language models (LMs). However, pre-training dedicated LMs is... | Junbo Huang, Ricardo Usbeck |  |
| 1000 |  |  [BaitAttack: Alleviating Intention Shift in Jailbreak Attacks via Adaptive Bait Crafting](https://doi.org/10.18653/v1/2024.emnlp-main.877) |  | 0 | Jailbreak attacks enable malicious queries to evade detection by LLMs. Existing attacks focus on meticulously constructing prompts to disguise harmful intentions. However, the incorporation of sophisticated disguising prompts may incur the challenge of “intention shift”. Intention shift occurs when... | Rui Pu, Chaozhuo Li, Rui Ha, Litian Zhang, Lirong Qiu, Xi Zhang |  |
| 1001 |  |  [Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.878) |  | 0 | Vision-language models (VLMs) pre-trained on extensive datasets can inadvertently learn biases by correlating gender information with specific objects or scenarios. Current methods, which focus on modifying inputs and monitoring changes in the model’s output probability scores, often struggle to... | Zhaotian Weng, Zijun Gao, Jerone Theodore Alexander Andrews, Jieyu Zhao |  |
| 1002 |  |  [Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing](https://doi.org/10.18653/v1/2024.emnlp-main.879) |  | 0 | Large Language Models (LLMs) have recently revolutionized the NLP field, while they still fall short in some specific down-stream tasks. In the work, we focus on utilizing LLMs to perform machine translation, where we observe that two patterns of errors frequently occur and drastically affect the... | Weichuan Wang, Zhaoyi Li, Defu Lian, Chen Ma, Linqi Song, Ying Wei |  |
| 1003 |  |  [SciAgent: Tool-augmented Language Models for Scientific Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.880) |  | 0 | Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and... | Yubo Ma, Zhibin Gou, Junheng Hao, Ruochen Xu, Shuohang Wang, Liangming Pan, Yujiu Yang, Yixin Cao, Aixin Sun |  |
| 1004 |  |  [Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents](https://doi.org/10.18653/v1/2024.emnlp-main.881) |  | 0 | We describe an approach for aligning an LLM based dialogue agent for long-term social dialogue, where there is only a single global score given by the user at the end of the session. In this paper, we propose the usage of denser naturally-occurring multimodal communicative signals as local implicit... | Dong Won Lee, Hae Park, Yoon Kim, Cynthia Breazeal, LouisPhilippe Morency |  |
| 1005 |  |  [Towards Measuring and Modeling "Culture" in LLMs: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.882) |  | 0 | We present a survey of more than 90 recent papers that aim to study cultural representation and inclusion in large language models (LLMs). We observe that none of the studies explicitly define “culture, which is a complex, multifaceted concept; instead, they probe the models on some specially... | Muhammad Farid Adilazuarda, Sagnik Mukherjee, Pradhyumna Lavania, Siddhant Singh, Alham Fikri Aji, Jacki O'Neill, Ashutosh Modi, Monojit Choudhury |  |
| 1006 |  |  [ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.883) |  | 0 | Emotion Support Conversation (ESC) is a crucial application, which aims to reduce human stress, offer emotional guidance, and ultimately enhance human mental and physical well-being. With the advancement of Large Language Models (LLMs), many researchers have employed LLMs as the ESC models.... | Haiquan Zhao, Lingyu Li, Shisong Chen, Shuqi Kong, Jiaan Wang, Kexin Huang, Tianle Gu, Yixu Wang, Jian Wang, Dandan Liang, Zhixu Li, Yan Teng, Yanghua Xiao, Yingchun Wang |  |
| 1007 |  |  [Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting](https://doi.org/10.18653/v1/2024.emnlp-main.884) |  | 0 | Socio-demographic prompting is a commonly employed approach to study cultural biases in LLMs as well as for aligning models to certain cultures. In this paper, we systematically probe four LLMs (Llama 3, Mistral v0.2, GPT-3.5 Turbo and GPT4) with prompts that are conditioned on culturally sensitive... | Sagnik Mukherjee, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, Monojit Choudhury |  |
| 1008 |  |  [Text Fluoroscopy: Detecting LLM-Generated Text through Intrinsic Features](https://doi.org/10.18653/v1/2024.emnlp-main.885) |  | 0 | Large language models (LLMs) have revolutionized the domain of natural language processing because of their excellent performance on various tasks. Despite their impressive capabilities, LLMs also have the potential to generate texts that pose risks of misuse. Consequently, detecting LLM-generated... | Xiao Yu, Kejiang Chen, Qi Yang, Weiming Zhang, Nenghai Yu |  |
| 1009 |  |  [Hate Personified: Investigating the role of LLMs in content moderation](https://doi.org/10.18653/v1/2024.emnlp-main.886) |  | 0 | For subjective tasks such as hate detection, where people perceive hate differently, the Large Language Model’s (LLM) ability to represent diverse groups is unclear. By including additional context in prompts, we comprehensively analyze LLM’s sensitivity to geographical priming, persona attributes,... | Sarah Masud, Sahajpreet Singh, Viktor Hangya, Alexander Fraser, Tanmoy Chakraborty |  |
| 1010 |  |  [Temporally Consistent Factuality Probing for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.887) |  | 0 | The prolific use of Large Language Models (LLMs) as an alternate knowledge base requires them to be factually consistent, necessitating both correctness and consistency traits for paraphrased queries. Recently, significant attempts have been made to benchmark datasets and metrics to evaluate LLMs... | Ashutosh Bajpai, Aaryan Goyal, Atif Anwer, Tanmoy Chakraborty |  |
| 1011 |  |  [A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives](https://doi.org/10.18653/v1/2024.emnlp-main.888) |  | 0 | Pretrained language models (PLMs) display impressive performances and have captured the attention of the NLP community.Establishing best practices in pretraining has, therefore, become a major focus of NLP research, especially since insights gained from monolingual English models may not... | Zihao Li, Shaoxiong Ji, Timothee Mickus, Vincent Segonne, Jörg Tiedemann |  |
| 1012 |  |  [Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators](https://doi.org/10.18653/v1/2024.emnlp-main.889) |  | 0 | Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users. In this work, we focus on evaluating the reliability of current LLMs as science communicators. Unlike existing benchmarks, our approach emphasizes... | Prasoon Bajpai, Niladri Chatterjee, Subhabrata Dutta, Tanmoy Chakraborty |  |
| 1013 |  |  [LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-Training](https://doi.org/10.18653/v1/2024.emnlp-main.890) |  | 0 | Mixture-of-Experts (MoE) has gained increasing popularity as a promising framework for scaling up large language models (LLMs). However, training MoE from scratch in a large-scale setting still suffers from data-hungry and instability problems. Motivated by this limit, we investigate building MoE... | Tong Zhu, Xiaoye Qu, Daize Dong, Jiacheng Ruan, Jingqi Tong, Conghui He, Yu Cheng |  |
| 1014 |  |  [Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability](https://doi.org/10.18653/v1/2024.emnlp-main.891) |  | 0 | The evaluation of natural language generation (NLG) tasks is a significant and longstanding research area. With the recent emergence of powerful large language models (LLMs), some studies have turned to LLM-based automatic evaluation methods, which demonstrate great potential to become a new... | Xinyu Hu, Li Lin, Mingqi Gao, Xunjian Yin, Xiaojun Wan |  |
| 1015 |  |  [Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging](https://doi.org/10.18653/v1/2024.emnlp-main.892) |  | 0 | Supervised fine-tuning (SFT) is crucial for adapting Large Language Models (LLMs) to specific tasks. In this work, we demonstrate that the order of training data can lead to significant training imbalances, potentially resulting in performance degradation. Consequently, we propose to mitigate this... | Yiming Ju, Ziyi Ni, Xingrun Xing, Zhixiong Zeng, Hanyu Zhao, Siqi Fan, Zheng Zhang |  |
| 1016 |  |  [Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning](https://doi.org/10.18653/v1/2024.emnlp-main.893) |  | 0 | In-Context-learning and few-shot prompting are viable methods compositional output generation. However, these methods can be very sensitive to the choice of support examples used. Retrieving good supports from the training data for a given test query is already a difficult problem, but in some... | Sam Spilsbury, Pekka Marttinen, Alexander Ilin |  |
| 1017 |  |  [FAME: Towards Factual Multi-Task Model Editing](https://doi.org/10.18653/v1/2024.emnlp-main.894) |  | 0 | Large language models (LLMs) embed extensive knowledge and utilize it to perform exceptionally well across various tasks. Nevertheless, outdated knowledge or factual errors within LLMs can lead to misleading or incorrect responses, causing significant issues in practical applications. To rectify... | Zeng Li, Yingyu Shan, Zeming Liu, Jiashu Yao, Yuhang Guo |  |
| 1018 |  |  [MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance](https://doi.org/10.18653/v1/2024.emnlp-main.895) |  | 0 | The deployment of multimodal large language models (MLLMs) has brought forth a unique vulnerability: susceptibility to malicious attacks through visual inputs. This paper investigates the novel challenge of defending MLLMs against such attacks. Compared to large language models (LLMs), MLLMs... | Renjie Pi, Tianyang Han, Jianshu Zhang, Yueqi Xie, Rui Pan, Qing Lian, Hanze Dong, Jipeng Zhang, Tong Zhang |  |
| 1019 |  |  [Leveraging Large Language Models for NLG Evaluation: Advances and Challenges](https://doi.org/10.18653/v1/2024.emnlp-main.896) |  | 0 | In the rapidly evolving domain of Natural Language Generation (NLG) evaluation, introducing Large Language Models (LLMs) has opened new avenues for assessing generated content quality, e.g., coherence, creativity, and context relevance. This paper aims to provide a thorough overview of leveraging... | Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, JiaChen Gu, Yuxuan Lai, Chongyang Tao, Shuai Ma |  |
| 1020 |  |  [InfiniPot: Infinite Context Processing on Memory-Constrained LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.897) |  | 0 | Handling long input contexts remains a significant challenge for Large Language Models (LLMs), particularly in resource-constrained environments such as mobile devices. Our work aims to address this limitation by introducing InfiniPot, a novel KV cache control framework designed to enable... | Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang |  |
| 1021 |  |  [VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models](https://doi.org/10.18653/v1/2024.emnlp-main.898) |  | 0 | Contrastive Language-Image Pre-training (CLIP) has been widely studied and applied in numerous applications. However, the emphasis on brief summary texts during pre-training prevents CLIP from understanding long descriptions. This issue is particularly acute regarding videos given that videos often... | Jiapeng Wang, Chengyu Wang, Kunzhe Huang, Jun Huang, Lianwen Jin |  |
| 1022 |  |  [CorrSynth - A Correlated Sampling Method for Diverse Dataset Generation from LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.899) |  | 0 | Large language models (LLMs) have demonstrated remarkable performance in diverse tasks using zero-shot and few-shot prompting. Even though their capabilities of data synthesis have been studied well in recent years, the generated data suffers from a lack of diversity, less adherence to the prompt,... | Suhas S. Kowshik, Abhishek Divekar, Vijit Malik |  |
| 1023 |  |  [Defining Knowledge: Bridging Epistemology and Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.900) |  | 0 | Knowledge claims are abundant in the literature on large language models (LLMs); but can we say that GPT-4 truly “knows” the Earth is round? To address this question, we review standard definitions of knowledge in epistemology and we formalize interpretations applicable to LLMs. In doing so, we... | Constanza Fierro, Ruchira Dhar, Filippos Stamatiou, Nicolas Garneau, Anders Søgaard |  |
| 1024 |  |  [TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.901) |  | 0 | The task of text-to-table receives widespread attention, yet its importance and difficulty are underestimated. Existing works use simple datasets similar to table-to-text tasks and employ methods that ignore domain structures. As a bridge between raw text and statistical analysis, the text-to-table... | Peiwen Jiang, Xinbo Lin, Zibo Zhao, Ruhui Ma, Yvonne Jie Chen, Jinhua Cheng |  |
| 1025 |  |  [Free your mouse! Command Large Language Models to Generate Code to Format Word Documents](https://doi.org/10.18653/v1/2024.emnlp-main.902) |  | 0 | Recently, LLMs have significantly improved code generation, making it increasingly accessible to users. As a result, LLM-powered code generation applications have sprung up, vastly boosting user productivity. This paper mainly explores how to improve the efficiency and experience of users in... | Shihao Rao, Liang Li, Jiapeng Liu, Weixin Guan, Xiyan Gao, Bing Lim, Can Ma |  |
| 1026 |  |  [CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.903) |  | 0 | Large Language Models (LLMs) excel in diverse tasks but often underperform in specialized fields due to limited domain-specific or proprietary corpus. Continual pre-training (CPT) enhances LLM capabilities by imbuing new domain-specific or proprietary knowledge while replaying general corpus to... | Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan |  |
| 1027 |  |  [The Instinctive Bias: Spurious Images lead to Illusion in MLLMs](https://doi.org/10.18653/v1/2024.emnlp-main.904) |  | 0 | Large language models (LLMs) have recently experienced remarkable progress, where the advent of multi-modal large language models (MLLMs) has endowed LLMs with visual capabilities, leading to impressive performances in various multi-modal tasks. However, those powerful MLLMs such as GPT-4V still... | Tianyang Han, Qing Lian, Rui Pan, Renjie Pi, Jipeng Zhang, Shizhe Diao, Yong Lin, Tong Zhang |  |
| 1028 |  |  [Rationale-Aware Answer Verification by Pairwise Self-Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.905) |  | 0 | Answer verification identifies correct solutions among candidates generated by large language models (LLMs). Current approaches typically train verifier models by labeling solutions as correct or incorrect based solely on whether the final answer matches the gold answer. However, this approach... | Akira Kawabata, Saku Sugawara |  |
| 1029 |  |  [On the Robustness of Editing Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.906) |  | 0 | Large language models (LLMs) have played a pivotal role in building communicative AI, yet they encounter the challenge of efficient updates. Model editing enables the manipulation of specific knowledge memories and the behavior of language generation without retraining. However, the robustness of... | Xinbei Ma, Tianjie Ju, Jiyang Qiu, Zhuosheng Zhang, Hai Zhao, Lifeng Liu, Yulong Wang |  |
| 1030 |  |  [IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method](https://doi.org/10.18653/v1/2024.emnlp-main.907) |  | 0 | Pre-trained Language Models (PLMs) have achieved remarkable performance on diverse NLP tasks through pre-training and fine-tuning. However, fine-tuning the model with a large number of parameters on limited downstream datasets often leads to vulnerability to adversarial attacks, causing overfitting... | Mihyeon Kim, Juhyoung Park, YoungBin Kim |  |
| 1031 |  |  [Distract Large Language Models for Automatic Jailbreak Attack](https://doi.org/10.18653/v1/2024.emnlp-main.908) |  | 0 | Extensive efforts have been made before the public release of Large language models (LLMs) to align their behaviors with human values. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. In this work, we propose... | Zeguan Xiao, Yan Yang, Guanhua Chen, Yun Chen |  |
| 1032 |  |  [Exploring Space Efficiency in a Tree-based Linear Model for Extreme Multi-label Classification](https://doi.org/10.18653/v1/2024.emnlp-main.909) |  | 0 | Extreme multi-label classification (XMC) aims to identify relevant subsets from numerous labels. Among the various approaches for XMC, tree-based linear models are effective due to their superior efficiency and simplicity. However, the space complexity of tree-based methods is not well-studied.... | HeZhe Lin, ChengHung Liu, ChihJen Lin |  |
| 1033 |  |  [WorryWords: Norms of Anxiety Association for over 44k English Words](https://doi.org/10.18653/v1/2024.emnlp-main.910) |  | 0 | Anxiety, the anticipatory unease about a potential negative outcome, is a common and beneficial human emotion. However, there is still much that is not known about anxiety, such as how it relates to our body and how it manifests in language; especially pertinent given the increasing impact of... | Saif Mohammad |  |
| 1034 |  |  [Finding Blind Spots in Evaluator LLMs with Interpretable Checklists](https://doi.org/10.18653/v1/2024.emnlp-main.911) |  | 0 | Large Language Models (LLMs) are increasingly relied upon to evaluate text outputs of other LLMs, thereby influencing leaderboards and development decisions. However, concerns persist over the accuracy of these assessments and the potential for misleading conclusions. In this work, we investigate... | Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Sshubam Verma, Mitesh M. Khapra |  |
| 1035 |  |  [LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration](https://doi.org/10.18653/v1/2024.emnlp-main.912) |  | 0 | Large language models (LLMs) have achieved tremendous success in understanding language and processing text. However, question-answering (QA) on lengthy documents faces challenges of resource constraints and a high propensity for errors, even for the most advanced models such as GPT-4 and... | Jun Zhao, Can Zu, Xu Hao, Yi Lu, Wei He, Yiwen Ding, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1036 |  |  [AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments](https://doi.org/10.18653/v1/2024.emnlp-main.913) |  | 0 | We introduce a three-part framework for constructing persuasive messages, AutoPersuade. First, we curate a large collection of arguments and gather human evaluations of their persuasiveness. Next, we introduce a novel topic model to identify the features of these arguments that influence... | Till Saenger, Musashi Hinck, Justin Grimmer, Brandon M. Stewart |  |
| 1037 |  |  [Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.914) |  | 0 | Translating text that contains entity names is a challenging task, as cultural-related references can vary significantly across languages. These variations may also be caused by transcreation, an adaptation process that entails more than transliteration and word-for-word translation. In this paper,... | Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li |  |
| 1038 |  |  [Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems](https://doi.org/10.18653/v1/2024.emnlp-main.915) |  | 0 | Human cognition exhibits systematic compositionality, the algebraic ability to generate infinite novel combinations from finite learned components, which is the key to understanding and reasoning about complex logic. In this work, we investigate the compositionality of large language models (LLMs)... | Jun Zhao, Jingqi Tong, Yurong Mou, Ming Zhang, Qi Zhang, Xuanjing Huang |  |
| 1039 |  |  [Scaling Laws for Linear Complexity Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.916) |  | 0 | The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their scalability. Specifically, we examine the... | Xuyang Shen, Dong Li, Ruitao Leng, Zhen Qin, Weigao Sun, Yiran Zhong |  |
| 1040 |  |  [Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards](https://doi.org/10.18653/v1/2024.emnlp-main.917) |  | 0 | Recent advances in automated essay scoring (AES) have shifted towards evaluating multiple traits to provide enriched feedback. Like typical AES systems, multi-trait AES employs the quadratic weighted kappa (QWK) to measure agreement with human raters, aligning closely with the rating schema;... | Heejin Do, Sangwon Ryu, Gary Geunbae Lee |  |
| 1041 |  |  [Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis](https://doi.org/10.18653/v1/2024.emnlp-main.918) |  | 0 | Large Language Models (LLMs) are capable of producing content that perpetuates stereotypes, discrimination, and toxicity.The recently proposed moral self-correction is a computationally efficient method for reducing harmful content in the responses of LLMs. However, the process of how injecting... | Guangliang Liu, Haitao Mao, Jiliang Tang, Kristen Marie Johnson |  |
| 1042 |  |  [ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.919) |  | 0 | The mission of commonsense knowledge graph completion (CKGC) is to infer missing facts from known commonsense knowledge. CKGC methods can be roughly divided into two categories: triple-based methods and text-based methods. Due to the imbalanced distribution of entities and limited structural... | Fu Zhang, Yifan Ding, Jingwei Cheng |  |
| 1043 |  |  [LM2: A Simple Society of Language Models Solves Complex Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.920) |  | 0 | Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems elicits more robustness in LLM reasoning – a decomposer... | Gurusha Juneja, Subhabrata Dutta, Tanmoy Chakraborty |  |
| 1044 |  |  [Towards a Similarity-adjusted Surprisal Theory](https://doi.org/10.18653/v1/2024.emnlp-main.921) |  | 0 | Surprisal theory posits that the cognitive effort required to comprehend a word is determined by its contextual predictability, quantified assurprisal. Traditionally, surprisal theory treats words as distinct entities, overlooking any potential similarity between them. Giulianelli et al. (2023)... | Clara Meister, Mario Giulianelli, Tiago Pimentel |  |
| 1045 |  |  [Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.922) |  | 0 | The Knowledge-Aware Visual Question Answering about Entity task aims to disambiguate entities using textual and visual information, as well as knowledge. It usually relies on two independent steps, information retrieval then reading comprehension, that do not benefit each other. Retrieval Augmented... | Omar Adjali, Olivier Ferret, Sahar Ghannay, Hervé Le Borgne |  |
| 1046 |  |  [Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?](https://doi.org/10.18653/v1/2024.emnlp-main.923) |  | 0 | Text summarization, a key natural language generation (NLG) task, is vital in various domains. However, the high cost of inaccurate summaries in risk-critical applications, particularly those involving human-in-the-loop decision-making, raises concerns about the reliability of uncertainty... | Jianfeng He, Runing Yang, Linlin Yu, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, ChangTien Lu |  |
| 1047 |  |  [Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP](https://doi.org/10.18653/v1/2024.emnlp-main.924) |  | 0 | Improvements in language models’ capabilities have pushed their applications towards longer contexts, making long-context evaluation and development an active research area. However, many disparate use-cases are grouped together under the umbrella term of “long-context”, defined simply by the total... | Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty |  |
| 1048 |  |  [BPE Gets Picky: Efficient Vocabulary Refinement During Tokenizer Training](https://doi.org/10.18653/v1/2024.emnlp-main.925) |  | 0 | Language models can greatly benefit from efficient tokenization. However, they still mostly utilize the classical Byte-Pair Encoding (BPE) algorithm, a simple and reliable method. BPE has been shown to cause such issues as under-trained tokens and sub-optimal compression that may affect the... | Pavel Chizhov, Catherine Arnett, Elizaveta Korotkova, Ivan P. Yamshchikov |  |
| 1049 |  |  [SEGMENT+: Long Text Processing with Short-Context Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.926) |  | 0 | There is a growing interest in expanding the input capacity of language models (LMs) across various domains. However, simply increasing the context window does not guarantee robust performance across diverse long-input processing tasks, such as understanding extensive documents and extracting... | Wei Shi, Shuang Li, Kerun Yu, Jinglei Chen, Zujie Liang, Xinhui Wu, Yuxi Qian, Feng Wei, Bo Zheng, Jiaqing Liang, Jiangjie Chen, Yanghua Xiao |  |
| 1050 |  |  [Explicit Memory Learning with Expectation Maximization](https://doi.org/10.18653/v1/2024.emnlp-main.927) |  | 0 |  | Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang |  |
| 1051 |  |  [Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions](https://doi.org/10.18653/v1/2024.emnlp-main.928) |  | 0 | Providing feedback is widely recognized as crucial for refining students’ writing skills. Recent advances in language models (LMs) have made it possible to automatically generate feedback that is actionable and well-aligned with human-specified attributes. However, it remains unclear whether the... | Inderjeet Nair, Jiaye Tan, Xiaotian Su, Anne Gere, Xu Wang, Lu Wang |  |
| 1052 |  |  [Small LLMs Are Weak Tool Learners: A Multi-LLM Agent](https://doi.org/10.18653/v1/2024.emnlp-main.929) |  | 0 | Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and... | Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang |  |
| 1053 |  |  [Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions](https://doi.org/10.18653/v1/2024.emnlp-main.930) |  | 0 | Understanding the inner workings of large language models (LLMs) is crucial for advancing their theoretical foundations and real-world applications. While the attention mechanism and multi-layer perceptrons (MLPs) have been studied independently, their interactions remain largely unexplored. This... | Clement Neo, Shay B. Cohen, Fazl Barez |  |
| 1054 |  |  [Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis](https://doi.org/10.18653/v1/2024.emnlp-main.931) |  | 0 | In this study, we introduce ANGST, a novel, first of its kind benchmark for depression-anxiety comorbidity classification from social media posts. Unlike contemporary datasets that often oversimplify the intricate interplay between different mental health disorders by treating them as isolated... | Amey Hengle, Atharva Kulkarni, Shantanu Patankar, Madhumitha Chandrasekaran, Sneha D'Silva, Jemima Jacob, Rashmi Gupta |  |
| 1055 |  |  [The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.932) |  | 0 | Understanding commonsense causality is a unique mark of intelligence for humans. It helps people understand the principles of the real world better and benefits the decision-making process related to causation. For instance, commonsense causality is crucial in judging whether a defendant’s action... | Shaobo Cui, Zhijing Jin, Bernhard Schölkopf, Boi Faltings |  |
| 1056 |  |  [Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups](https://doi.org/10.18653/v1/2024.emnlp-main.933) |  | 0 | Complex Word Identification (CWI) is an essential step in the lexical simplification task and has recently become a task on its own. Some variations of this binary classification task have emerged, such as lexical complexity prediction (LCP) and complexity evaluation of multi-word expressions... | RazvanAlexandru Smadu, DavidGabriel Ion, DumitruClementin Cercel, Florin Pop, MihaelaClaudia Cercel |  |
| 1057 |  |  [Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue](https://doi.org/10.18653/v1/2024.emnlp-main.934) |  | 0 | Model editing is a technique that edits the large language models (LLMs) with updated knowledge to alleviate hallucinations without resource-intensive retraining. While current model editing methods can effectively modify a model’s behavior within a specific area of interest, they often overlook... | JiaChen Gu, HaoXiang Xu, JunYu Ma, Pan Lu, ZhenHua Ling, KaiWei Chang, Nanyun Peng |  |
| 1058 |  |  [Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!](https://doi.org/10.18653/v1/2024.emnlp-main.935) |  | 0 |  | Divya Patel, Pathik Patel, Ankush Chander, Sourish Dasgupta, Tanmoy Chakraborty |  |
| 1059 |  |  [MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations](https://doi.org/10.18653/v1/2024.emnlp-main.936) |  | 0 | Medical task-oriented dialogue systems can assist doctors by collecting patient medical history, aiding in diagnosis, or guiding treatment selection, thereby reducing doctor burnout and expanding access to medical services. However, doctor-patient dialogue datasets are not readily available,... | Vishal Vivek Saley, Goonjan Saha, Rocktim Jyoti Das, Dinesh Raghu, Mausam |  |
| 1060 |  |  [\*\*\*YesBut\*\*\*: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.937) |  | 0 | Understanding satire and humor is a challenging task for even current Vision-Language models. In this paper, we propose the challenging tasks of Satirical Image Detection (detecting whether an image is satirical), Understanding (generating the reason behind the image being satirical), and... | Abhilash Nandy, Yash Agarwal, Ashish Patwa, Millon Madhur Das, Aman Bansal, Ankit Raj, Pawan Goyal, Niloy Ganguly |  |
| 1061 |  |  [Working Memory Identifies Reasoning Limits in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.938) |  | 0 | This study explores the inherent limitations of large language models (LLMs) from a scaling perspective, focusing on the upper bounds of their cognitive capabilities. We integrate insights from cognitive science to quantitatively examine how LLMs perform on n-back tasks—a benchmark used to assess... | Chunhui Zhang, Yiren Jian, Zhongyu Ouyang, Soroush Vosoughi |  |
| 1062 |  |  [RAFT: Realistic Attacks to Fool Text Detectors](https://doi.org/10.18653/v1/2024.emnlp-main.939) |  | 0 | Large language models (LLMs) have exhibited remarkable fluency across various tasks. However, their unethical applications, such as disseminating disinformation, have become a growing concern. Although recent works have proposed a number of LLM detection methods, their robustness and reliability... | James Wang, Ran Li, Junfeng Yang, Chengzhi Mao |  |
| 1063 |  |  [LLM-Evolve: Evaluation for LLM's Evolving Capability on Benchmarks](https://doi.org/10.18653/v1/2024.emnlp-main.940) |  | 0 | The advancement of large language models (LLMs) has extended their use to dynamic and interactive real-world applications, where models engage continuously with their environment and potentially enhance their performance over time. Most existing LLM benchmarks evaluate LLMs on i.i.d. tasks,... | Jiaxuan You, Mingjie Liu, Shrimai Prabhumoye, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro |  |
| 1064 |  |  [FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping](https://doi.org/10.18653/v1/2024.emnlp-main.941) |  | 0 | Autoregressive Large Language Models (e.g., LLaMa, GPTs) are omnipresent achieving remarkable success in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges for autoregressive token-by-token... | Ajay Jaiswal, Bodun Hu, Lu Yin, Yeonju Ro, Tianlong Chen, Shiwei Liu, Aditya Akella |  |
| 1065 |  |  [LLM-based Code-Switched Text Generation for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.emnlp-main.942) |  | 0 | With the rise of globalisation, code-switching (CSW) has become a ubiquitous part of multilingual conversation, posing new challenges for natural language processing (NLP), especially in Grammatical Error Correction (GEC). This work explores the complexities of applying GEC systems to CSW texts.... | Tom Potter, Zheng Yuan |  |
| 1066 |  |  [Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.943) |  | 0 | Generative language models often struggle with specialized or less-discussed knowledge. A potential solution is found in Retrieval-Augmented Generation (RAG) models which act like retrieving information before generating responses. In this study, we explore how the Atlas approach, a RAG model,... | Mehrdad Farahani, Richard Johansson |  |
| 1067 |  |  [On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.944) |  | 0 | Recent advancements in language and vision assistants have showcased impressive capabilities but suffer from a lack of transparency, limiting broader research and reproducibility. While open-source models handle general image tasks effectively, they face challenges with the high computational... | Geewook Kim, Minjoon Seo |  |
| 1068 |  |  [Community-Cross-Instruct: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities](https://doi.org/10.18653/v1/2024.emnlp-main.945) |  | 0 | Social scientists use surveys to probe the opinions and beliefs of populations, but these methods are slow, costly, and prone to biases. Recent advances in large language models (LLMs) enable the creating of computational representations or “digital twins” of populations that generate human-like... | Zihao He, Minh Duc Chu, Rebecca Dorn, Siyi Guo, Kristina Lerman |  |
| 1069 |  |  [Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.946) |  | 0 | We introduce Mathador-LM, a new benchmark for evaluating the mathematical reasoning on large language models (LLMs), combining ruleset interpretation, planning, and problem-solving. This benchmark is inspired by the Mathador game, where the objective is to reach a target number using basic... | Eldar Kurtic, Amir Moeini, Dan Alistarh |  |
| 1070 |  |  [Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.947) |  | 0 | Despite recent advances demonstrating vision- language models’ (VLMs) abilities to describe complex relationships among objects in images using natural language, their capability to quantitatively reason about object sizes and distances remains underexplored. In this work, we introduce a manually... | YuanHong Liao, Rafid Mahmood, Sanja Fidler, David Acuna |  |
| 1071 |  |  [One Thousand and One Pairs: A "novel" challenge for long-context language models](https://doi.org/10.18653/v1/2024.emnlp-main.948) |  | 0 | Synthetic long-context LLM benchmarks (e.g., “needle-in-the-haystack”) test only surface-level retrieval capabilities; but how well can long-context LLMs retrieve, synthesize, and reason over information across book-length inputs? We address this question by creating NoCha, a dataset of 1,001... | Marzena Karpinska, Katherine Thai, Kyle Lo, Tanya Goyal, Mohit Iyyer |  |
| 1072 |  |  [Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.949) |  | 0 | As large language models (LLMs) evolve, evaluating their output reliably becomes increasingly difficult due to the high cost of human evaluation. To address this, we introduce FLAMe, a family of Foundational Large Autorater Models. FLAMe is trained on a diverse set of over 100 quality assessment... | Tu Vu, Kalpesh Krishna, Salaheddin Alzubi, Chris Tar, Manaal Faruqui, YunHsuan Sung |  |
| 1073 |  |  [Do LLMs learn a true syntactic universal?](https://doi.org/10.18653/v1/2024.emnlp-main.950) |  | 0 | Do large multilingual language models learn language universals? We consider a candidate universal much-discussed in the linguistics literature, the Final-over-Final Condition (Sheehan et al., 2017b). This Condition is syntactic in the sense that it can only be stated by reference to abstract... | John T. Hale, Milos Stanojevic |  |
| 1074 |  |  [GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets](https://doi.org/10.18653/v1/2024.emnlp-main.951) |  | 0 | A critical component of the current generation of language models is preference alignment, which aims to precisely control the model’s behavior to meet human needs and values. The most notable among such methods is Reinforcement Learning with Human Feedback (RLHF) and its offline variant Direct... | Oh Joon Kwon, Daiki E. Matsunaga, KeeEung Kim |  |
| 1075 |  |  [How Susceptible are Large Language Models to Ideological Manipulation?](https://doi.org/10.18653/v1/2024.emnlp-main.952) |  | 0 | Large Language Models (LLMs) possess the potential to exert substantial influence on public perceptions and interactions with information. This raises concerns about the societal impact that could arise if the ideologies within these models can be easily manipulated. In this work, we investigate... | Kai Chen, Zihao He, Jun Yan, Taiwei Shi, Kristina Lerman |  |
| 1076 |  |  [Measuring Psychological Depth in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.953) |  | 0 | Evaluations of creative stories generated by large language models (LLMs) often focus on objective properties of the text, such as its style, coherence, and diversity. While these metrics are indispensable, they do not speak to a story’s subjective, psychological impact from a reader’s perspective.... | Fabrice HarelCanada, Hanyu Zhou, Sreya Muppalla, Zeynep Yildiz, Miryung Kim, Amit Sahai, Nanyun Peng |  |
| 1077 |  |  [Media Attitude Detection via Framing Analysis with Events and their Relations](https://doi.org/10.18653/v1/2024.emnlp-main.954) |  | 0 | Framing is used to present some selective aspects of an issue and making them more salient, which aims to promote certain values, interpretations, or solutions (Entman, 1993). This study investigates the nuances of media framing on public perception and understanding by examining how events are... | Jin Zhao, Jingxuan Tu, Han Du, Nianwen Xue |  |
| 1078 |  |  [Fill In The Gaps: Model Calibration and Generalization with Synthetic Data](https://doi.org/10.18653/v1/2024.emnlp-main.955) |  | 0 | As machine learning models continue to swiftly advance, calibrating their performance has become a major concern prior to practical and widespread implementation. Most existing calibration methods often negatively impact model accuracy due to the lack of diversity of validation data, resulting in... | Yang Ba, Michelle Mancenido, Rong Pan |  |
| 1079 |  |  [Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations](https://doi.org/10.18653/v1/2024.emnlp-main.956) |  | 0 | Resolving knowledge conflicts is a crucial challenge in Question Answering (QA) tasks, as the internet contains numerous conflicting facts and opinions. While some research has made progress in tackling ambiguous settings where multiple valid answers exist, these approaches often neglect to provide... | Sagi Shaier, Ari Kobren, Philip V. Ogren |  |
| 1080 |  |  [Granular Privacy Control for Geolocation with Vision Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.957) |  | 0 | Vision Language Models (VLMs) are rapidly advancing in their capability to answer information-seeking questions. As these models are widely deployed in consumer applications, they could lead to new privacy risks due to emergent abilities to identify people in photos, geolocate images, etc. As we... | Ethan Mendes, Yang Chen, James Hays, Sauvik Das, Wei Xu, Alan Ritter |  |
| 1081 |  |  [MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain](https://doi.org/10.18653/v1/2024.emnlp-main.958) |  | 0 | Medical texts are notoriously challenging to read. Properly measuring their readability is the first step towards making them more accessible. Here, we present the first systematic study on fine-grained readability measurements in the medical domain, at both sentence-level and span-level. We first... | Chao Jiang, Wei Xu |  |
| 1082 |  |  [MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification](https://doi.org/10.18653/v1/2024.emnlp-main.959) |  | 0 | The complexity of text-embedded images presents a formidable challenge in machine learning given the need for multimodal understanding of multiple aspects of expression conveyed by them. While previous research in multimodal analysis has primarily focused on singular aspects such as hate speech and... | Siddhant Bikram Shah, Shuvam Shiwakoti, Maheep Chaudhary, Haohan Wang |  |
| 1083 |  |  [FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization](https://doi.org/10.18653/v1/2024.emnlp-main.960) |  | 0 |  | Mingye Zhu, Yi Liu, Quan Wang, Junbo Guo, Zhendong Mao |  |
| 1084 |  |  [StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning](https://doi.org/10.18653/v1/2024.emnlp-main.961) |  | 0 | Interactive story reading is common in early childhood education, where teachers expect to teach both language skills and real-world knowledge beyond the story. While many story reading systems have been developed for this activity, they often fail to infuse real-world knowledge into the... | Jiaju Chen, Yuxuan Lu, Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li, Qianwen Wang, Dakuo Wang, Yuling Sun |  |
| 1085 |  |  [MedCoT: Medical Chain of Thought via Hierarchical Expert](https://doi.org/10.18653/v1/2024.emnlp-main.962) |  | 0 | Artificial intelligence has advanced in Medical Visual Question Answering (Med-VQA), but prevalent research tends to focus on the accuracy of the answers, often overlooking the reasoning paths and interpretability, which are crucial in clinical settings. Besides, current Med-VQA algorithms,... | Jiaxiang Liu, Yuan Wang, Jiawei Du, Joey Zhou, Zuozhu Liu |  |
| 1086 |  |  [Varying Sentence Representations via Condition-Specified Routers](https://doi.org/10.18653/v1/2024.emnlp-main.963) |  | 0 | Semantic similarity between two sentences is inherently subjective and can vary significantly based on the specific aspects emphasized. Consequently, traditional sentence encoders must be capable of generating conditioned sentence representations that account for diverse conditions or aspects. In... | Ziyong Lin, Quansen Wang, Zixia Jia, Zilong Zheng |  |
| 1087 |  |  [Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues](https://doi.org/10.18653/v1/2024.emnlp-main.964) |  | 0 | Aligning large language models (LLMs) with human expectations requires high-quality instructional dialogues, which can be achieved by raising diverse, in-depth, and insightful instructions that deepen interactions. Existing methods target instructions from real instruction dialogues as a learning... | Jiao Ou, Jiayu Wu, Che Liu, Fuzheng Zhang, Di Zhang, Kun Gai |  |
| 1088 |  |  [Information Flow Routes: Automatically Interpreting Language Models at Scale](https://doi.org/10.18653/v1/2024.emnlp-main.965) |  | 0 | Information flows by routes inside the network via mechanisms implemented in the model. These routes can be represented as graphs where nodes correspond to token representations and edges to computations. We automatically build these graphs in a top-down manner, for each prediction leaving only the... | Javier Ferrando, Elena Voita |  |
| 1089 |  |  [A Simple yet Effective Training-free Prompt-free Approach to Chinese Spelling Correction Based on Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.966) |  | 0 | This work proposes a simple training-free prompt-free approach to leverage large language models (LLMs) for the Chinese spelling correction (CSC) task, which is totally different from all previous CSC approaches. The key idea is to use an LLM as a pure language model in a conventional manner. The... | Houquan Zhou, Zhenghua Li, Bo Zhang, Chen Li, Shaopeng Lai, Ji Zhang, Fei Huang, Min Zhang |  |
| 1090 |  |  [Representational Analysis of Binding in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.967) |  | 0 | Entity tracking is essential for complex reasoning. To perform in-context entity tracking, language models (LMs) must bind an entity to its attribute (e.g., bind a container to its content) to recall attribute for a given entity. For example, given a context mentioning “The coffee is in Box Z, the... | Qin Dai, Benjamin Heinzerling, Kentaro Inui |  |
| 1091 |  |  [CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference](https://doi.org/10.18653/v1/2024.emnlp-main.968) |  | 0 | As large language models (LLMs) constantly evolve, ensuring their safety remains a critical research issue. Previous red teaming approaches for LLM safety have primarily focused on single prompt attacks or goal hijacking. To the best of our knowledge, we are the first to study LLM safety in... | Erxin Yu, Jing Li, Ming Liao, Siqi Wang, Zuchen Gao, Fei Mi, Lanqing Hong |  |
| 1092 |  |  [ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures](https://doi.org/10.18653/v1/2024.emnlp-main.969) |  | 0 | To handle the vast amounts of qualitative data produced in corporate climate communication, stakeholders increasingly rely on Retrieval Augmented Generation (RAG) systems. However, a significant gap remains in evaluating domain-specific information retrieval – the basis for answer generation. To... | Tobias Schimanski, Jingwei Ni, Roberto Martín, Nicola Ranger, Markus Leippold |  |
| 1093 |  |  [Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.970) |  | 0 | Knowledge graphs (KGs) are instrumental in various real-world applications, yet they often suffer from incompleteness due to missing relations. To predict instances for novel relations with limited training examples, few-shot relation learning approaches have emerged, utilizing techniques such as... | Liu Ran, Zhongzhou Liu, Xiaoli Li, Yuan Fang |  |
| 1094 |  |  [Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness](https://doi.org/10.18653/v1/2024.emnlp-main.971) |  | 0 | The increasing capability and widespread usage of large language models (LLMs) highlight the desirability of automatic detection of LLM-generated text. Zero-shot detectors, due to their training-free nature, have received considerable attention and notable success. In this paper, we identify a new... | Shixuan Ma, Quan Wang |  |
| 1095 |  |  [Dual-oriented Disentangled Network with Counterfactual Intervention for Multimodal Intent Detection](https://doi.org/10.18653/v1/2024.emnlp-main.972) |  | 0 | Multimodal intent detection is designed to leverage diverse modalities for a comprehensive understanding of user intentions in real-world scenarios, thus playing a critical role in modern task-oriented dialogue systems. Existing methods have made great progress in modal alignment and fusion,... | Zhanpeng Chen, Zhihong Zhu, Xianwei Zhuang, Zhiqi Huang, Yuexian Zou |  |
| 1096 |  |  [From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking](https://doi.org/10.18653/v1/2024.emnlp-main.973) |  | 0 | The rapid development of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has exposed vulnerabilities to various adversarial attacks. This paper provides a comprehensive overview of jailbreaking research targeting both LLMs and MLLMs, highlighting recent advancements in... | Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei |  |
| 1097 |  |  [Symbolic Working Memory Enhances Language Models for Complex Rule Application](https://doi.org/10.18653/v1/2024.emnlp-main.974) |  | 0 | Large Language Models (LLMs) have shown remarkable reasoning performance but struggle with multi-step deductive reasoning involving a series of rule application steps, especially when rules are presented non-sequentially. Our preliminary analysis shows that while LLMs excel in single-step rule... | Siyuan Wang, Zhongyu Wei, Yejin Choi, Xiang Ren |  |
| 1098 |  |  [LLoCO: Learning Long Contexts Offline](https://doi.org/10.18653/v1/2024.emnlp-main.975) |  | 0 | Processing long contexts remains a challenge for large language models (LLMs) due to the quadratic computational and memory overhead of the self-attention mechanism and the substantial KV cache sizes during generation. We propose LLoCO, a novel approach to address this problem by learning contexts... | Sijun Tan, Xiuyu Li, Shishir G. Patil, Ziyang Wu, Tianjun Zhang, Kurt Keutzer, Joseph Gonzalez, Raluca A. Popa |  |
| 1099 |  |  [Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration](https://doi.org/10.18653/v1/2024.emnlp-main.976) |  | 0 | While Reinforcement Learning from Human Feedback (RLHF) significantly enhances the generation quality of Large Language Models (LLMs), recent studies have raised concerns regarding the complexity and instability associated with the Proximal Policy Optimization (PPO) algorithm, proposing a series of... | Xin Mao, FengLin Li, Huimin Xu, Wei Zhang, Wang Chen, Anh Tuan Luu |  |
| 1100 |  |  [Mentor-KD: Making Small Language Models Better Multi-step Reasoners](https://doi.org/10.18653/v1/2024.emnlp-main.977) |  | 0 | Large Language Models (LLMs) have displayed remarkable performances across various complex tasks by leveraging Chain-of-Thought (CoT) prompting. Recently, studies have proposed a Knowledge Distillation (KD) approach, reasoning distillation, which transfers such reasoning ability of LLMs through... | Hojae Lee, Junho Kim, SangKeun Lee |  |
| 1101 |  |  [Are Large Language Models Capable of Generating Human-Level Narratives?](https://doi.org/10.18653/v1/2024.emnlp-main.978) |  | 0 | As daily reliance on large language models (LLMs) grows, assessing their generation quality is crucial to understanding how they might impact on our communications. This paper investigates the capability of LLMs in storytelling, focusing on narrative development and plot progression. We introduce a... | Yufei Tian, Tenghao Huang, Miri Liu, Derek Jiang, Alexander Spangher, Muhao Chen, Jonathan May, Nanyun Peng |  |
| 1102 |  |  [MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.979) |  | 0 | Despite advancements in on-topic dialogue systems, effectively managing topic shifts within dialogues remains a persistent challenge, largely attributed to the limited availability of training datasets. To address this issue, we propose Multi-Passage to Dialogue (MP2D), a data generation framework... | Yerin Hwang, Yongil Kim, Yunah Jang, Jeesoo Bang, Hyunkyung Bae, Kyomin Jung |  |
| 1103 |  |  [Can Large Language Models Enhance Predictions of Disease Progression? Investigating Through Disease Network Link Prediction](https://doi.org/10.18653/v1/2024.emnlp-main.980) |  | 0 | Large Language Models (LLMs) have made significant strides in various tasks, yet their effectiveness in predicting disease progression remains relatively unexplored. To fill this gap, we use LLMs and employ advanced graph prompting and Retrieval-Augmented Generation (RAG) to predict disease... | Haohui Lu, Usman Naseem |  |
| 1104 |  |  [Searching for Best Practices in Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.981) |  | 0 | Retrieval-augmented generation (RAG) techniques have proven to be effective in integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains. While many RAG approaches have been proposed to enhance large language models through... | Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze Lv, Xiaoqing Zheng, Xuanjing Huang |  |
| 1105 |  |  [Moral Foundations of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.982) |  | 0 | Moral foundations theory (MFT) is a psychological assessment tool that decomposes human moral reasoning into five factors, including care/harm, liberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary in the weight they place on these dimensions when making moral decisions,... | Marwa Abdulhai, Gregory SerapioGarcía, Clément Crepy, Daria Valter, John Canny, Natasha Jaques |  |
| 1106 |  |  [The Zeno's Paradox of 'Low-Resource' Languages](https://doi.org/10.18653/v1/2024.emnlp-main.983) |  | 0 | The disparity in the languages commonly studied in Natural Language Processing (NLP) is typically reflected by referring to languages as low vs high-resourced. However, there is limited consensus on what exactly qualifies as a ‘low-resource language.’ To understand how NLP papers define and study... | Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin Rosman, Thamar Solorio, Monojit Choudhury |  |
| 1107 |  |  [Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.984) |  | 0 | In mental health counseling, condensing dialogues into concise and relevant summaries (aka counseling notes) holds pivotal significance. Large Language Models (LLMs) exhibit remarkable capabilities in various generative tasks; however, their adaptation to domain-specific intricacies remains... | Aseem Srivastava, Smriti Joshi, Tanmoy Chakraborty, Md. Shad Akhtar |  |
| 1108 |  |  [Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition](https://doi.org/10.18653/v1/2024.emnlp-main.985) |  | 0 | Accurately attributing answer text to its source document is crucial for developing a reliable question-answering system. However, attribution for long documents remains largely unexplored. Post-hoc attribution systems are designed to map answer text back to the source document, yet the granularity... | Pritika Ramu, Koustava Goswami, Apoorv Saxena, Balaji Vasan Srinivasan |  |
| 1109 |  |  [From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment](https://doi.org/10.18653/v1/2024.emnlp-main.986) |  | 0 | Large language models (LLMs) have enhanced the capacity of vision-language models to caption visual text. This generative approach to image caption enrichment further makes textual captions more descriptive, improving alignment with the visual context. However, while many studies focus on the... | Yusuke Hirota, Ryo Hachiuma, ChaoHan Huck Yang, Yuta Nakashima |  |
| 1110 |  |  [Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging](https://doi.org/10.18653/v1/2024.emnlp-main.987) |  | 0 | While large language models (LLMs) excel in many domains, their complexity and scale challenge deployment in resource-limited environments. Current compression techniques, such as parameter pruning, often fail to effectively utilize the knowledge from pruned parameters. To address these challenges,... | Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Bo Li, Xi Chen, Cunhang Fan, Zhao Lv, Dianhui Chu, Zhiying Tu, Dianbo Sui |  |
| 1111 |  |  [Embedded Named Entity Recognition using Probing Classifiers](https://doi.org/10.18653/v1/2024.emnlp-main.988) |  | 0 | Streaming text generation, has become a common way of increasing the responsiveness of language model powered applications such as chat assistants. At the same time, extracting semantic information from generated text is a useful tool for applications such as automated fact checking or retrieval... | Nicholas Popovic, Michael Färber |  |
| 1112 |  |  [Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training](https://doi.org/10.18653/v1/2024.emnlp-main.989) |  | 0 | Emojis have gained immense popularity on social platforms, serving as a common means to supplement or replace text. However, existing data mining approaches generally either completely ignore or simply treat emojis as ordinary Unicode characters, which may limit the model’s ability to grasp the... | Zhou Zhang, Dongzeng Tan, Jiaan Wang, Yilong Chen, Jiarong Xu |  |
| 1113 |  |  [Data Contamination Can Cross Language Barriers](https://doi.org/10.18653/v1/2024.emnlp-main.990) |  | 0 | The opacity in developing large language models (LLMs) is raising growing concerns about the potential contamination of public benchmarks in the pre-training data. Existing contamination detection methods are typically based on the text overlap between training and evaluation data, which can be too... | Feng Yao, Yufan Zhuang, Zihao Sun, Sunan Xu, Animesh Kumar, Jingbo Shang |  |
| 1114 |  |  [Automated Essay Scoring: A Reflection on the State of the Art](https://doi.org/10.18653/v1/2024.emnlp-main.991) |  | 0 | While steady progress has been made on the task of automated essay scoring (AES) in the past decade, much of the recent work in this area has focused on developing models that beat existing models on a standard evaluation dataset. While improving performance numbers remains an important goal in the... | Shengjie Li, Vincent Ng |  |
| 1115 |  |  [Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate](https://doi.org/10.18653/v1/2024.emnlp-main.992) |  | 0 | Modern large language models (LLMs) like ChatGPT have shown remarkable performance on general language tasks but still struggle on complex reasoning tasks, which drives the research on cognitive behaviors of LLMs to explore human-like problem-solving strategies. Along this direction, one... | Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, Zhaopeng Tu |  |
| 1116 |  |  [Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.993) |  | 0 | Retrieval-Augmented Generation (RAG) significantly improved the ability of Large Language Models (LLMs) to solve knowledge-intensive tasks. While existing research seeks to enhance RAG performance by retrieving higher-quality documents or designing RAG-specific LLMs, the internal mechanisms within... | Xin Zhou, Ping Nie, Yiwen Guo, Haojie Wei, Zhanqiu Zhang, Pasquale Minervini, Ruotian Ma, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1117 |  |  [CURE: Context- and Uncertainty-Aware Mental Disorder Detection](https://doi.org/10.18653/v1/2024.emnlp-main.994) |  | 0 | As the explainability of mental disorder detection models has become important, symptom-based methods that predict disorders from identified symptoms have been widely utilized. However, since these approaches focused on the presence of symptoms, the context of symptoms can be often ignored, leading... | Migyeong Kang, Goun Choi, Hyolim Jeon, Ji Hyun An, Daejin Choi, Jinyoung Han |  |
| 1118 |  |  [PepRec: Progressive Enhancement of Prompting for Recommendation](https://doi.org/10.18653/v1/2024.emnlp-main.995) |  | 0 | With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, recent researchers have actively explored the potential of LLMs for recommendation systems by converting the input data into textual sentences through prompt templates. Although... | Yakun Yu, Shiang Qi, Baochun Li, Di Niu |  |
| 1119 |  |  [In-Context Compositional Generalization for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.996) |  | 0 | Recent work has revealed that in-context learning for large language models exhibits compositional generalization capacity, which can be enhanced by selecting in-context demonstrations similar to test cases to provide contextual information. However, how to exhibit in-context compositional... | Chuanhao Li, Chenchen Jing, Zhen Li, Mingliang Zhai, Yuwei Wu, Yunde Jia |  |
| 1120 |  |  [Improving Zero-shot LLM Re-Ranker with Risk Minimization](https://doi.org/10.18653/v1/2024.emnlp-main.997) |  | 0 |  | Xiaowei Yuan, Zhao Yang, Yequan Wang, Jun Zhao, Kang Liu |  |
| 1121 |  |  [Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory](https://doi.org/10.18653/v1/2024.emnlp-main.998) |  | 0 | Large Vision-Language Models (LVLMs) may produce outputs that are unfaithful to reality, also known as visual hallucinations (VH), which hinders their application in multimodal understanding and decision-making. In this work, we introduce a novel plug-and-play train-free decoding algorithm named... | Xianwei Zhuang, Zhihong Zhu, Zhanpeng Chen, Yuxin Xie, Liming Liang, Yuexian Zou |  |
| 1122 |  |  [Label Confidence Weighted Learning for Target-level Sentence Simplification](https://doi.org/10.18653/v1/2024.emnlp-main.999) |  | 0 | Multi-level sentence simplification generates simplified sentences with varying language proficiency levels. We propose Label Confidence Weighted Learning (LCWL), a novel approach that incorporates a label confidence weighting scheme in the training loss of the encoder-decoder model, setting it... | Xin Ying Qiu, Jingshen Zhang |  |
| 1123 |  |  [Quantum Recurrent Architectures for Text Classification](https://doi.org/10.18653/v1/2024.emnlp-main.1000) |  | 0 | We develop quantum RNNs with cells based on Parametrised Quantum Circuits (PQCs). PQCs can provide a form of hybrid quantum-classical computation where the input and the output is in the form of classical data. The previous “hidden” state is the quantum state from the previous time-step, and an... | Wenduan Xu, Stephen Clark, Douglas Brown, Gabriel Matos, Konstantinos Meichanetzidis |  |
| 1124 |  |  [Tree of Problems: Improving structured problem solving with compositionality](https://doi.org/10.18653/v1/2024.emnlp-main.1001) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance across multipletasks through in-context learning. For complex reasoning tasks that require step-by-step thinking, Chain-of-Thought (CoT) prompting has given impressive results, especially when combined with self-consistency.... | Armel Zebaze, Benoît Sagot, Rachel Bawden |  |
| 1125 |  |  [What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine Translation with a Human-centered Study](https://doi.org/10.18653/v1/2024.emnlp-main.1002) |  | 0 | Gender bias in machine translation (MT) is recognized as an issue that can harm people and society. And yet, advancements in the field rarely involve people, the final MT users, or inform how they might be impacted by biased technologies. Current evaluations are often restricted to automatic... | Beatrice Savoldi, Sara Papi, Matteo Negri, Ana Guerberof Arenas, Luisa Bentivogli |  |
| 1126 |  |  [Seg2Act: Global Context-aware Action Generation for Document Logical Structuring](https://doi.org/10.18653/v1/2024.emnlp-main.1003) |  | 0 | Document logical structuring aims to extract the underlying hierarchical structure of documents, which is crucial for document intelligence. Traditional approaches often fall short in handling the complexity and the variability of lengthy documents. To address these issues, we introduce Seg2Act, an... | Zichao Li, Shaojie He, Meng Liao, Xuanang Chen, Yaojie Lu, Hongyu Lin, Yanxiong Lu, Xianpei Han, Le Sun |  |
| 1127 |  |  [Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning](https://doi.org/10.18653/v1/2024.emnlp-main.1004) |  | 0 | Network pruning has emerged as a potential solution to make LLMs cheaper to deploy. However, existing LLM pruning approachesuniversally rely on the C4 dataset as the calibration data for calculating pruning scores, leaving its optimality unexplored. In this study, we evaluate the choice of... | Abhinav Bandari, Lu Yin, ChengYu Hsieh, Ajay Jaiswal, Tianlong Chen, Li Shen, Ranjay Krishna, Shiwei Liu |  |
| 1128 |  |  [Revisiting the Robustness of Watermarking to Paraphrasing Attacks](https://doi.org/10.18653/v1/2024.emnlp-main.1005) |  | 0 | Amidst rising concerns about the internet being proliferated with content generated from language models (LMs), watermarking is seen as a principled way to certify whether text was generated from a model. Many recent watermarking techniques slightly modify the output probabilities of LMs to embed a... | Saksham Rastogi, Danish Pruthi |  |
| 1129 |  |  [A Survey of Ontology Expansion for Conversational Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.1006) |  | 0 | In the rapidly evolving field of conversational AI, Ontology Expansion (OnExp) is crucial for enhancing the adaptability and robustness of conversational agents. Traditional models rely on static, predefined ontologies, limiting their ability to handle new and unforeseen user needs. This survey... | Jinggui Liang, Yuxia Wu, Yuan Fang, Hao Fei, Lizi Liao |  |
| 1130 |  |  [Calibrating Language Models with Adaptive Temperature Scaling](https://doi.org/10.18653/v1/2024.emnlp-main.1007) |  | 0 | The effectiveness of large language models (LLMs) is not only measured by their ability to generate accurate outputs but also by their calibration—how well their confidence scores reflect the probability of their outputs being correct. While unsupervised pre-training has been shown to yield LLMs... | Johnathan Xie, Annie S. Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn |  |
| 1131 |  |  [Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?](https://doi.org/10.18653/v1/2024.emnlp-main.1008) |  | 0 | Recent large language models (LLMs) have demonstrated remarkable generalization abilities in mathematics and logical reasoning tasks.Prior research indicates that LLMs pre-trained with programming language data exhibit high mathematical and reasoning abilities; however, this causal relationship has... | Fumiya Uchiyama, Takeshi Kojima, Andrew Gambardella, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo |  |
| 1132 |  |  [Why do objects have many names? A study on word informativeness in language use and lexical systems](https://doi.org/10.18653/v1/2024.emnlp-main.1009) |  | 0 | Human lexicons contain many different words that speakers can use to refer to the same object, e.g., \*purple\* or \*magenta\* for the same shade of color. On the one hand, studies on language use have explored how speakers adapt their referring expressions to successfully communicate in context,... | Eleonora Gualdoni, Gemma Boleda |  |
| 1133 |  |  [Dual-Space Knowledge Distillation for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1010) |  | 0 | Knowledge distillation (KD) is known as a promising solution to compress large language models (LLMs) via transferring their knowledge to smaller models. During this process, white-box KD methods usually minimize the distance between the output distributions of the two models so that more knowledge... | Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu |  |
| 1134 |  |  [NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.1011) |  | 0 | Available training data for named entity recognition (NER) often contains a significant percentage of incorrect labels for entity types and entity boundaries. Such label noise poses challenges for supervised learning and may significantly deteriorate model quality. To address this, prior work... | Elena Merdjanovska, Ansar Aynetdinov, Alan Akbik |  |
| 1135 |  |  [On the Universal Truthfulness Hyperplane Inside LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1012) |  | 0 | While large language models (LLMs) have demonstrated remarkable abilities across various fields, hallucination remains a significant challenge. Recent studies have explored hallucinations through the lens of internal representations, proposing mechanisms to decipher LLMs’ adherence to facts.... | Junteng Liu, Shiqi Chen, Yu Cheng, Junxian He |  |
| 1136 |  |  [PairDistill: Pairwise Relevance Distillation for Dense Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.1013) |  | 0 | Effective information retrieval (IR) from vast datasets relies on advanced techniques to extract relevant information in response to queries. Recent advancements in dense retrieval have showcased remarkable efficacy compared to traditional sparse retrieval methods. To further enhance retrieval... | ChaoWei Huang, YunNung Chen |  |
| 1137 |  |  [User Inference Attacks on Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1014) |  | 0 | Text written by humans makes up the vast majority of the data used to pre-train and fine-tune large language models (LLMs). Many sources of this data—like code, forum posts, personal websites, and books—are easily attributed to one or a few “users”. In this paper, we ask if it is possible to infer... | Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. ChoquetteChoo, Zheng Xu |  |
| 1138 |  |  [HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy](https://doi.org/10.18653/v1/2024.emnlp-main.1015) |  | 0 | Full-parameter fine-tuning (FPFT) has become the go-to choice for adapting language models (LMs) to downstream tasks due to its excellent performance. As LMs grow in size, fine-tuning the full parameters of LMs requires a prohibitively large amount of GPU memory. Existing approaches utilize... | Yongkang Liu, Yiqun Zhang, Qian Li, Tong Liu, Shi Feng, Daling Wang, Yifei Zhang, Hinrich Schütze |  |
| 1139 |  |  [Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models](https://doi.org/10.18653/v1/2024.emnlp-main.1016) |  | 0 | Large Vision-Language Models (LVLMs) have achieved impressive performance, yet research has pointed out a serious issue with object hallucinations within these models. However, there is no clear conclusion as to which part of the model these hallucinations originate from. In this paper, we present... | Yufang Liu, Tao Ji, Changzhi Sun, Yuanbin Wu, Aimin Zhou |  |
| 1140 |  |  [Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation](https://doi.org/10.18653/v1/2024.emnlp-main.1017) |  | 0 | Large language models (LLMs) have achieved state-of-the-art performance in various language processing tasks, motivating their adoption in simultaneous translation. Current fine-tuning methods to adapt LLMs for simultaneous translation focus on prompting optimization strategies using either data... | Matthew Raffel, Victor Agostinelli, Lizhong Chen |  |
| 1141 |  |  [ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.1018) |  | 0 | Recently, tool-augmented LLMs have gained increasing attention. Given an instruction, tool-augmented LLMs can interact with various external tools in multiple rounds and provide a final answer. However, previous LLMs were trained on overly detailed instructions, which included API names or... | Qinzhuo Wu, Wei Liu, Jian Luan, Bin Wang |  |
| 1142 |  |  [Please note that I'm just an AI: Analysis of Behavior Patterns of LLMs in (Non-)offensive Speech Identification](https://doi.org/10.18653/v1/2024.emnlp-main.1019) |  | 0 | Offensive speech is highly prevalent on online platforms. Being trained on online data, Large Language Models (LLMs) display undesirable behaviors, such as generating harmful text or failing to recognize it. Despite these shortcomings, the models are becoming a part of our everyday lives by being... | Esra Dönmez, Thang Vu, Agnieszka Falenska |  |
| 1143 |  |  [How to Compute the Probability of a Word](https://doi.org/10.18653/v1/2024.emnlp-main.1020) |  | 0 | Language models (LMs) estimate a probability distribution over strings in a natural language; these distributions are crucial for computing perplexity and surprisal in linguistics research. While we are usually concerned with measuring these values for words, most LMs operate over subwords. Despite... | Tiago Pimentel, Clara Meister |  |
| 1144 |  |  [A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks](https://doi.org/10.18653/v1/2024.emnlp-main.1021) |  | 0 | We introduce an evaluation methodology for reading comprehension tasks based on the intuition that certain examples, by the virtue of their linguistic complexity, consistently yield lower scores regardless of model size or architecture. We capitalize on semantic frame annotation for characterizing... | Elie Antoine, Frédéric Béchet, Géraldine Damnati, Philippe Langlais |  |
| 1145 |  |  [GuardBench: A Large-Scale Benchmark for Guardrail Models](https://doi.org/10.18653/v1/2024.emnlp-main.1022) |  | 0 | Generative AI systems powered by Large Language Models have become increasingly popular in recent years. Lately, due to the risk of providing users with unsafe information, the adoption of those systems in safety-critical domains has raised significant concerns. To respond to this situation,... | Elias Bassani, Ignacio Sanchez |  |
| 1146 |  |  [Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1023) |  | 0 | To address the issues of insufficient knowledge and hallucination in Large Language Models (LLMs), numerous studies have explored integrating LLMs with Knowledge Graphs (KGs). However, these methods are typically evaluated on conventional Knowledge Graph Question Answering (KGQA) with complete KGs,... | Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang Tong, Guang Liu, Jun Zhao, Kang Liu |  |
| 1147 |  |  [Language models and brains align due to more than next-word prediction and word-level information](https://doi.org/10.18653/v1/2024.emnlp-main.1024) |  | 0 | Pretrained language models have been shown to significantly predict brain recordings of people comprehending language. Recent work suggests that the prediction of the next word is a key mechanism that contributes to this alignment. What is not yet understood is whether prediction of the next word... | Gabriele Merlin, Mariya Toneva |  |
| 1148 |  |  [LLMEdgeRefine: Enhancing Text Clustering with LLM-Based Boundary Point Refinement](https://doi.org/10.18653/v1/2024.emnlp-main.1025) |  | 0 | Text clustering is a fundamental task in natural language processing with numerous applications. However, traditional clustering methods often struggle with domain-specific fine-tuning and the presence of outliers. To address these challenges, we introduce LLMEdgeRefine, an iterative clustering... | Zijin Feng, Luyang Lin, Lingzhi Wang, Hong Cheng, KamFai Wong |  |
| 1149 |  |  [CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures](https://doi.org/10.18653/v1/2024.emnlp-main.1026) |  | 0 | Explaining Artificial Intelligence (AI) decisions is a major challenge nowadays in AI, in particular when applied to sensitive scenarios like medicine and law. However, the need to explain the rationale behind decisions is a main issues also for human-based deliberation as it is important to... | Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri |  |
| 1150 |  |  [A Simple and Effective L_2 Norm-Based Strategy for KV Cache Compression](https://doi.org/10.18653/v1/2024.emnlp-main.1027) |  | 0 | The deployment of large language models (LLMs) is often hindered by the extensive memory requirements of the Key-Value (KV) cache, especially as context lengths increase. Existing approaches to reduce the KV cache size involve either fine-tuning the model to learn a compression strategy or... | Alessio Devoto, Yu Zhao, Simone Scardapane, Pasquale Minervini |  |
| 1151 |  |  [GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration](https://doi.org/10.18653/v1/2024.emnlp-main.1028) |  | 0 | The illustration or visualization of figurative language, such as linguistic metaphors, is an emerging challenge for existing Large Language Models (LLMs) and multimodal models. Due to their comparison of seemingly unrelated concepts in metaphors, existing LLMs have a tendency of... | Linhao Zhang, Jintao Liu, Li Jin, Hao Wang, Kaiwen Wei, Guangluan Xu |  |
| 1152 |  |  [D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation](https://doi.org/10.18653/v1/2024.emnlp-main.1029) |  | 0 | While human annotations play a crucial role in language technologies, annotator subjectivity has long been overlooked in data collection. Recent studies that critically examine this issue are often focused on Western contexts, and solely document differences across age, gender, or racial groups.... | Aida Mostafazadeh Davani, Mark Diaz, Dylan K. Baker, Vinodkumar Prabhakaran |  |
| 1153 |  |  [PALM: Few-Shot Prompt Learning for Audio Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1030) |  | 0 | Audio-Language Models (ALMs) have recently achieved remarkable success in zero-shot audio recognition tasks, which match features of audio waveforms with class-specific text prompt features, inspired by advancements in Vision-Language Models (VLMs). Given the sensitivity of zero-shot performance to... | Asif Hanif, Maha Tufail Agro, Mohammad Areeb Qazi, Hanan Aldarmaki |  |
| 1154 |  |  [Annotator-Centric Active Learning for Subjective NLP Tasks](https://doi.org/10.18653/v1/2024.emnlp-main.1031) |  | 0 | Active Learning (AL) addresses the high costs of collecting human annotations by strategically annotating the most informative samples. However, for subjective NLP tasks, incorporating a wide range of perspectives in the annotation process is crucial to capture the variability in human judgments.... | Michiel van der Meer, Neele Falk, Pradeep K. Murukannaiah, Enrico Liscio |  |
| 1155 |  |  [On the Proper Treatment of Tokenization in Psycholinguistics](https://doi.org/10.18653/v1/2024.emnlp-main.1032) |  | 0 | Language models are widely used in computational psycholinguistics to test theories that relate the negative log probability (the surprisal) of a region of interest (a substring of characters) under a language model to its cognitive cost experienced by readers, as operationalized, for example, by... | Mario Giulianelli, Luca Malagutti, Juan Luis Gastaldi, Brian DuSell, Tim Vieira, Ryan Cotterell |  |
| 1156 |  |  [Enhanced Hallucination Detection in Neural Machine Translation through Simple Detector Aggregation](https://doi.org/10.18653/v1/2024.emnlp-main.1033) |  | 0 | Hallucinated translations pose significant threats and safety concerns when it comes to practical deployment of machine translation systems. Previous research works have identified that detectors exhibit complementary performance — different detectors excel at detecting different types of... | Anas Himmi, Guillaume Staerman, Marine Picot, Pierre Colombo, Nuno Miguel Guerreiro |  |
| 1157 |  |  [Jailbreaking LLMs with Arabic Transliteration and Arabizi](https://doi.org/10.18653/v1/2024.emnlp-main.1034) |  | 0 | This study identifies the potential vulnerabilities of Large Language Models (LLMs) to ‘jailbreak’ attacks, specifically focusing on the Arabic language and its various forms. While most research has concentrated on English-based prompt manipulation, our investigation broadens the scope to... | Mansour Al Ghanim, Saleh Almohaimeed, Mengxin Zheng, Yan Solihin, Qian Lou |  |
| 1158 |  |  [Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1035) |  | 0 | Large language models (LLMs) have been shown to propagate and amplify harmful stereotypes, particularly those that disproportionately affect marginalised communities. To understand the effect of these stereotypes more comprehensively, we introduce GlobalBias, a dataset of 876k sentences... | Zara Siddique, Liam D. Turner, Luis Espinosa Anke |  |
| 1159 |  |  [Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks](https://doi.org/10.18653/v1/2024.emnlp-main.1036) |  | 0 | Instruction tuning has been proven effective in enhancing zero-shot generalization across various tasks and in improving the performance of specific tasks. For task-specific improvements, strategically selecting and training on related tasks that provide meaningful supervision is crucial, as this... | Changho Lee, Janghoon Han, Seonghyeon Ye, Stanley Jungkyu Choi, Honglak Lee, Kyunghoon Bae |  |
| 1160 |  |  [Recurrent Alignment with Hard Attention for Hierarchical Text Rating](https://doi.org/10.18653/v1/2024.emnlp-main.1037) |  | 0 | While large language models (LLMs) excel at understanding and generating plain text, they are not tailored to handle hierarchical text structures or directly predict task-specific properties such as text rating. In fact, selectively and repeatedly grasping the hierarchical structure of large-scale... | Chenxi Lin, Jiayu Ren, Guoxiu He, Zhuoren Jiang, Haiyan Yu, Xiaomin Zhu |  |
| 1161 |  |  [CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification](https://doi.org/10.18653/v1/2024.emnlp-main.1038) |  | 0 | Deploying large language models (LLMs) on edge devices presents significant challenges due to the substantial computational overhead and memory requirements. Activation sparsification can mitigate these resource challenges by reducing the number of activated neurons during inference. Existing... | Junhui He, Shangyu Wu, Weidong Wen, Chun Jason Xue, Qingan Li |  |
| 1162 |  |  [Semformer: Transformer Language Models with Semantic Planning](https://doi.org/10.18653/v1/2024.emnlp-main.1039) |  | 0 | Next-token prediction serves as the dominant component in current neural language models.During the training phase, the model employs teacher forcing, which predicts tokens based on all preceding ground truth tokens.However, this approach has been found to create shortcuts, utilizing the revealed... | Yongjing Yin, Junran Ding, Kai Song, Yue Zhang |  |
| 1163 |  |  [DocCGen: Document-based Controlled Code Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1040) |  | 0 | Recent developments show that Large Language Models (LLMs) produce state-of-the-art performance on natural language (NL) to code generation for resource-rich general-purpose languages like C++, Java, and Python. However, their practical usage for structured domain-specific languages (DSLs) such as... | Sameer Pimparkhede, Mehant Kammakomati, Srikanth Tamilselvam, Prince Kumar, Ashok Pon Kumar, Pushpak Bhattacharyya |  |
| 1164 |  |  [Semantics and Sentiment: Cross-lingual Variations in Emoji Use](https://doi.org/10.18653/v1/2024.emnlp-main.1041) |  | 0 | Over the past decade, the use of emojis in social media has seen a rapid increase. Despite their popularity and image-grounded nature, previous studies have found that people interpret emojis inconsistently when presented in context and in isolation. In this work, we explore whether emoji semantics... | Giulio Zhou, Sydelle De Souza, Ella Markham, Oghenetekevwe Kwakpovwe, Sumin Zhao |  |
| 1165 |  |  [The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations](https://doi.org/10.18653/v1/2024.emnlp-main.1042) |  | 0 | To study the requirements needed for a human-like language to develop, Language Emergence research uses jointly trained artificial agents which communicate to solve a task, the most popular of which is a referential game. The targets that agents refer to typically involve a single entity, which... | Daniel Akkerman, Phong Le, Raquel G. Alhama |  |
| 1166 |  |  [Transformers are Multi-State RNNs](https://doi.org/10.18653/v1/2024.emnlp-main.1043) |  | 0 |  | Matanel Oren, Michael Hassid, Yarden Nir, Yossi Adi, Roy Schwartz |  |
| 1167 |  |  [Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization](https://doi.org/10.18653/v1/2024.emnlp-main.1044) |  | 0 | While large language models exhibit certain cross-lingual generalization capabilities, they suffer from performance degradation (PD) on unseen closely-related languages (CRLs) and dialects relative to their high-resource language neighbour (HRLN). However, we currently lack a fundamental... | Niyati Bafna, Kenton Murray, David Yarowsky |  |
| 1168 |  |  [Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion](https://doi.org/10.18653/v1/2024.emnlp-main.1045) |  | 0 | Model fusion research aims to aggregate the knowledge of multiple individual models to enhance performance by combining their weights. In this work, we study the inverse problem: investigating whether model fusion can be used to reduce unwanted knowledge. We investigate the effects of model fusion... | Kerem Zaman, Leshem Choshen, Shashank Srivastava |  |
| 1169 |  |  [Collective Critics for Creative Story Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1046) |  | 0 | Generating a long story of several thousand words with narrative coherence using Large Language Models (LLMs) has been a challenging task. Previous research has addressed this challenge by proposing different frameworks that create a story plan and generate a long story based on that plan. However,... | Minwook Bae, Hyounghun Kim |  |
| 1170 |  |  [Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse](https://doi.org/10.18653/v1/2024.emnlp-main.1047) |  | 0 | The Uniform Information Density (UID) hypothesis posits that speakers tend to distribute information evenly across linguistic units to achieve efficient communication. Of course, information rate in texts and discourses is not perfectly uniform. While these fluctuations can be viewed as... | Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, Alex Warstadt |  |
| 1171 |  |  [Model-based Preference Optimization in Abstractive Summarization without Human Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.1048) |  | 0 | In abstractive summarization, the challenge of producing concise and accurate summaries arises from the vast amount of information contained in the source document. Consequently, although Large Language Models (LLMs) can generate fluent text, they often introduce inaccuracies by hallucinating... | Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim |  |
| 1172 |  |  [Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?](https://doi.org/10.18653/v1/2024.emnlp-main.1049) |  | 0 | This work investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks. For the future advance of NER in safety-critical fields like healthcare and finance, it is essential to achieve accurate predictions with calibrated... | Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe |  |
| 1173 |  |  [NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries](https://doi.org/10.18653/v1/2024.emnlp-main.1050) |  | 0 | Extracting and aggregating information from clinical trial registries could provide invaluable insights into the drug development landscape and advance the treatment of neurologic diseases. However, achieving this at scale is hampered by the volume of available data and the lack of an annotated... | Simona Doneva, Tilia Ellendorff, Beate Sick, JeanPhilippe Goldman, Amelia Cannon, Gerold Schneider, Benjamin Ineichen |  |
| 1174 |  |  [Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting](https://doi.org/10.18653/v1/2024.emnlp-main.1051) |  | 0 | The growing capabilities of AI models are leading to their wider use, including in safety-critical domains. Explainable AI (XAI) aims to make these models safer to use by making their inference process more transparent. However, current explainability methods are seldom evaluated in the way they... | Maxime Kayser, Bayar Menzat, Cornelius Emde, Bogdan Bercean, Alex Novak, Abdalá Morgado, Bartlomiej W. Papiez, Susanne Gaube, Thomas Lukasiewicz, OanaMaria Camburu |  |
| 1175 |  |  [Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1052) |  | 0 | The fusion of language models (LMs) and knowledge graphs (KGs) is widely used in commonsense question answering, but generating faithful explanations remains challenging. Current methods often overlook path decoding faithfulness, leading to divergence between graph encoder outputs and model... | Weihe Zhai, Arkaitz Zubiaga, Bingquan Liu, Chengjie Sun, Yalong Zhao |  |
| 1176 |  |  [Generation with Dynamic Vocabulary](https://doi.org/10.18653/v1/2024.emnlp-main.1053) |  | 0 | We introduce a new dynamic vocabulary for language models. It can involve arbitrary text spans during generation. These text spans act as basic generation bricks, akin to tokens in the traditional static vocabularies. We show that, the ability to generate multi-tokens atomically improve both... | Yanting Liu, Tao Ji, Changzhi Sun, Yuanbin Wu, Xiaoling Wang |  |
| 1177 |  |  [Argument Relation Classification through Discourse Markers and Adversarial Training](https://doi.org/10.18653/v1/2024.emnlp-main.1054) |  | 0 | Argument relation classification (ARC) identifies supportive, contrasting and neutral relations between argumentative units. The current approaches rely on transformer architectures which have proven to be more effective than traditional methods based on hand-crafted linguistic features. In this... | Michele Contalbo, Francesco Guerra, Matteo Paganelli |  |
| 1178 |  |  [Getting The Most Out of Your Training Data: Exploring Unsupervised Tasks for Morphological Inflection](https://doi.org/10.18653/v1/2024.emnlp-main.1055) |  | 0 | Pre-trained transformers such as BERT have been shown to be effective in many natural language tasks. However, they are under-explored for character-level sequence to sequence tasks. In this work, we investigate pre-training transformers for the character-level task of morphological inflection in... | Abhishek Purushothama, Adam Wiemerslage, Katharina von der Wense |  |
| 1179 |  |  [Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.1056) |  | 0 | Despite the recent advancements in information retrieval (IR), zero-shot IR remains a significant challenge, especially when dealing with new domains, languages, and newly-released use cases that lack historical query traffic from existing users. For such cases, it is common to use query... | Dae Yon Hwang, Bilal Taha, Harshit Pande, Yaroslav Nechaev |  |
| 1180 |  |  [Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1057) |  | 0 | Multilingual pre-trained language models (mPLMs) have demonstrated notable effectiveness in zero-shot cross-lingual transfer tasks. Specifically, they can be fine-tuned solely on tasks in the source language and subsequently applied to tasks in the target language. However, for low-resource... | PoHeng Chen, YunNung Chen |  |
| 1181 |  |  [Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1058) |  | 0 | Argumentative essay generation (AEG) aims to generate complete texts on specific controversial topics or debates. Although current AEG methods can generate individual opinions, they often overlook the high-level connections between these opinions. This often leads to the generated results being... | Ruiyu Xiao, Lei Wu, Yuhang Gou, Weinan Zhang, Ting Liu |  |
| 1182 |  |  [TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.1059) |  | 0 | It is challenging for models to understand complex, multimodal content such as television clips, and this is in part because video-language models often rely on single-modality reasoning and lack interpretability. To combat these issues we propose TV-TREES, the first multimodal entailment tree... | Kate Sanders, Nathaniel Weir, Benjamin Van Durme |  |
| 1183 |  |  [Unsupervised Extraction of Dialogue Policies from Conversations](https://doi.org/10.18653/v1/2024.emnlp-main.1060) |  | 0 | Dialogue policies play a crucial role in developing task-oriented dialogue systems, yet their development and maintenance are challenging and typically require substantial effort from experts in dialogue modeling. While in many situations, large amounts of conversational data are available for the... | Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien |  |
| 1184 |  |  [GRIZAL: Generative Prior-guided Zero-Shot Temporal Action Localization](https://doi.org/10.18653/v1/2024.emnlp-main.1061) |  | 0 | Zero-shot temporal action localization (TAL) aims to temporally localize actions in videos without prior training examples. To address the challenges of TAL, we offer GRIZAL, a model that uses multimodal embeddings and dynamic motion cues to localize actions effectively. GRIZAL achieves sample... | Onkar Susladkar, Gayatri Deshmukh, Vandan Gorade, Sparsh Mittal |  |
| 1185 |  |  [Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality](https://doi.org/10.18653/v1/2024.emnlp-main.1062) |  | 0 | In this paper, we propose a new method to enhance compositional understanding in pre-trained vision and language models (VLMs) without sacrificing performance in zero-shot multi-modal tasks. Traditional fine-tuning approaches often improve compositional reasoning at the cost of degrading... | Youngtaek Oh, JaeWon Cho, DongJin Kim, In So Kweon, Junmo Kim |  |
| 1186 |  |  [FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture](https://doi.org/10.18653/v1/2024.emnlp-main.1063) |  | 0 | Food is a rich and varied dimension of cultural heritage, crucial to both individuals and social groups. To bridge the gap in the literature on the often-overlooked regional diversity in this domain, we introduce FoodieQA, a manually curated, fine-grained image-text dataset capturing the intricate... | Wenyan Li, Xinyu Zhang, Jiaang Li, Qiwei Peng, Raphael Tang, Li Zhou, Weijia Zhang, Guimin Hu, Yifei Yuan, Anders Søgaard, Daniel Hershcovich, Desmond Elliott |  |
| 1187 |  |  [A Two-Step Approach for Data-Efficient French Pronunciation Learning](https://doi.org/10.18653/v1/2024.emnlp-main.1064) |  | 0 | Recent studies have addressed intricate phonological phenomena in French, relying on either extensive linguistic knowledge or a significant amount of sentence-level pronunciation data. However, creating such resources is expensive and non-trivial. To this end, we propose a novel two-step approach... | Hoyeon Lee, Hyeeun Jang, JongHwan Kim, JaeMin Kim |  |
| 1188 |  |  [Exploring Intra and Inter-language Consistency in Embeddings with ICA](https://doi.org/10.18653/v1/2024.emnlp-main.1065) |  | 0 | Word embeddings represent words as multidimensional real vectors, facilitating data analysis and processing, but are often challenging to interpret. Independent Component Analysis (ICA) creates clearer semantic axes by identifying independent key features. Previous research has shown ICA’s... | Rongzhi Li, Takeru Matsuda, Hitomi Yanaka |  |
| 1189 |  |  [DetoxLLM: A Framework for Detoxification with Explanations](https://doi.org/10.18653/v1/2024.emnlp-main.1066) |  | 0 | Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would... | Md Tawkat Islam Khondaker, Muhammad AbdulMageed, Laks V. S. Lakshmanan |  |
| 1190 |  |  [Comparing a BERT Classifier and a GPT classifier for Detecting Connective Language Across Multiple Social Media](https://doi.org/10.18653/v1/2024.emnlp-main.1067) |  | 0 | This study presents an approach for detecting connective language—defined as language that facilitates engagement, understanding, and conversation—from social media discussions. We developed and evaluated two types of classifiers: BERT and GPT-3.5 turbo. Our results demonstrate that the BERT... | Josephine Lukito, Bin Chen, Gina M. Masullo, Natalie Jomini Stroud |  |
| 1191 |  |  [ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1068) |  | 0 | The high power consumption and latency-sensitive deployments of large language models (LLMs) have motivated efficiency techniques like quantization and sparsity. Contextual sparsity, where the sparsity pattern is input-dependent, is crucial in LLMs because the permanent removal of attention heads... | Yash Akhauri, Ahmed F. AbouElhamayed, Jordan Dotzel, Zhiru Zhang, Alexander M. Rush, Safeen Huda, Mohamed S. Abdelfattah |  |
| 1192 |  |  [Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health](https://doi.org/10.18653/v1/2024.emnlp-main.1069) |  | 0 | We are united in how emotions are central to shaping our experiences; yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined... | Krishnapriya Vishnubhotla, Daniela Teodorescu, Mallory J. Feldman, Kristen A. Lindquist, Saif M. Mohammad |  |
| 1193 |  |  [BLSP-Emo: Towards Empathetic Large Speech-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1070) |  | 0 | The recent release of GPT-4o showcased the potential of end-to-end multimodal models, not just in terms of low latency but also in their ability to understand and generate expressive speech with rich emotions. While the details are unknown to the open research community, it likely involves... | Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang |  |
| 1194 |  |  [SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation](https://doi.org/10.18653/v1/2024.emnlp-main.1071) |  | 0 | It is often desirable to distill the capabilities of large language models (LLMs) into smaller student models due to compute and memory constraints. One way to do this for classification tasks is via dataset synthesis, which can be accomplished by generating examples of each label from the LLM.... | Abhishek Divekar, Greg Durrett |  |
| 1195 |  |  [Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.1072) |  | 0 | Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilities remains quite rudimentary. They often struggle with simple daily tasks, such... | Wenqi Zhang, Zhenglin Cheng, Yuanyu He, Mengna Wang, Yongliang Shen, Zeqi Tan, Guiyang Hou, Mingqian He, Yanna Ma, Weiming Lu, Yueting Zhuang |  |
| 1196 |  |  [DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts](https://doi.org/10.18653/v1/2024.emnlp-main.1073) |  | 0 | Data-driven storytelling is a powerful method for conveying insights by combining narrative techniques with visualizations and text. These stories integrate visual aids, such as highlighted bars and lines in charts, along with textual annotations explaining insights. However, creating such stories... | Mohammed Saidul Islam, Md. Tahmid Rahman Laskar, Md. Rizwan Parvez, Enamul Hoque, Shafiq Joty |  |
| 1197 |  |  [DEM: Distribution Edited Model for Training with Mixed Data Distributions](https://doi.org/10.18653/v1/2024.emnlp-main.1074) |  | 0 | Training with mixed data distributions is a common and important part of creating multi-task and instruction-following models. The diversity of the data distributions and cost of joint training makes the optimization procedure extremely challenging. Data mixing methods partially address this... | Dhananjay Ram, Aditya Rawal, Momchil Hardalov, Nikolaos Pappas, Sheng Zha |  |
| 1198 |  |  [Altogether: Image Captioning via Re-aligning Alt-text](https://doi.org/10.18653/v1/2024.emnlp-main.1075) |  | 0 | This paper focuses on creating synthetic data to improve the quality of image captions. Existing works typically have two shortcomings. First, they caption images from scratch, ignoring existing alt-text metadata, and second, lack transparency if the captioners’ training data (e.g. GPT) is unknown.... | Hu Xu, PoYao Huang, Xiaoqing Ellen Tan, ChingFeng Yeh, Jacob Kahn, Christine Jou, Gargi Ghosh, Omer Levy, Luke Zettlemoyer, Wentau Yih, ShangWen Li, Saining Xie, Christoph Feichtenhofer |  |
| 1199 |  |  [VerifyMatch: A Semi-Supervised Learning Paradigm for Natural Language Inference with Confidence-Aware MixUp](https://doi.org/10.18653/v1/2024.emnlp-main.1076) |  | 0 | While natural language inference (NLI) has emerged as a prominent task for evaluating a model’s capability to perform natural language understanding, creating large benchmarks for training deep learning models imposes a significant challenge since it requires extensive human annotations. To... | Seoyeon Park, Cornelia Caragea |  |
| 1200 |  |  [CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans](https://doi.org/10.18653/v1/2024.emnlp-main.1077) |  | 0 | Understanding the abilities of LLMs to reason about natural language plans, such as instructional text and recipes, is critical to reliably using them in decision-making systems. A fundamental aspect of plans is the temporal order in which their steps need to be executed, which reflects the... | Yash Kumar Lal, Vanya Cohen, Nathanael Chambers, Niranjan Balasubramanian, Raymond J. Mooney |  |
| 1201 |  |  [Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics](https://doi.org/10.18653/v1/2024.emnlp-main.1078) |  | 0 | Automatic metrics are used as proxies to evaluate abstractive summarization systems when human annotations are too expensive. To be useful, these metrics should be fine-grained, show a high correlation with human annotations, and ideally be independant of reference quality; however, most standard... | Théo Gigant, Camille Guinaudeau, Marc Decombas, Frédéric Dufaux |  |
| 1202 |  |  [An Empirical Analysis of the Writing Styles of Persona-Assigned LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1079) |  | 0 |  | Manuj Malik, Jing Jiang, Kian Ming Chai |  |
| 1203 |  |  [Investigating the Role of Instruction Variety and Task Difficulty in Robotic Manipulation Tasks](https://doi.org/10.18653/v1/2024.emnlp-main.1080) |  | 0 | Evaluating the generalisation capabilities of multimodal models based solely on their performance on out-of-distribution data fails to capture their true robustness. This work introduces a comprehensive evaluation framework that systematically examines the role of instructions and inputs in the... | Amit Parekh, Nikolas Vitsakis, Alessandro Suglia, Ioannis Konstas |  |
| 1204 |  |  [GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.1081) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation (RAG) have become popular methods for adapting large language models while minimizing compute requirements. In this paper, we apply PEFT methods (P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer... | Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev |  |
| 1205 |  |  [CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing](https://doi.org/10.18653/v1/2024.emnlp-main.1082) |  | 0 | Large Language Models have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and... | Xinyi He, Jiaru Zou, Yun Lin, Mengyu Zhou, Shi Han, Zejian Yuan, Dongmei Zhang |  |
| 1206 |  |  [Sequential API Function Calling Using GraphQL Schema](https://doi.org/10.18653/v1/2024.emnlp-main.1083) |  | 0 | Function calling using Large Language Models (LLMs) is an active research area that aims to empower LLMs with the ability to execute APIs to perform real-world tasks. However, sequential function calling using LLMs with interdependence between functions is still under-explored. To this end, we... | Avirup Saha, Lakshmi Mandal, Balaji Ganesan, Sambit Ghosh, Renuka Sindhgatta, Carlos Eberhardt, Dan Debrunner, Sameep Mehta |  |
| 1207 |  |  [The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems](https://doi.org/10.18653/v1/2024.emnlp-main.1084) |  | 0 | We examine how users perceive the limitations of an AI system when it encounters a task that it cannot perform perfectly and whether providing explanations alongside its answers aids users in constructing an appropriate mental model of the system’s capabilities and limitations. We employ a visual... | Judith Sieker, Simeon Junker, Ronja Utescher, Nazia Attari, Heiko Wersing, Hendrik Buschmeier, Sina Zarrieß |  |
| 1208 |  |  [Re-Evaluating Evaluation for Multilingual Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.1085) |  | 0 | Automatic evaluation approaches (ROUGE, BERTScore, LLM-based evaluators) have been widely used to evaluate summarization tasks. Despite the complexities of script differences and tokenization, these approaches have been indiscriminately applied to summarization across multiple languages. While... | Jessica Forde, Ruochen Zhang, Lintang Sutawika, Alham Fikri Aji, Samuel Cahyawijaya, Genta Indra Winata, Minghao Wu, Carsten Eickhoff, Stella Biderman, Ellie Pavlick |  |
| 1209 |  |  [Video-Text Prompting for Weakly Supervised Spatio-Temporal Video Grounding](https://doi.org/10.18653/v1/2024.emnlp-main.1086) |  | 0 | Weakly-supervised Spatio-Temporal Video Grounding(STVG) aims to localize target object tube given a text query, without densely annotated training data. Existing methods extract each candidate tube feature independently by cropping objects from video frame feature, discarding all contextual... | Heng Zhao, Yinjie Zhao, Bihan Wen, YewSoon Ong, Joey Zhou |  |
| 1210 |  |  [A Fast and Sound Tagging Method for Discontinuous Named-Entity Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.1087) |  | 0 | We introduce a novel tagging scheme for discontinuous named entity recognition based on an explicit description of the inner structure of discontinuous mentions. We rely on a weighted finite state automaton for both marginal and maximum a posteriori inference. As such, our method is sound in the... | Caio Corro |  |
| 1211 |  |  [Factuality of Large Language Models: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.1088) |  | 0 | Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a straightforward answer to a variety of questions in a single... | Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Fei Liu, Georgi N. Georgiev, Rocktim Jyoti Das, Preslav Nakov |  |
| 1212 |  |  [Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation](https://doi.org/10.18653/v1/2024.emnlp-main.1089) |  | 0 | Most of the efforts in interpreting neural relevance models have been on local explanations, which explain the relevance of a document to a query. However, local explanations are not effective in predicting the model’s behavior on unseen texts. We aim at explaining a neural relevance model by... | Youngwoo Kim, Razieh Rahimi, James Allan |  |
| 1213 |  |  [Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse](https://doi.org/10.18653/v1/2024.emnlp-main.1090) |  | 0 | This work provides an explanatory view of how LLMs can apply moral reasoning to both criticize and defend sexist language. We assessed eight large language models, all of which demonstrated the capability to provide explanations grounded in varying moral perspectives for both critiquing and... | Rongchen Guo, Isar Nejadgholi, Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko |  |
| 1214 |  |  [DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers](https://doi.org/10.18653/v1/2024.emnlp-main.1091) |  | 0 | Despite their high predictive accuracies, current machine learning systems often exhibit systematic biases stemming from annotation artifacts or insufficient support for certain classes in the dataset. Recent work proposes automatic methods for identifying and explaining systematic biases using... | Rakesh R. Menon, Shashank Srivastava |  |
| 1215 |  |  [IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.1092) |  | 0 | Image-text contrastive models such as CLIP learn transferable and robust representations for zero-shot transfer to a variety of downstream tasks. However, to obtain strong downstream performances, prompts need to be carefully curated, which can be a tedious engineering task. To address the issue of... | Soumya Suvra Ghosal, Samyadeep Basu, Soheil Feizi, Dinesh Manocha |  |
| 1216 |  |  [Scope-enhanced Compositional Semantic Parsing for DRT](https://doi.org/10.18653/v1/2024.emnlp-main.1093) |  | 0 | Discourse Representation Theory (DRT) distinguishes itself from other semantic representation frameworks by its ability to model complex semantic and discourse phenomena through structural nesting and variable binding. While seq2seq models hold the state of the art on DRT parsing, their accuracy... | Xiulin Yang, Jonas Groschwitz, Alexander Koller, Johan Bos |  |
| 1217 |  |  [The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1094) |  | 0 | We explore the alignment of values in Large Language Models (LLMs) with specific age groups, leveraging data from the World Value Survey across thirteen categories. Through a diverse set of prompts tailored to ensure response robustness, we find a general inclination of LLM values towards younger... | Siyang Liu, Trisha Maturi, Bowen Yi, Siqi Shen, Rada Mihalcea |  |
| 1218 |  |  [TempoFormer: A Transformer for Temporally-aware Representations in Change Detection](https://doi.org/10.18653/v1/2024.emnlp-main.1095) |  | 0 | Dynamic representation learning plays a pivotal role in understanding the evolution of linguistic content over time. On this front both context and time dynamics as well as their interplay are of prime importance. Current approaches model context via pre-trained representations, which are typically... | Talia Tseriotou, Adam Tsakalidis, Maria Liakata |  |
| 1219 |  |  [Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?](https://doi.org/10.18653/v1/2024.emnlp-main.1096) |  | 0 | Are LLMs ready to compete in creative writing skills with a top (rather than average) novelist? To provide an initial answer for this question, we have carried out a contest between Patricio Pron (an awarded novelist, considered one of the best of his generation) and GPT-4 (one of the top... | Guillermo Marco, Julio Gonzalo, María Teresa Mateo Girona, Ramón Santos |  |
| 1220 |  |  [Evaluating Diversity in Automatic Poetry Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1097) |  | 0 | Natural Language Generation (NLG), and more generally generative AI, are among the currently most impactful research fields. Creative NLG, such as automatic poetry generation, is a fascinating niche in this area. While most previous research has focused on forms of the Turing test when evaluating... | Yanran Chen, Hannes Gröner, Sina Zarrieß, Steffen Eger |  |
| 1221 |  |  [Evaluating Short-Term Temporal Fluctuations of Social Biases in Social Media Data and Masked Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1098) |  | 0 | Social biases such as gender or racial biases have been reported in language models (LMs), including Masked Language Models (MLMs). Given that MLMs are continuously trained with increasing amounts of additional data collected over time, an important yet unanswered question is how the social biases... | Yi Zhou, Danushka Bollegala, José CamachoCollados |  |
| 1222 |  |  [Delving into Qualitative Implications of Synthetic Data for Hate Speech Detection](https://doi.org/10.18653/v1/2024.emnlp-main.1099) |  | 0 | The use of synthetic data for training models for a variety of NLP tasks is now widespread. However, previous work reports mixed results with regards to its effectiveness on highly subjective tasks such as hate speech detection. In this paper, we present an in-depth qualitative analysis of the... | Camilla Casula, Sebastiano Vecellio Salto, Alan Ramponi, Sara Tonelli |  |
| 1223 |  |  [Grounding Language in Multi-Perspective Referential Communication](https://doi.org/10.18653/v1/2024.emnlp-main.1100) |  | 0 | We introduce a task and dataset for referring expression generation and comprehension in multi-agent embodied environments.In this task, two agents in a shared scene must take into account one another’s visual perspective, which may be different from their own, to both produce and understand... | Zineng Tang, Lingjun Mao, Alane Suhr |  |
| 1224 |  |  [Threshold-driven Pruning with Segmented Maximum Term Weights for Approximate Cluster-based Sparse Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.1101) |  | 0 | This paper revisits dynamic pruning through rank score thresholding in cluster-based sparse retrieval to skip the index partially at cluster and document levels during inference. It proposes a two-parameter pruning control scheme called ASC with a probabilistic guarantee on rank-safeness... | Yifan Qiao, Parker Carlson, Shanxiu He, Yingrui Yang, Tao Yang |  |
| 1225 |  |  [Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation](https://doi.org/10.18653/v1/2024.emnlp-main.1102) |  | 0 | Multilingual large language models (mLLMs) have significantly advanced machine translation, yet challenges remain for low-resource languages like Amharic. This study evaluates the performance of state-of-the-art mLLMs, specifically NLLB-200 (NLLB3.3, NLLB1.3 Distilled1.3, NLB600) and M2M (M2M1.2B,... | Hizkiel Alemayehu, Hamada M. Zahera, AxelCyrille Ngonga Ngomo |  |
| 1226 |  |  [MIPD: Exploring Manipulation and Intention In a Novel Corpus of Polish Disinformation](https://doi.org/10.18653/v1/2024.emnlp-main.1103) |  | 0 | This study presents a novel corpus of 15,356 Polish web articles, including articles identified as containing disinformation. Our dataset enables a multifaceted understanding of disinformation. We present a distinctive multilayered methodology for annotating disinformation in texts. What sets our... | Arkadiusz Modzelewski, Giovanni Da San Martino, Pavel Savov, Magdalena Wilczynska, Adam Wierzbicki |  |
| 1227 |  |  [Unsupervised Discrete Representations of American Sign Language](https://doi.org/10.18653/v1/2024.emnlp-main.1104) |  | 0 | Many modalities are naturally represented as continuous signals, making it difficult to use them with models that expect discrete units, such as LLMs. In this paper, we explore the use of audio compression techniques for the discrete representation of the gestures used in sign language. We train a... | Artem Abzaliev, Rada Mihalcea |  |
| 1228 |  |  [Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1105) |  | 0 | While humans naturally develop theory of mind (ToM), the capability to understand other people’s mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs’ ToM abilities by evaluating key... | Chani Jung, Dongkwan Kim, Jiho Jin, Jiseon Kim, Yeon Seonwoo, Yejin Choi, Alice Oh, Hyunwoo Kim |  |
| 1229 |  |  [Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1106) |  | 0 | Extractive summarization plays a pivotal role in natural language processing due to its wide-range applications in summarizing diverse content efficiently, while also being faithful to the original content. Despite significant advancement achieved in extractive summarization by Large Language... | Mihir Parmar, Hanieh Deilamsalehy, Franck Dernoncourt, Seunghyun Yoon, Ryan A. Rossi, Trung Bui |  |
| 1230 |  |  [Jump Starting Bandits with LLM-Generated Prior Knowledge](https://doi.org/10.18653/v1/2024.emnlp-main.1107) |  | 0 | We present substantial evidence demonstrating the benefits of integrating Large Language Models (LLMs) with a Contextual Multi-Armed Bandit framework. Contextual bandits have been widely used in recommendation systems to generate personalized suggestions based on user-specific contexts. We show... | Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson |  |
| 1231 |  |  [Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?](https://doi.org/10.18653/v1/2024.emnlp-main.1108) |  | 0 | In the last decade, the generalization and adaptation abilities of deep learning models were typically evaluated on fixed training and test distributions. Contrary to traditional deep learning, large language models (LLMs) are (i) even more overparameterized, (ii) trained on unlabeled text corpora... | Firat Öncel, Matthias Bethge, Beyza Ermis, Mirco Ravanelli, Cem Subakan, Çagatay Yildiz |  |
| 1232 |  |  [Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1109) |  | 0 | The rapid development of large language models has led to the widespread adoption of Retrieval-Augmented Generation (RAG), which integrates external knowledge to alleviate knowledge bottlenecks and mitigate hallucinations. However, the existing RAG paradigm inevitably suffers from the impact of... | Ruotong Pan, Boxi Cao, Hongyu Lin, Xianpei Han, Jia Zheng, Sirui Wang, Xunliang Cai, Le Sun |  |
| 1233 |  |  [Virtual Personas for Language Models via an Anthology of Backstories](https://doi.org/10.18653/v1/2024.emnlp-main.1110) |  | 0 | Large language models (LLMs) are trained from vast repositories of text authored by millions of distinct authors, reflecting an enormous diversity of human traits. While these models bear the potential to be used as approximations of human subjects in behavioral studies, prior efforts have been... | Suhong Moon, Marwa Abdulhai, Minwoo Kang, Joseph Suh, Widyadewi Soedarmadji, Eran Kohen Behar, David M. Chan |  |
| 1234 |  |  [Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?](https://doi.org/10.18653/v1/2024.emnlp-main.1111) |  | 0 | Solving grid puzzles involves a significant amount of logical reasoning. Hence, it is a good domain to evaluate reasoning capability of a model which can then guide us to improve the reasoning ability of models. However, most existing works evaluate only the final predicted answer of a puzzle,... | Nemika Tyagi, Mihir Parmar, Mohith Kulkarni, Aswin RRV, Nisarg Patel, Mutsumi Nakamura, Arindam Mitra, Chitta Baral |  |
| 1235 |  |  [Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies](https://doi.org/10.18653/v1/2024.emnlp-main.1112) |  | 0 | A diverse array of reasoning strategies has been proposed to elicit the capabilities of large language models. However, in this paper, we point out that traditional evaluations which focus solely on performance metrics miss a key factor: the increased effectiveness due to additional compute. By... | Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, Ben Athiwaratkun |  |
| 1236 |  |  [The Empirical Variability of Narrative Perceptions of Social Media Texts](https://doi.org/10.18653/v1/2024.emnlp-main.1113) |  | 0 | Most NLP work on narrative detection has focused on prescriptive definitions of stories crafted by researchers, leaving open the questions: how do crowd workers perceive texts to be a story, and why? We investigate this by building StoryPerceptions, a dataset of 2,496 perceptions of storytelling in... | Joel Mire, Maria Antoniak, Elliott Ash, Andrew Piper, Maarten Sap |  |
| 1237 |  |  [Which questions should I answer? Salience Prediction of Inquisitive Questions](https://doi.org/10.18653/v1/2024.emnlp-main.1114) |  | 0 | Inquisitive questions — open-ended, curiosity-driven questions people ask as they read — are an integral part of discourse processing and comprehension. Recent work in NLP has taken advantage of question generation capabilities of LLMs to enhance a wide range of applications. But the space of... | Yating Wu, Ritika Mangla, Alex Dimakis, Greg Durrett, Junyi Jessy Li |  |
| 1238 |  |  [Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues](https://doi.org/10.18653/v1/2024.emnlp-main.1115) |  | 0 | Personality recognition aims to identify the personality traits implied in user data such as dialogues and social media posts. Current research predominantly treats personality recognition as a classification task, failing to reveal the supporting evidence for the recognized personality. In this... | Lei Sun, Jinming Zhao, Qin Jin |  |
| 1239 |  |  [Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech](https://doi.org/10.18653/v1/2024.emnlp-main.1116) |  | 0 | Deep Learning-based end-to-end Automatic Speech Recognition (ASR) has made significant strides but still struggles with performance on out-of-domain samples due to domain shifts in real-world scenarios. Test-Time Adaptation (TTA) methods address this issue by adapting models using test samples at... | GuanTing Lin, Wei Huang, Hungyi Lee |  |
| 1240 |  |  [Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities](https://doi.org/10.18653/v1/2024.emnlp-main.1117) |  | 0 | When presented with questions involving visual thinking, humans naturally switch reasoning modalities, often forming mental images or drawing visual aids. Large language models have shown promising results in arithmetic and symbolic reasoning by expressing intermediate reasoning in text as a chain... | Sachit Menon, Richard S. Zemel, Carl Vondrick |  |
| 1241 |  |  [CodeJudge: Evaluating Code Generation with Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1118) |  | 0 | Large Language Models (LLMs) have shown promising performance in code generation. However, how to reliably evaluate code generated by LLMs remains an unresolved problem. This paper presents CodeJudge, a code evaluation framework that leverages LLMs to evaluate the semantic correctness of generated... | Weixi Tong, Tianyi Zhang |  |
| 1242 |  |  [Self-Training Large Language and Vision Assistant for Medical Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1119) |  | 0 | Large Vision-Language Models (LVLMs) have shown significant potential in assisting medical diagnosis by leveraging extensive biomedical datasets. However, the advancement of medical image understanding and reasoning critically depends on building high-quality visual instruction data, which is... | Guohao Sun, Can Qin, Huazhu Fu, Linwei Wang, Zhiqiang Tao |  |
| 1243 |  |  [SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization](https://doi.org/10.18653/v1/2024.emnlp-main.1120) |  | 0 | Large Language Models (LLMs) such as GPT & Llama have demonstrated significant achievements in summarization tasks but struggle with factual inaccuracies, a critical issue in clinical NLP applications where errors could lead to serious consequences. To counter the high costs and limited... | Prakamya Mishra, Zonghai Yao, Parth Vashisht, Feiyun Ouyang, Beining Wang, Vidhi Dhaval Mody, Hong Yu |  |
| 1244 |  |  [Defending Jailbreak Prompts via In-Context Adversarial Game](https://doi.org/10.18653/v1/2024.emnlp-main.1121) |  | 0 | Large Language Models (LLMs) demonstrate remarkable capabilities across diverse applications. However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist. Drawing inspiration from adversarial training in deep learning and LLM agent learning processes, we... | Yujun Zhou, Yufei Han, Haomin Zhuang, Kehan Guo, Zhenwen Liang, Hongyan Bao, Xiangliang Zhang |  |
| 1245 |  |  [Detecting Online Community Practices with Large Language Models: A Case Study of Pro-Ukrainian Publics on Twitter](https://doi.org/10.18653/v1/2024.emnlp-main.1122) |  | 0 | Communities on social media display distinct patterns of linguistic expression and behaviour, collectively referred to as practices. These practices can be traced in textual exchanges, and reflect the intentions, knowledge, values, and norms of users and communities. This paper introduces a... | Kateryna Kasianenko, Shima Khanehzar, Stephen Wan, Ehsan Dehghan, Axel Bruns |  |
| 1246 |  |  [Multilingual Topic Classification in X: Dataset and Analysis](https://doi.org/10.18653/v1/2024.emnlp-main.1123) |  | 0 | In the dynamic realm of social media, diverse topics are discussed daily, transcending linguistic boundaries. However, the complexities of understanding and categorising this content across various languages remain an important challenge with traditional techniques like topic modelling often... | Dimosthenis Antypas, Asahi Ushio, Francesco Barbieri, José CamachoCollados |  |
| 1247 |  |  [MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1124) |  | 0 | Large language models (LLMs) are increasingly used for complex multi-turn conversations across diverse real-world applications. However, existing benchmarks mainly focus on single-turn evaluations, overlooking the models’ capabilities in multi-turn interactions. To address this gap, we introduce ,... | WaiChung Kwan, Xingshan Zeng, Yuxin Jiang, Yufei Wang, Liangyou Li, Lifeng Shang, Xin Jiang, Qun Liu, KamFai Wong |  |
| 1248 |  |  [Updating CLIP to Prefer Descriptions Over Captions](https://doi.org/10.18653/v1/2024.emnlp-main.1125) |  | 0 | Although CLIPScore is a powerful generic metric that captures the similarity between a text and an image, it fails to distinguish between a caption that is meant to complement the information in an image and a description that is meant to replace an image entirely, e.g., for accessibility. We... | Amir Zur, Elisa Kreiss, Karel D'Oosterlinck, Christopher Potts, Atticus Geiger |  |
| 1249 |  |  [CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research](https://doi.org/10.18653/v1/2024.emnlp-main.1126) |  | 0 | This research addresses command-line embedding in cybersecurity, a field obstructed by the lack of comprehensive datasets due to privacy and regulation concerns. We propose the first dataset of similar command lines, named CyPHER, for training and unbiased evaluation. The training set is generated... | SianYao Huang, ChengLin Yang, CheYu Lin, ChunYing Huang |  |
| 1250 |  |  [Back to School: Translation Using Grammar Books](https://doi.org/10.18653/v1/2024.emnlp-main.1127) |  | 0 | Machine translation systems for high resource languages perform exceptionally well and produce high quality translations. Unfortunately, the vast majority of languages are not considered high resource and lack the quantity of parallel sentences needed to train such systems. These under-represented... | Jonathan Hus, Antonios Anastasopoulos |  |
| 1251 |  |  [VIEWS: Entity-Aware News Video Captioning](https://doi.org/10.18653/v1/2024.emnlp-main.1128) |  | 0 | Existing popular video captioning benchmarks and models often produce generic captions for videos that lack specific identification of individuals, locations, or organizations (named entities). However, in the case of news videos, the setting is more demanding, requiring the inclusion of such named... | Hammad A. Ayyubi, Tianqi Liu, Arsha Nagrani, Xudong Lin, Mingda Zhang, Anurag Arnab, Feng Han, Yukun Zhu, Xuande Feng, Kevin Zhang, Jialu Liu, ShihFu Chang |  |
| 1252 |  |  [Towards Aligning Language Models with Textual Feedback](https://doi.org/10.18653/v1/2024.emnlp-main.1129) |  | 0 | We present ALT (ALignment with Textual feedback), an approach that aligns language models with user preferences expressed in text. We argue that text offers greater expressiveness, enabling users to provide richer feedback than simple comparative preferences and this richer feedback can lead to... | Saüc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan |  |
| 1253 |  |  [AMPO: Automatic Multi-Branched Prompt Optimization](https://doi.org/10.18653/v1/2024.emnlp-main.1130) |  | 0 | Prompt engineering is very important to enhance the performance of large language models (LLMs). When dealing with complex issues, prompt engineers tend to distill multiple patterns from examples and inject relevant solutions to optimize the prompts, achieving satisfying results. However, existing... | Sheng Yang, Yurong Wu, Yan Gao, Zineng Zhou, Bin Zhu, Xiaodi Sun, JianGuang Lou, Zhiming Ding, Anbang Hu, Yuan Fang, Yunsong Li, Junyan Chen, Linjun Yang |  |
| 1254 |  |  [DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators](https://doi.org/10.18653/v1/2024.emnlp-main.1131) |  | 0 |  | Xinglin Lyu, Junhui Li, Yanqing Zhao, Min Zhang, Daimeng Wei, Shimin Tao, Hao Yang |  |
| 1255 |  |  [DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing](https://doi.org/10.18653/v1/2024.emnlp-main.1132) |  | 0 | Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT-UCS, a data-efficient fine-tuning framework that leverages unsupervised... | Devleena Das, Vivek Khetan |  |
| 1256 |  |  [Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1133) |  | 0 | In recent studies, researchers have used large language models (LLMs) to explore semantic representations in the brain; however, they have typically assessed different levels of semantic content, such as speech, objects, and stories, separately. In this study, we recorded brain activity using... | Yuko Nakagi, Takuya Matsuyama, Naoko KoideMajima, Hiroto Yamaguchi, Rieko Kubo, Shinji Nishimoto, Yu Takagi |  |
| 1257 |  |  ["They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations](https://doi.org/10.18653/v1/2024.emnlp-main.1134) |  | 0 | Large language models (LLMs) have emerged as an integral part of modern societies, powering user-facing applications such as personal assistants and enterprise applications like recruitment tools. Despite their utility, research indicates that LLMs perpetuate systemic biases. Yet, prior works on... | Preetam Prabhu Srikar Dammu, Hayoung Jung, Anjali Singh, Monojit Choudhury, Tanushree Mitra |  |
| 1258 |  |  [Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1135) |  | 0 | We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the... | Do Xuan Long, Duong Ngoc Yen, Anh Tuan Luu, Kenji Kawaguchi, MinYen Kan, Nancy F. Chen |  |
| 1259 |  |  [Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?](https://doi.org/10.18653/v1/2024.emnlp-main.1136) |  | 0 | The automatic detection of temporal relations among events has been mainly investigated with encoder-only models such as RoBERTa. Large Language Models (LLM) have recently shown promising performance in temporal reasoning tasks such as temporal question answering. Nevertheless, recent studies have... | Gabriel Roccabruna, Massimo Rizzoli, Giuseppe Riccardi |  |
| 1260 |  |  [Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties](https://doi.org/10.18653/v1/2024.emnlp-main.1137) |  | 0 |  | Keunwoo Peter Yu, Zheyuan Zhang, Fengyuan Hu, Shane Storks, Joyce Chai |  |
| 1261 |  |  [Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1138) |  | 0 | Protecting intellectual property (IP) of text such as articles and code is increasingly important, especially as sophisticated attacks become possible, such as paraphrasing by large language models (LLMs) or even unauthorized training of LLMs on copyrighted text to infringe such IP. However,... | Gregory Kang Ruey Lau, Xinyuan Niu, Hieu Dao, Jiangwei Chen, ChuanSheng Foo, Bryan Kian Hsiang Low |  |
| 1262 |  |  [MASIVE: Open-Ended Affective State Identification in English and Spanish](https://doi.org/10.18653/v1/2024.emnlp-main.1139) |  | 0 | In the field of emotion analysis, much NLP research focuses on identifying a limited number of discrete emotion categories, often applied across languages. These basic sets, however, are rarely designed with textual data in mind, and culture, language, and dialect can influence how particular... | Nicholas Deas, Elsbeth Turcan, Iván Pérez Mejía, Kathleen R. McKeown |  |
| 1263 |  |  [You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions](https://doi.org/10.18653/v1/2024.emnlp-main.1140) |  | 0 | Training question-answering QA and information retrieval systems for web queries require large, expensive datasets that are difficult to annotate and time-consuming to gather. Moreover, while natural datasets of information-seeking questions are often prone to ambiguity or ill-formed, there are... | Tasnim Kabir, Yoo Yeon Sung, Saptarashmi Bandyopadhyay, Hao Zou, Abhranil Chandra, Jordan L. BoydGraber |  |
| 1264 |  |  [AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality](https://doi.org/10.18653/v1/2024.emnlp-main.1141) |  | 0 | Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), are known to enhance training efficiency in Large Language Models (LLMs). Due to the limited parameters of LoRA, recent studies seek to combine LoRA with Mixture-of-Experts (MoE) to boost performance across various tasks.... | Peijun Qing, Chongyang Gao, Yefan Zhou, Xingjian Diao, Yaoqing Yang, Soroush Vosoughi |  |
| 1265 |  |  [Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling](https://doi.org/10.18653/v1/2024.emnlp-main.1142) |  | 0 | Prior research in computational argumentation has mainly focused on scoring the quality of arguments, with less attention on explicating logical errors. In this work, we introduce four sets of explainable templates for common informal logical fallacies designed to explicate a fallacy’s implicit... | Irfan Robbani, Paul Reisert, Surawat Pothong, Naoya Inoue, Camélia Guerraoui, Wenzhi Wang, Shoichi Naito, Jungmin Choi, Kentaro Inui |  |
| 1266 |  |  [Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions](https://doi.org/10.18653/v1/2024.emnlp-main.1143) |  | 0 | Building socially-intelligent AI agents (Social-AI) is a multidisciplinary, multimodal research goal that involves creating agents that can sense, perceive, reason about, learn from, and respond to affect, behavior, and cognition of other agents (human or artificial). Progress towards Social-AI has... | Leena Mathur, Paul Pu Liang, LouisPhilippe Morency |  |
| 1267 |  |  [RAt: Injecting Implicit Bias for Text-To-Image Prompt Refinement Models](https://doi.org/10.18653/v1/2024.emnlp-main.1144) |  | 0 | Text-to-image prompt refinement (T2I-Refine) aims to rephrase or extend an input prompt with more descriptive details that can be leveraged to generate images with higher quality. In this paper, we study an adversarial prompt attacking problem for T2I-Refine, where to goal is to implicitly inject... | Ziyi Kou, Shichao Pei, Meng Jiang, Xiangliang Zhang |  |
| 1268 |  |  [Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese](https://doi.org/10.18653/v1/2024.emnlp-main.1145) |  | 0 | Large Language Models (LLMs) are increasingly being used to generate synthetic data for training and evaluating models. However, it is unclear whether they can generate a good quality of question answering (QA) dataset that incorporates knowledge and cultural nuance embedded in a language,... | Rifki Afina Putri, Faiz Ghifari Haznitrama, Dea Adhista, Alice Oh |  |
| 1269 |  |  [Can Language Models Induce Grammatical Knowledge from Indirect Evidence?](https://doi.org/10.18653/v1/2024.emnlp-main.1146) |  | 0 | What kinds of and how much data is necessary for language models to induce grammatical knowledge to judge sentence acceptability? Recent language models still have much room for improvement in their data efficiency compared to humans. This paper investigates whether language models efficiently use... | Miyu Oba, Yohei Oseki, Akiyo Fukatsu, Akari Haga, Hiroki Ouchi, Taro Watanabe, Saku Sugawara |  |
| 1270 |  |  [Do LLMs Know to Respect Copyright Notice?](https://doi.org/10.18653/v1/2024.emnlp-main.1147) |  | 0 | Prior study shows that LLMs sometimes generate content that violates copyright. In this paper, we study another important yet underexplored problem, i.e., will LLMs respect copyright information in user input, and behave accordingly? The research problem is critical, as a negative answer would... | Jialiang Xu, Shenglan Li, Zhaozhuo Xu, Denghui Zhang |  |
| 1271 |  |  [SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding](https://doi.org/10.18653/v1/2024.emnlp-main.1148) |  | 0 | Large Language Models (LLMs) have become essential in advancing natural language processing (NLP) tasks, but their sequential token generation limits inference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising solution by using a smaller draft model to generate multiple token... | Ryan Sun, Tianyi Zhou, Xun Chen, Lichao Sun |  |
| 1272 |  |  [Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.1149) |  | 0 | Recently, pre-trained language models (PLMs) have been increasingly adopted in spoken language understanding (SLU). However, automatic speech recognition (ASR) systems frequently produce inaccurate transcriptions, leading to noisy inputs for SLU models, which can significantly degrade their... | YeonJoon Jung, Jaeseong Lee, Seungtaek Choi, Dohyeon Lee, Minsoo Kim, Seungwon Hwang |  |
| 1273 |  |  [Rethinking the Role of Proxy Rewards in Language Model Alignment](https://doi.org/10.18653/v1/2024.emnlp-main.1150) |  | 0 | Learning from human feedback via proxy reward modeling has been studied to align Large Language Models (LLMs) with human values. However, achieving reliable training through that proxy reward model (RM) is not a trivial problem, and its behavior remained as a black-box. In this paper, we study the... | Sungdong Kim, Minjoon Seo |  |
| 1274 |  |  [Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant](https://doi.org/10.18653/v1/2024.emnlp-main.1151) |  | 0 | We revisit knowledge-aware text-based visual question answering, also known as Text-KVQA in the light of modern advancements in large multimodal models (LMMs), and make the following contributions: (i) We propose VisTEL – a principled approach to perform visual text entity linking. The proposed... | Abhirama Subramanyam Penamakuri, Anand Mishra |  |
| 1275 |  |  [Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics](https://doi.org/10.18653/v1/2024.emnlp-main.1152) |  | 0 | Machine Translation (MT) evaluation metrics assess translation quality automatically. Recently, researchers have employed MT metrics for various new use cases, such as data filtering and translation re-ranking. However, most MT metrics return assessments as scalar scores that are difficult to... | Stefano Perrella, Lorenzo Proietti, PereLluís Huguet Cabot, Edoardo Barba, Roberto Navigli |  |
| 1276 |  |  [IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning](https://doi.org/10.18653/v1/2024.emnlp-main.1153) |  | 0 | Recent advancements in image captioning have explored text-only training methods to overcome the limitations of paired image-text data. However, existing text-only training methods often overlook the modality gap between using text data during training and employing images during inference. To... | Soeun Lee, SiWoo Kim, Taewhan Kim, DongJin Kim |  |
| 1277 |  |  [Encoding Spreadsheets for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1154) |  | 0 | Spreadsheets are characterized by their extensive two-dimensional grids, flexible layouts, and varied formatting options, which pose significant challenges for large language models (LLMs). In response, we introduce SheetEncoder, pioneering an efficient encoding method designed to unleash and... | Haoyu Dong, Jianbo Zhao, Yuzhang Tian, Junyu Xiong, Mengyu Zhou, Yun Lin, José Cambronero, Yeye He, Shi Han, Dongmei Zhang |  |
| 1278 |  |  [Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment](https://doi.org/10.18653/v1/2024.emnlp-main.1155) |  | 0 | Research in the computational assessment of Argumentation Quality has gained popularity over the last ten years. Various quality dimensions have been explored through the creation of domain-specific datasets and assessment methods. We survey the related literature (211 publications and 32... | Rositsa V. Ivanova, Thomas Huber, Christina Niklaus |  |
| 1279 |  |  [Automatic sentence segmentation of clinical record narratives in real-world data](https://doi.org/10.18653/v1/2024.emnlp-main.1156) |  | 0 | Sentence segmentation is a linguistic task and is widely used as a pre-processing step in many NLP applications. The need for sentence segmentation is particularly pronounced in clinical notes, where ungrammatical and fragmented texts are common. We propose a straightforward and effective sequence... | Dongfang Xu, Davy Weissenbacher, Karen O'Connor, Siddharth Rawal, Graciela GonzalezHernandez |  |
| 1280 |  |  [One-to-Many Communication and Compositionality in Emergent Communication](https://doi.org/10.18653/v1/2024.emnlp-main.1157) |  | 0 | Compositional languages leverage rules that derive meaning from combinations of simpler constituents. This property is considered to be the hallmark of human language as it enables the ability to express novel concepts and ease of learning. As such, numerous studies in the emergent communication... | Heeyoung Lee |  |
| 1281 |  |  [Bayesian Example Selection Improves In-Context Learning for Speech, Text and Visual Modalities](https://doi.org/10.18653/v1/2024.emnlp-main.1158) |  | 0 | Large language models (LLMs) can adapt to new tasks through in-context learning (ICL) based on a few examples presented in dialogue history without any model parameter update. Despite such convenience, the performance of ICL heavily depends on the quality of the in-context examples presented, which... | Siyin Wang, ChaoHan Huck Yang, Ji Wu, Chao Zhang |  |
| 1282 |  |  [Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?](https://doi.org/10.18653/v1/2024.emnlp-main.1159) |  | 0 | The adaption of multilingual pre-trained LLMs into eloquent and helpful assistants is essential to facilitate their use across different language regions. In that spirit, we are the first to conduct an extensive study of the performance of multilingual models instruction-tuned on different language... | Alexander Arno Weber, Klaudia Thellmann, Jan Ebert, Nicolas FloresHerr, Jens Lehmann, Michael Fromm, Mehdi Ali |  |
| 1283 |  |  [Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1160) |  | 0 | As Large Language Models (LLMs) continue to exhibit remarkable performance in natural language understanding tasks, there is a crucial need to measure their ability for human-like multi-step logical reasoning. Existing logical reasoning evaluation benchmarks often focus primarily on simplistic... | Nisarg Patel, Mohith Kulkarni, Mihir Parmar, Aashna Budhiraja, Mutsumi Nakamura, Neeraj Varshney, Chitta Baral |  |
| 1284 |  |  [Linear Layer Extrapolation for Fine-Grained Emotion Classification](https://doi.org/10.18653/v1/2024.emnlp-main.1161) |  | 0 | Certain abilities of Transformer-based language models consistently emerge in their later layers. Previous research has leveraged this phenomenon to improve factual accuracy through self-contrast, penalizing early-exit predictions based on the premise that later-layer updates are more factually... | Mayukh Sharma, Sean O'Brien, Julian J. McAuley |  |
| 1285 |  |  [Task Oriented In-Domain Data Augmentation](https://doi.org/10.18653/v1/2024.emnlp-main.1162) |  | 0 | Large Language Models (LLMs) have shown superior performance in various applications and fields. To achieve better performance on specialized domains such as law and advertisement, LLMs are often continue pre-trained on in-domain data. However, existing approaches suffer from two major issues.... | Xiao Liang, Xinyu Hu, Simiao Zuo, Yeyun Gong, Qiang Lou, Yi Liu, ShaoLun Huang, Jian Jiao |  |
| 1286 |  |  [SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers](https://doi.org/10.18653/v1/2024.emnlp-main.1163) |  | 0 | Scientific literature is typically dense, requiring significant background knowledge and deep comprehension for effective engagement. We introduce SciDQA, a new dataset for reading comprehension that challenges language models to deeply understand scientific articles, consisting of 2,937 QA pairs.... | Shruti Singh, Nandan Sarkar, Arman Cohan |  |
| 1287 |  |  [Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules](https://doi.org/10.18653/v1/2024.emnlp-main.1164) |  | 0 | Is it always necessary to compute tokens from shallow to deep layers in Transformers? The continued success of vanilla Transformers and their variants suggests an undoubted “yes”. In this work, however, we attempt to break the depth-ordered convention by proposing a novel architecture dubbed... | Zhuocheng Gong, Ang Lv, Jian Guan, Wei Wu, Huishuai Zhang, Minlie Huang, Dongyan Zhao, Rui Yan |  |
| 1288 |  |  [No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages](https://doi.org/10.18653/v1/2024.emnlp-main.1165) |  | 0 | Research in vision and language has made considerable progress thanks to benchmarks such as COCO. COCO captions focused on unambiguous facts in English; ArtEmis introduced subjective emotions and ArtELingo introduced some multilinguality (Chinese and Arabic). However we believe there should be more... | Youssef Mohamed, Runjia Li, Ibrahim Said Ahmad, Kilichbek Haydarov, Philip Torr, Kenneth Church, Mohamed Elhoseiny |  |
| 1289 |  |  [PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection](https://doi.org/10.18653/v1/2024.emnlp-main.1166) |  | 0 | While a few public benchmarks have been proposed for training hate speech detection models, the differences in labeling criteria between these benchmarks pose challenges for generalized learning, limiting the applicability of the models. Previous research has presented methods to generalize models... | Someen Park, Jaehoon Kim, Seungwan Jin, Sohyun Park, Kyungsik Han |  |
| 1290 |  |  [TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR](https://doi.org/10.18653/v1/2024.emnlp-main.1167) |  | 0 | In traditional conversational intelligence from speech, a cascaded pipeline is used, involving tasks such as voice activity detection, diarization, transcription, and subsequent processing with different NLP models for tasks like semantic endpointing and named entity recognition (NER). Our paper... | Shashi Kumar, Srikanth R. Madikeri, Juan Pablo ZuluagaGomez, Iuliia Thorbecke, Esaú VillatoroTello, Sergio Burdisso, Petr Motlícek, Karthik S, Aravind Ganapathiraju |  |
| 1291 |  |  [ApiQ: Finetuning of 2-Bit Quantized Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.1168) |  | 0 | Memory-efficient finetuning of large language models (LLMs) has recently attracted huge attention with the increasing size of LLMs, primarily due to the constraints posed by GPU memory limitations and the effectiveness of these methods compared to full finetuning. Despite the advancements, current... | Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz |  |
| 1292 |  |  [Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk](https://doi.org/10.18653/v1/2024.emnlp-main.1169) |  | 0 | The evolution of Large Language Models (LLMs) has led to significant advancements, with models like Claude and Gemini capable of processing contexts up to 1 million tokens. However, efficiently handling long sequences remains challenging, particularly during the prefilling stage when input lengths... | Zhiyuan Zeng, Qipeng Guo, Xiaoran Liu, Zhangyue Yin, Wentao Shu, Mianqiu Huang, Bo Wang, Yunhua Zhou, Linlin Li, Qun Liu, Xipeng Qiu |  |
| 1293 |  |  [A Morphology-Based Investigation of Positional Encodings](https://doi.org/10.18653/v1/2024.emnlp-main.1170) |  | 0 | Contemporary deep learning models effectively handle languages with diverse morphology despite not being directly integrated into them. Morphology and word order are closely linked, with the latter incorporated into transformer-based models through positional encodings. This prompts a fundamental... | Poulami Ghosh, Shikhar Vashishth, Raj Dabre, Pushpak Bhattacharyya |  |
| 1294 |  |  [I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining](https://doi.org/10.18653/v1/2024.emnlp-main.1171) |  | 0 | Sentence transformers excel at grouping topically similar texts, but struggle to differentiate opposing viewpoints on the same topic. This shortcoming hinders their utility in applications where understanding nuanced differences in opinion is essential, such as those related to social and political... | Vahid Ghafouri, Jose Such, Guillermo SuarezTangil |  |
| 1295 |  |  [BiasWipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability](https://doi.org/10.18653/v1/2024.emnlp-main.1172) |  | 0 | Toxic content detection plays a vital role in addressing the misuse of social media platforms to harm people or groups due to their race, gender or ethnicity. However, due to the nature of the datasets, systems develop an unintended bias due to the over-generalization of the model to the training... | Mamta Mamta, Rishikant Chigrupaatii, Asif Ekbal |  |
| 1296 |  |  [ArMeme: Propagandistic Content in Arabic Memes](https://doi.org/10.18653/v1/2024.emnlp-main.1173) |  | 0 | With the rise of digital communication memes have become a significant medium for cultural and political expression that is often used to mislead audience. Identification of such misleading and persuasive multimodal content become more important among various stakeholders, including social media... | Firoj Alam, Abul Hasnat, Fatema Ahmad, Md. Arid Hasan, Maram Hasanain |  |
| 1297 |  |  [Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts](https://doi.org/10.18653/v1/2024.emnlp-main.1174) |  | 0 | We propose misogyny detection as an Argumentative Reasoning task and we investigate the capacity of large language models (LLMs) to understand the implicit reasoning used to convey misogyny in both Italian and English. The central aim is to generate the missing reasoning link between a message and... | Arianna Muti, Federico Ruggeri, Khalid AlKhatib, Alberto BarrónCedeño, Tommaso Caselli |  |
| 1298 |  |  [Thoughts to Target: Enhance Planning for Target-driven Conversation](https://doi.org/10.18653/v1/2024.emnlp-main.1175) |  | 0 | In conversational AI, large-scale models excel in various tasks but struggle with target-driven conversation planning. Current methods, such as chain-of-thought reasoning and tree-search policy learning techniques, either neglect plan rationality or require extensive human simulation procedures.... | Zhonghua Zheng, Lizi Liao, Yang Deng, EePeng Lim, Minlie Huang, Liqiang Nie |  |
| 1299 |  |  [Scalable Data Ablation Approximations for Language Models through Modular Training and Merging](https://doi.org/10.18653/v1/2024.emnlp-main.1176) |  | 0 | Training data compositions for Large Language Models (LLMs) can significantly affect their downstream performance. However, a thorough data ablation study exploring large sets of candidate data mixtures is typically prohibitively expensive since the full effect is seen only after training the... | Clara Na, Ian Magnusson, Ananya Harsh Jha, Tom Sherborne, Emma Strubell, Jesse Dodge, Pradeep Dasigi |  |
| 1300 |  |  [Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation](https://doi.org/10.18653/v1/2024.emnlp-main.1177) |  | 0 | Multilingual neural machine translation models support fine-tuning hundreds of languages simultaneously. However, fine-tuning on full parameters solely is inefficient potentially leading to negative interactions among languages. In this work, we demonstrate that the fine-tuning for a language... | Zhe Cao, Zhi Qu, Hidetaka Kamigaito, Taro Watanabe |  |
| 1301 |  |  [Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters](https://doi.org/10.18653/v1/2024.emnlp-main.1178) |  | 0 |  | Zhiyu Guo, Hidetaka Kamigaito, Taro Watanabe |  |
| 1302 |  |  [Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1179) |  | 0 | Knowledge graph–grounded dialog generation requires retrieving a dialog-relevant subgraph from the given knowledge base graph and integrating it with the dialog history. Previous works typically represent the graph using an external encoder, such as graph neural networks, and retrieve relevant... | Jinyoung Park, Minseok Joo, JooKyung Kim, Hyunwoo J. Kim |  |
| 1303 |  |  [Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers](https://doi.org/10.18653/v1/2024.emnlp-main.1180) |  | 0 | Existing works show that augmenting the training data of pre-trained language models (PLMs) for classification tasks fine-tuned via parameter-efficient fine-tuning methods (PEFT) using both clean and adversarial examples can enhance their robustness under adversarial attacks. However, this... | Tuc Nguyen, Thai Le |  |
| 1304 |  |  [Generalizing Clinical De-identification Models by Privacy-safe Data Augmentation using GPT-4](https://doi.org/10.18653/v1/2024.emnlp-main.1181) |  | 0 | De-identification (de-ID) refers to removing the association between a set of identifying data and the data subject. In clinical data management, the de-ID of Protected Health Information (PHI) is critical for patient confidentiality. However, state-of-the-art de-ID models show poor generalization... | Woojin Kim, Sungeun Hahm, Jaejin Lee |  |
| 1305 |  |  [Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game](https://doi.org/10.18653/v1/2024.emnlp-main.1182) |  | 0 | The New York Times Connections game has emerged as a popular and challenging pursuit for word puzzle enthusiasts. We collect438 Connections games to evaluate the performance of state-of-the-art large language models (LLMs) against expert and novice humanplayers. Our results show that even the... | Prisha Samadarshi, Mariam Mustafa, Anushka Kulkarni, Raven Rothkopf, Tuhin Chakrabarty, Smaranda Muresan |  |
| 1306 |  |  [GottBERT: a pure German Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.1183) |  | 0 | Pre-trained language models have significantly advanced natural language processing (NLP), especially with the introduction of BERT and its optimized version, RoBERTa. While initial research focused on English, single-language models can be advantageous compared to multilingual ones in terms of... | Raphael Scheible, Johann Frei, Fabian Thomczyk, Henry He, Patric Tippmann, Jochen Knaus, Victor Jaravine, Frank Kramer, Martin Boeker |  |
| 1307 |  |  [Computational Meme Understanding: A Survey](https://doi.org/10.18653/v1/2024.emnlp-main.1184) |  | 0 | Computational Meme Understanding, which concerns the automated comprehension of memes, has garnered interest over the last four years and is facing both substantial opportunities and challenges. We survey this emerging area of research by first introducing a comprehensive taxonomy for memes along... | Khoi P. N. Nguyen, Vincent Ng |  |
| 1308 |  |  [CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage](https://doi.org/10.18653/v1/2024.emnlp-main.1185) |  | 0 | In-context learning (ICL) adapts Large Language Models (LLMs) to new tasks, without requiring any parameter updates, but few annotated examples as input. In this work, we investigate selective annotation for ICL, where there is a limited budget for annotating examples, similar to low-budget active... | Costas Mavromatis, Balasubramaniam Srinivasan, Zhengyuan Shen, Jiani Zhang, Huzefa Rangwala, Christos Faloutsos, George Karypis |  |
| 1309 |  |  [Retrieval-enriched zero-shot image classification in low-resource domains](https://doi.org/10.18653/v1/2024.emnlp-main.1186) |  | 0 | Low-resource domains, characterized by scarce data and annotations, present significant challenges for language and visual understanding tasks, with the latter much under-explored in the literature. Recent advancements in Vision-Language Models (VLM) have shown promising results in high-resource... | Nicola Dall'Asen, Yiming Wang, Enrico Fini, Elisa Ricci |  |
| 1310 |  |  [I-AM-G: Interest Augmented Multimodal Generator for Item Personalization](https://doi.org/10.18653/v1/2024.emnlp-main.1187) |  | 0 | The emergence of personalized generation has made it possible to create texts or images that meet the unique needs of users. Recent advances mainly focus on style or scene transfer based on given keywords. However, in e-commerce and recommender systems, it is almost an untouched area to explore... | Xianquan Wang, Likang Wu, Shukang Yin, Zhi Li, Yanjiang Chen, Hufeng Hufeng, Yu Su, Qi Liu |  |
| 1311 |  |  [Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps](https://doi.org/10.18653/v1/2024.emnlp-main.1188) |  | 0 | Current automatic speech recognition (ASR) models are designed to be used across many languages and tasks without substantial changes. However, this broad language coverage hides performance gaps within languages, for example, across genders. Our study systematically evaluates the performance of... | Giuseppe Attanasio, Beatrice Savoldi, Dennis Fucci, Dirk Hovy |  |
| 1312 |  |  [Enhancing Language Model Alignment: A Confidence-Based Approach to Label Smoothing](https://doi.org/10.18653/v1/2024.emnlp-main.1189) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains. Within the training pipeline of LLMs, the Reinforcement Learning with Human Feedback (RLHF) phase is crucial for aligning LLMs with human preferences and values. Label smoothing, a... | Baihe Huang, Hiteshi Sharma, Yi Mao |  |
| 1313 |  |  [Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion](https://doi.org/10.18653/v1/2024.emnlp-main.1190) |  | 0 | Reinforcement Learning (RL) has been used to finetune Large Language Models (LLMs) using a reward model trained from preference data, to better align with human judgment. The recently introduced direct alignment methods, which are often simpler, more stable, and computationally lighter, can more... | Yannis FletBerliac, Nathan Grinsztajn, Florian Strub, Eugene Choi, Bill Wu, Chris Cremer, Arash Ahmadian, Yash Chandak, Mohammad Gheshlaghi Azar, Olivier Pietquin, Matthieu Geist |  |
| 1314 |  |  [Show and Guide: Instructional-Plan Grounded Vision and Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.1191) |  | 0 | Guiding users through complex procedural plans is an inherently multimodal task in which having visually illustrated plan steps is crucial to deliver an effective plan guidance. However, existing works on plan-following language models (LMs) often are not capable of multimodal input and output. In... | Diogo GlóriaSilva, David Semedo, João Magalhães |  |
| 1315 |  |  [Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents](https://doi.org/10.18653/v1/2024.emnlp-main.1192) |  | 0 | Despite broad interest in modeling spoken dialogue agents, most approaches are inherently “half-duplex” – restricted to turn-based interaction with responses requiring explicit prompting by the user or implicit tracking of interruption or silence events. Human dialogue, by contrast, is... | Bandhav Veluri, Benjamin N. Peloquin, Bokai Yu, Hongyu Gong, Shyamnath Gollakota |  |
| 1316 |  |  [QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.1193) |  | 0 | Despite advancements in Large Language Models (LLMs), many complex tasks are not easily solved in a single inference step, requiring the use of agentic LLMs in interactive environments. However, agentic LLMs suffer from a phenomenon known as reasoning derailment, due to the indiscriminate... | Minsoo Kim, Jongyoon Kim, Jihyuk Kim, Seungwon Hwang |  |
| 1317 |  |  [CompAct: Compressing Retrieved Documents Actively for Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1194) |  | 0 | Retrieval-augmented generation supports language models to strengthen their factual groundings by providing external contexts. However, language models often face challenges when given extensive information, diminishing their effectiveness in solving questions. Context compression tackles this... | Chanwoong Yoon, Taewhoo Lee, Hyeon Hwang, Minbyul Jeong, Jaewoo Kang |  |
| 1318 |  |  [An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models](https://doi.org/10.18653/v1/2024.emnlp-main.1195) |  | 0 | Large Multimodal Models (LMMs) have achieved strong performance across a range of vision and language tasks. However, their spatial reasoning capabilities are under-investigated. In this paper, we construct a novel VQA dataset, Spatial-MM, to comprehensively study LMMs’ spatial understanding and... | Fatemeh Shiri, XiaoYu Guo, Mona Far, Xin Yu, Reza Haf, YuanFang Li |  |
| 1319 |  |  [Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1196) |  | 0 | Large language models (LLMs) are proficient in capturing factual knowledge across various domains. However, refining their capabilities on previously seen knowledge or integrating new knowledge from external sources remains a significant challenge. In this work, we propose a novel synthetic... | Jiaxin Zhang, Wendi Cui, Yiran Huang, Kamalika Das, Kumar Sricharan |  |
| 1320 |  |  [Local Contrastive Editing of Gender Stereotypes](https://doi.org/10.18653/v1/2024.emnlp-main.1197) |  | 0 | Stereotypical bias encoded in language models (LMs) poses a threat to safe language technology, yet our understanding of how bias manifests in the parameters of LMs remains incomplete. We introduce local contrastive editing that enables the localization and editing of a subset of weights in a... | Marlene Lutz, Rochelle Choenni, Markus Strohmaier, Anne Lauscher |  |
| 1321 |  |  [De-Identification of Sensitive Personal Data in Datasets Derived from IIT-CDIP](https://doi.org/10.18653/v1/2024.emnlp-main.1198) |  | 0 | The IIT-CDIP document collection is the source of several widely used and publicly accessible document understanding datasets. In this paper, manual inspection of 5 datasets derived from IIT-CDIP uncovers the presence of thousands of instances of sensitive personal data, including US Social... | Stefan Larson, Nicole Lima, Santiago Diaz, Amogh Manoj Joshi, Siddharth Betala, Jamiu Suleiman, Yash Mathur, Kaushal Prajapati, Ramla Alakraa, Junjie Shen, Temi Okotore, Kevin Leach |  |
| 1322 |  |  [RAR: Retrieval-augmented retrieval for code generation in low resource languages](https://doi.org/10.18653/v1/2024.emnlp-main.1199) |  | 0 | Language models struggle in generating code for low-resource programming languages, since these are underrepresented in training data. Either examples or documentation are commonly used for improved code generation. We propose to use both types of information together and present retrieval... | Avik Dutta, Mukul Singh, Gust Verbruggen, Sumit Gulwani, Vu Le |  |
| 1323 |  |  [STAR: SocioTechnical Approach to Red Teaming Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1200) |  | 0 | This research introduces STAR, a sociotechnical framework that improves on current best practices for red teaming safety of large language models. STAR makes two key contributions: it enhances steerability by generating parameterised instructions for human red teamers, leading to improved coverage... | Laura Weidinger, John Mellor, Bernat Guillen Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, A. Stevie Bergman, Mikel Rodriguez, Verena Rieser, William Isaac |  |
| 1324 |  |  [Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA](https://doi.org/10.18653/v1/2024.emnlp-main.1201) |  | 0 | Recent advancements of large language models (LLMs)have led to claims of AI surpassing humansin natural language processing NLP tasks such as textual understanding and reasoning.%This work investigates these assertions by introducingCAIMIRA, a novel framework rooted in item response theory IRTthat... | Maharshi Gor, Hal Daumé III, Tianyi Zhou, Jordan L. BoydGraber |  |
| 1325 |  |  [Memory-Efficient Fine-Tuning of Transformers via Token Selection](https://doi.org/10.18653/v1/2024.emnlp-main.1202) |  | 0 | Fine-tuning provides an effective means to specialize pre-trained models for various downstream tasks. However, fine-tuning often incurs high memory overhead, especially for large transformer-based models, such as LLMs. While existing methods may reduce certain parts of the memory required for... | Antoine Simoulin, Namyong Park, Xiaoyi Liu, Grey Yang |  |
| 1326 |  |  [Unveiling the mystery of visual attributes of concrete and abstract concepts: Variability, nearest neighbors, and challenging categories](https://doi.org/10.18653/v1/2024.emnlp-main.1203) |  | 0 | The visual representation of a concept varies significantly depending on its meaning and the context where it occurs; this poses multiple challenges both for vision and multimodal models. Our study focuses on concreteness, a well-researched lexical-semantic variable, using it as a case study to... | Tarun Tater, Sabine Schulte im Walde, Diego Frassinelli |  |
| 1327 |  |  [Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark](https://doi.org/10.18653/v1/2024.emnlp-main.1204) |  | 0 | Large Language Models (LLMs) offer the potential for automatic time series analysis and reporting, which is a critical task across many domains, spanning healthcare, finance, climate, energy, and many more. In this paper, we propose a framework for rigorously evaluating the capabilities of LLMs on... | Elizabeth Fons, Rachneet Kaur, Soham Palande, Zhen Zeng, Tucker Balch, Manuela Veloso, Svitlana Vyetrenko |  |
| 1328 |  |  [Can LLMs Learn Uncertainty on Their Own? Expressing Uncertainty Effectively in A Self-Training Manner](https://doi.org/10.18653/v1/2024.emnlp-main.1205) |  | 0 | Large language models (LLMs) often exhibit excessive, random, and uninformative uncertainty, rendering them unsuitable for decision-making in human-computer interactions. In this paper, we aim to instigate a heightened awareness of self-uncertainty in LLMs, enabling them to express uncertainty more... | Shudong Liu, Zhaocong Li, Xuebo Liu, Runzhe Zhan, Derek F. Wong, Lidia S. Chao, Min Zhang |  |
| 1329 |  |  [Preference-Guided Reflective Sampling for Aligning Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1206) |  | 0 | Iterative data generation and model re-training can effectively align large language models (LLMs) to human preferences. The process of data sampling is crucial, as it significantly influences the success of policy improvement. Repeated random sampling is a widely used method that independently... | Hai Ye, Hwee Tou Ng |  |
| 1330 |  |  [Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP](https://doi.org/10.18653/v1/2024.emnlp-main.1207) |  | 0 | This paper introduces the concept of actionability in the context of bias measures in natural language processing (NLP). We define actionability as the degree to which a measure’s results enable informed action and propose a set of desiderata for assessing it. Building on existing frameworks such... | Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat |  |
| 1331 |  |  [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1208) |  | 0 | Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena. However, most recent work has used a more omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally... | Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, Maarten Sap |  |
| 1332 |  |  [A Simple LLM Framework for Long-Range Video Question-Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1209) |  | 0 | We present LLoVi, a simple yet effective \*\*L\*\*anguage-based \*\*Lo\*\*ng-range \*\*Vi\*\*deo question-answering (LVQA) framework. Our method decomposes the short- and long-range modeling aspects of LVQA into two stages. First, we use a short-term visual captioner to generate textual... | Ce Zhang, Taixi Lu, Md Mohaiminul Islam, Ziyang Wang, Shoubin Yu, Mohit Bansal, Gedas Bertasius |  |
| 1333 |  |  [Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing](https://doi.org/10.18653/v1/2024.emnlp-main.1210) |  | 0 | Recent work using Rank-One Model Editing (ROME), a popular model editing method, has shown that there are certain facts that the algorithm is unable to edit without breaking the model. Such edits have previously been called disabling edits. These disabling edits cause immediate model collapse and... | Akshat Gupta, Sidharth Baskaran, Gopala Anumanchipalli |  |
| 1334 |  |  [Casablanca: Data and Models for Multidialectal Arabic Speech Recognition](https://doi.org/10.18653/v1/2024.emnlp-main.1211) |  | 0 | In spite of the recent progress in speech processing, the majority of world languages and dialects remain uncovered. This situation only furthers an already wide technological divide, thereby hindering technological and socioeconomic inclusion. This challenge is largely due to the absence of... | Bashar Talafha, Karima Kadaoui, Samar Mohamed Magdy, Mariem Habiboullah, Chafei Mohamed Chafei, Ahmed Oumar ElShangiti, Hiba Zayed, Mohamedou Cheikh Tourad, Rahaf Alhamouri, Rwaa Assi, Aisha Alraeesi, Hour Mohamed, Fakhraddin Alwajih, Abdelrahman Mohamed, Abdellah El Mekki, El Moatez Billah Nagoudi, Benelhadj Saadia, Hamzah A. Alsayadi, Walid AlDhabyani, Sara Shatnawi, Yasir EchChammakhy, Amal Makouar, Yousra Berrachedi, Mustafa Jarrar, Shady Shehata, Ismail Berrada, Muhammad AbdulMageed |  |
| 1335 |  |  [Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations](https://doi.org/10.18653/v1/2024.emnlp-main.1212) |  | 0 | Ensuring the safe alignment of large language models (LLMs) with human values is critical as they become integral to applications like translation and question answering. Current alignment methods struggle with dynamic user intentions and complex objectives, making models vulnerable to generating... | Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria |  |
| 1336 |  |  [Communicating with Speakers and Listeners of Different Pragmatic Levels](https://doi.org/10.18653/v1/2024.emnlp-main.1213) |  | 0 | This paper explores the impact of variable pragmatic competence on communicative success through simulating language learning and conversing between speakers and listeners with different levels of reasoning abilities. Through studying this interaction, we hypothesize that matching levels of... | Kata Naszádi, Frans A. Oliehoek, Christof Monz |  |
| 1337 |  |  [RECANTFormer: Referring Expression Comprehension with Varying Numbers of Targets](https://doi.org/10.18653/v1/2024.emnlp-main.1214) |  | 0 | The Generalized Referring Expression Comprehension (GREC) task extends classic REC by generating image bounding boxes for objects referred to in natural language expressions, which may indicate zero, one, or multiple targets. This generalization enhances the practicality of REC models for diverse... | Bhathiya Hemanthage, Hakan Bilen, Phil Bartie, Christian Dondrup, Oliver Lemon |  |
| 1338 |  |  [Sprout: Green Generative AI with Carbon-Efficient LLM Inference](https://doi.org/10.18653/v1/2024.emnlp-main.1215) |  | 0 | The rapid advancement of generative AI has heightened environmental concerns, particularly regarding carbon emissions. Our framework, Sprout, addresses these challenges by reducing the carbon footprint of inference in large language models (LLMs). Sprout introduces “generation directives” to guide... | Baolin Li, Yankai Jiang, Vijay Gadepally, Devesh Tiwari |  |
| 1339 |  |  [Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs](https://doi.org/10.18653/v1/2024.emnlp-main.1216) |  | 0 | Journalists engage in multiple steps in the news writing process that depend on human creativity, like exploring different “angles” (i.e. the specific perspectives a reporter takes). These can potentially be aided by large language models (LLMs). By affecting planning decisions, such interventions... | Alexander Spangher, Nanyun Peng, Sebastian Gehrmann, Mark Dredze |  |
| 1340 |  |  [T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings](https://doi.org/10.18653/v1/2024.emnlp-main.1217) |  | 0 | Tokenizers are crucial for encoding information in Large Language Models, but their development has recently stagnated, and they contain inherent weaknesses. Major limitations include computational overhead, ineffective vocabulary use, and unnecessarily large embedding and head layers.... | Björn Deiseroth, Manuel Brack, Patrick Schramowski, Kristian Kersting, Samuel Weinbach |  |
| 1341 |  |  [SpeechQE: Estimating the Quality of Direct Speech Translation](https://doi.org/10.18653/v1/2024.emnlp-main.1218) |  | 0 | Recent advances in automatic quality estimation for machine translation have exclusively focused on written language, leaving the speech modality underexplored. In this work, we formulate the task of quality estimation for speech translation (SpeechQE), construct a benchmark, and evaluate a family... | HyoJung Han, Kevin Duh, Marine Carpuat |  |
| 1342 |  |  [Assessing and Verifying Task Utility in LLM-Powered Applications](https://doi.org/10.18653/v1/2024.emnlp-main.1219) |  | 0 | The rapid development of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents, assisting humans in their daily tasks. However, a significant gap remains in assessing to what extent LLM-powered applications genuinely enhance user... | Negar Arabzadeh, Siqing Huo, Nikhil Mehta, Qingyun Wu, Chi Wang, Ahmed Awadallah, Charles L. A. Clarke, Julia Kiseleva |  |
| 1343 |  |  [Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1220) |  | 0 | Aligning Large Language Models (LLMs) traditionally relies on complex and costly training processes like supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF). To address the challenge of achieving alignment without these extensive tuning costs and expensive... | Somanshu Singla, Zhen Wang, Tianyang Liu, Abdullah Ashfaq, Zhiting Hu, Eric P. Xing |  |
| 1344 |  |  [Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree](https://doi.org/10.18653/v1/2024.emnlp-main.1221) |  | 0 | When annotators disagree, predicting the labels given by individual annotators can capture nuances overlooked by traditional label aggregation. We introduce three approaches to predict individual annotator ratings on the toxicity of text by incorporating individual annotator-specific information: a... | Harbani Jaggi, Kashyap Coimbatore Murali, Eve Fleisig, Erdem Biyik |  |
| 1345 |  |  [Adversarial Text Generation using Large Language Models for Dementia Detection](https://doi.org/10.18653/v1/2024.emnlp-main.1222) |  | 0 | Although large language models (LLMs) excel in various text classification tasks, regular prompting strategies (e.g., few-shot prompting) do not work well with dementia detection via picture description. The challenge lies in the language marks for dementia are unclear, and LLM may struggle with... | Youxiang Zhu, Nana Lin, Kiran Balivada, Daniel Haehn, Xiaohui Liang |  |
| 1346 |  |  [xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics](https://doi.org/10.18653/v1/2024.emnlp-main.1223) |  | 0 | State-of-the-art trainable machine translation evaluation metrics like xCOMET achieve high correlation with human judgment but rely on large encoders (up to 10.7B parameters), making them computationally expensive and inaccessible to researchers with limited resources. To address this issue, we... | Daniil Larionov, Mikhail Seleznyov, Vasiliy Viskov, Alexander Panchenko, Steffen Eger |  |
| 1347 |  |  [The Greatest Good Benchmark: Measuring LLMs' Alignment with Utilitarian Moral Dilemmas](https://doi.org/10.18653/v1/2024.emnlp-main.1224) |  | 0 | The question of how to make decisions that maximise the well-being of all persons is very relevant to design language models that are beneficial to humanity and free from harm. We introduce the Greatest Good Benchmark to evaluate the moral judgments of LLMs using utilitarian dilemmas. Our analysis... | Giovanni Marraffini, Andrés Cotton, Noe Hsueh, Axel Fridman, Juan Wisznia, Luciano Del Corro |  |
| 1348 |  |  [FairFlow: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding](https://doi.org/10.18653/v1/2024.emnlp-main.1225) |  | 0 | Language models are prone to dataset biases, known as shortcuts and spurious correlations in data, which often result in performance drop on new data. We present a new debiasing framework called FairFlow that mitigates dataset biases by learning to be undecided in its predictions for data samples... | Jiali Cheng, Hadi Amiri |  |
| 1349 |  |  [Style-Shifting Behaviour of the Manosphere on Reddit](https://doi.org/10.18653/v1/2024.emnlp-main.1226) |  | 0 | Hate speech groups (HSGs) may negatively influence online platforms through their distinctive language, which may affect the tone and topics of other spaces if spread beyond the HSGs. We explore the linguistic style of the Manosphere, a misogynistic HSG, on Reddit. We find that Manospheric authors... | Jai Aggarwal, Suzanne Stevenson |  |
| 1350 |  |  [The Death and Life of Great Prompts: Analyzing the Evolution of LLM Prompts from the Structural Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.1227) |  | 0 | Effective utilization of large language models (LLMs), such as ChatGPT, relies on the quality of input prompts. This paper explores prompt engineering, specifically focusing on the disparity between experimentally designed prompts and real-world “in-the-wild” prompts. We analyze 10,538 in-the-wild... | Yihan Ma, Xinyue Shen, Yixin Wu, Boyang Zhang, Michael Backes, Yang Zhang |  |
| 1351 |  |  [Holistic Evaluation for Interleaved Text-and-Image Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1228) |  | 0 | Interleaved text-and-image generation has been an intriguing research direction, where the models are required to generate both images and text pieces in an arbitrary order. Despite the emerging advancements in interleaved generation, the progress in its evaluation still significantly lags behind.... | Minqian Liu, Zhiyang Xu, Zihao Lin, Trevor Ashby, Joy Rimchala, Jiaxin Zhang, Lifu Huang |  |
| 1352 |  |  [FOLIO: Natural Language Reasoning with First-Order Logic](https://doi.org/10.18653/v1/2024.emnlp-main.1229) |  | 0 | Large language models (LLMs) have achieved remarkable performance on a variety of natural language understanding tasks. However, existing benchmarks are inadequate in measuring the complex logical reasoning capabilities of a model. We present FOLIO, a human-annotated, logically complex and diverse... | Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alexander WardleSolano, Hannah Szabó, Ekaterina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander R. Fabbri, Wojciech Kryscinski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying, Arman Cohan, Dragomir Radev |  |
| 1353 |  |  [The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?](https://doi.org/10.18653/v1/2024.emnlp-main.1230) |  | 0 | Large Language Models (LLMs) have shown capabilities close to human performance in various analytical tasks, leading researchers to use them for time and labor-intensive analyses. However, their capability to handle highly specialized and open-ended tasks in domains like policy studies remains in... | Alexander S. Choi, Syeda Sabrina Akter, JP Singh, Antonios Anastasopoulos |  |
| 1354 |  |  [Is Child-Directed Speech Effective Training Data for Language Models?](https://doi.org/10.18653/v1/2024.emnlp-main.1231) |  | 0 | While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data. What are the features of the data they receive, and how do these features support language modeling objectives? To... | Steven Y. Feng, Noah D. Goodman, Michael Frank |  |
| 1355 |  |  [RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference](https://doi.org/10.18653/v1/2024.emnlp-main.1232) |  | 0 | Large language models (LLMs) have brought a great breakthrough to the natural language processing (NLP) community, while leading the challenge of handling concurrent customer queries due to their high throughput demands. Data multiplexing addresses this by merging multiple inputs into a single... | Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao |  |
| 1356 |  |  [Inference Helps PLMs' Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs](https://doi.org/10.18653/v1/2024.emnlp-main.1233) |  | 0 | The abstract inference capability of the Language Model plays a pivotal role in boosting its generalization and reasoning prowess in Natural Language Inference (NLI). Entailment graphs are crafted precisely for this purpose, focusing on learning entailment relations among predicates. Yet,... | Juncai Li, Ru Li, Xiaoli Li, Qinghua Chai, Jeff Z. Pan |  |
| 1357 |  |  [M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought](https://doi.org/10.18653/v1/2024.emnlp-main.1234) |  | 0 | In recent years, there has been a significant rise in the phenomenon of hate against women on social media platforms, particularly through the use of misogynous memes. These memes often target women with subtle and obscure cues, making their detection a challenging task for automated systems.... | Gitanjali Kumari, Kirtan Jain, Asif Ekbal |  |
| 1358 |  |  [GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation](https://doi.org/10.18653/v1/2024.emnlp-main.1235) |  | 0 | Research on jailbreaking has been valuable for testing and understanding the safety and security issues of large language models (LLMs). In this paper, we introduce Iterative Refinement Induced Self-Jailbreak (IRIS), a novel approach that leverages the reflective capabilities of LLMs for... | Govind Ramesh, Yao Dou, Wei Xu |  |
| 1359 |  |  [RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.emnlp-main.1236) |  | 0 | The Retrieval Augmented Generation (RAG) framework utilizes a combination of parametric knowledge and external knowledge to demonstrate state-of-the-art performance on open-domain question answering tasks. However, the RAG framework suffers from performance degradation when the query is accompanied... | Kiseung Kim, JayYoon Lee |  |
| 1360 |  |  [Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets](https://doi.org/10.18653/v1/2024.emnlp-main.1237) |  | 0 | Language models, characterized by their black-box nature, often hallucinate and display sensitivity to input perturbations, causing concerns about trust. To enhance trust, it is imperative to gain a comprehensive understanding of the model’s failure modes and develop effective strategies to improve... | Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth |  |
| 1361 |  |  [Simul-MuST-C: Simultaneous Multilingual Speech Translation Corpus Using Large Language Model](https://doi.org/10.18653/v1/2024.emnlp-main.1238) |  | 0 | Simultaneous Speech Translation (SiST) begins translating before the entire source input is received, making it crucial to balance quality and latency. In real interpreting situations, interpreters manage this simultaneity by breaking sentences into smaller segments and translating them while... | Mana Makinae, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |  |
| 1362 |  |  [Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text](https://doi.org/10.18653/v1/2024.emnlp-main.1239) |  | 0 | Understanding whether a generated table is of good quality is important to be able to use it in creating or editing documents using automatic methods. In this work, we underline that existing measures for table quality evaluation fail to capture the overall semantics of the tables, and sometimes... | Pritika Ramu, Aparna Garimella, Sambaran Bandyopadhyay |  |
| 1363 |  |  [On the Fragility of Active Learners for Text Classification](https://doi.org/10.18653/v1/2024.emnlp-main.1240) |  | 0 | Active learning (AL) techniques optimally utilize a labeling budget by iteratively selecting instances that are most valuable for learning. However, they lack “prerequisite checks”, i.e., there are no prescribed criteria to pick an AL algorithm best suited for a dataset. A practitioner must pick a... | Abhishek Ghose, Emma Nguyen |  |
| 1364 |  |  [BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers](https://doi.org/10.18653/v1/2024.emnlp-main.1241) |  | 0 | Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the lack of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing... | Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Yanqiao Zhu, May Dongmei Wang, Joyce C. Ho, Chao Zhang, Carl Yang |  |
| 1365 |  |  [Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.1242) |  | 0 | A common retrieve-and-rerank paradigm involves retrieving relevant candidates from a broad set using a fast bi-encoder (BE), followed by applying expensive but accurate cross-encoders (CE) to a limited candidate set. However, relying on this small subset is often susceptible to error propagation... | Jonghyun Song, Cheyon Jin, Wenlong Zhao, Andrew McCallum, JayYoon Lee |  |
| 1366 |  |  [M3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection](https://doi.org/10.18653/v1/2024.emnlp-main.1243) |  | 0 | Fact-checking claims is a highly laborious task that involves understanding how each factual assertion within the claim relates to a set of trusted source materials. Existing approaches make sample-level predictions but fail to identify the specific aspects of the claim that are troublesome and the... | ChiaWei Tang, TingChih Chen, Kiet Nguyen, Kazi Sajeed Mehrab, Alvi Md. Ishmam, Chris Thomas |  |
| 1367 |  |  [MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning](https://doi.org/10.18653/v1/2024.emnlp-main.1244) |  | 0 | Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and privacy concerns. In this study, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs... | Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Haotian Sun, Hang Wu, Carl Yang, May Dongmei Wang |  |
| 1368 |  |  [EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records](https://doi.org/10.18653/v1/2024.emnlp-main.1245) |  | 0 | Clinicians often rely on data engineers to retrieve complex patient information from electronic health record (EHR) systems, a process that is both inefficient and time-consuming. We propose EHRAgent, a large language model (LLM) agent empowered with accumulative domain knowledge and robust coding... | Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce C. Ho, Carl Yang, May Dongmei Wang |  |
| 1369 |  |  [SimLLM: Detecting Sentences Generated by Large Language Models Using Similarity between the Generation and its Re-generation](https://doi.org/10.18653/v1/2024.emnlp-main.1246) |  | 0 | Large language models have emerged as a significant phenomenon due to their ability to produce natural text across various applications. However, the proliferation of generated text raises concerns regarding its potential misuse in fraudulent activities such as academic dishonesty, spam... | HoangQuoc NguyenSon, MinhSon Dao, Koji Zettsu |  |
| 1370 |  |  [CELLO: Causal Evaluation of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1247) |  | 0 | Causal reasoning is fundamental to human intelligence and crucial for effective decision-making in real-world environments. Despite recent advancements in large vision-language models (LVLMs), their ability to comprehend causality remains unclear. Previous work typically focuses on commonsense... | Meiqi Chen, Bo Peng, Yan Zhang, Chaochao Lu |  |
| 1371 |  |  [Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair](https://doi.org/10.18653/v1/2024.emnlp-main.1248) |  | 0 | In Simultaneous Machine Translation (SiMT), training with a simultaneous interpretation (SI) corpus is an effective method for achieving high-quality yet low-latency. However, constructing such a corpus is challenging due to high costs, and limitations in annotator capabilities, and as a result,... | Yusuke Sakai, Mana Makinae, Hidetaka Kamigaito, Taro Watanabe |  |
| 1372 |  |  [Training-free Deep Concept Injection Enables Language Models for Video Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1249) |  | 0 | Recently, enabling pretrained language models (PLMs) to perform zero-shot crossmodal tasks such as video question answering has been extensively studied. A popular approach is to learn a projection network that projects visual features into the input text embedding space of a PLM, as well as... | Xudong Lin, Manling Li, Richard S. Zemel, Heng Ji, ShihFu Chang |  |
| 1373 |  |  [MIBench: Evaluating Multimodal Large Language Models over Multiple Images](https://doi.org/10.18653/v1/2024.emnlp-main.1250) |  | 0 | Built on the power of LLMs, numerous multimodal large language models (MLLMs) have recently achieved remarkable performance on various vision-language tasks. However, most existing MLLMs and benchmarks primarily focus on single-image input scenarios, leaving the performance of MLLMs when handling... | Haowei Liu, Xi Zhang, Haiyang Xu, Yaya Shi, Chaoya Jiang, Ming Yan, Ji Zhang, Fei Huang, Chunfeng Yuan, Bing Li, Weiming Hu |  |
| 1374 |  |  [ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1251) |  | 0 | Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have equipped LLMs with mechanisms for knowledge retrieval, reasoning and... | Francesco Molfese, Simone Conia, Riccardo Orlando, Roberto Navigli |  |
| 1375 |  |  [ABLE: Personalized Disability Support with Politeness and Empathy Integration](https://doi.org/10.18653/v1/2024.emnlp-main.1252) |  | 0 | In today’s dynamic world, providing inclusive and personalized support for individuals with physical disabilities is imperative. With diverse needs and preferences, tailored assistance according to user personas is crucial. In this paper, we introduce ABLE (Adaptive, Bespoke, Listen and... | Kshitij Mishra, Manisha Burja, Asif Ekbal |  |
| 1376 |  |  [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1253) |  | 0 | Algorithmic reasoning tasks that involve complex logical patterns, such as completing Dyck language, pose challenges for large language models (LLMs), despite their recent success. Prior work has used LLMs to generate programming language and applied external compilers for such tasks. Yet, when on... | Hyungjoo Chae, Yeonghyeon Kim, Seungone Kim, Kai Tzuiunn Ong, Beongwoo Kwak, Moohyeon Kim, Sunghwan Kim, Taeyoon Kwon, Jiwan Chung, Youngjae Yu, Jinyoung Yeo |  |
| 1377 |  |  [Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code](https://doi.org/10.18653/v1/2024.emnlp-main.1254) |  | 0 | This paper presents Coffee-Gym, a comprehensive RL environment for training models that provide feedback on code editing. Coffee-Gym includes two major components: (1) Coffee, a dataset containing humans’ code edit traces for coding questions and human-written feedback for editing erroneous code;... | Hyungjoo Chae, Taeyoon Kwon, Seungjun Moon, Yongho Song, Dongjin Kang, Kai Tzuiunn Ong, Beongwoo Kwak, Seonghyeon Bae, Seungwon Hwang, Jinyoung Yeo |  |
| 1378 |  |  [Improving Minimum Bayes Risk Decoding with Multi-Prompt](https://doi.org/10.18653/v1/2024.emnlp-main.1255) |  | 0 | While instruction fine-tuned LLMs are effective text generators, sensitivity to prompt construction makes performance unstable and sub-optimal in practice. Relying on a single ‘best’ prompt cannot capture all differing approaches to a generation problem. Using this observation, we propose... | David Heineman, Yao Dou, Wei Xu |  |
| 1379 |  |  [Deciphering Cognitive Distortions in Patient-Doctor Mental Health Conversations: A Multimodal LLM-Based Detection and Reasoning Framework](https://doi.org/10.18653/v1/2024.emnlp-main.1256) |  | 0 | Cognitive distortion research holds increasing significance as it sheds light on pervasive errors in thinking patterns, providing crucial insights into mental health challenges and fostering the development of targeted interventions and therapies. This paper delves into the complex domain of... | Gopendra Vikram Singh, Sai Vemulapalli, Mauajama Firdaus, Asif Ekbal |  |
| 1380 |  |  [Nearest Neighbor Normalization Improves Multimodal Retrieval](https://doi.org/10.18653/v1/2024.emnlp-main.1257) |  | 0 | Multimodal models leverage large-scale pretraining to achieve strong but still imperfect performance on tasks such as image captioning, visual question answering, and cross-modal retrieval. In this paper, we present a simple and efficient method for correcting errors in trained contrastive... | Neil Chowdhury, Franklin Wang, Sumedh Shenoy, Douwe Kiela, Sarah Schwettmann, Tristan Thrush |  |
| 1381 |  |  [Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning](https://doi.org/10.18653/v1/2024.emnlp-main.1258) |  | 0 | This study addresses the challenges of assessing and enhancing social-pragmatic inference in large language models (LLMs). We first highlight the inadequacy of current accuracy-based multiple choice question answering (MCQA) formats in assessing social-pragmatic reasoning, and propose the direct... | Shengguang Wu, Shusheng Yang, Zhenglun Chen, Qi Su |  |
| 1382 |  |  [LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering](https://doi.org/10.18653/v1/2024.emnlp-main.1259) |  | 0 | Long-Context Question Answering (LCQA), a challenging task, aims to reason over long-context documents to yield accurate answers to questions. Existing long-context Large Language Models (LLMs) for LCQA often struggle with the “lost in the middle” issue. Retrieval-Augmented Generation (RAG)... | Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang |  |
| 1383 |  |  [Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.1260) |  | 0 | Watermarking enables people to determine whether the text is generated by a specific model. It injects a unique signature based on the “green-red” list that can be tracked during detection, where the words in green lists are encouraged to be generated. Recent researchers propose to fix the... | Yuxuan Guo, Zhiliang Tian, Yiping Song, Tianlun Liu, Liang Ding, Dongsheng Li |  |
| 1384 |  |  [Knowledge Graph Enhanced Large Language Model Editing](https://doi.org/10.18653/v1/2024.emnlp-main.1261) |  | 0 | Large language models (LLMs) are pivotal in advancing natural language processing (NLP) tasks, yet their efficacy is hampered by inaccuracies and outdated knowledge. Model editing emerges as a promising solution to address these challenges. However, existing editing methods struggle to track and... | Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen |  |
| 1385 |  |  ['Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews](https://doi.org/10.18653/v1/2024.emnlp-main.1262) |  | 0 | The integrity of the peer-review process is vital for maintaining scientific rigor and trust within the academic community. With the steady increase in the usage of large language models (LLMs) like ChatGPT in academic writing, there is a growing concern that AI-generated texts could compromise the... | Sandeep Kumar, Mohit Sahu, Vardhan Gacche, Tirthankar Ghosal, Asif Ekbal |  |
| 1386 |  |  [Mitigating Open-Vocabulary Caption Hallucinations](https://doi.org/10.18653/v1/2024.emnlp-main.1263) |  | 0 | While recent years have seen rapid progress in image-conditioned text generation, image captioning still suffers from the fundamental issue of hallucinations, namely, the generation of spurious details that cannot be inferred from the given image. Existing methods largely use closed-vocabulary... | Assaf BenKish, Moran Yanuka, Morris Alper, Raja Giryes, Hadar AverbuchElor |  |
| 1387 |  |  [Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes](https://doi.org/10.18653/v1/2024.emnlp-main.1264) |  | 0 | Loss spikes, a phenomenon in which the loss value diverges suddenly, is a fundamental issue in the pre-training of large language models. This paper supposes that the non-uniformity of the norm of the parameters is one of the causes of loss spikes. Here, in training of neural networks, the scale of... | Kosuke Nishida, Kyosuke Nishida, Kuniko Saito |  |
| 1388 |  |  [ALVIN: Active Learning Via INterpolation](https://doi.org/10.18653/v1/2024.emnlp-main.1265) |  | 0 | Active Learning aims to minimize annotation effort by selecting the most useful instances from a pool of unlabeled data. However, typical active learning methods overlook the presence of distinct example groups within a class, whose prevalence may vary, e.g., in occupation classification datasets... | Michalis Korakakis, Andreas Vlachos, Adrian Weller |  |
| 1389 |  |  [Filtered Direct Preference Optimization](https://doi.org/10.18653/v1/2024.emnlp-main.1266) |  | 0 | Reinforcement learning from human feedback (RLHF) plays a crucial role in aligning language models with human preferences. While the significance of dataset quality is generally recognized, explicit investigations into its impact within the RLHF framework, to our knowledge, have been limited. This... | Tetsuro Morimura, Mitsuki Sakamoto, Yuu Jinnai, Kenshi Abe, Kaito Ariu |  |
| 1390 |  |  [Instruction Fine-Tuning: Does Prompt Loss Matter?](https://doi.org/10.18653/v1/2024.emnlp-main.1267) |  | 0 | We present a novel study analyzing the effects of various prompt loss token weights (PLW) for supervised instruction fine-tuning (SIFT). While prompt-masking (PLW = 0) is common for SIFT, some fine-tuning APIs support fractional PLWs and suggest that using a small non-zero PLW can help stabilize... | Mathew HuertaEnochian, Seung Ko |  |
| 1391 |  |  [Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia](https://doi.org/10.18653/v1/2024.emnlp-main.1268) |  | 0 | Links are a fundamental part of information networks, turning isolated pieces of knowledge into a network of information that is much richer than the sum of its parts. However, adding a new link to the network is not trivial: it requires not only the identification of a suitable pair of source and... | Tomás Feith, Akhil Arora, Martin Gerlach, Debjit Paul, Robert West |  |
| 1392 |  |  [Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024](https://aclanthology.org/volumes/2024.findings-emnlp/) |  | 0 |  | Yaser AlOnaizan, Mohit Bansal, YunNung Chen |  |
| 1393 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.findings-emnlp.0) |  | 0 |  |  |  |
| 1394 |  |  [Are LLMs Good Annotators for Discourse-level Event Relation Extraction?](https://doi.org/10.18653/v1/2024.findings-emnlp.1) |  | 0 | Large Language Models (LLMs) have demonstrated proficiency in a wide array of natural language processing tasks. However, its effectiveness over discourse-level event relation extraction (ERE) tasks remains unexplored. In this paper, we assess the effectiveness of LLMs in addressing discourse-level... | Kangda Wei, Aayush Gautam, Ruihong Huang |  |
| 1395 |  |  [Transferability of Syntax-Aware Graph Neural Networks in Zero-Shot Cross-Lingual Semantic Role Labeling](https://doi.org/10.18653/v1/2024.findings-emnlp.2) |  | 0 | Recent models in cross-lingual semantic role labeling (SRL) barely analyze the applicability of their network selection.We believe that network selection is important since it affects the transferability of cross-lingual models, i.e., how the model can extract universal features from source... | Rachel Devianti, Yusuke Miyao |  |
| 1396 |  |  [Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing](https://doi.org/10.18653/v1/2024.findings-emnlp.3) |  | 0 | Cross-lingual AMR parsing is the task of predicting AMR graphs in a target language when training data is available only in a source language. Due to the small size of AMR training data and evaluation data, cross-lingual AMR parsing has only been explored in a small set of languages such as... | Jeongwoo Kang, Maximin Coavoux, Cédric Lopez, Didier Schwab |  |
| 1397 |  |  [General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.4) |  | 0 | Recently, unified information extraction has garnered widespread attention from the NLP community, which aims to use a unified paradigm to perform various information extraction tasks. However, prevalent unified IE approaches inevitably encounter challenges such as noise interference, abstract... | Kunlong Bao, Ning Wang |  |
| 1398 |  |  [SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement](https://doi.org/10.18653/v1/2024.findings-emnlp.5) |  | 0 | Conditional Semantic Textual Similarity (C-STS) introduces specific limiting conditions to the traditional Semantic Textual Similarity (STS) task, posing challenges for STS models. Language models employing cross-encoding demonstrate satisfactory performance in STS, yet their effectiveness... | Baixuan Li, Yunlong Fan, Zhiqiang Gao |  |
| 1399 |  |  [Search if you don't know! Knowledge-Augmented Korean Grammatical Error Correction with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.6) |  | 0 | Grammatical error correction (GEC) system is a practical task used in the real world, showing high achievements alongside the development of large language models (LLMs). However, these achievements have been primarily obtained in English, and there is a relative lack of performance for non-English... | Seonmin Koo, Jinsung Kim, Chanjun Park, Heuiseok Lim |  |
| 1400 |  |  [Measuring the Robustness of NLP Models to Domain Shifts](https://doi.org/10.18653/v1/2024.findings-emnlp.7) |  | 0 | Existing research on Domain Robustness (DR) suffers from disparate setups, limited task variety, and scarce research on recent capabilities such as in-context learning. Furthermore, the common practice of measuring DR might not be fully accurate. Current research focuses on challenge sets and... | Nitay Calderon, Naveh Porat, Eyal BenDavid, Alexander Chapanin, Zorik Gekhman, Nadav Oved, Vitaly Shalumov, Roi Reichart |  |
| 1401 |  |  [Text2Model: Text-based Model Induction for Zero-shot Image Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.8) |  | 0 | We address the challenge of building task-agnostic classifiers using only text descriptions, demonstrating a unified approach to image classification, 3D point cloud classification, and action recognition from scenes. Unlike approaches that learn a fixed representation of the output classes, we... | Ohad Amosy, Tomer Volk, Eilam Shapira, Eyal BenDavid, Roi Reichart, Gal Chechik |  |
| 1402 |  |  [InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem](https://doi.org/10.18653/v1/2024.findings-emnlp.9) |  | 0 | The integration of sentences poses an intriguing challenge within the realm of NLP, but it has not garnered the attention it deserves. Existing methods that focus on sentence arrangement, textual consistency, and question answering have been shown to be inadequate in addressing this issue. To... | Fang Wu, Stan Z. Li |  |
| 1403 |  |  [Unleashing Large Language Models' Proficiency in Zero-shot Essay Scoring](https://doi.org/10.18653/v1/2024.findings-emnlp.10) |  | 0 | Advances in automated essay scoring (AES) have traditionally relied on labeled essays, requiring tremendous cost and expertise for their acquisition. Recently, large language models (LLMs) have achieved great success in various tasks, but their potential is less explored in AES. In this paper, we... | Sanwoo Lee, Yida Cai, Desong Meng, Ziyang Wang, Yunfang Wu |  |
| 1404 |  |  [DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?](https://doi.org/10.18653/v1/2024.findings-emnlp.11) |  | 0 | Detecting evidence within the context is a key step in the process of reasoning task. Evaluating and enhancing the capabilities of LLMs in evidence detection will strengthen context-based reasoning performance. This paper proposes a benchmark called DetectBench for verifying the ability to detect... | Zhouhong Gu, Lin Zhang, Xiaoxuan Zhu, Jiangjie Chen, Wenhao Huang, Yikai Zhang, Shusen Wang, Zheyu Ye, Yan Gao, Hongwei Feng, Yanghua Xiao |  |
| 1405 |  |  [Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.12) |  | 0 | Meta-learning has emerged as a prominent technology for few-shot text classification and has achieved promising performance. However, existing methods often encounter difficulties in drawing accurate class prototypes from support set samples, primarily due to probable large intra-class differences... | Xinyue Liu, Yunlong Gao, Linlin Zong, Bo Xu |  |
| 1406 |  |  [CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity](https://doi.org/10.18653/v1/2024.findings-emnlp.13) |  | 0 | State-of-the-art performance in QA tasks is currently achieved by systems employing Large Language Models (LLMs), however these models tend to hallucinate information in their responses. One approach focuses on enhancing the generation process by incorporating attribution from the given input to... | Moshe Berchansky, Daniel Fleischer, Moshe Wasserblat, Peter Izsak |  |
| 1407 |  |  [SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM](https://doi.org/10.18653/v1/2024.findings-emnlp.14) |  | 0 | Vision-extended LLMs have made significant strides in Visual Question Answering (VQA). Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses. In this work, we... | Jielin Qiu, Andrea Madotto, Zhaojiang Lin, Paul A. Crook, Yifan Ethan Xu, Babak Damavandi, Xin Dong, Christos Faloutsos, Lei Li, Seungwhan Moon |  |
| 1408 |  |  [SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent](https://doi.org/10.18653/v1/2024.findings-emnlp.15) |  | 0 | Public scarce resource allocation plays a crucial role in economics as it directly influences the efficiency and equity in society. Traditional studies including theoretical model-based, empirical study-based and simulation-based methods encounter limitations due to the idealized assumption of... | Jiarui Ji, Yang Li, Hongtao Liu, Zhicheng Du, Zhewei Wei, Qi Qi, Weiran Shen, Yankai Lin |  |
| 1409 |  |  [Ukrainian Resilience: A Dataset for Detection of Help-Seeking Signals Amidst the Chaos of War](https://doi.org/10.18653/v1/2024.findings-emnlp.16) |  | 0 | We propose a novel dataset “Ukrainian Resilience” that brings together a collection of social media posts in the Ukrainian language for the detection of help-seeking posts in the Russia-Ukraine war. It is designed to help us analyze and categorize subtle signals in these posts that indicate people... | MSVPJ Sathvik, Abhilash Dowpati, Srreyansh Sethi |  |
| 1410 |  |  [Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model](https://doi.org/10.18653/v1/2024.findings-emnlp.17) |  | 0 | To obtain high-quality annotations under limited budget, semi-automatic annotation methods are commonly used, where a portion of the data is annotated by experts and a model is then trained to complete the annotations for the remaining data. However, these methods mainly focus on selecting... | Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Ido Dagan |  |
| 1411 |  |  [Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model](https://doi.org/10.18653/v1/2024.findings-emnlp.18) |  | 0 | Document hashing plays a crucial role in large-scale information retrieval. However, existing unsupervised document hashing methods merely consider flat semantics of documents, resulting in the inability of preserving hierarchical semantics in hash codes. In this paper, we propose a hierarchical... | Qian Zhang, Qinliang Su, Jiayang Chen, Zhenpeng Song |  |
| 1412 |  |  [Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction](https://doi.org/10.18653/v1/2024.findings-emnlp.19) |  | 0 | Knowledge graph embedding (KGE) models are often used to predict missing links for knowledge graphs (KGs). However, multiple KG embeddings can perform almost equally well for link prediction yet give conflicting predictions for unseen queries. This phenomenon is termed predictive multiplicity in... | Yuqicheng Zhu, Nico Potyka, Mojtaba Nayyeri, Bo Xiong, Yunjie He, Evgeny Kharlamov, Steffen Staab |  |
| 1413 |  |  [Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-emnlp.20) |  | 0 | Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs.... | Zifeng Ding, Jingcheng Wu, Jingpei Wu, Yan Xia, Bo Xiong, Volker Tresp |  |
| 1414 |  |  [GREEN: Generative Radiology Report Evaluation and Error Notation](https://doi.org/10.18653/v1/2024.findings-emnlp.21) |  | 0 | Evaluating radiology reports is a challenging problem as factual correctness is extremely important due to its medical nature. Existing automatic evaluation metrics either suffer from failing to consider factual correctness (e.g., BLEU and ROUGE) or are limited in their interpretability (e.g.,... | Sophie Ostmeier, Justin Xu, Zhihong Chen, Maya Varma, Louis Blankemeier, Christian Bluethgen, Arne Edward Michalson, Michael E. Moseley, Curtis P. Langlotz, Akshay Chaudhari, JeanBenoit Delbrouck |  |
| 1415 |  |  [XRec: Large Language Models for Explainable Recommendation](https://doi.org/10.18653/v1/2024.findings-emnlp.22) |  | 0 | Recommender systems help users navigate information overload by providing personalized recommendations aligned with their preferences. Collaborative Filtering (CF) is a widely adopted approach, but while advanced techniques like graph neural networks (GNNs) and self-supervised learning (SSL) have... | Qiyao Ma, Xubin Ren, Chao Huang |  |
| 1416 |  |  [LLM Questionnaire Completion for Automatic Psychiatric Assessment](https://doi.org/10.18653/v1/2024.findings-emnlp.23) |  | 0 | We employ a Large Language Model (LLM) to convert unstructured psychological interviews into structured questionnaires spanning various psychiatric and personality domains. The LLM is prompted to answer these questionnaires by impersonating the interviewee. The obtained answers are coded as... | Gony Rosenman, Talma Hendler, Lior Wolf |  |
| 1417 |  |  [Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts](https://doi.org/10.18653/v1/2024.findings-emnlp.24) |  | 0 | Aspect-based summarization has seen significant advancements, especially in structured text. Yet, summarizing disordered, large-scale texts, like those found in social media and customer feedback, remains a significant challenge. Current research largely targets predefined aspects within structured... | Xiaobo Guo, Soroush Vosoughi |  |
| 1418 |  |  [Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets](https://doi.org/10.18653/v1/2024.findings-emnlp.25) |  | 0 | Large language models (LLMs) have received a lot of attention in natural language processing (NLP) research because of their exceptional performance in understanding and generating human languages. However, low-resource languages are left behind due to the unavailability of resources. In this work,... | Israel Abebe Azime, Atnafu Lambebo Tonja, Tadesse Destaw Belay, Mitiku Yohannes Fuge, Aman Kassahun Wassie, Eyasu Shiferaw Jada, Yonas Chanie, Walelign Tewabe Sewunetie, Seid Muhie Yimam |  |
| 1419 |  |  [Can Large Language Models Identify Authorship?](https://doi.org/10.18653/v1/2024.findings-emnlp.26) |  | 0 | The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis remains under-explored.... | Baixiang Huang, Canyu Chen, Kai Shu |  |
| 1420 |  |  [TransLLaMa: LLM-based Simultaneous Translation System](https://doi.org/10.18653/v1/2024.findings-emnlp.27) |  | 0 | Decoder-only large language models (LLMs) have recently demonstrated impressive capabilities in text generation and reasoning. Nonetheless, they have limited applications in simultaneous machine translation (SiMT), currently dominated by encoder-decoder transformers. This study demonstrates that,... | Roman Koshkin, Katsuhito Sudoh, Satoshi Nakamura |  |
| 1421 |  |  [Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings](https://doi.org/10.18653/v1/2024.findings-emnlp.28) |  | 0 | Word embedding is one of the most important components in natural language processing, but interpreting high-dimensional embeddings remains a challenging problem. To address this problem, Independent Component Analysis (ICA) is identified as an effective solution. ICA-transformed word embeddings... | Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira |  |
| 1422 |  |  [Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation](https://doi.org/10.18653/v1/2024.findings-emnlp.29) |  | 0 | Applying differential privacy (DP) by means of the DP-SGD algorithm to protect individual data points during training is becoming increasingly popular in NLP. However, the choice of granularity at which DP is applied is often neglected. For example, neural machine translation (NMT) typically... | Doan Nam Long Vu, Timour Igamberdiev, Ivan Habernal |  |
| 1423 |  |  [An Open-Source Data Contamination Report for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.30) |  | 0 | Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to “cheat” via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model... | Yucheng Li, Yunhao Guo, Frank Guerin, Chenghua Lin |  |
| 1424 |  |  [Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering](https://doi.org/10.18653/v1/2024.findings-emnlp.31) |  | 0 | In this paper, we propose a modified version of the MedQA-USMLE dataset, named MEDQA-OPEN, which contains open-ended medical questions without options to mimic clinical scenarios, along with clinician-approved reasoned answers. Additionally, we implement a prompt driven by Chain of Thought (CoT)... | Saeel Sandeep Nachane, Ojas Gramopadhye, Prateek Chanda, Ganesh Ramakrishnan, Kshitij Sharad Jadhav, Yatin Nandwani, Dinesh Raghu, Sachindra Joshi |  |
| 1425 |  |  [Reformatted Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.32) |  | 0 | The quality of finetuning data is crucial for aligning large language models (LLMs) with human values. Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations. This paper explores elevating the quality of existing instruction data... | RunZe Fan, Xuefeng Li, Haoyang Zou, Junlong Li, Shwai He, Ethan Chern, Jiewen Hu, Pengfei Liu |  |
| 1426 |  |  [Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts](https://doi.org/10.18653/v1/2024.findings-emnlp.33) |  | 0 | Adapting keyphrase generation models to new domains typically involves few-shot fine-tuning with in-domain labeled data. However, annotating documents with keyphrases is often prohibitively expensive and impractical, requiring expert annotators. This paper presents silk, an unsupervised method... | Florian Boudin, Akiko Aizawa |  |
| 1427 |  |  [SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support](https://doi.org/10.18653/v1/2024.findings-emnlp.34) |  | 0 | Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations that could facilitate advancements in mental health support... | Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, Zhenzhong Lan |  |
| 1428 |  |  [DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.35) |  | 0 | Event extraction aims to identify events and then extract the arguments involved in those events. In recent years, there has been a gradual shift from sentence-level event extraction to document-level event extraction research. Despite the significant success achieved in English domain event... | Minghui Liu, Meihan Tong, Yangda Peng, Lei Hou, Juanzi Li, Bin Xu |  |
| 1429 |  |  [MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language](https://doi.org/10.18653/v1/2024.findings-emnlp.36) |  | 0 |  | Soon Chang Poh, Sze Jue Yang, Jeraelyn Tan, Lawrence Chieng, Jia Huei Tan, Zhenyu Yu, Foong Mun, Chee Seng Chan |  |
| 1430 |  |  [Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.37) |  | 0 | In many modern LLM applications, such as retrieval augmented generation, prompts have become programs themselves. In these settings, prompt programs are repeatedly called with different user queries or data instances. A big practical challenge is optimizing such prompt programs. Recent work has... | Tobias Schnabel, Jennifer Neville |  |
| 1431 |  |  [Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.38) |  | 0 | Parameter-efficient fine-tuning (PEFT) methods are increasingly used with pre-trained language models (PLMs) for continual learning (CL). These methods typically involve training a PEFT module for each new task and employing similarity-based selection to route modules during inference. However,... | Vladimir Araujo, MarieFrancine Moens, Tinne Tuytelaars |  |
| 1432 |  |  [LLM-supertagger: Categorial Grammar Supertagging via Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.39) |  | 0 | Supertagging is an essential task in Categorical grammar parsing and is crucial for dissecting sentence structures. Our research explores the capacity of Large Language Models (LLMs) in supertagging for both Combinatory Categorial Grammar (CCG) and Lambek Categorial Grammar (LCG). We also present a... | Jinman Zhao, Gerald Penn |  |
| 1433 |  |  [Editing Conceptual Knowledge for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.40) |  | 0 | Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of... | Xiaohan Wang, Shengyu Mao, Shumin Deng, Yunzhi Yao, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang |  |
| 1434 |  |  [RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.41) |  | 0 | Retrieval-Augmented Generation (RAG) has proven to be an effective paradigm for enhancing the quality of text generation by integrating large language models (LLMs) with external knowledge. However, an off-the-shelf RAG system, which relies on generally pre-trained LLMs and retrievers, often falls... | Kelong Mao, Zheng Liu, Hongjin Qian, Fengran Mo, Chenlong Deng, Zhicheng Dou |  |
| 1435 |  |  [MMCode: Benchmarking Multimodal Large Language Models for Code Generation with Visually Rich Programming Problems](https://doi.org/10.18653/v1/2024.findings-emnlp.42) |  | 0 | Programming often involves converting detailed and complex specifications into code, a process during which developers typically utilize visual aids to more effectively convey concepts. While recent developments in Large Multimodal Models have demonstrated remarkable abilities in visual reasoning... | Kaixin Li, Yuchen Tian, Qisheng Hu, Ziyang Luo, Zhiyong Huang, Jing Ma |  |
| 1436 |  |  [Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction](https://doi.org/10.18653/v1/2024.findings-emnlp.43) |  | 0 | Legal judgment prediction is essential for enhancing judicial efficiency. In this work, we identify that existing large language models (LLMs) underperform in this domain due to challenges in understanding case complexities and distinguishing between similar charges. To adapt LLMs for effective... | Chenlong Deng, Kelong Mao, Yuyao Zhang, Zhicheng Dou |  |
| 1437 |  |  [Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models](https://doi.org/10.18653/v1/2024.findings-emnlp.44) |  | 0 | Recently, we have observed that Large Multi-modal Models (LMMs) are revolutionizing the way machines interact with the world, unlocking new possibilities across various multi-modal applications. To adapt LMMs for downstream tasks, parameter-efficient fine-tuning (PEFT) which only trains additional... | Donghoon Kim, Gusang Lee, Kyuhong Shim, Byonghyo Shim |  |
| 1438 |  |  [What Would Happen Next? Predicting Consequences from An Event Causality Graph](https://doi.org/10.18653/v1/2024.findings-emnlp.45) |  | 0 | Existing script event prediction task forcasts the subsequent event based on an event script chain. However, the evolution of historical events are more complicated in real world scenarios and the limited information provided by the event script chain also make it difficult to accurately predict... | Chuanhong Zhan, Wei Xiang, Liang Chao, Bang Wang |  |
| 1439 |  |  [Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.46) |  | 0 | Towards enhancing the chain-of-thought (CoT) reasoning of large language models (LLMs), much existing work has revealed the effectiveness of straightforward learning on annotated/generated CoT paths. However, there is less evidence yet that reasoning capabilities can be enhanced through a reverse... | Shengnan An, Zexiong Ma, Siqi Cai, Zeqi Lin, Nanning Zheng, JianGuang Lou, Weizhu Chen |  |
| 1440 |  |  [Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.47) |  | 0 | Understanding and analyzing event temporal relations is a crucial task in Natural Language Processing (NLP). This task, known as Event Temporal Relation Extraction (ETRE), aims to identify and extract temporal connections between events in text. Recent studies focus on locating the relative... | Wanting Ning, Lishuang Li, Xueyang Qin, Yubo Feng, Jingyao Tang |  |
| 1441 |  |  [LongGenBench: Long-context Generation Benchmark](https://doi.org/10.18653/v1/2024.findings-emnlp.48) |  | 0 | Current long-context benchmarks primarily focus on retrieval-based tests, requiring Large Language Models (LLMs) to locate specific information within extensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark. Long-context generation refers to the ability of a language model to... | Xiang Liu, Peijie Dong, Xuming Hu, Xiaowen Chu |  |
| 1442 |  |  [RaFe: Ranking Feedback Improves Query Rewriting for RAG](https://doi.org/10.18653/v1/2024.findings-emnlp.49) |  | 0 | As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG) techniques have evolved, query rewriting has been widely incorporated into the RAG system for downstream tasks like open-domain QA to enhance document retrieval by reformulating queries. Many works have attempted to improve... | Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang |  |
| 1443 |  |  [BASES: Large-scale Web Search User Simulation with Large Language Model based Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.50) |  | 0 | Due to the excellent capacities of large language models (LLMs), it becomes feasible to develop LLM-based agents for reliable user simulation. Considering the scarcity and limit (e.g., privacy issues) of real user data, in this paper, we conduct large-scale user simulations for the web search... | Ruiyang Ren, Peng Qiu, Yingqi Qu, Jing Liu, Xin Zhao, Hua Wu, JiRong Wen, Haifeng Wang |  |
| 1444 |  |  [Make Large Language Model a Better Ranker](https://doi.org/10.18653/v1/2024.findings-emnlp.51) |  | 0 | Large Language Models (LLMs) demonstrate robust capabilities across various fields, leading to a paradigm shift in LLM-enhanced Recommender System (RS). Research to date focuses on point-wise and pair-wise recommendation paradigms, which are inefficient for LLM-based recommenders due to high... | Wenshuo Chao, Zhi Zheng, Hengshu Zhu, Hao Liu |  |
| 1445 |  |  [SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.52) |  | 0 | Specialized lexicons are collections of words with associated constraints such as special definitions, specific roles, and intended target audiences. These constraints are necessary for content generation and documentation tasks (e.g., writing technical manuals or children’s reading materials),... | Joseph Marvin Imperial, Harish Tayyar Madabushi |  |
| 1446 |  |  [Devil's Advocate: Anticipatory Reflection for LLM Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.53) |  | 0 | In this work, we introduce a novel approach that equips LLM agents with introspection, enhancing consistency and adaptability in solving complex tasks. Our approach prompts LLM agents to decompose a given task into manageable subtasks (i.e., to make a plan), and to continuously introspect upon the... | Haoyu Wang, Tao Li, Zhiwei Deng, Dan Roth, Yang Li |  |
| 1447 |  |  [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](https://doi.org/10.18653/v1/2024.findings-emnlp.54) |  | 0 | This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) with black-box API access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However,... | Jiayuan Su, Jing Luo, Hongwei Wang, Lu Cheng |  |
| 1448 |  |  [Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly](https://doi.org/10.18653/v1/2024.findings-emnlp.55) |  | 0 | Compilers are complex software containing millions of lines of code, taking years to develop. This paper investigates to what extent Large Language Models (LLMs) can replace hand-crafted compilers in translating high-level programming languages to machine instructions, using C to x86 assembly as a... | Shuoming Zhang, Jiacheng Zhao, Chunwei Xia, Zheng Wang, Yunji Chen, Huimin Cui |  |
| 1449 |  |  [Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.56) |  | 0 | Large language models (LLMs) have revolutionized the role of AI, yet pose potential social risks. To steer LLMs towards human preference, alignment technologies have been introduced and gained increasing attention. Nevertheless, existing methods heavily rely on high-quality positive-negative... | Shitong Duan, Xiaoyuan Yi, Peng Zhang, Yan Liu, Zheng Liu, Tun Lu, Xing Xie, Ning Gu |  |
| 1450 |  |  [OffsetBias: Leveraging Debiased Data for Tuning Evaluators](https://doi.org/10.18653/v1/2024.findings-emnlp.57) |  | 0 | Employing Large Language Models (LLMs) to assess the quality of generated responses has become a widely adopted evaluation method. Specifically, instruct-tuned models and fine-tuned judge models based on open-source LLMs have been reported. While it is known that judge models are vulnerable to... | Junsoo Park, Seungyeon Jwa, Meiying Ren, Daeyoung Kim, Sanghyuk Choi |  |
| 1451 |  |  [Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.58) |  | 0 | As a complex task that requires rich information input, features from various aspects have been utilized in event extraction. However, most of the previous works ignored the value of glyph, which could contain enriched semantic information and can not be fully expressed by the pre-trained embedding... | Xiaoyi Bao, Jinghang Gu, Zhongqing Wang, Minjie Qiang, ChuRen Huang |  |
| 1452 |  |  [Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP](https://doi.org/10.18653/v1/2024.findings-emnlp.59) |  | 0 | CLIP has demonstrated great versatility in adapting to various downstream tasks, such as image editing and generation, visual question answering, and video understanding. However, CLIP-based applications often suffer from misunderstandings regarding user intent, leading to discrepancies between the... | Zeliang Zhang, Zhuo Liu, Mingqian Feng, Chenliang Xu |  |
| 1453 |  |  [LLM-A\*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning](https://doi.org/10.18653/v1/2024.findings-emnlp.60) |  | 0 | Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A\* and its variants are capable of ensuring path validity but suffer from... | Silin Meng, Yiwei Wang, ChengFu Yang, Nanyun Peng, KaiWei Chang |  |
| 1454 |  |  [Guided Knowledge Generation with Language Models for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.61) |  | 0 | Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought (CoT) have shown promise in enhancing LLMs’ reasoning capabilities, mitigating... | Xiao Wei, Haoran Chen, Hang Yu, Hao Fei, Qian Liu |  |
| 1455 |  |  [BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain](https://doi.org/10.18653/v1/2024.findings-emnlp.62) |  | 0 | Retrieval Augmented Generation (RAG) system is important in domains such as e-commerce, which has many long-tail entities and frequently updated information. Most existing works adopt separate modules for retrieval and generation, which may be suboptimal since the retrieval task and the generation... | Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang, Ruihua Song |  |
| 1456 |  |  [NCPrompt: NSP-Based Prompt Learning and Contrastive Learning for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.63) |  | 0 | Implicit Discourse Relation Recognition (IDRR) is an important task to classify the discourse relation sense between argument pairs without an explicit connective. Recently, prompt learning methods have demonstrated success in IDRR. However, prior work primarily transform IDRR into a... | Yuetong Rong, Yijun Mo |  |
| 1457 |  |  [SAFETY-J: Evaluating Safety with Critique](https://doi.org/10.18653/v1/2024.findings-emnlp.64) |  | 0 | The deployment of Large Language Models (LLMs) in content generation raises significant safety concerns, particularly regarding the transparency and interpretability of content evaluations. Current methods, primarily focused on binary safety classifications, lack mechanisms for detailed critique,... | Yixiu Liu, Yuxiang Zheng, Shijie Xia, Jiajun Li, Yi Tu, Chaoling Song, Pengfei Liu |  |
| 1458 |  |  [Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL](https://doi.org/10.18653/v1/2024.findings-emnlp.65) |  | 0 | In-context learning with large language models (LLMs) is the current mainstream method for text-to-SQL. Previous studies have explored selecting relevant demonstrations from a human-labeled demonstration pool, but these methods lack diversity and incur high labeling costs. In this work, we address... | Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che |  |
| 1459 |  |  [A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.66) |  | 0 | Vision-language models (VLMs) have gained widespread adoption in both industry and academia. In this study, we propose a unified framework for systematically evaluating gender, race, and age biases in VLMs with respect to professions. Our evaluation encompasses all supported inference modes of the... | Ashutosh Sathe, Prachi Jain, Sunayana Sitaram |  |
| 1460 |  |  [Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech](https://doi.org/10.18653/v1/2024.findings-emnlp.67) |  | 0 | In recent years, with the vast and rapidly increasing amounts of spoken and textual data, Named Entity Recognition (NER) tasks have evolved into three distinct categories, i.e., text-based NER (TNER), Speech NER (SNER) and Multimodal NER (MNER). However, existing approaches typically require... | Jinzhong Ning, Yuanyuan Sun, Bo Xu, Zhihao Yang, Ling Luo, Hongfei Lin |  |
| 1461 |  |  [VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.68) |  | 0 | Large Vision-Language Models (VLMs) have already been applied to the understanding of Graphical User Interfaces (GUIs) and have achieved notable results. However, existing VLMs often overly rely on internal text-based knowledge while neglecting visual inputs. This imbalance may lead models to... | Ziyang Meng, Yu Dai, Zezheng Gong, Shaoxiong Guo, Minglong Tang, Tongquan Wei |  |
| 1462 |  |  [Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.69) |  | 0 | Robust therapeutic relationships between counselors and clients are fundamental to counseling effectiveness. The assessment of therapeutic alliance is well-established in traditional face-to-face therapy but may not directly translate to text-based settings. With millions of individuals seeking... | Anqi Li, Yu Lu, Nirui Song, Shuai Zhang, Lizhi Ma, Zhenzhong Lan |  |
| 1463 |  |  [Dynamic Planning for LLM-based Graphical User Interface Automation](https://doi.org/10.18653/v1/2024.findings-emnlp.70) |  | 0 | The advent of large language models (LLMs) has spurred considerable interest in advancing autonomous LLMs-based agents, particularly in intriguing applications within smartphone graphical user interfaces (GUIs). When presented with a task goal, these agents typically emulate human actions within a... | Shaoqing Zhang, Zhuosheng Zhang, Kehai Chen, Xinbei Ma, Muyun Yang, Tiejun Zhao, Min Zhang |  |
| 1464 |  |  [SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.71) |  | 0 | Large Language Models (LLMs) have shown great potential in the biomedical domain with the advancement of retrieval-augmented generation (RAG). However, existing retrieval-augmented approaches face challenges in addressing diverse queries and documents, particularly for medical knowledge queries,... | Minda Hu, Licheng Zong, Hongru Wang, Jingyan Zhou, Jingjing Li, Yichen Gao, KamFai Wong, Yu Li, Irwin King |  |
| 1465 |  |  [Large Language Model-based Human-Agent Collaboration for Complex Task Solving](https://doi.org/10.18653/v1/2024.findings-emnlp.72) |  | 0 | In recent developments within the research community, the integration of Large Language Models (LLMs) in creating fully autonomous agents has garnered significant interest. Despite this, LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully... | Xueyang Feng, Zhiyuan Chen, Yujia Qin, Yankai Lin, Xu Chen, Zhiyuan Liu, JiRong Wen |  |
| 1466 |  |  [MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.73) |  | 0 | To advance the evaluation of multimodal math reasoning in large multimodal models (LMMs), this paper introduces a novel benchmark, MM-MATH. MM-MATH consists of 5,929 open-ended middle school math problems with visual contexts, with fine-grained classification across difficulty, grade level, and... | Kai Sun, Yushi Bai, Ji Qi, Lei Hou, JuanZi Li |  |
| 1467 |  |  [LongAlign: A Recipe for Long Context Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.74) |  | 0 | Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign—a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long... | Yushi Bai, Xin Lv, Jiajie Zhang, Yuze He, Ji Qi, Lei Hou, Jie Tang, Yuxiao Dong, Juanzi Li |  |
| 1468 |  |  [Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.75) |  | 0 | Textual Attributed Graphs (TAGs) are crucial for modeling complex real-world systems, yet leveraging large language models (LLMs) for TAGs presents unique challenges due to the gap between sequential text processing and graph-structured data. We introduce AskGNN, a novel approach that bridges this... | Zhengyu Hu, Yichuan Li, Zhengyu Chen, Jingang Wang, Han Liu, Kyumin Lee, Kaize Ding |  |
| 1469 |  |  [CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.76) |  | 0 | Conversational explainable artificial intelligence (ConvXAI) systems based on large language models (LLMs) have garnered significant interest from the research community in natural language processing (NLP) and human-computer interaction (HCI). Such systems can provide answers to user questions... | Qianli Wang, Tatiana Anikina, Nils Feldhus, Simon Ostermann, Sebastian Möller |  |
| 1470 |  |  [Evaluating Language Model Character Traits](https://doi.org/10.18653/v1/2024.findings-emnlp.77) |  | 0 | Language models (LMs) can exhibit human-like behaviour, but it is unclear how to describe this behaviour without undue anthropomorphism. We formalise a behaviourist view of LM character traits: qualities such as truthfulness, sycophancy, and coherent beliefs and intentions, which may manifest as... | Francis Rhys Ward, Zejia Yang, Alex Jackson, Randy Brown, Chandler Smith, Grace Colverd, Louis Thomson, Raymond Douglas, Patrik Bartak, Andrew Rowan |  |
| 1471 |  |  [Self-Explore: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards](https://doi.org/10.18653/v1/2024.findings-emnlp.78) |  | 0 | Training on large amounts of rationales (i.e., CoT Fine-tuning) has been found effective for improving mathematical reasoning of large language models (LLMs). However, acquiring human-authored solutions or augmenting rationales from proprietary models is costly and not scalable. In this paper, we... | Hyeonbin Hwang, Doyoung Kim, Seungone Kim, Seonghyeon Ye, Minjoon Seo |  |
| 1472 |  |  [R-Judge: Benchmarking Safety Risk Awareness for LLM Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.79) |  | 0 | Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on the harmlessness of LLM-generated content... | Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao, Tian Xia, Lizhen Xu, Binglin Zhou, Fangqi Li, Zhuosheng Zhang, Rui Wang, Gongshen Liu |  |
| 1473 |  |  [EAVE: Efficient Product Attribute Value Extraction via Lightweight Sparse-layer Interaction](https://doi.org/10.18653/v1/2024.findings-emnlp.80) |  | 0 | Product attribute value extraction involves identifying the specific values associated with various attributes from a product profile. While existing methods often prioritize the development of effective models to improve extraction performance, there has been limited emphasis on extraction... | Li Yang, Qifan Wang, Jianfeng Chi, Jiahao Liu, Jingang Wang, Fuli Feng, Zenglin Xu, Yi Fang, Lifu Huang, Dongfang Liu |  |
| 1474 |  |  [MultiSkill: Evaluating Large Multimodal Models for Fine-grained Alignment Skills](https://doi.org/10.18653/v1/2024.findings-emnlp.81) |  | 0 | We propose MultiSkill, an evaluation protocol that assesses large multimodal models (LMMs) across multiple fine-grained skills for alignment with human values. Recent LMMs have shown various intriguing abilities, such as solving graph theory problems and explaining visual jokes. However, existing... | Zhenran Xu, Senbao Shi, Baotian Hu, Longyue Wang, Min Zhang |  |
| 1475 |  |  [To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.82) |  | 0 | Large Language Models (LLMs) trained on extensive corpora inevitably retain sensitive data, such as personal privacy information and copyrighted material. Recent advancements in knowledge unlearning involve updating LLM parameters to erase specific knowledge. However, current unlearning paradigms... | Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang |  |
| 1476 |  |  [EchoSight: Advancing Visual-Language Models with Wiki Knowledge](https://doi.org/10.18653/v1/2024.findings-emnlp.83) |  | 0 | Knowledge-based Visual Question Answering (KVQA) tasks require answering questions about images using extensive background knowledge. Despite significant advancements, generative models often struggle with these tasks due to the limited integration of external knowledge. In this paper, we introduce... | Yibin Yan, Weidi Xie |  |
| 1477 |  |  [Diversify, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA](https://doi.org/10.18653/v1/2024.findings-emnlp.84) |  | 0 | Knowledge-based Visual Qustion-answering (K-VQA) often requires the use of background knowledge beyond the image. However, we discover that a single knowledge generation strategy is often insuffcient for all K-VQA questions. To this end, we propose Diversifcation, Evidence Truncation, and... | Miaoyu Li, Haoxin Li, Zilin Du, Boyang Li |  |
| 1478 |  |  [Reconfidencing LLMs from the Grouping Loss Perspective](https://doi.org/10.18653/v1/2024.findings-emnlp.85) |  | 0 | Large Language Models (LLMs), such as GPT and LLaMA, are susceptible to generating hallucinated answers in a confident tone. While previous efforts to elicit and calibrate confidence scores have shown some success, they often overlook biases towards certain groups, such as specific nationalities.... | Lihu Chen, Alexandre PerezLebel, Fabian M. Suchanek, Gaël Varoquaux |  |
| 1479 |  |  [Tokenization Falling Short: On Subword Robustness in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.86) |  | 0 | Language models typically tokenize raw text into sequences of subword identifiers from a predefined vocabulary, a process inherently sensitive to typographical errors, length variations, and largely oblivious to the internal structure of tokens—issues we term \*the curse of tokenization\*. In this... | Yekun Chai, Yewei Fang, Qiwei Peng, Xuhong Li |  |
| 1480 |  |  [AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.87) |  | 0 | Given the importance of ancient Chinese in capturing the essence of rich historical and cultural heritage, the rapid advancements in Large Language Models (LLMs) necessitate benchmarks that can effectively evaluate their understanding of ancient contexts. To meet this need, we present AC-EVAL, an... | Yuting Wei, Yuanxing Xu, Xinru Wei, Simin Yang, Yangfu Zhu, Yuqing Li, Di Liu, Bin Wu |  |
| 1481 |  |  [MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos](https://doi.org/10.18653/v1/2024.findings-emnlp.88) |  | 0 | Multilingual anaphora resolution identifies referring expressions and implicit arguments in texts and links to antecedents that cover several languages. In the most challenging setting, cross-lingual anaphora resolution, training data, and test data are in different languages. As knowledge needs to... | Cennet Oguz, Pascal Denis, Simon Ostermann, Emmanuel Vincent, Natalia Skachkova, Josef van Genabith |  |
| 1482 |  |  [Dealing with Controversy: An Emotion and Coping Strategy Corpus Based on Role Playing](https://doi.org/10.18653/v1/2024.findings-emnlp.89) |  | 0 | There is a mismatch between psychological and computational studies on emotions. Psychological research aims at explaining and documenting internal mechanisms of these phenomena, while computational work often simplifies them into labels. Many emotion fundamentals remain under-explored in natural... | Enrica Troiano, Sofie Labat, Marco Stranisci, Rossana Damiano, Viviana Patti, Roman Klinger |  |
| 1483 |  |  [MATE: Meet At The Embedding - Connecting Images with Long Texts](https://doi.org/10.18653/v1/2024.findings-emnlp.90) |  | 0 | While advancements in Vision Language Models (VLMs) have significantly improved the alignment of visual and textual data, these models primarily focus on aligning images with short descriptive captions. This focus limits their ability to handle complex text interactions, particularly with longer... | Young Kyun Jang, Junmo Kang, Yong Jae Lee, Donghyun Kim |  |
| 1484 |  |  [Mixed Distillation Helps Smaller Language Models Reason Better](https://doi.org/10.18653/v1/2024.findings-emnlp.91) |  | 0 | As large language models (LLMs) have demonstrated impressive multiple step-by-step reasoning capabilities in recent natural language processing (NLP) reasoning tasks, many studies are interested in distilling reasoning abilities into smaller language models (SLMs) via fine-tuning. Previous... | Chenglin Li, Qianglong Chen, Liangyue Li, Caiyu Wang, Feng Tao, Yicheng Li, Zulong Chen, Yin Zhang |  |
| 1485 |  |  [The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.92) |  | 0 | Following multiple instructions is a crucial ability for large language models (LLMs). Evaluating this ability comes with significant challenges: (i) limited coherence between multiple instructions, (ii) positional bias where the order of instructions affects model performance, and (iii) a lack of... | Xinyi Chen, Baohao Liao, Jirui Qi, Panagiotis Eustratiadis, Christof Monz, Arianna Bisazza, Maarten de Rijke |  |
| 1486 |  |  [Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search](https://doi.org/10.18653/v1/2024.findings-emnlp.93) |  | 0 | Instruction tuning is a crucial technique for aligning language models with humans’ actual goals in the real world. Extensive research has highlighted the quality of instruction data is essential for the success of this alignment. However, creating high-quality data manually is labor-intensive and... | Chenglin Li, Qianglong Chen, Zhi Li, Feng Tao, Yicheng Li, Hao Chen, Fei Yu, Yin Zhang |  |
| 1487 |  |  [Suri: Multi-constraint Instruction Following in Long-form Text Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.94) |  | 0 | Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human-written long-form texts paired with LLM-generated... | Chau Pham, Simeng Sun, Mohit Iyyer |  |
| 1488 |  |  [Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.95) |  | 0 | Large-scale language models (LLMs) like ChatGPT have demonstrated impressive abilities in generating responses based on human instructions. However, their use in the medical field can be challenging due to their lack of specific, in-depth knowledge. In this study, we present a system called LLMs... | Yubo Wang, Xueguang Ma, Wenhu Chen |  |
| 1489 |  |  [Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?](https://doi.org/10.18653/v1/2024.findings-emnlp.96) |  | 0 | Prior research has revealed that certain abstract concepts are linearly represented as directions in the representation space of LLMs, predominantly centered around English. In this paper, we extend this investigation to a multilingual context, with a specific focus on human values-related concepts... | Shaoyang Xu, Weilong Dong, Zishan Guo, Xinwei Wu, Deyi Xiong |  |
| 1490 |  |  [PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.97) |  | 0 | Large language models (LLMs) are known to be trained on vast amounts of data, which may unintentionally or intentionally include data from commonly used benchmarks. This inclusion can lead to cheatingly high scores on model leaderboards, yet result in disappointing performance in real-world... | Huixuan Zhang, Yun Lin, Xiaojun Wan |  |
| 1491 |  |  [UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.98) |  | 0 | Location-based services play an critical role in improving the quality of our daily lives. Despite the proliferation of numerous specialized AI models within spatio-temporal context of location-based services, these models struggle to autonomously tackle problems regarding complex urban planing and... | Yue Jiang, Qin Chao, Yile Chen, Xiucheng Li, Shuai Liu, Gao Cong |  |
| 1492 |  |  [Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling](https://doi.org/10.18653/v1/2024.findings-emnlp.99) |  | 0 | Ensembling multiple models has always been an effective approach to push the limits of existing performance and is widely used in classification tasks by simply averaging the classification probability vectors from multiple classifiers to achieve better accuracy. However, in the thriving... | YaoChing Yu, ChunChih Kuo, Ziqi Ye, YuCheng Chang, YuehSe Li |  |
| 1493 |  |  [Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.100) |  | 0 | We study the code generation behavior of instruction-tuned models built on top of code pre-trained language models when they could access an auxiliary function to implement a function. We design several ways to provide auxiliary functions to the models by adding them to the query or providing a... | Seonghyeon Lee, Suyeon Kim, Joonwon Jang, Heejae Chon, Dongha Lee, Hwanjo Yu |  |
| 1494 |  |  [AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses](https://doi.org/10.18653/v1/2024.findings-emnlp.101) |  | 0 | Question answering (QA) tasks have been extensively studied in the field of natural language processing (NLP). Answers to open-ended questions are highly diverse and difficult to quantify, and cannot be simply evaluated as correct or incorrect, unlike close-ended questions with definitive answers.... | Xiaotian Lu, Jiyi Li, Koh Takeuchi, Hisashi Kashima |  |
| 1495 |  |  [Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.102) |  | 0 | Fine-grained image classification, especially in zero-/few-shot scenarios, poses a considerable challenge for vision-language models (VLMs) like CLIP, which often struggle to differentiate between semantically similar classes due to insufficient supervision for fine-grained tasks. On the other... | Canshi Wei |  |
| 1496 |  |  [Exploring the Best Practices of Query Expansion with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.103) |  | 0 | Large Language Models (LLMs) are foundational in language technologies, particularly in information retrieval (IR). In this paper, we thoroughly explore the best practice of leveraging LLMs for query expansion. To this end, we introduce a training-free, straightforward yet effective framework... | Le Zhang, Yihong Wu, Qian Yang, JianYun Nie |  |
| 1497 |  |  [Chain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.104) |  | 0 | Despite the advancements made with the retrieve-then-read pipeline on open-domain question answering task, current methods still face challenges stemming from term mismatch and limited interaction between information retrieval systems and large language models. To mitigate these issues, we propose... | Chunlei Xin, Yaojie Lu, Hongyu Lin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Zhongyi Liu, Xianpei Han, Le Sun |  |
| 1498 |  |  [MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-emnlp.105) |  | 0 | Emotion-cause pair extraction (ECPE) aims to identify emotion clauses and their corresponding cause clauses within a document. Traditional methods often rely on coarse-grained clause-level annotations, which can overlook valuable fine-grained clues. To address this issue, we propose... | Yang Yu, Xin Lin, Changqun Li, Shizhou Huang, Liang He |  |
| 1499 |  |  [Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](https://doi.org/10.18653/v1/2024.findings-emnlp.106) |  | 0 | Automating data generation with Large Language Models (LLMs) has become increasingly popular. In this work, we investigate the feasibility and effectiveness of LLM-based data generation in the challenging setting of source-grounded information-seeking dialogs, with response attribution, over long... | Lotem Golany, Filippo Galgani, Maya Mamo, Nimrod Parasol, Omer Vandsburger, Nadav Bar, Ido Dagan |  |
| 1500 |  |  [Visual Question Decomposition on Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.107) |  | 0 | Question decomposition has emerged as an effective strategy for prompting Large Language Models (LLMs) to answer complex questions. However, while existing methods primarily focus on unimodal language models, the question decomposition capability of Multimodal Large Language Models (MLLMs) has yet... | Haowei Zhang, Jianzhe Liu, Zhen Han, Shuo Chen, Bailan He, Volker Tresp, Zhiqiang Xu, Jindong Gu |  |
| 1501 |  |  [ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.108) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities across various tasks, but their performance is highly sensitive to the prompts utilized. This variability poses challenges for accurate assessment and user satisfaction. Current research frequently overlooks instance-level... | Jingming Zhuo, Songyang Zhang, Xinyu Fang, Haodong Duan, Dahua Lin, Kai Chen |  |
| 1502 |  |  [Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.109) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant popularity for adapting pre-trained Large Language Models (LLMs) to downstream tasks, primarily due to their potential to significantly reduce memory and computational overheads. However, a common limitation in most PEFT... | Kai Yao, Penglei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu |  |
| 1503 |  |  [Abstraction-of-Thought Makes Language Models Better Reasoners](https://doi.org/10.18653/v1/2024.findings-emnlp.110) |  | 0 | Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks to bridge this gap by introducing a novel structured... | Ruixin Hong, Hongming Zhang, Xiaoman Pan, Dong Yu, Changshui Zhang |  |
| 1504 |  |  [LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Communities in Long Form Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.111) |  | 0 | Retail investing is on the rise, and a growing number of users is relying on online finance communities to educate themselves.However, recent years have positioned Large Language Models (LLMs) as powerful question answering (QA) tools, shifting users away from interacting in communities towards... | KrisFillip Kahl, Tolga Buz, Russa Biswas, Gerard de Melo |  |
| 1505 |  |  [Automated Tone Transcription and Clustering with Tone2Vec](https://doi.org/10.18653/v1/2024.findings-emnlp.112) |  | 0 | Lexical tones play a crucial role in Sino-Tibetan languages. However, current phonetic fieldwork relies on manual effort, resulting in substantial time and financial costs. This is especially challenging for the numerous endangered languages that are rapidly disappearing, often compounded by... | Yi Yang, Yiming Wang, Zhiqiang Tang, Jiahong Yuan |  |
| 1506 |  |  [Multi-dimensional Evaluation of Empathetic Dialogue Responses](https://doi.org/10.18653/v1/2024.findings-emnlp.113) |  | 0 | Empathy is critical for effective and satisfactory conversational communication. Prior efforts to measure conversational empathy mostly focus on expressed communicative intents—that is, the way empathy is expressed. Yet, these works ignore the fact that conversation is also a collaboration... | Zhichao Xu, Jiepu Jiang |  |
| 1507 |  |  [Translation of Multifaceted Data without Re-Training of Machine Translation Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.114) |  | 0 | Translating major language resources to build minor language resources becomes a widely-used approach. Particularly in translating complex data points composed of multiple components, it is common to translate each component separately. However, we argue that this practice often overlooks the... | Hyeonseok Moon, Seungyoon Lee, Seongtae Hong, Seungjun Lee, Chanjun Park, Heuiseok Lim |  |
| 1508 |  |  [Reward Difference Optimization For Sample Reweighting In Offline RLHF](https://doi.org/10.18653/v1/2024.findings-emnlp.115) |  | 0 | With the wide deployment of Large Language Models (LLMs), aligning LLMs with human values becomes increasingly important. Although Reinforcement Learning with Human Feedback (RLHF) proves effective, it is complicated and highly resource-intensive. As such, offline RLHF has been introduced as an... | Shiqi Wang, Zhengze Zhang, Rui Zhao, Fei Tan, CamTu Nguyen |  |
| 1509 |  |  [AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories](https://doi.org/10.18653/v1/2024.findings-emnlp.116) |  | 0 | Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory tuning data collection featuring more than 50k diverse... | Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng, Sujian Li |  |
| 1510 |  |  [Are LLMs Aware that Some Questions are not Open-ended?](https://doi.org/10.18653/v1/2024.findings-emnlp.117) |  | 0 | Large Language Models (LLMs) have shown the impressive capability of answering questions in a wide range of scenarios. However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more... | Dongjie Yang, Hai Zhao |  |
| 1511 |  |  [Conditional Language Policy: A General Framework For Steerable Multi-Objective Finetuning](https://doi.org/10.18653/v1/2024.findings-emnlp.118) |  | 0 | Reward-based finetuning is crucial for aligning language policies with intended behaviors (\*e.g.\*, creativity and safety). A key challenge is to develop steerable language models that trade-off multiple (conflicting) objectives in a flexible and efficient manner. This paper presents Conditional... | Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, Johan Ferret, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent |  |
| 1512 |  |  [DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature](https://doi.org/10.18653/v1/2024.findings-emnlp.119) |  | 0 | Recent advancements in large language models (LLMs) have achieved promising performances across various applications. Nonetheless, the ongoing challenge of integrating long-tail knowledge continues to impede the seamless adoption of LLMs in specialized domains. In this work, we introduce DALK,... | Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sukwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy DuongTran, Ying Ding, Huan Liu, Li Shen, Tianlong Chen |  |
| 1513 |  |  [Can AI Relate: Testing Large Language Model Response for Mental Health Support](https://doi.org/10.18653/v1/2024.findings-emnlp.120) |  | 0 | Large language models (LLMs) are already being piloted for clinical use in hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed deployment use case is psychotherapy, where a LLM-powered chatbot can treat a patient undergoing a mental health crisis. Deployment of LLMs for mental... | Saadia Gabriel, Isha Puri, Xuhai Xu, Matteo Malgaroli, Marzyeh Ghassemi |  |
| 1514 |  |  [Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology](https://doi.org/10.18653/v1/2024.findings-emnlp.121) |  | 0 | This paper proposes a novel training method to improve the robustness of Extractive Question Answering (EQA) models. Previous research has shown that existing models, when trained on EQA datasets that include unanswerable questions, demonstrate a significant lack of robustness against distribution... | Son Tran, Matt Kretchmar |  |
| 1515 |  |  [Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion](https://doi.org/10.18653/v1/2024.findings-emnlp.122) |  | 0 | The creation of artificial polyglot voices remains a challenging task, despite considerable progress in recent years. This paper investigates self-supervised learning for voice conversion to create native-sounding polyglot voices. We introduce a novel cross-lingual any-to-one voice conversion... | Giuseppe Ruggiero, Matteo Testa, Jurgen Van de Walle, Luigi Di Caro |  |
| 1516 |  |  [IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce](https://doi.org/10.18653/v1/2024.findings-emnlp.123) |  | 0 | Enhancing Language Models’ (LMs) ability to understand purchase intentions in E-commerce scenarios is crucial for their effective assistance in various downstream tasks. However, previous approaches that distill intentions from LMs often fail to generate meaningful and human-centric intentions... | Wenxuan Ding, Weiqi Wang, Sze Heng Douglas Kwok, Minghao Liu, Tianqing Fang, Jiaxin Bai, Xin Liu, Changlong Yu, Zheng Li, Chen Luo, Qingyu Yin, Bing Yin, Junxian He, Yangqiu Song |  |
| 1517 |  |  [Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity](https://doi.org/10.18653/v1/2024.findings-emnlp.124) |  | 0 | We present a simple on the fly method for faster inference of large language models. Unlike other (self-)speculative decoding techniques, our method does not require fine-tuning or black-box optimization to generate a fixed draft model, relying instead on simple rules to generate varying draft... | Michael R. Metel, Peng Lu, Boxing Chen, Mehdi Rezagholizadeh, Ivan Kobyzev |  |
| 1518 |  |  [EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.125) |  | 0 | In this paper, we introduce EconLogicQA, a rigorous benchmark designed to assess the sequential reasoning capabilities of large language models (LLMs) within the intricate realms of economics, business, and supply chain management. Diverging from traditional benchmarks that predict subsequent... | Yinzhu Quan, Zefang Liu |  |
| 1519 |  |  [The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance](https://doi.org/10.18653/v1/2024.findings-emnlp.126) |  | 0 | Cloze testing is a common method for measuring the behavior of large language models on a number of benchmark tasks. Using the MMLU dataset, we show that the base-rate probability (BRP) differences across answer tokens are significant and affect task performance ie. guess A if uncertain. We find... | Kyle Moore, Jesse Roberts, Thao Pham, Oseremhen Ewaleifoh, Douglas H. Fisher |  |
| 1520 |  |  [Can LLM Graph Reasoning Generalize beyond Pattern Memorization?](https://doi.org/10.18653/v1/2024.findings-emnlp.127) |  | 0 | Large language models (LLMs) demonstrate great potential for problems with implicit graphical structures, while recent works seek to enhance the graph reasoning capabilities of LLMs through specialized instruction tuning. The resulting “graph LLMs” are evaluated with in-distribution settings only,... | Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov |  |
| 1521 |  |  [Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets](https://doi.org/10.18653/v1/2024.findings-emnlp.128) |  | 0 | Advancements in Large Language Models (LLMs) have significantly enhanced instruction-following capabilities. However, most Instruction Fine-Tuning (IFT) datasets are predominantly in English, limiting model performance in other languages. Traditional methods for creating multilingual IFT... | Sathish Reddy Indurthi, Wenxuan Zhou, Shamil Chollampatt, Ravi Agrawal, Kaiqiang Song, Lingxiao Zhao, Chenguang Zhu |  |
| 1522 |  |  [ASTE-Transformer: Modelling Dependencies in Aspect-Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.129) |  | 0 | Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of aspect-based sentiment analysis that consists in extracting (aspect phrase, opinion phrase, sentiment polarity) triples from a given sentence. Recent state-of-the-art methods approach this task by first extracting all... | Iwo Naglik, Mateusz Lango |  |
| 1523 |  |  [Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach](https://doi.org/10.18653/v1/2024.findings-emnlp.130) |  | 0 | Existing explanation methods for image classification struggle to provide faithful and plausible explanations. This paper addresses this issue by proposing a post-hoc natural language explanation method that can be applied to any CNN-based classifier without altering its training process or... | Adam Wojciechowski, Mateusz Lango, Ondrej Dusek |  |
| 1524 |  |  [SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA](https://doi.org/10.18653/v1/2024.findings-emnlp.131) |  | 0 | Text-to-SQL parsing and end-to-end question answering (E2E TQA) are two main approaches for Table-based Question Answering task. Despite success on multiple benchmarks, they have yet to be compared and their synergy remains unexplored. In this paper, we identify different strengths and weaknesses... | Siyue Zhang, Anh Tuan Luu, Chen Zhao |  |
| 1525 |  |  [OpenGraph: Towards Open Graph Foundation Models](https://doi.org/10.18653/v1/2024.findings-emnlp.132) |  | 0 | Graph learning has become essential in various domains, including recommendation systems and social network analysis. Graph Neural Networks (GNNs) have emerged as promising techniques for encoding structural information and improving performance in tasks like link prediction and node... | Lianghao Xia, Ben Kao, Chao Huang |  |
| 1526 |  |  [Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework](https://doi.org/10.18653/v1/2024.findings-emnlp.133) |  | 0 | Retrieval-augmented generation (RAG) has emerged as a popular solution to mitigate the hallucination issues of large language models. However, existing studies on RAG seldom address the issue of predictive uncertainty, i.e., how likely it is that a RAG model’s prediction is incorrect, resulting in... | Lu Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng |  |
| 1527 |  |  [Learning to Paraphrase for Alignment with LLM Preference](https://doi.org/10.18653/v1/2024.findings-emnlp.134) |  | 0 | Large Language Models (LLMs) exhibit the issue of paraphrase divergence. This means that when a question is phrased in a slightly different but semantically similar way, LLM may output a wrong response despite being able to answer the original question correctly. Previous research has regarded this... | Junbo Fu, Guoshuai Zhao, Yimin Deng, Yunqi Mi, Xueming Qian |  |
| 1528 |  |  [Mirror-Consistency: Harnessing Inconsistency in Majority Voting](https://doi.org/10.18653/v1/2024.findings-emnlp.135) |  | 0 | Self-Consistency, a widely-used decoding strategy, significantly boosts the reasoning capabilities of Large Language Models (LLMs). However, it depends on the plurality voting rule, which focuses on the most frequent answer while overlooking all other minority responses. These inconsistent minority... | Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Zhouhan Lin |  |
| 1529 |  |  [Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts](https://doi.org/10.18653/v1/2024.findings-emnlp.136) |  | 0 | When using large language models (LLMs) in knowledge-intensive tasks, such as open-domain question answering, external context can bridge the gap between external knowledge and the LLMs’ parametric knowledge.Recent research has been developed to amplify contextual knowledge over the parametric... | Youna Kim, Hyuhng Joon Kim, Cheonbok Park, Choonghyun Park, Hyunsoo Cho, Junyeob Kim, Kang Min Yoo, Sanggoo Lee, Taeuk Kim |  |
| 1530 |  |  [AnyTrans: Translate AnyText in the Image with Large Scale Models](https://doi.org/10.18653/v1/2024.findings-emnlp.137) |  | 0 | This paper introduces AnyText, an all-encompassing framework for the task–In-Image Machine Translation (IIMT), which includes multilingual text translation and text fusion within images. Our framework leverages the strengths of large-scale models, such as Large Language Models (LLMs) and... | Zhipeng Qian, Pei Zhang, Baosong Yang, Kai Fan, Yiwei Ma, Derek F. Wong, Xiaoshuai Sun, Rongrong Ji |  |
| 1531 |  |  [In-Context Former: Lightning-fast Compressing Context for Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.138) |  | 0 | With the rising popularity of Transformer-based large language models (LLMs), reducing their high inference costs has become a significant research focus. One effective approach to mitigate these costs is compressing the long input contexts. Existing methods typically leverage the self-attention... | Xiangfeng Wang, Zaiyi Chen, Tong Xu, Zheyong Xie, Yongyi He, Enhong Chen |  |
| 1532 |  |  [How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States](https://doi.org/10.18653/v1/2024.findings-emnlp.139) |  | 0 | Large language models (LLMs) rely on safety alignment to avoid responding to malicious user inputs. Unfortunately, jailbreak can circumvent safety guardrails, resulting in LLMs generating harmful content and raising concerns about LLM safety. Due to language models with intensive parameters often... | Zhenhong Zhou, Haiyang Yu, Xinghua Zhang, Rongwu Xu, Fei Huang, Yongbin Li |  |
| 1533 |  |  [A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.140) |  | 0 | Few-shot intent detection is a challenging task, particularly in scenarios involving multiple labels and diverse domains. This paper presents a novel prototype learning approach that combines the label synset augmentation and the coarse-to-fine prototype distillation for multi-label few-shot intent... | Xiaotong Zhang, Xinyi Li, Feng Zhang, Zhiyi Wei, Junfeng Liu, Han Liu |  |
| 1534 |  |  [Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study](https://doi.org/10.18653/v1/2024.findings-emnlp.141) |  | 0 | Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs’ capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not... | Keyu Wang, Guilin Qi, Jiaqi Li, Songlin Zhai |  |
| 1535 |  |  [Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration](https://doi.org/10.18653/v1/2024.findings-emnlp.142) |  | 0 | Black-box large language models (LLMs) are increasingly deployed in various environments, making it essential for these models to effectively convey their confidence and uncertainty, especially in high-stakes settings. However, these models often exhibit overconfidence, leading to potential risks... | Jeremy Qin, Bang Liu, Quoc Dinh Nguyen |  |
| 1536 |  |  [EvoR: Evolving Retrieval for Code Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.143) |  | 0 | Recently the retrieval-augmented generation (RAG) has been successfully applied in code generation. However, existing pipelines for retrieval-augmented code generation (RACG) employ static knowledge bases with a single source, limiting the adaptation capabilities of Large Language Models (LLMs) to... | Hongjin Su, Shuyang Jiang, Yuhang Lai, Haoyuan Wu, Boao Shi, Che Liu, Qian Liu, Tao Yu |  |
| 1537 |  |  [Head-wise Shareable Attention for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.144) |  | 0 |  | Zouying Cao, Yifei Yang, Hai Zhao |  |
| 1538 |  |  [Divide-or-Conquer? Which Part Should You Distill Your LLM?](https://doi.org/10.18653/v1/2024.findings-emnlp.145) |  | 0 | Recent methods have demonstrated that Large Language Models (LLMs) can solve reasoning tasks better when they are encouraged to solve subtasks of the main task first. In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving... | Zhuofeng Wu, Richard He Bai, Aonan Zhang, Jiatao Gu, V. G. Vinod Vydiswaran, Navdeep Jaitly, Yizhe Zhang |  |
| 1539 |  |  [Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.146) |  | 0 | Language models (LMs), despite their advances, often depend on spurious correlations, undermining their accuracy and generalizability. This study addresses the overlooked impact of subtler, more complex shortcuts that compromise model reliability beyond oversimplified shortcuts. We introduce a... | Yuqing Zhou, Ruixiang Tang, Ziyu Yao, Ziwei Zhu |  |
| 1540 |  |  [Privacy Evaluation Benchmarks for NLP Models](https://doi.org/10.18653/v1/2024.findings-emnlp.147) |  | 0 | By inducing privacy attacks on NLP models, attackers can obtain sensitive information such as training data and model parameters, etc. Although researchers have studied, in-depth, several kinds of attacks in NLP models, they are non-systematic analyses. It lacks a comprehensive understanding of the... | Wei Huang, Yinggui Wang, Cen Chen |  |
| 1541 |  |  [MM-ChatAlign: A Novel Multimodal Reasoning Framework based on Large Language Models for Entity Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.148) |  | 0 | Multimodal entity alignment (MMEA) integrates multi-source and cross-modal knowledge graphs, a crucial yet challenging task for data-centric applications.Traditional MMEA methods derive the visual embeddings of entities and combine them with other modal data for alignment by embedding similarity... | Xuhui Jiang, Yinghan Shen, Zhichao Shi, Chengjin Xu, Wei Li, Huang Zihe, Jian Guo, Yuanzhuo Wang |  |
| 1542 |  |  [Towards Explainable Computerized Adaptive Testing with Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.149) |  | 0 | As intelligent education evolves, it will provide students with multiple personalized learning services based on their individual abilities. Computerized adaptive testing (CAT) is designed to accurately measure a student’s ability using the least questions, providing an efficient and personalized... | Cheng Cheng, Guanhao Zhao, Zhenya Huang, Yan Zhuang, Zhaoyuan Pan, Qi Liu, Xin Li, Enhong Chen |  |
| 1543 |  |  [MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing](https://doi.org/10.18653/v1/2024.findings-emnlp.150) |  | 0 | Long document question answering (DocQA) aims to answer questions from long documents over 10k words. They usually contain content structures such as sections, sub-sections, and paragraph demarcations. However, the indexing methods of long documents remain under-explored, while existing systems... | Kuicai Dong, DerrickGohXin Deik, Yi Lee, Hao Zhang, Xiangyang Li, Cong Zhang, Yong Liu |  |
| 1544 |  |  [PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.151) |  | 0 | Multimodal language models that process both text and speech have a potential for applications in spoken dialogue systems. However, current models face two major challenges in response generation latency: (1) generating a spoken response requires the prior generation of a written response, and (2)... | Kentaro Mitsui, Koh Mitsuda, Toshiaki Wakatsuki, Yukiya Hono, Kei Sawada |  |
| 1545 |  |  [Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method](https://doi.org/10.18653/v1/2024.findings-emnlp.152) |  | 0 |  | Jiayi Lin, Chenyang Zhang, Haibo Tong, Dongyu Zhang, Qingqing Hong, Bingxuan Hou, Junli Wang |  |
| 1546 |  |  [Are Large Language Models (LLMs) Good Social Predictors?](https://doi.org/10.18653/v1/2024.findings-emnlp.153) |  | 0 | With the recent advancement of Large Language Models (LLMs), efforts have been made to leverage LLMs in crucial social science study methods, including predicting human features of social life such as presidential voting. Existing works suggest that LLMs are capable of generating human-like... | Kaiqi Yang, Hang Li, Hongzhi Wen, TaiQuan Peng, Jiliang Tang, Hui Liu |  |
| 1547 |  |  [Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS](https://doi.org/10.18653/v1/2024.findings-emnlp.154) |  | 0 | This research introduces a comprehensive Bahasa text-to-speech (TTS) dataset and a novel TTS model, EnGen-TTS, designed to enhance the quality and versatility of synthetic speech in the Bahasa language. The dataset, spanning 55.00 hours and 52K audio recordings, integrates diverse textual sources,... | Onkar Susladkar, Vishesh Tripathi, Biddwan Ahmed |  |
| 1548 |  |  [MINERS: Multilingual Language Models as Semantic Retrievers](https://doi.org/10.18653/v1/2024.findings-emnlp.155) |  | 0 | Words have been represented in a high-dimensional vector space that encodes their semantic similarities, enabling downstream applications such as retrieving synonyms, antonyms, and relevant contexts. However, despite recent advances in multilingual language models (LMs), the effectiveness of these... | Genta Indra Winata, Ruochen Zhang, David Ifeoluwa Adelani |  |
| 1549 |  |  [BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?](https://doi.org/10.18653/v1/2024.findings-emnlp.156) |  | 0 | Dense retrieval, which aims to encode the semantic information of arbitrary text into dense vector representations or embeddings, has emerged as an effective and efficient paradigm for text retrieval, consequently becoming an essential component in various natural language processing systems. These... | Zongmeng Zhang, Jinhua Zhu, Wengang Zhou, Xiang Qi, Peng Zhang, Houqiang Li |  |
| 1550 |  |  [McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.157) |  | 0 | Automated question answering (QA) systems are increasingly relying on robust cross-lingual retrieval to identify and utilize information from multilingual sources, ensuring comprehensive and contextually accurate responses. Existing approaches often struggle with consistency across multiple... | Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul, Potsawee Manakul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 1551 |  |  [A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios](https://doi.org/10.18653/v1/2024.findings-emnlp.158) |  | 0 | We evaluate the robustness of several large language models on multiple datasets. Robustness here refers to the relative insensitivity of the model’s answers to meaning-preserving variants of their input. Benchmark datasets are constructed by introducing naturally-occurring, non-malicious... | Samuel Ackerman, Ella Rabinovich, Eitan Farchi, Ateret AnabyTavor |  |
| 1552 |  |  [Learning Musical Representations for Music Performance Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.159) |  | 0 | Music performances are representative scenarios for audio-visual modeling. Unlike common scenarios with sparse audio, music performances continuously involve dense audio signals throughout. While existing multimodal learning methods on the audio-video QA demonstrate impressive capabilities on... | Xingjian Diao, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui |  |
| 1553 |  |  [Transfer Learning for Text Classification via Model Risk Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.160) |  | 0 | It has been well recognized that text classification can be satisfactorily performed by Deep Neural Network (DNN) models, provided that there are sufficient in-distribution training data. However, in the presence of distribution drift, a well trained DNN model may not perform well on a new dataset... | Yujie Sun, Chuyi Fan, Qun Chen |  |
| 1554 |  |  [Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations](https://doi.org/10.18653/v1/2024.findings-emnlp.161) |  | 0 | The robustness of recent Large Language Models (LLMs) has become increasingly crucial as their applicability expands across various domains and real-world applications. Retrieval-Augmented Generation (RAG) is a promising solution for addressing the limitations of LLMs, yet existing studies on the... | Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Taeho Hwang, Jong Park |  |
| 1555 |  |  [Enhancing Temporal Modeling of Video LLMs via Time Gating](https://doi.org/10.18653/v1/2024.findings-emnlp.162) |  | 0 | Video Large Language Models (Video LLMs) have achieved impressive performance on video-and-language tasks, such as video question answering. However, most existing Video LLMs neglect temporal information in video data, leading to struggles with temporal-aware video understanding. To address this... | ZiYuan Hu, Yiwu Zhong, Shijia Huang, Michael R. Lyu, Liwei Wang |  |
| 1556 |  |  [AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations](https://doi.org/10.18653/v1/2024.findings-emnlp.163) |  | 0 | Large Language Models prompting, such as using in-context demonstrations, is a mainstream technique for invoking LLMs to perform high-performance and solid complex reasoning (e.g., mathematical reasoning, commonsense reasoning), and has the potential for further human-machine collaborative... | Zhicheng Yang, Yinya Huang, Jing Xiong, Liang Feng, Xiaodan Liang, Yiwei Wang, Jing Tang |  |
| 1557 |  |  [On the Empirical Complexity of Reasoning and Planning in LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.164) |  | 0 | Chain-of-thought (CoT), tree-of-thought (ToT), and related techniques work surprisingly well in practice for some complex reasoning tasks with Large Language Models (LLMs), but why? This work seeks the underlying reasons by conducting experimental case studies and linking the performance benefits... | Liwei Kang, Zirui Zhao, David Hsu, Wee Sun Lee |  |
| 1558 |  |  [Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training](https://doi.org/10.18653/v1/2024.findings-emnlp.165) |  | 0 | Diffusion models have shown impressive performance in many domains. However, the model’s capability to follow natural language instructions (e.g., spatial relationships between objects, generating complex scenes) is still unsatisfactory. In this work, we propose Iterative Prompt Relabeling (IPR), a... | Xinyan Chen, Jiaxin Ge, Tianjun Zhang, Jiaming Liu, Shanghang Zhang |  |
| 1559 |  |  [Are modern neural ASR architectures robust for polysynthetic languages?](https://doi.org/10.18653/v1/2024.findings-emnlp.166) |  | 0 | Automatic speech recognition (ASR) technology is frequently proposed as a means of preservation and documentation of endangered languages, with promising results thus far. Among the endangered languages spoken today, a significant number exhibit complex morphology. The models employed in... | Éric Le Ferrand, Zoey Liu, Antti Arppe, Emily Prud'hommeaux |  |
| 1560 |  |  [A Notion of Complexity for Theory of Mind via Discrete World Models](https://doi.org/10.18653/v1/2024.findings-emnlp.167) |  | 0 | Theory of Mind (ToM) can be used to assess the capabilities of Large Language Models (LLMs) in complex scenarios where social reasoning is required. While the research community has proposed many ToM benchmarks, their hardness varies greatly, and their complexity is not well defined. This work... | X. Angelo Huang, Emanuele La Malfa, Samuele Marro, Andrea Asperti, Anthony G. Cohn, Michael J. Wooldridge |  |
| 1561 |  |  [Learning Dynamic Multi-attribute Interest for Personalized Product Search](https://doi.org/10.18653/v1/2024.findings-emnlp.168) |  | 0 | Personalized product search aims to learn personalized preferences from search logs and adjust the ranking lists returned by engines. Previous studies have extensively explored excavating valuable features to build accurate interest profiles. However, they overlook that the user’s attention varies... | Yutong Bai, Zhicheng Dou, JiRong Wen |  |
| 1562 |  |  [Evaluating Automatic Metrics with Incremental Machine Translation Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.169) |  | 0 | We introduce a dataset comprising commercial machine translations, gathered weekly over six years across 12 translation directions. Since human A/B testing is commonly used, we assume commercial systems improve over time, which enables us to evaluate machine translation (MT) metrics based on their... | Guojun Wu, Shay B. Cohen, Rico Sennrich |  |
| 1563 |  |  [LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble](https://doi.org/10.18653/v1/2024.findings-emnlp.170) |  | 0 | Employing large language models (LLMs) to enable embodied agents has become popular, yet it presents several limitations in practice. In this work, rather than using LLMs directly as agents, we explore their use as tools for embodied agent learning. Specifically, to train separate agents via... | Yujeong Lee, Sangwoo Shin, WeiJin Park, Honguk Woo |  |
| 1564 |  |  [Self-Renewal Prompt Optimizing with Implicit Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.171) |  | 0 | The effectiveness of Large Language Models (LLMs) relies on their capacity to understand instructions and generate human-like responses. However, aligning LLMs with complex human preferences remains a significant challenge due to the potential misinterpretation of user prompts. Current methods for... | Zihan Liang, Ben Chen, Zhuoran Ran, Zihan Wang, Huangyu Dai, Yufei Ma, Dehong Gao, Xiaoyan Cai, Libin Yang |  |
| 1565 |  |  [Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.172) |  | 0 | The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users’ needs due to their inherent difficulty in accurately... | Jiaming Li, Lei Zhang, Yunshui Li, Ziqiang Liu, Yuelin Bai, Run Luo, Longze Chen, Min Yang |  |
| 1566 |  |  [Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling](https://doi.org/10.18653/v1/2024.findings-emnlp.173) |  | 0 | We present GEST – a new manually created dataset designed to measure gender-stereotypical reasoning in language models and machine translation systems. GEST contains samples for 16 gender stereotypes about men and women (e.g., Women are beautiful, Men are leaders) that are compatible with the... | Matús Pikuliak, Stefan Oresko, Andrea Hrckova, Marián Simko |  |
| 1567 |  |  [Recent Trends in Linear Text Segmentation: A Survey](https://doi.org/10.18653/v1/2024.findings-emnlp.174) |  | 0 | Linear Text Segmentation is the task of automatically tagging text documents with topic shifts, i.e. the places in the text where the topics change. A well-established area of research in Natural Language Processing, drawing from well-understood concepts in linguistic and computational linguistic... | Iacopo Ghinassi, Lin Wang, Chris Newell, Matthew Purver |  |
| 1568 |  |  [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.175) |  | 0 | Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equipped with text recognition ability but lack general structure understanding... | Anwen Hu, Haiyang Xu, Jiabo Ye, Ming Yan, Liang Zhang, Bo Zhang, Ji Zhang, Qin Jin, Fei Huang, Jingren Zhou |  |
| 1569 |  |  [Exploring Question Guidance and Answer Calibration for Visually Grounded Video Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.176) |  | 0 | Video Question Answering (VideoQA) tasks require not only correct answers but also visual evidence. The “localize-then-answer” strategy, while enhancing accuracy and interpretability, faces challenges due to the lack of temporal localization labels in VideoQA datasets. Existing methods often train... | Yuanxing Xu, Yuting Wei, Shuai Zhong, Xinming Chen, Jinsheng Qi, Bin Wu |  |
| 1570 |  |  [LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation](https://doi.org/10.18653/v1/2024.findings-emnlp.177) |  | 0 | In this paper, we study parameter-efficient fine-tuning methods for large pre-trained models. Specifically, we improve LoRA approaches to alleviate the performance loss from the constrained adapter by introducing a non-linear transformation (call it LoRAN). For a better adaptation, we also design a... | Yinqiao Li, Linqi Song, Hanxu Hou |  |
| 1571 |  |  [Large Language Models are Limited in Out-of-Context Knowledge Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.178) |  | 0 | Large Language Models (LLMs) possess extensive knowledge and strong capabilities in performing in-context reasoning. However, previous work challenges their out-of-context reasoning ability, i.e., the ability to infer information from their training data, instead of from the context or prompt. This... | Peng Hu, Changjiang Gao, Ruiqi Gao, Jiajun Chen, Shujian Huang |  |
| 1572 |  |  [BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.179) |  | 0 | Adapting pretrained models to downstream tasks is important in practical applications. Existing frameworks adapt from an initial pretrained model to each downstream task directly, but ignore the sequential nature of the downstream tasks and their feedback effect on the pretrained model. In this... | Hang Zeng, Chaoyue Niu, Fan Wu, Shaojie Tang, Leihao Pei, Chengfei Lv, Guihai Chen |  |
| 1573 |  |  [Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.180) |  | 0 | Recently, few-shot Named Entity Recognition (NER) has attracted significant attention due to the high cost of obtaining high-quality labeled data. Decomposition-based methods have demonstrated remarkable performance on this task, which initially train a type-independent span detector and... | Wei Chen, Lili Zhao, Zhi Zheng, Tong Xu, Yang Wang, Enhong Chen |  |
| 1574 |  |  [Scaling Sentence Embeddings with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.181) |  | 0 | Large Language Models (LLMs) have recently gained significant interest due to their impressive results in various natural language tasks. However, their application to sentence embeddings is still under active research. In this work, we introduce PromptEOL, a simple and efficient method designed to... | Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, Fuzhen Zhuang |  |
| 1575 |  |  [Exploring the Relationship between In-Context Learning and Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.182) |  | 0 | In-Context Learning (ICL) and Instruction Tuning (IT) are two primary paradigms of adopting Large Language Models (LLMs) to downstream applications. However, they are significantly different. In ICL, a set of demonstrations is provided at the inference time, but the LLM’s parameters are not... | Hanyu Duan, Yixuan Tang, Yi Yang, Ahmed Abbasi, Kar Yan Tam |  |
| 1576 |  |  [Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding](https://doi.org/10.18653/v1/2024.findings-emnlp.183) |  | 0 | Multimodal Named Entity Recognition and Grounding (MNERG) aims to extract paired textual and visual entities from texts and images. It has been well explored through a two-step paradigm: initially identifying potential visual entities using object detection methods and then aligning the extracted... | Ziqi Wang, Chen Zhu, Zhi Zheng, Xinhang Li, Tong Xu, Yongyi He, Qi Liu, Ying Yu, Enhong Chen |  |
| 1577 |  |  [JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.184) |  | 0 | The use of Large Language Models (LLMs) in hiring has led to legislative actions to protect vulnerable demographic groups. This paper presents a novel framework for benchmarking hierarchical gender hiring bias in Large Language Models (LLMs) for resume scoring, revealing significant issues of... | Ze Wang, Zekun Wu, Xin Guan, Michael Thaler, Adriano S. Koshiyama, Skylar Lu, Sachin Beepath, Ediz Ertekin Jr., María PérezOrtiz |  |
| 1578 |  |  [Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.185) |  | 0 | For crosslingual conversation and trade, Neural Machine Translation (NMT) is pivotal yet faces persistent challenges with monotony and repetition in generated content. Traditional solutions that rely on penalizing text redundancy or token reoccurrence have shown limited efficacy, particularly for... | Huangyu Dai, Ben Chen, Kaidi Chen, Ying Han, Zihan Liang, Wen Jiang |  |
| 1579 |  |  [A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles](https://doi.org/10.18653/v1/2024.findings-emnlp.186) |  | 0 |  | EunKyoung Rosa Lee, Sathvik Nair, Naomi Feldman |  |
| 1580 |  |  [Tending Towards Stability: Convergence Challenges in Small Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.187) |  | 0 | Increasing the number of parameters in language models is a common strategy to enhance their performance. However, smaller language models remain valuable due to their lower operational costs. Despite their advantages, smaller models frequently underperform compared to their larger counterparts,... | Richard Diehl Martinez, Pietro Lesci, Paula Buttery |  |
| 1581 |  |  [Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming](https://doi.org/10.18653/v1/2024.findings-emnlp.188) |  | 0 | Large Language Models (LLMs) have gained increasing attention for their remarkable capacity, alongside concerns about safety arising from their potential to produce harmful content. Red teaming aims to find prompts that could elicit harmful responses from LLMs, and is essential to discover and... | Rui Li, Peiyi Wang, Jingyuan Ma, Di Zhang, Lei Sha, Zhifang Sui |  |
| 1582 |  |  [Modeling News Interactions and Influence for Financial Market Prediction](https://doi.org/10.18653/v1/2024.findings-emnlp.189) |  | 0 | The diffusion of financial news into market prices is a complex process, making it challenging to evaluate the connections between news events and market movements. This paper introduces FININ (Financial Interconnected News Influence Network), a novel market prediction model that captures not only... | Mengyu Wang, Shay B. Cohen, Tiejun Ma |  |
| 1583 |  |  [Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-emnlp.190) |  | 0 | Large language models (LLMs) have significantly advanced various natural language processing tasks, but deploying them remains computationally expensive. Knowledge distillation (KD) is a promising solution, enabling the transfer of capabilities from larger teacher LLMs to more compact student... | Yuhang Zhou, Jing Zhu, Paiheng Xu, Xiaoyu Liu, Xiyao Wang, Danai Koutra, Wei Ai, Furong Huang |  |
| 1584 |  |  [Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.191) |  | 0 | Natural language is a powerful complementary modality of communication for data visualizations, such as bar and line charts. To facilitate chart-based reasoning using natural language, various downstream tasks have been introduced recently such as chart question answering, chart summarization, and... | Mohammed Saidul Islam, Raian Rahman, Ahmed Masry, Md. Tahmid Rahman Laskar, Mir Tafseer Nayeem, Enamul Hoque |  |
| 1585 |  |  [HoneyComb: A Flexible LLM-Based Agent System for Materials Science](https://doi.org/10.18653/v1/2024.findings-emnlp.192) |  | 0 | The emergence of specialized large language models (LLMs) has shown promise in addressing complex tasks in materials science. Many LLMs, however, often struggle with the distinct complexities of materials science tasks, such as computational challenges, and rely heavily on outdated implicit... | Huan Zhang, Yu Song, Ziyu Hou, Santiago Miret, Bang Liu |  |
| 1586 |  |  [Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter](https://doi.org/10.18653/v1/2024.findings-emnlp.193) |  | 0 | Social media is recognized as an important source for deriving insights into public opinion dynamics and social impacts due to the vast textual data generated daily and the ‘unconstrained’ behavior of people interacting on these platforms. However, such analyses prove challenging due to the... | Zeqiang Wang, Jiageng Wu, Yuqi Wang, Wei Xjtlu, Jie Yang, Nishanth Sastry, Jon Johnson, Suparna De |  |
| 1587 |  |  [Divide and Conquer: Legal Concept-guided Criminal Court View Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.194) |  | 0 | The Criminal Court View Generation task aims to produce explanations that inform judicial decisions. This necessitates a nuanced understanding of diverse legal concepts, such as Recidivism, Confess, and Robbery, which often coexist within cases, complicating holistic analysis. However, existing... | Qi Xu, Xiao Wei, Hang Yu, Qian Liu, Hao Fei |  |
| 1588 |  |  [Data Diversity Matters for Robust Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.195) |  | 0 | Recent works have shown that by curating high quality and diverse instruction tuning datasets, we can significantly improve instruction-following capabilities. However, creating such datasets is difficult and most works rely on manual curation or proprietary language models. Automatic data curation... | Alexander Bukharin, Shiyang Li, Zhengyang Wang, Jingfeng Yang, Bing Yin, Xian Li, Chao Zhang, Tuo Zhao, Haoming Jiang |  |
| 1589 |  |  [GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion](https://doi.org/10.18653/v1/2024.findings-emnlp.196) |  | 0 | Text-to-Speech (TTS) systems have made significant strides, enabling the generation of speech from grapheme sequences. However, for low-resource languages, these models still struggle to produce natural and intelligible speech. Grapheme-to-Phoneme conversion (G2P) addresses this challenge by... | Elnaz Rahmati, Hossein Sameti |  |
| 1590 |  |  [Characterizing LLM Abstention Behavior in Science QA with Context Perturbations](https://doi.org/10.18653/v1/2024.findings-emnlp.197) |  | 0 | The correct model response in the face of uncertainty is to abstain from answering a question so as not to mislead the user. In this work, we study the ability of LLMs to abstain from answering context-dependent science questions when provided insufficient or incorrect context. We probe model... | Bingbing Wen, Bill Howe, Lucy Lu Wang |  |
| 1591 |  |  [Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.198) |  | 0 | Questions involving commonsense reasoning about everyday situations often admit many possible or plausible answers. In contrast, multiple-choice question (MCQ) benchmarks for commonsense reasoning require a hard selection of a single correct answer, which, in principle, should represent the most... | Shramay Palta, Nishant Balepur, Peter Rankel, Sarah Wiegreffe, Marine Carpuat, Rachel Rudinger |  |
| 1592 |  |  [Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation](https://doi.org/10.18653/v1/2024.findings-emnlp.199) |  | 0 | In subjective NLP tasks, where a single ground truth does not exist, the inclusion of diverse annotators becomes crucial as their unique perspectives significantly influence the annotations. In realistic scenarios, the annotation budget often becomes the main determinant of the number of... | Preni Golazizian, Alireza Salkhordeh Ziabari, Ali Omrani, Morteza Dehghani |  |
| 1593 |  |  [EDEN: Empathetic Dialogues for English Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.200) |  | 0 | Dialogue systems have been used as conversation partners in English learning, but few have studied whether these systems improve learning outcomes. Student passion and perseverance, or grit, has been associated with language learning success. Recent work establishes that as students perceive their... | Siyan Li, Teresa Shao, Zhou Yu, Julia Hirschberg |  |
| 1594 |  |  [Language Models Still Struggle to Zero-shot Reason about Time Series](https://doi.org/10.18653/v1/2024.findings-emnlp.201) |  | 0 | Time series are critical for decision-making in fields like finance and healthcare. Their importance has driven a recent influx of works passing time series into language models, leading to non-trivial forecasting on some datasets. But it remains unknown whether non-trivial forecasting implies that... | Mike A. Merrill, Mingtian Tan, Vinayak Gupta, Thomas Hartvigsen, Tim Althoff |  |
| 1595 |  |  [Enhancing Agent Learning through World Dynamics Modeling](https://doi.org/10.18653/v1/2024.findings-emnlp.202) |  | 0 | Large language models (LLMs), trained on vast amounts of internet data, have developed a broad understanding of the world, enhancing the decision-making capabilities of embodied agents. This success is largely due to the comprehensive and in-depth domain knowledge within their training datasets.... | Zhiyuan Sun, Haochen Shi, MarcAlexandre Côté, Glen Berseth, Xingdi Yuan, Bang Liu |  |
| 1596 |  |  [NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization](https://doi.org/10.18653/v1/2024.findings-emnlp.203) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in parsing textual data and generating code. However, their performance in tasks involving tabular data, especially those requiring symbolic reasoning, faces challenges due to the structural variance and... | Md Mahadi Hasan Nahid, Davood Rafiei |  |
| 1597 |  |  [Zero-Resource Hallucination Prevention for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.204) |  | 0 | The prevalent use of large language models (LLMs) in various domains has drawn attention to the issue of “hallucination”, which refers to instances where LLMs generate factually inaccurate or ungrounded information. Existing techniques usually identify hallucinations post-generation that cannot... | Junyu Luo, Cao Xiao, Fenglong Ma |  |
| 1598 |  |  [Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals](https://doi.org/10.18653/v1/2024.findings-emnlp.205) |  | 0 | The inevitable appearance of spurious correlations in training datasets hurts the generalization of NLP models on unseen data. Previous work has found that datasets with paired inputs are prone to correlations between a specific part of the input (e.g., the hypothesis in NLI) and the label;... | Yanai Elazar, Bhargavi Paranjape, Hao Peng, Sarah Wiegreffe, Khyathi Raghavi Chandu, Vivek Srikumar, Sameer Singh, Noah A. Smith |  |
| 1599 |  |  [LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.206) |  | 0 | Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT... | Zifan Xu, Haozhu Wang, Dmitriy Bespalov, Xian Wu, Peter Stone, Yanjun Qi |  |
| 1600 |  |  [TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning](https://doi.org/10.18653/v1/2024.findings-emnlp.207) |  | 0 | Zero-shot inference, where pre-trained models perform tasks without specific training data, is an exciting emergent ability of large models like CLIP. Although there has been considerable exploration into enhancing zero-shot abilities in image captioning (IC) for popular datasets such as MSCOCO and... | Joshua Feinglass, Yezhou Yang |  |
| 1601 |  |  [The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases](https://doi.org/10.18653/v1/2024.findings-emnlp.208) |  | 0 | In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model’s predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model’s certainty is low, or where the consequences... | T. Y. S. S. Santosh, Irtiza Chowdhury, Shanshan Xu, Matthias Grabmair |  |
| 1602 |  |  [InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration](https://doi.org/10.18653/v1/2024.findings-emnlp.209) |  | 0 | Large Language Models (LLMs) have achieved exceptional capabilities in open generation across various domains, yet they encounter difficulties with tasks that require intensive knowledge. To address these challenges, methods for integrating knowledge have been developed, which augment LLMs with... | Fali Wang, Runxue Bao, Suhang Wang, Wenchao Yu, Yanchi Liu, Wei Cheng, Haifeng Chen |  |
| 1603 |  |  [SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization](https://doi.org/10.18653/v1/2024.findings-emnlp.210) |  | 0 | Summarization is an important application of Large Language Models (LLMs). When judging the quality of a summary, factual consistency holds a significant weight. Despite numerous efforts dedicated to building factual inconsistency detectors, the exploration of explanability remains limited among... | Ge Luo, Weisi Fan, Miaoran Li, Guoruizhe Sun, Runlong Zhang, Chenyu Xu, Forrest Sheng Bao |  |
| 1604 |  |  [Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model](https://doi.org/10.18653/v1/2024.findings-emnlp.211) |  | 0 | Despite advancements in text-to-image models, generating images that precisely align with textual descriptions remains challenging due to misalignment in training data. In this paper, we analyze the critical role of caption precision and recall in text-to-image model training. Our analysis of... | Sheng Cheng, Maitreya Patel, Yezhou Yang |  |
| 1605 |  |  [Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.212) |  | 0 | Chain-of-Thought (CoT) prompting has been shown to enhance the multi-step reasoning capabilities of Large Language Models (LLMs). However, debates persist about whether LLMs exhibit \*abstract generalization\* or rely on \*shallow heuristics\* when given CoT prompts. To understand the factors... | Akshara Prabhakar, Thomas L. Griffiths, R. Thomas McCoy |  |
| 1606 |  |  [Self-contradictory reasoning evaluation and detection](https://doi.org/10.18653/v1/2024.findings-emnlp.213) |  | 0 | In a plethora of recent work, large language models (LLMs) demonstrated impressive reasoning ability, but many proposed downstream reasoning tasks only focus on performance-wise evaluation. Two fundamental questions persist: 1) how consistent is the reasoning, and 2) can models detect unreliable... | Ziyi Liu, Soumya Sanyal, Isabelle Lee, Yongkang Du, Rahul Gupta, Yang Liu, Jieyu Zhao |  |
| 1607 |  |  [Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases](https://doi.org/10.18653/v1/2024.findings-emnlp.214) |  | 0 | Inspired by the legal doctrine of stare decisis, which leverages precedents (prior cases) for informed decision-making, we explore methods to integrate them into LJP models. To facilitate precedent retrieval, we train a retriever with a fine-grained relevance signal based on the overlap ratio of... | T. Y. S. S. Santosh, Mohamed Hesham Elganayni, Stanislaw Sójka, Matthias Grabmair |  |
| 1608 |  |  [Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification](https://doi.org/10.18653/v1/2024.findings-emnlp.215) |  | 0 | Automatic factuality verification of large language model (LLM) generations is becoming more and more widely used to combat hallucinations. A major point of tension in the literature is the granularity of this fact-checking: larger chunks of text are hard to fact-check, but more atomic facts like... | Anisha Gunjal, Greg Durrett |  |
| 1609 |  |  [MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension](https://doi.org/10.18653/v1/2024.findings-emnlp.216) |  | 0 | Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information. Traditional evaluations fail to assess a model’s factual correctness. To rectify this absence, we present MoleculeQA, a novel question answering (QA)... | Xingyu Lu, He Cao, Zijing Liu, Shengyuan Bai, Leqing Chen, Yuan Yao, HaiTao Zheng, Yu Li |  |
| 1610 |  |  [Sanitizing Large Language Models in Bug Detection with Data-Flow](https://doi.org/10.18653/v1/2024.findings-emnlp.217) |  | 0 | Large language models (LLMs) show potential in code reasoning tasks, facilitating the customization of detecting bugs in software development. However, the hallucination effect can significantly compromise the reliability of bug reports. This work formulates a new schema of bug detection and... | Chengpeng Wang, Wuqi Zhang, Zian Su, Xiangzhe Xu, Xiangyu Zhang |  |
| 1611 |  |  [Scaling Behavior for Large Language Models regarding Numeral Systems: An Example using Pythia](https://doi.org/10.18653/v1/2024.findings-emnlp.218) |  | 0 |  | Zhejian Zhou, Jiayu Wang, Dahua Lin, Kai Chen |  |
| 1612 |  |  [When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context](https://doi.org/10.18653/v1/2024.findings-emnlp.219) |  | 0 | We introduce a neural architecture finetuned for the task of scenario context generation: The relevant location and time of an event or entity mentioned in text. Contextualizing information extraction helps to scope the validity of automated finings when aggregating them as knowledge graphs. Our... | Enrique NoriegaAtala, Robert Vacareanu, Salena Torres Ashton, Adarsh Pyarelal, Clayton T. Morrison, Mihai Surdeanu |  |
| 1613 |  |  [Enhancing Incremental Summarization with Structured Representations](https://doi.org/10.18653/v1/2024.findings-emnlp.220) |  | 0 | Large language models (LLMs) often struggle with processing extensive input contexts, which can lead to redundant, inaccurate, or incoherent summaries. Recent methods have used unstructured memory to incrementally process these contexts, but they still suffer from information overload due to the... | Eunjeong Hwang, Yichao Zhou, James B. Wendt, Beliz Gunel, Nguyen Vo, Jing Xie, Sandeep Tata |  |
| 1614 |  |  [Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.221) |  | 0 | Recent advancements in general-purpose or domain-specific multimodal large language models (LLMs) have witnessed remarkable progress for medical decision-making. However, they are designated for specific classification or generative tasks, and require model training or finetuning on large-scale... | Songtao Jiang, Tuo Zheng, Yan Zhang, Yeying Jin, Li Yuan, Zuozhu Liu |  |
| 1615 |  |  [Multiple Knowledge-Enhanced Interactive Graph Network for Multimodal Conversational Emotion Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.222) |  | 0 | Multimodal Emotion Recognition in Conversations (ERC) aims to identify emotions in conversational videos. Current efforts focus on modeling both context-sensitive and speaker-sensitive dependencies and multimodal fusion. Despite the progress, models in Multimodal ERC (MERC) still struggle due to a... | Geng Tu, Jun Wang, Zhenyu Li, Shiwei Chen, Bin Liang, Xi Zeng, Min Yang, Ruifeng Xu |  |
| 1616 |  |  [AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.223) |  | 0 | Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP... | Jia Fu, Xiaoting Qin, Fangkai Yang, Lu Wang, Jue Zhang, Qingwei Lin, Yubo Chen, Dongmei Zhang, Saravan Rajmohan, Qi Zhang |  |
| 1617 |  |  [Unleashing the Potential of Large Language Models through Spectral Modulation](https://doi.org/10.18653/v1/2024.findings-emnlp.224) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, garnering significant attention from both academia and industry. However, enhancing the performance of LLMs typically requires scaling up model sizes or fine-tuning with additional datasets, which results... | Peng Sun, Yao Zhu, Yunjian Zhang, Xiu Yan, Zizhe Wang, Xiangyang Ji |  |
| 1618 |  |  [LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization](https://doi.org/10.18653/v1/2024.findings-emnlp.225) |  | 0 | Pretrained language models (PLMs) have shown remarkable generalization toward multiple tasks and languages. Nonetheless, the generalization of PLMs towards unseen languages is poor, resulting in significantly worse language performance, or even generating nonsensical responses that are comparable... | Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Genta Indra Winata, Ayu Purwarianti, Alham Fikri Aji |  |
| 1619 |  |  [QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware](https://doi.org/10.18653/v1/2024.findings-emnlp.226) |  | 0 | Extreme multi-label text classification (EMTC) involves predicting multiple labels from a vast pool of candidates based on a user’s textual query. While traditional BERT-based methods have shown limited success, large language models (LLMs) have brought new possibilities. It is promising to... | Chuang Zhou, Junnan Dong, Xiao Huang, Zirui Liu, Kaixiong Zhou, Zhaozhuo Xu |  |
| 1620 |  |  [UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.227) |  | 0 | Existing benchmarks for summarization quality evaluation often lack diverse input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and struggle with subjective and coarse-grained annotation schemes. To address these shortcomings, we create UniSumEval benchmark, which extends... | Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song |  |
| 1621 |  |  [Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data](https://doi.org/10.18653/v1/2024.findings-emnlp.228) |  | 0 | Mathematical question answering over long-form documents is challenging across domains like finance or Wikipedia due to the abundance of candidate arguments within evidence, which complicates recognizing proper arguments for mathematical reasoning and poses hard to learning. In this paper, we... | Jinsu Lim, Yechan Hwang, YoungJun Lee, HoJin Choi |  |
| 1622 |  |  [Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check](https://doi.org/10.18653/v1/2024.findings-emnlp.229) |  | 0 | Chinese Spelling Check (CSC) aims to detect and correct potentially misspelled characters in Chinese sentences. Naturally, it involves the detection and correction subtasks, which interact with each other dynamically. Such interactions are bi-directional, i.e., the detection result would help... | Haiming Wu, Hanqing Zhang, Richeng Xuan, Dawei Song |  |
| 1623 |  |  [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.230) |  | 0 | Developing Large Language Models (LLMs) with robust long-context capabilities has been the recent research focus, resulting in the emergence of long-context LLMs proficient in Chinese. However, the evaluation of these models remains underdeveloped due to a lack of benchmarks. To address this gap,... | Zexuan Qiu, Jingjing Li, Shijue Huang, Xiaoqi Jiao, Wanjun Zhong, Irwin King |  |
| 1624 |  |  [Guided Profile Generation Improves Personalization with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.231) |  | 0 | In modern commercial systems, including Recommendation, Ranking, and E-Commerce platforms, there is a trend towards improving customer experiences by incorporating Personalization context as input into Large Language Models (LLM). However, LLMs often struggle to effectively parse and utilize sparse... | Jiarui Zhang |  |
| 1625 |  |  [mABC: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture](https://doi.org/10.18653/v1/2024.findings-emnlp.232) |  | 0 | Root cause analysis (RCA) in Micro-services architecture (MSA) with escalating complexity encounters complex challenges in maintaining system stability and efficiency due to fault propagation and circular dependencies among nodes. Diverse root cause analysis faults require multi-agents with diverse... | Wei Zhang, Hongcheng Guo, Jian Yang, Zhoujin Tian, Yi Zhang, Chaoran Yan, Zhoujun Li, Tongliang Li, Xu Shi, Liangfan Zheng, Bo Zhang |  |
| 1626 |  |  [Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens](https://doi.org/10.18653/v1/2024.findings-emnlp.233) |  | 0 | Large language models (LLMs) have shown promising efficacy across various tasks, becoming powerful tools in numerous aspects of human life. However, Transformer-based LLMs suffer a performance degradation when modeling long-term contexts due to they discard some information to reduce computational... | Weiyao Luo, Suncong Zheng, Heming Xia, Weikang Wang, Yan Lei, Tianyu Liu, Shuang Chen, Zhifang Sui |  |
| 1627 |  |  [Reward Modeling Requires Automatic Adjustment Based on Data Quality](https://doi.org/10.18653/v1/2024.findings-emnlp.234) |  | 0 | In Reinforcement Learning from Human Feedback (RLHF), the reward model plays a crucial role in aligning language model outputs with human values. The human preference data used to train the reward model consists of a prompt and a response pair, with humans annotating which response better aligns... | Binghai Wang, Rui Zheng, Lu Chen, Zhiheng Xi, Wei Shen, Yuhao Zhou, Dong Yan, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1628 |  |  [LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference](https://doi.org/10.18653/v1/2024.findings-emnlp.235) |  | 0 | Long-context Multimodal Large Language Models (MLLMs) demand substantial computational resources for inference as the growth of their multimodal Key-Value (KV) cache, in response to increasing input lengths, challenges memory and time efficiency. Unlike single-modality LLMs that manage only textual... | Zhongwei Wan, Ziang Wu, Che Liu, Jinfa Huang, Zhihong Zhu, Peng Jin, Longyue Wang, Li Yuan |  |
| 1629 |  |  [The Fall of ROME: Understanding the Collapse of LLMs in Model Editing](https://doi.org/10.18653/v1/2024.findings-emnlp.236) |  | 0 | Despite significant progress in model editing methods, their application in real-world scenarios remains challenging as they often cause large language models (LLMs) to collapse. Among them, ROME is particularly concerning, as it could disrupt LLMs with only a single edit. In this paper, we study... | Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Du Su, Dawei Yin, Huawei Shen |  |
| 1630 |  |  [OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.237) |  | 0 | Despite the recent advancements in Large Language Models (LLMs), which have significantly enhanced the generative capabilities for various NLP tasks, LLMs still face limitations in directly handling retrieval tasks. However, many practical applications demand the seamless integration of both... | Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang, Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang |  |
| 1631 |  |  [Self-Evolution Fine-Tuning for Policy Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.238) |  | 0 | The alignment of large language models (LLMs) is crucial not only for unlocking their potential in specific tasks but also for ensuring that responses meet human expectations and adhere to safety and ethical principles. To address the challenges of current alignment methodologies, we introduce... | Ruijun Chen, Jiehao Liang, Shiping Gao, Fanqi Wan, Xiaojun Quan |  |
| 1632 |  |  [Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.239) |  | 0 | Fine-tuning and in-context learning (ICL) are two prevalent methods in imbuing large language models with task-specific knowledge. It is commonly believed that fine-tuning can surpass ICL given sufficient training samples as it allows the model to adjust its internal parameters based on the data.... | Qingyu Yin, Xuzheng He, Chak Tou Leong, Fan Wang, Yanzhao Yan, Xiaoyu Shen, Qiang Zhang |  |
| 1633 |  |  [Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.240) |  | 0 | In recent years, large language models (LLMs) have driven advances in natural language processing. Still, their growing scale has increased the computational burden, necessitating a balance between efficiency and performance. Low-rank compression, a promising technique, reduces non-essential... | Yixin Ji, Yang Xiang, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Kehai Chen, Min Zhang |  |
| 1634 |  |  [Emosical: An Emotion-Annotated Musical Theatre Dataset](https://doi.org/10.18653/v1/2024.findings-emnlp.241) |  | 0 | This paper presents Emosical, a multimodal open-source dataset of musical films. Emosical comprises video, vocal audio, text, and character identity paired samples with annotated emotion tags. Emosical provides rich emotion annotations for each sample by inferring the background story of the... | Hayoon Kim, Ahyeon Choi, Sungho Lee, Hyun Jung, Kyogu Lee |  |
| 1635 |  |  [Inference-Time Language Model Alignment via Integrated Value Guidance](https://doi.org/10.18653/v1/2024.findings-emnlp.242) |  | 0 | Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce \*\*Integrated Value Guidance (IVG)\*\*, a method that uses implicit and explicit value functions to guide language model... | Zhixuan Liu, Zhanhui Zhou, Yuanfu Wang, Chao Yang, Yu Qiao |  |
| 1636 |  |  [TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.243) |  | 0 | Classical Chinese is a gateway to the rich heritage and wisdom of ancient China, yet its complexities pose formidable comprehension barriers for most modern people without specialized knowledge. While Large Language Models (LLMs) have shown remarkable capabilities in Natural Language Processing... | Jiahuan Cao, Dezhi Peng, Peirong Zhang, Yongxin Shi, Yang Liu, Kai Ding, Lianwen Jin |  |
| 1637 |  |  [NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding](https://doi.org/10.18653/v1/2024.findings-emnlp.244) |  | 0 | Large Language Models (LLMs) have sparked substantial interest and debate concerning their potential emergence of Theory of Mind (ToM) ability. Theory of mind evaluations currently focuses on testing models using machine-generated data or game settings prone to shortcuts and spurious correlations,... | Chunkit Chan, Cheng Jiayang, Yauwai Yim, Zheye Deng, Wei Fan, Haoran Li, Xin Liu, Hongming Zhang, Weiqi Wang, Yangqiu Song |  |
| 1638 |  |  [A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect](https://doi.org/10.18653/v1/2024.findings-emnlp.245) |  | 0 | Traditional VQA models are inherently vulnerable to language bias, resulting in a significant performance drop when encountering out-of-distribution datasets. The conventional VQA models suffer from language bias that indicates a spurious correlation between textual questions and answers. Given the... | Lingyun Song, Chengkun Yang, Xuanyu Li, Xuequn Shang |  |
| 1639 |  |  [PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain](https://doi.org/10.18653/v1/2024.findings-emnlp.246) |  | 0 | Generating well-structured long music compositions, spanning several minutes, remains a challenge due to inefficient representation and the lack of structured representation. In this paper, we propose PyramidCodec, a hierarchical discrete representation of audio, for long audio-domain music... | Jianyi Chen, Zheqi Dai, Zhen Ye, Xu Tan, Qifeng Liu, Yike Guo, Wei Xue |  |
| 1640 |  |  [Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations](https://doi.org/10.18653/v1/2024.findings-emnlp.247) |  | 0 | With the aid of large language models, current conversational recommender system (CRS) has gaining strong abilities to persuade users to accept recommended items. While these CRSs are highly persuasive, they can mislead users by incorporating incredible information in their explanations, ultimately... | Peixin Qin, Chen Huang, Yang Deng, Wenqiang Lei, TatSeng Chua |  |
| 1641 |  |  [Revisiting Query Variation Robustness of Transformer Models](https://doi.org/10.18653/v1/2024.findings-emnlp.248) |  | 0 | The most commonly used transformers for retrieval at present, BERT and T5, have been shown not to be robust to query variations such as typos or paraphrases. Although this is an important prerequisite for their practicality, this problem has hardly been investigated. More recent large language... | Tim Hagen, Harrisen Scells, Martin Potthast |  |
| 1642 |  |  [Revisiting Catastrophic Forgetting in Large Language Model Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.249) |  | 0 | Catastrophic Forgetting (CF) means models forgetting previously acquired knowledge when learning new data. It compromises the effectiveness of large language models (LLMs) during fine-tuning, yet the underlying causes have not been thoroughly investigated. This paper takes the first step to reveal... | Hongyu Li, Liang Ding, Meng Fang, Dacheng Tao |  |
| 1643 |  |  [M5 - A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.250) |  | 0 | Since the release of ChatGPT, the field of Natural Language Processing has experienced rapid advancements, particularly in Large Language Models (LLMs) and their multimodal counterparts, Large Multimodal Models (LMMs). Despite their impressive capabilities, LLMs often exhibit significant... | Florian Schneider, Sunayana Sitaram |  |
| 1644 |  |  [Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.251) |  | 0 | Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a... | Flor Miriam Plaza del Arco, Amanda Cercas Curry, Susanna Paoli, Alba Cercas Curry, Dirk Hovy |  |
| 1645 |  |  [Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.252) |  | 0 | Aspect-based sentiment analysis (ABSA) is an important subtask of sentiment analysis, which aims to extract the aspects and predict their sentiments. Most existing studies focus on improving the performance of the target domain by fine-tuning domain-specific models (trained on source domains) based... | Xuanwen Ding, Jie Zhou, Liang Dou, Qin Chen, Yuanbin Wu, Arlene Chen, Liang He |  |
| 1646 |  |  [ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context](https://doi.org/10.18653/v1/2024.findings-emnlp.253) |  | 0 | Tables play a crucial role in conveying information in various domains. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or... | Zirui Wu, Yansong Feng |  |
| 1647 |  |  [Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models](https://doi.org/10.18653/v1/2024.findings-emnlp.254) |  | 0 | Moderating hate speech (HS) in the evolving online landscape is a complex challenge, compounded by the multimodal nature of digital content. This survey examines recent advancements in HS moderation, focusing on the burgeoning role of large language models (LLMs) and large multimodal models (LMMs)... | Ming Shan Hee, Shivam Sharma, Rui Cao, Palash Nandi, Preslav Nakov, Tanmoy Chakraborty, Roy KaWei Lee |  |
| 1648 |  |  [Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles](https://doi.org/10.18653/v1/2024.findings-emnlp.255) |  | 0 | Large language models (LLMs) are increasingly being utilised across a range of tasks and domains, with a burgeoning interest in their application within the field of journalism. This trend raises concerns due to our limited understanding of LLM behaviour in this domain, especially with respect to... | Filip Trhlík, Pontus Stenetorp |  |
| 1649 |  |  [OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary](https://doi.org/10.18653/v1/2024.findings-emnlp.256) |  | 0 | To meet application needs, event extraction has shifted from simple entities to unconventional entities serving as event arguments. However, current corpora with unconventional entities as event arguments are limited in event types and lack rich multi-events and shared arguments. Financial... | Qizhi Wan, Changxuan Wan, Rong Hu, Dexi Liu, Xu Wenwu, Kang Xu, Zou Meihua, Liu Tao, Jie Yang, Zhenwei Xiong |  |
| 1650 |  |  [Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.257) |  | 0 | Long document classification presents challenges in capturing both local and global dependencies due to their extensive content and complex structure. Existing methods often struggle with token limits and fail to adequately model hierarchical relationships within documents. To address these... | Sudipta Singha Roy, Xindi Wang, Robert E. Mercer, Frank Rudzicz |  |
| 1651 |  |  [BookWorm: A Dataset for Character Description and Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.258) |  | 0 | Characters are at the heart of every story, driving the plot and engaging readers. In this study, we explore the understanding of characters in full-length books, which contain complex narratives and numerous interacting characters. We define two tasks: character description, which generates a... | Argyrios Papoudakis, Mirella Lapata, Frank Keller |  |
| 1652 |  |  [Leveraging Grammar Induction for Language Understanding and Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.259) |  | 0 | Grammar induction has made significant progress in recent years. However, it is not clear how the application of induced grammar could enhance practical performance in downstream tasks. In this work, we introduce an unsupervised grammar induction method for language understanding and generation. We... | Jushi Kai, Shengyuan Hou, Yusheng Huang, Zhouhan Lin |  |
| 1653 |  |  [SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully](https://doi.org/10.18653/v1/2024.findings-emnlp.260) |  | 0 | Large language models (LLMs) demonstrate great performance in text generation. However, LLMs are still suffering from hallucinations. In this work, we propose an inference-time method, Self-Highlighted Hesitation (SH2), to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in... | Jushi Kai, Tianhang Zhang, Hai Hu, Zhouhan Lin |  |
| 1654 |  |  [RoQLlama: A Lightweight Romanian Adapted Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.261) |  | 0 | The remarkable achievements obtained by open-source large language models (LLMs) in recent years have predominantly been concentrated on tasks involving the English language. In this paper, we aim to advance the performance of Llama2 models on Romanian tasks. We tackle the problem of reduced... | GeorgeAndrei Dima, AndreiMarius Avram, CristianGeorge Craciun, DumitruClementin Cercel |  |
| 1655 |  |  [Reference-free Hallucination Detection for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.262) |  | 0 | Large vision-language models (LVLMs) have made significant progress in recent years. While LVLMs exhibit excellent ability in language understanding, question answering, and conversations of visual inputs, they are prone to producing hallucinations. While several methods are proposed to evaluate... | Qing Li, Jiahui Geng, Chenyang Lyu, Derui Zhu, Maxim Panov, Fakhri Karray |  |
| 1656 |  |  [WavLLM: Towards Robust and Adaptive Speech Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.263) |  | 0 | Recent advancements in large language models (LLMs) have expanded their scope in natural language processing (NLP) to encompass multimodal functions. However, integrating listening capabilities effectively remains a significant challenge for generalization and complex auditory task execution. In... | Shujie Hu, Long Zhou, Shujie Liu, Sanyuan Chen, Lingwei Meng, Hongkun Hao, Jing Pan, Xunying Liu, Jinyu Li, Sunit Sivasankaran, Linquan Liu, Furu Wei |  |
| 1657 |  |  [Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.264) |  | 0 | Implicit user feedback, user emotions and demographic information have shown to be promising sources for improving the accuracy and user engagement of responses generated by dialogue systems. However, the influence of such information on task completion and factual consistency, which are important... | Dominic Petrak, Thy Thy Tran, Iryna Gurevych |  |
| 1658 |  |  [Improving Argument Effectiveness Across Ideologies using Instruction-tuned Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.265) |  | 0 | Different political ideologies (e.g., liberal and conservative Americans) hold different worldviews, which leads to opposing stances on different issues (e.g., gun control) and, thereby, fostering societal polarization. Arguments are a means of bringing the perspectives of people with different... | Roxanne El Baff, Khalid Al Khatib, Milad Alshomary, Kai Konen, Benno Stein, Henning Wachsmuth |  |
| 1659 |  |  [KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches](https://doi.org/10.18653/v1/2024.findings-emnlp.266) |  | 0 | Long context capability is a crucial competency for large language models (LLMs) as it mitigates the human struggle to digest long-form texts. This capability enables complex task-solving scenarios such as book summarization, code assistance, and many more tasks that are traditionally... | Jiayi Yuan, Hongyi Liu, Shaochen (Henry) Zhong, YuNeng Chuang, Songchen Li, Guanchu Wang, Duy Le, Hongye Jin, Vipin Chaudhary, Zhaozhuo Xu, Zirui Liu, Xia Ben Hu |  |
| 1660 |  |  [An Evaluation Mechanism of LLM-based Agents on Manipulating APIs](https://doi.org/10.18653/v1/2024.findings-emnlp.267) |  | 0 | LLM-based agents can greatly extend the abilities of LLMs and thus attract sharply increased studies. An ambitious vision – serving users by manipulating massive API-based tools – has been proposed and explored. However, we find a widely accepted evaluation mechanism for generic agents is still... | Bing Liu, Jianxiang Zhou, Dan Meng, Haonan Lu |  |
| 1661 |  |  [Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.268) |  | 0 | Large language models (LLMs) have demonstrated impressive reasoning capabilities, particularly in textual mathematical problem-solving. However, existing open-source image instruction fine-tuning datasets, containing limited question-answer pairs per image, do not fully exploit visual information... | Wenhao Shi, Zhiqiang Hu, Yi Bin, Junhua Liu, Yang Yang, SeeKiong Ng, Lidong Bing, Roy KaWei Lee |  |
| 1662 |  |  [Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation](https://doi.org/10.18653/v1/2024.findings-emnlp.269) |  | 0 | This study presents a novel evaluation framework for the Vision-Language Navigation (VLN) task. It aims to diagnose current models for various instruction categories at a finer-grained level. The framework is structured around the context-free grammar (CFG) of the task. The CFG serves as the basis... | Zehao Wang, Minye Wu, Yixin Cao, Yubo Ma, Meiqi Chen, Tinne Tuytelaars |  |
| 1663 |  |  [Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.270) |  | 0 | Recent advances in large language models (LLMs) have enabled autonomous agents with complex reasoning and task-fulfillment capabilities using a wide range of tools. However, effectively identifying the most relevant tools for a given task becomes a key bottleneck as the toolset size grows,... | Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent CohenAddad, MohammadHossein Bateni, ChenYu Lee, Tomas Pfister |  |
| 1664 |  |  [Rethinking Evaluation Methods for Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-emnlp.271) |  | 0 | Machine \*unlearning\* refers to methods for deleting information about specific training instances from a trained machine learning model. This enables models to delete user information and comply with privacy regulations. While retraining the model from scratch on the training set excluding the... | Leon Wichert, Sandipan Sikdar |  |
| 1665 |  |  [Evaluating Moral Beliefs across LLMs through a Pluralistic Framework](https://doi.org/10.18653/v1/2024.findings-emnlp.272) |  | 0 | Proper moral beliefs are fundamental for language models, yet assessing these beliefs poses a significant challenge. This study introduces a novel three-module framework to evaluate the moral beliefs of four prominent large language models. Initially, we constructed a dataset containing 472 moral... | Xuelin Liu, Yanfei Zhu, Shucheng Zhu, Pengyuan Liu, Ying Liu, Dong Yu |  |
| 1666 |  |  [Knowledge Editing in Language Models via Adapted Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.273) |  | 0 | Large Language Models (LLMs) can become outdated over time as they may lack updated world knowledge, leading to factual knowledge errors and gaps. Knowledge Editing (KE) aims to overcome this challenge using weight updates that do not require expensive retraining. We propose treating KE as an LLM... | Amit Rozner, Barak Battash, Lior Wolf, Ofir Lindenbaum |  |
| 1667 |  |  [Disentangling Questions from Query Generation for Task-Adaptive Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.274) |  | 0 | This paper studies the problem of information retrieval, to adapt to unseen tasks. Existing work generates synthetic queries from domain-specific documents to jointly train the retriever. However, the conventional query generator assumes the query as a question, thus failing to accommodate general... | Yoonsang Lee, Minsoo Kim, Seungwon Hwang |  |
| 1668 |  |  [Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora](https://doi.org/10.18653/v1/2024.findings-emnlp.275) |  | 0 | Media storms, dramatic outbursts of attention to a story, are central components of media dynamics and the attention landscape. Despite their importance, there has been little systematic and empirical research on this concept due to issues of measurement and operationalization. We introduce an... | Dror K. Markus, Effi Levi, Tamir Sheafer, Shaul R. Shenhav |  |
| 1669 |  |  [A Survey on Natural Language Counterfactual Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.276) |  | 0 | Natural language counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model’s predictions by highlighting which words significantly influence... | Yongjie Wang, Xiaoqi Qiu, Yu Yue, Xu Guo, Zhiwei Zeng, Yuhong Feng, Zhiqi Shen |  |
| 1670 |  |  [Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research](https://doi.org/10.18653/v1/2024.findings-emnlp.277) |  | 0 | The applications of large language models (LLMs) are promising for biomedical and healthcare research. Despite the availability of open-source LLMs trained using a wide range of biomedical data, current research on the applications of LLMs to genomics and proteomics is still limited. To fill this... | Tianyu Liu, Yijia Xiao, Xiao Luo, Hua Xu, Wenjin Jim Zheng, Hongyu Zhao |  |
| 1671 |  |  [QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism](https://doi.org/10.18653/v1/2024.findings-emnlp.278) |  | 0 | While LLMs have made notable advancements in natural language processing, they continue to struggle with processing extensive text. Memory mechanisms offer a flexible solution for managing long contexts, utilizing techniques such as compression, summarization, and structuring to facilitate nuanced... | Bo Wang, Heyan Huang, Yixin Cao, Jiahao Ying, Wei Tang, Chong Feng |  |
| 1672 |  |  [LONG²RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall](https://doi.org/10.18653/v1/2024.findings-emnlp.279) |  | 0 |  | Zehan Qi, Rongwu Xu, Zhijiang Guo, Cunxiang Wang, Hao Zhang, Wei Xu |  |
| 1673 |  |  [IndoCL: Benchmarking Indonesian Language Development Assessment](https://doi.org/10.18653/v1/2024.findings-emnlp.280) |  | 0 | Recently, the field of language acquisition (LA) has significantly benefited from natural language processing technologies. A crucial task in LA involves tracking the evolution of language learners’ competence, namely language development assessment (LDA). However, the majority of LDA research... | Nankai Lin, Hongyan Wu, Weixiong Zheng, Xingming Liao, Shengyi Jiang, Aimin Yang, Lixian Xiao |  |
| 1674 |  |  [Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs](https://doi.org/10.18653/v1/2024.findings-emnlp.281) |  | 0 | Retrieval-Augmented Large Language Models(RALMs) have made significant strides in enhancing the accuracy of generated responses. However, existing research often overlooks the data quality issues within retrieval results, often caused by inaccurate existing vector-distance-based retrieval methods.... | Kexin Ma, Ruochun Jin, Haotian Wang, Xi Wang, Huan Chen, Yuhua Tang, Qian Wang |  |
| 1675 |  |  [Counter Turing Test (CT²): Investigating AI-Generated Text Detection for Hindi - Ranking LLMs based on Hindi AI Detectability Index (ADI_hi)](https://doi.org/10.18653/v1/2024.findings-emnlp.282) |  | 0 |  | Ishan Kavathekar, Anku Rani, Ashmit Chamoli, Ponnurangam Kumaraguru, Amit P. Sheth, Amitava Das |  |
| 1676 |  |  [Generating Media Background Checks for Automated Source Critical Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.283) |  | 0 | Not everything on the internet is true. This unfortunate fact requires both humans and models to perform complex reasoning about credibility when working with retrieved information. In NLP, this problem has seen little attention. Indeed, retrieval-augmented models are not typically expected to... | Michael Sejr Schlichtkrull |  |
| 1677 |  |  [In Defense of Structural Sparse Adapters for Concurrent LLM Serving](https://doi.org/10.18653/v1/2024.findings-emnlp.284) |  | 0 | Adapting large language models (LLMs) to specific tasks remains challenging due to the extensive retraining required, prompting the need for efficient adapter techniques. Despite this, the concurrent serving of multiple adapters, each with unique matrix shapes, poses significant system-level... | Junda Su, Zirui Liu, Zeju Qiu, Weiyang Liu, Zhaozhuo Xu |  |
| 1678 |  |  [CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.285) |  | 0 | Multimodal Large Language Models (MLLMs) have shown promising results in various tasks, but their ability to perceive the visual world with deep, hierarchical understanding similar to humans remains uncertain. To address this gap, we introduce CONSTRUCTURE, a novel concept-level benchmark to assess... | Zhiwei Zha, Xiangru Zhu, Yuanyi Xu, Chenghua Huang, Jingping Liu, Zhixu Li, Xuwu Wang, Yanghua Xiao, Bei Yang, Xiaoxiao Xu |  |
| 1679 |  |  [Stanceformer: Target-Aware Transformer for Stance Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.286) |  | 0 | The task of Stance Detection involves discerning the stance expressed in a text towards a specific subject or target. Prior works have relied on existing transformer models that lack the capability to prioritize targets effectively. Consequently, these models yield similar performance regardless of... | Krishna Garg, Cornelia Caragea |  |
| 1680 |  |  [Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.287) |  | 0 | Traditional autonomous driving systems have mainly focused on making driving decisions without human interaction, overlooking human-like decision-making and human preference required in complex traffic scenarios. To bridge this gap, we introduce a novel framework leveraging Large Language Models... | Yunsheng Ma, Xu Cao, Wenqian Ye, Can Cui, Kai Mei, Ziran Wang |  |
| 1681 |  |  [CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies](https://doi.org/10.18653/v1/2024.findings-emnlp.288) |  | 0 | To enhance language models’ cultural awareness, we design a generalizable pipeline to construct cultural knowledge bases from different online communities on a massive scale. With the pipeline, we construct CultureBank, a knowledge base built upon users’ self-narratives with 12K cultural... | Weiyan Shi, Ryan Li, Yutong Zhang, Caleb Ziems, Sunny Yu, Raya Horesh, Rogério de Paula, Diyi Yang |  |
| 1682 |  |  [TOOLVERIFIER: Generalization to New Tools via Self-Verification](https://doi.org/10.18653/v1/2024.findings-emnlp.289) |  | 0 | Teaching language models to use tools is an important milestone towards building general assistants, but remains an open problem. While there has been significant progress on learning to use specific tools via fine-tuning, language models still struggle with learning how to robustly use new tools... | Dheeraj Mekala, Jason Weston, Jack Lanchantin, Roberta Raileanu, Maria Lomeli, Jingbo Shang, Jane DwivediYu |  |
| 1683 |  |  [FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.290) |  | 0 | We introduce FaithScore (Faithfulness to Atomic Image Facts Score), a reference-free and fine-grained evaluation metric that measures the faithfulness of the generated free-form answers from large vision-language models (LVLMs). The FaithScore evaluation first identifies sub-sentences containing... | Liqiang Jing, Ruosen Li, Yunmo Chen, Xinya Du |  |
| 1684 |  |  [Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain](https://doi.org/10.18653/v1/2024.findings-emnlp.291) |  | 0 | Questions are essential tools for acquiring the necessary information to complete information-seeking tasks. However, large language models (LLMs), especially open-source models, often perform poorly in generating informative questions, as measured by expected information gain (EIG). In this paper,... | Davide Mazzaccara, Alberto Testoni, Raffaella Bernardi |  |
| 1685 |  |  [Adversarial Math Word Problem Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.292) |  | 0 | Large language models (LLMs) have significantly transformed the educational landscape. As current plagiarism detection tools struggle to keep pace with LLMs’ rapid advancements, the educational community faces the challenge of assessing students’ true problem-solving abilities in the presence of... | Roy Xie, Chengxuan Huang, Junlin Wang, Bhuwan Dhingra |  |
| 1686 |  |  [Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing](https://doi.org/10.18653/v1/2024.findings-emnlp.293) |  | 0 | Large language models (LLMs) are increasingly being adopted in a wide range of real-world applications. Despite their impressive performance, recent studies have shown that LLMs are vulnerable to deliberately crafted adversarial prompts even when aligned via Reinforcement Learning from Human... | Wei Zhao, Zhe Li, Yige Li, Ye Zhang, Jun Sun |  |
| 1687 |  |  [Promoting Constructive Deliberation: Reframing for Receptiveness](https://doi.org/10.18653/v1/2024.findings-emnlp.294) |  | 0 | To promote constructive discussion of controversial topics online, we propose automatic reframing of disagreeing responses to signal receptiveness to a preceding comment. Drawing on research from psychology, communications, and linguistics, we identify six strategies for reframing. We automatically... | Gauri Kambhatla, Matthew Lease, Ashwin Rajadesingan |  |
| 1688 |  |  [A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.295) |  | 0 | Large language models (LLMs) have demonstrated impressive abilities in generating unstructured natural language according to instructions. However, their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications... | Yinghao Li, Rampi Ramprasad, Chao Zhang |  |
| 1689 |  |  [Rater Cohesion and Quality from a Vicarious Perspective](https://doi.org/10.18653/v1/2024.findings-emnlp.296) |  | 0 | Human feedback is essential for building human-centered AI systems across domains where disagreement is prevalent, such as AI safety, content moderation, or sentiment analysis. Many disagreements, particularly in politically charged settings, arise because raters have opposing values or beliefs.... | Deepak Pandita, Tharindu Cyril Weerasooriya, Sujan Dutta, Sarah Luger, Tharindu Ranasinghe, Ashiqur R. KhudaBukhsh, Marcos Zampieri, Christopher Homan |  |
| 1690 |  |  [Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.297) |  | 0 | Large Language Models (LLMs) have increasingly been utilized in social simulations, where they are often guided by carefully crafted instructions to stably exhibit human-like behaviors during simulations. Nevertheless, we doubt the necessity of shaping agents’ behaviors for accurate social... | Zengqing Wu, Run Peng, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Inhyuk Kwon, Makoto Onizuka, Shaojie Tang, Chuan Xiao |  |
| 1691 |  |  [Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction](https://doi.org/10.18653/v1/2024.findings-emnlp.298) |  | 0 | With the size and cost of large transformer-based language models growing, recently, there has been interest in shortcut casting of early transformer hidden-representations to final-representations for cheaper model inference. In particular, shortcutting pre-trained transformers with linear... | Amrit Diggavi Seshadri |  |
| 1692 |  |  [From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items](https://doi.org/10.18653/v1/2024.findings-emnlp.299) |  | 0 | LLMs can now perform a variety of complex writing tasks. They also excel in answering questions pertaining to natural language inference and commonsense reasoning. Composing these questions is itself a skilled writing task, so in this paper we consider LLMs as authors of commonsense assessment... | Melissa Roemmele, Andrew Gordon |  |
| 1693 |  |  ["I Never Said That": A dataset, taxonomy and baselines on response clarity classification](https://doi.org/10.18653/v1/2024.findings-emnlp.300) |  | 0 | Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from... | Konstantinos Thomas, Giorgos Filandrianos, Maria Lymperaiou, Chrysoula Zerva, Giorgos Stamou |  |
| 1694 |  |  [Immunization against harmful fine-tuning attacks](https://doi.org/10.18653/v1/2024.findings-emnlp.301) |  | 0 | Large Language Models (LLMs) are often trained with safety guards intended to prevent harmful text generation. However, such safety training can be removed by fine-tuning the LLM on harmful datasets. While this emerging threat (harmful fine-tuning attacks) has been characterized by previous work,... | Domenic Rosati, Jan Wehner, Kai Williams, Lukasz Bartoszcze, Hassan Sajjad, Frank Rudzicz |  |
| 1695 |  |  [UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause](https://doi.org/10.18653/v1/2024.findings-emnlp.302) |  | 0 | Multimodal emotion recognition in conversation (MERC) and multimodal emotion-cause pair extraction (MECPE) have recently garnered significant attention. Emotions are the expression of affect or feelings; responses to specific events, or situations – known as emotion causes. Both collectively... | Guimin Hu, Zhihong Zhu, Daniel Hershcovich, Lijie Hu, Hasti Seifi, Jiayuan Xie |  |
| 1696 |  |  [CodeFort: Robust Training for Code Generation Models](https://doi.org/10.18653/v1/2024.findings-emnlp.303) |  | 0 | Code generation models are not robust to small perturbations, which often lead to incorrect generations and significantly degrade the performance of these models. Although improving the robustness of code generation models is crucial to enhancing user experience in real-world applications, existing... | Yuhao Zhang, Shiqi Wang, Haifeng Qian, Zijian Wang, Mingyue Shang, Linbo Liu, Sanjay Krishna Gouda, Baishakhi Ray, Murali Krishna Ramanathan, Xiaofei Ma, Anoop Deoras |  |
| 1697 |  |  [MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction](https://doi.org/10.18653/v1/2024.findings-emnlp.304) |  | 0 | RNA foundation models (FMs) have been extensively used to interpret genomic sequences and address a wide range of in-silico genomic tasks. However, current RNA FMs often overlook the incorporation of secondary structures in the pretraining of FMs, which impedes the effectiveness in various genomic... | Heng Yang, Ke Li |  |
| 1698 |  |  ["Any Other Thoughts, Hedgehog?" Linking Deliberation Chains in Collaborative Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.305) |  | 0 | Question-asking in collaborative dialogue has long been established as key to knowledge construction, both in internal and collaborative problem solving. In this work, we examine probing questions in collaborative dialogues: questions that explicitly elicit responses from the speaker’s... | Abhijnan Nath, Videep Venkatesha, Mariah Bradford, Avyakta Chelle, Austin Youngren, Carlos Mabrey, Nathaniel Blanchard, Nikhil Krishnaswamy |  |
| 1699 |  |  [Evaluation of Question Answer Generation for Portuguese: Insights and Datasets](https://doi.org/10.18653/v1/2024.findings-emnlp.306) |  | 0 | Automatic question generation is an increasingly important task that can be applied in different settings, including educational purposes, data augmentation for question-answering (QA), and conversational systems. More specifically, we focus on question answer generation (QAG), which produces... | Felipe S. F. Paula, Cassiana Michelin, Viviane P. Moreira |  |
| 1700 |  |  [Evolutionary Contrastive Distillation for Language Model Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.307) |  | 0 | The ability of large language models (LLMs) to execute complex instructions is essential for their real-world applications. However, several recent studies indicate that LLMs struggle with challenging instructions. In this paper, we propose Evolutionary Contrastive Distillation (ECD), a novel... | Julian KatzSamuels, Zheng Li, Hyokun Yun, Priyanka Nigam, Yi Xu, Vaclav Petricek, Bing Yin, Trishul Chilimbi |  |
| 1701 |  |  [A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies](https://doi.org/10.18653/v1/2024.findings-emnlp.308) |  | 0 | Despite recent advancements in AI and NLP, negotiation remains a difficult domain for AI agents. Traditional game theoretic approaches that have worked well for two-player zero-sum games struggle in the context of negotiation due to their inability to learn human-compatible strategies. On the other... | Ryan Shea, Zhou Yu |  |
| 1702 |  |  [Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media](https://doi.org/10.18653/v1/2024.findings-emnlp.309) |  | 0 | The large scale usage of social media, combined with its significant impact, has made it increasingly important to understand it. In particular, identifying user communities, can be helpful for many downstream tasks. However, particularly when models are trained on past data and tested on future,... | Nikhil Mehta, Dan Goldwasser |  |
| 1703 |  |  [Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.310) |  | 0 | A successful negotiation requires a range of capabilities, including comprehension of the conversation context, Theory-of-Mind (ToM) skills to infer the partner’s motives, strategic reasoning, and effective communication, making it challenging for automated systems. Despite the remarkable... | Deuksin Kwon, Emily Weiss, Tara Kulshrestha, Kushal Chawla, Gale M. Lucas, Jonathan Gratch |  |
| 1704 |  |  [When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?](https://doi.org/10.18653/v1/2024.findings-emnlp.311) |  | 0 | The introduction of Large Language Models (LLMs) has advanced data representation and analysis, bringing significant progress in their use for medical questions and answering. Despite these advancements, integrating tabular data, especially numerical data pivotal in clinical contexts, into LLM... | Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A. Miller, Danielle S. Bitterman, Matthew M. Churpek, Majid Afshar |  |
| 1705 |  |  [Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts](https://doi.org/10.18653/v1/2024.findings-emnlp.312) |  | 0 | We present LoCoVQA, a dynamic benchmark generator for evaluating long-context reasoning in vision language models (VLMs). LoCoVQA augments test examples for mathematical reasoning, VQA, and character recognition tasks with increasingly long visual contexts composed of both in-distribution and... | Aditya Sharma, Michael Saxon, William Yang Wang |  |
| 1706 |  |  [Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring](https://doi.org/10.18653/v1/2024.findings-emnlp.313) |  | 0 | Generating rationales that justify scoring decisions has been a promising way to facilitate explainability in automated scoring systems. However, existing methods do not match the accuracy of classifier-based methods. Plus, the generated rationales often contain hallucinated information. To address... | Jiazheng Li, Hainiu Xu, Zhaoyue Sun, Yuxiang Zhou, David West, Cesare Aloisi, Yulan He |  |
| 1707 |  |  [LOCR: Location-Guided Transformer for Optical Character Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.314) |  | 0 | Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues,... | Yu Sun, Dongzhan Zhou, Chen Lin, Conghui He, Wanli Ouyang, HanSen Zhong |  |
| 1708 |  |  [Sing it, Narrate it: Quality Musical Lyrics Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.315) |  | 0 | Translating lyrics for musicals presents unique challenges due to the need to ensure high translation quality while adhering to singability requirements such as length and rhyme. Existing song translation approaches often prioritize these singability constraints at the expense of translation... | Zhuorui Ye, Jinhan Li, Rongwu Xu |  |
| 1709 |  |  [Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank](https://doi.org/10.18653/v1/2024.findings-emnlp.316) |  | 0 | In this paper, we study an under-explored area of language and vocabulary learning: keyword mnemonics, a technique for memorizing vocabulary through memorable associations with a target word via a verbal cue. Typically, creating verbal cues requires extensive human effort and is quite... | Jaewook Lee, Hunter McNichols, Andrew S. Lan |  |
| 1710 |  |  [Dual-teacher Knowledge Distillation for Low-frequency Word Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.317) |  | 0 | Neural Machine Translation (NMT) models are trained on parallel corpora with unbalanced word frequency distribution. As a result, NMT models are likely to prefer high-frequency words than low-frequency ones despite low-frequency word may carry the crucial semantic information, which may hamper the... | Yifan Guo, Hongying Zan, Hongfei Xu |  |
| 1711 |  |  [A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation](https://doi.org/10.18653/v1/2024.findings-emnlp.318) |  | 0 | Contrastive learning has been successfully adopted in VRL (visual representation learning) by constructing effective contrastive pairs. A promising baseline SimCSE has made notable breakthroughs in unsupervised SRL (sentence representation learning) following the success of contrastive learning.... | Yoo Hyun Jeong, Myeong Soo Han, DongKyu Chae |  |
| 1712 |  |  [Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.319) |  | 0 | Large language models (LLMs) have demonstrated remarkable performance in the legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However their efficacy remains limited for non-standardized tasks and tasks in languages other than English. This underscores the need for careful... | Kimyeeun Kimyeeun, Choi Youngrok, Eunkyung Choi, Jinhwan Choi, Hai Jin Park, Wonseok Hwang |  |
| 1713 |  |  [Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs](https://doi.org/10.18653/v1/2024.findings-emnlp.320) |  | 0 | Unsupervised multimodal machine translation (UMMT) aims to leverage vision information as a pivot between two languages to achieve better performance on low-resource language pairs. However, there is presently a challenge: how to handle alignment between distant language pairs (DLPs) in UMMT. To... | Turghun Tayir, Lin Li, Xiaohui Tao, Mieradilijiang Maimaiti, Ming Li, Jianquan Liu |  |
| 1714 |  |  [Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach](https://doi.org/10.18653/v1/2024.findings-emnlp.321) |  | 0 | We study the problem of fine-tuning a language model (LM) for a target task by optimally using the information from n auxiliary tasks. This problem has broad applications in NLP, such as targeted instruction tuning and data selection in chain-of-thought fine-tuning. The key challenge of this... | Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang Zhang |  |
| 1715 |  |  [In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.322) |  | 0 | Recent advancements in artificial intelligence have led to the creation of highly capable large language models (LLMs) that can perform tasks in a human-like manner. However, LLMs exhibit only infant-level cognitive abilities in certain areas. One such area is the A-Not-B error, a phenomenon seen... | Pengrui Han, Peiyang Song, Haofei Yu, Jiaxuan You |  |
| 1716 |  |  [MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula](https://doi.org/10.18653/v1/2024.findings-emnlp.323) |  | 0 | To ensure that math curriculum is grade-appropriate and aligns with critical skills or concepts in accordance with educational standards, pedagogical experts can spend months carefully reviewing published math problems. Drawing inspiration from this process, our work presents a novel angle for... | Li Lucy, Tal August, Rose E. Wang, Luca Soldaini, Courtney Allison, Kyle Lo |  |
| 1717 |  |  [Enhancing Multi-Label Text Classification under Label-Dependent Noise: A Label-Specific Denoising Framework](https://doi.org/10.18653/v1/2024.findings-emnlp.324) |  | 0 | Recent advancements in noisy multi-label text classification have primarily relied on the class-conditional noise (CCN) assumption, which treats each label independently undergoing label flipping to generate noisy labels. However, in real-world scenarios, noisy labels often exhibit dependencies... | Pengyu Xu, Liping Jing, Jian Yu |  |
| 1718 |  |  [Automatic Reconstruction of Ancient Chinese Pronunciations](https://doi.org/10.18653/v1/2024.findings-emnlp.325) |  | 0 | Reconstructing ancient Chinese pronunciation is a challenging task due to the scarcity of phonetic records. Different from historical linguistics’ comparative approaches, we reformulate this problem into a temporal prediction task with masked language models, digitizing existing phonology rules... | Zhige Huang, Haoan Jin, Mengyue Wu, Kenny Q. Zhu |  |
| 1719 |  |  [Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization](https://doi.org/10.18653/v1/2024.findings-emnlp.326) |  | 0 | Large language models perform well on tasks that have undergone fine-tuning of instructions, but their performance on completely unseen tasks is often less than ideal. To overcome the challenge of cross-task generalization, task-level LoRAs combination is proposed, which does not require training a... | Zhiqi Wang, Shizhu He, Kang Liu, Jun Zhao |  |
| 1720 |  |  [LongWanjuan: Towards Systematic Measurement for Long Text Quality](https://doi.org/10.18653/v1/2024.findings-emnlp.327) |  | 0 | The quality of training data is crucial for enhancing the long-text capabilities of foundation models. Despite existing efforts to refine data quality through heuristic rules and evaluations based on data diversity and difficulty, there’s a lack of systematic approaches specifically tailored for... | Xiaoran Liu, Kai Lv, Qipeng Guo, Hang Yan, Conghui He, Xipeng Qiu, Dahua Lin |  |
| 1721 |  |  [Large Language Model for Multi-Domain Translation: Benchmarking and Domain CoT Fine-tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.328) |  | 0 | Achieving consistent high-quality machine translation (MT) across diverse domains remains a significant challenge, primarily due to the limited and imbalanced parallel training data available in various domains. While large language models (LLMs) have demonstrated impressive general understanding... | Tianxiang Hu, Pei Zhang, Baosong Yang, Jun Xie, Derek F. Wong, Rui Wang |  |
| 1722 |  |  [TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage](https://doi.org/10.18653/v1/2024.findings-emnlp.329) |  | 0 | The global escalation in emergency department patient visits poses significant challenges to efficient clinical management, particularly in clinical triage. Traditionally managed by human professionals, clinical triage is susceptible to substantial variability and high workloads. Although large... | Meng Lu, Brandon Ho, Dennis Ren, Xuan Wang |  |
| 1723 |  |  [Generative Deduplication For Socia Media Data Selection](https://doi.org/10.18653/v1/2024.findings-emnlp.330) |  | 0 | Social media data exhibits severe redundancy caused by its noisy nature. It leads to increased training time and model bias in its processing. To address this issue, we propose a novel Generative Deduplication framework for social media data selection by removing semantically duplicate data. While... | Xianming Li, Jing Li |  |
| 1724 |  |  [Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts](https://doi.org/10.18653/v1/2024.findings-emnlp.331) |  | 0 | Large language models (LLMs) acquire beliefs about gender from training data and can therefore generate text with stereotypical gender attitudes. Prior studies have demonstrated model generations favor one gender or exhibit stereotypes about gender, but have not investigated the complex dynamics... | Sharon Levy, William D. Adler, Tahilin Sanchez Karver, Mark Dredze, Michelle R. Kaufman |  |
| 1725 |  |  [Evaluating Biases in Context-Dependent Sexual and Reproductive Health Questions](https://doi.org/10.18653/v1/2024.findings-emnlp.332) |  | 0 | Chat-based large language models have the opportunity to empower individuals lacking high-quality healthcare access to receive personalized information across a variety of topics. However, users may ask underspecified questions that require additional context for a model to correctly answer. We... | Sharon Levy, Tahilin Sanchez Karver, William D. Adler, Michelle R. Kaufman, Mark Dredze |  |
| 1726 |  |  [Self-Evaluation of Large Language Model based on Glass-box Features](https://doi.org/10.18653/v1/2024.findings-emnlp.333) |  | 0 | The proliferation of open-source Large Language Models (LLMs) underscores the pressing need for evaluation methods. Existing works primarily rely on external evaluators, focusing on training and prompting strategies. However, a crucial aspect – model-aware glass-box features – is overlooked. In... | Hui Huang, Yingqi Qu, Jing Liu, Muyun Yang, Bing Xu, Tiejun Zhao, Wenpeng Lu |  |
| 1727 |  |  [FASTTRACK: Reliable Fact Tracing via Clustering and LLM-Powered Evidence Validation](https://doi.org/10.18653/v1/2024.findings-emnlp.334) |  | 0 | Fact tracing seeks to identify specific training examples that serve as the knowledge source for a given query. Existing approaches to fact tracing rely on assessing the similarity between each training sample and the query along a certain dimension, such as lexical similarity, gradient, or... | Si Chen, Feiyang Kang, Ning Yu, Ruoxi Jia |  |
| 1728 |  |  [PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks](https://doi.org/10.18653/v1/2024.findings-emnlp.335) |  | 0 | In textual backdoor attacks, attackers insert poisoned samples with triggered inputs and target labels into training datasets to manipulate model behavior, threatening the model’s security and reliability. Current defense methods can generally be categorized into inference-time and training-time... | Yu Chen, Qi Cao, Kaike Zhang, Xuchao Liu, Huawei Shen |  |
| 1729 |  |  [Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.336) |  | 0 | Metaphor, as an advanced form of cognition, is challenging to understand their meaning. Current metaphor detection tasks only provide labels (i.e., metaphor or literal) without interpreting how to understand them. In this paper, we improve the metaphor detection task and explore the reason of... | Puli Chen, Cheng Yang, Qingbao Huang |  |
| 1730 |  |  [Can we teach language models to gloss endangered languages?](https://doi.org/10.18653/v1/2024.findings-emnlp.337) |  | 0 | Interlinear glossed text (IGT) is a popular format in language documentation projects, where each morpheme is labeled with a descriptive annotation. Automating the creation of interlinear glossed text would be desirable to reduce annotator effort and maintain consistency across annotated corpora.... | Michael Ginn, Mans Hulden, Alexis Palmer |  |
| 1731 |  |  [On the token distance modeling ability of higher RoPE attention dimension](https://doi.org/10.18653/v1/2024.findings-emnlp.338) |  | 0 | Length extrapolation algorithms based on Rotary position embedding (RoPE) have shown promising results in extending the context length of language models. However, understanding how position embedding can capture longer-range contextual information remains elusive. Based on the intuition that... | Xiangyu Hong, Che Jiang, Biqing Qi, Fandong Meng, Mo Yu, Bowen Zhou, Jie Zhou |  |
| 1732 |  |  [Enhancing Byzantine-Resistant Aggregations with Client Embedding](https://doi.org/10.18653/v1/2024.findings-emnlp.339) |  | 0 | Byzantine-resistant aggregations detect poisonous clients and discard them to ensure that the global model is not poisoned or attacked by malicious clients. However, these aggregations are mainly conducted on the parameter space, and the parameter distances cannot reflect the data distribution... | Zhiyuan Zhang, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun |  |
| 1733 |  |  [Exploiting Careful Design of SVM Solution for Aspect-term Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.340) |  | 0 | Aspect-term sentiment analysis (ATSA) identifies fine-grained sentiments towards specific aspects of the text. While pre-trained language models (PLMs) have set the state-of-the-art (SOTA) for ATSA, they are resource-intensive due to their large model sizes, restricting their wide applications to... | Hanfeng Liu, Minping Chen, Zhenya Zheng, Zeyi Wen |  |
| 1734 |  |  [Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach](https://doi.org/10.18653/v1/2024.findings-emnlp.341) |  | 0 | We propose a neuro-symbolic approach for realistic few-shot relation classification via rules. Instead of building neural models to predict relations, we design them to output straightforward rules that can be used to extract relations. The rules are generated using custom T5-style Encoder-Decoder... | Mayank Singh, Eduardo Blanco |  |
| 1735 |  |  [Plot Twist: Multimodal Models Don't Comprehend Simple Chart Details](https://doi.org/10.18653/v1/2024.findings-emnlp.342) |  | 0 | Recent advances in multimodal models show remarkable performance in real-world benchmarks for chart and figure understanding like ChartQA that involve interpreting trends, comparing data points, and extracting insights from visuals.In this paper, we investigate the extent to which these models... | Yasaman Razeghi, Ishita Dasgupta, Fangyu Liu, Vinay Ramasesh, Sameer Singh |  |
| 1736 |  |  [HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.343) |  | 0 | The widespread use of social media necessitates reliable and efficient detection of offensive content to mitigate harmful effects. Although sophisticated models perform well on individual datasets, they often fail to generalize due to varying definitions and labeling of “offensive content.” In this... | Huy Nghiem, Hal Daumé III |  |
| 1737 |  |  [Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases](https://doi.org/10.18653/v1/2024.findings-emnlp.344) |  | 0 | The rapid development of social media has led to an increase in online harassment and offensive speech, posing significant challenges for effective content moderation. Existing automated detection models often exhibit a bias towards predicting offensive speech based on specific vocabulary, which... | Jiapeng Liu, Weijie Li, Xiaochao Fan, Wenjun Deng, Liang Yang, Yong Li, Yufeng Diao |  |
| 1738 |  |  [Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option](https://doi.org/10.18653/v1/2024.findings-emnlp.345) |  | 0 | The recently proposed ToolkenGPT tool learning paradigm demonstrates promising performance but suffers from two major issues: first, it cannot benefit from tool documentation, and second, it often makes mistakes in whether to use a tool at all. We introduce Toolken+ that mitigates the first problem... | Konstantin Yakovlev, Sergey I. Nikolenko, Andrey Bout |  |
| 1739 |  |  [SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases](https://doi.org/10.18653/v1/2024.findings-emnlp.346) |  | 0 | With the widespread application of Large Language Models (LLMs) in Natural Language Interfaces to Databases (NLIDBs), concerns about security issues in NLIDBs have been increasing gradually. However, research on sensitive data leakage in NLIDBs is relatively limited. Therefore, we propose a... | Yanqi Song, Ruiheng Liu, Shu Chen, Qianhao Ren, Yu Zhang, Yongqi Yu |  |
| 1740 |  |  [Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection](https://doi.org/10.18653/v1/2024.findings-emnlp.347) |  | 0 | As a manner to augment pretrained large language models (LLM), knowledge injection is critical to develop vertical domain large models and has been widely studied. While most current approaches, including parameter-efficient fine-tuning (PEFT) and block expansion methods, uniformly apply knowledge... | Tianxiang Chen, Zhentao Tan, Tao Gong, Yue Wu, Qi Chu, Bin Liu, Jieping Ye, Nenghai Yu |  |
| 1741 |  |  [Entity or Relation Embeddings? An Analysis of Encoding Strategies for Relation Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.348) |  | 0 | Existing approaches to relation extraction obtain relation embeddings by concatenating embeddings of the head and tail entities. Despite the popularity of this approach, we find that such representations mostly capture the types of the entities involved, leading to false positives and confusion... | Frank Mtumbuka, Steven Schockaert |  |
| 1742 |  |  [Self-Consistency Boosts Calibration for Math Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.349) |  | 0 |  | Ante Wang, Linfeng Song, Ye Tian, Baolin Peng, Lifeng Jin, Haitao Mi, Jinsong Su, Dong Yu |  |
| 1743 |  |  [Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning](https://doi.org/10.18653/v1/2024.findings-emnlp.350) |  | 0 | Instruction tuning aims to align large language models (LLMs) with open-domain instructions and human-preferred responses. While several studies have explored autonomous approaches to distilling and annotating instructions from powerful proprietary LLMs, such as ChatGPT, they often neglect the... | Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang |  |
| 1744 |  |  [On Creating an English-Thai Code-switched Machine Translation in Medical Domain](https://doi.org/10.18653/v1/2024.findings-emnlp.351) |  | 0 | Machine translation (MT) in the medical domain plays a pivotal role in enhancing healthcare quality and disseminating medical knowledge. Despite advancements in English-Thai MT technology, common MT approaches often underperform in the medical field due to their inability to precisely translate... | Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Saejia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat |  |
| 1745 |  |  [CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.352) |  | 0 | Cognitive dynamics, which refer to the evolution in human cognitive processes, are pivotal to advance human understanding of the world. Recent advancements in large language models (LLMs) highlight their potential for cognitive simulation. However, these LLM-based cognitive studies primarily focus... | Yaojia Lv, Haojie Pan, Zekun Wang, Jiafeng Liang, Yuanxing Liu, Ruiji Fu, Ming Liu, Zhongyuan Wang, Bing Qin |  |
| 1746 |  |  [Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric](https://doi.org/10.18653/v1/2024.findings-emnlp.353) |  | 0 | In the pursuit of developing Large Language Models (LLMs) that adhere to societal standards, it is imperative to detect the toxicity in the generated text. The majority of existing toxicity metrics rely on encoder models trained on specific toxicity datasets, which are susceptible to... | Hyukhun Koh, Dohyung Kim, Minwoo Lee, Kyomin Jung |  |
| 1747 |  |  [Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter](https://doi.org/10.18653/v1/2024.findings-emnlp.354) |  | 0 | Political discourse on Twitter is a moving target: politicians continuously make statements about their positions. It is therefore crucial to track their discourse on social media to understand their ideological positions and goals. However, Twitter data is also challenging to work with since it is... | Maximilian Maurer, Tanise Ceron, Sebastian Padó, Gabriella Lapesa |  |
| 1748 |  |  [UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.355) |  | 0 | In the digital era, table structure recognition technology is a critical tool for processing and analyzing large volumes of tabular data. Previous methods primarily focus on visual aspects of table structure recovery but often fail to effectively comprehend the textual semantics within tables,... | Zhenrong Zhang, Shuhang Liu, Pengfei Hu, Jiefeng Ma, Jun Du, Jianshu Zhang, Yu Hu |  |
| 1749 |  |  [PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.356) |  | 0 | Code-switching in speech, particularly between languages that use different scripts, can potentially be correctly transcribed in various forms, including different ways of transliteration of the embedded language into the matrix language script. Traditional methods for measuring accuracy, such as... | Karima Kadaoui, Maryam Al Ali, Hawau Olamide Toyin, Ibrahim Mohammed, Hanan Aldarmaki |  |
| 1750 |  |  [A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations](https://doi.org/10.18653/v1/2024.findings-emnlp.357) |  | 0 | In this paper, we present a study on the impact of so-called multiword expressions (MWEs) and multiword named entities (NEs) on the performance of Chinese-English machine translation (MT) systems. Built on an extended version of the data from the WMT22 Metrics Shared Task (with extra labels of 9... | Huacheng Song, Hongzhi Xu |  |
| 1751 |  |  [SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.358) |  | 0 | Large language models (LLMs) have achieved impressive performance across various domains, but the limited context window and the expensive computational cost of processing long texts restrict their more comprehensive application. In this paper, we propose Selective Compression Attention (SCA), a... | Huanran Zheng, Wei Zhu, Xiaoling Wang |  |
| 1752 |  |  [FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking](https://doi.org/10.18653/v1/2024.findings-emnlp.359) |  | 0 | API call generation is the cornerstone of large language models’ tool-using ability that provides access to the larger world. However, existing supervised and in-context learning approaches suffer from high training costs, poor data efficiency, and generated API calls that can be unfaithful to the... | Zhuoer Wang, Leonardo F. R. Ribeiro, Alexandros Papangelis, Rohan Mukherjee, TzuYen Wang, Xinyan Zhao, Arijit Biswas, James Caverlee, Angeliki Metallinou |  |
| 1753 |  |  [Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.360) |  | 0 | Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs’ abilities in constructive geometric problem-solving, – one of the most fundamental steps in developing human... | Spyridon Mouselinos, Henryk Michalewski, Mateusz Tomasz Malinowski |  |
| 1754 |  |  [AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.361) |  | 0 | Mixture of experts (MoE) has become the standard for constructing production-level large language models (LLMs) due to its promise to boost model capacity without causing significant overheads. Nevertheless, existing MoE methods usually enforce a constant top-k routing for all tokens, which is... | Zihao Zeng, Yibo Miao, Hongcheng Gao, Hao Zhang, Zhijie Deng |  |
| 1755 |  |  [Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.362) |  | 0 | Task-oriented Dialog (ToD) systems have to solve multiple subgoals to accomplish user goals, whereas feedback is often obtained only at the end of the dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training), an iterative training approach for improving ToD systems. We sample... | Magdalena Kaiser, Patrick Ernst, György Szarvas |  |
| 1756 |  |  [CLEAR: Can Language Models Really Understand Causal Graphs?](https://doi.org/10.18653/v1/2024.findings-emnlp.363) |  | 0 | Causal reasoning is a cornerstone of how humans interpret the world. To model and reason about causality, causal graphs offer a concise yet effective solution. Given the impressive advancements in language models, a crucial question arises: can they really understand causal graphs? To this end, we... | Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu |  |
| 1757 |  |  [PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.364) |  | 0 | Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse,... | Gyeongman Kim, Doohyuk Jang, Eunho Yang |  |
| 1758 |  |  [M2QA: Multi-domain Multilingual Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.365) |  | 0 | Generalization and robustness to input variation are core desiderata of machine learning research. Language varies along several axes, most importantly, language instance (e.g. French) and domain (e.g. news). While adapting NLP models to new languages within a single domain, or to new domains... | Leon Engländer, Hannah Sterz, Clifton Poth, Jonas Pfeiffer, Ilia Kuznetsov, Iryna Gurevych |  |
| 1759 |  |  [Unveiling the Invisible: Captioning Videos with Metaphors](https://doi.org/10.18653/v1/2024.findings-emnlp.366) |  | 0 | Metaphors are a common communication tool used in our day-to-day life. The detection and generation of metaphors in textual form have been studied extensively but metaphors in other forms have been under-explored. Recent studies have shown that Vision-Language (VL) models cannot understand visual... | Abisek Rajakumar Kalarani, Pushpak Bhattacharyya, Sumit Shekhar |  |
| 1760 |  |  [How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?](https://doi.org/10.18653/v1/2024.findings-emnlp.367) |  | 0 | Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we perform a meta-evaluation of such methods and assess their reliability across a broad range of tasks. In... | Ehsan Doostmohammadi, Oskar Holmström, Marco Kuhlmann |  |
| 1761 |  |  [RippleCOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.368) |  | 0 |  | Zihao Zhao, Yuchen Yang, Yijiang Li, Yinzhi Cao |  |
| 1762 |  |  [Authorship Obfuscation in Multilingual Machine-Generated Text Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.369) |  | 0 | High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship... | Dominik Macko, Róbert Móro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Mária Bieliková |  |
| 1763 |  |  [Comparing Edge-based and Node-based Methods on a Citation Prediction Task](https://doi.org/10.18653/v1/2024.findings-emnlp.370) |  | 0 | Citation Prediction, estimating whether paper a cites paper b, is particularly interesting in a forecasting setting where the model is trained on papers published before time t, and evaluated on papers published after h, where h is the forecast horizon. Performance improves with t (larger training... | Peter Vickers, Kenneth Church |  |
| 1764 |  |  [DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.371) |  | 0 | Pre-trained Language Models (PLMs) exhibit good accuracy and generalization ability across various tasks using self-supervision, but their large size results in high inference latency. Early Exit (EE) strategies handle the issue by allowing the samples to exit from classifiers attached to the... | Divya Jyoti Bajpai, Manjesh K. Hanawal |  |
| 1765 |  |  [LaCo: Large Language Model Pruning via Layer Collapse](https://doi.org/10.18653/v1/2024.findings-emnlp.372) |  | 0 |  | Yifei Yang, Zouying Cao, Hai Zhao |  |
| 1766 |  |  [Llamipa: An Incremental Discourse Parser](https://doi.org/10.18653/v1/2024.findings-emnlp.373) |  | 0 | This paper provides the first discourse parsing experiments with a large language model (LLM) finetuned on corpora annotated in the style of SDRT (Segmented Discourse Representation Theory, Asher (1993), Asher and Lascarides (2003)). The result is a discourse parser, Llamipa (Llama Incremental... | Kate Thompson, Akshay Chaturvedi, Julie Hunter, Nicholas Asher |  |
| 1767 |  |  [Nebula: A discourse aware Minecraft Builder](https://doi.org/10.18653/v1/2024.findings-emnlp.374) |  | 0 | When engaging in collaborative tasks, humans efficiently exploit the semantic structure of a conversation to optimize verbal and nonverbal interactions. But in recent “language to code” or “language to action” models, this information is lacking. We show how incorporating the prior discourse and... | Akshay Chaturvedi, Kate Thompson, Nicholas Asher |  |
| 1768 |  |  [Improving Referring Ability for Biomedical Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.375) |  | 0 | Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into powerful LLMs that have been pre-trained in general... | Junfeng Jiang, Fei Cheng, Akiko Aizawa |  |
| 1769 |  |  [CapEEN: Image Captioning with Early Exits and Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-emnlp.376) |  | 0 | Deep neural networks (DNNs) have made significant progress in recognizing visual elements and generating descriptive text in image-captioning tasks. However, their improved performance comes from increased computational burden and inference latency. Early Exit (EE) strategies can be used to enhance... | Divya Jyoti Bajpai, Manjesh Kumar Hanawal |  |
| 1770 |  |  [LumberChunker: Long-Form Narrative Document Segmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.377) |  | 0 | Modern NLP tasks increasingly rely on dense retrieval methods to access up-to-date and relevant contextual information. We are motivated by the premise that retrieval benefits from segments that can vary in size such that a content’s semantic independence is better captured. We propose... | André V. Duarte, João Marques, Miguel Graça, Miguel Freire, Lei Li, Arlindo L. Oliveira |  |
| 1771 |  |  [Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions](https://doi.org/10.18653/v1/2024.findings-emnlp.378) |  | 0 | Language models (LMs) can hallucinate when performing complex mathematical reasoning. Physics provides a rich domain for assessing their mathematical capabilities, where physical context requires that any symbolic manipulation satisfies complex semantics (e.g., units, tensorial order). In this... | Jordan Meadows, Tamsin James, André Freitas |  |
| 1772 |  |  [Unlocking Continual Learning Abilities in Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.379) |  | 0 |  | Wenyu Du, Shuang Cheng, Tongxu Luo, Zihan Qiu, Zeyu Huang, Ka Chun Cheung, Reynold Cheng, Jie Fu |  |
| 1773 |  |  [On the Rigour of Scientific Writing: Criteria, Analysis, and Insights](https://doi.org/10.18653/v1/2024.findings-emnlp.380) |  | 0 | Rigour is crucial for scientific research as it ensures the reproducibility and validity of results and findings. Despite its importance, little work exists on modelling rigour computationally, and there is a lack of analysis on whether these criteria can effectively signal or measure the rigour of... | Joseph James, Chenghao Xiao, Yucheng Li, Chenghua Lin |  |
| 1774 |  |  [MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling](https://doi.org/10.18653/v1/2024.findings-emnlp.381) |  | 0 | With the advancement of multimedia technologies, news documents and user-generated content are often represented as multiple modalities, making Multimedia Event Extraction (MEE) an increasingly important challenge. However, recent MEE methods employ weak alignment strategies and data augmentation... | Philipp Seeberger, Dominik Wagner, Korbinian Riedhammer |  |
| 1775 |  |  [Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.382) |  | 0 | Iterative preference learning, though yielding superior performances, requires online annotated preference labels. In this work, we study strategies to save annotation budgets while achieving competitive or even better performances for iterative preference learning. Built on intuitions from active... | Sen Yang, Leyang Cui, Deng Cai, Xinting Huang, Shuming Shi, Wai Lam |  |
| 1776 |  |  [Cross-lingual Contextualized Phrase Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.383) |  | 0 | Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment... | Huayang Li, Deng Cai, Zhi Qu, Qu Cui, Hidetaka Kamigaito, Lemao Liu, Taro Watanabe |  |
| 1777 |  |  [VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.384) |  | 0 | In the video-language domain, recent works in leveraging zero-shot Large Language Model-based reasoning for video understanding have become competitive challengers to previous end-to-end models. However, long video understanding presents unique challenges due to the complexity of reasoning over... | Ruotong Liao, Max Erler, Huiyu Wang, Guangyao Zhai, Gengyuan Zhang, Yunpu Ma, Volker Tresp |  |
| 1778 |  |  [Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement](https://doi.org/10.18653/v1/2024.findings-emnlp.385) |  | 0 | Decompilation transforms compiled code back into a high-level programming language for analysis when source code is unavailable. Previous work has primarily focused on enhancing decompilation performance by increasing the scale of model parameters or training data for pre-training. Based on the... | Yunlong Feng, Dechuan Teng, Yang Xu, Honglin Mu, Xiao Xu, Libo Qin, Qingfu Zhu, Wanxiang Che |  |
| 1779 |  |  [Efficiently Computing Susceptibility to Context in Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.386) |  | 0 | One strength of modern language models is their ability to incorporate information from a user-input context when answering queries. However, they are not equally sensitive to the subtle changes to that context.To quantify this, Du et al. (2024) gives an information-theoretic metric to measure such... | Tianyu Liu, Kevin Du, Mrinmaya Sachan, Ryan Cotterell |  |
| 1780 |  |  [ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases](https://doi.org/10.18653/v1/2024.findings-emnlp.387) |  | 0 | With the expansion of pre-trained language model usage in recent years, the importance of datasets for performing tasks in specialized domains has significantly increased. Therefore, we have built a Korean dataset called ESG-Kor to automatically extract Environmental, Social, and Governance (ESG)... | Jaeyoung Lee, Geonyeong Son, Misuk Kim |  |
| 1781 |  |  [Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information](https://doi.org/10.18653/v1/2024.findings-emnlp.388) |  | 0 | Chain-of-Thought (CoT) has become a vital technique for enhancing the performance of Large Language Models (LLMs), attracting increasing attention from researchers. One stream of approaches focuses on the iterative enhancement of LLMs by continuously verifying and refining their reasoning outputs... | Yongheng Zhang, Qiguang Chen, Jingxuan Zhou, Peng Wang, Jiasheng Si, Jin Wang, Wenpeng Lu, Libo Qin |  |
| 1782 |  |  [Hope 'The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer](https://doi.org/10.18653/v1/2024.findings-emnlp.389) |  | 0 |  | Anas Anwarul Haq Khan, Tanik Saikh, Arpan Phukan, Asif Ekbal |  |
| 1783 |  |  [Learning Semantic Structure through First-Order-Logic Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.390) |  | 0 | In this paper, we study whether transformer-based language models can extract predicate argument structure from simple sentences. We firstly show that language models sometimes confuse which predicates apply to which objects. To mitigate this, we explore two tasks: question answering (Q/A), and... | Akshay Chaturvedi, Nicholas Asher |  |
| 1784 |  |  [A Training Data Recipe to Accelerate A\* Search with Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.391) |  | 0 | Combining Large Language Models (LLMs) with heuristic search algorithms like A\* holds the promise of enhanced LLM reasoning and scalable inference. To accelerate training and reduce computational demands, we investigate the coreset selection problem for the training data of LLM heuristic learning.... | Devaansh Gupta, Boyang Li |  |
| 1785 |  |  [From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions](https://doi.org/10.18653/v1/2024.findings-emnlp.392) |  | 0 | As artificial intelligence reasoning abilities gain prominence, generating reliable benchmarks becomes crucial. The Abstract and Reasoning Corpus (ARC) offers challenging problems yet unsolved by AI. While ARC effectively assesses reasoning, its generation-based evaluation overlooks other... | Donghyeon Shin, Seungpil Lee, Klea Kovacec, Sundong Kim |  |
| 1786 |  |  [What's under the hood: Investigating Automatic Metrics on Meeting Summarization](https://doi.org/10.18653/v1/2024.findings-emnlp.393) |  | 0 | Meeting summarization has become a critical task considering the increase in online interactions. Despite new techniques being proposed regularly, the evaluation of meeting summarization techniques relies on metrics not tailored to capture meeting-specific errors, leading to ineffective assessment.... | Frederic Kirstein, Jan Philip Wahle, Terry Ruas, Bela Gipp |  |
| 1787 |  |  [Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages](https://doi.org/10.18653/v1/2024.findings-emnlp.394) |  | 0 | LLMs have become a go-to solution not just for text generation, but also for natural language understanding (NLU) tasks. Acquiring extensive knowledge through language modeling on web-scale corpora, they excel on English NLU, yet struggle to extend their NLU capabilities to underrepresented... | Fabian David Schmidt, Philipp Borchert, Ivan Vulic, Goran Glavas |  |
| 1788 |  |  [CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays](https://doi.org/10.18653/v1/2024.findings-emnlp.395) |  | 0 |  | Nuowei Liu, Xinhao Chen, Hongyi Wu, Changzhi Sun, Man Lan, Yuanbin Wu, Xiaopeng Bai, Shaoguang Mao, Yan Xia |  |
| 1789 |  |  [An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference](https://doi.org/10.18653/v1/2024.findings-emnlp.396) |  | 0 | The development of state-of-the-art generative large language models (LLMs) disproportionately relies on English-centric tokenizers, vocabulary and pre-training data. Despite the fact that some LLMs have multilingual capabilities, recent studies have shown that their inference efficiency... | Atsuki Yamaguchi, Aline Villavicencio, Nikolaos Aletras |  |
| 1790 |  |  [AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.397) |  | 0 | Although Large Language Models (LLMs) are becoming increasingly powerful, they still exhibit significant but subtle weaknesses, such as mistakes in instruction-following or coding tasks.As these unexpected errors could lead to severe consequences in practical deployments, it is crucial to... | Jiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang |  |
| 1791 |  |  [BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization](https://doi.org/10.18653/v1/2024.findings-emnlp.398) |  | 0 | While learning to align Large Language Models (LLMs) with human preferences has shown remarkable success, aligning these models to meet the diverse user preferences presents further challenges in preserving previous knowledge. This paper examines the impact of personalized preference optimization... | Gihun Lee, Minchan Jeong, Yujin Kim, Hojung Jung, Jaehoon Oh, SangMook Kim, SeYoung Yun |  |
| 1792 |  |  [Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.399) |  | 0 | In this work, we address the challenge of cross-lingual proper noun recognition in automatic speech recognition (ASR), where proper nouns in an utterance may originate from a language different from the language in which the ASR system is trained. We enhance the performance of end-to-end ASR... | Rishabh Kumar, Sabyasachi Ghosh, Ganesh Ramakrishnan |  |
| 1793 |  |  [Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting](https://doi.org/10.18653/v1/2024.findings-emnlp.400) |  | 0 | Large language models (LLMs) have become the preferred solution for many natural language processing tasks. In low-resource environments such as specialized domains, their few-shot capabilities are expected to deliver high performance. Named Entity Recognition (NER) is a critical task in... | Marco Naguib, Xavier Tannier, Aurélie Névéol |  |
| 1794 |  |  [STTATTS: Unified Speech-To-Text And Text-To-Speech Model](https://doi.org/10.18653/v1/2024.findings-emnlp.401) |  | 0 | Speech recognition and speech synthesis models are typically trained separately, each with its own set of learning objectives, training data, and model parameters, resulting in two distinct large networks. We propose a parameter-efficient approach to learning ASR and TTS jointly via a multi-task... | Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki |  |
| 1795 |  |  [From Text Segmentation to Enhanced Representation Learning: A Novel Approach to Multi-Label Classification for Long Texts](https://doi.org/10.18653/v1/2024.findings-emnlp.402) |  | 0 | Multi-label text classification (MLTC) is an important task in the field of natural language processing. Most existing models rely on high-quality text representations provided by pre-trained language models (PLMs). They hence face the challenge of input length limitation caused by PLMs, when... | Wang Zhang, Xin Wang, Qian Wang, Tao Deng, Xiaoru Wu |  |
| 1796 |  |  [Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL](https://doi.org/10.18653/v1/2024.findings-emnlp.403) |  | 0 | Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy in real-world applications, highlighting the importance of... | Qihuang Zhong, Kunfeng Chen, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao |  |
| 1797 |  |  [ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees](https://doi.org/10.18653/v1/2024.findings-emnlp.404) |  | 0 | Uncertainty quantification (UQ) in natural language generation (NLG) tasks remains an open challenge, exacerbated by the closed-source nature of the latest large language models (LLMs). This study investigates applying conformal prediction (CP), which can transform any heuristic uncertainty notion... | Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Xiaoshuang Shi, Kaidi Xu, Heng Tao Shen, Xiaofeng Zhu |  |
| 1798 |  |  [Irrelevant Alternatives Bias Large Language Model Hiring Decisions](https://doi.org/10.18653/v1/2024.findings-emnlp.405) |  | 0 | We investigate whether LLMs display a well-known human cognitive bias, the attraction effect, in hiring decisions. The attraction effect occurs when the presence of an inferior candidate makes a superior candidate more appealing, increasing the likelihood of the superior candidate being chosen over... | Kremena Valkanova, Pencho Yordanov |  |
| 1799 |  |  [PclGPT: A Large Language Model for Patronizing and Condescending Language Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.406) |  | 0 | Disclaimer: Samples in this paper may be harmful and cause discomfort! Patronizing and condescending language (PCL) is a form of speech directed at vulnerable groups. As an essential branch of toxic language, this type of language exacerbates conflicts and confrontations among Internet communities... | Hongbo Wang, Mingda Li, Junyu Lu, Hebin Xia, Liang Yang, Bo Xu, Ruizhu Liu, Hongfei Lin |  |
| 1800 |  |  [MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate](https://doi.org/10.18653/v1/2024.findings-emnlp.407) |  | 0 | Large Language Models (LLMs) have shown exceptional results on current benchmarks when working individually. The advancement in their capabilities, along with a reduction in parameter size and inference times, has facilitated the use of these models as agents, enabling interactions among multiple... | Alfonso Amayuelas, Xianjun Yang, Antonis Antoniades, Wenyue Hua, Liangming Pan, William Yang Wang |  |
| 1801 |  |  [CEAMC: Corpus and Empirical Study of Argument Analysis in Education via LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.408) |  | 0 | This paper introduces the Chinese Essay Argument Mining Corpus (CEAMC), a manually annotated dataset designed for argument component classification on multiple levels of granularity. Existing argument component types in education remain simplistic and isolated, failing to encapsulate the complete... | Yupei Ren, Hongyi Wu, Zhaoguang Long, Shangqing Zhao, Xinyi Zhou, Zheqin Yin, Xinlin Zhuang, Xiaopeng Bai, Man Lan |  |
| 1802 |  |  [Ada-Instruct: Adapting Instruction Generators for Complex Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.409) |  | 0 | Instructions augmentation is a crucial step for unleashing the full potential of large language models (LLMs) in downstream tasks. Existing Self-Instruct methods primarily simulate new instructions from a few initial instructions with in-context learning. However, our study identifies a critical... | Wanyun Cui, Qianle Wang |  |
| 1803 |  |  [LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.410) |  | 0 | Non-Factoid (NF) Question Answering (QA) is challenging to evaluate due to diverse potential answers and no objective criterion. The commonly used automatic evaluation metrics like ROUGE or BERTScore cannot accurately measure semantic similarities or answers from different perspectives. Recently,... | Sihui Yang, Keping Bi, Wanqing Cui, Jiafeng Guo, Xueqi Cheng |  |
| 1804 |  |  [Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations](https://doi.org/10.18653/v1/2024.findings-emnlp.411) |  | 0 | Existing research predominantly focuses on developing powerful large language models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful... | Nuo Chen, Zinan Zheng, Ning Wu, Ming Gong, Dongmei Zhang, Jia Li |  |
| 1805 |  |  [SynthEval: Hybrid Behavioral Testing of NLP Models with Synthetic Evaluation](https://doi.org/10.18653/v1/2024.findings-emnlp.412) |  | 0 | Traditional benchmarking in NLP typically involves using static, held-out test sets and calculating aggregated statistics based on diverse examples. However, this approach often results in an overestimation of performance and lacks the ability to offer comprehensive, interpretable, and dynamic... | Raoyuan Zhao, Abdullatif Köksal, Yihong Liu, Leonie Weissweiler, Anna Korhonen, Hinrich Schütze |  |
| 1806 |  |  [TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish](https://doi.org/10.18653/v1/2024.findings-emnlp.413) |  | 0 | Multiple choice question answering tasks evaluate the reasoning, comprehension, and mathematical abilities of Large Language Models (LLMs). While existing benchmarks employ automatic translation for multilingual evaluation, this approach is error-prone and potentially introduces culturally biased... | Arda Yüksel, Abdullatif Köksal, Lütfi Kerem Senel, Anna Korhonen, Hinrich Schütze |  |
| 1807 |  |  [LongForm: Effective Instruction Tuning with Reverse Instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.414) |  | 0 | Instruction tuning enables language models to more effectively generalize and better follow user intent. However, obtaining instruction data is costly and challenging. Prior work employs methods such as expensive human annotation, crowd-sourced datasets with alignment issues, and generating noisy... | Abdullatif Köksal, Timo Schick, Anna Korhonen, Hinrich Schütze |  |
| 1808 |  |  [Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective on Molecule Graphs](https://doi.org/10.18653/v1/2024.findings-emnlp.415) |  | 0 | In recent years, Graph Neural Networks (GNNs) have become successful in molecular property prediction tasks such as toxicity analysis. However, due to the black-box nature of GNNs, their outputs can be concerning in high-stakes decision-making scenarios, e.g., drug discovery. Facing such an issue,... | Yinhan He, Zaiyi Zheng, Patrick Soga, Yaochen Zhu, Yushun Dong, Jundong Li |  |
| 1809 |  |  [Knowledge Mechanisms in Large Language Models: A Survey and Perspective](https://doi.org/10.18653/v1/2024.findings-emnlp.416) |  | 0 | Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial for advancing towards trustworthy AGI. This paper reviews knowledge mechanism analysis from a novel taxonomy including knowledge utilization and evolution. Knowledge utilization delves into the mechanism of memorization,... | Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen, JiaChen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang |  |
| 1810 |  |  [LongHeads: Multi-Head Attention is Secretly a Long Context Processor](https://doi.org/10.18653/v1/2024.findings-emnlp.417) |  | 0 | Large language models (LLMs) have achieved impressive performance in numerous domains but often struggle to process lengthy inputs effectively and efficiently due to limited length generalization and attention’s quadratic computational demands. Many sought to mitigate this by restricting the... | Yi Lu, Xin Zhou, Wei He, Jun Zhao, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1811 |  |  [Crisis counselor language and perceived genuine concern in crisis conversations](https://doi.org/10.18653/v1/2024.findings-emnlp.418) |  | 0 | Although clients’ perceptions of therapist empathy are known to correlate with therapy effectiveness, the specific ways that the therapist’s language use contributes to perceived empathy remain less understood. Natural Language Processing techniques, such as transformer models, permit the... | Greg Buda, Ignacio Tripodi, Margaret Meagher, Elizabeth A. Olson |  |
| 1812 |  |  [Edit-Constrained Decoding for Sentence Simplification](https://doi.org/10.18653/v1/2024.findings-emnlp.419) |  | 0 | We propose edit operation based lexically constrained decoding for sentence simplification. In sentence simplification, lexical paraphrasing is one of the primary procedures for rewriting complex sentences into simpler correspondences. While previous studies have confirmed the efficacy of lexically... | Tatsuya Zetsu, Yuki Arase, Tomoyuki Kajiwara |  |
| 1813 |  |  [Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas](https://doi.org/10.18653/v1/2024.findings-emnlp.420) |  | 0 | Large language models (LLMs) are increasingly being used in human-centered social scientific tasks, such as data annotation, synthetic data creation, and engaging in dialog. However, these tasks are highly subjective and dependent on human factors, such as one’s environment, attitudes, beliefs, and... | Salvatore Giorgi, Tingting Liu, Ankit Aich, Kelsey Isman, Garrick Sherman, Zachary Fried, João Sedoc, Lyle H. Ungar, Brenda Curtis |  |
| 1814 |  |  [Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.421) |  | 0 | Modern natural language generation (NLG) systems have led to the development of synthetic human-like open-ended texts, posing concerns as to who the original author of a text is. To address such concerns, we introduce DeB-Ang: the utilisation of a custom DeBERTa model with angular loss and... | Iqra Zahid, Yue Chang, Tharindu Madusanka, Youcheng Sun, Riza BatistaNavarro |  |
| 1815 |  |  [Intermediate Layer Distillation with the Reused Teacher Classifier: A Study on the Importance of the Classifier of Attention-based Models](https://doi.org/10.18653/v1/2024.findings-emnlp.422) |  | 0 |  | Hang Zhang, Seyyed Hasan Mozafari, James J. Clark, Brett H. Meyer, Warren J. Gross |  |
| 1816 |  |  [Enhancing Large Language Model Based Sequential Recommender Systems with Pseudo Labels Reconstruction](https://doi.org/10.18653/v1/2024.findings-emnlp.423) |  | 0 | Large language models (LLMs) are utilized in various studies, and they also demonstrate a potential to function independently as a recommendation model. Nevertheless, training sequences and text labels modifies LLMs’ pre-trained weights, diminishing their inherent strength in constructing and... | Hyunsoo Na, Minseok Gang, Youngrok Ko, Jinseok Seol, Sanggoo Lee |  |
| 1817 |  |  [On the Generalization of Training-based ChatGPT Detection Methods](https://doi.org/10.18653/v1/2024.findings-emnlp.424) |  | 0 | Large language models, such as ChatGPT, achieve amazing performance on various language processing tasks. However, they can also be exploited for improper purposes such as plagiarism or misinformation dissemination. Thus, there is an urgent need to detect the texts generated by LLMs. One type of... | Han Xu, Jie Ren, Pengfei He, Shenglai Zeng, Yingqian Cui, Amy Liu, Hui Liu, Jiliang Tang |  |
| 1818 |  |  [Private prediction for large-scale synthetic text generation](https://doi.org/10.18653/v1/2024.findings-emnlp.425) |  | 0 | We present an approach for generating differentially private synthetic text using large language models (LLMs), via private prediction. In the private prediction framework, we only require the output synthetic data to satisfy differential privacy guarantees. This is in contrast to approaches that... | Kareem Amin, Alex Bie, Weiwei Kong, Alexey Kurakin, Natalia Ponomareva, Umar Syed, Andreas Terzis, Sergei Vassilvitskii |  |
| 1819 |  |  [Generalists vs. Specialists: Evaluating Large Language Models for Urdu](https://doi.org/10.18653/v1/2024.findings-emnlp.426) |  | 0 |  | Samee Arif, Abdul Hameed Azeemi, Agha Ali Raza, Awais Athar |  |
| 1820 |  |  [Improving Multi-Agent Debate with Sparse Communication Topology](https://doi.org/10.18653/v1/2024.findings-emnlp.427) |  | 0 | Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm –... | Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, Eugene Ie |  |
| 1821 |  |  [Evidence Retrieval for Fact Verification using Multi-stage Reranking](https://doi.org/10.18653/v1/2024.findings-emnlp.428) |  | 0 | In the fact verification domain, the accuracy and efficiency of evidence retrieval are paramount. This paper presents a novel approach to enhance the fact verification process through a Multi-stage ReRanking (M-ReRank) paradigm, which addresses the inherent limitations of single-stage evidence... | Shrikant Malviya, Stamos Katsigiannis |  |
| 1822 |  |  [Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision](https://doi.org/10.18653/v1/2024.findings-emnlp.429) |  | 0 | Process supervision, using a trained verifier to evaluate the intermediate steps generated by a reasoner, has demonstrated significant improvements in multi-step problem solving. In this paper, to avoid the expensive effort of human annotation on the verifier training data, we introduce... | Zihan Wang, Yunxuan Li, Yuexin Wu, Liangchen Luo, Le Hou, Hongkun Yu, Jingbo Shang |  |
| 1823 |  |  [MUSCLE: A Model Update Strategy for Compatible LLM Evolution](https://doi.org/10.18653/v1/2024.findings-emnlp.430) |  | 0 | Large Language Models (LLMs) are regularly updated to enhance performance, typically through changes in data or architecture. Within the update process, developers often prioritize improving overall performance metrics, paying less attention to maintaining compatibility with earlier model versions.... | Jessica Maria Echterhoff, Fartash Faghri, Raviteja Vemulapalli, TingYao Hu, ChunLiang Li, Oncel Tuzel, Hadi Pouransari |  |
| 1824 |  |  [Event-Keyed Summarization](https://doi.org/10.18653/v1/2024.findings-emnlp.431) |  | 0 | We introduce \*event-keyed summarization\* (EKS), a novel task that marries traditional summarization and document-level event extraction, with the goal of generating a contextualized summary for a specific event, given a document and an extracted event structure. We introduce a dataset for this... | William Gantt, Alexander Martin, Pavlo Kuchmiichuk, Aaron Steven White |  |
| 1825 |  |  [The Effect of Sampling Temperature on Problem Solving in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.432) |  | 0 | In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then,... | Matthew Renze |  |
| 1826 |  |  [HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents](https://doi.org/10.18653/v1/2024.findings-emnlp.433) |  | 0 | Rhetorical Role Labeling (RRL) of legal documents is pivotal for various downstream tasks such as summarization, semantic case search and argument mining. Existing approaches often overlook the varying difficulty levels inherent in legal document discourse styles and rhetorical roles. In this work,... | T. Y. S. S. Santosh, Apolline Isaia, Shiyu Hong, Matthias Grabmair |  |
| 1827 |  |  [Semi-Supervised Reward Modeling via Iterative Self-Training](https://doi.org/10.18653/v1/2024.findings-emnlp.434) |  | 0 | Reward models (RM) capture the values and preferences of humans and play a central role in Reinforcement Learning with Human Feedback (RLHF) to align pretrained large language models (LLMs). Traditionally, training these models relies on extensive human-annotated preference data, which poses... | Yifei He, Haoxiang Wang, Ziyan Jiang, Alexandros Papangelis, Han Zhao |  |
| 1828 |  |  [Demonstration Selection Strategies for Numerical Time Series Data-to-Text](https://doi.org/10.18653/v1/2024.findings-emnlp.435) |  | 0 | Demonstration selection, the process of selecting examples used in prompts, plays a critical role in in-context learning. This paper explores demonstration selection methods for data-to-text tasks that involve numerical time series data as inputs.Previously developed demonstration selection methods... | Masayuki Kawarada, Tatsuya Ishigaki, Goran Topic, Hiroya Takamura |  |
| 1829 |  |  [ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings through Semantic Similarity Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.436) |  | 0 | Sentence embeddings play a pivotal role in a wide range of NLP tasks, yet evaluating and interpreting these real-valued vectors remains an open challenge to date, especially in a task-free setting. To address this challenge, we introduce a novel task-free test bed for evaluating and interpreting... | Yash Mahajan, Naman Bansal, Eduardo Blanco, Santu Karmaker |  |
| 1830 |  |  [BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.437) |  | 0 | Parameter Efficient Fine-Tuning (PEFT) offers an efficient solution for fine-tuning large pretrained language models for downstream tasks. However, most PEFT strategies are manually designed, often resulting in suboptimal performance. Recent automatic PEFT approaches aim to address this but face... | Aofei Chang, Jiaqi Wang, Han Liu, Parminder Bhatia, Cao Xiao, Ting Wang, Fenglong Ma |  |
| 1831 |  |  [In-Context Learning with Iterative Demonstration Selection](https://doi.org/10.18653/v1/2024.findings-emnlp.438) |  | 0 | Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as... | Chengwei Qin, Aston Zhang, Chen Chen, Anirudh Dagar, Wenming Ye |  |
| 1832 |  |  [On Evaluating Explanation Utility for Human-AI Decision Making in NLP](https://doi.org/10.18653/v1/2024.findings-emnlp.439) |  | 0 | Is explainability a false promise? This debate has emerged from the insufficient evidence that explanations help people in situations they are introduced for. More human-centered, application-grounded evaluations of explanations are needed to settle this. Yet, with no established guidelines for... | Fateme Hashemi Chaleshtori, Atreya Ghosal, Alexander Gill, Purbid Bambroo, Ana Marasovic |  |
| 1833 |  |  [Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance](https://doi.org/10.18653/v1/2024.findings-emnlp.440) |  | 0 | Hierarchical topic models nowadays tend to capture the relationship between words and topics, often ignoring the role of anchor words that guide text generation. For the first time, we detect and add anchor words to the text generation process in an unsupervised way. Firstly, we adopt a clustering... | Jiyuan Liu, Hegang Chen, Chunjiang Zhu, Yanghui Rao |  |
| 1834 |  |  [GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack](https://doi.org/10.18653/v1/2024.findings-emnlp.441) |  | 0 | Large language model (LLM) companies provide Embedding as a Service (EaaS) to assist the individual in efficiently dealing with downstream tasks such as text classification and recommendation. However, recent works reveal the risk of the model stealing attack, posing a financial threat to EaaS... | Liaoyaqi Wang, Minhao Cheng |  |
| 1835 |  |  [Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.442) |  | 0 | Multimodal Large Language Models (MLLMs) demonstrate a strong understanding of the real world and can even handle complex tasks. However, they still fail on some straightforward visual question-answering (VQA) problems. This paper dives deeper into this issue, revealing that models tend to err when... | Sihang Zhao, Youliang Yuan, Xiaoying Tang, Pinjia He |  |
| 1836 |  |  [Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery](https://doi.org/10.18653/v1/2024.findings-emnlp.443) |  | 0 | New intent discovery is a crucial capability for task-oriented dialogue systems. Existing methods focus on transferring in-domain (IND) prior knowledge to out-of-domain (OOD) data through pre-training and clustering stages. They either handle the two processes in a pipeline manner, which exhibits a... | Yimin Deng, Yuxia Wu, Guoshuai Zhao, Li Zhu, Xueming Qian |  |
| 1837 |  |  [RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization](https://doi.org/10.18653/v1/2024.findings-emnlp.444) |  | 0 | Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient Fine-Tuning (PEFT) method, significantly enhances the training efficiency by updating only a small portion of the weights in Large Language Models (LLMs). Recently, weight-only quantization techniques have also been applied to LoRA... | Xijie Huang, Zechun Liu, ShihYang Liu, KwangTing Cheng |  |
| 1838 |  |  [Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration](https://doi.org/10.18653/v1/2024.findings-emnlp.445) |  | 0 | Large Language Models (LLMs) could struggle to fully understand legal theories and perform complex legal reasoning tasks. In this study, we introduce a challenging task (confusing charge prediction) to better evaluate LLMs’ understanding of legal theories and reasoning capabilities. We also propose... | Weikang Yuan, Junjie Cao, Zhuoren Jiang, Yangyang Kang, Jun Lin, Kaisong Song, Tianqianjin Lin, Pengwei Yan, Changlong Sun, Xiaozhong Liu |  |
| 1839 |  |  [Retrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.446) |  | 0 | Despite Large Language Models (LLMs) have performed impressively in various Natural Language Processing (NLP) tasks, their inherent hallucination phenomena severely challenge their credibility in complex reasoning. Combining explainable Knowledge Graphs (KGs) with LLMs is a promising path to... | Yixin Ji, Kaixin Wu, Juntao Li, Wei Chen, Mingjie Zhong, Jia Xu, Min Zhang |  |
| 1840 |  |  [Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell](https://doi.org/10.18653/v1/2024.findings-emnlp.447) |  | 0 | Large Language Models (LLMs) exhibit positional bias, struggling to utilize information from the middle or end of long contexts. Our study explores LLMs’ long-context reasoning by probing their hidden representations. We find that while LLMs encode the position of target information, they often... | Muhan Gao, Taiming Lu, Kuai Yu, Adam Byerly, Daniel Khashabi |  |
| 1841 |  |  [E²CL: Exploration-based Error Correction Learning for Embodied Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.448) |  | 0 | Language models are exhibiting increasing capability in knowledge utilization and reasoning. However, when applied as agents in embodied environments, they often suffer from misalignment between their intrinsic knowledge and environmental knowledge, leading to infeasible actions. Traditional... | Hanlin Wang, Chak Tou Leong, Jian Wang, Wenjie Li |  |
| 1842 |  |  [BERGEN: A Benchmarking Library for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.449) |  | 0 | Retrieval-Augmented Generation allows to enhance Large Language Models with external knowledge. In response to the recent popularity of generative LLMs, many RAG approaches have been proposed, which involve an intricate number of different configurations such as evaluation datasets, collections,... | David Rau, Hervé Déjean, Nadezhda Chirkova, Thibault Formal, Shuai Wang, Stéphane Clinchant, Vassilina Nikoulina |  |
| 1843 |  |  [Contextualized Graph Representations for Generating Counter-Narratives against Hate Speech](https://doi.org/10.18653/v1/2024.findings-emnlp.450) |  | 0 | Hate speech (HS) is a widely acknowledged societal problem with potentially grave effects on vulnerable individuals and minority groups. Developing counter-narratives (CNs) that confront biases and stereotypes driving hateful narratives is considered an impactful strategy. Current automatic methods... | Selene Baez Santamaría, Helena GómezAdorno, Ilia Markov |  |
| 1844 |  |  [Modeling Historical Relevant and Local Frequency Context for Representation-Based Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.findings-emnlp.451) |  | 0 |  | Shengzhe Zhang, Wei Wei, Rikui Huang, Wenfeng Xie, Dangyang Chen |  |
| 1845 |  |  [Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing](https://doi.org/10.18653/v1/2024.findings-emnlp.452) |  | 0 | With the strong representational capabilities of pre-trained language models, dependency parsing in resource-rich languages has seen significant advancements. However, the parsing accuracy drops sharply when the model is transferred to low-resource language due to distribution shifts. To alleviate... | Ying Li, Jianjian Liu, Zhengtao Yu, Shengxiang Gao, Yuxin Huang, Cunli Mao |  |
| 1846 |  |  [An Instruction Tuning-Based Contrastive Learning Framework for Aspect Sentiment Quad Prediction with Implicit Aspects and Opinions](https://doi.org/10.18653/v1/2024.findings-emnlp.453) |  | 0 | Aspect sentiment quad prediction (ASQP) is crucial in aspect-based sentiment analysis (ABSA). It involves identifying a text’s aspect,sentiment, opinion, and category. Existing methods have insufficiently explored how to effectively leverage the knowledge of pre-trainedlanguage models (PLMs) to... | Hao Zhang, YuN Cheah, Congqing He, Feifan Yi |  |
| 1847 |  |  [MACAROON: Training Vision-Language Models To Be Your Engaged Partners](https://doi.org/10.18653/v1/2024.findings-emnlp.454) |  | 0 | Large vision-language models (LVLMs), while proficient in following instructions and responding to diverse questions, invariably generate detailed responses even when questions are ambiguous or unanswerable, leading to hallucinations and bias issues. Thus, it is essential for LVLMs to proactively... | Shujin Wu, Yi Fung, Sha Li, Yixin Wan, KaiWei Chang, Heng Ji |  |
| 1848 |  |  [ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.455) |  | 0 | In a practical scenario, multi-domain neural machine translation (MDNMT) aims to continuously acquire knowledge from new domain data while retaining old knowledge. Previous work separately learns each new domain knowledge based on parameter isolation methods, which effectively capture the new... | Zhibo Man, Kaiyu Huang, Yujie Zhang, Yuanmeng Chen, Yufeng Chen, Jinan Xu |  |
| 1849 |  |  [Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-emnlp.456) |  | 0 | The impressive capabilities of large language models (LLMs) have attracted extensive interests of applying LLMs to medical field. However, the complex nature of clinical environments presents significant hallucination challenges for LLMs, hindering their widespread adoption. In this paper, we... | Derong Xu, Ziheng Zhang, Zhihong Zhu, Zhenxi Lin, Qidong Liu, Xian Wu, Tong Xu, Xiangyu Zhao, Yefeng Zheng, Enhong Chen |  |
| 1850 |  |  [NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization](https://doi.org/10.18653/v1/2024.findings-emnlp.457) |  | 0 | Recent advances in neural topic models have concentrated on two primary directions: the integration of the inference network (encoder) with a pre-trained language model (PLM) and the modeling of the relationship between words and topics in the generative model (decoder). However, the use of large... | DuyTung Pham, Thien Trang Nguyen Vu, Tung Nguyen, Linh Ngo Van, Duc Anh Nguyen, Thien Huu Nguyen |  |
| 1851 |  |  [LLM Self-Correction with DeCRIM: Decompose, Critique, and Refine for Enhanced Following of Instructions with Multiple Constraints](https://doi.org/10.18653/v1/2024.findings-emnlp.458) |  | 0 | Instruction following is a key capability for LLMs. However, recent studies have shown that LLMs often struggle with instructions containing multiple constraints (e.g. a request to create a social media post “in a funny tone” with “no hashtag”). Despite this, most evaluations focus solely on... | Thomas Palmeira Ferraz, Kartik Mehta, YuHsiang Lin, HawShiuan Chang, Shereen Oraby, Sijia Liu, Vivek Subramanian, Tagyoung Chung, Mohit Bansal, Nanyun Peng |  |
| 1852 |  |  [Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-emnlp.459) |  | 0 | Improving the performance of large language models (LLMs) in complex question-answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs’ performance by combining step-wise planning with external retrieval. While effective for advanced models like... | Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen |  |
| 1853 |  |  [Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?](https://doi.org/10.18653/v1/2024.findings-emnlp.460) |  | 0 | Aspect-based sentiment analysis (ABSA) aims to predict aspect-based elements from the given text, mainly including four elements, i.e., aspect category, sentiment polarity, aspect term, and opinion term. Extracting pair, triple, or quad of elements is defined as compound ABSA. Due to its challenges... | Yinhao Bai, Zhixin Han, Yuhua Zhao, Hang Gao, Zhuowei Zhang, Xunzhi Wang, Mengting Hu |  |
| 1854 |  |  [Multilingual Fine-Grained News Headline Hallucination Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.461) |  | 0 | The popularity of automated news headline generation has surged with advancements in pre-trained language models. However, these models often suffer from the “hallucination” problem, where the generated headline is not fully supported by its source article. Efforts to address this issue have... | Jiaming Shen, Tianqi Liu, Jialu Liu, Zhen Qin, Jay Pavagadhi, Simon Baumgartner, Michael Bendersky |  |
| 1855 |  |  [PE: A Poincare Explanation Method for Fast Text Hierarchy Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.462) |  | 0 | The black-box nature of deep learning models in NLP hinders their widespread application. The research focus has shifted to Hierarchical Attribution (HA) for its ability to model feature interactions. Recent works model non-contiguous combinations with a time-costly greedy search in Eculidean... | Qian Chen, Dongyang Li, Xiaofeng He, Hongzhao Li, Hongyu Yi |  |
| 1856 |  |  [Step-level Value Preference Optimization for Mathematical Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.463) |  | 0 | Direct Preference Optimization (DPO) using an implicit reward model has proven to be an effective alternative to reinforcement learning from human feedback (RLHF) for fine-tuning preference aligned large language models (LLMs). However, the overall preference annotations of responses do not fully... | Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan |  |
| 1857 |  |  [Towards Benchmarking Situational Awareness of Large Language Models: Comprehensive Benchmark, Evaluation and Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.464) |  | 0 | Situational awareness refers to the capacity to perceive and comprehend the present context and anticipate forthcoming events, which plays a critical role in aiding decision-making, anticipating potential issues, and adapting to dynamic circumstances. Nevertheless, the situational awareness... | Guo Tang, Zheng Chu, Wenxiang Zheng, Ming Liu, Bing Qin |  |
| 1858 |  |  [Balancing Visual Context Understanding in Dialogue for Image Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.465) |  | 0 | In the realm of dialogue-to-image retrieval, the primary challenge is to fetch images from a pre-compiled database that accurately reflect the intent embedded within the dialogue history. Existing methods often overemphasize inter-modal alignment, neglecting the nuanced nature of conversational... | Zhaohui Wei, Lizi Liao, Xiaoyu Du, Xinguang Xiang |  |
| 1859 |  |  [Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations](https://doi.org/10.18653/v1/2024.findings-emnlp.466) |  | 0 | State-of-the-art language models (LMs) sometimes generate that misalign with world knowledge. To explore the mechanistic causes of these hallucinations, we create diagnostic datasets with subject-relation queries and adapt interpretability methods to trace hallucinations through internal model... | Lei Yu, Meng Cao, Jackie C. K. Cheung, Yue Dong |  |
| 1860 |  |  [A Study of Implicit Ranking Unfairness in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.467) |  | 0 | Recently, Large Language Models (LLMs) have demonstrated a superior ability to serve as ranking models. However, concerns have arisen as LLMs will exhibit discriminatory ranking behaviors based on users’ sensitive attributes (gender). Worse still, in this paper, we identify a subtler form of... | Chen Xu, Wenjie Wang, Yuxin Li, Liang Pang, Jun Xu, TatSeng Chua |  |
| 1861 |  |  [Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.468) |  | 0 | Large Language Models (LLMs) are increasingly deployed in user-facing applications worldwide, necessitating handling multiple languages across various tasks. We propose a metric called Information Parity (IP) that can predict an LLM’s capabilities across multiple languages in a task-agnostic... | Alexander Tsvetkov, Alon Kipnis |  |
| 1862 |  |  [Better Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization](https://doi.org/10.18653/v1/2024.findings-emnlp.469) |  | 0 | To ensure large language models contain up-to-date knowledge, they need to be updated regularly. However, model editing is challenging as it might also affect knowledge that is unrelated to the new data. State-of-the-art methods identify parameters associated with specific knowledge and then modify... | Mingyang Wang, Lukas Lange, Heike Adel, Jannik Strötgen, Hinrich Schütze |  |
| 1863 |  |  [A Semantic Search Engine for Mathlib4](https://doi.org/10.18653/v1/2024.findings-emnlp.470) |  | 0 | The interactive theorem prover Lean enables the verification of formal mathematical proofs and is backed by an expanding community. Central to this ecosystem is its mathematical library, mathlib4, which lays the groundwork for the formalization of an expanding range of mathematical theories.... | Guoxiong Gao, Haocheng Ju, Jiedong Jiang, Zihan Qin, Bin Dong |  |
| 1864 |  |  [DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.471) |  | 0 | LLMs acquire knowledge from massive data snapshots collected at different timestamps. Their knowledge is then commonly evaluated using static benchmarks. However, factual knowledge is generally subject to time-sensitive changes, and static benchmarks cannot address those cases. We present an... | Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi |  |
| 1865 |  |  [Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue](https://doi.org/10.18653/v1/2024.findings-emnlp.472) |  | 0 | Reinforcement learning (RL) is a powerful approach to enhance task-oriented dialogue (TOD) systems. However, existing RL methods tend to mainly focus on generation tasks, such as dialogue policy learning (DPL) or response generation (RG), while neglecting dialogue state tracking (DST) for... | Huifang Du, Shuqin Li, Minghao Wu, Xuejing Feng, YuanFang Li, Haofen Wang |  |
| 1866 |  |  [Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.473) |  | 0 | We develop assistive agents based on Large Language Models (LLMs) that aid interlocutors in business negotiations.Specifically, we simulate business negotiations by letting two LLM-based agents engage in role play. A third LLM acts as a remediator agent to rewrite utterances violating norms for... | Yuncheng Hua, Lizhen Qu, Reza Haf |  |
| 1867 |  |  [HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing](https://doi.org/10.18653/v1/2024.findings-emnlp.474) |  | 0 | Generative AI has demonstrated unprecedented creativity in the field of computer vision, yet such phenomena have not been observed in natural language processing. In particular, large language models (LLMs) can hardly produce written works at the level of human experts due to the extremely high... | Jing Chen, Xinyu Zhu, Cheng Yang, Chufan Shi, Yadong Xi, Yuxiang Zhang, Junjie Wang, Jiashu Pu, Tian Feng, Yujiu Yang, Rongsheng Zhang |  |
| 1868 |  |  [Advancing Cross-Lingual Entity Alignment with Large Language Models: Tailored Sample Segmentation and Zero-Shot Prompts](https://doi.org/10.18653/v1/2024.findings-emnlp.475) |  | 0 | In recent years, the advent of large language models (LLMs) like GPT and Llama has significantly influenced numerous domains, particularly in advancing natural language processing (NLP) capabilities. LLMs have shown remarkable performance in NLP tasks such as relation extraction (RE) and knowledge... | Linyan Yang, Jingwei Cheng, Fu Zhang |  |
| 1869 |  |  [Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.476) |  | 0 | This paper tackles the task of emotion-cause pair extraction in the unsupervised domain adaptation setting.The problem is challenging as the distributions of the events causing emotions in target domains are dramatically different than those in source domains, despite the distributions of emotional... | Yuncheng Hua, Yujin Huang, Shuo Huang, Tao Feng, Lizhen Qu, Christopher Bain, Richard Bassed, Reza Haf |  |
| 1870 |  |  [Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation](https://doi.org/10.18653/v1/2024.findings-emnlp.477) |  | 0 | Recent advancements in educational platforms have emphasized the importance of personalized education. Accurately estimating question difficulty based on the ability of the student group is essential for personalized question recommendations. Several studies have focused on predicting question... | JaeWoo Park, SeongJin Park, HyunSik Won, KangMin Kim |  |
| 1871 |  |  [Inverse-Q\*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data](https://doi.org/10.18653/v1/2024.findings-emnlp.478) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample... | Han Xia, Songyang Gao, Qiming Ge, Zhiheng Xi, Qi Zhang, Xuanjing Huang |  |
| 1872 |  |  [Activation Scaling for Steering and Interpreting Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.479) |  | 0 | Given the prompt “Rome is in”, can we steer a language model to flip its prediction of an incorrect token “France” to a correct token “Italy” by only multiplying a few relevant activation vectors with scalars? We argue that successfully intervening on a model is a prerequisite for interpreting its... | Niklas Stoehr, Kevin Du, Vésteinn Snæbjarnarson, Robert West, Ryan Cotterell, Aaron Schein |  |
| 1873 |  |  [LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.480) |  | 0 | Integrating speech and text capabilities into large language models (LLMs) is a challenging task and we present Large Rank Adaptation (LaRA) for effective cross-modal integration of speech and text in the LLM framework. Unlike conventional LoRA, our method requires significantly larger ranks... | Zuhair Hasan Shaik, Pradyoth Hegde, Prashant Bannulmath, Deepak K. T. |  |
| 1874 |  |  [DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.481) |  | 0 | Leading models for the text-to-SQL task heavily rely on proprietary Large Language Models (LLMs), posing concerns over data privacy. Closing the performance gap between small open-source models and large proprietary models is crucial to mitigate this reliance. To this end, we introduce a novel... | Mohammadreza Pourreza, Davood Rafiei |  |
| 1875 |  |  [MedINST: Meta Dataset of Biomedical Instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.482) |  | 0 | The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge. Medical data and tasks, which vary in format, size, and other parameters,... | Wenhan Han, Meng Fang, Zihan Zhang, Yu Yin, Zirui Song, Ling Chen, Mykola Pechenizkiy, Qingyu Chen |  |
| 1876 |  |  [PropTest: Automatic Property Testing for Improved Visual Programming](https://doi.org/10.18653/v1/2024.findings-emnlp.483) |  | 0 | Visual Programming has recently emerged as an alternative to end-to-end black-box visual reasoning models. This type of method leverages Large Language Models (LLMs) to generate the source code for an executable computer program that solves a given problem. This strategy has the advantage of... | Jaywon Koo, Ziyan Yang, Paola CascanteBonilla, Baishakhi Ray, Vicente Ordonez |  |
| 1877 |  |  [BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers](https://doi.org/10.18653/v1/2024.findings-emnlp.484) |  | 0 | Although many works have been developed to improve the fairness of deep learning models, their resilience against malicious attacks—particularly the growing threat of backdoor attacks—has not been thoroughly explored.Attacking fairness is crucial because compromised models can introduce biased... | Jiaqi Xue, Qian Lou, Mengxin Zheng |  |
| 1878 |  |  [Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts](https://doi.org/10.18653/v1/2024.findings-emnlp.485) |  | 0 | While effective data visualization is crucial to present complex information in academic research, its creation demands significant expertise in both data management and graphic design. We explore the potential of using Vision-Language Models (VLMs) in automating the creation of data visualizations... | Zhehao Zhang, Weicheng Ma, Soroush Vosoughi |  |
| 1879 |  |  [Financial Forecasting from Textual and Tabular Time Series](https://doi.org/10.18653/v1/2024.findings-emnlp.486) |  | 0 | There is a variety of multimodal data pertinent to public companies, spanning from accounting statements, macroeconomic statistics, earnings conference calls, and financial reports. These diverse modalities capture the state of firms from a variety of different perspectives but requires complex... | Ross Koval, Nicholas Andrews, Xifeng Yan |  |
| 1880 |  |  [Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA](https://doi.org/10.18653/v1/2024.findings-emnlp.487) |  | 0 | Large language models (LLMs) have attracted increasing attention due to its prominent performance on various tasks. Recent works seek to leverage LLMs on knowledge-based visual question answering (VQA) tasks which require common sense knowledge to answer the question about an image, since LLMs have... | Xiaoying Xing, Peixi Xiong, Lei Fan, Yunxuan Li, Ying Wu |  |
| 1881 |  |  [CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules](https://doi.org/10.18653/v1/2024.findings-emnlp.488) |  | 0 | We consider the problem of finding plausible rules that are missing from a given ontology. A number of strategies for this problem have already been considered in the literature. Little is known about the relative performance of these strategies, however, as they have thus far been evaluated on... | Na Li, Thomas Bailleux, Zied Bouraoui, Steven Schockaert |  |
| 1882 |  |  [Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout](https://doi.org/10.18653/v1/2024.findings-emnlp.489) |  | 0 | Recently, leveraging reinforcement learning (RL) to fine-tune language models (LMs), known as reinforcement learning from human feedback (RLHF), has become an important research topic. However, there is still a lack of theoretical understanding of how RLHF works, the conditions under which it... | Changhun Lee, Chiehyeon Lim |  |
| 1883 |  |  [Weak-to-Strong Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.490) |  | 0 | When large language models (LLMs) surpass human capabilities, supervising them effectively becomes difficult. Weak-to-strong learning, where a less capable model enhances a stronger one, proves valuable in this context. Yet, the efficacy of this paradigm for complex reasoning tasks is still... | Yuqing Yang, Yan Ma, Pengfei Liu |  |
| 1884 |  |  [Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation](https://doi.org/10.18653/v1/2024.findings-emnlp.491) |  | 0 | Language models are capable of memorizing detailed patterns and information, leading to a double-edged effect: they achieve impressive modeling performance on downstream tasks with the stored knowledge but also raise significant privacy concerns. Traditional differential privacy based training... | Xianzhi Li, Ran Zmigrod, Zhiqiang Ma, Xiaomo Liu, Xiaodan Zhu |  |
| 1885 |  |  [The Mystery of Compositional Generalization in Graph-based Generative Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.492) |  | 0 | While LLMs have emerged as performant architectures for reasoning tasks, their compositional generalization capabilities have been questioned. In this work, we introduce a Compositional Generalization Challenge for Graph-based Commonsense Reasoning (CGGC) that goes beyond previous evaluations that... | Xiyan Fu, Anette Frank |  |
| 1886 |  |  [AutoHallusion: Automatic Generation of Hallucination Benchmarks for Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.493) |  | 0 | Large vision-language models (LVLMs) are prone to hallucinations, where certain contextual cues in an image can trigger the language module to produce overconfident and incorrect reasoning about abnormal or hypothetical objects. While some benchmarks have been developed to investigate LVLM... | Xiyang Wu, Tianrui Guan, Dianqi Li, Shuaiyi Huang, Xiaoyu Liu, Xijun Wang, Ruiqi Xian, Abhinav Shrivastava, Furong Huang, Jordan L. BoydGraber, Tianyi Zhou, Dinesh Manocha |  |
| 1887 |  |  [MetaKP: On-Demand Keyphrase Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.494) |  | 0 | Traditional keyphrase prediction methods predict a single set of keyphrases per document, failing to cater to the diverse needs of users and downstream applications. To bridge the gap, we introduce on-demand keyphrase generation, a novel paradigm that requires keyphrases that conform to specific... | Di Wu, Xiaoxian Shen, KaiWei Chang |  |
| 1888 |  |  [PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer](https://doi.org/10.18653/v1/2024.findings-emnlp.495) |  | 0 | Language style is necessary for AI systems to accurately understand and generate diverse human language. However, previous text style transfer primarily focused on sentence-level data-driven approaches, limiting exploration of potential problems in large language models (LLMs) and the ability to... | Huashan Sun, Yixiao Wu, Yizhe Yang, Yinghao Li, Jiawei Li, Yuhao Ye, Yang Gao |  |
| 1889 |  |  [TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.496) |  | 0 | Retrieval-augmented generation (RAG) offers an effective approach for addressing question answering (QA) tasks. However, the imperfections of the retrievers in RAG models often result in the retrieval of irrelevant information, which could introduce noise and degrade the performance, especially... | Jinyuan Fang, Zaiqiao Meng, Craig MacDonald |  |
| 1890 |  |  [Enable Fast Sampling for Seq2Seq Text Diffusion](https://doi.org/10.18653/v1/2024.findings-emnlp.497) |  | 0 | Diffusion models exhibit promising capacity for generating high-quality text. However, owing to the curved nature of generation path, they necessitate traversing numerous steps to guarantee the text quality. In this paper, we propose an efficient model FMSeq, which utilizes flow matching to... | Pan Liu, Xiaohua Tian, Zhouhan Lin |  |
| 1891 |  |  [AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference](https://doi.org/10.18653/v1/2024.findings-emnlp.498) |  | 0 | Text summarization tasks commonly employ Pre-trained Language Models (PLMs) to fit diverse standard datasets. While these PLMs excel in automatic evaluations, they frequently underperform in human evaluations, indicating a deviation between their generated summaries and human summarization... | Yang Han, Yiming Wang, Rui Wang, Lu Chen, Kai Yu |  |
| 1892 |  |  [CHIRON: Rich Character Representations in Long-Form Narratives](https://doi.org/10.18653/v1/2024.findings-emnlp.499) |  | 0 | Characters are integral to long-form narratives, but are poorly understood by existing story analysis and generation systems. While prior work has simplified characters via graph-based methods and brief character descriptions, we aim to better tackle the problem of representing complex characters... | Alexander Gurung, Mirella Lapata |  |
| 1893 |  |  [Refiner: Restructure Retrieved Content Efficiently to Advance Question-Answering Capabilities](https://doi.org/10.18653/v1/2024.findings-emnlp.500) |  | 0 |  | Zhonghao Li, Xuming Hu, Aiwei Liu, Kening Zheng, Sirui Huang, Hui Xiong |  |
| 1894 |  |  [Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.501) |  | 0 | Expanding the understanding capabilities of multi-modal large language models (MLLMs) for infrared modality is a challenge due to the single-modality nature and limited amount of training data. Existing methods typically construct a uniform embedding space for cross-modal alignment and leverage... | Shixin Jiang, Zerui Chen, Jiafeng Liang, Yanyan Zhao, Ming Liu, Bing Qin |  |
| 1895 |  |  [LPZero: Language Model Zero-cost Proxy Search from Zero](https://doi.org/10.18653/v1/2024.findings-emnlp.502) |  | 0 | Despite the outstanding performance, Neural Architecture Search (NAS) is criticized for massive computation. Recently, Zero-shot NAS has emerged as a promising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce computational demands. Despite this, existing ZC proxies heavily rely... | Peijie Dong, Lujun Li, Xiang Liu, Zhenheng Tang, Xuebo Liu, Qiang Wang, Xiaowen Chu |  |
| 1896 |  |  [Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.503) |  | 0 | Phrases are fundamental linguistic units through which humans convey semantics. This study critically examines the capacity of API-based large language models (LLMs) to comprehend phrase semantics, utilizing three human-annotated datasets. We assess the performance of LLMs in executing phrase... | Rui Meng, Ye Liu, Lifu Tu, Daqing He, Yingbo Zhou, Semih Yavuz |  |
| 1897 |  |  [How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.504) |  | 0 | Recent studies have demonstrated that In-Context Learning (ICL), through the use of specific demonstrations, can align Large Language Models (LLMs) with human preferences known as In-Context Alignment (ICA), indicating that models can comprehend human instructions without requiring parameter... | Heyan Huang, Yinghao Li, Huashan Sun, Yu Bai, Yang Gao |  |
| 1898 |  |  [Variational Language Concepts for Interpreting Foundation Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.505) |  | 0 | Foundation Language Models (FLMs) such as BERT and its variants have achieved remarkable success in natural language processing. To date, the interpretability of FLMs has primarily relied on the attention weights in their self-attention layers. However, these attention weights only provide... | Hengyi Wang, Shiwei Tan, Zhiqing Hong, Desheng Zhang, Hao Wang |  |
| 1899 |  |  [Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.506) |  | 0 | Yonkoma Manga, characterized by its four-panel structure, presents unique challenges due to its rich contextual information and strong sequential features. To address the limitations of current multimodal large language models (MLLMs) in understanding this type of data, we create a novel dataset... | Qi Yang, Jingjie Zeng, Liang Yang, Zhihao Yang, Hongfei Lin |  |
| 1900 |  |  [TWBias: A Benchmark for Assessing Social Bias in Traditional Chinese Large Language Models through a Taiwan Cultural Lens](https://doi.org/10.18653/v1/2024.findings-emnlp.507) |  | 0 |  | HsinYi Hsieh, ShihCheng Huang, Richard TzongHan Tsai |  |
| 1901 |  |  [Unlocking the Potential of Model Merging for Low-Resource Languages](https://doi.org/10.18653/v1/2024.findings-emnlp.508) |  | 0 | Adapting large language models (LLMs) to new languages typically involves continual pre-training (CT) followed by supervised fine-tuning (SFT). However, this CT-then-SFT approach struggles with limited data in the context of low-resource languages, failing to balance language modeling and... | Mingxu Tao, Chen Zhang, Quzhe Huang, Tianyao Ma, Songfang Huang, Dongyan Zhao, Yansong Feng |  |
| 1902 |  |  [PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness](https://doi.org/10.18653/v1/2024.findings-emnlp.509) |  | 0 | Aligning large language models (LLMs) with human values and preferences is a significant challenge. Training-based methods, such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO), require substantial resources and are impractical for API-based LLMs.... | Wenjin Yao, Yidong Wang, Zhuohao Yu, Rui Xie, Shikun Zhang, Wei Ye |  |
| 1903 |  |  [MMedAgent: Learning to Use Medical Tools with Multi-modal Agent](https://doi.org/10.18653/v1/2024.findings-emnlp.510) |  | 0 | Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user... | Binxu Li, Tiankai Yan, Yuanting Pan, Jie Luo, Ruiyang Ji, Jiayuan Ding, Zhe Xu, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang |  |
| 1904 |  |  [SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.511) |  | 0 | Temporal knowledge graph reasoning (TKGR) is a crucial task that involves reasoning at known timestamps to complete the future facts and has attracted more and more attention in recent years. The current TKGR models are mainly based on graph neural networks or tensor decomposition techniques. Few... | Fu Zhang, Jinghao Lin, Jingwei Cheng |  |
| 1905 |  |  [Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping](https://doi.org/10.18653/v1/2024.findings-emnlp.512) |  | 0 | Decoding by contrasting layers (DoLa), is designed to improve the generation quality of large language models (LLMs) by contrasting the prediction probabilities between an early exit output (amateur logits) and the final output (expert logits).However, we find that this approach does not work well... | Wenhao Zhu, Sizhe Liu, Shujian Huang, Shuaijie She, Chris Wendler, Jiajun Chen |  |
| 1906 |  |  [The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.513) |  | 0 | Recent advances in Large Language Models (LLMs) have sparked wide interest in validating and comprehending the human-like cognitive-behavioral traits LLMs may capture and convey. These cognitive-behavioral traits include typically Attitudes, Opinions, Values (AOVs). However, measuring AOVs embedded... | Bolei Ma, Xinpeng Wang, Tiancheng Hu, AnnaCarolina Haensch, Michael A. Hedderich, Barbara Plank, Frauke Kreuter |  |
| 1907 |  |  [Low-Resource Machine Translation through the Lens of Personalized Federated Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.514) |  | 0 | We present a new approach called MeritOpt based on the Personalized Federated Learning algorithm MeritFed that can be applied to Natural Language Tasks with heterogeneous data. We evaluate it on the Low-Resource Machine Translation task, using the datasets of South East Asian and Finno-Ugric... | Viktor Moskvoretskii, Nazarii Tupitsa, Chris Biemann, Samuel Horváth, Eduard Gorbunov, Irina Nikishina |  |
| 1908 |  |  [Can Language Models Recognize Convincing Arguments?](https://doi.org/10.18653/v1/2024.findings-emnlp.515) |  | 0 | The capabilities of large language models (LLMs) have raised concerns about their potential to create and propagate convincing narratives. Here, we study their performance in detecting convincing arguments to gain insights into LLMs’ persuasive capabilities without directly engaging in... | Paula Rescala, Manoel Horta Ribeiro, Tiancheng Hu, Robert West |  |
| 1909 |  |  [Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature](https://doi.org/10.18653/v1/2024.findings-emnlp.516) |  | 0 | The exponential growth of scientific literature necessitates advanced tools for effective knowledge exploration. We present Knowledge Navigator, a system designed to enhance exploratory search abilities by organizing and structuring the retrieved documents from broad topical queries into a... | Uri Katz, Mosh Levy, Yoav Goldberg |  |
| 1910 |  |  [Scalable and Domain-General Abstractive Proposition Segmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.517) |  | 0 | Segmenting text into fine-grained units of meaning is important to a wide range of NLP applications. The default approach of segmenting text into sentences is often insufficient, especially since sentences are usually complex enough to include multiple units of meaning that merit separate treatment... | Mohammad Javad Hosseini, Yang Gao, Tim Baumgärtner, Alex Fabrikant, Reinald Kim Amplayo |  |
| 1911 |  |  [Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention](https://doi.org/10.18653/v1/2024.findings-emnlp.518) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) on small Pre-trained Language Models (PLMs) has emerged as a promising approach to enhance their multi-tasking capabilities. Prevalent methods simultaneously train additional modules (i.e., one task-shared module and multiple task-specific modules) for... | Wenxuan Lu, Songhao Jiang, Yijing Wang, Tianning Zang |  |
| 1912 |  |  [LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.519) |  | 0 | Large language models (LLMs) sometimes demonstrate poor performance on knowledge-intensive tasks, commonsense reasoning is one of them. Researchers typically address these issues by retrieving related knowledge from knowledge graphs or employing self-enhancement methods to elicit knowledge in LLMs.... | Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao |  |
| 1913 |  |  [Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals](https://doi.org/10.18653/v1/2024.findings-emnlp.520) |  | 0 | While current Automated Essay Scoring (AES) methods demonstrate high scoring agreement with human raters, their decision-making mechanisms are not fully understood. Our proposed method, using counterfactual intervention assisted by Large Language Models (LLMs), reveals that BERT-like models... | Yupei Wang, Renfen Hu, Zhe Zhao |  |
| 1914 |  |  [TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.521) |  | 0 | Mainstream approaches to aligning large language models (LLMs) heavily rely on human preference data, particularly when models require periodic updates. The standard process for iterative alignment of LLMs involves collecting new human feedback for each update. However, the data collection process... | Chen Zhang, Chengguang Tang, Dading Chong, Ke Shi, Guohua Tang, Feng Jiang, Haizhou Li |  |
| 1915 |  |  [Datasets for Multilingual Answer Sentence Selection](https://doi.org/10.18653/v1/2024.findings-emnlp.522) |  | 0 | Answer Sentence Selection (AS2) is a critical task for designing effective retrieval-based Question Answering (QA) systems. Most advancements in AS2 focus on English due to the scarcity of annotated datasets for other languages. This lack of resources prevents the training of effective AS2 models... | Matteo Gabburo, Stefano Campese, Federico Agostini, Alessandro Moschitti |  |
| 1916 |  |  [Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization](https://doi.org/10.18653/v1/2024.findings-emnlp.523) |  | 0 | For abstractive text summarization, laborious data annotation and time-consuming model training become two high walls, hindering its further progress. Active Learning, selecting a few informative instances for annotation and model training, sheds light on solving these issues. However, only few... | Dongyuan Li, Ying Zhang, Zhen Wang, Shiyin Tan, Satoshi Kosugi, Manabu Okumura |  |
| 1917 |  |  [Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.524) |  | 0 | Knowledge graph question answering (KGQA) involves answering natural language questions by leveraging structured information stored in a knowledge graph. Typically, KGQA initially retrieve a targeted subgraph from a large-scale knowledge graph, which serves as the basis for reasoning models to... | Yu Zhang, Kehai Chen, Xuefeng Bai, Zhao Kang, Quanjiang Guo, Min Zhang |  |
| 1918 |  |  [Achieving Stronger Generation via Simple Contrastive Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.525) |  | 0 | Instruction tuning is widely used to unlock the abilities of Large Language Models (LLMs) in following human instructions, resulting in substantial performance improvements across various downstream tasks.Furthermore, contrastive decoding methods are employed to enhance instruction-tuned models. To... | Zhimeng Wang, Pinzheng Wang, Juntao Li, Yibin Chen, Min Zhang |  |
| 1919 |  |  [Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling](https://doi.org/10.18653/v1/2024.findings-emnlp.526) |  | 0 | Predicting future international events from textual information, such as news articles, has tremendous potential for applications in global policy, strategic decision-making, and geopolitics. However, existing datasets available for this task are often limited in quality, hindering the progress of... | Daehoon Gwak, Junwoo Park, Minho Park, ChaeHun Park, Hyunchan Lee, Edward Choi, Jaegul Choo |  |
| 1920 |  |  [QPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.527) |  | 0 | Retrieval-augmented generation (RAG) has received much attention for Open-domain question-answering (ODQA) tasks as a means to compensate for the parametric knowledge of large language models (LLMs). While previous approaches focused on processing retrieved passages to remove irrelevant context,... | Minsang Kim, Cheoneum Park, Seung Baek |  |
| 1921 |  |  [ICON: Improving Inter-Report Consistency in Radiology Report Generation via Lesion-aware Mixup Augmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.528) |  | 0 | Previous research on radiology report generation has made significant progress in terms of increasing the clinical accuracy of generated reports. In this paper, we emphasize another crucial quality that it should possess, i.e., inter-report consistency, which refers to the capability of generating... | Wenjun Hou, Yi Cheng, Kaishuai Xu, Yan Hu, Wenjie Li, Jiang Liu |  |
| 1922 |  |  [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.529) |  | 0 | Though large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, and numerous benchmarks are proposed for hallucination detection. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced.... | Kedi Chen, Qin Chen, Jie Zhou, Yishen He, Liang He |  |
| 1923 |  |  [ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.530) |  | 0 | Text simplification is crucial for making texts more accessible, yet current research primarily focuses on sentence-level simplification, neglecting document-level simplification and the different reading levels of target audiences. To bridge these gaps, we introduce ExpertEase, a multi-agent... | Kaijie Mo, Renfen Hu |  |
| 1924 |  |  [Class Name Guided Out-of-Scope Intent Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.531) |  | 0 |  | Chandan Gautam, Sethupathy Parameswaran, Aditya Kane, Yuan Fang, Savitha Ramasamy, Suresh Sundaram, Sunil Sahu, Xiaoli Li |  |
| 1925 |  |  [Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation](https://doi.org/10.18653/v1/2024.findings-emnlp.532) |  | 0 | The training process of large language models (LLMs) often involves varying degrees of test data contamination. Although current LLMs are achieving increasingly better performance on various benchmarks, their performance in practical applications does not always match their benchmark results.... | Qin Zhu, Qinyuan Cheng, Runyu Peng, Xiaonan Li, Ru Peng, Tengxiao Liu, Xipeng Qiu, Xuanjing Huang |  |
| 1926 |  |  [MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech](https://doi.org/10.18653/v1/2024.findings-emnlp.533) |  | 0 | Text-to-speech (TTS) systems that scale up the amount of training data have achieved significant improvements in zero-shot speech synthesis. However, these systems have certain limitations: they require a large amount of training data, which increases costs, and often overlook prosody similarity.... | Taejun Bak, Youngsik Eom, SeungJae Choi, YoungSun Joo |  |
| 1927 |  |  [RoBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies](https://doi.org/10.18653/v1/2024.findings-emnlp.534) |  | 0 | Investigating “Hadith” texts, crucial for theological studies and Islamic jurisprudence, presents challenges due to the linguistic complexity of Arabic, such as its complex morphology. In this paper, we propose an innovative approach to address the challenges of topic modeling in Hadith studies by... | Sania Aftar, Luca Gagliardelli, Amina El Ganadi, Federico Ruozzi, Sonia Bergamaschi |  |
| 1928 |  |  [Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.findings-emnlp.535) |  | 0 | While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA provides a cost-effective pre-training objective and downstream task performance improvements, but worse sentence embeddings. The community tacitly stopped... | Ivan Rep, David Dukic, Jan Snajder |  |
| 1929 |  |  [DetectiveNN: Imitating Human Emotional Reasoning with a Recall-Detect-Predict Framework for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2024.findings-emnlp.536) |  | 0 | Emotion Recognition in conversations (ERC) involves an internal cognitive process that interprets emotional cues by using a collection of past emotional experiences. However, many existing methods struggle to decipher emotional cues in dialogues since they are insufficient in understanding the rich... | Simin Hong, Jun Sun, Taihao Li |  |
| 1930 |  |  [HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs](https://doi.org/10.18653/v1/2024.findings-emnlp.537) |  | 0 | Hypergraphs are characterized by complex topological structure, representing higher-order interactions among multiple entities through hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed... | Adrián Bazaga, Pietro Lio, Gos Micklem |  |
| 1931 |  |  [On Diversified Preferences of Large Language Model Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.538) |  | 0 | Aligning large language models (LLMs) with human preferences has been recognized as the key to improving LLMs’ interaction quality. However, in this pluralistic world, human preferences can be diversified due to annotators’ different tastes, which hinders the effectiveness of LLM alignment methods.... | Dun Zeng, Yong Dai, Pengyu Cheng, Longyue Wang, Tianhao Hu, Wanshun Chen, Nan Du, Zenglin Xu |  |
| 1932 |  |  [LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters](https://doi.org/10.18653/v1/2024.findings-emnlp.539) |  | 0 | Large Language Models (LLMs) have exhibited remarkable performance across various natural language processing tasks. However, deploying LLMs on resource-limited settings remains a challenge. While early-exit techniques offer an effective approach, they often require compromised training methods... | Jiacheng Liu, Peng Tang, Xiaofeng Hou, Chao Li, PhengAnn Heng |  |
| 1933 |  |  [Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.540) |  | 0 | Generative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model’s... | Tianhui Zhang, Bei Peng, Danushka Bollegala |  |
| 1934 |  |  [CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code](https://doi.org/10.18653/v1/2024.findings-emnlp.541) |  | 0 | Large Language Models (LLMs) have achieved remarkable progress in code generation. It now becomes crucial to identify whether the code is AI-generated and to determine the specific model used, particularly for purposes such as protecting Intellectual Property (IP) in industry and preventing... | Batu Guan, Yao Wan, Zhangqian Bi, Zheng Wang, Hongyu Zhang, Pan Zhou, Lichao Sun |  |
| 1935 |  |  [StablePT : Towards Stable Prompting for Few-shot Learning via Input Separation](https://doi.org/10.18653/v1/2024.findings-emnlp.542) |  | 0 | Large language models have shown their ability to become effective few-shot learners with prompting, revoluting the paradigm of learning with data scarcity. However, this approach largely depends on the quality of prompt initialization and always exhibits large variability among different runs.... | Xiaoming Liu, Chen Liu, Zhaohan Zhang, Chengzhengxu Li, Longtian Wang, Yu Lan, Chao Shen |  |
| 1936 |  |  [Natural Evolution-based Dual-Level Aggregation for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.543) |  | 0 | Temporal knowledge graph (TKG) reasoning aims to predict missing facts based on a given history. Most of the existing methods unifiedly model the evolution process of different events and ignore their inherent asynchronous characteristics, resulting in suboptimal performance. To tackle this... | Bin Chen, Chunjing Xiao, Fan Zhou |  |
| 1937 |  |  [Creative and Context-Aware Translation of East Asian Idioms with GPT-4](https://doi.org/10.18653/v1/2024.findings-emnlp.544) |  | 0 | As a type of figurative language, an East Asian idiom condenses rich cultural background into only a few characters. Translating such idioms is challenging for human translators, who often resort to choosing a context-aware translation from an existing list of candidates. However, compiling a... | Kenan Tang, Peiyang Song, Yao Qin, Xifeng Yan |  |
| 1938 |  |  [Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions](https://doi.org/10.18653/v1/2024.findings-emnlp.545) |  | 0 | As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain... | Angana Borah, Rada Mihalcea |  |
| 1939 |  |  [Exploring Hint Generation Approaches for Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.546) |  | 0 | Automatic Question Answering (QA) systems rely on contextual information to provide accurate answers. Commonly, contexts are prepared through either retrieval-based or generation-based methods. The former involves retrieving relevant documents from a corpus like Wikipedia, whereas the latter uses... | Jamshid Mozafari, Abdelrahman Abdallah, Bhawna Piryani, Adam Jatowt |  |
| 1940 |  |  [Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.547) |  | 0 | Sentiment analysis (SA) aims to identify the sentiment expressed in a piece of text, often in the form of a review. Assuming a review and the sentiment associated with it, in this paper we formulate SA as a combination of two tasks: (1) a causal discovery task that distinguishes whether a review... | Zhiheng Lyu, Zhijing Jin, Fernando Gonzalez Adauto, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan |  |
| 1941 |  |  [PEDANTS: Cheap but Effective and Interpretable Answer Equivalence](https://doi.org/10.18653/v1/2024.findings-emnlp.548) |  | 0 | Question answering (QA) can only make progress if we know if an answer is correct, but current answer correctness (AC) metrics struggle with verbose, free-form answers from large language models (LLMs). There are two challenges with current short-form QA evaluations: a lack of diverse styles of... | Zongxia Li, Ishani Mondal, Huy Nghiem, Yijun Liang, Jordan L. BoydGraber |  |
| 1942 |  |  [AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.549) |  | 0 | With the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus on tasks within individual judicial stages, making it difficult to handle complex tasks... | Zhitao He, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Jiexin Xu, Huaijun Li, Kang Liu, Jun Zhao |  |
| 1943 |  |  [Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.550) |  | 0 | Knowledge editing is a rising technique for efficiently updating factual knowledge in large language models (LLMs) with minimal alteration of parameters. However, recent studies have identified side effects, such as knowledge distortion and the deterioration of general abilities, that have emerged... | ChengHsun Hsueh, Paul KuoMing Huang, TzuHan Lin, CheWei Liao, HungChieh Fang, ChaoWei Huang, YunNung Chen |  |
| 1944 |  |  [Improving LLM Attributions with Randomized Path-Integration](https://doi.org/10.18653/v1/2024.findings-emnlp.551) |  | 0 | We present Randomized Path-Integration (RPI) - a path-integration method for explaining language models via randomization of the integration path over the attention information in the model. RPI employs integration on internal attention scores and their gradients along a randomized path, which is... | Oren Barkan, Yehonatan Elisha, Yonatan Toib, Jonathan Weill, Noam Koenigstein |  |
| 1945 |  |  [VeriScore: Evaluating the factuality of verifiable claims in long-form text generation](https://doi.org/10.18653/v1/2024.findings-emnlp.552) |  | 0 | Existing metrics for evaluating the factuality of long-form text, such as FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input text into “atomic claims” and verify each against a knowledge base like Wikipedia. These metrics are not suitable for most generation tasks because... | Yixiao Song, Yekyung Kim, Mohit Iyyer |  |
| 1946 |  |  [Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging](https://doi.org/10.18653/v1/2024.findings-emnlp.553) |  | 0 | Socratic questioning is an effective teaching strategy, encouraging critical thinking and problem-solving. The conversational capabilities of large language models (LLMs) show great potential for providing scalable, real-time student guidance. However, current LLMs often give away solutions... | Priyanka Kargupta, Ishika Agarwal, Dilek HakkaniTür, Jiawei Han |  |
| 1947 |  |  [Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance](https://doi.org/10.18653/v1/2024.findings-emnlp.554) |  | 0 | There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method for classification tasks inspired by how effective... | Ikhyun Cho, Gaeul Kwon, Julia Hockenmaier |  |
| 1948 |  |  [Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy](https://doi.org/10.18653/v1/2024.findings-emnlp.555) |  | 0 | Mental-health therapy involves a complex conversation flow in which patients and therapists continuously negotiate what should be talked about next. For example, therapists might try to shift the conversation’s direction to keep the therapeutic process on track and avoid stagnation, or patients... | Vivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D. Hull, Cristian DanescuNiculescuMizil |  |
| 1949 |  |  [LLM Explainability via Attributive Masking Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.556) |  | 0 | In this paper, we introduce Attributive Masking Learning (AML), a method designed for explaining language model predictions by learning input masks. AML trains an attribution model to identify influential tokens in the input for a given language model’s prediction. The central concept of AML is to... | Oren Barkan, Yonatan Toib, Yehonatan Elisha, Jonathan Weill, Noam Koenigstein |  |
| 1950 |  |  [How Entangled is Factuality and Deception in German?](https://doi.org/10.18653/v1/2024.findings-emnlp.557) |  | 0 | The statement “The earth is flat” is factually inaccurate, but if someone truly believes and argues in its favor, it is not deceptive. Research on deception detection and fact checking often conflates factual accuracy with the truthfulness of statements. This assumption makes it difficult to (a)... | Aswathy Velutharambath, Amelie Wührl, Roman Klinger |  |
| 1951 |  |  [Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation](https://doi.org/10.18653/v1/2024.findings-emnlp.558) |  | 0 | Recent neural news recommenders (NNRs) extend content-based recommendation (1) by aligning additional aspects (e.g., topic, sentiment) between candidate news and user history or (2) by diversifying recommendations w.r.t. these aspects. This customization is achieved by ”hardcoding” additional... | Andreea Iana, Goran Glavas, Heiko Paulheim |  |
| 1952 |  |  [A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.559) |  | 0 | This paper proposes a novel approach to evaluate Counter Narrative (CN) generation using a Large Language Model (LLM) as an evaluator. We show that traditional automatic metrics correlate poorly with human judgements and fail to capture the nuanced relationship between generated CNs and human... | Irune Zubiaga, Aitor Soroa, Rodrigo Agerri |  |
| 1953 |  |  [A Survey on Open Information Extraction from Rule-based Model to Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.560) |  | 0 | Open Information Extraction (OpenIE) represents a crucial NLP task aimed at deriving structured information from unstructured text, unrestricted by relation type or domain. This survey paper provides an overview of OpenIE technologies spanning from 2007 to 2024, emphasizing a chronological... | Pai Liu, Wenyang Gao, Wenjie Dong, Lin Ai, Ziwei Gong, Songfang Huang, Zongsheng Li, Ehsan Hoque, Julia Hirschberg, Yue Zhang |  |
| 1954 |  |  [Enhancing Tool Retrieval with Iterative Feedback from Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.561) |  | 0 | Tool learning aims to enhance and expand large language models’ (LLMs) capabilities with external tools, which has gained significant attention recently. Current methods have shown that LLMs can effectively handle a certain amount of tools through in-context learning or fine-tuning. However, in... | Qiancheng Xu, Yongqi Li, Heming Xia, Wenjie Li |  |
| 1955 |  |  [Detecting Temporal Ambiguity in Questions](https://doi.org/10.18653/v1/2024.findings-emnlp.562) |  | 0 | Detecting and answering ambiguous questions has been a challenging task in open-domain question answering. Ambiguous questions have different answers depending on their interpretation and can take diverse forms. Temporally ambiguous questions are one of the most common types of such questions. In... | Bhawna Piryani, Abdelrahman Abdallah, Jamshid Mozafari, Adam Jatowt |  |
| 1956 |  |  [LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation](https://doi.org/10.18653/v1/2024.findings-emnlp.563) |  | 0 | Low-rank adaptation (LoRA) has become the default approach to fine-tune large language models (LLMs) due to its significant reduction in trainable parameters. However, trainable parameter demand for LoRA increases with increasing model embedding dimensions, leading to high compute costs.... | Seyedarmin Azizi, Souvik Kundu, Massoud Pedram |  |
| 1957 |  |  [Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.564) |  | 0 | Recent advancements in massively multilingual machine translation systems have significantly enhanced translation accuracy; however, even the best performing systems still generate hallucinations, severely impacting user trust. Detecting hallucinations in Machine Translation (MT) remains a critical... | Kenza Benkirane, Laura Gongas, Shahar Pelles, Naomi Fuchs, Joshua Darmon, Pontus Stenetorp, David Ifeoluwa Adelani, Eduardo Sánchez |  |
| 1958 |  |  [Navigating Hallucinations for Reasoning of Unintentional Activities](https://doi.org/10.18653/v1/2024.findings-emnlp.565) |  | 0 | In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first... | Shresth Grover, Vibhav Vineet, Yogesh S. Rawat |  |
| 1959 |  |  [Pruning Foundation Models for High Accuracy without Retraining](https://doi.org/10.18653/v1/2024.findings-emnlp.566) |  | 0 | Despite the superior performance, it is challenging to deploy large language models (LLMs) due to their massive parameters and computations. While pruning is a promising technique to reduce model size and accelerate the inference, the traditional pruning techniques can hardly be applied for LLMs as... | Pu Zhao, Fei Sun, Xuan Shen, Pinrui Yu, Zhenglun Kong, Yanzhi Wang, Xue Lin |  |
| 1960 |  |  [From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.567) |  | 0 | Self-anthropomorphism in robots manifests itself through their display of human-like characteristics in dialogue, such as expressing preferences and emotions. Our study systematically analyzes self-anthropomorphic expression within various dialogue datasets, outlining the contrasts between... | Yu Li, Devamanyu Hazarika, Di Jin, Julia Hirschberg, Yang Liu |  |
| 1961 |  |  [DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking](https://doi.org/10.18653/v1/2024.findings-emnlp.568) |  | 0 | Recent advancements in Natural Language Processing (NLP) have impacted numerous sub-fields such as natural language generation, natural language inference, question answering, and more. However, in the field of question generation, the creation of distractors for multiple-choice questions (MCQ)... | Devrim Çavusoglu, Seçil Sen, Ulas Sert |  |
| 1962 |  |  [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](https://doi.org/10.18653/v1/2024.findings-emnlp.569) |  | 0 | Large language models (LLMs) have shown excellent mastering of human language but still struggle in real-world applications that require mathematical problem-solving. While many strategies and datasets to enhance LLMs’ mathematics are developed, it remains a challenge to simultaneously maintain and... | Yifan Xu, Xiao Liu, Xinghan Liu, Zhenyu Hou, Yueyan Li, Xiaohan Zhang, Zihan Wang, Aohan Zeng, Zhengxiao Du, Wenyi Zhao, Jie Tang, Yuxiao Dong |  |
| 1963 |  |  [MobileQuant: Mobile-friendly Quantization for On-device Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.570) |  | 0 | Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute costs, limiting their widespread use in devices such as... | Fuwen Tan, Royson Lee, Lukasz Dudziak, Shell Xu Hu, Sourav Bhattacharya, Timothy M. Hospedales, Georgios Tzimiropoulos, Brais Martínez |  |
| 1964 |  |  [Do \*they\* mean 'us'? Interpreting Referring Expression variation under Intergroup Bias](https://doi.org/10.18653/v1/2024.findings-emnlp.571) |  | 0 | The variations between in-group and out-group speech (intergroup bias) are subtle and could underlie many social phenomena like stereotype perpetuation and implicit bias. In this paper, we model intergroup bias as a tagging task on English sports comments from forums dedicated to fandom for NFL... | Venkata S. Govindarajan, Matianyu Zang, Kyle Mahowald, David Beaver, Junyi Jessy Li |  |
| 1965 |  |  [A Survey on Detection of LLMs-Generated Content](https://doi.org/10.18653/v1/2024.findings-emnlp.572) |  | 0 | The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated... | Xianjun Yang, Liangming Pan, Xuandong Zhao, Haifeng Chen, Linda R. Petzold, William Yang Wang, Wei Cheng |  |
| 1966 |  |  [Can LLMs Reason in the Wild with Programs?](https://doi.org/10.18653/v1/2024.findings-emnlp.573) |  | 0 | Large Language Models (LLMs) have shown superior capability to solve reasoning problems with programs. While being a promising direction, most of such frameworks are trained and evaluated in settings with a prior knowledge of task requirements. However, as LLMs become more capable, it is necessary... | Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, Faramarz Fekri |  |
| 1967 |  |  [Can Textual Unlearning Solve Cross-Modality Safety Alignment?](https://doi.org/10.18653/v1/2024.findings-emnlp.574) |  | 0 | Recent studies reveal that integrating new modalities into large language models (LLMs), such as vision-language models (VLMs), creates a new attack surface that bypasses existing safety training techniques like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).... | Trishna Chakraborty, Erfan Shayegani, Zikui Cai, Nael B. AbuGhazaleh, M. Salman Asif, Yue Dong, Amit K. RoyChowdhury, Chengyu Song |  |
| 1968 |  |  [VDebugger: Harnessing Execution Feedback for Debugging Visual Programs](https://doi.org/10.18653/v1/2024.findings-emnlp.575) |  | 0 | Visual programs are executable code generated by large language models to address visual reasoning problems. They decompose complex questions into multiple reasoning steps and invoke specialized models for each step to solve the problems. However, these programs are prone to logic errors, with our... | Xueqing Wu, Zongyu Lin, Songyan Zhao, TeLin Wu, Pan Lu, Nanyun Peng, KaiWei Chang |  |
| 1969 |  |  [Monotonic Paraphrasing Improves Generalization of Language Model Prompting](https://doi.org/10.18653/v1/2024.findings-emnlp.576) |  | 0 | Performance of large language models (LLMs) may vary with different prompts or instructions of even the same task. One commonly recognized factor for this phenomenon is the model’s familiarity with the given prompt or instruction, which is typically estimated by its perplexity. However, finding the... | Qin Liu, Fei Wang, Nan Xu, Tianyi Yan, Tao Meng, Muhao Chen |  |
| 1970 |  |  [MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.577) |  | 0 | RL-based techniques can be employed to search for prompts that, when fed into a target language model, maximize a set of user-specified reward functions. However, in many target applications, the natural reward functions are in tension with one another – for example, content preservation vs. style... | Yasaman Jafari, Dheeraj Mekala, Rose Yu, Taylor BergKirkpatrick |  |
| 1971 |  |  [Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries](https://doi.org/10.18653/v1/2024.findings-emnlp.578) |  | 0 | Generating plain biomedical summaries with Large Language Models (LLMs) can enhance the accessibility of biomedical knowledge to the public. However, how faithful the generated summaries are remains an open yet critical question. To address this, we propose FaReBio, a benchmark dataset with... | Biaoyan Fang, Xiang Dai, Sarvnaz Karimi |  |
| 1972 |  |  [Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy](https://doi.org/10.18653/v1/2024.findings-emnlp.579) |  | 0 | This paper introduces a novel model compression approach through dynamic layer-specific pruning in Large Language Models (LLMs), enhancing the traditional methodology established by SliceGPT. By transitioning from constant to dynamic slicing, our method leverages the newly proposed Layer Redundancy... | RazvanGabriel Dumitru, PaulIoan Clotan, Vikas Yadav, Darius Peteleaza, Mihai Surdeanu |  |
| 1973 |  |  [Pruning Multilingual Large Language Models for Multilingual Inference](https://doi.org/10.18653/v1/2024.findings-emnlp.580) |  | 0 | Multilingual large language models (MLLMs), trained on multilingual balanced data, demonstrate better zero-shot learning performance in non-English languages compared to large language models trained on English-dominant data. However, the disparity in performance between English and non-English... | Hwichan Kim, Jun Suzuki, Tosho Hirasawa, Mamoru Komachi |  |
| 1974 |  |  [Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches](https://doi.org/10.18653/v1/2024.findings-emnlp.581) |  | 0 | This paper tackles a new task: discourse parsing for videos, inspired by text discourse parsing based on Rhetorical Structure Theory (RST). The task aims to construct an RST tree for a video to represent its storyline and illustrate the event relationships. We first construct a benchmark dataset by... | Tsutomu Hirao, Naoki Kobayashi, Hidetaka Kamigaito, Manabu Okumura, Akisato Kimura |  |
| 1975 |  |  [Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding](https://doi.org/10.18653/v1/2024.findings-emnlp.582) |  | 0 | Built upon the Transformer, large language models (LLMs) have captured worldwide attention due to their remarkable abilities. Nevertheless, all Transformer-based models including LLMs suffer from a preset length limit and can hardly generalize from short training sequences to longer inference ones,... | Liang Zhao, Xiachong Feng, Xiaocheng Feng, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin, Ting Liu |  |
| 1976 |  |  [VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis](https://doi.org/10.18653/v1/2024.findings-emnlp.583) |  | 0 | Vision-language models like CLIP, utilizing class proxies derived from class name text features, have shown a notable capability in zero-shot medical image diagnosis which is vital in scenarios with limited disease databases or labeled samples. However, insufficient medical text precision and the... | Jiaxiang Liu, Tianxiang Hu, Huimin Xiong, Jiawei Du, Yang Feng, Jian Wu, Joey Zhou, Zuozhu Liu |  |
| 1977 |  |  [Word-Conditioned 3D American Sign Language Motion Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.584) |  | 0 | Sign words are the building blocks of any sign language. In this work, we present wSignGen, a word-conditioned 3D American Sign Language (ASL) generation model dedicated to synthesizing realistic and grammatically accurate motion sequences for sign words. Our approach leverages a transformer-based... | Lu Dong, Xiao Wang, Ifeoma Nwogu |  |
| 1978 |  |  [TrustAgent: Towards Safe and Trustworthy LLM-based Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.585) |  | 0 | The rise of LLM-based agents shows great potential to revolutionize task planning, capturing significant attention. Given that these agents will be integrated into high-stake domains, ensuring their reliability and safety is crucial. This paper presents an Agent-Constitution-based agent framework,... | Wenyue Hua, Xianjun Yang, Mingyu Jin, Zelong Li, Wei Cheng, Ruixiang Tang, Yongfeng Zhang |  |
| 1979 |  |  [Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity](https://doi.org/10.18653/v1/2024.findings-emnlp.586) |  | 0 | With the continuous growth of online communities, understanding their similarities and dissimilarities is more crucial than ever for enhancing digital interactions, maintaining healthy interactions, and improving content recommendation and moderation systems. In this work, we present two novel... | Prasanna Lakkur Subramanyam, JengYu Chou, Kevin Nam, Brian Levine |  |
| 1980 |  |  [CNEQ: Incorporating numbers into Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.587) |  | 0 | Complex logical reasoning over knowledge graphs lies at the heart of many semantic downstream applications and thus has been extensively explored in recent years. However, nearly all of them overlook the rich semantics of numerical entities (e.g., magnitude, unit, and distribution) and are simply... | Xianshu Peng, Wei Wei, Kaihe Xu, Dangyang Chen |  |
| 1981 |  |  [StraGo: Harnessing Strategic Guidance for Prompt Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.588) |  | 0 | Prompt engineering is pivotal for harnessing the capabilities of large language models (LLMs) across diverse applications. While existing prompt optimization methods improve prompt effectiveness, they often lead to prompt drifting, wherein newly generated prompts canadversely impact previously... | Yurong Wu, Yan Gao, Bin Zhu, Zineng Zhou, Xiaodi Sun, Sheng Yang, JianGuang Lou, Zhiming Ding, Linjun Yang |  |
| 1982 |  |  [Learning to Plan by Updating Natural Language](https://doi.org/10.18653/v1/2024.findings-emnlp.589) |  | 0 | Large Language Models (LLMs) have shown remarkable performance in various basic natural language tasks. For completing the complex task, we still need a plan for the task to guide LLMs to generate the specific solutions step by step. LLMs can directly generate task plans, but these plans may still... | Yiduo Guo, Yaobo Liang, Chenfei Wu, Wenshan Wu, Dongyan Zhao, Nan Duan |  |
| 1983 |  |  [C-ICL: Contrastive In-context Learning for Information Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.590) |  | 0 | There has been increasing interest in exploring the capabilities of advanced large language models (LLMs) in the field of information extraction (IE), specifically focusing on tasks related to named entity recognition (NER) and relation extraction (RE). Although researchers are exploring the use of... | Ying Mo, Jiahao Liu, Jian Yang, Qifan Wang, Shun Zhang, Jingang Wang, Zhoujun Li |  |
| 1984 |  |  [On the Similarity of Circuits across Languages: a Case Study on the Subject-verb Agreement Task](https://doi.org/10.18653/v1/2024.findings-emnlp.591) |  | 0 | Several algorithms implemented by language models have recently been successfully reversed-engineered. However, these findings have been concentrated on specific tasks and models, leaving it unclear how universal circuits are across different settings. In this paper, we study the circuits... | Javier Ferrando, Marta R. Costajussà |  |
| 1985 |  |  [Can LLM be a Personalized Judge?](https://doi.org/10.18653/v1/2024.findings-emnlp.592) |  | 0 | As large language models (LLMs) gain widespread adoption, ensuring they cater to diverse user needs has become increasingly important. While many researchers have studied LLM personalization and role-playing, they primarily use LLM-as-a-Judge for evaluation without thoroughly examining its... | Yijiang River Dong, Tiancheng Hu, Nigel Collier |  |
| 1986 |  |  [Who's Who: Large Language Models Meet Knowledge Conflicts in Practice](https://doi.org/10.18653/v1/2024.findings-emnlp.593) |  | 0 | Retrieval-augmented generation (RAG) methods are viable solutions for addressing the static memory limits of pre-trained language models. Nevertheless, encountering conflicting sources of information within the retrieval context is an inevitable practical challenge. In such situations, the language... | Quang Pham, Hoang Ngo, Anh Tuan Luu, Dat Quoc Nguyen |  |
| 1987 |  |  [Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.594) |  | 0 | Model fusing has always been an important topic, especially in an era where large language models (LLM) and multi-modal language models (MLM) with different architectures, parameter sizes and training pipelines, are being created all the time. In this work, we propose a post-hoc framework, aiming... | Shitian Zhao, Renrui Zhang, Xu Luo, Yan Wang, Shanghang Zhang, Peng Gao |  |
| 1988 |  |  [Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.595) |  | 0 | In recent years, the rapid increase in scientific papers has overwhelmed traditional review mechanisms, resulting in varying quality of publications. Although existing methods have explored the capabilities of Large Language Models (LLMs) for automated scientific reviewing, their generated contents... | Jianxiang Yu, Zichen Ding, Jiaqi Tan, Kangyang Luo, Zhenmin Weng, Chenghua Gong, Long Zeng, Renjing Cui, Chengcheng Han, Qiushi Sun, Zhiyong Wu, Yunshi Lan, Xiang Li |  |
| 1989 |  |  [Knowledge-based Consistency Testing of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.596) |  | 0 | In this work, we systematically expose and measure the inconsistency and knowledge gaps of Large Language Models (LLMs). Specifically, we propose an automated testing framework (called KONTEST) which leverages a knowledge graph to construct test cases. KONTEST probes and measures the... | Sai Sathiesh Rajan, Ezekiel Olamide Soremekun, Sudipta Chattopadhyay |  |
| 1990 |  |  [PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes](https://doi.org/10.18653/v1/2024.findings-emnlp.597) |  | 0 | Multimodal Large Language Models (MLLMs) have seen growing adoption across various scientific disciplines. These advancements encourage the investigation of molecule-text modeling within synthetic chemistry, a field dedicated to designing and conducting chemical reactions to synthesize new... | He Cao, Yanjun Shao, Zhiyuan Liu, Zijing Liu, Xiangru Tang, Yuan Yao, Yu Li |  |
| 1991 |  |  [Query Routing for Homogeneous Tools: An Instantiation in the RAG Scenario](https://doi.org/10.18653/v1/2024.findings-emnlp.598) |  | 0 | Current research on tool learning primarily focuses on selecting the most effective tool from a wide array of options, often overlooking cost-effectiveness, a crucial factor in human problem-solving. In this paper, we address query routing for homogeneous tools by predicting both their performance... | Feiteng Mu, Yong Jiang, Liwen Zhang, Chu Liu, Wenjie Li, Pengjun Xie, Fei Huang |  |
| 1992 |  |  [MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.599) |  | 0 | Recently, mobile AI agents based on VLMs have been gaining increasing attention. These works typically utilize VLM as a foundation, fine-tuning it with instruction-based mobile datasets. However, these VLMs are typically pre-trained on general-domain data, which often results in a lack of... | Qinzhuo Wu, Weikai Xu, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Shuo Shang |  |
| 1993 |  |  [Schema-Driven Information Extraction from Heterogeneous Tables](https://doi.org/10.18653/v1/2024.findings-emnlp.600) |  | 0 | In this paper, we explore the question of whether large language models can support cost-efficient information extraction from tables. We introduce schema-driven information extraction, a new task that transforms tabular data into structured records following a human-authored schema. To assess... | Fan Bai, Junmo Kang, Gabriel Stanovsky, Dayne Freitag, Mark Dredze, Alan Ritter |  |
| 1994 |  |  [Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases](https://doi.org/10.18653/v1/2024.findings-emnlp.601) |  | 0 | Definition bias is a negative phenomenon that can mislead models. However, definition bias in information extraction appears not only across datasets from different domains but also within datasets sharing the same domain. We identify two types of definition bias in IE: bias among information... | Wenhao Huang, Qianyu He, Zhixu Li, Jiaqing Liang, Yanghua Xiao |  |
| 1995 |  |  [PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.602) |  | 0 | Recent advances in fine-tuning large language models (LLMs) have greatly enhanced their usage in domain-specific tasks. Despite the success, fine-tuning continues to rely on repeated and lengthy prompts, which escalate computational expenses, require more resources, and lead to slower inference. In... | Jiaru Zou, Mengyu Zhou, Tao Li, Shi Han, Dongmei Zhang |  |
| 1996 |  |  [TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.603) |  | 0 | Table reasoning tasks have shown remarkable progress with the development of large language models (LLMs), which involve interpreting and drawing conclusions from tabular data based on natural language (NL) questions. Existing solutions mainly tested on smaller tables face scalability issues and... | Yuan Sui, Jiaru Zou, Mengyu Zhou, Xinyi He, Lun Du, Shi Han, Dongmei Zhang |  |
| 1997 |  |  [In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.604) |  | 0 | Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open-source community. To address this challenge, we propose... | Ayrton San Joaquin, Bin Wang, Zhengyuan Liu, Philippe Muller, Nicholas Asher, Brian Lim, Nancy F. Chen |  |
| 1998 |  |  [How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.605) |  | 0 | Psychological evidence reveals the influence of personality traits on decision-making. For instance, agreeableness is generally associated with positive outcomes in negotiations, whereas neuroticism is often linked to less favorable outcomes. This paper introduces a simulation framework centered on... | Yin Jou Huang, Rafik Hadfi |  |
| 1999 |  |  [Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.606) |  | 0 | This paper focuses on the task of open-domain live commentary generation. Compared to domain-specific work in this task, this setting proved particularly challenging due to the absence of domain-specific features. Aiming to bridge this gap, we integrate spatial information by proposing an utterance... | Erica K. Shimomoto, Edison MarreseTaylor, Ichiro Kobayashi, Hiroya Takamura, Yusuke Miyao |  |
| 2000 |  |  [Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.607) |  | 0 | Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language Models (LLMs) by incorporating extensive knowledge retrieved from external sources. However, such approach encounters some challenges: Firstly, the original queries may not be suitable for precise retrieval, resulting in... | Bolei He, Nuo Chen, Xinran He, Lingyong Yan, Zhenkai Wei, Jinchang Luo, ZhenHua Ling |  |
| 2001 |  |  [Detecting Machine-Generated Long-Form Content with Latent-Space Variables](https://doi.org/10.18653/v1/2024.findings-emnlp.608) |  | 0 | The increasing capability of large language models (LLMs) to generate fluent long-form texts is presenting new challenges in distinguishing these outputs from those of humans. Existing zero-shot detectors that primarily focus on token-level distributions are vulnerable to real-world domain shift... | Yufei Tian, Zeyu Pan, Nanyun Peng |  |
| 2002 |  |  [Learning to Match Representations is Better for End-to-End Task-Oriented Dialog System](https://doi.org/10.18653/v1/2024.findings-emnlp.609) |  | 0 | Due to the rapid development with pre-trained language models, fully end-to-end Task-Oriented Dialogue (TOD) systems exhibit superior performance. How to achieve the ability to efficiently retrieve entities in cross-domain large-scale databases is a key issue. Most existing end-to-end Task-Oriented... | Wanshi Xu, Xuxin Cheng, Zhihong Zhu, Zhanpeng Chen, Yuexian Zou |  |
| 2003 |  |  [ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors](https://doi.org/10.18653/v1/2024.findings-emnlp.610) |  | 0 | The safety of Large Language Models (LLMs) has gained increasing attention in recent years, but there still lacks a comprehensive approach for detecting safety issues within LLMs’ responses in an aligned, customizable and explainable manner. In this paper, we propose ShieldLM, an LLM-based safety... | Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang |  |
| 2004 |  |  [BiasDora: Exploring Hidden Biased Associations in Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.611) |  | 0 | Existing works examining Vision-Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, restricting the identification... | Chahat Raj, Anjishnu Mukherjee, Aylin Caliskan, Antonios Anastasopoulos, Ziwei Zhu |  |
| 2005 |  |  [MoE-I²: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition](https://doi.org/10.18653/v1/2024.findings-emnlp.612) |  | 0 | The emergence of Mixture of Experts (MoE) LLMs has significantly advanced the development of language models. Compared to traditional LLMs, MoE LLMs outperform traditional LLMs by achieving higher performance with considerably fewer activated parameters. Despite this efficiency, their enormous... | Cheng Yang, Yang Sui, Jinqi Xiao, Lingyi Huang, Yu Gong, Yuanlin Duan, Wenqi Jia, Miao Yin, Yu Cheng, Bo Yuan |  |
| 2006 |  |  [Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.613) |  | 0 | Detecting multimodal misinformation, especially in the form of image-text pairs, is crucial. Obtaining large-scale, high-quality real-world fact-checking datasets for training detectors is costly, leading researchers to use synthetic datasets generated by AI technologies. However, the... | Fengzhu Zeng, Wenqian Li, Wei Gao, Yan Pang |  |
| 2007 |  |  [Exploring Design Choices for Building Language-Specific LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.614) |  | 0 | Despite rapid progress in large language models (LLMs), their performance on a vast majority of languages remains unsatisfactory. In this paper, we study building language-specific LLMs by adapting monolingual and multilingual LLMs. We conduct systematic experiments on how design choices (base... | Atula Tejaswi, Nilesh Gupta, Eunsol Choi |  |
| 2008 |  |  [Promoting Data and Model Privacy in Federated Learning through Quantized LoRA](https://doi.org/10.18653/v1/2024.findings-emnlp.615) |  | 0 | Conventional federated learning primarily aims to secure the privacy of data distributed across multiple edge devices, with the global model dispatched to edge devices for parameter updates during the learning process. However, the development of large language models (LLMs) requires substantial... | Jianhao Zhu, Changze Lv, Xiaohua Wang, Muling Wu, Wenhao Liu, Tianlong Li, Zixuan Ling, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang |  |
| 2009 |  |  [Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.616) |  | 0 | In this study, we investigate the potential of language models (LMs) in aiding patients experiencing anomia, a difficulty identifying the names of items. Identifying the intended target item from patient’s circumlocution involves the two challenges of term failure and error. (1) The terms relevant... | Jongho Kim, Romain Storaï, Seungwon Hwang |  |
| 2010 |  |  [Fine-tuning Smaller Language Models for Question Answering over Financial Documents](https://doi.org/10.18653/v1/2024.findings-emnlp.617) |  | 0 | Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain, focusing on the challenge of answering questions that... | Karmvir Singh Phogat, Sai Akhil Puranam, Sridhar Dasaratha, Chetan Harsha, Shashishekar Ramakrishna |  |
| 2011 |  |  [Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.618) |  | 0 | Large Language Models (LLMs) have demonstrated significant potential in revolutionizing clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct fine-tuning, NEFTune, and prompt engineering. We... | Clément Christophe, Tathagata Raha, Svetlana Maslenkova, Muhammad Umar Salman, Praveen K. Kanithi, Marco AF Pimentel, Shadab Khan |  |
| 2012 |  |  [MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation](https://doi.org/10.18653/v1/2024.findings-emnlp.619) |  | 0 | Large language models (LLMs) have shown substantial progress in natural language understanding and generation, proving valuable especially in the medical field. Despite advancements, challenges persist due to the complexity and diversity inherent in medical tasks, which can be categorized as... | Yusheng Liao, Shuyang Jiang, Zhe Chen, Yanfeng Wang, Yu Wang |  |
| 2013 |  |  [Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-emnlp.620) |  | 0 | Reinforcement learning from human feedback (RLHF) has emerged as the primary method for aligning large language models (LLMs) with human preferences. The RLHF process typically starts by training a reward model (RM) using human preference data. Conventional RMs are trained on pairwise responses to... | Haoxiang Wang, Wei Xiong, Tengyang Xie, Han Zhao, Tong Zhang |  |
| 2014 |  |  [Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.621) |  | 0 | Code pre-trained language models (CPLMs) have received great attention since they can benefit various tasks that facilitate software development and maintenance. However, CPLMs are trained on massive open-source code, raising concerns about potential data infringement. This paper launches the study... | Sheng Zhang, Hui Li, Rongrong Ji |  |
| 2015 |  |  [Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA](https://doi.org/10.18653/v1/2024.findings-emnlp.622) |  | 0 | Augmenting Large Language Models (LLMs) with information retrieval capabilities (i.e., Retrieval-Augmented Generation (RAG)) has proven beneficial for knowledge-intensive tasks. However, understanding users’ contextual search intent when generating responses is an understudied topic for... | Nirmal Roy, Leonardo F. R. Ribeiro, Rexhina Blloshmi, Kevin Small |  |
| 2016 |  |  [Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication](https://doi.org/10.18653/v1/2024.findings-emnlp.623) |  | 0 | Natural language (NL) has long been the predominant format for human cognition and communication, and by extension, has been similarly pivotal in the development and application of Large Language Models (LLMs). Yet, besides NL, LLMs have seen various non-NL formats during pre-training, such as code... | Weize Chen, Chenfei Yuan, Jiarui Yuan, Yusheng Su, Chen Qian, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun |  |
| 2017 |  |  [Learning to Use Tools via Cooperative and Interactive Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.624) |  | 0 | Tool learning empowers large language models (LLMs) as agents to use external tools and extend their utility. Existing methods employ one single LLM-based agent to iteratively select and execute tools, thereafter incorporating execution results into the next action prediction. Despite their... | Zhengliang Shi, Shen Gao, Xiuyi Chen, Yue Feng, Lingyong Yan, Haibo Shi, Dawei Yin, Pengjie Ren, Suzan Verberne, Zhaochun Ren |  |
| 2018 |  |  [STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals](https://doi.org/10.18653/v1/2024.findings-emnlp.625) |  | 0 | Statute retrieval aims to find relevant statutory articles for specific queries. This process is the basis of a wide range of legal applications such as legal advice, automated judicial decisions, legal document drafting, etc. Existing statute retrieval benchmarks emphasize formal and professional... | Weihang Su, Yiran Hu, Anzhe Xie, Qingyao Ai, Quezi Bing, Ning Zheng, Yun Liu, Weixing Shen, Yiqun Liu |  |
| 2019 |  |  [What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models](https://doi.org/10.18653/v1/2024.findings-emnlp.626) |  | 0 | This paper presents a way of enhancing the reliability of Large Multi-modal Models (LMMs) in addressing hallucination, where the models generate cross-modal inconsistent responses. Without additional training, we propose Counterfactual Inception, a novel method that implants counterfactual thinking... | Junho Kim, Yeonju Kim, Yong Man Ro |  |
| 2020 |  |  [MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science](https://doi.org/10.18653/v1/2024.findings-emnlp.627) |  | 0 | We introduce a novel continued pre-training method, MELT (MatEriaLs-aware continued pre-Training), specifically designed to efficiently adapt the pre-trained language models (PLMs) for materials science. Unlike previous adaptation strategies that solely focus on constructing domain-specific corpus,... | Junho Kim, Yeachan Kim, JunHyung Park, Yerim Oh, Suho Kim, SangKeun Lee |  |
| 2021 |  |  [PDF-to-Tree: Parsing PDF Text Blocks into a Tree](https://doi.org/10.18653/v1/2024.findings-emnlp.628) |  | 0 | In many PDF documents, the reading order of text blocks is missing, which can hinder machine understanding of the document’s content.Existing works try to extract one universal reading order for a PDF file.However, applications, like Retrieval Augmented Generation (RAG), require breaking long... | Yue Zhang, Zhihao Zhang, Wenbin Lai, Chong Zhang, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 2022 |  |  [Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes](https://doi.org/10.18653/v1/2024.findings-emnlp.629) |  | 0 | Detecting offensive memes is crucial, yet standard deep neural network systems often remain opaque. Various input attribution-based methods attempt to interpret their behavior, but they face challenges with implicitly offensive memes and non-causal attributions. To address these issues, we propose... | Dibyanayan Bandyopadhyay, Mohammed Hasanuzzaman, Asif Ekbal |  |
| 2023 |  |  [Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.630) |  | 0 | Pretrained language models memorize vast amounts of information, including private and copyrighted data, raising significant safety concerns. Retraining these models after excluding sensitive data is prohibitively expensive, making machine unlearning a viable, cost-effective alternative. Previous... | Minseok Choi, Kyunghyun Min, Jaegul Choo |  |
| 2024 |  |  [LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages](https://doi.org/10.18653/v1/2024.findings-emnlp.631) |  | 0 | Large Language Models (LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we conduct extensive multilingual continual pre-training... | Yinquan Lu, Wenhao Zhu, Lei Li, Yu Qiao, Fei Yuan |  |
| 2025 |  |  [Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.632) |  | 0 | Emotion-Cause Pair Extraction in Conversations (ECPEC) aims to identify emotion utterances and their corresponding cause utterances in unannotated conversations, this task that has garnered increasing attention recently. Previous methods often apply Emotion-Cause Pair Extraction (ECPE) task models,... | Botao Wang, Keke Tang, Peican Zhu |  |
| 2026 |  |  [Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.633) |  | 0 | Fine-tuning pre-trained Vision-Language Models (VLMs) has shown remarkable capabilities in medical image and textual depiction synergy. Nevertheless, many pre-training datasets are restricted by patient privacy concerns, potentially containing noise that can adversely affect downstream performance.... | Xu Han, Linghao Jin, Xuezhe Ma, Xiaofeng Liu |  |
| 2027 |  |  [Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages](https://doi.org/10.18653/v1/2024.findings-emnlp.634) |  | 0 | This exploratory study investigates the potential of multilingual Automatic Post-Editing (APE) systems to enhance the quality of machine translations for low-resource Indo-Aryan languages. Focusing on two closely related language pairs, English-Marathi and English-Hindi, we exploit the linguistic... | Sourabh Dattatray Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya |  |
| 2028 |  |  [CERT-ED: Certifiably Robust Text Classification for Edit Distance](https://doi.org/10.18653/v1/2024.findings-emnlp.635) |  | 0 | With the growing integration of AI in daily life, ensuring the robustness of systems to inference-time attacks is crucial. Among the approaches for certifying robustness to such adversarial examples, randomized smoothing has emerged as highly promising due to its nature as a wrapper around... | Zhuoqun Huang, Neil G. Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein |  |
| 2029 |  |  [Ask-before-Plan: Proactive Language Agents for Real-World Planning](https://doi.org/10.18653/v1/2024.findings-emnlp.636) |  | 0 |  | Xuan Zhang, Yang Deng, Zifeng Ren, SeeKiong Ng, TatSeng Chua |  |
| 2030 |  |  [From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.637) |  | 0 | It is imperative for Large language models (LLMs) to follow instructions with elaborate requirements (i.e. Complex Instructions Following). Yet, it remains under-explored how to enhance the ability of LLMs to follow complex instructions with multiple constraints. To bridge the gap, we initially... | Qianyu He, Jie Zeng, Qianxi He, Jiaqing Liang, Yanghua Xiao |  |
| 2031 |  |  [FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.638) |  | 0 | LLM-based agents have emerged as promising tools, which are crafted to fulfill complex tasks by iterative planning and action. However, these agents are susceptible to undesired planning hallucinations when lacking specific knowledge for expertise-intensive tasks. To address this, preliminary... | Ruixuan Xiao, Wentao Ma, Ke Wang, Yuchuan Wu, Junbo Zhao, Haobo Wang, Fei Huang, Yongbin Li |  |
| 2032 |  |  [Mental Disorder Classification via Temporal Representation of Text](https://doi.org/10.18653/v1/2024.findings-emnlp.639) |  | 0 | Mental disorders pose a global challenge, aggravated by the shortage of qualified mental health professionals. Mental disorder prediction from social media posts by current LLMs is challenging due to the complexities of sequential text data and the limited context length of language models. Current... | Raja Kumar, Kishan Maharaj, Ashita Saxena, Pushpak Bhattacharyya |  |
| 2033 |  |  [Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.640) |  | 0 | Various audio-LLMs (ALLMs) have been explored recently for tackling different audio tasks simultaneously using a single, unified model. While existing evaluations of ALLMs primarily focus on single-audio tasks, real-world applications often involve processing multiple audio streams simultaneously.... | Yiming Chen, Xianghu Yue, Xiaoxue Gao, Chen Zhang, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li |  |
| 2034 |  |  [Multimodal Procedural Planning via Dual Text-Image Prompting](https://doi.org/10.18653/v1/2024.findings-emnlp.641) |  | 0 | Embodied agents have achieved prominent performance in following human instructions to complete tasks. However, the potential of providing instructions informed by texts and images to assist humans in completing tasks remains underexplored. To uncover this capability, we present the multimodal... | Yujie Lu, Pan Lu, Zhiyu Chen, Wanrong Zhu, Xin Wang, William Yang Wang |  |
| 2035 |  |  [Functionality learning through specification instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.642) |  | 0 | Test suites assess natural language processing models’ performance on specific functionalities: cases of interest involving model robustness, fairness, or particular linguistic capabilities. This paper introduces specification instructions: text descriptions specifying fine-grained task-specific... | Pedro Henrique Luz de Araujo, Benjamin Roth |  |
| 2036 |  |  [DictDis: Dictionary Constrained Disambiguation for Improved NMT](https://doi.org/10.18653/v1/2024.findings-emnlp.643) |  | 0 | Domain-specific neural machine translation (NMT) systems (, in educational applications) are socially significant with the potential to help make information accessible to a diverse set of users in multilingual societies. Such NMT systems should be lexically constrained and draw from... | Ayush Maheshwari, Preethi Jyothi, Ganesh Ramakrishnan |  |
| 2037 |  |  [Fighting Randomness with Randomness: Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation](https://doi.org/10.18653/v1/2024.findings-emnlp.644) |  | 0 | While fine-tuning of pre-trained language models generally helps to overcome the lack of labelled training samples, it also displays model performance instability. This instability mainly originates from randomness in initialisation or data shuffling. To address this, researchers either modify the... | Branislav Pecher, Ján Cegin, Róbert Belanec, Jakub Simko, Ivan Srba, Mária Bieliková |  |
| 2038 |  |  [Rethinking Code Refinement: Learning to Judge Code Efficiency](https://doi.org/10.18653/v1/2024.findings-emnlp.645) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in understanding and generating codes. Due to these capabilities, many recent methods are proposed to automatically refine the codes with LLMs. However, we should rethink that the refined codes (from LLMs and even humans) are... | Minju Seo, Jinheon Baek, Sung Ju Hwang |  |
| 2039 |  |  [Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability](https://doi.org/10.18653/v1/2024.findings-emnlp.646) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in a wide range of natural language processing tasks when leveraging in-context learning. To mitigate the additional computational and financial costs associated with in-context learning, several prompt compression methods have... | Tsz Ting Chung, Leyang Cui, Lemao Liu, Xinting Huang, Shuming Shi, DitYan Yeung |  |
| 2040 |  |  [Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities](https://doi.org/10.18653/v1/2024.findings-emnlp.647) |  | 0 | The parametric knowledge memorized by large language models (LLMs) becomes outdated quickly. In-context editing (ICE) is currently the most effective method for updating the knowledge of LLMs. Recent advancements involve enhancing ICE by modifying the decoding strategy, obviating the need for... | Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Hongcheng Gao, Yilong Xu, Xueqi Cheng |  |
| 2041 |  |  [Improving Factual Consistency of News Summarization by Contrastive Preference Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.648) |  | 0 | Despite the recent progress in news summarization made by large language models (LLMs), they often generate summaries that are factually inconsistent with original articles, known as “hallucinations” in text generation. Unlike previous small models (e.g., BART, T5), current LLMs make fewer silly... | Huawen Feng, Yan Fan, Xiong Liu, TingEn Lin, Zekun Yao, Yuchuan Wu, Fei Huang, Yongbin Li, Qianli Ma |  |
| 2042 |  |  [AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.649) |  | 0 | AI personal assistants deployed via robots or wearables require embodied understanding to collaborate with humans effectively. However, current Vision-Language Models (VLMs) primarily focus on third-person view videos, neglecting the richness of egocentric perceptual experience. To address this... | Alessandro Suglia, Claudio Greco, Katie Baker, Jose L. Part, Ioannis Papaioannou, Arash Eshghi, Ioannis Konstas, Oliver Lemon |  |
| 2043 |  |  [Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias](https://doi.org/10.18653/v1/2024.findings-emnlp.650) |  | 0 | Cross-platform topic dissemination is one of the research subjects that delved into media analysis; sometimes it fails to grasp the authentic topics due to platform-induced biases, which may be caused by aggregating documents from multiple platforms and running them on an existing topic model. This... | Minseo Koo, Doeun Kim, Sungwon Han, Sungkyu Park |  |
| 2044 |  |  [MAVEN-FACT: A Large-scale Event Factuality Detection Dataset](https://doi.org/10.18653/v1/2024.findings-emnlp.651) |  | 0 | Event Factuality Detection (EFD) task determines the factuality of textual events, i.e., classifying whether an event is a fact, possibility, or impossibility, which is essential for faithfully understanding and utilizing event knowledge. However, due to the lack of high-quality large-scale data,... | Chunyang Li, Hao Peng, Xiaozhi Wang, Yunjia Qi, Lei Hou, Bin Xu, Juanzi Li |  |
| 2045 |  |  [Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft](https://doi.org/10.18653/v1/2024.findings-emnlp.652) |  | 0 | In the Minecraft Collaborative Building Task, two players collaborate: an Architect (A) provides instructions to a Builder (B) to assemble a specified structure using 3D blocks. In this work, we investigate the use of large language models (LLMs) to predict the sequence of actions taken by the... | Kranti Chalamalasetti, Sherzod Hakimov, David Schlangen |  |
| 2046 |  |  [Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.653) |  | 0 | In the domain of Aspect-Based Sentiment Analysis (ABSA), generative methods have shown promising results and achieved substantial advancements. However, despite these advancements, the tasks of extracting sentiment quadruplets, which capture the nuanced sentiment expressions within a sentence,... | Yongsik Seo, Sungwon Song, Ryang Heo, Jieyong Kim, Dongha Lee |  |
| 2047 |  |  [LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement](https://doi.org/10.18653/v1/2024.findings-emnlp.654) |  | 0 | This paper introduces the innovative “LLMs-as-Instructors” framework, which leverages the advanced Large Language Models (LLMs) to autonomously enhance the training of smaller target models. Inspired by the theory of “Learning from Errors”, this framework employs an instructor LLM to meticulously... | Jiahao Ying, Mingbao Lin, Yixin Cao, Wei Tang, Bo Wang, Qianru Sun, Xuanjing Huang, Shuicheng Yan |  |
| 2048 |  |  [ITER: Iterative Transformer-based Entity Recognition and Relation Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.655) |  | 0 | When extracting structured information from text, recognizing entities and extracting relationships are essential. Recent advances in both tasks generate a structured representation of the information in an autoregressive manner, a time-consuming and computationally expensive approach. This... | Moritz Hennen, Florian Babl, Michaela Geierhos |  |
| 2049 |  |  [Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.656) |  | 0 | Persuasion plays a pivotal role in a wide range of applications from health intervention to the promotion of social good. Persuasive chatbots employed responsibly for social good can be an enabler of positive individual and social change. Existing methods rely on fine-tuning persuasive chatbots... | Kazuaki Furumai, Roberto Legaspi, Julio Romero, Yudai Yamazaki, Yasutaka Nishimura, Sina J. Semnani, Kazushi Ikeda, Weiyan Shi, Monica S. Lam |  |
| 2050 |  |  [Logits Reranking via Semantic Labels for Hard Samples in Text Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.657) |  | 0 | Pre-trained Language Models (PLMs) have achieved significant success in text classification. However, they still face challenges with hard samples, which refer to instances where the model exhibits diminished confidence in distinguishing new samples. Existing research has addressed related issues,... | Peijie Huang, Junbao Huang, Yuhong Xu, Weizhen Li, Xisheng Xiao |  |
| 2051 |  |  [Scaling Laws for Fact Memorization of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.658) |  | 0 | Fact knowledge memorization is crucial for Large Language Models (LLM) to generate factual and reliable responses. However, the behaviors of LLM fact memorization remain under-explored. In this paper, we analyze the scaling laws for LLM’s fact knowledge and LLMs’ behaviors of memorizing different... | Xingyu Lu, Xiaonan Li, Qinyuan Cheng, Kai Ding, Xuanjing Huang, Xipeng Qiu |  |
| 2052 |  |  [Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.659) |  | 0 |  | Orgest Xhelili, Yihong Liu, Hinrich Schütze |  |
| 2053 |  |  [Leveraging Web-Crawled Data for High-Quality Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.660) |  | 0 | Most large language models are fine-tuned using either expensive human-annotated data or GPT-4 generated data which cannot guarantee performance in certain domains. We argue that although the web-crawled data often has formatting errors causing semantic inaccuracies, it can still serve as a... | Jing Zhou, Chenglin Jiang, Wei Shen, Xiao Zhou, Xiaonan He |  |
| 2054 |  |  [Designing Logic Pattern Templates for Counter-Argument Logical Structure Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.661) |  | 0 |  | Shoichi Naito, Wenzhi Wang, Paul Reisert, Naoya Inoue, Camélia Guerraoui, Kenshi Yamaguchi, Jungmin Choi, Irfan Robbani, Surawat Pothong, Kentaro Inui |  |
| 2055 |  |  [Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.662) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional proficiency in language-related tasks, but their deployment poses significant challenges due to substantial memory and storage requirements. Weight-only quantization has emerged as a promising solution to address these challenges. Previous... | Wenhua Cheng, Weiwei Zhang, Haihao Shen, Yiyang Cai, Xin He, Kaokao Lv, Yi Liu |  |
| 2056 |  |  [Using LLMs to simulate students' responses to exam questions](https://doi.org/10.18653/v1/2024.findings-emnlp.663) |  | 0 | Previous research leveraged Large Language Models (LLMs) in numerous ways in the educational domain. Here, we show that they can be used to answer exam questions simulating students of different skill levels and share a prompt, engineered for GPT-3.5, that enables the simulation of varying student... | Luca Benedetto, Giovanni Aradelli, Antonia Donvito, Alberto Lucchetti, Andrea Cappelli, Paula Buttery |  |
| 2057 |  |  [HSDreport: Heart Sound Diagnosis with Echocardiography Reports](https://doi.org/10.18653/v1/2024.findings-emnlp.664) |  | 0 | Heart sound auscultation holds significant importance in the diagnosis of congenital heart disease. However, existing methods for Heart Sound Diagnosis (HSD) tasks are predominantly limited to a few fixed categories, framing the HSD task as a rigid classification problem that does not fully align... | Zihan Zhao, Pingjie Wang, Liudan Zhao, Yuchen Yang, Ya Zhang, Kun Sun, Xin Sun, Xin Zhou, Yu Wang, Yanfeng Wang |  |
| 2058 |  |  [Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement](https://doi.org/10.18653/v1/2024.findings-emnlp.665) |  | 0 | Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention for their ability to generate high-quality images from textual descriptions.However, these models often produce images that do not fully align with the input prompts, resulting in semantic inconsistencies.The most... | Zhiyuan Chang, Mingyang Li, Junjie Wang, Yi Liu, Qing Wang, Yang Liu |  |
| 2059 |  |  [Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing](https://doi.org/10.18653/v1/2024.findings-emnlp.666) |  | 0 | In visual speech processing, context modeling capability is one of the most important requirements due to the ambiguous nature of lip movements. For example, homophenes, words that share identical lip movements but produce different sounds, can be distinguished by considering the context. In this... | Jeong Hun Yeo, Seunghee Han, Minsu Kim, Yong Man Ro |  |
| 2060 |  |  [MDCR: A Dataset for Multi-Document Conditional Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.667) |  | 0 | The same real-life questions posed to different individuals may lead to different answers based on their unique situations. For instance, whether a student is eligible for a scholarship depends on eligibility conditions, such as major or degree required. ConditionalQA was proposed to evaluate... | Peter Baile Chen, Yi Zhang, Chunwei Liu, Sejal Gupta, Yoon Kim, Mike Cafarella |  |
| 2061 |  |  [Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure](https://doi.org/10.18653/v1/2024.findings-emnlp.668) |  | 0 | Recent advancements in Large Language Models (LLMs) have demonstrated their ability to simulate human-like decision-making, yet the impact of psychological pressures on their decision-making processes remains underexplored. To understand how psychological pressures influence decision-making in... | Kyusik Kim, Hyeonseok Jeon, Jeongwoo Ryu, Bongwon Suh |  |
| 2062 |  |  [Zero-shot Commonsense Reasoning over Machine Imagination](https://doi.org/10.18653/v1/2024.findings-emnlp.669) |  | 0 | Recent approaches to zero-shot commonsense reasoning have enabled Pre-trained Language Models (PLMs) to learn a broad range of commonsense knowledge without being tailored to specific situations. However, they often suffer from human reporting bias inherent in textual commonsense knowledge, leading... | Hyuntae Park, Yeachan Kim, JunHyung Park, SangKeun Lee |  |
| 2063 |  |  [A Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval](https://doi.org/10.18653/v1/2024.findings-emnlp.670) |  | 0 | Knowledge graphs (KGs) can provide explainable reasoning for large language models (LLMs), alleviating their hallucination problem. Knowledge graph question answering (KGQA) is a typical benchmark to evaluate the methods enhancing LLMs with KG. Previous methods on KG-enhanced LLM for KGQA either... | Yading Li, Dandan Song, Changzhi Zhou, Yuhang Tian, Hao Wang, Ziyi Yang, Shuhao Zhang |  |
| 2064 |  |  [Vanessa: Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.671) |  | 0 | Prevailing research concentrates on superficial features or descriptions of images, revealing a significant gap in the systematic exploration of their connotative and aesthetic attributes. Furthermore, the use of cross-modal relation detection modules to eliminate noise from comprehensive image... | Luwei Xiao, Rui Mao, Xulang Zhang, Liang He, Erik Cambria |  |
| 2065 |  |  [Consistent Document-level Relation Extraction via Counterfactuals](https://doi.org/10.18653/v1/2024.findings-emnlp.672) |  | 0 | Many datasets have been developed to train and evaluate document-level relation extraction (RE) models. Most of these are constructed using real-world data. It has been shown that RE models trained on real-world data suffer from factual biases. To evaluate and address this issue, we present... | Ali Modarressi, Abdullatif Köksal, Hinrich Schütze |  |
| 2066 |  |  [Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants](https://doi.org/10.18653/v1/2024.findings-emnlp.673) |  | 0 | Compared to identifying binary versions of the same function under different compilation options, existing Learning-Based Binary Code Similarity Detection (LB-BCSD) methods exhibit lower accuracy in recognizing functions with the same functionality but different implementations. To address this... | Lichen Jia, Chenggang Wu, Bowen Tang, Peihua Zhang, Zihan Jiang, Yang Yang, Ning Liu, Jingfeng Zhang, Zhe Wang |  |
| 2067 |  |  [Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-AI collaboration](https://doi.org/10.18653/v1/2024.findings-emnlp.674) |  | 0 | Large Language Models (LLMs) are being employed by end-users for various tasks, including sensitive ones such as health counseling, disregarding potential safety concerns. It is thus necessary to understand how adequately LLMs perform in such domains. We conduct a case study on ChatGPT in nutrition... | Simone Balloccu, Ehud Reiter, Karen Li, Rafael Sargsyan, Vivek Kumar, Diego Reforgiato Recupero, Daniele Riboni, Ondrej Dusek |  |
| 2068 |  |  [HealthAlignSumm : Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.675) |  | 0 | As generative AI progresses, collaboration be-tween doctors and AI scientists is leading to thedevelopment of personalized models to stream-line healthcare tasks and improve productivity.Summarizing doctor-patient dialogues has be-come important, helping doctors understandconversations faster and... | Akash Ghosh, Arkadeep Acharya, Sriparna Saha, Gaurav Pandey, Dinesh Raghu, Setu Sinha |  |
| 2069 |  |  [Revisiting the Impact of Pursuing Modularity for Code Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.676) |  | 0 | Modular programming, which aims to construct the final program by integrating smaller, independent building blocks, has been regarded as a desirable practice in software development. However, with the rise of recent code generation agents built upon large language models (LLMs), a question emerges:... | Deokyeong Kang, Ki Jung Seo, Taeuk Kim |  |
| 2070 |  |  [A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers](https://doi.org/10.18653/v1/2024.findings-emnlp.677) |  | 0 | Length-control summarization aims to condense long texts into a short one within a certain length limit. Previous approaches often use autoregressive (AR) models and treat the length requirement as a soft constraint, which may not always be satisfied. In this study, we propose a novel... | Chenyang Huang, Hao Zhou, Cameron Jen, Kangjie Zheng, Osmar R. Zaïane, Lili Mou |  |
| 2071 |  |  [R²AG: Incorporating Retrieval Information into Retrieval Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.678) |  | 0 | Retrieval augmented generation (RAG) has been applied in many scenarios to augment large language models (LLMs) with external documents provided by retrievers. However, a semantic gap exists between LLMs and retrievers due to differences in their training objectives and architectures. This... | Fuda Ye, Shuangyin Li, Yongqi Zhang, Lei Chen |  |
| 2072 |  |  [Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition](https://doi.org/10.18653/v1/2024.findings-emnlp.679) |  | 0 | Visual storytelling consists in generating a natural language story given a temporally ordered sequence of images. This task is not only challenging for models, but also very difficult to evaluate with automatic metrics since there is no consensus about what makes a story ‘good’. In this paper, we... | Aditya Kaushik Surikuchi, Raquel Fernández, Sandro Pezzelle |  |
| 2073 |  |  [Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing](https://doi.org/10.18653/v1/2024.findings-emnlp.680) |  | 0 | Pretrained language models (PLMs) have been shown to encode binary gender information of text authors, raising the risk of skewed representations and downstream harms. This effect is yet to be examined for transgender and non-binary identities, whose frequent marginalization may exacerbate harmful... | Urban Knuples, Agnieszka Falenska, Filip Miletic |  |
| 2074 |  |  [“Vorbești Românește?” A Recipe to Train Powerful Romanian LLMs with English Instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.681) |  | 0 | In recent years, Large Language Models (LLMs) have achieved almost human-like performance on various tasks. While some LLMs have been trained on multilingual data, most of the training data is in English; hence, their performance in English greatly exceeds other languages. To our knowledge, we are... | Mihai Masala, Denis C. IlieAblachim, Alexandru Dima, DragosGeorgian Corlatescu, MirunaAndreea Zavelca, Ovio Olaru, SiminaMaria Terian, Andrei Terian, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea |  |
| 2075 |  |  [Generalized Measures of Anticipation and Responsivity in Online Language Processing](https://doi.org/10.18653/v1/2024.findings-emnlp.682) |  | 0 | We introduce a generalization of classic information-theoretic measures of predictive uncertainty in online language processing, based on the simulation of expected continuations of incremental linguistic contexts. Our framework provides a formal definition of anticipatory and responsive measures,... | Mario Giulianelli, Andreas Opedal, Ryan Cotterell |  |
| 2076 |  |  [Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling](https://doi.org/10.18653/v1/2024.findings-emnlp.683) |  | 0 | Trolling in online communities typically involves disruptive behaviors such as provoking anger and manipulating discussions, leading to a polarized atmosphere and emotional distress. Robust moderation is essential for mitigating these negative impacts and maintaining a healthy and constructive... | Huije Lee, Hoyun Song, Jisu Shin, Sukmin Cho, SeungYoon Han, Jong Park |  |
| 2077 |  |  [Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.684) |  | 0 | Although human evaluation remains the gold standard for open-domain dialogue evaluation, the growing popularity of automated evaluation using Large Language Models (LLMs) has also extended to dialogue. However, most frameworks leverage benchmarks that assess older chatbots on aspects such as... | John Mendonça, Isabel Trancoso, Alon Lavie |  |
| 2078 |  |  [A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models](https://doi.org/10.18653/v1/2024.findings-emnlp.685) |  | 0 | The rapid advancement of foundation models (FMs) across language, image, audio, and video domains has shown remarkable capabilities in diverse tasks. However, the proliferation of FMs brings forth a critical challenge: the potential to generate hallucinated outputs, particularly in high-stakes... | Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha |  |
| 2079 |  |  [Predicting generalization performance with correctness discriminators](https://doi.org/10.18653/v1/2024.findings-emnlp.686) |  | 0 | The ability to predict an NLP model’s accuracy on unseen, potentially out-of-distribution data is a prerequisite for trustworthiness. We present a novel model that establishes upper and lower bounds on the accuracy, without requiring gold labels for the unseen data. We achieve this by training a... | Yuekun Yao, Alexander Koller |  |
| 2080 |  |  [FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.687) |  | 0 | Large language models (LLMs) excel in generating coherent text, but they often struggle with context awareness, leading to inaccuracies in tasks requiring faithful adherence to provided information. We introduce FastMem, a novel method designed to enhance instruction fine-tuned LLMs’ context... | Junyi Zhu, Shuochen Liu, Yu Yu, Bo Tang, Yibo Yan, Zhiyu Li, Feiyu Xiong, Tong Xu, Matthew B. Blaschko |  |
| 2081 |  |  [Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks](https://doi.org/10.18653/v1/2024.findings-emnlp.688) |  | 0 | The evaluation of natural language processing (NLP) systems is crucial for advancing the field, but current benchmarking approaches often assume that all systems have scores available for all tasks, which is not always practical. In reality, several factors such as the cost of running baseline,... | Anas Himmi, Ekhine Irurozki, Nathan Noiry, Stéphan Clémençon, Pierre Colombo |  |
| 2082 |  |  [Mixed-Session Conversation with Egocentric Memory](https://doi.org/10.18653/v1/2024.findings-emnlp.689) |  | 0 | Recently introduced dialogue systems have demonstrated high usability. However, they still fall short of reflecting real-world conversation scenarios. Current dialogue systems exhibit an inability to replicate the dynamic, continuous, long-term interactions involving multiple partners. This... | Jihyoung Jang, Taeyoung Kim, Hyounghun Kim |  |
| 2083 |  |  [CSLM: A Framework for Question Answering Dataset Generation through Collaborative Small Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.690) |  | 0 | Collecting high-quality question-answer (QA) pairs is vital for the training of large language models (LLMs), yet this process is traditionally laborious and time-intensive. With the rapid evolution of LLMs, the potential for leveraging these models to autonomously generate QA pairs has become... | Yiming Wang, Yang Liu, Lingchen Wang, An Xiao |  |
| 2084 |  |  [Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?](https://doi.org/10.18653/v1/2024.findings-emnlp.691) |  | 0 | Despite their promising performance across various tasks, recent studies reveal that Large language models (LLMs) still exhibit significant deficiencies in handling several word-level and character-level tasks, e.g., word unscrambling and sentence editing, indicating urgent needs for substantial... | Yidan Zhang, Zhenan He |  |
| 2085 |  |  [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://doi.org/10.18653/v1/2024.findings-emnlp.692) |  | 0 | Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource... | Yuqi Zhou, Lin Lu, Ryan Sun, Pan Zhou, Lichao Sun |  |
| 2086 |  |  [Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection](https://doi.org/10.18653/v1/2024.findings-emnlp.693) |  | 0 | Self-detection for Large Language Models (LLMs) seeks to evaluate the trustworthiness of the LLM’s output by leveraging its own capabilities, thereby alleviating the issue of output hallucination. However, existing self-detection approaches only retrospectively evaluate answers generated by LLM,... | Moxin Li, Wenjie Wang, Fuli Feng, Fengbin Zhu, Qifan Wang, TatSeng Chua |  |
| 2087 |  |  [Automating Easy Read Text Segmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.694) |  | 0 | Easy Read text is one of the main forms of access to information for people with reading difficulties. One of the key characteristics of this type of text is the requirement to split sentences into smaller grammatical segments, to facilitate reading. Automated segmentation methods could foster the... | Jesus Calleja, Thierry Etchegoyhen, Antonio David Ponce Martínez |  |
| 2088 |  |  [Position Paper: Data-Centric AI in the Age of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.695) |  | 0 | This position paper proposes a data-centric viewpoint of AI research, focusing on large language models (LLMs). We start by making a key observation that data is instrumental in the developmental (e.g., pretraining and fine-tuning) and inferential stages (e.g., in-context learning) of LLMs, and... | Xinyi Xu, Zhaoxuan Wu, Rui Qiao, Arun Verma, Yao Shu, Jingtan Wang, Xinyuan Niu, Zhenfeng He, Jiangwei Chen, Zijian Zhou, Gregory Kang Ruey Lau, Hieu Dao, Lucas Agussurja, Rachael Hwee Ling Sim, Xiaoqiang Lin, Wenyang Hu, Zhongxiang Dai, Pang Wei Koh, Bryan Kian Hsiang Low |  |
| 2089 |  |  [MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations](https://doi.org/10.18653/v1/2024.findings-emnlp.696) |  | 0 | Math word problems are critical K-8 educational tools, but writing them is time consuming and requires extensive expertise. To be educational, problems must be solvable, have accurate answers, and, most importantly, be educationally appropriate. We propose that language models have potential to... | Bryan R. Christ, Jonathan Kropko, Thomas Hartvigsen |  |
| 2090 |  |  [Resilience of Large Language Models for Noisy Instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.697) |  | 0 | As the rapidly advancing domain of natural language processing (NLP), large language models (LLMs) have emerged as powerful tools for interpreting human commands and generating text across various tasks. Nonetheless, the resilience of LLMs to handle text containing inherent errors, stemming from... | Bin Wang, Chengwei Wei, Zhengyuan Liu, Geyu Lin, Nancy F. Chen |  |
| 2091 |  |  [LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity](https://doi.org/10.18653/v1/2024.findings-emnlp.698) |  | 0 |  | Selim F. Tekin, Fatih Ilhan, Tiansheng Huang, Sihao Hu, Ling Liu |  |
| 2092 |  |  [Augmenting Reasoning Capabilities of LLMs with Graph Structures in Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.699) |  | 0 | Recently, significant progress has been made in employing Large Language Models (LLMs) for semantic parsing to address Knowledge Base Question Answering (KBQA) tasks. Previous work utilize LLMs to generate query statements on Knowledge Bases (KBs) for retrieving answers. However, LLMs often... | Yuhang Tian, Dandan Song, Zhijing Wu, Changzhi Zhou, Hao Wang, Jun Yang, Jing Xu, Ruanmin Cao, Haoyu Wang |  |
| 2093 |  |  [Creative Problem Solving in Large Language and Vision Models - What Would it Take?](https://doi.org/10.18653/v1/2024.findings-emnlp.700) |  | 0 | We advocate for a strong integration of Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this... | Lakshmi Nair, Evana Gizzi, Jivko Sinapov |  |
| 2094 |  |  [Cross-Lingual Multi-Hop Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-emnlp.701) |  | 0 | Large language models (LLMs) are often expected to be constantly adapted to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual knowledge editing in English, even though new... | Aditi Khandelwal, Harman Singh, Hengrui Gu, Tianlong Chen, Kaixiong Zhou |  |
| 2095 |  |  [Android in the Zoo: Chain-of-Action-Thought for GUI Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.702) |  | 0 | Large language model (LLM) leads to a surge of autonomous GUI agents for smartphone, which completes a task triggered by natural language through predicting a sequence of actions of API. Even though the task highly relies on past actions and visual observations, existing studies typically consider... | Jiwen Zhang, Jihao Wu, Yihua Teng, Minghui Liao, Nuo Xu, Xiao Xiao, Zhongyu Wei, Duyu Tang |  |
| 2096 |  |  [Self-Recognition in Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.703) |  | 0 | A rapidly growing number of applications rely on a small set of closed-source language models (LMs). This dependency might introduce novel security risks if LMs develop self-recognition capabilities. Inspired by human identity verification methods, we propose a novel approach for assessing... | Tim R. Davidson, Viacheslav Surkov, Veniamin Veselovsky, Giuseppe Russo Latona, Robert West, Caglar Gulcehre |  |
| 2097 |  |  [Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.704) |  | 0 | Large Language Models (LLMs) have demonstrated impressive performance across various tasks. However, current training approaches combine standard cross-entropy loss with extensive data, human feedback, or ad hoc methods to enhance performance. These solutions are often not scalable or feasible due... | Daniele Rege Cambrin, Giuseppe Gallipoli, Irene Benedetto, Luca Cagliero, Paolo Garza |  |
| 2098 |  |  [The Shape of Word Embeddings: Quantifying Non-Isometry with Topological Data Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.705) |  | 0 | Word embeddings represent language vocabularies as clouds of d-dimensional points. We investigate how information is conveyed by the general shape of these clouds, instead of representing the semantic meaning of each token. Specifically, we use the notion of persistent homology from topological... | Ondrej Draganov, Steven Skiena |  |
| 2099 |  |  [Towards Robust Evaluation of Unlearning in LLMs via Data Transformations](https://doi.org/10.18653/v1/2024.findings-emnlp.706) |  | 0 | Large Language Models (LLMs) have shown to be a great success in a wide range of applications ranging from regular NLP-based use cases to AI agents. LLMs have been trained on a vast corpus of texts from various sources; despite the best efforts during the data pre-processing stage while training... | Abhinav Joshi, Shaswati Saha, Divyaksh Shukla, Sriram Vema, Harsh Jhamtani, Manas Gaur, Ashutosh Modi |  |
| 2100 |  |  [Numbers Matter! Bringing Quantity-awareness to Retrieval Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.707) |  | 0 | Quantitative information plays a crucial role in understanding and interpreting the content of documents. Many user queries contain quantities and cannot be resolved without understanding their semantics, e.g., “car that costs less than $10k”. Yet, modern search engines apply the same ranking... | Satya Almasian, Milena Bruseva, Michael Gertz |  |
| 2101 |  |  [Stark: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge](https://doi.org/10.18653/v1/2024.findings-emnlp.708) |  | 0 | Humans share a wide variety of images related to their personal experiences within conversations via instant messaging tools. However, existing works focus on (1) image-sharing behavior in singular sessions, leading to limited long-term social interaction, and (2) a lack of personalized... | YoungJun Lee, Dokyong Lee, Junyoung Youn, Kyeongjin Oh, Byungsoo Ko, Jonghwan Hyeon, HoJin Choi |  |
| 2102 |  |  [Dual-Phase Accelerated Prompt Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.709) |  | 0 | Gradient-free prompt optimization methods have made significant strides in enhancing the performance of closed-source Large Language Model (LLMs) across a wide range of tasks. However, existing approaches make light of the importance of high-quality prompt initialization and the identification of... | Muchen Yang, Moxin Li, Yongle Li, Zijun Chen, Chongming Gao, Junqi Zhang, Yangyang Li, Fuli Feng |  |
| 2103 |  |  [ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.710) |  | 0 | Chart question answering (ChartQA) tasks play a critical role in interpreting and extracting insights from visualization charts. While recent advancements in multimodal large language models (MLLMs) like GPT-4o have shown promise in high-level ChartQA tasks, such as chart captioning, their... | Yifan Wu, Lutao Yan, Leixian Shen, Yunhai Wang, Nan Tang, Yuyu Luo |  |
| 2104 |  |  [Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication](https://doi.org/10.18653/v1/2024.findings-emnlp.711) |  | 0 | In this paper, we study how culture leads to differences in common ground and how this influences communication. During communication, cultural differences in common ground during communication may result in pragmatic failure and misunderstandings. We develop our method Rational Speech Acts for... | Isadora White, Sashrika Pandey, Michelle Pan |  |
| 2105 |  |  [SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles](https://doi.org/10.18653/v1/2024.findings-emnlp.712) |  | 0 | In an era where information is quickly shared across many cultural and language contexts, the neutrality and integrity of news media are essential. Ensuring that media content remains unbiased and factual is crucial for maintaining public trust. With this in mind, we introduce SAFARI (CroSs-lingual... | Dilshod Azizov, Zain Muhammad Mujahid, Hilal AlQuabeh, Preslav Nakov, Shangsong Liang |  |
| 2106 |  |  [CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.713) |  | 0 | Recent advancements in instruction-tuning datasets have predominantly focused on specific tasks like mathematical or logical reasoning. There has been a notable gap in data designed for aligning language models to maintain topic relevance in conversations - a critical aspect for deploying chatbots... | Makesh Narsimhan Sreedhar, Traian Rebedea, Shaona Ghosh, Jiaqi Zeng, Christopher Parisien |  |
| 2107 |  |  [An LLM-Enabled Knowledge Elicitation and Retrieval Framework for Zero-Shot Cross-Lingual Stance Identification](https://doi.org/10.18653/v1/2024.findings-emnlp.714) |  | 0 | Stance detection aims to identify the attitudes toward specific targets from text, which is an important research area in text mining and social media analytics. Existing research is mainly conducted in monolingual setting on English datasets. To tackle the data scarcity problem in low-resource... | Ruike Zhang, Yuan Tian, Penghui Wei, Daniel Zeng, Wenji Mao |  |
| 2108 |  |  [TuringQ: Benchmarking AI Comprehension in Theory of Computation](https://doi.org/10.18653/v1/2024.findings-emnlp.715) |  | 0 | We present TuringQ, the first benchmark designed to evaluate the reasoning capabilities of large language models (LLMs) in the theory of computation. TuringQ consists of 4,006 undergraduate and graduate-level question-answer pairs, categorized into four difficulty levels and covering seven core... | Pardis Sadat Zahraei, Ehsaneddin Asgari |  |
| 2109 |  |  [Learning to Refine with Fine-Grained Natural Language Feedback](https://doi.org/10.18653/v1/2024.findings-emnlp.716) |  | 0 | Recent work has explored the capability of large language models (LLMs) to identify and correct errors in LLM-generated responses. These refinement approaches frequently evaluate what sizes of models are able to do refinement for what problems, but less attention is paid to what effective feedback... | Manya Wadhwa, Xinyu Zhao, Junyi Jessy Li, Greg Durrett |  |
| 2110 |  |  [Implicit Personalization in Language Models: A Systematic Study](https://doi.org/10.18653/v1/2024.findings-emnlp.717) |  | 0 | Implicit Personalization (IP) is a phenomenon of language models inferring a user’s background from the implicit cues in the input prompts and tailoring the response based on this inference. While previous work has touched upon various instances of this problem, there lacks a unified framework to... | Zhijing Jin, Nils Heil, Jiarui Liu, Shehzaad Dhuliawala, Yahang Qi, Bernhard Schölkopf, Rada Mihalcea, Mrinmaya Sachan |  |
| 2111 |  |  [When the Misidentified Adverbial Phrase Functions as a Complement](https://doi.org/10.18653/v1/2024.findings-emnlp.718) |  | 0 | This study investigates the predicate-argument structure in Korean language processing. Despite the importance of distinguishing mandatory arguments and optional modifiers in sentences, research in this area has been limited. We introduce a dataset with token-level annotations which labels... | Yige Chen, Kyuwon Kim, Kyungtae Lim, Jungyeul Park, Chulwoo Park |  |
| 2112 |  |  [Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization](https://doi.org/10.18653/v1/2024.findings-emnlp.719) |  | 0 | Implicit knowledge hidden within the explicit table cells, such as data insights, is the key to generating a high-quality table summary. However, unveiling such implicit knowledge is a non-trivial task. Due to the complex nature of structured tables, it is challenging even for large language models... | Kwangwook Seo, Jinyoung Yeo, Dongha Lee |  |
| 2113 |  |  [Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model](https://doi.org/10.18653/v1/2024.findings-emnlp.720) |  | 0 | A supervised ranking model, despite its effectiveness over traditional approaches, usually involves complex processing - typically multiple stages of task-specific pre-training and fine-tuning. This has motivated researchers to explore simpler pipelines leveraging large language models (LLMs) that... | Nilanjan Sinhababu, Andrew Parry, Debasis Ganguly, Debasis Samanta, Pabitra Mitra |  |
| 2114 |  |  [Self-training Language Models for Arithmetic Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.721) |  | 0 | Recent language models achieve impressive results in tasks involving complex multistep reasoning, but scaling these capabilities further traditionally requires expensive collection of more annotated data.In this work, we explore the potential of improving models’ reasoning capabilities without new... | Marek Kadlcík, Michal Stefánik |  |
| 2115 |  |  [PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](https://doi.org/10.18653/v1/2024.findings-emnlp.722) |  | 0 | The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations. To address this critical need, we propose the PowerPoint Task Completion-Robustness (PPTC-R)... | Zekai Zhang, Yiduo Guo, Yaobo Liang, Dongyan Zhao, Nan Duan |  |
| 2116 |  |  [Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation](https://doi.org/10.18653/v1/2024.findings-emnlp.723) |  | 0 | News recommendation is a challenging task that involves personalization based on the interaction history and preferences of each user. Recent works have leveraged the power of pretrained language models (PLMs) to directly rank news items by using inference approaches that predominately fall into... | Nithish Kannen, Yao Ma, Gerrit J. J. van den Burg, Jean Baptiste Faddoul |  |
| 2117 |  |  [Fast Matrix Multiplications for Lookup Table-Quantized LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.724) |  | 0 | The deployment of large language models (LLMs) is often constrained by memory bandwidth, where the primary bottleneck is the cost of transferring model parameters from the GPU’s global memory to its registers. When coupled with custom kernels that fuse the dequantization and matmul operations,... | Han Guo, William Brandon, Radostin Cholakov, Jonathan RaganKelley, Eric P. Xing, Yoon Kim |  |
| 2118 |  |  [Distance-aware Calibration for Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.725) |  | 0 | Language Models for text classification often produce overconfident predictions for both in-distribution and out-of-distribution samples, i.e., the model’s output probabilities do not match their accuracy. Prior work showed that simple post-hoc approaches are effective for mitigating this issue,... | Alberto Gasparin, Gianluca Detommaso |  |
| 2119 |  |  [Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks](https://doi.org/10.18653/v1/2024.findings-emnlp.726) |  | 0 | Medical knowledge is context-dependent and requires consistent reasoning across various natural language expressions of semantically equivalent phrases. This is particularly crucial for drug names, where patients often use brand names like Advil or Tylenol instead of their generic equivalents. To... | Jack Gallifant, Shan Chen, Pedro Moreira, Nikolaj Munch, Mingye Gao, Jackson Pond, Leo Anthony Celi, Hugo J. W. L. Aerts, Thomas Hartvigsen, Danielle S. Bitterman |  |
| 2120 |  |  [To Err Is Human, but Llamas Can Learn It Too](https://doi.org/10.18653/v1/2024.findings-emnlp.727) |  | 0 | This study explores enhancing grammatical error correction (GEC) through automatic error generation (AEG) using language models (LMs). Specifically, we fine-tune Llama 2 LMs for error generation and find that this approach yields synthetic errors akin to human errors. Next, we train GEC Llama... | Agnes Luhtaru, Taido Purason, Martin Vainikko, Maksym Del, Mark Fishel |  |
| 2121 |  |  [PizzaCommonSense: A Dataset for Commonsense Reasoning about Intermediate Steps in Cooking Recipes](https://doi.org/10.18653/v1/2024.findings-emnlp.728) |  | 0 | Understanding procedural texts, such as cooking recipes, is essential for enabling machines to follow instructions and reason about tasks, a key aspect of intelligent reasoning. In cooking, these instructions can be interpreted as a series of modifications to a food preparation.For a model to... | Aïssatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller |  |
| 2122 |  |  [Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation](https://doi.org/10.18653/v1/2024.findings-emnlp.729) |  | 0 | Due to the high complexity of Discourse Dependency Parsing (DDP) tasks, their existing annotation resources are relatively scarce compared to other NLP tasks, and different DDP tasks also have significant differences in annotation schema. These issues have led to the dilemma of low resources for... | Zizhuo Shen, Yanqiu Shao, Wei Li |  |
| 2123 |  |  ["Knowing When You Don't Know": A Multilingual Relevance Assessment Dataset for Robust Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.730) |  | 0 | Retrieval-Augmented Generation (RAG) grounds Large Language Model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior work lacks a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against... | Nandan Thakur, Luiz Bonifacio, Xinyu Zhang, Odunayo Ogundepo, Ehsan Kamalloo, David AlfonsoHermelo, Xiaoguang Li, Qun Liu, Boxing Chen, Mehdi Rezagholizadeh, Jimmy Lin |  |
| 2124 |  |  [Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking](https://doi.org/10.18653/v1/2024.findings-emnlp.731) |  | 0 | We demonstrate substantial performance gains in zero-shot dialogue state tracking (DST) by enhancing training data diversity through synthetic data generation.Existing DST datasets are severely limited in the number of application domains and slot types they cover due to the high costs of data... | James D. Finch, Jinho D. Choi |  |
| 2125 |  |  [Can We Instruct LLMs to Compensate for Position Bias?](https://doi.org/10.18653/v1/2024.findings-emnlp.732) |  | 0 | Position bias in large language models (LLMs) leads to difficulty in accessing information retrieved from the retriever, thus downgrading the effectiveness of Retrieval-Augmented Generation (RAG) approaches in open-question answering. Recent studies reveal that this bias is related to... | Meiru Zhang, Zaiqiao Meng, Nigel Collier |  |
| 2126 |  |  [Textual Dataset Distillation via Language Model Embedding](https://doi.org/10.18653/v1/2024.findings-emnlp.733) |  | 0 | Dataset distillation is a process aimed at condensing datasets while preserving essential characteristics. In the text domain, prevailing methods typically generate distilled data as embedding vectors, which are not human-readable. This approach simplifies optimization but limits the... | Yefan Tao, Luyang Kong, Andrey Kan, Laurent Callot |  |
| 2127 |  |  [TARA: Token-level Attribute Relation Adaptation for Multi-Attribute Controllable Text Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.734) |  | 0 |  | Yilin Cao, Jiahao Zhao, Ruike Zhang, Hanyi Zou, Wenji Mao |  |
| 2128 |  |  [AuriSRec: Adversarial User Intention Learning in Sequential Recommendation](https://doi.org/10.18653/v1/2024.findings-emnlp.735) |  | 0 | With recommender systems broadly deployed in various online platforms, many efforts have been devoted to learning user preferences and building effective sequential recommenders. However, existing work mainly focuses on capturing user implicit preferences from historical interactions and simply... | Junjie Zhang, Ruobing Xie, Wenqi Sun, Leyu Lin, Xin Zhao, JiRong Wen |  |
| 2129 |  |  [Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer](https://doi.org/10.18653/v1/2024.findings-emnlp.736) |  | 0 | The success of deep learning models on multi-hop fact verification has prompted researchers to understand the behavior behind their veracity. One feasible way is erasure search: obtaining the rationale by entirely removing a subset of input without compromising verification accuracy. Despite... | Jiasheng Si, Yingjie Zhu, Wenpeng Lu, Deyu Zhou |  |
| 2130 |  |  [README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP](https://aclanthology.org/2024.findings-emnlp.737) |  | 0 | The advancement in healthcare has shifted focus toward patient-centric approaches, particularly in self-care and patient education, facilitated by access to Electronic Health Records (EHR). However, medical jargon in EHRs poses significant challenges in patient comprehension. To address this, we... | Zonghai Yao, Nandyala Siddharth Kantu, Guanghao Wei, Hieu Tran, Zhangqi Duan, Sunjae Kwon, Zhichao Yang, README annotation team, Hong Yu |  |
| 2131 |  |  [Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts](https://doi.org/10.18653/v1/2024.findings-emnlp.738) |  | 0 | In this work, we show the pre-trained language models return distinguishable generation probability and uncertainty distribution to unfaithfully hallucinated texts, regardless of their size and structure. By examining 24 models on 6 data sets, we find out that 88-98% of cases return statistically... | Taehun Cha, Donghun Lee |  |
| 2132 |  |  [Cognitive Bias in Decision-Making with LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.739) |  | 0 | Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. Given their training on human (created) data, LLMs have been shown to inherit societal biases against protected groups, as well as be subject to bias functionally resembling... | Jessica Maria Echterhoff, Yao Liu, Abeer Alessa, Julian J. McAuley, Zexue He |  |
| 2133 |  |  [Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations](https://doi.org/10.18653/v1/2024.findings-emnlp.740) |  | 0 | Many open-ended conversations (e.g., tutoring lessons or business meetings) revolve around pre-defined reference materials, like worksheets or meeting bullets. To provide a framework for studying such conversation structure, we introduce \*Problem-Oriented Segmentation & Retrieval (POSR), the task... | Rose E. Wang, Pawan Wirawarn, Kenny Lam, Omar Khattab, Dorottya Demszky |  |
| 2134 |  |  [Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.741) |  | 0 | Prompt-based learning is susceptible to intrinsic bias present in pre-trained language models (LMs), leading to sub-optimal performance in prompt-based zero/few-shot settings. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different... | Kang He, Yinghan Long, Kaushik Roy |  |
| 2135 |  |  [Can't Remember Details in Long Documents? You Need Some R&R](https://doi.org/10.18653/v1/2024.findings-emnlp.742) |  | 0 | Long-context large language models (LLMs) hold promise for tasks such as question-answering (QA) over long documents, but they tend to miss important information in the middle of context documents [(Liu 2023)](https://arxiv.org/abs/2307.03172). Here, we introduce \*R&R\*—a combination of two novel... | Devanshu Agrawal, Shang Gao, Martin Gajek |  |
| 2136 |  |  [HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid](https://doi.org/10.18653/v1/2024.findings-emnlp.743) |  | 0 | Humanitarian organizations can enhance their effectiveness by analyzing data to discover trends, gather aggregated insights, manage their security risks, support decision-making, and inform advocacy and funding proposals. However, data about violent incidents with direct impact and relevance for... | Hemank Lamba, Anton Abilov, Ke Zhang, Elizabeth M. Olson, Henry Kudzanai Dambanemuya, João C. Bárcia, David Batista, Christina Wille, Aoife Cahill, Joel R. Tetreault, Alejandro Jaimes |  |
| 2137 |  |  [Improving Quotation Attribution with Fictional Character Embeddings](https://doi.org/10.18653/v1/2024.findings-emnlp.744) |  | 0 | Humans naturally attribute utterances of direct speech to their speaker in literary works.When attributing quotes, we process contextual information but also access mental representations of characters that we build and revise throughout the narrative. Recent methods to automatically attribute such... | Gaspard Michel, Elena V. Epure, Romain Hennequin, Christophe Cerisara |  |
| 2138 |  |  [Robust Text Classification: Analyzing Prototype-Based Networks](https://doi.org/10.18653/v1/2024.findings-emnlp.745) |  | 0 | Downstream applications often require text classification models to be accurate and robust. While the accuracy of state-of-the-art Language Models (LMs) approximates human performance, they often exhibit a drop in performance on real-world noisy data. This lack of robustness can be concerning, as... | Zhivar Sourati, Darshan Deshpande, Filip Ilievski, Kiril Gashteovski, Sascha Saralajew |  |
| 2139 |  |  [GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.746) |  | 0 | Long-context capabilities are essential for large language models (LLMs) to tackle complex and long-input tasks. Despite numerous efforts made to optimize LLMs for long contexts, challenges persist in robustly processing long inputs. In this paper, we introduce GraphReader, a graph-based agent... | Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng |  |
| 2140 |  |  [Compare without Despair: Reliable Preference Evaluation with Generation Separability](https://doi.org/10.18653/v1/2024.findings-emnlp.747) |  | 0 | Human evaluation of generated language through pairwise preference judgments is pervasive. However, under common scenarios, such as when generations from a model pair are very similar, or when stochastic decoding results in large variations in generations, it results in inconsistent preference... | Sayan Ghosh, Tejas Srinivasan, Swabha Swayamdipta |  |
| 2141 |  |  [LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.748) |  | 0 | Efficient fine-tuning plays a fundamental role in modern large models, with low-rank adaptation emerging as a particularly promising approach. However, the existing variants of LoRA are hampered by limited expressiveness, a tendency to overfit, and sensitivity to hyperparameter settings. This paper... | Siwei Li, Yifan Yang, Yifei Shen, Fangyun Wei, Zongqing Lu, Lili Qiu, Yuqing Yang |  |
| 2142 |  |  [SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models](https://doi.org/10.18653/v1/2024.findings-emnlp.749) |  | 0 | Large pre-trained models (LPMs), such as large language models, have become ubiquitous and are employed in many applications. These models are often adapted to a desired domain or downstream task through a fine-tuning stage. This paper proposes SQFT, an end-to-end solution for low-precision sparse... | Juan Pablo Muñoz, Jinjie Yuan, Nilesh Jain |  |
| 2143 |  |  [Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks](https://doi.org/10.18653/v1/2024.findings-emnlp.750) |  | 0 | Large language models (LLMs) have acquired the ability to handle longer context lengths and understand nuances in text, expanding their dialogue capabilities beyond a single utterance. A popular user-facing application of LLMs is the multi-turn chat setting. Though longer chat memory and better... | Terry Tong, Qin Liu, Jiashu Xu, Muhao Chen |  |
| 2144 |  |  [InternalInspector I²: Robust Confidence Estimation in LLMs through Internal States](https://doi.org/10.18653/v1/2024.findings-emnlp.751) |  | 0 | Despite their vast capabilities, Large Language Models (LLMs) often struggle with generating reliable outputs, frequently producing high-confidence inaccuracies known as hallucinations. Addressing this challenge, our research introduces InternalInspector, a novel framework designed to enhance... | Mohammad Beigi, Ying Shen, Runing Yang, Zihao Lin, Qifan Wang, Ankith Mohan, Jianfeng He, Ming Jin, ChangTien Lu, Lifu Huang |  |
| 2145 |  |  [All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.752) |  | 0 | This paper introduces LADAM, a novel method for enhancing the performance of text classification tasks. LADAM employs attention mechanisms to exchange semantically similar words between sentences. This approach generates a greater diversity of synthetic sentences compared to simpler operations like... | Junehyung Kim, Sungjae Hwang |  |
| 2146 |  |  [Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.753) |  | 0 | Recent studies show that text-to-image (T2I) models are vulnerable to adversarial attacks, especially with noun perturbations in text prompts. In this study, we investigate the impact of adversarial attacks on different POS tags within text prompts on the images generated by T2I models. We create a... | G. M. Shahariar, Jia Chen, Jiachen Li, Yue Dong |  |
| 2147 |  |  [Enhancing Alignment using Curriculum Learning & Ranked Preferences](https://doi.org/10.18653/v1/2024.findings-emnlp.754) |  | 0 | Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (one chosen and rejected response per prompt) to align LLMs to human preferences. In practice, multiple responses could exist for a given prompt with varying quality relative to each other. We... | Pulkit Pattnaik, Rishabh Maheshwary, Kelechi Ogueji, Vikas Yadav, Sathwik Tejaswi Madhusudhan |  |
| 2148 |  |  [Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach](https://doi.org/10.18653/v1/2024.findings-emnlp.755) |  | 0 | Cross-lingual summarization aims to bridge language barriers by summarizing documents in different languages. However, ensuring semantic coherence across languages is an overlooked challenge and can be critical in several contexts. To fill this gap, we introduce multi-target cross-lingual... | Diogo Pernes, Gonçalo M. Correia, Afonso Mendes |  |
| 2149 |  |  [Tab2Text - A framework for deep learning with tabular data](https://doi.org/10.18653/v1/2024.findings-emnlp.756) |  | 0 | Tabular data, from public opinion surveys to records of interactions with social services, is foundational to the social sciences. One application of such data is to fit supervised learning models in order to predict consequential outcomes, for example: whether a family is likely to be evicted,... | Tong Lin, Jason Yan, David Jurgens, Sabina Tomkins |  |
| 2150 |  |  [More Bang for your Context: Virtual Documents for Question Answering over Long Documents](https://doi.org/10.18653/v1/2024.findings-emnlp.757) |  | 0 | We deal with the problem of Question Answering (QA) over a long document, which poses a challenge for modern Large Language Models (LLMs). Although LLMs can handle increasingly longer context windows, they struggle to effectively utilize the long content. To address this issue, we introduce the... | Yosi Mass, Boaz Carmeli, Asaf Yehudai, Assaf Toledo, Nathaniel Mills |  |
| 2151 |  |  [Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression](https://doi.org/10.18653/v1/2024.findings-emnlp.758) |  | 0 | As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and... | Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha Swayamdipta, Antonio Ortega |  |
| 2152 |  |  [Synthetic Multimodal Question Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.759) |  | 0 | Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to question-answering over multimodal documents. A key challenge with evaluating MMRAG is the paucity of high-quality datasets matching the question styles and modalities of interest. In light of this, we propose SMMQG, a... | Ian Wu, Sravan Jayanthi, Vijay Viswanathan, Simon Rosenberg, Sina Pakazad, Tongshuang Wu, Graham Neubig |  |
| 2153 |  |  [Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures](https://doi.org/10.18653/v1/2024.findings-emnlp.760) |  | 0 | The recent integration of chemistry with natural language processing (NLP) has advanced drug discovery. Molecule representation in language models (LMs) is crucial in enhancing chemical understanding. We propose Augmented Molecular Retrieval (AMORE), a flexible zero-shot framework for assessment of... | Veronika Ganeeva, Andrey Sakhovskiy, Kuzma Khrabrov, Andrey V. Savchenko, Artur Kadurin, Elena Tutubalina |  |
| 2154 |  |  [HyQE: Ranking Contexts with Hypothetical Query Embeddings](https://doi.org/10.18653/v1/2024.findings-emnlp.761) |  | 0 | In retrieval-augmented systems, context ranking techniques are commonly employed to reorder the retrieved contexts based on their relevance to a user query. A standard approach is to measure this relevance through the similarity between contexts and queries in the embedding space. However, such... | Weichao Zhou, Jiaxin Zhang, Hilaf Hasson, Anu Singh, Wenchao Li |  |
| 2155 |  |  [Model Merging and Safety Alignment: One Bad Model Spoils the Bunch](https://doi.org/10.18653/v1/2024.findings-emnlp.762) |  | 0 | Merging Large Language Models (LLMs) is a cost-effective technique for combining multiple expert LLMs into a single versatile model, retaining the expertise of the original ones. However, current approaches often overlook the importance of safety alignment during merging, leading to highly... | Hasan Hammoud, Umberto Michieli, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem, Mete Ozay |  |
| 2156 |  |  [Large Language Models Are Challenged by Habitat-Centered Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.763) |  | 0 | In this paper we perform a novel in-depth evaluation of text-only and multimodal LLMs’ abilities to reason about object \*habitats\* or conditions on how objects are situated in their environments that affect the types of behaviors (or \*affordances\*) that can be enacted upon them. We present a... | Sadaf Ghaffari, Nikhil Krishnaswamy |  |
| 2157 |  |  [How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models](https://doi.org/10.18653/v1/2024.findings-emnlp.764) |  | 0 | Given the growing influx of misinformation across news and social media, there is a critical need for systems that can provide effective real-time verification of news claims. Large language or multimodal model based verification has been proposed to scale up online policing mechanisms for... | Jaeyoung Lee, Ximing Lu, Jack Hessel, Faeze Brahman, Youngjae Yu, Yonatan Bisk, Yejin Choi, Saadia Gabriel |  |
| 2158 |  |  [Benchmarking Machine Translation with Cultural Awareness](https://doi.org/10.18653/v1/2024.findings-emnlp.765) |  | 0 | Translating culture-related content is vital for effective cross-cultural communication. However, many culture-specific items (CSIs) often lack literal translation across languages, making it challenging to collect high-quality, diverse parallel corpora with CSI annotations. This difficulty hinders... | Binwei Yao, Ming Jiang, Tara Bobinac, Diyi Yang, Junjie Hu |  |
| 2159 |  |  [Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?](https://doi.org/10.18653/v1/2024.findings-emnlp.766) |  | 0 | The vast majority of today’s large language models (LLMs) are English-centric, having been pretrained predominantly on English text. Yet, in order to meet user expectations, models need to be able to respond appropriately in multiple languages once deployed in downstream applications. This requires... | Tannon Kew, Florian Schottmann, Rico Sennrich |  |
| 2160 |  |  [Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-emnlp.767) |  | 0 | Speculative decoding stands as a pivotal technique to expedite inference in autoregressive (large) language models. This method employs a smaller \*draft\* model to speculate a block of tokens, which the \*target\* model then evaluates for acceptance. Despite a wealth of studies aimed at increasing... | Siru Ouyang, Shuohang Wang, Minhao Jiang, Ming Zhong, Donghan Yu, Jiawei Han, Yelong Shen |  |
| 2161 |  |  [Generate then Refine: Data Augmentation for Zero-shot Intent Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.768) |  | 0 | In this short paper we propose a data augmentation method for intent detection in zero-resource domains.Existing data augmentation methods rely on few labelled examples for each intent category, which can be expensive in settings with many possible intents.We use a two-stage approach: First, we... | IFan Lin, Faegheh Hasibi, Suzan Verberne |  |
| 2162 |  |  [Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting](https://doi.org/10.18653/v1/2024.findings-emnlp.769) |  | 0 | Recent research in zero-shot Relation Extraction (RE) has focused on using Large Language Models (LLMs) due to their impressive zero-shot capabilities. However, current methods often perform suboptimally, mainly due to a lack of detailed, context-specific prompts needed for understanding various... | Siyi Liu, Yang Li, Jiang Li, Shan Yang, Yunshi Lan |  |
| 2163 |  |  ["What is the value of templates?" Rethinking Document Information Extraction Datasets for LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.770) |  | 0 | The rise of large language models (LLMs) for visually rich document understanding (VRDU) has kindled a need for prompt-response, document-based datasets. As annotating new datasets from scratch is labor-intensive, the existing literature has generated prompt-response datasets from available... | Ran Zmigrod, Pranav Shetty, Mathieu Sibue, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu, Manuela Veloso |  |
| 2164 |  |  [What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.771) |  | 0 | Language models often struggle with handling factual knowledge, exhibiting factual hallucination issue. This makes it vital to evaluate the models’ ability to recall its parametric knowledge about facts. In this study, we introduce a knowledge probing benchmark, BELIEF(ICL), to evaluate the... | Xin Zhao, Naoki Yoshinaga, Daisuke Oba |  |
| 2165 |  |  [On Leakage of Code Generation Evaluation Datasets](https://doi.org/10.18653/v1/2024.findings-emnlp.772) |  | 0 | In this paper, we consider contamination by code generation test sets, in particular in their use in modern large language models.We discuss three possible sources of such contamination and show findings supporting each of them: (i) direct data leakage, (ii) indirect data leakage through the use of... | Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen GilsenanMcMahon, Matthias Gallé |  |
| 2166 |  |  [The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI](https://doi.org/10.18653/v1/2024.findings-emnlp.773) |  | 0 | Psychological trauma can manifest following various distressing events and is captured in diverse online contexts. However, studies traditionally focus on a single aspect of trauma, often neglecting the transferability of findings across different scenarios. We address this gap by training various... | Miriam Schirmer, Tobias Leemann, Gjergji Kasneci, Jürgen Pfeffer, David Jurgens |  |
| 2167 |  |  [Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework](https://doi.org/10.18653/v1/2024.findings-emnlp.774) |  | 0 | Recent advancements in prompt engineering strategies, such as Chain-of-Thought (CoT) and Self-Discover, have demonstrated significant potential in improving the reasoning abilities of Large Language Models (LLMs). However, these state-of-the-art (SOTA) prompting strategies rely on a fixed set of... | Krishna Aswani, Huilin Lu, Pranav Patankar, Priya Dhalwani, Xue Tan, Jayant Ganeshmohan, Simon Lacasse |  |
| 2168 |  |  [V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.775) |  | 0 | Large vision-language models (LVLMs) suffer from hallucination, resulting in misalignment between the output textual response and the input visual content. Recent research indicates that the over-reliance on the Large Language Model (LLM) backbone, as one cause of the LVLM hallucination, inherently... | Yuxi Xie, Guanzhen Li, Xiao Xu, MinYen Kan |  |
| 2169 |  |  [Exploring the Potential of Multimodal LLM with Knowledge-Intensive Multimodal ASR](https://doi.org/10.18653/v1/2024.findings-emnlp.776) |  | 0 | Recent advancements in multimodal large language models (MLLMs) have made significant progress in integrating information across various modalities, yet real-world applications in educational and scientific domains remain challenging. This paper introduces the Multimodal Scientific ASR (MS-ASR)... | Minghan Wang, Yuxia Wang, ThuyTrang Vu, Ehsan Shareghi, Reza Haf |  |
| 2170 |  |  [Better Alignment with Instruction Back-and-Forth Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.777) |  | 0 | We propose a new method, instruction back-and-forth translation, to improve the quality of instruction-tuning data used for aligning large language models (LLMs). Given preprocessed texts from an initial web corpus (e.g. Dolma (Soldaini et al., 2024)), we generate synthetic instructions using the... | Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li |  |
| 2171 |  |  [AliGATr: Graph-based layout generation for form understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.778) |  | 0 | Forms constitute a large portion of layout-rich documents that convey information through key-value pairs. Form understanding involves two main tasks, namely, the identification of keys and values (a.k.a Key Information Extraction or KIE) and the association of keys to corresponding values (a.k.a.... | Armineh Nourbakhsh, Zhao Jin, Siddharth Parekh, Sameena Shah, Carolyn P. Rosé |  |
| 2172 |  |  [Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification](https://doi.org/10.18653/v1/2024.findings-emnlp.779) |  | 0 | We propose a constraint learning schema forfine-tuning Large Language Models (LLMs)with attribute control. Given a training corpusand control criteria formulated as a sequence-level constraint on model outputs, our methodfine-tunes the LLM on the training corpus whileenhancing constraint... | Tao Meng, Ninareh Mehrabi, Palash Goyal, Anil Ramakrishna, Aram Galstyan, Richard S. Zemel, KaiWei Chang, Rahul Gupta, Charith Peris |  |
| 2173 |  |  [SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement](https://doi.org/10.18653/v1/2024.findings-emnlp.780) |  | 0 | Automating the creation of scientific diagrams from academic papers can significantly streamline the development of tutorials, presentations, and posters, thereby saving time and accelerating the process. Current text-to-image models (Rombach et al., 2022a; Belouadi et al., 2023) struggle with... | Ishani Mondal, Zongxia Li, Yufang Hou, Anandhavelu Natarajan, Aparna Garimella, Jordan L. BoydGraber |  |
| 2174 |  |  [TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings](https://doi.org/10.18653/v1/2024.findings-emnlp.781) |  | 0 | The goal of text style transfer is to transform the style of texts while preserving their original meaning, often with only a few examples of the target style. Existing style transfer methods generally rely on the few-shot capabilities of large language models or on complex controllable text... | Zachary Horvitz, Ajay Patel, Kanishk Singh, Chris CallisonBurch, Kathleen R. McKeown, Zhou Yu |  |
| 2175 |  |  [Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?](https://doi.org/10.18653/v1/2024.findings-emnlp.782) |  | 0 | Emphasis is a crucial component in human communication, which indicates speaker’s intention and implication beyond pure text in dialogue. While Large Language Models (LLMs) have revolutionized natural language processing, their ability to understand emphasis in dialogue remains uncertain. This... | GuanTing Lin, Hungyi Lee |  |
| 2176 |  |  [Why do LLaVA Vision-Language Models Reply to Images in English?](https://doi.org/10.18653/v1/2024.findings-emnlp.783) |  | 0 | We uncover a surprising multilingual bias occurring in a popular class of multimodal vision-language models (VLMs). Including an image in the query to a LLaVA-style VLM significantly increases the likelihood of the model returning an English response, regardless of the language of the query. This... | Musashi Hinck, Carolin Holtermann, Matthew L. Olson, Florian Schneider, Sungduk Yu, Anahita Bhiwandiwalla, Anne Lauscher, ShaoYen Tseng, Vasudev Lal |  |
| 2177 |  |  [Preference Tuning For Toxicity Mitigation Generalizes Across Languages](https://doi.org/10.18653/v1/2024.findings-emnlp.784) |  | 0 | Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other... | Xiaochen Li, Zheng Xin Yong, Stephen H. Bach |  |
| 2178 |  |  [Calibrating Long-form Generations From Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.785) |  | 0 | To enhance Large Language Models’ (LLMs) reliability, calibration is essential—the model’s confidence scores should align with the likelihood of its responses being correct. However, traditional calibration methods typically rely on a binary true/false assessment of response correctness, unsuitable... | Yukun Huang, Yixin Liu, Raghuveer Thirukovalluru, Arman Cohan, Bhuwan Dhingra |  |
| 2179 |  |  [Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation](https://doi.org/10.18653/v1/2024.findings-emnlp.786) |  | 0 | Despite recent advancements in language and vision modeling, integrating rich multimodal knowledge into recommender systems continues to pose significant challenges. This is primarily due to the need for efficient recommendation, which requires adaptive and interactive responses. In this study, we... | Yueqi Wang, Zhenrui Yue, Huimin Zeng, Dong Wang, Julian J. McAuley |  |
| 2180 |  |  [Exploring Quantization for Efficient Pre-Training of Transformer Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.787) |  | 0 | The increasing scale of Transformer models has led to an increase in their pre-training computational requirements. While quantization has proven to be effective after pre-training and during fine-tuning, applying quantization in Transformers during pre-training has remained largely unexplored at... | Kamran Chitsaz, Quentin Fournier, Gonçalo Mordido, Sarath Chandar |  |
| 2181 |  |  [Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.788) |  | 0 | Story video-text alignment, a core task in computational story understanding, aims to align video clips with corresponding sentences in their descriptions. However, progress on the task has been held back by the scarcity of manually annotated video-text correspondence and the heavy concentration on... | Yidan Sun, Jianfei Yu, Boyang Li |  |
| 2182 |  |  [MVP-Bench: Can Large Vision-Language Models Conduct Multi-level Visual Perception Like Humans?](https://doi.org/10.18653/v1/2024.findings-emnlp.789) |  | 0 | Humans perform visual perception at multiple levels, including low-level object recognition and high-level semantic interpretation such as behavior understanding. Subtle differences in low-level details can lead to substantial changes in high-level perception. For example, substituting the shopping... | Guanzhen Li, Yuxi Xie, MinYen Kan |  |
| 2183 |  |  [Topic Modeling: Contextual Token Embeddings Are All You Need](https://doi.org/10.18653/v1/2024.findings-emnlp.790) |  | 0 | The goal of topic modeling is to find meaningful topics that capture the information present in a collection of documents. The main challenges of topic modeling are finding the optimal number of topics, labeling the topics, segmenting documents by topic, and evaluating topic model performance.... | Dimo Angelov, Diana Inkpen |  |
| 2184 |  |  [Dense Passage Retrieval: Is it Retrieving?](https://doi.org/10.18653/v1/2024.findings-emnlp.791) |  | 0 | Large Language Models (LLMs) internally store repositories of knowledge. However, their access to this repository is imprecise and they frequently hallucinate information that is not true or does not exist. A paradigm called Retrieval Augmented Generation (RAG) promises to fix these issues. Dense... | Benjamin Z. Reichman, Larry Heck |  |
| 2185 |  |  [Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback](https://doi.org/10.18653/v1/2024.findings-emnlp.792) |  | 0 | Large language models (LLMs) fine-tuned with alignment techniques, such as reinforcement learning from human feedback, have been instrumental in developing some of the most capable AI systems to date. Despite their success, existing methods typically rely on simple binary labels, such as those... | Kyuyoung Kim, Ah Jeong Seo, Hao Liu, Jinwoo Shin, Kimin Lee |  |
| 2186 |  |  [AfriInstruct: Instruction Tuning of African Languages for Diverse Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.793) |  | 0 | Large language models (LLMs) for African languages perform worse compared to their performance in high-resource languages. To address this issue, we introduce AfriInstruct, which specializes in instruction-tuning of multiple African languages covering various tasks. We trained the LLaMa-2-7B using... | Kosei Uemura, Mahe Chen, Alex Pejovic, Chika Maduabuchi, Yifei Sun, EnShiun Lee |  |
| 2187 |  |  [LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-emnlp.794) |  | 0 | Capturing the unique knowledge demands for each dialogue context plays a crucial role in commonsense knowledge-grounded response generation. However, current CoT-based and RAG-based methods are still unsatisfactory in the era of LLMs because 1) CoT often overestimates the capabilities of LLMs and... | Jiong Yu, Sixing Wu, Jiahao Chen, Wei Zhou |  |
| 2188 |  |  [ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-emnlp.795) |  | 0 | In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they... | Preetam Prabhu Srikar Dammu, Himanshu Naidu, Mouly Dewan, YoungMin Kim, Tanya Roosta, Aman Chadha, Chirag Shah |  |
| 2189 |  |  [Empirical Prior for Text Autoencoders](https://doi.org/10.18653/v1/2024.findings-emnlp.796) |  | 0 | This paper explores the application of Variational Autoencoders (VAE) in text generation, focusing on overcoming challenges like posterior collapse and the limitations of simplistic prior distributions. We investigate a transition from VAE to text autoencoders (AE), which model a compact latent... | Yongjing Yin, Wenyang Gao, Haodong Wu, Jianhao Yan, Yue Zhang |  |
| 2190 |  |  [Pedagogical Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.797) |  | 0 | Large Language Models (LLMs), when used in educational settings without pedagogical fine-tuning, often provide immediate answers rather than guiding students through the problem-solving process. This approach falls short of pedagogically best practices and limits their effectiveness as educational... | Shashank Sonkar, Kangqi Ni, Sapana Chaudhary, Richard G. Baraniuk |  |
| 2191 |  |  [Reference-based Metrics Disprove Themselves in Question Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.798) |  | 0 | Reference-based metrics such as BLEU and BERTScore are widely used to evaluate question generation (QG). In this study, on QG benchmarks such as SQuAD and HotpotQA, we find that using human-written references cannot guarantee the effectiveness of the reference-based metrics. Most QG benchmarks have... | Bang Nguyen, Mengxia Yu, Yun Huang, Meng Jiang |  |
| 2192 |  |  [Regression Aware Inference with LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.799) |  | 0 | Large language models (LLMs) have shown strong results on a range of applications, including regression and scoring tasks.Typically, one obtains outputs from an LLM via autoregressive sampling from the model’s output distribution. We show that this inference strategy can be sub-optimal for common... | Michal Lukasik, Harikrishna Narasimhan, Aditya Krishna Menon, Felix X. Yu, Sanjiv Kumar |  |
| 2193 |  |  [R³-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL](https://doi.org/10.18653/v1/2024.findings-emnlp.800) |  | 0 | While current tasks of converting natural language to SQL (NL2SQL) using Foundation Models have shown impressive achievements, adapting these approaches for converting natural language to Graph Query Language (NL2GQL) encounters hurdles due to the distinct nature of GQL compared to SQL, alongside... | Yuhang Zhou, Yu He, Siyu Tian, Yuchen Ni, Zhangyue Yin, Xiang Liu, Chuanjun Ji, Sen Liu, Xipeng Qiu, Guangnan Ye, Hongfeng Chai |  |
| 2194 |  |  [Updating Large Language Models' Memories with Time Constraints](https://doi.org/10.18653/v1/2024.findings-emnlp.801) |  | 0 | By incorporating the latest external knowledge, large language models (LLMs) can modify their internal memory. However, in practical applications, LLMs may encounter outdated information, necessitating the filtering of such data and updating of knowledge beyond internal memory. This paper explores... | Xin Wu, Yuqi Bu, Yi Cai, Tao Wang |  |
| 2195 |  |  [DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.802) |  | 0 | To enhance the performance of large language models (LLM) on downstream tasks, one solution is to fine-tune certain LLM parameters and make them better align with the characteristics of the training dataset. This process is commonly known as parameter-efficient fine-tuning (PEFT). Due to the scale... | Chao Gao, Sai Qian Zhang |  |
| 2196 |  |  [Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.803) |  | 0 |  | Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang |  |
| 2197 |  |  [Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions](https://doi.org/10.18653/v1/2024.findings-emnlp.804) |  | 0 | Large Language Models (LLMs) have introduced novel opportunities for text comprehension and generation. Yet, they are vulnerable to adversarial perturbations and data poisoning attacks, particularly in tasks like text classification and translation. However, the adversarial robustness of... | Poojitha Thota, Shirin Nilizadeh |  |
| 2198 |  |  [One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.805) |  | 0 | Morphologically rich languages are notoriously challenging to process for downstream NLP applications. This paper presents a new pretrained language model, ByT5-Sanskrit, designed for NLP applications involving the morphologically rich language Sanskrit. We evaluate ByT5-Sanskrit on established... | Sebastian Nehrdich, Oliver Hellwig, Kurt Keutzer |  |
| 2199 |  |  [NALA: an Effective and Interpretable Entity Alignment Method](https://doi.org/10.18653/v1/2024.findings-emnlp.806) |  | 0 | Entity alignment (EA) aims to find equivalent entities between two Knowledge Graphs. Existing embedding-based EA methods usually encode entities as embeddings, triples as embeddings’ constraint and learn to align the embeddings. However, the details of the underlying logical inference steps among... | Chuanhao Xu, Jingwei Cheng, Fu Zhang |  |
| 2200 |  |  [ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.807) |  | 0 | Open-domain long-form text generation requires generating coherent, comprehensive responses that address complex queries with both breadth and depth. This task is challenging due to the need to accurately capture diverse facets of input queries. Existing iterative retrieval-augmented generation... | Kashob Kumar Roy, Pritom Saha Akash, Kevin ChenChuan Chang, Lucian Popa |  |
| 2201 |  |  [Aligners: Decoupling LLMs and Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.808) |  | 0 | Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training \*aligner\* models... | Lilian Ngweta, Mayank Agarwal, Subha Maity, Alex Gittens, Yuekai Sun, Mikhail Yurochkin |  |
| 2202 |  |  [TOWER: Tree Organized Weighting for Evaluating Complex Instructions](https://doi.org/10.18653/v1/2024.findings-emnlp.809) |  | 0 | Evaluating the ability of large language models (LLMs) to follow complex human-written instructions is essential for their deployment in real-world applications. While benchmarks like Chatbot Arena use human judges to assess model performance, they are resource-intensive and time-consuming.... | Noah Ziems, Zhihan Zhang, Meng Jiang |  |
| 2203 |  |  [Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information](https://doi.org/10.18653/v1/2024.findings-emnlp.810) |  | 0 | Medical entity disambiguation (MED) aims to ground medical mentions in text with ontological entities in knowledge bases (KBs). A notable challenge of MED is the long medical text usually contains multiple entities’ mentions with intricate correlations. However, limited by computation overhead,... | Guobiao Zhang, Xueping Peng, Tao Shen, Guodong Long, Jiasheng Si, Libo Qin, Wenpeng Lu |  |
| 2204 |  |  [QEFT: Quantization for Efficient Fine-Tuning of LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.811) |  | 0 | With the rapid growth in the use of fine-tuning for large language models (LLMs), optimizing fine-tuning while keeping inference efficient has become highly important. However, this is a challenging task as it requires improvements in all aspects, including inference speed, fine-tuning speed,... | Changhun Lee, Jungyu Jin, Younghyun Cho, Eunhyeok Park |  |
| 2205 |  |  [Skills-in-Context: Unlocking Compositionality in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.812) |  | 0 | We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills, a critical reasoning ability akin to human intelligence. However, even the most advanced... | Jiaao Chen, Xiaoman Pan, Dian Yu, Kaiqiang Song, Xiaoyang Wang, Dong Yu, Jianshu Chen |  |
| 2206 |  |  [DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLMs Jailbreakers](https://doi.org/10.18653/v1/2024.findings-emnlp.813) |  | 0 | Safety-aligned Large Language Models (LLMs) are still vulnerable to some manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, existing jailbreaking methods usually view a harmful prompt as a whole but they are not effective at reducing LLMs’... | Xirui Li, Ruochen Wang, Minhao Cheng, Tianyi Zhou, ChoJui Hsieh |  |
| 2207 |  |  [Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.814) |  | 0 | The bias of disease prediction in Large Language Models (LLMs) is a critical yet underexplored issue, with potential implications for healthcare outcomes and equity. As LLMs increasingly find applications in healthcare, understanding and addressing their biases becomes paramount. This study focuses... | Yutian Zhao, Huimin Wang, Yuqi Liu, Suhuang Wu, Xian Wu, Yefeng Zheng |  |
| 2208 |  |  [BLADE: Benchmarking Language Model Agents for Data-Driven Science](https://doi.org/10.18653/v1/2024.findings-emnlp.815) |  | 0 | Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents... | Ken Gu, Ruoxi Shang, Ruien Jiang, Keying Kuang, RichardJohn Lin, Donghe Lyu, Yue Mao, Youran Pan, Teng Wu, Jiaqian Yu, Yikun Zhang, Tianmai M. Zhang, Lanyi Zhu, Mike A. Merrill, Jeffrey Heer, Tim Althoff |  |
| 2209 |  |  [Phonetic and Lexical Discovery of Canine Vocalization](https://doi.org/10.18653/v1/2024.findings-emnlp.816) |  | 0 | This paper attempts to discover communication patterns automatically within dog vocalizations in a data-driven approach, which breaks the barrier previous approaches that rely on human prior knowledge on limited data. We present a self-supervised approach with HuBERT, enabling the accurate... | Theron Wang, Xingyuan Li, Chunhao Zhang, Mengyue Wu, Kenny Q. Zhu |  |
| 2210 |  |  [Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech](https://doi.org/10.18653/v1/2024.findings-emnlp.817) |  | 0 | The difficulty of acquiring abundant, high-quality data, especially in multi-lingual contexts, has sparked interest in addressing low-resource scenarios. Moreover, current literature rely on fixed expressions from language IDs, which results in the inadequate learning of language representations,... | Youngjae Kim, Yejin Jeon, Gary Geunbae Lee |  |
| 2211 |  |  [LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons](https://doi.org/10.18653/v1/2024.findings-emnlp.818) |  | 0 | Data scarcity in low-resource languages can be addressed with word-to-word translations from labeled task data in high-resource languages using bilingual lexicons. However, bilingual lexicons often have limited lexical overlap with task data, which results in poor translation coverage and lexicon... | Zheng Xin Yong, Cristina Menghini, Stephen H. Bach |  |
| 2212 |  |  [Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks](https://doi.org/10.18653/v1/2024.findings-emnlp.819) |  | 0 | Creating human-like large language model (LLM) agents is crucial for faithful social simulation. Having LLMs role-play based on demographic information sometimes improves human likeness but often does not. This study assessed whether LLM alignment with human behavior can be improved by integrating... | YunShiuan Chuang, Krirk Nirunwiroj, Zach Studdiford, Agam Goyal, Vincent Frigo, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers |  |
| 2213 |  |  [PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-emnlp.820) |  | 0 | Spoken Language Understanding (SLU) is a critical component of voice assistants; it consists of converting speech to semantic parses for task execution. Previous works have explored end-to-end models to improve the quality and robustness of SLU models with Deliberation, however these models have... | Trang Le, Daniel Lazar, Suyoun Kim, Shan Jiang, Duc Le, Adithya Sagar, Aleksandr Livshits, Ahmed Aly, Akshat Shrivastava |  |
| 2214 |  |  [Downstream Trade-offs of a Family of Text Watermarks](https://doi.org/10.18653/v1/2024.findings-emnlp.821) |  | 0 | Watermarking involves implanting an imperceptible signal into generated text that can later be detected via statistical tests. A prominent family of watermarking strategies for LLMs embeds this signal by upsampling a (pseudorandomly-chosen) subset of tokens at every generation step. However, such... | Anirudh Ajith, Sameer Singh, Danish Pruthi |  |
| 2215 |  |  [Knowledge-Aware Reasoning over Multimodal Semi-structured Tables](https://doi.org/10.18653/v1/2024.findings-emnlp.822) |  | 0 | Existing datasets for tabular question answering typically focus exclusively on text within cells. However, real-world data is inherently multimodal, often blending images such as symbols, faces, icons, patterns, and charts with textual content in tables. With the evolution of AI models capable of... | Suyash Vardhan Mathur, Jainit Sushil Bafna, Kunal Kartik, Harshita Khandelwal, Manish Shrivastava, Vivek Gupta, Mohit Bansal, Dan Roth |  |
| 2216 |  |  [Representational Isomorphism and Alignment of Multilingual Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.823) |  | 0 | In this paper, we investigate the capability of Large Language Models (LLMs) to represent texts in multilingual contexts. Our findings show that sentence representations derived from LLMs exhibit a high degree of isomorphism across languages.This existing isomorphism can facilitate representational... | Di Wu, Yibin Lei, Andrew Yates, Christof Monz |  |
| 2217 |  |  [SWAG: Storytelling With Action Guidance](https://doi.org/10.18653/v1/2024.findings-emnlp.824) |  | 0 | Automated long-form story generation typically employs long-context large language models (LLMs) for one-shot creation, which can produce cohesive but not necessarily engaging content. We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach... | Jonathan Pei, Zeeshan Patel, Karim ElRefai, Tianle Li |  |
| 2218 |  |  [Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems](https://doi.org/10.18653/v1/2024.findings-emnlp.825) |  | 0 | Text classification is one of the essential topics in natural language processing, and each text is often associated with multiple labels. Recently, the number of labels has become larger and larger, especially in the applications of e-commerce, so handling text-related e-commerce problems further... | ShengWei Chen, ChihJen Lin |  |
| 2219 |  |  [Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting](https://doi.org/10.18653/v1/2024.findings-emnlp.826) |  | 0 | Large language models (LLMs) capable of casual conversation have recently become widely available. We hypothesize that users of conversational systems want a more personalized experience, and existing work shows that users are highly receptive to personalized questions (PQs). Question Generation... | Kevin Bowden, Yue Fan, Winson Chen, Wen Cui, Davan Harrison, Xin Wang, Marilyn A. Walker |  |
| 2220 |  |  [Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM](https://doi.org/10.18653/v1/2024.findings-emnlp.827) |  | 0 | The Transformer’s quadratic complexity with input length imposes an unsustainable computational load on large language models (LLMs). In contrast, the Selective Scan Structured State-Space Model, or Mamba, addresses this computational challenge effectively. This paper explores a query-based... | SooHwan Eom, Jay Shim, Gwanhyeong Koo, Haebin Na, Mark HasegawaJohnson, Sungwoong Kim, Chang Dong Yoo |  |
| 2221 |  |  [LLM as a metric critic for low resource relation identification](https://doi.org/10.18653/v1/2024.findings-emnlp.828) |  | 0 | In extremely low resource relation identification scenario, small language models (SLMs) incline to overfit, which significantly diminishes their accuracy. Recently, large language models (LLMs) are gradually applied to classification tasks with converting original objective into the generation... | Zhe Yang, Yi Huang, Yaqin Chen, Xiaoting Wu, Junlan Feng, Chao Deng |  |
| 2222 |  |  [Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues](https://doi.org/10.18653/v1/2024.findings-emnlp.829) |  | 0 | Target-driven recommendation dialogues present unique challenges in dialogue management due to the necessity of anticipating user interactions for successful conversations. Current methods face significant limitations: (I) inadequate capabilities for conversation anticipation, (II) computational... | Huy Dao, Yang Deng, KhanhHuyen Bui, Dung D. Le, Lizi Liao |  |
| 2223 |  |  [Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers](https://doi.org/10.18653/v1/2024.findings-emnlp.830) |  | 0 | The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the factual accuracy of their outputs. In this work, we present Factcheck-Bench, a holistic end-to-end framework for annotating and evaluating the factuality of LLM-generated... | Yuxia Wang, Revanth Gangi Reddy, Zain Muhammad Mujahid, Arnav Arora, Aleksandr Rubashevskii, Jiahui Geng, Osama Mohammed Afzal, Liangming Pan, Nadav Borenstein, Aditya Pillai, Isabelle Augenstein, Iryna Gurevych, Preslav Nakov |  |
| 2224 |  |  [Open-RAG: Enhanced Retrieval Augmented Reasoning with Open-Source Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.831) |  | 0 | Retrieval Augmented Generation (RAG) has been shown to enhance the factual accuracy of Large Language Models (LLMs) by providing external evidence, but existing methods often suffer from limited reasoning capabilities (e.g., multi-hop complexities) in effectively using such evidence, particularly... | Shayekh Bin Islam, Md. Asib Rahman, K. S. M. Tozammel Hossain, Enamul Hoque, Shafiq Joty, Md. Rizwan Parvez |  |
| 2225 |  |  [Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory](https://doi.org/10.18653/v1/2024.findings-emnlp.832) |  | 0 | Recently, the demand for psychological counseling has significantly increased as more individuals express concerns about their mental health. This surge has accelerated efforts to improve the accessibility of counseling by using large language models (LLMs) as counselors. To ensure client privacy,... | Suyeon Lee, Sunghwan Kim, Minju Kim, Dongjin Kang, Dongil Yang, Harim Kim, Minseok Kang, Dayi Jung, Min Hee Kim, Seungbeen Lee, KyoungMee Chung, Youngjae Yu, Dongha Lee, Jinyoung Yeo |  |
| 2226 |  |  [TextLap: Customizing Language Models for Text-to-Layout Planning](https://doi.org/10.18653/v1/2024.findings-emnlp.833) |  | 0 | Automatic generation of graphical layouts is crucial for many real-world applications, including designing posters, flyers, advertisements, and graphical user interfaces. Given the incredible ability of Large language models (LLMs) in both natural language understanding and generation, we believe... | Jian Chen, Ruiyi Zhang, Yufan Zhou, Jennifer Healey, Jiuxiang Gu, Zhiqiang Xu, Changyou Chen |  |
| 2227 |  |  [Data-driven Coreference-based Ontology Building](https://doi.org/10.18653/v1/2024.findings-emnlp.834) |  | 0 | While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus. We derive... | Shir AshuryTahan, Amir David Nissan Cohen, Nadav Cohen, Yoram Louzoun, Yoav Goldberg |  |
| 2228 |  |  [Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision](https://doi.org/10.18653/v1/2024.findings-emnlp.835) |  | 0 | Long-form question answering (LFQA) aims at generating in-depth answers to end-user questions, providing relevant information beyond the direct answer. However, existing retrievers are typically optimized towards information that directly targets the question, missing out on such contextual... | Philipp Christmann, Svitlana Vakulenko, Ionut Sorodoc, Bill Byrne, Adrià de Gispert |  |
| 2229 |  |  [Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking](https://doi.org/10.18653/v1/2024.findings-emnlp.836) |  | 0 | Generating free-text rationales is among the emergent capabilities of Large Language Models (LLMs). These rationales have been found to enhance LLM performance across various NLP tasks. Recently, there has been growing interest in using these rationales to provide insights for various important... | Mohamed Elaraby, Diane J. Litman, Xiang Li, Ahmed Magooda |  |
| 2230 |  |  [Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP](https://doi.org/10.18653/v1/2024.findings-emnlp.837) |  | 0 | A text encoder within Vision-Language Models (VLMs) like CLIP plays a crucial role in translating textual input into an embedding space shared with images, thereby facilitating the interpretative analysis of vision tasks through natural language. Despite the varying significance of different... | Eunji Kim, Kyuhong Shim, Simyung Chang, Sungroh Yoon |  |
| 2231 |  |  [DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.838) |  | 0 | Knowledge-intensive language understanding tasks require Language Models (LMs) to integrate relevant context, mitigating their inherent weaknesses, such as incomplete or outdated knowledge. However, conflicting knowledge can be present in the LM’s parameters, termed intra-memory conflict, which can... | Sara Marjanovic, Haeun Yu, Pepa Atanasova, Maria Maistro, Christina Lioma, Isabelle Augenstein |  |
| 2232 |  |  [LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification](https://doi.org/10.18653/v1/2024.findings-emnlp.839) |  | 0 | The lack of high-quality training data remains a significant challenge in NLP. Manual annotation methods, such as crowdsourcing, are costly, require intricate task design skills, and, if used incorrectly, may result in poor data quality. From the other hand, LLMs have demonstrated proficiency in... | Daniil Moskovskiy, Sergey Pletenev, Alexander Panchenko |  |
| 2233 |  |  [Efficient Active Learning with Adapters](https://doi.org/10.18653/v1/2024.findings-emnlp.840) |  | 0 | One of the main obstacles for deploying Active Learning (AL) in practical NLP tasks is high computational cost of modern deep learning models. This issue can be partially mitigated by applying lightweight models as an acquisition model, but it can lead to the acquisition-successor mismatch (ASM)... | Daria Galimzianova, Leonid Sanochkin |  |
| 2234 |  |  [How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.841) |  | 0 | To combat the misuse of Large Language Models (LLMs), many recent studies have presented LLM-generated-text detectors with promising performance. When users instruct LLMs to generate texts, the instruction can include different constraints depending on the user’s need. However, most recent studies... | Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki |  |
| 2235 |  |  ["Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?](https://doi.org/10.18653/v1/2024.findings-emnlp.842) |  | 0 | Human label variation (HLV) is a valuable source of information that arises when multiple human annotators provide different labels for valid reasons. In Natural Language Inference (NLI) earlier approaches to capturing HLV involve either collecting annotations from many crowd workers to represent... | Beiduo Chen, Xinpeng Wang, Siyao Peng, Robert Litschko, Anna Korhonen, Barbara Plank |  |
| 2236 |  |  [Language Models in Dialogue: Conversational Maxims for Human-AI Interactions](https://doi.org/10.18653/v1/2024.findings-emnlp.843) |  | 0 | Modern language models, while sophisticated, exhibit some inherent shortcomings, particularly in conversational settings. We claim that many of the observed shortcomings can be attributed to violation of one or more conversational principles. By drawing upon extensive research from both the social... | Erik Miehling, Manish Nagireddy, Prasanna Sattigeri, Elizabeth Daly, David Piorkowski, John T. Richards |  |
| 2237 |  |  [LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments](https://doi.org/10.18653/v1/2024.findings-emnlp.844) |  | 0 | The important challenge of keeping knowledge in Large Language Models (LLMs) up-to-date has led to the development of various methods for incorporating new facts. However, existing methods for such knowledge editing still face difficulties with multi-hop questions that require accurate fact... | Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai |  |
| 2238 |  |  [Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness](https://doi.org/10.18653/v1/2024.findings-emnlp.845) |  | 0 | Recently, there has been significant interest in replacing the reward model in Reinforcement Learning with Human Feedback (RLHF) methods for Large Language Models (LLMs), such as Direct Preference Optimization (DPO) and its variants. These approaches commonly use a binary cross-entropy mechanism on... | Jian Li, Haojing Huang, Yujia Zhang, Pengfei Xu, Xi Chen, Rui Song, Lida Shi, Jingwen Wang, Hao Xu |  |
| 2239 |  |  [Mitigating Hallucination in Fictional Character Role-Play](https://doi.org/10.18653/v1/2024.findings-emnlp.846) |  | 0 | Role-playing has wide-ranging applications in customer support, embodied agents, and computational social science. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and to hallucinate about things outside the... | Nafis Sadeq, Zhouhang Xie, Byungkyu Kang, Prarit Lamba, Xiang Gao, Julian J. McAuley |  |
| 2240 |  |  [I'm sure you're a real scholar yourself: Exploring Ironic Content Generation by Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.847) |  | 0 | Generating ironic content is challenging: it requires a nuanced understanding of context and implicit references and balancing seriousness and playfulness. Moreover, irony is highly subjective and can depend on various factors, such as social, cultural, or generational aspects. This paper explores... | Pier Felice Balestrucci, Silvia Casola, Soda Marem Lo, Valerio Basile, Alessandro Mazzei |  |
| 2241 |  |  [Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.848) |  | 0 | Time-Sensitive Question Answering (TSQA) demands the effective utilization of specific temporal contexts, encompassing multiple time-evolving facts, to address time-sensitive questions. This necessitates not only the parsing of temporal information within questions but also the identification and... | Wanqi Yang, Yanda Li, Meng Fang, Ling Chen |  |
| 2242 |  |  [Minimal Yet Big Impact: How AI Agent Back-channeling Enhances Conversational Engagement through Conversation Persistence and Context Richness](https://doi.org/10.18653/v1/2024.findings-emnlp.849) |  | 0 | The increasing use of AI agents in conversational services, such as counseling, highlights the importance of back-channeling (BC) as an active listening strategy to enhance conversational engagement. BC improves conversational engagement by providing timely acknowledgments and encouraging the... | Jin Yea Jang, Saim Shin, Gahgene Gweon |  |
| 2243 |  |  [Large Language Models for Propaganda Span Annotation](https://doi.org/10.18653/v1/2024.findings-emnlp.850) |  | 0 | The use of propagandistic techniques in online content has increased in recent years aiming to manipulate online audiences. Fine-grained propaganda detection and extraction of textual spans where propaganda techniques are used, are essential for more informed content consumption. Automatic systems... | Maram Hasanain, Fatema Ahmad, Firoj Alam |  |
| 2244 |  |  [Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles](https://doi.org/10.18653/v1/2024.findings-emnlp.851) |  | 0 | Prompt compression condenses contexts while maintaining their informativeness for different usage scenarios. It not only shortens the inference time and reduces computational costs during the usage of large language models, but also lowers expenses when using closed-source models. In a preliminary... | Xiao Pu, Tianxing He, Xiaojun Wan |  |
| 2245 |  |  [POSIX: A Prompt Sensitivity Index For Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.852) |  | 0 | Despite their remarkable capabilities, Large Language Models (LLMs) are found to be surprisingly sensitive to minor variations in prompts, often generating significantly divergent outputs in response to minor variations in the prompts, such as spelling errors, alteration of wording or the prompt... | Anwoy Chatterjee, H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty |  |
| 2246 |  |  [Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data](https://doi.org/10.18653/v1/2024.findings-emnlp.853) |  | 0 | Role-playing agents (RPA) have been a popular application area for large language models (LLMs), attracting significant interest from both industry and academia. While existing RPAs well portray the characters’ knowledge and tones, they face challenges in capturing their minds, especially for small... | Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang |  |
| 2247 |  |  [Local and Global Decoding in Text Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.854) |  | 0 | Text generation, a component in applications such as dialogue systems, relies heavily on decoding algorithms that sample strings from a language model distribution. Traditional methods like top-k and top-𝜋 decoding locally normalise the model’s output, which can significantly distort the original... | Daniel Gareev, Thomas Hofmann, Ezhilmathi Krishnasamy, Tiago Pimentel |  |
| 2248 |  |  [LEGOBench: Scientific Leaderboard Generation Benchmark](https://doi.org/10.18653/v1/2024.findings-emnlp.855) |  | 0 | The ever-increasing volume of paper submissions makes it difficult to stay informed about the latest state-of-the-art research. To address this challenge, we introduce LEGOBench, a benchmark for evaluating systems that generate scientific leaderboards. LEGOBench is curated from 22 years of preprint... | Shruti Singh, Shoaib Alam, Husain Malwat, Mayank Singh |  |
| 2249 |  |  [H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.856) |  | 0 | Legal question answering (LQA) aims to bridge the gap between the limited availability of legal professionals and the high demand for legal assistance. Traditional LQA approaches typically either select the optimal answers from an answer set or extract answers from law texts. However, they often... | Yue Jiang, Ziyu Guan, Jie Zhao, Wei Zhao, Jiaqi Yang |  |
| 2250 |  |  [Identifying Factual Inconsistencies in Summaries: Grounding LLM Inference via Task Taxonomy](https://doi.org/10.18653/v1/2024.findings-emnlp.857) |  | 0 | Factual inconsistencies pose a significant hurdle for the faithful summarization by generative models. While a major direction to enhance inconsistency detection is to derive stronger Natural Language Inference (NLI) models, we propose an orthogonal aspect that underscores the importance of... | Liyan Xu, Zhenlin Su, Mo Yu, Jin Xu, Jinho D. Choi, Jie Zhou, Fei Liu |  |
| 2251 |  |  [Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.858) |  | 0 | As the demand for processing extended textual data grows, the ability to handle long-range dependencies and maintain computational efficiency is more critical than ever. One of the key issues for long-sequence modeling using attention-based model is the mismatch between the limited-range modeling... | Aosong Feng, Rex Ying, Leandros Tassiulas |  |
| 2252 |  |  [BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla](https://doi.org/10.18653/v1/2024.findings-emnlp.859) |  | 0 | Low-resource languages like Bangla are severely limited by the lack of datasets. Romanized Bangla texts are ubiquitous on the internet, offering a rich source of data for Bangla NLP tasks and extending the available data sources. However, due to the informal nature of romanized text, they often... | Md Fahim, Fariha Tanjim Shifat, Fabiha Haider, Deeparghya Dutta Barua, Md Sakib Ul Rahman Sourove, Md Farhan Ishmam, Md Bhuiyan |  |
| 2253 |  |  [Finding the Optimal Byte-Pair Encoding Merge Operations for Neural Machine Translation in a Low-Resource Setting](https://doi.org/10.18653/v1/2024.findings-emnlp.860) |  | 0 | This paper investigates the impact of different Byte Pair Encoding (BPE) configurations, specifically, merge operations on neural machine translation (NMT) performance for the Filipino-Cebuano language pair across various text domains. Results demonstrate that smaller BPE configurations, notably... | Kristine Mae M. Adlaon, Nelson Marcos |  |
| 2254 |  |  [Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs](https://doi.org/10.18653/v1/2024.findings-emnlp.861) |  | 0 | Empathy plays a pivotal role in fostering prosocial behavior, often triggered by the sharing of personal experiences through narratives. However, modeling empathy using NLP approaches remains challenging due to its deep interconnection with human interaction dynamics. Previous approaches, which... | Muhammad Arslan Manzoor, Yuxia Wang, Minghan Wang, Preslav Nakov |  |
| 2255 |  |  [EU DisinfoTest: a Benchmark for Evaluating Language Models' Ability to Detect Disinformation Narratives](https://doi.org/10.18653/v1/2024.findings-emnlp.862) |  | 0 | As narratives shape public opinion and influence societal actions, distinguishing between truthful and misleading narratives has become a significant challenge. To address this, we introduce the EU DisinfoTest, a novel benchmark designed to evaluate the efficacy of Language Models in identifying... | Witold Sosnowski, Arkadiusz Modzelewski, Kinga Skorupska, Jahna Otterbacher, Adam Wierzbicki |  |
| 2256 |  |  [Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.863) |  | 0 |  | Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly |  |
| 2257 |  |  [From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression](https://doi.org/10.18653/v1/2024.findings-emnlp.864) |  | 0 | Large language models (LLMs) have achieved significant performance gains using advanced prompting techniques over various tasks. However, the increasing length of prompts leads to high computational costs and often obscures crucial information. Prompt compression has been proposed to alleviate... | Eunseong Choi, Sunkyung Lee, Minjin Choi, June Park, Jongwuk Lee |  |
| 2258 |  |  [Knowledge-Guided Dynamic Modality Attention Fusion Framework for Multimodal Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.865) |  | 0 | Multimodal Sentiment Analysis (MSA) utilizes multimodal data to infer the users’ sentiment. Previous methods focus on equally treating the contribution of each modality or statically using text as the dominant modality to conduct interaction, which neglects the situation where each modality may... | Xinyu Feng, Yuming Lin, Lihua He, You Li, Liang Chang, Ya Zhou |  |
| 2259 |  |  [LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.866) |  | 0 | The fine-tuning of open-source large language models (LLMs) for machine translation has recently received considerable attention, marking a shift towards data-centric research from traditional neural machine translation. However, the area of data collection for instruction fine-tuning in machine... | Yongjing Yin, Jiali Zeng, Yafu Li, Fandong Meng, Yue Zhang |  |
| 2260 |  |  [SARCAT: Generative Span-Act Guided Response Generation using Copy-enhanced Target Augmentation](https://doi.org/10.18653/v1/2024.findings-emnlp.867) |  | 0 | In this paper, we present a novel extension to improve the document grounded response generation, by proposing the Generative Span Act Guided Response Generation using Copy enhanced Target Augmentation (SARCAT) that consists of two major components as follows: 1) Copy-enhanced target-side input... | JeongDoo Lee, Hyeongjun Choi, Beomseok Hong, Youngsub Han, ByoungKi Jeon, SeungHoon Na |  |
| 2261 |  |  [Does Context Help Mitigate Gender Bias in Neural Machine Translation?](https://doi.org/10.18653/v1/2024.findings-emnlp.868) |  | 0 | Neural Machine Translation models tend to perpetuate gender bias present in their training data distribution. Context-aware models have been previously suggested as a means to mitigate this type of bias. In this work, we examine this claim by analysing in detail the translation of stereotypical... | Harritxu Gete, Thierry Etchegoyhen |  |
| 2262 |  |  [A Critical Look at Meta-evaluating Summarisation Evaluation Metrics](https://doi.org/10.18653/v1/2024.findings-emnlp.869) |  | 0 | Effective summarisation evaluation metrics enable researchers and practitioners to compare different summarisation systems efficiently. Estimating the effectiveness of an automatic evaluation metric, termed meta-evaluation, is a critically important research question. In this position paper, we... | Xiang Dai, Sarvnaz Karimi, Biaoyan Fang |  |
| 2263 |  |  [LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study](https://doi.org/10.18653/v1/2024.findings-emnlp.870) |  | 0 | As NLP models become more complex, understanding their decisions becomes more crucial. Counterfactuals (CFs), where minimal changes to inputs flip a model’s prediction, offer a way to explain these models. While Large Language Models (LLMs) have shown remarkable performance in NLP tasks, their... | Van Bach Nguyen, Paul Youssef, Christin Seifert, Jörg Schlötterer |  |
| 2264 |  |  [Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.871) |  | 0 | Prompt optimization emerges as an important technique for adapting Large Language Models (LLMs) to specific tasks. Unfortunately, LLM proprietors often limit access to models’ internal weights, confining users to inference API services. This restriction poses a significant challenge for prompt... | Heshen Zhan, Congliang Chen, Tian Ding, Ziniu Li, Ruoyu Sun |  |
| 2265 |  |  [Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses](https://doi.org/10.18653/v1/2024.findings-emnlp.872) |  | 0 | Large language models (LLMs) equipped with chain-of-thoughts (CoT) prompting have shown significant multi-step reasoning capabilities in factual content like mathematics, commonsense, and logic. However, their performance in narrative reasoning, which demands greater abstraction capabilities,... | HungTing Su, YaChing Hsu, Xudong Lin, Xiang Qian Shi, Yulei Niu, HanYuan Hsu, Hungyi Lee, Winston H. Hsu |  |
| 2266 |  |  [Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.873) |  | 0 | Synthetic data has been proposed as a solution to address the issue of high-quality data scarcity in the training of large language models (LLMs). Studies have shown that synthetic data can effectively improve the performance of LLMs on downstream benchmarks. However, despite its potential... | Jie Chen, Yupeng Zhang, Bingning Wang, Xin Zhao, JiRong Wen, Weipeng Chen |  |
| 2267 |  |  [CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text](https://doi.org/10.18653/v1/2024.findings-emnlp.874) |  | 0 | Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety and robustness of models deployed in real-world scenarios. While most studies on OOD detection focus on fine-tuned models trained on in-distribution (ID) data, detecting OOD in pre-trained models is also important due to... | Hakyung Lee, KeonHee Park, Hoyoon Byun, Jeyoon Yeom, Jihee Kim, GyeongMoon Park, Kyungwoo Song |  |
| 2268 |  |  [CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.875) |  | 0 | Ambiguity is an inherent feature of language, whose management is crucial for effective communication and collaboration. This is particularly true for Chinese, a language with extensive lexical-morphemic ambiguity. Despite the wide use of large language models (LLMs) in numerous domains and their... | Qin Zhang, Sihan Cai, Jiaxu Zhao, Mykola Pechenizkiy, Meng Fang |  |
| 2269 |  |  [Analyzing Context Contributions in LLM-based Machine Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.876) |  | 0 | Large language models (LLMs) have achieved state-of-the-art performance in machine translation (MT) and demonstrated the ability to leverage in-context learning through few-shot examples. However, the mechanisms by which LLMs use different parts of the input context remain largely unexplored. In... | Emmanouil Zaranis, Nuno Miguel Guerreiro, André F. T. Martins |  |
| 2270 |  |  [ARTS: Assessing Readability & Text Simplicity](https://doi.org/10.18653/v1/2024.findings-emnlp.877) |  | 0 | Automatic text simplification aims to reduce a text’s complexity. Its evaluation should quantify how easy it is to understand a text. Datasets with simplicity labels on text level are a prerequisite for developing such evaluation approaches. However, current publicly available datasets do not align... | Björn Engelmann, Christin Kreutz, Fabian Haak, Philipp Schaer |  |
| 2271 |  |  [AXCEL: Automated eXplainable Consistency Evaluation using LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.878) |  | 0 | Large Language Models (LLMs) are widely used in both industry and academia for various tasks, yet evaluating the consistency of generated text responses continues to be a challenge. Traditional metrics like ROUGE and BLEU show a weak correlation with human judgment. More sophisticated metrics using... | P. Aditya Sreekar, Sahil Verma, Suransh Chopra, Abhishek Persad, Sarik Ghazarian, Narayanan Sadagopan |  |
| 2272 |  |  [Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking](https://doi.org/10.18653/v1/2024.findings-emnlp.879) |  | 0 | Large language models (LLMs) have shown the ability to solve complex decision-making tasks beyond natural language processing tasks. LLM agents based on few-shot in-context learning (ICL) achieve surprisingly high performance without training. Despite their simplicity and generalizability,... | Byoungjip Kim, Youngsoo Jang, Lajanugen Logeswaran, GeonHyeong Kim, Yu Jin Kim, Honglak Lee, Moontae Lee |  |
| 2273 |  |  [Characterizing Text Datasets with Psycholinguistic Features](https://doi.org/10.18653/v1/2024.findings-emnlp.880) |  | 0 | Fine-tuning pretrained language models on task-specific data is a common practice in Natural Language Processing (NLP) applications. However, the number of pretrained models available to choose from can be very large, and it remains unclear how to select the optimal model without spending... | Marcio Monteiro, Charu Karakkaparambil James, Marius Kloft, Sophie Fellenz |  |
| 2274 |  |  [Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.881) |  | 0 | Verbs form the backbone of language, providing the structure and meaning to sentences. Yet, their intricate semantic nuances pose a longstanding challenge. Understanding verb relations through the concept of lexical entailment is crucial for comprehending sentence meanings and grasping verb... | Candida Maria Greco, Lucio La Cava, Andrea Tagarelli |  |
| 2275 |  |  [Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.882) |  | 0 | Large language models (LLMs) have been shown to perform better when asked to reason step-by-step before answering a question. However, it is unclear to what degree the model’s final answer is faithful to the stated reasoning steps. In this paper, we perform a causal mediation analysis on twelve... | Debjit Paul, Robert West, Antoine Bosselut, Boi Faltings |  |
| 2276 |  |  [Self-training Large Language Models through Knowledge Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.883) |  | 0 | Large language models (LLMs) often necessitate extensive labeled datasets and training compute to achieve impressive performance across downstream tasks. This paper explores a self-training paradigm, where the LLM autonomously curates its own labels and selectively trains on unknown data samples... | Wei Jie Yeo, Teddy Ferdinan, Przemyslaw Kazienko, Ranjan Satapathy, Erik Cambria |  |
| 2277 |  |  [VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.884) |  | 0 | We propose VE-KD, a novel method that balances knowledge distillation and vocabulary expansion with the aim of training efficient domain-specific language models. Compared with traditional pre-training approaches, VE-KD exhibits competitive performance in downstream tasks while reducing model size... | Pengju Gao, Tomohiro Yamasaki, Kazunori Imoto |  |
| 2278 |  |  [Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.885) |  | 0 | Despite the remarkable capabilities of large language models, generating high-quality text remains a challenging task. Numerous decoding strategies—such as beam search, sampling with temperature, top‐k sampling, nucleus (top‐p) sampling, typical decoding, contrastive decoding, and contrastive... | Esteban Garces Arias, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher |  |
| 2279 |  |  [SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.886) |  | 0 | Recently, very large language models (LLMs) have shown exceptional performance on several English NLP tasks with just in-context learning (ICL), but their utility in other languages is still underexplored. We investigate their effectiveness for NLP tasks in low-resource languages (LRLs), especially... | Vipul Kumar Rathore, Aniruddha Deb, Ankish Kumar Chandresh, Parag Singla, Mausam |  |
| 2280 |  |  [Re-examining Sexism and Misogyny Classification with Annotator Attitudes](https://doi.org/10.18653/v1/2024.findings-emnlp.887) |  | 0 | Gender-Based Violence (GBV) is an increasing problem online, but existing datasets fail to capture the plurality of possible annotator perspectives or ensure the representation of affected groups. We revisit two important stages in the moderation pipeline for GBV: (1) manual data labelling; and (2)... | Aiqi Jiang, Nikolas Vitsakis, Tanvi Dinkar, Gavin Abercrombie, Ioannis Konstas |  |
| 2281 |  |  [When "A Helpful Assistant" Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.888) |  | 0 | Prompting serves as the major way humans interact with Large Language Models (LLM). Commercial AI systems commonly define the role of the LLM in system prompts. For example, ChatGPT uses ”You are a helpful assistant” as part of its default system prompt. Despite current practices of adding personas... | Mingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran, Moontae Lee, David Jurgens |  |
| 2282 |  |  [Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks](https://doi.org/10.18653/v1/2024.findings-emnlp.889) |  | 0 | Recent advancements in large language models have demonstrated enhanced capabilities in visual reasoning tasks by employing additional encoders for aligning different modalities. While the Q-Former has been widely used as a general encoder for aligning several modalities including image, video,... | Sungkyung Kim, Adam Lee, Junyoung Park, Andrew Chung, Jusang Oh, JayYoon Lee |  |
| 2283 |  |  [Modeling Gender and Dialect Bias in Automatic Speech Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.890) |  | 0 | Dialect and gender-based biases have become an area of concern in language-dependent AI systemsincluding around automatic speech recognition (ASR) which processes speech audio into text. These potential biases raise concern for discriminatory outcomes with AI systems depending on demographic-... | Camille Harris, Chijioke Mgbahurike, Neha Kumar, Diyi Yang |  |
| 2284 |  |  [Are Large Language Models Consistent over Value-laden Questions?](https://doi.org/10.18653/v1/2024.findings-emnlp.891) |  | 0 | Large language models (LLMs) appear to bias their survey answers toward certain values. Nonetheless, some argue that LLMs are too inconsistent to simulate particular values. Are they? To answer, we first define value consistency as the similarity of answers across 1) paraphrases of one question, 2)... | Jared Moore, Tanvi Deshpande, Diyi Yang |  |
| 2285 |  |  [xTower: A Multilingual LLM for Explaining and Correcting Translation Errors](https://doi.org/10.18653/v1/2024.findings-emnlp.892) |  | 0 | While machine translation (MT) systems are achieving increasingly strong performance on benchmarks, they often produce translations with errors and anomalies. Understanding these errors can potentially help improve the translation quality and user experience. This paper introduces xTower, an open... | Marcos V. Treviso, Nuno Miguel Guerreiro, Sweta Agrawal, Ricardo Rei, José Pombal, Tânia Vaz, Helena Wu, Beatriz Silva, Daan van Stigt, André F. T. Martins |  |
| 2286 |  |  [LAMBDA: Large Language Model-Based Data Augmentation for Multi-Modal Machine Translation](https://doi.org/10.18653/v1/2024.findings-emnlp.893) |  | 0 | Multi-modal machine translation (MMT) can reduce ambiguity and semantic distortion compared with traditional machine translation (MT) by utilizing auxiliary information such as images. However, current MMT methods face two primary challenges. The first is their underperformance compared to MT... | Yusong Wang, Dongyuan Li, Jialun Shen, Yicheng Xu, Mingkun Xu, Kotaro Funakoshi, Manabu Okumura |  |
| 2287 |  |  [Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains](https://doi.org/10.18653/v1/2024.findings-emnlp.894) |  | 0 | The difficulty of anonymizing text data hinders the development and deployment of NLP in high-stakes domains that involve private data, such as healthcare and social services. Poorly anonymized sensitive data cannot be easily shared with annotators or external researchers, nor can it be used to... | Krithika Ramesh, Nupoor Gandhi, Pulkit Madaan, Lisa Bauer, Charith Peris, Anjalie Field |  |
| 2288 |  |  [Dual Process Masking for Dialogue Act Recognition](https://doi.org/10.18653/v1/2024.findings-emnlp.895) |  | 0 | Dialogue act recognition is the task of classifying conversational utterances based on their communicative intent or function. To address this problem, we propose a novel two-phase processing approach called Dual-Process Masking. This approach streamlines the task by masking less important tokens... | Yeo Jin Kim, Halim Acosta, Wookhee Min, Jonathan P. Rowe, Bradford W. Mott, Snigdha Chaturvedi, James C. Lester |  |
| 2289 |  |  [XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference](https://doi.org/10.18653/v1/2024.findings-emnlp.896) |  | 0 | Prompts are often employed to condition decoder-only language model generation on reference information. Just-in-time processing of a context is inefficient due to the quadratic cost of self-attention operations, and caching is desirable. However, caching transformer states can easily require... | João Monteiro, Étienne Marcotte, PierreAndré Noël, Valentina Zantedeschi, David Vázquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian |  |
| 2290 |  |  [Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion](https://doi.org/10.18653/v1/2024.findings-emnlp.897) |  | 0 | During pre-training, the Text-to-Image (T2I) diffusion models encode factual knowledge into their parameters. These parameterized facts enable realistic image generation, but they may become obsolete over time, thereby misrepresenting the current state of the world. Knowledge editing techniques aim... | Hengrui Gu, Kaixiong Zhou, Yili Wang, Ruobing Wang, Xin Wang |  |
| 2291 |  |  [DEFT: Distribution-guided Efficient Fine-Tuning for Human Alignment](https://doi.org/10.18653/v1/2024.findings-emnlp.898) |  | 0 |  | Liang Zhu, Feiteng Fang, Yuelin Bai, Longze Chen, Zhexiang Zhang, Minghuan Tan, Min Yang |  |
| 2292 |  |  [Eigen Attention: Attention in Low-Rank Space for KV Cache Compression](https://doi.org/10.18653/v1/2024.findings-emnlp.899) |  | 0 | Large language models (LLMs) represent a groundbreaking advancement in the domain of natural language processing due to their impressive reasoning abilities. Recently, there has been considerable interest in increasing the context lengths for these models to enhance their applicability to complex... | Utkarsh Saxena, Gobinda Saha, Sakshi Choudhary, Kaushik Roy |  |
| 2293 |  |  [ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.900) |  | 0 | Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method attributed to its remarkable performance with few updated parameters on various large-scale pretrained Language Models (PLMs). Traditionally, each prompt has been considered indivisible and updated independently, leading the... | YuChen Lin, WeiHua Li, JunCheng Chen, ChuSong Chen |  |
| 2294 |  |  [Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression](https://doi.org/10.18653/v1/2024.findings-emnlp.901) |  | 0 | Increasingly, model compression techniques enable large language models (LLMs) to be deployed in real-world applications. As a result of this momentum towards local deployment, compressed LLMs will interact with a large population. Prior work on compression typically prioritize preserving... | Zhichao Xu, Ashim Gupta, Tao Li, Oliver Bentham, Vivek Srikumar |  |
| 2295 |  |  [One-to-many testing for code generation from (just) natural language](https://doi.org/10.18653/v1/2024.findings-emnlp.902) |  | 0 | MBPP is a popular dataset for evaluating the task of code generation from natural language. Despite its popularity, there are three problems: (1) it relies on providing test cases to generate the right signature, (2) there is poor alignment between instruction and evaluation test cases, and (3)... | Mansi Uniyal, Mukul Singh, Gust Verbruggen, Sumit Gulwani, Vu Le |  |
| 2296 |  |  [A Unified Framework for Model Editing](https://doi.org/10.18653/v1/2024.findings-emnlp.903) |  | 0 | ROME and MEMIT are largely believed to be two different model editing algorithms, with the major difference between them being the ability to perform batched edits. In this paper, we unify these two algorithms under a single conceptual umbrella, optimizing for the same goal, which we call the... | Akshat Gupta, Dev Sajnani, Gopala Anumanchipalli |  |
| 2297 |  |  [M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models](https://doi.org/10.18653/v1/2024.findings-emnlp.904) |  | 0 | Existing evaluation benchmarks for foundation models in understanding scientific literature predominantly focus on single-document, text-only tasks. Such benchmarks often do not adequately represent the complexity of research workflows, which typically also involve interpreting non-textual data,... | Chuhan Li, Ziyao Shangguan, Yilun Zhao, Deyuan Li, Yixin Liu, Arman Cohan |  |
| 2298 |  |  [Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction](https://doi.org/10.18653/v1/2024.findings-emnlp.905) |  | 0 | Large language model (LLM) agents show promise in an increasing number of domains. In many proposed applications, it is expected that the agent reasons over accumulated experience presented in an input prompt. We propose the OEDD (Operationalize Experience Despite Distraction) corpus, a... | Sonny George, Chris Sypherd, Dylan Cashman |  |
| 2299 |  |  [Knowledge-Centric Templatic Views of Documents](https://doi.org/10.18653/v1/2024.findings-emnlp.906) |  | 0 | Authors seeking to communicate with broader audiences often share their ideas in various document formats, such as slide decks, newsletters, reports, and posters. Prior work on document generation has generally tackled the creation of each separate format to be a different task, leading to... | Isabel Cachola, Silviu Cucerzan, Allen Herring, Vuksan Mijovic, Erik Oveson, Sujay Kumar Jauhar |  |
| 2300 |  |  [Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.907) |  | 0 | We explore \*implicit opinion extraction\* as a new component of aspect-based sentiment analysis (ABSA) systems. Prior work in ABSA has investigated opinion extraction as an important subtask, however, these works only label concise, \*explicitly\*-stated opinion spans. In this work, we present... | Joseph Peper, Wenzhao Qiu, Ryan Bruggeman, Yi Han, Estefania Chehade, Lu Wang |  |
| 2301 |  |  [Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.908) |  | 0 | Large Language Models (LLMs) are increasingly used for generating code solutions, empowered by features like self-debugging and self-reflection. However, LLMs often struggle with complex programming problems without human guidance. This paper investigates the strategies employed by expert... | Subramanian Chidambaram, Li Erran Li, Min Bai, Xiaopeng Li, Kaixiang Lin, Xiong Zhou, Alex C. Williams |  |
| 2302 |  |  [Large Language Models Know What To Say But Not When To Speak](https://doi.org/10.18653/v1/2024.findings-emnlp.909) |  | 0 | Turn-taking is a fundamental mechanism in human communication that ensures smooth and coherent verbal interactions. Recent advances in Large Language Models (LLMs) have motivated their use in improving the turn-taking capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond... | Muhammad Umair, Vasanth Sarathy, Jan Peter de Ruiter |  |
| 2303 |  |  [Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method](https://doi.org/10.18653/v1/2024.findings-emnlp.910) |  | 0 | Grammatical Error Correction (GEC) is a crucial technique in Automated Essay Scoring (AES) for evaluating the fluency of essays. However, in Chinese, existing GEC datasets often fail to consider the importance of specific grammatical error types within compositional scenarios, lack research on data... | Xinshu Shen, Hongyi Wu, Yadong Zhang, Man Lan, Xiaopeng Bai, Shaoguang Mao, Yuanbin Wu, Xinlin Zhuang, Li Cai |  |
| 2304 |  |  [CoCoHD: Congress Committee Hearing Dataset](https://doi.org/10.18653/v1/2024.findings-emnlp.911) |  | 0 | U.S. congressional hearings significantly influence the national economy and social fabric, impacting individual lives. Despite their importance, there is a lack of comprehensive datasets for analyzing these discourses. To address this, we propose the \*\*Co\*\*ngress \*\*Co\*\*mmittee... | Arnav Hiray, Yunsong Liu, Mingxiao Song, Agam Shah, Sudheer Chava |  |
| 2305 |  |  [Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.912) |  | 0 | The pursuit of personalized education has led to the integration of Large Language Models (LLMs) in developing intelligent tutoring systems. To better understand and adapt to individual student needs, including their misconceptions, LLMs need to be trained on extensive datasets of student-tutor... | Shashank Sonkar, Naiming Liu, Richard G. Baraniuk |  |
| 2306 |  |  [MalAlgoQA: Pedagogical Evaluation of Counterfactual Reasoning in Large Language Models and Implications for AI in Education](https://doi.org/10.18653/v1/2024.findings-emnlp.913) |  | 0 | This paper introduces MalAlgoQA, a novel dataset designed to evaluate the counterfactual reasoning capabilities of Large Language Models (LLMs) through a pedagogical approach. The dataset comprises mathematics and reading comprehension questions, each accompanied by four answer choices and their... | Shashank Sonkar, Naiming Liu, Myco Le, Richard G. Baraniuk |  |
| 2307 |  |  [Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets](https://doi.org/10.18653/v1/2024.findings-emnlp.914) |  | 0 | Large language models (LLMs) can now generate and recognize poetry. But what do LLMs really know about poetry? We develop a task to evaluate how well LLMs recognize one aspect of English-language poetry—poetic form—which captures many different poetic features, including rhyme scheme, meter, and... | Melanie Walsh, Maria Antoniak, Anna Preus |  |
| 2308 |  |  [Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging](https://doi.org/10.18653/v1/2024.findings-emnlp.915) |  | 0 | Adapting general-purpose language models to new skills is currently an expensive process that must be repeated as new instruction datasets targeting new skills are created, or can cause the models to forget older skills. In this work, we investigate the effectiveness of adding new skills to... | Jacob Morrison, Noah A. Smith, Hannaneh Hajishirzi, Pang Wei Koh, Jesse Dodge, Pradeep Dasigi |  |
| 2309 |  |  [To Ask LLMs about English Grammaticality, Prompt Them in a Different Language](https://doi.org/10.18653/v1/2024.findings-emnlp.916) |  | 0 | In addition to asking questions about facts in the world, some internet users—in particular, second language learners—ask questions about language itself. Depending on their proficiency level and audience, they may pose these questions in an L1 (first language) or an L2 (second language). We... | Shabnam Behzad, Amir Zeldes, Nathan Schneider |  |
| 2310 |  |  [Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs](https://doi.org/10.18653/v1/2024.findings-emnlp.917) |  | 0 | Topic modeling is a powerful technique for uncovering hidden themes within a collection of documents. However, the effectiveness of traditional topic models often relies on sufficient word co-occurrence, which is lacking in short texts. Therefore, existing approaches, whether probabilistic or... | Pritom Saha Akash, Kevin ChenChuan Chang |  |
| 2311 |  |  [Targeted Multilingual Adaptation for Low-resource Language Families](https://doi.org/10.18653/v1/2024.findings-emnlp.918) |  | 0 | Massively multilingual models are known to have limited utility in any one language, and to perform particularly poorly on low-resource languages. By contrast, targeted multinguality has been shown to benefit low-resource languages. To test this approach more rigorously, we systematically study... | C. M. Downey, Terra Blevins, Dhwani Serai, Dwija Parikh, Shane SteinertThrelkeld |  |
| 2312 |  |  [A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents](https://doi.org/10.18653/v1/2024.findings-emnlp.919) |  | 0 | In task-oriented dialogue systems, intent detection is crucial for interpreting user queries and providing appropriate responses. Existing research primarily addresses simple queries with a single intent, lacking effective systems for handling complex queries with multiple intents and extracting... | Ankan Mullick, Sombit Bose, Abhilash Nandy, Gajula Chaitanya, Pawan Goyal |  |
| 2313 |  |  [Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.920) |  | 0 | Large Language Models (LLMs) exhibit impressive zero/few-shot inference and generation quality for high-resource languages (HRLs). A few of them have been trained on low-resource languages (LRLs) and give decent performance. Owing to the prohibitive costs of training LLMs, they are usually used as... | Arijit Nag, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti |  |
| 2314 |  |  [Advancing Vision-Language Models with Adapter Ensemble Strategies](https://doi.org/10.18653/v1/2024.findings-emnlp.921) |  | 0 | CLIP revolutes vision-language pretraining by using contrastive learning on paired web data. However, the sheer size of these pretrained models makes full-model finetuning exceedingly costly. One common solution is the “adapter”, which finetunes a few additional parameters while freezing the... | Yue Bai, Handong Zhao, Zhe Lin, Ajinkya Kale, Jiuxiang Gu, Tong Yu, Sungchul Kim, Yun Fu |  |
| 2315 |  |  [Who Wrote When? Author Diarization in Social Media Discussions](https://doi.org/10.18653/v1/2024.findings-emnlp.922) |  | 0 | We are proposing a novel framework for author diarization, i.e. attributing comments in online discussions to individual authors. We consider an innovative approach that merges pre-trained neural representations of writing style with author-conditional encoder-decoder diarization, enhanced by a... | Benedikt T. Boenninghoff, Henry Hosseini, Robert M. Nickel, Dorothea Kolossa |  |
| 2316 |  |  [Controlled Transformation of Text-Attributed Graphs](https://doi.org/10.18653/v1/2024.findings-emnlp.923) |  | 0 | Graph generation is the process of generating novel graphs with similar attributes to real world graphs. The explicit and precise control of granular structural attributes, such as node centrality and graph density, is crucial for effective graph generation. This paper introduces a controllable... | Nidhi Vakil, Hadi Amiri |  |
| 2317 |  |  [Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation](https://doi.org/10.18653/v1/2024.findings-emnlp.924) |  | 0 | Misinformation, defined as false or inaccurate information, can result in significant societal harm when it is spread with malicious or even unintentional intent. The rapid online information exchange necessitates advanced detection mechanisms to mitigate misinformation-induced harm. Existing... | Chu Fei Luo, Radin Shayanfar, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu |  |
| 2318 |  |  [CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models](https://doi.org/10.18653/v1/2024.findings-emnlp.925) |  | 0 | The limited availability of psychologists necessitates efficient identification of individuals requiring urgent mental healthcare. This study explores the use of Natural Language Processing (NLP) pipelines to analyze text data from online mental health forums used for consultations. By analyzing... | Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, T. K. Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi |  |
| 2319 |  |  [Explicit Inductive Inference using Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.926) |  | 0 | Large Language Models (LLMs) are reported to hold undesirable attestation bias on inference tasks: when asked to predict if a premise P entails a hypothesis H, instead of considering H‘s conditional truthfulness entailed by P, LLMs tend to use the out-of-context truth label of H as a fragile proxy.... | Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman |  |
| 2320 |  |  [Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA](https://doi.org/10.18653/v1/2024.findings-emnlp.927) |  | 0 | Retrieval-Augmented Generation (RAG) is widely used to inject external non-parametric knowledge into large language models (LLMs). Recent works suggest that Knowledge Graphs (KGs) contain valuable external knowledge for LLMs. Retrieving information from KGs differs from extracting it from document... | Wenyu Huang, Guancheng Zhou, Hongru Wang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan |  |
| 2321 |  |  [Evaluating Gender Bias of LLMs in Making Morality Judgements](https://doi.org/10.18653/v1/2024.findings-emnlp.928) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in a multitude of Natural Language Processing (NLP) tasks. However, these models are still not immune to limitations such as social biases, especially gender bias. This work investigates whether current closed and open-source LLMs... | Divij Bajaj, Yuanyuan Lei, Jonathan Tong, Ruihong Huang |  |
| 2322 |  |  [A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune](https://doi.org/10.18653/v1/2024.findings-emnlp.929) |  | 0 | The growing size of large language models (LLMs) requires parameter-efficient fine-tuning (PEFT) methods for their adaptation to new tasks. Existing methods, such as Low-Rank Adaptation (LoRA), typically involve model adaptation by training the PEFT parameters. One open problem required to be... | Taha Ceritli, Savas Özkan, Jeongwon Min, Eunchung Noh, Cho Min, Mete Ozay |  |
| 2323 |  |  [Explaining Mixtures of Sources in News Articles](https://doi.org/10.18653/v1/2024.findings-emnlp.930) |  | 0 | Human writers plan, _then_ write. For large language models (LLMs) to play a role in longer-form article generation, we must understand the planning steps humans make before writing. We explore one kind of planning, source-selection in news, as a case-study for evaluating plans in long-form... | Alexander Spangher, James Youn, Matt DeButts, Nanyun Peng, Emilio Ferrara, Jonathan May |  |
| 2324 |  |  [LLM generated responses to mitigate the impact of hate speech](https://doi.org/10.18653/v1/2024.findings-emnlp.931) |  | 0 | In this study, we explore the use of Large Language Models (LLMs) to counteract hate speech. We conducted the first real-life A/B test assessing the effectiveness of LLM-generated counter-speech. During the experiment, we posted 753 automatically generated responses aimed at reducing user... | Jakub Podolak, Szymon Lukasik, Pawel Balawender, Jan Ossowski, Jan Piotrowski, Katarzyna Bakowicz, Piotr Sankowski |  |
| 2325 |  |  [Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level Perspective](https://doi.org/10.18653/v1/2024.findings-emnlp.932) |  | 0 | NLP research on aligning lexical representation spaces to one another has so far focused on aligning language spaces in their entirety. However, cognitive science has long focused on a local perspective, investigating whether translation equivalents truly share the same meaning or the extent that... | Taelin Karidi, Eitan Grossman, Omri Abend |  |
| 2326 |  |  [SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.933) |  | 0 | Audio-Visual Question Answering (AVQA) is a challenging task that involves answering questions based on both auditory and visual information in videos. A significant challenge is interpreting complex multi-modal scenes, which include both visual objects and sound sources, and connecting them to the... | Tianyu Yang, Yiyang Nan, Lisen Dai, Zhenwen Liang, Yapeng Tian, Xiangliang Zhang |  |
| 2327 |  |  [Grounding Partially-Defined Events in Multimodal Data](https://doi.org/10.18653/v1/2024.findings-emnlp.934) |  | 0 | How are we able to learn about complex current events just from short snippets of video? While natural language enables straightforward ways to represent under-specified, partially observable events, visual data does not facilitate analogous methods and, consequently, introduces unique challenges... | Kate Sanders, Reno Kriz, David Etter, Hannah Recknor, Alexander Martin, Cameron Carpenter, Jingyang Lin, Benjamin Van Durme |  |
| 2328 |  |  [How Does Quantization Affect Multilingual LLMs?](https://doi.org/10.18653/v1/2024.findings-emnlp.935) |  | 0 | Quantization techniques are widely used to improve inference speed and deployment of large language models. While a wide body of work examines the impact of quantization on LLMs in English, none have evaluated across languages. We conduct a thorough analysis of quantized multilingual LLMs, focusing... | Kelly Marchisio, Saurabh Dash, Hongyu Chen, Dennis Aumiller, Ahmet Üstün, Sara Hooker, Sebastian Ruder |  |
| 2329 |  |  [Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution](https://doi.org/10.18653/v1/2024.findings-emnlp.936) |  | 0 | Automatically generating a presentation from the text of a long document is a challenging and useful problem. In contrast to a flat summary, a presentation needs to have a better and non-linear narrative, i.e., the content of a slide can come from different and non-contiguous parts of the given... | Himanshu Maheshwari, Sambaran Bandyopadhyay, Aparna Garimella, Anandhavelu Natarajan |  |
| 2330 |  |  [Domain Adaptation via Prompt Learning for Alzheimer's Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.937) |  | 0 | Spoken language presents a compelling medium for non-invasive Alzheimer’s disease (AD) screening, and prior work has examined the use of fine-tuned pretrained language models (PLMs) for this purpose. However, PLMs are often optimized on tasks that are inconsistent with AD classification. Spoken... | Shahla Farzana, Natalie Parde |  |
| 2331 |  |  [SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions](https://doi.org/10.18653/v1/2024.findings-emnlp.938) |  | 0 | Large Language Models (LLMs) have led to significant improvements in the Knowledge Base Question Answering (KBQA) task. However, datasets used in KBQA studies do not capture the true complexity of KBQA tasks. They either have simple questions, use synthetically generated logical forms, or are based... | Shicheng Liu, Sina J. Semnani, Harold Triedman, Jialiang Xu, Isaac Dan Zhao, Monica S. Lam |  |
| 2332 |  |  [Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.939) |  | 0 | The correct specification of reward models is a well-known challenge in reinforcement learning.Hand-crafted reward functions often lead to inefficient or suboptimal policies and may not be aligned with user values.Reinforcement learning from human feedback is a successful technique that can... | Muhan Lin, Shuyang Shi, Yue Guo, Behdad Chalaki, Vaishnav Tadiparthi, Ehsan MoradiPari, Simon Stepputtis, Joseph Campbell, Katia P. Sycara |  |
| 2333 |  |  [On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-emnlp.940) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) is an effective approach for aligning language models to human preferences. Central to RLHF is learning a reward function for scoring human preferences. Two main approaches for learning a reward model are 1) training an EXplicit Reward Model (EXRM)... | Yong Lin, Skyler Seto, Maartje ter Hoeve, Katherine Metcalf, BarryJohn Theobald, Xuan Wang, Yizhe Zhang, Chen Huang, Tong Zhang |  |
| 2334 |  |  [Gazelle: An Instruction Dataset for Arabic Writing Assistance](https://doi.org/10.18653/v1/2024.findings-emnlp.941) |  | 0 | Writing has long been considered a hallmark of human intelligence and remains a pinnacle task for artificial intelligence (AI) due to the intricate cognitive processes involved. Recently, rapid advancements in generative AI, particularly through the development of Large Language Models (LLMs), have... | Samar Mohamed Magdy, Fakhraddin Alwajih, Sang Yun Kwon, Reem AbdelSalam, Muhammad AbdulMageed |  |
| 2335 |  |  [Extrinsic Evaluation of Cultural Competence in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.942) |  | 0 | Productive interactions between diverse users and language technologies require outputs from the latter to be culturally relevant and sensitive. Prior works have evaluated models’ knowledge of cultural norms, values, and artefacts, without considering how this knowledge manifests in downstream... | Shaily Bhatt, Fernando Diaz |  |
| 2336 |  |  [BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation](https://doi.org/10.18653/v1/2024.findings-emnlp.943) |  | 0 | We present BLASER 2.0, an automatic metric of machine translation quality which supports both speech and text modalities. Compared to its predecessor BLASER (Chen et al., 2023), BLASER 2.0 is based on better underlying text and speech representations that cover 202 text languages and 57 speech ones... | David Dale, Marta R. Costajussà |  |
| 2337 |  |  [Multi-label Sequential Sentence Classification via Large Language Model](https://doi.org/10.18653/v1/2024.findings-emnlp.944) |  | 0 | Sequential sentence classification (SSC) in scientific publications is crucial for supporting downstream tasks such as fine-grained information retrieval and extractive summarization. However, current SSC methods are constrained by model size, sequence length, and single-label setting. To address... | Mengfei Lan, Lecheng Zheng, Shufan Ming, Halil Kilicoglu |  |
| 2338 |  |  [Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants](https://doi.org/10.18653/v1/2024.findings-emnlp.945) |  | 0 | Conversational systems must be robust to user interactions that naturally exhibit diverse conversational traits. Capturing and simulating these diverse traits coherently and efficiently presents a complex challenge. This paper introduces Multi-Trait Adaptive Decoding (mTAD), a method that generates... | Rafael Ferreira, David Semedo, João Magalhães |  |
| 2339 |  |  [VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation](https://doi.org/10.18653/v1/2024.findings-emnlp.946) |  | 0 | As large language models achieve impressive scores on traditional benchmarks, an increasing number of researchers are becoming concerned about benchmark data leakage during pre-training, commonly known as the data contamination problem. To ensure fair evaluation, recent benchmarks release only the... | Kun Qian, Shunji Wan, Claudia Tang, Youzhi Wang, Xuanming Zhang, Maximillian Chen, Zhou Yu |  |
| 2340 |  |  [Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing](https://doi.org/10.18653/v1/2024.findings-emnlp.947) |  | 0 | Sign language translation from video to spoken text presents unique challenges owing to the distinct grammar, expression nuances, and high variation of visual appearance across different speakers and contexts. Gloss annotations serve as an intermediary to guide the translation process. In our work,... | Pooya Fayyazsanavi, Antonios Anastasopoulos, Jana Kosecka |  |
| 2341 |  |  [Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations](https://doi.org/10.18653/v1/2024.findings-emnlp.948) |  | 0 | We introduce a structured chain-of-thought (SCoT) prompting approach to generating content-grounded multi-turn question-answer conversations with a pre-trained large language model (LLM). At the core of our proposal is a structured breakdown of the complex task into a number of states in a state... | Md. Arafat Sultan, Jatin Ganhotra, Ramón Fernandez Astudillo |  |
| 2342 |  |  [Gradient Localization Improves Lifelong Pretraining of Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.949) |  | 0 | Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this work, we examine two types of knowledge relating to... | Jared Fernandez, Yonatan Bisk, Emma Strubell |  |
| 2343 |  |  [PFA-ERC: Psuedo-Future Augmented Dynamic Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2024.findings-emnlp.950) |  | 0 | AI systems’ ability to interpret human emotions and adapt to variations is becoming more crucial as AI gets embedded into everyone’s daily lives. Emotion Recognition in Conversations (ERC) is based on this fundamental challenge. Current state-of-the-art technologies in ERC are limited due to the... | Tanmay Khule, Rishabh Agrawal, Apurva Narayan |  |
| 2344 |  |  [Textless Speech-to-Speech Translation With Limited Parallel Data](https://doi.org/10.18653/v1/2024.findings-emnlp.951) |  | 0 | Existing speech-to-speech translation (S2ST) models fall into two camps: they either leverage text as an intermediate step or require hundreds of hours of parallel speech data. Both approaches are incompatible with textless languages or language pairs with limited parallel data. We present PFB, a... | Anuj Diwan, Anirudh Srinivasan, David Harwath, Eunsol Choi |  |
| 2345 |  |  [The Overlooked Repetitive Lengthening Form in Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-emnlp.952) |  | 0 | Individuals engaging in online communication frequently express personal opinions with informal styles (e.g., memes and emojis). While Language Models (LMs) with informal communications have been widely discussed, a unique and emphatic style, the Repetitive Lengthening Form (RLF), has been... | Lei Wang, Eduard C. Dragut |  |
| 2346 |  |  [Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.953) |  | 0 | Large Language Models (LLMs) are increasingly ubiquitous, yet their ability to retain and reason about temporal information remains limited, hindering their application in real-world scenarios where understanding the sequential nature of events is crucial. Our study experiments with 12... | Himanshu Beniwal, Dishant Patel, Kowsik Nandagopan D, Hritik Ladia, Ankit Yadav, Mayank Singh |  |
| 2347 |  |  [Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.954) |  | 0 | Various types of learning rate (LR) schedulers are being used for training or fine tuning of Large Language Models today. In practice, several mid-flight changes are required in the LR schedule either manually, or with careful choices around warmup steps, peak LR, type of decay and restarts. To... | Shreyas Subramanian, Vignesh Ganapathiraman, Corey Barrett |  |
| 2348 |  |  [FactAlign: Long-form Factuality Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.955) |  | 0 | Large language models have demonstrated significant potential as the next-generation information access engines. However, their reliability is hindered by issues of hallucination and generating non-factual content. This is particularly problematic in long-form responses, where assessing and... | ChaoWei Huang, YunNung Chen |  |
| 2349 |  |  [HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.956) |  | 0 | Adapting pre-trained language models (PLMs) for cross-task generalization is a crucial research area within the field of NLP. While fine-tuning and in-context learning are effective approaches for adapting LMs to emerging tasks, they can be costly and inefficient. Recently, some researchers have... | Chuancheng Lv, Lei Li, Shitou Zhang, Gang Chen, Fanchao Qi, Ningyu Zhang, HaiTao Zheng |  |
| 2350 |  |  [Inference and Verbalization Functions During In-Context Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.957) |  | 0 | Large language models (LMs) are capable of in-context learning from a few demonstrations (example-label pairs) to solve new tasks during inference. Despite the intuitive importance of high-quality demonstrations, previous work has observed that, in some settings, ICL performance is minimally... | Junyi Tao, Xiaoyin Chen, Nelson F. Liu |  |
| 2351 |  |  [Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction](https://doi.org/10.18653/v1/2024.findings-emnlp.958) |  | 0 | We propose a multi-agent debate as optimization (DAO) system for event extraction, where the primary objective is to iteratively refine the large language models (LLMs) outputs through debating without parameter tuning. In DAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the... | Sijia Wang, Lifu Huang |  |
| 2352 |  |  [MiRAGeNews: Multimodal Realistic AI-Generated News Detection](https://doi.org/10.18653/v1/2024.findings-emnlp.959) |  | 0 | The proliferation of inflammatory or misleading “fake” news content has become increasingly common in recent years. Simultaneously, it has become easier than ever to use AI tools to generate photorealistic images depicting any scene imaginable. Combining these two—AI-generated fake news content—is... | Runsheng Huang, Liam Dugan, Yue Yang, Chris CallisonBurch |  |
| 2353 |  |  [Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective](https://doi.org/10.18653/v1/2024.findings-emnlp.960) |  | 0 | Recent advancements in Large Language Models (LLMs) have facilitated the development of Multimodal LLMs (MLLMs). Despite their impressive capabilities, MLLMs often suffer from over-reliance on unimodal biases (e.g., language bias and vision bias), leading to incorrect answers in complex multimodal... | Meiqi Chen, Yixin Cao, Yan Zhang, Chaochao Lu |  |
| 2354 |  |  [Large Language Models are In-context Teachers for Knowledge Reasoning](https://doi.org/10.18653/v1/2024.findings-emnlp.961) |  | 0 | In this work, we study in-context teaching(ICT), where a teacher provides in-context example rationales to teach a student to reasonover unseen cases. Human teachers are usually required to craft in-context demonstrations, which are costly and have high variance. We ask whether a large language... | Jiachen Zhao, Zonghai Yao, Zhichao Yang, Hong Yu |  |
| 2355 |  |  [SocialGaze: Improving the Integration of Human Social Norms in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.962) |  | 0 | While much research has explored enhancing the reasoning capabilities of large language models (LLMs) in the last few years, there is a gap in understanding the alignment of these models with social values and norms. We introduce the task of judging social acceptance. Social acceptance requires... | Anvesh Rao Vijjini, Rakesh R. Menon, Jiayi Fu, Shashank Srivastava, Snigdha Chaturvedi |  |
| 2356 |  |  [Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives](https://doi.org/10.18653/v1/2024.findings-emnlp.963) |  | 0 | Reasoning about time and temporal relations is an integral aspect of human cognition, essential for perceiving the world and navigating our experiences. Though large language models (LLMs) have demonstrated impressive performance in many reasoning tasks, temporal reasoning remains challenging due... | Xinliang Frederick Zhang, Nicholas Beauchamp, Lu Wang |  |
| 2357 |  |  [Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.964) |  | 0 | In this paper, we introduce Auto-Intent, a method to adapt a pre-trained large language model (LLM) as an agent for a target domain without direct fine-tuning, where we empirically focus on web navigation tasks. Our approach first discovers the underlying intents from target domain demonstrations... | Jaekyeom Kim, DongKi Kim, Lajanugen Logeswaran, Sungryull Sohn, Honglak Lee |  |
| 2358 |  |  [See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning](https://doi.org/10.18653/v1/2024.findings-emnlp.965) |  | 0 | Brain CT report generation is significant to aid physicians in diagnosing cranial diseases.Recent studies concentrate on handling the consistency between visual and textual pathological features to improve the coherence of report.However, there exist some challenges: 1) Redundant visual... | Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu |  |
| 2359 |  |  [P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains](https://doi.org/10.18653/v1/2024.findings-emnlp.966) |  | 0 | Existing methods on understanding the capabilities of LLMs in logical reasoning rely on binary entailment classification or synthetically derived rationales, which are not sufficient for properly assessing model’s capabilities. We present P-FOLIO, a human-annotated dataset consisting of diverse and... | Simeng Han, Aaron Yu, Rui Shen, Zhenting Qi, Martin Riddell, Wenfei Zhou, Yujie Qiao, Yilun Zhao, Semih Yavuz, Ye Liu, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Dragomir Radev, Rex Ying, Arman Cohan |  |
| 2360 |  |  [TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism](https://doi.org/10.18653/v1/2024.findings-emnlp.967) |  | 0 | A sophisticated negotiation dialogue system for tourism should engage in negotiations beyond mere price considerations, encompassing various other aspects and amenities inherent in the tourism package. To ensure such tailored interaction, it is imperative to understand the intricacies of traveler... | Priyanshu Priya, Desai Yasheshbhai, Ratnesh Kumar Joshi, Roshni R. Ramnani, Anutosh Maitra, Shubhashis Sengupta, Asif Ekbal |  |
| 2361 |  |  [Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.968) |  | 0 | Conditional question answering (CQA) is an important task that aims to find probable answers and identify missing conditions. Existing approaches struggle with CQA due to two challenges: (1) precisely identifying necessary conditions and the logical relationship, and (2) verifying conditions to... | Jiuheng Lin, Yuxuan Lai, Yansong Feng |  |
| 2362 |  |  [Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization](https://doi.org/10.18653/v1/2024.findings-emnlp.969) |  | 0 | The concept of \*persona\*, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (\*e.g.\*, personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively... | YuMin Tseng, YuChao Huang, TengYun Hsiao, WeiLin Chen, ChaoWei Huang, Yu Meng, YunNung Chen |  |
| 2363 |  |  [ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information](https://doi.org/10.18653/v1/2024.findings-emnlp.970) |  | 0 | In different NLP tasks, detecting harmful content is crucial for online environments, especially with the growing influence of social media. However, previous research has two main issues: 1) a lack of data in low-resource settings, and 2) inconsistent definitions and criteria for judging harmful... | Zheng Hui, Zhaoxiao Guo, Hang Zhao, Juanyong Duan, Congrui Huang |  |
| 2364 |  |  [Look Who's Talking Now: Covert Channels From Biased LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.971) |  | 0 | Large language model-based steganography encodes hidden messages into model-generated tokens. The key tradeoff is between how much hidden information can be introduced and how much the model can be perturbed. To address this tradeoff, we show how to adapt strategies previously used for LLM... | Daniel Silva, Frederic Sala, Ryan Gabrys |  |
| 2365 |  |  [ValueScope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions](https://doi.org/10.18653/v1/2024.findings-emnlp.972) |  | 0 | This study introduces ValueScope, a framework leveraging language models to quantify social norms and values within online communities, grounded in social science perspectives on normative structures. We employ ValueScope to dissect and analyze linguistic and stylistic expressions across 13 Reddit... | Chan Young Park, Shuyue Stella Li, Hayoung Jung, Svitlana Volkova, Tanushree Mitra, David Jurgens, Yulia Tsvetkov |  |
| 2366 |  |  [Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness](https://doi.org/10.18653/v1/2024.findings-emnlp.973) |  | 0 | Chart question answering (CQA) is a crucial area of Visual Language Understanding. However, the robustness and consistency of current Visual Language Models (VLMs) in this field remain under-explored. This paper evaluates state-of-the-art VLMs on comprehensive datasets, developed specifically for... | Srija Mukhopadhyay, Adnan Qidwai, Aparna Garimella, Pritika Ramu, Vivek Gupta, Dan Roth |  |
| 2367 |  |  [Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification](https://doi.org/10.18653/v1/2024.findings-emnlp.974) |  | 0 | Citation intention Classification (CIC) tools classify citations by their intention (e.g., background, motivation) and assist readers in evaluating the contribution of scientific literature. Prior research has shown that pretrained language models (PLMs) such as SciBERT can achieve state-of-the-art... | Zeren Shui, Petros Karypis, Daniel S. Karls, Mingjian Wen, Saurav Manchanda, Ellad B. Tadmor, George Karypis |  |
| 2368 |  |  [TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling](https://doi.org/10.18653/v1/2024.findings-emnlp.975) |  | 0 | Recent large vision-language multimodal models pre-trained with huge amount of image-text pairs show remarkable performances in downstream tasks. However, the multimodal pre-training has limitations in terms of resources and training time when it comes to obtaining new models that surpass existing... | Dongha Choi, JungJae Kim, Hyunju Lee |  |
| 2369 |  |  [Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper](https://doi.org/10.18653/v1/2024.findings-emnlp.976) |  | 0 | The training of automatic speech recognition (ASR) with little to no supervised data remains an open question. In this work, we demonstrate that streaming Transformer-Transducer (TT) models can be trained from scratch in consumer and accessible GPUs in their entirety with pseudo-labeled (PL) speech... | Iuliia Thorbecke, Juan Pablo ZuluagaGomez, Esaú VillatoroTello, Shashi Kumar, Pradeep Rangappa, Sergio Burdisso, Petr Motlícek, Karthik S, Aravind Ganapathiraju |  |
| 2370 |  |  [Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths](https://doi.org/10.18653/v1/2024.findings-emnlp.977) |  | 0 | Advanced models such as OpenAI o1 exhibit impressive problem-solving capabilities through step-by-step reasoning. However, they may still falter on more complex problems, making errors that disrupt their reasoning paths. We attribute this to the expansive solution space, where each step has the... | Yew Ken Chia, Guizhen Chen, Weiwen Xu, Anh Tuan Luu, Soujanya Poria, Lidong Bing |  |
| 2371 |  |  [Uncertainty Calibration for Tool-Using Language Agents](https://doi.org/10.18653/v1/2024.findings-emnlp.978) |  | 0 | There is increasing interest in equipping language models with the ability to leverage external tools for complex, goal-oriented tasks. However, interacting with external tools introduces inherent uncertainties due to imperfections and misalignments between the tools’ outputs and the agents’... | Hao Liu, ZiYi Dou, Yixin Wang, Nanyun Peng, Yisong Yue |  |
| 2372 |  |  [Personalized Video Comment Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.979) |  | 0 | Generating personalized responses, particularly in the context of video, poses a unique challenge for language models. This paper introduces the novel task of Personalized Video Comment Generation (PVCG), aiming to predict user comments tailored to both the input video and the user’s comment... | Xudong Lin, Ali Zare, Shiyuan Huang, MingHsuan Yang, ShihFu Chang, Li Zhang |  |
| 2373 |  |  [Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?](https://doi.org/10.18653/v1/2024.findings-emnlp.980) |  | 0 | Large Language Models have demonstrates remarkable performance in solving math problems, a hallmark of human intelligence.Despite high success rates on current benchmarks, however, these often feature simple problems with only one or two unknowns, which do not sufficiently challenge their reasoning... | KueiChun Kao, Ruochen Wang, ChoJui Hsieh |  |
| 2374 |  |  [MedLogic-AQA: Enhancing Medicare Question Answering with Abstractive Models Focusing on Logical Structures](https://doi.org/10.18653/v1/2024.findings-emnlp.981) |  | 0 | In Medicare question-answering (QA) tasks, the need for effective systems is pivotal in delivering accurate responses to intricate medical queries. However, existing approaches often struggle to grasp the intricate logical structures and relationships inherent in medical contexts, thus limiting... | Aizan Zafar, Kshitij Mishra, Asif Ekbal |  |
| 2375 |  |  [EmbodiedBERT: Cognitively Informed Metaphor Detection Incorporating Sensorimotor Information](https://doi.org/10.18653/v1/2024.findings-emnlp.982) |  | 0 | The identification of metaphor is a crucial prerequisite for many downstream language tasks, such as sentiment analysis, opinion mining, and textual entailment. State-of-the-art systems of metaphor detection implement heuristic principles such as Metaphor Identification Procedure (MIP) and... | Yu Li, Bo Peng, YuYin Hsu, ChuRen Huang |  |
| 2376 |  |  [PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness](https://doi.org/10.18653/v1/2024.findings-emnlp.983) |  | 0 | Large Language Models (LLMs) demonstrate impressive capabilities across various domains, including role-playing, creative writing, mathematical reasoning, and coding. Despite these advancements, LLMs still encounter challenges with length control, frequently failing to adhere to specific length... | Noah Wang, Feiyu Duan, Yibo Zhang, Wangchunshu Zhou, Ke Xu, Wenhao Huang, Jie Fu |  |
| 2377 |  |  [SedarEval: Automated Evaluation using Self-Adaptive Rubrics](https://doi.org/10.18653/v1/2024.findings-emnlp.984) |  | 0 | The evaluation paradigm of LLM-as-judge gains popularity due to its significant reduction in human labor and time costs. This approach utilizes one or more large language models (LLMs) to assess the quality of outputs from other LLMs. However, existing methods rely on generic scoring rubrics that... | Zhiyuan Fan, Weinong Wang, Xing Wu, Debing Zhang |  |
| 2378 |  |  [Towards One-to-Many Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.985) |  | 0 | Most existing Visual Question Answering (VQA) systems are constrained to support domain-specific questions, i.e., to train different models separately for different VQA tasks, thus generalizing poorly to others. For example, models trained on the reasoning-focused dataset GQA struggle to... | Huishan Ji, Qingyi Si, Zheng Lin, Yanan Cao, Weiping Wang |  |
| 2379 |  |  [Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering](https://doi.org/10.18653/v1/2024.findings-emnlp.986) |  | 0 | As an essential task in information extraction (IE), Event-Event Causal Relation Extraction (ECRE) aims to identify and classify the causal relationships between event mentions in natural language texts. However, existing research on ECRE has highlighted two critical challenges, including the lack... | Zimu Wang, Lei Xia, Wei Xjtlu, Xinya Du |  |
| 2380 |  |  [Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding](https://doi.org/10.18653/v1/2024.findings-emnlp.987) |  | 0 | The primary aim of Knowledge Graph Embeddings (KGE) is to learn low-dimensional representations of entities and relations for predicting missing facts. While rotation-based methods like RotatE and QuatE perform well in KGE, they face two challenges: limited model flexibility requiring proportional... | Yihua Zhu, Hidetoshi Shimodaira |  |
| 2381 |  |  [When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.988) |  | 0 | Large language models (LLMs) exhibit excellent performance in various tasks. However, the memory requirements of LLMs present a great challenge when deploying on memory-limited devices, even for quantized LLMs. This paper introduces a framework to compress LLM after quantization further, achieving... | Weilan Wang, Yu Mao, Dongdong Tang, Hongchao Du, Nan Guan, Chun Jason Xue |  |
| 2382 |  |  [BiMediX: Bilingual Medical Mixture of Experts LLM](https://doi.org/10.18653/v1/2024.findings-emnlp.989) |  | 0 | In this paper, we introduce BiMediX, the first bilingual medical mixture of experts LLM designed for seamless interaction in both English and Arabic. Our model facilitates a wide range of medical interactions in English and Arabic, including multi-turn chats to inquire about additional details such... | Sara Pieri, Sahal Shaji Mullappilly, Fahad Shahbaz Khan, Rao Muhammad Anwer, Salman H. Khan, Timothy Baldwin, Hisham Cholakkal |  |
| 2383 |  |  [Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design](https://doi.org/10.18653/v1/2024.findings-emnlp.990) |  | 0 | Vision-Language Models (VLMs) have seen a significant increase in both research interest and real-world applications across various domains, including healthcare, autonomous systems, and security. However, their growing prevalence demands higher reliability and safety including robustness to... | Rishika Bhagwatkar, Shravan Nayak, Pouya Bashivan, Irina Rish |  |
| 2384 |  |  [Zero-Shot Fact Verification via Natural Logic and Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.991) |  | 0 | The recent development of fact verification systems with natural logic has enhanced their explainability by aligning claims with evidence through set-theoretic operators, providing faithful justifications. Despite these advancements, such systems often rely on a large amount of training data... | Marek Strong, Rami Aly, Andreas Vlachos |  |
| 2385 |  |  [Robust AI-Generated Text Detection by Restricted Embeddings](https://doi.org/10.18653/v1/2024.findings-emnlp.992) |  | 0 | Growing amount and quality of AI-generated texts makes detecting such content more difficult. In most real-world scenarios, the domain (style and topic) of generated data and the generator model are not known in advance. In this work, we focus on the robustness of classifier-based detectors of... | Kristian Kuznetsov, Eduard Tulchinskii, Laida Kushnareva, German Magai, Serguei Barannikov, Sergey I. Nikolenko, Irina Piontkovskaya |  |
| 2386 |  |  [CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack](https://doi.org/10.18653/v1/2024.findings-emnlp.993) |  | 0 | Language models are vulnerable to clandestinely modified data and manipulation by attackers. Despite considerable research dedicated to enhancing robustness against adversarial attacks, the realm of provable robustness for backdoor attacks remains relatively unexplored. In this paper, we initiate a... | Siqi Sun, Procheta Sen, Wenjie Ruan |  |
| 2387 |  |  [MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.994) |  | 0 | Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are highly effective parameter-efficient fine-tuning (PEFT) methods. However, they introduce significant latency in multi-tenant settings due to the LoRA modules and MOE routers added to multiple linear modules in the Transformer... | Jingfan Zhang, Yi Zhao, Dan Chen, Xing Tian, Huanran Zheng, Wei Zhu |  |
| 2388 |  |  [LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.995) |  | 0 | Uncovering latent values and opinions embedded in large language models (LLMs) can help identify biases and mitigate potential harm. Recently, this has been approached by prompting LLMs with survey questions and quantifying the stances in the outputs towards morally and politically charged... | Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge J. Belongie, Isabelle Augenstein |  |
| 2389 |  |  [PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs](https://doi.org/10.18653/v1/2024.findings-emnlp.996) |  | 0 | Driven by the surge in code generation using large language models (LLMs), numerous benchmarks have emerged to evaluate these LLMs capabilities. We conducted a large-scale human evaluation of \*HumanEval\* and \*MBPP\*, two popular benchmarks for Python code generation, analyzing their diversity... | Ankit Yadav, Himanshu Beniwal, Mayank Singh |  |
| 2390 |  |  [Efficient and Interpretable Grammatical Error Correction with Mixture of Experts](https://doi.org/10.18653/v1/2024.findings-emnlp.997) |  | 0 | Error type information has been widely used to improve the performance of grammatical error correction (GEC) models, whether for generating corrections, re-ranking them, or combining GEC models. Combining GEC models that have complementary strengths in correcting different error types is very... | Muhammad Reza Qorib, Alham Aji, Hwee Tou Ng |  |
| 2391 |  |  [Dial BeInfo for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-emnlp.998) |  | 0 | Factual faithfulness is a crucial requirement in information-seeking dialogue: the system should respond to the user queries so that the responses are meaningful and aligned with the knowledge provided to the system. However, most modern large language models (LLMs) suffer from hallucinations, that... | Evgeniia Razumovskaia, Ivan Vulic, Pavle Markovic, Tomasz Cichy, Qian Zheng, TsungHsien Wen, Pawel Budzianowski |  |
| 2392 |  |  [Unified Active Retrieval for Retrieval Augmented Generation](https://doi.org/10.18653/v1/2024.findings-emnlp.999) |  | 0 | In Retrieval-Augmented Generation (RAG), retrieval is not always helpful and applying it to every instruction is sub-optimal. Therefore, determining whether to retrieve is crucial for RAG, which is usually referred to as Active Retrieval. However, existing active retrieval methods face two... | Qinyuan Cheng, Xiaonan Li, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, Xipeng Qiu |  |
| 2393 |  |  [Mitigating Catastrophic Forgetting in Language Transfer via Model Merging](https://doi.org/10.18653/v1/2024.findings-emnlp.1000) |  | 0 | As open-weight large language models (LLMs) achieve ever more impressive performance across a wide range of tasks in English, practitioners aim to adapt these models to different languages. However, such language adaptation is often accompanied by catastrophic forgetting of the base model’s... | Anton Alexandrov, Veselin Raychev, Mark Mueller, Ce Zhang, Martin T. Vechev, Kristina Toutanova |  |
| 2394 |  |  [ATQ: Activation Transformation forWeight-Activation Quantization of Large Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.1001) |  | 0 | There are many emerging quantization methods to resolve the problem that the huge demand on computational and storage costs hinders the deployment of Large language models (LLMs). However, their accuracy performance still can not satisfy the entire academic and industry community. In this work, we... | Yundong Gai, Ping Li |  |
| 2395 |  |  [Stochastic Fine-Tuning of Language Models Using Masked Gradients](https://doi.org/10.18653/v1/2024.findings-emnlp.1002) |  | 0 | Large Language Models (LLMs) have emerged as the dominant paradigm in Natural Language Processing owing to their remarkable performance across various target tasks. However, naively fine-tuning them for specific downstream tasks often requires updating a vast number of parameters, resulting in high... | Mohammad AkbarTajari, Mohammad Taher Pilehvar |  |
| 2396 |  |  [To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity](https://doi.org/10.18653/v1/2024.findings-emnlp.1003) |  | 0 | One of the major aspects contributing to the striking performance of large language models (LLMs) is the vast amount of factual knowledge accumulated during pre-training. Yet, many LLMs suffer from self-inconsistency, which raises doubts about their trustworthiness and reliability. This paper... | Anastasiia Sedova, Robert Litschko, Diego Frassinelli, Benjamin Roth, Barbara Plank |  |

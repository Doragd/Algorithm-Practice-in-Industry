# WSDM2025

## 会议论文列表

本会议共有 147 篇论文

| 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- |
|  |  [Exploration and Exploitation of Hard Negative Samples for Cross-Domain Sequential Recommendation](https://doi.org/10.1145/3701551.3703535) |  | 0 | Negative sampling plays a crucial role for cross-domain recommendation as it provides contrastive signals to learn user preference. Existing methods usually select items with high predicted scores or popularity as hard negative samples to improve model training. However, such methods suffer from choosing false negative samples since items with high predicted scores or popularity could also indicate potential positive user preference. Although several studies devoted to discovering true negative samples, few of them leverage user cross-domain behaviors to alleviate the false negative issue. How to effectively mine and utilize hard negative samples to improve cross-domain recommendation remains an open question. In this work, we propose exploration and exploitation of hard negative samples (EXHANS) for cross-domain sequential recommendation. For better exploration, we utilize the user preference from the source domain to guide negative sampling in the target domain. The key idea is that compared with hard negative samples, false negative samples have higher probability to be consistent with the user preference in both domains. Besides, we propose adaptive popularity-based score correction to account for users' different tastes of popular items. The idea is that for users who favor popular items, such items are more likely to be false negatives rather than hard negatives. For better exploitation, we design a replay buffer to cache the obtained negative samples and further propose a curriculum learning framework to balance exploration and exploitation of hard negative samples. Extensive experiments on three real-world datasets show that our method significantly outperforms state-of-the-art negative sampling methods for cross-domain sequential recommendation, which verify the effectiveness of EXHANS. | Yidan Wang, Xuri Ge, Xin Chen, Ruobing Xie, Su Yan, Xu Zhang, Zhumin Chen, Jun Ma, Xin Xin | Shandong University, Qingdao, China; Tencent, Beijing, China; Shandong University, Jinan, China; WeChat, Tencent, Beijing, China |
|  |  [Personalization At Doordash: From Conversion Modeling To Multi-objective Long-term Value Optimization](https://doi.org/10.1145/3701551.3706132) |  | 0 | Doordash is one of the largest platform in the world to connect millions of local business with customers. We use advanced machine learning technologies to build a personalized customer experience and help customers discover a variant of local businesses they love. In this talk, we will introduce a few technologies we used to build our personalized homepage experience and the lessons learned during the process. Customers use our platform in different ways, they can browse on homepage, search on search bar or respond to a push notification or an email sent to them. There are also different types of actions they can take during their shopping journeys, included but not limited to views, (good) clicks, add-to-cart, and checkout. We will first introduce how we leverage customers various action sequence and transformer to build our user interest model to understand customer interests. Doordash homepage has a very vivid design containing different components and complex layout to serve our customers. The stores are organized with themes into an UI component that we call carousel. The stores, carousels and other UI components are mixed on our homepage to showcase a diverse set of options and deals customers can choose from. The complex homepage design poses challenges for homepage ranking. We build a heterogeneous ranking system to rank different type of components in a 2-D layout. Traditionally, our ranking model is optimized for conversion. However, as our business grows, we have multiple business objectives to care about. In the meanwhile, we also want to optimize for customers long term satisfaction so we can sustain and grow our platform. We will describe how do we model customers long term value and build a multi-objective ranking and optimization system to optimize and balance multiple business objectives. | Qilin Qi | Doordash Inc., San Francisco, CA, USA |
|  |  [Towards Personalized Federated Multi-Scenario Multi-Task Recommendation](https://doi.org/10.1145/3701551.3703523) |  | 0 | In modern recommender systems, especially in e-commerce, predicting multiple targets such as click-through rate (CTR) and post-view conversion rate (CTCVR) is common. Multi-task recommender systems are increasingly popular in both research and practice, as they leverage shared knowledge across diverse business scenarios to enhance performance. However, emerging real-world scenarios and data privacy concerns complicate the development of a unified multi-task recommendation model. In this paper, we propose PF-MSMTrec, a novel framework for personalized federated multi-scenario multi-task recommendation. In this framework, each scenario is assigned to a dedicated client utilizing the Multi-gate Mixture-of-Experts (MMoE) structure. To address the unique challenges of multiple optimization conflicts, we introduce a bottom-up joint learning mechanism. First, we design a parameter template to decouple the expert network parameters, distinguishing scenario-specific parameters as shared knowledge for federated parameter aggregation. Second, we implement personalized federated learning for each expert network during a federated communication round, using three modules: federated batch normalization, conflict coordination, and personalized aggregation. Finally, we conduct an additional round of personalized federated parameter aggregation on the task tower network to obtain prediction results for multiple tasks. Extensive experiments on two public datasets demonstrate that our proposed method outperforms state-of-the-art approaches. The source code and datasets will be released as open-source for public access. | Yue Ding, Yanbiao Ji, Xun Cai, Xin Xin, Yuxiang Lu, Suizhi Huang, Chang Liu, Xiaofeng Gao, Tsuyoshi Murata, Hongtao Lu |  |
|  |  [Sigmoid Similarity in Semantic HCP Networks: An Approach for Context Aware Search and Recommendations](https://doi.org/10.1145/3701551.3708809) |  | 0 | Large datasets in silos are available to be harnessed for potential benefits in terms of insights for better recommendations, search and clustering. Healthcare datasets include health care professionals' (HCP) data about their affiliations, publications, participation in conferences, events, clinical trials, specialty and much more. Such datasets in silos are integrated based on the different dimensions such as specialty, participation in various healthcare related events and clinical trials. Integration of healthcare related datasets provide various benefits like better search results, better recommendations of healthcare professionals based on their specialty and needs of patients and better insights to determine key opinion leaders in various therapy areas. In this work, we apply the Sigmoid similarity algorithm to find similar health care professionals based on the HCP Ontology we have developed. Sigmoid similarity is a feature based semantic similarity measure which outperforms the other hierarchy based approaches for computing semantic similarity. This semantic similarity measure enables us to compare and evaluate the semantic similarity amongst various health care professionals to accurately retrieve and recommend healthcare professionals based on the context of search. | Pallavi Karanth | TIB Leibniz Information Centre for Science and Technology, Hannover, Germany |
|  |  [S-Diff: An Anisotropic Diffusion Model for Collaborative Filtering in Spectral Domain](https://doi.org/10.1145/3701551.3703490) |  | 0 | Recovering user preferences from user-item interaction matrices is a key challenge in recommender systems. While diffusion models can sample and reconstruct preferences from latent distributions, they often fail to capture similar users' collective preferences effectively. Additionally, latent variables degrade into pure Gaussian noise during the forward process, lowering the signal-to-noise ratio, which in turn degrades performance. To address this, we propose S-Diff, inspired by graph-based collaborative filtering, better to utilize low-frequency components in the graph spectral domain. S-Diff maps user interaction vectors into the spectral domain and parameterizes diffusion noise to align with graph frequency. This anisotropic diffusion retains significant low-frequency components, preserving a high signal-to-noise ratio. S-Diff further employs a conditional denoising network to encode user interactions, recovering true preferences from noisy data. This method achieves strong results across multiple datasets. | Rui Xia, Yanhua Cheng, Yongxiang Tang, Xiaocheng Liu, Xialong Liu, Lisong Wang, Peng Jiang |  |
|  |  [Temporal Linear Item-Item Model for Sequential Recommendation](https://doi.org/10.1145/3701551.3703554) |  | 0 | In sequential recommendation (SR), neural models have been actively explored due to their remarkable performance, but they suffer from inefficiency inherent to their complexity. On the other hand, linear SR models exhibit high efficiency and achieve competitive or superior accuracy compared to neural models. However, they solely deal with the sequential order of items (i.e., sequential information) and overlook the actual timestamp (i.e., temporal information). It is limited to effectively capturing various user preference drifts over time. To address this issue, we propose a novel linear SR model, named TemporAl LinEar item-item model (TALE), incorporating temporal information while preserving training/inference efficiency, with three key components. (i) Single-target augmentation concentrates on a single target item, enabling us to learn the temporal correlation for the target item. (ii) Time interval-aware weighting utilizes the actual timestamp to discern the item correlation depending on time intervals. (iii) Trend-aware normalization reflects the dynamic shift of item popularity over time. Our empirical studies show that TALE outperforms ten competing SR models by up to 18.71 five benchmark datasets. It also exhibits remarkable effectiveness in evaluating long-tail items by up to 30.45 at https://github.com/psm1206/TALE. | Seongmin Park, Mincheol Yoon, Minjin Choi, Jongwuk Lee |  |
|  |  [Oracle-guided Dynamic User Preference Modeling for Sequential Recommendation](https://doi.org/10.1145/3701551.3703542) |  | 0 | Sequential recommendation methods can capture dynamic user preferences from user historical interactions to achieve better performance. However, most existing methods only use past information extracted from user historical interactions to train the models, leading to the deviations of user preference modeling. Besides past information, future information is also available during training, which contains the “oracle” user preferences in the future and will be beneficial to model dynamic user preferences. Therefore, we propose an oracle-guided dynamic user preference modeling method for sequential recommendation (Oracle4Rec), which leverages future information to guide model training on past information, aiming to learn “forward-looking” models. Specifically, Oracle4Rec first extracts past and future information through two separate encoders, then learns a forward-looking model through an oracle-guiding module which minimizes the discrepancy between past and future information. We also tailor a two-phase model training strategy to make the guiding more effective. Extensive experiments demonstrate that Oracle4Rec is superior to state-of-the-art sequential methods. Further experiments show that Oracle4Rec can be leveraged as a generic module in other sequential recommendation methods to improve their performance with a considerable margin. | Jiafeng Xia, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Li Shang, Ning Gu |  |
|  |  [SCONE: A Novel Stochastic Sampling to Generate Contrastive Views and Hard Negative Samples for Recommendation](https://doi.org/10.1145/3701551.3703522) |  | 0 | Graph-based collaborative filtering (CF) has emerged as a promising approach in recommender systems. Despite its achievements, graph-based CF models face challenges due to data sparsity and negative sampling. In this paper, we propose a novel Stochastic sampling for i) COntrastive views and ii) hard NEgative samples (SCONE) to overcome these issues. SCONE generates dynamic augmented views and diverse hard negative samples via a unified stochastic sampling approach based on score-based generative models. Our extensive experiments on 6 benchmark datasets show that SCONE consistently outperforms state-of-the-art baselines. SCONE shows efficacy in addressing user sparsity and item popularity issues, while enhancing performance for both cold-start users and long-tail items. Furthermore, our approach improves the diversity of the recommendation and the uniformity of the representations. The code is available at https://github.com/jeongwhanchoi/SCONE. | Chaejeong Lee, Jeongwhan Choi, Hyowon Wi, SungBae Cho, Noseong Park |  |
|  |  [How Do Recommendation Models Amplify Popularity Bias? An Analysis from the Spectral Perspective](https://doi.org/10.1145/3701551.3703579) |  | 0 | Recommendation Systems (RS) are often plagued by popularity bias. When training a recommendation model on a typically long-tailed dataset, the model tends to not only inherit this bias but often exacerbate it, resulting in over-representation of popular items in the recommendation lists. This study conducts comprehensive empirical and theoretical analyses to expose the root causes of this phenomenon, yielding two core insights: 1) Item popularity is memorized in the principal spectrum of the score matrix predicted by the recommendation model; 2) The dimension collapse phenomenon amplifies the relative prominence of the principal spectrum, thereby intensifying the popularity bias. Building on these insights, we propose a novel debiasing strategy that leverages a spectral norm regularizer to penalize the magnitude of the principal singular value. We have developed an efficient algorithm to expedite the calculation of the spectral norm by exploiting the spectral property of the score matrix. Extensive experiments across seven real-world datasets and three testing paradigms have been conducted to validate the superiority of the proposed method. | Siyi Lin, Chongming Gao, Jiawei Chen, Sheng Zhou, Binbin Hu, Yan Feng, Chun Chen, Can Wang |  |
|  |  [Sequentially Diversified and Accurate Recommendations in Chronological Order for a Series of Users](https://doi.org/10.1145/3701551.3703564) |  | 0 | When we sequentially recommend top-k items to users, how can we recommend them diversely while maintaining accuracy? Aggregate-level diversity is an important topic in recommender system since it is essential to maximize the potential profit of platforms by exposing a variety of items to users. However, previous studies do not consider the order of users receiving recommendations and assume that all users receive recommendations at once. In reality, users do not simultaneously receive recommendations so the preferences of the latter users are not given during recommending to the former users. In this work, we introduce the problem of sequentially diversified recommendation and propose SAPID, an accurate method to address the problem. SAPID removes the popularity bias from the model through a negative sampling mechanism based on temporal popularities. Then, SAPID collects candidate items to recommend based on the distribution of preference scores. Finally, SAPID decides which items to recommend immediately or later according to their estimated exposure opportunities. Extensive experiments show that SAPID shows the state-of-the-art performance in real-world datasets by achieving up to 61.0% increased diversity with 38.9% higher accuracy compared to the second-best competitor. | Jongjin Kim, U Kang | Seoul National University, Seoul, Republic of Korea |
|  |  [Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential Recommendation](https://doi.org/10.1145/3701551.3703552) |  | 0 | Sequential recommendation (SR) systems excel at capturing users' dynamic preferences by leveraging their interaction histories. Most existing SR systems assign a single embedding vector to each item to represent its features, and various types of models are adopted to combine these item embeddings into a sequence representation vector to capture the user intent. However, we argue that this representation alone is insufficient to capture an item's multi-faceted nature (e.g., movie genres, starring actors). Besides, users often exhibit complex and varied preferences within these facets (e.g., liking both action and musical films in the facet of genre), which are challenging to fully represent. To address the issues above, we propose a novel structure called Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential Recommendation (FAME). We leverage sub-embeddings from each head in the last multi-head attention layer to predict the next item separately. This approach captures the potential multi-faceted nature of items without increasing model complexity. A gating mechanism integrates recommendations from each head and dynamically determines their importance. Furthermore, we introduce a Mixture-of-Experts (MoE) network in each attention head to disentangle various user preferences within each facet. Each expert within the MoE focuses on a specific preference. A learnable router network is adopted to compute the importance weight for each expert and aggregate them. We conduct extensive experiments on four public sequential recommendation datasets and the results demonstrate the effectiveness of our method over existing baseline models. | Mingrui Liu, Sixiao Zhang, Cheng Long |  |
|  |  [DDualSE: Decoupled Dual-head Squeeze and Excitation Attention for Sequential Recommendation](https://doi.org/10.1145/3701551.3703509) |  | 0 | Sequential recommendation is one of the key tasks in recommendation systems. Current approaches employed context-aware models with enhanced expressive capabilities, typically incorporating input with temporal and spatial information --- specifically, historical interaction items and their attributes. However, these models often represented the input as a 1D or 2D matrix, performing coarse-grained fusion of item attributes. This approach did not explicitly model the relationships between spatial and temporal information, consequently impeding the model's ability to acquire intricate local details. In this study, we propose the Decoupled Dual -headed Squeeze and Excitation attention module (DDualSE), which constructs a fine-grained 3D input by separately modeling temporal and spatial information. Additionally, DDualSE decouples embedding dimensions and the number of attention heads from both the sequence length and the number of attributes simultaneously, solving the low-rank bottleneck issue without introducing extra parameters or specifying additional hyper-parameters. We integrate DDualSE into BERT and conduct extensive experiments on three benchmark datasets to validate the effectiveness of the proposed model. | Nijia Mo, Jianxiang Zang, Zhan Wang, Hui Liu |  |
|  |  [RSM: Reinforced Subgraph Matching Framework with Fine-grained Operation based Search Plan](https://doi.org/10.1145/3701551.3703516) |  | 0 | Subgraph matching is one of the fundamental problems in graph analytics. Existing methods generate matching orders to guide their search, which consists of a series of extensions. Each time, they extend smaller partial matches into larger ones until all complete answers are obtained. However, these methods have two significant drawbacks. Firstly, their matching order generations are usually heuristic and challenging to be effective for different queries. Secondly, each extension, serving as its computation unit, is coarse-grained and may hinder performance. This granularity issue stems from merging generation and expansion operations into a single computation unit. To address these challenges, we introduce a pioneering framework for Reinforced Subgraph Matching (RSM) that features a fine-grained operation-based search plan. Initially, RSM proposes a fresh paradigm for search, referred to as operation-level search, where each computation unit is defined as an operation that either generates or expands a candidate set under a query vertex. To deal with the second problem and fully exploit the potential of this novel search paradigm, RSM implements a reinforcement learning strategy to generate operation-level search plans. RSM's reinforcement learning approach for constructing operation-based search plans encompasses three modules. In the first module, we employ graph neural networks to extract query vertex representation from graphs. Then, the other two modules leverage multilayer perceptron and are designed to create the generation and expansion operations, respectively. Extensive experiments on real-world graph datasets validate that RSM cuts down query processing time, outperforming existing algorithms by up to 1 to 2 orders of magnitude. | Ziming Li, Yuequn Dou, Youhuan Li, Xinhuan Chen, Chuxu Zhang | University of Connecticut, Connecticut, USA; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Tencent Inc., Shenzhen, China |
|  |  [Context Embeddings for Efficient Answer Generation in Retrieval-Augmented Generation](https://doi.org/10.1145/3701551.3703527) |  | 0 | Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledge of LLMs by extending the input with external information. As a consequence, the contextual inputs to the model become much longer slowing down decoding time affecting the time a user has to wait for an answer. We address this challenge by presenting COCOM, an effective context compression method, reducing long contexts to only a handful of Context Embeddings, speeding up the generation time by a large margin. Our method allows for different compression rates, trading off decoding time for answer quality. Compared to earlier methods, COCOM allows for handling multiple contexts more effectively, significantly reducing decoding time for long inputs. Our method demonstrates an inference speed-up of up to 5.69 times while achieving higher performance compared to existing efficient context compression methods | David Rau, Shuai Wang, Hervé Déjean, Stéphane Clinchant, Jaap Kamps | The University of Queensland, Brisbane, Australia; Naver Labs Europe, Grenoble, France; University of Amsterdam, Amsterdam, Netherlands |
|  |  [Personalised Outfit Recommendation via History-aware Transformers](https://doi.org/10.1145/3701551.3703545) |  | 0 | We present the history-aware transformer (HAT), a transformer-based model that uses shoppers' purchase history to personalise outfit predictions. The aim of this work is to recommend outfits that are internally coherent while matching an individual shopper's style and taste. To achieve this, we stack two transformer models, one that produces outfit representations and another one that processes the history of purchased outfits for a given shopper. We use these models to score an outfit's compatibility in the context of a shopper's preferences as inferred from their previous purchases. During training, the model learns to discriminate between purchased and random outfits using 3 losses: the focal loss for outfit compatibility typically used in the literature, a contrastive loss to bring closer learned outfit embeddings from a shopper's history, and an adaptive margin loss to facilitate learning from weak negatives. Together, these losses enable the model to make personalised recommendations based on a shopper's purchase history. Our experiments on the IQON3000 and Polyvore datasets show that HAT outperforms strong baselines on the outfit Compatibility Prediction (CP) and the Fill In The Blank (FITB) tasks. The model improves AUC for the CP hard task by 15.7 further improves accuracy on the FITB hard task by 6.5 We provide ablation studies on the personalisation, constrastive loss, and adaptive margin loss that highlight the importance of these modelling choices. | Myong Chol Jung, Julien Monteil, Philip Schulz, Volodymyr Vaskovych |  |
|  |  [DimeRec: A Unified Framework for Enhanced Sequential Recommendation via Generative Diffusion Models](https://doi.org/10.1145/3701551.3703555) |  | 0 | Sequential Recommendation (SR) plays a pivotal role in recommender systems by tailoring recommendations to user preferences based on their non-stationary historical interactions. Achieving high-quality performance in SR requires attention to both item representation and diversity. However, designing an SR method that simultaneously optimizes these merits remains a long-standing challenge. In this study, we address this issue by integrating recent generative Diffusion Models (DM) into SR. DM has demonstrated utility in representation learning and diverse image generation. Nevertheless, a straightforward combination of SR and DM leads to sub-optimal performance due to discrepancies in learning objectives (recommendation vs. noise reconstruction) and the respective learning spaces (non-stationary vs. stationary). To overcome this, we propose a novel framework called DimeRec (Diffusion with multi-interest enhanced Recommender). DimeRec synergistically combines a guidance extraction module (GEM) and a generative diffusion aggregation module (DAM). The GEM extracts crucial stationary guidance signals from the user's non-stationary interaction history, while the DAM employs a generative diffusion process conditioned on GEM's outputs to reconstruct and generate consistent recommendations. Our numerical experiments demonstrate that DimeRec significantly outperforms established baseline methods across three publicly available datasets. Furthermore, we have successfully deployed DimeRec on a large-scale short video recommendation platform, serving hundreds of millions of users. Live A/B testing confirms that our method improves both users' time spent and result diversification. | Wuchao Li, Rui Huang, Haijun Zhao, Chi Liu, Kai Zheng, Qi Liu, Na Mou, Guorui Zhou, Defu Lian, Yang Song, Wentian Bao, Enyun Yu, Wenwu Ou |  |
|  |  [Fusion Matters: Learning Fusion in Deep Click-through Rate Prediction Models](https://doi.org/10.1145/3701551.3703557) |  | 0 | The evolution of previous Click-Through Rate (CTR) models has mainly been driven by proposing complex components, whether shallow or deep, that are adept at modeling feature interactions. However, there has been less focus on improving fusion design. Instead, two naive solutions, stacked and parallel fusion, are commonly used. Both solutions rely on pre-determined fusion connections and fixed fusion operations. It has been repetitively observed that changes in fusion design may result in different performances, highlighting the critical role that fusion plays in CTR models. While there have been attempts to refine these basic fusion strategies, these efforts have often been constrained to specific settings or dependent on specific components. Neural architecture search has also been introduced to partially deal with fusion design, but it comes with limitations. The complexity of the search space can lead to inefficient and ineffective results. To bridge this gap, we introduce OptFusion, a method that automates the learning of fusion, encompassing both the connection learning and the operation selection. We have proposed a one-shot learning algorithm tackling these tasks concurrently. Our experiments are conducted over three large-scale datasets. Extensive experiments prove both the effectiveness and efficiency of OptFusion in improving CTR model performance. Our code implementation is available here. | Kexin Zhang, Fuyuan Lyu, Xing Tang, Dugang Liu, Chen Ma, Kaize Ding, Xiuqiang He, Xue Liu |  |
|  |  [Spectrum-based Modality Representation Fusion Graph Convolutional Network for Multimodal Recommendation](https://doi.org/10.1145/3701551.3703561) |  | 0 | Incorporating multi-modal features as side information has recently become a trend in recommender systems. To elucidate user-item preferences, recent studies focus on fusing modalities via concatenation, element-wise sum, or attention mechanisms. Despite having notable success, existing approaches do not account for the modality-specific noise encapsulated within each modality. As a result, direct fusion of modalities will lead to the amplification of cross-modality noise. Moreover, the variation of noise that is unique within each modality results in noise alleviation and fusion being more challenging. In this work, we propose a new Spectrum-based Modality Representation (SMORE) fusion graph recommender that aims to capture both uni-modal and fusion preferences while simultaneously suppressing modality noise. Specifically, SMORE projects the multi-modal features into the frequency domain and leverages the spectral space for fusion. To reduce dynamic contamination that is unique to each modality, we introduce a filter to attenuate and suppress the modality noise adaptively while capturing the universal modality patterns effectively. Furthermore, we explore the item latent structures by designing a new multi-modal graph learning module to capture associative semantic correlations and universal fusion patterns among similar items. Finally, we formulate a new modality-aware preference module, which infuses behavioral features and balances the uni- and multi-modal features for precise preference modeling. This empowers SMORE with the ability to infer both user modality-specific and fusion preferences more accurately. Experiments on three real-world datasets show the efficacy of our proposed model. The source code for this work has been made publicly available at https://github.com/kennethorq/SMORE. | Rongqing Kenneth Ong, Andy W. H. Khong |  |
|  |  [Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation](https://doi.org/10.1145/3701551.3703573) |  | 0 | Large language models (LLMs) are revolutionizing conversational recommendersystems by adeptly indexing item content, understanding complex conversationalcontexts, and generating relevant item titles. However, controlling thedistribution of recommended items remains a challenge. This leads to suboptimalperformance due to the failure to capture rapidly changing data distributions,such as item popularity, on targeted conversational recommendation platforms.In conversational recommendation, LLMs recommend items by generating the titles(as multiple tokens) autoregressively, making it difficult to obtain andcontrol the recommendations over all items. Thus, we propose aReindex-Then-Adapt (RTA) framework, which converts multi-token item titles intosingle tokens within LLMs, and then adjusts the probability distributions overthese single-token item titles accordingly. The RTA framework marries thebenefits of both LLMs and traditional recommender systems (RecSys):understanding complex queries as LLMs do; while efficiently controlling therecommended item distributions in conversational recommendations as traditionalRecSys do. Our framework demonstrates improved accuracy metrics across threedifferent conversational recommendation datasets and two adaptation settings | Zhankui He, Zhouhang Xie, Harald Steck, Dawen Liang, Rahul Jha, Nathan Kallus, Julian J. McAuley |  |
|  |  [Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation](https://doi.org/10.1145/3701551.3703544) |  | 0 | In specialized fields like the scientific domain, constructing large-scale human-annotated datasets poses a significant challenge due to the need for domain expertise. Recent methods have employed large language models to generate synthetic queries, which serve as proxies for actual user queries. However, they lack control over the content generated, often resulting in incomplete coverage of academic concepts in documents. We introduce Concept Coverage-based Query set Generation (CCQGen) framework, designed to generate a set of queries with comprehensive coverage of the document's concepts. A key distinction of CCQGen is that it adaptively adjusts the generation process based on the previously generated queries. We identify concepts not sufficiently covered by previous queries, and leverage them as conditions for subsequent query generation. This approach guides each new query to complement the previous ones, aiding in a thorough understanding of the document. Extensive experiments demonstrate that CCQGen significantly enhances query quality and retrieval performance. | SeongKu Kang, Bowen Jin, Wonbin Kweon, Yu Zhang, Dongha Lee, Jiawei Han, Hwanjo Yu |  |
|  |  [RetriEVAL: Evaluating Text Generation with Contextualized Lexical Match](https://doi.org/10.1145/3701551.3703581) |  | 0 | Pre-trained language models have made significant advancements in text generation tasks. Nevertheless, evaluating the generated text with automatic metrics is still challenging. Compared with supervised metrics, unsupervised metrics which are known for generality and robustness, are frequently employed to assess the quality of generated text efficiently. The representative unsupervised metric BERTScore uses pretrained embedding to calculate the word-to-word similarity across all tokens as evaluation scores, which can introduce potential noise due to the inclusion of tokens that do not contribute significantly to the semantics of the text. Furthermore, its heavy reliance on dense embeddings may lead to lower accuracy when evaluating text outside the common contexts represented in the training data, making it less effective in handling uncommon linguistic patterns Additionally, BERTScore treats all tokens with equal importance and lacks the ability to perform meaningful contextual expansion, which can result in less accurate similarity measurements, particularly when dealing with paraphrased or semantically rich text. To address this problem, we propose an unsupervised automatic evaluation metric inspired by the concept of lexical match in information retrieval. Our method leverages contextualized lexical matching to measure exact matches between identical tokens and dynamically matches different tokens based on their contextualized representations. Experiments on SummEval and Topical-Chat demonstrate our proposed RetriEVAL can correlate better with human judgments than previous unsupervised metrics. | Zhen Li, Xinchi Li, Chongyang Tao, Jiazhan Feng, Tao Shen, Can Xu, Hao Wang, Dongyan Zhao, Shuai Ma | WICT, Peking University, Beijing, China, SKLMCPTS, Beijing, China, & KLIPMT, Beijing, China; Wangxuan Institute of Computer Technology, Peking University, Beijing, China; China Telecom Beijing Research Institute, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; Peking University, Beijing, China; University of Technology Sydney, Sydney, Australia |
|  |  [Quam: Adaptive Retrieval through Query Affinity Modelling](https://doi.org/10.1145/3701551.3703584) |  | 0 | Building relevance models to rank documents based on user information needs is a central task in information retrieval and the NLP community. Beyond the direct ad-hoc search setting, many knowledge-intense tasks are powered by a first-stage retrieval stage for context selection, followed by a more involved task-specific model. However, most first-stage ranking stages are inherently limited by the recall of the initial ranking documents. Recently, adaptive re-ranking techniques have been proposed to overcome this issue by continually selecting documents from the whole corpus, rather than only considering an initial pool of documents. However, so far these approaches have been limited to heuristic design choices, particularly in terms of the criteria for document selection. In this work, we propose a unifying view of the nascent area of adaptive retrieval by proposing, Quam, a \textit{query-affinity model} that exploits the relevance-aware document similarity graph to improve recall, especially for low re-ranking budgets. Our extensive experimental evidence shows that our proposed approach, Quam improves the recall performance by up to 26\% over the standard re-ranking baselines. Further, the query affinity modelling and relevance-aware document graph modules can be injected into any adaptive retrieval approach. The experimental results show the existing adaptive retrieval approach improves recall by up to 12\%. The code of our work is available at \url{https://github.com/Mandeep-Rathee/quam}. | Mandeep Rathee, Sean MacAvaney, Avishek Anand | Delft University of Technology (TU Delft), Delft, The Netherlands; L3S Research Center, Hannover, Germany; University of Glasgow, Glasgow, United Kingdom |
|  |  [CRS Arena: Crowdsourced Benchmarking of Conversational Recommender Systems](https://doi.org/10.1145/3701551.3704120) |  | 0 | We introduce CRS Arena, a research platform for scalable benchmarking of Conversational Recommender Systems (CRS) based on human feedback. The platform displays pairwise battles between anonymous conversational recommender systems, where users interact with the systems one after the other before declaring either a winner or a draw. CRS Arena collects conversations and user feedback, providing a foundation for reliable evaluation and ranking of CRSs. We conduct experiments with CRS Arena on both open and closed crowdsourcing platforms, confirming that both setups produce highly correlated rankings of CRSs and conversations with similar characteristics. We release CRSArena-Dial, a dataset of 474 conversations and their corresponding user feedback, along with a preliminary ranking of the systems based on the Elo rating system. The platform is accessible at https://iai-group-crsarena.hf.space/. | Nolwenn Bernard, Hideaki Joko, Faegheh Hasibi, Krisztian Balog |  |
|  |  [Compliant Personalization for Recommended Documents in Microsoft 365 with L-Profile as an Exemplary Feature](https://doi.org/10.1145/3701551.3706129) |  | 0 | Collecting and utilizing user data is essential for effective recommender systems to personalize content. However, privacy and compliance regulations protect personal user data. With strict regulations such as the General Data Protection Regulation (GDPR) or California Privacy Rights Act (CPRA) in effect, one may ask: how can a recommender system be both compliant and effective? This paper aims to answer this question, demonstrating privacy-compliant personalization for the Recommended Documents service within Microsoft 365 (M365), particularly Microsoft Feed. It outlines the development of an exemplary L-Profile personalization feature from conception to productionization, covering offline and online evaluations. | Matthias Braunhofer, Grzegorz Kukla, Abhishek Arun | Microsoft Corporation, Warsaw, Poland; Microsoft Corporation, London, United Kingdom; Microsoft Corporation, Munich, Germany |
|  |  [Zero-Shot Image Moderation in Google Ads with LLM-Assisted Textual Descriptions and Cross-modal Co-embeddings](https://doi.org/10.1145/3701551.3706127) |  | 0 | We present a scalable and agile approach for ads image content moderation at Google, addressing the challenges of moderating massive volumes of ads with diverse content and evolving policies. The proposed method utilizes human-curated textual descriptions and cross-modal text-image co-embeddings to enable zero-shot classification of policy violating ads images, bypassing the need for extensive supervised training data and human labeling. By leveraging large language models (LLMs) and user expertise, the system generates and refines a comprehensive set of textual descriptions representing policy guidelines. During inference, co-embedding similarity between incoming images and the textual descriptions serves as a reliable signal for policy violation detection, enabling efficient and adaptable ads content moderation. Evaluation results demonstrate the efficacy of this framework in significantly boosting the detection of policy violating content. | Enming Luo, Wei Qiao, Katie Warren, Jingxiang Li, Eric Xiao, Krishna Viswanathan, Yuan Wang, Yintao Liu, Jimin Li, Ariel Fuxman |  |
|  |  [UIPN: User Intent Profiling Network for Multi Behavior Modeling in CTR Prediction](https://doi.org/10.1145/3701551.3703570) |  | 0 | Click-through rate (CTR) prediction models often depict a user's interest as a fixed-length vector derived from her historical behaviors, encompassing various types of actions such as clicks, likes, and purchases. Recently, several approaches have been developed to capture users' multiple interests. For accurate multi-behavior prediction, it is essential to represent complex behavior dependencies effectively, as these dependencies are manifested through different behavior types. Advanced multi-behavior models learn relationships among behaviors based on all previous interactions. However, diverse behaviors may indicate different user intentions and unrelated interactions can distract from the target behavior that needs to be predicted. In order to address the limitations highlighted before, we propose a new approach called User Intent Profiling Network (UIPN) for modeling multiple behaviors. UIPN is capable of learning behavior-specific and behavior-dependent intention embedding vectors for users' various behaviors using user intent extractors. These extractors can provide explicit explanations of users' interactions in the online advertising system. The proposed approach has been validated by extensive experiments on public datasets, which illustrate its effectiveness. | Xu Yang, Guangyuan Yu, Jun He | Tencent Inc., Shenzhen, Guangdong, China |
|  |  [A Contrastive Framework with User, Item and Review Alignment for Recommendation](https://doi.org/10.1145/3701551.3703530) |  | 0 | Learning effective latent representations for users and items is the cornerstone of recommender systems. Traditional approaches rely on user-item interaction data to map users and items into a shared latent space, but the sparsity of interactions often poses challenges. While leveraging user reviews could mitigate this sparsity, existing review-aware recommendation models often exhibit two key limitations. First, they typically rely on reviews as additional features, but reviews are not universal, with many users and items lacking them. Second, such approaches do not integrate reviews into the user-item space, leading to potential divergence or inconsistency among user, item, and review representations. To overcome these limitations, our work introduces a Review-centric Contrastive Alignment Framework for Recommendation (ReCAFR), which incorporates reviews into the core learning process, ensuring alignment among user, item, and review representations within a unified space. Specifically, we leverage two self-supervised contrastive strategies that not only exploit review-based augmentation to alleviate sparsity, but also align the tripartite representations to enhance robustness. Empirical studies on public benchmark datasets demonstrate the effectiveness and robustness of ReCAFR. | Hoang V. Dong, Yuan Fang, Hady W. Lauw |  |
|  |  [DeMBR: Denoising Model with Memory Pruning and Semantic Guidance for Multi-Behavior Recommendation](https://doi.org/10.1145/3701551.3703532) |  | 0 | Multi-behavior recommendation systems aim to incorporate auxiliary behaviors (e.g., click, cart, etc.) to enhance the understanding of sparse target behaviors (e.g., purchase), thereby capturing user preferences more accurately. Currently, multi-behavior recommendation research focuses on modeling the associations between different user behaviors, but ignores the large amount of noise in user interaction data. This noise may come from accidental touches, curiosity, or ineffective operations during the purchasing process, and can be further categorized into two types: 1) hard noise is significantly deviates from the user's true preferences, and 2) soft noise is closer to the user's true preferences. The presence of noise can interfere with the model's ability to accurately identify the user's true preferences. To overcome the aforementioned issue, we innovatively propose a Denoising Model with Memory Pruning and Semantic Guidance for Multi-Behavior Recommendation (DeMBR). The model eliminates different types of noise at the data level and the representation level, respectively. Specifically, since hard noise significantly deviates from user preferences, we design a pruning-based denoising module that leverages a memory bank, which identifies and removes hard noise interactions from the data. Since soft noise reflects some user preferences, we design a semantic guidance denoising module that leverages behaviors with strong expressive ability (e.g., purchase) to guide those with weaker ability (e.g., click), effectively suppressing noise while preserving true's preferences. Finally, we designed a cross-learning module that allows noise-identifying signals to be exchanged between the two modules, and ultimately learn representations that accurately reflect user's preferences. Extensive experiments conducted on two public datasets demonstrate that our model substantially surpasses the state-of-the-art recommendation models. Our code is publicly available at: https://github.com/DeMBR2024/DeMBR.git | Shuai Zhang, Hua Chu, Jianan Li, Yangtao Zhou, Shirong Wang, Qiaofei Sun | Xidian University, Xi'an, China |
|  |  [Enhancing Code Search Intent with Programming Context Exploration](https://doi.org/10.1145/3701551.3703537) |  | 0 | An intelligent code search engine tries to find and suggest a code piece given a developer's query quickly from a large-scale program database, which can significantly promote software development efficiency. Existing solutions can search the relevant codes to some extent. However, most of them fail to precisely understand the search intent of developers since they only mine their natural language queries, while ignoring the valuable programming context (e.g., the code written by the developer). In this paper, we study the novel problem of context-aware code search. To promote a step forward, we first provide the CodeSearchNet-C dataset with constructing sufficient programming context from the GitHub website for each query-code instance. The dataset is supplemented on the CodeSearchNet benchmark, ensuring both generality and comparability for relevant research. Then, by analyzing the characteristics of programming context, we propose a novel two-stage Context-aware Code Retrieval (ConCR) framework. In the first stage, we propose a Context Walking algorithm, which simulates the programming habits of different developers. The generated programming context could ensure the diversity of search intent among developers. In the second stage, imitating the reading habits of developers, we introduce a novel Context Hierarchical Encoder, to understand the search intent with contextual information from local to global. Our ConCR framework is general, and we give three implementations on the basis of typical code search models as backbones. Extensive experimental results clearly prove that our ConCR significantly enhances the code search performance, effectively fulfilling developers' needs for efficient code resource searching on the web. These results also verify the necessity of introducing programming context to understand developers' intent. | Yanmin Dong, Zhenya Huang, Zheng Zhang, Guanhao Zhao, Likang Wu, Hongke Zhao, Binbin Jin, Qi Liu | College of Management and Economics, Tianjin University, Tianjin, China |
|  |  [Improving CTR Prediction with Graph-Enhanced Interest Networks for Sparse Behavior Sequences](https://doi.org/10.1145/3701551.3703567) |  | 0 | Predicting click-through rates is crucial in various fields, including online advertising and recommendation systems. The key to improving the performance of CTR prediction lies in learning a robust user representation, particularly by analyzing their historical behaviors. Previous studies usually model behavior sequences through attention-based sequence models or graph-based methods, which usually struggle to explore diverse latent interests or accurately model user behaviors. Moreover, this challenge is exacerbated when users' historical behaviors are sparse, a common issue in real-world business-to-business (B2B) e-commerce scenarios. In this paper, we propose a novel Graph-Enhanced Interest Network (GEIN) to capture users' latent intents and facilitate the sequential learning of sparse behavior sequences. Specifically, we first construct a hierarchical item-intent heterogeneous graph to enrich the representation of sparse behaviors using diverse information from graphs. Next, we build a user-level behavior interest factor graph to accurately capture user interests. Additionally, a contrastive learning mechanism is incorporated to mitigate the negative robustness impacts caused by sparsity. Extensive experiments on real-world datasets demonstrate that our proposed GEIN outperforms a wide range of state-of-the-art methods. Furthermore, online A/B testing also confirms the superiority of GEIN over competing baselines in a real-world production environment. | Xuanzhou Liu, Zhibo Xiao, Luwei Yang, Hansheng Xue, Jianxing Ma, Yujiu Yang | SIGS, Tsinghua University, Shenzheng, Guangdong, China; Alibaba Group, Hangzhou, Zhejiang, China; The Australian National University, Canberra, Australia |
|  |  [Large Language Model driven Policy Exploration for Recommender Systems](https://doi.org/10.1145/3701551.3703496) |  | 0 | Recent advancements in Recommender Systems (RS) have incorporated Reinforcement Learning (RL), framing the recommendation as a Markov Decision Process (MDP). However, offline RL policies trained on static user data are vulnerable to distribution shift when deployed in dynamic online environments. Additionally, excessive focus on exploiting short-term relevant items can hinder exploration, leading to suboptimal recommendations and negatively impacting long-term user gains. Online RL-based RS also face challenges in production deployment, due to the risks of exposing users to untrained or unstable policies. Large Language Models (LLMs) offer a promising solution to mimic user objectives and preferences for pre-training policies offline to enhance the initial recommendations in online settings. Effectively managing distribution shift and balancing exploration are crucial for improving RL-based RS, especially when leveraging LLM-based pre-training. To address these challenges, we propose an Interaction-Augmented Learned Policy (iALP) that utilizes user preferences distilled from an LLM. Our approach involves prompting the LLM with user states to extract item preferences, learning rewards based on feedback, and updating the RL policy using an actor-critic framework. Furthermore, to deploy iALP in an online scenario, we introduce an adaptive variant, A-iALP, that implements a simple fine-tuning strategy (A-iALP_ft), and an adaptive approach (A-iALP_ap) designed to mitigate issues with compromised policies and limited exploration. Experiments across three simulated environments demonstrate that A-iALP introduces substantial performance improvements | Jie Wang, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose |  |
|  |  [Review-Based Hyperbolic Cross-Domain Recommendation](https://doi.org/10.1145/3701551.3703486) |  | 0 | The issue of data sparsity poses a significant challenge to recommender systems. In response to this, algorithms that leverage side information such as review texts have been proposed. Furthermore, Cross-Domain Recommendation (CDR), which captures domain-shareable knowledge and transfers it from a richer domain (source) to a sparser one (target) has emerged recently. Nevertheless, existing methodologies assume an Euclidean embedding space, encountering difficulties in accurately representing richer text information and managing complex user-item interactions. This paper advocates a hyperbolic CDR approach for modeling review-based user-item relationships. We first emphasize that conventional distance-based domain alignment techniques may cause problems because small modifications in hyperbolic geometry result in magnified perturbations, ultimately leading to the collapse of hierarchical structures. To address this challenge, we propose hierarchy-aware embedding and domain alignment schemes that adjust the scale to extract domain-shareable information without disrupting structural forms. Extensive experiments substantiate the efficiency, robustness, and scalability of the proposed model. The source code is given here https://github.com/ChoiYoonHyuk/HEAD. | Yoonhyuk Choi, Jiho Choi, Taewook Ko, ChongKwon Kim | Korea Institute of Energy Technology, Naju, Republic of Korea; KAIST, Seoul, Republic of Korea; Samsung, Seoul, Republic of Korea |
|  |  [Combating Heterogeneous Model Biases in Recommendations via Boosting](https://doi.org/10.1145/3701551.3703505) |  | 0 | Collaborative Filtering (CF) based recommenders often exhibit model biases, delivering strong recommendation utility to certain users or items at the expense of others. Prior research approaches these biases as isolated and standalone issues, ignoring their interconnected nature and developing separate methods, thereby compromising the specialized debiasing efforts. Thus, we introduce a boosting-based framework designed to alleviate a broad spectrum of biases. This framework employs a series of sub-models, each tailored for different user and item subgroups. Theoretically, our model ensures an exponentially decreasing upper bound on the training loss across all user and item types with increasing boosting iterations. Extensive experiments demonstrate its superior debiasing capabilities against state-of-the-art methods across four model bias types. Appendix, data and code are available at https://github.com/JP-25/CFBoost | Jinhao Pan, James Caverlee, Ziwei Zhu | Department of Computer Science and Engineering, Texas A&M University, College Station, Texas, USA; Department of Computer Science, George Mason University, Fairfax, Virginia, USA |
|  |  [Large Language Model Simulator for Cold-Start Recommendation](https://doi.org/10.1145/3701551.3703546) |  | 0 | Recommending cold items remains a significant challenge in billion-scale online recommendation systems. While warm items benefit from historical user behaviors, cold items rely solely on content features, limiting their recommendation performance and impacting user experience and revenue. Current models generate synthetic behavioral embeddings from content features but fail to address the core issue: the absence of historical behavior data. To tackle this, we introduce the LLM Simulator framework, which leverages large language models to simulate user interactions for cold items, fundamentally addressing the cold-start problem. However, simply using LLM to traverse all users can introduce significant complexity in billion-scale systems. To manage the computational complexity, we propose a coupled funnel ColdLLM framework for online recommendation. ColdLLM efficiently reduces the number of candidate users from billions to hundreds using a trained coupled filter, allowing the LLM to operate efficiently and effectively on the filtered set. Extensive experiments show that ColdLLM significantly surpasses baselines in cold-start recommendations, including Recall and NDCG metrics. A two-week A/B test also validates that ColdLLM can effectively increase the cold-start period GMV. | Feiran Huang, Yuanchen Bei, Zhenghang Yang, Junyi Jiang, Hao Chen, Qijie Shen, Senzhang Wang, Fakhri Karray, Philip S. Yu | Zhejiang University, Hangzhou, China; Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Alibaba Group, Hangzhou, China; Central South University, Changsha, China; City University of Macau, Macao, China; Jinan University, Guangzhou, China; University of Illinois Chicago, Chicago, USA |
|  |  [Writing Style Matters: An Examination of Bias and Fairness in Information Retrieval Systems](https://doi.org/10.1145/3701551.3703514) |  | 0 | The rapid advancement of Language Model technologies has opened new opportunities, but also introduced new challenges related to bias and fairness. This paper explores the uncharted territory of potential biases in state-of-the-art universal text embedding models towards specific document and query writing styles within Information Retrieval (IR) systems. Our investigation reveals that different embedding models exhibit different preferences of document writing style, while more informal and emotive styles are less favored by most embedding models. In terms of query writing styles, many embedding models tend to match the style of the query with the style of the retrieved documents, but some show a consistent preference for specific styles. Text embedding models fine-tuned on synthetic data generated by LLMs display a consistent preference for certain style of generated data. These biases in text embedding based IR systems can inadvertently silence or marginalize certain communication styles, thereby posing a significant threat to fairness in information retrieval. Finally, we also compare the answer styles of Retrieval Augmented Generation (RAG) systems based on different LLMs and find out that most text embedding models are biased towards LLM's answer styles when used as evaluation metrics for answer correctness. This study sheds light on the critical issue of writing style based bias in IR systems, offering valuable insights for the development of more fair and robust models. | Hongliu Cao |  |
|  |  [AMLCDR: An Adaptive Meta-Learning Model for Cross-Domain Recommendation by Aligning Preference Distributions](https://doi.org/10.1145/3701551.3703539) |  | 0 | The issue of data sparsity poses a formidable challenge in the field of recommender systems. Encouragingly, leveraging the interactions among overlapping users in the source domain can enhance item recommendation in the target domain. The transfer of user preferences across domains is a crucial concern in the cross-domain recommendation and represents a hopeful method to address data sparsity. Most existing methods transfer users' preference information by building a preference transfer network. These methods focus on the cross-domain mapping of preference features and ignore the inherent data distribution differences between the source domain and target domain. Consequently, the mapped user embeddings do not align with the item embeddings in the target domain and the recommendation quality decreases. On this basis, we propose a new method called Adaptive Meta-Learning for Cross-Domain Recommendation (AMLCDR). The method includes a meta-learning network for fully extracting user characteristics and generating a transfer network to reduce the user preference loss, as well as a domain adaptation network to align user preference distributions. We perform comprehensive experiments to assess the efficacy of AMLCDR by utilizing a substantial real-world dataset. We validate the effectiveness of data distribution alignment in domain adaptation. For diverse cross-domain recommendation tasks under different start conditions, AMLCDR outperforms state-of-the-art models in multiple evaluation metrics. | Fanqi Meng, Zhiyuan Zhang | Beijing Jiaotong University, Beijing, China |
|  |  [Unifying Bias and Unfairness in Information Retrieval: New Challenges in the LLM Era](https://doi.org/10.1145/3701551.3703478) |  | 0 | With the rapid advancements of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a paradigm shift due to their integration. However, integrating LLMs into the IR pipelines has also introduced new challenges, particularly in the form of biases and unfairness that may disrupt the information ecosystem. This tutorial will offer a comprehensive overview of emerging and pressing bias and unfairness issues associated with integrating LLMs into IR systems. Specifically, this tutorial first unifies bias and unfairness issues as problems of distribution mismatch and further categorizes the mitigation strategies under the umbrella of distribution alignment. Then, we summarize several types of bias and unfairness issues emerging from three critical stages of LLM integration into IR systems: data collection, model development, and result evaluation. We will systematically review and analyze their definitions, characteristics, and corresponding mitigation strategies in recent literature. Finally, we will highlight some open problems and future research directions. We hope this tutorial can raise the awareness of researchers and stakeholders in the IR field and beyond regarding bias and unfairness issues in this LLM era. | Sunhao Dai, Chen Xu, Shicheng Xu, Liang Pang, Zhenhua Dong, Jun Xu | Huawei Noah's Ark Lab, Shenzhen, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China |
|  |  [Towards Ethical and Personalized Web Navigation Agents: A Framework for User-Aligned Task Execution](https://doi.org/10.1145/3701551.3707420) |  | 0 | Generative AI has advanced the capabilities of autonomous agents, enabling autonomous execution of complex web navigation tasks that can reshape digital interactions across various domains. Yet, to reach their full potential, these agents must be ethically aligned and personalized to individual user needs-a challenge complicated by privacy concerns and the risk of reinforcing biases. This work introduces a novel framework that enables responsible, user-guided personalization of web navigation agents, ensuring alignment with ethical standards and user preferences. By developing agents capable of perceiving, reasoning, and adapting in alignment with user preferences, this work proposes an approach that transcends generic task execution. Employing a structured representation of user-specific tasks, the agent utilizes interactive and reasoning actions to personalize workflows, adapting responsively to individual contexts. Evaluation through task success metrics and user satisfaction scores further assesses the ethical alignment and utility of personalized interactions. This research lays the groundwork for responsible agents that offer personalized assistance while adhering to ethical and privacy standards, with implications for information retrieval, e-commerce, and other knowledge-intensive applications. | Preetam Prabhu Srikar Dammu | University of Washington, Seattle, WA, USA |
|  |  [A Sublinear Algorithm for Approximate Shortest Paths in Large Networks](https://doi.org/10.1145/3701551.3703512) |  | 0 | Computing distances and finding shortest paths in massive real-world networksis a fundamental algorithmic task in network analysis. There are two mainapproaches to solving this task. On one hand are traversal-based algorithmslike bidirectional breadth-first search (BiBFS) with no preprocessing step andslow individual distance inquiries. On the other hand are indexing-basedapproaches, which maintain a large index. This allows for answering individualinquiries very fast; however, index creation is prohibitively expensive. Weseek to bridge these two extremes: quickly answer distance inquiries withoutthe need for costly preprocessing. In this work, we propose a new algorithm and data structure, WormHole, forapproximate shortest path computations. WormHole leverages structuralproperties of social networks to build a sublinearly sized index, drawing uponthe explicit core-periphery decomposition of Ben-Eliezer et al. Empirically,the preprocessing time of WormHole improves upon index-based solutions byorders of magnitude, and individual inquiries are consistently much faster thanin BiBFS. The acceleration comes at the cost of a minor accuracy trade-off.Nonetheless, our empirical evidence demonstrates that WormHole accuratelyanswers essentially all inquiries within a maximum additive error of 2. Wecomplement these empirical results with provable theoretical guarantees,showing that WormHole requires n^o(1) node queries per distance inquiry inrandom power-law networks. In contrast, any approach without a preprocessingstep requires n^Ω(1) queries for the same task. WormHole does not require reading the whole graph. Unlike the vast majorityof index-based algorithms, it returns paths, not just distances. For fasterinquiry times, it can be combined effectively with other index-based solutions,by running them only on the sublinear core. | Sabyasachi Basu, Nadia Koshima, Talya Eden, Omri BenEliezer, C. Seshadhri |  |
|  |  [MixRec: Heterogeneous Graph Collaborative Filtering](https://doi.org/10.1145/3701551.3703591) |  | 0 | For modern recommender systems, the use of low-dimensional latent representations to embed users and items based on their observed interactions has become commonplace. However, many existing recommendation models are primarily designed for coarse-grained and homogeneous interactions, which limits their effectiveness in two critical dimensions. Firstly, these models fail to leverage the relational dependencies that exist across different types of user behaviors, such as page views, collects, comments, and purchases. Secondly, they struggle to capture the fine-grained latent factors that drive user interaction patterns. To address these limitations, we present a heterogeneous graph collaborative filtering model MixRec that excels at disentangling users' multi-behavior interaction patterns and uncovering the latent intent factors behind each behavior. Our model achieves this by incorporating intent disentanglement and multi-behavior modeling, facilitated by a parameterized heterogeneous hypergraph architecture. Furthermore, we introduce a novel contrastive learning paradigm that adaptively explores the advantages of self-supervised data augmentation, thereby enhancing the model's resilience against data sparsity and expressiveness with relation heterogeneity. To validate the efficacy of MixRec, we conducted extensive experiments on three public datasets. The results clearly demonstrate its superior performance, significantly outperforming various state-of-the-art baselines. Our model is open-sourced and available at: https://github.com/HKUDS/MixRec. | Lianghao Xia, Meiyan Xie, Yong Xu, Chao Huang |  |
|  |  [Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts](https://doi.org/10.1145/3701551.3703500) |  | 0 | Cross-lingual entity alignment (EA) enables the integration of multiple knowledge graphs (KGs) across different languages, providing users with seamless access to diverse and comprehensive knowledge. Existing methods, mostly supervised, face challenges in obtaining labeled entity pairs. To address this, recent studies have shifted towards self-supervised and unsupervised frameworks. Despite their effectiveness, these approaches have limitations: (1) Relation passing: mainly focusing on the entity while neglecting the semantic information of relations, (2) Isomorphic assumption: assuming isomorphism between source and target graphs, which leads to noise and reduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise in the textual features, especially when encountering inconsistent translations or Out-Of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an unsupervised and robust cross-lingual EA pipeline that jointly performs Entity-level and Relation-level Alignment by neighbor triple matching strategy using semantic textual features of relations and entities. Its refinement step iteratively enhances results by fusing entity-level and relation-level alignments based on neighbor triple matching. The additional verification step examines the entities' neighbor triples as the linearized text. This Align-then-Verify pipeline rigorously assesses alignment results, achieving near-perfect alignment even in the presence of noisy textual features of entities. Our extensive experiments demonstrate that the robustness and general applicability of ERAlign improved the accuracy and effectiveness of EA tasks, contributing significantly to knowledge-oriented applications. | Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee |  |
|  |  [Gradient Deconfliction via Orthogonal Projections onto Subspaces For Multi-task Learning](https://doi.org/10.1145/3701551.3703503) |  | 0 | Although multi-task learning (MTL) has been a preferred approach and successfully applied in many real-world scenarios, MTL models are not guaranteed to outperform single-task models on all tasks mainly due to the negative effects of conflicting gradients among the tasks. In this paper, we fully examine the influence of conflicting gradients and further emphasize the importance and advantages of achieving non-conflicting gradients which allows simple but effective trade-off strategies among the tasks with stable performance. Based on our findings, we propose the Gradient Deconfliction via Orthogonal Projections onto Subspaces (GradOPS) spanned by other task-specific gradients. Our method not only solves all conflicts among the tasks, but can also effectively search for diverse solutions towards different trade-off preferences among the tasks. Theoretical analysis on convergence is provided, and performance of our algorithm is fully testified on multiple benchmarks in various domains. Results demonstrate that our method can effectively find multiple state-of-the-art solutions with different trade-off strategies among the tasks on multiple datasets. | Shijie Zhu, Hui Zhao, Tianshu Wu, Pengjie Wang, Hongbo Deng, Jian Xu, Bo Zheng | Google; Alibaba Group; Principal Researcher, Alibaba Group |
|  |  [Q-DISCO: Query-Centric Densest Subgraphs in Networks with Opinion Information](https://doi.org/10.1145/3701551.3703502) |  | 0 | Given a network G=(V,E), where each node v is associated with a vector p_v ∈ℝ^d representing its opinion about d different topics, how can we uncover subsets of nodes that not only exhibit exceptionally high density but also possess positively aligned opinions on multiple topics? In this paper we focus on this novel algorithmic question, that is essential in an era where digital social networks are hotbeds of opinion formation and dissemination. We introduce a novel methodology anchored in the well-established densest subgraph problem. We analyze the computational complexity of our formulation, indicating that our problem is NP-hard and eludes practically acceptable approximation guarantees. To navigate these challenges, we design two heuristic algorithms: the first is predicated on the Lagrangian relaxation of our formulation, while the second adopts a peeling algorithm based on the dual of a Linear Programming relaxation. We elucidate the theoretical underpinnings of their performance and validate their utility through empirical evaluation on real-world datasets. Among others, we delve into Twitter datasets we collected concerning timely issues, such as the Ukraine conflict and the discourse surrounding COVID-19 mRNA vaccines, to gauge the effectiveness of our methodology. Our empirical investigations verify that our algorithms are able to extract valuable insights from networks with opinion information. | Tianyi Chen, Atsushi Miyauchi, Charalampos E. Tsourakakis |  |
|  |  [Robustness Verification of Deep Graph Neural Networks Tightened by Linear Approximation](https://doi.org/10.1145/3701551.3703506) |  | 0 | Recent research indicates that adding residual connections in Graph Neural Networks (GNNs) would amplify susceptibility to anomalous nodes, consequently undermining the robustness of deep GNNs in practical settings. However, existing verification methods encounter challenges with the increasing number of parameters and computational overhead in deep GNNs. In this paper, we derive the general form of the residual connections and apply the dual backpropagation network to deep GNNs. Considering the heightened computational errors arising from the increased number of layers in deep GNNs, we propose a new method for calculating intermediate activation bounds of GNNs based on linear approximation. Experimental results show that new method can effectively enhance the verification accuracy. Notably, the maximum perturbation value of nodes correctly classified shows an average improvement of 119.5%. To showcase the the efficacy and scalability of our method, we verify robustness of deep GNNs on six different graph datasets, and our method can effectively verify the robustness of deep GNNs even with 32 layers of residual connections, i.e. verify over 87.29% of nodes in the Citeseer dataset. Furthermore, we analyse the influence of the graph structural properties on the robustness of the model. | Xingyu Zeng, Han Li, Qi Qi, Jingyu Wang, Haodong Deng, Haifeng Sun, Zirui Zhuang, Jianxin Liao | WOMUSIC, China Unicom Network Communications Co., Ltd., Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China |
|  |  [Lighter And Better: Towards Flexible Context Adaptation For Retrieval Augmented Generation](https://doi.org/10.1145/3701551.3703580) |  | 0 | The existing Retrieval-Augmented Generation (RAG) systems face significant challenges in terms of cost and effectiveness. On one hand, they need to encode the lengthy retrieved contexts before responding to the input tasks, which imposes substantial computational overhead. On the other hand, directly using generic Large Language Models (LLMs) often leads to sub-optimal answers, while task-specific fine-tuning may compromise the LLMs' general capabilities. To address these challenges, we introduce a novel approach called FlexRAG (Flexible Context Adaptation for RAG). In this approach, the retrieved contexts are compressed into compact embeddings before being encoded by the LLMs. Simultaneously, these compressed embeddings are optimized to enhance downstream RAG performance. A key feature of FlexRAG is its flexibility, which enables effective support for diverse compression ratios and selective preservation of important contexts. Thanks to these technical designs, FlexRAG achieves superior generation quality while significantly reducing running costs. Comprehensive experiments on various question-answering datasets validate our approach as a cost-effective and flexible solution for RAG systems. | Chenyuan Wu, Ninglu Shao, Zheng Liu, Shitao Xiao, Chaozhuo Li, Chen Zhang, Senzhang Wang, Defu Lian |  |
|  |  [Privacy-Preserving Orthogonal Aggregation for Guaranteeing Gender Fairness in Federated Recommendation](https://doi.org/10.1145/3701551.3703513) |  | 0 | Under stringent privacy constraints, whether federated recommendation systems can achieve group fairness remains an inadequately explored question. Taking gender fairness as a representative issue, we identify three phenomena in federated recommendation systems: performance difference, data imbalance, and preference disparity. We discover that the state-of-the-art methods only focus on the first phenomenon. Consequently, their imposition of inappropriate fairness constraints detrimentally affects the model training. Moreover, due to insufficient sensitive attribute protection of existing works, we can infer the gender of all users with 99.90 noise. In this work, we propose Privacy-Preserving Orthogonal Aggregation (PPOA), which employs the secure aggregation scheme and quantization technique, to prevent the suppression of minority groups by the majority and preserve the distinct preferences for better group fairness. PPOA can assist different groups in obtaining their respective model aggregation results through a designed orthogonal mapping while keeping their attributes private. Experimental results on three real-world datasets demonstrate that PPOA enhances recommendation effectiveness for both females and males by up to 8.25 and 6.36 achieves optimal fairness in most cases. Extensive ablation experiments and visualizations indicate that PPOA successfully maintains preferences for different gender groups. | Siqing Zhang, Yuchen Ding, Wei Tang, Wei Sun, Yong Liao, Peng Yuan Zhou |  |
|  |  [Sequential Diversification with Provable Guarantees](https://doi.org/10.1145/3701551.3703531) |  | 0 | Diversification is a useful tool for exploring large collections of information items. It has been used to reduce redundancy and cover multiple perspectives in information-search settings. Diversification finds applications in many different domains, including presenting search results of information-retrieval systems and selecting suggestions for recommender systems. Interestingly, existing measures of diversity are defined over \emph{sets} of items, rather than evaluating \emph{sequences} of items. This design choice comes in contrast with commonly-used relevance measures, which are distinctly defined over sequences of items, taking into account the ranking of items. The importance of employing sequential measures is that information items are almost always presented in a sequential manner, and during their information-exploration activity users tend to prioritize items with higher~ranking. In this paper, we study the problem of \emph{maximizing sequential diversity}. This is a new measure of \emph{diversity}, which accounts for the \emph{ranking} of the items, and incorporates \emph{item relevance} and \emph{user behavior}. The overarching framework can be instantiated with different diversity measures, and here we consider the measures of \emph{sum~diversity} and \emph{coverage~diversity}. The problem was recently proposed by Coppolillo et al.~\citep{coppolillo2024relevance}, where they introduce empirical methods that work well in practice. Our paper is a theoretical treatment of the problem: we establish the problem hardness and present algorithms with constant approximation guarantees for both diversity measures we consider. Experimentally, we demonstrate that our methods are competitive against strong baselines. | Honglian Wang, Sijing Tu, Aristides Gionis |  |
|  |  [An Aspect Performance-aware Hypergraph Neural Network for Review-based Recommendation](https://doi.org/10.1145/3701551.3703528) |  | 0 | Online reviews allow consumers to provide detailed feedback on various aspects of items. Existing methods utilize these aspects to model users' fine-grained preferences for specific item features through graph neural networks. We argue that the performance of items on different aspects is important for making precise recommendations, which has not been taken into account by existing approaches, due to lack of data. In this paper, we propose an aspect performance-aware hypergraph neural network (APH) for the review-based recommendation, which learns the performance of items from the conflicting sentiment polarity of user reviews. Specifically, APH comprehensively models the relationships among users, items, aspects, and sentiment polarity by systematically constructing an aspect hypergraph based on user reviews. In addition, APH aggregates aspects representing users and items by employing an aspect performance-aware hypergraph aggregation method. It aggregates the sentiment polarities from multiple users by jointly considering user preferences and the semantics of their sentiments, determining the weights of sentiment polarities to infer the performance of items on various aspects. Such performances are then used as weights to aggregate neighboring aspects. Experiments on six real-world datasets demonstrate that APH improves MSE, Precision@5, and Recall@5 by an average of 2.30 best baseline. The source code and data are available at https://github.com/dianziliu/APH. | Junrui Liu, Tong Li, Di Wu, Zifang Tang, Yuan Fang, Zhen Yang |  |
|  |  [LightGNN: Simple Graph Neural Network for Recommendation](https://doi.org/10.1145/3701551.3703536) |  | 0 | Graph neural networks (GNNs) have demonstrated superior performance in collaborative recommendation through their ability to conduct high-order representation smoothing, effectively capturing structural information within users' interaction patterns. However, existing GNN paradigms face significant challenges in scalability and robustness when handling large-scale, noisy, and real-world datasets. To address these challenges, we present LightGNN, a lightweight and distillation-based GNN pruning framework designed to substantially reduce model complexity while preserving essential collaboration modeling capabilities. Our LightGNN framework introduces a computationally efficient pruning module that adaptively identifies and removes redundant edges and embedding entries for model compression. The framework is guided by a resource-friendly hierarchical knowledge distillation objective, whose intermediate layer augments the observed graph to maintain performance, particularly in high-rate compression scenarios. Extensive experiments on public datasets demonstrate LightGNN's effectiveness, significantly improving both computational efficiency and recommendation accuracy. Notably, LightGNN achieves an 80 while maintaining performance comparable to more complex state-of-the-art baselines. The implementation of our LightGNN framework is available at the github repository: https://github.com/HKUDS/LightGNN. | Guoxuan Chen, Lianghao Xia, Chao Huang |  |
|  |  [Your Causal Self-Attentive Recommender Hosts a Lonely Neighborhood](https://doi.org/10.1145/3701551.3703587) |  | 0 | In the context of sequential recommendation, a pivotal issue pertains to the comparative analysis between bi-directional/auto-encoding (AE) and uni-directional/auto-regressive (AR) attention mechanisms, where the conclusions regarding architectural and performance superiority remain inconclusive. Previous efforts in such comparisons primarily involve summarizing existing works to identify a consensus or conducting ablation studies on peripheral modeling techniques, such as choices of loss functions. However, far fewer efforts have been made in (1) theoretical and (2) extensive empirical analysis of the self-attention module, the very pivotal structure on which performance and designing insights should be anchored. In this work, we first provide a comprehensive theoretical analysis of AE/AR attention matrix in the aspect of (1) sparse local inductive bias, a.k.a neighborhood effects, and (2) low rank approximation. Analytical metrics reveal that the AR attention exhibits sparse neighborhood effects suitable for generally sparse recommendation scenarios. Secondly, to support our theoretical analysis, we conduct extensive empirical experiments on comparing vanilla and variant AE/AR attention on five popular benchmarks with AR performing better overall. Results based on adaptive tuning, modularized design and Huggingface are reported. Lastly, we shed light on future design choices for performant self-attentive recommenders. We make our code and data available at https://github.com/yueqirex/Self-Attention-Direction-Check. | Yueqi Wang, Zhankui He, Zhenrui Yue, Julian J. McAuley, Dong Wang |  |
|  |  [Explainable CTR Prediction via LLM Reasoning](https://doi.org/10.1145/3701551.3703551) |  | 0 | Recommendation Systems have become integral to modern user experiences, but lack transparency in their decision-making processes. Existing explainable recommendation methods are hindered by reliance on a post-hoc paradigm, wherein explanation generators are trained independently of the underlying recommender models. This paradigm necessitates substantial human effort in data construction and raises concerns about explanation reliability. In this paper, we present ExpCTR, a novel framework that integrates large language model based explanation generation directly into the CTR prediction process. Inspired by recent advances in reinforcement learning, we employ two carefully designed reward mechanisms, LC alignment, which ensures explanations reflect user intentions, and IC alignment, which maintains consistency with traditional ID-based CTR models. Our approach incorporates an efficient training paradigm with LoRA and a three-stage iterative process. ExpCTR circumvents the need for extensive explanation datasets while fostering synergy between CTR prediction and explanation generation. Experimental results demonstrate that ExpCTR significantly enhances both recommendation accuracy and interpretability across three real-world datasets. | Xiaohan Yu, Li Zhang, Chong Chen |  |
|  |  [Teach Me How to Denoise: A Universal Framework for Denoising Multi-modal Recommender Systems via Guided Calibration](https://doi.org/10.1145/3701551.3703507) |  | 0 | The surge in multimedia content has led to the development of Multi-Modal Recommender Systems (MMRecs), which use diverse modalities such as text, images, videos, and audio for more personalized recommendations. However, MMRecs struggle with noisy data caused by misalignment among modal content and the gap between modal semantics and recommendation semantics. Traditional denoising methods are inadequate due to the complexity of multi-modal data. To address this, we propose a universal guided in-sync distillation denoising framework for multi-modal recommendation (GUIDER), designed to improve MMRecs by denoising user feedback. Specifically, GUIDER uses a re-calibration strategy to identify clean and noisy interactions from modal content. It incorporates a Denoising Bayesian Personalized Ranking (DBPR) loss function to handle implicit user feedback. Finally, it applies a denoising knowledge distillation objective based on Optimal Transport distance to guide the alignment from modality representations to recommendation semantics. GUIDER can be seamlessly integrated into existing MMRecs methods as a plug-and-play solution. Experimental results on four public datasets demonstrate its effectiveness and generalizability. Our source code is available at https://github.com/Neon-Jing/Guider | Hongji Li, Hanwen Du, Youhua Li, Junchen Fu, Chunxiao Li, Ziyi Zhuang, Jiakang Li, Yongxin Ni | The Ohio State University, Columbus, USA; University of Glasgow, Glasgow, UK; Rutgers University, New Brunswick, USA; University of Science and Technoloogy of China, Hefei, China; Lanzhou University, Lanzhou, China; Shanghai Jiao Tong University, Shanghai, China; City University of Hong Kong, HongKong, China; National University of Singapore, Singapore, Singapore |
|  |  [DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems](https://doi.org/10.1145/3701551.3703572) |  | 0 | The integration of Large Language Models (LLMs) into recommender systems has led to substantial performance improvements. However, this often comes at the cost of diminished recommendation diversity, which can negatively impact user satisfaction. To address this issue, controllable recommendation has emerged as a promising approach, allowing users to specify their preferences and receive recommendations that meet their diverse needs. Despite its potential, existing controllable recommender systems frequently rely on simplistic mechanisms, such as a single prompt, to regulate diversity-an approach that falls short of capturing the full complexity of user preferences. In response to these limitations, we propose DLCRec, a novel framework designed to enable fine-grained control over diversity in LLM-based recommendations. Unlike traditional methods, DLCRec adopts a fine-grained task decomposition strategy, breaking down the recommendation process into three sequential sub-tasks: genre prediction, genre filling, and item prediction. These sub-tasks are trained independently and inferred sequentially according to user-defined control numbers, ensuring more precise control over diversity. Furthermore, the scarcity and uneven distribution of diversity-related user behavior data pose significant challenges for fine-tuning. To overcome these obstacles, we introduce two data augmentation techniques that enhance the model's robustness to noisy and out-of-distribution data. These techniques expose the model to a broader range of patterns, improving its adaptability in generating recommendations with varying levels of diversity. Our extensive empirical evaluation demonstrates that DLCRec not only provides precise control over diversity but also outperforms state-of-the-art baselines across multiple recommendation scenarios. | Jiaju Chen, Chongming Gao, Shuai Yuan, Shuchang Liu, Qingpeng Cai, Peng Jiang |  |
|  |  [HaGAR: Hardness-aware Generative Adversarial Recommender](https://doi.org/10.1145/3701551.3703569) |  | 0 | Implicit Collaborative filtering is a fundamental technique in recommendation systems, leveraging implicit user interactions to suggest items of interest. A significant challenge in this domain is the absence of explicit negative feedback, limiting the recommendation performance. Previous researchers have tried to tackle the challenge through the Generative Adversarial Network (GAN). The generator produces increasingly challenging samples for the discriminator, driving the optimization of the discrimination objective. Although GAN-style recommender systems can achieve decent performance by generating harder negative samples, the negatives selected by the generator may not always be ideal for training the discriminator. In this study, we focus on two types of undesirable negatives that persist in modern GAN-style recommenders: false negatives and uninformative negatives. In response to these issues, we propose a novel Hardness-aware Generative Adversarial Recommender (HaGAR). To the best of our knowledge, it is the first adversarial recommender that explicitly aims to alleviate the adverse impact of false and uninformative negatives. Our approach incorporates a relevance monitoring module and a hardness-aware weighting module to identify and address false and uninformative negatives during training with minimal additional computational cost. Our experimental results demonstrate that HaGAR significantly improves recommendation performance, achieving over a 21% increase in terms of NDCG@10 compared to the state-of-the-art GAN-style recommender. These findings highlight the efficacy of our improvement in providing more robust negative samples, leading to better-performing recommendation systems. | YuanHeng Lee, Josh JiaChing Ying, Vincent S. Tseng | National Chung Hsing University, Taichung, Taiwan; National Yang Ming Chiao Tung University, Hsinchu, Taiwan |
|  |  [Predicting Eviction Status Using Airbnb Data in the Absence of Ground-Truth Eviction Records](https://doi.org/10.1145/3701551.3703549) |  | 0 | The eviction of tenants is a pressing problem, which is prevalent among low-income renters in the USA, and has devastating consequences. Despite the presence of various measures to combat evictions, identifying high-need regions and tenant groups is highly challenging in many regions due to a lack of access to eviction records (partly because of some infrastructural/policy constraints). In response to this information gap, this paper proposes a solution driven by Machine Learning (ML) to monitor eviction status at various spatial resolutions using Airbnb data when ground-truth eviction data is inaccessible. In particular, we begin by demonstrating the potential of utilizing Airbnb data to build ML-driven methods for distinguishing different neighborhoods across different spatial resolutions with respect to eviction status. We then proceed to develop an ML model capable of learning eviction status levels from Airbnb data, even in the absence of ground-truth labels. Empirical evidence is presented, showcasing the model's performance on par with several robust fully-supervised ML models that had access to ground-truth labels during training. Finally, we conduct a set of cross-region tests to comprehensively study the generalizability of the achieved performance across various unseen regions in the USA that were not used during model training. The code of this project can be accessed via https://github.com/maryam-tabar/Airbnb-Eviction. | Maryam Tabar, Anusha Abdulla, J. Andrew Petersen, Dongwon Lee | The Pennsylvania State University, University Park, PA, USA; University of Texas at San Antonio, San Antonio, TX, USA |
|  |  [MCRanker: Generating Diverse Criteria On-the-Fly to Improve Pointwise LLM Rankers](https://doi.org/10.1145/3701551.3703583) |  | 0 | The most recent pointwise Large Language Model (LLM) rankers have achieved remarkable ranking results. However, these rankers are hindered by two major drawbacks: (1) they fail to follow a standardized comparison guidance during the ranking process, and (2) they struggle with comprehensive considerations when dealing with diverse semantics of the query and complicated info in the passages. To address these shortcomings, we propose to build a zero-shot pointwise ranker that first recruits a virtual annotation team to generate query-based criteria from various perspectives and then uses these criteria to conduct an ensemble passage evaluation. Additionally, we are among the first to explore how criteria can be generated automatically and used in text ranking tasks. Our method, tested on eight datasets from the BEIR benchmark, demonstrates that incorporating this multi-perspective criteria ensemble approach significantly enhanced the performance of pointwise LLM rankers. | Fang Guo, Wenyu Li, Honglei Zhuang, Yun Luo, Yafu Li, Le Yan, Qi Zhu, Yue Zhang | Zhejiang University, Hangzhou, China; Google, Mountain View, USA; Westlake University, Hangzhou, China; South China University of Technology, Guangzhou, China; Google, Seattle, USA; Zhejiang University, Hanghzou, China |
|  |  [Adaptive Loss-based Curricula for Neural Team Recommendation](https://doi.org/10.1145/3701551.3703574) |  | 0 | Neural team recommendation models have excelled at recommending collaborative teams of experts who, more likely than not, can solve complex tasks. Yet, they suffer from popularity bias due to the disproportionate distribution of popular experts over many teams and the sparse long-tailed distribution of non-popular ones in training datasets, overlooking the difficulty of recommending hard non-popular vs. easy popular experts. To bridge the gap, we propose three curriculum-based learning strategies to empower neural team recommenders sifting through easy popular and hard non-popular experts and to mitigate popularity bias and improve upon them. We propose (1) a parametric curriculum that assigns a learnable parameter to each expert enabling the model to learn an expert's levels of difficulty (or conversely, levels of popularity) during training, (2) a parameter-free (non-parametric) curriculum that presumes the worst-case difficulty for each expert based on the model's loss, and (3) a static curriculum to provide a minimum base for comparison amongst curriculum-based learning strategies and lack thereof. Our experiments on two benchmark datasets with distinct distributions of teams over skills showed that our parameter-free curriculum improved the performance of non-variational models across different domains, outperforming its parametric counterpart, and the static curriculum was the poorest. Moreover, among neural models, variational models obtain little to no gain from our proposed curricula, urging further research on more effective curricula for them. The code to reproduce our experiments is publically available at https://github.com/fani-lab/OpeNTF/tree/cl-wsdm25. | Reza Barzegar, Marco Nikola Kurepa, Hossein Fani | School of Computer Science, University of Windsor, Windsor, ON, Canada; Vincent Massey Secondary School, Windsor, ON, Canada |
|  |  [UniGLM: Training One Unified Language Model for Text-Attributed Graphs Embedding](https://doi.org/10.1145/3701551.3703586) |  | 0 | Representation learning on text-attributed graphs (TAGs), where nodes are represented by textual descriptions, is crucial for textual and relational knowledge systems and recommendation systems. Currently, state-of-the-art embedding methods for TAGs primarily focus on fine-tuning language models (e.g., BERT) using structure-aware training signals. While effective, these methods are tailored for individual TAG and cannot generalize across various graph scenarios. Given the shared textual space, leveraging multiple TAGs for joint fine-tuning, aligning text and graph structure from different aspects, would be more beneficial. Motivated by this, we introduce a novel Unified Graph Language Model (UniGLM) framework, the first graph embedding model that generalizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM is trained over multiple TAGs with different domains and scales using self-supervised contrastive learning. UniGLM includes an adaptive positive sample selection technique for identifying structurally similar nodes and a lazy contrastive module that is devised to accelerate training by minimizing repetitive encoding calculations. Extensive empirical results across 9 benchmark TAGs demonstrate UniGLM's efficacy against leading embedding baselines in terms of generalization (various downstream tasks and backbones) and transfer learning (in and out of domain scenarios). The code is available at https://github.com/NYUSHCS/UniGLM. | Yi Fang, Dongzhe Fan, Sirui Ding, Ninghao Liu, Qiaoyu Tan |  |
|  |  [Query Performance Prediction: Theory, Techniques and Applications](https://doi.org/10.1145/3701551.3703480) |  | 0 | Query performance prediction (QPP) is a key task in information retrieval (IR), focusing on estimating the retrieval quality of a given query without relying on human-labeled relevance judgments. Over the decades, QPP has gained increasing significance, with a surge in research activity in recent years. It has proven to benefit various aspects of retrieval, such as optimizing retrieval effectiveness by selecting the most appropriate ranking function for each query. Despite its critical role, there were only a few tutorials that cover the QPP techniques. The topic is even playing a more important role in the new era of pre-trained and large language models (LLMs), and the emerging fields of multi-agent intelligent systems and conversational search (CS ). Moreover, while research in QPP has yielded promising outcomes, studies on its practical application and integration into real-world search engines remain limited. This tutorial has four main objectives. First, it aims to cover both the fundamentals and the latest advancements in QPP methods. Second, it broadens the scope of QPP beyond ad-hoc search to various search scenarios, e.g., CS and image search. Third, this tutorial provides a comprehensive review of QPP applications across various aspects of IR, providing insights on where and how to apply QPP in practice. Fourth, we equip participants with hands-on materials, enabling them to apply QPP implementation in practice. This tutorial seeks to benefit both researchers and practitioners in IR, encouraging further exploration and innovation in QPP. | Negar Arabzadeh, Chuan Meng, Mohammad Aliannejadi, Ebrahim Bagheri | University of Waterloo, Waterloo, Canada; University of Amsterdam, Amsterdam, NL; Toronto Metropolitan University, Toronto, Canada |
|  |  [HTEA: Heterogeneity-aware Embedding Learning for Temporal Entity Alignment](https://doi.org/10.1145/3701551.3703588) |  | 0 | Temporal entity alignment (TEA), which identifies equivalent entities across temporal knowledge graphs (TKGs), plays a vital role in integrating multiple TKGs.Simply adapting traditional EA models to TKGs cannot achieve satisfactory results, driving the need for dedicated studies in TEA. However, existing TEA models often fail to effectively capture the importance of temporal features and the richness of temporal context during embedding learning. Moreover, the challenge of temporal heterogeneity, which is prevalent in real-world TKGs, has not been adequately studied. In this work, we propose a HTEA framework to address these limitations. Specifically, we introduce a frequency-based temporal embedding module that incorporates the importance of temporal features for each entity, along with a temporal attention mechanism that prioritizes more informative context based on temporal richness. We further design an iterative module to detect temporal heterogeneity and refine the related facts accordingly. In this way, entity embeddings can be improved progressively, yielding more accurate and consistent alignment outcomes.Extensive experiments showcase the efficacy of our HTEA model, especially under the existence of temporal heterogeneity in real-world TKGs. | Jiayun Li, Wen Hua, Fengmei Jin, Xue Li | The Unversity of Queensland, Brisbane, QLD, Australia; The Hong Kong Polytechnic University, Hong Kong SAR, China; The University of Queensland, Brisbane, QLD, Australia |
|  |  [Advances in Vector Search](https://doi.org/10.1145/3701551.3703482) |  | 0 | Whether a text document is freed from the rules of grammar, stripped of word order, and thereby turned into a bag of words, or whether its semantic nuances learnt and condensed into an embedding space, its final representation is the same mathematical object: a vector. In fact, vectors represent much more than just text documents. Any object, be it a document or query, that contains text, images, speech, or a mix of these modalities, is often represented as a vector. Collect a large enough quantity of these vectors and the fundamental question of retrieval from the Information Retrieval (IR) discipline becomes urgently relevant: Finding k vectors that are more similar to a query. This full-day tutorial is concerned with the question above and intends to cover foundational concepts and advanced algorithms for vector retrieval or vector search. The tutorial begins with a focus on foundational concepts, including a brief history from space partitioning, to locality-sensitive hashing, graph-based, and clustering-based methods. As we discuss each class of solutions, we show failure scenarios and explain why they prove insufficient. We conclude the tutorial by turning our attention in the second half to recent developments for maximum inner product search over dense and sparse vectors, as well as open questions that need further research. Through this tutorial, we wish to recap the fascinating topic of retrieval in modern IR for the community, lower barriers of entry into this rich area of research, and inspire interest in conducting research on the underlying theoretical and empirical questions that are specific to IR. | Sebastian Bruch | Northeastern University, Boston, MA, USA |
|  |  [Tutorial on Recommendation with Generative Models (Gen-RecSys)](https://doi.org/10.1145/3701551.3703485) |  | 0 | This intermediate-level tutorial, titled "Gen-RecSys", merges both industrial and academic perspectives on recent advances in Generative AI for recommender systems (beyond LLMs). It aims to highlight the transformative role of generative models in modern recommender systems, which have significantly impacted the AI field-particularly with the rise of large language models (LLMs) like ChatGPT-and have contributed to a rapid convergence of the fields of search, data mining, and recommendation. By providing attendees with a modern perspective on GenAI applications in recommendation, the tutorial will emphasize how generative models can drive recommendation by unlocking and interacting with rich data representations, including behavioral, textual, and multi-modal data-knowledge highly transferable across many applications of interest to the WSDM community. Participants will learn about the categorization of generative models in recommender systems based on underlying data modalities: (i) ID-based collaborative models, (ii) text-driven models such as LLMs, and (iii) multi-modal models. Within each category, various deep generative model paradigms (e.g., AR, GAN, diffusion models) will be introduced, along with insights into their application areas. The tutorial will also cover evaluation aspects, including benchmarks, metrics, and assessments of social and ethical impacts and harms. This tutorial presents a condensed version of the industrial and academic work featured in the forthcoming book at FntIR 2024-25, titled "Recommendation with Generative Models [7]," and a shorter version prepared, and presented by the team, see GenRecSys-Survey [6]. | Yashar Deldjoo, Zhankui He, Julian J. McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, René Vidal, Maheswaran Sathiamoorthy, Atoosa Kasirzadeh, Silvia Milano | Bespoke Labs, Santa Clara, CA, USA; Amazon, Palo Alto, CA, USA; University of Toronto, Toronto, ON, Canada; University of Edinburgh, Edinburgh, United Kingdom; Polytechnic University of Bari, Bari, Italy; University of Pennsylvania, Palo Alto, PA, USA; UCSD, La Jolla, CA, USA; University of Exeter and LMU Munich, Munich, Germany |
|  |  [Bridging Historical Subgraph Optimization and Modern Graph Neural Network Approaches in Team Recommendation](https://doi.org/10.1145/3701551.3703483) |  | 0 | Team recommendation involves selecting experts with certain skills to form a successful task-oriented team. This tutorial provides a comprehensive study of conventional graph-based and a detailed review of cutting-edge neural network-based methods through unified definitions and formulations, along with insights into future research directions and real-world applications. | Mahdis Saeedi, Christine Wong, Hossein Fani | University of Windsor, Windsor, ON, Canada |
|  |  [Robust Information Retrieval](https://doi.org/10.1145/3701551.3703476) |  | 0 | Beyond effectiveness, the robustness of an information retrieval (IR) systemis increasingly attracting attention. When deployed, a critical technology suchas IR should not only deliver strong performance on average but also have theability to handle a variety of exceptional situations. In recent years,research into the robustness of IR has seen significant growth, with numerousresearchers offering extensive analyses and proposing myriad strategies toaddress robustness challenges. In this tutorial, we first provide backgroundinformation covering the basics and a taxonomy of robustness in IR. Then, weexamine adversarial robustness and out-of-distribution (OOD) robustness withinIR-specific contexts, extensively reviewing recent progress in methods toenhance robustness. The tutorial concludes with a discussion on the robustnessof IR in the context of large language models (LLMs), highlighting ongoingchallenges and promising directions for future research. This tutorial aims togenerate broader attention to robustness issues in IR, facilitate anunderstanding of the relevant literature, and lower the barrier to entry forinterested researchers and practitioners. | YuAn Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke | Univ Amsterdam, Amsterdam, Netherlands; Univ Chinese Acad Sci, CAS Key Lab Network Data Sci & Technol, ICT, CAS, Beijing, Peoples R China |
|  |  [Towards Secure and Robust Recommender Systems: A Data-Centric Perspective](https://doi.org/10.1145/3701551.3703484) |  | 0 | As recommender systems (RS) continue to evolve, the field has seen a pivotal shift from model-centric to data-centric paradigms, where the quality, integrity, and security of data are increasingly becoming the key drivers of system performance and personalization. This transformation has unlocked new avenues for more precise recommendations, yet it also introduces significant challenges. As reliance on data intensifies, RS face mounting threats that can compromise both their effectiveness and user trust. These challenges include (1) Malicious Data Manipulation, where adversaries corrupt or tamper with datasets, distorting recommendation outcomes and undermining system reliability; (2) Data Privacy Leakage, where adversarial actors exploit system outputs to infer sensitive user information, leading to serious privacy concerns; and (3) Erroneous Data Noise, where inaccuracies, inconsistencies, and redundant data obscure the true user preferences, degrading recommendation quality and user satisfaction. By focusing on these critical data-centric challenges, this tutorial aims to equip participants with the knowledge to build RS that are secure, privacy-preserving, and resilient to data-driven threats, ensuring reliable and trustworthy performance in real-world environments. In addition, attendees will gain hands-on experience with our newly released toolkit for RS-based attacks and defenses, providing them with practical, actionable insights into safeguarding RS against emerging vulnerabilities. | Zongwei Wang, Junliang Yu, Tong Chen, Hongzhi Yin, Shazia Sadiq, Min Gao | The University of Queensland, Brisbane, Australia; The University of Queesland, Brisbane, Australia; Chongqing University, Chongqing, China |
|  |  [Integrating Knowledge Graphs and Neuro-Symbolic AI: LDM Enables FAIR and Federated Research Data Management](https://doi.org/10.1145/3701551.3704125) |  | 0 | Managing research digital objects (RDOs) in compliance with FAIR principles is crucial for ensuring accessibility, interoperability, and reusability across scientific domains. The Leibniz Data Manager (LDM) is a state-of-the-art framework that integrates Knowledge Graphs (KGs) and Neuro-Symbolic AI, combining the reasoning power of Large Language Models (LLMs) with structured metadata. LDM supports the management and enhancement of RDOs through entity linking, connecting datasets to external KGs like Wikidata and the Open Research Knowledge Graph (ORKG). Additionally, LDM offers federated query processing across KGs, enabling users to explore related papers, datasets, and resources through natural language questions. This demo showcases LDM's capabilities to explore RDOs, compare existing datasets, and extend metadata. By blending Neuro-Symbolic AI with FAIR and federated research data management, LDM offers a powerful tool for accelerating data-driven discovery in science. LDM is publicly accessible at https://service.tib.eu/ldmservice/. | Ahmad Sakor, Mauricio Brunet, Enrique Iglesias, Ariam Rivas, Philipp D. Rohde, Angelina Kraft, MariaEsther Vidal | TIB-Leibniz Information Centre for Science and Technology, Hannover, Germany; TIB -- Leibniz Information Centre for Science and Technology, Hannover, Germany; Leibniz University Hannover & L3S Research Center, Hannover, Germany |
|  |  [Don't Forget This: Augmenting Results with Event-Aware Search](https://doi.org/10.1145/3701551.3704119) |  | 0 | Events like Valentine's Day and Christmas can influence user intent when interacting with search engines. For example, a user searching for gift around Valentine's Day is likely to be looking for Valentine's-themed options, whereas the same query close to Christmas would more likely suggest an interest in Holiday-themed gifts. These shifts in user intent, driven by temporal factors, are often implicit but important to determine the relevance of search results. In this demo, we explore how incorporating temporal awareness can enhance search relevance in an e-commerce setting. We constructed a database of 2K events and, using historical purchase data, developed a temporal model that estimates each event's importance on a specific date. The most relevant events on the date the query was issued are then used to enrich search results with event-specific items. Our demo illustrates how this approach enables a search system to better adapt to temporal nuances, ultimately delivering more contextually relevant products. | Hugo Sousa, Austin R. Ward, Omar Alonso | Amazon, Palo Alto, CA, USA; INESC TEC, University of Porto, Porto, Portugal; Amazon, Seattle, WA, USA |
|  |  [Lightning IR: Straightforward Fine-tuning and Inference of Transformer-based Language Models for Information Retrieval](https://doi.org/10.1145/3701551.3704118) |  | 0 | A wide range of transformer-based language models have been proposed for information retrieval tasks. However, fine-tuning and inference of these models is often complex and requires substantial engineering effort. This paper introduces Lightning IR, a PyTorch Lightning-based framework for fine-tuning and inference of transformer-based language models for information retrieval. Lightning IR provides a modular and extensible architecture that supports all stages of an information retrieval pipeline: from fine-tuning and indexing to searching and re-ranking. It is designed to be straightforward to use, scalable, and reproducible. Lightning IR is available as open-source: https://github.com/webis-de/lightning-ir. | Ferdinand Schlatt, Maik Fröbe, Matthias Hagen |  |
|  |  [Evidence Contextualization and Counterfactual Attribution for Conversational QA over Heterogeneous Data with RAG Systems](https://doi.org/10.1145/3701551.3704126) |  | 0 | Retrieval Augmented Generation (RAG) works as a backbone for interacting with an enterprise's own data via Conversational Question Answering (ConvQA). In a RAG system, a retriever fetches passages from a collection in response to a question, which are then included in the prompt of a large language model (LLM) for generating a natural language (NL) answer. However, several RAG systems today suffer from two shortcomings: (i) retrieved passages usually contain their raw text and lack appropriate document context, negatively impacting both retrieval and answering quality; and (ii) attribution strategies that explain answer generation usually rely only on similarity between the answer and the retrieved passages, thereby only generating plausible but not causal explanations. In this work, we demonstrate RAGONITE, a RAG system that remedies the above concerns by: (i) contextualizing evidence with source metadata and surrounding text; and (ii) computing counterfactual attribution, a causal explanation approach where the contribution of an evidence to an answer is determined by the similarity of the original response to the answer obtained by removing that evidence. To evaluate our proposals, we release a new benchmark ConfQuestions, with 300 hand-created conversational questions, each in English and German, coupled with ground truth URLs, completed questions, and answers from 215 public Confluence pages, that are typical of enterprise wiki spaces with heterogeneous elements. Experiments with RAGONITE on ConfQuestions show the viability of our ideas: contextualization improves RAG performance, and counterfactual attribution is effective at explaining RAG answers. | Rishiraj Saha Roy, Joel Schlotthauer, Chris Hinze, Andreas Foltyn, Luzian Hahn, Fabian Küch |  |
|  |  [Advancing Voice AI for E-commerce: Tracking ASR Model Performance at Scale](https://doi.org/10.1145/3701551.3706130) |  | 0 | Traditionally, automatic speech recognition (ASR) systems rely on human transcriptions to calculate word error rate (WER) by comparing ASR outputs to manual transcriptions. Recently, Amazon's mobile voice shopping platform stopped storing audio from incoming requests to enhance customer privacy, making offline, human-based evaluation unfeasible. This presentation introduces a multitask Speech LLM-based system that processes real-time audio, extracting key features to track ASR performance and detect traffic shifts-all without storing audio or requiring human annotations. Additionally, we demonstrate how combining these features with a synthetic audio generation model (TTS) enables accurate detection of ASR performance degradation, ensuring continuous optimization of the customer voice experience. | Dhruv Agarwal, Nupur Neti, Federica Cerina | Amazon, Seattle, WA, USA |
|  |  [Beyond Relevance: A Demand Balancer Model for Rental Platforms with Single-Unit Inventory](https://doi.org/10.1145/3701551.3706126) |  | 0 | House rental marketplace platforms face unique challenges due to their single-unit inventory nature, where each property is distinct and can only be rented to one tenant. Traditional ranking systems typically optimize for user-item fit [1--5]. For the rental market, this optimization creates demand bottlenecks by continuously directing users to already popular properties. This approach results in high-competition scenarios where multiple users are drawn to the same high-relevance properties, generating excessive competing offers. This can lead to user frustration, as only one individual can ultimately secure the property, leaving others dissatisfied despite their high compatibility with the listing. At the same time, given the nature of property technology businesses being inherently supply-constrained, demand concentration negatively impacts landlords as well, creating challenges for those struggling to rent out their properties, facing longer vacancy periods and increasing the risk of renting elsewhere. To redistribute demand across our house rental marketplace, our solution incorporates the likelihood of successful conversion based on historical user-house interaction signals, including visits, offers, and others. By dynamically adjusting property visibility based on predicted rental probability, we effectively redistribute user attention to low demand properties while minimizing losses in relevance. The implementation of this system in a large-scale rental marketplace through an online controlled experiment resulted in 4% increase in unique houses receiving offers from users and a 3% improvement in contract conversion rates. These results suggest that incorporating availability predictions into ranking systems can lead to more efficient marketplace dynamics while maintaining user satisfaction, without impacting user engagement. Our approach provides a framework for balancing demand in marketplaces with unique inventory constraints. | Guilherme G. Bonaldo, Pedro F. Nogueira, Tetiana Torovets, Thays F. da Silva | QuintoAndar, Lisbon, Portugal |
|  |  [LLM4Eval@WSDM 2025: Large Language Model for Evaluation in Information Retrieval](https://doi.org/10.1145/3701551.3705706) |  | 0 | Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference. This is the second iteration of the workshop. The first version was held in conjunction with SIGIR 2024, attracting over 50 participants. | Hossein A. Rahmani, Clemencia Siro, Mohammad Aliannejadi, Nick Craswell, Charles L. A. Clarke, Guglielmo Faggioli, Bhaskar Mitra, Paul Thomas, Emine Yilmaz | University College London & Amazon, London, United Kingdom; University of Amsterdam, Amsterdam, The Netherlands; University of Waterloo, Waterloo, ON, Canada; Microsoft, Montréal, Canada; Microsoft, Adelaide, Australia; University of Padova, Padua, Italy; Microsoft, Bellevue, USA; University College London, London, United Kingdom |
|  |  [VARIUM: Variational Autoencoder for Multi-Interest Representation with Inter-User Memory](https://doi.org/10.1145/3701551.3703558) |  | 0 | Frameworks for discovering multiple user interest factors based on Variational AutoEncoder (VAE) has demonstrated competitive recommendation performance. However, as VAE only considers one user as input at a time, sharing across like-minded users may not be adequately facilitated. Moreover, interest sharing between users is not always available and thus, poses a challenge for VAE to explicitly model this information. To resolve this, we introduce an inter-user memory-based mechanism to unsupervisedly discover latent interest sharing between users under VAE framework. Concretely, we design a memory including an array of prototypes, each hypothetically representing a group of users sharing a particular interest. These memory prototypes are jointly trained with the backbone VAE-based recommendation model. For each user, we first discover multiple intra-user interest factors behind their item adoptions. Next, intra-user interest factors query to memory to retrieve the inter-user interest clues from like-minded users. This query-retrieve process is performed sequentially via a series of attention-transformation steps. Then, interest clues retrieved from memory are incorporated into interest factor representations of each user to increase their expressiveness. Thorough experiments on real-world datasets verify the strength of our method over an array of baselines. We further conduct qualitative analysis to understand the inner working of our memory-based refinement approach. | NhuThuat Tran, Hady W. Lauw | School of Computing and Information Systems, Singapore Management University, Singapore, Singapore |
|  |  [Dynamic Interaction-Driven Intent Evolver with Semantic Probability Distributions](https://doi.org/10.1145/3701551.3703508) |  | 0 | Accurately capturing a user's dynamic search intent based on her/his interactions with the system is crucial for improving the performance of session-based search. Existing methods often require the entire interaction sequence within a session to be recomputed continuously at each interaction step, and the token-level interactions are either captured within an overall transformer structure or simply ignored. As a consequence, the current approaches suffer from an increased computation burden and fall short of accurately capturing the dynamic evolution of user intent. In this paper, we propose a novel representation approach which treats both search intent and candidate documents as dimension-specific probability distributions of token embedding representations. Based on this representation, we propose an Dynamic Interaction-Driven intent Evolver (DIDE) for dynamically updating the user's search intent throughout a session with a lightweight similarity calculation method for document ranking. Comprehensive experimental results demonstrate that DIDE adeptly captures the dynamic nature of session-based search and significantly outperforms a range of strong baseline models across three different datasets. | Zelin Li, Cheng Zhang, Dawei Song | Tianjin University of Finance and Economics, Tianjin, China; Beijing Institute of Technology, Beijing, China |
|  |  [Efficient Creative Selection in Online Advertising using Top-Two Thompson Sampling](https://doi.org/10.1145/3701551.3706128) |  | 0 | In online advertising, identifying the optimal creative is critical to maximizing performance. This study examines the application of top-two Thompson sampling (TTTS), an adaptive experimental design method, as an efficient alternative to traditional A/B testing for identifying the optimal creative. Our experiments on an online advertising platform highlight the effectiveness of TTTS in both accurately identifying the optimal creative and minimizing experimental costs, underscoring its potential as a promising approach to creative selection. | Daiki Katsuragawa, Yusuke Kaneko, Kaito Ariu, Kenshi Abe | CyberAgent, Tokyo, Japan |
|  |  [Polaris: Sampling from the Multigraph Configuration Model with Prescribed Color Assortativity](https://doi.org/10.1145/3701551.3703560) |  | 0 | We introduce Polaris, a network null model for colored multi-graphs that preserves the Joint Color Matrix. Polaris is specifically designed for studying network polarization, where vertices belong to a side in a debate or a partisan group, represented by a vertex color, and relations have different strengths, represented by an integer-valued edge multiplicity. The key feature of Polaris is preserving the Joint Color Matrix (JCM) of the multigraph, which specifies the number of edges connecting vertices of any two given colors. The JCM is the basic property that determines color assortativity, a fundamental aspect in studying homophily and segregation in polarized networks. By using Polaris, network scientists can test whether a phenomenon is entirely explained by the JCM of the observed network or whether other phenomena might be at play. Technically, our null model is an extension of the configuration model: an ensemble of colored multigraphs characterized by the same degree sequence and the same JCM. To sample from this ensemble, we develop a suite of Markov Chain Monte Carlo algorithms, collectively named Polaris-\*. It includes Polaris-B, an adaptation of a generic Metropolis-Hastings algorithm, and Polaris-C, a faster, specialized algorithm with higher acceptance probabilities. This new null model and the associated algorithms provide a more nuanced toolset for examining polarization in social networks, thus enabling statistically sound conclusions. | Giulia Preti, Matteo Riondato, Aristides Gionis, Gianmarco De Francisci Morales |  |
|  |  [Maintaining k-MinHash Signatures over Fully-Dynamic Data Streams with Recovery](https://doi.org/10.1145/3701551.3703491) |  | 0 | We consider the task of performing Jaccard similarity queries over a large collection of items that are dynamically updated according to a streaming input model. An item here is a subset of a large universe U of elements. A well-studied approach to address this important problem in data mining is to design fast-similarity data sketches. In this paper, we focus on global solutions for this problem, i.e., a single data structure which is able to answer both Similarity Estimation and All-Candidate Pairs queries, while also dynamically managing an arbitrary, online sequence of element insertions and deletions received in input. We introduce and provide an in-depth analysis of a dynamic, buffered version of the well-known k-MinHash sketch. This buffered version better manages critical update operations thus significantly reducing the number of times the sketch needs to be rebuilt from scratch using expensive recovery queries. We prove that the buffered k-MinHash uses O(k log \|U\|) memory words per subset and that its amortized update time per insertion/deletion is O(k log \|U\|) with high probability. Moreover, our data structure can return the k-MinHash signature of any subset in O(k) time, and this signature is exactly the same signature that would be computed from scratch (and thus the quality of the signature is the same as the one guaranteed by the static k-MinHash). Analytical and experimental comparisons with the other, state-of-the-art global solutions for this problem given in [Bury et al.,WSDM'18] show that the buffered k-MinHash turns out to be competitive in a wide and relevant range of the online input parameters. | Andrea Clementi, Luciano Gualà, Luca Pepè Sciarria, Alessandro Straziota |  |
|  |  [Cross-Domain Pre-training with Language Models for Transferable Time Series Representations](https://doi.org/10.1145/3701551.3703498) |  | 0 | Pre-training universal models across multiple domains to enhance downstream tasks is a prevalent learning paradigm. However, there has been minimal progress in pre-training transferable models across domains for time series representation. This dilemma is incurred by two key factors: the limited availability of training set within each domain and the substantial differences in data characteristics between domains. To address these challenges, we present a novel framework, namely CrossTimeNet, designed to perform cross-domain self-supervised pre-training to benefit target tasks. Specifically, to address the issue of data scarcity, we utilize a pre-trained language model as the backbone network to effectively capture the sequence dependencies of the input time series. Meanwhile, we adopt the recovery of corrupted region inputs as a self-supervised optimization objective, taking into account the locality of the time series. To address discrepancies in data characteristics, we introduce a novel tokenization module that converts continuous time series inputs into discrete token sequences using vector quantization techniques. This approach facilitates the learning of transferable time series models across different domains. Extensive experimental results on diverse time series tasks, including classification and forecasting, demonstrate the effectiveness of our approach. Our codes are publicly available at https://github.com/Mingyue-Cheng/CrossTimeNet. | Mingyue Cheng, Xiaoyu Tao, Qi Liu, Hao Zhang, Yiheng Chen, Defu Lian |  |
|  |  [Beyond Answers: Transferring Reasoning Capabilities to Smaller LLMs Using Multi-Teacher Knowledge Distillation](https://doi.org/10.1145/3701551.3703577) |  | 0 | Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a new knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing Chain-of-Thought strategy to ensure that the rationales are accurate and grounded in contextually appropriate scenarios. Extensive experiments on six datasets across two reasoning tasks demonstrate the superiority of our method. Results show that TinyLLM can outperform large teacher LLMs significantly, despite a considerably smaller model size. The source code is available at: https://github.com/YikunHan42/TinyLLM. | Yijun Tian, Yikun Han, Xiusi Chen, Wei Wang, Nitesh V. Chawla | University of Notre Dame; University of California; University of Michigan |
|  |  [Do Stubborn Users Always Cause More Polarization and Disagreement? A Mathematical Study](https://doi.org/10.1145/3701551.3703510) |  | 0 | We study how the stubbornness of social network users influences opinion polarization and disagreement. Our work is in the context of the popular Friedkin-Johnson opinion formation model, where users update their opinion as a function of the opinion of their connections and their own innate opinion. Stubbornness then is formulated in terms of the stress a user puts on its innate opinion. We examine two scenarios: one where all nodes have uniform stubbornness levels (homogeneous) and another where stubbornness varies among nodes (inhomogeneous). In the homogeneous scenario, we prove that as the network's stubbornness factor increases, the polarization and disagreement index grows. In the more general inhomogeneous scenario, our findings surprisingly demonstrate that increasing the stubbornness of some users (particularly, neutral/unbiased users) can reduce the polarization and disagreement. We characterize specific conditions under which this phenomenon occurs. Finally, we conduct an extensive set of experiments on real-world network data to corroborate and complement our theoretical findings. | Mohammad Shirzadi, Ahad N. Zehmakan |  |
|  |  [BAKER: Bayesian Kernel Uncertainty in Domain-Specific Document Modelling](https://doi.org/10.1145/3701551.3703517) |  | 0 | In critical domains such as healthcare and law, accurately modelling the uncertainty of automatic computational models is essential. For instance, healthcare models must produce reliable estimates to guide human decision-making. However, modelling uncertainty remains challenging, particularly for models handling low-resource datasets and complex, domain-specific vocabulary. Most existing predictive models model point estimates rather than probability distributions, limiting our ability to quantify model uncertainty. This paper introduces a novel model, BAKER, designed to address these limitations. BAKER combines the strengths of Bayesian inference, known for its effectiveness in modelling uncertainty, and kernel methods, which excel at capturing complex data relationships. Incorporating kernel functions enhances model performance, particularly by reducing overfitting in data-limited scenarios. Our experimental analysis shows that BAKER significantly improves uncertainty reasoning compared to existing models. | Ubaid Azam, Imran Razzak, Shelly Vishwakarma, Hakim Hacid, Dell Zhang, Shoaib Jameel | Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Institute of Artificial Intelligence (TeleAI), China Telecom, Shanghai, China; University of Southampton, Southampton, United Kingdom |
|  |  [Progressive Tasks Guided Multi-Source Network for Customer Lifetime Value Prediction in Online Advertising](https://doi.org/10.1145/3701551.3703533) |  | 0 | Customer lifetime value (LTV) is crucial to companies who are intending to adopt personalized promoting strategies to optimize the profits. However, LTV prediction in the scenario of online App advertising usually suffers from label sparsity issue, towards which existing methods designed complex model structures but ignored the information contained in intermediate user behaviors. Moreover, previous works mainly focus on fitting the overall LTV distribution, overlooking the fact that LTV in online App advertising consists of sources with diverse data distributions and thus resulting in sub-optimal solutions. In this paper, we propose a novel Progressive Tasks guided Multi-Source Network (PTMSN) to tackle the aforementioned problems. Specifically, a Cascaded Sub-task Module (CSM) is introduced to alleviate data sparsity by modeling reliance between explicit interactions and implicit monetization. In addition, as the overall LTV is assembled from multiple sources, we propose a divide-and-conquer scheme named Multi-source Integrating Module (MIM) to disentangle the original single target into several source distributions and model in a fine-grained manner. Extensive offline experiments on real-world industrial datasets compared to state-of-the-art baseline models validate the effectiveness of our approach. PTMSN has been successfully deployed in industrial online advertising system, serving various business scenarios and acquiring 2.97% absolute ROI gains. | Zheng Pan, Xingyu Lou, Xiao Jin, Chiye Ou, Feng Liu, Tieyong Zeng, Chengwei He, Xiang Liu, Lilong Wei, Jun Wang | OPPO Research Institute, Shenzhen, China, & The Chinese University of Hong Kong, Hong Kong, China; OPPO, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China; OPPO Research Institute, Shenzhen, China |
|  |  [Balancing Revenue and Privacy with Signaling Schemes in Online Ad Auctions](https://doi.org/10.1145/3701551.3703529) |  | 0 | In online ad auctions, when an Internet user's certain actions trigger an auction, the auctioneer (the platform) usually sends the information about the user to help the buyers better estimate their valuations. However, by strategically revealing only partial information, we cannot only improve the revenue of the auction, but also help protect the privacy of the user. In this paper, we propose a privacy measure in the online ad auction setting, and seek to maximize a convex combination of revenue and privacy. We formulate the problem as a convex optimization program and derive structural results and properties of the program. We prove that any combination coefficient achieves a certain fraction of the optimal revenue gain and privacy gain, and that we can trade-off between revenue and privacy by simply tuning the combination coefficient. We also show that the gap between the optimal revenue and the revenue achieved by revealing no information can be bounded by a certain valuation discrepancy between the buyers. We also conduct extensive experiments (on both synthetic and real data) to show the effectiveness of our method. | Hongtao Liu, Luxi Chen, Yiming Ding, Changcheng Li, Han Li, Peng Jiang, Weiran Shen | Kuaishou Technology, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China |
|  |  [D2: Customizing Two-Stage Graph Neural Networks for Early Rumor Detection through Cascade Diffusion Prediction](https://doi.org/10.1145/3701551.3703589) |  | 0 | Early rumor detection is crucial for mitigating the widespread dissemination of misinformation. Existing methods predominantly rely on complete rumor diffusion graphs, which are challenging to obtain in real-world scenarios, complicating early detection efforts. To address this challenge, we propose D2, a two-stage framework for early rumor Detection, integrating cascade Diffusion prediction. This framework aims to enhance early rumor detection by incorporating diffusion prediction capabilities. Specifically, a dynamic heterogeneous graph neural network (GNN) is developed to jointly model users' social and propagation graphs, enabling accurate prediction of potential diffusion paths using limited observed data within short time windows. The inferred diffusion paths are then integrated with early-stage data, and GNNs are employed for graph classification. However, the varying data distributions across different social media platforms necessitate extensive tuning to optimize GNN architectures. To facilitate the detection of rumor diffusion graphs at the initial stages, a search space is designed across four dimensions- aggregation, merge, readout, and sequence functions-encompassing various GNN architectures. Subsequently, D2 employs an efficient differentiable search algorithm to identify high-performance GNNs within this search space. Experimental results on real social media datasets demonstrate that this approach significantly improves both the accuracy and robustness of early rumor detection. | Haowei Xu, Chao Gao, Xianghua Li, Zhen Wang | School of Cybersecurity, Northwestern Polytechnical University, Xian, China |
|  |  [HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection](https://doi.org/10.1145/3701551.3703540) |  | 0 | Community detection plays a pivotal role in uncovering closely connected subgraphs, aiding various real-world applications such as recommendation systems and anomaly detection. With the surge of rich information available for entities in real-world networks, the community detection problem in attributed networks has attracted widespread attention. While previous research has effectively leveraged network topology and attribute information for attributed community detection, these methods overlook two critical issues: (i) the semantic similarity between node attributes within the community, and (ii) the inherent mesoscopic structure, which differs from the pairwise connections of the micro-structure. To address these limitations, we propose HACD, a novel attributed community detection model based on heterogeneous graph attention networks. HACD treats node attributes as another type of node, constructs attributed networks into heterogeneous graph structures and employs attribute-level attention mechanisms to capture semantic similarity. Furthermore, HACD introduces a community membership function to explore mesoscopic community structures, enhancing the robustness of detected communities. Extensive experiments demonstrate the effectiveness and efficiency of HACD, outperforming state-of-the-art methods in attributed community detection tasks. Our code is publicly available at https://github.com/Anniran1/HACD1-wsdm. | Anran Zhang, Xingfen Wang, Yuhan Zhao |  |
|  |  [Density-aware and Cluster-based Federated Anomaly Detection on Data Streams](https://doi.org/10.1145/3701551.3703548) |  | 0 | Federated active anomaly detection on data streams becomes a crucial research problem, since it attempts to discover anomalous data with protecting data privacy and avoiding extensive data labeling. Although extensive work has been conducted on anomaly detection, distinguishing similar anomalies of different categories still remains quite a challenging issue. The requirement of privacy protection in federated settings aggravates the difficulties for instance query and scoring in active anomaly detection when solving this issue. To the best of our knowledge, limited work has focused on this research area. Therefore, we propose Density-aware and cluster-based Federated Active anomaly detection on data Streams, called DFAS. We design a novel lightweight federated anomaly detection clusters with density-aware hash cells, which successfully capture evolving data distribution. The federated anomaly detection clusters are incrementally updated with an acceptable theoretical reconstruction error guarantee. In addition, we propose a straightforward but effective metric divergences accompanied by a greedy search algorithm, which takes both global aggregation bias mitigation and efficiency into account. At last, DFAS detects anomalies and queries the instances for manual labels by measuring the density in hash cells of each cluster, effectively distinguishing closely distributed anomaly classes while maintaining data privacy in the federated setting. Comprehensive experiments on several real-world data sets show that DFAS outperforms previous methods, improving F1 scores by up to 26.7%. | Bin Li, Li Cheng, Zheng Qin, Yunlong Wu | Intelligent Game and Decision Lab (IGDL), Beijing, China, Beijing, China; National University of Defense Technology, Changsha, China; Defense Innovation Institute, Academy of Military Sciences, Beijing, China; Intelligent Game and Decision Lab (IGDL), Beijing, China |
|  |  [Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs](https://doi.org/10.1145/3701551.3703519) |  | 0 | Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), which trains a classifier on the labeled source graph and adapts it to the unlabeled target graph, is attracting increasing attention. Various approaches have been proposed to alleviate the distribution shift between the source and target graphs to facilitate the classifier adaptation. However, most of them simply adopt existing UDA techniques developed for independent and identically distributed data to gain domain-invariant node embeddings for graphs, which do not fully consider the graph structure and message-passing mechanism of GNNs during the adaptation and will fail when label distribution shift exists among domains. In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have "in-distribution'' neighborhoods with the source domain. This strategy modified the target graph on the input level to reduce its deviation from the source domain in the embedding space and is insensitive to disproportional label distributions across domains. To prevent the loss of discriminative information in the target graph, we further design a novel identity-preserving learning objective, which guides the learning of the edge insertion module together with reconstruction and adaptation losses. Experimental results on real-world datasets demonstrate the effectiveness of our framework. | Yilong Wang, Tianxiang Zhao, Zongyu Wu, Suhang Wang | The Pennsylvania State University, State College, USA |
|  |  [Towards Reliable Latent Knowledge Estimation in LLMs: Zero-Prompt Many-Shot Based Factual Knowledge Extraction](https://doi.org/10.1145/3701551.3703562) |  | 0 | In this paper, we focus on the challenging task of reliably estimating factual knowledge that is embedded inside large language models (LLMs). To avoid reliability concerns with prior approaches, we propose to eliminate prompt engineering when probing LLMs for factual knowledge. Our approach, called Zero-Prompt Latent Knowledge Estimator (ZP-LKE), leverages the in-context learning ability of LLMs to communicate both the factual knowledge question as well as the expected answer format. Our knowledge estimator is both conceptually simpler (i.e., doesn't depend on meta-linguistic judgments of LLMs) and easier to apply (i.e., is not LLM-specific), and we demonstrate that it can surface more of the latent knowledge embedded in LLMs. We also investigate how different design choices affect the performance of ZP-LKE. Using the proposed estimator, we perform a large-scale evaluation of the factual knowledge of a variety of open-source LLMs, like OPT, Pythia, Llama(2), Mistral, Gemma, etc. over a large set of relations and facts from the Wikidata knowledge base. We observe differences in the factual knowledge between different model families and models of different sizes, that some relations are consistently better known than others but that models differ in the precise facts they know, and differences in the knowledge of base models and their finetuned counterparts. Code available at: https://github.com/QinyuanWu0710/ZeroPrompt_LKE | Qinyuan Wu, Mohammad Aflah Khan, Soumi Das, Vedant Nanda, Bishwamittra Ghosh, Camila Kolling, Till Speicher, Laurent Bindschaedler, Krishna P. Gummadi, Evimaria Terzi | University of Maryland Max Planck Institute for Software Systems; Boston University; MPI-SWS Max Planck Institute for Software Systems |
|  |  [Exploring the Explainability of Time Series Clustering: A Review of Methods and Practices](https://doi.org/10.1145/3701551.3703479) |  | 0 | With the increasing use of time series data, particularly in critical applications and high-risk decision-making contexts, understanding and improving the explainability of time-series clustering(TSC) techniques is essential. While machine learning models excel in processing time series data, their explainability often needs enhancement, challenging human comprehension and trust. Time series data clustering, as an unsupervised learning method, extracts valuable patterns from complex datasets without prior knowledge, spanning various domains like biology and finance. However, the complexity of clustering models and their opaque decision-making processes raise concerns about understanding and trusting the results. Research in this area aims to enhance the explainability of TSC by developing new interpretation methods that not only ensure the accuracy of clustering results but also make them user-friendly and comprehensible to human users. This is crucial for overcoming challenges related to understanding and trusting the decision-making processes and outcomes of the model. In this study, we embarked on two significant endeavors: (a) We explored the use of explainable artificial intelligence (XAI) for TSC for the first time, conducting a comprehensive literature review. (b) We subdivided the research field through innovative classification methods, categorizing the explainability methods of TSC into three main categories: data preprocessing techniques based on time series data, single or hybrid methods based model training, and instance-based visualization algorithm applications. This analytical framework aims to elucidate how the explainability of TSC can be enhanced across these three dimensions, thereby improving its credibility. Our work not only opens new research avenues but also provides robust strategies for enhancing the explainability and credibility of TSC methods. | Zheng Huang, Hao Hao, Lun Du | Shanghai Polytechnic University, Shanghai, China; Ant Research, Beijing, China |
|  |  [A Shopping Agent for Addressing Subjective Product Needs](https://doi.org/10.1145/3701551.3704124) |  | 0 | In e-commerce, customers often struggle to find relevant items when their needs involve subjective properties characterized by personal or collective perception, tastes, and opinions, which are typically not captured in catalog data. This challenge is particularly pronounced in event-based scenarios like gifting, where selecting the right product involves complex subjective reasoning. Customer reviews can be a valuable source of subjective information to bridge this gap. Consequently, customers often spend significant amount of time navigating multiple products and reading numerous reviews to find suitable gifts that meet their needs. In order to reduce the effort involved, we propose an agentic approach driven by large language models to streamline this process by autonomously executing various user actions. These include computational tasks like vagueness detection and subjective product needs extraction, conversational interactions to gather missing user information, and web browsing actions that search for product details, reviews, and review images. Additionally, the agent employs generative actions to synthesize gifting ideas and explanations, helping users discover suitable products more efficiently. The proposed approach not only reduces the cognitive burden on users but also facilitates the exploration of a wider range of products. Our solution highlights the potential of autonomous agents to handle subjective queries in e-commerce, enhancing personalization, product exploration, and selection in a user-centric manner. | Preetam Prabhu Srikar Dammu, Omar Alonso, Barbara Poblete | Amazon, Palo Alto, CA, USA; University of Washington, Seattle, WA, USA; Amazon, Seattle, WA, United States |
|  |  [Cluster Insight: A Weighted Clustering Tool for Large Textual Data Exploration](https://doi.org/10.1145/3701551.3704127) |  | 0 | In unsupervised learning, the exploration of large volumes of textual data is a topic of significant interest. In this article, we present our compact and easy-to-use application to explore large volumes of textual data using clustering and generative models. We demonstrate how to adapt the Lasso weighted k-means algorithm to handle textual data. In addition, we present in detail a user-friendly package that shows how to use LLMs effectively to describe document classes. | Amine Ferdjaoui, Séverine Affeldt, Mohamed Nadif | Centre Borelli UMR 9010, Université Paris Cité, Paris, France; SogetiLabs, Paris, France, & Centre Borelli, Université Paris Cité, Paris, France |
|  |  [LiveFC: A System for Live Fact-Checking of Audio Streams](https://doi.org/10.1145/3701551.3704128) |  | 0 | The advances in the digital era have led to rapid dissemination of information. This has also aggravated the spread of misinformation and disinformation. This has potentially serious consequences, such as civil unrest. While fact-checking aims to combat this, manual fact-checking is cumbersome and not scalable. While automated fact-checking approaches exist, they do not operate in real-time and do not always account for spread of misinformation through different modalities. This is particularly important as proactive fact-checking on live streams in real-time can help people be informed of false narratives and prevent catastrophic consequences that may cause civil unrest. This is particularly relevant with the rapid dissemination of information through video on social media platforms or other streams like political rallies and debates. Hence, in this work we develop a platform named \name{}, that can aid in fact-checking live audio streams in real-time. \name{} has a user-friendly interface that displays the claims detected along with their veracity and evidence for live streams with associated speakers for claims from respective segments. The app can be accessed at http://livefc.factiverse.ai and a screen recording of the demo can be found at https://bit.ly/3WVAoIw. | Venktesh V, Vinay Setty |  |
|  |  [Navigating the Hype and Embracing the Hope: The Future of Generative AI in Retail Product Discovery](https://doi.org/10.1145/3701551.3706133) |  | 0 | Generative AI is poised to revolutionize the retail industry, offering transformative potential to enhance customer experiences and operational efficiencies. Despite immense benefits -- such as personalized search, shopping assistance, product content enrichment, and dynamic recommendations -- the industry faces challenges distinguishing genuine value from overhyped applications. According to McKinsey & Company, Generative AI could unlock $240 billion to $390 billion in economic value for retailers, potentially increasing margins by up to 1.9 percentage points [1]. This paper navigates the delicate balance between the hype and the tangible promise of Generative AI in retail. We explore practical applications that deliver real value, critically examine overhyped use cases, and share strategies for successful AI integration. Readers will gain insights into effectively leveraging Generative AI while avoiding common pitfalls. | Darshan Nagaraja | Target Corporation, Minneapolis, Minnesota, USA |
|  |  [HyKG-CF: A Hybrid Approach for Counterfactual Prediction using Domain Knowledge](https://doi.org/10.1145/3701551.3708813) |  | 0 | Predictive models are gaining attention as powerful tools for aiding clinicians in diagnosis, prognosis, and treatment recommendations. However, their reliance on associative patterns may raise concerns about reliability of decision support, as association does not necessarily imply causation. To address this limit, we propose HyKG-CF, a hybrid approach to counterfactual prediction that leverages data and domain knowledge encoded in knowledge graph (KG). HyKG-CF integrates symbolic reasoning (on knowledge) with numerical learning (on data) using large language models (LLMs) and statistical models to learn causal Bayesian networks (CBNs) for accurate counterfactual prediction. Using data and knowledge, HyKG-CF improves the accuracy of causal discovery and counterfactual prediction. We evaluate HyKG-CF on a non-small cell lung cancer (NSCLC) KG, demonstrating that it outperforms other baselines. The results highlight the promise of combining domain knowledge with causal models to improve counterfactual prediction. | Hao Huang, MariaEsther Vidal | L3S Research Center, Hannover, Lower Saxony, Germany; TIB - Leibniz Information Centre for Science and Technology, Hannover, Lower Saxony, Germany |
|  |  [Graph Disentangle Causal Model: Enhancing Causal Inference in Networked Observational Data](https://doi.org/10.1145/3701551.3703525) |  | 0 | Estimating individual treatment effects (ITE) from observational data is a critical task across various domains. However, many existing works on ITE estimation overlook the influence of hidden confounders, which remain unobserved at the individual unit level. To address this limitation, researchers have utilized graph neural networks to aggregate neighbors' features to capture the hidden confounders and mitigate confounding bias by minimizing the discrepancy of confounder representations between the treated and control groups. Despite the success of these approaches, practical scenarios often treat all features as confounders and involve substantial differences in feature distributions between the treated and control groups. Confusing the adjustment and confounder and enforcing strict balance on the confounder representations could potentially undermine the effectiveness of outcome prediction. To mitigate this issue, we propose a novel framework called the Graph Disentangle Causal model (GDC) to conduct ITE estimation in the network setting. GDC utilizes a causal disentangle module to separate unit features into adjustment and confounder representations. Then we design a graph aggregation module consisting of three distinct graph aggregators to obtain adjustment, confounder, and counterfactual confounder representations. Finally, a causal constraint module is employed to enforce the disentangled representations as true causal factors. The effectiveness of our proposed method is demonstrated by conducting comprehensive experiments on two networked datasets. | Binbin Hu, Zhicheng An, Zhengwei Wu, Ke Tu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Yufei Feng, Jiawei Chen |  |
|  |  [DiffGraph: Heterogeneous Graph Diffusion Model](https://doi.org/10.1145/3701551.3703590) |  | 0 | Recent advances in Graph Neural Networks (GNNs) have revolutionized graph-structured data modeling, yet traditional GNNs struggle with complex heterogeneous structures prevalent in real-world scenarios. Despite progress in handling heterogeneous interactions, two fundamental challenges persist: noisy data significantly compromising embedding quality and learning performance, and existing methods' inability to capture intricate semantic transitions among heterogeneous relations, which impacts downstream predictions. To address these fundamental issues, we present the Heterogeneous Graph Diffusion Model (DiffGraph), a pioneering framework that introduces an innovative cross-view denoising strategy. This advanced approach transforms auxiliary heterogeneous data into target semantic spaces, enabling precise distillation of task-relevant information. At its core, DiffGraph features a sophisticated latent heterogeneous graph diffusion mechanism, implementing a novel forward and backward diffusion process for superior noise management. This methodology achieves simultaneous heterogeneous graph denoising and cross-type transition, while significantly simplifying graph generation through its latent-space diffusion capabilities. Through rigorous experimental validation on both public and industrial datasets, we demonstrate that DiffGraph consistently surpasses existing methods in link prediction and node classification tasks, establishing new benchmarks for robustness and efficiency in heterogeneous graph processing. The model implementation is publicly available at: https://github.com/HKUDS/DiffGraph. | Zongwei Li, Lianghao Xia, Hua Hua, Shijie Zhang, Shuangyang Wang, Chao Huang |  |
|  |  [CIMAGE: Exploiting the Conditional Independence in Masked Graph Auto-encoders](https://doi.org/10.1145/3701551.3703515) |  | 0 | Recent Self-Supervised Learning (SSL) methods encapsulating relational information via masking in Graph Neural Networks (GNNs) have shown promising performance. However, most existing approaches rely on random masking strategies in either feature or graph space, which may fail to capture task-relevant information fully. We posit that this limitation stems from an inability to achieve minimum redundancy between masked and unmasked components while ensuring maximum relevance of both to potential downstream tasks. Conditional Independence (CI) inherently satisfies the minimum redundancy and maximum relevance criteria, but its application typically requires access to downstream labels. To address this challenge, we introduce CIMAGE, a novel approach that leverages Conditional Independence to guide an effective masking strategy within the latent space. CIMAGE utilizes CI-aware latent factor decomposition to generate two distinct contexts, leveraging high-confidence pseudo-labels derived from unsupervised graph clustering. In this framework, the pretext task involves reconstructing the masked second context solely from the information provided by the first context. Our theoretical analysis further supports the superiority of CIMAGE's novel CI-aware masking method by demonstrating that the learned embedding exhibits approximate linear separability, which enables accurate predictions for the downstream task. Comprehensive evaluations across diverse graph benchmarks illustrate the advantage of CIMAGE, with notably higher average rankings on node classification and link prediction tasks. Notably, our proposed model highlights the under-explored potential of CI in enhancing graph SSL methodologies and offers enriched insights for effective graph representation learning. | Jongwon Park, Heesoo Jung, Hogun Park | Sungkyunkwan University, Suwon, Republic of Korea |
|  |  [Hyperdimensional Representation Learning for Node Classification and Link Prediction](https://doi.org/10.1145/3701551.3703492) |  | 0 | We introduce Hyperdimensional Graph Learner (HDGL), a novel method for node classification and link prediction in graphs. HDGL maps node features into a very high-dimensional space (hyperdimensional or HD space for short) using the injectivity property of node representations in a family of Graph Neural Networks (GNNs) and then uses HD operators such as bundling and binding to aggregate information from the local neighborhood of each node yielding latent node representations that can support both node classification and link prediction tasks. HDGL, unlike GNNs that rely on computationally expensive iterative optimization and hyperparameter tuning, requires only a single pass through the data set. We report results of experiments using widely used benchmark datasets which demonstrate that, on the node classification task, HDGL achieves accuracy that is competitive with that of the state-of-the-art GNN methods at substantially reduced computational cost; and on the link prediction task, HDGL matches the performance of DeepWalk and related methods, although it falls short of computationally demanding state-of-the-art GNNs. | Abhishek Dalvi, Vasant G. Honavar | The Pennsylvania State University |
|  |  [Mitigating Overfitting in Graph Neural Networks via Feature and Hyperplane Perturbation](https://doi.org/10.1145/3701551.3703487) |  | 0 | Message-passing neural networks are widely employed in various graph mining applications. However, these methods are susceptible to the scarcity of labeled data, which often leads to overfitting. Our observations suggest that sparse initial vectors further exacerbate this issue by failing to fully represent the range of learnable parameters. This sparsity can hinder the optimization of specific dimensions in the initial projection matrix, as the training samples may not adequately span these parameters. To overcome this challenge, we propose a novel perturbation technique that introduces variability to the initial features and the projection hyperplane. Notably, even without employing grid search, we demonstrate that shifting with a small estimated value mitigates this problem more effectively than other perturbation methods. Experimental results on real-world datasets reveal that our technique significantly enhances node classification accuracy in semi-supervised scenarios. | Yoonhyuk Choi, Jiho Choi, Taewook Ko, ChongKwon Kim | Korea Institute of Energy Technology, Naju, Republic of Korea; KAIST, Seoul, Republic of Korea; Samsung, Seoul, Republic of Korea |
|  |  [Dynamic Graph Transformer with Correlated Spatial-Temporal Positional Encoding](https://doi.org/10.1145/3701551.3703489) |  | 0 | Learning effective representations for Continuous-Time Dynamic Graphs (CTDGs) has garnered significant research interest, largely due to its powerful capabilities in modeling complex interactions between nodes. A fundamental and crucial requirement for representation learning in CTDGs is the appropriate estimation and preservation of proximity. However, due to the sparse and evolving characteristics of CTDGs, the spatial-temporal properties inherent in high-order proximity remain largely unexplored. Despite its importance, this property presents significant challenges due to the computationally intensive nature of personalized interaction intensity estimation and the dynamic attributes of CTDGs. To this end, we propose a novel Correlated Spatial-Temporal Positional encoding that incorporates a parameter-free personalized interaction intensity estimation under the weak assumption of the Poisson Point Process. Building on this, we introduce the Dynamic Graph Transformer with Correlated Spatial-Temporal Positional Encoding (CorDGT), which efficiently retains the evolving spatial-temporal high-order proximity for effective node representation learning in CTDGs. Extensive experiments on seven small and two large-scale datasets demonstrate the superior performance and scalability of the proposed CorDGT. The code is available at: https://github.com/wangz3066/CorDGT. | Zhe Wang, Sheng Zhou, Jiawei Chen, Zhen Zhang, Binbin Hu, Yan Feng, Chun Chen, Can Wang |  |
|  |  [Prospective Multi-Graph Cohesion for Multivariate Time Series Anomaly Detection](https://doi.org/10.1145/3701551.3703494) |  | 0 | Anomaly detection in high-dimensional time series data is pivotal for numerous industrial applications. Recent advances in multivariate time series anomaly detection (TSAD) have increasingly leveraged graph structures to model inter-variable relationships, typically employing Graph Neural Networks (GNNs). Despite their promising results, existing methods often rely on a single graph representation, which are insufficient for capturing the complex, diverse relationships inherent in multivariate time series. To address this, we propose the Prospective Multi-Graph Cohesion (PMGC) framework for multivariate TSAD. PMGC exploits spatial correlations by integrating a long-term static graph with a series of short-term instance-wise dynamic graphs, regulated through a graph cohesion loss function. Our theoretical analysis shows that this loss function promotes diversity among dynamic graphs while aligning them with the stable long-term relationships encapsulated by the static graph. Additionally, we introduce a "prospective graphing" strategy to mitigate the limitations of traditional forecasting-based TSAD methods, which often struggle with unpredictable future variations. This strategy allows the model to accurately reflect concurrent inter-series relationships under normal conditions, thereby enhancing anomaly detection efficacy. Empirical evaluations on real-world datasets demonstrate the superior performance of our method compared to existing TSAD techniques. | Jiazhen Chen, Mingbin Feng, Tony S. Wirjanto | University of Waterloo, Waterloo, Ontario, Canada |
|  |  [The Initial Screening Order Problem](https://doi.org/10.1145/3701551.3703497) |  | 0 | We investigate the role of the initial screening order (ISO) in candidate screening processes, such as hiring and academic admissions. ISO refers to the order in which the screener sorts the candidate pool before the evaluation. It has been largely overlooked in the literature, despite its potential impact on the optimality and fairness of the chosen set, especially under a human screener. We define two problem formulations: best-$k$, where the screener chooses the $k$ best candidates, and good-$k$, where the screener chooses the first $k$ good-enough candidates. To study the impact of ISO, we introduce a human-like screener and compare to its algorithmic counterpart. The human-like screener is conceived to be inconsistent over time due to fatigue. Our analysis shows that the ISO under a human-like screener hinders individual fairness despite meeting group level fairness. This is due to the position bias, where a candidate's evaluation is affected by its position within ISO. We report extensive simulated experiments exploring the parameters of the problem formulations both for algorithmic and human-like screeners. This work is motivated by a real world candidate screening problem studied in collaboration with a large European company. | José M. Álvarez, Antonio Mastropietro, Salvatore Ruggieri | SALVATORE RUGGIERI Scuola Normale Superiore |
|  |  [LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework](https://doi.org/10.1145/3701551.3703488) |  | 0 | Recent prevailing works on graph machine learning typically follow a similarmethodology that involves designing advanced variants of graph neural networks(GNNs) to maintain the superior performance of GNNs on different graphs. Inthis paper, we aim to streamline the GNN design process and leverage theadvantages of Large Language Models (LLMs) to improve the performance of GNNson downstream tasks. We formulate a new paradigm, coined "LLMs-as-Consultants,"which integrates LLMs with GNNs in an interactive manner. A framework namedLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactiveutilization of LLMs within the GNN training process. First, we attentivelycraft concise prompts for spotted nodes, carrying comprehensive semantic andtopological information, and serving as input to LLMs. Second, we refine GNNsby devising a complementary coping mechanism that utilizes the responses fromLLMs, depending on their correctness. We empirically evaluate the effectivenessof LOGIN on node classification tasks across both homophilic and heterophilicgraphs. The results illustrate that even basic GNN architectures, when employedwithin the proposed LLMs-as-Consultants paradigm, can achieve comparableperformance to advanced GNNs with intricate designs. Our codes are available athttps://github.com/QiaoYRan/LOGIN. | Yiran Qiao, Xiang Ao, Yang Liu, Jiarong Xu, Xiaoqian Sun, Qing He | Key Lab of AI Safety of Chinese Academy of Sciences (CAS) |
|  |  [Self-supervised Time-aware Heterogeneous Hypergraph Learning for Dynamic Graph-level Classification](https://doi.org/10.1145/3701551.3703504) |  | 0 | Graph-level learning has gained significant importance in understanding complex systems, such as social and biological networks, but often fails to capture evolving and multi-entity interaction. Current dynamic graph-level classification methods struggle with evolving structures, global properties, and high-order interactions. To address these challenges, we propose DyH2GNet, a novel time-aware self-supervised heterogeneous hypergraph neural network that models complex, non-pairwise interactions and their temporal dynamics by integrating k-hop nodes and attribute correlations into a heterogeneous hypergraph. It features a temporal embedding method that captures high-order proximity and the dynamic context of heterogeneous interactions through intra- and inter-snapshot attention. Furthermore, a graph-level pooling layer aggregates node features with temporal context, supported by self-supervised learning that leverages temporal contrastive learning to maximize the use of unlabeled data. Experiments on real-world datasets demonstrated significant improvements in capturing dynamic graph-level features through unsupervised graph-level tasks, including graph similarity ranking, anomaly detection, and trend analysis. | Malik Khizar Hayat, Shan Xue, Jia Wu, Bilal Khan, Jian Yang | Macquarie University, Sydney, NSW, Australia |
|  |  [MoKGNN: Boosting Graph Neural Networks via Mixture of Generic and Task-Specific Language Models](https://doi.org/10.1145/3701551.3703571) |  | 0 | Text-Attributed Graphs (TAGs) are prevalent in various real-world scenarios, where each node is associated with a text attribute. Representation learning on TAGs relies on a comprehensive understanding of both the textual attributes associated with nodes and the topological connections between nodes. Recent works have tried to enhance graph neural networks (GNNs) with pre-trained language models (PLMs) for textual attribute learning, which has achieved promising result compared with shallow text representation learning models such as BoW. With the advent of more powerful LLMs, it is worth to further exploring how to effectively and efficiently incorporate the generic knowledge in LLMs to enhance GNNs. To this aim, we for the first time investigate whether the mainstream generative LLMs can provide high-quality generic text embedding for GNNs. To simultaneously use the generic knowledge in the LLM and the task-specific knowledge in the tuned PLM (TLM), we propose a dual channel knowledge fusion framework, named MoKGNN, to enhance the representation learning on TAGs. Specifically, we first propose a dual channel feature extraction stage to derive text embeddings that contain generic knowledge and task-specific knowledge separately. Next, we introduce a Knowledge Alignment Network to align the higher-dimensional General Embedding with the lower-dimensional Task-Specific Embedding. Finally, we adopt a mix-up operation to integrate the generic and task-specific textual attribute representation to enhance downstream GNNs. Extensive experiments on four TAG datasets demonstrate the effectiveness of our approach in improving the performance of GNNs in the tasks of node classification and link prediction. | Hao Yan, Chaozhuo Li, Jun Yin, Weihao Han, Hao Sun, Senzhang Wang, Jian Zhang, Jianxin Wang | Central South University, Changsha, China; Microsoft Research Asia, Beijing, China; Microsoft AI, Beijing, China |
|  |  [HHGT: Hierarchical Heterogeneous Graph Transformer for Heterogeneous Graph Representation Learning](https://doi.org/10.1145/3701551.3703511) |  | 0 | Despite the success of Heterogeneous Graph Neural Networks (HGNNs) in modeling real-world Heterogeneous Information Networks (HINs), challenges such as expressiveness limitations and over-smoothing have prompted researchers to explore Graph Transformers (GTs) for enhanced HIN representation learning. However, research on GT in HINs remains limited, with two key shortcomings in existing work: (1) A node's neighbors at different distances in HINs convey diverse semantics. Unfortunately, existing methods ignore such differences and uniformly treat neighbors within a given distance in a coarse manner, which results in semantic confusion. (2) Nodes in HINs have various types, each with unique semantics. Nevertheless, existing methods mix nodes of different types during neighbor aggregation, hindering the capture of proper correlations between nodes of diverse types. To bridge these gaps, we design an innovative structure named (k,t)-ring neighborhood, where nodes are initially organized by their distance, forming different non-overlapping k-ring neighborhoods for each distance. Within each k-ring structure, nodes are further categorized into different groups according to their types, thus emphasizing the heterogeneity of both distances and types in HINs naturally. Based on this structure, we propose a novel Hierarchical Heterogeneous Graph Transformer (HHGT) model, which seamlessly integrates a Type-level Transformer for aggregating nodes of different types within each k-ring neighborhood, followed by a Ring-level Transformer for aggregating different k-ring neighborhoods in a hierarchical manner. Extensive experiments are conducted on downstream tasks to verify HHGT's superiority over 14 baselines, with a notable improvement of up to 24.75% in NMI and 29.25% in ARI for node clustering task on the ACM dataset compared to the best baseline. | Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Kaijun Liu, Cheng Long, Xiaoyang Wang |  |
|  |  [Neo-TKGC: Enhancing Temporal Knowledge Graph Completion with Integrated Node Weights and Future Information](https://doi.org/10.1145/3701551.3703538) |  | 0 | Temporal Knowledge Graph Completion (TKGC) involves predicting and filling in missing facts within time series data, a crucial task with wide-ranging applications across various domains. The dynamic evolution of Temporal Knowledge Graphs (TKGs) adds complexity to this task, making it inherently challenging. Existing research predominantly relies on historical data to complete the missing facts. However, these approaches often overlook the potential of future information and the significance of node weights.To address these challenges, we propose Neo-TKGC, a novel temporal knowledge graph completion model that integrates a graph structure encoding module and a temporal encoding module. The graph structure encoding module introduces node weights to enhance the capabilities of graph neural networks (GNNs) for entity and relation representation learning, implemented using CompGCN. This module can be easily extended to any GNN models utilizing node and edge aggregation. The temporal encoding module leverages both future and historical information to capture relevant contexts and temporal dependencies among entities and relations.By combining node weights and future information, Neo-TKGC achieves more accurate entity and relation representations, thereby improving the model's ability to infer unknown entities. Extensive experiments on three real-world TKGC datasets demonstrate the superior performance of our model compared to existing approaches, achieving at least a 1.7% relative improvement in Hits@1 across most metrics. | Zihan Qiu, Xiaoling Zhou, Chunyan An, Qiang Yang, Zhixu Li | Renmin University of China, Beijing, China; University of Florida, Gainesville, Florida, USA; Inner Mongolia University, Hohhot, Inner Mongolia, China |
|  |  [Hawkes Point Process-enhanced Dynamic Graph Neural Network](https://doi.org/10.1145/3701551.3703520) |  | 0 | Dynamic graph representation learning aims to capture the evolution of graph structures and obtain accurate node embeddings, a crucial task in graph machine learning. The Hawkes point process, a mathematical framework effective for modeling the influence of historical events on future occurrences, has been validated as a powerful tool for capturing the dynamics of graph evolution in dynamic graph representation learning. However, existing dynamic graph representation learning methods based on the Hawkes point process primarily model excitation at the individual node level, failing to adequately account for structural influences during graph evolution. This limitation restricts their ability to comprehensively capture network evolution patterns. To address this limitation, we propose a Hawkes Point Process-enhanced Dynamic Graph Neural Network (HP-DGNN) model. This model leverages the Hawkes point process to model both individual node histories and structural histories, capturing their respective influences on future node interactions. By integrating individual and structural influences in computing Hawkes conditional intensity, the model comprehensively captures the impacts of both layers on future node interactions. We evaluate our proposed model on two downstream tasks of dynamic graph representation learning: dynamic link prediction and future node degree prediction. Compared to 12 state-of-the-art methods, our model consistently demonstrates superior performance, underscoring its effectiveness in capturing the complexities of graph evolution. | Zhiqiang Wang, Baijing Hu, Kaixuan Yao, Jiye Liang |  |
|  |  [Edge Classification on Graphs: New Directions in Topological Imbalance](https://doi.org/10.1145/3701551.3703518) |  | 0 | Recent years have witnessed the remarkable success of applying Graph machinelearning (GML) to node/graph classification and link prediction. However, edgeclassification task that enjoys numerous real-world applications such as socialnetwork analysis and cybersecurity, has not seen significant advancement. Toaddress this gap, our study pioneers a comprehensive approach to edgeclassification. We identify a novel \`Topological Imbalance Issue', which arisesfrom the skewed distribution of edges across different classes, affecting thelocal subgraph of each edge and harming the performance of edgeclassifications. Inspired by the recent studies in node classification that theperformance discrepancy exists with varying local structural patterns, we aimto investigate if the performance discrepancy in topological imbalanced edgeclassification can also be mitigated by characterizing the local classdistribution variance. To overcome this challenge, we introduce TopologicalEntropy (TE), a novel topological-based metric that measures the topologicalimbalance for each edge. Our empirical studies confirm that TE effectivelymeasures local class distribution variance, and indicate that prioritizingedges with high TE values can help address the issue of topological imbalance.Based on this, we develop two strategies - Topological Reweighting and TEWedge-based Mixup - to focus training on (synthetic) edges based on their TEs.While topological reweighting directly manipulates training edge weightsaccording to TE, our wedge-based mixup interpolates synthetic edges betweenhigh TE wedges. Ultimately, we integrate these strategies into a noveltopological imbalance strategy for edge classification: TopoEdge. Throughextensive experiments, we demonstrate the efficacy of our proposed strategieson newly curated datasets and thus establish a new benchmark for (imbalanced)edge classification. | Xueqi Cheng, Yu Wang, Yunchao Liu, Yuying Zhao, Charu C. Aggarwal, Tyler Derr |  |
|  |  [FedGF: Enhancing Structural Knowledge via Graph Factorization for Federated Graph Learning](https://doi.org/10.1145/3701551.3703493) |  | 0 | Federated graph learning involves training graph neural networks distributively on local graphs and aggregating model parameters in a central server. However, existing methods fail to effectively capture and leverage the inherent global structures, hindering local structural modeling. To address this, we propose Federated Graph Factorization (FedGF), which enhances structural knowledge via privacy-preserving graph factorization. Specifically, FedGF includes three modules, i.e., global structure reconstruction (GSR), local structure exploration (LSE), and global-local structure alignment (GLSA). Firstly, GSR factorizes client graphs into a series of learnable graph atoms and conducts reconstruction to capture the globally shared structure. Then, LSE explores the local structure, mining potential but unrevealed connections within client subgraphs. GLSA further aligns the global and local structure to alternatively refine the graph atoms and GNN model, enhancing the overall structural modeling. Extensive experiments on six datasets consistently validate the effectiveness of \modelname. | Pengyang Zhou, Chaochao Chen, Weiming Liu, Xinting Liao, Fengyuan Yu, Zhihui Fu, Xingyu Lou, Wu Wen, Xiaolin Zheng, Jun Wang | Zhejiang University, Hangzhou, China; OPPO, Shenzhen, China; OPPO Research Institute, Shenzhen, China; Zhejiang university, Hangzhou, China |
|  |  [ESA: Example Sieve Approach for Multi-Positive and Unlabeled Learning](https://doi.org/10.1145/3701551.3703526) |  | 0 | Learning from Multi-Positive and Unlabeled (MPU) data has gradually attracted significant attention from practical applications. Unfortunately, the risk of MPU also suffer from the shift of minimum risk, particularly when the models are very flexible as shown in Fig.. In this paper, to alleviate the shifting of minimum risk problem, we propose an Example Sieve Approach (ESA) to select examples for training a multi-class classifier. Specifically, we sieve out some examples by utilizing the Certain Loss (CL) value of each example in the training stage and analyze the consistency of the proposed risk estimator. Besides, we show that the estimation error of proposed ESA obtains the optimal parametric convergence rate. Extensive experiments on various real-world datasets show the proposed approach outperforms previous methods. | Zhongnian Li, Meng Wei, Peng Ying, Xinzheng Xu |  |
|  |  [Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks](https://doi.org/10.1145/3701551.3703521) |  | 0 | Blockchain technology, with implications in the financial domain, offers data in the form of large-scale transaction networks. Analyzing transaction networks facilitates fraud detection, market analysis, and supports government regulation. Despite many graph representation learning methods for transaction network analysis, we pinpoint two salient limitations that merit more investigation. Existing methods predominantly focus on the snapshots of transaction networks, sidelining the evolving nature of blockchain transaction networks. Existing methodologies may not sufficiently emphasize efficient, incremental learning capabilities, which are essential for addressing the scalability challenges in ever-expanding large-scale transaction networks. To address these challenges, we employed an incremental approach for random walk-based node representation learning in transaction networks. Further, we proposed a Metropolis-Hastings-based random walk mechanism for improved efficiency. The empirical evaluation conducted on blockchain transaction datasets reveals comparable performance in node classification tasks while reducing computational overhead. Potential applications include transaction network monitoring, the efficient classification of blockchain addresses for fraud detection or the identification of specialized address types within the network. | Junliang Luo, Xue Liu |  |
|  |  [Inductive Graph Few-shot Class Incremental Learning](https://doi.org/10.1145/3701551.3703578) |  | 0 | Node classification with Graph Neural Networks (GNN) under a fixed set of labels is well known in contrast to Graph Few-Shot Class Incremental Learning (GFSCIL), which involves learning a GNN classifier as graph nodes and classes growing over time sporadically. We introduce inductive GFSCIL that continually learns novel classes with newly emerging nodes while maintaining performance on old classes without accessing previous data. This addresses the practical concern of transductive GFSCIL, which requires storing the entire graph with historical data. Compared to the transductive GFSCIL, the inductive setting exacerbates catastrophic forgetting due to inaccessible previous data during incremental training, in addition to overfitting issue caused by label sparsity. Thus, we propose a novel method, called Topology-based class Augmentation and Prototype calibration (TAP). To be specific, it first creates a triple-branch multi-topology class augmentation method to enhance model generalization ability. As each incremental session receives a disjoint subgraph with nodes of novel classes, the multi-topology class augmentation method helps replicate such a setting in the base session to boost backbone versatility. In incremental learning, given the limited number of novel class samples, we propose an iterative prototype calibration to improve the separation of class prototypes. Furthermore, as backbone fine-tuning poses the feature distribution drift, prototypes of old classes start failing over time, we propose the prototype shift method for old classes to compensate for the drift. We showcase the proposed method on four datasets. | Yayong Li, Peyman Moghadam, Can Peng, Nan Ye, Piotr Koniusz |  |
|  |  [Graph Size-imbalanced Learning with Energy-guided Structural Smoothing](https://doi.org/10.1145/3701551.3703559) |  | 0 | Graph is a prevalent data structure employed to represent the relationships between entities, frequently serving as a tool to depict and simulate numerous systems, such as molecules and social networks. However, real-world graphs usually suffer from the size-imbalanced problem in the multi-graph classification, i.e., a long-tailed distribution with respect to the number of nodes. Recent studies find that off-the-shelf Graph Neural Networks (GNNs) would compromise model performance under the long-tailed settings. We investigate this phenomenon and discover that the long-tailed graph distribution greatly exacerbates the discrepancies in structural features. To alleviate this problem, we propose a novel energy-based size-imbalanced learning framework named SIMBA, which smooths the features between head and tail graphs and re-weights them based on the energy propagation. Specifically, we construct a higher-level graph abstraction named Graphs-to-Graph according to the correlations between graphs to link independent graphs and smooths the structural discrepancies. We further devise an energy-based message-passing belief propagation method for re-weighting lower compatible graphs in the training process and further smooth local feature discrepancies. Extensive experimental results over five public size-imbalanced datasets demonstrate the superior effectiveness of the model for size-imbalanced graph classification tasks. | Jiawen Qin, Pengfeng Huang, Qingyun Sun, Cheng Ji, Xingcheng Fu, Jianxin Li |  |
|  |  [Incomplete Multi-view Clustering via Local Reasoning and Correlation Analysis](https://doi.org/10.1145/3701551.3703495) |  | 0 | In recent years, incomplete multi-view clustering (IMVC) has attracted considerable attention for its ability to acheieve effective clustering results through the integration of key information amidst missing view. However, the existing IMVC methods are still faced with 3 limitations: (1) They exhibit deficiencies in considering the weight distribution within views, (2) they ignore the varying contributions of different views to the common consistent representation, and (3) they struggle to sufficiently extract and recover the vital information within incomplete views. To address these limitations, we incorporates local reasoning and correlation analysis to design an incomplete multi-view clustering method(IMVCLRCA), which introduces a new strategy of feature learning and missing view recovery, fully exploiting local similarity and structural continuity within views and performing precise local reasoning recovery on missing data. By maximizing mutual information between views through contrastive learning, we achieve the consistent representation learning of multiple views. Furthermore, based on semantic consistency, we comprehensively consider the correlation between views, utilized a weight matrix to fuse cross-view data, and constructed a view with a correlation structure, ultimately obtaining a common consistent representation. We conduct extensive experiments on 4 public datasets including Caltech101-20, BBCSport, Scene-15, and LandUse-21. Experimental results demonstrate that IMVCLRCA has higher accuracy and robustness compared to the state-of-the-art IMVC methods. The anonymous code of this project is available on GitHub at https://github.com/ggg2111/2025WSDM-IMVCLRCA. | Xiaocui Li, Guoliang Li, Xinyu Zhang, Yangtao Wang, Qingyu Shi, Wei Liang | Guangzhou University, Guangzhou, Guangzhou, China; Hunan University of Technology and Business, Changsha, Hunan, China |
|  |  [Mining Topics towards ChatGPT Using a Disentangled Contextualized-neural Topic Model](https://doi.org/10.1145/3701551.3703534) |  | 0 | Mining topics relevant to the advanced AI dialogue system, such as ChatGPT, from short-length posts on social media poses several challenges for existing topic-mining approaches. Firstly, Bag-Of-Words approaches, including probabilistic topic models and their embedding-based variants, may struggle to extract interpretable topics due to insufficient word co-occurrence. Secondly, contextualized based approaches, built on the autoencoding framework, often yield entangled topic spaces, resulting in the mixing of irrelevant words into topics. To address these limitations, we propose a novel Dis entangled Contextualized-neural Topic Model (DisCTM) based on textual representation learning. DisCTM leverages a pre-trained transformer language model to incorporate word sequence information and deal with the sparsity in short text. Additionally, it employs a topic disentangling mechanism to decorrelate dimensions of the latent topic space, effectively separating semantically irrelevant words into different topics. Extensive experiments have been conducted on three publicly available text corpora, and the results demonstrate the effectiveness of DisCTM in extracting high-quality topics, as measured by topic coherence and diversity metrics. | Rui Wang, Xing Liu, Yanan Wang, Shuyu Chang, Yuanzhi Yao, Haiping Huang |  |
|  |  [Adjacent Neighborhood Transformer-based Diffusion Model for Anomaly Detection under Incomplete Industrial Data Sources](https://doi.org/10.1145/3701551.3703565) |  | 0 | Anomaly detection in an industrial setting is crucial for operational monitoring, yet it remains challenging under incomplete data conditions. Common issues, such as sensor failures, data transmission loss, and storage malfunctions, often result in missing data, complicating the detection of anomalies, particularly when these are localized within specific regions. To address the challenges, this paper proposes DiffANT, an unsupervised anomaly detection method that integrates a diffusion model with the Adjacent Neighborhood Transformer (ANT). Specifically, DiffANT begins by applying various data masking techniques to simulate realistic missing values that reflect real-world industrial scenarios. The ANT utilizes a Transformer encoder architecture augmented with an adjacent neighborhood attention mechanism. It effectively focuses on relevant non-immediate vicinities to enhance anomaly detection. DiffANT then reconstructs the original data from randomly sampled noise through diffusion and denoising processes and utilizes a multi-level reconstruction strategy to refine the generated samples. We demonstrate the efficacy of DiffANT through extensive experiments in diverse industrial applications, such as secure water treatment and server machine monitoring. The results indicate that DiffANT consistently outperforms state-of-the-art methods in detecting anomalies in time series data, regardless of whether the data is incomplete. | Lulu Wang, Chengqing Li | School of Computer Science, Xiangtan University, Xiangtan, China; School of Mathematics and Computational Science, Xiangtan University, Xiangtan, China |
|  |  [Revisiting Fake News Detection: Towards Temporality-aware Evaluation by Leveraging Engagement Earliness](https://doi.org/10.1145/3701551.3703524) |  | 0 | Social graph-based fake news detection aims to identify news articles containing false information by utilizing social contexts, e.g., user information, tweets and comments. However, conventional methods are evaluated under less realistic scenarios, where the model has access to future knowledge on article-related and context-related data during training. In this work, we newly formalize a more realistic evaluation scheme that mimics real-world scenarios, where the data is temporality-aware and the detection model can only be trained on data collected up to a certain point in time. We show that the discriminative capabilities of conventional methods decrease sharply under this new setting, and further propose DAWN, a method more applicable to such scenarios. Our empirical findings indicate that later engagements (e.g., consuming or reposting news) contribute more to noisy edges that link real news-fake news pairs in the social graph. Motivated by this, we utilize feature representations of engagement earliness to guide an edge weight estimator to suppress the weights of such noisy edges, thereby enhancing the detection performance of DAWN. Through extensive experiments, we demonstrate that DAWN outperforms existing fake news detection methods under real-world environments. The source code is available at https://github.com/LeeJunmo/DAWN. | Junghoon Kim, Junmo Lee, Yeonjun In, Kanghoon Yoon, Chanyoung Park |  |
|  |  [GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake News Detection](https://doi.org/10.1145/3701551.3703541) |  | 0 | Multimodal fake news detection often involves modelling heterogeneous data sources, such as vision and language. Existing detection methods typically rely on fusion effectiveness and cross-modal consistency to model the content, complicating understanding how each modality affects prediction accuracy. Additionally, these methods are primarily based on static feature modelling, making it difficult to adapt to the dynamic changes and relationships between different data modalities. This paper develops a significantly novel approach, GAMED, for multimodal modelling, which focuses on generating distinctive and discriminative features through modal decoupling to enhance cross-modal synergies, thereby optimizing overall performance in the detection process. GAMED leverages multiple parallel expert networks to refine features and pre-embed semantic knowledge to improve the experts' ability in information selection and viewpoint sharing. Subsequently, the feature distribution of each modality is adaptively adjusted based on the respective experts' opinions. GAMED also introduces a novel classification technique to dynamically manage contributions from different modalities, while improving the explainability of decisions. Experimental results on the Fakeddit and Yang datasets demonstrate that GAMED performs better than recently developed state-of-the-art models. The source code can be accessed at https://github.com/slz0925/GAMED. | Lingzhi Shen, Yunfei Long, Xiaohao Cai, Imran Razzak, Guanming Chen, Kang Liu, Shoaib Jameel |  |
|  |  [IMPO: Interpretable Memory-based Prototypical Pooling](https://doi.org/10.1145/3701551.3703543) |  | 0 | Graph Neural Networks (GNNs) have proven their effectiveness in various graph-structured data applications. However, one of the significant challenges in the realm of GNNs is representation learning, a critical concept that bridges graph pooling, aimed at creating compressed graph representations, and explainable artificial intelligence, which focuses on building models with transparent reasoning mechanisms. This research paper introduces a novel approach called Interpretable Memory-based Prototypical Pooling (IMPO) to address this challenge. IMPO is a graph pooling layer designed to enhance the interpretability of GNNs while maintaining high performance in graph classification tasks. It builds upon the MemPool algorithm and incorporates prototypical components to cluster nodes around class-aware centroids. This approach allows IMPO to selectively aggregate relevant substructures, paving the way for generating more interpretable graph representations. The experimental results in our study underscore the potential of pooling architectures in constructing inherently explainable GNNs. Notably, IMPO achieves state-of-the-art results in both classification and explanatory capacities across a diverse set of graph classification datasets. | Alessio Ragno, Roberto Capobianco | Sony AI, Zurich, Switzerland |
|  |  [DTPN: A Diffusion-based Traffic Purification Network for Tor Website Fingerprinting](https://doi.org/10.1145/3701551.3703547) |  | 0 | Website Fingerprinting attack is a type of method used to classify network traffic generated by users on the Tor (The Onion Router) based on the websites they visit, leading to the leakage of individuals' privacy . For Website Fingerprinting attack, network traffic defense methods involve adding noise to the original network traffic to render the attacker's methods ineffective. Previous attack methods primarily focused on improving classification accuracy by enhancing the attack model, with adversarial training being the most common approach. However, adversarial training requires frequent updates and exhibits poor generalization when dealing with previously unseen network traffic protection methods. In order to address the limitations of adversarial training, a novel method is proposed leveraging a diffusion model for network traffic purification. This paper is the first to use a diffusion model to resist network traffic defense based on adversarial perturbations. The diffusion models are theoretically suited for data purification in the training mode, i.e., removing noises generated by adversarial perturbations from the data. Our method enables existing network traffic classification methods to maintain effective classification of network traffic after protection without requiring retraining, while also achieving good generalization performance with previously unseen network traffic defense methods. The purified network traffic data can effectively improve the robustness of existing website fingerprinting methods. Experiments conducted under various network traffic defense strategies demonstrate that the proposed method increases accuracy by up to 60.8% on DF dataset and 50.3% on CW100 dataset, respectively, compared to adversarial training. | Chenchen Yang, Xi Xiao, Guangwu Hu, Zhen Ling, Hao Li, Bin Zhang | Peng Cheng Laboratory, Shenzhen, China; Shenzhen Institute of Information Technology, Shenzhen, China; Southeast University, Nanjing, China; National Key Laboratory of Advanced Communication Network, Shijiazhuang, China |
|  |  [Adaptive Graph Enhancement for Imbalanced Multi-relation Graph Learning](https://doi.org/10.1145/3701551.3703553) |  | 0 | Graph Neural Networks (GNNs), as the mainstream graph representation learning method, has demonstrated its effectiveness in learning graph embeddings over benchmark datasets. However, existing GNNs still have limitations in handling real-world graphs in the following aspects: (i) nodes in most real-world graphs are inherently class-imbalanced; (ii) node degrees vary considerably in real-world graphs; (iii) most existing works study these two issues separately but ignore the co-occurrence between class imbalance and topology imbalance in graphs. They overlook the fact that topology imbalance varies significantly across different relation types. Hence, we propose a novel model called AD-GSMOTE (Adaptive Graph SMOTE) to tackle the class and topology issues simultaneously in multi-relation graphs. Specifically, we first design an adaptive topology-aware node generator and an efficient triadic edge generator to enhance the graph structure under each relation type by generating synthetic nodes for all tail nodes in minority classes and creating rich connections among tail nodes and others. Then, the enhanced multi-relation graph is fed into a GNN encoder to get node embeddings. Afterward, a class-aware logit adjustment module is designed to adjust the pre-softmax logit during model training, which enables the model to learn larger margins between minority and majority classes. To evaluate the performance of AD-GSMOTE, we build a new real-world graph (Twitter-Drug) to classify user roles in the drug trafficking community. The excellent performance on three real-world graphs demonstrates the effectiveness and efficiency of AD-GSMOTE compared with state-of-the-art methods. Source code and dataset are available at https://github.com/graphprojects/AD-GSMOTE https://github.com/graphprojects/AD-GSMOTE. | Yiyue Qian, Tianyi Ma, Chuxu Zhang, Yanfang Ye | University of Notre Dame, Notre Dame, USA; University of Connecticut, Storrs, USA |
|  |  [Training MLPs on Graphs without Supervision](https://doi.org/10.1145/3701551.3703550) |  | 0 | Graph Neural Networks (GNNs) have demonstrated their effectiveness in various graph learning tasks, yet their reliance on neighborhood aggregation during inference poses challenges for deployment in latency-sensitive applications, such as real-time financial fraud detection. To address this limitation, recent studies have proposed distilling knowledge from teacher GNNs into student Multi-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate inference. However, these approaches often inadequately explore structural information when inferring unseen nodes. To this end, we introduce SimMLP, a Self-supervised framework for learning MLPs on graphs, designed to fully integrate rich structural information into MLPs. Notably, SimMLP is the first MLP-learning method that can achieve equivalence to GNNs in the optimal case. The key idea is to employ self-supervised learning to align the representations encoded by graph context-aware GNNs and neighborhood dependency-free MLPs, thereby fully integrating the structural information into MLPs. We provide a comprehensive theoretical analysis, demonstrating the equivalence between SimMLP and GNNs based on mutual information and inductive bias, highlighting SimMLP's advanced structural learning capabilities. Additionally, we conduct extensive experiments on 20 benchmark datasets, covering node classification, link prediction, and graph classification, to showcase SimMLP's superiority over state-of-the-art baselines, particularly in scenarios involving unseen nodes (e.g., inductive and cold-start node classification) where structural insights are crucial. Our codes are available at: https://github.com/Zehong-Wang/SimMLP. | Zehong Wang, Zheyuan Zhang, Chuxu Zhang, Yanfang Ye |  |
|  |  [An Edge-Based Decomposition Framework for Temporal Networks](https://doi.org/10.1145/3701551.3703556) |  | 0 | A temporal network is a dynamic graph where every edge is assigned an integer time label that indicates at which discrete time step the edge is available. We consider the problem of hierarchically decomposing the network and introduce an edge-based decomposition framework that unifies the core and truss decompositions for temporal networks while allowing us to consider the network's temporal dimension. Based on our new framework, we introduce the (k,Δ)-core and (k,Δ)-truss decompositions, which are generalizations of the classic k-core and k-truss decompositions for multigraphs. Moreover, we show how (k,Δ)-cores and (k,Δ)-trusses can be efficiently further decomposed to obtain spatially and temporally connected components. We evaluate the characteristics of our new decompositions and the efficiency of our algorithms. Moreover, we demonstrate how our (k,Δ)-decompositions can be applied to analyze malicious content in a Twitter network to obtain insights that state-of-the-art baselines cannot obtain. | Lutz Oettershagen, Athanasios L. Konstantinidis, Giuseppe F. Italiano | KTH Royal Institute of Technology; Luiss University |
|  |  [MedTransTab: Advancing Medical Cross-Table Tabular Data Generation](https://doi.org/10.1145/3701551.3703501) |  | 0 | In medical research, clinical trials are pivotal. While prospective clinical research provides a systematic approach to collecting patient data, it grapples with challenges like long durations, increased costs, and most crucially, data scarcity. To address above-mentioned challenge, this paper introduces a novel approach: using cross-table generation to create relevant data. Unlike existing work focused on single-table operations, our method leverages data from multiple sources across various tables, integrating diverse data types and ensuring data consistency across multiple tables. We develop a new framework, MedTransTab, tailored for cross-table tabular data generation in the medical context. This framework extends our previous efforts and is built upon the newly constructed PMC-Struct, derived from an unstructured PMC-patient dataset. Our MedTransTab can generate high-quality patient records, synthesizing detailed biomedical information to align with real or simulated tables from multiple sources. The experiments show that the proposed method significantly improves performance in cross-table tasks. On the PMC-Struct-Plus dataset, we observe an average improvement of 28.85% in data generation and prediction. Similarly, on the Out-Of-Domain (OOD) dataset, there's an average improvement of 22.56%, indicating substantial progress in medical data analysis. | Yuyan Chen, Qingpei Guo, Shuangjie You, Zhixu Li | Ant Group, Beijing, China; Georgia Institute of Technology, Atlanta, GA, USA |
|  |  [InstrucTime: Advancing Time Series Classification with Multimodal Language Modeling](https://doi.org/10.1145/3701551.3703499) |  | 0 |  | Mingyue Cheng, Yiheng Chen, Qi Liu, Zhiding Liu, Yucong Luo, Enhong Chen |  |
|  |  [Improving FIM Code Completions via Context & Curriculum Based Learning](https://doi.org/10.1145/3701551.3703563) |  | 0 | Fill-in-the-Middle (FIM) models play a vital role in code completion tasks, leveraging both prefix and suffix context to provide more accurate and contextually relevant suggestions. This paper presents approaches to improve FIM code completion while addressing the challenge of maintaining low latency for real-time coding assistance. We enhance FIM code completion by incorporating context and curriculum examples in the training process. We identify patterns where completion suggestions fail more frequently, revealing complexities that smaller language models struggle with. To address these challenges, we develop a curriculum dataset by extracting hard-to-complete patterns from code repositories and generate context examples using semantic and static analysis tools (e.g. TSC compiler). We fine-tune various sized models, including StarCoder and DeepSeek, on this enhanced dataset. Our evaluation encompasses three key dimensions: the Santa Coder FIM task, the Amazon CCEval benchmark, and a new Multi-Line Infilling evaluation benchmark derived from SWE-bench. Comprehensive ablation studies across multiple model sizes reveal that while all fine-tuned models show improvements, the performance gains are more pronounced for smaller parameter models and incorporating difficult-to-complete examples, as part of curriculum learning, improves the code completion performance. This finding is particularly significant given the latency constraints of code completion tasks. While larger models like GPT and Claude perform well in multi-line completions but are prohibitively challenging to use given high latency, and our fine-tuned models achieve a balance between performance and latency. Finally, we validate our approach through online A/B testing, demonstrating tangible improvements in Completion Acceptance Rate (CAR) and Completion Persistence Rate (CPR), with zero latency impact. | Hitesh Sagtani, Rishabh Mehrotra, Beyang Liu |  |
|  |  [Heterophilic Graph Neural Networks Optimization with Causal Message-passing](https://doi.org/10.1145/3701551.3703568) |  | 0 | In this work, we discover that causal inference provides a promising approach to capture heterophilic message-passing in Graph Neural Network (GNN). By leveraging cause-effect analysis, we can discern heterophilic edges based on asymmetric node dependency. The learned causal structure offers more accurate relationships among nodes. To reduce the computational complexity, we introduce intervention-based causal inference in graph learning. We first simplify causal analysis on graphs by formulating it as a structural learning model and define the optimization problem within the Bayesian scheme. We then present an analysis of decomposing the optimization target into a consistency penalty and a structure modification based on cause-effect relations. We then estimate this target by conditional entropy and present insights into how conditional entropy quantifies the heterophily. Accordingly, we propose CausalMP, a causal message-passing discovery network for heterophilic graph learning, that iteratively learns the explicit causal structure of input graphs. We conduct extensive experiments in both heterophilic and homophilic graph settings. The result demonstrates that the our model achieves superior link prediction performance. Training on causal structure can also enhance node representation in classification task across different base models. | Botao Wang, Jia Li, Heng Chang, Keli Zhang, Fugee Tsung |  |
|  |  [Untapping the Power of Indirect Relationships in Entity Summarization](https://doi.org/10.1145/3701551.3703566) |  | 0 | Knowledge graphs form large networks of millions of entities (e.g., Michelle Obama, Barack Obama) and relationships (e.g., married). To obtain an overview of the entity, we need to inspect a potentially large number of relationships to other entities. For this reason, entity summarization aims to extract succinct but expressive descriptions of each entity. Yet, existing methods build their summaries only based on the immediate connections of an entity, disregarding how indirect relationships contain essential information for describing the entity (e.g., understanding Michelle Obama also via her husband's role as former president). We propose IRES, an unsupervised entity summarization method built on graph theoretical principles. We draw a notable connection between the informativeness of a summary and graph partitioning, and devise an effective approach to learn diverse aspects that characterize an entity. In a comprehensive experimental study, IRES shows superior summary quality. In particular, when full neighborhood information is available, IRES outperforms existing methods by 6 percentage points F1 while maintaining competitive computational efficiency. | Atefeh Moradan, Mohammad Sorkhpar, Atsushi Miyauchi, Davide Mottin, Ira Assent | CENTAI Institute, Turin, Italy; Aarhus University, Aarhus, Demark; Indiana State University, Terre Haute, USA |
|  |  [Demystify Epidemic Containment in Directed Networks: Theory and Algorithms](https://doi.org/10.1145/3701551.3703575) |  | 0 | Epidemic containment has long been a crucial task in many high-stake application domains, ranging from public health to misinformation dissemination. Existing studies for epidemic containment are primarily focused on undirected networks, assuming that the infection rate is constant throughout the contact network regardless of the strength and direction of contact. However, such an assumption can be unrealistic given the asymmetric nature of the real-world infection process. To tackle the epidemic containment problem in directed networks, simply grafting the methods designed for undirected network can be problematic, as most of the existing methods rely on the orthogonality and Lipschitz continuity in the eigensystem of the underlying contact network, which do not hold for directed networks. In this work, we derive a theoretical analysis on the general epidemic threshold condition for directed networks and show that such threshold condition can be used as an optimization objective to control the spread of the disease. Based on the epidemic threshold, we propose an asymptotically greedy algorithm DINO (DIrected NetwOrk epidemic containment) to identify the most critical nodes for epidemic containment. The proposed algorithm is evaluated on real-world directed networks, and the results validate its effectiveness and efficiency. The code is available at https://github.com/YinhanHe123/DINO/. | Yinhan He, Chen Chen, Song Wang, Guanghui Min, Jundong Li | University of Virginia, Charlottesville, VA, USA |
|  |  [How Does Memorization Impact LLMs' Social Reasoning? An Assessment using Seen and Unseen Queries](https://doi.org/10.1145/3701551.3703576) |  | 0 | As Large Language Models (LLMs) have rapidly advanced in social reasoning tasks, their applications have expanded to domains such as healthcare and psychology. Given the direct interaction of users with these applications, it is essential to evaluate the performance of LLMs, particularly in human-like social reasoning capabilities. While previous studies have explored human-aligned social reasoning in LLMs, they have not adequately assessed whether the generated reasoning answers stem from the LLMs' memorization of training data or their natural language understanding. In this study, we aim to address this gap by assessing the impact of training data memorization on the human-aligned social reasoning capabilities of LLMs. We introduce IR+CoT (Information Retrieval (IR) + Chain of Thought (CoT)), a framework that leverages retrieved information from input questions to fine-tune prompt templates and employs CoT methods. IR+CoT mitigates the effects of memorization and enhances the LLMs' social reasoning performance. Experiments on three LLMs, using seen (present during the training of the LLMs) and unseen (introduced post-training) questions from Reddit and Lemmy, show that IR+CoT enhances social reasoning and reduces memorization effects. This research's novelty lies in using old and new questions to assess memorization's impact on social reasoning. | Maryam Amirizaniani, Maryna Sivachenko, Adrian Lavergne, Chirag Shah, Afra Mashhadi | University of Washington, Seattle, USA; University of Washington-Bothell, Bothell, USA |
|  |  [ProCC: Programmatic Reinforcement Learning for Efficient and Transparent TCP Congestion Control](https://doi.org/10.1145/3701551.3703585) |  | 0 | Transmission Control Protocol (TCP) congestion control is a fundamental mechanism in the Internet that maintains network stability and performance by adjusting the sending rate of connections. Recently, Deep Reinforcement Learning (DRL) methods have shown superior performance over traditional expert-designed solutions. However, the DRL policies are often represented by black-box neural networks, they lack interpretability, making verification challenging and requiring excessive floating-point computation. This work introduces a novel approach, Programmatic reinforcement learning for Congestion Control (ProCC), designed to autonomously discover a program as a control policy from scratch. Programs in ProCC include branching structures (e.g., if blocks and if-else blocks), conditions and actions. However, directly optimizing such program structures is challenging due to their discrete non-differentiable nature, and the program space grows exponentially as the depth increases. To address this issue, ProCC defines a Domain-Specific Language (DSL) and program transformation rules, enabling the construction of a program search graph where similar programs are closer in proximity. Subsequently, ProCC employs Monte Carlo Tree Search (MCTS) to efficiently explore the discrete space and obtain promising programs. Extensive experiments conducted in multiple simulated environments demonstrate that ProCC is adaptive and consistently performs well under varying network conditions. The learned program's performance surpasses that of state-of-the-art DRL agents, and more importantly, the generated policies are concise, transparent, and computationally efficient. | Yin Gu, Kai Zhang, Qi Liu, Runlong Yu, Xin Lin, Xinjie Sun | Department of Computer Science, University of Pittsburgh, Pittsburgh, Pennsylvania, USA |
|  |  [Building Trustworthy AI Models for Medicine: From Theory to Applications](https://doi.org/10.1145/3701551.3703477) |  | 0 | AI is emerging as an efficient companion in medicine. While AI holds promise for reducing the cognitive load of researchers and practitioners, its adoption is often hindered by a lack of trust in new AI advancements. We present sophisticated techniques for developing trustworthy artificial intelligence (AI) models in medicine, bridging breakthroughs in AI research with practical healthcare applications. We will discuss in-depth the four stages (Design, Development, Implementation, and Evaluation) involved in the process of building trustworthy AI models customized for the medical domain. We present various techniques for incorporating important Trustworthy AI principles like data privacy, robustness, explainability, interpretability, medical experts-in-the-loop, and risk assessment while developing AI models for medicine. In contrast to prior tutorials, we make the following two key contributions: (i) While explaining the 'Implementation' stage, we cover various real-world healthcare applications developed as part of research projects in academia in collaboration with medical schools in India and Germany. (ii) By including a health informatics professional as one of the tutorial organizers, we provide a fresh and much-needed perspective on the research challenges and mitigation strategies in building AI models for medicine. | Soumyadeep Roy, Sowmya S. Sundaram, Dominik Wolff, Niloy Ganguly | IIT Kharagpur, Kharagpur, India; Stanford University, Stanford, CA, USA |
|  |  [SAGESSE: A System for Argument Generation, Extraction and Structuring of Social Exchanges](https://doi.org/10.1145/3701551.3704122) |  | 0 | Online debates provide critical insights into public opinion and societal trends, yet the unstructured nature of these discussions presents significant challenges for analysis. In this paper, we present SAGESSE, a novel argumentation parsing pipeline tailored to Reddit debates, leveraging the capabilities of large language models to structure and interpret complex online arguments. SAGESSE generates detailed argument maps that organize debates systematically, offering a clearer understanding of discourse dynamics. We have developed a web application where users can select controversial Reddit topics and visualize the corresponding argument maps generated from user comments. This tool has the potential to aid analysts, policymakers, and researchers in tracking debate progress, gauging public sentiment, and identifying influential arguments. The web application is available at https://modemos.epfl.ch/sagesse/ . | Nicolas Almerge, Matteo Santelmo, Ilker Gül, Amin Asadi Sarijalou, Rémi Lebret, Léo Laugier, Karl Aberer | EPFL, Lausanne, Switzerland |
|  |  [Ventana a la Verdad (Window to the Truth): A Chatbot Application for Navigating The Colombian Truth Commission's Archives](https://doi.org/10.1145/3701551.3704123) |  | 0 | We present Ventana a la Verdad, a chatbot designed to make the Clar- ification Archive and the reports of the Colombian Truth Commis- sion [6] more accessible to a wider audience. These archives contain a wealth of documents, interviews, and testimonies from Colom- bia's armed conflict, but navigating them can be challenging due to their volume and complexity. Using existing large language models (LLMs) and natural language processing techniques, our chatbot allows users to interact with the archives through natural language queries, receiving relevant and contextually appropriate responses. In the sensitive context of peace and reconciliation, where misin- formation or hallucinations can have significant adverse effects, ensuring the accuracy and reliability of information is paramount. This tool aims to facilitate better understanding and engagement with historical content, supporting educational and research efforts. We discuss the development of the chatbot, the challenges encoun- tered, and its potential impact on making the Colombian Truth Commission's archives more accessible. The chatbot is available by link here: http://ventanaverdad.lucyapps.net:1337/ | Anna Sokol, Matthew L. Sisk, Josefina Echavarría Alvarez, Nitesh V. Chawla | University of Notre Dame, Notre Dame, IN, USA |
|  |  [WildlifeLookup: A Chatbot Facilitating Wildlife Management with Accessible Data and Insights](https://doi.org/10.1145/3701551.3704121) |  | 0 | Wildlife management is increasingly reliant on data-driven insights to address the impacts of climate change on species and ecosystems. However, the complexity of accessing and querying large, multimodal datasets often limits the ability of non-technical users, such as wildlife managers and conservationists, to make informed decisions. To address this challenge, we present WildlifeLookup, a public accessible, intelligent chatbot designed to facilitate natural language interaction with a novel knowledge graph (KN-Wildlife) that houses critical wildlife and environmental data. WildlifeLookup simplifies access to species distributions, habitat interactions, and climate-related events by converting user queries into precise graph queries, reducing the technical barriers for end users. The chatbot WildlifeLookup is available at https://oknbot.ngrok.dev/ | Xiangqi Wang, Tianyu Yang, Jason Rohr, Brett Scheffers, Nitesh V. Chawla, Xiangliang Zhang | University of Notre Dame, South Bend, IN, USA; University of Florida, Gainesville, FL, USA |
|  |  [Mind Over Machine: Evaluating Theory of Mind Reasoning in LLMs and Humans](https://doi.org/10.1145/3701551.3707417) |  | 0 | As Large Language Models (LLMs) become increasingly integrated into applications demanding human-like understanding-such as mental health support, education, and social robotics-their capacity to exhibit Theory of Mind (ToM) reasoning is essential. Although previous research has evaluated LLMs' capability in ToM tasks, a critical gap remains as few studies have systematically investigated how LLMs' ToM reasoning diverges from human reasoning and the extent of these differences. This study introduces a reinforcement learning-based framework designed to bridge this gap. This approach seeks to enhance LLM alignment with human ToM reasoning, effectively narrowing the differences in their reasoning processes. Finally, future research directions to advance this field will be discussed, including strategies for developing LLMs that can better approximate human social cognition. This work lays a foundation for responsible LLM deployment, offering guidelines for applications in sensitive contexts where accurate ToM understanding is crucial. | Maryam Amirizaniani | University of Washington, Seattle, WA, USA |
|  |  [Edge-Centric Network Analytics](https://doi.org/10.1145/3701551.3707418) |  | 0 | Network analysis has evolved substantially, with notable advancements in node-centric and graph-centric tasks, yet the exploration of edge-centric analytics has been notably limited. This oversight is significant given the crucial role of edges in elucidating the complex relationships within networks, particularly in fields such as social network analysis, cybersecurity, and bioinformatics, where the dynamics of connections between entities are often pivotal. My doctoral research aims to address this gap by delving into the under-explored domain of edge-centric analytics, providing a foundational background that is crucial for advancing the field and enhancing the application of network theory in real-world scenarios. The significance of this research lies in its potential to open new avenues for inquiry and application across diverse disciplines where understanding the nuances of relational dynamics is essential. | Xueqi Cheng | Vanderbilt University, Nashville, TN, USA |
|  |  [Bearing Power Loss Predictions in Wind Turbine Gearbox: An Approach Based on LLMs](https://doi.org/10.1145/3701551.3707419) |  | 0 | A constant and consistent supply in electrical energy in a location is a reflection of a good economy. Developing countries nevertheless don't have access to this quality of energy, which slows down their economy and consequently development. Wind is a clean, sustainable and renewable resource which can be used to meet the energy needs in such countries. However, the intermittent nature of wind yields fluctuations on the amount of energy produced by a wind turbine. Coupled with frictional power losses in the wind turbine gearbox bearings, one can't be sure on the exact amount of energy that will be produced. This leads to the distribution and management issues. To tackle this issue, we propose here the use of Large Language models. These are tools which have been proving their potential in various domains till date and whose potential are still to be seen in the field to our knowledge. Taking advantage of their flexibility and adaptability to any model and dataset, we intend to explore its abilities in the fields of wind energy and tribology. Making use of available data, predictions on the wind energy potential and power losses will be carried out using Large Language models such as BERT. The results of this work intends to promote the use of wind energy by lifting barriers in thee management and knowledge of the resource. | Janice Anta Zebaze, Azanzi Jiomekong, Innocent Souopgui, Germaine Djuidje Kenmoe | RedLine Performance Solutions, LLC, USA; Department of Physics, University of Yaounde 1, Yaounde, Cameroon |
|  |  [The Generalization and Error Detection in LLM-based Text-to-SQL Systems](https://doi.org/10.1145/3701551.3707416) |  | 0 | Text-to-SQL systems streamline human-database interactions, improving data retrieval and decision-making. Although large language models (LLMs) can now generate SQL code, challenges with generalization and uncontrolled generation hinder their use in production. Text-to-SQL tasks are particularly sensitive to distribution shifts, where performance declines with unfamiliar database elements or novel queries. Effective systems must maintain quality, measured in terms of generalization (correct processing of novel user requests) and error detection (identification of incorrect generations). This study empirically assesses LLM-based Text-to-SQL systems limitations, defining reliable production scenarios. Current contributions include a cross-lingual generalization research, study on generative model generalization abilities and the quality of selective classification for error detection risk under different distribution shifts in task of Text-to-SQL. | Oleg Somov | AIRI, Moscow, Russian Federation |
|  |  [SpecialtyScribe: Enhancing SOAP note Scribing for Medical Specialties using LLMs](https://doi.org/10.1145/3701551.3706131) |  | 0 | The healthcare industry has accumulated vast amounts of unstructured clinical data, including medical records, patient communications, and visit notes. Clinician-patient conversations are central to medical records, with the clinician's final summary (the medical note) serving as the key reference for future interactions and treatments. Creating a concise and accurate medical SOAP note is crucial for quality patient care and is especially challenging for specialty care, which requires added focus on relevance to the specialty, clarity, absence of hallucinations, and adherence to doctor preferences. This makes it very challenging for a general-purpose LLM to create satisfactory notes. Some recent LLMs, like GPT-4, have shown promise in medical note generation; however, the high cost, size, latency, and privacy concerns associated with closed models make them impractical for many healthcare facilities. In this talk, we will present our method ''SpecialtyScribe'', which is a modular pipeline for generating specialty-specific medical notes. It consists of three main components: an Information Extractor module that captures relevant specialty data, a Context Retriever module that retrieves and verifies the relevant context from the transcript, and a Note Writer module that generates medically acceptable notes based on the extracted information. Our framework outperforms any naively prompt-engineered model by more than 32% on expert scoring, and our in-house models surpass similarly sized open-source models by more than 100% on ROUGE based metrics. The in-house models also match the overall performance of the best closed-source LLMs while being less than 1% the estimated size of them. We'll showcase multiple ablations across our pipeline, mitigation of hallucinations, the role of retrievers, and the importance of scalable pipelines for multiple specialties. We'll also discuss the design of our human-expert scoring mechanism for various language model use cases. | Eti Rastogi, Sagar Goyal, Fen Zhao, Dong Yuan | DeepScribe Inc., San Francisco, CA, USA |
|  |  [Fact-checking Multilingual Podcasts](https://doi.org/10.1145/3701551.3706134) |  | 0 | Long-form content, such as YouTube videos and podcasts, has become widely popular, particularly among younger audiences. However, the extended format of this content presents unique challenges for fact-checking them. This talk explores the feasibility of an end-to-end solution for transcribing and fact-checking long-form content in a multilingual context. I will conclude by presenting the selected technologies and models for end-to-end fact-checking in this domain. | Vinay Setty | Factiverse AI, Stavanger, Norway, & University of Stavanger, Stavanger, Norway |
|  |  [Using Photon-Counting CT Images for Lung Nodule Classification](https://doi.org/10.1145/3701551.3708810) |  | 0 | An automatic classification of the malignancy of lung nodules in computed tomography (CT) scans can support early detection of lung cancer, which is crucial for the treatment success. The novel photon-counting CT (PCCT) technology enables high image quality with a low radiation dose and provides additional spectral information. This research focuses on whether PCCT scans offer a benefit in the automatic classification of lung nodules. Establishing a dataset of PCCT images poses several challenges, such as the extraction of annotations or the data imbalance. | Leonie Basso, Zahra Ahmadi, Steffen OeltzeJafra, Eike Petersen, Hoenoh Shin, Andrea Schenk | Hannover Medical School, Hannover, Germany |
|  |  [A Systematic Evaluation of Single-Cell Foundation Models on Cell-Type Classification Task](https://doi.org/10.1145/3701551.3708811) |  | 0 | This study presents a comprehensive benchmarking of three state-of-the-art single-cell foundation models scGPT, Geneformer, and scFoundation, on cell-type classification tasks. We evaluate the models on three datasets: myeloid, human pancreas, and multiple sclerosis, examining both standard fine-tuning and few-shot learning scenarios. Our work reveals that scFoundation consistently achieves the best performance while Geneformer performs poorly, yielding results sometimes even worse than those of the baseline models. Additionally, we demonstrate that a good foundation model can generalize well even when fine-tuned with out-of-distribution data, a capability that the baseline models lack. Our work highlights the potential of foundation models for addressing challenging biomedical questions, particularly in contexts where models are trained on one population but deployed on another. | Nicolas Steiner, Ziteng Li, Omid Vosoughi, Johanna Schrader, Soumyadeep Roy, Wolfgang Nejdl, Ming Tang | IIT Kharagpur, Kharagpur, India; L3S Research Center, Hannover, Germany; L3S Research Center, hANNOVER, Germany |
|  |  [Enhancing Medical Knowledge Discovery: A Neuro-symbolic System for Inductive Learning over Medical KGs](https://doi.org/10.1145/3701551.3708814) |  | 0 | Medical knowledge graphs (KGs) excel at integrating heterogeneous healthcare data with domain knowledge, but face challenges due to incompleteness. While Knowledge Graph Embedding (KGE) models show promise in link prediction, they often fail to incorporate crucial semantic constraints from medical ontologies and clinical guidelines. We propose a neuro-symbolic system that enhances medical knowledge discovery by combining symbolic learning from medical ontologies, inductive learning through KGE, and semantic constraint validation. Applied to lung cancer care, our system demonstrates enhanced performance in predicting novel medical relationships while maintaining semantic consistency with medical knowledge. Experimental results show our approach enhances the KGE model's performance while ensuring clinical validity and the implementation is publicly accessible on GitHub https://github.com/SDM-TIB/KOSMOS. | Disha Purohit, Yashrajsinh Chudasama, MariaEsther Vidal |  |
|  |  [BioLinkerAI: Leveraging LLMs to Improve Biomedical Entity Linking and Knowledge Capture](https://doi.org/10.1145/3701551.3708812) |  | 0 | We introduce BioLinkerAI, a neuro-symbolic framework for biomedical entity linking that integrates symbolic (domain-specific and linguistic rules) and sub-symbolic (large language models) components. Unlike traditional approaches requiring extensive labeled training data, BioLinkerAI harnesses a knowledge base and rules for candidate generation, while a pre-trained LLM handles final disambiguation. This combination ensures adaptability to diverse biomedical knowledge bases and complex entity mentions. Empirical evaluations show that BioLinkerAI surpasses state-of-the-art benchmarks, notably increasing unseen data accuracy from 65.4 to 78.5 without relying on extensive labeled datasets. | Ahmad Sakor, Kuldeep Singh, MariaEsther Vidal | Cerence GmbH, Aachen, Germany |
|  |  [Disinformation and Misinformation in the Age of Generative AI](https://doi.org/10.1145/3701551.3705708) |  | 0 | The rapid rise of generative AI (GenAI) technologies has revolutionized the way content is created and disseminated. As a result, highly convincing human-like malicious content including disinformation, misinformation, and propaganda can now be easily produced and distributed across the web. The diversity of generation models combined with various manipulation strategies applied to different modalities presents significant challenges for fact-checking systems and content moderation. To address this issue, we organize a workshop that focuses on harmful content that has been created intentionally (disinformation) and unintentionally (misinformation) in the era of generative AI. The workshop features specialized tracks on multimodal solutions, investigating narratives, trustworthy AI systems, and policy interventions. By bringing together experts from computer science and law, the workshop offers a comprehensive framework for combating fake content online. | Koustav Rudra, Niloy Ganguly, Jeanne Mifsud Bonnici, Eric MüllerBudack, Ritumbra Manuvie | IIT Kharagpur, Kharagpur, India; University of Groningen, Groningen, Netherlands; TIB - Leibniz Information Centre for Science and Technology, Hannover, Germany |

# ACL2023

## 会议论文列表

本会议共有 2153 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Frontmatter](https://aclanthology.org/2023.acl-demo.0) |  | 0 |  |  |  |
| 2 |  |  [Human-in-the-loop Schema Induction](https://doi.org/10.18653/v1/2023.acl-demo.1) |  | 0 | Schema induction builds a graph representation explaining how events unfold in a scenario. Existing approaches have been based on information retrieval (IR) and information extraction (IE), often with limited human curation. We demonstrate a human-in-the-loop schema induction system powered by GPT-3. We first describe the different modules of our system, including prompting to generate schematic elements, manual edit of those elements, and conversion of those into a schema graph. By qualitatively comparing our system to previous ones, we show that our system not only transfers to new domains more easily than previous approaches, but also reduces efforts of human curation thanks to our interactive interface. | Tianyi Zhang, Isaac Tham, Zhaoyi Hou, Jiaxuan Ren, Leon Zhou, Hainiu Xu, Li Zhang, Lara J. Martin, Rotem Dror, Sha Li, Heng Ji, Martha Palmer, Susan Windisch Brown, Reece Suchocki, Chris CallisonBurch |  |
| 3 |  |  [PersLEARN: Research Training through the Lens of Perspective Cultivation](https://doi.org/10.18653/v1/2023.acl-demo.2) |  | 0 | Scientific research is inherently shaped by its authors’ perspectives, influenced by various factorssuch as their personality, community, or society. Junior researchers often face challenges in identifying the perspectives reflected in the existing literature and struggle to develop their own viewpoints. In response to this issue, we introduce PersLEARN , a tool designed to facilitate the cultivation of scientific perspectives, starting from a basic seed idea and progressing to a well-articulated framework. By interacting with a prompt-based model, researchers can develop their perspectives explicitly. Our humanstudy reveals that scientific perspectives developed by students using PersLEARN exhibit a superior level of logical coherence and depth compared to those that did not. Furthermore, our pipeline outperforms baseline approaches across multiple domains of literature from various perspectives. These results suggest that PersLEARN could help foster a greater appreciation of diversity in scientific perspectives as an essential component of research training. | YuZhe Shi, Shiqian Li, Xinyi Niu, Qiao Xu, Jiawen Liu, Yifan Xu, Shiyu Gu, Bingru He, Xinyang Li, Xinyu Zhao, Zijian Zhao, Yidong Lyu, Zhen Li, Sijia Liu, Lin Qiu, Jinhao Ji, Lecheng Ruan, Yuxi Ma, Wenjuan Han, Yixin Zhu |  |
| 4 |  |  [LAVIS: A One-stop Library for Language-Vision Intelligence](https://doi.org/10.18653/v1/2023.acl-demo.3) |  | 0 | We introduce LAVIS, an open-source deep learning library for LAnguage-VISion research and applications. LAVIS aims to serve as a one-stop comprehensive library that brings recent advancements in the language-vision field accessible for researchers and practitioners, as well as fertilizing future research and development. It features a unified interface to easily access state-of-the-art image-language, video-language models and common datasets. LAVIS supports training, evaluation and benchmarking on a rich variety of tasks, including multimodal classification, retrieval, captioning, visual question answering, dialogue and pre-training. In the meantime, the library is also highly extensible and configurable, facilitating future development and customization. In this technical report, we describe design principles, key components and functionalities of the library, and also present benchmarking results across common language-vision tasks. | Dongxu Li, Junnan Li, Hung Le, Guangsen Wang, Silvio Savarese, Steven C. H. Hoi |  |
| 5 |  |  [Finspector: A Human-Centered Visual Inspection Tool for Exploring and Comparing Biases among Foundation Models](https://doi.org/10.18653/v1/2023.acl-demo.4) |  | 0 | Pre-trained transformer-based language models are becoming increasingly popular due to their exceptional performance on various benchmarks. However, concerns persist regarding the presence of hidden biases within these models, which can lead to discriminatory outcomes and reinforce harmful stereotypes. To address this issue, we propose Finspector, a human-centered visual inspection tool designed to detect biases in different categories through log-likelihood scores generated by language models. The goal of the tool is to enable researchers to easily identify potential biases using visual analytics, ultimately contributing to a fairer and more just deployment of these models in both academic and industrial settings. Finspector is available at https://github.com/IBM/finspector. | Bum Chul Kwon, Nandana Mihindukulasooriya |  |
| 6 |  |  [PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question Answering Research and Development](https://doi.org/10.18653/v1/2023.acl-demo.5) |  | 0 | The field of Question Answering (QA) has made remarkable progress in recent years, thanks to the advent of large pre-trained language models, newer realistic benchmark datasets with leaderboards, and novel algorithms for key components such as retrievers and readers. In this paper, we introduce PrimeQA: a one-stop and open-source QA repository with an aim to democratize QA research and facilitate easy replication of state-of-the-art (SOTA) QA methods. PrimeQA supports core QA functionalities like retrieval and reading comprehension as well as auxiliary capabilities such as question generation. It has been designed as an end-to-end toolkit for various use cases: building front-end applications, replicating SOTA methods on public benchmarks, and expanding pre-existing methods. PrimeQA is available at: https://github.com/primeqa. | Avi Sil, Jaydeep Sen, Bhavani Iyer, Martin Franz, Kshitij Fadnis, Mihaela A. Bornea, Sara Rosenthal, J. Scott McCarley, Rong Zhang, Vishwajeet Kumar, Yulong Li, Md. Arafat Sultan, Riyaz A. Bhat, Jürgen Broß, Radu Florian, Salim Roukos |  |
| 7 |  |  [Lingxi: A Diversity-aware Chinese Modern Poetry Generation System](https://doi.org/10.18653/v1/2023.acl-demo.6) |  | 0 | Chinese modern poetry generation has been a challenging task. One issue is the Chinese word segmentation (CWS) which is critical to comprehend the Chinese language but was not always considered in common tokenization methods. Another is the decoding (sampling) method which may induce repetition and boredom and severely lower the diversity of the generated poetry. To address these issues, we present Lingxi, a diversity-aware Chinese modern poetry generation system. For the CWS issue, we propose a novel framework that incorporates CWS in the tokenization process. The proposed method can achieve a high vocabulary coverage rate with a reasonable vocabulary size. For the decoding method and the diversity issue, we propose a novel sampling algorithm that flattens the high likelihood part of the predicted distribution of the language model to emphasize the comparatively low-likelihood words and increase the diversity of generated poetry. Empirical results show that even when the top 60% of cumulative probability mass of the predicted distribution is flattened, our method achieves comparable or even better performance than baseline sampling methods. Our system is available at http://lingxi.website. | Xinran Zhang, Maosong Sun, Jiafeng Liu, Xiaobing Li |  |
| 8 |  |  [Autodive: An Integrated Onsite Scientific Literature Annotation Tool](https://doi.org/10.18653/v1/2023.acl-demo.7) |  | 0 | Scientific literature is always available in Adobe’s Portable Document Format (PDF), which is friendly for scientists to read. Compared with raw text, annotating directly on PDF documents can greatly improve the labeling efficiency of scientists whose annotation costs are very high. In this paper, we present Autodive, an integrated onsite scientific literature annotation tool for natural scientists and Natural Language Processing (NLP) researchers. This tool provides six core functions of annotation that support the whole lifecycle of corpus generation including i)annotation project management, ii)resource management, iii)ontology management, iv)manual annotation, v)onsite auto annotation, and vi)annotation task statistic. Two experiments are carried out to verify efficiency of the presented tool. A live demo of Autodive is available at http://autodive.sciwiki.cn. The source code is available at https://github.com/Autodive. | Yi Du, Ludi Wang, Mengyi Huang, Dongze Song, Wenjuan Cui, Yuanchun Zhou |  |
| 9 |  |  [A Practical Toolkit for Multilingual Question and Answer Generation](https://doi.org/10.18653/v1/2023.acl-demo.8) |  | 0 | Generating questions along with associated answers from a text has applications in several domains, such as creating reading comprehension tests for students, or improving document search by providing auxiliary questions and answers based on the query. Training models for question and answer generation (QAG) is not straightforward due to the expected structured output (i.e. a list of question and answer pairs), as it requires more than generating a single sentence. This results in a small number of publicly accessible QAG models. In this paper, we introduce AutoQG, an online service for multilingual QAG along with lmqg, an all-in-one python package for model fine-tuning, generation, and evaluation. We also release QAG models in eight languages fine-tuned on a few variants of pre-trained encoder-decoder language models, which can be used online via AutoQG or locally via lmqg. With these resources, practitioners of any level can benefit from a toolkit that includes a web interface for end users, and easy-to-use code for developers who require custom models or fine-grained controls for generation. | Asahi Ushio, Fernando AlvaManchego, José CamachoCollados |  |
| 10 |  |  [OpenSLU: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding](https://doi.org/10.18653/v1/2023.acl-demo.9) |  | 0 | Spoken Language Understanding (SLU) is one of the core components of a task-oriented dialogue system, which aims to extract the semantic meaning of user queries (e.g., intents and slots). In this work, we introduce OpenSLU, an open-source toolkit to provide a unified, modularized, and extensible toolkit for spoken language understanding. Specifically, OpenSLU unifies 10 SLU models for both single-intent and multi-intent scenarios, which support both non-pretrained and pretrained models simultaneously. Additionally, OpenSLU is highly modularized and extensible by decomposing the model architecture, inference, and learning process into reusable modules, which allows researchers to quickly set up SLU experiments with highly flexible configurations. OpenSLU is implemented based on PyTorch, and released at https://github.com/LightChen233/OpenSLU. | Libo Qin, Qiguang Chen, Xiao Xu, Yunlong Feng, Wanxiang Che |  |
| 11 |  |  [SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface for Pedagogical and Annotation Purposes](https://doi.org/10.18653/v1/2023.acl-demo.10) |  | 0 | We present a neural Sanskrit Natural Language Processing (NLP) toolkit named SanskritShala (a school of Sanskrit) to facilitate computational linguistic analyses for several tasks such as word segmentation, morphological tagging, dependency parsing, and compound type identification. Our systems currently report state-of-the-art performance on available benchmark datasets for all tasks. SanskritShala is deployed as a web-based application, which allows a user to get real-time analysis for the given input. It is built with easy-to-use interactive data annotation features that allow annotators to correct the system predictions when it makes mistakes. We publicly release the source codes of the 4 modules included in the toolkit, 7 word embedding models that have been trained on publicly available Sanskrit corpora and multiple annotated datasets such as word similarity, relatedness, categorization, analogy prediction to assess intrinsic properties of word embeddings. So far as we know, this is the first neural-based Sanskrit NLP toolkit that has a web-based interface and a number of NLP modules. We are sure that the people who are willing to work with Sanskrit will find it useful for pedagogical and annotative purposes. SanskritShala is available at: https://cnerg.iitkgp.ac.in/sanskritshala. The demo video of our platform can be accessed at: https://youtu.be/x0X31Y9k0mw4. | Jivnesh Sandhan, Anshul Agarwal, Laxmidhar Behera, Tushar Sandhan, Pawan Goyal |  |
| 12 |  |  [LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models](https://doi.org/10.18653/v1/2023.acl-demo.11) |  | 0 | Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and multilingual natural language) for interactive chart, infographics and data story generation. Code and demo are available at this url - https://microsoft.github.io/lida/ | Victor Dibia |  |
| 13 |  |  [MetaPro Online: A Computational Metaphor Processing Online System](https://doi.org/10.18653/v1/2023.acl-demo.12) |  | 0 | Metaphoric expressions are a special linguistic phenomenon, frequently appearing in everyday language. Metaphors do not take their literal meanings in contexts, which may cause obstacles for language learners to understand them. Metaphoric expressions also reflect the cognition of humans via concept mappings, attracting great attention from cognitive science and psychology communities. Thus, we aim to develop a computational metaphor processing online system, termed MetaPro Online, that allows users without a coding background, e.g., language learners and linguists, to easily query metaphoricity labels, metaphor paraphrases, and concept mappings for non-domain-specific text. The outputs of MetaPro can be directly used by language learners and natural language processing downstream tasks because MetaPro is an end-to-end system. | Rui Mao, Xiao Li, Kai He, Mengshi Ge, Erik Cambria |  |
| 14 |  |  [DIAGRAPH: An Open-Source Graphic Interface for Dialog Flow Design](https://doi.org/10.18653/v1/2023.acl-demo.13) |  | 0 | In this work, we present DIAGRAPH, an open-source graphical dialog flow editor built on the ADVISER toolkit. Our goal for this tool is threefold: 1) To support subject-experts to intuitively create complex and flexible dialog systems,2) To support rapid prototyping of dialog system behavior, e.g., for research, and 3) To provide a hands-on test bed for students learning about dialog systems. To facilitate this, DIAGRAPH aims to provide a clean and intuitive graphical interface for creating dialog systems without requiring any coding knowledge. Once a dialog graph has been created, it is automatically turned into a dialog system using state of the art language models. This allows for rapid prototyping and testing. Dialog designers can then distribute a link to their finished dialog system or embed it into a website.Additionally, to support scientific experiments and data collection, dialog designers can access chat logs. Finally, to verify the usability of DIAGRAPH, we performed evaluation with subject-experts who extensively worked with the tool and users testing it for the first time, receiving above average System Usability Scale (SUS) scores from both (82 out 100 and 75 out of 100, respectively).In this way, we hope DIAGRAPH helps reduce the barrier to entry for creating dialog interactions. | Dirk Väth, Lindsey Vanderlyn, Ngoc Thang Vu |  |
| 15 |  |  [disco: a toolkit for Distributional Control of Generative Models](https://doi.org/10.18653/v1/2023.acl-demo.14) |  | 0 | Pre-trained language models and other generative models have revolutionized NLP and beyond. However, these models tend to reproduce undesirable biases present in their training data. Also, they may overlook patterns that are important but challenging to capture. To address these limitations, researchers have introduced distributional control techniques. These techniques, not limited to language, allow controlling the prevalence (i.e. expectations) of any features of interest in the model’s outputs. Despite their potential, the widespread adoption of these techniques has been hindered by the difficulty in adapting the complex, disconnected code. Here, we present disco, an open-source Python library that brings these techniques to the broader public | Germán Kruszewski, Jos Rozen, Marc Dymetman |  |
| 16 |  |  [A Hyperparameter Optimization Toolkit for Neural Machine Translation Research](https://doi.org/10.18653/v1/2023.acl-demo.15) |  | 0 | Hyperparameter optimization is an important but often overlooked process in the research of deep learning technologies. To obtain a good model, one must carefully tune hyperparameters that determine the architecture and training algorithm. Insufficient tuning may result in poor results, while inequitable tuning may lead to exaggerated differences between models. We present a hyperparameter optimization toolkit for neural machine translation (NMT) to help researchers focus their time on the creative rather than the mundane. The toolkit is implemented as a wrapper on top of the open-source Sockeye NMT software. Using the Asynchronous Successive Halving Algorithm (ASHA), we demonstrate that it is possible to discover near-optimal models under a computational budget with little effort. Code: https://github.com/kevinduh/sockeye-recipes3Video demo: https://cs.jhu.edu/kevinduh/j/demo.mp4 | Xuan Zhang, Kevin Duh, Paul McNamee |  |
| 17 |  |  [Japanese-to-English Simultaneous Dubbing Prototype](https://doi.org/10.18653/v1/2023.acl-demo.16) |  | 0 | Live video streaming has become an important form of communication such as virtual conferences. However, for cross-language communication in live video streaming, reading subtitles degrades the viewing experience. To address this problem, our simultaneous dubbing prototype translates and replaces the original speech of a live video stream in a simultaneous manner. Tests on a collection of 90 public videos show that our system achieves a low average latency of 11.90 seconds for smooth playback. Our method is general and can be extended to other language pairs. | Xiaolin Wang, Masao Utiyama, Eiichiro Sumita |  |
| 18 |  |  [VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering](https://doi.org/10.18653/v1/2023.acl-demo.17) |  | 0 | We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries. VisKoP not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements. KoPL programs can be edited with simple graphical operators, such as ”dragging” to add knowledge operators and ”slot filling” to designate operator arguments. Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results. To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end. Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer. The VisKoP online demo, highly efficient KoPL engine, and screencast video are now publicly available. | Zijun Yao, Yuanyong Chen, Xin Lv, Shulin Cao, Amy Xin, Jifan Yu, Hailong Jin, Jianjun Xu, Peng Zhang, Lei Hou, Juanzi Li |  |
| 19 |  |  [PEEP-Talk: A Situational Dialogue-based Chatbot for English Education](https://doi.org/10.18653/v1/2023.acl-demo.18) |  | 0 | English is acknowledged worldwide as a mode of communication. However, due to the absence of realistic practicing scenarios, students learning English as a foreign language (EFL) typically have limited chances to converse and share feedback with others. In this paper, we propose PEEP-Talk, a real-world situational dialogue-based chatbot designed for English education. It also naturally switches to a new topic or situation in response to out-of-topic utterances, which are common among English beginners. Furthermore, PEEP-Talk provides feedback score on conversation and grammar error correction. We performed automatic and user evaluations to validate performance and education efficiency of our system. The results show that PEEP-Talk generates appropriate responses in various real-life situations while providing accurate feedback to learners. Moreover, we demonstrate a positive impact on English-speaking, grammar, and English learning anxiety, implying that PEEP-Talk can lower the barrier to learning natural conversation in effective ways. | Seungjun Lee, Yoonna Jang, Chanjun Park, Jungseob Lee, Jaehyung Seo, Hyeonseok Moon, Sugyeong Eo, Seounghoon Lee, Bernardo Yahya, Heuiseok Lim |  |
| 20 |  |  [OpenTIPE: An Open-source Translation Framework for Interactive Post-Editing Research](https://doi.org/10.18653/v1/2023.acl-demo.19) |  | 0 | Despite the latest improvements on machine translation, professional translators still must review and post-edit the automatic output to ensure high-quality translations. The research on automating this process lacks an interactive post-editing environment implemented for this purpose; therefore, current approaches do not consider the human interactions that occur in real post-editing scenarios. To address this issue, we present OpenTIPE, a flexible and extensible framework that aims at supporting research on interactive post-editing. Specifically, the interactive environment of OpenTIPE allows researchers to explore human-centered approaches for the post-editing task. We release the OpenTIPE source code and showcase its main functionalities with a demonstration video and an online live demo. | Fabian Landwehr, Thomas Steinmann, Laura Mascarell |  |
| 21 |  |  [TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities](https://doi.org/10.18653/v1/2023.acl-demo.20) |  | 0 | Recently, the success of pre-training in text domain has been fully extended to vision, audio, and cross-modal scenarios. The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework. In this paper, we present TencentPretrain, a toolkit supporting pre-training models of different modalities. The core feature of TencentPretrain is the modular design. The toolkit uniformly divides pre-training models into 5 components: embedding, encoder, target embedding, decoder, and target. As almost all of common modules are provided in each component, users can choose the desired modules from different components to build a complete pre-training model. The modular design enables users to efficiently reproduce existing pre-training models or build brand-new one. We test the toolkit on text, vision, and audio benchmarks and show that it can match the performance of the original implementations. | Zhe Zhao, Yudong Li, Cheng Hou, Jing Zhao, Rong Tian, Weijie Liu, Yiren Chen, Ningyuan Sun, Haoyan Liu, Weiquan Mao, Han Guo, Weigang Guo, Taiqiang Wu, Tao Zhu, Wenhang Shi, Chen Chen, Shan Huang, Sihong Chen, Liqun Liu, Feifei Li, Xiaoshuai Chen, Xingwu Sun, Zhanhui Kang, Xiaoyong Du, Linlin Shen, Kimmo Yan |  |
| 22 |  |  [NeuroX Library for Neuron Analysis of Deep NLP Models](https://doi.org/10.18653/v1/2023.acl-demo.21) |  | 0 | Neuron analysis provides insights into how knowledge is structured in representations and discovers the role of neurons in the network. In addition to developing an understanding of our models, neuron analysis enables various applications such as debiasing, domain adaptation and architectural search. We present NeuroX, a comprehensive open-source toolkit to conduct neuron analysis of natural language processing models. It implements various interpretation methods under a unified API, and provides a framework for data processing and evaluation, thus making it easier for researchers and practitioners to perform neuron analysis. The Python toolkit is available at https://www.github.com/fdalvi/NeuroX.Demo Video available at: https://youtu.be/mLhs2YMx4u8 | Fahim Dalvi, Hassan Sajjad, Nadir Durrani |  |
| 23 |  |  [SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation](https://doi.org/10.18653/v1/2023.acl-demo.22) |  | 0 | Scientific writing involves retrieving, summarizing, and citing relevant papers, which can be time-consuming processes. Although in many workflows these processes are serially linked, there are opportunities for natural language processing (NLP) to provide end-to-end assistive tools. We propose SciLit, a pipeline that automatically recommends relevant papers, extracts highlights, and suggests a reference sentence as a citation of a paper, taking into consideration the user-provided context and keywords. SciLit efficiently recommends papers from large databases of hundreds of millions of papers using a two-stage pre-fetching and re-ranking literature search system that flexibly deals with addition and removal of a paper database. We provide a convenient user interface that displays the recommended papers as extractive summaries and that offers abstractively-generated citing sentences which are aligned with the provided context and which mention the chosen keyword(s). Our assistive tool for literature discovery and scientific writing is available at https://scilit.vercel.app | Nianlong Gu, Richard H. R. Hahnloser |  |
| 24 |  |  [Massively Multi-Lingual Event Understanding: Extraction, Visualization, and Search](https://doi.org/10.18653/v1/2023.acl-demo.23) |  | 0 | In this paper, we present ISI-Clear, a state-of-the-art, cross-lingual, zero-shot event extraction system and accompanying user interface for event visualization & search. Using only English training data, ISI-Clear makes global events available on-demand, processing user-supplied text in 100 languages ranging from Afrikaans to Yiddish. We provide multiple event-centric views of extracted events, including both a graphical representation and a document-level summary. We also integrate existing cross-lingual search algorithms with event extraction capabilities to provide cross-lingual event-centric search, allowing English-speaking users to search over events automatically extracted from a corpus of non-English documents, using either English natural language queries (e.g. “cholera outbreaks in Iran”) or structured queries (e.g. find all events of type Disease-Outbreak with agent “cholera” and location “Iran”). | Chris Jenkins, Shantanu Agarwal, Joel Barry, Steven Fincke, Elizabeth Boschee |  |
| 25 |  |  [YANMTT: Yet Another Neural Machine Translation Toolkit](https://doi.org/10.18653/v1/2023.acl-demo.24) |  | 0 | In this paper, we present our open-source neural machine translation (NMT) toolkit called “Yet Another Neural Machine Translation Toolkit” abbreviated as YANMTT - https://github.com/prajdabre/yanmtt, which is built on top of the HuggingFace Transformers library. YANMTT focuses on transfer learning and enables easy pre-training and fine-tuning of sequence-to-sequence models at scale. It can be used for training parameter-heavy models with minimal parameter sharing and efficient, lightweight models via heavy parameter sharing. Additionally, it supports parameter-efficient fine-tuning (PEFT) through adapters and prompts. Our toolkit also comes with a user interface that can be used to demonstrate these models and visualize various parts of the model. Apart from these core features, our toolkit also provides other advanced functionalities such as but not limited to document/multi-source NMT, simultaneous NMT, mixtures-of-experts, model compression and continual learning. | Raj Dabre, Diptesh Kanojia, Chinmay Sawant, Eiichiro Sumita |  |
| 26 |  |  [XMD: An End-to-End Framework for Interactive Explanation-Based Debugging of NLP Models](https://doi.org/10.18653/v1/2023.acl-demo.25) |  | 0 | NLP models are susceptible to learning spurious biases (i.e., bugs) that work on some datasets but do not properly reflect the underlying task. Explanation-based model debugging aims to resolve spurious biases by showing human users explanations of model behavior, asking users to give feedback on the behavior, thenusing the feedback to update the model. While existing model debugging methods have shown promise, their prototype-level implementations provide limited practical utility. Thus, we propose XMD: the first open-source, end-to-end framework for explanation-based model debugging. Given task- or instance-level explanations,users can flexibly provide various forms of feedback via an intuitive, web-based UI. After receiving user feedback, XMD automatically updates the model in real time, by regularizing the model so that its explanationsalign with the user feedback. The new model can then be easily deployed into real-world applications via Hugging Face. Using XMD, we can improve the model’s OOD performance on text classification tasks by up to 18%. | DongHo Lee, Akshen Kadakia, Brihi Joshi, Aaron Chan, Ziyi Liu, Kiran Narahari, Takashi Shibuya, Ryosuke Mitani, Toshiyuki Sekiya, Jay Pujara, Xiang Ren |  |
| 27 |  |  [OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models](https://doi.org/10.18653/v1/2023.acl-demo.26) |  | 0 | The scale of large pre-trained models (PTMs) poses significant challenges in adapting to downstream tasks due to the high optimization overhead and storage costs associated with full-parameter fine-tuning. To address this, many studies explore parameter-efficient tuning methods, also framed as “delta tuning” in Ding et al. (2022), which updates only a small subset of parameters, known as “delta modules”, while keeping the backbone model’s parameters fixed. However, the practicality and flexibility of delta tuning have been limited due to existing implementations that directly modify the code of the backbone PTMs and hard-code specific delta tuning methods for each PTM. In this paper, we present OpenDelta, an open-source library that overcomes these limitations by providing a plug-and-play implementation of various delta tuning methods. Our novel techniques eliminate the need to modify the backbone PTMs’ code, making OpenDelta compatible with different, even novel PTMs. OpenDelta is designed to be simple, modular, and extensible, providing a comprehensive platform for researchers and practitioners to adapt large PTMs efficiently. | Shengding Hu, Ning Ding, Weilin Zhao, Xingtai Lv, Zhen Zhang, Zhiyuan Liu, Maosong Sun |  |
| 28 |  |  [Hierarchy Builder: Organizing Textual Spans into a Hierarchy to Facilitate Navigation](https://doi.org/10.18653/v1/2023.acl-demo.27) |  | 0 | Information extraction systems often producehundreds to thousands of strings on a specifictopic. We present a method that facilitatesbetter consumption of these strings, in an ex-ploratory setting in which a user wants to bothget a broad overview of what’s available, and achance to dive deeper on some aspects. The sys-tem works by grouping similar items together,and arranging the remaining items into a hierar-chical navigable DAG structure. We apply themethod to medical information extraction. | Itay Yair, Hillel TaubTabib, Yoav Goldberg |  |
| 29 |  |  [CARE: Collaborative AI-Assisted Reading Environment](https://doi.org/10.18653/v1/2023.acl-demo.28) |  | 0 | Recent years have seen impressive progress in AI-assisted writing, yet the developments in AI-assisted reading are lacking. We propose inline commentary as a natural vehicle for AI-based reading assistance, and present CARE: the first open integrated platform for the study of inline commentary and reading. CARE facilitates data collection for inline commentaries in a commonplace collaborative reading environment, and provides a framework for enhancing reading with NLP-based assistance, such as text classification, generation or question answering. The extensible behavioral logging allows unique insights into the reading and commenting behavior, and flexible configuration makes the platform easy to deploy in new scenarios. To evaluate CARE in action, we apply the platform in a user study dedicated to scholarly peer review. CARE facilitates the data collection and study of inline commentary in NLP, extrinsic evaluation of NLP assistance, and application prototyping. We invite the community to explore and build upon the open source implementation of CARE.Github Repository: https://github.com/UKPLab/CAREPublic Live Demo: https://care.ukp.informatik.tu-darmstadt.de | Dennis Zyska, Nils Dycke, Jan Buchmann, Ilia Kuznetsov, Iryna Gurevych |  |
| 30 |  |  [The ROOTS Search Tool: Data Transparency for LLMs](https://doi.org/10.18653/v1/2023.acl-demo.29) |  | 0 | ROOTS is a 1.6TB multilingual text corpus developed for the training of BLOOM, currently the largest language model explicitly accompanied by commensurate data governance efforts. In continuation of these efforts, we present the ROOTS Search Tool: a search engine over the entire ROOTS corpus offering both fuzzy and exact search capabilities. ROOTS is the largest corpus to date that can be investigated this way. The ROOTS Search Tool is open-sourced and available on Hugging Face Spaces: https://huggingface.co/spaces/bigscience-data/roots-search. We describe our implementation and the possible use cases of our tool. | Aleksandra Piktus, Christopher Akiki, Paulo Villegas, Hugo Laurençon, Gérard Dupont, Sasha Luccioni, Yacine Jernite, Anna Rogers |  |
| 31 |  |  [The OPUS-MT Dashboard - A Toolkit for a Systematic Evaluation of Open Machine Translation Models](https://doi.org/10.18653/v1/2023.acl-demo.30) |  | 0 | The OPUS-MT dashboard is a web-based platform that provides a comprehensive overview of open translation models. We focus on a systematic collection of benchmark results with verifiable translation performance and large coverage in terms of languages and domains. We provide results for in-house OPUS-MT and Tatoeba models as well as external models from the Huggingface repository and user-contributed translations. The functionalities of the evaluation tool include summaries of benchmarks for over 2,300 models covering 4,560 language directions and 294 languages, as well as the inspection of predicted translations against their human reference. We focus on centralization, reproducibility and coverage of MT evaluation combined with scalability. The dashboard can be accessed live at https://opus.nlpl.eu/dashboard/. | Jörg Tiedemann, Ona de Gibert |  |
| 32 |  |  [The D-WISE Tool Suite: Multi-Modal Machine-Learning-Powered Tools Supporting and Enhancing Digital Discourse Analysis](https://doi.org/10.18653/v1/2023.acl-demo.31) |  | 0 | This work introduces the D-WISE Tool Suite (DWTS), a novel working environment for digital qualitative discourse analysis in the Digital Humanities (DH). The DWTS addresses limitations of current DH tools induced by the ever-increasing amount of heterogeneous, unstructured, and multi-modal data in which the discourses of contemporary societies are encoded. To provide meaningful insights from such data, our system leverages and combines state-of-the-art machine learning technologies from Natural Language Processing and Com-puter Vision. Further, the DWTS is conceived and developed by an interdisciplinary team ofcultural anthropologists and computer scientists to ensure the tool’s usability for modernDH research. Central features of the DWTS are: a) import of multi-modal data like text, image, audio, and video b) preprocessing pipelines for automatic annotations c) lexical and semantic search of documents d) manual span, bounding box, time-span, and frame annotations e) documentation of the research process. | Florian Schneider, Tim Fischer, Fynn PetersenFrey, Isabel Eiser, Gertraud Koch, Chris Biemann |  |
| 33 |  |  [OpenRT: An Open-source Framework for Reasoning Over Tabular Data](https://doi.org/10.18653/v1/2023.acl-demo.32) |  | 0 | There are a growing number of table pre-training methods proposed for reasoning over tabular data (e.g., question answering, fact checking, and faithful text generation). However, most existing methods are benchmarked solely on a limited number of datasets, varying in configuration, which leads to a lack of unified, standardized, fair, and comprehensive comparison between methods. This paper presents OpenRT, the first open-source framework for reasoning over tabular data, to reproduce existing table pre-training models for performance comparison and develop new models quickly. We implemented and compared six table pre-training models on four question answering, one fact checking, and one faithful text generation datasets. Moreover, to enable the community to easily construct new table reasoning datasets, we developed TaRAT, an annotation tool which supports multi-person collaborative annotations for various kinds of table reasoning tasks. The researchers are able to deploy the newly-constructed dataset to OpenRT and compare the performances of different baseline systems. | Yilun Zhao, Boyu Mi, Zhenting Qi, Linyong Nan, Minghao Guo, Arman Cohan, Dragomir Radev |  |
| 34 |  |  [UINAUIL: A Unified Benchmark for Italian Natural Language Understanding](https://doi.org/10.18653/v1/2023.acl-demo.33) |  | 0 | This paper introduces the Unified Interactive Natural Understanding of the Italian Language (UINAUIL), a benchmark of six tasks for Italian Natural Language Understanding. We present a description of the tasks and software library that collects the data from the European Language Grid, harmonizes the data format, and exposes functionalities to facilitates data manipulation and the evaluation of custom models. We also present the results of tests conducted with available Italian and multilingual language models on UINAUIL, providing an updated picture of the current state of the art in Italian NLU. | Valerio Basile, Livio Bioglio, Alessio Bosca, Cristina Bosco, Viviana Patti |  |
| 35 |  |  [Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction](https://doi.org/10.18653/v1/2023.acl-demo.34) |  | 0 | The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training. ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years. With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance. There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models. In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges. Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we have designed our framework to support the industry with readily available APIs for production under the standard SpaCy NLP pipeline. Our API is extendible and evaluable, moreover, we include numerous enhancements such as boosting the accuracy with pipeline ensembling and visualization utilities available as a SpaCy extension. | Gabriele Picco, Marcos Martínez Galindo, Alberto Purpura, Leopold Fuchs, Vanessa López, Thanh Lam Hoang |  |
| 36 |  |  [BiSync: A Bilingual Editor for Synchronized Monolingual Texts](https://doi.org/10.18653/v1/2023.acl-demo.35) |  | 0 | In our globalized world, a growing number of situations arise where people are required to communicate in one or several foreign languages. In the case of written communication, users with a good command of a foreign language may find assistance from computer-aided translation (CAT) technologies. These technologies often allow users to access external resources, such as dictionaries, terminologies or bilingual concordancers, thereby interrupting and considerably hindering the writing process. In addition, CAT systems assume that the source sentence is fixed and also restrict the possible changes on the target side. In order to make the writing process smoother, we present BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. We also include additional functionalities, such as the display of alternative prefix translations and paraphrases, which are intended to facilitate the authoring of texts. We detail the model architecture used for synchronization and evaluate the resulting tool, showing that high accuracy can be attained with limited computational resources. The interface and models are publicly available at https://github.com/jmcrego/BiSync and a demonstration video can be watched on YouTube https://youtu.be/_l-ugDHfNgU. | Josep Maria Crego, Jitao Xu, François Yvon |  |
| 37 |  |  [Riveter: Measuring Power and Social Dynamics Between Entities](https://doi.org/10.18653/v1/2023.acl-demo.36) |  | 0 | Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research. | Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap |  |
| 38 |  |  [Fast Whitespace Correction with Encoder-Only Transformers](https://doi.org/10.18653/v1/2023.acl-demo.37) |  | 0 | The goal of whitespace correction is to fix space errors in arbitrary given text. For example, given the text “whi te space correctio nwithTransf or mers”, produce “whitespace correction with Transformers”. We compare two Transformer-based models, a character-level encoder-decoder model and a byte-level encoder-only model. We find that the encoder-only model is both faster and achieves higher quality. We provide an easy-to-use tool that is over 900 times faster than the previous best tool, with the same high quality. Our tool repairs text at a rate of over 200 kB/s on GPU, with a sequence-averaged F1-score ranging from 87.5% for hard-to-correct text up to 99% for text without any spaces. | Hannah Bast, Matthias Hertel, Sebastian Walter |  |
| 39 |  |  [ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit](https://doi.org/10.18653/v1/2023.acl-demo.38) |  | 0 | ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) – each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet. | Brian Yan, Jiatong Shi, Yun Tang, Hirofumi Inaguma, Yifan Peng, Siddharth Dalmia, Peter Polak, Patrick Fernandes, Dan Berrebbi, Tomoki Hayashi, Xiaohui Zhang, Zhaoheng Ni, Moto Hira, Soumi Maiti, Juan Pino, Shinji Watanabe |  |
| 40 |  |  [CB2: Collaborative Natural Language Interaction Research Platform](https://doi.org/10.18653/v1/2023.acl-demo.39) |  | 0 | CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at https://cb2.ai as a system demonstration with a learned instruction following model. | Jacob Sharf, Mustafa Omer Gul, Yoav Artzi |  |
| 41 |  |  [Inseq: An Interpretability Toolkit for Sequence Generation Models](https://doi.org/10.18653/v1/2023.acl-demo.40) |  | 0 | Past work in natural language processing interpretability focused mainly on popular classification tasks while largely overlooking generation settings, partly due to a lack of dedicated tools. In this work, we introduce Inseq, a Python library to democratize access to interpretability analyses of sequence generation models. Inseq enables intuitive and optimized extraction of models’ internal information and feature importance scores for popular decoder-only and encoder-decoder Transformers architectures. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Thanks to its extensible interface supporting cutting-edge techniques such as contrastive feature attribution, Inseq can drive future advances in explainable natural language generation, centralizing good practices and enabling fair and reproducible model evaluations. | Gabriele Sarti, Nils Feldhus, Ludwig Sickert, Oskar van der Wal |  |
| 42 |  |  [Pipeline for modeling causal beliefs from natural language](https://doi.org/10.18653/v1/2023.acl-demo.41) |  | 0 | We present a causal language analysis pipeline that leverages a Large Language Model to identify causal claims made in natural language documents, and aggregates claims across a corpus to produce a causal claim network. The pipeline then applies a clustering algorithm that groups causal claims based on their semantic topics. We demonstrate the pipeline by modeling causal belief systems surrounding the Covid-19 vaccine from tweets. | John Priniski, Ishaan Verma, Fred Morstatter |  |
| 43 |  |  [TabGenie: A Toolkit for Table-to-Text Generation](https://doi.org/10.18653/v1/2023.acl-demo.42) |  | 0 | Heterogenity of data-to-text generation datasets limits the research on data-to-text generation systems. We present TabGenie – a toolkit which enables researchers to explore, preprocess, and analyze a variety of data-to-text generation datasets through the unified framework of table-to-text generation. In TabGenie, all inputs are represented as tables with associated metadata. The tables can be explored through a web interface, which also provides an interactive mode for debugging table-to-text generation, facilitates side-by-side comparison of generated system outputs, and allows easy exports for manual analysis. Furthermore, TabGenie is equipped with command line processing tools and Python bindings for unified dataset loading and processing. We release TabGenie as a PyPI package and provide its open-source code and a live demo at https://github.com/kasnerz/tabgenie. | Zdenek Kasner, Ekaterina Garanina, Ondrej Plátek, Ondrej Dusek |  |
| 44 |  |  [An Efficient Conversational Smart Compose System](https://doi.org/10.18653/v1/2023.acl-demo.43) |  | 0 | Online conversation is a ubiquitous way to share information and connect everyone but repetitive idiomatic text typing takes users a lot of time. This paper demonstrates a simple yet effective cloud based smart compose system to improve human-to-human conversation efficiency. Heuristics from different perspectives are designed to achieve the best trade-off between quality and latency. From the modeling side, the decoder-only model exploited the previous turns of conversational history in a computation lightweight manner. Besides, a novel phrase tokenizer is proposed to reduce latency without losing the composing quality further. Additionally, the caching mechanism is applied to the serving framework. The demo video of the system is available at https://youtu.be/U1KXkaqr60g.We open-sourced our phrase tokenizer in https://github.com/tensorflow/text. | Yun Zhu, Xiayu Chen, Lei Shu, Bowen Tan, Xinying Song, Lijuan Liu, Maria Wang, Jindong Chen, Ning Ruan |  |
| 45 |  |  [Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals](https://doi.org/10.18653/v1/2023.acl-demo.44) |  | 0 | We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models’ robustness by creating adversarial test suites. | Robin Chan, Afra Amini, Mennatallah ElAssady |  |
| 46 |  |  [LaTeX2Solver: a Hierarchical Semantic Parsing of LaTeX Document into Code for an Assistive Optimization Modeling Application](https://doi.org/10.18653/v1/2023.acl-demo.45) |  | 0 | We demonstrate an interactive system to help operations research (OR) practitioners convert the mathematical formulation of optimization problems from TeX document format into the solver modeling language. In practice, a manual translation is cumbersome and time-consuming. Moreover, it requires an in-depth understanding of the problem description and a technical expertise to produce the modeling code. Thus, our proposed system TeX2Solver helps partially automate this conversion and help the users build optimization models more efficiently. In this paper, we describe its interface and the components of the hierarchical parsing system. A video demo walk-through is available online at http://bit.ly/3kuOm3x | Rindra Ramamonjison, Timothy T. L. Yu, Linzi Xing, Mahdi Mostajabdaveh, Xiaorui Li, Xiaojin Fu, Xiongwei Han, Yuanzhe Chen, Ren Li, Kun Mao, Yong Zhang |  |
| 47 |  |  [Alfred: A System for Prompted Weak Supervision](https://doi.org/10.18653/v1/2023.acl-demo.46) |  | 0 | Alfred is the first system for programmatic weak supervision (PWS) that creates training data for machine learning by prompting. In contrast to typical PWS systems where weak supervision sources are programs coded by experts, Alfred enables users to encode their subject matter expertise via natural language prompts for language and vision-language models. Alfred provides a simple Python interface for the key steps of this emerging paradigm, with a high-throughput backend for large-scale data labeling. Users can quickly create, evaluate, and refine their prompt-based weak supervision sources; map the results to weak labels; and resolve their disagreements with a label model. Alfred enables a seamless local development experience backed by models served from self-managed computing clusters. It automatically optimizes the execution of prompts with optimized batching mechanisms. We find that this optimization improves query throughput by 2.9x versus a naive approach. We present two example use cases demonstrating Alfred on YouTube comment spam detection and pet breeds classification. Alfred is open source, available at https://github.com/BatsResearch/alfred. | Peilin Yu, Stephen H. Bach |  |
| 48 |  |  [OpenICL: An Open-Source Framework for In-context Learning](https://doi.org/10.18653/v1/2023.acl-demo.47) |  | 0 | In recent years, In-context Learning (ICL) has gained increasing attentionand emerged as the new paradigm for large language model (LLM) evaluation. Unlike traditional fine-tuning methods, ICL instead adapts the pre-trained models to unseen tasks without any parameter updates. However, the implementation of ICL is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks. A unified and flexible framework for ICL is urgently needed to ease the implementation of the aforementioned components. To facilitate ICL research, we introduce OpenICL, an open-source toolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly flexible architecture that users can easily combine different components to suit their needs. It also provides various state-of-the-art retrieval and inference methods to streamline the process of adapting ICL to cutting-edge research. The effectiveness of OpenICL has been validated on a wide range of NLP tasks, including classification, QA, machine translation, and semantic parsing. As a side-product, we found OpenICL to be an efficient yet robust tool for LLMs evaluation. OpenICL is released at https://github.com/Shark-NLP/OpenICL. | Zhenyu Wu, Yaoxiang Wang, Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Jingjing Xu, Yu Qiao |  |
| 49 |  |  [Self-Supervised Sentence Polishing by Adding Engaging Modifiers](https://doi.org/10.18653/v1/2023.acl-demo.48) |  | 0 | Teachers often guide students to improve their essays by adding engaging modifiers to polish the sentences. In this work, we present the first study on automatic sentence polishing by adding modifiers. Since there is no available dataset for the new task, we first automatically construct a large number of parallel data by removing modifiers in the engaging sentences collected from public resources. Then we fine-tune LongLM to reconstruct the original sentences from the corrupted ones. Considering that much overlap between inputs and outputs may bias the model to completely copy the inputs, we split each source sentence into sub-sentences and only require the model to generate the modified sub-sentences. Furthermore, we design a retrieval augmentation algorithm to prompt the model to add suitable modifiers. Automatic and manual evaluation on the auto-constructed test set and real human texts show that our model can generate more engaging sentences with suitable modifiers than strong baselines while keeping fluency. We deploy the model at http://coai.cs.tsinghua.edu.cn/static/polishSent/. A demo video is available at https://youtu.be/Y6gFHOgSv8Y. | Zhexin Zhang, Jian Guan, Xin Cui, Yu Ran, Bo Liu, Minlie Huang |  |
| 50 |  |  [Effidit: An Assistant for Improving Writing Efficiency](https://doi.org/10.18653/v1/2023.acl-demo.49) |  | 0 | Writing assistants are valuable tools that can help writers improve their writing skills. We introduce Effidit (Efficient and Intelligent Editing), a digital writing assistant that facilitates users to write higher-quality text more efficiently through the use of Artificial Intelligence (AI) and Natural Language Processing (NLP) technologies. We significantly expand the capacities of a writing assistantby providing functions in three modules: text completion, hint recommendation, and writing refinement. Based on the above efforts, Effidit can efficiently assist users in creating their own text. Effidit has been deployed to several Tencent products and publicly released at https://effidit.qq.com/. | Shuming Shi, Enbo Zhao, Wei Bi, Deng Cai, Leyang Cui, Xinting Huang, Haiyun Jiang, Duyu Tang, Kaiqiang Song, Longyue Wang, Chenyan Huang, Guoping Huang, Yan Wang, Piji Li |  |
| 51 |  |  [WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings](https://doi.org/10.18653/v1/2023.acl-demo.50) |  | 0 | Machine learning models often learn latent embedding representations that capture the domain semantics of their training data. These embedding representations are valuable for interpreting trained models, building new models, and analyzing new datasets. However, interpreting and using embeddings can be challenging due to their opaqueness, high dimensionality, and the large size of modern datasets. To tackle these challenges, we present WizMap, an interactive visualization tool to help researchers and practitioners easily explore large embeddings. With a novel multi-resolution embedding summarization method and a familiar map-like interaction design, WizMap enables users to navigate and interpret embedding spaces with ease. Leveraging modern web technologies such as WebGL and Web Workers, WizMap scales to millions of embedding points directly in users’ web browsers and computational notebooks without the need for dedicated backend servers. WizMap is open-source and available at the following public demo link: https://poloclub.github.io/wizmap. | Zijie J. Wang, Fred Hohman, Duen Horng Chau |  |
| 52 |  |  [A System for Answering Simple Questions in Multiple Languages](https://doi.org/10.18653/v1/2023.acl-demo.51) |  | 0 | Our research focuses on the most prevalent type of queries— simple questions —exemplified by questions like “What is the capital of France?”. These questions reference an entity such as “France”, which is directly connected (one hop) to the answer entity “Paris” in the underlying knowledge graph (KG). We propose a multilingual Knowledge Graph Question Answering (KGQA) technique that orders potential responses based on the distance between the question’s text embeddings and the answer’s graph embeddings. A system incorporating this novel method is also described in our work. Through comprehensive experimentation using various English and multilingual datasets and two KGs — Freebase and Wikidata — we illustrate the comparative advantage of the proposed method across diverse KG embeddings and languages. This edge is apparent even against robust baseline systems, including seq2seq QA models, search-based solutions and intricate rule-based pipelines. Interestingly, our research underscores that even advanced AI systems like ChatGPT encounter difficulties when tasked with answering simple questions. This finding emphasizes the relevance and effectiveness of our approach, which consistently outperforms such systems. We are making the source code and trained models from our study publicly accessible to promote further advancements in multilingual KGQA. | Anton Razzhigaev, Mikhail Salnikov, Valentin Malykh, Pavel Braslavski, Alexander Panchenko |  |
| 53 |  |  [KWJA: A Unified Japanese Analyzer Based on Foundation Models](https://doi.org/10.18653/v1/2023.acl-demo.52) |  | 0 | We present KWJA, a high-performance unified Japanese text analyzer based on foundation models.KWJA supports a wide range of tasks, including typo correction, word segmentation, word normalization, morphological analysis, named entity recognition, linguistic feature tagging, dependency parsing, PAS analysis, bridging reference resolution, coreference resolution, and discourse relation analysis, making it the most versatile among existing Japanese text analyzers.KWJA solves these tasks in a multi-task manner but still achieves competitive or better performance compared to existing analyzers specialized for each task.KWJA is publicly available under the MIT license at https://github.com/ku-nlp/kwja. | Nobuhiro Ueda, Kazumasa Omura, Takashi Kodama, Hirokazu Kiyomaru, Yugo Murawaki, Daisuke Kawahara, Sadao Kurohashi |  |
| 54 |  |  [Disease Network Constructor: a Pathway Extraction and Visualization](https://doi.org/10.18653/v1/2023.acl-demo.53) |  | 0 | We present Disease Network Constructor (DNC), a system that extracts and visualizes a disease network, in which nodes are entities such as diseases, proteins, and genes, and edges represent regulation relation. We focused on the disease network derived through regulation events found in scientific articles on idiopathic pulmonary fibrosis (IPF). The front-end web-base user interface of DNC includes two-dimensional (2D) and 3D visualizations of the constructed disease network. The back-end system of DNC includes several natural language processing (NLP) techniques to process biomedical text including BERT-based tokenization on the basis of Bidirectional Encoder Representations from Transformers (BERT), flat and nested named entity recognition (NER), candidate generation and candidate ranking for entity linking (EL) or, relation extraction (RE), and event extraction (EE) tasks. We evaluated the end-to-end EL and end-to-end nested EE systems to determine the DNC’s back-endimplementation performance. To the best of our knowledge, this is the first attempt that addresses neural NER, EL, RE, and EE tasks in an end-to-end manner that constructs a path-way visualization from events, which we name Disease Network Constructor. The demonstration video can be accessed from https://youtu.be/rFhWwAgcXE8. We release an online system for end users and the source code is available at https://github.com/aistairc/PRISM-APIs/. | Mohammad Golam Sohrab, Khoa Duong, Goran Topic, Ikeda Masami, Nozomi Nagano, Yayoi NatsumeKitatani, Masakata Kuroda, Mari Nogami Itoh, Hiroya Takamura |  |
| 55 |  |  [Petals: Collaborative Inference and Fine-tuning of Large Models](https://doi.org/10.18653/v1/2023.acl-demo.54) |  | 0 | Many NLP tasks benefit from using large language models (LLMs) that often have more than 100 billion parameters. With the release of BLOOM-176B and OPT-175B, everyone can download pretrained models of this scale. Still, using these models requires high-end hardware unavailable to many researchers. In some cases, LLMs can be used more affordably via RAM offloading or hosted APIs. However, these techniques have innate limitations: offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits. In this work, we propose Petals - a system for inference and fine-tuning of large models collaboratively by joining the resources of multiple parties. We demonstrate that this strategy outperforms offloading for very large models, running inference of BLOOM-176B on consumer GPUs with ≈1 step per second, which is enough for many interactive LLM applications. Unlike most inference APIs, Petals also natively exposes hidden states of served models, allowing to train and share custom model extensions based on efficient fine-tuning methods. The system, its source code, and documentation are available at https://petals.mlVideo (2 min): https://youtu.be/F4muLI-0hTE | Alexander Borzunov, Dmitry Baranchuk, Tim Dettmers, Maksim Riabinin, Younes Belkada, Artem Chumachenko, Pavel Samygin, Colin Raffel |  |
| 56 |  |  [UKP-SQuARE v3: A Platform for Multi-Agent QA Research](https://doi.org/10.18653/v1/2023.acl-demo.55) |  | 0 | The continuous development of Question Answering (QA) datasets has drawn the research community’s attention toward multi-domain models. A popular approach is to use multi-dataset models, which are models trained on multiple datasets to learn their regularities and prevent overfitting to a single dataset. However, with the proliferation of QA models in online repositories such as GitHub or Hugging Face, an alternative is becoming viable. Recent works have demonstrated that combining expert agents can yield large performance gains over multi-dataset models. To ease research in multi-agent models, we extend UKP-SQuARE, an online platform for QA research, to support three families of multi-agent systems: i) agent selection, ii) early-fusion of agents, and iii) late-fusion of agents. We conduct experiments to evaluate their inference speed and discuss the performance vs. speed trade-off compared to multi-dataset models. UKP-SQuARE is open-source and publicly available. | Haritz Puerto, Tim Baumgärtner, Rachneet Sachdeva, Haishuo Fang, Hao Zhang, Sewin Tariverdian, Kexin Wang, Iryna Gurevych |  |
| 57 |  |  [Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation](https://doi.org/10.18653/v1/2023.acl-demo.56) |  | 0 | In this paper, we introduce Ranger - a toolkit to facilitate the easy use of effect-size-based meta-analysis for multi-task evaluation in NLP and IR. We observed that our communities often face the challenge of aggregating results over incomparable metrics and scenarios, which makes conclusions and take-away messages less reliable. With Ranger, we aim to address this issue by providing a task-agnostic toolkit that combines the effect of a treatment on multiple tasks into one statistical evaluation, allowing for comparison of metrics and computation of an overall summary effect. Our toolkit produces publication-ready forest plots that enable clear communication of evaluation results over multiple tasks. Our goal with the ready-to-use Ranger toolkit is to promote robust, effect-size-based evaluation and improve evaluation standards in the community. We provide two case studies for common IR and NLP settings to highlight Ranger’s benefits. | Mete Sertkan, Sophia Althammer, Sebastian Hofstätter |  |
| 58 |  |  [GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training Data Exploration](https://doi.org/10.18653/v1/2023.acl-demo.57) |  | 0 | Noticing the urgent need to provide tools for fast and user-friendly qualitative analysis of large-scale textual corpora of the modern NLP, we propose to turn to the mature and well-tested methods from the domain of Information Retrieval (IR) - a research field with a long history of tackling TB-scale document collections. We discuss how Pyserini - a widely used toolkit for reproducible IR research can be integrated with the Hugging Face ecosystem of open-source AI libraries and artifacts. We leverage the existing functionalities of both platforms while proposing novel features further facilitating their integration. Our goal is to give NLP researchers tools that will allow them to develop retrieval-based instrumentation for their data analytics needs with ease and agility. We include a Jupyter Notebook-based walk through the core interoperability features, available on GitHub: https://github.com/huggingface/gaia. We then demonstrate how the ideas we present can be operationalized to create a powerful tool for qualitative data analysis in NLP. We present GAIA Search - a search engine built following previously laid out principles, giving access to four popular large-scale text collections. GAIA serves a dual purpose of illustrating the potential of methodologies we discuss but also as a standalone qualitative analysis tool that can be leveraged by NLP researchers aiming to understand datasets prior to using them in training. GAIA is hosted live on Hugging Face Spaces: https://huggingface.co/spaces/spacerini/gaia. | Aleksandra Piktus, Odunayo Ogundepo, Christopher Akiki, Akintunde Oladipo, Xinyu Zhang, Hailey Schoelkopf, Stella Biderman, Martin Potthast, Jimmy Lin |  |
| 59 |  |  [DeepPavlov Dream: Platform for Building Generative AI Assistants](https://doi.org/10.18653/v1/2023.acl-demo.58) |  | 0 | An open-source DeepPavlov Dream Platform is specifically tailored for development of complex dialog systems like Generative AI Assistants. The stack prioritizes efficiency, modularity, scalability, and extensibility with the goal to make it easier to develop complex dialog systems from scratch. It supports modular approach to implementation of conversational agents enabling their development through the choice of NLP components and conversational skills from a rich library organized into the distributions of ready-for-use multi-skill AI assistant systems. In DeepPavlov Dream, multi-skill Generative AI Assistant consists of NLP components that extract features from user utterances, conversational skills that generate or retrieve a response, skill and response selectors that facilitate choice of relevant skills and the best response, as well as a conversational orchestrator that enables creation of multi-skill Generative AI Assistants scalable up to industrial grade AI assistants. The platform allows to integrate large language models into dialog pipeline, customize with prompt engineering, handle multiple prompts during the same dialog session and create simple multimodal assistants. | Diliara Zharikova, Daniel Kornev, Fedor Ignatov, Maxim Talimanchuk, Dmitry Evseev, Ksenya Petukhova, Veronika Smilga, Dmitry Karpov, Yana Shishkina, Dmitry Kosenko, Mikhail Burtsev |  |
| 60 |  |  [Frontmatter](https://aclanthology.org/2023.acl-industry.0) |  | 0 |  |  |  |
| 61 |  |  [CWSeg: An Efficient and General Approach to Chinese Word Segmentation](https://doi.org/10.18653/v1/2023.acl-industry.1) |  | 0 | In this work, we report our efforts in advancing Chinese Word Segmentation for the purpose of rapid deployment in different applications. The pre-trained language model (PLM) based segmentation methods have achieved state-of-the-art (SOTA) performance, whereas this paradigm also poses challenges in the deployment. It includes the balance between performance and cost, segmentation ambiguity due to domain diversity and vague words boundary, and multi-grained segmentation. In this context, we propose a simple yet effective approach, namely CWSeg, to augment PLM-based schemes by developing cohort training and versatile decoding strategies. Extensive experiments on benchmark datasets demonstrate the efficiency and generalization of our approach. The corresponding segmentation system is also implemented for practical usage and the demo is recorded. | Dedong Li, Rui Zhao, Fei Tan |  |
| 62 |  |  ["Knowledge is Power": Constructing Knowledge Graph of Abdominal Organs and Using Them for Automatic Radiology Report Generation](https://doi.org/10.18653/v1/2023.acl-industry.2) |  | 0 | In conventional radiology practice, the radiologist dictates the diagnosis to the transcriptionist, who then prepares a preliminary formatted report referring to the notes, after which the radiologist reviews the report, corrects the errors, and signs off. This workflow is prone to delay and error. In this paper, we report our work on automatic radiology report generation from radiologists’ dictation, which is in collaboration with a startup about to become Unicorn. A major contribution of our work is the set of knowledge graphs (KGs) of ten abdominal organs- Liver, Kidney, Gallbladder, Uterus, Urinary bladder, Ovary, Pancreas, Prostate, Biliary Tree, and Bowel. Our method for constructing these KGs relies on extracting entity1-relation-entity2 triplets from a large collection (about 10,000) of free-text radiology reports. The quality and coverage of the KGs are verified by two experienced radiologists (practicing for the last 30 years and 8 years, respectively). The dictation of the radiologist is automatically converted to what is called a pathological description which is the clinical description of the findings of the radiologist during ultrasonography (USG). Our knowledge-enhanced deep learning model improves the reported BLEU-3, ROUGE-L, METEOR, and CIDEr scores of the pathological description generation by 2%, 4%, 2% and 2% respectively. To the best of our knowledge, this is the first attempt at representing the abdominal organs in the form of knowledge graphs and utilising these graphs for the automatic generation of USG reports. A Minimum Viable Product (MVP) has been made available to the beta users, i.e., radiologists of reputed hospitals, for testing and evaluation. Our solution guarantees report generation within 30 seconds of running a scan. | Kaveri Kale, Pushpak Bhattacharyya, Aditya Shetty, Milind Gune, Kush Shrivastava, Rustom Lawyer, Spriha Biswas |  |
| 63 |  |  [Hunt for Buried Treasures: Extracting Unclaimed Embodiments from Patent Specifications](https://doi.org/10.18653/v1/2023.acl-industry.3) |  | 0 | Patent applicants write patent specificationsthat describe embodiments of inventions. Some embodiments are claimed for a patent,while others may be unclaimeddue to strategic considerations. Unclaimed embodiments may be extracted byapplicants later and claimed incontinuing applications togain advantages over competitors. Despite being essential for corporate intellectual property (IP) strategies,unclaimed embodiment extraction is conducted manually,and little research has been conducted on its automation. This paper presents a novel task ofunclaimed embodiment extraction (UEE)and a novel dataset for the task. Our experiments with Transformer-based modelsdemonstratedthat the task was challenging as it requiredconducting natural language inference onpatent specifications, which consisted oftechnical, long, syntactically and semanticallyinvolved sentences. We release the dataset and code to foster this new area of research. | Chikara Hashimoto, Gautam Kumar, Shuichiro Hashimoto, Jun Suzuki |  |
| 64 |  |  [MathPrompter: Mathematical Reasoning using Large Language Models](https://doi.org/10.18653/v1/2023.acl-industry.4) |  | 0 | Large Language Models (LLMs) have limited performance when solving arithmetic reasoning tasks and often provide incorrect answers. Unlike natural language understanding, math problems typically have a single correct answer, making the task of generating accurate solutions more challenging for LLMs. To the best of our knowledge, we are not aware of any LLMs that indicate their level of confidence in their responses which fuels a trust deficit in these models impeding their adoption. To address this deficiency, we propose ‘MathPrompter’, a technique that improves performance of LLMs on arithmetic problems along with increased reliance in the predictions. MathPrompter uses the Zero-shot chain-of-thought prompting technique to generate multiple algebraic expressions or python functions to solve the same math problem in different ways and thereby raise the confidence level in the output results. This is in contrast to other prompt based CoT methods, where there is no check on the validity of the intermediate steps followed. Our technique improves over state-of-the-art on the ‘MultiArith’ dataset (78.7% - 92.5%) evaluated using 175B parameter GPT-based LLM. | Shima Imani, Liang Du, Harsh Shrivastava |  |
| 65 |  |  [Constrained Policy Optimization for Controlled Self-Learning in Conversational AI Systems](https://doi.org/10.18653/v1/2023.acl-industry.5) |  | 0 | Recently, self-learning methods based on user satisfaction metrics and contextual bandits have shown promising results to enable consistent improvements in conversational AI systems. However, directly targeting such metrics by off-policy bandit learning objectives often increases the risk of making abrupt policy changes that break the current user experience. In this study, we introduce a scalable framework for supporting fine-grained exploration targets for individual domains via user-defined constraints. For example, we may want to ensure fewer policy deviations in business-critical domains such as shopping, while allocating more exploration budget to domains such as music. We present a novel meta-gradient learning approach that is scalable and practical to address this problem. The proposed method adjusts constraint violation penalty terms adaptively through a meta objective that encourages balanced constraint satisfaction across domains. We conducted extensive experiments on a real-world conversational AI and using a set of realistic constraint benchmarks. The proposed approach has been deployed in production for a large-scale commercial assistant, enabling the best balance between the policy value and constraint satisfaction rate. | Mohammad Kachuee, Sungjin Lee |  |
| 66 |  |  [pNLP-Mixer: an Efficient all-MLP Architecture for Language](https://doi.org/10.18653/v1/2023.acl-industry.6) |  | 0 | Large pre-trained language models based on transformer architectureƒhave drastically changed the natural language processing (NLP) landscape. However, deploying those models for on-device applications in constrained devices such as smart watches is completely impractical due to their size and inference cost. As an alternative to transformer-based architectures, recent work on efficient NLP has shown that weight-efficient models can attain competitive performance for simple tasks, such as slot filling and intent classification, with model sizes in the order of the megabyte. This work introduces the pNLP-Mixer architecture, an embedding-free MLP-Mixer model for on-device NLP that achieves high weight-efficiency thanks to a novel projection layer. We evaluate a pNLP-Mixer model of only one megabyte in size on two multi-lingual semantic parsing datasets, MTOP and multiATIS. Our quantized model achieves 99.4% and 97.8% the performance of mBERT on MTOP and multiATIS, while using 170x less parameters. Our model consistently beats the state-of-the-art of tiny models (pQRNN), which is twice as large, by a margin up to 7.8% on MTOP. | Francesco Fusco, Damian Pascual, Peter W. J. Staar, Diego Antognini |  |
| 67 |  |  [Extracting Text Representations for Terms and Phrases in Technical Domains](https://doi.org/10.18653/v1/2023.acl-industry.7) |  | 0 | Extracting dense representations for terms and phrases is a task of great importance for knowledge discovery platforms targeting highly-technical fields. Dense representations are used as features for downstream components and have multiple applications ranging from ranking results in search to summarization. Common approaches to create dense representations include training domain-specific embeddings with self-supervised setups or using sentence encoder models trained over similarity tasks. In contrast to static embeddings, sentence encoders do not suffer from the out-of-vocabulary (OOV) problem, but impose significant computational costs. In this paper, we propose a fully unsupervised approach to text encoding that consists of training small character-based models with the objective of reconstructing large pre-trained embedding matrices. Models trained with this approach can not only match the quality of sentence encoders in technical domains, but are 5 times smaller and up to 10 times faster, even on high-end GPUs. | Francesco Fusco, Diego Antognini |  |
| 68 |  |  [CocaCLIP: Exploring Distillation of Fully-Connected Knowledge Interaction Graph for Lightweight Text-Image Retrieval](https://doi.org/10.18653/v1/2023.acl-industry.8) |  | 0 | Large-scale pre-trained text-image models with dual-encoder architectures (such as CLIP) are typically adopted for various vision-language applications, including text-image retrieval. However, these models are still less practical on edge devices or for real-time situations, due to the substantial indexing and inference time and the large consumption of computational resources. Although knowledge distillation techniques have been widely utilized for uni-modal model compression, how to expand them to the situation when the numbers of modalities and teachers/students are doubled has been rarely studied. In this paper, we conduct comprehensive experiments on this topic and propose the fully-Connected knowledge interaction graph (Coca) technique for cross-modal pre-training distillation. Based on our findings, the resulting CocaCLIP achieves SOTA performances on the widely-used Flickr30K and MSCOCO benchmarks under the lightweight setting. An industry application of our method on an e-commercial platform further demonstrates the significant effectiveness of CocaCLIP. | Jiapeng Wang, Chengyu Wang, Xiaodan Wang, Jun Huang, Lianwen Jin |  |
| 69 |  |  [KG-FLIP: Knowledge-guided Fashion-domain Language-Image Pre-training for E-commerce](https://doi.org/10.18653/v1/2023.acl-industry.9) |  | 0 | Various Vision-Language Pre-training (VLP) models (e.g., CLIP, BLIP) have sprung up and dramatically advanced the benchmarks for public general-domain datasets (e.g., COCO, Flickr30k). Such models usually learn the cross-modal alignment from large-scale well-aligned image-text datasets without leveraging external knowledge. Adapting these models to downstream applications in specific domains like fashion requires fine-grained in-domain image-text corpus, which are usually less semantically aligned and in small scale that requires efficient pre-training strategies. In this paper, we propose a knowledge-guided fashion-domain language-image pre-training (FLIP) framework that focuses on learning fine-grained representations in e-commerce domain and utilizes external knowledge (i.e., product attribute schema), to improve the pre-training efficiency. Experiments demonstrate that FLIP outperforms previous state-of-the-art VLP models on Amazon data and on the Fashion-Gen dataset by large margins. FLIP has been successfully deployed in the Amazon catalog system to backfill missing attributes and improve the customer shopping experience. | Qinjin Jia, Yang Liu, Daoping Wu, Shaoyuan Xu, Huidong Liu, Jinmiao Fu, Roland Vollgraf, Bryan Wang |  |
| 70 |  |  [Domain-specific transformer models for query translation](https://doi.org/10.18653/v1/2023.acl-industry.10) |  | 0 | Due to the democratization of e-commerce, many product companies are listing their goods for online shopping. For periodic buying within a domain such as Grocery, consumers are generally inclined to buy certain brands of products. Due to a large non-English speaking population in India, we observe a significant percentage of code-mix Hinglish search queries e.g., sasta atta. An intuitive approach to dealing with code-mix queries is to train an encoder-decoder model to translate the query to English to perform the search. However, the problem becomes non-trivial when the brand names themselves have Hinglish names and possibly have a literal English translation. In such queries, only the context (non-brand name) Hinglish words needs to be translated. In this paper, we propose a simple yet effective modification to the transformer training to preserve/correct Grocery brand names in the output while selectively translating the context words. To achieve this, we use an additional dataset of popular Grocery brand names. Brand names are added as tokens to the model vocabulary, and the token embeddings are randomly initialized. Further, we introduce a Brand loss in training the translation model. Brand loss is a cross entropy loss computed using a denoising auto-encoder objective with brand name data. We warm-start the training from a public pre-trained checkpoint (such as BART/T5) and further adapt it for query translation using the domain data. The proposed model is generic and can be used with English as well as code-mix Hinglish queries alleviating the need for language detection. To reduce the latency of the model for the production deployment, we use knowledge distillation and quantization. Experimental evaluation indicates that the proposed approach improves translation results by preserving/correcting English/Hinglish brand names. After positive results with A/B testing, the model is currently deployed in production. | Mandar Kulkarni, Nikesh Garera, Anusua Trivedi |  |
| 71 |  |  [Label efficient semi-supervised conversational intent classification](https://doi.org/10.18653/v1/2023.acl-industry.11) |  | 0 | To provide a convenient shopping experience and to answer user queries at scale, conversational platforms are essential for e-commerce. The user queries can be pre-purchase questions, such as product specifications and delivery time related, or post-purchase queries, such as exchange and return. A chatbot should be able to understand and answer a variety of such queries to help users with relevant information. One of the important modules in the chatbot is automated intent identification, i.e., understanding the user’s intention from the query text. Due to non-English speaking users interacting with the chatbot, we often get a significant percentage of code mix queries and queries with grammatical errors, which makes the problem more challenging. This paper proposes a simple yet competent Semi-Supervised Learning (SSL) approach for label-efficient intent classification. We use a small labeled corpus and relatively larger unlabeled query data to train a transformer model. For training the model with labeled data, we explore supervised MixUp data augmentation. To train with unlabeled data, we explore label consistency with dropout noise. We experiment with different pre-trained transformer architectures, such as BERT and sentence-BERT. Experimental results demonstrate that the proposed approach significantly improves over the supervised baseline, even with a limited labeled set. A variant of the model is currently deployed in production. | Mandar Kulkarni, Kyung Kim, Nikesh Garera, Anusua Trivedi |  |
| 72 |  |  [xPQA: Cross-Lingual Product Question Answering in 12 Languages](https://doi.org/10.18653/v1/2023.acl-industry.12) |  | 0 | Product Question Answering (PQA) systems are key in e-commerce applications as they provide responses to customers’ questions as they shop for products. While existing work on PQA focuses mainly on English, in practice there is need to support multiple customer languages while leveraging product information available in English. To study this practical industrial task, we present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages, and report results in (1) candidate ranking, to select the best English candidate containing the information to answer a non-English question; and (2) answer generation, to generate a natural-sounding non-English answer based on the selected English candidate. We evaluate various approaches involving machine translation at runtime or offline, leveraging multilingual pre-trained LMs, and including or excluding xPQA training data. We find that in-domain data is essential as cross-lingual rankers trained on other domains perform poorly on the PQA task, and that translation-based approaches are most effective for candidate ranking while multilingual finetuning works best for answer generation. Still, there remains a significant performance gap between the English and the cross-lingual test sets. | Xiaoyu Shen, Akari Asai, Bill Byrne, Adrià de Gispert |  |
| 73 |  |  [Learn over Past, Evolve for Future: Forecasting Temporal Trends for Fake News Detection](https://doi.org/10.18653/v1/2023.acl-industry.13) |  | 0 | Fake news detection has been a critical task for maintaining the health of the online news ecosystem. However, very few existing works consider the temporal shift issue caused by the rapidly-evolving nature of news data in practice, resulting in significant performance degradation when training on past data and testing on future data. In this paper, we observe that the appearances of news events on the same topic may display discernible patterns over time, and posit that such patterns can assist in selecting training instances that could make the model adapt better to future data. Specifically, we design an effective framework FTT (Forecasting Temporal Trends), which could forecast the temporal distribution patterns of news data and then guide the detector to fast adapt to future distribution. Experiments on the real-world temporally split dataset demonstrate the superiority of our proposed framework. | Beizhe Hu, Qiang Sheng, Juan Cao, Yongchun Zhu, Danding Wang, Zhengjia Wang, Zhiwei Jin |  |
| 74 |  |  [AVEN-GR: Attribute Value Extraction and Normalization using product GRaphs](https://doi.org/10.18653/v1/2023.acl-industry.14) |  | 0 | Getting a good understanding of the user intent is vital for e-commerce applications to surface the right product to a given customer query. Query Understanding (QU) systems are essential for this purpose, and many e-commerce providers are working on complex solutions that need to be data efficient and able to capture early emerging market trends. Query Attribute Understanding (QAU) is a sub-component of QU that involves extracting named attributes from user queries and linking them to existing e-commerce entities such as brand, material, color, etc. While extracting named entities from text has been extensively explored in the literature, QAU requires specific attention due to the nature of the queries, which are often short, noisy, ambiguous, and constantly evolving. This paper makes three contributions to QAU. First, we propose a novel end-to-end approach that jointly solves Named Entity Recognition (NER) and Entity Linking (NEL) and enables open-world reasoning for QAU. Second, we introduce a novel method for utilizing product graphs to enhance the representation of query entities. Finally, we present a new dataset constructed from public sources that can be used to evaluate the performance of future QAU systems. | Thomas Ricatte, Donato Crisostomi |  |
| 75 |  |  [GKD: A General Knowledge Distillation Framework for Large-scale Pre-trained Language Model](https://doi.org/10.18653/v1/2023.acl-industry.15) |  | 0 | Currently, the reduction in the parameter scale of large-scale pre-trained language models (PLMs) through knowledge distillation has greatly facilitated their widespread deployment on various devices. However, the deployment of knowledge distillation systems faces great challenges in real-world industrial-strength applications, which require the use of complex distillation methods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the switching of methods. To overcome these challenges, we propose GKD, a general knowledge distillation framework that supports distillation on larger-scale PLMs using various distillation methods. With GKD, developers can build larger distillation models on memory-limited GPUs and easily switch and combine different distillation methods within a single framework. Experimental results show that GKD can support the distillation of at least 100B-scale PLMs and 25 mainstream methods on 8 NVIDIA A100 (40GB) GPUs. | Shicheng Tan, Weng Lam Tam, Yuanchun Wang, Wenwen Gong, Shu Zhao, Peng Zhang, Jie Tang |  |
| 76 |  |  [FashionKLIP: Enhancing E-Commerce Image-Text Retrieval with Fashion Multi-Modal Conceptual Knowledge Graph](https://doi.org/10.18653/v1/2023.acl-industry.16) |  | 0 | Image-text retrieval is a core task in the multi-modal domain, which arises a lot of attention from both research and industry communities. Recently, the booming of visual-language pre-trained (VLP) models has greatly enhanced the performance of cross-modal retrieval. However, the fine-grained interactions between objects from different modalities are far from well-established. This issue becomes more severe in the e-commerce domain, which lacks sufficient training data and fine-grained cross-modal knowledge. To alleviate the problem, this paper proposes a novel e-commerce knowledge-enhanced VLP model FashionKLIP. We first automatically establish a multi-modal conceptual knowledge graph from large-scale e-commerce image-text data, and then inject the prior knowledge into the VLP model to align across modalities at the conceptual level. The experiments conducted on a public benchmark dataset demonstrate that FashionKLIP effectively enhances the performance of e-commerce image-text retrieval upon state-of-the-art VLP models by a large margin. The application of the method in real industrial scenarios also proves the feasibility and efficiency of FashionKLIP. | Xiaodan Wang, Chengyu Wang, Lei Li, Zhixu Li, Ben Chen, Linbo Jin, Jun Huang, Yanghua Xiao, Ming Gao |  |
| 77 |  |  [Entity Contrastive Learning in a Large-Scale Virtual Assistant System](https://doi.org/10.18653/v1/2023.acl-industry.17) |  | 0 | Conversational agents are typically made up of domain (DC) and intent classifiers (IC) that identify the general subject an utterance belongs to and the specific action a user wishes to achieve. In addition, named entity recognition (NER) performs per token labeling to identify specific entities of interest in a spoken utterance. We investigate improving joint IC and NER models using entity contrastive learning that attempts to cluster similar entities together in a learned representation space. We compare a full virtual assistant system trained using entity contrastive learning to a production baseline system that does not use contrastive learning. We present both offline results, using retrospective test sets, as well as live online results from an A/B test that compared the two systems. In both the offline and online settings, entity contrastive training improved overall performance against production baselines. Furthermore, we provide a detailed analysis of learned entity embeddings, including both qualitative analysis via dimensionality-reduced visualizations and quantitative analysis by computing alignment and uniformity metrics. We show that entity contrastive learning improves alignment metrics and produces well-formed embedding clusters in representation space. | Jonathan Rubin, Jason Crowley, George Leung, Morteza Ziyadi, Maria Minakova |  |
| 78 |  |  [Tab-Cleaner: Weakly Supervised Tabular Data Cleaning via Pre-training for E-commerce Catalog](https://doi.org/10.18653/v1/2023.acl-industry.18) |  | 0 | Product catalogs, conceptually in the form of text-rich tables, are self-reported by individual retailers and thus inevitably contain noisy facts. Verifying such textual attributes in product catalogs is essential to improve their reliability. However, popular methods for processing free-text content, such as pre-trained language models, are not particularly effective on structured tabular data since they are typically trained on free-form natural language texts. In this paper, we present Tab-Cleaner, a model designed to handle error detection over text-rich tabular data following a pre-training / fine-tuning paradigm. We train Tab-Cleaner on a real-world Amazon Product Catalog table w.r.t millions of products and show improvements over state-of-the-art methods by 16\% on PR AUC over attribute applicability classification task and by 11\% on PR AUC over attribute value validation task. | Kewei Cheng, Xian Li, Zhengyang Wang, Chenwei Zhang, Binxuan Huang, Yifan Ethan Xu, Xin Luna Dong, Yizhou Sun |  |
| 79 |  |  [Toward More Accurate and Generalizable Evaluation Metrics for Task-Oriented Dialogs](https://doi.org/10.18653/v1/2023.acl-industry.19) |  | 0 | Measurement of interaction quality is a critical task for the improvement of large-scale spoken dialog systems. Existing approaches to dialog quality estimation either focus on evaluating the quality of individual turns, or collect dialog-level quality measurements from end users immediately following an interaction. In contrast to these approaches, we introduce a new dialog-level annotation workflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate the quality of dialogs as a whole, and also label dialogs for attributes such as goal completion and user sentiment. In this contribution, we show that: (i) while dialog quality cannot be completely decomposed into dialog-level attributes, there is a strong relationship between some objective dialog attributes and judgments of dialog quality; (ii) for the task of dialog-level quality estimation, a supervised model trained on dialog-level annotations outperforms methods based purely on aggregating turn-level features; and (iii) the proposed evaluation model shows better domain generalization ability compared to the baselines. On the basis of these results, we argue that having high-quality human-annotated data is an important component of evaluating interaction quality for large industrial-scale voice assistant platforms. | Abishek Komma, Nagesh Panyam Chandrasekarasastry, Timothy Leffel, Anuj Goyal, Angeliki Metallinou, Spyros Matsoukas, Aram Galstyan |  |
| 80 |  |  [Tab-CQA: A Tabular Conversational Question Answering Dataset on Financial Reports](https://doi.org/10.18653/v1/2023.acl-industry.20) |  | 0 | Existing conversational question answering (CQA) datasets have been usually constructed from unstructured texts in English. In this paper, we propose Tab-CQA, a tabular CQA dataset created from Chinese financial reports that are extracted from listed companies in a wide range of different sectors in the past 30 years. From these reports, we select 2,463 tables, and manually generate 2,463 conversations with 35,494 QA pairs. Additionally, we select 4,578 tables, from which 4,578 conversations with 73,595 QA pairs are automatically created via a template-based method. With the manually- and automatically-generated conversations, Tab-CQA contains answerable and unanswerable questions. For the answerable questions, we further diversify them to cover a wide range of skills, e.g., table retrieval, fact checking, numerical reasoning, so as to accommodate real-world scenarios. We further propose two different tabular CQA models, a text-based model and an operation-based model, and evaluate them on Tab-CQA. Experiment results show that Tab-CQA is a very challenging dataset, where a huge performance gap exists between human and neural models. We will publicly release Tab-CQA as a benchmark testbed to promote further research on Chinese tabular CQA. | Chuang Liu, Junzhuo Li, Deyi Xiong |  |
| 81 |  |  [KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Applications](https://doi.org/10.18653/v1/2023.acl-industry.21) |  | 0 | Large language models (LLMs) not only learn natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications. Existing research and resources are not readily applicable in South Korea due to the differences in language and culture, both of which significantly affect the biases and targeted demographic groups. This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs. To this end, we present KosBi, a new social bias dataset of 34k pairs of contexts and sentences in Korean covering 72 demographic groups in 15 categories. We find that through filtering-based moderation, social biases in generated content can be reduced by 16.47%p on average for HyperClova (30B and 82B), and GPT-3. | Hwaran Lee, Seokhee Hong, Joonsuk Park, Takyoung Kim, Gunhee Kim, JungWoo Ha |  |
| 82 |  |  [Improving Knowledge Production Efficiency With Question Answering on Conversation](https://doi.org/10.18653/v1/2023.acl-industry.22) |  | 0 | Through an online customer service application, we have collected many conversations between customer service agents and customers. Building a knowledge production system can help reduce the labor cost of maintaining the FAQ database for the customer service chatbot, whose core module is question answering (QA) on these conversations. However, most existing researches focus on document-based QA tasks, and there is a lack of researches on conversation-based QA and related datasets, especially in Chinese language. The challenges of conversation-based QA include: 1) answers may be scattered among multiple dialogue turns; 2) understanding complex dialogue contexts is more complicated than documents. To address these challenges, we propose a multi-span extraction model on this task and introduce continual pre-training and multi-task learning schemes to further improve model performance. To validate our approach, we construct two Chinese datasets using dialogues as the knowledge source, namely cs-qaconv and kd-qaconv, respectively. Experimental results demonstrate that the proposed model outperforms the baseline on both datasets. The online application also verifies the effectiveness of our method. The dataset kd-qaconv will be released publicly for research purposes. | Changlin Yang, Siye Liu, Sen Hu, Wangshu Zhang, Teng Xu, Jing Zheng |  |
| 83 |  |  [Mitigating the Burden of Redundant Datasets via Batch-Wise Unique Samples and Frequency-Aware Losses](https://doi.org/10.18653/v1/2023.acl-industry.23) |  | 0 | Datasets used to train deep learning models in industrial settings often exhibit skewed distributions with some samples repeated a large number of times. This paper presents a simple yet effective solution to reduce the increased burden of repeated computation on redundant datasets. Our approach eliminates duplicates at the batch level, without altering the data distribution observed by the model, making it model-agnostic and easy to implement as a plug-and-play module. We also provide a mathematical expression to estimate the reduction in training time that our approach provides. Through empirical evidence, we show that our approach significantly reduces training times on various models across datasets with varying redundancy factors, without impacting their performance on the Named Entity Recognition task, both on publicly available datasets and in real industrial settings. In the latter, the approach speeds training by up to 87%, and by 46% on average, with a drop in model performance of 0.2% relative at worst. We finally release a modular and reusable codebase to further advance research in this area. | Donato Crisostomi, Andrea Caciolai, Alessandro Pedrani, Kay Rottmann, Alessandro Manzotti, Enrico Palumbo, Davide Bernardi |  |
| 84 |  |  [Distilled Language Models are economically efficient for the enterprise. ...mostly](https://doi.org/10.18653/v1/2023.acl-industry.24) |  | 0 | Contacting customer service via chat is a common practice. Because employing customer service agents is expensive, many companies are turning to NLP that assists human agents by auto-generating responses that can be used directly or with modifications. With their ability to handle large context windows, Large Language Models (LLMs) are a natural fit for this use case. However, their efficacy must be balanced with the cost of training and serving them. This paper assesses the practical cost and impact of LLMs for the enterprise as a function of the usefulness of the responses that they generate. We present a cost framework for evaluating an NLP model’s utility for this use case and apply it to a single brand as a case study in the context of an existing agent assistance product. We compare three strategies for specializing an LLM — prompt engineering, fine-tuning, and knowledge distillation — using feedback from the brand’s customer service agents. We find that the usability of a model’s responses can make up for a large difference in inference cost for our case study brand, and we extrapolate our findings to the broader enterprise space. | Kristen Howell, Gwen Christian, Pavel Fomitchov, Gitit Kehat, Julianne Marzulla, Leanne Rolston, Jadin Tredup, Ilana Zimmerman, Ethan Selfridge, Joseph Bradley |  |
| 85 |  |  [Application-Agnostic Language Modeling for On-Device ASR](https://doi.org/10.18653/v1/2023.acl-industry.25) |  | 0 | On-device automatic speech recognition systems face several challenges compared to server-based systems. They have to meet stricter constraints in terms of speed, disk size and memory while maintaining the same accuracy. Often they have to serve several ap- plications with different distributions at once, such as communicating with a virtual assistant and speech-to-text. The simplest solution to serve multiple applications is to build application-specific (language) models, but this leads to an increase in memory. Therefore, we explore different data- and architecture-driven language modeling approaches to build a single application-agnostic model. We propose two novel feed-forward architectures that find an optimal trade off between different on-device constraints. In comparison to the application-specific solution, one of our novel approaches reduces the disk size by half, while maintaining speed and accuracy of the original model. | Markus NußbaumThom, Lyan Verwimp, Youssef Oualil |  |
| 86 |  |  [Building Accurate Low Latency ASR for Streaming Voice Search in E-commerce](https://doi.org/10.18653/v1/2023.acl-industry.26) |  | 0 | Automatic Speech Recognition (ASR) is essential for any voice-based application. The streaming capability of ASR becomes necessary to provide immediate feedback to the user in applications like Voice Search. LSTM/RNN and CTC based ASR systems are very simple to train and deploy for low latency streaming applications but have lower accuracy when compared to the state-of-the-art models. In this work, we build accurate LSTM, attention and CTC based streaming ASR models for large-scale Hinglish (blend of Hindi and English) Voice Search. We evaluate how various modifications in vanilla LSTM training improve the system’s accuracy while preserving the streaming capabilities. We also discuss a simple integration of end-of-speech (EOS) detection with CTC models, which helps reduce the overall search latency. Our model achieves a word error rate (WER) of 3.69% without EOS and 4.78% with EOS, with ~1300 ms (~46.64%) reduction in latency. | Abhinav Goyal, Nikesh Garera |  |
| 87 |  |  [PLAtE: A Large-scale Dataset for List Page Web Extraction](https://doi.org/10.18653/v1/2023.acl-industry.27) |  | 0 | Recently, neural models have been leveraged to significantly improve the performance of information extraction from semi-structured websites. However, a barrier for continued progress is the small number of datasets large enough to train these models. In this work, we introduce the PLAtE (Pages of Lists Attribute Extraction) benchmark dataset as a challenging new web extraction task. PLAtE focuses on shopping data, specifically extractions from product review pages with multiple items encompassing the tasks of: (1) finding product list segmentation boundaries and (2) extracting attributes for each product. PLAtE is composed of 52,898 items collected from 6,694 pages and 156,014 attributes, making it the first large-scale list page web extraction dataset. We use a multi-stage approach to collect and annotate the dataset and adapt three state-of-the-art web extraction models to the two tasks comparing their strengths and weaknesses both quantitatively and qualitatively. | Aidan San, Yuan Zhuang, Jan Bakus, Colin Lockard, David M. Ciemiewicz, Sandeep Atluri, Kevin Small, Yangfeng Ji, Heba Elfardy |  |
| 88 |  |  [Rapid Diffusion: Building Domain-Specific Text-to-Image Synthesizers with Fast Inference Speed](https://doi.org/10.18653/v1/2023.acl-industry.28) |  | 0 | Text-to-Image Synthesis (TIS) aims to generate images based on textual inputs. Recently, several large pre-trained diffusion models have been released to create high-quality images with pre-trained text encoders and diffusion-based image synthesizers. However, popular diffusion-based models from the open-source community cannot support industrial domain-specific applications due to the lack of entity knowledge and low inference speed. In this paper, we propose Rapid Diffusion, a novel framework for training and deploying super-resolution, text-to-image latent diffusion models with rich entity knowledge injected and optimized networks. Furthermore, we employ BladeDISC, an end-to-end Artificial Intelligence (AI) compiler, and FlashAttention techniques to optimize computational graphs of the generated models for online deployment. Experiments verify the effectiveness of our approach in terms of image quality and inference speed. In addition, we present industrial use cases and integrate Rapid Diffusion to an AI platform to show its practical values. | Bingyan Liu, Weifeng Lin, Zhongjie Duan, Chengyu Wang, Ziheng Wu, Zhang Zipeng, Kui Jia, Lianwen Jin, Cen Chen, Jun Huang |  |
| 89 |  |  [Large Scale Generative Multimodal Attribute Extraction for E-commerce Attributes](https://doi.org/10.18653/v1/2023.acl-industry.29) |  | 0 | E-commerce websites (e.g. Amazon, Alibaba) have a plethora of structured and unstructured information (text and images) present on the product pages. Sellers often don’t label or mislabel values of the attributes (e.g. color, size etc.) for their products. Automatically identifying these attribute values from an eCommerce product page that contains both text and images is a challenging task, especially when the attribute value is not explicitly mentioned in the catalog. In this paper, we present a scalable solution for this problem where we pose attribute extraction problem as a question-answering task, which we solve using MXT, that consists of three key components: (i) MAG (Multimodal Adaptation Gate), (ii) Xception network, and (iii) T5 encoder-decoder. Our system consists of a generative model that generates attribute-values for a given product by using both textual and visual characteristics (e.g. images) of the product. We show that our system is capable of handling zero-shot attribute prediction (when attribute value is not seen in training data) and value-absent prediction (when attribute value is not mentioned in the text) which are missing in traditional classification-based and NER-based models respectively. We have trained our models using distant supervision, removing dependency on human labeling, thus making them practical for real-world applications. With this framework, we are able to train a single model for 1000s of (product-type, attribute) pairs, thus reducing the overhead of training and maintaining separate models. Extensive experiments on two real world datasets (total 57 attributes) show that our framework improves the absolute recall@90P by 10.16% and 6.9 from the existing state of the art models. In a popular e-commerce store, we have productionized our models that cater to 12K (product-type, attribute) pairs, and have extracted 150MM attribute values. | Anant Khandelwal, Happy Mittal, Shreyas Sunil Kulkarni, Deepak Gupta |  |
| 90 |  |  [Consistent Text Categorization using Data Augmentation in e-Commerce](https://doi.org/10.18653/v1/2023.acl-industry.30) |  | 0 | The categorization of massive e-Commerce data is a crucial, well-studied task, which is prevalent in industrial settings. In this work, we aim to improve an existing product categorization model that is already in use by a major web company, serving multiple applications. At its core, the product categorization model is a text classification model that takes a product title as an input and outputs the most suitable category out of thousands of available candidates. Upon a closer inspection, we found inconsistencies in the labeling of similar items. For example, minor modifications of the product title pertaining to colors or measurements majorly impacted the model’s output. This phenomenon can negatively affect downstream recommendation or search applications, leading to a sub-optimal user experience. To address this issue, we propose a new framework for consistent text categorization. Our goal is to improve the model’s consistency while maintaining its production-level performance. We use a semi-supervised approach for data augmentation and presents two different methods for utilizing unlabeled samples. One method relies directly on existing catalogs, while the other uses a generative model. We compare the pros and cons of each approach and present our experimental results. | Noa Avigdor, Guy Horowitz, Ariel Raviv, Stav Yanovsky Daye |  |
| 91 |  |  [An efficient method for Natural Language Querying on Structured Data](https://doi.org/10.18653/v1/2023.acl-industry.31) |  | 0 | We present an efficient and reliable approach to Natural Language Querying (NLQ) on databases (DB) which is not based on text-to-SQL type semantic parsing. Our approach simplifies the NLQ on structured data problem to the following “bread and butter” NLP tasks: (a) Domain classification, for choosing which DB table to query, whether the question is out-of-scope (b) Multi-head slot/entity extraction (SE) to extract the field criteria and other attributes such as its role (filter, sort etc) from the raw text and (c) Slot value disambiguation (SVD) to resolve/normalize raw spans from SE to format suitable to query a DB. This is a general purpose, DB language agnostic approach and the output can be used to query any DB and return results to the user. Also each of these tasks is extremely well studied, mature, easier to collect data for and enables better error analysis by tracing problems to specific components when something goes wrong. | Hanoz Bhathena, Aviral Joshi, Prateek Singh |  |
| 92 |  |  [Boosting Transformers and Language Models for Clinical Prediction in Immunotherapy](https://doi.org/10.18653/v1/2023.acl-industry.32) |  | 0 | Clinical prediction is an essential task in the healthcare industry. However, the recent success of transformers, on which large language models are built, has not been extended to this domain. In this research, we explore the use of transformers and language models in prognostic prediction for immunotherapy using real-world patients’ clinical data and molecular profiles. This paper investigates the potential of transformers to improve clinical prediction compared to conventional machine learning approaches and addresses the challenge of few-shot learning in predicting rare disease areas. The study benchmarks the efficacy of baselines and language models on prognostic prediction across multiple cancer types and investigates the impact of different pretrained language models under few-shot regimes. The results demonstrate significant improvements in accuracy and highlight the potential of NLP in clinical research to improve early detection and intervention for different diseases. | Zekai Chen, Mariann Micsinai Balan, Kevin Brown |  |
| 93 |  |  [EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only](https://doi.org/10.18653/v1/2023.acl-industry.33) |  | 0 | This work proposes a method named EvolveMT for the efficient combination of multiple machine translation (MT) engines. The method selects the output from one engine for each segment, using online learning techniques to predict the most appropriate system for each translation request. A neural quality estimation metric supervises the method without requiring reference translations. The method’s online learning capability enables it to adapt to changes in the domain or MT engines dynamically, eliminating the requirement for retraining. The method selects a subset of translation engines to be called based on the source sentence features. The degree of exploration is configurable according to the desired quality-cost trade-off. Results from custom datasets demonstrate that EvolveMT achieves similar translation accuracy at a lower cost than selecting the best translation of each segment from all translations using an MT quality estimator. To the best of our knowledge, EvolveMT is the first MT system that adapts itself after deployment to incoming translation requests from the production environment without needing costly retraining on human feedback. | Kamer Ali Yüksel, Ahmet Gunduz, Mohamed AlBadrashiny, Hassan Sawaf |  |
| 94 |  |  [A Static Evaluation of Code Completion by Large Language Models](https://doi.org/10.18653/v1/2023.acl-industry.34) |  | 0 | Large language models trained on code have shown great potential to increase productivity of software developers. Several execution-based benchmarks have been proposed to evaluate functional correctness of model-generated code on simple programming problems. Nevertheless, it is expensive to perform the same evaluation on complex real-world projects considering the execution cost. On the other hand, static analysis tools such as linters, which can detect errors without running the program, haven’t been well explored for evaluating code generation models. In this work, we propose a static evaluation framework to quantify static errors in Python code completions, by leveraging Abstract Syntax Trees. Compared with execution-based evaluation, our method is not only more efficient, but also applicable to code in the wild. For experiments, we collect code context from open source repos to generate one million function bodies using public models. Our static analysis reveals that Undefined Name and Unused Variable are the most common errors among others made by language models. Through extensive studies, we also show the impact of sampling temperature, model size, and context on static errors in code completions. | Hantian Ding, Varun Kumar, Yuchen Tian, Zijian Wang, Rob Kwiatkowski, Xiaopeng Li, Murali Krishna Ramanathan, Baishakhi Ray, Parminder Bhatia, Sudipta Sengupta, Dan Roth, Bing Xiang |  |
| 95 |  |  [Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems](https://doi.org/10.18653/v1/2023.acl-industry.35) |  | 0 | Off-Policy reinforcement learning has been the driving force for the state-of-the-art conversational AIs leading to more natural human-agent interactions and improving the user satisfaction for goal-oriented agents. However, in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the broad spectrum of applications handled by such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics has been commonly used to address this problem. In this paper, we propose method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from a real-world conversational system and actual regression incidents. The proposed method is currently deployed in our production system to protect customers against broken experiences and enable long-term policy improvements. | Sarthak Ahuja, Mohammad Kachuee, Fatemeh Sheikholeslami, Weiqing Liu, Jaeyoung Do |  |
| 96 |  |  [MobileNMT: Enabling Translation in 15MB and 30ms](https://doi.org/10.18653/v1/2023.acl-industry.36) |  | 0 | Deploying NMT models on mobile devices is essential for privacy, low latency, and offline scenarios. For high model capacity, NMT models are rather large. Running these models on devices is challenging with limited storage, memory, computation, and power consumption. Existing work either only focuses on a single metric such as FLOPs or general engine which is not good at auto-regressive decoding. In this paper, we present MobileNMT, a system that can translate in 15MB and 30ms on devices. We propose a series of principles for model compression when combined with quantization. Further, we implement an engine that is friendly to INT8 and decoding. With the co-design of model and engine, compared with the existing system, we speed up 47.0x and save 99.5% of memory with only 11.6% loss of BLEU. Our code will be publicly available after the anonymity period. | Ye Lin, Xiaohui Wang, Zhexi Zhang, Mingxuan Wang, Tong Xiao, Jingbo Zhu |  |
| 97 |  |  [Multi-doc Hybrid Summarization via Salient Representation Learning](https://doi.org/10.18653/v1/2023.acl-industry.37) |  | 0 | Multi-document summarization is gaining more and more attention recently and serves as an invaluable tool to obtain key facts among a large information pool. In this paper, we proposed a multi-document hybrid summarization approach, which simultaneously generates a human-readable summary and extracts corresponding key evidences based on multi-doc inputs. To fulfill that purpose, we crafted a salient representation learning method to induce latent salient features, which are effective for joint evidence extraction and summary generation. In order to train this model, we conducted multi-task learning to optimize a composited loss, constructed over extractive and abstractive sub-components in a hierarchical way. We implemented the system based on a ubiquiotously adopted transformer architecture and conducted experimental studies on multiple datasets across two domains, achieving superior performance over the baselines. | Min Xiao |  |
| 98 |  |  [SaFER: A Robust and Efficient Framework for Fine-tuning BERT-based Classifier with Noisy Labels](https://doi.org/10.18653/v1/2023.acl-industry.38) |  | 0 | Learning on noisy datasets is a challenging problem when pre-trained language models are applied to real-world text classification tasks. In numerous industrial applications, acquiring task-specific datasets with 100% accurate labels is difficult, thus many datasets are accompanied by label noise at different levels. Previous work has shown that existing noise-handling methods could not improve the peak performance of BERT on noisy datasets, and might even deteriorate it. In this paper, we propose SaFER, a robust and efficient fine-tuning framework for BERT-based text classifiers, combating label noises without access to any clean data for training or validation. Utilizing a label-agnostic early-stopping strategy and self-supervised learning, our proposed framework achieves superior performance in terms of both accuracy and speed on multiple text classification benchmarks. The trained model is finally fully deployed in several industrial biomedical literature mining tasks and demonstrates high effectiveness and efficiency. | Zhenting Qi, Xiaoyu Tan, Chao Qu, Yinghui Xu, Yuan Qi |  |
| 99 |  |  [Chemical Language Understanding Benchmark](https://doi.org/10.18653/v1/2023.acl-industry.39) |  | 0 | In this paper, we introduce the benchmark datasets named CLUB (Chemical Language Understanding Benchmark) to facilitate NLP research in the chemical industry. We have 4 datasets consisted of text and token classification tasks. As far as we have recognized, it is one of the first examples of chemical language understanding benchmark datasets consisted of tasks for both patent and literature articles provided by industrial organization. All the datasets are internally made by chemists from scratch. Finally, we evaluate the datasets on the various language models based on BERT and RoBERTa, and demonstrate the model performs better when the domain of the pretrained models are closer to chemistry domain. We provide baselines for our benchmark as 0.8054 in average, and we hope this benchmark is used by many researchers in both industry and academia. | Yunsoo Kim, Hyuk Ko, Jane Lee, Hyun Young Heo, Jinyoung Yang, Sungsoo Lee, KyuHwang Lee |  |
| 100 |  |  [HyperT5: Towards Compute-Efficient Korean Language Modeling](https://doi.org/10.18653/v1/2023.acl-industry.40) |  | 0 | Pretraining and fine-tuning language models have become the standard practice in industrial natural language processing (NLP), but developing and deploying general-purpose language models without the abundant computation or data resources is a real-world issue faced by smaller organizations or communities whose main focus is languages with less accessible resources (e.g., non-English). This paper explores the sequence-to-sequence (seq2seq) language model architecture as a more practical and compute-efficient alternative to the decoder-oriented approach (e.g., GPT-3), accompanied by novel findings in compute-optimality analyses. We successfully trained billion-scale Korean-language seq2seq language models that strongly outperform other competitive models in Korean benchmarks. Moreover, we demonstrate that such language models can be more efficiently utilized by employing a heavy pre-finetuning strategy, by showcasing a case study on dialog-task adaptation. Our case study shows that adopting language models with more readily available domain-specific unlabeled data greatly improves fine-tuning data efficiency in low-resource settings. | Dongju Park, Soonwon Ka, Kang Min Yoo, Gichang Lee, Jaewook Kang |  |
| 101 |  |  [Semantic Ambiguity Detection in Sentence Classification using Task-Specific Embeddings](https://doi.org/10.18653/v1/2023.acl-industry.41) |  | 0 | Ambiguity is a major obstacle to providing services based on sentence classification. However, because of the structural limitations of the service, there may not be sufficient contextual information to resolve the ambiguity. In this situation, we focus on ambiguity detection so that service design considering ambiguity is possible. We utilize similarity in a semantic space to detect ambiguity in service scenarios and training data. In addition, we apply task-specific embedding to improve performance. Our results demonstrate that ambiguities and resulting labeling errors in training data or scenarios can be detected. Additionally, we confirm that it can be used to debug services | Jong Myoung Kim, YoungJun Lee, Sangkeun Jung, HoJin Choi |  |
| 102 |  |  [Reliable and Interpretable Drift Detection in Streams of Short Texts](https://doi.org/10.18653/v1/2023.acl-industry.42) |  | 0 | Data drift is the change in model input data that is one of the key factors leading to machine learning models performance degradation over time. Monitoring drift helps detecting these issues and preventing their harmful consequences. Meaningful drift interpretation is a fundamental step towards effective re-training of the model. In this study we propose an end-to-end framework for reliable model-agnostic change-point detection and interpretation in large task-oriented dialog systems, proven effective in multiple customer deployments. We evaluate our approach and demonstrate its benefits with a novel variant of intent classification training dataset, simulating customer requests to a dialog system. We make the data publicly available. | Ella Rabinovich, Matan Vetzler, Samuel Ackerman, Ateret AnabyTavor |  |
| 103 |  |  [Sharing Encoder Representations across Languages, Domains and Tasks in Large-Scale Spoken Language Understanding](https://doi.org/10.18653/v1/2023.acl-industry.43) |  | 0 | Leveraging representations from pre-trained transformer-based encoders achieves state-of-the-art performance on numerous NLP tasks. Larger encoders can improve accuracy for spoken language understanding (SLU) but are challenging to use given the inference latency constraints of online systems (especially on CPU machines).We evaluate using a larger 170M parameter BERT encoder that shares representations across languages, domains and tasks for SLU compared to using smaller 17M parameter BERT encoders with language-, domain- and task-decoupled finetuning.Running inference with a larger shared encoder on GPU is latency neutral and reduces infrastructure cost compared to running inference for decoupled smaller encoders on CPU machines. The larger shared encoder reduces semantic error rates by 4.62% for test sets representing user requests to voice-controlled devices and 5.79% on the tail of the test sets on average across four languages. | Jonathan J. Hüser, Judith Gaspers, Thomas Gueudré, Chandana Satya Prakash, Jin Cao, Daniil Sorokin, Quynh Do, Nicolas Anastassacos, Tobias Falke, Turan Gojayev |  |
| 104 |  |  [Annotating Research Infrastructure in Scientific Papers: An NLP-driven Approach](https://doi.org/10.18653/v1/2023.acl-industry.44) |  | 0 | In this work, we present a natural language processing (NLP) pipeline for the identification, extraction and linking of Research Infrastructure (RI) used in scientific publications. Links between scientific equipment and publications where the equipment was used can support multiple use cases, such as evaluating the impact of RI investment, and supporting Open Science and research reproducibility. These links can also be used to establish a profile of the RI portfolio of each institution and associate each equipment with scientific output. The system we are describing here is already in production, and has been used to address real business use cases, some of which we discuss in this paper. The computational pipeline at the heart of the system comprises both supervised and unsupervised modules to detect the usage of research equipment by processing the full text of the articles. Additionally, we have created a knowledge graph of RI, which is utilized to annotate the articles with metadata. Finally, examples of the business value of the insights made possible by this NLP pipeline are illustrated. | Seyed Amin Tabatabaei, Georgios Cheirmpos, Marius A. Doornenbal, Alberto Zigoni, Véronique Moore, Georgios Tsatsaronis |  |
| 105 |  |  [Event-Centric Query Expansion in Web Search](https://doi.org/10.18653/v1/2023.acl-industry.45) |  | 0 | In search engines, query expansion (QE) is a crucial technique to improve search experience. Previous studies often rely on long-term search log mining, which leads to slow updates and is sub-optimal for time-sensitive news searches. In this work, we present Event-Centric Query Expansion (EQE), the QE system used in a famous Chinese search engine. EQE utilizes a novel event retrieval framework that consists of four stages, i.e., event collection, event reformulation, semantic retrieval and online ranking, which can select the best expansion from a significant amount of potential events rapidly and accurately. Specifically, we first collect and filter news headlines from websites. Then we propose a generation model that incorporates contrastive learning and prompt-tuning techniques to reformulate these headlines to concise candidates. Additionally, we fine-tune a dual-tower semantic model to serve as an encoder for event retrieval and explore a two-stage contrastive training approach to enhance the accuracy of event retrieval. Finally, we rank the retrieved events and select the optimal one as QE, which is then used to improve the retrieval of event-related documents. Through offline analysis and online A/B testing, we observed that the EQE system has significantly improved many indicators compared to the baseline. The system has been deployed in a real production environment and serves hundreds of millions of users. | Yanan Zhang, Weijie Cui, Yangfan Zhang, Xiaoling Bai, Zhe Zhang, Jin Ma, Xiang Chen, Tianhua Zhou |  |
| 106 |  |  [Transferable and Efficient: Unifying Dynamic Multi-Domain Product Categorization](https://doi.org/10.18653/v1/2023.acl-industry.46) |  | 0 | As e-commerce platforms develop different business lines, a special but challenging product categorization scenario emerges, where there are multiple domain-specific category taxonomies and each of them evolves dynamically over time. In order to unify the categorization process and ensure efficiency, we propose a two-stage taxonomy-agnostic framework that relies solely on calculating the semantic relatedness between product titles and category names in the vector space. To further enhance domain transferability and better exploit cross-domain data, we design two plug-in modules: a heuristic mapping scorer and a pretrained contrastive ranking module with the help of meta concepts, which represent keyword knowledge shared across domains. Comprehensive offline experiments show that our method outperforms strong baselineson three dynamic multi-domain product categorization (DMPC) tasks,and online experiments reconfirm its efficacy with a5% increase on seasonal purchase revenue. Related datasets will be released. | Shansan Gong, Zelin Zhou, Shuo Wang, Fengjiao Chen, Xiujie Song, Xuezhi Cao, Yunsen Xian, Kenny Q. Zhu |  |
| 107 |  |  [DISCOSQA: A Knowledge Base Question Answering System for Space Debris based on Program Induction](https://doi.org/10.18653/v1/2023.acl-industry.47) |  | 0 | Space program agencies execute complex satellite operations that need to be supported by the technical knowledge contained in their extensive information systems. Knowledge Base (KB) databases are an effective way of storing and accessing such information to scale. In this work we present a system, developed for the European Space Agency, that can answer complex natural language queries, to support engineers in accessing the information contained in a KB that models the orbital space debris environment. Our system is based on a pipeline which first generates a program sketch from a natural language question, then specializes the sketch into a concrete query program with mentions of entities, attributes and relations, and finally executes the program against the database. This pipeline decomposition approach enables us to train the system by leveraging out-of-domain data and semi-synthetic data generated by GPT-3, thus reducing overfitting and shortcut learning even with limited amount of in-domain training data. | Paul Darm, Antonio Valerio Miceli Barone, Shay B. Cohen, Annalisa Riccardi |  |
| 108 |  |  [BADGE: Speeding Up BERT Inference after Deployment via Block-wise Bypasses and Divergence-based Early Exiting](https://doi.org/10.18653/v1/2023.acl-industry.48) |  | 0 | Early exiting can reduce the average latency of pre-trained language models (PLMs) via its adaptive inference mechanism and work with other inference speed-up methods like model pruning, thus drawing much attention from the industry. In this work, we propose a novel framework, BADGE, which consists of two off-the-shelf methods for improving PLMs’ early exiting. We first address the issues of training a multi-exit PLM, the backbone model for early exiting. We propose the novel architecture of block-wise bypasses, which can alleviate the conflicts in jointly training multiple intermediate classifiers and thus improve the overall performances of multi-exit PLM while introducing negligible additional flops to the model. Second, we propose a novel divergence-based early exiting (DGE) mechanism, which obtains early exiting signals by comparing the predicted distributions of two adjacent layers’ exits. Extensive experiments on three proprietary datasets and three GLUE benchmark tasks demonstrate that our method can obtain a better speedup-performance trade-off than the existing baseline methods.\footnote{Code will be made publicly available to the research community upon acceptance.} | Wei Zhu, Peng Wang, Yuan Ni, Guotong Xie, Xiaoling Wang |  |
| 109 |  |  [K-pop and fake facts: from texts to smart alerting for maritime security](https://doi.org/10.18653/v1/2023.acl-industry.49) |  | 0 | Maritime security requires full-time monitoring of the situation, mainly based on technical data (radar, AIS) but also from OSINT-like inputs (e.g., newspapers). Some threats to the operational reliability of this maritime surveillance, such as malicious actors, introduce discrepancies between hard and soft data (sensors and texts), either by tweaking their AIS emitters or by emitting false information on pseudo-newspapers. Many techniques exist to identify these pieces of false information, including using knowledge base population techniques to build a structured view of the information. This paper presents a use case for suspect data identification in a maritime setting. The proposed system UMBAR ingests data from sensors and texts, processing them through an information extraction step, in order to feed a Knowledge Base and finally perform coherence checks between the extracted facts. | Maxime Prieur, Souhir Gahbiche, Guillaume Gadek, Sylvain Gatepaille, Kilian Vasnier, Valerian Justine |  |
| 110 |  |  [Evaluating Embedding APIs for Information Retrieval](https://doi.org/10.18653/v1/2023.acl-industry.50) |  | 0 | The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers. For non-English retrieval, re-ranking still improves the results, but a hybrid model with BM25 works best albeit at a higher cost. We hope our work lays the groundwork for thoroughly evaluating APIs that are critical in search and more broadly, in information retrieval. | Ehsan Kamalloo, Xinyu Zhang, Odunayo Ogundepo, Nandan Thakur, David AlfonsoHermelo, Mehdi Rezagholizadeh, Jimmy Lin |  |
| 111 |  |  [Domain-Agnostic Neural Architecture for Class Incremental Continual Learning in Document Processing Platform](https://doi.org/10.18653/v1/2023.acl-industry.51) |  | 0 | Production deployments in complex systems require ML architectures to be highly efficient and usable against multiple tasks. Particularly demanding are classification problems in which data arrives in a streaming fashion and each class is presented separately. Recent methods with stochastic gradient learning have been shown to struggle in such setups or have limitations like memory buffers, and being restricted to specific domains that disable its usage in real-world scenarios. For this reason, we present a fully differentiable architecture based on the Mixture of Experts model, that enables the training of high-performance classifiers when examples from each class are presented separately. We conducted exhaustive experiments that proved its applicability in various domains and ability to learn online in production environments. The proposed technique achieves SOTA results without a memory buffer and clearly outperforms the reference methods. | Mateusz Wójcik, Witold Kosciukiewicz, Mateusz Baran, Tomasz Kajdanowicz, Adam Gonczarek |  |
| 112 |  |  [Regression-Free Model Updates for Spoken Language Understanding](https://doi.org/10.18653/v1/2023.acl-industry.52) |  | 0 | In real-world systems, an important requirement for model updates is to avoid regressions in user experience caused by flips of previously correct classifications to incorrect ones. Multiple techniques for that have been proposed in the recent literature. In this paper, we apply one such technique, focal distillation, to model updates in a goal-oriented dialog system and assess its usefulness in practice. In particular, we evaluate its effectiveness for key language understanding tasks, including sentence classification and sequence labeling tasks, we further assess its effect when applied to repeated model updates over time, and test its compatibility with mislabeled data. Our experiments on a public benchmark and data from a deployed dialog system demonstrate that focal distillation can substantially reduce regressions, at only minor drops in accuracy, and that it further outperforms naive supervised training in challenging mislabeled data and label expansion settings. | Andrea Caciolai, Verena Weber, Tobias Falke, Alessandro Pedrani, Davide Bernardi |  |
| 113 |  |  [Reducing cohort bias in natural language understanding systems with targeted self-training scheme](https://doi.org/10.18653/v1/2023.acl-industry.53) |  | 0 | Bias in machine learning models can be an issue when the models are trained on particular types of data that do not generalize well, causing under performance in certain groups of users. In this work, we focus on reducing the bias related to new customers in a digital voice assistant system. It is observed that natural language understanding models often have lower performance when dealing with requests coming from new users rather than experienced users. To mitigate this problem, we propose a framework that consists of two phases (1) a fixing phase with four active learning strategies used to identify important samples coming from new users, and (2) a self training phase where a teacher model trained from the first phase is used to annotate semi-supervised samples to expand the training data with relevant cohort utterances. We explain practical strategies that involve an identification of representative cohort-based samples through density clustering as well as employing implicit customer feedbacks to improve new customers’ experience. We demonstrate the effectiveness of our approach in a real world large scale voice assistant system for two languages, German and French through both offline experiments as well as A/B testings. | DieuThu Le, Gabriela Hernández, Bei Chen, Melanie Bradford |  |
| 114 |  |  [Content Moderation for Evolving Policies using Binary Question Answering](https://doi.org/10.18653/v1/2023.acl-industry.54) |  | 0 | Content moderation on social media is governed by policies that are intricate and frequently updated with evolving world events. However, automated content moderation systems often restrict easy adaptation to policy changes and are expected to learn policy intricacies from limited amounts of labeled data, which make effective policy compliance challenging. We propose to model content moderation as a binary question answering problem where the questions validate the loosely coupled themes constituting a policy. A decision logic is applied on top to aggregate the theme-specific validations. This way the questions pass theme information to a transformer network as explicit policy prompts, that in turn enables explainability. This setting further allows for faster adaptation to policy updates by leveraging zero-shot capabilities of pre-trained transformers. We showcase improved recall for our proposed method at 95\% precision on two proprietary datasets of social media posts and comments respectively annotated under curated Hate Speech and Commercial Spam policies. | Sankha Subhra Mullick, Mohan Bhambhani, Suhit Sinha, Akshat Mathur, Somya Gupta, Jidnya Shah |  |
| 115 |  |  [Weighted Contrastive Learning With False Negative Control to Help Long-tailed Product Classification](https://doi.org/10.18653/v1/2023.acl-industry.55) |  | 0 | Item categorization (IC) aims to classify product descriptions into leaf nodes in a categorical taxonomy, which is a key technology used in a wide range of applications. Along with the fact that most datasets often has a long-tailed distribution, classification performances on tail labels tend to be poor due to scarce supervision, causing many issues in real-life applications. To address IC task’s long-tail issue, K-positive contrastive loss (KCL) is proposed on image classification task and can be applied on the IC task when using text-based contrastive learning, e.g., SimCSE. However, one shortcoming of using KCL has been neglected in previous research: false negative (FN) instances may harm the KCL’s representation learning. To address the FN issue in the KCL, we proposed to re-weight the positive pairs in the KCL loss with a regularization that the sum of weights should be constrained to K+1 as close as possible. After controlling FN instances with the proposed method, IC performance has been further improved and is superior to other LT-addressing methods. | Tianqi Wang, Lei Chen, Xiaodan Zhu, Younghun Lee, Jing Gao |  |
| 116 |  |  [Towards Building a Robust Toxicity Predictor](https://doi.org/10.18653/v1/2023.acl-industry.56) |  | 0 | Recent NLP literature pays little attention to the robustness of toxicity language predictors, while these systems are most likely to be used in adversarial contexts. This paper presents a novel adversarial attack, \texttt{ToxicTrap}, introducing small word-level perturbations to fool SOTA text classifiers to predict toxic text samples as benign. \texttt{ToxicTrap} exploits greedy based search strategies to enable fast and effective generation of toxic adversarial examples. Two novel goal function designs allow \texttt{ToxicTrap} to identify weaknesses in both multiclass and multilabel toxic language detectors. Our empirical results show that SOTA toxicity text classifiers are indeed vulnerable to the proposed attacks, attaining over 98\% attack success rates in multilabel cases. We also show how a vanilla adversarial training and its improved version can help increase robustness of a toxicity detector even against unseen attacks. | Dmitriy Bespalov, Sourav Bhabesh, Yi Xiang, Liutong Zhou, Yanjun Qi |  |
| 117 |  |  [AI Coach Assist: An Automated Approach for Call Recommendation in Contact Centers for Agent Coaching](https://doi.org/10.18653/v1/2023.acl-industry.57) |  | 0 | In recent years, the utilization of Artificial Intelligence (AI) in the contact center industry is on the rise. One area where AI can have a significant impact is in the coaching of contact center agents. By analyzing call transcripts, AI can quickly determine which calls are most relevant for coaching purposes, and provide relevant feedback and insights to the contact center manager or supervisor. In this paper, we present “AI Coach Assis”, which leverages the pre-trained transformer-based language models to determine whether a given call is coachable or not based on the quality assurance (QA) queries/questions asked by the contact center managers or supervisors. The system was trained and evaluated on a large dataset collected from real-world contact centers and provides an efficient and effective way to determine which calls are most relevant for coaching purposes. Extensive experimental evaluation demonstrates the potential of AI Coach Assist to improve the coaching process, resulting in enhancing the performance of contact center agents. | Md. Tahmid Rahman Laskar, Cheng Chen, XueYong Fu, Mahsa Azizi, Shashi Bhushan TN, Simon CorstonOliver |  |
| 118 |  |  [Unified Contextual Query Rewriting](https://doi.org/10.18653/v1/2023.acl-industry.58) |  | 0 | Query rewriting (QR) is an important technique for user friction (i.e. recovering ASR error or system error) reduction and contextual carryover (i.e. ellipsis and co-reference) in conversational AI systems. Recently, generation-based QR models have achieved promising results on these two tasks separately. Although these two tasks have many similarities such as they both use the previous dialogue along with the current request as model input, there is no unified model to solve them jointly. To this end, we propose a unified contextual query rewriting model that unifies QR for both reducing friction and contextual carryover purpose. Moreover, we involve multiple auxiliary tasks such as trigger prediction and NLU interpretation tasks to boost the performance of the rewrite. We leverage the text-to-text unified framework which uses independent tasks with weighted loss to account for task importance. Then we propose new unified multitask learning strategies including a sequential model which outputs one sentence for multi-tasks, and a hybrid model where some tasks are independent and some tasks are sequentially generated. Our experimental results demonstrate the effectiveness of the proposed unified learning methods. | Yingxue Zhou, Jie Hao, Mukund Rungta, Yang Liu, Eunah Cho, Xing Fan, Yanbin Lu, Vishal Thanvantri Vasudevan, Kellen Gillespie, Zeynab Raeesy |  |
| 119 |  |  [Context-Aware Query Rewriting for Improving Users' Search Experience on E-commerce Websites](https://doi.org/10.18653/v1/2023.acl-industry.59) |  | 0 | E-commerce queries are often short and ambiguous. Consequently, query understanding often uses query rewriting to disambiguate user-input queries. While using e-commerce search tools, users tend to enter multiple searches, which we call context, before purchasing. These history searches contain contextual insights about users’ true shopping intents. Therefore, modeling such contextual information is critical to a better query rewriting model. However, existing query rewriting models ignore users’ history behaviors and consider only the instant search query, which is often a short string offering limited information about the true shopping intent. We propose an end-to-end context-aware query rewriting model to bridge this gap, which takes the search context into account. Specifically, our model builds a session graph using the history search queries and their contained words. We then employ a graph attention mechanism that models cross-query relations and computes contextual information of the session. The model subsequently calculates session representations by combining the contextual information with the instant search query using an aggregation network. The session representations are then decoded to generate rewritten queries. Empirically, we demonstrate the superiority of our method to state-of-the-art approaches under various metrics. | Simiao Zuo, Qingyu Yin, Haoming Jiang, Shaohui Xi, Bing Yin, Chao Zhang, Tuo Zhao |  |
| 120 |  |  [Federated Learning of Gboard Language Models with Differential Privacy](https://doi.org/10.18653/v1/2023.acl-industry.60) |  | 0 | We train and deploy language models (LMs) with federated learning (FL) and differential privacy (DP) in Google Keyboard (Gboard). The recent DP-Follow the Regularized Leader (DP-FTRL) algorithm is applied to achieve meaningfully formal DP guarantees without requiring uniform sampling of clients. To provide favorable privacy-utility trade-offs, we introduce a new client participation criterion and discuss the implication of its configuration in large scale systems. We show how quantile-based clip estimation can be combined with DP-FTRL to adaptively choose the clip norm during training or reduce the hyperparameter tuning in preparation of training. With the help of pretraining on public data, we trained and deployed more than fifteen Gboard LMs that achieve high utility and $\rho-$zCDP privacy guarantees with $\rho \in (0.3, 2)$, with one model additionally trained with secure aggregation. We summarize our experience and provide concrete suggestions on DP training for practitioners. | Zheng Xu, Yanxiang Zhang, Galen Andrew, Christopher A. ChoquetteChoo, Peter Kairouz, H. Brendan McMahan, Jesse Rosenstock, Yuanbo Zhang |  |
| 121 |  |  [RadLing: Towards Efficient Radiology Report Understanding](https://doi.org/10.18653/v1/2023.acl-industry.61) |  | 0 | Most natural language tasks in the radiology domain use language models pre-trained on biomedical corpus. There are few pretrained language models trained specifically for radiology, and fewer still that have been trained in a low data setting and gone on to produce comparable results in fine-tuning tasks. We present RadLing, a continuously pretrained language model using ELECTRA-small architecture, trained using over 500K radiology reports that can compete with state-of-the-art results for fine tuning tasks in radiology domain. Our main contribution in this paper is knowledge-aware masking which is an taxonomic knowledge-assisted pre-training task that dynamically masks tokens to inject knowledge during pretraining. In addition, we also introduce an knowledge base-aided vocabulary extension to adapt the general tokenization vocabulary to radiology domain. | Rikhiya Ghosh, Oladimeji Farri, Sanjeev Kumar Karn, Manuela Daniela Danu, Ramya Vunikili, Larisa Micu |  |
| 122 |  |  [Predicting Customer Satisfaction with Soft Labels for Ordinal Classification](https://doi.org/10.18653/v1/2023.acl-industry.62) |  | 0 | In a typical call center, only up to 8% of callersleave a Customer Satisfaction (CSAT) surveyresponse at the end of the call, and these tend tobe customers with strongly positive or negativeexperiences. To manage this data sparsity andresponse bias, we outline a predictive CSATdeep learning algorithm that infers CSAT onthe 1-5 scale on inbound calls to the call centerwith minimal latency. The key metric to maximize is the precision for CSAT = 1 (lowestCSAT). We maximize this metric in two ways. First, reframing the problemas a binary class, rather than five-class problem during model fine-tuning, and then mapping binary outcomes back to five classes usingtemperature-scaled model probabilities. Second, using soft labels to represent the classes. Theresult is a production model able to support keycustomer workflows with high accuracy overmillions of calls a month. | Etienne Manderscheid, Matthias Lee |  |
| 123 |  |  [Accurate Training of Web-based Question Answering Systems with Feedback from Ranked Users](https://doi.org/10.18653/v1/2023.acl-industry.63) |  | 0 | Recent work has shown that large-scale annotated datasets are essential for training state-of-the-art Question Answering (QA) models. Unfortunately, creating this data is expensive and requires a huge amount of annotation work. An alternative and cheaper source of supervision is given by feedback data collected from deployed QA systems. This data can be collected from tens of millions of user with no additional cost, for real-world QA services, e.g., Alexa, Google Home, and etc. The main drawback is the noise affecting feedback on individual examples. Recent literature on QA systems has shown the benefit of training models even with noisy feedback. However, these studies have multiple limitations: (i) they used uniform random noise to simulate feedback responses, which is typically an unrealistic approximation as noise follows specific patterns, depending on target examples and users; and (ii) they do not show how to aggregate feedback for improving training signals. In this paper, we first collect a large scale (16M) QA dataset with real feedback sampled from the QA traffic of a popular Virtual Assistant.Second, we use this data to develop two strategies for filtering unreliable users and thus de-noise feedback: (i) ranking users with an automatic classifier, and (ii) aggregating feedback over similar instances and comparing users between each other. Finally, we train QA models on our filtered feedback data, showing a significant improvement over the state of the art. | Liang Wang, Ivano Lauriola, Alessandro Moschitti |  |
| 124 |  |  [SPM: A Split-Parsing Method for Joint Multi-Intent Detection and Slot Filling](https://doi.org/10.18653/v1/2023.acl-industry.64) |  | 0 | In a task-oriented dialogue system, joint intent detection and slot filling for multi-intent utterances become meaningful since users tend to query more. The current state-of-the-art studies choose to process multi-intent utterances through a single joint model of sequence labelling and multi-label classification, which cannot generalize to utterances with more intents than training samples. Meanwhile, it lacks the ability to assign slots to each corresponding intent. To overcome these problems, we propose a Split-Parsing Method (SPM) for joint multiple intent detection and slot filling, which is a two-stage method. It first splits an input sentence into multiple sub-sentences which contain a single-intent, and then a joint single intent detection and slot filling model is applied to parse each sub-sentence recurrently. Finally, we integrate the parsed results. The sub-sentence split task is also treated as a sequence labelling problem with only one entity-label, which can effectively generalize to a sentence with more intents unseen in the training set. Experimental results on three multi-intent datasets show that our method obtains substantial improvements over different baselines. | Sheng Jiang, Su Zhu, Ruisheng Cao, Qingliang Miao, Kai Yu |  |
| 125 |  |  [NAG-NER: a Unified Non-Autoregressive Generation Framework for Various NER Tasks](https://doi.org/10.18653/v1/2023.acl-industry.65) |  | 0 | Recently, the recognition of flat, nested, and discontinuous entities by a unified generative model framework has received increasing attention both in the research field and industry. However, the current generative NER methods force the entities to be generated in a predefined order, suffering from error propagation and inefficient decoding. In this work, we propose a unified non-autoregressive generation (NAG) framework for general NER tasks, referred to as NAG-NER. First, we propose to generate entities as a set instead of a sequence, avoiding error propagation. Second, we propose incorporating NAG in NER tasks for efficient decoding by treating each entity as a target sequence. Third, to enhance the generation performances of the NAG decoder, we employ the NAG encoder to detect potential entity mentions. Extensive experiments show that our NAG-NER model outperforms the state-of-the-art generative NER models on three benchmark NER datasets of different types and two of our proprietary NER tasks.\footnote{Code will be publicly available to the research community upon acceptance.} | Xinpeng Zhang, Ming Tan, Jingfan Zhang, Wei Zhu |  |
| 126 |  |  [Search Query Spell Correction with Weak Supervision in E-commerce](https://doi.org/10.18653/v1/2023.acl-industry.66) |  | 0 | Misspelled search queries in e-commerce can lead to empty or irrelevant products. Besides inadvertent typing mistakes, most spell mistakes occur because the user does not know the correct spelling, hence typing it as it is pronounced colloquially. This colloquial typing creates countless misspelling patterns for a single correct query. In this paper, we first systematically analyze and group different spell errors into error classes and then leverage the state-of-the-art Transformer model for contextual spell correction. We overcome the constraint of limited human labelled data by proposing novel synthetic data generation techniques for voluminous generation of training pairs needed by data hungry Transformers, without any human intervention. We further utilize weakly supervised data coupled with curriculum learning strategies to improve on tough spell mistakes without regressing on the easier ones. We show significant improvements from our model on human labeled data and online A/B experiments against multiple state-of-art models. | Vishal Kakkar, Chinmay Sharma, Madhura Pande, Surender Kumar |  |
| 127 |  |  ["Let's not Quote out of Context": Unified Vision-Language Pretraining for Context Assisted Image Captioning](https://doi.org/10.18653/v1/2023.acl-industry.67) |  | 0 | Well-formed context aware image captions and tags in enterprise content such as marketing material are critical to ensure their brand presence and content recall. Manual creation and updates to ensure the same is non trivial given the scale and the tedium towards this task. We propose a new unified Vision-Language (VL) model based on the One For All (OFA) model, with a focus on context-assisted image captioning where the caption is generated based on both the image and its context. Our approach aims to overcome the context-independent (image and text are treated independently) nature of the existing approaches. We exploit context by pretraining our model with datasets of three tasks- news image captioning where the news article is the context, contextual visual entailment, and keyword extraction from the context. The second pretraining task is a new VL task, and we construct and release two datasets for the task with 1.1M and 2.2K data instances. Our system achieves state-of-the-art results with an improvement of up to 8.34 CIDEr score on the benchmark news image captioning datasets. To the best of our knowledge, ours is the first effort at incorporating contextual information in pretraining the models for the VL tasks. | Abisek Rajakumar Kalarani, Pushpak Bhattacharyya, Niyati Chhaya, Sumit Shekhar |  |
| 128 |  |  [What, When, and How to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue](https://doi.org/10.18653/v1/2023.acl-industry.68) |  | 0 | This paper presents a method for building a personalized open-domain dialogue system to address the WWH (WHAT, WHEN, and HOW) problem for natural response generation in a commercial setting, where personalized dialogue responses are heavily interleaved with casual response turns. The proposed approach involves weighted dataset blending, negative persona information augmentation methods, and the design of personalized conversation datasets to address the challenges of WWH in personalized, open-domain dialogue systems. Our work effectively balances dialogue fluency and tendency to ground, while also introducing a response-type label to improve the controllability and explainability of the grounded responses. The combination of these methods leads to more fluent conversations, as evidenced by subjective human evaluations as well as objective evaluations. | Deuk Sin Kwon, Sunwoo Lee, Ki Hyun Kim, Seojin Lee, Taeyoon Kim, Eric Davis |  |
| 129 |  |  [CUPID: Curriculum Learning Based Real-Time Prediction using Distillation](https://doi.org/10.18653/v1/2023.acl-industry.69) |  | 0 | Relevance in E-commerce Product Search is crucial for providing customers with accurate results that match their query intent. With recent advancements in NLP and Deep Learning, Transformers have become the default choice for relevance classification tasks. In such a setting, the relevance model uses query text and product title as input features, and estimates if the product is relevant for the customer query. While cross-attention in Transformers enables a more accurate relevance prediction in such a setting, its high evaluation latency makes it unsuitable for real-time predictions in which thousands of products must be evaluated against a user query within few milliseconds. To address this issue, we propose CUPID: a Curriculum learning based real-time Prediction using Distillation that utilizes knowledge distillation within a curriculum learning setting to learn a simpler architecture that can be evaluated within low latency budgets. In a bi-lingual relevance prediction task, our approach shows an 302 bps improvement on English and 676 bps improvement for low-resource Arabic, while maintaining the low evaluation latency on CPUs. | Arindam Bhattacharya, Ankith M. S, Ankit Gandhi, Vijay Huddar, Atul Saroop, Rahul Bhagat |  |
| 130 |  |  [Answering Unanswered Questions through Semantic Reformulations in Spoken QA](https://doi.org/10.18653/v1/2023.acl-industry.70) |  | 0 | Spoken Question Answering (QA) is a key feature of voice assistants, usually backed by multiple QA systems. Users ask questions via spontaneous speech that can contain disfluencies, errors, and informal syntax or phrasing. This is a major challenge in QA, causing unanswered questions or irrelevant answers, leading to bad user experiences. We analyze failed QA requests to identify core challenges: lexical gaps, proposition types, complex syntactic structure, and high specificity. We propose a Semantic Question Reformulation (SURF) model offering three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite questions to facilitate answering. Offline evaluation on 1M unanswered questions from a leading voice assistant shows that SURF significantly improves answer rates: up to 24% of previously unanswered questions obtain relevant answers (75%). Live deployment shows positive impact for millions of customers with unanswered questions; explicit relevance feedback shows high user satisfaction. | Pedro Faustini, Zhiyu Chen, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi |  |
| 131 |  |  [Exploring Zero and Few-shot Techniques for Intent Classification](https://doi.org/10.18653/v1/2023.acl-industry.71) |  | 0 | Conversational NLU providers often need to scale to thousands of intent-classification models where new customers often face the cold-start problem. Scaling to so many customers puts a constraint on storage space as well. In this paper, we explore four different zero and few-shot intent classification approaches with this low-resource constraint: 1) domain adaptation, 2) data augmentation, 3) zero-shot intent classification using descriptions large language models (LLMs), and 4) parameter-efficient fine-tuning of instruction-finetuned language models. Our results show that all these approaches are effective to different degrees in low-resource settings. Parameter-efficient fine-tuning using T-few recipe on Flan-T5 yields the best performance even with just one sample per intent. We also show that the zero-shot method of prompting LLMs using intent descriptions is also very competitive. | Soham Parikh, Mitul Tiwari, Prashil Tumbade, Quaizar Vohra |  |
| 132 |  |  [Referring to Screen Texts with Voice Assistants](https://doi.org/10.18653/v1/2023.acl-industry.72) |  | 0 | Voice assistants help users make phone calls, send messages, create events, navigate and do a lot more. However assistants have limited capacity to understand their users’ context. In this work, we aim to take a step in this direction. Our work dives into a new experience for users to refer to phone numbers, addresses, email addresses, urls, and dates on their phone screens. We focus on reference understanding, which is particularly interesting when, similar to visual grounding, there are multiple similar texts on screen. We collect a dataset and propose a lightweight general purpose model for this novel experience. Since consuming pixels directly is expensive, our system is designed to rely only on text extracted from the UI. Our model is modular, offering flexibility, better interpretability and efficient run time memory. | Shruti Bhargava, Anand Dhoot, IngMarie Jonsson, Hoang Long Nguyen, Alkesh Patel, Hong Yu, Vincent Renkens |  |
| 133 |  |  [Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search](https://doi.org/10.18653/v1/2023.acl-industry.73) |  | 0 | Frequently Asked Question (FAQ) retrieval aims at retrieving question-answer pairs for a given a user query. Integrating FAQ retrieval with product search can not only empower users to make more informed purchase decisions, but also enhance user retention through efficient post-purchase support. Providing FAQ content without disrupting user’s shopping experience poses challenges on deciding when and how to show FAQ results. Our proposed intent-aware FAQ retrieval consists of (1) an intent classifier that predicts whether the query is looking for an FAQ; (2) a reformulation model that rewrites query into a natural question. Offline evaluation demonstrates that our approach improves 12% in Hit@1 on retrieving ground-truth FAQs, while reducing latency by 95% compared to baseline systems. These improvements are further validated by real user feedback, where more than 99% of users consider FAQs displayed on top of product search results is helpful. Overall, our findings show promising directions for integrating FAQ retrieval into product search at scale. | Zhiyu Chen, Jason Ingyu Choi, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi |  |
| 134 |  |  [KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature Adaptation of Vision-Language Models](https://doi.org/10.18653/v1/2023.acl-industry.74) |  | 0 | Image ad understanding is a crucial task with wide real-world applications. Although highly challenging with the involvement of diverse atypical scenes, real-world entities, and reasoning over scene-texts, how to interpret image ads is relatively under-explored, especially in the era of foundational vision-language models (VLMs) featuring impressive generalizability and adaptability. In this paper, we perform the first empirical study of image ad understanding through the lens of pre-trained VLMs. We benchmark and reveal practical challenges in adapting these VLMs to image ad understanding. We propose a simple feature adaptation strategy to effectively fuse multimodal information for image ads and further empower it with knowledge of real-world entities. We hope our study draws more attention to image ad understanding which is broadly relevant to the advertising industry. | Zhiwei Jia, Pradyumna Narayana, Arjun R. Akula, Garima Pruthi, Hao Su, Sugato Basu, Varun Jampani |  |
| 135 |  |  [Weakly supervised hierarchical multi-task classification of customer questions](https://doi.org/10.18653/v1/2023.acl-industry.75) |  | 0 | Identifying granular and actionable topics from customer questions (CQ) posted on e-commerce websites helps surface the missing information expected by customers on the product detail page (DP), provide insights to brands and sellers on what critical product information that the customers are looking before making a purchase decision and helps enrich the catalog quality to improve the overall customer experience (CX). We propose a weakly supervised Hierarchical Multi-task Classification Framework (HMCF) to identify topics from customer questions at various granularities. Complexity lies in creating a list of granular topics (taxonomy) for 1000s of product categories and building a scalable classification system. To this end, we introduce a clustering based Taxonomy Creation and Data Labeling (TCDL) module for creating taxonomy and labelled data with minimal supervision. Using TCDL module, taxonomy and labelled data creation task reduces to 2 hours as compared to 2 weeks of manual efforts by a subject matter expert. For classification, we propose a two level HMCF that performs multi-class classification to identify coarse level-1 topic and leverages NLI based label-aware approach to identify granular level-2 topic. We showcase that HMCF (based on BERT and NLI) a) achieves absolute improvement of 13% in Top-1 accuracy over single-task non-hierarchical baselines b) learns a generic domain invariant function that can adapt to constantly evolving taxonomy (open label set) without need of re-training. c) reduces model deployment efforts significantly since it needs only one model that caters to 1000s of product categories. | Jitenkumar Rana, Promod Yenigalla, Chetan Aggarwal, Sandeep Sricharan Mukku, Manan Soni, Rashmi Patange |  |
| 136 |  |  [Automated Digitization of Unstructured Medical Prescriptions](https://doi.org/10.18653/v1/2023.acl-industry.76) |  | 0 | Automated digitization of prescription images is a critical prerequisite to scale digital healthcare services such as online pharmacies. This is challenging in emerging markets since prescriptions are not digitized at source and patients lack the medical expertise to interpret prescriptions to place orders. In this paper, we present prescription digitization system for online medicine ordering built with minimal supervision. Our system uses a modular pipeline comprising a mix of ML and rule-based components for (a) image to text extraction, (b) segmentation into blocks and medication items, (c) medication attribute extraction, (d) matching against medicine catalog, and (e) shopping cart building. Our approach efficiently utilizes multiple signals like layout, medical ontologies, and semantic embeddings via LayoutLMv2 model to yield substantial improvement relative to strong baselines on medication attribute extraction. Our pipeline achieves +5.9% gain in precision@3 and +5.6% in recall@3 over catalog-based fuzzy matching baseline for shopping cart building for printed prescriptions. | Megha Sharma, Tushar Vatsal, Srujana Merugu, Aruna Rajan |  |
| 137 |  |  [Frontmatter](https://aclanthology.org/2023.acl-tutorials.0) |  | 0 |  |  |  |
| 138 |  |  [Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond](https://doi.org/10.18653/v1/2023.acl-tutorials.1) |  | 0 | Conversational systems are envisioned to provide social support or functional service to human users via natural language interactions. Conventional conversation researches mainly focus on the responseability of the system, such as dialogue context understanding and response generation, but overlooks the design of an essential property in intelligent conversations, i.e., goal awareness. The awareness of goals means the state of not only being responsive to the users but also aware of the target conversational goal and capable of leading the conversation towards the goal, which is a significant step towards higher-level intelligence and artificial consciousness. It can not only largely improve user engagement and service efficiency in the conversation, but also empower the system to handle more complicated conversation tasks that involve strategical and motivational interactions. In this tutorial, we will introduce the recent advances on the design of agent’s awareness of goals in a wide range of conversational systems. | Yang Deng, Wenqiang Lei, Minlie Huang, TatSeng Chua |  |
| 139 |  |  [Complex Reasoning in Natural Languag](https://doi.org/10.18653/v1/2023.acl-tutorials.2) |  | 0 | Teaching machines to reason over texts has been a long-standing goal of natural language processing (NLP). To this end, researchers have designed a diverse set of complex reasoning tasks that involve compositional reasoning, knowledge retrieval, grounding, commonsense reasoning, etc. A standard choice for building systems that perform a desired type of reasoning is to fine-tune a pretrained language model (LM) on specific downstream tasks. However, recent research has demonstrated that such a straightforward approach is often brittle. For example, Elazar et al. (2021) and Branco et al. (2021) show that, on question-answering (QA) tasks, similar performance can be achieved with questions removed from the inputs. Min et al. (2019), Chen and Durrett (2019), and Tang et al. (2021) show that models trained on multi-hop QA do not generalize to answer single-hop questions. The reasoning capabilities of these models thus remain at a surface level, i.e., exploiting data patterns. Consequently, augmenting LMs with techniques that make them robust and effective becomes an active research area. We will start the tutorial by providing an overview of complex reasoning tasks where the standard application of pretrained language models fails. This tutorial then reviews recent promising directions for tackling these tasks. Specifically, we focus on the following groups of approaches that explicitly consider problem structures: (1) knowledge-augmented methods, where the knowledge is either incorporated during fine-tuning or pretraining; (2) few-shot prompting methods, which effectively guide the models to follow instructions; (3) neuro-symbolic methods, which produce explicit intermediate representations; and, (4) rationale-based methods, one of the most popular forms of the neuro-symbolic methods, which highlight subsets of input as explanations for individual model predictions. | Wenting Zhao, Mor Geva, Bill Yuchen Lin, Michihiro Yasunaga, Aman Madaan, Tao Yu |  |
| 140 |  |  [Everything you need to know about Multilingual LLMs: Towards fair, performant and reliable models for languages of the world](https://doi.org/10.18653/v1/2023.acl-tutorials.3) |  | 0 | This tutorial will describe various aspects of scaling up language technologies to many of the world’s languages by describing the latest research in Massively Multilingual Language Models (MMLMs). We will cover topics such as data collection, training and fine-tuning of models, Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages. Further, we will also talk about some of the real-world challenges in deploying these models in language communities in the field. With the performance of MMLMs improving in the zero-shot setting for many languages, it is now becoming feasible to use them for building language technologies in many languages of the world, and this tutorial will provide the computational linguistics community with unique insights from the latest research in multilingual models. | Sunayana Sitaram, Monojit Choudhury, Barun Patra, Vishrav Chaudhary, Kabir Ahuja, Kalika Bali |  |
| 141 |  |  [Generating Text from Language Models](https://doi.org/10.18653/v1/2023.acl-tutorials.4) |  | 0 | An increasingly large percentage of natural language processing (NLP) tasks center around the generation of text from probabilistic language models. Despite this trend, techniques for improving or specifying preferences in these generated texts rely mostly on intuition-based heuristics. Further, there lacks a unified presentation of their motivations, practical implementation, successes and pitfalls. Practitioners must, therefore, choose somewhat blindly between generation algorithms—like top-p sampling or beam search—which can lead to wildly different results. At the same time, language generation research continues to criticize and improve the standard toolboxes, further adding entropy to the state of the field. In this tutorial, we will provide a centralized and cohesive discussion of critical considerations when choosing how to generate from a language model. We will cover a wide range of empirically-observed problems (like degradation, hallucination, repetition) and their corresponding proposed algorithmic solutions from recent research (like top-p sampling and its successors). We will then discuss a subset of these algorithms under a unified light; most stochastic generation strategies can be framed as locally adapting the probabilities of a model to avoid failure cases. Finally, we will then cover methods in controlled generation, that go beyond just ensuring coherence to ensure text exhibits specific desired properties. We aim for NLP practitioners and researchers to leave our tutorial with a unified framework which they can use to evaluate and contribute to the latest research in language generation. | Afra Amini, Ryan Cotterell, John Hewitt, Clara Meister, Tiago Pimentel |  |
| 142 |  |  [Indirectly Supervised Natural Language Processing](https://doi.org/10.18653/v1/2023.acl-tutorials.5) |  | 0 | This tutorial targets researchers and practitioners who are interested in ML technologies for NLP from indirect supervision. In particular, we will present a diverse thread of indirect supervision studies that try to answer the following questions: (i) when and how can we provide supervision for a target task T, if all we have is data that corresponds to a “related” task T′? (ii) humans do not use exhaustive supervision; they rely on occasional feedback, and learn from incidental signals from various sources; how can we effectively incorporate such supervision in machine learning? (iii) how can we leverage multi-modal supervision to help NLP? To the end, we will discuss several lines of research that address those challenges, including (i) indirect supervision from T ′ that handles T with outputs spanning from a moderate size to an open space, (ii) the use of sparsely occurring and incidental signals, such as partial labels, noisy labels, knowledge-based constraints, and cross-domain or cross-task annotations—all having statistical associations with the task, (iii) principled ways to measure and understand why these incidental signals can contribute to our target tasks, and (iv) indirect supervision from vision-language signals. We will conclude the tutorial by outlining directions for further investigation. | Wenpeng Yin, Muhao Chen, Ben Zhou, Qiang Ning, KaiWei Chang, Dan Roth |  |
| 143 |  |  [Retrieval-based Language Models and Applications](https://doi.org/10.18653/v1/2023.acl-tutorials.6) |  | 0 | Retrieval-based language models (LMs) have shown impressive performance on diverse NLP tasks. In this tutorial, we will provide a comprehensive and coherent overview of recent advances in retrieval-based LMs. We will start by providing preliminaries covering the foundation of LMs (e.g., masked LMs, autoregressive LMs) and retrieval systems (e.g., nearest-neighbor search). We will then detail recent progress in retrieval-based models, focusing on their model architectures and learning approaches. Finally, we will show how retrieval-based LMs are adapted to downstream applications, and extended to multilingual and multi-modal settings. Finally, we will use an exercise to showcase the effectiveness of retrieval-based LMs. | Akari Asai, Sewon Min, Zexuan Zhong, Danqi Chen |  |
| 144 |  |  [ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer](https://doi.org/10.18653/v1/2023.acl-srw.1) |  | 0 | Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT’s performance in two controllable generation tasks, with respect to ChatGPT’s ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model’s performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style. | Dongqi Liu, Vera Demberg |  |
| 145 |  |  [Multi-Dialectal Representation Learning of Sinitic Phonology](https://doi.org/10.18653/v1/2023.acl-srw.2) |  | 0 | Machine learning techniques have shown their competence for representing and reasoning in symbolic systems such as language and phonology. In Sinitic Historical Phonology, notable tasks that could benefit from machine learning include the comparison of dialects and reconstruction of proto-languages systems. Motivated by this, this paper provides an approach for obtaining multi-dialectal representations of Sinitic syllables, by constructing a knowledge graph from structured phonological data ,then applying the BoxE technique from knowledge base learning. We applied unsupervised clustering techniques to the obtained representations to observe that the representations capture phonemic contrast from the input dialects. Furthermore, we trained classifiers to perform inference of unobserved Middle Chinese labels, showing the representations’ potential for indicating archaic, proto-language features. The representations can be used for performing completion of fragmented Sinitic phonological knowledge bases, estimating divergences between different characters, or aiding the exploration and reconstruction of archaic features. | Zhibai Jia |  |
| 146 |  |  [Prompt-based Zero-shot Text Classification with Conceptual Knowledge](https://doi.org/10.18653/v1/2023.acl-srw.4) |  | 0 | In recent years, pre-trained language models have garnered significant attention due to their effectiveness, which stems from the rich knowledge acquired during pre-training. To mitigate the inconsistency issues between pre-training tasks and downstream tasks and to facilitate the resolution of language-related issues, prompt-based approaches have been introduced, which are particularly useful in low-resource scenarios. However, existing approaches mostly rely on verbalizers to translate the predicted vocabulary to task-specific labels. The major limitations of this approach are the ignorance of potentially relevant domain-specific words and being biased by the pre-training data. To address these limitations, we propose a framework that incorporates conceptual knowledge for text classification in the extreme zero-shot setting. The framework includes prompt-based keyword extraction, weight assignment to each prompt keyword, and final representation estimation in the knowledge graph embedding space. We evaluated the method on four widely-used datasets for sentiment analysis and topic detection, demonstrating that it consistently outperforms recently-developed prompt-based approaches in the same experimental settings. | Yuqi Wang, Wei Wang, Qi Chen, Kaizhu Huang, Anh Nguyen, Suparna De |  |
| 147 |  |  [How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in Japanese](https://doi.org/10.18653/v1/2023.acl-srw.5) |  | 0 | This paper investigates the effect of tokenizers on the downstream performance of pretrained language models (PLMs) in scriptio continua languages where no explicit spaces exist between words, using Japanese as a case study. The tokenizer for such languages often consists of a morphological analyzer and a subword tokenizer, requiring us to conduct a comprehensive study of all possible pairs. However, previous studies lack this comprehensiveness. We therefore train extensive sets of tokenizers, build a PLM using each, and measure the downstream performance on a wide range of tasks. Our results demonstrate that each downstream task has a different optimal morphological analyzer, and that it is better to use Byte-Pair-Encoding or Unigram rather than WordPiece as a subword tokenizer, regardless of the type of task. | Takuro Fujii, Koki Shibata, Atsuki Yamaguchi, Terufumi Morishita, Yasuhiro Sogawa |  |
| 148 |  |  [Semantic-Aware Dynamic Retrospective-Prospective Reasoning for Event-Level Video Question Answering](https://doi.org/10.18653/v1/2023.acl-srw.7) |  | 0 | Event-Level Video Question Answering (EVQA) requires complex reasoning across video events to obtain the visual information needed to provide optimal answers. However, despite significant progress in model performance, few studies have focused on using the explicit semantic connections between the question and visual information especially at the event level. There is need for using such semantic connections to facilitate complex reasoning across video frames. Therefore, we propose a semantic-aware dynamic retrospective-prospective reasoning approach for video-based question answering. Specifically, we explicitly use the Semantic Role Labeling (SRL) structure of the question in the dynamic reasoning process where we decide to move to the next frame based on which part of the SRL structure (agent, verb, patient, etc.) of the question is being focused on. We conduct experiments on a benchmark EVQA dataset - TrafficQA. Results show that our proposed approach achieves superior performance compared to previous state-of-the-art models. Our code is publicly available at https://github.com/lyuchenyang/Semantic-aware-VideoQA. | Chenyang Lyu, Tianbo Ji, Yvette Graham, Jennifer Foster |  |
| 149 |  |  [Jamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models](https://doi.org/10.18653/v1/2023.acl-srw.8) |  | 0 | Natural Language Inference (NLI) tasks involving temporal inference remain challenging for pre-trained language models (LMs). Although various datasets have been created for this task, they primarily focus on English and do not address the need for resources in other languages. It is unclear whether current LMs realize the generalization capacity for temporal inference across languages. In this paper, we present Jamp, a Japanese NLI benchmark focused on temporal inference. Our dataset includes a range of temporal inference patterns, which enables us to conduct fine-grained analysis. To begin the data annotation process, we create diverse inference templates based on the formal semantics test suites. We then automatically generate diverse NLI examples by using the Japanese case frame dictionary and well-designed templates while controlling the distribution of inference patterns and gold labels. We evaluate the generalization capacities of monolingual/multilingual LMs by splitting our dataset based on tense fragments (i.e., temporal inference patterns). Our findings demonstrate that LMs struggle with specific linguistic phenomena, such as habituality, indicating that there is potential for the development of more effective NLI models across languages. | Tomoki Sugimoto, Yasumasa Onoe, Hitomi Yanaka |  |
| 150 |  |  [Constructing Multilingual Code Search Dataset Using Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-srw.10) |  | 0 | Code search is a task to find programming codes that semantically match the given natural language queries. Even though some of the existing datasets for this task are multilingual on the programming language side, their query data are only in English. In this research, we create a multilingual code search dataset in four natural and four programming languages using a neural machine translation model. Using our dataset, we pre-train and fine-tune the Transformer-based models and then evaluate them on multiple code search test sets. Our results show that the model pre-trained with all natural and programming language data has performed best in most cases. By applying back-translation data filtering to our dataset, we demonstrate that the translation quality affects the model’s performance to a certain extent, but the data size matters more. | Ryo Sekizawa, Nan Duan, Shuai Lu, Hitomi Yanaka |  |
| 151 |  |  [Multimodal Neural Machine Translation Using Synthetic Images Transformed by Latent Diffusion Model](https://doi.org/10.18653/v1/2023.acl-srw.12) |  | 0 | This study proposes a new multimodal neural machine translation (MNMT) model using synthetic images transformed by a latent diffusion model. MNMT translates a source language sentence based on its related image, but the image usually contains noisy information that are not relevant to the source language sentence. Our proposed method first generates a synthetic image corresponding to the content of the source language sentence by using a latent diffusion model and then performs translation based on the synthetic image. The experiments on the English-German translation tasks using the Multi30k dataset demonstrate the effectiveness of the proposed method. | Ryoya Yuasa, Akihiro Tamura, Tomoyuki Kajiwara, Takashi Ninomiya, Tsuneo Kato |  |
| 152 |  |  [Enhancing Ancient Chinese Understanding with Derived Noisy Syntax Trees](https://doi.org/10.18653/v1/2023.acl-srw.15) |  | 0 | Despite the rapid development of neural-based models, syntax still plays a crucial role in modern natural language processing. However, few studies have incorporated syntactic information into ancient Chinese understanding tasks due to the lack of syntactic annotation. This paper explores the role of syntax in ancient Chinese understanding based on the noisy syntax trees from unsupervised derivation and modern Chinese syntax parsers. On top of that, we propose a novel syntax encoding component – confidence-based syntax encoding network (cSEN) to alleviate the side effects from the existing noise caused by unsupervised syntax derivation and the incompatibility between ancient and modern Chinese. Experiments on two typical ancient Chinese understanding tasks, ancient poetry theme classification and ancient-modern Chinese translation, demonstrate that syntactic information can effectively enhance the understanding of ancient Chinese over strong baselines, and that the proposed cSEN plays an important role in noisy scenarios. | Ping Wang, Shitou Zhang, Zuchao Li, Jingrui Hou |  |
| 153 |  |  [The Turing Quest: Can Transformers Make Good NPCs?](https://doi.org/10.18653/v1/2023.acl-srw.17) |  | 0 | In this paper, we study the viability of the deployment of language models towards non-playable character (NPC) scripts, by introducing a novel pipeline for the automatic construction of NPC scripts using Transformer-based believable scripts for a variety of game genres and specifications. In addition, we propose a self-diagnosis method inspired by previous work to develop language models, tailored specifically to desirable NPC qualities such as coherency, believability, and degree of repetition. Finally, we propose a new benchmark, called The Turing Quest, which we use to show that the pipeline, when applied to GPT-3, can generate for a variety of game genres and contexts, NPC scripts that can fool judges in thinking they have been written by humans. We believe that these findings can greatly benefit both the gaming industry and its global community of users, since many current games continue to base their NPCs on manually-curated scripts that are resource-demanding and may curb the immersiveness and enjoyment of the user. | Qi Chen Gao, Ali Emami |  |
| 154 |  |  [Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section](https://doi.org/10.18653/v1/2023.acl-srw.18) |  | 0 | Recent advances in large language models have led to renewed interest in natural language processing in healthcare using the free text of clinical notes. One distinguishing characteristic of clinical notes is their long time span over multiple long documents. The unique structure of clinical notes creates a new design choice: when the context length for a language model predictor is limited, which part of clinical notes should we choose as the input? Existing studies either choose the inputs with domain knowledge or simply truncate them. We propose a framework to analyze the sections with high predictive power. Using MIMIC-III, we show that: 1) predictive power distribution is different between nursing notes and discharge notes and 2) combining different types of notes could improve performance when the context length is large. Our findings suggest that a carefully selected sampling function could enable more efficient information extraction from clinical notes. | Hongyi Zheng, Yixin Zhu, Lavender Y. Jiang, Kyunghyun Cho, Eric K. Oermann |  |
| 155 |  |  [Intriguing Effect of the Correlation Prior on ICD-9 Code Assignment](https://doi.org/10.18653/v1/2023.acl-srw.19) |  | 0 | The Ninth Revision of the International Classification of Diseases (ICD-9) is a standardized coding system used to classify health conditions. It is used for billing, tracking individual patient conditions, and for epidemiology. The highly detailed and technical nature of the codes and their associated medical conditions make it difficult for humans to accurately record them. Researchers have explored the use of neural networks, particularly language models, for automated ICD-9 code assignment. However, the imbalanced distribution of ICD-9 codes leads to poor performance. One solution is to use domain knowledge to incorporate a useful prior. This paper evaluates the usefulness of the correlation bias: we hypothesize that correlations between ICD-9 codes and other medical codes could help improve language models’ performance. We showed that while the correlation bias worsens the overall performance, the effect on individual class can be negative or positive. Performance on classes that are more imbalanced and less correlated with other codes is more sensitive to incorporating the correlation bias. This suggests that while the correlation bias has potential to improve ICD-9 code assignment in certain cases, the applicability criteria need to be more carefully studied. | Zihao Yang, Chenkang Zhang, Muru Wu, Xujin Liu, Lavender Y. Jiang, Kyunghyun Cho, Eric K. Oermann |  |
| 156 |  |  [Classical Out-of-Distribution Detection Methods Benchmark in Text Classification Tasks](https://doi.org/10.18653/v1/2023.acl-srw.20) |  | 0 | State-of-the-art models can perform well in controlled environments, but they often struggle when presented with out-of-distribution (OOD) examples, making OOD detection a critical component of NLP systems. In this paper, we focus on highlighting the limitations of existing approaches to OOD detection in NLP. Specifically, we evaluated eight OOD detection methods that are easily integrable into existing NLP systems and require no additional OOD data or model modifications. One of our contributions is providing a well-structured research environment that allows for full reproducibility of the results. Additionally, our analysis shows that existing OOD detection methods for NLP tasks are not yet sufficiently sensitive to capture all samples characterized by various types of distributional shifts. Particularly challenging testing scenarios arise in cases of background shift and randomly shuffled word order within in domain texts. This highlights the need for future work to develop more effective OOD detection approaches for the NLP problems, and our work provides a well-defined foundation for further research in this area. | Mateusz Baran, Joanna Baran, Mateusz Wójcik, Maciej Zieba, Adam Gonczarek |  |
| 157 |  |  [Can LMs Store and Retrieve 1-to-N Relational Knowledge?](https://doi.org/10.18653/v1/2023.acl-srw.22) |  | 0 | It has been suggested that pretrained language models can be viewed as knowledge bases. One of the prerequisites for using language models as knowledge bases is how accurately they can store and retrieve world knowledge. It is already revealed that language models can store much 1-to-1 relational knowledge, such as ”country and its capital,” with high memorization accuracy. On the other hand, world knowledge includes not only 1-to-1 but also 1-to-N relational knowledge, such as ”parent and children.”However, it is not clear how accurately language models can handle 1-to-N relational knowledge. To investigate language models’ abilities toward 1-to-N relational knowledge, we start by designing the problem settings. Specifically, we organize the character of 1-to-N relational knowledge and define two essential skills: (i) memorizing multiple objects individually and (ii) retrieving multiple stored objects without excesses or deficiencies at once. We inspect LMs’ ability to handle 1-to-N relational knowledge on the controlled synthesized data. As a result, we report that it is possible to memorize multiple objects with high accuracy, but generalizing the retrieval ability (expressly, enumeration) is challenging. | Haruki Nagasawa, Benjamin Heinzerling, Kazuma Kokuta, Kentaro Inui |  |
| 158 |  |  [Theoretical Linguistics Rivals Embeddings in Language Clustering for Multilingual Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-srw.24) |  | 0 | While embedding-based methods have been dominant in language clustering for multilingual tasks, clustering based on linguistic features has not yet been explored much, as it remains baselines (Tan et al., 2019; Shaffer, 2021). This study investigates whether and how theoretical linguistics improves language clustering for multilingual named entity recognition (NER). We propose two types of language groupings: one based on morpho-syntactic features in a nominal domain and one based on a head parameter. Our NER experiments show that the proposed methods largely outperform a state-of-the-art embedding-based model, suggesting that theoretical linguistics plays a significant role in multilingual learning tasks. | Sakura Imai, Daisuke Kawahara, Naho Orita, Hiromune Oda |  |
| 159 |  |  [Native Language Prediction from Gaze: a Reproducibility Study](https://doi.org/10.18653/v1/2023.acl-srw.26) |  | 0 | Numerous studies found that the linguistic properties of a person’s native language affect the cognitive processing of other languages. However, only one study has shown that it was possible to identify the native language based on eye-tracking records of natural L2 reading using machine learning. A new corpus allows us to replicate these results on a more interrelated and larger set of native languages. Our results show that comparable classification performance is maintained despite using less data. However, analysis shows that the correlation between L2 eye movements and native language similarity may be more complex than the original study found. | Lina Skerath, Paulina Toborek, Anita Zielinska, Maria Barrett, Rob van der Goot |  |
| 160 |  |  [MedTem2.0: Prompt-based Temporal Classification of Treatment Events from Discharge Summaries](https://doi.org/10.18653/v1/2023.acl-srw.27) |  | 0 | Discharge summaries are comprehensive medical records that encompass vital information about a patient’s hospital stay. A crucial aspect of discharge summaries is the temporal information of treatments administered throughout the patient’s illness. With an extensive volume of clinical documents, manually extracting and compiling a patient’s medication list can be laborious, time-consuming, and susceptible to errors. The objective of this paper is to build upon the recent development on clinical NLP by temporally classifying treatments in clinical texts, specifically determining whether a treatment was administered between the time of admission and discharge from the hospital. State-of-the-art NLP methods including prompt-based learning on Generative Pre-trained Transformers (GPTs) models and fine-tuning on pre-trained language models (PLMs) such as BERT were employed to classify temporal relations between treatments and hospitalisation periods in discharge summaries. Fine-tuning with the BERT model achieved an F1 score of 92.45% and a balanced accuracy of 77.56%, while prompt learning using the T5 model and mixed templates resulted in an F1 score of 90.89% and a balanced accuracy of 72.07%.Our codes and data are available at https://github.com/HECTA-UoM/MedTem. | Yang Cui, Lifeng Han, Goran Nenadic |  |
| 161 |  |  [Sudden Semantic Shifts in Swedish NATO discourse](https://doi.org/10.18653/v1/2023.acl-srw.28) |  | 0 | In this paper, we investigate a type of semantic shift that occurs when a sudden event radically changes public opinion on a topic. Looking at Sweden’s decision to apply for NATO membership in 2022, we use word embeddings to study how the associations users on Twitter have regarding NATO evolve. We identify several changes that we successfully validate against real-world events. However, the low engagement of the public with the issue often made it challenging to distinguish true signals from noise. We thus find that domain knowledge and data selection are of prime importance when using word embeddings to study semantic shifts. | Brian Bonafilia, Bastiaan Bruinsma, Denitsa Saynova, Moa Johansson |  |
| 162 |  |  [Building a Buzzer-quiz Answering System](https://doi.org/10.18653/v1/2023.acl-srw.29) |  | 0 | A buzzer quiz is a genre of quiz in which multiple players simultaneously listen to a quiz being read aloud and respond it by buzzing in as soon as they can predict the answer. Because incorrect answers often result in penalties, a buzzer-quiz answering system must not only predict the answer from only part of a question but also estimate the predicted answer’s accuracy. In this paper, we introduce two types of buzzer-quiz answering systems: (1) a system that directly generates an answer from part of a question by using an autoregressive language model; and (2) a system that first reconstructs the entire question by using an autoregressive language model and then determines the answer according to the reconstructed question. We then propose a method to estimate the accuracy of the answers for each system by using the internal scores of each model. | Naoya Sugiura, Kosuke Yamada, Ryohei Sasano, Koichi Takeda, Katsuhiko Toyama |  |
| 163 |  |  [Probing for Hyperbole in Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.acl-srw.30) |  | 0 | Hyperbole is a common figure of speech, which is under-explored in NLP research. In this study, we conduct edge and minimal description length (MDL) probing experiments on three pre-trained language models (PLMs) in an attempt to explore the extent to which hyperbolic information is encoded in these models. We use both word-in-context and sentence-level representations as model inputs as a basis for comparison. We also annotate 63 hyperbole sentences from the HYPO dataset according to an operational taxonomy to conduct an error analysis to explore the encoding of different hyperbole categories. Our results show that hyperbole is to a limited extent encoded in PLMs, and mostly in the final layers. They also indicate that hyperbolic information may be better encoded by the sentence-level representations, which, due to the pragmatic nature of hyperbole, may therefore provide a more accurate and informative representation in PLMs. Finally, the inter-annotator agreement for our annotations, a Cohen’s Kappa of 0.339, suggest that the taxonomy categories may not be intuitive and need revision or simplification. | Nina Schneidermann, Daniel Hershcovich, Bolette S. Pedersen |  |
| 164 |  |  [Towards Efficient Dialogue Processing in the Emergency Response Domain](https://doi.org/10.18653/v1/2023.acl-srw.31) |  | 0 | In this paper we describe the task of adapting NLP models to dialogue processing in the emergency response domain. Our goal is to provide a recipe for building a system that performs dialogue act classification and domain-specific slot tagging while being efficient, flexible and robust. We show that adapter models Pfeiffer et al. (2020) perform well in the emergency response domain and benefit from additional dialogue context and speaker information. Comparing adapters to standard fine-tuned Transformer models we show that they achieve competitive results and can easily accommodate new tasks without significant memory increase since the base model can be shared between the adapters specializing on different tasks. We also address the problem of scarce annotations in the emergency response domain and evaluate different data augmentation techniques in a low-resource setting. | Tatiana Anikina |  |
| 165 |  |  [I already said that! Degenerating redundant questions in open-domain dialogue systems](https://doi.org/10.18653/v1/2023.acl-srw.33) |  | 0 | Neural text generation models have achieved remarkable success in carrying on short open-domain conversations. However, their performance degrades significantly in the long term, especially in their ability to ask coherent questions. A significant issue is the generation of redundant questions where the answer has already been provided by the user. We adapt and evaluate different methods, including negative training, decoding, and classification, to mitigate the redundancy problem. We also propose a simple yet effective method for generating training data without the need for crowdsourcing human-human or human-bot conversations. Experiments with the BlenderBot model show that our combined method significantly reduces the rate of redundant questions from 27.2% to 8.7%, while improving the quality of the original model. The code, dataset, and trained models can be found at our repository. | Long Mai, Julie CarsonBerndsen |  |
| 166 |  |  [Is a Knowledge-based Response Engaging?: An Analysis on Knowledge-Grounded Dialogue with Information Source Annotation](https://doi.org/10.18653/v1/2023.acl-srw.34) |  | 0 | Currently, most knowledge-grounded dialogue response generation models focus on reflecting given external knowledge. However, even when conveying external knowledge, humans integrate their own knowledge, experiences, and opinions with external knowledge to make their utterances engaging. In this study, we analyze such human behavior by annotating the utterances in an existing knowledge-grounded dialogue corpus. Each entity in the corpus is annotated with its information source, either derived from external knowledge (database-derived) or the speaker’s own knowledge, experiences, and opinions (speaker-derived). Our analysis shows that the presence of speaker-derived information in the utterance improves dialogue engagingness. We also confirm that responses generated by an existing model, which is trained to reflect the given knowledge, cannot include speaker-derived information in responses as often as humans do. | Takashi Kodama, Hirokazu Kiyomaru, Yin Jou Huang, Taro Okahisa, Sadao Kurohashi |  |
| 167 |  |  [Choosing What to Mask: More Informed Masking for Multimodal Machine Translation](https://doi.org/10.18653/v1/2023.acl-srw.35) |  | 0 | Pre-trained language models have achieved remarkable results on several NLP tasks. Most of them adopt masked language modeling to learn representations by randomly masking tokens and predicting them based on their context. However, this random selection of tokens to be masked is inefficient to learn some language patterns as it may not consider linguistic information that can be helpful for many NLP tasks, such as multimodal machine translation (MMT). Hence, we propose three novel masking strategies for cross-lingual visual pre-training - more informed visual masking, more informed textual masking, and more informed visual and textual masking - each one focusing on learning different linguistic patterns. We apply them to Vision Translation Language Modelling for video subtitles (Sato et al., 2022) and conduct extensive experiments on the Portuguese-English MMT task. The results show that our masking approaches yield significant improvements over the original random masking strategy for downstream MMT performance. Our models outperform the MMT baseline and we achieve state-of-the-art accuracy (52.70 in terms of BLEU score) on the How2 dataset, indicating that more informed masking helps in acquiring an understanding of specific language structures and has great potential for language understanding. | Júlia Sato, Helena de Medeiros Caseli, Lucia Specia |  |
| 168 |  |  [Combining Tradition with Modernness: Exploring Event Representations in Vision-and-Language Models for Visual Goal-Step Inference](https://doi.org/10.18653/v1/2023.acl-srw.36) |  | 0 | Procedural knowledge understanding (PKU) underlies the ability to infer goal-step relations. The task of Visual Goal–Step Inference addresses this ability in the multimodal domain. It requires to identify images that represent the steps towards achieving a textually expressed goal. The best existing methods encode texts and images either with independent encoders, or with object-level multimodal encoders using blackbox transformers. This stands in contrast to early, linguistically inspired methods for event representations, which focus on capturing the most crucial information, namely actions and the participants, to learn stereotypical event sequences and hence procedural knowledge. In this work, we study various methods and their effects on PKU of injecting the early shallow event representations to nowadays multimodal deep learning-based models. We find that the early, linguistically inspired methods for representing event knowledge does contribute to understand procedures in combination with modern vision-and-language models. In the future, we are going to explore more complex structure of events and study how to exploit it on top of large language models. | Chong Shen, Carina Silberer |  |
| 169 |  |  [Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values](https://doi.org/10.18653/v1/2023.acl-srw.37) |  | 0 | Although Shapley values have been shown to be highly effective for identifying harmful training instances, dataset size and model complexity constraints limit the ability to apply Shapley-based data valuation to fine-tuning large pre-trained language models. To address this, we propose TS-DShapley, an algorithm that reduces computational cost of Shapley-based data valuation through: 1) an efficient sampling-based method that aggregates Shapley values computed from subsets for valuation of the entire training set, and 2) a value transfer method that leverages value information extracted from a simple classifier trained using representations from the target language model. Our experiments applying TS-DShapley to select data for fine-tuning BERT-based language models on benchmark natural language understanding (NLU) datasets show that TS-DShapley outperforms existing data selection methods. Further, TS-DShapley can filter fine-tuning data to increase language model performance compared to training with the full fine-tuning dataset. | Stephanie Schoch, Ritwick Mishra, Yangfeng Ji |  |
| 170 |  |  [Distractor Generation for Fill-in-the-Blank Exercises by Question Type](https://doi.org/10.18653/v1/2023.acl-srw.38) |  | 0 | This study addresses the automatic generation of distractors for English fill-in-the-blank exercises in the entrance examinations for Japanese universities. While previous studies applied the same method to all questions, actual entrance examinations have multiple question types that reflect the purpose of the questions. Therefore, we define three types of questions (grammar, function word, and context) and propose a method to generate distractors according to the characteristics of each question type. Experimental results on 500 actual questions show the effectiveness of the proposed method for both automatic and manual evaluation. | Nana Yoshimi, Tomoyuki Kajiwara, Satoru Uchida, Yuki Arase, Takashi Ninomiya |  |
| 171 |  |  [Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity](https://doi.org/10.18653/v1/2023.acl-srw.40) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in generating fluent text, as well as tendencies to reproduce undesirable social biases. This work investigates whether LLMs reproduce the moral biases associated with political groups in the United States, an instance of a broader capability herein termed moral mimicry. This work explores this hypothesis in the GPT-3/3.5 and OPT families of Transformer-based LLMs. Using tools from Moral Foundations Theory, this work shows that these LLMs are indeed moral mimics. When prompted with a liberal or conservative political identity, the models generate text reflecting corresponding moral biases. This study also explores the relationship between moral mimicry and model size, and similarity between human and LLM moral word use. | Gabriel Simmons |  |
| 172 |  |  [LECO: Improving Early Exiting via Learned Exits and Comparison-based Exiting Mechanism](https://doi.org/10.18653/v1/2023.acl-srw.43) |  | 0 | Recently, dynamic early exiting has attracted much attention since it can accelerate the inference speed of pre-trained models (PTMs). However, previous work on early exiting has neglected the intermediate exits’ architectural designs. In this work, we propose a novel framework, Learned Exits and COmparison-based early exiting (LECO) to improve PTMs’ early exiting performances. First, to fully uncover the potentials of multi-exit BERT, we design a novel search space for intermediate exits and employ the idea of differentiable neural architecture search (DNAS) to design proper exit architectures for different intermediate layers automatically. Second, we propose a simple-yet-effective comparison-based early exiting mechanism (COBEE), which can help PTMs achieve better performance and speedup tradeoffs. Extensive experiments show that our LECO achieves the SOTA performances for multi-exit BERT training and dynamic early exiting. | Jingfan Zhang, Ming Tan, Pengyu Dai, Wei Zhu |  |
| 173 |  |  [Authorship Attribution of Late 19th Century Novels using GAN-BERT](https://doi.org/10.18653/v1/2023.acl-srw.44) |  | 0 | Authorship attribution aims to identify the author of an anonymous text. The task becomes even more worthwhile when it comes to literary works. For example, pen names were commonly used by female authors in the 19th century resulting in some literary works being incorrectly attributed or claimed. With this motivation, we collated a dataset of late 19th century novels in English. Due to the imbalance in the dataset and the unavailability of enough data per author, we employed the GANBERT model along with data sampling strategies to fine-tune a transformer-based model for authorship attribution. Differently from the earlier studies on the GAN-BERT model, we conducted transfer learning on comparatively smaller author subsets to train more focused author-specific models yielding performance over 0.88 accuracy and F1 scores. Furthermore, we observed that increasing the sample size has a negative impact on the model’s performance. Our research mainly contributes to the ongoing authorship attribution research using GAN-BERT architecture, especially in attributing disputed novelists in the late 19th century. | Kanishka Silva, Burcu Can, Frédéric Blain, Raheem Sarwar, Laura Ugolini, Ruslan Mitkov |  |
| 174 |  |  [How-to Guides for Specific Audiences: A Corpus and Initial Findings](https://doi.org/10.18653/v1/2023.acl-srw.46) |  | 0 | Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work. | Nicola Fanton, Agnieszka Falenska, Michael Roth |  |
| 175 |  |  ["When Words Fail, Emojis Prevail": A Novel Architecture for Generating Sarcastic Sentences With Emoji Using Valence Reversal and Semantic Incongruity](https://doi.org/10.18653/v1/2023.acl-srw.47) |  | 0 | Sarcasm is a form of figurative language that serves as a humorous tool for mockery and ridicule. We present a novel architecture for sarcasm generation with emoji from a non-sarcastic input sentence in English. We divide the generation task into two sub tasks: one for generating textual sarcasm and another for collecting emojis associated with those sarcastic sentences. Two key elements of sarcasm are incorporated into the textual sarcasm generation task: valence reversal and semantic incongruity with context, where the context may involve shared commonsense or general knowledge between the speaker and their audience. The majority of existing sarcasm generation works have focused on this textual form. However, in the real world, when written texts fall short of effectively capturing the emotional cues of spoken and face-to-face communication, people often opt for emojis to accurately express their emotions. Due to the wide range of applications of emojis, incorporating appropriate emojis to generate textual sarcastic sentences helps advance sarcasm generation. We conclude our study by evaluating the generated sarcastic sentences using human judgement. All the codes and data used in this study has been made publicly available. | Faria Binte Kader, Nafisa Hossain Nujat, Tasmia Binte Sogir, Mohsinul Kabir, Hasan Mahmud, Md. Kamrul Hasan |  |
| 176 |  |  [Semantic Accuracy in Natural Language Generation: A Thesis Proposal](https://doi.org/10.18653/v1/2023.acl-srw.48) |  | 0 | With the fast-growing popularity of current large pre-trained language models (LLMs), it is necessary to dedicate efforts to making them more reliable. In this thesis proposal, we aim to improve the reliability of natural language generation systems (NLG) by researching the semantic accuracy of their outputs. We look at this problem from the outside (evaluation) and from the inside (interpretability). We propose a novel method for evaluating semantic accuracy and discuss the importance of working towards a unified and objective benchmark for NLG metrics. We also review interpretability approaches which could help us pinpoint the sources of inaccuracies within the models and explore potential mitigation strategies. | Patrícia Schmidtová |  |
| 177 |  |  [Should you marginalize over possible tokenizations?](https://doi.org/10.18653/v1/2023.acl-short.1) |  | 0 | Autoregressive language models (LMs) map token sequences to probabilities. The usual practice for computing the probability of any character string (e.g. English sentences) is to first transform it into a sequence of tokens that is scored by the model. However, there are exponentially many token sequences that represent any given string. To truly compute the probability of a string one should marginalize over all tokenizations, which is typically intractable. Here, we analyze whether the practice of ignoring the marginalization is justified. To this end, we devise an importance-sampling-based algorithm that allows us to compute estimates of the marginal probabilities and compare them to the default procedure in a range of state-of-the-art models and datasets. Our results show that the gap in log-likelihood is no larger than 0.5% in most cases, but that it becomes more pronounced for data with long complex words. | Nadezhda Chirkova, Germán Kruszewski, Jos Rozen, Marc Dymetman |  |
| 178 |  |  [Back to Patterns: Efficient Japanese Morphological Analysis with Feature-Sequence Trie](https://doi.org/10.18653/v1/2023.acl-short.2) |  | 0 | Accurate neural models are much less efficient than non-neural models and are useless for processing billions of social media posts or handling user queries in real time with a limited budget. This study revisits the fastest pattern-based NLP methods to make them as accurate as possible, thus yielding a strikingly simple yet surprisingly accurate morphological analyzer for Japanese. The proposed method induces reliable patterns from a morphological dictionary and annotated data. Experimental results on two standard datasets confirm that the method exhibits comparable accuracy to learning-based baselines, while boasting a remarkable throughput of over 1,000,000 sentences per second on a single modern CPU. The source code is available at https://www.tkl.iis.u-tokyo.ac.jp/ynaga/jagger/ | Naoki Yoshinaga |  |
| 179 |  |  [Transformed Protoform Reconstruction](https://doi.org/10.18653/v1/2023.acl-short.3) |  | 0 | Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023. | Young Min Kim, Kalvin Chang, Chenxuan Cui, David R. Mortensen |  |
| 180 |  |  [Ellipsis-Dependent Reasoning: a New Challenge for Large Language Models](https://doi.org/10.18653/v1/2023.acl-short.4) |  | 0 | We propose a novel challenge for large language models: ellipsis-dependent reasoning. We define several structures of paired examples, where an ellipsis example is matched to its non-ellipsis counterpart, and a question is posed which requires resolution of the ellipsis. Test results show that the best models perform well on non-elliptical examples but struggle with all but the simplest ellipsis structures. | Daniel Hardt |  |
| 181 |  |  [Bootstrapping Neural Relation and Explanation Classifiers](https://doi.org/10.18653/v1/2023.acl-short.5) |  | 0 | We introduce a method that self trains (or bootstraps) neural relation and explanation classifiers. Our work expands the supervised approach of CITATION, which jointly trains a relation classifier with an explanation classifier that identifies context words important for the relation at hand, to semi-supervised scenarios. In particular, our approach iteratively converts the explainable models’ outputs to rules and applies them to unlabeled text to produce new annotations. Our evaluation on the TACRED dataset shows that our method outperforms the rule-based model we started from by 15 F1 points, outperforms traditional self-training that relies just on the relation classifier by 5 F1 points, and performs comparatively with the prompt-based approach of CITATION (without requiring an additional natural language inference component). | Zheng Tang, Mihai Surdeanu |  |
| 182 |  |  [A Fast Algorithm for Computing Prefix Probabilities](https://doi.org/10.18653/v1/2023.acl-short.6) |  | 0 | Multiple algorithms are known for efficiently calculating the prefix probability of a string under a probabilistic context-free grammar (PCFG). Good algorithms for the problem have a runtime cubic in the length of the input string. However, some proposed algorithms are suboptimal with respect to the size of the grammar. This paper proposes a new speed-up of Jelinek and Lafferty’s (1991) algorithm, which runs in O(n3\|N\|3 + \|N\|4), where n is the input length and \|N\| is the number of non-terminals in the grammar. In contrast, our speed-up runs in O(n2\|N\|3 + n3\|N\|2). | Franz Nowak, Ryan Cotterell |  |
| 183 |  |  [Analyzing Text Representations by Measuring Task Alignment](https://doi.org/10.18653/v1/2023.acl-short.7) |  | 0 | Textual representations based on pre-trained language models are key, especially in few-shot learning scenarios. What makes a representation good for text classification? Is it due to the geometric properties of the space or because it is well aligned with the task? We hypothesize the second claim. To test it, we develop a task alignment score based on hierarchical clustering that measures alignment at different levels of granularity. Our experiments on text classification validate our hypothesis by showing that task alignment can explain the classification performance of a given representation. | César GonzálezGutiérrez, Audi Primadhanty, Francesco Cazzaro, Ariadna Quattoni |  |
| 184 |  |  [Tracing Linguistic Markers of Influence in a Large Online Organisation](https://doi.org/10.18653/v1/2023.acl-short.8) |  | 0 | Social science and psycholinguistic research have shown that power and status affect how people use language in a range of domains. Here, we investigate a similar question in a large, distributed, consensus-driven community with little traditional power hierarchy – the Internet Engineering Task Force (IETF), a collaborative organisation that designs internet standards. Our analysis based on lexical categories (LIWC) and BERT, shows that participants’ levels of influence can be predicted from their email text, and identify key linguistic differences (e.g., certain LIWC categories, such as “WE” are positively correlated with high-influence). We also identify the differences in language use for the same person before and after becoming influential. | Prashant Khare, Ravi Shekhar, Mladen Karan, Stephen McQuistin, Colin Perkins, Ignacio Castro, Gareth Tyson, Patrick Healey, Matthew Purver |  |
| 185 |  |  [Metaphor Detection via Explicit Basic Meanings Modelling](https://doi.org/10.18653/v1/2023.acl-short.9) |  | 0 | One noticeable trend in metaphor detection is the embrace of linguistic theories such as the metaphor identification procedure (MIP) for model architecture design. While MIP clearly defines that the metaphoricity of a lexical unit is determined based on the contrast between its contextual meaning and its basic meaning, existing work does not strictly follow this principle, typically using the aggregated meaning to approximate the basic meaning of target words. In this paper, we propose a novel metaphor detection method, which models the basic meaning of the word based on literal annotation from the training set, and then compares this with the contextual meaning in a target sentence to identify metaphors. Empirical results show that our method outperforms the state-of-the-art method significantly by 1.0% in F1 score. Moreover, our performance even reaches the theoretical upper bound on the VUA18 benchmark for targets with basic annotations, which demonstrates the importance of modelling basic meanings for metaphor detection. | Yucheng Li, Shun Wang, Chenghua Lin, Frank Guerin |  |
| 186 |  |  [xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages](https://doi.org/10.18653/v1/2023.acl-short.10) |  | 0 | We introduce a new proxy score for evaluating bitext mining based on similarity in a multilingual embedding space: xsim++. In comparison to xsim, this improved proxy leverages rule-based approaches to extend English sentences in any evaluation set with synthetic, hard-to-distinguish examples which more closely mirror the scenarios we encounter during large-scale mining. We validate this proxy by running a significant number of bitext mining experiments for a set of low-resource languages, and subsequently train NMT systems on the mined data. In comparison to xsim, we show that xsim++ is better correlated with the downstream BLEU scores of translation systems trained on mined bitexts, providing a reliable proxy of bitext mining performance without needing to run expensive bitext mining pipelines. xsim++ also reports performance for different error types, offering more fine-grained feedbacks for model development. | Mingda Chen, Kevin Heffernan, Onur Çelebi, Alexandre Mourachko, Holger Schwenk |  |
| 187 |  |  [Graph Propagation based Data Augmentation for Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-short.11) |  | 0 | Data augmentation is an effective solution to improve model performance and robustness for low-resource named entity recognition (NER). However, synthetic data often suffer from poor diversity, which leads to performance limitations. In this paper, we propose a novel Graph Propagated Data Augmentation (GPDA) framework for Named Entity Recognition (NER), leveraging graph propagation to build relationships between labeled data and unlabeled natural texts. By projecting the annotations from the labeled text to the unlabeled text, the unlabeled texts are partially labeled, which has more diversity rather than synthetic annotated data. To strengthen the propagation precision, a simple search engine built on Wikipedia is utilized to fetch related texts of labeled data and to propagate the entity labels to them in the light of the anchor links. Besides, we construct and perform experiments on a real-world low-resource dataset of the E-commerce domain, which will be publicly available to facilitate the low-resource NER research. Experimental results show that GPDA presents substantial improvements over previous data augmentation methods on multiple low-resource NER datasets. | Jiong Cai, Shen Huang, Yong Jiang, Zeqi Tan, Pengjun Xie, Kewei Tu |  |
| 188 |  |  [Dataset Distillation with Attention Labels for Fine-tuning BERT](https://doi.org/10.18653/v1/2023.acl-short.12) |  | 0 | Dataset distillation aims to create a small dataset of informative synthetic samples to rapidly train neural networks that retain the performance of the original dataset. In this paper, we focus on constructing distilled few-shot datasets for natural language processing (NLP) tasks to fine-tune pre-trained transformers. Specifically, we propose to introduce attention labels, which can efficiently distill the knowledge from the original dataset and transfer it to the transformer models via attention probabilities. We evaluated our dataset distillation methods in four various NLP tasks and demonstrated that it is possible to create distilled few-shot datasets with the attention labels, yielding impressive performances for fine-tuning BERT. Specifically, in AGNews, a four-class news classification task, our distilled few-shot dataset achieved up to 93.2% accuracy, which is 98.5% performance of the original dataset even with only one sample per class and only one gradient step. | Aru Maekawa, Naoki Kobayashi, Kotaro Funakoshi, Manabu Okumura |  |
| 189 |  |  [Multi-Document Summarization with Centroid-Based Pretraining](https://doi.org/10.18653/v1/2023.acl-short.13) |  | 0 | In Multi-Document Summarization (MDS), the input can be modeled as a set of documents, and the output is its summary. In this paper, we focus on pretraining objectives for MDS. Specifically, we introduce a novel pretraining objective, which involves selecting the ROUGE-based centroid of each document cluster as a proxy for its summary. Our objective thus does not require human written summaries and can be utilized for pretraining on a dataset consisting solely of document sets. Through zero-shot, few-shot, and fully supervised experiments on multiple MDS datasets, we show that our model Centrum is better or comparable to a state-of-the-art model. We make the pretrained and fine-tuned models freely available to the research community https://github.com/ratishsp/centrum. | Ratish Surendran Puduppully, Parag Jain, Nancy Chen, Mark Steedman |  |
| 190 |  |  [Scaling in Cognitive Modelling: a Multilingual Approach to Human Reading Times](https://doi.org/10.18653/v1/2023.acl-short.14) |  | 0 | Neural language models are increasingly valued in computational psycholinguistics, due to their ability to provide conditional probability distributions over the lexicon that are predictive of human processing times. Given the vast array of available models, it is of both theoretical and methodological importance to assess what features of a model influence its psychometric quality. In this work we focus on parameter size, showing that larger Transformer-based language models generate probabilistic estimates that are less predictive of early eye-tracking measurements reflecting lexical access and early semantic integration. However, relatively bigger models show an advantage in capturing late eye-tracking measurements that reflect the full semantic and syntactic integration of a word into the current language context. Our results are supported by eye movement data in ten languages and consider four models, spanning from 564M to 4.5B parameters. | Andrea Gregor de Varda, Marco Marelli |  |
| 191 |  |  [Improving Generalization in Language Model-based Text-to-SQL Semantic Parsing: Two Simple Semantic Boundary-based Techniques](https://doi.org/10.18653/v1/2023.acl-short.15) |  | 0 | Compositional and domain generalization present significant challenges in semantic parsing, even for state-of-the-art semantic parsers based on pre-trained language models (LMs). In this study, we empirically investigate improving an LM’s generalization in semantic parsing with two simple techniques: at the token level, we introduce a token preprocessing method to preserve the semantic boundaries of tokens produced by LM tokenizers; at the sequence level, we propose to use special tokens to mark the boundaries of components aligned between input and output. Our experimental results on two text-to-SQL semantic parsing datasets show that our token preprocessing, although simple, can substantially improve the LM performance on both types of generalization, and our component boundary marking method is particularly helpful for compositional generalization. | Daking Rai, Bailin Wang, Yilun Zhou, Ziyu Yao |  |
| 192 |  |  [HiPool: Modeling Long Documents Using Graph Neural Networks](https://doi.org/10.18653/v1/2023.acl-short.16) |  | 0 | Encoding long sequences in Natural Language Processing (NLP) is a challenging problem. Though recent pretraining language models achieve satisfying performances in many NLP tasks, they are still restricted by a pre-defined maximum length, making them challenging to be extended to longer sequences. So some recent works utilize hierarchies to model long sequences. However, most of them apply sequential models for upper hierarchies, suffering from long dependency issues. In this paper, we alleviate these issues through a graph-based method. We first chunk the sequence with a fixed length to model the sentence-level information. We then leverage graphs to model intra- and cross-sentence correlations with a new attention mechanism. Additionally, due to limited standard benchmarks for long document classification (LDC), we propose a new challenging benchmark, totaling six datasets with up to 53k samples and 4034 average tokens’ length. Evaluation shows our model surpasses competitive baselines by 2.6% in F1 score, and 4.8% on the longest sequence dataset. Our method is shown to outperform hierarchical sequential models with better performance and scalability, especially for longer sequences. | Irene Li, Aosong Feng, Dragomir Radev, Rex Ying |  |
| 193 |  |  [A Weakly Supervised Classifier and Dataset of White Supremacist Language](https://doi.org/10.18653/v1/2023.acl-short.17) |  | 0 | We present a dataset and classifier for detecting the language of white supremacist extremism, a growing issue in online hate speech. Our weakly supervised classifier is trained on large datasets of text from explicitly white supremacist domains paired with neutral and anti-racist data from similar domains. We demonstrate that this approach improves generalization performance to new domains. Incorporating anti-racist texts as counterexamples to white supremacist language mitigates bias. | Michael Yoder, Ahmad Diab, David West Brown, Kathleen M. Carley |  |
| 194 |  |  [BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases](https://doi.org/10.18653/v1/2023.acl-short.18) |  | 0 | Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model’s output logits. Unlike prior work, BOLT maintains the generator’s autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in 74.4% of the evaluation samples according to human judges. | Xin Liu, Muhammad Khalifa, Lu Wang |  |
| 195 |  |  [mOKB6: A Multilingual Open Knowledge Base Completion Benchmark](https://doi.org/10.18653/v1/2023.acl-short.19) |  | 0 | Automated completion of open knowledge bases (Open KBs), which are constructed from triples of the form (subject phrase, relation phrase, object phrase), obtained via open information extraction (Open IE) system, are useful for discovering novel facts that may not be directly present in the text. However, research in Open KB completion (Open KBC) has so far been limited to resource-rich languages like English. Using the latest advances in multilingual Open IE, we construct the first multilingual Open KBC dataset, called mOKB6, containing facts from Wikipedia in six languages (including English). Improvingthe previous Open KB construction pipeline by doing multilingual coreference resolution andkeeping only entity-linked triples, we create a dense Open KB. We experiment with several models for the task and observe a consistent benefit of combining languages with the help of shared embedding space as well as translations of facts. We also observe that current multilingual models struggle to remember facts seen in languages of different scripts. | Shubham Mittal, Keshav Kolluru, Soumen Chakrabarti, Mausam |  |
| 196 |  |  [Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment](https://doi.org/10.18653/v1/2023.acl-short.20) |  | 0 | Human communication often involves information gaps between the interlocutors. For example, in an educational dialogue a student often provides an answer that is incomplete, and there is a gap between this answer and the perfect one expected by the teacher. Successful dialogue then hinges on the teacher asking about this gap in an effective manner, thus creating a rich and interactive educational experience. We focus on the problem of generating such gap-focused questions (GFQs) automatically. We define the task, highlight key desired aspects of a good GFQ, and propose a model that satisfies these. Finally, we provide an evaluation by human annotators of our generated questions compared against human generated ones, demonstrating competitive performance. | Roni Rabin, Alexandre Djerbetian, Roee Engelberg, Lidan Hackmon, Gal Elidan, Reut Tsarfaty, Amir Globerson |  |
| 197 |  |  [Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts](https://doi.org/10.18653/v1/2023.acl-short.21) |  | 0 | Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo’s rewrites are preferred 2.1 times more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate. | Skyler Hallinan, Alisa Liu, Yejin Choi, Maarten Sap |  |
| 198 |  |  [A Natural Bias for Language Generation Models](https://doi.org/10.18653/v1/2023.acl-short.22) |  | 0 | After just a few hundred training updates, a standard probabilistic model for language generation has likely not yet learnt many semantic or syntactic rules of natural language, making it difficult to estimate the probability distribution over next tokens. Yet around this point, these models have identified a simple, loss-minimising behaviour: to output the unigram distribution of the target training corpus. The use of such a heuristic raises the question: Can we initialise our models with this behaviour and save precious compute resources and model capacity? Here we show that we can effectively endow standard neural language generation models with a separate module that reflects unigram frequency statistics as prior knowledge, simply by initialising the bias term in a model’s final linear layer with the log-unigram distribution. We use neural machine translation as a test bed for this simple technique and observe that it: (i) improves learning efficiency; (ii) achieves better overall performance; and perhaps most importantly (iii) appears to disentangle strong frequency effects by encouraging the model to specialise in non-frequency-related aspects of language. | Clara Meister, Wojciech Stokowiec, Tiago Pimentel, Lei Yu, Laura Rimell, Adhiguna Kuncoro |  |
| 199 |  |  [Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.acl-short.23) |  | 0 | High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using rules without augmentations. | Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam |  |
| 200 |  |  [Parameter-efficient Weight Ensembling Facilitates Task-level Knowledge Transfer](https://doi.org/10.18653/v1/2023.acl-short.24) |  | 0 | Recent studies show that large-scale pre-trained language models could be efficaciously adapted to particular tasks in a parameter-efficient manner. The trained lightweight set of parameters, such as adapters, can be easily stored and shared as a capability equipped with the corresponding models. Owning many lightweight parameters, we focus on transferring them between tasks to acquire an improvement in performance of new tasks, the key point of which is to obtain the similarity between tasks. In this paper, we explore 5 parameter-efficient weight ensembling methods to achieve such transferability and verify the effectiveness of them. These methods extract the information of datasets and trained lightweight parameters from different perspectives to obtain the similarity between tasks, and weight the existing lightweight parameters according to the comparability to acquire a suitable module for the initialization of new tasks. We apply them to three parameter-efficient tuning methods and test them on a wide set of downstream tasks. Experimental results show that our methods show an improvement of 5%~8% over baselines and could largely facilitate task-level knowledge transfer. | Xingtai Lv, Ning Ding, Yujia Qin, Zhiyuan Liu, Maosong Sun |  |
| 201 |  |  [Faithfulness Tests for Natural Language Explanations](https://doi.org/10.18653/v1/2023.acl-short.25) |  | 0 | Explanations of neural models aim to reveal a model’s decision-making process for its predictions. However, recent work shows that current methods giving explanations such as saliency maps or counterfactuals can be misleading, as they are prone to present reasons that are unfaithful to the model’s inner workings. This work explores the challenging question of evaluating the faithfulness of natural language explanations (NLEs). To this end, we present two tests. First, we propose a counterfactual input editor for inserting reasons that lead to counterfactual predictions but are not reflected by the NLEs. Second, we reconstruct inputs from the reasons stated in the generated NLEs and check how often they lead to the same predictions. Our tests can evaluate emerging NLE models, proving a fundamental tool in the development of faithful NLEs. | Pepa Atanasova, OanaMaria Camburu, Christina Lioma, Thomas Lukasiewicz, Jakob Grue Simonsen, Isabelle Augenstein |  |
| 202 |  |  [COGEN: Abductive Commonsense Language Generation](https://doi.org/10.18653/v1/2023.acl-short.26) |  | 0 | Reasoning is one of the most important elements in achieving Artificial General Intelligence (AGI), specifically when it comes to Abductive and counterfactual reasoning. In order to introduce these capabilities of reasoning in Natural Language Processing (NLP) models, there have been recent advances towards training NLP models to better perform on two main tasks - Abductive Natural Language Inference (alphaNLI) and Abductive Natural Language Generation Task (alphaNLG). This paper proposes CoGen, a model for both alphaNLI and alphaNLG tasks that employ a novel approach of combining the temporal commonsense reasoning for each observation (before and after a real hypothesis) from pre-trained models with contextual filtering for training. Additionally, we use state-of-the-art semantic entailment to filter out the contradictory hypothesis during the inference. Our experimental results show that CoGen outperforms current models and set a new state of the art in regards to alphaNLI and alphaNLG tasks. We make the source code of CoGen model publicly available for reproducibility and to facilitate relevant future research. | Rohola Zandie, Diwanshu Shekhar, Mohammad H. Mahoor |  |
| 203 |  |  [Multimodal Relation Extraction with Cross-Modal Retrieval and Synthesis](https://doi.org/10.18653/v1/2023.acl-short.27) |  | 0 | Multimodal relation extraction (MRE) is the task of identifying the semantic relationships between two entities based on the context of the sentence image pair. Existing retrieval-augmented approaches mainly focused on modeling the retrieved textual knowledge, but this may not be able to accurately identify complex relations. To improve the prediction, this research proposes to retrieve textual and visual evidence based on the object, sentence, and whole image. We further develop a novel approach to synthesize the object-level, image-level, and sentence-level information for better reasoning between the same and different modalities. Extensive experiments and analyses show that the proposed method is able to effectively select and compare evidence across modalities and significantly outperforms state-of-the-art models. | Xuming Hu, Zhijiang Guo, Zhiyang Teng, Irwin King, Philip S. Yu |  |
| 204 |  |  [Characterization of Stigmatizing Language in Medical Records](https://doi.org/10.18653/v1/2023.acl-short.28) |  | 0 | Widespread disparities in clinical outcomes exist between different demographic groups in the United States. A new line of work in medical sociology has demonstrated physicians often use stigmatizing language in electronic medical records within certain groups, such as black patients, which may exacerbate disparities. In this study, we characterize these instances at scale using a series of domain-informed NLP techniques. We highlight important differences between this task and analogous bias-related tasks studied within the NLP community (e.g., classifying microaggressions). Our study establishes a foundation for NLP researchers to contribute timely insights to a problem domain brought to the forefront by recent legislation regarding clinical documentation transparency. We release data, code, and models. | Keith Harrigian, Ayah Zirikly, Brant Chee, Alya Ahmad, Anne Links, Somnath Saha, Mary Catherine Beach, Mark Dredze |  |
| 205 |  |  [Abstractive Summarizers are Excellent Extractive Summarizers](https://doi.org/10.18653/v1/2023.acl-short.29) |  | 0 | Extractive and abstractive summarization designs have historically been fragmented, limiting the benefits that often arise from compatible model architectures. In this paper, we explore the potential synergies of modeling extractive summarization with an abstractive summarization system and propose three novel inference algorithms using the sequence-to-sequence architecture. We evaluate them on the CNN & Dailymail dataset and show that recent advancements in abstractive system designs enable abstractive systems to not only compete, but even surpass the performance of extractive systems with custom architectures. To our surprise, abstractive systems achieve this without being exposed to extractive oracle summaries and, therefore, for the first time allow a single model to produce both abstractive and extractive summaries. This evidence questions our fundamental understanding of extractive system design, and the necessity for extractive labels while pathing the way for promising research directions in hybrid models. | Daniel Varab, Yumo Xu |  |
| 206 |  |  [Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions](https://doi.org/10.18653/v1/2023.acl-short.30) |  | 0 | Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people. Since large-scale retraining of these models from scratch is both time and compute-expensive, a variety of approaches have been previously proposed that de-bias a pre-trained model. While the majority of current state-of-the-art debiasing methods focus on changes to the training regime, in this paper, we propose data intervention strategies as a powerful yet simple technique to reduce gender bias in pre-trained models. Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced. Since our proposed method only needs a few training examples, we argue that our few-shot de-biasing approach is highly feasible and practical. Through extensive experimentation, we show that our de-biasing technique performs better than competitive state-of-the-art baselines with minimal loss in language modeling ability. | Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, Paul Pu Liang, LouisPhilippe Morency |  |
| 207 |  |  [PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English](https://doi.org/10.18653/v1/2023.acl-short.31) |  | 0 | Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We evaluate several generic pre-trained language models and continue pre-training them on the collected corpus. We demonstrate that domain-specific continual pre-training offers performance improvements across all tasks. The code and models are released at https://github.com/JFChi/PLUE. | Jianfeng Chi, Wasi Uddin Ahmad, Yuan Tian, KaiWei Chang |  |
| 208 |  |  [Stop Pre-Training: Adapt Visual-Language Models to Unseen Languages](https://doi.org/10.18653/v1/2023.acl-short.32) |  | 0 | Vision-Language Pre-training (VLP) has advanced the performance of many vision-language tasks, such as image-text retrieval, visual entailment, and visual reasoning. The pre-training mostly utilizes lexical databases and image queries in English. Previous work has demonstrated that the pre-training in English does not transfer well to other languages in a zero-shot setting. However, multilingual pre-trained language models (MPLM) have excelled at a variety of single-modal language tasks. In this paper, we propose a simple yet efficient approach to adapt VLP to unseen languages using MPLM.We utilize a cross-lingual contextualised token embeddings alignment approach to train text encoders for non-English languages. Our approach does not require image input and primarily uses machine translation, eliminating the need for target language data. Our evaluation across three distinct tasks (image-text retrieval, visual entailment, and natural language visual reasoning) demonstrates that this approach outperforms the state-of-the-art multilingual vision-language models without requiring large parallel corpora. Our code is available at https://github.com/Yasminekaroui/CliCoTea. | Yasmine Karoui, Rémi Lebret, Negar Foroutan Eghlidi, Karl Aberer |  |
| 209 |  |  [BUCA: A Binary Classification Approach to Unsupervised Commonsense Question Answering](https://doi.org/10.18653/v1/2023.acl-short.33) |  | 0 | Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), but this usually requires a large number of training examples. In this paper, we propose to transform the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. To this end, for training the model, we convert the knowledge graph triples into reasonable and unreasonable texts. Extensive experimental results show the effectiveness of our approach on various multiple choice question answering benchmarks. Furthermore, compared with existing UCR approaches using KGs, ours is less data hungry. | Jie He, Simon Chi Lok U, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 210 |  |  [Nichelle and Nancy: The Influence of Demographic Attributes and Tokenization Length on First Name Biases](https://doi.org/10.18653/v1/2023.acl-short.34) |  | 0 | Through the use of first name substitution experiments, prior research has demonstrated the tendency of social commonsense reasoning models to systematically exhibit social biases along the dimensions of race, ethnicity, and gender (An et al., 2023). Demographic attributes of first names, however, are strongly correlated with corpus frequency and tokenization length, which may influence model behavior independent of or in addition to demographic factors. In this paper, we conduct a new series of first name substitution experiments that measures the influence of these factors while controlling for the others. We find that demographic attributes of a name (race, ethnicity, and gender) and name tokenization length are both factors that systematically affect the behavior of social commonsense reasoning models. | Haozhe An, Rachel Rudinger |  |
| 211 |  |  [Improving Syntactic Probing Correctness and Robustness with Control Tasks](https://doi.org/10.18653/v1/2023.acl-short.35) |  | 0 | Syntactic probing methods have been used to examine whether and how pre-trained language models (PLMs) encode syntactic features. However, the probing methods are usually biased by the PLMs’ memorization of common word co-occurrences, even if they do not form syntactic relations. This paper presents a random-word-substitution and random-label-matching control task to reduce these biases and improve the robustness of syntactic probing methods. Our control tasks are also shown to notably improve the consistency of probing results between different probing methods and make the methods more robust with respect to the text attributes of the probing instances. Our control tasks make syntactic probing methods better at reconstructing syntactic features and more generalizable to unseen text domains. Our experiments show that our proposed control tasks are effective on different PLMs, probing methods, and syntactic features. | Weicheng Ma, Brian Wang, Hefan Zhang, Lili Wang, Rolando CotoSolano, Saeed Hassanpour, Soroush Vosoughi |  |
| 212 |  |  [Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications](https://doi.org/10.18653/v1/2023.acl-short.36) |  | 0 | In this work, we address the NER problem by splitting it into two logical sub-tasks: (1) Span Detection which simply extracts entity mention spans irrespective of entity type; (2) Span Classification which classifies the spans into their entity types. Further, we formulate both sub-tasks as question-answering (QA) problems and produce two leaner models which can be optimized separately for each sub-task. Experiments with four cross-domain datasets demonstrate that this two-step approach is both effective and time efficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17 and a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all cases, it achieves a significant reduction in training time compared to its QA baseline counterpart. The effectiveness of our system stems from fine-tuning the BERT model twice, separately for span detection and classification. The source code can be found at https://github.com/c3sr/split-ner. | Jatin Arora, Youngja Park |  |
| 213 |  |  [Credible without Credit: Domain Experts Assess Generative Language Models](https://doi.org/10.18653/v1/2023.acl-short.37) |  | 0 | Language models have recently broken into the public consciousness with the release of the wildly popular ChatGPT. Commentators have argued that language models could replace search engines, make college essays obsolete, or even write academic research papers. All of these tasks rely on accuracy of specialized information which can be difficult to assess for non-experts. Using 10 domain experts across science and culture, we provide an initial assessment of the coherence, conciseness, accuracy, and sourcing of two language models across 100 expert-written questions. While we find the results are consistently cohesive and concise, we find that they are mixed in their accuracy. These results raise questions of the role language models should play in general-purpose and expert knowledge seeking. | Denis Peskoff, Brandon M. Stewart |  |
| 214 |  |  [Grokking of Hierarchical Structure in Vanilla Transformers](https://doi.org/10.18653/v1/2023.acl-short.38) |  | 0 | For humans, language production and comprehension is sensitive to the hierarchical structure of sentences. In natural language processing, past work has questioned how effectively neural sequence models like transformers capture this hierarchical structure when generalizing to structurally novel inputs. We show that transformer language models can learn to generalize hierarchically after training for extremely long periods—far beyond the point when in-domain accuracy has saturated. We call this phenomenon structural grokking. On multiple datasets, structural grokking exhibits inverted U-shaped scaling in model depth: intermediate-depth models generalize better than both very deep and very shallow transformers. When analyzing the relationship between model-internal properties and grokking, we find that optimal depth for grokking can be identified using the tree-structuredness metric of CITATION. Overall, our work provides strong evidence that, with extended training, vanilla transformers discover and use hierarchical structure. | Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher D. Manning |  |
| 215 |  |  [Zero-shot Cross-lingual Transfer With Learned Projections Using Unlabeled Target-Language Data](https://doi.org/10.18653/v1/2023.acl-short.39) |  | 0 | Adapters have emerged as a parameter-efficient Transformer-based framework for cross-lingual transfer by inserting lightweight language-specific modules (language adapters) and task-specific modules (task adapters) within pretrained multilingual models. Zero-shot transfer is enabled by pairing the language adapter in the target language with an appropriate task adapter in a source language. If our target languages are known apriori, we explore how zero-shot transfer can be further improved within the adapter framework by utilizing unlabeled text during task-specific finetuning. We construct language-specific subspaces using standard linear algebra constructs and selectively project source-language representations into the target language subspace during task-specific finetuning using two schemes. Our experiments on three cross-lingual tasks, Named Entity Recognition (NER), Question Answering (QA) and Natural Language Inference (NLI) yield consistent benefits compared to adapter baselines over a wide variety of target languages with up to 11% relative improvement in NER, 2% relative improvement in QA and 5% relative improvement in NLI. | Ujan Deb, Ridayesh Parab, Preethi Jyothi |  |
| 216 |  |  [Context-Aware Transformer Pre-Training for Answer Sentence Selection](https://doi.org/10.18653/v1/2023.acl-short.40) |  | 0 | Answer Sentence Selection (AS2) is a core component for building an accurate Question Answering pipeline. AS2 models rank a set of candidate sentences based on how likely they answer a given question. The state of the art in AS2 exploits pre-trained transformers by transferring them on large annotated datasets, while using local contextual information around the candidate sentence. In this paper, we propose three pre-training objectives designed to mimic the downstream fine-tuning task of contextual AS2. This allows for specializing LMs when fine-tuning for contextual AS2. Our experiments on three public and two large-scale industrial datasets show that our pre-training approaches (applied to RoBERTa and ELECTRA) can improve baseline contextual AS2 accuracy by up to 8% on some datasets. | Luca Di Liello, Siddhant Garg, Alessandro Moschitti |  |
| 217 |  |  [Toward Expanding the Scope of Radiology Report Summarization to Multiple Anatomies and Modalities](https://doi.org/10.18653/v1/2023.acl-short.41) |  | 0 | Radiology report summarization (RRS) is a growing area of research. Given the Findings section of a radiology report, the goal is to generate a summary (called an Impression section) that highlights the key observations and conclusions of the radiology study. However, RRS currently faces essential limitations. First, many prior studies conduct experiments on private datasets, preventing reproduction of results and fair comparisons across different systems and solutions. Second, most prior approaches are evaluated solely on chest X-rays. To address these limitations, we propose a dataset (MIMIC-RRS) involving three new modalities and seven new anatomies based on the MIMIC-III and MIMIC-CXR datasets. We then conduct extensive experiments to evaluate the performance of models both within and across modality-anatomy pairs in MIMIC-RRS. In addition, we evaluate their clinical efficacy via RadGraph, a factual correctness metric. | Zhihong Chen, Maya Varma, Xiang Wan, Curtis P. Langlotz, JeanBenoit Delbrouck |  |
| 218 |  |  [Efficient Diagnosis Assignment Using Unstructured Clinical Notes](https://doi.org/10.18653/v1/2023.acl-short.42) |  | 0 | Electronic phenotyping entails using electronic health records (EHRs) to identify patients with specific health outcomes and determine when those outcomes occurred. Unstructured clinical notes, which contain a vast amount of information, are a valuable resource for electronic phenotyping. However, traditional methods, such as rule-based labeling functions or neural networks, require significant manual effort to tune and may not generalize well to multiple indications. To address these challenges, we propose HyDE (hybrid diagnosis extractor). HyDE is a simple framework for electronic phenotyping that integrates labeling functions and a disease-agnostic neural network to assign diagnoses to patients. By training HyDE’s model to correct predictions made by labeling functions, we are able to disambiguate hypertension true positives and false positives with a supervised area under the precision-recall curve (AUPRC) of 0.85. We extend this hypertension-trained model to zero-shot evaluation of four other diseases, generating AUPRC values ranging from 0.82 - 0.95 and outperforming a labeling function baseline by 44 points in F1 score and a Word2Vec baseline by 24 points in F1 score on average. Furthermore, we demonstrate a speedup of >4x by pruning the length of inputs into our language model to ~2.3% of the full clinical notes, with negligible impact to the AUPRC. HyDE has the potential to improve the efficiency and efficacy of interpreting large-scale unstructured clinical notes for accurate EHR phenotyping. | Louis Blankemeier, Jason A. Fries, Robert Tinn, Joseph Preston, Nigam Shah, Akshay Chaudhari |  |
| 219 |  |  [MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models](https://doi.org/10.18653/v1/2023.acl-short.43) |  | 0 | Large-scale language models have shown the ability to adapt to a new task via conditioning on a few demonstrations (i.e., in-context learning). However, in the vision-language domain, most large-scale pre-trained vision-language (VL) models do not possess the ability to conduct in-context learning. How can we enable in-context learning for VL models? In this paper, we study an interesting hypothesis: can we transfer the in-context learning ability from the language domain to the VL domain? Specifically, we first meta-trains a language model to perform in-context learning on NLP tasks (as in MetaICL); then we transfer this model to perform VL tasks by attaching a visual encoder. Our experiments suggest that indeed in-context learning ability can be transferred cross modalities: our model considerably improves the in-context learning capability on VL tasks and can even compensate for the size of the model significantly. On VQA, OK-VQA, and GQA, our method could outperform the baseline model while having ~20 times fewer parameters. | Masoud Monajatipoor, Liunian Harold Li, Mozhdeh Rouhsedaghat, Lin Yang, KaiWei Chang |  |
| 220 |  |  [On the Interpretability and Significance of Bias Metrics in Texts: a PMI-based Approach](https://doi.org/10.18653/v1/2023.acl-short.44) |  | 0 | In recent years, word embeddings have been widely used to measure biases in texts. Even if they have proven to be effective in detecting a wide variety of biases, metrics based on word embeddings lack transparency and interpretability. We analyze an alternative PMI-based metric to quantify biases in texts. It can be expressed as a function of conditional probabilities, which provides a simple interpretation in terms of word co-occurrences. We also prove that it can be approximated by an odds ratio, which allows estimating confidence intervals and statistical significance of textual biases. This approach produces similar results to metrics based on word embeddings when capturing gender gaps of the real world embedded in large corpora. | Francisco Valentini, Germán Rosati, Damián E. Blasi, Diego Fernández Slezak, Edgar Altszyler |  |
| 221 |  |  [Surface-Based Retrieval Reduces Perplexity of Retrieval-Augmented Language Models](https://doi.org/10.18653/v1/2023.acl-short.45) |  | 0 | Augmenting language models with a retrieval mechanism has been shown to significantly improve their performance while keeping the number of parameters low. Retrieval-augmented models commonly rely on a semantic retrieval mechanism based on the similarity between dense representations of the query chunk and potential neighbors. In this paper, we study the state-of-the-art Retro model and observe that its performance gain is better explained by surface-level similarities, such as token overlap. Inspired by this, we replace the semantic retrieval in Retro with a surface-level method based on BM25, obtaining a significant reduction in perplexity. As full BM25 retrieval can be computationally costly for large datasets, we also apply it in a re-ranking scenario, gaining part of the perplexity reduction with minimal computational overhead. | Ehsan Doostmohammadi, Tobias Norlund, Marco Kuhlmann, Richard Johansson |  |
| 222 |  |  [MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents](https://doi.org/10.18653/v1/2023.acl-short.46) |  | 0 | Learning semantically meaningful representations from scientific documents can facilitate academic literature search and improve performance of recommendation systems. Pretrained language models have been shown to learn rich textual representations, yet they cannot provide powerful document-level representations for scientific articles. We propose MIReAD, a simple method that learns highquality representations of scientific papers by fine-tuning transformer model to predict the target journal class based on the abstract. We train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000 journal classes. We show that MIReAD produces representations that can be used for similar papers retrieval, topic categorization and literature search. Our proposed approach outperforms six existing models for representation learning on scientific documents across four evaluation standards. | Anastasia Razdaibiedina, Aleksander Brechalov |  |
| 223 |  |  [KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating Inconsistencies in Natural Language Explanations](https://doi.org/10.18653/v1/2023.acl-short.47) |  | 0 | While recent works have been considerably improving the quality of the natural language explanations (NLEs) generated by a model to justify its predictions, there is very limited research in detecting and alleviating inconsistencies among generated NLEs. In this work, we leverage external knowledge bases to significantly improve on an existing adversarial attack for detecting inconsistent NLEs. We apply our attack to high-performing NLE models and show that models with higher NLE quality do not necessarily generate fewer inconsistencies. Moreover, we propose an off-the-shelf mitigation method to alleviate inconsistencies by grounding the model into external background knowledge. Our method decreases the inconsistencies of previous high-performing NLE models as detected by our attack. | Myeongjun Jang, Bodhisattwa Prasad Majumder, Julian J. McAuley, Thomas Lukasiewicz, OanaMaria Camburu |  |
| 224 |  |  [Measuring the Effect of Influential Messages on Varying Personas](https://doi.org/10.18653/v1/2023.acl-short.48) |  | 0 | Predicting how a user responds to news events enables important applications such as allowing intelligent agents or content producers to estimate the effect on different communities and revise unreleased messages to prevent unexpected bad outcomes such as social conflict and moral injury. We present a new task, Response Forecasting on Personas for News Media, to estimate the response a persona (characterizing an individual or a group) might have upon seeing a news message. Compared to the previous efforts which only predict generic comments to news, the proposed task not only introduces personalization in the modeling but also predicts the sentiment polarity and intensity of each response. This enables more accurate and comprehensive inference on the mental state of the persona. Meanwhile, the generated sentiment dimensions make the evaluation and application more reliable. We create the first benchmark dataset, which consists of 13,357 responses to 3,847 news headlines from Twitter. We further evaluate the SOTA neural language models with our dataset. The empirical results suggest that the included persona attributes are helpful for the performance of all response dimensions. Our analysis shows that the best-performing models are capable of predicting responses that are consistent with the personas, and as a byproduct, the task formulation also enables many interesting applications in the analysis of social network groups and their opinions, such as the discovery of extreme opinion groups. | Chenkai Sun, Jinning Li, Hou Pong Chan, ChengXiang Zhai, Heng Ji |  |
| 225 |  |  [Going Beyond Sentence Embeddings: A Token-Level Matching Algorithm for Calculating Semantic Textual Similarity](https://doi.org/10.18653/v1/2023.acl-short.49) |  | 0 | Semantic Textual Similarity (STS) measures the degree to which the underlying semantics of paired sentences are equivalent. State-of-the-art methods for STS task use language models to encode sentences into embeddings. However, these embeddings are limited in representing semantics because they mix all the semantic information together in fixed-length vectors, which are difficult to recover and lack explainability. This paper presents a token-level matching inference algorithm, which can be applied on top of any language model to improve its performance on STS task. Our method calculates pairwise token-level similarity and token matching scores, and then aggregates them with pretrained token weights to produce sentence similarity. Experimental results on seven STS datasets show that our method improves the performance of almost all language models, with up to 12.7% gain in Spearman’s correlation. We also demonstrate that our method is highly explainable and computationally efficient. | Hongwei Wang, Dong Yu |  |
| 226 |  |  [Robust Learning for Multi-party Addressee Recognition with Discrete Addressee Codebook](https://doi.org/10.18653/v1/2023.acl-short.50) |  | 0 | Addressee recognition aims to identify addressees in multi-party conversations. While state-of-the-art addressee recognition models have achieved promising performance, they still suffer from the issue of robustness when applied in real-world scenes. When exposed to a noisy environment, these models regard the noise as input and identify the addressee in a pre-given addressee closed set, while the addressees of the noise do not belong to this closed set, thus leading to the wrong identification of addressee. To this end, we propose a Robust Addressee Recognition (RAR) method, which discrete the addressees into a character codebook, making it able to represent open set addressees and robust in a noisy environment. Experimental results show that the introduction of the addressee character codebook helps to represent the open set addressees and highly improves the robustness of addressee recognition even if the input is noise. | Pengcheng Zhu, Wei Zhou, Kuncai Zhang, Yuankai Ma, Haiqing Chen |  |
| 227 |  |  [TwistList: Resources and Baselines for Tongue Twister Generation](https://doi.org/10.18653/v1/2023.acl-short.51) |  | 0 | Previous work in phonetically-grounded language generation has mainly focused on domains such as lyrics and poetry. In this paper, we present work on the generation of tongue twisters - a form of language that is required to be phonetically conditioned to maximise sound overlap, whilst maintaining semantic consistency with an input topic, and still being grammatically correct. We present TwistList, a large annotated dataset of tongue twisters, consisting of 2.1K+ human-authored examples. We additionally present several benchmark systems (referred to as TwisterMisters) for the proposed task of tongue twister generation, including models that both do and do not require training on in-domain data. We present the results of automatic and human evaluation to demonstrate the performance ofexisting mainstream pre-trained models in this task with limited (or no) task specific training and data, and no explicit phonetic knowledge. We find that the task of tongue twister generation is challenging for models under these conditions, yet some models are still capable of generating acceptable examples of this language type. | Tyler Loakman, Chen Tang, Chenghua Lin |  |
| 228 |  |  [Substitution-based Semantic Change Detection using Contextual Embeddings](https://doi.org/10.18653/v1/2023.acl-short.52) |  | 0 | Measuring semantic change has thus far remained a task where methods using contextual embeddings have struggled to improve upon simpler techniques relying only on static word vectors. Moreover, many of the previously proposed approaches suffer from downsides related to scalability and ease of interpretation. We present a simplified approach to measuring semantic change using contextual embeddings, relying only on the most probable substitutes for masked terms. Not only is this approach directly interpretable, it is also far more efficient in terms of storage, achieves superior average performance across the most frequently cited datasets for this task, and allows for more nuanced investigation of change than is possible with static word vectors. | Dallas Card |  |
| 229 |  |  [Probing Physical Reasoning with Counter-Commonsense Context](https://doi.org/10.18653/v1/2023.acl-short.53) |  | 0 | In this study, we create a CConS (Counter-commonsense Contextual Size comparison) dataset to investigate how physical commonsense affects the contextualized size comparison task; the proposed dataset consists of both contexts that fit physical commonsense and those that do not. This dataset tests the ability of language models to predict the size relationship between objects under various contexts generated from our curated noun list and templates. We measure the ability of several masked language models and encoder-decoder models. The results show that while large language models can use prepositions such as “in” and “into” in the provided context to infer size relationships, they fail to use verbs and thus make incorrect judgments led by their prior physical commonsense. | Kazushi Kondo, Saku Sugawara, Akiko Aizawa |  |
| 230 |  |  [Morphological Inflection with Phonological Features](https://doi.org/10.18653/v1/2023.acl-short.54) |  | 0 | Recent years have brought great advances into solving morphological tasks, mostly due to powerful neural models applied to various tasks as (re)inflection and analysis. Yet, such morphological tasks cannot be considered solved, especially when little training data is available or when generalizing to previously unseen lemmas. This work explores effects on performance obtained through various ways in which morphological models get access to sub-character phonological features that are often the targets of morphological processes. We design two methods to achieve this goal: one that leaves models as is but manipulates the data to include features instead of characters, and another that manipulates models to take phonological features into account when building representations for phonemes. We elicit phonemic data from standard graphemic data using language-specific grammars for languages with shallow grapheme-to-phoneme mapping, and we experiment with two reinflection models over eight languages. Our results show that our methods yield comparable results to the grapheme-based baseline overall, with minor improvements in some of the languages. All in all, we conclude that patterns in character distributions are likely to allow models to infer the underlying phonological characteristics, even when phonemes are not explicitly represented. | David Guriel, Omer Goldman, Reut Tsarfaty |  |
| 231 |  |  [A Holistic Approach to Reference-Free Evaluation of Machine Translation](https://doi.org/10.18653/v1/2023.acl-short.55) |  | 0 | Traditional machine translation evaluation relies on reference written by humans. While reference-free evaluation gets rid of the constraints of labor-intensive annotations, which can pivot easily to new domains and is more scalable. In this paper, we propose a reference-free evaluation approach that characterizes evaluation as two aspects: (1) fluency: how well the translated text conforms to normal human language usage; (2) faithfulness: how well the translated text reflects the source data. We further split the faithfulness into word-level and sentence-level. Extensive experiments spanning WMT18/19/21 Metrics segment-level daRR and MQM datasets demonstrate that our proposed reference-free approach, ReFreeEval, outperforms SOTA reference-fee metrics like YiSi-2. | Hanming Wu, Wenjuan Han, Hui Di, Yufeng Chen, Jinan Xu |  |
| 232 |  |  [Balancing Lexical and Semantic Quality in Abstractive Summarization](https://doi.org/10.18653/v1/2023.acl-short.56) |  | 0 | An important problem of the sequence-to-sequence neural models widely used in abstractive summarization is exposure bias. To alleviate this problem, re-ranking systems have been applied in recent years. Despite some performance improvements, this approach remains underexplored. Previous works have mostly specified the rank through the ROUGE score and aligned candidate summaries, but there can be quite a large gap between the lexical overlap metric and semantic similarity. In this paper, we propose a novel training method in which a re-ranker balances the lexical and semantic quality. We further newly define false positives in ranking and present a strategy to reduce their influence. Experiments on the CNN/DailyMail and XSum datasets show that our method can estimate the meaning of summaries without seriously degrading the lexical aspect. More specifically, it achieves an 89.67 BERTScore on the CNN/DailyMail dataset, reaching new state-of-the-art performance. Our code is publicly available at https://github.com/jeewoo1025/BalSum. | Jeewoo Sul, Yong Suk Choi |  |
| 233 |  |  [Learning Neuro-Symbolic World Models with Conversational Proprioception](https://doi.org/10.18653/v1/2023.acl-short.57) |  | 0 | The recent emergence of Neuro-Symbolic Agent (NeSA) approaches to natural language-based interactions calls for the investigation of model-based approaches. In contrast to model-free approaches, which existing NeSAs take, learning an explicit world model has an interesting potential especially in the explainability, which is one of the key selling points of NeSA. To learn useful world models, we leverage one of the recent neuro-symbolic architectures, Logical Neural Networks (LNN). Here, we describe a method that can learn neuro-symbolic world models on the TextWorld-Commonsense set of games. We then show how this can be improved further by taking inspiration from the concept of proprioception, but for conversation. This is done by enhancing the internal logic state with a memory of previous actions while also guiding future actions by augmenting the learned model with constraints based on this memory. This greatly improves the game-solving agents performance in a TextWorld setting, where the advantage over the baseline is an 85% average steps reduction and x2.3 average score. | Don Joven Agravante, Daiki Kimura, Michiaki Tatsubori, Asim Munawar, Alexander Gray |  |
| 234 |  |  [In and Out-of-Domain Text Adversarial Robustness via Label Smoothing](https://doi.org/10.18653/v1/2023.acl-short.58) |  | 0 | Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study the adversarial robustness provided by label smoothing strategies in foundational models for diverse NLP tasks in both in-domain and out-of-domain settings. Our experiments show that label smoothing significantly improves adversarial robustness in pre-trained models like BERT, against various popular attacks. We also analyze the relationship between prediction confidence and robustness, showing that label smoothing reduces over-confident errors on adversarial examples. | Yahan Yang, Soham Dan, Dan Roth, Insup Lee |  |
| 235 |  |  [LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning](https://doi.org/10.18653/v1/2023.acl-short.59) |  | 0 | In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets. To address this issue, researchers have proposed various adaptation approaches. Prompt-based tuning is arguably the most common way, especially for larger models. Previous research shows that adding contrastive learning to prompt-based fine-tuning is effective as it helps the model generate embeddings that are more distinguishable between classes, and it can also be more sample-efficient as the model learns from positive and negative examples simultaneously. One of the most important components of contrastive learning is data augmentation, but unlike computer vision, effective data augmentation for NLP is still challenging. This paper proposes LM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language Models, which leverages prompt-based few-shot paraphrasing using generative language models, especially large language models such as GPT-3 and OPT-175B, for data augmentation. Our experiments on multiple text classification benchmarks show that this augmentation method outperforms other methods, such as easy data augmentation, back translation, and multiple templates. | Amirhossein Abaskohi, Sascha Rothe, Yadollah Yaghoobzadeh |  |
| 236 |  |  [Considerations for meaningful sign language machine translation based on glosses](https://doi.org/10.18653/v1/2023.acl-short.60) |  | 0 | Automatic sign language processing is gaining popularity in Natural Language Processing (NLP) research (Yin et al., 2021). In machine translation (MT) in particular, sign language translation based on glosses is a prominent approach. In this paper, we review recent works on neural gloss translation. We find that limitations of glosses in general and limitations of specific datasets are not discussed in a transparent manner and that there is no common standard for evaluation. To address these issues, we put forward concrete recommendations for future research on gloss translation. Our suggestions advocate awareness of the inherent limitations of gloss-based approaches, realistic datasets, stronger baselines and convincing evaluation. | Mathias Müller, Zifan Jiang, Amit Moryossef, Annette Rios, Sarah Ebling |  |
| 237 |  |  [Detecting Contradictory COVID-19 Drug Efficacy Claims from Biomedical Literature](https://doi.org/10.18653/v1/2023.acl-short.61) |  | 0 | The COVID-19 pandemic created a deluge of questionable and contradictory scientific claims about drug efficacy – an “infodemic” with lasting consequences for science and society. In this work, we argue that NLP models can help domain experts distill and understand the literature in this complex, high-stakes area. Our task is to automatically identify contradictory claims about COVID-19 drug efficacy. We frame this as a natural language inference problem and offer a new NLI dataset created by domain experts. The NLI framing allows us to create curricula combining existing datasets and our own. The resulting models are useful investigative tools. We provide a case study of how these models help a domain expert summarize and assess evidence concerning remdisivir and hydroxychloroquine. | Daniel N. Sosa, Malavika Suresh, Christopher Potts, Russ B. Altman |  |
| 238 |  |  [The Role of Global and Local Context in Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-short.62) |  | 0 | Pre-trained transformer-based models have recently shown great performance when applied to Named Entity Recognition (NER). As the complexity of their self-attention mechanism prevents them from processing long documents at once, these models are usually applied in a sequential fashion. Such an approach unfortunately only incorporates local context and prevents leveraging global document context in long documents such as novels, which might hinder performance. In this article, we explore the impact of global document context, and its relationships with local context. We find that correctly retrieving global document context has a greater impact on performance than only leveraging local context, prompting for further research on how to better retrieve that context. | Arthur Amalvy, Vincent Labatut, Richard Dufour |  |
| 239 |  |  [Joint End-to-end Semantic Proto-role Labeling](https://doi.org/10.18653/v1/2023.acl-short.63) |  | 0 | Semantic proto-role labeling (SPRL) assigns properties to arguments based on a series of binary labels. While multiple studies have evaluated various approaches to SPRL, it has only been studied in-depth as a standalone task using gold predicate/argument pairs. How do SPRL systems perform as part of an information extraction pipeline? We model SPRL jointly with predicate-argument extraction using a deep transformer model. We find that proto-role labeling is surprisingly robust in this setting, with only a small decrease when using predicted arguments. We include a detailed analysis of each component of the joint system, and an error analysis to understand correlations in errors between system stages. Finally, we study the effects of annotation errors on SPRL. | Elizabeth Spaulding, Gary Kazantsev, Mark Dredze |  |
| 240 |  |  [Improving Automatic Quotation Attribution in Literary Novels](https://doi.org/10.18653/v1/2023.acl-short.64) |  | 0 | Current models for quotation attribution in literary novels assume varying levels of available information in their training and test data, which poses a challenge for in-the-wild inference. Here, we approach quotation attribution as a set of four interconnected sub-tasks: character identification, coreference resolution, quotation identification, and speaker attribution. We benchmark state-of-the-art models on each of these sub-tasks independently, using a large dataset of annotated coreferences and quotations in literary novels (the Project Dialogism Novel Corpus). We also train and evaluate models for the speaker attribution task in particular, showing that a simple sequential prediction model achieves accuracy scores on par with state-of-the-art models. | Krishnapriya Vishnubhotla, Frank Rudzicz, Graeme Hirst, Adam Hammond |  |
| 241 |  |  [Modular Visual Question Answering via Code Generation](https://doi.org/10.18653/v1/2023.acl-short.65) |  | 0 | We present a framework that formulates visual question answering as modular code generation. In contrast to prior work on modular approaches to VQA, our approach requires no additional training and relies on pre-trained language models (LMs), visual models pre-trained on image-caption pairs, and fifty VQA examples used for in-context learning. The generated Python programs invoke and compose the outputs of the visual models using arithmetic and conditional logic. Our approach improves accuracy on the COVR dataset by at least 3% and on the GQA dataset by 2% compared to the few-shot baseline that does not employ code generation. | Sanjay Subramanian, Medhini Narasimhan, Kushal Khangaonkar, Kevin Yang, Arsha Nagrani, Cordelia Schmid, Andy Zeng, Trevor Darrell, Dan Klein |  |
| 242 |  |  [Target-Based Offensive Language Identification](https://doi.org/10.18653/v1/2023.acl-short.66) |  | 0 | We present TBO, a new dataset for Target-based Offensive language identification. TBO contains post-level annotations regarding the harmfulness of an offensive post and token-level annotations comprising of the target and the offensive argument expression. Popular offensive language identification datasets for social media focus on annotation taxonomies only at the post level and more recently, some datasets have been released that feature only token-level annotations. TBO is an important resource that bridges the gap between post-level and token-level annotation datasets by introducing a single comprehensive unified annotation taxonomy. We use the TBO taxonomy to annotate post-level and token-level offensive language on English Twitter posts. We release an initial dataset of over 4,500 instances collected from Twitter and we carry out multiple experiments to compare the performance of different models trained and tested on TBO. | Marcos Zampieri, Skye Morgan, Kai North, Tharindu Ranasinghe, Austin Simmmons, Paridhi Khandelwal, Sara Rosenthal, Preslav Nakov |  |
| 243 |  |  [Unsupervised Subtitle Segmentation with Masked Language Models](https://doi.org/10.18653/v1/2023.acl-short.67) |  | 0 | We describe a novel unsupervised approach to subtitle segmentation, based on pretrained masked language models, where line endings and subtitle breaks are predicted according to the likelihood of punctuation to occur at candidate segmentation points. Our approach obtained competitive results in terms of segmentation accuracy across metrics, while also fully preserving the original text and complying with length constraints. Although supervised models trained on in-domain data and with access to source audio information can provide better segmentation accuracy, our approach is highly portable across languages and domains and may constitute a robust off-the-shelf solution for subtitle segmentation. | David Ponce, Thierry Etchegoyhen, Victor Ruiz Gómez |  |
| 244 |  |  [Exploring Continual Learning for Code Generation Models](https://doi.org/10.18653/v1/2023.acl-short.68) |  | 0 | Large-scale code generation models such as Copilot and CodeT5 have achieved impressive performance. However, libraries are upgraded or deprecated very frequently and re-training large-scale language models is computationally expensive. Therefore, Continual Learning (CL) is an important aspect that remains under-explored in the code domain. In this paper, we introduce a benchmark called CodeTask-CL that covers a wide range of tasks, including code generation, translation, summarization, and refinement, with different input and output programming languages. Next, on our CodeTask-CL benchmark, we compare popular CL techniques from NLP and Vision domains. We find that effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks. We address this issue with our proposed method, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training by enforcing constraints on the prompt selection mechanism and leads to a 21.54% improvement over Prompt Pooling. Along with the benchmark, we establish a training pipeline that can be used for CL on code models, which we believe can motivate further development of CL methods for code models. | Prateek Yadav, Qing Sun, Hantian Ding, Xiaopeng Li, Dejiao Zhang, Ming Tan, Parminder Bhatia, Xiaofei Ma, Ramesh Nallapati, Murali Krishna Ramanathan, Mohit Bansal, Bing Xiang |  |
| 245 |  |  [Deep Active Learning for Morphophonological Processing](https://doi.org/10.18653/v1/2023.acl-short.69) |  | 0 | Building a system for morphological processing is a challenging task in morphologically complex languages like Arabic. Although there are some deep learning based models that achieve successful results, these models rely on a large amount of annotated data. Building such datasets, specially for some of the lower-resource Arabic dialects, is very difficult, time-consuming, and expensive. In addition, some parts of the annotated data do not contain useful information for training machine learning models. Active learning strategies allow the learner algorithm to select the most informative samples for annotation. There has been little research that focuses on applying active learning for morphological inflection and morphophonological processing. In this paper, we have proposed a deep active learning method for this task. Our experiments on Egyptian Arabic show that with only about 30% of annotated data, we achieve the same results as does the state-of-the-art model on the whole dataset. | Seyed Morteza Mirbostani, Yasaman Boreshban, Salam Khalifa, Seyed Abolghasem Mirroshandel, Owen Rambow |  |
| 246 |  |  [Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios](https://doi.org/10.18653/v1/2023.acl-short.70) |  | 0 | Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge—however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nuances of counterfactuals, we find that only GPT-3 shows sensitivity to these nuances, though this sensitivity is also non-trivially impacted by lexical associative factors. | Jiaxuan Li, Lang Yu, Allyson Ettinger |  |
| 247 |  |  [Bhasa-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages](https://doi.org/10.18653/v1/2023.acl-short.71) |  | 0 | We create publicly available language identification (LID) datasets and models in all 22 Indian languages listed in the Indian constitution in both native-script and romanized text. First, we create Bhasha-Abhijnaanam, a language identification test set for native-script as well as romanized text which spans all 22 Indic languages. We also train IndicLID, a language identifier for all the above-mentioned languages in both native and romanized script. For native-script text, it has better language coverage than existing LIDs and is competitive or better than other LIDs. IndicLID is the first LID for romanized text in Indian languages. Two major challenges for romanized text LID are the lack of training data and low-LID performance when languages are similar. We provide simple and effective solutions to these problems. In general, there has been limited work on romanized text in any language, and our findings are relevant to other languages that need romanized language identification. Our models are publicly available at https://github.com/AI4Bharat/IndicLID under open-source licenses. Our training and test sets are also publicly available at https://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam under open-source licenses. | Yash Madhani, Mitesh M. Khapra, Anoop Kunchukuttan |  |
| 248 |  |  [Using contradictions improves question answering systems](https://doi.org/10.18653/v1/2023.acl-short.72) |  | 0 | This work examines the use of contradiction in natural language inference (NLI) for question answering (QA). Typically, NLI systems help answer questions by determining if a potential answer is entailed (supported) by some background context. But is it useful to also determine if an answer contradicts the context? We test this in two settings, multiple choice and extractive QA, and find that systems that incorporate contradiction can do slightly better than entailment-only systems on certain datasets. However, the best performances come from using contradiction, entailment, and QA model confidence scores together. This has implications for the deployment of QA systems in domains such as medicine and science where safety is an issue. | Etienne FortierDubois, Domenic Rosati |  |
| 249 |  |  [Token-Level Self-Evolution Training for Sequence-to-Sequence Learning](https://doi.org/10.18653/v1/2023.acl-short.73) |  | 0 | Adaptive training approaches, widely used in sequence-to-sequence models, commonly reweigh the losses of different target tokens based on priors, e.g. word frequency. However, most of them do not consider the variation of learning difficulty in different training steps, and overly emphasize the learning of difficult one-hot labels, making the learning deterministic and sub-optimal. In response, we present Token-Level Self-Evolution Training (SE), a simple and effective dynamic training method to fully and wisely exploit the knowledge from data. SE focuses on dynamically learning the under-explored tokens for each forward pass and adaptively regularizes the training by introducing a novel token-specific label smoothing approach. Empirically, SE yields consistent and significant improvements in three tasks, i.e. machine translation, summarization, and grammatical error correction. Encouragingly, we achieve averaging +0.93 BLEU improvement on three machine translation tasks. Analyses confirm that, besides improving lexical accuracy, SE enhances generation diversity and model generalization. | Keqin Peng, Liang Ding, Qihuang Zhong, Yuanxin Ouyang, Wenge Rong, Zhang Xiong, Dacheng Tao |  |
| 250 |  |  [Gradient Ascent Post-training Enhances Language Model Generalization](https://doi.org/10.18653/v1/2023.acl-short.74) |  | 0 | In this work, we empirically show that updating pretrained LMs (350M, 1.3B, 2.7B) with just a few steps of Gradient Ascent Post-training (GAP) on random, unlabeled text corpora enhances its zero-shot generalization capabilities across diverse NLP tasks. Specifically, we show that GAP can allow LMs to become comparable to 2-3x times larger LMs across 12 different NLP tasks. We also show that applying GAP on out-of-distribution corpora leads to the most reliable performance improvements. Our findings indicate that GAP can be a promising method for improving the generalization capability of LMs without any task-specific fine-tuning. | Dongkeun Yoon, Joel Jang, Sungdong Kim, Minjoon Seo |  |
| 251 |  |  [An Open Dataset and Model for Language Identification](https://doi.org/10.18653/v1/2023.acl-short.75) |  | 0 | Language identification (LID) is a fundamental step in many natural language processing pipelines. However, current LID systems are far from perfect, particularly on lower-resource languages. We present a LID model which achieves a macro-average F1 score of 0.93 and a false positive rate of 0.033% across 201 languages, outperforming previous work. We achieve this by training on a curated dataset of monolingual data, which we audit manually to ensure reliability. We make both the model and the dataset available to the research community. Finally, we carry out detailed analysis into our model’s performance, both in comparison to existing open models and by language class. | Laurie Burchell, Alexandra Birch, Nikolay Bogoychev, Kenneth Heafield |  |
| 252 |  |  [Evaluating Paraphrastic Robustness in Textual Entailment Models](https://doi.org/10.18653/v1/2023.acl-short.76) |  | 0 | We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models’ predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16% of paraphrased examples, indicating that there is still room for improvement. | Dhruv Verma, Yash Kumar Lal, Shreyashee Sinha, Benjamin Van Durme, Adam Poliak |  |
| 253 |  |  [Are Pre-trained Language Models Useful for Model Ensemble in Chinese Grammatical Error Correction?](https://doi.org/10.18653/v1/2023.acl-short.77) |  | 0 | Model ensemble has been in widespread use for Grammatical Error Correction (GEC), boosting model performance. We hypothesize that model ensemble based on the perplexity (PPL) computed by pre-trained language models (PLMs) should benefit the GEC system. To this end, we explore several ensemble strategies based on strong PLMs with four sophisticated single models. However, the performance does not improve but even gets worse after the PLM-based ensemble. This surprising result sets us doing a detailed analysis on the data and coming up with some insights on GEC. The human references of correct sentences is far from sufficient in the test data, and the gap between a correct sentence and an idiomatic one is worth our attention. Moreover, the PLM-based ensemble strategies provide an effective way to extend and improve GEC benchmark data. Our source code is available at https://github.com/JamyDon/PLM-based-CGEC-Model-Ensemble. | Chenming Tang, Xiuyu Wu, Yunfang Wu |  |
| 254 |  |  [Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality](https://doi.org/10.18653/v1/2023.acl-short.78) |  | 0 | Improving factual consistency of abstractive summarization has been a widely studied topic. However, most of the prior works on training factuality-aware models have ignored the negative effect it has on summary quality. We propose {pasted macro ‘MODEL’}name (i.e. Effective Factual Summarization), a candidate summary generation and ranking technique to improve summary factuality without sacrificing quality. We show that using a contrastive learning framework with our refined candidate summaries leads to significant gains on both factuality and similarity-based metrics. Specifically, we propose a ranking strategy in which we effectively combine two metrics, thereby preventing any conflict during training. Models trained using our approach show up to 6 points of absolute improvement over the base model with respect to FactCC on XSUM and 11 points on CNN/DM, without negatively affecting either similarity-based metrics or absractiveness. | Tanay Dixit, Fei Wang, Muhao Chen |  |
| 255 |  |  [With a Little Push, NLI Models can Robustly and Efficiently Predict Faithfulness](https://doi.org/10.18653/v1/2023.acl-short.79) |  | 0 | Conditional language models still generate unfaithful output that is not supported by their input. These unfaithful generations jeopardize trust in real-world applications such as summarization or human-machine interaction, motivating a need for automatic faithfulness metrics. To implement such metrics, NLI models seem attractive, since they solve a strongly related task that comes with a wealth of prior research and data. But recent research suggests that NLI models require costly additional machinery to perform reliably across datasets, e.g., by running inference on a cartesian product of input and generated sentences, or supporting them with a question-generation/answering step. In this work we show that pure NLI models _can_ outperform more complex metrics when combining task-adaptive data augmentation with robust inference procedures. We propose: (1) Augmenting NLI training data toadapt NL inferences to the specificities of faithfulness prediction in dialogue;(2) Making use of both entailment and contradiction probabilities in NLI, and(3) Using Monte-Carlo dropout during inference. Applied to the TRUE benchmark, which combines faithfulness datasets across diverse domains and tasks, our approach strongly improves a vanilla NLI model and significantly outperforms previous work, while showing favourable computational cost. | Julius Steen, Juri Opitz, Anette Frank, Katja Markert |  |
| 256 |  |  [A Better Way to Do Masked Language Model Scoring](https://doi.org/10.18653/v1/2023.acl-short.80) |  | 0 | Estimating the log-likelihood of a given sentence under an autoregressive language model is straightforward: one can simply apply the chain rule and sum the log-likelihood values for each successive token. However, for masked language models (MLMs), there is no direct way to estimate the log-likelihood of a sentence. To address this issue, Salazar et al. (2020) propose to estimate sentence pseudo-log-likelihood (PLL) scores, computed by successively masking each sentence token, retrieving its score using the rest of the sentence as context, and summing the resulting values. Here, we demonstrate that the original PLL method yields inflated scores for out-of-vocabulary words and propose an adapted metric, in which we mask not only the target token, but also all within-word tokens to the right of the target. We show that our adapted metric (PLL-word-l2r) outperforms both the original PLL metric and a PLL metric in which all within-word tokens are masked. In particular, it better satisfies theoretical desiderata and better correlates with scores from autoregressive models. Finally, we show that the choice of metric affects even tightly controlled, minimal pair evaluation benchmarks (such as BLiMP), underscoring the importance of selecting an appropriate scoring metric for evaluating MLM properties. | Carina Kauf, Anna A. Ivanova |  |
| 257 |  |  [ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?](https://doi.org/10.18653/v1/2023.acl-short.81) |  | 0 | Recent research on dialog state tracking (DST) focuses on methods that allow few- and zero-shot transfer to new domains or schemas. However, performance gains heavily depend on aggressive data augmentation and fine-tuning of ever larger language model based architectures. In contrast, general purpose language models, trained on large amounts of diverse data, hold the promise of solving any kind of task without task-specific training. We present preliminary experimental results on the ChatGPT research preview, showing that ChatGPT achieves state-of-the-art performance in zero-shot DST. Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems. We further theorize that the in-context learning capabilities of such models will likely become powerful tools to support the development of dedicated dialog state trackers and enable dynamic methods. | Michael Heck, Nurul Lubis, Benjamin Matthias Ruppik, Renato Vukovic, Shutong Feng, Christian Geishauser, HsienChin Lin, Carel van Niekerk, Milica Gasic |  |
| 258 |  |  [Controllable Mixed-Initiative Dialogue Generation through Prompting](https://doi.org/10.18653/v1/2023.acl-short.82) |  | 0 | Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations. | Maximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi, Zhou Yu |  |
| 259 |  |  [Enhancing Event Causality Identification with Counterfactual Reasoning](https://doi.org/10.18653/v1/2023.acl-short.83) |  | 0 | Existing methods for event causality identification (ECI) focus on mining potential causal signals, i.e., causal context keywords and event pairs. However, causal signals are ambiguous, which may lead to the context-keywords bias and the event-pairs bias. To solve this issue, we propose the counterfactual reasoning that explicitly estimates the influence of context keywords and event pairs in training, so that we are able to eliminate the biases in inference.Experiments are conducted on two datasets, the result demonstrates the effectiveness of our method. | Feiteng Mu, Wenjie Li |  |
| 260 |  |  [Contrastive Bootstrapping for Label Refinement](https://doi.org/10.18653/v1/2023.acl-short.84) |  | 0 | Traditional text classification typically categorizes texts into pre-defined coarse-grained classes, from which the produced models cannot handle the real-world scenario where finer categories emerge periodically for accurate services. In this work, we investigate the setting where fine-grained classification is done only using the annotation of coarse-grained categories and the coarse-to-fine mapping. We propose a lightweight contrastive clustering-based bootstrapping method to iteratively refine the labels of passages. During clustering, it pulls away negative passage-prototype pairs under the guidance of the mapping from both global and local perspectives. Experiments on NYT and 20News show that our method outperforms the state-of-the-art methods by a large margin. | Shudi Hou, Yu Xia, Muhao Chen, Sujian Li |  |
| 261 |  |  [NollySenti: Leveraging Transfer Learning and Machine Translation for Nigerian Movie Sentiment Classification](https://doi.org/10.18653/v1/2023.acl-short.85) |  | 0 | Africa has over 2000 indigenous languages but they are under-represented in NLP research due to lack of datasets. In recent years, there have been progress in developing labelled corpora for African languages. However, they are often available in a single domain and may not generalize to other domains. In this paper, we focus on the task of sentiment classification for cross-domain adaptation. We create a new dataset, Nollywood movie reviews for five languages widely spoken in Nigeria (English, Hausa, Igbo, Nigerian Pidgin, and Yoruba). We provide an extensive empirical evaluation using classical machine learning methods and pre-trained language models. By leveraging transfer learning, we compare the performance of cross-domain adaptation from Twitter domain, and cross-lingual adaptation from English language. Our evaluation shows that transfer from English in the same target domain leads to more than 5% improvement in accuracy compared to transfer from Twitter in the same language. To further mitigate the domain difference, we leverage machine translation from English to other Nigerian languages, which leads to a further improvement of 7% over cross-lingual evaluation. While machine translation to low-resource languages are often of low quality, our analysis shows that sentiment related words are often preserved. | Iyanuoluwa Shode, David Ifeoluwa Adelani, Jing Peng, Anna Feldman |  |
| 262 |  |  [Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words Extraction with Wordpieces and Aspect Enhancement](https://doi.org/10.18653/v1/2023.acl-short.86) |  | 0 | State-of-the-art target-oriented opinion word extraction (TOWE) models typically use BERT-based text encoders that operate on the word level, along with graph convolutional networks (GCNs) that incorporate syntactic information extracted from syntax trees. These methods achieve limited gains with GCNs and have difficulty using BERT wordpieces. Meanwhile, BERT wordpieces are known to be effective at representing rare words or words with insufficient context information. To address this issue, this work trades syntax trees for BERT wordpieces by entirely removing the GCN component from the methods’ architectures. To enhance TOWE performance, we tackle the issue of aspect representation loss during encoding. Instead of solely utilizing a sentence as the input, we use a sentence-aspect pair. Our relatively simple approach achieves state-of-the-art results on benchmark datasets and should serve as a strong baseline for further research. | Samuel Mensah, Kai Sun, Nikolaos Aletras |  |
| 263 |  |  [An (unhelpful) guide to selecting the best ASR architecture for your under-resourced language](https://doi.org/10.18653/v1/2023.acl-short.87) |  | 0 | Advances in deep neural models for automatic speech recognition (ASR) have yielded dramatic improvements in ASR quality for resource-rich languages, with English ASR now achieving word error rates comparable to that of human transcribers. The vast majority of the world’s languages, however, lack the quantity of data necessary to approach this level of accuracy. In this paper we use four of the most popular ASR toolkits to train ASR models for eleven languages with limited ASR training resources: eleven widely spoken languages of Africa, Asia, and South America, one endangered language of Central America, and three critically endangered languages of North America. We find that no single architecture consistently outperforms any other. These differences in performance so far do not appear to be related to any particular feature of the datasets or characteristics of the languages. These findings have important implications for future research in ASR for under-resourced languages. ASR systems for languages with abundant existing media and available speakers may derive the most benefit simply by collecting large amounts of additional acoustic and textual training data. Communities using ASR to support endangered language documentation efforts, who cannot easily collect more data, might instead focus on exploring multiple architectures and hyperparameterizations to optimize performance within the constraints of their available data and resources. | Robert Jimerson, Zoey Liu, Emily Prud'hommeaux |  |
| 264 |  |  [The Ecological Fallacy in Annotation: Modeling Human Label Variation goes beyond Sociodemographics](https://doi.org/10.18653/v1/2023.acl-short.88) |  | 0 | Many NLP tasks exhibit human label variation, where different annotators give different labels to the same texts. This variation is known to depend, at least in part, on the sociodemographics of annotators. Recent research aims to model individual annotator behaviour rather than predicting aggregated labels, and we would expect that sociodemographic information is useful for these models. On the other hand, the ecological fallacy states that aggregate group behaviour, such as the behaviour of the average female annotator, does not necessarily explain individual behaviour. To account for sociodemographics in models of individual annotator behaviour, we introduce group-specific layers to multi-annotator models. In a series of experiments for toxic content detection, we find that explicitly accounting for sociodemographic attributes in this way does not significantly improve model performance. This result shows that individual annotation behaviour depends on much more than just sociodemographics. | Matthias Orlikowski, Paul Röttger, Philipp Cimiano, Dirk Hovy |  |
| 265 |  |  [Decomposed scoring of CCG dependencies](https://doi.org/10.18653/v1/2023.acl-short.89) |  | 0 | In statistical parsing with CCG, the standard evaluation method is based on predicate-argument structure and evaluates dependencies labelled in part by lexical categories. When a predicate has multiple argument slots that can be filled, the same lexical category is used for the label of multiple dependencies. In this paper, we show that this evaluation can result in disproportionate penalization of supertagging errors and obfuscate the truly erroneous dependencies. Enabled by the compositional nature of CCG lexical categories, we propose \*decomposed scoring\* based on subcategorial labels to address this. To evaluate our scoring method, we engage fellow categorial grammar researchers in two English-language judgement tasks: (1) directly ranking the outputs of the standard and experimental scoring methods; and (2) determining which of two sentences has the better parse in cases where the two scoring methods disagree on their ranks. Overall, the judges prefer decomposed scoring in each task; but there is substantial disagreement among the judges in 24% of the given cases, pointing to potential issues with parser evaluations in general. | Aditya Bhargava, Gerald Penn |  |
| 266 |  |  [Do GPTs Produce Less Literal Translations?](https://doi.org/10.18653/v1/2023.acl-short.90) |  | 0 | Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating sentences that contain idiomatic expressions. | Vikas Raunak, Arul Menezes, Matt Post, Hany Hassan |  |
| 267 |  |  [Environmental Claim Detection](https://doi.org/10.18653/v1/2023.acl-short.91) |  | 0 | To transition to a green economy, environmental claims made by companies must be reliable, comparable, and verifiable. To analyze such claims at scale, automated methods are needed to detect them in the first place. However, there exist no datasets or models for this. Thus, this paper introduces the task of environmental claim detection. To accompany the task, we release an expert-annotated dataset and models trained on this dataset. We preview one potential application of such models: We detect environmental claims made in quarterly earning calls and find that the number of environmental claims has steadily increased since the Paris Agreement in 2015. | Dominik Stammbach, Nicolas Webersinke, Julia Anna Bingler, Mathias Kraus, Markus Leippold |  |
| 268 |  |  [Black-box language model explanation by context length probing](https://doi.org/10.18653/v1/2023.acl-short.92) |  | 0 | The increasingly widespread adoption of large language models has highlighted the need for improving their explainability. We present \*context length probing\*, a novel explanation technique for causal language models, based on tracking the predictions of a model as a function of the length of available context, and allowing to assign \*differential importance scores\* to different contexts. The technique is model-agnostic and does not rely on access to model internals beyond computing token-level probabilities. We apply context length probing to large pre-trained language models and offer some initial analyses and insights, including the potential for studying long-range dependencies. The [source code](https://github.com/cifkao/context-probing/) and an [interactive demo](https://cifkao.github.io/context-probing/) of the method are available. | Ondrej Cífka, Antoine Liutkus |  |
| 269 |  |  [Let Me Check the Examples: Enhancing Demonstration Learning via Explicit Imitation](https://doi.org/10.18653/v1/2023.acl-short.93) |  | 0 | Demonstration learning aims to guide the prompt prediction by providing answered demonstrations in the few shot settings. Despite achieving promising results, existing work only concatenates the answered examples as demonstrations to the prompt template (including the raw context) without any additional operation, neglecting the prompt-demonstration dependencies. Besides, prior research found that randomly replacing the labels of demonstrations marginally hurts performance, illustrating that the model could not properly learn the knowledge brought by the demonstrations. Inspired by the human learning process, in this paper, we introduce Imitation DEMOnstration learning (Imitation-Demo) to strengthen demonstration learning via explicitly imitating human review behaviour, which includes: (1) contrastive learning mechanism to concentrate on similar demonstrations.(2) demonstration-label re-prediction method to consolidate known knowledge. Experiment results show that our proposed method achieves state-of-the-art performance on 5 out of 14 classification corpus. Further studies also prove that Imitation-Demo strengthens the associations between the prompt and demonstrations, which could provide the basis for exploring how demonstration learning works. | Sirui Wang, Kaiwen Wei, Hongzhi Zhang, Yuntao Li, Wei Wu |  |
| 270 |  |  [The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics](https://doi.org/10.18653/v1/2023.acl-short.94) |  | 0 | Neural metrics for machine translation evaluation, such as COMET, exhibit significant improvements in their correlation with human judgments, as compared to traditional metrics based on lexical overlap, such as BLEU. Yet, neural metrics are, to a great extent, “black boxes” returning a single sentence-level score without transparency about the decision-making process. In this work, we develop and compare several neural explainability methods and demonstrate their effectiveness for interpreting state-of-the-art fine-tuned neural metrics. Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors. To ease future research, we release our code at: https://github.com/Unbabel/COMET/tree/explainable-metrics | Ricardo Rei, Nuno Miguel Guerreiro, Marcos V. Treviso, Luísa Coheur, Alon Lavie, André F. T. Martins |  |
| 271 |  |  [Typo-Robust Representation Learning for Dense Retrieval](https://doi.org/10.18653/v1/2023.acl-short.95) |  | 0 | Dense retrieval is a basic building block of information retrieval applications. One of the main challenges of dense retrieval in real-world settings is the handling of queries containing misspelled words. A popular approach for handling misspelled queries is minimizing the representations discrepancy between misspelled queries and their pristine ones. Unlike the existing approaches, which only focus on the alignment between misspelled and pristine queries, our method also improves the contrast between each misspelled query and its surrounding queries. To assess the effectiveness of our proposed method, we compare it against the existing competitors using two benchmark datasets and two base encoders. Our method outperforms the competitors in all cases with misspelled queries. Our code and models are available at https://github.com/panuthept/DST-DenseRetrieval. | Panuthep Tasawong, Wuttikorn Ponwitayarat, Peerat Limkonchotiwat, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 272 |  |  [Focused Prefix Tuning for Controllable Text Generation](https://doi.org/10.18653/v1/2023.acl-short.96) |  | 0 | In a controllable text generation dataset, there exist unannotated attributes that could provide irrelevant learning signals to models that use it for training and thus degrade their performance. We propose focused prefix tuning (FPT) to mitigate the problem and to enable the control to focus on the desired attribute. Experimental results show that FPT can achieve better control accuracy and text fluency than baseline models in single-attribute control tasks. In multi-attribute control tasks, FPT achieves comparable control accuracy with the state-of-the-art approach while keeping the flexibility to control new attributes without retraining existing models. | Congda Ma, Tianyu Zhao, Makoto Shing, Kei Sawada, Manabu Okumura |  |
| 273 |  |  [ReAugKD: Retrieval-Augmented Knowledge Distillation For Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-short.97) |  | 0 | Knowledge Distillation (KD) is one of the most effective approaches to deploying large-scale pre-trained language models in low-latency environments by transferring the knowledge contained in the large-scale models to smaller student models. Prior KD approaches use the soft labels and intermediate activations generated by the teacher to transfer knowledge to the student model parameters alone. In this paper, we show that having access to non-parametric memory in the form of a knowledge base with the teacher’s soft labels and predictions can further improve student generalization. To enable the student to retrieve from the knowledge base effectively, we propose a new framework and loss function that preserves the semantic similarities of teacher and student training examples. We show through extensive experiments that our retrieval mechanism can achieve state-of-the-art performance for task-specific knowledge distillation on the GLUE benchmark. | Jianyi Zhang, Aashiq Muhamed, Aditya Anantharaman, Guoyin Wang, Changyou Chen, Kai Zhong, Qingjun Cui, Yi Xu, Belinda Zeng, Trishul Chilimbi, Yiran Chen |  |
| 274 |  |  [Debiasing Generative Named Entity Recognition by Calibrating Sequence Likelihood](https://doi.org/10.18653/v1/2023.acl-short.98) |  | 0 | Recognizing flat, overlapped and discontinuous entities uniformly has been paid increasing attention. Among these works, Seq2Seq formulation prevails for its flexibility and effectiveness. It arranges the output entities into a specific target sequence. However, it introduces bias by assigning all the probability mass to the observed sequence. To alleviate the bias, previous works either augment the data with possible sequences or resort to other formulations. In this paper, we stick to the Seq2Seq formulation and propose a reranking-based approach. It redistributes the likelihood among candidate sequences depending on their performance via a contrastive loss. Extensive experiments show that our simple yet effective method consistently boosts the baseline, and yields competitive or better results compared with the state-of-the-art methods on 8 widely-used datasets for Named Entity Recognition. | Yu Xia, Yongwei Zhao, Wenhao Wu, Sujian Li |  |
| 275 |  |  [Deriving Language Models from Masked Language Models](https://doi.org/10.18653/v1/2023.acl-short.99) |  | 0 | Masked language models (MLM) do not explicitly define a distribution over language, i.e., they are not language models per se. However, recent work has implicitly treated them as such for the purposes of generation and scoring. This paper studies methods for deriving explicit joint distributions from MLMs, focusing on distributions over two tokens, which makes it possible to calculate exact distributional properties. We find that an approach based on identifying joints whose conditionals are closest to those of the MLM works well and outperforms existing Markov random field-based approaches. We further find that this derived model’s conditionals can even occasionally outperform the original MLM’s conditionals. | Lucas Torroba Hennigen, Yoon Kim |  |
| 276 |  |  [UniTRec: A Unified Text-to-Text Transformer and Joint Contrastive Learning Framework for Text-based Recommendation](https://doi.org/10.18653/v1/2023.acl-short.100) |  | 0 | Prior study has shown that pretrained language models (PLM) can boost the performance of text-based recommendation. In contrast to previous works that either use PLM to encode user history as a whole input text, or impose an additional aggregation network to fuse multi-turn history representations, we propose a unified local- and global-attention Transformer encoder to better model two-level contexts of user history. Moreover, conditioned on user history encoded by Transformer encoders, our framework leverages Transformer decoders to estimate the language perplexity of candidate text items, which can serve as a straightforward yet significant contrastive signal for user-item text matching. Based on this, our framework, UniTRec, unifies the contrastive objectives of discriminative matching scores and candidate text perplexity to jointly enhance text-based recommendation. Extensive evaluation shows that UniTRec delivers SOTA performance on three text-based recommendation tasks. | Zhiming Mao, Huimin Wang, Yiming Du, KamFai Wong |  |
| 277 |  |  [Reasoning Implicit Sentiment with Chain-of-Thought Prompting](https://doi.org/10.18653/v1/2023.acl-short.101) |  | 0 | While sentiment analysis systems try to determine the sentiment polarities of given targets based on the key opinion expressions in input texts, in implicit sentiment analysis (ISA) the opinion cues come in an implicit and obscure manner. Thus detecting implicit sentiment requires the common-sense and multi-hop reasoning ability to infer the latent intent of opinion. Inspired by the recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA. We design a three-step prompting principle for THOR to step-by-step induce the implicit aspect, opinion, and finally the sentiment polarity. Our THOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on supervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50% F1 on zero-shot setting. | Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, TatSeng Chua |  |
| 278 |  |  [Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings](https://doi.org/10.18653/v1/2023.acl-short.102) |  | 0 | The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models. | TaChung Chi, TingHan Fan, LiWei Chen, Alexander Rudnicky, Peter J. Ramadge |  |
| 279 |  |  [Is Anisotropy Truly Harmful? A Case Study on Text Clustering](https://doi.org/10.18653/v1/2023.acl-short.103) |  | 0 | In the last few years, several studies have been devoted to dissecting dense text representations in order to understand their effectiveness and further improve their quality. Particularly, the anisotropy of such representations has been observed, which means that the directions of the word vectors are not evenly distributed across the space but rather concentrated in a narrow cone. This has led to several attempts to counteract this phenomenon both on static and contextualized text representations. However, despite this effort, there is no established relationship between anisotropy and performance. In this paper, we aim to bridge this gap by investigating the impact of different transformations on both the isotropy and the performance in order to assess the true impact of anisotropy. To this end, we rely on the clustering task as a means of evaluating the ability of text representations to produce meaningful groups. Thereby, we empirically show a limited impact of anisotropy on the expressiveness of sentence representations both in terms of directions and L2 closeness. | Mira Ait Saada, Mohamed Nadif |  |
| 280 |  |  [Class based Influence Functions for Error Detection](https://doi.org/10.18653/v1/2023.acl-short.104) |  | 0 | Influence functions (IFs) are a powerful tool for detecting anomalous examples in large scale datasets. However, they are unstable when applied to deep networks. In this paper, we provide an explanation for the instability of IFs and develop a solution to this problem. We show that IFs are unreliable when the two data points belong to two different classes. Our solution leverages class information to improve the stability of IFs.Extensive experiments show that our modification significantly improves the performance and stability of IFs while incurring no additional computational cost. | Thang NguyenDuc, Hoang ThanhTung, Quan Hung Tran, HuuTien Dang, Hieu Nguyen, Anh T. V. Dau, Nghi D. Q. Bui |  |
| 281 |  |  [Leveraging Prefix Transfer for Multi-Intent Text Revision](https://doi.org/10.18653/v1/2023.acl-short.105) |  | 0 | Text revision is a necessary process to improve text quality. During this process, writers constantly edit texts out of different edit intentions. Identifying edit intention for a raw text is always an ambiguous work, and most previous work on revision systems mainly focuses on editing texts according to one specific edit intention. In this work, we aim to build a multi-intent text revision system that could revise texts without explicit intent annotation. Our system is based on prefix-tuning, which first gets prefixes for every edit intent, and then trains a prefix transfer module, enabling the system to selectively leverage the knowledge from various prefixes according to the input text. We conduct experiments on the IteraTeR dataset, and the results show that our system outperforms baselines. The system can significantly improve the SARI score with more than 3% improvements, which thrives on the learned editing intention prefixes. | Ruining Chong, Cunliang Kong, Liu Wu, Zhenghao Liu, Ziye Jin, Liner Yang, Yange Fan, Hanghang Fan, Erhong Yang |  |
| 282 |  |  [Learning Multi-Step Reasoning by Solving Arithmetic Tasks](https://doi.org/10.18653/v1/2023.acl-short.106) |  | 0 | Mathematical reasoning is regarded as a necessary ability for Language Models (LMs). Recent works demonstrate large LMs’ impressive performance in solving math problems. The success is attributed to their Chain-of-Thought (CoT) reasoning abilities, i.e., the ability to decompose complex questions into step-by-step reasoning chains, but such ability seems only to emerge from models with abundant parameters. This work investigates how to incorporate relatively small LMs with the capabilities of multi-step reasoning. We propose to inject such abilities by continually pre-training LMs on a synthetic dataset MsAT which is composed of Multi-step Arithmetic Tasks. Our experiments on four math word problem datasets show the effectiveness of the proposed method in enhancing LMs’ math reasoning abilities. | Tianduo Wang, Wei Lu |  |
| 283 |  |  [Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning](https://doi.org/10.18653/v1/2023.acl-short.107) |  | 0 | Fine-tuning large pre-trained language models on various downstream tasks with whole parameters is prohibitively expensive. Hence, Parameter-efficient fine-tuning has attracted attention that only optimizes a few task-specific parameters with the frozen pre-trained model. In this work, we focus on prefix tuning, which only optimizes continuous prefix vectors (i.e. pseudo tokens) inserted into Transformer layers. Based on the observation that the learned syntax and semantics representation varies a lot at different layers, we argue that the adaptive prefix will be further tailored to each layer than the fixed one, enabling the fine-tuning more effective and efficient. Thus, we propose Adaptive Prefix Tuning (APT) to adjust the prefix in terms of both fine-grained token level and coarse-grained layer level with a gate mechanism. Experiments on the SuperGLUE and NER datasets show the effectiveness of APT. In addition, taking the gate as a probing, we validate the efficiency and effectiveness of the variable prefix. | Zhenru Zhang, Chuanqi Tan, Haiyang Xu, Chengyu Wang, Jun Huang, Songfang Huang |  |
| 284 |  |  [Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting](https://doi.org/10.18653/v1/2023.acl-short.108) |  | 0 | Existing studies addressing gender bias of pre-trained language models, usually build a small gender-neutral data set and conduct a second phase pre-training on the model with such data. However, given the limited size and concentrated focus of the gender-neutral data, catastrophic forgetting would occur during second-phase pre-training. Forgetting information in the original training data may damage the model’s downstream performance by a large margin. In this work, we empirically show that catastrophic forgetting occurs in such methods by evaluating them with general NLP tasks in GLUE. Then, we propose a new method, GEnder Equality Prompt (GEEP), to improve gender fairness of pre-trained models with less forgetting. GEEP freezes the pre-trained model and learns gender-related prompts with gender-neutral data. Empirical results show that GEEP not only achieves SOTA performances on gender fairness tasks, but also forgets less and performs better on GLUE by a large margin. | Zahra Fatemi, Chen Xing, Wenhao Liu, Caiming Xiong |  |
| 285 |  |  [Class-Incremental Learning based on Label Generation](https://doi.org/10.18653/v1/2023.acl-short.109) |  | 0 | Despite the great success of pre-trained language models, it is still a challenge to use these models for continual learning, especially for the class-incremental learning (CIL) setting due to catastrophic forgetting (CF). This paper reports our finding that if we formulate CIL as a continual label generation problem, CF is drastically reduced and the generalizable representations of pre-trained models can be better retained. We thus propose a new CIL method (VAG) that also leverages the sparsity of vocabulary to focus the generation and creates pseudo-replay samples by using label semantics. Experimental results show that VAG outperforms baselines by a large margin. | Yijia Shao, Yiduo Guo, Dongyan Zhao, Bing Liu |  |
| 286 |  |  [Evaluating pragmatic abilities of image captioners on A3DS](https://doi.org/10.18653/v1/2023.acl-short.110) |  | 0 | Evaluating grounded neural language model performance with respect to pragmatic qualities like the trade off between truthfulness, contrastivity and overinformativity of generated utterances remains a challenge in absence of data collected from humans. To enable such evaluation, we present a novel open source image-text dataset “Annotated 3D Shapes” (A3DS) comprising over nine million exhaustive natural language annotations and over 12 million variable-granularity captions for the 480,000 images provided by Burgess & Kim (2018).We showcase the evaluation of pragmatic abilities developed by a task-neutral image captioner fine-tuned in a multi-agent communication setting to produce contrastive captions. The evaluation is enabled by the dataset because the exhaustive annotations allow to quantify the presence of contrastive features in the model’s generations. We show that the model develops human-like patterns (informativity, brevity, over-informativity for specific features (e.g., shape, color biases)). | Polina Tsvilodub, Michael Franke |  |
| 287 |  |  [The Art of Prompting: Event Detection based on Type Specific Prompts](https://doi.org/10.18653/v1/2023.acl-short.111) |  | 0 | We compare various forms of prompts to represent event types and develop a unified framework to incorporate the event type specific prompts for supervised, few-shot, and zero-shot event detection. The experimental results demonstrate that a well-defined and comprehensive event type prompt can significantly improve event detection performance, especially when the annotated data is scarce (few-shot event detection) or not available (zero-shot event detection). By leveraging the semantics of event types, our unified framework shows up to 22.2% F-score gain over the previous state-of-the-art baselines. | Sijia Wang, Mo Yu, Lifu Huang |  |
| 288 |  |  [Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-short.112) |  | 0 | This paper studies the impact of layer normalization (LayerNorm) on zero-shot translation (ZST). Recent efforts for ZST often utilize the Transformer architecture as the backbone, with LayerNorm at the input of layers (PreNorm) set as the default. However, Xu et al. (2019) has revealed that PreNorm carries the risk of overfitting the training data. Based on this, we hypothesize that PreNorm may overfit supervised directions and thus have low generalizability for ZST. Through experiments on OPUS, IWSLT, and Europarl datasets for 54 ZST directions, we demonstrate that the original Transformer setting of LayerNorm after residual connections (PostNorm) consistently outperforms PreNorm by up to 12.3 BLEU points. We then study the performance disparities by analyzing the differences in off-target rates and structural variations between PreNorm and PostNorm. This study highlights the need for careful consideration of the LayerNorm setting for ZST. | Zhuoyuan Mao, Raj Dabre, Qianying Liu, Haiyue Song, Chenhui Chu, Sadao Kurohashi |  |
| 289 |  |  [Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning](https://doi.org/10.18653/v1/2023.acl-short.113) |  | 0 | Recent works on instruction tuning (IT) have achieved great performance with zero-shot generalizability to unseen tasks. With additional context (e.g., task definition, examples) provided to models for fine-tuning, they achieved much higher performance than untuned models. Despite impressive performance gains, what models learn from IT remains understudied. In this work, we analyze how models utilize instructions during IT by comparing model training with altered vs. original instructions. Specifically, we create simplified task definitions by removing all semantic components and only leaving the output space information, and delusive examples that contain incorrect input-output mapping. Our experiments show that models trained on simplified task definition or delusive examples can achieve comparable performance to the ones trained on the original instructions and examples. Furthermore, we introduce a random baseline to perform zeroshot classification tasks, and find it achieves similar performance (42.6% exact-match) as IT does (43% exact-match) in low resource setting, while both methods outperform naive T5 significantly (30% per exact-match). Our analysis provides evidence that the impressive performance gain of current IT models can come from picking up superficial patterns, such as learning the output format and guessing. Our study highlights the urgent need for more reliable IT methods and evaluation. | PoNien Kung, Nanyun Peng |  |
| 290 |  |  [Self-Distilled Quantization: Achieving High Compression Rates in Transformer-Based Language Models](https://doi.org/10.18653/v1/2023.acl-short.114) |  | 0 | We investigate the effects of post-training quantization and quantization-aware training on the generalization of Transformer language models. We present a new method called self-distilled quantization (SDQ) that minimizes accumulative quantization errors and outperforms baselines. We apply SDQ to multilingual models XLM-RBase and InfoXLMBase and demonstrate that both models can be reduced from 32-bit floating point weights to 8-bit integer weights while maintaining a high level of performance on the XGLUE benchmark. Our results also highlight the challenges of quantizing multilingual models, which must generalize to languages they were not fine-tuned on. | James O'Neill, Sourav Dutta |  |
| 291 |  |  [Modality Adaption or Regularization? A Case Study on End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.acl-short.115) |  | 0 | Pre-training and fine-tuning is a paradigm for alleviating the data scarcity problem in end-to-end speech translation (E2E ST). The commonplace ”modality gap” between speech and text data often leads to inconsistent inputs between pre-training and fine-tuning. However, we observe that this gap occurs in the early stages of fine-tuning, but does not have a major impact on the final performance. On the other hand, we find that there has another gap, which we call the ”capacity gap”: high resource tasks (such as ASR and MT) always require a large model to fit, when the model is reused for a low resource task (E2E ST), it will get a sub-optimal performance due to the over-fitting. In a case study, we find that the regularization plays a more important role than the well-designed modality adaption method, which achieves 29.0 for en-de and 40.3 for en-fr on the MuST-C dataset. | Yuchen Han, Chen Xu, Tong Xiao, Jingbo Zhu |  |
| 292 |  |  [Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data](https://doi.org/10.18653/v1/2023.acl-short.116) |  | 0 | Jointly extracting entity pairs and their relations is challenging when working on distantly-supervised data with ambiguous or noisy labels. To mitigate such impact, we propose uncertainty-aware bootstrap learning, which is motivated by the intuition that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. Specifically, we first explore instance-level data uncertainty to create an initial high-confident examples. Such subset serves as filtering noisy instances and facilitating the model to converge fast at the early stage. During bootstrap learning, we propose self-ensembling as a regularizer to alleviate inter-model uncertainty produced by noisy labels. We further define probability variance of joint tagging probabilities to estimate inner-model parametric uncertainty, which is used to select and build up new reliable training instances for the next iteration. Experimental results on two large datasets reveal that our approach outperforms existing strong baselines and related methods. | Yufei Li, Xiao Yu, Yanchi Liu, Haifeng Chen, Cong Liu |  |
| 293 |  |  [Text-to-SQL Error Correction with Language Models of Code](https://doi.org/10.18653/v1/2023.acl-short.117) |  | 0 | Despite recent progress in text-to-SQL parsing, current semantic parsers are still not accurate enough for practical use. In this paper, we investigate how to build automatic text-to-SQL error correction models. Noticing that token-level edits are out of context and sometimes ambiguous, we propose building clause-level edit models instead. Besides, while most language models of code are not specifically pre-trained for SQL, they know common data structures and their operations in programming languages such as Python. Thus, we propose a novel representation for SQL queries and their edits that adheres more closely to the pre-training corpora of language models of code. Our error correction model improves the exact set match accuracy of different parsers by 2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong baselines. | Ziru Chen, Shijie Chen, Michael White, Raymond J. Mooney, Ali Payani, Jayanth Srinivasa, Yu Su, Huan Sun |  |
| 294 |  |  [The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks](https://doi.org/10.18653/v1/2023.acl-short.118) |  | 0 | How reliably can we trust the scores obtained from social bias benchmarks as faithful indicators of problematic social biases in a given model? In this work, we study this question by contrasting social biases with non-social biases that stem from choices made during dataset construction (which might not even be discernible to the human eye). To do so, we empirically simulate various alternative constructions for a given benchmark based on seemingly innocuous modifications (such as paraphrasing or random-sampling) that maintain the essence of their social bias. On two well-known social bias benchmarks (Winogender and BiasNLI), we observe that these shallow modifications have a surprising effect on the resulting degree of bias across various models and consequently the relative ordering of these models when ranked by measured bias. We hope these troubling observations motivate more robust measures of social biases. | Nikil Roashan Selvam, Sunipa Dev, Daniel Khashabi, Tushar Khot, KaiWei Chang |  |
| 295 |  |  [Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)](https://doi.org/10.18653/v1/2023.acl-short.119) |  | 0 | Large language models, particularly GPT-3, are able to produce high quality summaries ofgeneral domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized domains such as biomedicine. In this paper we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given no supervision. We consider bothsingle- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in thelatter, we assess the degree to which GPT-3 is able to synthesize evidence reported acrossa collection of articles. We design an annotation scheme for evaluating model outputs, withan emphasis on assessing the factual accuracy of generated summaries. We find that whileGPT-3 is able to summarize and simplify single biomedical articles faithfully, it strugglesto provide accurate aggregations of findings over multiple documents. We release all data,code, and annotations used in this work. | Chantal Shaib, Millicent L. Li, Sebastian Joseph, Iain James Marshall, Junyi Jessy Li, Byron C. Wallace |  |
| 296 |  |  [Prefix Propagation: Parameter-Efficient Tuning for Long Sequences](https://doi.org/10.18653/v1/2023.acl-short.120) |  | 0 | Parameter-efficient tuning aims to mitigate the large memory requirements of adapting pretrained language models for downstream tasks. For example, one popular method, prefix-tuning, prepends trainable tokens to sequences while freezing the rest of the model’s parameters. Although such models attain comparable performance with fine-tuning when applied to sequences with short to moderate lengths, we show their inferior performance when modelling long sequences. To bridge this gap, we propose prefix-propagation, a simple but effective approach that conditions prefixes on previous hidden states. We empirically demonstrate that prefix-propagation outperforms prefix-tuning across long-document tasks, while using 50% fewer parameters. To further investigate the proposed architecture, we also show its advantage in calibration, and perform additional study on its relationship with kernel attention. To the best of our knowledge, this work is the first to focus on parameter-efficient learning for long-sequence language tasks. | Jonathan Li, Will Aitken, Rohan Bhambhoria, Xiaodan Zhu |  |
| 297 |  |  [Listener Model for the PhotoBook Referential Game with CLIPScores as Implicit Reference Chain](https://doi.org/10.18653/v1/2023.acl-short.121) |  | 0 | PhotoBook is a collaborative dialogue game where two players receive private, partially-overlapping sets of images and resolve which images they have in common. It presents machines with a great challenge to learn how people build common ground around multimodal context to communicate effectively. Methods developed in the literature, however, cannot be deployed to real gameplaysince they only tackle some subtasks of the game,and they require additional reference chains inputs, whose extraction process is imperfect. Therefore, we propose a reference chain-free listener modelthat directly addresses the game’s predictive task, i.e., deciding whether an image is shared with partner. Our DeBERTa-based listener model reads the full dialogue, and utilizesCLIPScore features to assess utterance-image relevance. We achieve >77% accuracy on unseen sets of images/game themes, outperforming baseline by >17 points. | ShihLun Wu, YiHui Chou, Liangze Li |  |
| 298 |  |  [Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations](https://doi.org/10.18653/v1/2023.acl-short.122) |  | 0 | Automatic postediting (APE) is an automated process to refine a given machine translation (MT). Recent findings present that existing APE systems are not good at handling high-quality MTs even for a language pair with abundant data resources, English–German: the better the given MT is, the harder it is to decide what parts to edit and how to fix these errors. One possible solution to this problem is to instill deeper knowledge about the target language into the model. Thus, we propose a linguistically motivated method of regularization that is expected to enhance APE models’ understanding of the target language: a loss function that encourages symmetric self-attention on the given MT. Our analysis of experimental results demonstrates that the proposed method helps improving the state-of-the-art architecture’s APE quality for high-quality MTs. | Baikjin Jung, Myungji Lee, JongHyeok Lee, Yunsu Kim |  |
| 299 |  |  [An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-short.123) |  | 0 | Named entity recognition (NER) is the task to detect and classify entity spans in the text. When entity spans overlap between each other, the task is named as nested NER. Span-based methods have been widely used to tackle nested NER. Most of these methods get a score matrix, where each entry corresponds to a span. However, previous work ignores spatial relations in the score matrix. In this paper, we propose using Convolutional Neural Network (CNN) to model these spatial relations. Despite being simple, experiments in three commonly used nested NER datasets show that our model surpasses several recently proposed methods with the same pre-trained encoders. Further analysis shows that using CNN can help the model find more nested entities. Besides, we find that different papers use different sentence tokenizations for the three nested NER datasets, which will influence the comparison. Thus, we release a pre-processing script to facilitate future comparison. | Hang Yan, Yu Sun, Xiaonan Li, Xipeng Qiu |  |
| 300 |  |  [Hexatagging: Projective Dependency Parsing as Tagging](https://doi.org/10.18653/v1/2023.acl-short.124) |  | 0 | We introduce a novel dependency parser, the hexatagger, that constructs dependency trees by tagging the words in a sentence with elements from a finite set of possible tags. In contrast to many approaches to dependency parsing, our approach is fully parallelizable at training time, i.e., the structure-building actions needed to build a dependency parse can be predicted in parallel to each other. Additionally, exact decoding is linear in time and space complexity. Furthermore, we derive a probabilistic dependency parser that predicts hexatags using no more than a linear model with features from a pretrained language model, i.e., we forsake a bespoke architecture explicitly designed for the task. Despite the generality and simplicity of our approach, we achieve state-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test set. Additionally, our parser’s linear time complexity and parallelism significantly improve computational efficiency, with a roughly 10-times speed-up over previous state-of-the-art models during decoding. | Afra Amini, Tianyu Liu, Ryan Cotterell |  |
| 301 |  |  [Understanding Demonstration-based Learning from a Causal Perspective](https://doi.org/10.18653/v1/2023.acl-short.125) |  | 0 | Demonstration-based learning has shown impressive performance in exploiting pretrained language models under few-shot learning settings. It is interesting to see that demonstrations, even those composed of random tokens, can still improve performance. In this paper, we build a Structural Causal Model (SCM) to understand demonstration-based learning from causal perspectives and interpret random demonstrations as interventions on the demonstration variable within the causal model. We investigate the causal effects and find that the concurrence of specific words in the demonstration will induce bias, while randomly sampled tokens in the demonstration do not. Based on this finding, we further propose simple ways to construct random demonstrations, which even outperform hand-crafted, meaningful demonstrations on public sequence labeling benchmarks. | Ruiyi Zhang, Tong Yu |  |
| 302 |  |  [RAMP: Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation](https://doi.org/10.18653/v1/2023.acl-short.126) |  | 0 | Attribute-controlled translation (ACT) is a subtask of machine translation that involves controlling stylistic or linguistic attributes (like formality and gender) of translation outputs. While ACT has garnered attention in recent years due to its usefulness in real-world applications, progress in the task is currently limited by dataset availability, since most prior approaches rely on supervised methods. To address this limitation, we propose Retrieval and Attribute-Marking enhanced Prompting (RAMP), which leverages large multilingual language models to perform ACT in few-shot and zero-shot settings. RAMP improves generation accuracy over the standard prompting approach by (1) incorporating a semantic similarity retrieval component for selecting similar in-context examples, and (2) marking in-context examples with attribute annotations. Our comprehensive experiments show that RAMP is a viable approach in both zero-shot and few-shot settings. | Gabriele Sarti, Phu Mon Htut, Xing Niu, Benjamin Hsu, Anna Currey, Georgiana Dinu, Maria Nadejde |  |
| 303 |  |  [Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation](https://doi.org/10.18653/v1/2023.acl-short.127) |  | 0 | Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance. | Haoyang Wen, Alexander G. Hauptmann |  |
| 304 |  |  [Discourse-Level Representations can Improve Prediction of Degree of Anxiety](https://doi.org/10.18653/v1/2023.acl-short.128) |  | 0 | Anxiety disorders are the most common of mental illnesses, but relatively little is known about how to detect them from language. The primary clinical manifestation of anxiety is worry associated cognitive distortions, which are likely expressed at the discourse-level of semantics. Here, we investigate the development of a modern linguistic assessment for degree of anxiety, specifically evaluating the utility of discourse-level information in addition to lexical-level large language model embeddings. We find that a combined lexico-discourse model outperforms models based solely on state-of-the-art contextual embeddings (RoBERTa), with discourse-level representations derived from Sentence-BERT and DiscRE both providing additional predictive power not captured by lexical-level representations. Interpreting the model, we find that discourse patterns of causal explanations, among others, were used significantly more by those scoring high in anxiety, dovetailing with psychological literature. | Swanie Juhng, Matthew Matero, Vasudha Varadarajan, Johannes C. Eichstaedt, Adithya V. Ganesan, H. Andrew Schwartz |  |
| 305 |  |  [Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning](https://doi.org/10.18653/v1/2023.acl-short.129) |  | 0 | Large Language Models (LLMs) are known to memorize significant portions of their training data. Parts of this memorized content have been shown to be extractable by simply querying the model, which poses a privacy risk. We present a novel approach which uses prompt-tuning to control the extraction rates of memorized content in LLMs. We present two prompt training strategies to increase and decrease extraction rates, which correspond to an attack and a defense, respectively. We demonstrate the effectiveness of our techniques by using models from the GPT-Neo family on a public benchmark. For the 1.3B parameter GPT-Neo model, our attack yields a 9.3 percentage point increase in extraction rate compared to our baseline. Our defense can be tuned to achieve different privacy-utility trade-offs by a user-specified hyperparameter. We achieve an extraction rate reduction of up to 97.7% relative to our baseline, with a perplexity increase of 16.9%. | Mustafa Özdayi, Charith Peris, Jack FitzGerald, Christophe Dupuy, Jimit Majmudar, Haidar Khan, Rahil Parikh, Rahul Gupta |  |
| 306 |  |  [MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting](https://doi.org/10.18653/v1/2023.acl-short.130) |  | 0 | Large language models (LLMs) have achieved impressive performance on various reasoning tasks. To further improve the performance, we propose MultiTool-CoT, a novel framework that leverages chain-of-thought (CoT) prompting to incorporate multiple external tools, such as a calculator and a knowledge retriever, during the reasoning process. We apply MultiTool-CoT to the Task 2 dataset of NumGLUE, which requires both numerical reasoning and domain-specific knowledge. The experiments show that our method significantly outperforms strong baselines and achieves state-of-the-art performance. | Tatsuro Inaba, Hirokazu Kiyomaru, Fei Cheng, Sadao Kurohashi |  |
| 307 |  |  [mPMR: A Multilingual Pre-trained Machine Reader at Scale](https://doi.org/10.18653/v1/2023.acl-short.131) |  | 0 | We present multilingual Pre-trained Machine Reader (mPMR), a novel method for multilingual machine reading comprehension (MRC)-style pre-training. mPMR aims to guide multilingual pre-trained language models (mPLMs) to perform natural language understanding (NLU) including both sequence classification and span extraction in multiple languages. To achieve cross-lingual generalization when only source-language fine-tuning data is available, existing mPLMs solely transfer NLU capability from a source language to target languages. In contrast, mPMR allows the direct inheritance of multilingual NLU capability from the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires better NLU capability for target languages. mPMR also provides a unified solver for tackling cross-lingual span extraction and sequence classification, thereby enabling the extraction of rationales to explain the sentence-pair classification process. | Weiwen Xu, Xin Li, Wai Lam, Lidong Bing |  |
| 308 |  |  [MOSPC: MOS Prediction Based on Pairwise Comparison](https://doi.org/10.18653/v1/2023.acl-short.132) |  | 0 | As a subjective metric to evaluate the quality of synthesized speech, Mean opinion score(MOS) usually requires multiple annotators to score the same speech. Such an annotation approach requires a lot of manpower and is also time-consuming. MOS prediction model for automatic evaluation can significantly reduce labor cost. In previous works, it is difficult to accurately rank the quality of speech when the MOS scores are close. However, in practical applications, it is more important to correctly rank the quality of synthesis systems or sentences than simply predicting MOS scores. Meanwhile, as each annotator scores multiple audios during annotation, the score is probably a relative value based on the first or the first few speech scores given by the annotator. Motivated by the above two points, we propose a general framework for MOS prediction based on pair comparison (MOSPC), and we utilize C-Mixup algorithm to enhance the generalization performance of MOSPC.The experiments on BVCC and VCC2018 show that our framework outperforms the baselines on most of the correlation coefficient metrics, especially on the metric KTAU related to quality ranking. And our framework also surpasses the strong baseline in ranking accuracy on each fine-grained segment. These results indicate that our framework contributes to improving the ranking accuracy of speech quality. | Kexin Wang, Yunlong Zhao, Qianqian Dong, Tom Ko, Mingxuan Wang |  |
| 309 |  |  [LI-RAGE: Late Interaction Retrieval Augmented Generation with Explicit Signals for Open-Domain Table Question Answering](https://doi.org/10.18653/v1/2023.acl-short.133) |  | 0 | Recent open-domain TableQA models are typically implemented as retriever-reader pipelines. The retriever component is usually a variant of the Dense Passage Retriever, which computes the similarities between questions and tables based on a single representation of each. These fixed vectors can be insufficient to capture fine-grained features of potentially very big tables with heterogeneous row/column information. We address this limitation by 1) applying late interaction models which enforce a finer-grained interaction between question and table embeddings at retrieval time. In addition, we 2) incorporate a joint training scheme of the retriever and reader with explicit table-level signals, and 3) embed a binary relevance token as a prefix to the answer generated by the reader, so we can determine at inference time whether the table used to answer the question is reliable and filter accordingly. The combined strategies set a new state-to-the-art performance on two public open-domain TableQA datasets. | Weizhe Lin, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert, Gonzalo Iglesias |  |
| 310 |  |  [How Well Apply Simple MLP to Incomplete Utterance Rewriting?](https://doi.org/10.18653/v1/2023.acl-short.134) |  | 0 | Incomplete utterance rewriting (IUR) aims to restore the incomplete utterance with sufficient context information for comprehension. This paper introduces a simple yet efficient IUR method. Different from prior studies, we first employ only one-layer MLP architecture to mine latent semantic information between joint utterances for IUR task (MIUR). After that, we conduct a joint feature matrix to predict the token type and thus restore the incomplete utterance. The well-designed network and simple architecture make our method significantly superior to existing methods in terms of quality and inference speedOur code is available at https://github.com/IMU-MachineLearningSXD/MIUR. | Jiang Li, Xiangdong Su, Xinlan Ma, Guanglai Gao |  |
| 311 |  |  [XL-LEXEME: WiC Pretrained Model for Cross-Lingual LEXical sEMantic changE](https://doi.org/10.18653/v1/2023.acl-short.135) |  | 0 | The recent introduction of large-scale datasets for the WiC (Word in Context) task enables the creation of more reliable and meaningful contextualized word embeddings.However, most of the approaches to the WiC task use cross-encoders, which prevent the possibility of deriving comparable word embeddings.In this work, we introduce XL-LEXEME, a Lexical Semantic Change Detection model.XL-LEXEME extends SBERT, highlighting the target word in the sentence. We evaluate XL-LEXEME on the multilingual benchmarks for SemEval-2020 Task 1 - Lexical Semantic Change (LSC) Detection and the RuShiftEval shared task involving five languages: English, German, Swedish, Latin, and Russian.XL-LEXEME outperforms the state-of-the-art in English, German and Swedish with statistically significant differences from the baseline results and obtains state-of-the-art performance in the RuShiftEval shared task. | Pierluigi Cassotti, Lucia Siciliani, Marco de Gemmis, Giovanni Semeraro, Pierpaolo Basile |  |
| 312 |  |  [Theory-Grounded Computational Text Analysis](https://doi.org/10.18653/v1/2023.acl-short.136) |  | 0 | In this position paper, we argue that computational text analysis lacks and requires organizing principles. A broad space separates its two constituent disciplines—natural language processing and social science—which has to date been sidestepped rather than filled by applying increasingly complex computational models to problems in social science research. We contrast descriptive and integrative findings, and our review of approximately 60 papers on computational text analysis reveals that those from \*ACL venues are typically descriptive. The lack of theory began at the area’s inception and has over the decades, grown more important and challenging. A return to theoretically grounded research questions will propel the area from both theoretical and methodological points of view. | Arya D. McCarthy, Giovanna Maria Dora Dore |  |
| 313 |  |  [AMRs Assemble! Learning to Ensemble with Autoregressive Models for AMR Parsing](https://doi.org/10.18653/v1/2023.acl-short.137) |  | 0 | In this paper, we examine the current state-of-the-art in AMR parsing, which relies on ensemble strategies by merging multiple graph predictions. Our analysis reveals that the present models often violate AMR structural constraints. To address this issue, we develop a validation method, and show how ensemble models can exploit SMATCH metric weaknesses to obtain higher scores, but sometimes result in corrupted graphs. Additionally, we highlight the demanding need to compute the SMATCH score among all possible predictions. To overcome these challenges, we propose two novel ensemble strategies based on Transformer models, improving robustness to structural constraints, while also reducing the computational time. Our methods provide new insights for enhancing AMR parsers and metrics. Our code is available at [https://www.github.com/babelscape/AMRs-Assemble](https://www.github.com/babelscape/AMRs-Assemble). | Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Roberto Navigli |  |
| 314 |  |  [MolXPT: Wrapping Molecules with Text for Generative Pre-training](https://doi.org/10.18653/v1/2023.acl-short.138) |  | 0 | Generative pre-trained Transformer (GPT) has demonstrates its great success in natural language processing and related techniques have been adapted into molecular modeling. Considering that text is the most important record for scientific discovery, in this paper, we propose MolXPT, a unified language model of text and molecules pre-trained on SMILES (a sequence representation of molecules) wrapped by text. Briefly, we detect the molecule names in each sequence and replace them to the corresponding SMILES. In this way, the SMILES could leverage the information from surrounding text, and vice versa. The above wrapped sequences, text sequences from PubMed and SMILES sequences from PubChem are all fed into a language model for pre-training. Experimental results demonstrate that MolXPT outperforms strong baselines of molecular property prediction on MoleculeNet, performs comparably to the best model in text-molecule translation while using less than half of its parameters, and enables zero-shot molecular generation without finetuning. | Zequn Liu, Wei Zhang, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Ming Zhang, TieYan Liu |  |
| 315 |  |  [A Study on the Efficiency and Generalization of Light Hybrid Retrievers](https://doi.org/10.18653/v1/2023.acl-short.139) |  | 0 | Hybrid retrievers can take advantage of both sparse and dense retrievers. Previous hybrid retrievers leverage indexing-heavy dense retrievers. In this work, we study “Is it possible to reduce the indexing memory of hybrid retrievers without sacrificing performance”? Driven by this question, we leverage an indexing-efficient dense retriever (i.e. DrBoost) and introduce a LITE retriever that further reduces the memory of DrBoost. LITE is jointly trained on contrastive learning and knowledge distillation from DrBoost. Then, we integrate BM25, a sparse retriever, with either LITE or DrBoost to form light hybrid retrievers. Our Hybrid-LITE retriever saves 13× memory while maintaining 98.0% performance of the hybrid retriever of BM25 and DPR. In addition, we study the generalization capacity of our light hybrid retrievers on out-of-domain dataset and a set of adversarial attacks datasets. Experiments showcase that light hybrid retrievers achieve better generalization performance than individual sparse and dense retrievers. Nevertheless, our analysis shows that there is a large room to improve the robustness of retrievers, suggesting a new research direction. | Man Luo, Shashank Jain, Anchit Gupta, Arash Einolghozati, Barlas Oguz, Debojeet Chatterjee, Xilun Chen, Chitta Baral, Peyman Heidari |  |
| 316 |  |  [The Mechanical Bard: An Interpretable Machine Learning Approach to Shakespearean Sonnet Generation](https://doi.org/10.18653/v1/2023.acl-short.140) |  | 0 | We consider the automated generation of sonnets, a poetic form constrained according to meter, rhyme scheme, and length. Sonnets generally also use rhetorical figures, expressive language, and a consistent theme or narrative. Our constrained decoding approach allows for the generation of sonnets within preset poetic constraints, while using a relatively modest neural backbone. Human evaluation confirms that our approach produces Shakespearean sonnets that resemble human-authored sonnets, and which adhere to the genre’s defined constraints and contain lyrical language and literary devices. | Edwin Agnew, Michelle Qiu, Lily Zhu, Sam Wiseman, Cynthia Rudin |  |
| 317 |  |  [When to Use Efficient Self Attention? Profiling Text, Speech and Image Transformer Variants](https://doi.org/10.18653/v1/2023.acl-short.141) |  | 0 | We present the first unified study of the efficiency of self-attention-based Transformer variants spanning text, speech and vision. We identify input length thresholds (tipping points) at which efficient Transformer variants become more efficient than vanilla models, using a variety of efficiency metrics (latency, throughput, and memory). To conduct this analysis for speech, we introduce L-HuBERT, a novel local-attention variant of a self-supervised speech model. We observe that these thresholds are (a) much higher than typical dataset sequence lengths and (b) dependent on the metric and modality, showing that choosing the right model depends on modality, task type (long-form vs. typical context) and resource constraints (time vs. memory). By visualising the breakdown of the computational costs for transformer components, we also show that non-self-attention components exhibit significant computational costs. We release our profiling toolkit at https://github.com/ajd12342/profiling-transformers . | Anuj Diwan, Eunsol Choi, David Harwath |  |
| 318 |  |  [Evaluating Zero-Shot Event Structures: Recommendations for Automatic Content Extraction (ACE) Annotations](https://doi.org/10.18653/v1/2023.acl-short.142) |  | 0 | Zero-shot event extraction (EE) methods infer richly structured event records from text, based only on a minimal user specification and no training examples, which enables flexibility in exploring and developing applications. Most event extraction research uses the Automatic Content Extraction (ACE) annotated dataset to evaluate supervised EE methods, but can it be used to evaluate zero-shot and other low-supervision EE? We describe ACE’s event structures and identify significant ambiguities and issues in current evaluation practice, including (1) coreferent argument mentions, (2) conflicting argument head conventions, and (3) ignorance of modality and event class details. By sometimes mishandling these subtleties, current work may dramatically understate the actual performance of zero-shot and other low-supervision EE, considering up to 32% of correctly identified arguments and 25% of correctly ignored event mentions as false negatives. For each issue, we propose recommendations for future evaluations so the research community can better utilize ACE as an event evaluation resource. | Erica Cai, Brendan T. O'Connor |  |
| 319 |  |  [Event Extraction as Question Generation and Answering](https://doi.org/10.18653/v1/2023.acl-short.143) |  | 0 | Recent work on Event Extraction has reframed the task as Question Answering (QA), with promising results. The advantage of this approach is that it addresses the error propagation issue found in traditional token-based classification approaches by directly predicting event arguments without extracting candidates first. However, the questions are typically based on fixed templates and they rarely leverage contextual information such as relevant arguments. In addition, prior QA-based approaches have difficulty handling cases where there are multiple arguments for the same role. In this paper, we propose QGA-EE, which enables a Question Generation (QG) model to generate questions that incorporate rich contextual information instead of using fixed templates. We also propose dynamic templates to assist the training of QG model. Experiments show that QGA-EE outperforms all prior single-task-based models on the ACE05 English dataset. | Di Lu, Shihao Ran, Joel R. Tetreault, Alejandro Jaimes |  |
| 320 |  |  [Are Sample-Efficient NLP Models More Robust?](https://doi.org/10.18653/v1/2023.acl-short.144) |  | 0 | Recent results in image classification and extractive question answering have observed that pre-trained models trained on less in-distribution data have better out-ofdistribution performance. However, it is unclear how broadly these trends hold. We conduct a large empirical study across three tasks, three broadly-applicable modeling interventions (increasing model size, using a different adaptation method, and pre-training on more data), and 14 diverse datasets to investigate the relationship between sample efficiency (amount of data needed to reach a given ID accuracy) and robustness (how models fare on OOD evaluation). We find that higher sample efficiency is only correlated with better average OOD robustness on some modeling interventions and tasks, but not others. On individual datasets, models with lower sample efficiency can even be more robust. These results suggest that general-purpose methods for improving sample efficiency are unlikely to yield universal OOD robustness improvements, since such improvements are highly dataset- and task-dependent. Even in an era of large, multi-purpose pre-trained models, task-specific decisions may often be necessary for OOD generalization. | Nelson F. Liu, Ananya Kumar, Percy Liang, Robin Jia |  |
| 321 |  |  [Diversity-Aware Coherence Loss for Improving Neural Topic Models](https://doi.org/10.18653/v1/2023.acl-short.145) |  | 0 | The standard approach for neural topic modeling uses a variational autoencoder (VAE) framework that jointly minimizes the KL divergence between the estimated posterior and prior, in addition to the reconstruction loss. Since neural topic models are trained by recreating individual input documents, they do not explicitly capture the coherence between words on the corpus level. In this work, we propose a novel diversity-aware coherence loss that encourages the model to learn corpus-level coherence scores while maintaining high diversity between topics. Experimental results on multiple datasets show that our method significantly improves the performance of neural topic models without requiring any pretraining or additional parameters. | Raymond Li, Felipe GonzálezPizarro, Linzi Xing, Gabriel Murray, Giuseppe Carenini |  |
| 322 |  |  [NarrowBERT: Accelerating Masked Language Model Pretraining and Inference](https://doi.org/10.18653/v1/2023.acl-short.146) |  | 0 | Large-scale language model pretraining is a very successful form of self-supervised learning in natural language processing, but it is increasingly expensive to perform as the models and pretraining corpora have become larger over time. We propose NarrowBERT, a modified transformer encoder that increases the throughput for masked language model pretraining by more than 2x. NarrowBERT sparsifies the transformer model such that the self-attention queries and feedforward layers only operate on the masked tokens of each sentence during pretraining, rather than all of the tokens as with the usual transformer encoder. We also show that NarrowBERT increases the throughput at inference time by as much as 3.5x with minimal (or no) performance degradation on sentence encoding tasks like MNLI. Finally, we examine the performance of NarrowBERT on the IMDB and Amazon reviews classification and CoNLL NER tasks and show that it is also comparable to standard BERT performance. | Haoxin Li, Phillip Keung, Daniel Cheng, Jungo Kasai, Noah A. Smith |  |
| 323 |  |  [S3HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering](https://doi.org/10.18653/v1/2023.acl-short.147) |  | 0 | Answering multi-hop questions over hybrid factual knowledge from the given text and table (TextTableQA) is a challenging task. Existing models mainly adopt a retriever-reader framework, which have several deficiencies, such as noisy labeling in training retriever, insufficient utilization of heterogeneous information over text and table, and deficient ability for different reasoning operations. In this paper, we propose a three-stage TextTableQA framework S3HQA, which comprises of retriever, selector, and reasoner. We use a retriever with refinement training to solve the noisy labeling problem. Then, a hybrid selector considers the linked relationships between heterogeneous data to select the most relevant factual knowledge. For the final stage, instead of adapting a reading comprehension module like in previous methods, we employ a generation-based reasoner to obtain answers. This includes two approaches: a row-wise generator and an LLM prompting generator (first time used in this task). The experimental results demonstrate that our method achieves competitive results in the few-shot setting. When trained on the full dataset, our approach outperforms all baseline methods, ranking first on the HybridQA leaderboard. | Fangyu Lei, Xiang Li, Yifan Wei, Shizhu He, Yiming Huang, Jun Zhao, Kang Liu |  |
| 324 |  |  [Towards Fewer Hallucinations in Knowledge-Grounded Dialogue Generation via Augmentative and Contrastive Knowledge-Dialogue](https://doi.org/10.18653/v1/2023.acl-short.148) |  | 0 | Existing knowledge-grounded open-domain dialogue generation models often face the hallucination problem, i.e. the dialogue generative model will persist in an inappropriate knowledge and generate responses that inconsistent with the facts. We argue that this problem mainly stems from the polarized optimization objectives and weak knowledge generation ability. To mitigate the hallucination, we take inspiration from human communicating that people will replay euphemistic responses for the unclear or unrecognizable knowledge, and propose an Augmentative and Contrastive Knowledge Dialogue Expansion Framework (ACK-DEF). ACK-DEF constructs the augmentative and contrastive knowledge dialogue samples, which consist of the knowledge of different degrees of errors and the response of manual design, to expand the original training set and smooth the polarized optimization objective that enables models to generate ground-truth with or without gold knowledge. Not only the knowledge, ACK-DEF also provides the tactful responses of manual design corresponding to the incomplete correct knowledge. Experimental results on the Wikipedia of Wizard dataset show that employing the ACK-DEF is effective to alleviate the hallucination problem. | Bin Sun, Yitong Li, Fei Mi, Fanhu Bie, Yiwei Li, Kan Li |  |
| 325 |  |  [AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models](https://doi.org/10.18653/v1/2023.acl-short.149) |  | 0 | Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research. | Siheng Li, Cheng Yang, Yichun Yin, Xinyu Zhu, Zesen Cheng, Lifeng Shang, Xin Jiang, Qun Liu, Yujiu Yang |  |
| 326 |  |  [STT4SG-350: A Speech Corpus for All Swiss German Dialect Regions](https://doi.org/10.18653/v1/2023.acl-short.150) |  | 0 | We present STT4SG-350, a corpus of Swiss German speech, annotated with Standard German text at the sentence level. The data is collected using a web app in which the speakers are shown Standard German sentences, which they translate to Swiss German and record. We make the corpus publicly available. It contains 343 hours of speech from all dialect regions and is the largest public speech corpus for Swiss German to date. Application areas include automatic speech recognition (ASR), text-to-speech, dialect identification, and speaker recognition. Dialect information, age group, and gender of the 316 speakers are provided. Genders are equally represented and the corpus includes speakers of all ages. Roughly the same amount of speech is provided per dialect region, which makes the corpus ideally suited for experiments with speech technology for different dialects. We provide training, validation, and test splits of the data. The test set consists of the same spoken sentences for each dialect region and allows a fair evaluation of the quality of speech technologies in different dialects. We train an ASR model on the training set and achieve an average BLEU score of 74.7 on the test set. The model beats the best published BLEU scores on 2 other Swiss German ASR test sets, demonstrating the quality of the corpus. | Michel Plüss, Jan Deriu, Yanick Schraner, Claudio Paonessa, Julia Hartmann, Larissa Schmidt, Christian Scheller, Manuela Hürlimann, Tanja Samardzic, Manfred Vogel, Mark Cieliebak |  |
| 327 |  |  [Teaching Small Language Models to Reason](https://doi.org/10.18653/v1/2023.acl-short.151) |  | 0 | Chain of thought prompting successfully improves the reasoning capabilities of large language models, achieving state of the art results on a range of datasets. However, these reasoning capabilities only appear to emerge in models with at least tens of billions of parameters. In this paper, we explore the transfer of such reasoning capabilities to smaller models via knowledge distillation, also investigating model and dataset size trade-off. Specifically, we finetune a student model on the chain of thought outputs generated by a larger teacher model. Our experiments show that the proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets. For example, the accuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% and 18.42% when finetuned on PaLM 540B and GPT-3 175B generated chains of thought, respectively. | Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adámek, Eric Malmi, Aliaksei Severyn |  |
| 328 |  |  [A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification](https://doi.org/10.18653/v1/2023.acl-short.152) |  | 0 | In recent years, large language models (LLMs) have achieved strong performance on benchmark tasks, especially in zero or few-shot settings. However, these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. In order to address this challenge, we propose refactoring conventional tasks on hierarchical datasets into a more indicative long-tail prediction task. We observe LLMs are more prone to failure in these cases. To address these limitations, we propose the use of entailment-contradiction prediction in conjunction with LLMs, which allows for strong performance in a strict zero-shot setting. Importantly, our method does not require any parameter updates, a resource-intensive process and achieves strong performance across multiple datasets. | Rohan Bhambhoria, Lei Chen, Xiaodan Zhu |  |
| 329 |  |  [A Simple Concatenation can Effectively Improve Speech Translation](https://doi.org/10.18653/v1/2023.acl-short.153) |  | 0 | A triple speech translation data comprises speech, transcription, and translation. In the end-to-end paradigm, text machine translation (MT) usually plays the role of a teacher model for the speech translation (ST) via knowledge distillation. Parameter sharing with the teacher is often adopted to construct the ST model architecture, however, the two modalities are independently fed and trained via different losses. This situation does not match ST’s properties across two modalities and also limits the upper bound of the performance. Inspired by the works of video Transformer, we propose a simple unified cross-modal ST method, which concatenates speech and text as the input, and builds a teacher that can utilize both cross-modal information simultaneously. Experimental results show that in our unified ST framework, models can effectively utilize the auxiliary information from speech and text, and achieve compelling results on MuST-C datasets. | Linlin Zhang, Kai Fan, Boxing Chen, Luo Si |  |
| 330 |  |  [ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning](https://doi.org/10.18653/v1/2023.acl-short.154) |  | 0 | A number of recent benchmarks seek to assess how well models handle natural language negation. However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope. To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and in-context learning strategies. We find that RoBERTa and DeBERTa models solve ScoNe-NLI after many shot fine-tuning. For in-context learning, we test the latest InstructGPT models and find that most prompt strategies are not successful, including those using step-by-step reasoning. To better understand this result, we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds negation reasoning in short narratives. Here, InstructGPT is successful, which reveals the model can correctly reason about negation, but struggles to do so on NLI examples outside of its core pretraining regime. | Jingyuan Selena She, Christopher Potts, Samuel R. Bowman, Atticus Geiger |  |
| 331 |  |  [Revisiting Automated Prompting: Are We Actually Doing Better?](https://doi.org/10.18653/v1/2023.acl-short.155) |  | 0 | Current literature demonstrates that Large Language Models (LLMs) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. An attempt to automate human-led prompting followed, with some progress achieved. In particular, subsequent work demonstrates that automation can outperform fine-tuning in certain K-shot learning scenarios. In this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of K-shot learning settings. We find that automated prompting does not consistently outperform simple manual prompting. Our work suggests that, in addition to fine-tuning, manual prompting should be used as a baseline in this line of research. | Yulin Zhou, Yiren Zhao, Ilia Shumailov, Robert D. Mullins, Yarin Gal |  |
| 332 |  |  [Mind the Gap between the Application Track and the Real World](https://doi.org/10.18653/v1/2023.acl-short.156) |  | 0 | Recent advances in NLP have led to a rise in inter-disciplinary and application-oriented research. While this demonstrates the growing real-world impact of the field, research papers frequently feature experiments that do not account for the complexities of realistic data and environments. To explore the extent of this gap, we investigate the relationship between the real-world motivations described in NLP papers and the models and evaluation which comprise the proposed solution. We first survey papers from the NLP Applications track from ACL 2020 and EMNLP 2020, asking which papers have differences between their stated motivation and their experimental setting, and if so, mention them. We find that many papers fall short of considering real-world input and output conditions due to adopting simplified modeling or evaluation settings. As a case study, we then empirically show that the performance of an educational dialog understanding system deteriorates when used in a realistic classroom environment. | Ananya Ganesh, Jie Cao, E. Margaret Perkoff, Rosy Southwell, Martha Palmer, Katharina Kann |  |
| 333 |  |  [How to Distill your BERT: An Empirical Study on the Impact of Weight Initialisation and Distillation Objectives](https://doi.org/10.18653/v1/2023.acl-short.157) |  | 0 | Recently, various intermediate layer distillation (ILD) objectives have been shown to improve compression of BERT models via Knowledge Distillation (KD). However, a comprehensive evaluation of the objectives in both task-specific and task-agnostic settings is lacking. To the best of our knowledge, this is the first work comprehensively evaluating distillation objectives in both settings. We show that attention transfer gives the best performance overall. We also study the impact of layer choice when initializing the student from the teacher layers, finding a significant impact on the performance in task-specific distillation. For vanilla KD and hidden states transfer, initialisation with lower layers of the teacher gives a considerable improvement over higher layers, especially on the task of QNLI (up to an absolute percentage change of 17.8 in accuracy). Attention transfer behaves consistently under different initialisation settings. We release our code as an efficient transformer-based model distillation framework for further studies. | Xinpeng Wang, Leonie Weissweiler, Hinrich Schütze, Barbara Plank |  |
| 334 |  |  [ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.acl-short.158) |  | 0 | Self-supervised knowledge-graph completion (KGC) relies on estimating a scoring model over (entity, relation, entity)-tuples, for example, by embedding an initial knowledge graph. Prediction quality can be improved by calibrating the scoring model, typically by adjusting the prediction thresholds using manually annotated examples. In this paper, we attempt for the first time cold-start calibration for KGC, where no annotated examples exist initially for calibration, and only a limited number of tuples can be selected for annotation. Our new method ACTC finds good per-relation thresholds efficiently based on a limited set of annotated tuples. Additionally to a few annotated tuples, ACTC also leverages unlabeled tuples by estimating their correctness with Logistic Regression or Gaussian Process classifiers. We also experiment with different methods for selecting candidate tuples for annotation: density-based and random selection. Experiments with five scoring models and an oracle annotator show an improvement of 7% points when using ACTC in the challenging setting with an annotation budget of only 10 tuples, and an average improvement of 4% points over different budgets. | Anastasiia Sedova, Benjamin Roth |  |
| 335 |  |  [Task-Aware Specialization for Efficient and Robust Dense Retrieval for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.acl-short.159) |  | 0 | Given its effectiveness on knowledge-intensive natural language processing tasks, dense retrieval models have become increasingly popular. Specifically, the de-facto architecture for open-domain question answering uses two isomorphic encoders that are initialized from the same pretrained model but separately parameterized for questions and passages. This biencoder architecture is parameter-inefficient in that there is no parameter sharing between encoders. Further, recent studies show that such dense retrievers underperform BM25 in various settings. We thus propose a new architecture, Task-Aware Specialization for dEnse Retrieval (TASER), which enables parameter sharing by interleaving shared and specialized blocks in a single encoder. Our experiments on five question answering datasets show that TASER can achieve superior accuracy, surpassing BM25, while using about 60% of the parameters as bi-encoder dense retrievers. In out-of-domain evaluations, TASER is also empirically more robust than bi-encoder dense retrievers. Our code is available at https://github.com/microsoft/taser. | Hao Cheng, Hao Fang, Xiaodong Liu, Jianfeng Gao |  |
| 336 |  |  [Linear Classifier: An Often-Forgotten Baseline for Text Classification](https://doi.org/10.18653/v1/2023.acl-short.160) |  | 0 | Large-scale pre-trained language models such as BERT are popular solutions for text classification. Due to the superior performance of these advanced methods, nowadays, people often directly train them for a few epochs and deploy the obtained model. In this opinion paper, we point out that this way may only sometimes get satisfactory results. We argue the importance of running a simple baseline like linear classifiers on bag-of-words features along with advanced methods. First, for many text data, linear methods show competitive performance, high efficiency, and robustness. Second, advanced models such as BERT may only achieve the best results if properly applied. Simple baselines help to confirm whether the results of advanced models are acceptable. Our experimental results fully support these points. | YuChen Lin, SiAn Chen, JieJyun Liu, ChihJen Lin |  |
| 337 |  |  [Randomized Positional Encodings Boost Length Generalization of Transformers](https://doi.org/10.18653/v1/2023.acl-short.161) |  | 0 | Transformers have impressive generalization capabilities on tasks with a fixed context length. However, they fail to generalize to sequences of arbitrary length, even for seemingly simple tasks such as duplicating a string. Moreover, simply training on longer sequences is inefficient due to the quadratic computation complexity of the global attention mechanism. In this work, we demonstrate that this failure mode is linked to positional encodings being out-of-distribution for longer sequences (even for relative encodings) and introduce a novel family of positional encodings that can overcome this problem. Concretely, our randomized positional encoding scheme simulates the positions of longer sequences and randomly selects an ordered subset to fit the sequence’s length. Our large-scale empirical evaluation of 6000 models across 15 algorithmic reasoning tasks shows that our method allows Transformers to generalize to sequences of unseen length (increasing test accuracy by 12.0% on average). | Anian Ruoss, Grégoire Delétang, Tim Genewein, Jordi GrauMoya, Róbert Csordás, Mehdi Bennani, Shane Legg, Joel Veness |  |
| 338 |  |  [Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models](https://doi.org/10.18653/v1/2023.acl-short.162) |  | 0 | In this paper, we propose a table and image generation task to verify how the knowledge about entities acquired from natural language is retained in Vision & Language (V & L) models. This task consists of two parts: the first is to generate a table containing knowledge about an entity and its related image, and the second is to generate an image from an entity with a caption and a table containing related knowledge of the entity. In both tasks, the model must know the entities used to perform the generation properly. We created the Wikipedia Table and Image Generation (WikiTIG) dataset from about 200,000 infoboxes in English Wikipedia articles to perform the proposed tasks. We evaluated the performance on the tasks with respect to the above research question using the V & L model OFA, which has achieved state-of-the-art results in multiple tasks. Experimental results show that OFA forgets part of its entity knowledge by pre-training as a complement to improve the performance of image related tasks. | Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe |  |
| 339 |  |  [Improving Grammar-based Sequence-to-Sequence Modeling with Decomposition and Constraints](https://doi.org/10.18653/v1/2023.acl-short.163) |  | 0 | Neural QCFG is a grammar-based sequence-to-sequence model with strong inductive biases on hierarchical structures. It excels in interpretability and generalization but suffers from expensive inference. In this paper, we study two low-rank variants of Neural QCFG for faster inference with different trade-offs between efficiency and expressiveness. Furthermore, utilizing the symbolic interface provided by the grammar, we introduce two soft constraints over tree hierarchy and source coverage. We experiment with various datasets and find that our models outperform vanilla Neural QCFG in most settings. | Chao Lou, Kewei Tu |  |
| 340 |  |  [TeCS: A Dataset and Benchmark for Tense Consistency of Machine Translation](https://doi.org/10.18653/v1/2023.acl-short.164) |  | 0 | Tense inconsistency frequently occurs in machine translation. However, there are few criteria to assess the model’s mastery of tense prediction from a linguistic perspective. In this paper, we present a parallel tense test set, containing French-English 552 utterances. We also introduce a corresponding benchmark, tense prediction accuracy. With the tense test set and the benchmark, researchers are able to measure the tense consistency performance of machine translation systems for the first time. | Yiming Ai, Zhiwei He, Kai Yu, Rui Wang |  |
| 341 |  |  [Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023](https://aclanthology.org/volumes/2023.findings-acl/) |  | 0 |  | Anna Rogers, Jordan L. BoydGraber, Naoaki Okazaki |  |
| 342 |  |  [Frontmatter](https://aclanthology.org/2023.findings-acl.0) |  | 0 |  |  |  |
| 343 |  |  [Investigating Glyph-Phonetic Information for Chinese Spell Checking: What Works and What's Next?](https://doi.org/10.18653/v1/2023.findings-acl.1) |  | 0 | While pre-trained Chinese language models have demonstrated impressive performance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task remains a challenge. Previous research has explored using information such as glyphs and phonetics to improve the ability of CSC models to distinguish misspelled characters, with good results at the accuracy level on public datasets. However, the generalization ability of these CSC models has not been well understood: it is unclear whether they incorporate glyph-phonetic information and, if so, whether this information is fully utilized. In this paper, we aim to better understand the role of glyph-phonetic information in the CSC task and suggest directions for improvement. Additionally, we propose a new, more challenging, and practical setting for testing the generalizability of CSC models. All code is made publicly available. | Xiaotian Zhang, Yanjun Zheng, Hang Yan, Xipeng Qiu |  |
| 344 |  |  [A Self-Supervised Integration Method of Pretrained Language Models and Word Definitions](https://doi.org/10.18653/v1/2023.findings-acl.2) |  | 0 | We investigate the representation of pretrained language models and humans, using the idea of word definition modeling–how well a word is represented by its definition, and vice versa. Our analysis shows that a word representation in pretrained language models does not successfully map its human-written definition and its usage in example sentences. We then present a simple method DefBERT that integrates pretrained models with word semantics in dictionaries. We show its benefits on newly-proposed tasks of definition ranking and definition sense disambiguation. Furthermore, we present the results on standard word similarity tasks and short text classification tasks where models are required to encode semantics with only a few words. The results demonstrate the effectiveness of integrating word definitions and pretrained language models. | Hwiyeol Jo |  |
| 345 |  |  [Conformal Nucleus Sampling](https://doi.org/10.18653/v1/2023.findings-acl.3) |  | 0 | Language models generate text based on successively sampling the next word. A decoding procedure based on nucleus (top-p) sampling chooses from the smallest possible set of words whose cumulative probability exceeds the probability p. In this work, we assess whether a top-p set is indeed aligned with its probabilistic meaning in various linguistic contexts.We employ conformal prediction, a calibration procedure that focuses on the construction of minimal prediction sets according to a desired confidence level, to calibrate the parameter p as a function of the entropy of the next word distribution. We find that OPT models are overconfident, and that calibration shows a moderate inverse scaling with model size. | Shauli Ravfogel, Yoav Goldberg, Jacob Goldberger |  |
| 346 |  |  [DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.findings-acl.4) |  | 0 | Implicit Discourse Relation Recognition (IDRR) is a sophisticated and challenging task to recognize the discourse relations between the arguments with the absence of discourse connectives. The sense labels for each discourse relation follow a hierarchical classification scheme in the annotation process (Prasad et al., 2008), forming a hierarchy structure. Most existing works do not well incorporate the hierarchy structure but focus on the syntax features and the prior knowledge of connectives in the manner of pure text classification. We argue that it is more effective to predict the paths inside the hierarchical tree (e.g., “Comparison -> Contrast -> however”) rather than flat labels (e.g., Contrast) or connectives (e.g., however). We propose a prompt-based path prediction method to utilize the interactive information and intrinsic senses among the hierarchy in IDRR. This is the first work that injects such structure information into pre-trained language models via prompt tuning, and the performance of our solution shows significant and consistent improvement against competitive baselines. | Chunkit Chan, Xin Liu, Jiayang Cheng, Zihan Li, Yangqiu Song, Ginny Y. Wong, Simon See |  |
| 347 |  |  [Modularized Zero-shot VQA with Pre-trained Models](https://doi.org/10.18653/v1/2023.findings-acl.5) |  | 0 | Large-scale pre-trained models (PTMs) show great zero-shot capabilities. In this paper, we study how to leverage them for zero-shot visual question answering (VQA).Our approach is motivated by a few observations. First, VQA questions often require multiple steps of reasoning, which is still a capability that most PTMs lack. Second, different steps in VQA reasoning chains require different skills such as object detection and relational reasoning, but a single PTM may not possess all these skills. Third, recent work on zero-shot VQA does not explicitly consider multi-step reasoning chains, which makes them less interpretable compared with a decomposition-based approach. We propose a modularized zero-shot network that explicitly decomposes questions into sub reasoning steps and is highly interpretable. We convert sub reasoning tasks to acceptable objectives of PTMs and assign tasks to proper PTMs without any adaptation. Our experiments on two VQA benchmarks under the zero-shot setting demonstrate the effectiveness of our method and better interpretability compared with several baselines. | Rui Cao, Jing Jiang |  |
| 348 |  |  [TimelineQA: A Benchmark for Question Answering over Timelines](https://doi.org/10.18653/v1/2023.findings-acl.6) |  | 0 | Lifelogs are descriptions of experiences that a person had during their life. Lifelogs are created by fusing data from the multitude of digital services, such as online photos, maps, shopping and content streaming services. Question answering over lifelogs can offer personal assistants a critical resource when they try to provide advice in context. However, obtaining answers to questions over lifelogs is beyond the current state of the art of question answering techniques for a variety of reasons, the most pronounced of which is that lifelogs combine free text with some degree of structure such as temporal and geographical information. We create and publicly release TimelineQA, a benchmark for accelerating progress on querying lifelogs. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We describe a set of experiments on TimelineQA with several state-of-the-art QA models. Our experiments reveal that for atomic queries, an extractive QA system significantly out-performs a state-of-the-art retrieval-augmented QA system. For multi-hop queries involving aggregates, we show that the best result is obtained with a state-of-the-art table QA technique, assuming the ground truth set of episodes for deriving the answer is available. | WangChiew Tan, Jane DwivediYu, Yuliang Li, Lambert Mathias, Marzieh Saeidi, Jing Nathan Yan, Alon Y. Halevy |  |
| 349 |  |  [Abstractive Text Summarization Using the BRIO Training Paradigm](https://doi.org/10.18653/v1/2023.findings-acl.7) |  | 0 | Summary sentences produced by abstractive summarization models may be coherent and comprehensive, but they lack control and rely heavily on reference summaries. The BRIO training paradigm assumes a non-deterministic distribution to reduce the model’s dependence on reference summaries, and improve model performance during inference. This paper presents a straightforward but effective technique to improve abstractive summaries by fine-tuning pre-trained language models, and training them with the BRIO paradigm. We build a text summarization dataset for Vietnamese, called VieSum. We perform experiments with abstractive summarization models trained with the BRIO paradigm on the CNNDM and the VieSum datasets. The results show that the models, trained on basic hardware, outperform all existing abstractive summarization models, especially for Vietnamese. | Khang Nhut Lam, Thieu Gia Doan, Khang Thua Pham, Jugal Kalita |  |
| 350 |  |  [Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization](https://doi.org/10.18653/v1/2023.findings-acl.8) |  | 0 | Models trained with empirical risk minimization (ERM) are revealed to easily rely on spurious correlations, resulting in poor generalization. Group distributionally robust optimization (group DRO) can alleviate this problem by minimizing the worst-case loss over pre-defined groups. While promising, in practice factors like expensive annotations and privacy preclude the availability of group labels. More crucially, when taking a closer look at the failure modes of out-of-distribution generalization, the typical procedure of reweighting in group DRO loses efficiency. Hinged on the limitations, in this work, we reformulate the group DRO framework by proposing Q-Diversity. Characterized by an interactive training mode, Q-Diversity relaxes the group identification from annotation into direct parameterization. Furthermore, a novel mixing strategy across groups is presented to diversify the under-represented groups. In a series of experiments on both synthetic and real-world text classification tasks, results demonstrate that Q-Diversity can consistently improve worst-case accuracy under different distributional shifts, outperforming state-of-the-art alternatives. | Ting Wu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 351 |  |  [Pre-training Language Model as a Multi-perspective Course Learner](https://doi.org/10.18653/v1/2023.findings-acl.9) |  | 0 | ELECTRA, the generator-discriminator pre-training framework, has achieved impressive semantic construction capability among various downstream tasks. Despite the convincing performance, ELECTRA still faces the challenges of monotonous training and deficient interaction. Generator with only masked language modeling (MLM) leads to biased learning and label imbalance for discriminator, decreasing learning efficiency; no explicit feedback loop from discriminator to generator results in the chasm between these two components, underutilizing the course learning. In this study, a multi-perspective course learning (MCL) method is proposed to fetch a many degrees and visual angles for sample-efficient pre-training, and to fully leverage the relationship between generator and discriminator. Concretely, three self-supervision courses are designed to alleviate inherent flaws of MLM and balance the label in a multi-perspective way. Besides, two self-correction courses are proposed to bridge the chasm between the two encoders by creating a “correction notebook” for secondary-supervision. Moreover, a course soups trial is conducted to solve the “tug-of-war” dynamics problem of MCL, evolving a stronger pre-trained model. Experimental results show that our method significantly improves ELECTRA’s average performance by 2.8% and 3.2% absolute points respectively on GLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style models under the same settings. The pre-trained MCL model is available at https://huggingface.co/McmanusChen/MCL-base. | Beiduo Chen, Shaohan Huang, Zihan Zhang, Wu Guo, Zhenhua Ling, Haizhen Huang, Furu Wei, Weiwei Deng, Qi Zhang |  |
| 352 |  |  [Layerwise universal adversarial attack on NLP models](https://doi.org/10.18653/v1/2023.findings-acl.10) |  | 0 | In this work, we examine the vulnerability of language models to universal adversarial triggers (UATs). We propose a new white-box approach to the construction of layerwise UATs (LUATs), which searches the triggers by perturbing hidden layers of a network. On the example of three transformer models and three datasets from the GLUE benchmark, we demonstrate that our method provides better transferability in a model-to-model setting with an average gain of 9.3% in the fooling rate over the baseline. Moreover, we investigate triggers transferability in the task-to-task setting. Using small subsets from the datasets similar to the target tasks for choosing a perturbed layer, we show that LUATs are more efficient than vanilla UATs by 7.1% in the fooling rate. | Olga Tsymboi, Danil Malaev, Andrei Petrovskii, Ivan V. Oseledets |  |
| 353 |  |  [Scene-robust Natural Language Video Localization via Learning Domain-invariant Representations](https://doi.org/10.18653/v1/2023.findings-acl.11) |  | 0 | Natural language video localization(NLVL) task involves the semantic matching of a text query with a moment from an untrimmed video. Previous methods primarily focus on improving performance with the assumption of independently identical data distribution while ignoring the out-of-distribution data. Therefore, these approaches often fail when handling the videos and queries in novel scenes, which is inevitable in real-world scenarios. In this paper, we, for the first time, formulate the scene-robust NLVL problem and propose a novel generalizable NLVL framework utilizing data in multiple available scenes to learn a robust model. Specifically, our model learns a group of generalizable domain-invariant representations by alignment and decomposition. First, we propose a comprehensive intra- and inter-sample distance metric for complex multi-modal feature space, and an asymmetric multi-modal alignment loss for different information densities of text and vision. Further, to alleviate the conflict between domain-invariant features for generalization and domain-specific information for reasoning, we introduce domain-specific and domain-agnostic predictors to decompose and refine the learned features by dynamically adjusting the weights of samples. Based on the original video tags, we conduct extensive experiments on three NLVL datasets with different-grained scene shifts to show the effectiveness of our proposed methods. | Zehan Wang, Yang Zhao, Haifeng Huang, Yan Xia, Zhou Zhao |  |
| 354 |  |  [Exploiting Pseudo Image Captions for Multimodal Summarization](https://doi.org/10.18653/v1/2023.findings-acl.12) |  | 0 | Multimodal summarization with multimodal output (MSMO) faces a challenging semantic gap between visual and textual modalities due to the lack of reference images for training. Our pilot investigation indicates that image captions, which naturally connect texts and images, can significantly benefit MSMO. However, exposure of image captions during training is inconsistent with MSMO’s task settings, where prior cross-modal alignment information is excluded to guarantee the generalization of cross-modal semantic modeling. To this end, we propose a novel coarse-to-fine image-text alignment mechanism to identify the most relevant sentence of each image in a document, resembling the role of image captions in capturing visual knowledge and bridging the cross-modal semantic gap. Equipped with this alignment mechanism, our method easily yet impressively sets up state-of-the-art performances on all intermodality and intramodality metrics (e.g., more than 10% relative improvement on image recommendation precision). Further experiments reveal the correlation between image captions and text summaries, and prove that the pseudo image captions we generated are even better than the original ones in terms of promoting multimodal summarization. | Chaoya Jiang, Rui Xie, Wei Ye, Jinan Sun, Shikun Zhang |  |
| 355 |  |  [Cross-Lingual Transfer with Target Language-Ready Task Adapters](https://doi.org/10.18653/v1/2023.findings-acl.13) |  | 0 | Adapters have emerged as a modular and parameter-efficient approach to (zero-shot) cross-lingual transfer. The established MAD-X framework employs separate language and task adapters which can be arbitrarily combined to perform the transfer of any task to any target language. Subsequently, BAD-X, an extension of the MAD-X framework, achieves improved transfer at the cost of MAD-X’s modularity by creating ‘bilingual’ adapters specific to the source-target language pair. In this work, we aim to take the best of both worlds by (i) fine-tuning \*task\* adapters adapted to the target language(s) (so-called \*‘target language-ready’ (TLR)\* adapters) to maintain high transfer performance, but (ii) without sacrificing the highly modular design of MAD-X. The main idea of ‘target language-ready’ adapters is to resolve the training-vs-inference discrepancy of MAD-X: the task adapter ‘sees’ the target language adapter for the very first time during inference, and thus might not be fully compatible with it. We address this mismatch by exposing the task adapter to the target language adapter during training, and empirically validate several variants of the idea: in the simplest form, we alternate between using the source and target language adapters during task adapter training, which can be generalized to cycling over any set of language adapters. We evaluate different TLR-based transfer configurations with varying degrees of generality across a suite of standard cross-lingual benchmarks, and find that the most general (and thus most modular) configuration consistently outperforms MAD-X and BAD-X on most tasks and languages. | Marinela Parovic, Alan Ansell, Ivan Vulic, Anna Korhonen |  |
| 356 |  |  [DynaMiTE: Discovering Explosive Topic Evolutions with User Guidance](https://doi.org/10.18653/v1/2023.findings-acl.14) |  | 0 | Dynamic topic models (DTMs) analyze text streams to capture the evolution of topics. Despite their popularity, existing DTMs are either fully supervised, requiring expensive human annotations, or fully unsupervised, producing topic evolutions that often do not cater to a user’s needs. Further, the topic evolutions produced by DTMs tend to contain generic terms that are not indicative of their designated time steps. To address these issues, we propose the task of discriminative dynamic topic discovery. This task aims to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. We solve this task by developing DynaMiTE, a framework that ensembles semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions. Through experiments on three diverse datasets, including the use of a newly-designed human evaluation experiment, we demonstrate that DynaMiTE is a practical and efficient framework for helping users discover high-quality topic evolutions suited to their interests. | Nishant Balepur, Shivam Agarwal, Karthik Venkat Ramanan, Susik Yoon, Diyi Yang, Jiawei Han |  |
| 357 |  |  [Boost Transformer-based Language Models with GPU-Friendly Sparsity and Quantization](https://doi.org/10.18653/v1/2023.findings-acl.15) |  | 0 | Along with the performance improvement in NLP domain, the sizes of transformer-based language models (TLM) are also dramatically increased. Some prior works intend to compress TLM models into more compact forms, but do not fully consider the hardware characters may not support the efficient execution for these forms, leading to the deployment of TLM on hardware with noticeable acceleration is still challenging. This paper thoroughly designs a compression scheme named GPUSQ-TLM to maximally utilize the GPU-friendly 2:4 fine-grained structured sparsity and quantization characters. Especially, a dense TLM model is first pruned to meet the GPU’s acceleration constraint of sparse patterns with FP16 type, then it is further quantized into a fixed-point one by quantization-aware training, to provide an extra speedup for integer tensors on GPU. A mixed-strategy knowledge distillation of labels, logits and feature maps is used for best accuracy compensation during pruning and quantization process. Experiment results show GPUSQ-TLM scheme achieves state-of-the-art compression on TLM model of various encoder and decoder blocks with negligible accuracy degradation on SQuAD, GLUE, CNN-DM & XSum and WikiText benchmarking tasks. Moreover, GPUSQ-TLM can boost actual deployment performance by up to 4.08-4.25x latency and 6.18-6.79x throughput on A100 GPU. | Chong Yu, Tao Chen, Zhongxue Gan |  |
| 358 |  |  [RMSSinger: Realistic-Music-Score based Singing Voice Synthesis](https://doi.org/10.18653/v1/2023.findings-acl.16) |  | 0 | We are interested in a challenging task, Realistic-Music-Score based Singing Voice Synthesis (RMS-SVS). RMS-SVS aims to generate high-quality singing voices given realistic music scores with different note types (grace, slur, rest, etc.). Though significant progress has been achieved, recent singing voice synthesis (SVS) methods are limited to fine-grained music scores, which require a complicated data collection pipeline with time-consuming manual annotation to align music notes with phonemes. % Furthermore, existing approaches cannot synthesize rhythmic singing voices given realistic music scores due to the domain gap between fine-grained music scores and realistic music scores. Furthermore, these manual annotation destroys the regularity of note durations in music scores, making fine-grained music scores inconvenient for composing. To tackle these challenges, we propose RMSSinger, the first RMS-SVS method, which takes realistic music scores as input, eliminating most of the tedious manual annotation and avoiding the aforementioned inconvenience. Note that music scores are based on words rather than phonemes, in RMSSinger, we introduce word-level modeling to avoid the time-consuming phoneme duration annotation and the complicated phoneme-level mel-note alignment. Furthermore, we propose the first diffusion-based pitch modeling method, which ameliorates the naturalness of existing pitch-modeling methods. To achieve these, we collect a new dataset containing realistic music scores and singing voices according to these realistic music scores from professional singers. Extensive experiments on the dataset demonstrate the effectiveness of our methods. Audio samples are available at https://rmssinger.github.io/. | Jinzheng He, Jinglin Liu, Zhenhui Ye, Rongjie Huang, Chenye Cui, Huadai Liu, Zhou Zhao |  |
| 359 |  |  [Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.17) |  | 0 | The current generation of intelligent assistants require explicit user requests to perform tasks or services, often leading to lengthy and complex conversations. In contrast, human assistants can infer multiple implicit intents from utterances via their commonsense knowledge, thereby simplifying interactions. To bridge this gap, this paper proposes a framework for multi-domain dialogue systems. This framework automatically infers implicit intents from user utterances, and prompts a large pre-trained language model to suggest suitable task-oriented bots. By leveraging commonsense knowledge, our framework recommends associated bots in a zero-shot manner, enhancing interaction efficiency and effectiveness. This approach substantially reduces interaction complexity, seamlessly integrates various domains and tasks, and represents a significant step towards creating more human-like intelligent assistants that can reason about implicit intents, offering a superior user experience. | HuiChi Kuo, YunNung Chen |  |
| 360 |  |  [MTGP: Multi-turn Target-oriented Dialogue Guided by Generative Global Path with Flexible Turns](https://doi.org/10.18653/v1/2023.findings-acl.18) |  | 0 | Target-oriented dialogue guides the dialogue to a target quickly and smoothly. The latest approaches focus on global planning, which plans toward the target before the conversation instead of adopting a greedy strategy during the conversation. However, the global plan in existing works is fixed to certain turns by generating paths with certain nodes, which limits the optimization of turns and coherence of the target-oriented process. Toward flexible global planning, we propose to generate a global path as a natural language sentence instead of a sequence of nodes. With this path, the dialog is guided to the target with flexible turns of dialog. For model training, we also extract targetoriented dialogues from the chit-chat corpus with a knowledge graph. We conduct experiments on three datasets and simulate scenarios with and without user participation. The results show that our method has fewer turns, more coherent semantics, and a higher success rate in reaching the target than baselines. | Anqi Liu, Bo Wang, Yue Tan, Dongming Zhao, Kun Huang, Ruifang He, Yuexian Hou |  |
| 361 |  |  [The Larger they are, the Harder they Fail: Language Models do not Recognize Identifier Swaps in Python](https://doi.org/10.18653/v1/2023.findings-acl.19) |  | 0 | Large Language Models (LLMs) have successfully been applied to code generation tasks, raising the question of how well these models understand programming. Typical programming languages have invariances and equivariances in their semantics that human programmers intuitively understand and exploit, such as the (near) invariance to the renaming of identifiers. We show that LLMs not only fail to properly generate correct Python code when default function names are swapped, but some of them even become more confident in their incorrect predictions as the model size increases, an instance of the recently discovered phenomenon of Inverse Scaling, which runs contrary to the commonly observed trend of increasing prediction quality with increasing model size. Our findings indicate that, despite their astonishing typical-case performance, LLMs still lack a deep, abstract understanding of the content they manipulate, making them unsuitable for tasks that statistically deviate from their training data, and that mere scaling is not enough to achieve such capability. | Antonio Valerio Miceli Barone, Fazl Barez, Shay B. Cohen, Ioannis Konstas |  |
| 362 |  |  [Class Lifelong Learning for Intent Detection via Structure Consolidation Networks](https://doi.org/10.18653/v1/2023.findings-acl.20) |  | 0 | Intent detection, which estimates diverse intents behind user utterances, is an essential component of task-oriented dialogue systems. Previous intent detection models are usually trained offline, which can only handle predefined intent classes. In the real world, new intents may keep challenging deployed models. For example, with the prevalence of the COVID-19 pandemic, users may pose various issues related to the pandemic to conversational systems, which brings many new intents. A general intent detection model should be intelligent enough to continually learn new data and recognize new arriving intent classes. Therefore, this work explores Class Lifelong Learning for Intent Detection (CLL-ID), where the model continually learns new intent classes from new data while avoiding catastrophic performance degradation on old data. To this end, we propose a novel lifelong learning method, called Structure Consolidation Networks (SCN), which consists of structure-based retrospection and contrastive knowledge distillation to handle the problems of expression diversity and class imbalance in the CLL-ID task. In addition to formulating the new task, we construct 3 benchmarks based on 8 intent detection datasets. Experimental results demonstrate the effectiveness of SCN, which significantly outperforms previous lifelong learning methods on the three benchmarks. | Qingbin Liu, Yanchao Hao, Xiaolong Liu, Bo Li, Dianbo Sui, Shizhu He, Kang Liu, Jun Zhao, Xi Chen, Ningyu Zhang, Jiaoyan Chen |  |
| 363 |  |  [On Evaluating and Mitigating Gender Biases in Multilingual Settings](https://doi.org/10.18653/v1/2023.findings-acl.21) |  | 0 | While understanding and removing gender biases in language models has been a long-standing problem in Natural Language Processing, prior research work has primarily been limited to English. In this work, we investigate some of the challenges with evaluating and mitigating biases in multilingual settings which stem from a lack of existing benchmarks and resources for bias evaluation beyond English especially for non-western context. In this paper, we first create a benchmark for evaluating gender biases in pre-trained masked language models by extending DisCo to different Indian languages using human annotations. We extend various debiasing methods to work beyond English and evaluate their effectiveness for SOTA massively multilingual models on our proposed metric. Overall, our work highlights the challenges that arise while studying social biases in multilingual settings and provides resources as well as mitigation techniques to take a step toward scaling to more languages. | Aniket Vashishtha, Kabir Ahuja, Sunayana Sitaram |  |
| 364 |  |  [Rethinking Round-Trip Translation for Machine Translation Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.22) |  | 0 | Automatic evaluation methods for translation often require model training, and thus the availability of parallel corpora limits their applicability to low-resource settings. Round-trip translation is a potential workaround, which can reframe bilingual evaluation into a much simpler monolingual task. Early results from the era of statistical machine translation (SMT) raised fundamental concerns about the utility of this approach, based on poor correlation with human translation quality judgments. In this paper, we revisit this technique with modern neural translation (NMT) and show that round-trip translation does allow for accurate automatic evaluation without the need for reference translations. These opposite findings can be explained through the copy mechanism in SMT that is absent in NMT. We demonstrate that round-trip translation benefits multiple machine translation evaluation tasks: i) predicting forward translation scores; ii) improving the performance of a quality estimation model; and iii) identifying adversarial competitors in shared tasks via cross-system verification. | Terry Yue Zhuo, Qiongkai Xu, Xuanli He, Trevor Cohn |  |
| 365 |  |  [G³R: A Graph-Guided Generate-and-Rerank Framework for Complex and Cross-domain Text-to-SQL Generation](https://doi.org/10.18653/v1/2023.findings-acl.23) |  | 0 | We present a framework called G3R for complex and cross-domain Text-to-SQL generation. G3R aims to address two limitations of current approaches: (1) The structure of the abstract syntax tree (AST) is not fully explored during the decoding process which is crucial for complex SQL generation; (2) Domain knowledge is not incorporated to enhance their ability to generalise to unseen domains. G3R consists of a graph-guided SQL generator and a knowledge-enhanced re-ranking mechanism. Firstly, during the decoding process, An AST-Grammar bipartite graph is constructed for both the AST and corresponding grammar rules of the generated partial SQL query. The graph-guided SQL generator captures its structural information and fuses heterogeneous information to predict the action sequence which can construct the AST for the corresponding SQL query uniquely. Then, in the inference stage, a knowledge-enhanced re-ranking mechanism is proposed to introduce domain knowledge to re-rank candidate SQL queries from the beam output and choose the final answer. The SQL ranker is based on pre-trained language models (PLM) and contrastive learning with hybrid prompt tuning is incorporated to stimulate the knowledge of PLMs and make it more discriminative. The proposed approach achieves state-of-the-art results on the Spider and Spider-DK benchmarks, which are challenging complex and cross-domain benchmarks for Text-to-SQL semantic analysis. | Yanzheng Xiang, QianWen Zhang, Xu Zhang, Zejie Liu, Yunbo Cao, Deyu Zhou |  |
| 366 |  |  [A Unified Knowledge Graph Augmentation Service for Boosting Domain-specific NLP Tasks](https://doi.org/10.18653/v1/2023.findings-acl.24) |  | 0 | By focusing the pre-training process on domain-specific corpora, some domain-specific pre-trained language models (PLMs) have achieved state-of-the-art results. However, it is under-investigated to design a unified paradigm to inject domain knowledge in the PLM fine-tuning stage. We propose KnowledgeDA, a unified domain language model development service to enhance the task-specific training procedure with domain knowledge graphs. Given domain-specific task texts input, KnowledgeDA can automatically generate a domain-specific language model following three steps: (i) localize domain knowledge entities in texts via an embedding-similarity approach; (ii) generate augmented samples by retrieving replaceable domain entity pairs from two views of both knowledge graph and training data; (iii) select high-quality augmented samples for fine-tuning via confidence-based assessment. We implement a prototype of KnowledgeDA to learn language models for two domains, healthcare and software development. Experiments on domain-specific text classification and QA tasks verify the effectiveness and generalizability of KnowledgeDA. | Ruiqing Ding, Xiao Han, Leye Wang |  |
| 367 |  |  [Dialogue Planning via Brownian Bridge Stochastic Process for Goal-directed Proactive Dialogue](https://doi.org/10.18653/v1/2023.findings-acl.25) |  | 0 | Goal-directed dialogue systems aim to proactively reach a pre-determined target through multi-turn conversations. The key to achieving this task lies in planning dialogue paths that smoothly and coherently direct conversations towards the target. However, this is a challenging and under-explored task. In this work, we propose a coherent dialogue planning approach that uses a stochastic process to model the temporal dynamics of dialogue paths. We define a latent space that captures the coherence of goal-directed behavior using a Brownian bridge process, which allows us to incorporate user feedback flexibly in dialogue planning. Based on the derived latent trajectories, we generate dialogue paths explicitly using pre-trained language models. We finally employ these paths as natural language prompts to guide dialogue generation. Our experiments show that our approach generates more coherent utterances and achieves the goal with a higher success rate. | Jian Wang, Dongding Lin, Wenjie Li |  |
| 368 |  |  [A Match Made in Heaven: A Multi-task Framework for Hyperbole and Metaphor Detection](https://doi.org/10.18653/v1/2023.findings-acl.26) |  | 0 | Hyperbole and metaphor are common in day-to-day communication (e.g., “I am in deep trouble”: how does trouble have depth?), which makes their detection important, especially in a conversational AI setting. Existing approaches to automatically detect metaphor and hyperbole have studied these language phenomena independently, but their relationship has hardly, if ever, been explored computationally. In this paper, we propose a multi-task deep learning framework to detect hyperbole and metaphor simultaneously. We hypothesize that metaphors help in hyperbole detection, and vice-versa. To test this hypothesis, we annotate two hyperbole datasets- HYPO and HYPO-L- with metaphor labels. Simultaneously, we annotate two metaphor datasets- TroFi and LCC- with hyperbole labels. Experiments using these datasets give an improvement of the state of the art of hyperbole detection by 12%. Additionally, our multi-task learning (MTL) approach shows an improvement of up to 17% over single-task learning (STL) for both hyperbole and metaphor detection, supporting our hypothesis. To the best of our knowledge, ours is the first demonstration of computational leveraging of linguistic intimacy between metaphor and hyperbole, leading to showing the superiority of MTL over STL for hyperbole and metaphor detection. | Naveen Badathala, Abisek Rajakumar Kalarani, Tejpalsingh Siledar, Pushpak Bhattacharyya |  |
| 369 |  |  [Prompt Tuning for Unified Multimodal Pretrained Models](https://doi.org/10.18653/v1/2023.findings-acl.27) |  | 0 | Prompt tuning has become a new paradigm for model tuning and it has demonstrated success in natural language pretraining and even vision pretraining. The parameter-efficient prompt tuning methods that optimize soft embeddings while keeping the pretrained model frozen demonstrate advantages in low computation costs and almost lossless performance. In this work, we explore the transfer of prompt tuning to multimodal pretrained models. Specifically, we implement prompt tuning to a unified sequence-to-sequence pretrained model by adding a sequence of learnable embeddings to each layer and finetuning the pretrained model on downstream task with only the learnable embeddings being optimized. Experimental results on a series of multimodal understanding and generation tasks demonstrate that our method OFA-PT can achieve comparable performance with finetuning across a series of multimodal generation and understanding tasks. Additionally, it significantly outperforms the unified multimodal pretrained model with other parameter-efficient tuning methods, e.g., Adapter, BitFit. etc. Besides, in comparison with finetuned models, the prompt-tuned models demonstrate improved robustness against adversarial attacks. We further figure out that experimental factors, including prompt length, prompt depth, and reparameteratization, have great impacts on the model performance, and thus we empirically provide a recommendation for the setups of prompt tuning. | Hao Yang, Junyang Lin, An Yang, Peng Wang, Chang Zhou |  |
| 370 |  |  [Learning Joint Structural and Temporal Contextualized Knowledge Embeddings for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.findings-acl.28) |  | 0 | Temporal knowledge graph completion that predicts missing links for incomplete temporal knowledge graphs (TKG) is gaining increasing attention. Most existing works have achieved good results by incorporating time information into static knowledge graph embedding methods. However, they ignore the contextual nature of the TKG structure, i.e., query-specific subgraph contains both structural and temporal neighboring facts. This paper presents the SToKE, a novel method that employs the pre-trained language model (PLM) to learn joint Structural and Temporal Contextualized Knowledge Embeddings.Specifically, we first construct an event evolution tree (EET) for each query to enable PLMs to handle the TKG, which can be seen as a structured event sequence recording query-relevant structural and temporal contexts. We then propose a novel temporal embedding and structural matrix to learn the time information and structural dependencies of facts in EET.Finally, we formulate TKG completion as a mask prediction problem by masking the missing entity of the query to fine-tune pre-trained language models. Experimental results on three widely used datasets show the superiority of our model. | Yifu Gao, Yongquan He, Zhigang Kan, Yi Han, Linbo Qiao, Dongsheng Li |  |
| 371 |  |  [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets](https://doi.org/10.18653/v1/2023.findings-acl.29) |  | 0 | The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT’s performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instructions that we mostly found in ChatGPT and other instruction-tuned models. Our extensive evaluation shows that even though ChatGPT is capable of performing a wide variety of tasks, and may obtain impressive performance in several benchmark datasets, it is still far from achieving the ability to reliably solve many challenging tasks. By providing a thorough assessment of ChatGPT’s performance across diverse NLP tasks, this paper sets the stage for a targeted deployment of ChatGPT-like LLMs in real-world applications. | Md. Tahmid Rahman Laskar, M. Saiful Bari, Mizanur Rahman, Md Amran Hossen Bhuiyan, Shafiq Joty, Jimmy Xiangji Huang |  |
| 372 |  |  [Generating Deep Questions with Commonsense Reasoning Ability from the Text by Disentangled Adversarial Inference](https://doi.org/10.18653/v1/2023.findings-acl.30) |  | 0 | This paper proposes a new task of commonsense question generation, which aims to yield deep-level and to-the-point questions from the text. Their answers need to reason over disjoint relevant contexts and external commonsense knowledge, such as encyclopedic facts and causality. The knowledge may not be explicitly mentioned in the text but is used by most humans for problem-shooting. Such complex reasoning with hidden contexts involves deep semantic understanding. Thus, this task has great application value, such as making high-quality quizzes in advanced exams. Due to the lack of modeling complexity, existing methods may produce shallow questions that can be answered by simple word matching. To address these challenges, we propose a new QG model by simultaneously considering asking contents, expressive ways, and answering complexity. We first retrieve text-related commonsense context. Then we disentangle the key factors that control questions in terms of reasoning content and verbalized way. Independence priors and constraints are imposed to facilitate disentanglement. We further develop a discriminator to promote the deep results by considering their answering complexity. Through adversarial inference, we learn the latent factors from data. By sampling the expressive factor from the data distributions, diverse questions can be yielded. Evaluations of two typical data sets show the effectiveness of our approach. | Jianxing Yu, Shiqi Wang, Libin Zheng, Qinliang Su, Wei Liu, Baoquan Zhao, Jian Yin |  |
| 373 |  |  [TADA: Efficient Task-Agnostic Domain Adaptation for Transformers](https://doi.org/10.18653/v1/2023.findings-acl.31) |  | 0 | Intermediate training of pre-trained transformer-based language models on domain-specific data leads to substantial gains for downstream tasks. To increase efficiency and prevent catastrophic forgetting alleviated from full domain-adaptive pre-training, approaches such as adapters have been developed. However, these require additional parameters for each layer, and are criticized for their limited expressiveness. In this work, we introduce TADA, a novel task-agnostic domain adaptation method which is modular, parameter-efficient, and thus, data-efficient. Within TADA, we retrain the embeddings to learn domain-aware input representations and tokenizers for the transformer encoder, while freezing all other parameters of the model. Then, task-specific fine-tuning is performed. We further conduct experiments with meta-embeddings and newly introduced meta-tokenizers, resulting in one model per task in multi-domain use cases. Our broad evaluation in 4 downstream tasks for 14 domains across single- and multi-domain setups and high- and low-resource scenarios reveals that TADA is an effective and efficient alternative to full domain-adaptive pre-training and adapters for domain adaptation, while not introducing additional parameters or complex training steps. | ChiaChien Hung, Lukas Lange, Jannik Strötgen |  |
| 374 |  |  [Robust Natural Language Understanding with Residual Attention Debiasing](https://doi.org/10.18653/v1/2023.findings-acl.32) |  | 0 | Natural language understanding (NLU) models often suffer from unintended dataset biases. Among bias mitigation methods, ensemble-based debiasing methods, especially product-of-experts (PoE), have stood out for their impressive empirical success. However, previous ensemble-based debiasing methods typically apply debiasing on top-level logits without directly addressing biased attention patterns. Attention serves as the main media of feature interaction and aggregation in PLMs and plays a crucial role in providing robust prediction. In this paper, we propose REsidual Attention Debiasing (READ), an end-to-end debiasing method that mitigates unintended biases from attention. Experiments on three NLU benchmarks show that READ significantly improves the OOD performance of BERT-based models, including +12.9% accuracy on HANS, +11.0% accuracy on FEVER-Symmetric, and +2.7% F1 on PAWS. Detailed analyses demonstrate the crucial role of unbiased attention in robust NLU models and that READ effectively mitigates biases in attention. | Fei Wang, James Y. Huang, Tianyi Yan, Wenxuan Zhou, Muhao Chen |  |
| 375 |  |  [MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking](https://doi.org/10.18653/v1/2023.findings-acl.33) |  | 0 | Dialogue state tracking (DST) aims to convert the dialogue history into dialogue states which consist of slot-value pairs. As condensed structural information memorizes all history information, the dialogue state in the previous turn is typically adopted as the input for predicting the current state by DST models. However, these models tend to keep the predicted slot values unchanged, which is defined as state momentum in this paper. Specifically, the models struggle to update slot values that need to be changed and correct wrongly predicted slot values in the previous turn. To this end, we propose MoNET to tackle state momentum via noise-enhanced training. First, the previous state of each turn in the training data is noised via replacing some of its slot values. Then, the noised previous state is used as the input to learn to predict the current state, improving the model’s ability to update and correct slot values. Furthermore, a contrastive contextmatching framework is designed to narrow the representation distance between a state and itscorresponding noised variant, which reduces the impact of noised state and makes the model better understand the dialogue history. Experimental results on MultiWOZ datasets show that MoNET outperforms previous DST methods. Ablations and analysis verify the effectiveness of MoNET in alleviating state momentum issues and improving the anti-noise ability. | Haoning Zhang, Junwei Bao, Haipeng Sun, Youzheng Wu, Wenye Li, Shuguang Cui, Xiaodong He |  |
| 376 |  |  [PAL: Persona-Augmented Emotional Support Conversation Generation](https://doi.org/10.18653/v1/2023.findings-acl.34) |  | 0 | Due to the lack of human resources for mental health support, there is an increasing demand for employing conversational agents for support. Recent work has demonstrated the effectiveness of dialogue models in providing emotional support. As previous studies have demonstrated that seekers’ persona is an important factor for effective support, we investigate whether there are benefits to modeling such information in dialogue models for support. In this paper, our empirical analysis verifies that persona has an important impact on emotional support. Therefore, we propose a framework for dynamically inferring and modeling seekers’ persona. We first train a model for inferring the seeker’s persona from the conversation history. Accordingly, we propose PAL, a model that leverages persona information and, in conjunction with our strategy-based controllable generation method, provides personalized emotional support. Automatic and manual evaluations demonstrate that PAL achieves state-of-the-art results, outperforming the baselines on the studied benchmark. Our code and data are publicly available at https://github.com/chengjl19/PAL. | Jiale Cheng, Sahand Sabour, Hao Sun, Zhuang Chen, Minlie Huang |  |
| 377 |  |  [Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model](https://doi.org/10.18653/v1/2023.findings-acl.35) |  | 0 | Pretrained language models have achieved remarkable success in various natural language processing tasks. However, pretraining has recently shifted toward larger models and larger data, which has resulted in significant computational and energy costs. In this paper, we propose Influence Subset Selection (ISS) for language model, which explicitly utilizes end-task knowledge to select a tiny subset of the pretraining corpus. Specifically, the ISS selects the samples that will provide the most positive influence on the performance of the end task. Furthermore, we design a gradient matching-based influence estimation method, which can drastically reduce the computation time of influence. With only 0.45% of the data and a three-orders-of-magnitude lower computational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight datasets covering four domains. | Xiao Wang, Weikang Zhou, Qi Zhang, Jie Zhou, Songyang Gao, Junzhe Wang, Menghan Zhang, Xiang Gao, Yunwen Chen, Tao Gui |  |
| 378 |  |  [Exclusive Supermask Subnetwork Training for Continual Learning](https://doi.org/10.18653/v1/2023.findings-acl.36) |  | 0 | Continual Learning (CL) methods focus on accumulating knowledge over time while avoiding catastrophic forgetting. Recently, Wortsman et al. (2020) proposed a CL method, SupSup, which uses a randomly initialized, fixed base network (model) and finds a supermask for each new task that selectively keeps or removes each weight to produce a subnetwork. They prevent forgetting as the network weights are not being updated. Although there is no forgetting, the performance of SupSup is sub-optimal because fixed weights restrict its representational power. Furthermore, there is no accumulation or transfer of knowledge inside the model when new tasks are learned. Hence, we propose ExSSNeT (Exclusive Supermask SubNetwork Training), that performs exclusive and non-overlapping subnetwork weight training. This avoids conflicting updates to the shared weights by subsequent tasks to improve performance while still preventing forgetting. Furthermore, we propose a novel KNN-based Knowledge Transfer (KKT) module that utilizes previously acquired knowledge to learn new tasks better and faster. We demonstrate that ExSSNeT outperforms strong previous methods on both NLP and Vision domains while preventing forgetting. Moreover, ExSSNeT is particularly advantageous for sparse masks that activate 2-10% of the model parameters, resulting in an average improvement of 8.3% over SupSup. Furthermore, ExSSNeT scales to a large number of tasks (100). | Prateek Yadav, Mohit Bansal |  |
| 379 |  |  [Transferring General Multimodal Pretrained Models to Text Recognition](https://doi.org/10.18653/v1/2023.findings-acl.37) |  | 0 | This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained models to text recognition. Specifically, we recast text recognition as image captioning and directly transfer a unified vision-language pretrained model to the end task. Without pretraining on large-scale annotated or synthetic text recognition data, OFA-OCR outperforms the baselines and achieves state-of-the-art performance in the Chinese text recognition benchmark. Additionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate that it can achieve competitive performance with the product-level API. | Junyang Lin, Xuancheng Ren, Yichang Zhang, Gao Liu, Peng Wang, An Yang, Chang Zhou |  |
| 380 |  |  [A Formal Perspective on Byte-Pair Encoding](https://doi.org/10.18653/v1/2023.findings-acl.38) |  | 0 | Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in NLP, despite being devised initially as a compression method.BPE appears to be a greedy algorithm at face value, but the underlying optimization problem that BPE seeks to solve has not yet been laid down. We formalize BPE as a combinatorial optimization problem. Via submodular functions, we prove that the iterative greedy version is a 1/sigma\*(1-e(-sigma))-approximation of an optimal merge sequence, where sigma is the total backward curvature with respect to the optimal merge sequence. Empirically the lower bound of the approximation is approx0.37.We provide a faster implementation of BPE which improves the runtime complexity from O(NM) to O(N log M), where N is the sequence length and M is the merge count. Finally, we optimize the brute-force algorithm for optimal BPE using memoization. | Vilém Zouhar, Clara Meister, Juan Luis Gastaldi, Li Du, Tim Vieira, Mrinmaya Sachan, Ryan Cotterell |  |
| 381 |  |  [Automatic Named Entity Obfuscation in Speech](https://doi.org/10.18653/v1/2023.findings-acl.39) |  | 0 | Sharing data containing personal information often requires its anonymization, even when consent for sharing was obtained from the data originator. While approaches exist for automated anonymization of text, the area is not as thoroughly explored in speech. This work focuses on identifying, replacing and inserting replacement named entities synthesized using voice cloning into original audio thereby retaining prosodic information while reducing the likelihood of deanonymization. The approach employs a novel named entity recognition (NER) system built directly on speech by training HuBERT (Hsu et al, 2021) using the English speech NER dataset (Yadav et al, 2020). Name substitutes are found using a masked language model and are synthesized using text to speech voice cloning (Eren and team, 2021), upon which the substitute named entities are re-inserted into the original text. The approach is prototyped on a sample of the LibriSpeech corpus (Panyatov et al, 2015) with each step evaluated individually. | Judita Preiss |  |
| 382 |  |  [Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models](https://doi.org/10.18653/v1/2023.findings-acl.40) |  | 0 | Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models’ (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs’ inference capability to solve problems, whose solution consists of hundreds of thousands of tokens. | Soochan Lee, Gunhee Kim |  |
| 383 |  |  [UniS-MMC: Multimodal Classification via Unimodality-supervised Multimodal Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-acl.41) |  | 0 | Multimodal learning aims to imitate human beings to acquire complementary information from multiple modalities for various downstream tasks. However, traditional aggregation-based multimodal fusion methods ignore the inter-modality relationship, treat each modality equally, suffer sensor noise, and thus reduce multimodal learning performance. In this work, we propose a novel multimodal contrastive method to explore more reliable multimodal representations under the weak supervision of unimodal predicting. Specifically, we first capture task-related unimodal representations and the unimodal predictions from the introduced unimodal predicting task. Then the unimodal representations are aligned with the more effective one by the designed multimodal contrastive method under the supervision of the unimodal predictions. Experimental results with fused features on two image-text classification benchmarks UPMC-Food-101 and N24News show that our proposed Unimodality-Supervised MultiModal Contrastive UniS-MMC learning method outperforms current state-of-the-art multimodal methods. The detailed ablation study and analysis further demonstrate the advantage of our proposed method. | Heqing Zou, Meng Shen, Chen Chen, Yuchen Hu, Deepu Rajan, Eng Siong Chng |  |
| 384 |  |  [Robustness-Aware Word Embedding Improves Certified Robustness to Adversarial Word Substitutions](https://doi.org/10.18653/v1/2023.findings-acl.42) |  | 0 | Natural Language Processing (NLP) models have gained great success on clean texts, but they are known to be vulnerable to adversarial examples typically crafted by synonym substitutions. In this paper, we target to solve this problem and find that word embedding is important to the certified robustness of NLP models. Given the findings, we propose the Embedding Interval Bound Constraint (EIBC) triplet loss to train robustness-aware word embeddings for better certified robustness. We optimize the EIBC triplet loss to reduce distances between synonyms in the embedding space, which is theoretically proven to make the verification boundary tighter. Meanwhile, we enlarge distances among non-synonyms, maintaining the semantic representation of word embeddings. Our method is conceptually simple and componentized. It can be easily combined with IBP training and improves the certified robust accuracy from 76.73% to 84.78% on the IMDB dataset. Experiments demonstrate that our method outperforms various state-of-the-art certified defense baselines and generalizes well to unseen substitutions. The code is available at https://github.com/JHL-HUST/EIBC-IBP/. | Yibin Wang, Yichen Yang, Di He, Kun He |  |
| 385 |  |  [Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing](https://doi.org/10.18653/v1/2023.findings-acl.43) |  | 0 | In the context-dependent Text-to-SQL task, the generated SQL statements are refined iteratively based on the user input utterance from each interaction. The input text from each interaction can be viewed as component modifications to the previous SQL statements, which could be further extracted as the modification patterns. Since these modification patterns could also be combined with other SQL statements, the models are supposed to have the compositional generalization to these novel combinations. This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios. To facilitate related studies, we constructed two challenging benchmarks named CoSQL-CG and SParC-CG by recombining the modification patterns and existing SQL statements. The following experiments show that almost all current models struggle on our proposed benchmarks. Furthermore, we found that better aligning the previous SQL statements with the input utterance could give models better combinatorial generalization ability. Based on these observations, we propose a method name p-align to improve the combinatorial generalization of Text-to-SQL models. Further experiments validate the effectiveness of our model. | Aiwei Liu, Wei Liu, Xuming Hu, Shuang Li, Fukun Ma, Yawen Yang, Lijie Wen |  |
| 386 |  |  [Towards Generative Event Factuality Prediction](https://doi.org/10.18653/v1/2023.findings-acl.44) |  | 0 | We present a novel end-to-end generative task and system for predicting event factuality holders, targets, and their associated factuality values. We perform the first experiments using all sources and targets of factuality statements from the FactBank corpus. We perform multi-task learning with other tasks and event-factuality corpora to improve on the FactBank source and target task. We argue that careful domain specific target text output format in generative systems is important and verify this with multiple experiments on target text output structure. We redo previous state-of-the-art author-only event factuality experiments and also offer insights towards a generative paradigm for the author-only event factuality prediction task. | John Murzaku, Tyler Osborne, Amittai Aviram, Owen Rambow |  |
| 387 |  |  [Can Language Models Be Specific? How?](https://doi.org/10.18653/v1/2023.findings-acl.45) |  | 0 | “He is a person”, “Paris is located on the earth”. Both statements are correct but meaningless - due to lack of specificity. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given “Toronto is located in [MASK].”, we want to test whether a more specific answer will be better filled in by PLMs, e.g., Ontario instead of Canada. From our evaluations, we show that existing PLMs have only a slight preference for more specific answers. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We hope this work can bring to awareness the notion of specificity of language models and encourage the research community to further explore this important but understudied problem. | Jie Huang, Kevin ChenChuan Chang, Jinjun Xiong, WenMei Hwu |  |
| 388 |  |  [The Web Can Be Your Oyster for Improving Language Models](https://doi.org/10.18653/v1/2023.findings-acl.46) |  | 0 | Pretrained language models (PLMs) encode a large amount of world knowledge. However, as such knowledge is frozen at the time of model training, the models become static and limited by the training data at that time. In order to further improve the capacity of PLMs for knowledge-intensive tasks, we consider augmenting PLMs with the large-scale web using search engine. Unlike previous augmentation sources (e.g., Wikipedia data dump), the web provides broader, more comprehensive and constantly updated information. In this paper, we present a web-augmented PLM – UniWeb, which is trained over 16 knowledge-intensive tasks in a unified text-to-text format. Instead of simply using the retrieved contents from web, our approach has made two major improvements. Firstly, we propose an adaptive search engine assisted learning method that can self-evaluate the confidence level of PLM’s predictions, and adaptively determine when to refer to the web for more data, which can avoid useless or noisy augmentation from web. Secondly, we design a pretraining task, i.e., continual knowledge learning, based on salient spans prediction, to reduce the discrepancy between the encoded and retrieved knowledge. Experiments on a wide range of knowledge-intensive tasks show that our model significantly outperforms previous retrieval-augmented methods. | Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jingyuan Wang, JianYun Nie, JiRong Wen |  |
| 389 |  |  [Enhancing Few-shot Cross-lingual Transfer with Target Language Peculiar Examples](https://doi.org/10.18653/v1/2023.findings-acl.47) |  | 0 | Few-shot cross-lingual transfer, fine-tuning Multilingual Masked Language Model (MMLM) with source language labeled data and a small amount of target language labeled data, provides excellent performance in the target language. However, if no labeled data in the target language are available, they need to be created through human annotations. In this study, we devise a metric to select annotation candidates from an unlabeled data pool that efficiently enhance accuracy for few-shot cross-lingual transfer. It is known that training a model with hard examples is important to improve the model’s performance. Therefore, we first identify examples that MMLM cannot solve in a zero-shot cross-lingual transfer setting and demonstrate that it is hard to predict peculiar examples in the target language, i.e., the examples distant from the source language examples in cross-lingual semantic space of the MMLM.We then choose high peculiarity examples as annotation candidates and perform few-shot cross-lingual transfer. In comprehensive experiments with 20 languages and 6 tasks, we demonstrate that the high peculiarity examples improve the target language accuracy compared to other candidate selection methods proposed in previous studies. | Hwichan Kim, Mamoru Komachi |  |
| 390 |  |  [Overcoming Catastrophic Forgetting in Massively Multilingual Continual Learning](https://doi.org/10.18653/v1/2023.findings-acl.48) |  | 0 | Real-life multilingual systems should be able to efficiently incorporate new languages as data distributions fed to the system evolve and shift over time. To do this, systems need to handle the issue of catastrophic forgetting, where the model performance drops for languages or tasks seen further in its past. In this paper, we study catastrophic forgetting, as well as methods to minimize this, in a massively multilingual continual learning framework involving up to 51 languages and covering both classification and sequence labeling tasks. We present LR ADJUST, a learning rate scheduling method that is simple, yet effective in preserving new information without strongly overwriting past knowledge. Furthermore, we show that this method is effective across multiple continual learning approaches. Finally, we provide further insights into the dynamics of catastrophic forgetting in this massively multilingual setup. | Genta Indra Winata, Lingjue Xie, Karthik Radhakrishnan, Shijie Wu, Xisen Jin, Pengxiang Cheng, Mayank Kulkarni, Daniel PreotiucPietro |  |
| 391 |  |  [UniFine: A Unified and Fine-grained Approach for Zero-shot Vision-Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.49) |  | 0 | Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because they require the model’s reasoning ability to understand the semantics of the visual world and natural language. Supervised methods working for vision-language tasks have been well-studied. However, solving these tasks in a zero-shot setting is less explored. Since Contrastive Language-Image Pre-training (CLIP) has shown remarkable zero-shot performance on image-text matching, previous works utilized its strong zero-shot ability by converting vision-language tasks into an image-text matching problem, and they mainly consider global-level matching (e.g., the whole image or sentence). However, we find visual and textual fine-grained information, e.g., keywords in the sentence and objects in the image, can be fairly informative for semantics understanding. Inspired by this, we propose a unified framework to take advantage of the fine-grained information for zero-shot vision-language learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our experiments show that our framework outperforms former zero-shot methods on VQA and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our ablation studies confirm the effectiveness and generalizability of our proposed method. | Rui Sun, Zhecan Wang, Haoxuan You, Noel Codella, KaiWei Chang, ShihFu Chang |  |
| 392 |  |  [Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors](https://doi.org/10.18653/v1/2023.findings-acl.50) |  | 0 | Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instruction-tuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to RE’s low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al. 2022). To address this limitation, we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets. Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA. | Kai Zhang, Bernal Jimenez Gutierrez, Yu Su |  |
| 393 |  |  [TADA : Task Agnostic Dialect Adapters for English](https://doi.org/10.18653/v1/2023.findings-acl.51) |  | 0 | Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). Prior work addresses this using task specific data or synthetic data augmentation, both of which require intervention for each dialect and task pair. This poses a scalability issue that prevents the broad adoption of robust dialectal English NLP. We introduce a simple yet effective method for task-agnostic dialect adaptation by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on 4 dialectal variants of the GLUE benchmark without task-specific supervision. | William Held, Caleb Ziems, Diyi Yang |  |
| 394 |  |  [Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting](https://doi.org/10.18653/v1/2023.findings-acl.52) |  | 0 | Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness. In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work. Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt tuning strategy to boost higher performance only training fewer prompt parameters. Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots. | Xuefeng Li, Liwen Wang, Guanting Dong, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu |  |
| 395 |  |  [Re-appraising the Schema Linking for Text-to-SQL](https://doi.org/10.18653/v1/2023.findings-acl.53) |  | 0 | Most text-to-SQL models, even though based on the same grammar decoder, generate the SQL structure first and then fill in the SQL slots with the correct schema items. This second step depends on schema linking: aligning the entity references in the question with the schema columns or tables. This is generally approached via Exact Match based Schema Linking (EMSL) within a neural network-based schema linking module. EMSL has become standard in text-to-SQL: many state-of-the-art models employ EMSL, with performance dropping significantly when the EMSL component is removed. In this work, however, we show that EMSL reduces robustness, rendering models vulnerable to synonym substitution and typos. Instead of relying on EMSL to make up for deficiencies in question-schema encoding, we show that using a pre-trained language model as an encoder can improve performance without using EMSL, giving a more robust model. We also study the design choice of the schema linking module, finding that a suitable design benefits performance and interoperability. Finally, based on the above study of schema linking, we introduce the grammar linking to help model align grammar references in the question with the SQL keywords. | Yujian Gan, Xinyun Chen, Matthew Purver |  |
| 396 |  |  [Echoes from Alexandria: A Large Resource for Multilingual Book Summarization](https://doi.org/10.18653/v1/2023.findings-acl.54) |  | 0 | In recent years, research in text summarization has mainly focused on the news domain, where texts are typically short and have strong layout features. The task of full-book summarization presents additional challenges which are hard to tackle with current resources, due to their limited size and availability in English only. To overcome these limitations, we present “Echoes from Alexandria”, or in shortened form, “Echoes”, a large resource for multilingual book summarization. Echoes featuresthree novel datasets: i) Echo-Wiki, for multilingual book summarization, ii) Echo-XSum, for extremely-compressive multilingual book summarization, and iii) Echo-FairySum, for extractive book summarization. To the best of our knowledge, Echoes – with its thousands of books and summaries – is the largest resource, and the first to be multilingual, featuring 5 languages and 25 language pairs. In addition to Echoes, we also introduce a new extractive-then-abstractive baseline, and, supported by our experimental results and manual analysis of the summaries generated, we argue that this baseline is more suitable for book summarization than purely-abstractive approaches. We release our resource and software at https://github.com/Babelscape/echoes-from-alexandria in the hope of fostering innovative research in multilingual booksummarization. | Alessandro Scirè, Simone Conia, Simone Ciciliano, Roberto Navigli |  |
| 397 |  |  [When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario](https://doi.org/10.18653/v1/2023.findings-acl.55) |  | 0 | Large pre-trained language models (PLMs) have garnered significant attention for their versatility and potential for solving a wide spectrum of natural language processing (NLP) tasks. However, the cost of running these PLMs may be prohibitive. Furthermore, PLMs may not be open-sourced due to commercial considerations and potential risks of misuse, such as GPT-3. The parameters and gradients of PLMs are unavailable in this scenario. To solve the issue, black-box tuning has been proposed, which utilizes derivative-free optimization (DFO), instead of gradient descent, for training task-specific continuous prompts. However, these gradient-free methods still exhibit a significant gap compared to gradient-based methods. In this paper, we introduce gradient descent into black-box tuning scenario through knowledge distillation. Furthermore, we propose a novel method GDFO, which integrates gradient descent and derivative-free optimization to optimize task-specific continuous prompts in a harmonized manner. Experimental results show that GDFO can achieve significant performance gains over previous state-of-the-art methods. | Chengcheng Han, Liqing Cui, Renyu Zhu, Jianing Wang, Nuo Chen, Qiushi Sun, Xiang Li, Ming Gao |  |
| 398 |  |  [Align-then-Enhance: Multilingual Entailment Graph Enhancement with Soft Predicate Alignment](https://doi.org/10.18653/v1/2023.findings-acl.56) |  | 0 | Entailment graphs (EGs) with predicates as nodes and entailment relations as edges are typically incomplete, while EGs in different languages are often complementary to each other. In this paper, we propose a new task, multilingual entailment graph enhancement, which aims to utilize the entailment information from one EG to enhance another EG in a different language. The ultimate goal is to obtain an enhanced EG containing richer and more accurate entailment information. We present an align-then-enhance framework (ATE) to achieve accurate multilingual entailment graph enhancement, which first exploits a cross-graph guided interaction mechanism to automatically discover potential equivalent predicates between different EGs and then constructs more accurate enhanced entailment graphs based on soft predicate alignments. Extensive experiments show that ATE achieves better and more robust predicate alignment results between different EGs, and the enhanced entailment graphs generated by ATE outperform the original graphs for entailment detection. | Yuting Wu, Yutong Hu, Yansong Feng, Tianyi Li, Mark Steedman, Dongyan Zhao |  |
| 399 |  |  [Few-shot Classification with Hypersphere Modeling of Prototypes](https://doi.org/10.18653/v1/2023.findings-acl.57) |  | 0 | Metric-based meta-learning is one of the de facto standards in few-shot learning. It composes of representation learning and metrics calculation designs. Previous works construct class representations in different ways, varying from mean output embedding to covariance and distributions. However, using embeddings in space lacks expressivity and cannot capture class information robustly, while statistical complex modeling poses difficulty to metric designs. In this work, we use tensor fields (“areas”) to model classes from the geometrical perspective for few-shot learning. We present a simple and effective method, dubbed as hypersphere prototypes (HyperProto), where class information is represented by hyperspheres with dynamic sizes with two sets of learnable parameters: the hypersphere’s center and the radius. Extending from points to areas, hyperspheres are much more expressive than embeddings. Moreover, it is more convenient to perform metric-based classification with hypersphere prototypes than statistical modeling, as we only need to calculate the distance from a data point to the surface of the hypersphere. Following this idea, we also develop two variants of prototypes under other measurements. Extensive experiments and analysis on few-shot NLP tasks and comparison with 20+ competitive baselines demonstrate the effectiveness of our approach. | Ning Ding, Yulin Chen, Ganqu Cui, Xiaobin Wang, Haitao Zheng, Zhiyuan Liu, Pengjun Xie |  |
| 400 |  |  [Structured Mean-Field Variational Inference for Higher-Order Span-Based Semantic Role](https://doi.org/10.18653/v1/2023.findings-acl.58) |  | 0 | In this work, we enhance higher-order graph-based approaches for span-based semantic role labeling (SRL) by means of structured modeling. To decrease the complexity of higher-order modeling, we decompose the edge from predicate word to argument span into three different edges, predicate-to-head (P2H), predicate-to-tail (P2T), and head-to-tail (H2T), where head/tail means the first/last word of the semantic argument span. As such, we use a CRF-based higher-order dependency parser and leverage Mean-Field Variational Inference (MFVI) for higher-order inference. Moreover, since semantic arguments of predicates are often constituents within a constituency parse tree, we can leverage such nice structural property by defining a TreeCRF distribution over all H2T edges, using the idea of partial marginalization to define structural training loss. We further leverage structured MFVI to enhance inference. We experiment on span-based SRL benchmarks, showing the effectiveness of both higher-order and structured modeling and the combination thereof. In addition, we show superior performance of structured MFVI against vanilla MFVI. | Wei Liu, Songlin Yang, Kewei Tu |  |
| 401 |  |  [AQE: Argument Quadruplet Extraction via a Quad-Tagging Augmented Generative Approach](https://doi.org/10.18653/v1/2023.findings-acl.59) |  | 0 | Argument mining involves multiple sub-tasks that automatically identify argumentative elements, such as claim detection, evidence extraction, stance classification, etc. However, each subtask alone is insufficient for a thorough understanding of the argumentative structure and reasoning process. To learn a complete view of an argument essay and capture the interdependence among argumentative components, we need to know what opinions people hold (i.e., claims), why those opinions are valid (i.e., supporting evidence), which source the evidence comes from (i.e., evidence type), and how those claims react to the debating topic (i.e., stance). In this work, we for the first time propose a challenging argument quadruplet extraction task (AQE), which can provide an all-in-one extraction of four argumentative components, i.e., claims, evidence, evidence types, and stances. To support this task, we construct a large-scale and challenging dataset. However, there is no existing method that can solve the argument quadruplet extraction. To fill this gap, we propose a novel quad-tagging augmented generative approach, which leverages a quadruplet tagging module to augment the training of the generative framework. The experimental results on our dataset demonstrate the empirical superiority of our proposed approach over several strong baselines. | Jia Guo, Liying Cheng, Wenxuan Zhang, Stanley Kok, Xin Li, Lidong Bing |  |
| 402 |  |  [The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.60) |  | 0 | Large language models are known to produce output which sounds fluent and convincing, but is also often wrong, e.g. “unfaithful” with respect to a rationale as retrieved from a knowledge base. In this paper, we show that task-based systems which exhibit certain advanced linguistic dialog behaviors, such as lexical alignment (repeating what the user said), are in fact preferred and trusted more, whereas other phenomena, such as pronouns and ellipsis are dis-preferred. We use open-domain question answering systems as our test-bed for task based dialog generation and compare several open- and closed-book models. Our results highlight the danger of systems that appear to be trustworthy by parroting user input while providing an unfaithful response. | Sabrina Chiesurin, Dimitris Dimakopoulos, Marco Antonio Sobrevilla Cabezudo, Arash Eshghi, Ioannis Papaioannou, Verena Rieser, Ioannis Konstas |  |
| 403 |  |  [Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker](https://doi.org/10.18653/v1/2023.findings-acl.61) |  | 0 | Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans against other prompt optimization methods. | Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Jong C. Park |  |
| 404 |  |  [Triggering Multi-Hop Reasoning for Question Answering in Language Models using Soft Prompts and Random Walks](https://doi.org/10.18653/v1/2023.findings-acl.62) |  | 0 | Despite readily memorizing world knowledge about entities, pre-trained language models (LMs) struggle to compose together two or more facts to perform multi-hop reasoning in question-answering tasks. In this work, we propose techniques that improve upon this limitation by relying on random-walks over structured knowledge graphs. Specifically, we use soft-prompts to guide LMs to chain together their encoded knowledge by learning to map multi-hop questions to random-walk paths that lead to the answer. Applying our methods on two T5 LMs shows substantial improvements over standard tuning approaches in answering questions that require multi-hop reasoning. | Kanishka Misra, Cícero Nogueira dos Santos, Siamak Shakeri |  |
| 405 |  |  [Multimedia Generative Script Learning for Task Planning](https://doi.org/10.18653/v1/2023.findings-acl.63) |  | 0 | Goal-oriented generative script learning aims to generate subsequent steps to reach a particular goal, which is an essential task to assist robots or humans in performing stereotypical activities. An important aspect of this process is the ability to capture historical states visually, which provides detailed information that is not covered by text and will guide subsequent steps. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 5,652 tasks and 79,089 multimedia steps. This task is challenging in three aspects: the multimedia challenge of capturing the visual states in images, the induction challenge of performing unseen tasks, and the diversity challenge of covering different information in individual steps. We propose to encode visual state changes through a selective multimedia encoder to address the multimedia challenge, transfer knowledge from previously observed tasks using a retrieval-augmented decoder to overcome the induction challenge, and further present distinct information at each step by optimizing a diversity-oriented contrastive learning objective. We define metrics to evaluate both generation and inductive quality. Experiment results demonstrate that our approach significantly outperforms strong baselines. | Qingyun Wang, Manling Li, Hou Pong Chan, Lifu Huang, Julia Hockenmaier, Girish Chowdhary, Heng Ji |  |
| 406 |  |  [Label Agnostic Pre-training for Zero-shot Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.64) |  | 0 | Conventional approaches to text classification typically assume the existence of a fixed set of predefined labels to which a given text can be classified. However, in real-world applications, there exists an infinite label space for describing a given text. In addition, depending on the aspect (sentiment, topic, etc.) and domain of the text (finance, legal, etc.), the interpretation of the label can vary greatly. This makes the task of text classification, particularly in the zero-shot scenario, extremely challenging. In this paper, we investigate the task of zero-shot text classification with the aim of improving the ability of pre-trained language models (PLMs) to generalize to both seen and unseen data across varying aspects and domains. To solve this we introduce two new simple yet effective pre-training strategies, Implicit and Explicit pre-training. These methods inject aspect-level understanding into the model at train time with the goal of conditioning the model to build task-level understanding. To evaluate this, we construct and release UTCD, a new benchmark dataset for evaluating text classification in zero-shot settings. Experimental results on UTCD show that our approach achieves improved zero-shot generalization on a suite of challenging datasets across an array of zero-shot formalizations. | Christopher Clarke, Yuzhao Heng, Yiping Kang, Krisztián Flautner, Lingjia Tang, Jason Mars |  |
| 407 |  |  [Click: Controllable Text Generation with Sequence Likelihood Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-acl.65) |  | 0 | It has always been an important yet challenging problem to control language models to avoid generating texts with undesirable attributes, such as toxic language and unnatural repetition. We introduce Leo for controllable text generation, which needs no modification to the model architecture and facilitates out-of-the-box use of trained models. It employs a contrastive loss on sequence likelihood, which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes). It also adopts a novel likelihood ranking-based strategy to construct contrastive samples from model generations. On the tasks of language detoxification, sentiment steering, and repetition reduction, we show that Leo outperforms strong baselines of controllable text generation and demonstrate the superiority of Leo’s sample construction strategy. | Chujie Zheng, Pei Ke, Zheng Zhang, Minlie Huang |  |
| 408 |  |  [Improving Embedding-based Unsupervised Keyphrase Extraction by Incorporating Structural Information](https://doi.org/10.18653/v1/2023.findings-acl.66) |  | 0 | Keyphrase extraction aims to extract a set of phrases with the central idea of the source document. In a structured document, there are certain locations (e.g., the title or the first sentence) where a keyphrase is most likely to appear. However, when extracting keyphrases from the document, most existing embedding-based unsupervised keyphrase extraction models ignore the indicative role of the highlights in certain locations, leading to wrong keyphrases extraction. In this paper, we propose a new Highlight-Guided Unsupervised Keyphrase Extraction model (HGUKE) to address the above issue. Specifically, HGUKE first models the phrase-document relevance via the highlights of the documents. Next, HGUKE calculates the cross-phrase relevance between all candidate phrases. Finally, HGUKE aggregates the above two relevance as the importance score of each candidate phrase to rank and extract keyphrases. The experimental results on three benchmarks demonstrate that HGUKE outperforms the state-of-the-art unsupervised keyphrase extraction baselines. | Mingyang Song, Huafeng Liu, Yi Feng, Liping Jing |  |
| 409 |  |  [Towards Reasoning in Large Language Models: A Survey](https://doi.org/10.18653/v1/2023.findings-acl.67) |  | 0 | Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work. | Jie Huang, Kevin ChenChuan Chang |  |
| 410 |  |  [Transitioning from benchmarks to a real-world case of information-seeking in Scientific Publications](https://doi.org/10.18653/v1/2023.findings-acl.68) |  | 0 | Although recent years have been marked by incredible advances in the whole development process of NLP systems, there are still blind spots in characterizing what is still hampering real-world adoption of models in knowledge-intensive settings. In this paper, we illustrate through a real-world zero-shot text search case for information seeking in scientific papers, the masked phenomena that the current process of measuring performance might not reflect, even when benchmarks are, in appearance, faithfully representative of the task at hand. In addition to experimenting with TREC-COVID and NFCorpus, we provide an industrial, expert-carried/annotated, case of studying vitamin B’s impact on health. We thus discuss the misalignment between solely focusing on single-metric performance as a criterion for model choice and relevancy as a subjective measure for meeting a user’s need. | Chyrine Tahri, Aurore Bochnakian, Patrick Haouat, Xavier Tannier |  |
| 411 |  |  [CLIPText: A New Paradigm for Zero-shot Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.69) |  | 0 | While CLIP models are useful for zero-shot vision-and-language (VL) tasks or computer vision tasks, little attention has been paid to the application of CLIP for language tasks. Intuitively, CLIP model have a rich representation pre-trained with natural language supervision, in which we argue that it is useful for language tasks. Hence, this work bridge this gap by investigating a CLIP model for zero-shot text classification. Specifically, we introduce CLIPText, a novel paradigm for zero-shot text classification, which reformulates zero-shot text classification into a text-image matching problem that CLIP can be applied to. In addition, we further incorporate prompt into CLIPText (Prompt-CLIPText) to better derive knowledge from CLIP. Experimental results on seven publicly available zero-shot text classification datasets show that both CLIPText and Prompt-CLIPText attain promising performance. Besides, extensive analysis further verifies that knowledge from CLIP can benefit zero-shot text classification task. We hope this work can attract more breakthroughs on applying VL pre-trained models for language tasks. | Libo Qin, Weiyun Wang, Qiguang Chen, Wanxiang Che |  |
| 412 |  |  [Rethinking Dictionaries and Glyphs for Chinese Language Pre-training](https://doi.org/10.18653/v1/2023.findings-acl.70) |  | 0 | We introduce CDBert, a new learning paradigm that enhances the semantics understanding ability of the Chinese PLMs with dictionary knowledge and structure of Chinese characters. We name the two core modules of CDBert as Shuowen and Jiezi, where Shuowen refers to the process of retrieving the most appropriate meaning from Chinese dictionaries and Jiezi refers to the process of enhancing characters’ glyph representations with structure understanding. To facilitate dictionary understanding, we propose three pre-training tasks, i.e.„ Masked Entry Modeling, Contrastive Learning for Synonym and Antonym, and Example Learning. We evaluate our method on both modern Chinese understanding benchmark CLUE and ancient Chinese benchmark CCLUE. Moreover, we propose a new polysemy discrimination task PolyMRC based on the collected dictionary of ancient Chinese. Our paradigm demonstrates consistent improvements on previous Chinese PLMs across all tasks. Moreover, our approach yields significant boosting on few-shot setting of ancient Chinese understanding. | Yuxuan Wang, Jianghui Wang, Dongyan Zhao, Zilong Zheng |  |
| 413 |  |  [One Embedder, Any Task: Instruction-Finetuned Text Embeddings](https://doi.org/10.18653/v1/2023.findings-acl.71) |  | 0 | We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our analysis suggests that INSTRUCTOR is robust to changes in instructions, and that instruction finetuning mitigates the challenge of training a single model on diverse datasets. Our model, code, and data are available at https://instructor-embedding.github.io. | Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wentau Yih, Noah A. Smith, Luke Zettlemoyer, Tao Yu |  |
| 414 |  |  [Towards Speech Dialogue Translation Mediating Speakers of Different Languages](https://doi.org/10.18653/v1/2023.findings-acl.72) |  | 0 | We present a new task, speech dialogue translation mediating speakers of different languages. We construct the SpeechBSD dataset for the task and conduct baseline experiments. Furthermore, we consider context to be an important aspect that needs to be addressed in this task and propose two ways of utilizing context, namely monolingual context and bilingual context. We conduct cascaded speech translation experiments using Whisper and mBART, and show that bilingual context performs better in our settings. | Shuichiro Shimizu, Chenhui Chu, Sheng Li, Sadao Kurohashi |  |
| 415 |  |  [Adaptation Approaches for Nearest Neighbor Language Models](https://doi.org/10.18653/v1/2023.findings-acl.73) |  | 0 | Semi-parametric Nearest Neighbor Language Models (kNN-LMs) have produced impressive gains over purely parametric LMs, by leveraging large-scale neighborhood retrieval over external memory datastores. However, there has been little investigation into adapting such models for new domains. This work attempts to fill that gap and suggests the following approaches for adapting kNN-LMs — 1) adapting the underlying LM (using Adapters), 2) expanding neighborhood retrieval over an additional adaptation datastore, and 3) adapting the weights (scores) of retrieved neighbors using a learned Rescorer module. We study each adaptation strategy separately, as well as the combined performance improvement through ablation experiments and an extensive set of evaluations run over seven adaptation domains. Our combined adaptation approach consistently outperforms purely parametric adaptation and zero-shot (kNN-LM) baselines that construct datastores from the adaptation data. On average, we see perplexity improvements of 17.1% and 16% for these respective baselines, across domains. | Rishabh Bhardwaj, George Polovets, Monica Sunkara |  |
| 416 |  |  [Language Models for German Text Simplification: Overcoming Parallel Data Scarcity through Style-specific Pre-training](https://doi.org/10.18653/v1/2023.findings-acl.74) |  | 0 | Automatic text simplification systems help to reduce textual information barriers on the internet. However, for languages other than English, only few parallel data to train these systems exists. We propose a two-step approach to overcome this data scarcity issue. First, we fine-tuned language models on a corpus of German Easy Language, a specific style of German. Then, we used these models as decoders in a sequence-to-sequence simplification task. We show that the language models adapt to the style characteristics of Easy Language and output more accessible texts. Moreover, with the style-specific pre-training, we reduced the number of trainable parameters in text simplification models. Hence, less parallel data is sufficient for training. Our results indicate that pre-training on unaligned data can reduce the required parallel data while improving the performance on downstream tasks. | Miriam Anschütz, Joshua Oehms, Thomas Wimmer, Bartlomiej Jezierski, Georg Groh |  |
| 417 |  |  [Client-Customized Adaptation for Parameter-Efficient Federated Learning](https://doi.org/10.18653/v1/2023.findings-acl.75) |  | 0 | Despite the versatility of pre-trained language models (PLMs) across domains, their large memory footprints pose significant challenges in federated learning (FL), where the training model has to be distributed between a server and clients. One potential solution to bypass such constraints might be the use of parameter-efficient fine-tuning (PEFT) in the context of FL. However, we have observed that typical PEFT tends to severely suffer from heterogeneity among clients in FL scenarios, resulting in unstable and slow convergence. In this paper, we propose Client-Customized Adaptation (C2A), a novel hypernetwork-based FL framework that generates client-specific adapters by conditioning the client information. With the effectiveness of the hypernetworks in generating customized weights through learning to adopt the different characteristics of inputs, C2A can maximize the utility of shared model parameters while minimizing the divergence caused by client heterogeneity. To verify the efficacy of C2A, we perform extensive evaluations on FL scenarios involving heterogeneity in label and language distributions. Comprehensive evaluation results clearly support the superiority of C2A in terms of both efficiency and effectiveness in FL scenarios. | Yeachan Kim, Junho Kim, WingLam Mok, JunHyung Park, SangKeun Lee |  |
| 418 |  |  [FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery](https://doi.org/10.18653/v1/2023.findings-acl.76) |  | 0 | Understanding users’ intentions in e-commerce platforms requires commonsense knowledge. In this paper, we present FolkScope, an intention knowledge graph construction framework, to reveal the structure of humans’ minds about purchasing items. As commonsense knowledge is usually ineffable and not expressed explicitly, it is challenging to perform information extraction. Thus, we propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph. LLMs first generate intention assertions via e-commerce specific prompts to explain shopping behaviors, where the intention can be an open reason or a predicate falling into one of 18 categories aligning with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility and typicality labels of sampled intentions as training data in order to populate human judgments to all automatic generations. Last, to structurize the assertions, we propose pattern mining and conceptualization to form more condensed and abstract knowledge. Extensive evaluations and study demonstrate that our constructed knowledge graph can well model e-commerce knowledge and have many potential applications. | Changlong Yu, Weiqi Wang, Xin Liu, Jiaxin Bai, Yangqiu Song, Zheng Li, Yifan Gao, Tianyu Cao, Bing Yin |  |
| 419 |  |  [I am PsyAM: Modeling Happiness with Cognitive Appraisal Dimensions](https://doi.org/10.18653/v1/2023.findings-acl.77) |  | 0 | This paper proposes and evaluates PsyAM (https://anonymous.4open.science/r/BERT-PsyAM-10B9), a framework that incorporates adaptor modules in a sequential multi-task learning setup to generate high-dimensional feature representations of hedonic well-being (momentary happiness) in terms of its psychological underpinnings. PsyAM models emotion in text through its cognitive antecedents through auxiliary models that achieve multi-task learning through novel feature fusion methods. We show that BERT-PsyAM has cross-task validity and cross-domain generalizability through experiments with emotion-related tasks – on new emotion tasks and new datasets, as well as against traditional methods and BERT baselines. We further probe the robustness of BERT-PsyAM through feature ablation studies, as well as discuss the qualitative inferences we can draw regarding the effectiveness of the framework for representing emotional states. We close with a discussion of a future agenda of psychology-inspired neural network architectures. | Xuan Liu, Kokil Jaidka |  |
| 420 |  |  [Value type: the bridge to a better DST model](https://doi.org/10.18653/v1/2023.findings-acl.78) |  | 0 | Value type of the slots can provide lots of useful information for DST tasks. However, it has been ignored in most previous works. In this paper, we propose a new framework for DST task based on these value types. Firstly, we extract the type of token from each turn. Specifically, we divide the slots in the dataset into 9 categories according to the type of slot value, and then train a Ner model to extract the corresponding type-entity from each turn of conversation according to the token. Secondly, we improve the attention mode which is integrated into value type information between the slot and the conversation history to help each slot pay more attention to the turns that contain the same value type. Meanwhile, we introduce a sampling strategy to integrate these types into the attention formula, which decrease the error of Ner model. Finally, we conduct a comprehensive experiment on two multi-domain task-oriented conversation datasets, MultiWOZ 2.1 and MultiWOZ 2.4. The ablation experimental results show that our method is effective on both datasets, which verify the necessity of considering the type of slot value. | QiXiang Gao, Mingyang Sun, Yutao Mou, Chen Zeng, Weiran Xu |  |
| 421 |  |  [Hypothetical Training for Robust Machine Reading Comprehension of Tabular Context](https://doi.org/10.18653/v1/2023.findings-acl.79) |  | 0 | Machine Reading Comprehension (MRC) models easily learn spurious correlations from complex contexts such as tabular data. Counterfactual training—using the factual and counterfactual data by augmentation—has become a promising solution. However, it is costly to construct faithful counterfactual examples because it is tricky to maintain the consistency and dependency of the tabular data. In this paper, we take a more efficient fashion to ask hypothetical questions like “in which year would the net profit be larger if the revenue in 2019 were $38,298?”, whose effects on the answers are equivalent to those expensive counterfactual tables. We propose a hypothetical training framework that uses paired examples with different hypothetical questions to supervise the direction of model gradient towards the counterfactual answer change. The superior generalization results on tabular MRC datasets, including a newly constructed stress test and MultiHiertt, validate our effectiveness. | Moxin Li, Wenjie Wang, Fuli Feng, Hanwang Zhang, Qifan Wang, TatSeng Chua |  |
| 422 |  |  [BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews](https://doi.org/10.18653/v1/2023.findings-acl.80) |  | 0 | The analysis of consumer sentiment, as expressed through reviews, can provide a wealth of insight regarding the quality of a product. While the study of sentiment analysis has been widely explored in many popular languages, relatively less attention has been given to the Bangla language, mostly due to a lack of relevant data and cross-domain adaptability. To address this limitation, we present BanglaBook, a large-scale dataset of Bangla book reviews consisting of 158,065 samples classified into three broad categories: positive, negative, and neutral. We provide a detailed statistical analysis of the dataset and employ a range of machine learning models to establish baselines including SVM, LSTM, and Bangla-BERT. Our findings demonstrate a substantial performance advantage of pre-trained models over models that rely on manually crafted features, emphasizing the necessity for additional training resources in this domain. Additionally, we conduct an in-depth error analysis by examining sentiment unigrams, which may provide insight into common classification errors in under-resourced languages like Bangla. Our codes and data are publicly available at https://github.com/mohsinulkabir14/BanglaBook. | Mohsinul Kabir, Obayed Bin Mahfuz, Syed Rifat Raiyan, Hasan Mahmud, Md. Kamrul Hasan |  |
| 423 |  |  [Risks and NLP Design: A Case Study on Procedural Document QA](https://doi.org/10.18653/v1/2023.findings-acl.81) |  | 0 | As NLP systems are increasingly deployed at scale, concerns about their potential negative impacts have attracted the attention of the research community, yet discussions of risk have mostly been at an abstract level and focused on generic AI or NLP applications. We argue that clearer assessments of risks and harms to users—and concrete strategies to mitigate them—will be possible when we specialize the analysis to more concrete applications and their plausible users. As an illustration, this paper is grounded in cooking recipe procedural document question answering (ProcDocQA), where there are well-defined risks to users such as injuries or allergic reactions. Our case study shows that an existing language model, applied in “zero-shot” mode, quantitatively answers real-world questions about recipes as well or better than the humans who have answered the questions on the web. Using a novel questionnaire informed by theoretical work on AI risk, we conduct a risk-oriented error analysis that could then inform the design of a future system to be deployed with lower risk of harm and better performance. | Nikita Haduong, Alice Gao, Noah A. Smith |  |
| 424 |  |  [The Diminishing Returns of Masked Language Models to Science](https://doi.org/10.18653/v1/2023.findings-acl.82) |  | 0 | Transformer-based masked language models such as BERT, trained on general corpora, have shown impressive performance on downstream tasks. It has also been demonstrated that the downstream task performance of such models can be improved by pretraining larger models for longer on more data. In this work, we empirically evaluate the extent to which these results extend to tasks in science. We use 14 domain-specific transformer-based models (including ScholarBERT, a new 770Mparameter science-focused masked language model pretrained on up to 225B tokens) to evaluate the impact of training data, model size, pretraining and finetuning time on 12 downstream scientific tasks. Interestingly, we find that increasing model size, training data, or compute time does not always lead to significant improvements (i.e., >1% F1), if any, in scientific information extraction tasks. We offer possible explanations for this surprising result. | Zhi Hong, Aswathy Ajith, J. Gregory Pauloski, Eamon Duede, Kyle Chard, Ian T. Foster |  |
| 425 |  |  [Causal Matching with Text Embeddings: A Case Study in Estimating the Causal Effects of Peer Review Policies](https://doi.org/10.18653/v1/2023.findings-acl.83) |  | 0 | A promising approach to estimate the causal effects of peer review policies is to analyze data from publication venues that shift policies from single-blind to double-blind from one year to the next. However, in these settings the content of the manuscript is a confounding variable—each year has a different distribution of scientific content which may naturally affect the distribution of reviewer scores. To address this textual confounding, we extend variable ratio nearest neighbor matching to incorporate text embeddings. We compare this matching method to a widely-used causal method of stratified propensity score matching and a baseline of randomly selected matches. For our case study of the ICLR conference shifting from single- to double-blind review from 2017 to 2018, we find human judges prefer manuscript matches from our method in 70% of cases. While the unadjusted estimate of the average causal effect of reviewers’ scores is -0.25, our method shifts the estimate to -0.17, a slightly smaller difference between the outcomes of single- and double-blind policies. We hope this case study enables exploration of additional text-based causal estimation methods and domains in the future. | Raymond Zhang, Neha Nayak Kennard, Daniel Scott Smith, Daniel A. McFarland, Andrew McCallum, Katherine Keith |  |
| 426 |  |  [Learning to Generalize for Cross-domain QA](https://doi.org/10.18653/v1/2023.findings-acl.84) |  | 0 | There have been growing concerns regarding the out-of-domain generalization ability of natural language processing (NLP) models, particularly in question-answering (QA) tasks. Current synthesized data augmentation methods for QA are hampered by increased training costs. To address this issue, we propose a novel approach that combines prompting methods and linear probing with fine-tuning strategy, which does not entail additional cost. Our method has been theoretically and empirically shown to be effective in enhancing the generalization ability of both generative and discriminative models. Our approach outperforms state-of-the-art baselines, with an average increase in F1 score of 4.5%-7.9%. Furthermore, our method can be easily integrated into any pre-trained models and offers a promising solution to the under-explored cross-domain QA task. | Yingjie Niu, Linyi Yang, Ruihai Dong, Yue Zhang |  |
| 427 |  |  [Enhanced Chart Understanding via Visual Language Pre-training on Plot Table Pairs](https://doi.org/10.18653/v1/2023.findings-acl.85) |  | 0 | Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language (V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over 8% performance gains. | Mingyang Zhou, Yi Ren Fung, Long Chen, Christopher Thomas, Heng Ji, ShihFu Chang |  |
| 428 |  |  [Importance of Synthesizing High-quality Data for Text-to-SQL Parsing](https://doi.org/10.18653/v1/2023.findings-acl.86) |  | 0 | There has been increasing interest in synthesizing data to improve downstream text-to-SQL tasks. In this paper, we examined the existing synthesized datasets and discovered that state-of-the-art text-to-SQL algorithms did not further improve on popular benchmarks when trained with augmented synthetic data. We observed three shortcomings: illogical synthetic SQL queries from independent column sampling, arbitrary table joins, and language gaps between the synthesized SQL and natural language question (NLQ) pair. To address these issues, we propose a novel synthesis framework that imposes strong typing constraints, incorporates key relationships from schema, and conducts schema-distance-weighted column sampling. We also adopt an intermediate representation (IR) for the SQL-to-text task to further improve the quality of the generated NLQ. When existing powerful text-to-SQL parsers are pretrained on our high-quality synthesized data, these models have significant accuracy boosts and achieve new state-of-the-art performance on Spider. We also demonstrate the effectiveness of our techniques with ablation studies | Yiqun Hu, Yiyun Zhao, Jiarong Jiang, Wuwei Lan, Henghui Zhu, Anuj Chauhan, Alexander Hanbo Li, Lin Pan, Jun Wang, ChungWei Hang, Sheng Zhang, Jiang Guo, Mingwen Dong, Joseph Lilien, Patrick Ng, Zhiguo Wang, Vittorio Castelli, Bing Xiang |  |
| 429 |  |  [Exploring Schema Generalizability of Text-to-SQL](https://doi.org/10.18653/v1/2023.findings-acl.87) |  | 0 | Exploring the generalizability of a text-to-SQL parser is essential for a system to automatically adapt the real-world databases. Previous investigation works mostly focus on lexical diversity, including the influence of the synonym and perturbations in both natural language questions and databases. However, the structural variability of database schema (DS), as a widely seen real-world scenario, is yet underexplored. Specifically, confronted with the same input question, the target SQL may be represented in different ways when the DS comes to a different structure. In this work, we provide in-depth discussions about the schema generalizability challenge of text-to-SQL tasks. We observe that current datasets are too templated to study schema generalization. To collect suitable test data, we propose a framework to generate novel text-to-SQL data via automatic and synchronous (DS, SQL) pair altering. When evaluating state-of-the-art text-to-SQL models on the synthetic samples, performance is significantly degraded, which demonstrates the limitation of current research regarding schema generalization. | Jieyu Li, Lu Chen, Ruisheng Cao, Su Zhu, Hongshen Xu, Zhi Chen, Hanchong Zhang, Kai Yu |  |
| 430 |  |  [Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer](https://doi.org/10.18653/v1/2023.findings-acl.88) |  | 0 | Cross-lingual natural language inference is a fundamental problem in cross-lingual language understanding. Many recent works have used prompt learning to address the lack of annotated parallel corpora in XNLI.However, these methods adopt discrete prompting by simply translating the templates to the target language and need external expert knowledge to design the templates. Besides, discrete prompts of human-designed template words are not trainable vectors and can not be migrated to target languages in the inference stage flexibly. In this paper, we propose a novel Soft prompt learning framework with the Multilingual Verbalizer (SoftMV) for XNLI. SoftMV first constructs cloze-style question with soft prompts for the input sample. Then we leverage bilingual dictionaries to generate an augmented multilingual question for the original question. SoftMV adopts a multilingual verbalizer to align the representations of original and augmented multilingual questions into a unified semantic space with consistency regularization. Experimental results on XNLI demonstrate that SoftMV can achieve state-of-the-art performance and significantly outperform the previous methods under the few-shot and full-shot cross-lingual transfer settings. | Shuang Li, Xuming Hu, Aiwei Liu, Yawen Yang, Fukun Ma, Philip S. Yu, Lijie Wen |  |
| 431 |  |  [A Confidence-based Partial Label Learning Model for Crowd-Annotated Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.89) |  | 0 | Existing models for named entity recognition (NER) are mainly based on large-scale labeled datasets, which always obtain using crowdsourcing. However, it is hard to obtain a unified and correct label via majority voting from multiple annotators for NER due to the large labeling space and complexity of this task. To address this problem, we aim to utilize the original multi-annotator labels directly. Particularly, we propose a CONfidence-based partial Label Learning (CONLL) method to integrate the prior confidence (given by annotators) and posterior confidences (learned by models) for crowd-annotated NER. This model learns a token- and content-dependent confidence via an Expectation–Maximization (EM) algorithm by minimizing empirical risk. The true posterior estimator and confidence estimator perform iteratively to update the true posterior and confidence respectively. We conduct extensive experimental results on both real-world and synthetic datasets, which show that our model can improve performance effectively compared with strong baselines. | Limao Xiong, Jie Zhou, Qunxi Zhu, Xiao Wang, Yuanbin Wu, Qi Zhang, Tao Gui, Xuanjing Huang, Jin Ma, Ying Shan |  |
| 432 |  |  [Towards Zero-Shot Persona Dialogue Generation with In-Context Learning](https://doi.org/10.18653/v1/2023.findings-acl.90) |  | 0 | Much work has been done to improve persona consistency by finetuning a pretrained dialogue model on high-quality human-annoated persona datasets. However, these methods still face the challenges of high cost and poor scalability. To this end, we propose a simple-yet-effective approach to significantly improve zero-shot persona consistency via in-context learning. Specifically, we first pre-train a persona-augmented dialogue generation model and then utilize in-context prompting mechanism to realize zero-shot persona customization. Experimental results demonstrate that our method can dramatically improve persona consistency without compromising coherence and informativeness in zero-shot settings. | Xinchao Xu, Zeyang Lei, Wenquan Wu, ZhengYu Niu, Hua Wu, Haifeng Wang |  |
| 433 |  |  [Grammar-based Decoding for Improved Compositional Generalization in Semantic Parsing](https://doi.org/10.18653/v1/2023.findings-acl.91) |  | 0 | Sequence-to-sequence (seq2seq) models have achieved great success in semantic parsing tasks, but they tend to struggle on out-of-distribution (OOD) data. Despite recent progress, robust semantic parsing on large-scale tasks with combined challenges from both compositional generalization and natural language variations remains an unsolved problem. To promote research in this area, this work presents CUDON, a large-scale dialogue dataset in Chinese language, particularly designed for evaluating compositional generalization of semantic parsing. The dataset contains about ten thousand multi-turn complex queries, and provides multiple splits with different degrees of train-test distribution divergence. We have investigated improving compositional generalization with grammar-based decodering on this dataset. With specially designed grammars leveraging program schema, we are able to substantially improve accuracy of seq2seq semantic parsers on OOD splits: A LSTM-based parser using a Context-free Grammar (CFG) achieves over 25% higher accuracy than a standard seq2seq baseline; a parser using Tree-Substitution Grammar (TSG) improves parsing speed five to seven times over the CFG parser with only a small accuracy loss. The grammar-based LSTM parsers also outperforms BART- and T5-based seq2seq parsers on the OOD splits, despite having less than one tenth of parameters and no pretraining. We also verified our approach on the SMCalflow-CS dataset, particularly, on the zero-shot learning task. | Jing Zheng, JyhHerng Chow, Zhongnan Shen, Peng Xu |  |
| 434 |  |  [Exploiting Rich Textual User-Product Context for Improving Personalized Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.92) |  | 0 | User and product information associated with a review is useful for sentiment polarity prediction. Typical approaches incorporating such information focus on modeling users and products as implicitly learned representation vectors. Most do not exploit the potential of historical reviews, or those that currently do require unnecessary modifications to model architectureor do not make full use of user/product associations. The contribution of this work is twofold: i) a method to explicitly employ historical reviews belonging to the same user/product in initializing representations, and ii) efficient incorporation of textual associations between users and products via a user-product cross-context module. Experiments on the IMDb, Yelp-2013 and Yelp-2014 English benchmarks with BERT, SpanBERT and Longformer pretrained language models show that our approach substantially outperforms previous state-of-the-art. | Chenyang Lyu, Linyi Yang, Yue Zhang, Yvette Graham, Jennifer Foster |  |
| 435 |  |  [Efficient Out-of-Domain Detection for Sequence to Sequence Models](https://doi.org/10.18653/v1/2023.findings-acl.93) |  | 0 | Sequence-to-sequence (seq2seq) models based on the Transformer architecture have become a ubiquitous tool applicable not only to classical text generation tasks such as machine translation and summarization but also to any other task where an answer can be represented in a form of a finite text fragment (e.g., question answering). However, when deploying a model in practice, we need not only high performance but also an ability to determine cases where the model is not applicable. Uncertainty estimation (UE) techniques provide a tool for identifying out-of-domain (OOD) input where the model is susceptible to errors. State-of-the-art UE methods for seq2seq models rely on computationally heavyweight and impractical deep ensembles. In this work, we perform an empirical investigation of various novel UE methods for large pre-trained seq2seq models T5 and BART on three tasks: machine translation, text summarization, and question answering. We apply computationally lightweight density-based UE methods to seq2seq models and show that they often outperform heavyweight deep ensembles on the task of OOD detection. | Artem Vazhentsev, Akim Tsvigun, Roman Vashurin, Sergey Petrakov, Daniil Vasilev, Maxim Panov, Alexander Panchenko, Artem Shelmanov |  |
| 436 |  |  [Emotion Cause Extraction on Social Media without Human Annotation](https://doi.org/10.18653/v1/2023.findings-acl.94) |  | 0 | In social media, there is a vast amount of information pertaining to people’s emotions and the corresponding causes. The emotion cause extraction (ECE) from social media data is an important research area that has not been thoroughly explored due to the lack of fine-grained annotations. Early studies referred to either unsupervised rule-based methods or supervised machine learning methods using a number of manually annotated data in specific domains. However, the former suffers from limitations in extraction performance, while the latter is constrained by the availability of fine-grained annotations and struggles to generalize to diverse domains. To address these issues, this paper proposes a new ECE framework on Chinese social media that achieves high extraction performance and generalizability without relying on human annotation. Specifically, we design a more dedicated rule-based system based on constituency parsing tree to discover causal patterns in social media. This system enables us to acquire large amounts of fine-grained annotated data. Next, we train a neural model on the rule-annotated dataset with a specific training strategy to further improve the model’s generalizability. Extensive experiments demonstrate the superiority of our approach over other methods in unsupervised and weakly-supervised settings. | Debin Xiao, Rui Xia, Jianfei Yu |  |
| 437 |  |  [Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers](https://doi.org/10.18653/v1/2023.findings-acl.95) |  | 0 | For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold.A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers.A comprehensive comparison with state-of-the-art algorithms demonstrates POE’s competitiveness on several text classification benchmarks. | Jaeyoung Kim, Kyuheon Jung, Dongbin Na, Sion Jang, Eunbin Park, Sungchul Choi |  |
| 438 |  |  [Adversarial Multi-task Learning for End-to-end Metaphor Detection](https://doi.org/10.18653/v1/2023.findings-acl.96) |  | 0 | Metaphor detection (MD) suffers from limited training data. In this paper, we started with a linguistic rule called Metaphor Identification Procedure and then proposed a novel multi-task learning framework to transfer knowledge in basic sense discrimination (BSD) to MD. BSD is constructed from word sense disambiguation (WSD), which has copious amounts of data. We leverage adversarial training to align the data distributions of MD and BSD in the same feature space, so task-invariant representations can be learned. To capture fine-grained alignment patterns, we utilize the multi-mode structures of MD and BSD. Our method is totally end-to-end and can mitigate the data scarcity problem in MD. Competitive results are reported on four public datasets. Our code and datasets are available. | Shenglong Zhang, Ying Liu |  |
| 439 |  |  [SERENGETI: Massively Multilingual Language Models for Africa](https://doi.org/10.18653/v1/2023.findings-acl.97) |  | 0 | Multilingual pretrained language models (mPLMs) acquire valuable, generalizable linguistic information during pretraining and have advanced the state of the art on task-specific finetuning. To date, only ~31 out of ~2,000 African languages are covered in existing language models. We ameliorate this limitation by developing SERENGETI, a set of massively multilingual language model that covers 517 African languages and language varieties. We evaluate our novel models on eight natural language understanding tasks across 20 datasets, comparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms other models on 11 datasets across the eights tasks, achieving 82.27 average F_1. We also perform analyses of errors from our models, which allows us to investigate the influence of language genealogy and linguistic similarity when the models are applied under zero-shot settings. We will publicly release our models for research. Anonymous link | Ife Adebara, AbdelRahim A. Elmadany, Muhammad AbdulMageed, Alcides Alcoba Inciarte |  |
| 440 |  |  [Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring](https://doi.org/10.18653/v1/2023.findings-acl.98) |  | 0 | Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity loss that encapsulates the correlations of traits. Experiments prove the efficacy of our model, showing state-of-the-art results for all prompts and traits. Significant improvements in low-resource-prompt and inferior traits further indicate our model’s strength. | Heejin Do, Yunsu Kim, Gary Geunbae Lee |  |
| 441 |  |  [AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation](https://doi.org/10.18653/v1/2023.findings-acl.99) |  | 0 | Crowdsourced dialogue corpora are usually limited in scale and topic coverage due to the expensive cost of data curation. This would hinder the generalization of downstream dialogue models to open-domain topics. In this work, we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). By treating dialogue augmentation as a dialogue completion task, we prompt a fine-tuned language model to complete full dialogues from available dialogue posts of various topics, which are then postprocessed based on heuristics. Applying this approach, we construct AugESC, an augmented dataset for the ESC task, which largely extends the scale and topic coverage of the crowdsourced ESConv corpus. Through comprehensive human evaluation, we demonstrate that our approach is superior to strong baselines of dialogue augmentation and that AugESC has comparable dialogue quality to the crowdsourced corpus. We also conduct human interactive evaluation and prove that post-training on AugESC improves downstream dialogue models’ generalization ability to open-domain topics. These results suggest the utility of AugESC and highlight the potential of large language models in improving data-scarce dialogue generation tasks. | Chujie Zheng, Sahand Sabour, Jiaxin Wen, Zheng Zhang, Minlie Huang |  |
| 442 |  |  [2\*n is better than n²: Decomposing Event Coreference Resolution into Two Tractable Problems](https://doi.org/10.18653/v1/2023.findings-acl.100) |  | 0 | Event Coreference Resolution (ECR) is the task of linking mentions of the same event either within or across documents. Most mention pairs are not coreferent, yet many that are coreferent can be identified through simple techniques such as lemma matching of the event triggers or the sentences in which they appear. Existing methods for training coreference systems sample from a largely skewed distribution, making it difficult for the algorithm to learn coreference beyond surface matching. Additionally, these methods are intractable because of the quadratic operations needed. To address these challenges, we break the problem of ECR into two parts: a) a heuristic to efficiently filter out a large number of non-coreferent pairs, and b) a training approach on a balanced set of coreferent and non-coreferent mention pairs. By following this approach, we show that we get comparable results to the state of the art on two popular ECR datasets while significantly reducing compute requirements. We also analyze the mention pairs that are “hard” to accurately classify as coreferent or non-coreferentcode repo: github.com/ahmeshaf/lemma_ce_coref. | Shafiuddin Rehan Ahmed, Abhijnan Nath, James H. Martin, Nikhil Krishnaswamy |  |
| 443 |  |  [SCCS: Semantics-Consistent Cross-domain Summarization via Optimal Transport Alignment](https://doi.org/10.18653/v1/2023.findings-acl.101) |  | 0 | Multimedia summarization with multimodal output (MSMO) is a recently explored application in language grounding. It plays an essential role in real-world applications, i.e., automatically generating cover images and titles for news articles or providing introductions to online videos. However, existing methods extract features from the whole video and article and use fusion methods to select the representative one, thus usually ignoring the critical structure and varying semantics with video/document. In this work, we propose a Semantics-Consistent Cross-domain Summarization (SCCS) model based on optimal transport alignment with visual and textual segmentation. Our method first decomposes both videos and articles into segments in order to capture the structural semantics, and then follows a cross-domain alignment objective with optimal transport distance, which leverages multimodal interaction to match and select the visual and textual summary. We evaluated our method on three MSMO datasets, and achieved performance improvement by 8% & 6% of textual and 6.6% &5.7% of video summarization, respectively, which demonstrated the effectiveness of our method in producing high-quality multimodal summaries. | Jielin Qiu, Jiacheng Zhu, Mengdi Xu, Franck Dernoncourt, Trung Bui, Zhaowen Wang, Bo Li, Ding Zhao, Hailin Jin |  |
| 444 |  |  [General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation](https://doi.org/10.18653/v1/2023.findings-acl.102) |  | 0 | Training keyphrase generation (KPG) models require a large amount of annotated data, which can be prohibitively expensive and often limited to specific domains. In this study, we first demonstrate that large distribution shifts among different domains severely hinder the transferability of KPG models. We then propose a three-stage pipeline, which gradually guides KPG models’ learning focus from general syntactical features to domain-related semantics, in a data-efficient manner. With domain-general phrase pre-training, we pre-train Sequence-to-Sequence models with generic phrase annotations that are widely available on the web, which enables the models to generate phrases in a wide range of domains. The resulting model is then applied in the Transfer Labeling stage to produce domain-specific pseudo keyphrases, which help adapt models to a new domain. Finally, we fine-tune the model with limited data with true labels to fully adapt it to the target domain. Our experiment results show that the proposed process can produce good quality keyphrases in new domains and achieve consistent improvements after adaptation with limited in-domain annotated data. All code and datasets are available at https://github.com/memray/OpenNMT-kpg-release. | Rui Meng, Tong Wang, Xingdi Yuan, Yingbo Zhou, Daqing He |  |
| 445 |  |  [E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.103) |  | 0 | Most named entity recognition (NER) systems focus on improving model performance, ignoring the need to quantify model uncertainty, which is critical to the reliability of NER systems in open environments. Evidential deep learning (EDL) has recently been proposed as a promising solution to explicitly model predictive uncertainty for classification tasks. However, directly applying EDL to NER applications faces two challenges, i.e., the problems of sparse entities and OOV/OOD entities in NER tasks. To address these challenges, we propose a trustworthy NER framework named E-NER by introducing two uncertainty-guided loss terms to the conventional EDL, along with a series of uncertainty-guided training strategies. Experiments show that E-NER can be applied to multiple NER paradigms to obtain accurate uncertainty estimation. Furthermore, compared to state-of-the-art baselines, the proposed method achieves a better OOV/OOD detection performance and better generalization ability on OOV entities. | Zhen Zhang, Mengting Hu, Shiwan Zhao, Minlie Huang, Haotian Wang, Lemao Liu, Zhirui Zhang, Zhe Liu, Bingzhe Wu |  |
| 446 |  |  [LMCap: Few-shot Multilingual Image Captioning by Retrieval Augmented Language Model Prompting](https://doi.org/10.18653/v1/2023.findings-acl.104) |  | 0 | Multilingual image captioning has recently been tackled by training with large-scale machine translated data, which is an expensive, noisy, and time-consuming process. Without requiring any multilingual caption data, we propose LMCap, an image-blind few-shot multilingual captioning model that works by prompting a language model with retrieved captions. Specifically, instead of following the standard encoder-decoder paradigm, given an image, LMCap first retrieves the captions of similar images using a multilingual CLIP encoder. These captions are then combined into a prompt for an XGLM decoder, in order to generate captions in the desired language. In other words, the generation model does not directly process the image, instead it processes retrieved captions. Experiments on the XM3600 dataset of geographically diverse images show that our model is competitive with fully-supervised multilingual captioning models, without requiring any supervised training on any captioning data. | Rita Ramos, Bruno Martins, Desmond Elliott |  |
| 447 |  |  [Boosting Text Augmentation via Hybrid Instance Filtering Framework](https://doi.org/10.18653/v1/2023.findings-acl.105) |  | 0 | Text augmentation is an effective technique for addressing the problem of insufficient data in natural language processing. However, existing text augmentation methods tend to focus on few-shot scenarios and usually perform poorly on large public datasets. Our research indicates that existing augmentation methods often generate instances with shifted feature spaces, which leads to a drop in performance on the augmented data (for example, EDA generally loses approximately 2% in aspect-based sentiment classification). To address this problem, we propose a hybrid instance-filtering framework (BoostAug) based on pre-trained language models that can maintain a similar feature space with natural datasets. BoostAug is transferable to existing text augmentation methods (such as synonym substitution and back translation) and significantly improves the augmentation performance by 2-3% in classification accuracy. Our experimental results on three classification tasks and nine public datasets show that BoostAug addresses the performance drop problem and outperforms state-of-the-art text augmentation methods. Additionally, we release the code to help improve existing augmentation methods on large datasets. | Heng Yang, Ke Li |  |
| 448 |  |  [Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal Review Helpfulness Prediction](https://doi.org/10.18653/v1/2023.findings-acl.106) |  | 0 | Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews based on predicted helpfulness scores and has been widely applied in e-commerce via presenting customers with useful reviews. Previous studies commonly employ fully-connected neural networks (FCNNs) as the final score predictor and pairwise loss as the training objective. However, FCNNs have been shown to perform inefficient splitting for review features, making the model difficult to clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise objective, which works on review pairs, may not completely capture the MRHP goal to produce the ranking for the entire review list, and possibly induces low generalization during testing. To address these issues, we propose a listwise attention network that clearly captures the MRHP ranking context and a listwise optimization objective that enhances model generalization. We further propose gradient-boosted decision tree as the score predictor to efficaciously partition product reviews’ representations. Extensive experiments demonstrate that our method achieves state-of-the-art results and polished generalization performance on two large-scale MRHP benchmark datasets. | Thong Nguyen, Xiaobao Wu, Xinshuai Dong, CongDuy Nguyen, Zhen Hai, Lidong Bing, Anh Tuan Luu |  |
| 449 |  |  [Extract and Attend: Improving Entity Translation in Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.107) |  | 0 | While Neural Machine Translation (NMT) has achieved great progress in recent years, it still suffers from inaccurate translation of entities (e.g., person/organization name, location), due to the lack of entity training instances. When we humans encounter an unknown entity during translation, we usually first look up in a dictionary and then organize the entity translation together with the translations of other parts to form a smooth target sentence. Inspired by this translation process, we propose an Extract-and-Attend approach to enhance entity translation in NMT, where the translation candidates of source entities are first extracted from a dictionary and then attended to by the NMT model to generate the target sentence. Specifically, the translation candidates are extracted by first detecting the entities in a source sentence and then translating the entities through looking up in a dictionary. Then, the extracted candidates are added as a prefix of the decoder input to be attended to by the decoder when generating the target sentence through self-attention. Experiments conducted on En-Zh and En-Ru demonstrate that the proposed method is effective on improving both the translation accuracy of entities and the overall translation quality, with up to 35% reduction on entity error rate and 0.85 gain on BLEU and 13.8 gain on COMET. | Zixin Zeng, Rui Wang, Yichong Leng, Junliang Guo, Shufang Xie, Xu Tan, Tao Qin, TieYan Liu |  |
| 450 |  |  [Real-World Compositional Generalization with Disentangled Sequence-to-Sequence Learning](https://doi.org/10.18653/v1/2023.findings-acl.108) |  | 0 | Compositional generalization is a basic mechanism in human language learning, which current neural networks struggle with. A recently proposed Disentangled sequence-to-sequence model (Dangle) shows promising generalization capability by learning specialized encodings for each decoding step. We introduce two key modifications to this model which encourage more disentangled representations and improve its compute and memory efficiency, allowing us to tackle compositional generalization in a more realistic setting. Specifically, instead of adaptively re-encoding source keys and values at each time step, we disentangle their representations and only re-encode keys periodically, at some interval. Our new architecture leads to better generalization performance across existing tasks and datasets, and a new machine translation benchmark which we create by detecting naturally occurring compositional patterns in relation to a training set. We show this methodology better emulates real-world requirements than artificial challenges. | Hao Zheng, Mirella Lapata |  |
| 451 |  |  [Cross-lingual AMR Aligner: Paying Attention to Cross-Attention](https://doi.org/10.18653/v1/2023.findings-acl.109) |  | 0 | This paper introduces a novel aligner for Abstract Meaning Representation (AMR) graphs that can scale cross-lingually, and is thus capable of aligning units and spans in sentences of different languages. Our approach leverages modern Transformer-based parsers, which inherently encode alignment information in their cross-attention weights, allowing us to extract this information during parsing. This eliminates the need for English-specific rules or the Expectation Maximization (EM) algorithm that have been used in previous approaches. In addition, we propose a guided supervised method using alignment to further enhance the performance of our aligner. We achieve state-of-the-art results in the benchmarks for AMR alignment and demonstrate our aligner’s ability to obtain them across multiple languages. Our code will be available at [https://www.github.com/babelscape/AMR-alignment](https://www.github.com/babelscape/AMR-alignment). | Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Roberto Navigli |  |
| 452 |  |  [Zero-Shot Text Classification via Self-Supervised Tuning](https://doi.org/10.18653/v1/2023.findings-acl.110) |  | 0 | Existing solutions to zero-shot text classification either conduct prompting with pre-trained language models, which is sensitive to the choices of templates, or rely on large-scale annotated data of relevant tasks for meta-tuning. In this work, we propose a new paradigm based on self-supervised learning to solve zero-shot text classification tasks by tuning the language models with unlabeled data, called self-supervised tuning. By exploring the inherent structure of free texts, we propose a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks. After tuning the model to learn to predict the first sentence in a paragraph based on the rest, the model is able to conduct zero-shot inference on unseen tasks such as topic classification and sentiment analysis. Experimental results show that our model outperforms the state-of-the-art baselines on 7 out of 10 tasks. Moreover, the analysis reveals that our model is less sensitive to the prompt design. Our code and pre-trained models are publicly available at https://github.com/DAMO-NLP-SG/SSTuning. | Chaoqun Liu, Wenxuan Zhang, Guizhen Chen, Xiaobao Wu, Anh Tuan Luu, ChipHong Chang, Lidong Bing |  |
| 453 |  |  [Logical Transformers: Infusing Logical Structures into Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.111) |  | 0 | Natural language contains rich logical structures and logical information, and correctly detecting and accurately understanding these logical structures and information underlying natural language texts is very crucial for NLP models’ performance on many important NLU and NLG tasks. Existing pre-trained language models based on the transformer architecture mostly adopt a classical design for constructing their input embeddings that ignores the logical structures underlying natural language texts, thus limiting their ability to better capture and encode key logical information in the input sequences. To overcome such limitations, in this paper we first propose a novel approach to construct logic-aware input embeddings for transformer language models through a combination of logic detection, logic mapping and hierarchical logical projections, and then develop a corresponding new modeling paradigm that can upgrade existing transformer language models into logical transformers to boost their performance on different NLU and NLG tasks. Our empirical experiments on four important and challenging NLU and NLG tasks demonstrate that our proposed logical transformer language models can achieve superior performance over their baseline transformer models through a deeper understanding of the logical structures of texts. | Borui Wang, Qiuyuan Huang, Budhaditya Deb, Aaron Halfaker, Liqun Shao, Daniel McDuff, Ahmed Hassan Awadallah, Dragomir Radev, Jianfeng Gao |  |
| 454 |  |  [Large Language Models with Controllable Working Memory](https://doi.org/10.18653/v1/2023.findings-acl.112) |  | 0 | Large language models (LLMs) have led to a series of breakthroughs in natural language processing (NLP), partly owing to the massive amounts of world knowledge they memorize during pretraining. While many downstream applications provide the model with an informational context to aid its underlying task, how the model’s world knowledge interacts with the factual information presented in the context remains under explored. As a desirable behavior, an LLM should give precedence to the context whenever it contains task-relevant information that conflicts with the model’s memorized knowledge. This enables model predictions to be grounded in the context, which then facilitates updating specific model predictions without frequently retraining the model. By contrast, when the context is irrelevant to the task, the model should ignore it and fall back on its internal knowledge. In this paper, we undertake a first joint study of the aforementioned two properties, namely controllability and robustness, in the context of LLMs. We demonstrate that state-of-the-art T5 and PaLM models (both pretrained and finetuned) could exhibit low controllability and robustness that does not improve with increasing the model size. As a solution, we propose a simple yet effective method – knowledge aware finetuning (KAFT) – to strengthen both controllability and robustness by injecting counterfactual and irrelevant contexts to standard supervised datasets. Our comprehensive evaluation showcases the utility of KAFT across model architectures and sizes. | Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix X. Yu, Sanjiv Kumar |  |
| 455 |  |  [A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution](https://doi.org/10.18653/v1/2023.findings-acl.113) |  | 0 | State-of-the-art natural language processing models have been shown to achieve remarkable performance in ‘closed-world’ settings where all the labels in the evaluation set are known at training time. However, in real-world settings, ‘novel’ instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of ‘dealing with novelties’, we introduce NoveltyTask, a multi-stage task to evaluate a system’s performance on pipelined novelty ‘detection’ and ‘accommodation’ tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results show that the methods achieve considerably low performance making the task challenging and leaving sufficient room for improvement. Finally, we believe our work will encourage research in this underexplored area of dealing with novelties, an important step en route to developing robust systems. | Neeraj Varshney, Himanshu Gupta, Eric Robertson, Bing Liu, Chitta Baral |  |
| 456 |  |  [CDA: A Contrastive Data Augmentation Method for Alzheimer's Disease Detection](https://doi.org/10.18653/v1/2023.findings-acl.114) |  | 0 | Alzheimer’s Disease (AD) is a neurodegenerative disorder that significantly impacts a patient’s ability to communicate and organize language. Traditional methods for detecting AD, such as physical screening or neurological testing, can be challenging and time-consuming. Recent research has explored the use of deep learning techniques to distinguish AD patients from non-AD patients by analysing the spontaneous speech. These models, however, are limited by the availability of data. To address this, we propose a novel contrastive data augmentation method, which simulates the cognitive impairment of a patient by randomly deleting a proportion of text from the transcript to create negative samples. The corrupted samples are expected to be in worse conditions than the original by a margin. Experimental results on the benchmark ADReSS Challenge dataset demonstrate that our model achieves the best performance among language-based models. | Junwen Duan, Fangyuan Wei, Jin Liu, Hongdong Li, Tianming Liu, Jianxin Wang |  |
| 457 |  |  [Disentangling Aspect and Stance via a Siamese Autoencoder for Aspect Clustering of Vaccination Opinions](https://doi.org/10.18653/v1/2023.findings-acl.115) |  | 0 | Mining public opinions about vaccines from social media has been increasingly relevant to analyse trends in public debates and to provide quick insights to policy-makers. However, the application of existing models has been hindered by the wide variety of users’ attitudes and the new aspects continuously arising in the public debate. Existing approaches, frequently framed via well-known tasks, such as aspect classification or text span detection, make direct usage of the supervision information constraining the models to predefined aspect classes, while still not distinguishing those aspects from users’ stances. As a result, this has significantly hindered the dynamic integration of new aspects. We thus propose a model, namely Disentangled Opinion Clustering (DOC), for vaccination opinion mining from social media. DOC is able to disentangle users’ stances from opinions via a disentangling attention mechanism and a Swapping-Autoencoder, and is designed to process unseen aspect categories via a clustering approach, leveraging clustering-friendly representations induced by out-of-the-box Sentence-BERT encodings and disentangling mechanisms. We conduct a thorough experimental assessment demonstrating the benefit of the disentangling mechanisms and cluster-based approach on both the quality of aspect clusters and the generalization across new aspect categories, outperforming existing methodologies on aspect-based opinion mining. | Lixing Zhu, Runcong Zhao, Gabriele Pergola, Yulan He |  |
| 458 |  |  [Temporal Relation Classification using Boolean Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.116) |  | 0 | Classifying temporal relations between a pair of events is crucial to natural language understanding and a well-known natural language processing task. Given a document and two event mentions, the task is aimed at finding which one started first. We propose an efficient approach for temporal relation classification (TRC) using a boolean question answering (QA) model which we fine-tune on questions that we carefully design based on the TRC annotation guidelines, thereby mimicking the way human annotators approach the task. Our new QA-based TRC model outperforms previous state-of-the-art results by 2.4%. | Omer Cohen, Kfir Bar |  |
| 459 |  |  [Are Synonym Substitution Attacks Really Synonym Substitution Attacks?](https://doi.org/10.18653/v1/2023.findings-acl.117) |  | 0 | In this paper, we explore the following question: Are synonym substitution attacks really synonym substitution attacks (SSAs)?We approach this question by examining how SSAs replace words in the original sentence and show that there are still unresolved obstacles that make current SSAs generate invalid adversarial samples. We reveal that four widely used word substitution methods generate a large fraction of invalid substitution words that are ungrammatical or do not preserve the original sentence’s semantics. Next, we show that the semantic and grammatical constraints used in SSAs for detecting invalid word replacements are highly insufficient in detecting invalid adversarial samples. | David ChengHan Chiang, Hungyi Lee |  |
| 460 |  |  [DivHSK: Diverse Headline Generation using Self-Attention based Keyword Selection](https://doi.org/10.18653/v1/2023.findings-acl.118) |  | 0 | Diverse headline generation is an NLP task where given a news article, the goal is to generate multiple headlines that are true to the content of the article but are different among themselves. This task aims to exhibit and exploit semantically similar one-to-many relationships between a source news article and multiple target headlines. Toward this, we propose a novel model called DIVHSK. It has two components:KEYSELECT for selecting the important keywords, and SEQGEN, for finally generating the multiple diverse headlines. In KEYSELECT, we cluster the self-attention heads of the last layer of the pre-trained encoder and select the most-attentive theme and general keywords from the source article. Then, cluster-specific keyword sets guide the SEQGEN, a pre-trained encoder-decoder model, to generate diverse yet semantically similar headlines. The proposed model consistently outperformed existing literature and our strong baselines and emerged as a state-of-the-art model. We have also created a high-quality multi-reference headline dataset from news articles. | Venkatesh Elangovan, Kaushal Maurya, Deepak Kumar, Maunendra Sankar Desarkar |  |
| 461 |  |  [Similarity-Based Content Scoring - A more Classroom-Suitable Alternative to Instance-Based Scoring?](https://doi.org/10.18653/v1/2023.findings-acl.119) |  | 0 | Automatically scoring student answers is an important task that is usually solved using instance-based supervised learning. Recently, similarity-based scoring has been proposed as an alternative approach yielding similar perfor- mance. It has hypothetical advantages such as a lower need for annotated training data and better zero-shot performance, both of which are properties that would be highly beneficial when applying content scoring in a realistic classroom setting. In this paper we take a closer look at these alleged advantages by comparing different instance-based and similarity-based methods on multiple data sets in a number of learning curve experiments. We find that both the demand on data and cross-prompt performance is similar, thus not confirming the former two suggested advantages. The by default more straightforward possibility to give feedback based on a similarity-based approach may thus tip the scales in favor of it, although future work is needed to explore this advantage in practice. | Marie Bexte, Andrea Horbach, Torsten Zesch |  |
| 462 |  |  [Pragmatic Inference with a CLIP Listener for Contrastive Captioning](https://doi.org/10.18653/v1/2023.findings-acl.120) |  | 0 | We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision-language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity — outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations. | Jiefu Ou, Benno Krojer, Daniel Fried |  |
| 463 |  |  [A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus](https://doi.org/10.18653/v1/2023.findings-acl.121) |  | 0 | We present a pipeline for a statistical stylometric exploration of a hypothesized partition of a text. Given a parameterization of the text, our pipeline: (1) detects literary features yielding the optimal overlap between the hypothesized and unsupervised partitions, (2) performs a hypothesis-testing analysis to quantify the statistical significance of the optimal overlap, while conserving implicit correlations between units of text that are more likely to be grouped, and (3) extracts and quantifies the importance of features most responsible for the classification, estimates their statistical stability and cluster-wise abundance. We apply our pipeline to the first two books in the Bible, where one stylistic component stands out in the eyes of biblical scholars, namely, the Priestly component. We identify and explore statistically significant stylistic differences between the Priestly and non-Priestly components. | Gideon Yoffe, Axel Bühler, Nachum Dershowitz, Thomas Römer, Eli Piasetzky, Israel Finkelstein, Barak Sober |  |
| 464 |  |  [A Language-First Approach for Procedure Planning](https://doi.org/10.18653/v1/2023.findings-acl.122) |  | 0 | Procedure planning, or the ability to predict a series of steps that can achieve a given goal conditioned on the current observation, is critical for building intelligent embodied agents that can assist users in everyday tasks. Encouraged by the recent success of language models (LMs) for zero-shot and few-shot planning, we hypothesize that LMs may be equipped with stronger priors for planning compared to their visual counterparts. To this end, we propose a language-first procedure planning framework with a modularized design: we first align the current and goal observations with corresponding steps and then use a pre-trained LM to predict the intermediate steps. Under this framework, we find that using an image captioning model for alignment can already match state-of-the-art performance and by designing a double retrieval model conditioned over current and goal observations jointly, we can achieve large improvements (19.2%-98.9% relatively higher success rate than state-of-the-art) on both COIN and CrossTask benchmarks. Our work verifies the planning ability of LMs and demonstrates how LMs can serve as a powerful “reasoning engine” even when the input is provided in another modality. | Jiateng Liu, Sha Li, Zhenhailong Wang, Manling Li, Heng Ji |  |
| 465 |  |  [An Empirical Analysis of Leveraging Knowledge for Low-Resource Task-Oriented Semantic Parsing](https://doi.org/10.18653/v1/2023.findings-acl.123) |  | 0 | Task-oriented semantic parsing has drawn a lot of interest from the NLP community, and especially the voice assistant industry as it enables representing the meaning of user requests with arbitrarily nested semantics, including multiple intents and compound entities. SOTA models are large seq2seq transformers and require hundreds of thousands of annotated examples to be trained. However annotating such data to bootstrap new domains or languages is expensive and error-prone, especially for requests made of nested semantics. In addition large models easily break the tight latency constraints imposed in a user-facing production environment. As part of this work we explore leveraging external knowledge to improve model accuracy in low-resource and low-compute settings. We demonstrate that using knowledge-enhanced encoders inside seq2seq models does not result in performance gains by itself, but jointly learning to uncover entities in addition to the parse generation is a simple yet effective way of improving performance across the board. We show this is especially true in the low-compute scarce-data setting and for entity-rich domains, with relative gains up to 74.48% on the TOPv2 dataset. | Mayank Kulkarni, Aoxiao Zhong, Nicolas Guenon des Mesnards, Sahar Movaghati, Mukund Sridhar, He Xie, Jianhua Lu |  |
| 466 |  |  [TempLM: Distilling Language Models into Template-Based Generators](https://doi.org/10.18653/v1/2023.findings-acl.124) |  | 0 | While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is more fluent than prior template systems. Notably, on an out-of-domain evaluation, TempLM reduces a finetuned BART model’s unfaithfulness rate from 83% to 0%. In a human study, we find that TempLM’s templates substantially improve upon human-written ones in BERTScore. | Tianyi Zhang, Mina Lee, Xiang Lisa Li, Ende Shen, Tatsunori Hashimoto |  |
| 467 |  |  [Incorporating Graph Information in Transformer-based AMR Parsing](https://doi.org/10.18653/v1/2023.findings-acl.125) |  | 0 | Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that aims at providing a semantic graph abstraction representing a given text. Current approaches are based on autoregressive language models such as BART or T5, fine-tuned through Teacher Forcing to obtain a linearized version of the AMR graph from a sentence. In this paper, we present LeakDistill, a model and method that explores a modification to the Transformer architecture, using structural adapters to explicitly incorporate graph information into the learned representations and improve AMR parsing performance. Our experiments show how, by employing word-to-node alignment to embed graph structural information into the encoder at training time, we can obtain state-of-the-art AMR parsing through self-knowledge distillation, even without the use of additional data. We release the code at [http://www.github.com/sapienzanlp/LeakDistill](http://www.github.com/sapienzanlp/LeakDistill). | Pavlo Vasylenko, PereLluís Huguet Cabot, Abelardo Carlos Martinez Lorenzo, Roberto Navigli |  |
| 468 |  |  [Rethinking the Word-level Quality Estimation for Machine Translation from Human Judgement](https://doi.org/10.18653/v1/2023.findings-acl.126) |  | 0 | Word-level Quality Estimation (QE) of Machine Translation (MT) aims to detect potential translation errors in the translated sentence without reference. Typically, conventional works on word-level QE are usually designed to predict the quality of translated words in terms of the post-editing effort, where the word labels in the dataset, i.e., OK or BAD, are automatically generated by comparing words between MT sentences and the post-edited sentences through a Translation Error Rate (TER) toolkit. While the post-editing effort can be used to measure the translation quality to some extent, we find it usually conflicts with human judgment on whether the word is well or poorly translated. To investigate this conflict, we first create a golden benchmark dataset, namely HJQE (Human Judgement on Quality Estimation), where the source and MT sentences are identical to the original TER-based dataset and the expert translators directly annotate the poorly translated words on their judgments. Based on our analysis, we further propose two tag-correcting strategies which can make the TER-based artificial QE corpus closer to HJQE. We conduct substantial experiments based on the publicly available WMT En-De and En-Zh corpora. The results not only show our proposed dataset is more consistent with human judgment but also confirm the effectiveness of the proposed tag-correcting strategies.For reviewers, the corpora and codes can be found in the attached files. | Zhen Yang, Fandong Meng, Yuanmeng Yan, Jie Zhou |  |
| 469 |  |  [PV2TEA: Patching Visual Modality to Textual-Established Information Extraction](https://doi.org/10.18653/v1/2023.findings-acl.127) |  | 0 | Information extraction, e.g., attribute value extraction, has been extensively studied and formulated based only on text. However, many attributes can benefit from image-based extraction, like color, shape, pattern, among others. The visual modality has long been underutilized, mainly due to multimodal annotation difficulty. In this paper, we aim to patch the visual modality to the textual-established attribute in- formation extractor. The cross-modality integration faces several unique challenges: (C1) images and textual descriptions are loosely paired intra-sample and inter-samples; (C2) images usually contain rich backgrounds that can mislead the prediction; (C3) weakly supervised labels from textual-established ex- tractors are biased for multimodal training. We present PV2TEA, an encoder-decoder architecture equipped with three bias reduction schemes: (S1) Augmented label-smoothed contrast to improve the cross-modality alignment for loosely-paired image and text; (S2) Attention-pruning that adaptively distinguishes the visual foreground; (S3) Two-level neighborhood regularization that mitigates the label textual bias via reliability estimation. Empirical results on real-world e-Commerce datasets1 demonstrate up to 11.74% absolute (20.97% relatively) F1 increase over unimodal baselines. | Hejie Cui, Rongmei Lin, Nasser Zalmout, Chenwei Zhang, Jingbo Shang, Carl Yang, Xian Li |  |
| 470 |  |  [Structural Contrastive Pretraining for Cross-Lingual Comprehension](https://doi.org/10.18653/v1/2023.findings-acl.128) |  | 0 | To present, multilingual language models trained using various pre-training tasks like mask language modeling (MLM) have yielded encouraging results on a wide range of downstream tasks. Despite the promising performances, structural knowledge in cross-lingual corpus is less explored in current works, leading to the semantic misalignment. In this paper, we propose a new pre-training task named Structural Contrast Pretraining (SCP) to align the structural words in a parallel sentence, enhancing the models’ ability to comprehend cross-lingual representations. Concretely, each structural word in source and target languages is regarded as a positive pair in SCP. Since contrastive learning compares positive and negative pairs, an increase in the frequency of negative pairings could enhance the performance of the resulting model. Therefore, we further propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large size of the queue. CL-MoCo extends the original Moco approach into cross-lingual training and jointly optimizes the source-to-target language and target-to-source language representations, resulting in a more suitable encoder for cross-lingual transfer. We conduct extensive experiments to validate the proposed approach on three cross-lingual tasks across five datasets such as MLQA, WikiAnn, etc, and results prove the effectiveness of our method. | Nuo Chen, Linjun Shou, Tengtao Song, Ming Gong, Jian Pei, Jianhui Chang, Daxin Jiang, Jia Li |  |
| 471 |  |  [Reducing Sensitivity on Speaker Names for Text Generation from Dialogues](https://doi.org/10.18653/v1/2023.findings-acl.129) |  | 0 | Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a model’s sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation. | Qi Jia, Haifeng Tang, Kenny Q. Zhu |  |
| 472 |  |  [Topic and Style-aware Transformer for Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-acl.130) |  | 0 | Understanding emotion expressions in multimodal signals is key for machines to have a better understanding of human communication. While language, visual and acoustic modalities can provide clues from different perspectives, the visual modality is shown to make minimal contribution to the performance in the emotion recognition field due to its high dimensionality. Therefore, we first leverage the strong multimodality backbone VATT to project the visual signal to the common space with language and acoustic signals. Also, we propose content-oriented features Topic and Speaking style on top of it to approach the subjectivity issues. Experiments conducted on the benchmark dataset MOSEI show our model can outperform SOTA results and effectively incorporate visual signals and handle subjectivity issues by serving as content “normalization”. | Shuwen Qiu, Nitesh Sekhar, Prateek Singhal |  |
| 473 |  |  [Exploiting Abstract Meaning Representation for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.131) |  | 0 | The Open-Domain Question Answering (ODQA) task involves retrieving and subsequently generating answers from fine-grained relevant passages within a database. Current systems leverage Pretrained Language Models (PLMs) to model the relationship between questions and passages. However, the diversity in surface form expressions can hinder the model’s ability to capture accurate correlations, especially within complex contexts. Therefore, we utilize Abstract Meaning Representation (AMR) graphs to assist the model in understanding complex semantic information. We introduce a method known as Graph-as-Token (GST) to incorporate AMRs into PLMs. Results from Natural Questions (NQ) and TriviaQA (TQ) demonstrate that our GST method can significantly improve performance, resulting in up to 2.44/3.17 Exact Match score improvements on NQ/TQ respectively. Furthermore, our method enhances robustness and outperforms alternative Graph Neural Network (GNN) methods for integrating AMRs. To the best of our knowledge, we are the first to employ semantic graphs in ODQA. | Cunxiang Wang, Zhikun Xu, Qipeng Guo, Xiangkun Hu, Xuefeng Bai, Zheng Zhang, Yue Zhang |  |
| 474 |  |  [Nonparametric Masked Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.132) |  | 0 | Existing language models (LMs) predict tokens with a softmax over a finite vocabulary, which can make it difficult to predict rare tokens or phrases. We introduce NPM, the first nonparametric masked language model that replaces this softmax with a nonparametric distribution over every phrase in a reference corpus. NPM fills in the [MASK] solely from retrieving a token from a text corpus. We show that NPM can be efficiently trained with a contrastive objective and an in-batch approximation to full corpus retrieval. Zero-shot evaluation on 16 tasks including classification, fact probing and question answering demonstrates that NPM outperforms significantly larger parametric models, either with or without a retrieve-and-generate approach. It is particularly better at dealing with rare patterns (word senses or facts) and predicting rare or nearly unseen words (e.g., non-Latin script). We release the model and code at github.com/facebookresearch/NPM. | Sewon Min, Weijia Shi, Mike Lewis, Xilun Chen, Wentau Yih, Hannaneh Hajishirzi, Luke Zettlemoyer |  |
| 475 |  |  [Pay More Attention to Relation Exploration for Knowledge Base Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.133) |  | 0 | Knowledge base question answering (KBQA) is a challenging task that aims to retrieve correct answers from large-scale knowledge bases. Existing attempts primarily focus on entity representation and final answer reasoning, which results in limited supervision for this task. Moreover, the relations, which empirically determine the reasoning path selection, are not fully considered in recent advancements. In this study, we propose a novel framework, RE-KBQA, that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision. We explore guidance from relations in three aspects, including (1) distinguishing similar entities by employing a variational graph auto-encoder to learn relation importance; (2) exploring extra supervision by predicting relation distributions as soft labels with a multi-task scheme; (3) designing a relation-guided re-ranking algorithm for post-processing. Experimental results on two benchmark datasets demonstrate the effectiveness and superiority of our framework, improving the F1 score by 5.8% from 40.5 to 46.3 on CWQ and 5.7% from 62.8 to 68.5 on WebQSP, better or on par with state-of-the-art methods. | Yong Cao, Xianzhi Li, Huiwen Liu, Wen Dai, Shuai Chen, Bin Wang, Min Chen, Daniel Hershcovich |  |
| 476 |  |  [Speaking Multiple Languages Affects the Moral Bias of Language Models](https://doi.org/10.18653/v1/2023.findings-acl.134) |  | 0 | Pre-trained multilingual language models (PMLMs) are commonly used when dealing with data from multiple languages and cross-lingual transfer. However, PMLMs are trained on varying amounts of data for each language. In practice this means their performance is often much better on English than many other languages. We explore to what extent this also applies to moral norms. Do the models capture moral norms from English and impose them on other languages? Do the models exhibit random and thus potentially harmful beliefs in certain languages? Both these issues could negatively impact cross-lingual transfer and potentially lead to harmful outcomes. In this paper, we (1) apply the MORALDIRECTION framework to multilingual models, comparing results in German, Czech, Arabic, Chinese, and English, (2) analyse model behaviour on filtered parallel subtitles corpora, and (3) apply the models to a Moral Foundations Questionnaire, comparing with human responses from different countries. Our experiments demonstrate that, indeed, PMLMs encode differing moral biases, but these do not necessarily correspond to cultural differences or commonalities in human opinions. We release our code and models. | Katharina Hämmerl, Björn Deiseroth, Patrick Schramowski, Jindrich Libovický, Constantin A. Rothkopf, Alexander Fraser, Kristian Kersting |  |
| 477 |  |  [Retrieving Relevant Context to Align Representations for Cross-lingual Event Detection](https://doi.org/10.18653/v1/2023.findings-acl.135) |  | 0 | We study the problem of cross-lingual transfer learning for event detection (ED) where models trained on a source language are expected to perform well on data for a new target language. Among a few recent works for this problem, the main approaches involve representation matching (e.g., adversarial training) that aims to eliminate language-specific features from the representations to achieve the language-invariant representations. However, due to the mix of language-specific features with event-discriminative context, representation matching methods might also remove important features for event prediction, thus hindering the performance for ED. To address this issue, we introduce a novel approach for cross-lingual ED where representations are augmented with additional context (i.e., not eliminating) to bridge the gap between languages while enriching the contextual information to facilitate ED. At the core of our method involves a retrieval model that retrieves relevant sentences in the target language for an input sentence to compute augmentation representations. Experiments on three languages demonstrate the state-of-the-art performance of our model for cross-lingual ED. | Chien Nguyen, Linh Ngo Van, Thien Huu Nguyen |  |
| 478 |  |  [NormNet: Normalize Noun Phrases for More Robust NLP](https://doi.org/10.18653/v1/2023.findings-acl.136) |  | 0 | A critical limitation of deep NLP models is their over-fitting over spurious features. Previous work has proposed several approaches to debunk such features and reduce their impact on the learned models. In this work, a normalization strategy is proposed to eliminate the false features caused by the textual surfaces of noun phrases. The motivation for this strategy is that noun phrases often play the role of slots in textual expressions and their exact forms are often not that important for performing the final task. As an intuitive example, consider the expression ”x like eating y". There are a huge number of suitable instantiations for x and y in the locale. However, humans can already infer the sentiment polarity of x toward y without knowing their exact forms.Based on this intuition, we introduce NormNet, a pretrained language model based network, to implement the normalization strategy. NormNet learns to replace as many noun phrases in the input sentence as possible with pre-defined base forms. The output of NormNet is then fed as input to a prompt-based learning model to perform label prediction. To evaluate the effectiveness of our strategy, we conducted experimental studies on several tasks, including aspect sentiment classification (ASC), semantic text similarity (STS), and natural language inference (NLI). The experimental results confirm the effectiveness of our strategy. | Minlong Peng, Mingming Sun |  |
| 479 |  |  [Cross Encoding as Augmentation: Towards Effective Educational Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.137) |  | 0 | Text classification in education, usually called auto-tagging, is the automated process of assigning relevant tags to educational content, such as questions and textbooks. However, auto-tagging suffers from a data scarcity problem, which stems from two major challenges: 1) it possesses a large tag space and 2) it is multi-label. Though a retrieval approach is reportedly good at low-resource scenarios, there have been fewer efforts to directly address the data scarcity problem. To mitigate these issues, here we propose a novel retrieval approach CEAA that provides effective learning in educational text classification. Our main contributions are as follows: 1) we leverage transfer learning from question-answering datasets, and 2) we propose a simple but effective data augmentation method introducing cross-encoder style texts to a bi-encoder architecture for more efficient inference. An extensive set of experiments shows that our proposed method is effective in multi-label scenarios and low-resource tags compared to state-of-the-art models. | Hyun Seung Lee, Seungtaek Choi, Yunsung Lee, Hyeongdon Moon, Shinhyeok Oh, Myeongho Jeong, Hyojun Go, Christian Wallraven |  |
| 480 |  |  [Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.138) |  | 0 | State-of-the-art few-shot learning (FSL) methods leverage prompt-based fine-tuning to obtain remarkable results for natural language understanding (NLU) tasks. While much of the prior FSL methods focus on improving downstream task performance, there is a limited understanding of the adversarial robustness of such methods. In this work, we conduct an extensive study of several state-of-the-art FSL methods to assess their robustness to adversarial perturbations. To better understand the impact of various factors towards robustness (or the lack of it), we evaluate prompt-based FSL methods against fully fine-tuned models for aspects such as the use of unlabeled data, multiple prompts, number of few-shot examples, model size and type. Our results on six GLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL methods lead to a notable relative drop in task performance (i.e., are less robust) in the face of adversarial perturbations. However, using (i) unlabeled data for prompt-based FSL and (ii) multiple prompts flip the trend – the few-shot learning approaches demonstrate a lesser drop in task performance than fully fine-tuned models. We further demonstrate that increasing the number of few-shot examples and model size lead to increased adversarial robustness of vanilla FSL methods. Broadly, our work sheds light on the adversarial robustness evaluation of prompt-based FSL methods for NLU tasks. | Venkata Prabhakara Sarath Nookala, Gaurav Verma, Subhabrata Mukherjee, Srijan Kumar |  |
| 481 |  |  [This prompt is measuring \textlessmask\textgreater: evaluating bias evaluation in language models](https://doi.org/10.18653/v1/2023.findings-acl.139) |  | 0 | Bias research in NLP seeks to analyse models for social biases, thus helping NLP practitioners uncover, measure, and mitigate social harms. We analyse the body of work that uses prompts and templates to assess bias in language models. We draw on a measurement modelling framework to create a taxonomy of attributes that capture what a bias test aims to measure and how that measurement is carried out. By applying this taxonomy to 90 bias tests, we illustrate qualitatively and quantitatively that core aspects of bias test conceptualisations and operationalisations are frequently unstated or ambiguous, carry implicit assumptions, or be mismatched. Our analysis illuminates the scope of possible bias types the field is able to measure, and reveals types that are as yet under-researched. We offer guidance to enable the community to explore a wider section of the possible bias space, and to better close the gap between desired outcomes and experimental design, both for bias and for evaluating language models more broadly. | Seraphina GoldfarbTarrant, Eddie Ungless, Esma Balkir, Su Lin Blodgett |  |
| 482 |  |  [Towards Open Environment Intent Prediction](https://doi.org/10.18653/v1/2023.findings-acl.140) |  | 0 | Out-of-Domain (OOD) Intent Classification and New Intent Discovering are two basic and critical tasks in the Task-Oriented Dialogue System, which are typically treated two independent tasks. Classification focuses on identifying intents beyond the predefined set of the dialog system, but it will not further differentiate detected OOD intents in fine granularity. Discovering focuses on how to cluster unlabeled samples according to their semantic representation, which relies heavily on prior knowledge and can not provide label information for the formed clusters. To be closer to the real user-facing scenarios, we introduce a task paradigm to extend Classification with Discovering referred as Open Environment Intent Prediction, which is to make a further fine-grained discovery of OOD based on OOD Intent Classification. Using various widely-used generative models as an archetype, we propose a general scheme for Open Environment Intent Prediction. In a nutshell, we first perform intent detection to identify the In-domain (IND) samples and then generate labels for those identified as OOD. With these generated labels, we can discover new general intents and provide label information for them. We develop a suite of benchmarks on the existing intent datasets and present a simple yet effective implementation. Extensive experiments demonstrate that our method establishes substantial improvement compared to the baselines. | Yunhua Zhou, Jiawei Hong, Xipeng Qiu |  |
| 483 |  |  [Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in Class-incremental Information Extraction](https://doi.org/10.18653/v1/2023.findings-acl.141) |  | 0 | Class-incremental learning (CIL) aims to develop a learning system that can continually learn new classes from a data stream without forgetting previously learned classes. When learning classes incrementally, the classifier must be constantly updated to incorporate new classes, and the drift in decision boundary may lead to severe forgetting. This fundamental challenge, however, has not yet been studied extensively, especially in the setting where no samples from old classes are stored for rehearsal. In this paper, we take a closer look at how the drift in the classifier leads to forgetting, and accordingly, design four simple yet (super-) effective solutions to alleviate the classifier drift: an Individual Classifiers with Frozen Feature Extractor (ICE) framework where we individually train a classifier for each learning session, and its three variants ICE-PL, ICE-O, and ICE-PL&O which further take the logits of previously learned classes from old sessions or a constant logit of an Other class as constraint to the learning of new classifiers. Extensive experiments and analysis on 6 class-incremental information extraction tasks demonstrate that our solutions, especially ICE-O, consistently show significant improvement over the previous state-of-the-art approaches with up to 44.7% absolute F-score gain, providing a strong baseline and insights for future research on class-incremental learning. | Minqian Liu, Lifu Huang |  |
| 484 |  |  [C-XNLI: Croatian Extension of XNLI Dataset](https://doi.org/10.18653/v1/2023.findings-acl.142) |  | 0 | Comprehensive multilingual evaluations have been encouraged by emerging cross-lingual benchmarks and constrained by existing parallel datasets. To partially mitigate this limitation, we extended the Cross-lingual Natural Language Inference (XNLI) corpus with Croatian. The development and test sets were translated by a professional translator, and we show that Croatian is consistent with other XNLI dubs. The train set is translated using Facebook’s 1.2B parameter m2m_100 model. We thoroughly analyze the Croatian train set and compare its quality with the existing machine-translated German set. The comparison is based on 2000 manually scored sentences per language using a variant of the Direct Assessment (DA) score commonly used at the Conference on Machine Translation (WMT). Our findings reveal that a less-resourced language like Croatian is still lacking in translation quality of longer sentences compared to German. However, both sets have a substantial amount of poor quality translations, which should be considered in translation-based training or evaluation setups. | Leo Obadic, Andrej Jertec, Marko Rajnovic, Branimir Dropuljic |  |
| 485 |  |  [AVATAR: A Parallel Corpus for Java-Python Program Translation](https://doi.org/10.18653/v1/2023.findings-acl.143) |  | 0 | Program translation refers to migrating source code from one programming language to another. It has tremendous practical value in software development, as porting software across languages is time-consuming and costly. Automating program translation is of paramount importance in software migration, and recently researchers explored unsupervised approaches due to the unavailability of parallel corpora. However, the availability of pre-trained language models for programming languages enables supervised fine-tuning with a small number of labeled examples. Therefore, we present AVATAR, a collection of 9,515 programming problems and their solutions written in two popular languages, Java and Python. AVATAR is collected from competitive programming sites, online platforms, and open-source repositories. Furthermore, AVATAR includes unit tests for 250 examples to facilitate functional correctness evaluation. We benchmark several pre-trained language models fine-tuned on AVATAR. Experiment results show that the models lack in generating functionally accurate code. | Wasi Uddin Ahmad, Md Golam Rahman Tushar, Saikat Chakraborty, KaiWei Chang |  |
| 486 |  |  [On Dataset Transferability in Active Learning for Transformers](https://doi.org/10.18653/v1/2023.findings-acl.144) |  | 0 | Active learning (AL) aims to reduce labeling costs by querying the examples most beneficial for model learning. While the effectiveness of AL for fine-tuning transformer-based pre-trained language models (PLMs) has been demonstrated, it is less clear to what extent the AL gains obtained with one model transfer to others. We consider the problem of transferability of actively acquired datasets in text classification and investigate whether AL gains persist when a dataset built using AL coupled with a specific PLM is used to train a different PLM. We link the AL dataset transferability to the similarity of instances queried by the different PLMs and show that AL methods with similar acquisition sequences produce highly transferable datasets regardless of the models used. Additionally, we show that the similarity of acquisition sequences is influenced more by the choice of the AL method than the choice of the model. | Fran Jelenic, Josip Jukic, Nina Drobac, Jan Snajder |  |
| 487 |  |  [Structured Persuasive Writing Support in Legal Education: A Model and Tool for German Legal Case Solutions](https://doi.org/10.18653/v1/2023.findings-acl.145) |  | 0 | We present an annotation approach for capturing structured components and arguments inlegal case solutions of German students. Based on the appraisal style, which dictates the structured way of persuasive writing in German law, we propose an annotation scheme with annotation guidelines that identify structured writing in legal case solutions. We conducted an annotation study with two annotators and annotated legal case solutions to capture the structures of a persuasive legal text. Based on our dataset, we trained three transformer-based models to show that the annotated components can be successfully predicted, e.g. to provide users with writing assistance for legal texts. We evaluated a writing support system in which our models were integrated in an online experiment with law students and found positive learning success and users’ perceptions. Finally, we present our freely available corpus of 413 law student case studies to support the development of intelligent writing support systems. | Florian Weber, Thiemo Wambsganss, Seyed Parsa Neshaei, Matthias Söllner |  |
| 488 |  |  [Characterizing the Impacts of Instances on Robustness](https://doi.org/10.18653/v1/2023.findings-acl.146) |  | 0 | Building robust deep neural networks (DNNs) against adversarial attacks is an important but challenging task. Previous defense approaches mainly focus on developing new model structures or training algorithms, but they do little to tap the potential of training instances, especially instances with robust patterns carring innate robustness. In this paper, we show that robust and non-robust instances in the training dataset, though are both important for test performance, have contrary impacts on robustness, which makes it possible to build a highly robust model by leveraging the training dataset in a more effective way. We propose a new method that can distinguish between robust instances from non-robust ones according to the model’s sensitivity to perturbations on individual instances during training. Surprisingly, we find that the model under standard training easily overfits the robust instances by relying on their simple patterns before the model completely learns their robust features. Finally, we propose a new mitigation algorithm to further release the potential of robust instances. Experimental results show that proper use of robust instances in the original dataset is a new line to achieve highly robust models. | Rui Zheng, Zhiheng Xi, Qin Liu, Wenbin Lai, Tao Gui, Qi Zhang, Xuanjing Huang, Jin Ma, Ying Shan, Weifeng Ge |  |
| 489 |  |  [Generate then Select: Open-ended Visual Question Answering Guided by World Knowledge](https://doi.org/10.18653/v1/2023.findings-acl.147) |  | 0 | The open-ended Visual Question Answering (VQA) task requires AI models to jointly reason over visual and natural language inputs using world knowledge. Recently, pre-trained Language Models (PLM) such as GPT-3 have been applied to the task and shown to be powerful world knowledge sources. However, these methods suffer from low knowledge coverage caused by PLM bias – the tendency to generate certain tokens over other tokens regardless of prompt changes, and high dependency on the PLM quality – only models using GPT-3 can achieve the best result. To address the aforementioned challenges, we propose RASO: a new VQA pipeline that deploys a generate-then-select strategy guided by world knowledge for the first time. Rather than following the de facto standard to train a multi-modal model that directly generates the VQA answer, {pasted macro ‘MODEL’}name first adopts PLM to generate all the possible answers, and then trains a lightweight answer selection model for the correct answer. As proved in our analysis, RASO expands the knowledge coverage from in-domain training data by a large margin. We provide extensive experimentation and show the effectiveness of our pipeline by advancing the state-of-the-art by 4.1% on OK-VQA, without additional computation cost. | Xingyu Fu, Sheng Zhang, Gukyeong Kwon, Pramuditha Perera, Henghui Zhu, Yuhao Zhang, Alexander Hanbo Li, William Yang Wang, Zhiguo Wang, Vittorio Castelli, Patrick Ng, Dan Roth, Bing Xiang |  |
| 490 |  |  [Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.148) |  | 0 | Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogistic reasoning, we develop a benchmark called SylloBase that differs from existing syllogistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset’s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. State-of-the-art pre-trained language models can achieve the best generation ROUGE-L of 38.72 by T5 and the best multi-choice accuracy of 72.77% by RoBERTa on SylloBase, which indicates the great challenge of learning diverse syllogistic reasoning types on SylloBase. Our datasets are released at https://github.com/casually-PYlearner/SYLLOBASE. | Yongkang Wu, Meng Han, Yutao Zhu, Lei Li, Xinyu Zhang, Ruofei Lai, Xiaoguang Li, Yuanhang Ren, Zhicheng Dou, Zhao Cao |  |
| 491 |  |  [Categorial grammar induction from raw data](https://doi.org/10.18653/v1/2023.findings-acl.149) |  | 0 | Grammar induction, the task of learning a set of grammatical rules from raw or minimally labeled text data, can provide clues about what kinds of syntactic structures are learnable without prior knowledge. Recent work (e.g., Kim et al., 2019; Zhu et al., 2020; Jin et al., 2021a) has achieved advances in unsupervised induction of probabilistic context-free grammars (PCFGs). However, categorial grammar induction has received less recent attention, despite allowing inducers to support a larger set of syntactic categories—due to restrictions on how categories can combine—and providing a transparent interface with compositional semantics, opening up possibilities for models that jointly learn form and meaning. Motivated by this, we propose a new model for inducing a basic (Ajdukiewicz, 1935; Bar-Hillel, 1953) categorial grammar. In contrast to earlier categorial grammar induction systems (e.g., Bisk and Hockenmaier, 2012), our model learns from raw data without any part-of-speech information. Experiments on child-directed speech show that our model attains a recall-homogeneity of 0.33 on average, which dramatically increases to 0.59 when a bias toward forward function application is added to the model. | Christian Clark, William Schuler |  |
| 492 |  |  [Attribute Controlled Dialogue Prompting](https://doi.org/10.18653/v1/2023.findings-acl.150) |  | 0 | Prompt-tuning has become an increasingly popular parameter-efficient method for adapting large pretrained language models to downstream tasks. However, both discrete prompting and continuous prompting assume fixed prompts for all data samples within a task, neglecting the fact that inputs vary greatly in some tasks such as open-domain dialogue generation. In this paper, we present a novel, instance-specific prompt-tuning algorithm for dialogue generation. Specifically, we generate prompts based on instance-level control code, rather than the conversation history, to explore their impact on controlled dialogue generation. Experiments on popular open-domain dialogue datasets, evaluated on both automated metrics and human evaluation, demonstrate that our method is superior to prompting baselines and comparable to fine-tuning with only 5%-6% of total parameters. | Runcheng Liu, Ahmad Rashid, Ivan Kobyzev, Mehdi Rezagholizadeh, Pascal Poupart |  |
| 493 |  |  [Open-World Factually Consistent Question Generation](https://doi.org/10.18653/v1/2023.findings-acl.151) |  | 0 | Question generation methods based on pre-trained language models often suffer from factual inconsistencies and incorrect entities and are not answerable from the input paragraph. Domain shift – where the test data is from a different domain than the training data - further exacerbates the problem of hallucination. This is a critical issue for any natural language application doing question generation. In this work, we propose an effective data processing technique based on de-lexicalization for consistent question generation across domains. Unlike existing approaches for remedying hallucination, the proposed approach does not filter training data and is generic across question-generation models. Experimental results across six benchmark datasets show that our model is robust to domain shift and produces entity-level factually consistent questions without significant impact on traditional metrics. | Himanshu Maheshwari, Sumit Shekhar, Apoorv Saxena, Niyati Chhaya |  |
| 494 |  |  [Contrastive Learning of Sociopragmatic Meaning in Social Media](https://doi.org/10.18653/v1/2023.findings-acl.152) |  | 0 | Recent progress in representation and contrastive learning in NLP has not widely considered the class of sociopragmatic meaning (i.e., meaning in interaction within different language communities). To bridge this gap, we propose a novel framework for learning task-agnostic representations transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate speech, humor, sarcasm). Our framework outperforms other contrastive learning frameworks for both in-domain and out-of-domain data, across both the general and few-shot settings. For example, compared to two popular pre-trained language models, our model obtains an improvement of 11.66 average F1 on 16 datasets when fine-tuned on only 20 training samples per dataset. We also show that our framework improves uniformity and preserves the semantic structure of representations. Our code is available at: https://github.com/UBC-NLP/infodcl | Chiyu Zhang, Muhammad AbdulMageed, Ganesh Jawahar |  |
| 495 |  |  [Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.153) |  | 0 | This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both false negative issue (i.e., potential true facts being excluded) and false positive issue (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call label posterior) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies missing facts to provide high-quality grounds of reasoning. They are unified in a simple yet effective self-training procedure. Empirically, extensive experiments on three benchmark KG and one Twitter dataset with various degrees of false negative/positive cases demonstrate the effectiveness of nPUGraph. | Ruijie Wang, Baoyu Li, Yichen Lu, Dachun Sun, Jinning Li, Yuchen Yan, Shengzhong Liu, Hanghang Tong, Tarek F. Abdelzaher |  |
| 496 |  |  [ACROSS: An Alignment-based Framework for Low-Resource Many-to-One Cross-Lingual Summarization](https://doi.org/10.18653/v1/2023.findings-acl.154) |  | 0 | This research addresses the challenges of Cross-Lingual Summarization (CLS) in low-resource scenarios and over imbalanced multilingual data. Existing CLS studies mostly resort to pipeline frameworks or multi-task methods in bilingual settings. However, they ignore the data imbalance in multilingual scenarios and do not utilize the high-resource monolingual summarization data. In this paper, we propose the Aligned CROSs-lingual Summarization (ACROSS) model to tackle these issues. Our framework aligns low-resource cross-lingual data with high-resource monolingual data via contrastive and consistency loss, which help enrich low-resource information for high-quality summaries. In addition, we introduce a data augmentation method that can select informative monolingual sentences, which facilitates a deep exploration of high-resource information and introduce new information for low-resource languages. Experiments on the CrossSum dataset show that ACROSS outperforms baseline models and obtains consistently dominant performance on 45 language pairs. | Peiyao Li, Zhengkun Zhang, Jun Wang, Liang Li, Adam Jatowt, Zhenglu Yang |  |
| 497 |  |  [RFiD: Towards Rational Fusion-in-Decoder for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.155) |  | 0 | Open-Domain Question Answering (ODQA) systems necessitate a reader model capable of generating answers by simultaneously referring to multiple passages. Although representative models like Fusion-in-Decoder (FiD) have been proposed to address this challenge, these systems can inadvertently rely on spurious features instead of genuine causal relationships between the question and the passages to generate answers. To counter this problem, we introduce the Rational Fusion-in-Decoder (RFiD) model. Our model leverages the encoders of FiD to differentiate between causal relationships and spurious features, subsequently guiding the decoder to generate answers informed by this discernment. Experimental results on two ODQA datasets, Natural Questions (NQ) and TriviaQA (TQ), demonstrate that our model surpasses previous methods, achieving improvements of up to 1.5 and 0.7 in Exact Match scores on NQ, and exhibits an enhanced ability to identify causal relationships. | Cunxiang Wang, Haofei Yu, Yue Zhang |  |
| 498 |  |  [Unsupervised Keyphrase Extraction by Learning Neural Keyphrase Set Function](https://doi.org/10.18653/v1/2023.findings-acl.156) |  | 0 | We create a paradigm shift concerning building unsupervised keyphrase extraction systems in this paper. Instead of modeling the relevance between an individual candidate phrase and the document as in the commonly used framework, we formulate the unsupervised keyphrase extraction task as a document-set matching problem from a set-wise perspective, in which the document and the candidate set are globally matched in the semantic space to particularly take into account the interactions among all candidate phrases. Since it is intractable to exactly extract the keyphrase set by the matching function during the inference, we propose an approximate approach, which obtains the candidate subsets via a set extractor agent learned by reinforcement learning. Exhaustive experimental results demonstrate the effectiveness of our model, which outperforms the recent state-of-the-art unsupervised keyphrase extraction baselines by a large margin. | Mingyang Song, Haiyun Jiang, Lemao Liu, Shuming Shi, Liping Jing |  |
| 499 |  |  [Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias](https://doi.org/10.18653/v1/2023.findings-acl.157) |  | 0 | Pre-trained Language Models (PLMs) may be poisonous with backdoors or bias injected by the suspicious attacker during the fine-tuning process. A core challenge of purifying potentially poisonous PLMs is precisely finding poisonous dimensions. To settle this issue, we propose the Fine-purifying approach, which utilizes the diffusion theory to study the dynamic process of fine-tuning for finding potentially poisonous dimensions. According to the relationship between parameter drifts and Hessians of different dimensions, we can detect poisonous dimensions with abnormal dynamics, purify them by resetting them to clean pre-trained weights, and then fine-tune the purified weights on a small clean dataset. To the best of our knowledge, we are the first to study the dynamics guided by the diffusion theory for safety or defense purposes. Experimental results validate the effectiveness of Fine-purifying even with a small clean dataset. | Zhiyuan Zhang, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun |  |
| 500 |  |  [Retrieving Multimodal Prompts for Generative Visual Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.158) |  | 0 | Recent years have witnessed impressive results of pre-trained vision-language models on knowledge-intensive tasks such as visual question answering (VQA). Despite the recent advances in VQA, existing methods mainly adopt a discriminative formulation that predicts answers within a pre-defined label set, leading to easy overfitting on low-resource domains (e.g., medicine) and poor generalization under domain shift to another dataset. To tackle this limitation, we propose a novel generative model enhanced by multimodal prompt retrieval (MPR) that integrates retrieved prompts and multimodal features to generate answers in free text. Our generative model enables rapid zero-shot dataset adaptation to unseen data distributions and open-set answer labels across datasets. Our experiments on medical VQA tasks show that MPR outperforms its non-retrieval counterpart by up to 30% accuracy points in a few-shot domain adaptation setting. | Timothy Ossowski, Junjie Hu |  |
| 501 |  |  [InfoSync: Information Synchronization across Multilingual Semi-structured Tables](https://doi.org/10.18653/v1/2023.findings-acl.159) |  | 0 | Information Synchronization of semi-structured data across languages is challenging. For example, Wikipedia tables in one language need to be synchronized with others. To address this problem, we introduce a new dataset InfoSync and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (~3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en <-> non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 532 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method. | Siddharth Khincha, Chelsi Jain, Vivek Gupta, Tushar Kataria, Shuo Zhang |  |
| 502 |  |  [T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image Generation](https://doi.org/10.18653/v1/2023.findings-acl.160) |  | 0 | \*Warning: This paper contains several contents that may be toxic, harmful, or offensive.\*In the last few years, text-to-image generative models have gained remarkable success in generating images with unprecedented quality accompanied by a breakthrough of inference speed. Despite their rapid progress, human biases that manifest in the training examples, particularly with regard to common stereotypical biases, like gender and skin tone, still have been found in these generative models. In this work, we seek to measure more complex human biases exist in the task of text-to-image generations. Inspired by the well-known Implicit Association Test (IAT) from social psychology, we propose a novel Text-to-Image Association Test (T2IAT) framework that quantifies the implicit stereotypes between concepts and valence, and those in the images. We replicate the previously documented bias tests on generative models, including morally neutral tests on flowers and insects as well as demographic stereotypical tests on diverse social attributes. The results of these experiments demonstrate the presence of complex stereotypical behaviors in image generations. | Jialu Wang, Xinyue Liu, Zonglin Di, Yang Liu, Xin Eric Wang |  |
| 503 |  |  [An Investigation of Evaluation Methods in Automatic Medical Note Generation](https://doi.org/10.18653/v1/2023.findings-acl.161) |  | 0 | Recent studies on automatic note generation have shown that doctors can save significant amounts of time when using automatic clinical note generation (Knoll et al., 2022). Summarization models have been used for this task to generate clinical notes as summaries of doctor-patient conversations (Krishna et al., 2021; Cai et al., 2022). However, assessing which model would best serve clinicians in their daily practice is still a challenging task due to the large set of possible correct summaries, and the potential limitations of automatic evaluation metrics. In this paper we study evaluation methods and metrics for the automatic generation of clinical notes from medical conversation. In particular, we propose new task-specific metrics and we compare them to SOTA evaluation metrics in text summarization and generation, including: (i) knowledge-graph embedding-based metrics, (ii) customized model-based metrics with domain-specific weights, (iii) domain-adapted/fine-tuned metrics, and (iv) ensemble metrics. To study the correlation between the automatic metrics and manual judgments, we evaluate automatic notes/summaries by comparing the system and reference facts and computing the factual correctness, and the hallucination and omission rates for critical medical facts. This study relied on seven datasets manually annotated by domain experts. Our experiments show that automatic evaluation metrics can have substantially different behaviors on different types of clinical notes datasets. However, the results highlight one stable subset of metrics as the most correlated with human judgments with a relevant aggregation of different evaluation criteria. | Asma Ben Abacha, Wenwai Yim, George Michalopoulos, Thomas Lin |  |
| 504 |  |  [Rethinking Translation Memory Augmented Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.162) |  | 0 | This paper rethinks translation memory augmented neural machine translation (TM-augmented NMT) from two perspectives, i.e., a probabilistic view of retrieval and the variance-bias decomposition principle. The finding demonstrates that TM-augmented NMT is good at the ability of fitting data (i.e., lower bias) but is more sensitive to the fluctuations in the training data (i.e., higher variance), which provides an explanation to a recently reported contradictory phenomenon on the same translation task: TM-augmented NMT substantially advances NMT without TM under the high resource scenario whereas it fails under the low resource scenario. Then this paper proposes a simple yet effective TM-augmented NMT model to promote the variance and address the contradictory phenomenon. Extensive experiments show that the proposed TM-augmented NMT achieves consistent gains over both conventional NMT and existing TM-augmented NMT under two variance-preferable (low resource and plug-and-play) scenarios as well as the high resource scenario. | Hongkun Hao, Guoping Huang, Lemao Liu, Zhirui Zhang, Shuming Shi, Rui Wang |  |
| 505 |  |  [Controlling Styles in Neural Machine Translation with Activation Prompt](https://doi.org/10.18653/v1/2023.findings-acl.163) |  | 0 | Controlling styles in neural machine translation (NMT) has attracted wide attention, as it is crucial for enhancing user experience. Earlier studies on this topic typically concentrate on regulating the level of formality and achieve some progress in this area. However, they still encounter two major challenges. The first is the difficulty in style evaluation. The style comprises various aspects such as lexis, syntax, and others that provide abundant information. Nevertheless, only formality has been thoroughly investigated. The second challenge involves excessive dependence on incremental adjustments, particularly when new styles are necessary. To address both challenges, this paper presents a new benchmark and approach. A multiway stylized machine translation (MSMT) benchmark is introduced, incorporating diverse categories of styles across four linguistic domains. Then, we propose a method named style activation prompt (StyleAP) by retrieving prompts from stylized monolingual corpus, which does not require extra fine-tuning. Experiments show that StyleAP could effectively control the style of translation and achieve remarkable performance. | Yifan Wang, Zewei Sun, Shanbo Cheng, Weiguo Zheng, Mingxuan Wang |  |
| 506 |  |  [Focusing, Bridging and Prompting for Few-shot Nested Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.164) |  | 0 | Few-shot named entity recognition (NER), identifying named entities with a small number of labeled data, has attracted much attention. Frequently, entities are nested within each other. However, most of the existing work on few-shot NER addresses flat entities instead of nested entities. To tackle nested NER in a few-shot setting, it is crucial to utilize the limited labeled data to mine unique features of nested entities, such as the relationship between inner and outer entities and contextual position information. Therefore, in this work, we propose a novel method based on focusing, bridging and prompting for few-shot nested NER without using source domain data. Both focusing and bridging components provide accurate candidate spans for the prompting component. The prompting component leverages the unique features of nested entities to classify spans based on soft prompts and contrastive learning. Experimental results show that the proposed approach achieves state-of-the-art performance consistently on the four benchmark datasets (ACE2004, ACE2005, GENIA and KBP2017) and outperforms several competing baseline models on F1-score by 9.33% on ACE2004, 6.17% on ACE2005, 9.40% on GENIA and 5.12% on KBP2017 on the 5-shot setting. | Yuanyuan Xu, Zeng Yang, Linhai Zhang, Deyu Zhou, Tiandeng Wu, Rong Zhou |  |
| 507 |  |  [Together We Make Sense-Learning Meta-Sense Embeddings](https://doi.org/10.18653/v1/2023.findings-acl.165) |  | 0 | Sense embedding learning methods learn multiple vectors for a given ambiguous word, corresponding to its different word senses. For this purpose, different methods have been proposed in prior work on sense embedding learning that use different sense inventories, sense-tagged corpora and learning methods. However, not all existing sense embeddings cover all senses of ambiguous words equally well due to the discrepancies in their training resources. To address this problem, we propose the first-ever meta-sense embedding method – Neighbour Preserving Meta-Sense Embeddings, which learns meta-sense embeddings by combining multiple independently trained source sense embeddings such that the sense neighbourhoods computed from the source embeddings are preserved in the meta-embedding space. Our proposed method can combine source sense embeddings that cover different sets of word senses. Experimental results on Word Sense Disambiguation (WSD) and Word-in-Context (WiC) tasks show that the proposed meta-sense embedding method consistently outperforms several competitive baselines. An anonymised version of the source code implementation for our proposed method is submitted to reviewing system. Both source code and the learnt meta-sense embeddings will be publicly released upon paper acceptance. | Haochen Luo, Yi Zhou, Danushka Bollegala |  |
| 508 |  |  [Multimodal Prompt Learning for Product Title Generation with Extremely Limited Labels](https://doi.org/10.18653/v1/2023.findings-acl.166) |  | 0 | Generating an informative and attractive title for the product is a crucial task for e-commerce. Most existing works follow the standard multimodal natural language generation approaches, e.g., image captioning, and employ the large scale of human-labelled datasets to train desirable models. However, for novel products, especially in a different domain, there are few existing labelled data. In this paper, we propose a prompt-based approach, i.e., the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. We observe that the core challenges of novel product title generation are the understanding of novel product characteristics and the generation of titles in a novel writing style. To this end, we build a set of multimodal prompts from different modalities to preserve the corresponding characteristics and writing styles of novel products. As a result, with extremely limited labels for training, the proposed method can retrieve the multimodal prompts to generate desirable titles for novel products. The experiments and analyses are conducted on five novel product categories under both the in-domain and out-of-domain experimental settings. The results show that, with only 1% of downstream labelled data for training, our proposed approach achieves the best few-shot results and even achieves competitive results with fully-supervised methods trained on 100% of training data; With the full labelled data for training, our method achieves state-of-the-art results. | Bang Yang, Fenglin Liu, Zheng Li, Qingyu Yin, Chenyu You, Bing Yin, Yuexian Zou |  |
| 509 |  |  [Large Language Models are Built-in Autoregressive Search Engines](https://doi.org/10.18653/v1/2023.findings-acl.167) |  | 0 | Document retrieval is a key stage of standard Web search engines. Existing dual-encoder dense retrievers obtain representations for questions and documents independently, allowing for only shallow interactions between them. To overcome this limitation, recent autoregressive search engines replace the dual-encoder architecture by directly generating identifiers for relevant documents in the candidate pool. However, the training cost of such autoregressive search engines rises sharply as the number of candidate documents increases. In this paper, we find that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval. Surprisingly, when providing a few Query-URL pairs as in-context demonstrations, LLMs can generate Web URLs where nearly 90% of the corresponding documents contain correct answers to open-domain questions. In this way, LLMs can be thought of as built-in search engines, since they have not been explicitly trained to map questions to document identifiers. Experiments demonstrate that our method can consistently achieve better retrieval performance than existing retrieval approaches by a significant margin on three open-domain question answering benchmarks, under both zero and few-shot settings. The code for this work can be found at https://github.com/Ziems/llm-url. | Noah Ziems, Wenhao Yu, Zhihan Zhang, Meng Jiang |  |
| 510 |  |  [Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.168) |  | 0 | Multimodal machine translation (MMT) aims to improve translation quality by incorporating information from other modalities, such as vision. Previous MMT systems focus on better access and use of visual information and tend to validate their methods on image-related datasets. However, these studies face two challenges. First, they can only utilize a limited amount of data that is composed of bilingual texts and images (referred to as “triple data”), which is scarce. Second, current benchmarks for MMT are restricted and do not correspond to realistic scenarios. Therefore, this paper correspondingly establishes new methods and a new dataset for MMT. We propose a novel framework for MMT that addresses these challenges by utilizing large-scale non-triple data, such as monolingual image-text and parallel text-only data. Additionally, we construct a new e-commercial multimodal translation dataset, named EMMT, of which the test set is specifically designed to include ambiguous words that require visual context for accurate translation. Experiments show that our method is well-suited for real-world scenarios and can significantly improve translation performance with more non-triple data. In addition, our model also rivals or surpasses various SOTA models in conventional multimodal translation benchmarks. | Yaoming Zhu, Zewei Sun, Shanbo Cheng, Luyang Huang, Liwei Wu, Mingxuan Wang |  |
| 511 |  |  [From chocolate bunny to chocolate crocodile: Do Language Models Understand Noun Compounds?](https://doi.org/10.18653/v1/2023.findings-acl.169) |  | 0 | Noun compound interpretation is the task of expressing a noun compound (e.g. chocolate bunny) in a free-text paraphrase that makes the relationship between the constituent nouns explicit (e.g. bunny-shaped chocolate). We propose modifications to the data and evaluation setup of the standard task (Hendrickx et al., 2013), and show that GPT-3 solves it almost perfectly. We then investigate the task of noun compound conceptualization, i.e. paraphrasing a novel or rare noun compound. E.g., chocolate crocodile is a crocodile-shaped chocolate. This task requires creativity, commonsense, and the ability to generalize knowledge about similar concepts. While GPT-3’s performance is not perfect, it is better than that of humans—likely thanks to its access to vast amounts of knowledge, and because conceptual processing is effortful for people (Connell and Lynott, 2012). Finally, we estimate the extent to which GPT-3 is reasoning about the world vs. parroting its training data. We find that the outputs from GPT-3 often have significant overlap with a large web corpus, but that the parroting strategy is less beneficial for novel noun compounds. | Albert Coil, Vered Shwartz |  |
| 512 |  |  [Measuring Intersectional Biases in Historical Documents](https://doi.org/10.18653/v1/2023.findings-acl.170) |  | 0 | Data-driven analyses of biases in historical texts can help illuminate the origin and development of biases prevailing in modern society. However, digitised historical documents pose a challenge for NLP practitioners as these corpora suffer from errors introduced by optical character recognition (OCR) and are written in an archaic language. In this paper, we investigate the continuities and transformations of bias in historical newspapers published in the Caribbean during the colonial era (18th to 19th centuries). Our analyses are performed along the axes of gender, race, and their intersection. We examine these biases by conducting a temporal study in which we measure the development of lexical associations using distributional semantics models and word embeddings. Further, we evaluate the effectiveness of techniques designed to process OCR-generated data and assess their stability when trained on and applied to the noisy historical newspapers. We find that there is a trade-off between the stability of the word embeddings and their compatibility with the historical dataset. We provide evidence that gender and racial biases are interdependent, and their intersection triggers distinct effects. These findings align with the theory of intersectionality, which stresses that biases affecting people with multiple marginalised identities compound to more than the sum of their constituents. | Nadav Borenstein, Karolina Stanczak, Thea Rolskov, Natacha Klein Käfer, Natalia da Silva Perez, Isabelle Augenstein |  |
| 513 |  |  [Incomplete Utterance Rewriting by A Two-Phase Locate-and-Fill Regime](https://doi.org/10.18653/v1/2023.findings-acl.171) |  | 0 | Rewriting incomplete and ambiguous utterances can improve dialogue models’ understanding of the context and help them generate better results. However, the existing end-to-end models will have the problem of too large search space, resulting in poor quality of rewriting results. We propose a 2-phase rewriting framework which first predicts the empty slots in the utterance that need to be completed, and then generate the part to be filled into each positions. Our framework is simple to implement, fast to run, and achieves the state-of-the-art results on several public rewriting datasets. | Zitong Li, Jiawei Li, Haifeng Tang, Kenny Q. Zhu, Ruolan Yang |  |
| 514 |  |  [Exploring Variation of Results from Different Experimental Conditions](https://doi.org/10.18653/v1/2023.findings-acl.172) |  | 0 | It might reasonably be expected that running multiple experiments for the same task using the same data and model would yield very similar results. Recent research has, however, shown this not to be the case for many NLP experiments. In this paper, we report extensive coordinated work by two NLP groups to run the training and testing pipeline for three neural text simplification models under varying experimental conditions, including different random seeds, run-time environments, and dependency versions, yielding a large number of results for each of the three models using the same data and train/dev/test set splits. From one perspective, these results can be interpreted as shedding light on the reproducibility of evaluation results for the three NTS models, and we present an in-depth analysis of the variation observed for different combinations of experimental conditions. From another perspective, the results raise the question of whether the averaged score should be considered the ‘true’ result for each model. | Maja Popovic, Mohammad Arvan, Natalie Parde, Anya Belz |  |
| 515 |  |  [Playing the Part of the Sharp Bully: Generating Adversarial Examples for Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2023.findings-acl.173) |  | 0 | Research on abusive content detection on social media has primarily focused on explicit forms of hate speech (HS), that are often identifiable by recognizing hateful words and expressions. Messages containing linguistically subtle and implicit forms of hate speech still constitute an open challenge for automatic hate speech detection. In this paper, we propose a new framework for generating adversarial implicit HS short-text messages using Auto-regressive Language Models. Moreover, we propose a strategy to group the generated implicit messages in complexity levels (EASY, MEDIUM, and HARD categories) characterizing how challenging these messages are for supervised classifiers. Finally, relying on (Dinan et al., 2019; Vidgen et al., 2021), we propose a “build it, break it, fix it”, training scheme using HARD messages showing how iteratively retraining on HARD messages substantially leverages SOTA models’ performances on implicit HS benchmarks. | Nicolás Benjamín Ocampo, Elena Cabrio, Serena Villata |  |
| 516 |  |  [X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents](https://doi.org/10.18653/v1/2023.findings-acl.174) |  | 0 | Task-oriented dialogue research has mainly focused on a few popular languages like English and Chinese, due to the high dataset creation cost for a new language. To reduce the cost, we apply manual editing to automatically translated data. We create a new multilingual benchmark, X-RiSAWOZ, by translating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean; and a code-mixed English-Hindi language.X-RiSAWOZ has more than 18,000 human-verified dialogue utterances for each language, and unlike most multilingual prior work, is an end-to-end dataset for building fully-functioning agents. The many difficulties we encountered in creating X-RiSAWOZ led us to develop a toolset to accelerate the post-editing of a new language dataset after translation. This toolset improves machine translation with a hybrid entity alignment technique that combines neural with dictionary-based methods, along with many automated and semi-automated validation checks. We establish strong baselines for X-RiSAWOZ by training dialogue agents in the zero- and few-shot settings where limited gold data is available in the target language. Our results suggest that our translation and post-editing methodology and toolset can be used to create new high-quality multilingual dialogue agents cost-effectively. Our dataset, code, and toolkit are released open-source. | Mehrad Moradshahi, Tianhao Shen, Kalika Bali, Monojit Choudhury, Gaël de Chalendar, Anmol Goel, Sungkyun Kim, Prashant Kodali, Ponnurangam Kumaraguru, Nasredine Semmar, Sina J. Semnani, Jiwon Seo, Vivek Seshadri, Manish Shrivastava, Michael Sun, Aditya Yadavalli, Chaobin You, Deyi Xiong, Monica S. Lam |  |
| 517 |  |  [Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation](https://doi.org/10.18653/v1/2023.findings-acl.175) |  | 0 | Subword segmenters like BPE operate as a preprocessing step in neural machine translation and other (conditional) language models. They are applied to datasets before training, so translation or text generation quality relies on the quality of segmentations. We propose a departure from this paradigm, called subword segmental machine translation (SSMT). SSMT unifies subword segmentation and MT in a single trainable model. It learns to segment target sentence words while jointly learning to generate target sentences. To use SSMT during inference we propose dynamic decoding, a text generation algorithm that adapts segmentations as it generates translations. Experiments across 6 translation directions show that SSMT improves chrF scores for morphologically rich agglutinative languages. Gains are strongest in the very low-resource scenario. SSMT also learns subwords that are closer to morphemes compared to baselines and proves more robust on a test set constructed for evaluating morphological compositional generalisation. | Francois Meyer, Jan Buys |  |
| 518 |  |  [Measuring and Mitigating Local Instability in Deep Neural Networks](https://doi.org/10.18653/v1/2023.findings-acl.176) |  | 0 | Deep Neural Networks (DNNs) are becoming integral components of real world services relied upon by millions of users. Unfortunately, architects of these systems can find it difficult to ensure reliable performance as irrelevant details like random initialization can unexpectedly change the outputs of a trained system with potentially disastrous consequences. We formulate the model stability problem by studying how the predictions of a model change, even when it is retrained on the same data, as a consequence of stochasticity in the training process. For Natural Language Understanding (NLU) tasks, we find instability in predictions for a significant fraction of queries. We formulate principled metrics, like per-sample “label entropy” across training runs or within a single training run, to quantify this phenomenon. Intriguingly, we find that unstable predictions do not appear at random, but rather appear to be clustered in data-specific ways. We study data-agnostic regularization methods to improve stability and propose new data-centric methods that exploit our local stability estimates. We find that our localized data-specific mitigation strategy dramatically outperforms data-agnostic methods, and comes within 90% of the gold standard, achieved by ensembling, at a fraction of the computational cost. | Arghya Datta, Subhrangshu Nandi, Jingcheng Xu, Greg Ver Steeg, He Xie, Anoop Kumar, Aram Galstyan |  |
| 519 |  |  [What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain Adaptation](https://doi.org/10.18653/v1/2023.findings-acl.177) |  | 0 | kNN-MT presents a new paradigm for domain adaptation by building an external datastore, which usually saves all target language token occurrences in the parallel corpus. As a result, the constructed datastore is usually large and possibly redundant. In this paper, we investigate the interpretability issue of this approach: what knowledge does the NMT model need? We propose the notion of local correctness (LAC) as a new angle, which describes the potential translation correctness for a single entry and for a given neighborhood. Empirical study shows that our investigation successfully finds the conditions where the NMT model could easily fail and need related knowledge. Experiments on six diverse target domains and two language-pairs show that pruning according to local correctness brings a light and more explainable memory for kNN-MT domain adaptation. | Wenhao Zhu, Shujian Huang, Yunzhe Lv, Xin Zheng, Jiajun Chen |  |
| 520 |  |  [Measuring Your ASTE Models in The Wild: A Diversified Multi-domain Dataset For Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.findings-acl.178) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) is widely used in various applications. However, existing ASTE datasets are limited in their ability to represent real-world scenarios, hindering the advancement of research in this area. In this paper, we introduce a new dataset, named DMASTE, which is manually annotated to better fit real-world scenarios by providing more diverse and realistic reviews for the task. The dataset includes various lengths, diverse expressions, more aspect types, and more domains than existing datasets. We conduct extensive experiments on DMASTE in multiple settings to evaluate previous ASTE approaches. Empirical results demonstrate that DMASTE is a more challenging ASTE dataset. Further analyses of in-domain and cross-domain settings provide some promising directions for future research. | Ting Xu, Huiyun Yang, Zhen Wu, Jiaze Chen, Fei Zhao, Xinyu Dai |  |
| 521 |  |  [Grounding the Lexical Substitution Task in Entailment](https://doi.org/10.18653/v1/2023.findings-acl.179) |  | 0 | Existing definitions of lexical substitutes are often vague or inconsistent with the gold annotations. We propose a new definition which is grounded in the relation of entailment; namely, that the sentence that results from the substitution should be in the relation of mutual entailment with the original sentence. We argue that the new definition is well-founded and supported by previous work on lexical entailment. We empirically validate our definition by verifying that it covers the majority of gold substitutes in existing datasets. Based on this definition, we create a new dataset from existing semantic resources. Finally, we propose a novel context augmentation method motivated by the definition, which relates the substitutes to the sense of the target word by incorporating glosses and synonyms directly into the context. Experimental results demonstrate that our augmentation approach improves the performance of lexical substitution systems on the existing benchmarks. | Talgat Omarov, Grzegorz Kondrak |  |
| 522 |  |  [Operator Selection and Ordering in a Pipeline Approach to Efficiency Optimizations for Transformers](https://doi.org/10.18653/v1/2023.findings-acl.180) |  | 0 | There exists a wide variety of efficiency methods for natural language processing (NLP) tasks, such as pruning, distillation, dynamic inference, quantization, etc. From a different perspective, we can consider an efficiency method as an operator applied on a model. Naturally, we may construct a pipeline of operators, i.e., to apply multiple efficiency methods on the model sequentially. In this paper, we study the plausibility of this idea, and more importantly, the commutativity and cumulativeness of efficiency operators. We make two interesting observations from our experiments: (1) The operators are commutative—the order of efficiency methods within the pipeline has little impact on the final results; (2) The operators are also cumulative—the final results of combining several efficiency methods can be estimated by combining the results of individual methods. These observations deepen our understanding of efficiency operators and provide useful guidelines for building them in real-world applications. | Ji Xin, Raphael Tang, Zhiying Jiang, Yaoliang Yu, Jimmy Lin |  |
| 523 |  |  [AraMUS: Pushing the Limits of Data and Model Scale for Arabic Natural Language Processing](https://doi.org/10.18653/v1/2023.findings-acl.181) |  | 0 | Developing monolingual large Pre-trained Language Models (PLMs) is shown to be very successful in handling different tasks in Natural Language Processing (NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B parameters trained on 529GB of high-quality Arabic textual data. AraMUS achieves state-of-the-art performances on a diverse set of Arabic classification and generative tasks. Moreover, AraMUS shows impressive few-shot learning abilities compared with the best existing Arabic PLMs. | Asaad Alghamdi, Xinyu Duan, Wei Jiang, Zhenhai Wang, Yimeng Wu, Qingrong Xia, Zhefeng Wang, Yi Zheng, Mehdi Rezagholizadeh, Baoxing Huai, Peilun Cheng, Abbas Ghaddar |  |
| 524 |  |  [Leveraging Explicit Procedural Instructions for Data-Efficient Action Prediction](https://doi.org/10.18653/v1/2023.findings-acl.182) |  | 0 | Task-oriented dialogues often require agents to enact complex, multi-step procedures in order to meet user requests. While large language models have found success automating these dialogues in constrained environments, their widespread deployment is limited by the substantial quantities of task-specific data required for training. The following paper presents a data-efficient solution to constructing dialogue systems, leveraging explicit instructions derived from agent guidelines, such as company policies or customer service manuals. Our proposed Knowledge-Augmented Dialogue System (KADS) combines a large language model with a knowledge retrieval module that pulls documents outlining relevant procedures from a predefined set of policies, given a user-agent interaction. To train this system, we introduce a semi-supervised pre-training scheme that employs dialogue-document matching and action-oriented masked language modeling with partial parameter freezing. We evaluate the effectiveness of our approach on prominent task-oriented dialogue datasets, Action-Based Conversations Dataset and Schema-Guided Dialogue, for two dialogue tasks: action state tracking and workflow discovery. Our results demonstrate that procedural knowledge augmentation improves accuracy predicting in- and out-of-distribution actions while preserving high performance in settings with low or sparse data. | Julia White, Arushi Raghuvanshi, Yada Pruksachatkun |  |
| 525 |  |  [Quantifying Train-Evaluation Overlap with Nearest Neighbors](https://doi.org/10.18653/v1/2023.findings-acl.183) |  | 0 | Characterizing benchmark datasets is crucial to interpreting model performance. In this work, we study train-evaluation overlap as a measure of an individual dataset’s adequacy to evaluate model generalization over a wide range of datasets. We quantify the overlap with a simple novel metric based on a nearest neighbors approach between the training and evaluation sets. We identify nearest training examples for each evaluation example by mapping instances with generic and task-specific embedding methods. Our study on eleven classification and extractive QA tasks reveals a wide range of train-evaluation overlap, and we show that the data collection method of the dataset and the difficulty of the task may play a role in the amount of overlap. Lastly, we use our nearest neighbor analysis to identify challenging or potentially mislabeled examples. Our analysis quantifies train-evaluation overlap, providing insights for constructing datasets to study generalization. | Gauri Kambhatla, Thuy Nguyen, Eunsol Choi |  |
| 526 |  |  [Unsupervised Mapping of Arguments of Deverbal Nouns to Their Corresponding Verbal Labels](https://doi.org/10.18653/v1/2023.findings-acl.184) |  | 0 | Deverbal nouns are nominal forms of verbs commonly used in written English texts to describe events or actions, as well as their arguments. However, many NLP systems, and in particular pattern-based ones, neglect to handle such nominalized constructions. The solutions that do exist for handling arguments of nominalized constructions are based on semantic annotation and require semantic ontologies, making their applications restricted to a small set of nouns. We propose to adopt instead a more syntactic approach, which maps the arguments of deverbal nouns to the universal-dependency relations of the corresponding verbal construction. We present an unsupervised mechanism—based on contextualized word representations—which allows to enrich universal-dependency trees with dependency arcs denoting arguments of deverbal nouns, using the same labels as the corresponding verbal cases. By sharing the same label set as in the verbal case, patterns that were developed for verbs can be applied without modification but with high accuracy also to the nominal constructions. | Aviv Weinstein, Yoav Goldberg |  |
| 527 |  |  [The Decades Progress on Code-Switching Research in NLP: A Systematic Survey on Trends and Challenges](https://doi.org/10.18653/v1/2023.findings-acl.185) |  | 0 | Code-Switching, a common phenomenon in written text and conversation, has been studied over decades by the natural language processing (NLP) research community. Initially, code-switching is intensively explored by leveraging linguistic theories and, currently, more machine-learning oriented approaches to develop models. We introduce a comprehensive systematic survey on code-switching research in natural language processing to understand the progress of the past decades and conceptualize the challenges and tasks on the code-switching topic. Finally, we summarize the trends and findings and conclude with a discussion for future direction and open questions for further investigation. | Genta Indra Winata, Alham Fikri Aji, Zheng Xin Yong, Thamar Solorio |  |
| 528 |  |  [Learning to Predict Persona Information for Dialogue Personalization without Explicit Persona Description](https://doi.org/10.18653/v1/2023.findings-acl.186) |  | 0 | Personalizing dialogue agents is important for dialogue systems to generate more specific,consistent, and engaging responses. However, most current dialogue personalization approaches rely on explicit persona descriptions during inference, which severely restricts its application. In this paper, we propose a novel approach that learns to predict persona information based on the dialogue history to personalize the dialogue agent without relying on any explicit persona descriptions during inference. Experimental results on the PersonaChat dataset show that the proposed method can improve the consistency of generated responses when conditioning on the predicted profile of the dialogue agent (i.e. “self persona”), and improve the engagingness of the generated responses when conditioning on the predicted persona of the dialogue partner (i.e. “their persona”). We also find that a trained persona prediction model can be successfully transferred to other datasets and help generate more relevant responses. | Wangchunshu Zhou, Qifei Li, Chenle Li |  |
| 529 |  |  [Automated Refugee Case Analysis: A NLP Pipeline for Supporting Legal Practitioners](https://doi.org/10.18653/v1/2023.findings-acl.187) |  | 0 | In this paper, we introduce an end-to-end pipeline for retrieving, processing, and extracting targeted information from legal cases. We investigate an under-studied legal domain with a case study on refugee law Canada. Searching case law for past similar cases is a key part of legal work for both lawyers and judges, the potential end-users of our prototype. While traditional named-entity recognition labels such as dates are meaningful information in law, we propose to extend existing models and retrieve a total of 19 categories of items from refugee cases. After creating a novel data set of cases, we perform information extraction based on state-of-the-art neural named-entity recognition (NER). We test different architectures including two transformer models, using contextual and non-contextual embeddings, and compare general purpose versus domain-specific pre-training. The results demonstrate that models pre-trained on legal data perform best despite their smaller size, suggesting that domain-matching had a larger effect than network architecture. We achieve a F1- score superior to 90% on five of the targeted categories and superior to 80% on an additional 4 categories. | Claire Barale, Michael Rovatsos, Nehal Bhuta |  |
| 530 |  |  [Recurrent Attention Networks for Long-text Modeling](https://doi.org/10.18653/v1/2023.findings-acl.188) |  | 0 | Self-attention-based models have achieved remarkable progress in short-text mining. However, the quadratic computational complexities restrict their application in long text processing. Prior works have adopted the chunking strategy to divide long documents into chunks and stack a self-attention backbone with the recurrent structure to extract semantic representation. Such an approach disables parallelization of the attention mechanism, significantly increasing the training cost and raising hardware requirements. Revisiting the self-attention mechanism and the recurrent structure, this paper proposes a novel long-document encoding model, Recurrent Attention Network (RAN), to enable the recurrent operation of self-attention. Combining the advantages from both sides, the well-designed RAN is capable of extracting global semantics in both token-level and document-level representations, making it inherently compatible with both sequential and classification tasks, respectively. Furthermore, RAN is computationally scalable as it supports parallelization on long document processing. Extensive experiments demonstrate the long-text encoding ability of the proposed RAN model on both classification and sequential tasks, showing its potential for a wide range of applications. | Xianming Li, Zongxi Li, Xiaotian Luo, Haoran Xie, Xing Lee, Yingbin Zhao, Fu Lee Wang, Qing Li |  |
| 531 |  |  [Exploring the Relationship between Alignment and Cross-lingual Transfer in Multilingual Transformers](https://doi.org/10.18653/v1/2023.findings-acl.189) |  | 0 | Without any explicit cross-lingual training data, multilingual language models can achieve cross-lingual transfer. One common way to improve this transfer is to perform realignment steps before fine-tuning, i.e., to train the model to build similar representations for pairs of words from translated sentences. But such realignment methods were found to not always improve results across languages and tasks, which raises the question of whether aligned representations are truly beneficial for cross-lingual transfer. We provide evidence that alignment is actually significantly correlated with cross-lingual transfer across languages, models and random seeds. We show that fine-tuning can have a significant impact on alignment, depending mainly on the downstream task and the model. Finally, we show that realignment can, in some instances, improve cross-lingual transfer, and we identify conditions in which realignment methods provide significant improvements. Namely, we find that realignment works better on tasks for which alignment is correlated with cross-lingual transfer when generalizing to a distant language and with smaller models, as well as when using a bilingual dictionary rather than FastAlign to extract realignment pairs. For example, for POS-tagging, between English and Arabic, realignment can bring a +15.8 accuracy improvement on distilmBERT, even outperforming XLM-R Large by 1.7. We thus advocate for further research on realignment methods for smaller multilingual models as an alternative to scaling. | Félix Gaschi, Patricio Cerda, Parisa Rastin, Yannick Toussaint |  |
| 532 |  |  [Aerial Vision-and-Dialog Navigation](https://doi.org/10.18653/v1/2023.findings-acl.190) |  | 0 | The ability to converse with humans and follow natural language commands is crucial for intelligent unmanned aerial vehicles (a.k.a. drones). It can relieve people’s burden of holding a controller all the time, allow multitasking, and make drone control more accessible for people with disabilities or with their hands occupied. To this end, we introduce Aerial Vision-and-Dialog Navigation (AVDN), to navigate a drone via natural language conversation. We build a drone simulator with a continuous photorealistic environment and collect a new AVDN dataset of over 3k recorded navigation trajectories with asynchronous human-human dialogs between commanders and followers. The commander provides initial navigation instruction and further guidance by request, while the follower navigates the drone in the simulator and asks questions when needed. During data collection, followers’ attention on the drone’s visual observation is also recorded. Based on the AVDN dataset, we study the tasks of aerial navigation from (full) dialog history and propose an effective Human Attention Aided Transformer model (HAA-Transformer), which learns to predict both navigation waypoints and human attention. | Yue Fan, Winson Chen, Tongzhou Jiang, Chun Zhou, Yi Zhang, Xin Wang |  |
| 533 |  |  [Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming](https://doi.org/10.18653/v1/2023.findings-acl.191) |  | 0 | Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length. | Hanlin Zhang, Jiani Huang, Ziyang Li, Mayur Naik, Eric P. Xing |  |
| 534 |  |  [B2T Connection: Serving Stability and Performance in Deep Transformers](https://doi.org/10.18653/v1/2023.findings-acl.192) |  | 0 | In the perspective of a layer normalization (LN) position, the architecture of Transformers can be categorized into two types: Post-LN and Pre-LN.Recent Transformers prefer to select Pre-LN because the training in Post-LN with deep Transformers, e.g., ten or more layers, often becomes unstable, resulting in useless models. However, in contrast, Post-LN has also consistently achieved better performance than Pre-LN in relatively shallow Transformers, e.g., six or fewer layers. This study first investigates the reason for these discrepant observations empirically and theoretically and discovers 1, the LN in Post-LN is the source of the vanishing gradient problem that mainly leads the unstable training whereas Pre-LN prevents it, and 2, Post-LN tends to preserve larger gradient norms in higher layers during the back-propagation that may lead an effective training. Exploiting the new findings, we propose a method that can equip both higher stability and effective training by a simple modification from Post-LN.We conduct experiments on a wide range of text generation tasks and demonstrate that our method outperforms Pre-LN, and stable training regardless of the shallow or deep layer settings. | Sho Takase, Shun Kiyono, Sosuke Kobayashi, Jun Suzuki |  |
| 535 |  |  [Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data](https://doi.org/10.18653/v1/2023.findings-acl.193) |  | 0 | Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distant languages (up to 2x absolute gain). We further show that our approach is robust towards the ratio of code-switched tokens and also extends to unseen languages. Our results demonstrate that training on code-switched data is a cheap and effective way of generalizing zero-shot rankers for cross-lingual and multilingual retrieval. | Robert Litschko, Ekaterina Artemova, Barbara Plank |  |
| 536 |  |  [Domain-specific Attention with Distributional Signatures for Multi-Domain End-to-end Task-Oriented Dialogue](https://doi.org/10.18653/v1/2023.findings-acl.194) |  | 0 | The end-to-end task-oriented dialogue system has achieved great success in recent years. Most of these dialogue systems need to accommodate multi-domain dialogue in real-world scenarios. However, due to the high cost of dialogue data annotation and the scarcity of labeled dialogue data, existing methods are difficult to extend to new domains. Therefore, it is important to use limited data to construct multi-domain dialogue systems. To solve this problem, we propose a novel domain attention module. It use the distributional signatures to construct a multi-domain dialogue system effectively with limited data, which has strong extensibility. We also define a adjacent n-gram pattern to explore potential patterns for dialogue entities. Experimental results show that our approach outperforms the baseline models on most metrics. In the few-shot scenario, we show our method get a great improvement compared with previous methods while keeping smaller model scale. | Xing Ma, Peng Zhang, Feifei Zhao |  |
| 537 |  |  [CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation](https://doi.org/10.18653/v1/2023.findings-acl.195) |  | 0 | Distilling knowledge from a high-resource task, e.g., machine translation, is an effective way to alleviate the data scarcity problem of end-to-end speech translation. However, previous works simply use the classical knowledge distillation that does not allow for adequate transfer of knowledge from machine translation. In this paper, we propose a comprehensive knowledge distillation framework for speech translation, CKDST, which is capable of comprehensively and effectively distilling knowledge from machine translation to speech translation from two perspectives: cross-modal contrastive representation distillation and simultaneous decoupled knowledge distillation. In the former, we leverage a contrastive learning objective to optmize the mutual information between speech and text representations for representation distillation in the encoder. In the later, we decouple the non-target class knowledge from target class knowledge for logits distillation in the decoder. Experiments on the MuST-C benchmark dataset demonstrate that our CKDST substantially improves the baseline by 1.2 BLEU on average in all translation directions, and outperforms previous state-of-the-art end-to-end and cascaded speech translation models. | Yikun Lei, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong |  |
| 538 |  |  [Follow the leader(board) with confidence: Estimating p-values from a single test set with item and response variance](https://doi.org/10.18653/v1/2023.findings-acl.196) |  | 0 | Among the problems with leaderboard culture in NLP has been the widespread lack of confidence estimation in reported results. In this work, we present a framework and simulator for estimating p-values for comparisons between the results of two systems, in order to understand the confidence that one is actually better (i.e. ranked higher) than the other. What has made this difficult in the past is that each system must itself be evaluated by comparison to a gold standard. We define a null hypothesis that each system’s metric scores are drawn from the same distribution, using variance found naturally (though rarely reported) in test set items and individual labels on an item (responses) to produce the metric distributions. We create a test set that evenly mixes the responses of the two systems under the assumption the null hypothesis is true. Exploring how to best estimate the true p-value from a single test set under different metrics, tests, and sampling methods, we find that the presence of response variance (from multiple raters or multiple model versions) has a profound impact on p-value estimates for model comparison, and that choice of metric and sampling method is critical to providing statistical guarantees on model comparisons. | Shira Wein, Christopher Homan, Lora Aroyo, Chris Welty |  |
| 539 |  |  [Parallel Data Helps Neural Entity Coreference Resolution](https://doi.org/10.18653/v1/2023.findings-acl.197) |  | 0 | Coreference resolution is the task of finding expressions that refer to the same entity in a text. Coreference models are generally trained on monolingual annotated data but annotating coreference is expensive and challenging. Hardmeier et al. (2013) have shown that parallel data contains latent anaphoric knowledge, but it has not been explored in end-to-end neural models yet. In this paper, we propose a simple yet effective model to exploit coreference knowledge from parallel data. In addition to the conventional modules learning coreference from annotations, we introduce an unsupervised module to capture cross-lingual coreference knowledge. Our proposed cross-lingual model achieves consistent improvements, up to 1.74 percentage points, on the OntoNotes 5.0 English dataset using 9 different synthetic parallel datasets. These experimental results confirm that parallel data can provide additional coreference knowledge which is beneficial to coreference resolution tasks. | Gongbo Tang, Christian Hardmeier |  |
| 540 |  |  [Towards Open-Domain Twitter User Profile Inference](https://doi.org/10.18653/v1/2023.findings-acl.198) |  | 0 | Twitter user profile inference utilizes information from Twitter to predict user attributes (e.g., occupation, location), which is controversial because of its usefulness for downstream applications and its potential to reveal users’ privacy. Therefore, it is important for researchers to determine the extent of profiling in a safe environment to facilitate proper use and make the public aware of the potential risks. Contrary to existing approaches on limited attributes, we explore open-domain Twitter user profile inference. We conduct a case study where we collect publicly available WikiData public figure profiles and use diverse WikiData predicates for profile inference. After removing sensitive attributes, our data contains over 150K public figure profiles from WikiData, over 50 different attribute predicates, and over 700K attribute values. We further propose a prompt-based generation method, which can infer values that are implicitly mentioned in the Twitter information. Experimental results show that the generation-based approach can infer more comprehensive user profiles than baseline extraction-based methods, but limitations still remain to be applied for real-world use. We also enclose a detailed ethical statement for our data, potential benefits and risks from this work, and our efforts to mitigate the risks. | Haoyang Wen, Zhenxin Xiao, Eduard H. Hovy, Alexander G. Hauptmann |  |
| 541 |  |  [Eliciting Affective Events from Language Models by Multiple View Co-prompting](https://doi.org/10.18653/v1/2023.findings-acl.199) |  | 0 | Prior research on affective event classification showed that exploiting weakly labeled data for training can improve model performance. In this work, we propose a simpler and more effective approach for generating training data by automatically acquiring and labeling affective events with Multiple View Co-prompting, which leverages two language model prompts that provide independent views of an event. The approach starts with a modest amount of gold data and prompts pre-trained language models to generate new events. Next, information about the probable affective polarity of each event is collected from two complementary language model prompts and jointly used to assign polarity labels. Experimental results on two datasets show that the newly acquired events improve a state-of-the-art affective event classifier. We also present analyses which show that using multiple views produces polarity labels of higher quality than either view on its own. | Yuan Zhuang, Ellen Riloff |  |
| 542 |  |  [ZeroAE: Pre-trained Language Model based Autoencoder for Transductive Zero-shot Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.200) |  | 0 | Many text classification tasks require handling unseen domains with plenty of unlabeled data, thus giving rise to the self-adaption or the so-called transductive zero-shot learning (TZSL) problem. However, current methods based solely on encoders or decoders overlook the possibility that these two modules may promote each other. As a first effort to bridge this gap, we propose an autoencoder named ZeroAE. Specifically, the text is encoded with two separate BERT-based encoders into two disentangled spaces, i.e., label-relevant (for classification) and label-irrelevant respectively. The two latent spaces are then decoded by prompting GPT-2 to recover the text as well as to further generate text with labels in the unseen domains to train the encoder in turn. To better exploit the unlabeled data, a novel indirect uncertainty-aware sampling (IUAS) approach is proposed to train ZeroAE. Extensive experiments show that ZeroAE largely surpasses the SOTA methods by 15.93% and 8.70% on average respectively in the label-partially-unseen and label-fully-unseen scenario. Notably, the label-fully-unseen ZeroAE even possesses superior performance to the label-partially-unseen SOTA methods. | Kaihao Guo, Hang Yu, Cong Liao, Jianguo Li, Haipeng Zhang |  |
| 543 |  |  [PRAM: An End-to-end Prototype-based Representation Alignment Model for Zero-resource Cross-lingual Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.201) |  | 0 | Zero-resource cross-lingual named entity recognition (ZRCL-NER) aims to leverage rich labeled source language data to address the NER problem in the zero-resource target language. Existing methods are built either based on data transfer or representation transfer. However, the former usually leads to additional computation costs, and the latter lacks explicit optimization specific to the NER task. To overcome the above limitations, we propose a novel prototype-based representation alignment model (PRAM) for the challenging ZRCL-NER task. PRAM models the cross-lingual (CL) NER task and transfers knowledge from source languages to target languages in a unified neural network, and performs end-to-end training, avoiding additional computation costs. Moreover, PRAM borrows the CL inference ability of multilingual language models and enhances it with a novel training objective—attribution-prediction consistency (APC)—for explicitly enforcing the entity-level alignment between entity representations and predictions, as well as that across languages using prototypes as bridges. The experimental results show that PRAM significantly outperforms existing state-of-the-art methods, especially in some challenging scenarios. | Yucheng Huang, Wenqiang Liu, Xianli Zhang, Jun Lang, Tieliang Gong, Chen Li |  |
| 544 |  |  [It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance](https://doi.org/10.18653/v1/2023.findings-acl.202) |  | 0 | Progress in NLP is increasingly measured through benchmarks; hence, contextualizing progress requires understanding when and why practitioners may disagree about the validity of benchmarks. We develop a taxonomy of disagreement, drawing on tools from measurement modeling, and distinguish between two types of disagreement: 1) how tasks are conceptualized and 2) how measurements of model performance are operationalized. To provide evidence for our taxonomy, we conduct a meta-analysis of relevant literature to understand how NLP tasks are conceptualized, as well as a survey of practitioners about their impressions of different factors that affect benchmark validity. Our meta-analysis and survey across eight tasks, ranging from coreference resolution to question answering, uncover that tasks are generally not clearly and consistently conceptualized and benchmarks suffer from operationalization disagreements. These findings support our proposed taxonomy of disagreement. Finally, based on our taxonomy, we present a framework for constructing benchmarks and documenting their limitations. | Arjun Subramonian, Xingdi Yuan, Hal Daumé III, Su Lin Blodgett |  |
| 545 |  |  [Task-adaptive Label Dependency Transfer for Few-shot Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.203) |  | 0 | Named Entity Recognition (NER), as a crucial subtask in natural language processing (NLP), suffers from limited labeled samples (a.k.a. few-shot). Meta-learning methods are widely used for few-shot NER, but these existing methods overlook the importance of label dependency for NER, resulting in suboptimal performance. However, applying meta-learning methods to label dependency learning faces a special challenge, that is, due to the discrepancy of label sets in different domains, the label dependencies can not be transferred across domains. In this paper, we propose the Task-adaptive Label Dependency Transfer (TLDT) method to make label dependency transferable and effectively adapt to new tasks by a few samples. TLDT improves the existing optimization-based meta-learning methods by learning general initialization and individual parameter update rule for label dependency. Extensive experiments show that TLDT achieves significant improvement over the state-of-the-art methods. | Shan Zhang, Bin Cao, Tianming Zhang, Yuqi Liu, Jing Fan |  |
| 546 |  |  [WYWEB: A NLP Evaluation Benchmark For Classical Chinese](https://doi.org/10.18653/v1/2023.findings-acl.204) |  | 0 | To fully evaluate the overall performance of different NLP models in a given domain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and CLUE. The field of natural language understanding has traditionally focused on benchmarks for various tasks in languages such as Chinese, English, and multilingual, however, there has been a lack of attention given to the area of classical Chinese, also known as "wen yan wen (文言文)", which has a rich history spanning thousands of years and holds significant cultural and academic value. For the prosperity of the NLP community, in this paper, we introduce the WYWEB evaluation benchmark, which consists of nine NLP tasks in classical Chinese, implementing sentence classification, sequence labeling, reading comprehension, and machine translation. We evaluate the existing pre-trained language models, which are all struggling with this benchmark. We also introduce a number of supplementary datasets and additional tools to help facilitate further progress on classical Chinese NLU. The github repository is https://github.com/baudzhou/WYWEB. | Bo Zhou, Qianglong Chen, Xiaomi Zhong, Yin Zhang |  |
| 547 |  |  [A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment](https://doi.org/10.18653/v1/2023.findings-acl.205) |  | 0 | Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 distinct KGs across five languages. Without any supervision or hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including cutting-edge supervised entity alignment methods. Our code is available at https://github.com/squareRoot3/FusedGW-Entity-Alignment. | Jianheng Tang, Kangfei Zhao, Jia Li |  |
| 548 |  |  [Two Examples are Better than One: Context Regularization for Gradient-based Prompt Tuning](https://doi.org/10.18653/v1/2023.findings-acl.206) |  | 0 | Prompting has gained tremendous attention as an efficient method for the adaptation of large-scale language models. However, prompts often act against human intuition and report unstable performances, which has motivated methods that automatically find effective prompts. One popular approach is gradient-based search, which iteratively updates a (randomly) initialized prompt towards the optimal one with the guide of gradients. We propose a novel regularization method, CoRe, for gradient-based prompt tuning techniques, which guides a prompt to produce a task context properly. CoRe realizes two regularization effects — context attuning and context filtering — that improve prediction performance in a zero-shot in-context learning setting where a model makes inferences only with the prompt tuned by CoRe, without any demonstration examples for in-context learning. Context attuning guides the context generated by the input and the tuned prompt toward embedding the appropriate context for the task. In our theoretical analysis, regularizing the context extends to improving zero-shot in-context learning performance. Context filtering steers the prompt to select only the task-related context so that context attuning solely focuses on creating and sending the right task context. We evaluate CoRe on natural language understanding datasets and two large language models, GPT2-XL and GPT-J.Our training scheme shows performance improvements up to 11.9% on GPT2-XL, and up to 6.3% on GPT-J in zero-shot settings. | Hyeonmin Ha, Soyoung Jung, Jinsol Park, Minjoon Seo, Seungwon Hwang, ByungGon Chun |  |
| 549 |  |  [An Investigation of Noise in Morphological Inflection](https://doi.org/10.18653/v1/2023.findings-acl.207) |  | 0 | With a growing focus on morphological inflection systems for languages where high-quality data is scarce, training data noise is a serious but so far largely ignored concern. We aim at closing this gap by investigating the types of noise encountered within a pipeline for truly unsupervised morphological paradigm completion and its impact on morphological inflection systems: First, we propose an error taxonomy and annotation pipeline for inflection training data. Then, we compare the effect of different types of noise on multiple state-of-the- art inflection models. Finally, we propose a novel character-level masked language modeling (CMLM) pretraining objective and explore its impact on the models’ resistance to noise. Our experiments show that various architectures are impacted differently by separate types of noise, but encoder-decoders tend to be more robust to noise than models trained with a copy bias. CMLM pretraining helps transformers, but has lower impact on LSTMs. | Adam Wiemerslage, Changbing Yang, Garrett Nicolai, Miikka Silfverberg, Katharina Kann |  |
| 550 |  |  [Graph Reasoning for Question Answering with Triplet Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.208) |  | 0 | Answering complex questions often requires reasoning over knowledge graphs (KGs). State-of-the-art methods often utilize entities in questions to retrieve local subgraphs, which are then fed into KG encoder, e.g. graph neural networks (GNNs), to model their local structures and integrated into language models for question answering. However, this paradigm constrains retrieved knowledge in local subgraphs and discards more diverse triplets buried in KGs that are disconnected but useful for question answering. In this paper, we propose a simple yet effective method to first retrieve the most relevant triplets from KGs and then rerank them, which are then concatenated with questions to be fed into language models. Extensive results on both CommonsenseQA and OpenbookQA datasets show that our method can outperform state-of-the-art up to 4.6% absolute accuracy. | Shiyang Li, Yifan Gao, Haoming Jiang, Qingyu Yin, Zheng Li, Xifeng Yan, Chao Zhang, Bing Yin |  |
| 551 |  |  [End-to-End Argument Mining over Varying Rhetorical Structures](https://doi.org/10.18653/v1/2023.findings-acl.209) |  | 0 |  | Elena Chistova |  |
| 552 |  |  [Unsupervised Task Graph Generation from Instructional Video Transcripts](https://doi.org/10.18653/v1/2023.findings-acl.210) |  | 0 |  | Lajanugen Logeswaran, Sungryull Sohn, Yunseok Jang, Moontae Lee, Honglak Lee |  |
| 553 |  |  [Exploiting Hierarchically Structured Categories in Fine-grained Chinese Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.211) |  | 0 |  | Jiuding Yang, Jinwen Luo, Weidong Guo, Di Niu, Yu Xu |  |
| 554 |  |  [Adversarial Textual Robustness on Visual Dialog](https://doi.org/10.18653/v1/2023.findings-acl.212) |  | 0 |  | Lu Yu, Verena Rieser |  |
| 555 |  |  [Language Model Analysis for Ontology Subsumption Inference](https://doi.org/10.18653/v1/2023.findings-acl.213) |  | 0 |  | Yuan He, Jiaoyan Chen, Ernesto JiménezRuiz, Hang Dong, Ian Horrocks |  |
| 556 |  |  [Exploring Automatically Perturbed Natural Language Explanations in Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.214) |  | 0 |  | Wanyun Cui, Xingran Chen |  |
| 557 |  |  [Varta: A Large-Scale Headline-Generation Dataset for Indic Languages](https://doi.org/10.18653/v1/2023.findings-acl.215) |  | 0 |  | Rahul Aralikatte, Ziling Cheng, Sumanth Doddapaneni, Jackie Chi Kit Cheung |  |
| 558 |  |  [Better Zero-Shot Reasoning with Self-Adaptive Prompting](https://doi.org/10.18653/v1/2023.findings-acl.216) |  | 0 |  | Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan Ö. Arik, Tomas Pfister |  |
| 559 |  |  [Multimodal Recommendation Dialog with Subjective Preference: A New Challenge and Benchmark](https://doi.org/10.18653/v1/2023.findings-acl.217) |  | 0 |  | Yuxing Long, Binyuan Hui, Caixia Yuan, Fei Huang, Yongbin Li, Xiaojie Wang |  |
| 560 |  |  [ANALOGICAL - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models](https://doi.org/10.18653/v1/2023.findings-acl.218) |  | 0 |  | Thilini Wijesiriwardene, Ruwan Wickramarachchi, Bimal G. Gajera, Shreeyash Mukul Gowaikar, Chandan Gupta, Aman Chadha, Aishwarya Naresh Reganti, Amit P. Sheth, Amitava Das |  |
| 561 |  |  [Financial Numeric Extreme Labelling: A dataset and benchmarking](https://doi.org/10.18653/v1/2023.findings-acl.219) |  | 0 |  | Soumya Sharma, Subhendu Khatuya, Manjunath Hegde, Afreen Shaikh, Koustuv Dasgupta, Pawan Goyal, Niloy Ganguly |  |
| 562 |  |  [Multilingual Summarization with Factual Consistency Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.220) |  | 0 |  | Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, Mirella Lapata |  |
| 563 |  |  [Enhancing Out-of-Vocabulary Estimation with Subword Attention](https://doi.org/10.18653/v1/2023.findings-acl.221) |  | 0 |  | Raj Patel, Carlotta Domeniconi |  |
| 564 |  |  [Encoder and Decoder, Not One Less for Pre-trained Language Model Sponsored NMT](https://doi.org/10.18653/v1/2023.findings-acl.222) |  | 0 |  | Sufeng Duan, Hai Zhao |  |
| 565 |  |  [TransGEC: Improving Grammatical Error Correction with Translationese](https://doi.org/10.18653/v1/2023.findings-acl.223) |  | 0 |  | Tao Fang, Xuebo Liu, Derek F. Wong, Runzhe Zhan, Liang Ding, Lidia S. Chao, Dacheng Tao, Min Zhang |  |
| 566 |  |  [NewsDialogues: Towards Proactive News Grounded Conversation](https://doi.org/10.18653/v1/2023.findings-acl.224) |  | 0 |  | Siheng Li, Yichun Yin, Cheng Yang, Wangjie Jiang, Yiwei Li, Zesen Cheng, Lifeng Shang, Xin Jiang, Qun Liu, Yujiu Yang |  |
| 567 |  |  [Task-aware Retrieval with Instructions](https://doi.org/10.18653/v1/2023.findings-acl.225) |  | 0 |  | Akari Asai, Timo Schick, Patrick Lewis, Xilun Chen, Gautier Izacard, Sebastian Riedel, Hannaneh Hajishirzi, Wentau Yih |  |
| 568 |  |  [Non-Repeatable Experiments and Non-Reproducible Results: The Reproducibility Crisis in Human Evaluation in NLP](https://doi.org/10.18653/v1/2023.findings-acl.226) |  | 0 |  | Anya Belz, Craig Thomson, Ehud Reiter, Simon Mille |  |
| 569 |  |  [Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models](https://doi.org/10.18653/v1/2023.findings-acl.227) |  | 0 |  | Lingjun Zhao, Khanh Nguyen, Hal Daumé III |  |
| 570 |  |  [Robustness of Multi-Source MT to Transcription Errors](https://doi.org/10.18653/v1/2023.findings-acl.228) |  | 0 |  | Dominik Machácek, Peter Polak, Ondrej Bojar, Raj Dabre |  |
| 571 |  |  [Not The End of Story: An Evaluation of ChatGPT-Driven Vulnerability Description Mappings](https://doi.org/10.18653/v1/2023.findings-acl.229) |  | 0 |  | Xin Liu, Yuan Tan, Zhenghang Xiao, Jianwei Zhuge, Rui Zhou |  |
| 572 |  |  [Multi3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue](https://doi.org/10.18653/v1/2023.findings-acl.230) |  | 0 |  | Nikita Moghe, Evgeniia Razumovskaia, Liane Guillou, Ivan Vulic, Anna Korhonen, Alexandra Birch |  |
| 573 |  |  [A Robust Information-Masking Approach for Domain Counterfactual Generation](https://doi.org/10.18653/v1/2023.findings-acl.231) |  | 0 |  | Pengfei Hong, Rishabh Bhardwaj, Navonil Majumder, Somak Aditya, Soujanya Poria |  |
| 574 |  |  [Misleading Relation Classifiers by Substituting Words in Texts](https://doi.org/10.18653/v1/2023.findings-acl.232) |  | 0 |  | Tian Jiang, Yunqi Liu, Yan Feng, Yuqing Li, Xiaohui Cui |  |
| 575 |  |  [Automatic Table Union Search with Tabular Representation Learning](https://doi.org/10.18653/v1/2023.findings-acl.233) |  | 0 |  | Xuming Hu, Shen Wang, Xiao Qin, Chuan Lei, Zhengyuan Shen, Christos Faloutsos, Asterios Katsifodimos, George Karypis, Lijie Wen, Philip S. Yu |  |
| 576 |  |  [Bidirectional Transformer Reranker for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.findings-acl.234) |  | 0 |  | Ying Zhang, Hidetaka Kamigaito, Manabu Okumura |  |
| 577 |  |  [Not Enough Data to Pre-train Your Language Model? MT to the Rescue!](https://doi.org/10.18653/v1/2023.findings-acl.235) |  | 0 |  | Gorka Urbizu, Iñaki San Vicente, Xabier Saralegi, Ander Corral |  |
| 578 |  |  [UMSE: Unified Multi-scenario Summarization Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.236) |  | 0 |  | Shen Gao, Zhitao Yao, Chongyang Tao, Xiuying Chen, Pengjie Ren, Zhaochun Ren, Zhumin Chen |  |
| 579 |  |  [Maximum Entropy Loss, the Silver Bullet Targeting Backdoor Attacks in Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.237) |  | 0 |  | Zhengxiao Liu, Bowen Shen, Zheng Lin, Fali Wang, Weiping Wang |  |
| 580 |  |  [Improving Named Entity Recognition via Bridge-based Domain Adaptation](https://doi.org/10.18653/v1/2023.findings-acl.238) |  | 0 |  | Jingyun Xu, Changmeng Zheng, Yi Cai, TatSeng Chua |  |
| 581 |  |  [SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.239) |  | 0 |  | Shuzheng Si, Zefan Cai, Shuang Zeng, Guoqiang Feng, Jiaxing Lin, Baobao Chang |  |
| 582 |  |  [The State of Profanity Obfuscation in Natural Language Processing Scientific Publications](https://doi.org/10.18653/v1/2023.findings-acl.240) |  | 0 |  | Debora Nozza, Dirk Hovy |  |
| 583 |  |  [Teacher and Student Models of Offensive Language in Social Media](https://doi.org/10.18653/v1/2023.findings-acl.241) |  | 0 |  | Tharindu Ranasinghe, Marcos Zampieri |  |
| 584 |  |  [A Simple Yet Strong Domain-Agnostic De-bias Method for Zero-Shot Sentiment Classification](https://doi.org/10.18653/v1/2023.findings-acl.242) |  | 0 |  | Yang Zhao, Tetsuya Nasukawa, Masayasu Muraoka, Bishwaranjan Bhattacharjee |  |
| 585 |  |  [Balancing the Effect of Training Dataset Distribution of Multiple Styles for Multi-Style Text Transfer](https://doi.org/10.18653/v1/2023.findings-acl.243) |  | 0 |  | Debarati Das, David Ma, Dongyeop Kang |  |
| 586 |  |  [A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches](https://doi.org/10.18653/v1/2023.findings-acl.244) |  | 0 |  | Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang |  |
| 587 |  |  [Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for Word Sense Disambiguation](https://doi.org/10.18653/v1/2023.findings-acl.245) |  | 0 |  | Zhu Liu, Ying Liu |  |
| 588 |  |  [Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks](https://doi.org/10.18653/v1/2023.findings-acl.246) |  | 0 |  | Zhenhailong Wang, Xiaoman Pan, Dian Yu, Dong Yu, Jianshu Chen, Heng Ji |  |
| 589 |  |  [Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers](https://doi.org/10.18653/v1/2023.findings-acl.247) |  | 0 |  | Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, Furu Wei |  |
| 590 |  |  [Dramatic Conversation Disentanglement](https://doi.org/10.18653/v1/2023.findings-acl.248) |  | 0 |  | Kent K. Chang, Danica Chen, David Bamman |  |
| 591 |  |  [Injecting Comparison Skills in Task-Oriented Dialogue Systems for Database Search Results Disambiguation](https://doi.org/10.18653/v1/2023.findings-acl.249) |  | 0 |  | Yongil Kim, Yerin Hwang, Joongbo Shin, Hyunkyung Bae, Kyomin Jung |  |
| 592 |  |  [Emergent Modularity in Pre-trained Transformers](https://doi.org/10.18653/v1/2023.findings-acl.250) |  | 0 |  | Zhengyan Zhang, Zhiyuan Zeng, Yankai Lin, Chaojun Xiao, Xiaozhi Wang, Xu Han, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Jie Zhou |  |
| 593 |  |  [Universal Information Extraction with Meta-Pretrained Self-Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.251) |  | 0 |  | Xin Cong, Bowen Yu, Mengcheng Fang, Tingwen Liu, Haiyang Yu, Zhongkai Hu, Fei Huang, Yongbin Li, Bin Wang |  |
| 594 |  |  [SETI: Systematicity Evaluation of Textual Inference](https://doi.org/10.18653/v1/2023.findings-acl.252) |  | 0 |  | Xiyan Fu, Anette Frank |  |
| 595 |  |  [Coarse-to-fine Few-shot Learning for Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.253) |  | 0 |  | Ruotian Ma, Zhang Lin, Xuanting Chen, Xin Zhou, Junzhe Wang, Tao Gui, Qi Zhang, Xiang Gao, Yun Wen Chen |  |
| 596 |  |  [Self-Evolution Learning for Discriminative Language Model Pretraining](https://doi.org/10.18653/v1/2023.findings-acl.254) |  | 0 |  | Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao |  |
| 597 |  |  [QueryForm: A Simple Zero-shot Form Entity Query Framework](https://doi.org/10.18653/v1/2023.findings-acl.255) |  | 0 |  | Zifeng Wang, Zizhao Zhang, Jacob Devlin, ChenYu Lee, Guolong Su, Hao Zhang, Jennifer G. Dy, Vincent Perot, Tomas Pfister |  |
| 598 |  |  [Search-Oriented Conversational Query Editing](https://doi.org/10.18653/v1/2023.findings-acl.256) |  | 0 |  | Kelong Mao, Zhicheng Dou, Bang Liu, Hongjin Qian, Fengran Mo, Xiangli Wu, Xiaohua Cheng, Zhao Cao |  |
| 599 |  |  [TAPIR: Learning Adaptive Revision for Incremental Natural Language Understanding with a Two-Pass Model](https://doi.org/10.18653/v1/2023.findings-acl.257) |  | 0 |  | Patrick Kahardipraja, Brielen Madureira, David Schlangen |  |
| 600 |  |  [Speaking the Language of Your Listener: Audience-Aware Adaptation via Plug-and-Play Theory of Mind](https://doi.org/10.18653/v1/2023.findings-acl.258) |  | 0 |  | Ece Takmaz, Nicolo' Brandizzi, Mario Giulianelli, Sandro Pezzelle, Raquel Fernández |  |
| 601 |  |  [A Semi-Autoregressive Graph Generative Model for Dependency Graph Parsing](https://doi.org/10.18653/v1/2023.findings-acl.259) |  | 0 |  | Ye Ma, Mingming Sun, Ping Li |  |
| 602 |  |  [AMR-TST: Abstract Meaning Representation-based Text Style Transfer](https://doi.org/10.18653/v1/2023.findings-acl.260) |  | 0 |  | Kaize Shi, Xueyao Sun, Li He, Dingxian Wang, Qing Li, Guandong Xu |  |
| 603 |  |  [Understanding the Cooking Process with English Recipe Text](https://doi.org/10.18653/v1/2023.findings-acl.261) |  | 0 |  | Yi Fan, Anthony Hunter |  |
| 604 |  |  [Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2023.findings-acl.262) |  | 0 |  | Mirac Suzgun, Luke MelasKyriazi, Dan Jurafsky |  |
| 605 |  |  [RobustQA: Benchmarking the Robustness of Domain Adaptation for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.263) |  | 0 |  | Rujun Han, Peng Qi, Yuhao Zhang, Lan Liu, Juliette Burger, William Yang Wang, Zhiheng Huang, Bing Xiang, Dan Roth |  |
| 606 |  |  [SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations](https://doi.org/10.18653/v1/2023.findings-acl.264) |  | 0 |  | Victoria Lin, LouisPhilippe Morency |  |
| 607 |  |  [Reinforcement Learning for Topic Models](https://doi.org/10.18653/v1/2023.findings-acl.265) |  | 0 |  | Jeremy Costello, Marek Z. Reformat |  |
| 608 |  |  [Contextualized Soft Prompts for Extraction of Event Arguments](https://doi.org/10.18653/v1/2023.findings-acl.266) |  | 0 |  | Chien Van Nguyen, Hieu Man, Thien Huu Nguyen |  |
| 609 |  |  [TextVerifier: Robustness Verification for Textual Classifiers with Certifiable Guarantees](https://doi.org/10.18653/v1/2023.findings-acl.267) |  | 0 |  | Siqi Sun, Wenjie Ruan |  |
| 610 |  |  [OASum: Large-Scale Open Domain Aspect-based Summarization](https://doi.org/10.18653/v1/2023.findings-acl.268) |  | 0 |  | Xianjun Yang, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Xiaoman Pan, Linda R. Petzold, Dong Yu |  |
| 611 |  |  [On the Limitations of Simulating Active Learning](https://doi.org/10.18653/v1/2023.findings-acl.269) |  | 0 |  | Katerina Margatina, Nikolaos Aletras |  |
| 612 |  |  [Towards Alleviating the Object Bias in Prompt Tuning-based Factual Knowledge Extraction](https://doi.org/10.18653/v1/2023.findings-acl.270) |  | 0 |  | Yuhang Wang, Dongyuan Lu, Chao Kong, Jitao Sang |  |
| 613 |  |  [vONTSS: vMF based semi-supervised neural topic modeling with optimal transport](https://doi.org/10.18653/v1/2023.findings-acl.271) |  | 0 |  | Weijie Xu, Xiaoyu Jiang, Srinivasan Sengamedu Hanumantha Rao, Francis Iannacci, Jinjin Zhao |  |
| 614 |  |  [Bias Beyond English: Counterfactual Tests for Bias in Sentiment Analysis in Four Languages](https://doi.org/10.18653/v1/2023.findings-acl.272) |  | 0 |  | Seraphina GoldfarbTarrant, Adam Lopez, Roi Blanco, Diego Marcheggiani |  |
| 615 |  |  [Complementary Explanations for Effective In-Context Learning](https://doi.org/10.18653/v1/2023.findings-acl.273) |  | 0 |  | Xi Ye, Srinivasan Iyer, Asli Celikyilmaz, Veselin Stoyanov, Greg Durrett, Ramakanth Pasunuru |  |
| 616 |  |  [MISMATCH: Fine-grained Evaluation of Machine-generated Text with Mismatch Error Types](https://doi.org/10.18653/v1/2023.findings-acl.274) |  | 0 |  | Keerthiram Murugesan, Sarathkrishna Swaminathan, Soham Dan, Subhajit Chaudhury, R. Chulaka Gunasekara, Maxwell Crouse, Diwakar Mahajan, Ibrahim Abdelaziz, Achille Fokoue, Pavan Kapanipathi, Salim Roukos, Alexander Gray |  |
| 617 |  |  [RHO: Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding](https://doi.org/10.18653/v1/2023.findings-acl.275) |  | 0 |  | Ziwei Ji, Zihan Liu, Nayeon Lee, Tiezheng Yu, Bryan Wilie, Min Zeng, Pascale Fung |  |
| 618 |  |  [Transformer Language Models Handle Word Frequency in Prediction Head](https://doi.org/10.18653/v1/2023.findings-acl.276) |  | 0 |  | Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui |  |
| 619 |  |  [Prompted LLMs as Chatbot Modules for Long Open-domain Conversation](https://doi.org/10.18653/v1/2023.findings-acl.277) |  | 0 |  | Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, Kangwook Lee |  |
| 620 |  |  [Prompt to be Consistent is Better than Self-Consistent? Few-Shot and Zero-Shot Fact Verification with Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.278) |  | 0 |  | Fengzhu Zeng, Wei Gao |  |
| 621 |  |  [Model Analysis & Evaluation for Ambiguous Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.279) |  | 0 |  | Konstantinos Papakostas, Irene Papadopoulou |  |
| 622 |  |  [Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models](https://doi.org/10.18653/v1/2023.findings-acl.280) |  | 0 |  | Robert Morabito, Jad Kabbara, Ali Emami |  |
| 623 |  |  [Critic-Guided Decoding for Controlled Text Generation](https://doi.org/10.18653/v1/2023.findings-acl.281) |  | 0 |  | Minbeom Kim, Hwanhee Lee, Kang Min Yoo, Joonsuk Park, Hwaran Lee, Kyomin Jung |  |
| 624 |  |  [MedNgage: A Dataset for Understanding Engagement in Patient-Nurse Conversations](https://doi.org/10.18653/v1/2023.findings-acl.282) |  | 0 |  | Yan Wang, Heidi Ann Scharf Donovan, Sabit Hassan, Malihe Alikhani |  |
| 625 |  |  [SEAG: Structure-Aware Event Causality Generation](https://doi.org/10.18653/v1/2023.findings-acl.283) |  | 0 |  | Zhengwei Tao, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Chengfeng Dou, Yongqiang Zhao, Fang Wang, Chongyang Tao |  |
| 626 |  |  [Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning](https://doi.org/10.18653/v1/2023.findings-acl.284) |  | 0 |  | Ruixiang Tang, Dehan Kong, Longtao Huang, Hui Xue |  |
| 627 |  |  [A Two-Stage Decoder for Efficient ICD Coding](https://doi.org/10.18653/v1/2023.findings-acl.285) |  | 0 |  | ThanhTung Nguyen, Viktor Schlegel, Abhinav Ramesh Kashyap, Stefan Winkler |  |
| 628 |  |  [Asymmetric feature interaction for interpreting model predictions](https://doi.org/10.18653/v1/2023.findings-acl.286) |  | 0 |  | Xiaolei Lu, Jianghong Ma, Haode Zhang |  |
| 629 |  |  [Disagreement Matters: Preserving Label Diversity by Jointly Modeling Item and Annotator Label Distributions with DisCo](https://doi.org/10.18653/v1/2023.findings-acl.287) |  | 0 |  | Tharindu Cyril Weerasooriya, Alexander Ororbia, Raj Bhensadadia, Ashiqur R. KhudaBukhsh, Christopher Homan |  |
| 630 |  |  [Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.288) |  | 0 |  | Pranav Ajit Nair, Sukomal Pal, Pradeepika Verma |  |
| 631 |  |  [ClaimDiff: Comparing and Contrasting Claims on Contentious Issues](https://doi.org/10.18653/v1/2023.findings-acl.289) |  | 0 |  | Miyoung Ko, Ingyu Seong, Hwaran Lee, Joonsuk Park, Minsuk Chang, Minjoon Seo |  |
| 632 |  |  [Unsupervised Paraphrasing of Multiword Expressions](https://doi.org/10.18653/v1/2023.findings-acl.290) |  | 0 |  | Takashi Wada, Yuji Matsumoto, Timothy Baldwin, Jey Han Lau |  |
| 633 |  |  [G-Tuning: Improving Generalization of Pre-trained Language Models with Generative Adversarial Network](https://doi.org/10.18653/v1/2023.findings-acl.291) |  | 0 |  | Rongxiang Weng, Wensen Cheng, Min Zhang |  |
| 634 |  |  [Unified Language Representation for Question Answering over Text, Tables, and Images](https://doi.org/10.18653/v1/2023.findings-acl.292) |  | 0 |  | Bowen Yu, Cheng Fu, Haiyang Yu, Fei Huang, Yongbin Li |  |
| 635 |  |  [A Set Prediction Network For Extractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.293) |  | 0 |  | Xiaoxia Cheng, Yongliang Shen, Weiming Lu |  |
| 636 |  |  [Geo-Seq2seq: Twitter User Geolocation on Noisy Data through Sequence to Sequence Learning](https://doi.org/10.18653/v1/2023.findings-acl.294) |  | 0 |  | Jingyu Zhang, Alexandra DeLucia, Chenyu Zhang, Mark Dredze |  |
| 637 |  |  [Predicting Numerals in Text Using Nearest Neighbor Language Models](https://doi.org/10.18653/v1/2023.findings-acl.295) |  | 0 |  | Taku Sakamoto, Akiko Aizawa |  |
| 638 |  |  [HonestBait: Forward References for Attractive but Faithful Headline Generation](https://doi.org/10.18653/v1/2023.findings-acl.296) |  | 0 |  | ChihYao Chen, Dennis Wu, LunWei Ku |  |
| 639 |  |  [Few Shot Rationale Generation using Self-Training with Dual Teachers](https://doi.org/10.18653/v1/2023.findings-acl.297) |  | 0 |  | Aditya Srikanth Veerubhotla, Lahari Poddar, Jun Yin, György Szarvas, Sharanya Eswaran |  |
| 640 |  |  [Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints](https://doi.org/10.18653/v1/2023.findings-acl.298) |  | 0 |  | Yujin Baek, Koanho Lee, Dayeon Ki, Cheonbok Park, HyoungGyu Lee, Jaegul Choo |  |
| 641 |  |  [NoisywikiHow: A Benchmark for Learning with Real-world Noisy Labels in Natural Language Processing](https://doi.org/10.18653/v1/2023.findings-acl.299) |  | 0 |  | Tingting Wu, Xiao Ding, Minji Tang, Hao Zhang, Bing Qin, Ting Liu |  |
| 642 |  |  [Sampling Better Negatives for Distantly Supervised Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.300) |  | 0 |  | Lu Xu, Lidong Bing, Wei Lu |  |
| 643 |  |  [Prototype-Based Interpretability for Legal Citation Prediction](https://doi.org/10.18653/v1/2023.findings-acl.301) |  | 0 |  | Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu |  |
| 644 |  |  [LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models](https://doi.org/10.18653/v1/2023.findings-acl.302) |  | 0 |  | Philipp Wicke |  |
| 645 |  |  [Making Better Use of Training Corpus: Retrieval-based Aspect Sentiment Triplet Extraction via Label Interpolation](https://doi.org/10.18653/v1/2023.findings-acl.303) |  | 0 |  | Guoxin Yu, Lemao Liu, Haiyun Jiang, Shuming Shi, Xiang Ao |  |
| 646 |  |  [Multi-Domain Dialogue State Tracking with Disentangled Domain-Slot Attention](https://doi.org/10.18653/v1/2023.findings-acl.304) |  | 0 |  | Longfei Yang, Jiyi Li, Sheng Li, Takahiro Shinozaki |  |
| 647 |  |  [Improved Visual Story Generation with Adaptive Context Modeling](https://doi.org/10.18653/v1/2023.findings-acl.305) |  | 0 |  | Zhangyin Feng, Yuchen Ren, Xinmiao Yu, Xiaocheng Feng, Duyu Tang, Shuming Shi, Bing Qin |  |
| 648 |  |  [Question-Interlocutor Scope Realized Graph Modeling over Key Utterances for Dialogue Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-acl.306) |  | 0 |  | Jiangnan Li, Mo Yu, Fandong Meng, Zheng Lin, Peng Fu, Weiping Wang, Jie Zhou |  |
| 649 |  |  [Speech-to-Speech Translation for a Real-world Unwritten Language](https://doi.org/10.18653/v1/2023.findings-acl.307) |  | 0 |  | PengJen Chen, Kevin Tran, Yilin Yang, Jingfei Du, Justine Kao, YuAn Chung, Paden Tomasello, PaulAmbroise Duquenne, Holger Schwenk, Hongyu Gong, Hirofumi Inaguma, Sravya Popuri, Changhan Wang, Juan Pino, WeiNing Hsu, Ann Lee |  |
| 650 |  |  [Code Execution with Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.308) |  | 0 |  | Chenxiao Liu, Shuai Lu, Weizhu Chen, Daxin Jiang, Alexey Svyatkovskiy, Shengyu Fu, Neel Sundaresan, Nan Duan |  |
| 651 |  |  [BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.309) |  | 0 |  | Shibo Hao, Bowen Tan, Kaiwen Tang, Bin Ni, Xiyan Shao, Hengzhe Zhang, Eric P. Xing, Zhiting Hu |  |
| 652 |  |  [Sequential Path Signature Networks for Personalised Longitudinal Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.310) |  | 0 |  | Talia Tseriotou, Adam Tsakalidis, Peter Foster, Terence Lyons, Maria Liakata |  |
| 653 |  |  [A Multi-modal Debiasing Model with Dynamical Constraint for Robust Visual Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.311) |  | 0 |  | Yu Li, Bojie Hu, Fengshuo Zhang, Yahan Yu, Jian Liu, Yufeng Chen, Jinan Xu |  |
| 654 |  |  [Trigger-Argument based Explanation for Event Detection](https://doi.org/10.18653/v1/2023.findings-acl.312) |  | 0 |  | Yong Guan, Jiaoyan Chen, Freddy Lécué, Jeff Z. Pan, Juanzi Li, Ru Li |  |
| 655 |  |  [Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections](https://doi.org/10.18653/v1/2023.findings-acl.313) |  | 0 |  | Maria Leonor Pacheco, Tunazzina Islam, Lyle H. Ungar, Ming Yin, Dan Goldwasser |  |
| 656 |  |  [NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm Discovery](https://doi.org/10.18653/v1/2023.findings-acl.314) |  | 0 |  | Farhad Moghimifar, Shilin Qu, Tongtong Wu, YuanFang Li, Gholamreza Haffari |  |
| 657 |  |  [VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations](https://doi.org/10.18653/v1/2023.findings-acl.315) |  | 0 |  | HoangQuoc NguyenSon, Seira Hidano, Kazuhide Fukushima, Shinsaku Kiyomoto, Isao Echizen |  |
| 658 |  |  [Fusion or Defusion? Flexible Vision-and-Language Pre-Training](https://doi.org/10.18653/v1/2023.findings-acl.316) |  | 0 |  | Rongyi Sun, Ziran Li, Yifeng Ding, Qifan Wang, Jingang Wang, Haitao Zheng, Wei Wu, Yunsen Xian |  |
| 659 |  |  [COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP](https://doi.org/10.18653/v1/2023.findings-acl.317) |  | 0 |  | Fanny Jourdan, Agustin Martin Picard, Thomas Fel, Laurent Risser, JeanMichel Loubes, Nicholas Asher |  |
| 660 |  |  [Code-Switched Text Synthesis in Unseen Language Pairs](https://doi.org/10.18653/v1/2023.findings-acl.318) |  | 0 |  | IHung Hsu, Avik Ray, Shubham Garg, Nanyun Peng, Jing Huang |  |
| 661 |  |  [Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on Long Short-Term Dialogue Planning](https://doi.org/10.18653/v1/2023.findings-acl.319) |  | 0 |  | JustusJonas Erker, Stefan Schaffer, Gerasimos Spanakis |  |
| 662 |  |  [Data-Efficient French Language Modeling with CamemBERTa](https://doi.org/10.18653/v1/2023.findings-acl.320) |  | 0 |  | Wissam Antoun, Benoît Sagot, Djamé Seddah |  |
| 663 |  |  [Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text](https://doi.org/10.18653/v1/2023.findings-acl.321) |  | 0 |  | Zhun Yang, Adam Ishay, Joohyung Lee |  |
| 664 |  |  [Evaluating the Factual Consistency of Large Language Models Through News Summarization](https://doi.org/10.18653/v1/2023.findings-acl.322) |  | 0 |  | Derek Tam, Anisha Mascarenhas, Shiyue Zhang, Sarah Kwan, Mohit Bansal, Colin Raffel |  |
| 665 |  |  [Text Generation Model Enhanced with Semantic Information in Aspect Category Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.323) |  | 0 |  | Tu Tran, Kiyoaki Shirai, Natthawut Kertkeidkachorn |  |
| 666 |  |  [Mind the Biases: Quantifying Cognitive Biases in Language Model Prompting](https://doi.org/10.18653/v1/2023.findings-acl.324) |  | 0 |  | Ruixi Lin, Hwee Tou Ng |  |
| 667 |  |  [CodePrompt: Task-Agnostic Prefix Tuning for Program and Language Generation](https://doi.org/10.18653/v1/2023.findings-acl.325) |  | 0 |  | YunSeok Choi, JeeHyong Lee |  |
| 668 |  |  [Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale](https://doi.org/10.18653/v1/2023.findings-acl.326) |  | 0 |  | Vijeta Deshpande, Dan Pechi, Shree Thatte, Vladislav Lialin, Anna Rumshisky |  |
| 669 |  |  [Communication Efficient Federated Learning for Multilingual Neural Machine Translation with Adapter](https://doi.org/10.18653/v1/2023.findings-acl.327) |  | 0 |  | Yi Liu, Xiaohan Bi, Lei Li, Sishuo Chen, Wenkai Yang, Xu Sun |  |
| 670 |  |  [Cross-task Knowledge Transfer for Extremely Weakly Supervised Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.328) |  | 0 |  | Seongmin Park, Kyungho Kim, Jihwa Lee |  |
| 671 |  |  [GVdoc - Graph-based Visual DOcument Classification](https://doi.org/10.18653/v1/2023.findings-acl.329) |  | 0 |  | Fnu Mohbat, Mohammed J. Zaki, Catherine FineganDollak, Ashish Verma |  |
| 672 |  |  [A Sequence-to-Sequence&Set Model for Text-to-Table Generation](https://doi.org/10.18653/v1/2023.findings-acl.330) |  | 0 |  | Tong Li, Zhihao Wang, Liangying Shao, Xuling Zheng, Xiaoli Wang, Jinsong Su |  |
| 673 |  |  [Automatic Readability Assessment for Closely Related Languages](https://doi.org/10.18653/v1/2023.findings-acl.331) |  | 0 |  | Joseph Marvin Imperial, Ekaterina Kochmar |  |
| 674 |  |  [Towards Robust Ranker for Text Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.332) |  | 0 |  | Yucheng Zhou, Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Guodong Long, Binxing Jiao, Daxin Jiang |  |
| 675 |  |  [Semi-Supervised Domain Adaptation for Emotion-Related Tasks](https://doi.org/10.18653/v1/2023.findings-acl.333) |  | 0 |  | Mahshid Hosseini, Cornelia Caragea |  |
| 676 |  |  [Boosting Distress Support Dialogue Responses with Motivational Interviewing Strategy](https://doi.org/10.18653/v1/2023.findings-acl.334) |  | 0 |  | Anuradha Welivita, Pearl Pu |  |
| 677 |  |  [ECOLA: Enhancing Temporal Knowledge Embeddings with Contextualized Language Representations](https://doi.org/10.18653/v1/2023.findings-acl.335) |  | 0 |  | Zhen Han, Ruotong Liao, Jindong Gu, Yao Zhang, Zifeng Ding, Yujia Gu, Heinz Koeppl, Hinrich Schütze, Volker Tresp |  |
| 678 |  |  [Gender-tuning: Empowering Fine-tuning for Debiasing Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.336) |  | 0 |  | Somayeh Ghanbarzadeh, Yan Huang, Hamid Palangi, Radames Cruz Moreno, Hamed Khanpour |  |
| 679 |  |  [TextObfuscator: Making Pre-trained Language Model a Privacy Protector via Obfuscating Word Representations](https://doi.org/10.18653/v1/2023.findings-acl.337) |  | 0 |  | Xin Zhou, Yi Lu, Ruotian Ma, Tao Gui, Yuran Wang, Yong Ding, Yibo Zhang, Qi Zhang, Xuanjing Huang |  |
| 680 |  |  [Mini-Model Adaptation: Efficiently Extending Pretrained Models to New Languages via Aligned Shallow Training](https://doi.org/10.18653/v1/2023.findings-acl.338) |  | 0 |  | Kelly Marchisio, Patrick S. H. Lewis, Yihong Chen, Mikel Artetxe |  |
| 681 |  |  [DSP: Discriminative Soft Prompts for Zero-Shot Entity and Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.339) |  | 0 |  | Bo Lv, Xin Liu, Shaojie Dai, Nayu Liu, Fan Yang, Ping Luo, Yue Yu |  |
| 682 |  |  [Exploring Robust Overfitting for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.340) |  | 0 |  | Bin Zhu, Yanghui Rao |  |
| 683 |  |  [Improving Cross-task Generalization of Unified Table-to-text Models with Compositional Task Configurations](https://doi.org/10.18653/v1/2023.findings-acl.341) |  | 0 |  | Jifan Chen, Yuhao Zhang, Lan Liu, Rui Dong, Xinchi Chen, Patrick Ng, William Yang Wang, Zhiheng Huang |  |
| 684 |  |  [D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias](https://doi.org/10.18653/v1/2023.findings-acl.342) |  | 0 |  | Sabit Hassan, Malihe Alikhani |  |
| 685 |  |  [Language Anisotropic Cross-Lingual Model Editing](https://doi.org/10.18653/v1/2023.findings-acl.343) |  | 0 |  | Yang Xu, Yutai Hou, Wanxiang Che, Min Zhang |  |
| 686 |  |  [Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking](https://doi.org/10.18653/v1/2023.findings-acl.344) |  | 0 |  | Brendan King, Jeffrey Flanigan |  |
| 687 |  |  [Pre-Trained Language-Meaning Models for Multilingual Parsing and Generation](https://doi.org/10.18653/v1/2023.findings-acl.345) |  | 0 |  | Chunliu Wang, Huiyuan Lai, Malvina Nissim, Johan Bos |  |
| 688 |  |  [Multi-modal Sarcasm Generation: Dataset and Solution](https://doi.org/10.18653/v1/2023.findings-acl.346) |  | 0 |  | Wenye Zhao, Qingbao Huang, Dongsheng Xu, Peizhi Zhao |  |
| 689 |  |  [Rethinking Semi-supervised Learning with Language Models](https://doi.org/10.18653/v1/2023.findings-acl.347) |  | 0 |  | Zhengxiang Shi, Francesco Tonolini, Nikolaos Aletras, Emine Yilmaz, Gabriella Kazai, Yunlong Jiao |  |
| 690 |  |  [Retrieval-Based Transformer for Table Augmentation](https://doi.org/10.18653/v1/2023.findings-acl.348) |  | 0 |  | Michael R. Glass, Xueqing Wu, Ankita Rajaram Naik, Gaetano Rossiello, Alfio Gliozzo |  |
| 691 |  |  [ECG-QALM: Entity-Controlled Synthetic Text Generation using Contextual Q&A for NER](https://doi.org/10.18653/v1/2023.findings-acl.349) |  | 0 |  | Karan Aggarwal, Henry Jin, Aitzaz Ahmad |  |
| 692 |  |  [Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages](https://doi.org/10.18653/v1/2023.findings-acl.350) |  | 0 |  | Tomasz Limisiewicz, Jirí Balhar, David Marecek |  |
| 693 |  |  [The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding](https://doi.org/10.18653/v1/2023.findings-acl.351) |  | 0 |  | Hao Fang, Anusha Balakrishnan, Harsh Jhamtani, John Bufe, Jean Crawford, Jayant Krishnamurthy, Adam Pauls, Jason Eisner, Jacob Andreas, Dan Klein |  |
| 694 |  |  [Know What I don't Know: Handling Ambiguous and Unknown Questions for Text-to-SQL](https://doi.org/10.18653/v1/2023.findings-acl.352) |  | 0 |  | Bing Wang, Yan Gao, Zhoujun Li, JianGuang Lou |  |
| 695 |  |  [Rethinking Document-Level Relation Extraction: A Reality Check](https://doi.org/10.18653/v1/2023.findings-acl.353) |  | 0 |  | Jing Li, Yequan Wang, Shuai Zhang, Min Zhang |  |
| 696 |  |  [Optimizing Test-Time Query Representations for Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.354) |  | 0 |  | Mujeen Sung, Jungsoo Park, Jaewoo Kang, Danqi Chen, Jinhyuk Lee |  |
| 697 |  |  [A Customized Text Sanitization Mechanism with Differential Privacy](https://doi.org/10.18653/v1/2023.findings-acl.355) |  | 0 |  | Sai Chen, Fengran Mo, Yanhao Wang, Cen Chen, JianYun Nie, Chengyu Wang, Jamie Cui |  |
| 698 |  |  [LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization](https://doi.org/10.18653/v1/2023.findings-acl.356) |  | 0 |  | Peng Lu, Ahmad Rashid, Ivan Kobyzev, Mehdi Rezagholizadeh, Philippe Langlais |  |
| 699 |  |  [Frustratingly Easy Label Projection for Cross-lingual Transfer](https://doi.org/10.18653/v1/2023.findings-acl.357) |  | 0 |  | Yang Chen, Chao Jiang, Alan Ritter, Wei Xu |  |
| 700 |  |  [Enhancing Hierarchical Text Classification through Knowledge Graph Integration](https://doi.org/10.18653/v1/2023.findings-acl.358) |  | 0 |  | Ye Liu, Kai Zhang, Zhenya Huang, Kehang Wang, Yanghai Zhang, Qi Liu, Enhong Chen |  |
| 701 |  |  [How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-acl.359) |  | 0 |  | Chen Zhang, Jiuheng Lin, Xiao Liu, Yuxuan Lai, Yansong Feng, Dongyan Zhao |  |
| 702 |  |  [An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text](https://doi.org/10.18653/v1/2023.findings-acl.360) |  | 0 |  | Yova Kementchedjhieva, Ilias Chalkidis |  |
| 703 |  |  [Domain Incremental Lifelong Learning in an Open World](https://doi.org/10.18653/v1/2023.findings-acl.361) |  | 0 |  | Yi Dai, Hao Lang, Yinhe Zheng, Bowen Yu, Fei Huang, Yongbin Li |  |
| 704 |  |  [Improving Knowledge Graph Completion with Generative Hard Negative Mining](https://doi.org/10.18653/v1/2023.findings-acl.362) |  | 0 |  | Zile Qiao, Wei Ye, Dingyao Yu, Tong Mo, Weiping Li, Shikun Zhang |  |
| 705 |  |  [Visually-Enhanced Phrase Understanding](https://doi.org/10.18653/v1/2023.findings-acl.363) |  | 0 |  | TsuYuan Hsu, ChenAn Li, ChaoWei Huang, YunNung Chen |  |
| 706 |  |  [Reasoning in Large Language Models Through Symbolic Math Word Problems](https://doi.org/10.18653/v1/2023.findings-acl.364) |  | 0 |  | Vedant Gaur, Nikunj Saunshi |  |
| 707 |  |  [It's not Sexually Suggestive; It's Educative \| Separating Sex Education from Suggestive Content on TikTok videos](https://doi.org/10.18653/v1/2023.findings-acl.365) |  | 0 |  | Enfa George, Mihai Surdeanu |  |
| 708 |  |  [Dynamic Structured Neural Topic Model with Self-Attention Mechanism](https://doi.org/10.18653/v1/2023.findings-acl.366) |  | 0 |  | Nozomu Miyamoto, Masaru Isonuma, Sho Takase, Junichiro Mori, Ichiro Sakata |  |
| 709 |  |  [Hybrid-Regressive Paradigm for Accurate and Speed-Robust Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.367) |  | 0 |  | Qiang Wang, Xinhui Hu, Ming Chen |  |
| 710 |  |  [Commonsense Knowledge Transfer for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.368) |  | 0 |  | Wangchunshu Zhou, Ronan Le Bras, Yejin Choi |  |
| 711 |  |  [Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection](https://doi.org/10.18653/v1/2023.findings-acl.369) |  | 0 |  | Shadi Iskander, Kira Radinsky, Yonatan Belinkov |  |
| 712 |  |  [Focal Training and Tagger Decouple for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.findings-acl.370) |  | 0 |  | Minghuan Tan, Min Yang, Ruifeng Xu |  |
| 713 |  |  [LET: Leveraging Error Type Information for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.findings-acl.371) |  | 0 |  | Lingyu Yang, Hongjia Li, Lei Li, Chengyin Xu, Shutao Xia, Chun Yuan |  |
| 714 |  |  [On the Role of Parallel Data in Cross-lingual Transfer Learning](https://doi.org/10.18653/v1/2023.findings-acl.372) |  | 0 |  | Machel Reid, Mikel Artetxe |  |
| 715 |  |  [CoMave: Contrastive Pre-training with Multi-scale Masking for Attribute Value Extraction](https://doi.org/10.18653/v1/2023.findings-acl.373) |  | 0 |  | Xinnan Guo, Wentao Deng, Yongrui Chen, Yang Li, Mengdi Zhou, Guilin Qi, Tianxing Wu, Dong Yang, Liubin Wang, Yong Pan |  |
| 716 |  |  [Phrase Retrieval for Open Domain Conversational Question Answering with Conversational Dependency Modeling via Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-acl.374) |  | 0 |  | Soyeong Jeong, Jinheon Baek, Sung Ju Hwang, Jong Park |  |
| 717 |  |  [Unlearning Bias in Language Models by Partitioning Gradients](https://doi.org/10.18653/v1/2023.findings-acl.375) |  | 0 |  | Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, Heng Ji |  |
| 718 |  |  [Meta-training with Demonstration Retrieval for Efficient Few-shot Learning](https://doi.org/10.18653/v1/2023.findings-acl.376) |  | 0 |  | Aaron Mueller, Kanika Narang, Lambert Mathias, Qifan Wang, Hamed Firooz |  |
| 719 |  |  [VCSUM: A Versatile Chinese Meeting Summarization Dataset](https://doi.org/10.18653/v1/2023.findings-acl.377) |  | 0 |  | Han Wu, Mingjie Zhan, Haochen Tan, Zhaohui Hou, Ding Liang, Linqi Song |  |
| 720 |  |  [LEDA: a Large-Organization Email-Based Decision-Dialogue-Act Analysis Dataset](https://doi.org/10.18653/v1/2023.findings-acl.378) |  | 0 |  | Mladen Karan, Prashant Khare, Ravi Shekhar, Stephen McQuistin, Ignacio Castro, Gareth Tyson, Colin Perkins, Patrick Healey, Matthew Purver |  |
| 721 |  |  [Negation Scope Refinement via Boundary Shift Loss](https://doi.org/10.18653/v1/2023.findings-acl.379) |  | 0 |  | Yin Wu, Aixin Sun |  |
| 722 |  |  [Towards Diverse and Effective Question-Answer Pair Generation from Children Storybooks](https://doi.org/10.18653/v1/2023.findings-acl.380) |  | 0 |  | Sugyeong Eo, Hyeonseok Moon, Jinsung Kim, Yuna Hur, Jeongwook Kim, Songeun Lee, Changwoo Chun, Sungsoo Park, Heuiseok Lim |  |
| 723 |  |  [Pulling Out All The Full Stops: Punctuation Sensitivity in Neural Machine Translation and Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.381) |  | 0 |  | Prathyusha Jwalapuram |  |
| 724 |  |  [Reimagining Retrieval Augmented Language Models for Answering Queries](https://doi.org/10.18653/v1/2023.findings-acl.382) |  | 0 |  | WangChiew Tan, Yuliang Li, Pedro Rodriguez, Richard James, Xi Victoria Lin, Alon Y. Halevy, Wentau Yih |  |
| 725 |  |  [Numeric Magnitude Comparison Effects in Large Language Models](https://doi.org/10.18653/v1/2023.findings-acl.383) |  | 0 |  | Raj Sanjay Shah, Vijay Marupudi, Reba Koenen, Khushi Bhardwaj, Sashank Varma |  |
| 726 |  |  [Multi-Relational Probabilistic Event Representation Learning via Projected Gaussian Embedding](https://doi.org/10.18653/v1/2023.findings-acl.384) |  | 0 |  | Linhai Zhang, Congzhi Zhang, Deyu Zhou |  |
| 727 |  |  [PragmatiCQA: A Dataset for Pragmatic Question Answering in Conversations](https://doi.org/10.18653/v1/2023.findings-acl.385) |  | 0 |  | Peng Qi, Nina Du, Christopher D. Manning, Jing Huang |  |
| 728 |  |  [Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks](https://doi.org/10.18653/v1/2023.findings-acl.386) |  | 0 |  | Lukas Hauzenberger, Shahed Masoudian, Deepak Kumar, Markus Schedl, Navid Rekabsaz |  |
| 729 |  |  [Scientific Fact-Checking: A Survey of Resources and Approaches](https://doi.org/10.18653/v1/2023.findings-acl.387) |  | 0 |  | Juraj Vladika, Florian Matthes |  |
| 730 |  |  [Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems](https://doi.org/10.18653/v1/2023.findings-acl.388) |  | 0 |  | Chiyu Song, Hongliang He, Haofei Yu, Pengfei Fang, Leyang Cui, Zhenzhong Lan |  |
| 731 |  |  [DLAMA: A Framework for Curating Culturally Diverse Facts for Probing the Knowledge of Pretrained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.389) |  | 0 |  | Amr Keleg, Walid Magdy |  |
| 732 |  |  [Self-adaptive Context and Modal-interaction Modeling For Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-acl.390) |  | 0 |  | Haozhe Yang, Xianqiang Gao, Jianlong Wu, Tian Gan, Ning Ding, Feijun Jiang, Liqiang Nie |  |
| 733 |  |  [Structure-Discourse Hierarchical Graph for Conditional Question Answering on Long Documents](https://doi.org/10.18653/v1/2023.findings-acl.391) |  | 0 |  | Haowei Du, Yansong Feng, Chen Li, Yang Li, Yunshi Lan, Dongyan Zhao |  |
| 734 |  |  [COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements](https://doi.org/10.18653/v1/2023.findings-acl.392) |  | 0 |  | Xuhui Zhou, Hao Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap |  |
| 735 |  |  [Distilling Calibrated Knowledge for Stance Detection](https://doi.org/10.18653/v1/2023.findings-acl.393) |  | 0 |  | Yingjie Li, Cornelia Caragea |  |
| 736 |  |  [PTCSpell: Pre-trained Corrector Based on Character Shape and Pinyin for Chinese Spelling Correction](https://doi.org/10.18653/v1/2023.findings-acl.394) |  | 0 |  | Xiao Wei, Jianbao Huang, Hang Yu, Qian Liu |  |
| 737 |  |  [Disentangling Text Representation With Counter-Template For Unsupervised Opinion Summarization](https://doi.org/10.18653/v1/2023.findings-acl.395) |  | 0 |  | Yanyue Zhang, Deyu Zhou |  |
| 738 |  |  [Evaluation of Question Generation Needs More References](https://doi.org/10.18653/v1/2023.findings-acl.396) |  | 0 |  | Shinhyeok Oh, Hyojun Go, Hyeongdon Moon, Yunsung Lee, Myeongho Jeong, Hyun Seung Lee, Seungtaek Choi |  |
| 739 |  |  [XtremeCLIP: Extremely Parameter-efficient Tuning for Low-resource Vision Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.397) |  | 0 |  | Moming Tang, Chengyu Wang, Jianing Wang, Chuanqi Tan, Songfang Huang, Cen Chen, Weining Qian |  |
| 740 |  |  [FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing](https://doi.org/10.18653/v1/2023.findings-acl.398) |  | 0 |  | Zhuang Li, Yuyang Chai, Terry Yue Zhuo, Lizhen Qu, Gholamreza Haffari, Fei Li, Donghong Ji, Quan Hung Tran |  |
| 741 |  |  [Target-Oriented Relation Alignment for Cross-Lingual Stance Detection](https://doi.org/10.18653/v1/2023.findings-acl.399) |  | 0 |  | Ruike Zhang, Nan Xu, Hanxuan Yang, Yuan Tian, Wenji Mao |  |
| 742 |  |  [NonFactS: NonFactual Summary Generation for Factuality Evaluation in Document Summarization](https://doi.org/10.18653/v1/2023.findings-acl.400) |  | 0 |  | Amir Soleimani, Christof Monz, Marcel Worring |  |
| 743 |  |  [When to Read Documents or QA History: On Unified and Selective Open-domain QA](https://doi.org/10.18653/v1/2023.findings-acl.401) |  | 0 |  | Kyungjae Lee, Sangeun Han, Seungwon Hwang, Moontae Lee |  |
| 744 |  |  [Interpretable Automatic Fine-grained Inconsistency Detection in Text Summarization](https://doi.org/10.18653/v1/2023.findings-acl.402) |  | 0 |  | Hou Pong Chan, Qi Zeng, Heng Ji |  |
| 745 |  |  [A Multi-dimensional study on Bias in Vision-Language models](https://doi.org/10.18653/v1/2023.findings-acl.403) |  | 0 |  | Gabriele Ruggeri, Debora Nozza |  |
| 746 |  |  [Correction of Errors in Preference Ratings from Automated Metrics for Text Generation](https://doi.org/10.18653/v1/2023.findings-acl.404) |  | 0 |  | Jan Deriu, Pius von Däniken, Don Tuggener, Mark Cieliebak |  |
| 747 |  |  [PEER: Pre-training ELECTRA Extended by Ranking](https://doi.org/10.18653/v1/2023.findings-acl.405) |  | 0 |  | Ru He, Wei Wang, Songfang Huang, Fei Huang |  |
| 748 |  |  [ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for Improving ASR Robustness in Spoken Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.406) |  | 0 |  | Xuxin Cheng, Bowen Cao, Qichen Ye, Zhihong Zhu, Hongxiang Li, Yuexian Zou |  |
| 749 |  |  [Guiding Dialogue Agents to Complex Semantic Targets by Dynamically Completing Knowledge Graph](https://doi.org/10.18653/v1/2023.findings-acl.407) |  | 0 |  | Yue Tan, Bo Wang, Anqi Liu, Dongming Zhao, Kun Huang, Ruifang He, Yuexian Hou |  |
| 750 |  |  [Chain of Thought Prompting Elicits Knowledge Augmentation](https://doi.org/10.18653/v1/2023.findings-acl.408) |  | 0 |  | Dingjun Wu, Jing Zhang, Xinmei Huang |  |
| 751 |  |  [TACR: A Table Alignment-based Cell Selection Method for HybridQA](https://doi.org/10.18653/v1/2023.findings-acl.409) |  | 0 |  | Jian Wu, Yicheng Xu, Yan Gao, JianGuang Lou, Börje Karlsson, Manabu Okumura |  |
| 752 |  |  [Modeling Cross-Cultural Pragmatic Inference with Codenames Duet](https://doi.org/10.18653/v1/2023.findings-acl.410) |  | 0 |  | Omar Shaikh, Caleb Ziems, William Held, Aryan J. Pariani, Fred Morstatter, Diyi Yang |  |
| 753 |  |  [Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games](https://doi.org/10.18653/v1/2023.findings-acl.411) |  | 0 |  | Bolin Lai, Hongxin Zhang, Miao Liu, Aryan J. Pariani, Fiona Ryan, Wenqi Jia, Shirley Anugrah Hayati, James M. Rehg, Diyi Yang |  |
| 754 |  |  [Long to reign over us: A Case Study of Machine Translation and a New Monarch](https://doi.org/10.18653/v1/2023.findings-acl.412) |  | 0 |  | Rebecca Knowles, Samuel Larkin |  |
| 755 |  |  [A Unified Generative Approach to Product Attribute-Value Identification](https://doi.org/10.18653/v1/2023.findings-acl.413) |  | 0 |  | Keiji Shinzato, Naoki Yoshinaga, Yandi Xia, WeiTe Chen |  |
| 756 |  |  [K-UniMorph: Korean Universal Morphology and its Feature Schema](https://doi.org/10.18653/v1/2023.findings-acl.414) |  | 0 |  | Eunkyul Leah Jo, Kyuwon Kim, Xihan Wu, Kyungtae Lim, Jungyeul Park, Chulwoo Park |  |
| 757 |  |  [How does the brain process syntactic structure while listening?](https://doi.org/10.18653/v1/2023.findings-acl.415) |  | 0 |  | Subba Reddy Oota, Mounika Marreddy, Manish Gupta, Raju S. Bapi |  |
| 758 |  |  [Towards Imperceptible Document Manipulations against Neural Ranking Models](https://doi.org/10.18653/v1/2023.findings-acl.416) |  | 0 |  | Xuanang Chen, Ben He, Zheng Ye, Le Sun, Yingfei Sun |  |
| 759 |  |  [Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models](https://doi.org/10.18653/v1/2023.findings-acl.417) |  | 0 |  | Qiang Zhang, Jason Naradowsky, Yusuke Miyao |  |
| 760 |  |  [SciReviewGen: A Large-scale Dataset for Automatic Literature Review Generation](https://doi.org/10.18653/v1/2023.findings-acl.418) |  | 0 |  | Tetsu Kasanishi, Masaru Isonuma, Junichiro Mori, Ichiro Sakata |  |
| 761 |  |  [Revisiting Sample Size Determination in Natural Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.419) |  | 0 |  | Ernie Chang, Muhammad Hassan Rashid, PinJie Lin, Changsheng Zhao, Vera Demberg, Yangyang Shi, Vikas Chandra |  |
| 762 |  |  [TransESC: Smoothing Emotional Support Conversation via Turn-Level State Transition](https://doi.org/10.18653/v1/2023.findings-acl.420) |  | 0 |  | Weixiang Zhao, Yanyan Zhao, Shilong Wang, Bing Qin |  |
| 763 |  |  [Residual Prompt Tuning: improving prompt tuning with residual reparameterization](https://doi.org/10.18653/v1/2023.findings-acl.421) |  | 0 |  | Anastasia Razdaibiedina, Yuning Mao, Madian Khabsa, Mike Lewis, Rui Hou, Jimmy Ba, Amjad Almahairi |  |
| 764 |  |  [Attend, Select and Eliminate: Accelerating Multi-turn Response Selection with Dual-attention-based Content Elimination](https://doi.org/10.18653/v1/2023.findings-acl.422) |  | 0 |  | Jianxin Liang, Chang Liu, Chongyang Tao, Jiazhan Feng, Dongyan Zhao |  |
| 765 |  |  [Medical Dialogue Generation via Dual Flow Modeling](https://doi.org/10.18653/v1/2023.findings-acl.423) |  | 0 |  | Kaishuai Xu, Wenjun Hou, Yi Cheng, Jian Wang, Wenjie Li |  |
| 766 |  |  [Listen, Decipher and Sign: Toward Unsupervised Speech-to-Sign Language Recognition](https://doi.org/10.18653/v1/2023.findings-acl.424) |  | 0 |  | Liming Wang, Junrui Ni, Heting Gao, Jialu Li, Kai Chieh Chang, Xulin Fan, Junkai Wu, Mark HasegawaJohnson, Chang Dong Yoo |  |
| 767 |  |  [Distinguishing Address vs. Reference Mentions of Personal Names in Text](https://doi.org/10.18653/v1/2023.findings-acl.425) |  | 0 |  | Vinodkumar Prabhakaran, Aida Mostafazadeh Davani, Melissa Ferguson, Stav Atir |  |
| 768 |  |  ["Low-Resource" Text Classification: A Parameter-Free Classification Method with Compressors](https://doi.org/10.18653/v1/2023.findings-acl.426) |  | 0 |  | Zhiying Jiang, Matthew Y. R. Yang, Mikhail Tsirlin, Raphael Tang, Yiqin Dai, Jimmy Lin |  |
| 769 |  |  [LR-Sum: Summarization for Less-Resourced Languages](https://doi.org/10.18653/v1/2023.findings-acl.427) |  | 0 |  | Chester PalenMichel, Constantine Lignos |  |
| 770 |  |  [RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question](https://doi.org/10.18653/v1/2023.findings-acl.428) |  | 0 |  | Alireza Mohammadshahi, Thomas Scialom, Majid Yazdani, Pouya Yanki, Angela Fan, James Henderson, Marzieh Saeidi |  |
| 771 |  |  [Unsupervised Semantic Variation Prediction using the Distribution of Sibling Embeddings](https://doi.org/10.18653/v1/2023.findings-acl.429) |  | 0 |  | Taichi Aida, Danushka Bollegala |  |
| 772 |  |  [TranSFormer: Slow-Fast Transformer for Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.430) |  | 0 |  | Bei Li, Yi Jing, Xu Tan, Zhen Xing, Tong Xiao, Jingbo Zhu |  |
| 773 |  |  [Mitigating the Learning Bias towards Repetition by Self-Contrastive Training for Open-Ended Generation](https://doi.org/10.18653/v1/2023.findings-acl.431) |  | 0 |  | Jian Guan, Minlie Huang |  |
| 774 |  |  [Digging out Discrimination Information from Generated Samples for Robust Visual Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.432) |  | 0 |  | Zhiquan Wen, Yaowei Wang, Mingkui Tan, Qingyao Wu, Qi Wu |  |
| 775 |  |  [Words as Gatekeepers: Measuring Discipline-specific Terms and Meanings in Scholarly Publications](https://doi.org/10.18653/v1/2023.findings-acl.433) |  | 0 |  | Li Lucy, Jesse Dodge, David Bamman, Katherine A. Keith |  |
| 776 |  |  [Trade-Offs Between Fairness and Privacy in Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.434) |  | 0 |  | Cleo Matzken, Steffen Eger, Ivan Habernal |  |
| 777 |  |  [CSS: A Large-scale Cross-schema Chinese Text-to-SQL Medical Dataset](https://doi.org/10.18653/v1/2023.findings-acl.435) |  | 0 |  | Hanchong Zhang, Jieyu Li, Lu Chen, Ruisheng Cao, Yunyan Zhang, Yu Huang, Yefeng Zheng, Kai Yu |  |
| 778 |  |  [Silver Syntax Pre-training for Cross-Domain Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.436) |  | 0 |  | Elisa Bassignana, Filip Ginter, Sampo Pyysalo, Rob van der Goot, Barbara Plank |  |
| 779 |  |  [FastDiff 2: Revisiting and Incorporating GANs and Diffusion Models in High-Fidelity Speech Synthesis](https://doi.org/10.18653/v1/2023.findings-acl.437) |  | 0 |  | Rongjie Huang, Yi Ren, Ziyue Jiang, Chenye Cui, Jinglin Liu, Zhou Zhao |  |
| 780 |  |  [Uncovering Hidden Consequences of Pre-training Objectives in Sequence-to-Sequence Models](https://doi.org/10.18653/v1/2023.findings-acl.438) |  | 0 |  | Tannon Kew, Rico Sennrich |  |
| 781 |  |  [Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity](https://doi.org/10.18653/v1/2023.findings-acl.439) |  | 0 |  | Katharina Hämmerl, Alina Fastowski, Jindrich Libovický, Alexander Fraser |  |
| 782 |  |  [Revisiting Sentence Union Generation as a Testbed for Text Consolidation](https://doi.org/10.18653/v1/2023.findings-acl.440) |  | 0 |  | Eran Hirsch, Valentina Pyatkin, Ruben Wolhandler, Avi Caciularu, Asi Shefer, Ido Dagan |  |
| 783 |  |  [Distilling Reasoning Capabilities into Smaller Language Models](https://doi.org/10.18653/v1/2023.findings-acl.441) |  | 0 |  | Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan |  |
| 784 |  |  [AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment](https://doi.org/10.18653/v1/2023.findings-acl.442) |  | 0 |  | Ruiqi Li, Rongjie Huang, Lichao Zhang, Jinglin Liu, Zhou Zhao |  |
| 785 |  |  [A New Task and Dataset on Detecting Attacks on Human Rights Defenders](https://doi.org/10.18653/v1/2023.findings-acl.443) |  | 0 |  | Shihao Ran, Di Lu, Aoife Cahill, Joel R. Tetreault, Alejandro Jaimes |  |
| 786 |  |  [Improving Language Model Integration for Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.444) |  | 0 |  | Christian Herold, Yingbo Gao, Mohammad Zeineldeen, Hermann Ney |  |
| 787 |  |  [Type Enhanced BERT for Correcting NER Errors](https://doi.org/10.18653/v1/2023.findings-acl.445) |  | 0 |  | Kuai Li, Chen Chen, Tao Yang, Tianming Du, Peijie Yu, Dong Du, Feng Zhang |  |
| 788 |  |  [Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework](https://doi.org/10.18653/v1/2023.findings-acl.446) |  | 0 |  | Lifan Yuan, Yichi Zhang, Yangyi Chen, Wei Wei |  |
| 789 |  |  [DUB: Discrete Unit Back-translation for Speech Translation](https://doi.org/10.18653/v1/2023.findings-acl.447) |  | 0 |  | Dong Zhang, Rong Ye, Tom Ko, Mingxuan Wang, Yaqian Zhou |  |
| 790 |  |  [Knowledge Graph Embeddings using Neural Ito Process: From Multiple Walks to Stochastic Trajectories](https://doi.org/10.18653/v1/2023.findings-acl.448) |  | 0 |  | Mojtaba Nayyeri, Bo Xiong, Majid Mohammadi, Mst. Mahfuja Akter, Mirza Mohtashim Alam, Jens Lehmann, Steffen Staab |  |
| 791 |  |  [Leveraging Denoised Abstract Meaning Representation for Grammatical Error Correction](https://doi.org/10.18653/v1/2023.findings-acl.449) |  | 0 |  | Hejing Cao, Dongyan Zhao |  |
| 792 |  |  [Prediction and Calibration: Complex Reasoning over Knowledge Graph with Bi-directional Directed Acyclic Graph Neural Network](https://doi.org/10.18653/v1/2023.findings-acl.450) |  | 0 |  | Yao Xu, Shizhu He, Li Cai, Kang Liu, Jun Zhao |  |
| 793 |  |  [Prompt-Based Metric Learning for Few-Shot NER](https://doi.org/10.18653/v1/2023.findings-acl.451) |  | 0 |  | Yanru Chen, Yanan Zheng, Zhilin Yang |  |
| 794 |  |  [OpenPI-C: A Better Benchmark and Stronger Baseline for Open-Vocabulary State Tracking](https://doi.org/10.18653/v1/2023.findings-acl.452) |  | 0 |  | Xueqing Wu, Sha Li, Heng Ji |  |
| 795 |  |  [I run as fast as a rabbit, can you? A Multilingual Simile Dialogues Datasets](https://doi.org/10.18653/v1/2023.findings-acl.453) |  | 0 |  | Longxuan Ma, Weinan Zhang, Shuhan Zhou, Churui Sun, Changxin Ke, Ting Liu |  |
| 796 |  |  [Controllable Conversation Generation with Conversation Structures via Diffusion Models](https://doi.org/10.18653/v1/2023.findings-acl.454) |  | 0 |  | Jiaao Chen, Diyi Yang |  |
| 797 |  |  [Few-shot Low-resource Knowledge Graph Completion with Reinforced Task Generation](https://doi.org/10.18653/v1/2023.findings-acl.455) |  | 0 |  | Shichao Pei, Qiannan Zhang, Xiangliang Zhang |  |
| 798 |  |  [Incomplete Utterance Rewriting as Sequential Greedy Tagging](https://doi.org/10.18653/v1/2023.findings-acl.456) |  | 0 |  | Yunshan Chen |  |
| 799 |  |  [Exploiting Commonsense Knowledge about Objects for Visual Activity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.457) |  | 0 |  | Tianyu Jiang, Ellen Riloff |  |
| 800 |  |  [Tucker Decomposition with Frequency Attention for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.findings-acl.458) |  | 0 |  | Likang Xiao, Richong Zhang, Zijie Chen, Junfan Chen |  |
| 801 |  |  [Another Dead End for Morphological Tags? Perturbed Inputs and Parsing](https://doi.org/10.18653/v1/2023.findings-acl.459) |  | 0 |  | Alberto MuñozOrtiz, David Vilares |  |
| 802 |  |  [HeGeL: A Novel Dataset for Geo-Location from Hebrew Text](https://doi.org/10.18653/v1/2023.findings-acl.460) |  | 0 |  | Tzuf PazArgaman, Tal Bauman, Itai Mondshine, Itzhak Omer, Sagi Dalyot, Reut Tsarfaty |  |
| 803 |  |  [Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making](https://doi.org/10.18653/v1/2023.findings-acl.461) |  | 0 |  | Xuanjie Fang, Sijie Cheng, Yang Liu, Wei Wang |  |
| 804 |  |  [Towards Robust Personalized Dialogue Generation via Order-Insensitive Representation Regularization](https://doi.org/10.18653/v1/2023.findings-acl.462) |  | 0 |  | Liang Chen, Hongru Wang, Yang Deng, WaiChung Kwan, Zezhong Wang, KamFai Wong |  |
| 805 |  |  [Cost-effective Distillation of Large Language Models](https://doi.org/10.18653/v1/2023.findings-acl.463) |  | 0 |  | Sayantan Dasgupta, Trevor Cohn, Timothy Baldwin |  |
| 806 |  |  [Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System](https://doi.org/10.18653/v1/2023.findings-acl.464) |  | 0 |  | Namo Bang, Jeehyun Lee, MyoungWan Koo |  |
| 807 |  |  [I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors](https://doi.org/10.18653/v1/2023.findings-acl.465) |  | 0 |  | Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou, Yue Yang, Marianna Apidianaki, Smaranda Muresan |  |
| 808 |  |  [Text Augmentation Using Dataset Reconstruction for Low-Resource Classification](https://doi.org/10.18653/v1/2023.findings-acl.466) |  | 0 |  | Adir Rahamim, Guy Uziel, Esther Goldbraich, Ateret AnabyTavor |  |
| 809 |  |  [LaSQuE: Improved Zero-Shot Classification from Explanations Through Quantifier Modeling and Curriculum Learning](https://doi.org/10.18653/v1/2023.findings-acl.467) |  | 0 |  | Sayan Ghosh, Rakesh R. Menon, Shashank Srivastava |  |
| 810 |  |  [Learned Adapters Are Better Than Manually Designed Adapters](https://doi.org/10.18653/v1/2023.findings-acl.468) |  | 0 |  | Yuming Zhang, Peng Wang, Ming Tan, Wei Zhu |  |
| 811 |  |  [Automatic Identification of Code-Switching Functions in Speech Transcripts](https://doi.org/10.18653/v1/2023.findings-acl.469) |  | 0 |  | Ritu Belani, Jeffrey Flanigan |  |
| 812 |  |  [Federated Domain Adaptation for Named Entity Recognition via Distilling with Heterogeneous Tag Sets](https://doi.org/10.18653/v1/2023.findings-acl.470) |  | 0 |  | Rui Wang, Tong Yu, Junda Wu, Handong Zhao, Sungchul Kim, Ruiyi Zhang, Subrata Mitra, Ricardo Henao |  |
| 813 |  |  [Interpreting Sentiment Composition with Latent Semantic Tree](https://doi.org/10.18653/v1/2023.findings-acl.471) |  | 0 |  | Zhongtao Jiang, Yuanzhe Zhang, Cao Liu, Jiansong Chen, Jun Zhao, Kang Liu |  |
| 814 |  |  [Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models](https://doi.org/10.18653/v1/2023.findings-acl.472) |  | 0 |  | Yuhui Zhang, Michihiro Yasunaga, Zhengping Zhou, Jeff Z. HaoChen, James Zou, Percy Liang, Serena Yeung |  |
| 815 |  |  [Contrastive Training Improves Zero-Shot Classification of Semi-structured Documents](https://doi.org/10.18653/v1/2023.findings-acl.473) |  | 0 |  | Muhammad Khalifa, Yogarshi Vyas, Shuai Wang, Graham Horwood, Sunil Mallya, Miguel Ballesteros |  |
| 816 |  |  [Extracting Shopping Interest-Related Product Types from the Web](https://doi.org/10.18653/v1/2023.findings-acl.474) |  | 0 |  | Yinghao Li, Colin Lockard, Prashant Shiralkar, Chao Zhang |  |
| 817 |  |  [Multilingual Pre-training with Self-supervision from Global Co-occurrence Information](https://doi.org/10.18653/v1/2023.findings-acl.475) |  | 0 |  | Xi Ai, Bin Fang |  |
| 818 |  |  [Low-Rank Updates of pre-trained Weights for Multi-Task Learning](https://doi.org/10.18653/v1/2023.findings-acl.476) |  | 0 |  | Alexandre Audibert, MassihReza Amini, Konstantin Usevich, Marianne Clausel |  |
| 819 |  |  [Sequential Integrated Gradients: a simple but effective method for explaining language models](https://doi.org/10.18653/v1/2023.findings-acl.477) |  | 0 |  | Joseph Enguehard |  |
| 820 |  |  [DiffuDetox: A Mixed Diffusion Model for Text Detoxification](https://doi.org/10.18653/v1/2023.findings-acl.478) |  | 0 |  | Griffin Floto, Mohammad Mahdi Abdollah Pour, Parsa Farinneya, Zhenwei Tang, Ali Pesaranghader, Manasa Bharadwaj, Scott Sanner |  |
| 821 |  |  [Separating Context and Pattern: Learning Disentangled Sentence Representations for Low-Resource Extractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.479) |  | 0 |  | Ruifeng Yuan, Shichao Sun, Zili Wang, Ziqiang Cao, Wenjie Li |  |
| 822 |  |  [Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers](https://doi.org/10.18653/v1/2023.findings-acl.480) |  | 0 |  | Wanjun Zhong, Tingting Ma, Jiahai Wang, Jian Yin, Tiejun Zhao, ChinYew Lin, Nan Duan |  |
| 823 |  |  [Towards Argument-Aware Abstractive Summarization of Long Legal Opinions with Summary Reranking](https://doi.org/10.18653/v1/2023.findings-acl.481) |  | 0 |  | Mohamed Elaraby, Yang Zhong, Diane J. Litman |  |
| 824 |  |  [Probabilistic Transformer: A Probabilistic Dependency Model for Contextual Word Representation](https://doi.org/10.18653/v1/2023.findings-acl.482) |  | 0 |  | Haoyi Wu, Kewei Tu |  |
| 825 |  |  [Joint Speech Transcription and Translation: Pseudo-Labeling with Out-of-Distribution Data](https://doi.org/10.18653/v1/2023.findings-acl.483) |  | 0 |  | Mozhdeh Gheini, Tatiana Likhomanenko, Matthias Sperber, Hendra Setiawan |  |
| 826 |  |  [Word-level Prefix/Suffix Sense Detection: A Case Study on Negation Sense with Few-shot Learning](https://doi.org/10.18653/v1/2023.findings-acl.484) |  | 0 |  | Yameng Li, Zicheng Li, Ying Chen, Shoushan Li |  |
| 827 |  |  [End-to-End Simultaneous Speech Translation with Differentiable Segmentation](https://doi.org/10.18653/v1/2023.findings-acl.485) |  | 0 |  | Shaolei Zhang, Yang Feng |  |
| 828 |  |  [Joint Generator-Ranker Learning for Natural Language Generation](https://doi.org/10.18653/v1/2023.findings-acl.486) |  | 0 |  | Weizhou Shen, Yeyun Gong, Yelong Shen, Song Wang, Xiaojun Quan, Nan Duan, Weizhu Chen |  |
| 829 |  |  [Multilingual Sequence-to-Sequence Models for Hebrew NLP](https://doi.org/10.18653/v1/2023.findings-acl.487) |  | 0 |  | Matan Eyal, Hila Noga, Roee Aharoni, Idan Szpektor, Reut Tsarfaty |  |
| 830 |  |  [Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints](https://doi.org/10.18653/v1/2023.findings-acl.488) |  | 0 |  | Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao |  |
| 831 |  |  [Towards Better Hierarchical Text Classification with Data Generation](https://doi.org/10.18653/v1/2023.findings-acl.489) |  | 0 |  | Yue Wang, Dan Qiao, Juntao Li, Jinxiong Chang, Qishen Zhang, Zhongyi Liu, Guannan Zhang, Min Zhang |  |
| 832 |  |  [History repeats: Overcoming catastrophic forgetting for event-centric temporal knowledge graph completion](https://doi.org/10.18653/v1/2023.findings-acl.490) |  | 0 |  | Mehrnoosh Mirtaheri, Mohammad Rostami, Aram Galstyan |  |
| 833 |  |  [Multi-Agent Language Learning: Symbolic Mapping](https://doi.org/10.18653/v1/2023.findings-acl.491) |  | 0 |  | Yicheng Feng, Zongqing Lu |  |
| 834 |  |  [Scaling Laws for BERT in Low-Resource Settings](https://doi.org/10.18653/v1/2023.findings-acl.492) |  | 0 |  | Gorka Urbizu, Iñaki San Vicente, Xabier Saralegi, Rodrigo Agerri, Aitor Soroa |  |
| 835 |  |  [Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.findings-acl.493) |  | 0 |  | Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, Min Peng |  |
| 836 |  |  [Is Continuous Prompt a Combination of Discrete Prompts? Towards a Novel View for Interpreting Continuous Prompts](https://doi.org/10.18653/v1/2023.findings-acl.494) |  | 0 |  | Tianjie Ju, Yubin Zheng, Hanyi Wang, Haodong Zhao, Gongshen Liu |  |
| 837 |  |  [Putting Natural in Natural Language Processing](https://doi.org/10.18653/v1/2023.findings-acl.495) |  | 0 |  | Grzegorz Chrupala |  |
| 838 |  |  [Impact of Adversarial Training on Robustness and Generalizability of Language Models](https://doi.org/10.18653/v1/2023.findings-acl.496) |  | 0 |  | Enes Altinisik, Hassan Sajjad, Husrev T. Sencar, Safa Messaoud, Sanjay Chawla |  |
| 839 |  |  [Benchmarking Diverse-Modal Entity Linking with Generative Models](https://doi.org/10.18653/v1/2023.findings-acl.497) |  | 0 |  | Sijia Wang, Alexander Hanbo Li, Henghui Zhu, Sheng Zhang, Pramuditha Perera, ChungWei Hang, Jie Ma, William Yang Wang, Zhiguo Wang, Vittorio Castelli, Bing Xiang, Patrick Ng |  |
| 840 |  |  [Improving Empathetic Dialogue Generation by Dynamically Infusing Commonsense Knowledge](https://doi.org/10.18653/v1/2023.findings-acl.498) |  | 0 |  | Hua Cai, Xuli Shen, Qing Xu, Weilin Shen, Xiaomei Wang, Weifeng Ge, Xiaoqing Zheng, Xiangyang Xue |  |
| 841 |  |  [Additive manifesto decomposition: A policy domain aware method for understanding party positioning](https://doi.org/10.18653/v1/2023.findings-acl.499) |  | 0 |  | Tanise Ceron, Dmitry Nikolaev, Sebastian Padó |  |
| 842 |  |  [Similarizing the Influence of Words with Contrastive Learning to Defend Word-level Adversarial Text Attack](https://doi.org/10.18653/v1/2023.findings-acl.500) |  | 0 |  | Pengwei Zhan, Jing Yang, He Wang, Chao Zheng, Xiao Huang, Liming Wang |  |
| 843 |  |  [Responsibility Perspective Transfer for Italian Femicide News](https://doi.org/10.18653/v1/2023.findings-acl.501) |  | 0 |  | Gosse Minnema, Huiyuan Lai, Benedetta Muscato, Malvina Nissim |  |
| 844 |  |  [Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models](https://doi.org/10.18653/v1/2023.findings-acl.502) |  | 0 |  | Eddie L. Ungless, Björn Ross, Anne Lauscher |  |
| 845 |  |  [Fine-grained Artificial Neurons in Audio-transformers for Disentangling Neural Auditory Encoding](https://doi.org/10.18653/v1/2023.findings-acl.503) |  | 0 |  | Mengyue Zhou, Xu Liu, David Liu, Zihao Wu, Zhengliang Liu, Lin Zhao, Dajiang Zhu, Lei Guo, Junwei Han, Tianming Liu, Xintao Hu |  |
| 846 |  |  [Deeply Coupled Cross-Modal Prompt Learning](https://doi.org/10.18653/v1/2023.findings-acl.504) |  | 0 |  | Xuejing Liu, Wei Tang, Jinghui Lu, Rui Zhao, Zhaojun Guo, Fei Tan |  |
| 847 |  |  [Opinion Tree Parsing for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.505) |  | 0 |  | Xiaoyi Bao, Xiaotong Jiang, Zhongqing Wang, Yue Zhang, Guodong Zhou |  |
| 848 |  |  [CoMix: Guide Transformers to Code-Mix using POS structure and Phonetics](https://doi.org/10.18653/v1/2023.findings-acl.506) |  | 0 |  | Gaurav Arora, Srujana Merugu, Vivek Sembium |  |
| 849 |  |  [Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes](https://doi.org/10.18653/v1/2023.findings-acl.507) |  | 0 |  | ChengYu Hsieh, ChunLiang Li, ChihKuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay Krishna, ChenYu Lee, Tomas Pfister |  |
| 850 |  |  [Prosody-TTS: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech](https://doi.org/10.18653/v1/2023.findings-acl.508) |  | 0 |  | Rongjie Huang, Chunlei Zhang, Yi Ren, Zhou Zhao, Dong Yu |  |
| 851 |  |  [Duplex Diffusion Models Improve Speech-to-Speech Translation](https://doi.org/10.18653/v1/2023.findings-acl.509) |  | 0 |  | Xianchao Wu |  |
| 852 |  |  [Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.findings-acl.510) |  | 0 |  | Yuxin Jiang, Linhan Zhang, Wei Wang |  |
| 853 |  |  [PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.511) |  | 0 |  | Zhuocheng Gong, Jiahao Liu, Qifan Wang, Yang Yang, Jingang Wang, Wei Wu, Yunsen Xian, Dongyan Zhao, Rui Yan |  |
| 854 |  |  [Synthetic Pre-Training Tasks for Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.512) |  | 0 |  | Zexue He, Graeme Blackwood, Rameswar Panda, Julian J. McAuley, Rogério Feris |  |
| 855 |  |  [IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.513) |  | 0 |  | Zihang Xu, Ziqing Yang, Yiming Cui, Shijin Wang |  |
| 856 |  |  [Adversarial Training for Low-Resource Disfluency Correction](https://doi.org/10.18653/v1/2023.findings-acl.514) |  | 0 |  | Vineet Bhat, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 857 |  |  [Computer says "No": The Case Against Empathetic Conversational AI](https://doi.org/10.18653/v1/2023.findings-acl.515) |  | 0 |  | Alba Curry, Amanda Cercas Curry |  |
| 858 |  |  [Stubborn Lexical Bias in Data and Models](https://doi.org/10.18653/v1/2023.findings-acl.516) |  | 0 |  | Sofia Serrano, Jesse Dodge, Noah A. Smith |  |
| 859 |  |  [Distilling Efficient Language-Specific Models for Cross-Lingual Transfer](https://doi.org/10.18653/v1/2023.findings-acl.517) |  | 0 |  | Alan Ansell, Edoardo Maria Ponti, Anna Korhonen, Ivan Vulic |  |
| 860 |  |  [An Extensive Exploration of Back-Translation in 60 Languages](https://doi.org/10.18653/v1/2023.findings-acl.518) |  | 0 |  | Paul McNamee, Kevin Duh |  |
| 861 |  |  [AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.519) |  | 0 |  | Ru Zhou, Wenya Guo, Xumeng Liu, Shenglong Yu, Ying Zhang, Xiaojie Yuan |  |
| 862 |  |  [Forecasting Earnings Surprises from Conference Call Transcripts](https://doi.org/10.18653/v1/2023.findings-acl.520) |  | 0 |  | Ross Koval, Nicholas Andrews, Xifeng Yan |  |
| 863 |  |  [MTCue: Learning Zero-Shot Control of Extra-Textual Attributes by Leveraging Unstructured Context in Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.521) |  | 0 |  | Sebastian T. Vincent, Robert Flynn, Carolina Scarton |  |
| 864 |  |  [Evaluation for Change](https://doi.org/10.18653/v1/2023.findings-acl.522) |  | 0 |  | Rishi Bommasani |  |
| 865 |  |  [Reconstruction Probing](https://doi.org/10.18653/v1/2023.findings-acl.523) |  | 0 |  | Najoung Kim, Jatin Khilnani, Alex Warstadt, Abdelrahim Qaddoumi |  |
| 866 |  |  [Towards Distribution-shift Robust Text Classification of Emotional Content](https://doi.org/10.18653/v1/2023.findings-acl.524) |  | 0 |  | Luana Bulla, Aldo Gangemi, Misael Mongiovì |  |
| 867 |  |  [Multi-lingual and Multi-cultural Figurative Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.525) |  | 0 |  | Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Aremu Anuoluwapo, Perez Ogayo, Graham Neubig |  |
| 868 |  |  [Open-WikiTable : Dataset for Open Domain Question Answering with Complex Reasoning over Table](https://doi.org/10.18653/v1/2023.findings-acl.526) |  | 0 |  | Sunjun Kweon, Yeonsu Kwon, Seonhee Cho, Yohan Jo, Edward Choi |  |
| 869 |  |  [What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning](https://doi.org/10.18653/v1/2023.findings-acl.527) |  | 0 |  | Jane Pan, Tianyu Gao, Howard Chen, Danqi Chen |  |
| 870 |  |  [Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages](https://doi.org/10.18653/v1/2023.findings-acl.528) |  | 0 |  | Ercong Nie, Sheng Liang, Helmut Schmid, Hinrich Schütze |  |
| 871 |  |  [Unsupervised Summarization Re-ranking](https://doi.org/10.18653/v1/2023.findings-acl.529) |  | 0 |  | Mathieu Ravaut, Shafiq R. Joty, Nancy F. Chen |  |
| 872 |  |  [GRACE: Gradient-guided Controllable Retrieval for Augmenting Attribute-based Text Generation](https://doi.org/10.18653/v1/2023.findings-acl.530) |  | 0 |  | Zhihua Wen, Zhiliang Tian, Zhen Huang, Yuxin Yang, Zexin Jian, Changjian Wang, Dongsheng Li |  |
| 873 |  |  [So many design choices: Improving and interpreting neural agent communication in signaling games](https://doi.org/10.18653/v1/2023.findings-acl.531) |  | 0 |  | Timothée Bernard, Timothee Mickus |  |
| 874 |  |  [Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.532) |  | 0 |  | Fanyu Wang, Zhenping Xie |  |
| 875 |  |  [Fixed Input Parameterization for Efficient Prompting](https://doi.org/10.18653/v1/2023.findings-acl.533) |  | 0 |  | Eunbi Choi, Yongrae Jo, Joel Jang, Joonwon Jang, Minjoon Seo |  |
| 876 |  |  [Data Augmentation for Low-Resource Keyphrase Generation](https://doi.org/10.18653/v1/2023.findings-acl.534) |  | 0 |  | Krishna Garg, Jishnu Ray Chowdhury, Cornelia Caragea |  |
| 877 |  |  [BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.535) |  | 0 |  | Liyan Kang, Luyang Huang, Ningxin Peng, Peihao Zhu, Zewei Sun, Shanbo Cheng, Mingxuan Wang, Degen Huang, Jinsong Su |  |
| 878 |  |  [Constructing Procedural Graphs with Multiple Dependency Relations: A New Dataset and Baseline](https://doi.org/10.18653/v1/2023.findings-acl.536) |  | 0 |  | Haopeng Ren, Yushi Zeng, Yi Cai, Bihan Zhou, Zetao Lian |  |
| 879 |  |  [Multi-Dimensional Evaluation of Text Summarization with In-Context Learning](https://doi.org/10.18653/v1/2023.findings-acl.537) |  | 0 |  | Sameer Jain, Vaishakh Keshava, Swarnashree Mysore Sathyendra, Patrick Fernandes, Pengfei Liu, Graham Neubig, Chunting Zhou |  |
| 880 |  |  [Learning to Rank Utterances for Query-Focused Meeting Summarization](https://doi.org/10.18653/v1/2023.findings-acl.538) |  | 0 |  | Xingxian Liu, Yajing Xu |  |
| 881 |  |  [Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.539) |  | 0 |  | Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver Steeg |  |
| 882 |  |  [Aligning Offline Metrics and Human Judgments of Value for Code Generation Models](https://doi.org/10.18653/v1/2023.findings-acl.540) |  | 0 |  | Victor Dibia, Adam Fourney, Gagan Bansal, Forough PoursabziSangdeh, Han Liu, Saleema Amershi |  |
| 883 |  |  [Do transformer models do phonology like a linguist?](https://doi.org/10.18653/v1/2023.findings-acl.541) |  | 0 |  | Saliha Muradoglu, Mans Hulden |  |
| 884 |  |  [DiMS: Distilling Multiple Steps of Iterative Non-Autoregressive Transformers for Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.542) |  | 0 |  | Sajad Norouzi, Rasa Hosseinzadeh, Felipe Pérez, Maksims Volkovs |  |
| 885 |  |  [Retrieval-augmented Video Encoding for Instructional Captioning](https://doi.org/10.18653/v1/2023.findings-acl.543) |  | 0 |  | YeonJoon Jung, Minsoo Kim, Seungtaek Choi, Jihyuk Kim, Minji Seo, Seungwon Hwang |  |
| 886 |  |  [Bi-level Finetuning with Task-dependent Similarity Structure for Low-resource Training](https://doi.org/10.18653/v1/2023.findings-acl.544) |  | 0 |  | Sai Ashish Somayajula, Lifeng Jin, Linfeng Song, Haitao Mi, Dong Yu |  |
| 887 |  |  [Kanbun-LM: Reading and Translating Classical Chinese in Japanese Methods by Language Models](https://doi.org/10.18653/v1/2023.findings-acl.545) |  | 0 |  | Hao Wang, Hirofumi Shimizu, Daisuke Kawahara |  |
| 888 |  |  [Adaptive Attention for Sparse-based Long-sequence Transformer](https://doi.org/10.18653/v1/2023.findings-acl.546) |  | 0 |  | Xuanyu Zhang, Zhepeng Lv, Qing Yang |  |
| 889 |  |  [Sentiment Analysis using the Relationship between Users and Products](https://doi.org/10.18653/v1/2023.findings-acl.547) |  | 0 |  | Natthawut Kertkeidkachorn, Kiyoaki Shirai |  |
| 890 |  |  [Entropy-guided Vocabulary Augmentation of Multilingual Language Models for Low-resource Tasks](https://doi.org/10.18653/v1/2023.findings-acl.548) |  | 0 |  | Arijit Nag, Bidisha Samanta, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti |  |
| 891 |  |  [Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data](https://doi.org/10.18653/v1/2023.findings-acl.549) |  | 0 |  | Qingyu Tan, Lu Xu, Lidong Bing, Hwee Tou Ng |  |
| 892 |  |  [Solving Cosine Similarity Underestimation between High Frequency Words by \ell₂ Norm Discounting](https://doi.org/10.18653/v1/2023.findings-acl.550) |  | 0 |  | Saeth Wannasuphoprasit, Yi Zhou, Danushka Bollegala |  |
| 893 |  |  [Do Large Language Models Know What They Don't Know?](https://doi.org/10.18653/v1/2023.findings-acl.551) |  | 0 |  | Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, Xuanjing Huang |  |
| 894 |  |  [AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities](https://doi.org/10.18653/v1/2023.findings-acl.552) |  | 0 |  | Zhongzhi Chen, Guang Liu, BoWen Zhang, Qinghong Yang, Ledell Wu |  |
| 895 |  |  [RHGN: Relation-gated Heterogeneous Graph Network for Entity Alignment in Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-acl.553) |  | 0 |  | Xukai Liu, Kai Zhang, Ye Liu, Enhong Chen, Zhenya Huang, Linan Yue, Jiaxian Yan |  |
| 896 |  |  [Feature Interactions Reveal Linguistic Structure in Language Models](https://doi.org/10.18653/v1/2023.findings-acl.554) |  | 0 |  | Jaap Jumelet, Willem H. Zuidema |  |
| 897 |  |  [Clustering-Aware Negative Sampling for Unsupervised Sentence Representation](https://doi.org/10.18653/v1/2023.findings-acl.555) |  | 0 |  | Jinghao Deng, Fanqi Wan, Tao Yang, Xiaojun Quan, Rui Wang |  |
| 898 |  |  [An Effective Deployment of Contrastive Learning in Multi-label Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.556) |  | 0 |  | Nankai Lin, Guanqiu Qin, Gang Wang, Dong Zhou, Aimin Yang |  |
| 899 |  |  [Segment-Level and Category-Oriented Network for Knowledge-Based Referring Expression Comprehension](https://doi.org/10.18653/v1/2023.findings-acl.557) |  | 0 |  | Yuqi Bu, Xin Wu, Liuwu Li, Yi Cai, Qiong Liu, Qingbao Huang |  |
| 900 |  |  [MVP: Multi-task Supervised Pre-training for Natural Language Generation](https://doi.org/10.18653/v1/2023.findings-acl.558) |  | 0 |  | Tianyi Tang, Junyi Li, Wayne Xin Zhao, JiRong Wen |  |
| 901 |  |  [From Alignment to Entailment: A Unified Textual Entailment Framework for Entity Alignment](https://doi.org/10.18653/v1/2023.findings-acl.559) |  | 0 |  | Yu Zhao, Yike Wu, Xiangrui Cai, Ying Zhang, Haiwei Zhang, Xiaojie Yuan |  |
| 902 |  |  [It is a Bird Therefore it is a Robin: On BERT's Internal Consistency Between Hypernym Knowledge and Logical Words](https://doi.org/10.18653/v1/2023.findings-acl.560) |  | 0 |  | Nicolas Guérin, Emmanuel Chemla |  |
| 903 |  |  [Defending against Insertion-based Textual Backdoor Attacks via Attribution](https://doi.org/10.18653/v1/2023.findings-acl.561) |  | 0 |  | Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran |  |
| 904 |  |  [ActiveAED: A Human in the Loop Improves Annotation Error Detection](https://doi.org/10.18653/v1/2023.findings-acl.562) |  | 0 |  | Leon Weber, Barbara Plank |  |
| 905 |  |  [Assessing Word Importance Using Models Trained for Semantic Tasks](https://doi.org/10.18653/v1/2023.findings-acl.563) |  | 0 |  | Dávid Javorský, Ondrej Bojar, François Yvon |  |
| 906 |  |  [In-context Examples Selection for Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.564) |  | 0 |  | Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, Marjan Ghazvininejad |  |
| 907 |  |  [PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition](https://doi.org/10.18653/v1/2023.findings-acl.565) |  | 0 |  | Sihao Chen, Senaka Buthpitiya, Alex Fabrikant, Dan Roth, Tal Schuster |  |
| 908 |  |  [CIF-PT: Bridging Speech and Text Representations for Spoken Language Understanding via Continuous Integrate-and-Fire Pre-Training](https://doi.org/10.18653/v1/2023.findings-acl.566) |  | 0 |  | Linhao Dong, Zhecheng An, Peihao Wu, Jun Zhang, Lu Lu, Zejun Ma |  |
| 909 |  |  [Improving Diachronic Word Sense Induction with a Nonparametric Bayesian method](https://doi.org/10.18653/v1/2023.findings-acl.567) |  | 0 |  | Ashjan Alsulaimani, Erwan Moreau |  |
| 910 |  |  [What to Fuse and How to Fuse: Exploring Emotion and Personality Fusion Strategies for Explainable Mental Disorder Detection](https://doi.org/10.18653/v1/2023.findings-acl.568) |  | 0 |  | Sourabh Zanwar, Xiaofei Li, Daniel Wiechmann, Yu Qiao, Elma Kerz |  |
| 911 |  |  [Adaptive Contrastive Knowledge Distillation for BERT Compression](https://doi.org/10.18653/v1/2023.findings-acl.569) |  | 0 |  | Jinyang Guo, Jiaheng Liu, Zining Wang, Yuqing Ma, Ruihao Gong, Ke Xu, Xianglong Liu |  |
| 912 |  |  [Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator](https://doi.org/10.18653/v1/2023.findings-acl.570) |  | 0 |  | Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, Jingwen Leng, Zhouhan Lin |  |
| 913 |  |  [Zero-Shot Classification by Logical Reasoning on Natural Language Explanations](https://doi.org/10.18653/v1/2023.findings-acl.571) |  | 0 |  | Chi Han, Hengzhi Pei, Xinya Du, Heng Ji |  |
| 914 |  |  [Dual-Gated Fusion with Prefix-Tuning for Multi-Modal Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.572) |  | 0 |  | Qian Li, Shu Guo, Cheng Ji, Xutan Peng, Shiyao Cui, Jianxin Li, Lihong Wang |  |
| 915 |  |  [Pruning Pre-trained Language Models with Principled Importance and Self-regularization](https://doi.org/10.18653/v1/2023.findings-acl.573) |  | 0 |  | Siyu Ren, Kenny Q. Zhu |  |
| 916 |  |  [The Magic of IF: Investigating Causal Reasoning Abilities in Large Language Models of Code](https://doi.org/10.18653/v1/2023.findings-acl.574) |  | 0 |  | Xiao Liu, Da Yin, Chen Zhang, Yansong Feng, Dongyan Zhao |  |
| 917 |  |  [Learning to Leverage High-Order Medical Knowledge Graph for Joint Entity and Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.575) |  | 0 |  | Zhe Yang, Yi Huang, Junlan Feng |  |
| 918 |  |  [Data-Efficient Finetuning Using Cross-Task Nearest Neighbors](https://doi.org/10.18653/v1/2023.findings-acl.576) |  | 0 |  | Hamish Ivison, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi |  |
| 919 |  |  [CoAug: Combining Augmentation of Labels and Labelling Rules](https://doi.org/10.18653/v1/2023.findings-acl.577) |  | 0 |  | Rakesh R. Menon, Bingqing Wang, Jun Araki, Zhengyu Zhou, Zhe Feng, Liu Ren |  |
| 920 |  |  [Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks](https://doi.org/10.18653/v1/2023.findings-acl.578) |  | 0 |  | Xuming Hu, Yong Jiang, Aiwei Liu, Zhongqiang Huang, Pengjun Xie, Fei Huang, Lijie Wen, Philip S. Yu |  |
| 921 |  |  [World Models for Math Story Problems](https://doi.org/10.18653/v1/2023.findings-acl.579) |  | 0 |  | Andreas Opedal, Niklas Stoehr, Abulhair Saparov, Mrinmaya Sachan |  |
| 922 |  |  [AutoMoE: Heterogeneous Mixture-of-Experts with Adaptive Computation for Efficient Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.580) |  | 0 |  | Ganesh Jawahar, Subhabrata Mukherjee, Xiaodong Liu, Young Jin Kim, Muhammad AbdulMageed, Laks V. S. Lakshmanan, Ahmed Hassan Awadallah, Sébastien Bubeck, Jianfeng Gao |  |
| 923 |  |  [Language Agnostic Multilingual Information Retrieval with Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-acl.581) |  | 0 |  | Xiyang Hu, Xinchi Chen, Peng Qi, Deguang Kong, Kunlun Liu, William Yang Wang, Zhiheng Huang |  |
| 924 |  |  [Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods](https://doi.org/10.18653/v1/2023.findings-acl.582) |  | 0 |  | Josip Jukic, Martin Tutek, Jan Snajder |  |
| 925 |  |  [Enhancing Cross-lingual Transfer via Phonemic Transcription Integration](https://doi.org/10.18653/v1/2023.findings-acl.583) |  | 0 |  | Hoang Nguyen, Chenwei Zhang, Tao Zhang, Eugene Rohrbaugh, Philip S. Yu |  |
| 926 |  |  [Human-in-the-loop Abstractive Dialogue Summarization](https://doi.org/10.18653/v1/2023.findings-acl.584) |  | 0 |  | Jiaao Chen, Mohan Dodda, Diyi Yang |  |
| 927 |  |  [A Multi-task Learning Framework for Quality Estimation](https://doi.org/10.18653/v1/2023.findings-acl.585) |  | 0 |  | Sourabh Dattatray Deoghare, Paramveer Choudhary, Diptesh Kanojia, Tharindu Ranasinghe, Pushpak Bhattacharyya, Constantin Orasan |  |
| 928 |  |  [The Devil is in the Details: On the Pitfalls of Event Extraction Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.586) |  | 0 |  | Hao Peng, Xiaozhi Wang, Feng Yao, Kaisheng Zeng, Lei Hou, Juanzi Li, Zhiyuan Liu, Weixing Shen |  |
| 929 |  |  [Yes, this Way! Learning to Ground Referring Expressions into Actions with Intra-episodic Feedback from Supportive Teachers](https://doi.org/10.18653/v1/2023.findings-acl.587) |  | 0 |  | Philipp Sadler, Sherzod Hakimov, David Schlangen |  |
| 930 |  |  [Investigating Transformer-Guided Chaining for Interpretable Natural Logic Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.588) |  | 0 |  | Kanagasabai Rajaraman, Saravanan Rajamanickam, Wei Shi |  |
| 931 |  |  [Multilingual Multi-Figurative Language Detection](https://doi.org/10.18653/v1/2023.findings-acl.589) |  | 0 |  | Huiyuan Lai, Antonio Toral, Malvina Nissim |  |
| 932 |  |  [Zero-shot Visual Question Answering with Language Model Feedback](https://doi.org/10.18653/v1/2023.findings-acl.590) |  | 0 |  | Yifan Du, Junyi Li, Tianyi Tang, Wayne Xin Zhao, JiRong Wen |  |
| 933 |  |  [Prompted Opinion Summarization with GPT-3.5](https://doi.org/10.18653/v1/2023.findings-acl.591) |  | 0 |  | Adithya Bhaskar, Alexander R. Fabbri, Greg Durrett |  |
| 934 |  |  [Sentence Ordering with a Coherence Verifier](https://doi.org/10.18653/v1/2023.findings-acl.592) |  | 0 |  | Sainan Jia, Wei Song, Jiefu Gong, Shijin Wang, Ting Liu |  |
| 935 |  |  [GUMSum: Multi-Genre Data and Evaluation for English Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.593) |  | 0 |  | Yang Janet Liu, Amir Zeldes |  |
| 936 |  |  [Improving Grammatical Error Correction with Multimodal Feature Integration](https://doi.org/10.18653/v1/2023.findings-acl.594) |  | 0 |  | Tao Fang, Jinpeng Hu, Derek F. Wong, Xiang Wan, Lidia S. Chao, TsungHui Chang |  |
| 937 |  |  [Teaching the Pre-trained Model to Generate Simple Texts for Text Simplification](https://doi.org/10.18653/v1/2023.findings-acl.595) |  | 0 |  | Renliang Sun, Wei Xu, Xiaojun Wan |  |
| 938 |  |  [Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic Frame Induction](https://doi.org/10.18653/v1/2023.findings-acl.596) |  | 0 |  | Kosuke Yamada, Ryohei Sasano, Koichi Takeda |  |
| 939 |  |  [Leveraging Synthetic Targets for Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.597) |  | 0 |  | Sarthak Mittal, Oleksii Hrinchuk, Oleksii Kuchaiev |  |
| 940 |  |  [Recipes for Sequential Pre-training of Multilingual Encoder and Seq2Seq Models](https://doi.org/10.18653/v1/2023.findings-acl.598) |  | 0 |  | Saleh Soltan, Andy Rosenbaum, Tobias Falke, Qin Lu, Anna Rumshisky, Wael Hamza |  |
| 941 |  |  [Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.599) |  | 0 |  | Hao Fei, Meishan Zhang, Min Zhang, TatSeng Chua |  |
| 942 |  |  [Spontaneous gestures encoded by hand positions improve language models: An Information-Theoretic motivated study](https://doi.org/10.18653/v1/2023.findings-acl.600) |  | 0 |  | Yang Xu, Yang Cheng |  |
| 943 |  |  [Progressive Translation: Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences](https://doi.org/10.18653/v1/2023.findings-acl.601) |  | 0 |  | Chaojun Wang, Yang Liu, Wai Lam |  |
| 944 |  |  [Controlled Text Generation with Hidden Representation Transformations](https://doi.org/10.18653/v1/2023.findings-acl.602) |  | 0 |  | Vaibhav Kumar, Hana Koorehdavoudi, Masud Moshtaghi, Amita Misra, Ankit Chadha, Emilio Ferrara |  |
| 945 |  |  [Visual Coherence Loss for Coherent and Visually Grounded Story Generation](https://doi.org/10.18653/v1/2023.findings-acl.603) |  | 0 |  | Xudong Hong, Vera Demberg, Asad B. Sayeed, Qiankun Zheng, Bernt Schiele |  |
| 946 |  |  [AnaMeta: A Table Understanding Dataset of Field Metadata Knowledge Shared by Multi-dimensional Data Analysis Tasks](https://doi.org/10.18653/v1/2023.findings-acl.604) |  | 0 |  | Xinyi He, Mengyu Zhou, Mingjie Zhou, Jialiang Xu, Xiao Lv, Tianle Li, Yijia Shao, Shi Han, Zejian Yuan, Dongmei Zhang |  |
| 947 |  |  [Large Language Models Are Partially Primed in Pronoun Interpretation](https://doi.org/10.18653/v1/2023.findings-acl.605) |  | 0 |  | SuetYing Lam, Qingcheng Zeng, Kexun Zhang, Chenyu You, Rob Voigt |  |
| 948 |  |  [Counterfactuals of Counterfactuals: a back-translation-inspired approach to analyse counterfactual editors](https://doi.org/10.18653/v1/2023.findings-acl.606) |  | 0 |  | George Filandrianos, Edmund Dervakos, Orfeas MenisMastromichalakis, Chrysoula Zerva, Giorgos Stamou |  |
| 949 |  |  [A Pilot Study on Dialogue-Level Dependency Parsing for Chinese](https://doi.org/10.18653/v1/2023.findings-acl.607) |  | 0 |  | Gongyao Jiang, Shuang Liu, Meishan Zhang, Min Zhang |  |
| 950 |  |  [On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.608) |  | 0 |  | Liang Chen, Shuming Ma, Dongdong Zhang, Furu Wei, Baobao Chang |  |
| 951 |  |  [ORCA: A Challenging Benchmark for Arabic Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.609) |  | 0 |  | AbdelRahim A. Elmadany, El Moatez Billah Nagoudi, Muhammad AbdulMageed |  |
| 952 |  |  [Delving into the Openness of CLIP](https://doi.org/10.18653/v1/2023.findings-acl.610) |  | 0 |  | Shuhuai Ren, Lei Li, Xuancheng Ren, Guangxiang Zhao, Xu Sun |  |
| 953 |  |  [From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework](https://doi.org/10.18653/v1/2023.findings-acl.611) |  | 0 |  | Yangyi Chen, Hongcheng Gao, Ganqu Cui, Lifan Yuan, Dehan Kong, Hanlu Wu, Ning Shi, Bo Yuan, Longtao Huang, Hui Xue, Zhiyuan Liu, Maosong Sun, Heng Ji |  |
| 954 |  |  [An Empirical Study of Sentiment-Enhanced Pre-Training for Aspect-Based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.612) |  | 0 |  | Yice Zhang, Yifan Yang, Bin Liang, Shiwei Chen, Bing Qin, Ruifeng Xu |  |
| 955 |  |  [NatCS: Eliciting Natural Customer Support Dialogues](https://doi.org/10.18653/v1/2023.findings-acl.613) |  | 0 |  | James Gung, Emily Moeng, Wesley Rose, Arshit Gupta, Yi Zhang, Saab Mansour |  |
| 956 |  |  [Are Intermediate Layers and Labels Really Necessary? A General Language Model Distillation Method](https://doi.org/10.18653/v1/2023.findings-acl.614) |  | 0 |  | Shicheng Tan, Weng Lam Tam, Yuanchun Wang, Wenwen Gong, Shu Zhao, Peng Zhang, Jie Tang |  |
| 957 |  |  [Diable: Efficient Dialogue State Tracking as Operations on Tables](https://doi.org/10.18653/v1/2023.findings-acl.615) |  | 0 |  | Pietro Lesci, Yoshinari Fujinuma, Momchil Hardalov, Chao Shang, Lluís Màrquez |  |
| 958 |  |  [Neural Topic Modeling based on Cycle Adversarial Training and Contrastive Learning](https://doi.org/10.18653/v1/2023.findings-acl.616) |  | 0 |  | Boyu Wang, Linhai Zhang, Deyu Zhou, Yi Cao, Jiandong Ding |  |
| 959 |  |  [Alleviating Exposure Bias via Multi-level Contrastive Learning and Deviation Simulation in Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.617) |  | 0 |  | Jiawen Xie, Qi Su, Shaoting Zhang, Xiaofan Zhang |  |
| 960 |  |  [Mapping Brains with Language Models: A Survey](https://doi.org/10.18653/v1/2023.findings-acl.618) |  | 0 |  | Antonia Karamolegkou, Mostafa Abdou, Anders Søgaard |  |
| 961 |  |  [Parameter-Efficient Finetuning for Robust Continual Multilingual Learning](https://doi.org/10.18653/v1/2023.findings-acl.619) |  | 0 |  | Kartikeya Badola, Shachi Dave, Partha Talukdar |  |
| 962 |  |  [Interpretable Multimodal Misinformation Detection with Logic Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.620) |  | 0 |  | Hui Liu, Wenya Wang, Haoliang Li |  |
| 963 |  |  [Semantic-conditioned Dual Adaptation for Cross-domain Query-based Visual Segmentation](https://doi.org/10.18653/v1/2023.findings-acl.621) |  | 0 |  | Ye Wang, Tao Jin, Wang Lin, Xize Cheng, Linjun Li, Zhou Zhao |  |
| 964 |  |  [Figurative Language Processing: A Linguistically Informed Feature Analysis of the Behavior of Language Models and Humans](https://doi.org/10.18653/v1/2023.findings-acl.622) |  | 0 |  | Hyewon Jang, Qi Yu, Diego Frassinelli |  |
| 965 |  |  [Taxonomy of Problems in Lexical Semantics](https://doi.org/10.18653/v1/2023.findings-acl.623) |  | 0 |  | Bradley Hauer, Grzegorz Kondrak |  |
| 966 |  |  [Making Pre-trained Language Models both Task-solvers and Self-calibrators](https://doi.org/10.18653/v1/2023.findings-acl.624) |  | 0 |  | Yangyi Chen, Xingyao Wang, Heng Ji |  |
| 967 |  |  [EmbedTextNet: Dimension Reduction with Weighted Reconstruction and Correlation Losses for Efficient Text Embedding](https://doi.org/10.18653/v1/2023.findings-acl.625) |  | 0 |  | Dae Yon Hwang, Bilal Taha, Yaroslav Nechaev |  |
| 968 |  |  [Denoising Enhanced Distantly Supervised Ultrafine Entity Typing](https://doi.org/10.18653/v1/2023.findings-acl.626) |  | 0 |  | Yue Zhang, Hongliang Fei, Ping Li |  |
| 969 |  |  [INTapt: Information-Theoretic Adversarial Prompt Tuning for Enhanced Non-Native Speech Recognition](https://doi.org/10.18653/v1/2023.findings-acl.627) |  | 0 |  | Eunseop Yoon, Hee Suk Yoon, John B. Harvill, Mark HasegawaJohnson, Chang Dong Yoo |  |
| 970 |  |  [Local Temperature Beam Search: Avoid Neural Text DeGeneration via Enhanced Calibration](https://doi.org/10.18653/v1/2023.findings-acl.628) |  | 0 |  | Dongkyu Lee, Gyeonghun Kim, Janghoon Han, Taesuk Hong, Yireun Kim, Stanley Jungkyu Choi, Nevin L. Zhang |  |
| 971 |  |  [Explanation Graph Generation via Generative Pre-training over Synthetic Graphs](https://doi.org/10.18653/v1/2023.findings-acl.629) |  | 0 |  | Han Cui, Shangzhan Li, Yu Zhang, Qi Shi |  |
| 972 |  |  [NaSGEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native Speaker Texts](https://doi.org/10.18653/v1/2023.findings-acl.630) |  | 0 |  | Yue Zhang, Bo Zhang, Haochen Jiang, Zhenghua Li, Chen Li, Fei Huang, Min Zhang |  |
| 973 |  |  [FORK: A Bite-Sized Test Set for Probing Culinary Cultural Biases in Commonsense Reasoning Models](https://doi.org/10.18653/v1/2023.findings-acl.631) |  | 0 |  | Shramay Palta, Rachel Rudinger |  |
| 974 |  |  [FedPETuning: When Federated Learning Meets the Parameter-Efficient Tuning Methods of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.632) |  | 0 |  | Zhuo Zhang, Yuanhang Yang, Yong Dai, Qifan Wang, Yue Yu, Lizhen Qu, Zenglin Xu |  |
| 975 |  |  [MixPAVE: Mix-Prompt Tuning for Few-shot Product Attribute Value Extraction](https://doi.org/10.18653/v1/2023.findings-acl.633) |  | 0 |  | Li Yang, Qifan Wang, Jingang Wang, Xiaojun Quan, Fuli Feng, Yu Chen, Madian Khabsa, Sinong Wang, Zenglin Xu, Dongfang Liu |  |
| 976 |  |  [SlowBERT: Slow-down Attacks on Input-adaptive Multi-exit BERT](https://doi.org/10.18653/v1/2023.findings-acl.634) |  | 0 |  | Shengyao Zhang, Xudong Pan, Mi Zhang, Min Yang |  |
| 977 |  |  [Compositional Mathematical Encoding for Math Word Problems](https://doi.org/10.18653/v1/2023.findings-acl.635) |  | 0 |  | Zhenwen Liang, Jipeng Zhang, Kehan Guo, Xiaodong Wu, Jie Shao, Xiangliang Zhang |  |
| 978 |  |  [PREADD: Prefix-Adaptive Decoding for Controlled Text Generation](https://doi.org/10.18653/v1/2023.findings-acl.636) |  | 0 |  | Jonathan Pei, Kevin Yang, Dan Klein |  |
| 979 |  |  [EventOA: An Event Ontology Alignment Benchmark Based on FrameNet and Wikidata](https://doi.org/10.18653/v1/2023.findings-acl.637) |  | 0 |  | Shaoru Guo, Chenhao Wang, Yubo Chen, Kang Liu, Ru Li, Jun Zhao |  |
| 980 |  |  [Enhancing Continual Relation Extraction via Classifier Decomposition](https://doi.org/10.18653/v1/2023.findings-acl.638) |  | 0 |  | Heming Xia, Peiyi Wang, Tianyu Liu, Binghuai Lin, Yunbo Cao, Zhifang Sui |  |
| 981 |  |  [A Comparative Analysis of the Effectiveness of Rare Tokens on Creative Expression using ramBERT](https://doi.org/10.18653/v1/2023.findings-acl.639) |  | 0 |  | Youbin Lee, Deokgi Kim, ByungWon On, Ingyu Lee |  |
| 982 |  |  [MTR: A Dataset Fusing Inductive, Deductive, and Defeasible Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.640) |  | 0 |  | Yitian Li, Jidong Tian, Caoyun Fan, Wenqing Chen, Hao He, Yaohui Jin |  |
| 983 |  |  [NewsMet : A 'do it all' Dataset of Contemporary Metaphors in News Headlines](https://doi.org/10.18653/v1/2023.findings-acl.641) |  | 0 |  | Rohan Joseph, Timothy Liu, Aik Beng Ng, Simon See, Sunny Rai |  |
| 984 |  |  [Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs](https://doi.org/10.18653/v1/2023.findings-acl.642) |  | 0 |  | Zijie Huang, Daheng Wang, Binxuan Huang, Chenwei Zhang, Jingbo Shang, Yan Liang, Zhengyang Wang, Xian Li, Christos Faloutsos, Yizhou Sun, Wei Wang |  |
| 985 |  |  [Noise-Robust Training with Dynamic Loss and Contrastive Learning for Distantly-Supervised Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.643) |  | 0 |  | Zhiyuan Ma, Jintao Du, Shuheng Zhou |  |
| 986 |  |  [Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation](https://doi.org/10.18653/v1/2023.findings-acl.644) |  | 0 |  | Xinze Li, Yixin Cao, Muhao Chen, Aixin Sun |  |
| 987 |  |  [End-to-End Task-Oriented Dialogue Systems Based on Schema](https://doi.org/10.18653/v1/2023.findings-acl.645) |  | 0 |  | Wiradee Imrattanatrai, Ken Fukuda |  |
| 988 |  |  [HaVQA: A Dataset for Visual Question Answering and Multimodal Research in Hausa Language](https://doi.org/10.18653/v1/2023.findings-acl.646) |  | 0 |  | Shantipriya Parida, Idris Abdulmumin, Shamsuddeen Hassan Muhammad, Aneesh Bose, Guneet Singh Kohli, Ibrahim Said Ahmad, Ketan Kotwal, Sayan Deb Sarkar, Ondrej Bojar, Habeebah A. Kakudi |  |
| 989 |  |  [Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction](https://doi.org/10.18653/v1/2023.findings-acl.647) |  | 0 |  | Martin Fajcik, Petr Motlícek, Pavel Smrz |  |
| 990 |  |  [StructSP: Efficient Fine-tuning of Task-Oriented Dialog System by Using Structure-aware Boosting and Grammar Constraints](https://doi.org/10.18653/v1/2023.findings-acl.648) |  | 0 |  | Truong Do, Phuong Nguyen, LeMinh Nguyen |  |
| 991 |  |  [GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks](https://doi.org/10.18653/v1/2023.findings-acl.649) |  | 0 |  | Xuming Hu, Aiwei Liu, Zeqi Tan, Xin Zhang, Chenwei Zhang, Irwin King, Philip S. Yu |  |
| 992 |  |  [WebDP: Understanding Discourse Structures in Semi-Structured Web Documents](https://doi.org/10.18653/v1/2023.findings-acl.650) |  | 0 |  | Peilin Liu, Hongyu Lin, Meng Liao, Hao Xiang, Xianpei Han, Le Sun |  |
| 993 |  |  [Tab-CoT: Zero-shot Tabular Chain of Thought](https://doi.org/10.18653/v1/2023.findings-acl.651) |  | 0 |  | Ziqi Jin, Wei Lu |  |
| 994 |  |  [KNSE: A Knowledge-aware Natural Language Inference Framework for Dialogue Symptom Status Recognition](https://doi.org/10.18653/v1/2023.findings-acl.652) |  | 0 |  | Wei Chen, Shiqi Wei, Zhongyu Wei, Xuanjing Huang |  |
| 995 |  |  [Augmenting Large Language Model Translators via Translation Memories](https://doi.org/10.18653/v1/2023.findings-acl.653) |  | 0 |  | Yongyu Mu, Abudurexiti Reheman, Zhiquan Cao, Yuchun Fan, Bei Li, Yinqiao Li, Tong Xiao, Chunliang Zhang, Jingbo Zhu |  |
| 996 |  |  [Character Coreference Resolution in Movie Screenplays](https://doi.org/10.18653/v1/2023.findings-acl.654) |  | 0 |  | Sabyasachee Baruah, Shrikanth Narayanan |  |
| 997 |  |  [Enhancing Event Causality Identification with Event Causal Label and Event Pair Interaction Graph](https://doi.org/10.18653/v1/2023.findings-acl.655) |  | 0 |  | Ruili Pu, Yang Li, Suge Wang, Deyu Li, Jianxing Zheng, Jian Liao |  |
| 998 |  |  [LightFormer: Light-weight Transformer Using SVD-based Weight Transfer and Parameter Sharing](https://doi.org/10.18653/v1/2023.findings-acl.656) |  | 0 |  | Xiuqing Lv, Peng Zhang, Sunzhu Li, Guobing Gan, Yueheng Sun |  |
| 999 |  |  [Multi-hop Evidence Retrieval for Cross-document Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.657) |  | 0 |  | Keming Lu, IHung Hsu, Wenxuan Zhou, Mingyu Derek Ma, Muhao Chen |  |
| 1000 |  |  [Which Examples Should be Multiply Annotated? Active Learning When Annotators May Disagree](https://doi.org/10.18653/v1/2023.findings-acl.658) |  | 0 |  | Connor Baumler, Anna Sotnikova, Hal Daumé III |  |
| 1001 |  |  [PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation](https://doi.org/10.18653/v1/2023.findings-acl.659) |  | 0 |  | Yixin Wan, KuanHao Huang, KaiWei Chang |  |
| 1002 |  |  [DePlot: One-shot visual language reasoning by plot-to-table translation](https://doi.org/10.18653/v1/2023.findings-acl.660) |  | 0 |  | Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun |  |
| 1003 |  |  [Stochastic Bridges as Effective Regularizers for Parameter-Efficient Tuning](https://doi.org/10.18653/v1/2023.findings-acl.661) |  | 0 |  | Weize Chen, Xu Han, Yankai Lin, Zhiyuan Liu, Maosong Sun, Jie Zhou |  |
| 1004 |  |  [Learning from a Friend: Improving Event Extraction via Self-Training with Feedback from Abstract Meaning Representation](https://doi.org/10.18653/v1/2023.findings-acl.662) |  | 0 |  | Zhiyang Xu, Jay Yoon Lee, Lifu Huang |  |
| 1005 |  |  [How Well Do Large Language Models Perform on Faux Pas Tests?](https://doi.org/10.18653/v1/2023.findings-acl.663) |  | 0 |  | Natalie Shapira, Guy Zwirn, Yoav Goldberg |  |
| 1006 |  |  [Modular Transformers: Compressing Transformers into Modularized Layers for Flexible Efficient Inference](https://doi.org/10.18653/v1/2023.findings-acl.664) |  | 0 |  | Wangchunshu Zhou, Ronan Le Bras, Yejin Choi |  |
| 1007 |  |  [ISLTranslate: Dataset for Translating Indian Sign Language](https://doi.org/10.18653/v1/2023.findings-acl.665) |  | 0 |  | Abhinav Joshi, Susmit Agrawal, Ashutosh Modi |  |
| 1008 |  |  [LMentry: A Language Model Benchmark of Elementary Language Tasks](https://doi.org/10.18653/v1/2023.findings-acl.666) |  | 0 |  | Avia Efrat, Or Honovich, Omer Levy |  |
| 1009 |  |  [Differentiable Instruction Optimization for Cross-Task Generalization](https://doi.org/10.18653/v1/2023.findings-acl.667) |  | 0 |  | Masaru Isonuma, Junichiro Mori, Ichiro Sakata |  |
| 1010 |  |  [Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.668) |  | 0 |  | Zhanming Jie, Wei Lu |  |
| 1011 |  |  [How does the task complexity of masked pretraining objectives affect downstream performance?](https://doi.org/10.18653/v1/2023.findings-acl.669) |  | 0 |  | Atsuki Yamaguchi, Hiroaki Ozaki, Terufumi Morishita, Gaku Morio, Yasuhiro Sogawa |  |
| 1012 |  |  [AUGUST: an Automatic Generation Understudy for Synthesizing Conversational Recommendation Datasets](https://doi.org/10.18653/v1/2023.findings-acl.670) |  | 0 |  | Yu Lu, Junwei Bao, Zichen Ma, Xiaoguang Han, Youzheng Wu, Shuguang Cui, Xiaodong He |  |
| 1013 |  |  [Knowing-how & Knowing-that: A New Task for Machine Comprehension of User Manuals](https://doi.org/10.18653/v1/2023.findings-acl.671) |  | 0 |  | Hongru Liang, Jia Liu, Weihong Du, Dingnan Jin, Wenqiang Lei, Zujie Wen, Jiancheng Lv |  |
| 1014 |  |  [Deep Span Representations for Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.672) |  | 0 |  | Enwei Zhu, Yiyang Liu, Jinpeng Li |  |
| 1015 |  |  [Disambiguated Lexically Constrained Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.673) |  | 0 |  | Jinpeng Zhang, Nini Xiao, Ke Wang, Chuanqi Dong, Xiangyu Duan, Yuqi Zhang, Min Zhang |  |
| 1016 |  |  [Curating Datasets for Better Performance with Example Training Dynamics](https://doi.org/10.18653/v1/2023.findings-acl.674) |  | 0 |  | Aviad SarShalom, Roy Schwartz |  |
| 1017 |  |  [Multi-armed bandits for resource efficient, online optimization of language model pre-training: the use case of dynamic masking](https://doi.org/10.18653/v1/2023.findings-acl.675) |  | 0 |  | Iñigo Urteaga, MoulayZaïdane Draïdia, Tomer Lancewicki, Shahram Khadivi |  |
| 1018 |  |  [ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages](https://doi.org/10.18653/v1/2023.findings-acl.676) |  | 0 |  | Yekun Chai, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu |  |
| 1019 |  |  [PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts](https://doi.org/10.18653/v1/2023.findings-acl.677) |  | 0 |  | Xiangjue Dong, Yun He, Ziwei Zhu, James Caverlee |  |
| 1020 |  |  [Understanding Programs by Exploiting (Fuzzing) Test Cases](https://doi.org/10.18653/v1/2023.findings-acl.678) |  | 0 |  | Jianyu Zhao, Yuyang Rong, Yiwen Guo, Yifeng He, Hao Chen |  |
| 1021 |  |  [Hybrid Hierarchical Retrieval for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.679) |  | 0 |  | Manoj Ghuhan Arivazhagan, Lan Liu, Peng Qi, Xinchi Chen, William Yang Wang, Zhiheng Huang |  |
| 1022 |  |  [Coherent or Not? Stressing a Neural Language Model for Discourse Coherence in Multiple Languages](https://doi.org/10.18653/v1/2023.findings-acl.680) |  | 0 |  | Dominique Brunato, Felice Dell'Orletta, Irene Dini, Andrea Amelio Ravelli |  |
| 1023 |  |  [Understanding Differential Search Index for Text Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.681) |  | 0 |  | Xiaoyang Chen, Yanjiang Liu, Ben He, Le Sun, Yingfei Sun |  |
| 1024 |  |  [Masked Audio Text Encoders are Effective Multi-Modal Rescorers](https://doi.org/10.18653/v1/2023.findings-acl.682) |  | 0 |  | Jinglun Cai, Monica Sunkara, Xilai Li, Anshu Bhatia, Xiao Pan, Sravan Bodapati |  |
| 1025 |  |  [Replace and Report: NLP Assisted Radiology Report Generation](https://doi.org/10.18653/v1/2023.findings-acl.683) |  | 0 |  | Kaveri Kale, Pushpak Bhattacharyya, Kshitij S. Jadhav |  |
| 1026 |  |  [Pre-trained Personalized Review Summarization with Effective Salience Estimation](https://doi.org/10.18653/v1/2023.findings-acl.684) |  | 0 |  | Hongyan Xu, Hongtao Liu, Zhepeng Lv, Qing Yang, Wenjun Wang |  |
| 1027 |  |  [CaPE: Contrastive Parameter Ensembling for Reducing Hallucination in Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.685) |  | 0 |  | Prafulla Kumar Choubey, Alexander R. Fabbri, Jesse Vig, ChienSheng Wu, Wenhao Liu, Nazneen Rajani |  |
| 1028 |  |  [OpineSum: Entailment-based self-training for abstractive opinion summarization](https://doi.org/10.18653/v1/2023.findings-acl.686) |  | 0 |  | Annie Louis, Joshua Maynez |  |
| 1029 |  |  [A Call for Standardization and Validation of Text Style Transfer Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.687) |  | 0 |  | Phil Ostheimer, Mayank Kumar Nagda, Marius Kloft, Sophie Fellenz |  |
| 1030 |  |  [Bridging the Granularity Gap for Acoustic Modeling](https://doi.org/10.18653/v1/2023.findings-acl.688) |  | 0 |  | Chen Xu, Yuhao Zhang, Chengbo Jiao, Xiaoqian Liu, Chi Hu, Xin Zeng, Tong Xiao, Anxiang Ma, Huizhen Wang, Jingbo Zhu |  |
| 1031 |  |  [MMSD2.0: Towards a Reliable Multi-modal Sarcasm Detection System](https://doi.org/10.18653/v1/2023.findings-acl.689) |  | 0 |  | Libo Qin, Shijue Huang, Qiguang Chen, Chenran Cai, Yudi Zhang, Bin Liang, Wanxiang Che, Ruifeng Xu |  |
| 1032 |  |  [Learn to Not Link: Exploring NIL Prediction in Entity Linking](https://doi.org/10.18653/v1/2023.findings-acl.690) |  | 0 |  | Fangwei Zhu, Jifan Yu, Hailong Jin, Lei Hou, Juanzi Li, Zhifang Sui |  |
| 1033 |  |  [On Text-based Personality Computing: Challenges and Future Directions](https://doi.org/10.18653/v1/2023.findings-acl.691) |  | 0 |  | Qixiang Fang, Anastasia Giachanou, Ayoub Bagheri, Laura Boeschoten, ErikJan van Kesteren, Mahdi Shafiee Kamalabad, Daniel L. Oberski |  |
| 1034 |  |  [Structured Pruning for Efficient Generative Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.692) |  | 0 |  | Chaofan Tao, Lu Hou, Haoli Bai, Jiansheng Wei, Xin Jiang, Qun Liu, Ping Luo, Ngai Wong |  |
| 1035 |  |  [Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks](https://doi.org/10.18653/v1/2023.findings-acl.693) |  | 0 |  | Zhicheng Guo, Sijie Cheng, Yile Wang, Peng Li, Yang Liu |  |
| 1036 |  |  [Contextualized Semantic Distance between Highly Overlapped Texts](https://doi.org/10.18653/v1/2023.findings-acl.694) |  | 0 |  | Letian Peng, Zuchao Li, Hai Zhao |  |
| 1037 |  |  [Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training](https://doi.org/10.18653/v1/2023.findings-acl.695) |  | 0 |  | Yibin Lei, Liang Ding, Yu Cao, Changtong Zan, Andrew Yates, Dacheng Tao |  |
| 1038 |  |  [Verifying Annotation Agreement without Multiple Experts: A Case Study with Gujarati SNACS](https://doi.org/10.18653/v1/2023.findings-acl.696) |  | 0 |  | Maitrey Mehta, Vivek Srikumar |  |
| 1039 |  |  [Reinforced Active Learning for Low-Resource, Domain-Specific, Multi-Label Text Classification](https://doi.org/10.18653/v1/2023.findings-acl.697) |  | 0 |  | Lukas Wertz, Jasmina Bogojeska, Katsiaryna Mirylenka, Jonas Kuhn |  |
| 1040 |  |  [Improving Classroom Dialogue Act Recognition from Limited Labeled Data with Self-Supervised Contrastive Learning Classifiers](https://doi.org/10.18653/v1/2023.findings-acl.698) |  | 0 |  | Vikram Kumaran, Jonathan P. Rowe, Bradford W. Mott, Snigdha Chaturvedi, James C. Lester |  |
| 1041 |  |  [Contrastive Token-Wise Meta-Learning for Unseen Performer Visual Temporal-Aligned Translation](https://doi.org/10.18653/v1/2023.findings-acl.699) |  | 0 |  | Linjun Li, Tao Jin, Xize Cheng, Ye Wang, Wang Lin, Rongjie Huang, Zhou Zhao |  |
| 1042 |  |  [Enhancing Cross-lingual Prompting with Dual Prompt Augmentation](https://doi.org/10.18653/v1/2023.findings-acl.700) |  | 0 |  | Meng Zhou, Xin Li, Yue Jiang, Lidong Bing |  |
| 1043 |  |  [Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI](https://doi.org/10.18653/v1/2023.findings-acl.701) |  | 0 |  | Alex Mei, Sharon Levy, William Yang Wang |  |
| 1044 |  |  [Multijugate Dual Learning for Low-Resource Task-Oriented Dialogue System](https://doi.org/10.18653/v1/2023.findings-acl.702) |  | 0 |  | Shimin Li, Xiaotian Zhang, Yanjun Zheng, Linyang Li, Xipeng Qiu |  |
| 1045 |  |  [A Class-Rebalancing Self-Training Framework for Distantly-Supervised Named Entity Recognition](https://doi.org/10.18653/v1/2023.findings-acl.703) |  | 0 |  | Qi Li, Tingyu Xie, Peng Peng, Hongwei Wang, Gaoang Wang |  |
| 1046 |  |  [MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation](https://doi.org/10.18653/v1/2023.findings-acl.704) |  | 0 |  | Swarnadeep Saha, Xinyan Yu, Mohit Bansal, Ramakanth Pasunuru, Asli Celikyilmaz |  |
| 1047 |  |  [Learning by Analogy: Diverse Questions Generation in Math Word Problem](https://doi.org/10.18653/v1/2023.findings-acl.705) |  | 0 |  | Zihao Zhou, Maizhen Ning, Qiufeng Wang, Jie Yao, Wei Wang, Xiaowei Huang, Kaizhu Huang |  |
| 1048 |  |  [Revisit Few-shot Intent Classification with PLMs: Direct Fine-tuning vs. Continual Pre-training](https://doi.org/10.18653/v1/2023.findings-acl.706) |  | 0 |  | Haode Zhang, Haowen Liang, LiMing Zhan, XiaoMing Wu, Albert Y. S. Lam |  |
| 1049 |  |  [Improving Contrastive Learning of Sentence Embeddings from AI Feedback](https://doi.org/10.18653/v1/2023.findings-acl.707) |  | 0 |  | Qinyuan Cheng, Xiaogui Yang, Tianxiang Sun, Linyang Li, Xipeng Qiu |  |
| 1050 |  |  [Mars: Modeling Context & State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog](https://doi.org/10.18653/v1/2023.findings-acl.708) |  | 0 |  | Haipeng Sun, Junwei Bao, Youzheng Wu, Xiaodong He |  |
| 1051 |  |  [Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.709) |  | 0 |  | Pengcheng Jiang, Shivam Agarwal, Bowen Jin, Xuan Wang, Jimeng Sun, Jiawei Han |  |
| 1052 |  |  [Discourse Analysis via Questions and Answers: Parsing Dependency Structures of Questions Under Discussion](https://doi.org/10.18653/v1/2023.findings-acl.710) |  | 0 |  | WeiJen Ko, Yating Wu, Cutter Dalton, Dananjay Srinivas, Greg Durrett, Junyi Jessy Li |  |
| 1053 |  |  [An Integrated Approach for Political Bias Prediction and Explanation Based on Discursive Structure](https://doi.org/10.18653/v1/2023.findings-acl.711) |  | 0 |  | Nicolas Devatine, Philippe Muller, Chloé Braud |  |
| 1054 |  |  [Smart Word Suggestions for Writing Assistance](https://doi.org/10.18653/v1/2023.findings-acl.712) |  | 0 |  | Chenshuo Wang, Shaoguang Mao, Tao Ge, Wenshan Wu, Xun Wang, Yan Xia, Jonathan Tien, Dongyan Zhao |  |
| 1055 |  |  [JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions](https://doi.org/10.18653/v1/2023.findings-acl.713) |  | 0 |  | Mo Yu, Yi Gu, Xiaoxiao Guo, Yufei Feng, Xiaodan Zhu, Michael A. Greenspan, Murray Campbell, Chuang Gan |  |
| 1056 |  |  [A Study on Knowledge Distillation from Weak Teacher for Scaling Up Pre-trained Language Models](https://doi.org/10.18653/v1/2023.findings-acl.714) |  | 0 |  | Hayeon Lee, Rui Hou, Jongpil Kim, Davis Liang, Sung Ju Hwang, Alexander Min |  |
| 1057 |  |  [SORTIE: Dependency-Aware Symbolic Reasoning for Logical Data-to-text Generation](https://doi.org/10.18653/v1/2023.findings-acl.715) |  | 0 |  | Xueliang Zhao, Tingchen Fu, Lemao Liu, Lingpeng Kong, Shuming Shi, Rui Yan |  |
| 1058 |  |  [Boosting Event Extraction with Denoised Structure-to-Text Augmentation](https://doi.org/10.18653/v1/2023.findings-acl.716) |  | 0 |  | Bo Wang, Heyan Huang, Xiaochi Wei, Ge Shi, Xiao Liu, Chong Feng, Tong Zhou, Shuaiqiang Wang, Dawei Yin |  |
| 1059 |  |  [Detecting Adversarial Samples through Sharpness of Loss Landscape](https://doi.org/10.18653/v1/2023.findings-acl.717) |  | 0 |  | Rui Zheng, Shihan Dou, Yuhao Zhou, Qin Liu, Tao Gui, Qi Zhang, Zhongyu Wei, Xuanjing Huang, Menghan Zhang |  |
| 1060 |  |  [A Simple, Yet Effective Approach to Finding Biases in Code Generation](https://doi.org/10.18653/v1/2023.findings-acl.718) |  | 0 |  | Spyridon Mouselinos, Mateusz Malinowski, Henryk Michalewski |  |
| 1061 |  |  [Membership Inference Attacks against Language Models via Neighbourhood Comparison](https://doi.org/10.18653/v1/2023.findings-acl.719) |  | 0 |  | Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, Bernhard Schölkopf, Mrinmaya Sachan, Taylor BergKirkpatrick |  |
| 1062 |  |  [CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation](https://doi.org/10.18653/v1/2023.findings-acl.720) |  | 0 |  | Rahul Madhavan, Rishabh Garg, Kahini Wadhawan, Sameep Mehta |  |
| 1063 |  |  [Can Diffusion Model Achieve Better Performance in Text Generation ? Bridging the Gap between Training and Inference !](https://doi.org/10.18653/v1/2023.findings-acl.721) |  | 0 |  | Zecheng Tang, Pinzheng Wang, Keyan Zhou, Juntao Li, Ziqiang Cao, Min Zhang |  |
| 1064 |  |  [Topic-Guided Self-Introduction Generation for Social Media Users](https://doi.org/10.18653/v1/2023.findings-acl.722) |  | 0 |  | Chunpu Xu, Jing Li, Piji Li, Min Yang |  |
| 1065 |  |  [Recyclable Tuning for Continual Pre-training](https://doi.org/10.18653/v1/2023.findings-acl.723) |  | 0 |  | Yujia Qin, Cheng Qian, Xu Han, Yankai Lin, Huadong Wang, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou |  |
| 1066 |  |  [BLOCSUM: Block Scope-based Source Code Summarization via Shared Block Representation](https://doi.org/10.18653/v1/2023.findings-acl.724) |  | 0 |  | YunSeok Choi, Hyojun Kim, JeeHyong Lee |  |
| 1067 |  |  [HyperPELT: Unified Parameter-Efficient Language Model Tuning for Both Language and Vision-and-Language Tasks](https://doi.org/10.18653/v1/2023.findings-acl.725) |  | 0 |  | Zhengkun Zhang, Wenya Guo, Xiaojun Meng, Yasheng Wang, Yadao Wang, Xin Jiang, Qun Liu, Zhenglu Yang |  |
| 1068 |  |  [Enhancing Unsupervised Semantic Parsing with Distributed Contextual Representations](https://doi.org/10.18653/v1/2023.findings-acl.726) |  | 0 |  | Zixuan Ling, Xiaoqing Zheng, Jianhan Xu, Jinshu Lin, KaiWei Chang, ChoJui Hsieh, Xuanjing Huang |  |
| 1069 |  |  [Generating Labeled Data for Relation Extraction: A Meta Learning Approach with Joint GPT-2 Training](https://doi.org/10.18653/v1/2023.findings-acl.727) |  | 0 |  | Amir Pouran Ben Veyseh, Franck Dernoncourt, Bonan Min, Thien Huu Nguyen |  |
| 1070 |  |  [Disfluency Generation for More Robust Dialogue Systems](https://doi.org/10.18653/v1/2023.findings-acl.728) |  | 0 |  | Benjamin Marie |  |
| 1071 |  |  [Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge Graph Completion via Conditional Soft Prompting](https://doi.org/10.18653/v1/2023.findings-acl.729) |  | 0 |  | Chen Chen, Yufei Wang, Aixin Sun, Bing Li, KwokYan Lam |  |
| 1072 |  |  [Revisiting Pathologies of Neural Models under Input Reduction](https://doi.org/10.18653/v1/2023.findings-acl.730) |  | 0 |  | Canasai Kruengkrai, Junichi Yamagishi |  |
| 1073 |  |  [Lego-MT: Learning Detachable Models for Massively Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.731) |  | 0 |  | Fei Yuan, Yinquan Lu, Wenhao Zhu, Lingpeng Kong, Lei Li, Yu Qiao, Jingjing Xu |  |
| 1074 |  |  [FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference](https://doi.org/10.18653/v1/2023.findings-acl.732) |  | 0 |  | Michiel de Jong, Yury Zemlyanskiy, Joshua Ainslie, Nicholas FitzGerald, Sumit Sanghai, Fei Sha, William W. Cohen |  |
| 1075 |  |  [Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark](https://doi.org/10.18653/v1/2023.findings-acl.733) |  | 0 |  | Jason HoelscherObermaier, Julia Persson, Esben Kran, Ioannis Konstas, Fazl Barez |  |
| 1076 |  |  [Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data](https://doi.org/10.18653/v1/2023.findings-acl.734) |  | 0 |  | Xinze Li, Zhenghao Liu, Chenyan Xiong, Shi Yu, Yu Gu, Zhiyuan Liu, Ge Yu |  |
| 1077 |  |  [Few-shot Joint Multimodal Aspect-Sentiment Analysis Based on Generative Multimodal Prompt](https://doi.org/10.18653/v1/2023.findings-acl.735) |  | 0 |  | Xiaocui Yang, Shi Feng, Daling Wang, Qi Sun, Wenfang Wu, Yifei Zhang, Pengfei Hong, Soujanya Poria |  |
| 1078 |  |  [Predicting Human Translation Difficulty Using Automatic Word Alignment](https://doi.org/10.18653/v1/2023.findings-acl.736) |  | 0 |  | Zheng Wei Lim, Trevor Cohn, Charles Kemp, Ekaterina Vylomova |  |
| 1079 |  |  [Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2023.findings-acl.737) |  | 0 |  | Mozhdeh Gheini, Xuezhe Ma, Jonathan May |  |
| 1080 |  |  [Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking](https://doi.org/10.18653/v1/2023.findings-acl.738) |  | 0 |  | Keshav Santhanam, Jon SaadFalcon, Martin Franz, Omar Khattab, Avi Sil, Radu Florian, Md. Arafat Sultan, Salim Roukos, Matei Zaharia, Christopher Potts |  |
| 1081 |  |  [AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese](https://doi.org/10.18653/v1/2023.findings-acl.739) |  | 0 |  | Abhijnan Nath, Sheikh Mannan, Nikhil Krishnaswamy |  |
| 1082 |  |  [An Exploratory Study on Model Compression for Text-to-SQL](https://doi.org/10.18653/v1/2023.findings-acl.740) |  | 0 |  | Shuo Sun, Yuze Gao, Yuchen Zhang, Jian Su, Bin Chen, Yingzhan Lin, Shuqi Sun |  |
| 1083 |  |  [FluentSpeech: Stutter-Oriented Automatic Speech Editing with Context-Aware Diffusion Models](https://doi.org/10.18653/v1/2023.findings-acl.741) |  | 0 |  | Ziyue Jiang, Qian Yang, Jialong Zuo, Zhenhui Ye, Rongjie Huang, Yi Ren, Zhou Zhao |  |
| 1084 |  |  [HyHTM: Hyperbolic Geometry-based Hierarchical Topic Model](https://doi.org/10.18653/v1/2023.findings-acl.742) |  | 0 |  | Simra Shahid, Tanay Anand, Nikitha Srikanth, Sumit Bhatia, Balaji Krishnamurthy, Nikaash Puri |  |
| 1085 |  |  [KoRC: Knowledge Oriented Reading Comprehension Benchmark for Deep Text Understanding](https://doi.org/10.18653/v1/2023.findings-acl.743) |  | 0 |  | Zijun Yao, Yantao Liu, Xin Lv, Shulin Cao, Jifan Yu, Juanzi Li, Lei Hou |  |
| 1086 |  |  [DKAF: KB Arbitration for Learning Task-Oriented Dialog Systems with Dialog-KB Inconsistencies](https://doi.org/10.18653/v1/2023.findings-acl.744) |  | 0 |  | Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu, Mausam |  |
| 1087 |  |  [Scale-Invariant Infinite Hierarchical Topic Model](https://doi.org/10.18653/v1/2023.findings-acl.745) |  | 0 |  | Shusei Eshima, Daichi Mochihashi |  |
| 1088 |  |  [RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training](https://doi.org/10.18653/v1/2023.findings-acl.746) |  | 0 |  | Chulun Zhou, Yunlong Liang, Fandong Meng, Jinan Xu, Jinsong Su, Jie Zhou |  |
| 1089 |  |  [Deep Equilibrium Non-Autoregressive Sequence Learning](https://doi.org/10.18653/v1/2023.findings-acl.747) |  | 0 |  | Zaixiang Zheng, Yi Zhou, Hao Zhou |  |
| 1090 |  |  [ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.748) |  | 0 |  | Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, Chao Zhang |  |
| 1091 |  |  [Race, Gender, and Age Biases in Biomedical Masked Language Models](https://doi.org/10.18653/v1/2023.findings-acl.749) |  | 0 |  | Michelle Kim, Junghwan Kim, Kristen Marie Johnson |  |
| 1092 |  |  [Neighboring Words Affect Human Interpretation of Saliency Explanations](https://doi.org/10.18653/v1/2023.findings-acl.750) |  | 0 |  | Alon Jacovi, Hendrik Schuff, Heike Adel, Ngoc Thang Vu, Yoav Goldberg |  |
| 1093 |  |  [HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models](https://doi.org/10.18653/v1/2023.findings-acl.751) |  | 0 |  | Swaroop Mishra, Elnaz Nouri |  |
| 1094 |  |  [Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification](https://doi.org/10.18653/v1/2023.findings-acl.752) |  | 0 |  | Anni Zou, Zhuosheng Zhang, Hai Zhao |  |
| 1095 |  |  [DopplerBAS: Binaural Audio Synthesis Addressing Doppler Effect](https://doi.org/10.18653/v1/2023.findings-acl.753) |  | 0 |  | Jinglin Liu, Zhenhui Ye, Qian Chen, Siqi Zheng, Wen Wang, Qinglin Zhang, Zhou Zhao |  |
| 1096 |  |  [Easy-to-Hard Learning for Information Extraction](https://doi.org/10.18653/v1/2023.findings-acl.754) |  | 0 |  | Chang Gao, Wenxuan Zhang, Wai Lam, Lidong Bing |  |
| 1097 |  |  [SConE: Simplified Cone Embeddings with Symbolic Operators for Complex Logical Queries](https://doi.org/10.18653/v1/2023.findings-acl.755) |  | 0 |  | Chau D. M. Nguyen, Tim French, Wei Liu, Michael Stewart |  |
| 1098 |  |  [Two Heads Are Better Than One: Improving Fake News Video Detection by Correlating with Neighbors](https://doi.org/10.18653/v1/2023.findings-acl.756) |  | 0 |  | Peng Qi, Yuyang Zhao, Yufeng Shen, Wei Ji, Juan Cao, TatSeng Chua |  |
| 1099 |  |  [An Annotated Dataset for Explainable Interpersonal Risk Factors of Mental Disturbance in Social Media Posts](https://doi.org/10.18653/v1/2023.findings-acl.757) |  | 0 |  | Muskan Garg, Amirmohammad Shahbandegan, Amrit Chadha, Vijay Mago |  |
| 1100 |  |  [Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control](https://doi.org/10.18653/v1/2023.findings-acl.758) |  | 0 |  | Xiang Fan, Yiwei Lyu, Paul Pu Liang, Ruslan Salakhutdinov, LouisPhilippe Morency |  |
| 1101 |  |  [Connectivity Patterns are Task Embeddings](https://doi.org/10.18653/v1/2023.findings-acl.759) |  | 0 |  | Zhiheng Xi, Rui Zheng, Yuansen Zhang, Xuanjing Huang, Zhongyu Wei, Minlong Peng, Mingming Sun, Qi Zhang, Tao Gui |  |
| 1102 |  |  [Improving Autoregressive Grammatical Error Correction with Non-autoregressive Models](https://doi.org/10.18653/v1/2023.findings-acl.760) |  | 0 |  | Hang Cao, Zhiquan Cao, Chi Hu, Baoyu Hou, Tong Xiao, Jingbo Zhu |  |
| 1103 |  |  [SamToNe: Improving Contrastive Loss for Dual Encoder Retrieval Models with Same Tower Negatives](https://doi.org/10.18653/v1/2023.findings-acl.761) |  | 0 |  | Fedor Moiseev, Gustavo Hernández Abrego, Péter Dornbach, Imed Zitouni, Enrique Alfonseca, Zhe Dong |  |
| 1104 |  |  [On the Strength of Sequence Labeling and Generative Models for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2023.findings-acl.762) |  | 0 |  | Shen Zhou, Tieyun Qian |  |
| 1105 |  |  [Revisiting Non-Autoregressive Translation at Scale](https://doi.org/10.18653/v1/2023.findings-acl.763) |  | 0 |  | Zhihao Wang, Longyue Wang, Jinsong Su, Junfeng Yao, Zhaopeng Tu |  |
| 1106 |  |  [Improving Radiology Summarization with Radiograph and Anatomy Prompts](https://doi.org/10.18653/v1/2023.findings-acl.764) |  | 0 |  | Jinpeng Hu, Zhihong Chen, Yang Liu, Xiang Wan, TsungHui Chang |  |
| 1107 |  |  [Explanation Regeneration via Information Bottleneck](https://doi.org/10.18653/v1/2023.findings-acl.765) |  | 0 |  | Qintong Li, Zhiyong Wu, Lingpeng Kong, Wei Bi |  |
| 1108 |  |  [Improving Zero-shot Multilingual Neural Machine Translation by Leveraging Cross-lingual Consistency Regularization](https://doi.org/10.18653/v1/2023.findings-acl.766) |  | 0 |  | Pengzhi Gao, Liwen Zhang, Zhongjun He, Hua Wu, Haifeng Wang |  |
| 1109 |  |  [ReactIE: Enhancing Chemical Reaction Extraction with Weak Supervision](https://doi.org/10.18653/v1/2023.findings-acl.767) |  | 0 |  | Ming Zhong, Siru Ouyang, Minhao Jiang, Vivian Hu, Yizhu Jiao, Xuan Wang, Jiawei Han |  |
| 1110 |  |  [Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.768) |  | 0 |  | YungSung Chuang, Wei Fang, ShangWen Li, Wentau Yih, James R. Glass |  |
| 1111 |  |  [Neural Networks Against (and For) Self-Training: Classification with Small Labeled and Large Unlabeled Sets](https://doi.org/10.18653/v1/2023.findings-acl.769) |  | 0 |  | Payam Karisani |  |
| 1112 |  |  [Inducing Character-level Structure in Subword-based Language Models with Type-level Interchange Intervention Training](https://doi.org/10.18653/v1/2023.findings-acl.770) |  | 0 |  | Jing Huang, Zhengxuan Wu, Kyle Mahowald, Christopher Potts |  |
| 1113 |  |  [Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning](https://doi.org/10.18653/v1/2023.findings-acl.771) |  | 0 |  | Daniel Saggau, Mina Rezaei, Bernd Bischl, Ilias Chalkidis |  |
| 1114 |  |  [QAP: A Quantum-Inspired Adaptive-Priority-Learning Model for Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2023.findings-acl.772) |  | 0 |  | Ziming Li, Yan Zhou, Yaxin Liu, Fuqing Zhu, Chuanpeng Yang, Songlin Hu |  |
| 1115 |  |  [Language acquisition: do children and language models follow similar learning stages?](https://doi.org/10.18653/v1/2023.findings-acl.773) |  | 0 |  | Linnea Evanson, Yair Lakretz, JeanRémi King |  |
| 1116 |  |  [The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing](https://doi.org/10.18653/v1/2023.findings-acl.774) |  | 0 |  | Debayan Banerjee, Pranav Ajit Nair, Ricardo Usbeck, Chris Biemann |  |
| 1117 |  |  [UniCOQE: Unified Comparative Opinion Quintuple Extraction As A Set](https://doi.org/10.18653/v1/2023.findings-acl.775) |  | 0 |  | Zinong Yang, Feng Xu, Jianfei Yu, Rui Xia |  |
| 1118 |  |  [Response-conditioned Turn-taking Prediction](https://doi.org/10.18653/v1/2023.findings-acl.776) |  | 0 |  | Bing'er Jiang, Erik Ekstedt, Gabriel Skantze |  |
| 1119 |  |  [A Unified One-Step Solution for Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2023.findings-acl.777) |  | 0 |  | Junxian Zhou, Haiqin Yang, Yuxuan He, Hao Mou, Junbo Yang |  |
| 1120 |  |  [On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning](https://doi.org/10.18653/v1/2023.findings-acl.778) |  | 0 |  | Chenghao Xiao, Yang Long, Noura Al Moubayed |  |
| 1121 |  |  [Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.779) |  | 0 |  | Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, Yanai Elazar |  |
| 1122 |  |  [Common Law Annotations: Investigating the Stability of Dialog System Output Annotations](https://doi.org/10.18653/v1/2023.findings-acl.780) |  | 0 |  | Seunggun Lee, Alexandra DeLucia, Nikita Nangia, Praneeth Ganedi, Ryan Guan, Rubing Li, Britney Ngaw, Aditya Singhal, Shalaka Vaidya, Zijun Yuan, Lining Zhang, João Sedoc |  |
| 1123 |  |  [HuaSLIM: Human Attention Motivated Shortcut Learning Identification and Mitigation for Large Language models](https://doi.org/10.18653/v1/2023.findings-acl.781) |  | 0 |  | Yuqi Ren, Deyi Xiong |  |
| 1124 |  |  [PMI-Align: Word Alignment With Point-Wise Mutual Information Without Requiring Parallel Training Data](https://doi.org/10.18653/v1/2023.findings-acl.782) |  | 0 |  | Fatemeh Azadi, Heshaam Faili, Mohammad Javad Dousti |  |
| 1125 |  |  [Exploring Non-Verbal Predicates in Semantic Role Labeling: Challenges and Opportunities](https://doi.org/10.18653/v1/2023.findings-acl.783) |  | 0 |  | Riccardo Orlando, Simone Conia, Roberto Navigli |  |
| 1126 |  |  [DSPM-NLG: A Dual Supervised Pre-trained Model for Few-shot Natural Language Generation in Task-oriented Dialogue System](https://doi.org/10.18653/v1/2023.findings-acl.784) |  | 0 |  | Yufan Wang, Bowei Zou, Rui Fan, Ai Ti Aw, Tingting He |  |
| 1127 |  |  [TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.findings-acl.785) |  | 0 |  | Wei Xiang, Chao Liang, Bang Wang |  |
| 1128 |  |  [Evaluating Factuality in Cross-lingual Summarization](https://doi.org/10.18653/v1/2023.findings-acl.786) |  | 0 |  | Mingqi Gao, Wenqing Wang, Xiaojun Wan, Yuemei Xu |  |
| 1129 |  |  [On the Correspondence between Compositionality and Imitation in Emergent Neural Communication](https://doi.org/10.18653/v1/2023.findings-acl.787) |  | 0 |  | Emily Cheng, Mathieu Rita, Thierry Poibeau |  |
| 1130 |  |  [The Coreference under Transformation Labeling Dataset: Entity Tracking in Procedural Texts Using Event Models](https://doi.org/10.18653/v1/2023.findings-acl.788) |  | 0 |  | Kyeongmin Rim, Jingxuan Tu, Bingyang Ye, Marc Verhagen, Eben Holderness, James Pustejovsky |  |
| 1131 |  |  [Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a Solution](https://doi.org/10.18653/v1/2023.findings-acl.789) |  | 0 |  | Tianjian Li, Kenton Murray |  |
| 1132 |  |  [Distractor Generation based on Text2Text Language Models with Pseudo Kullback-Leibler Divergence Regulation](https://doi.org/10.18653/v1/2023.findings-acl.790) |  | 0 |  | HuiJuan Wang, KaiYu Hsieh, HanCheng Yu, JuiChing Tsou, YuAn Shih, ChenHua Huang, YaoChung Fan |  |
| 1133 |  |  [Lexical Translation Inconsistency-Aware Document-Level Translation Repair](https://doi.org/10.18653/v1/2023.findings-acl.791) |  | 0 |  | Zhen Zhang, Junhui Li, Shimin Tao, Hao Yang |  |
| 1134 |  |  [CausalDialogue: Modeling Utterance-level Causality in Conversations](https://doi.org/10.18653/v1/2023.findings-acl.792) |  | 0 |  | YiLin Tuan, Alon Albalak, Wenda Xu, Michael Saxon, Connor Pryor, Lise Getoor, William Yang Wang |  |
| 1135 |  |  [Towards Unified Spoken Language Understanding Decoding via Label-aware Compact Linguistics Representations](https://doi.org/10.18653/v1/2023.findings-acl.793) |  | 0 |  | Zhihong Zhu, Xuxin Cheng, Zhiqi Huang, Dongsheng Chen, Yuexian Zou |  |
| 1136 |  |  [Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses](https://doi.org/10.18653/v1/2023.findings-acl.794) |  | 0 |  | Liyan Tang, Yifan Peng, Yanshan Wang, Ying Ding, Greg Durrett, Justin F. Rousseau |  |
| 1137 |  |  [Language Modeling with Latent Situations](https://doi.org/10.18653/v1/2023.findings-acl.795) |  | 0 |  | Belinda Z. Li, Maxwell I. Nye, Jacob Andreas |  |
| 1138 |  |  [Can Cross-Lingual Transferability of Multilingual Transformers Be Activated Without End-Task Data?](https://doi.org/10.18653/v1/2023.findings-acl.796) |  | 0 |  | Zewen Chi, Heyan Huang, XianLing Mao |  |
| 1139 |  |  [Focus-aware Response Generation in Inquiry Conversation](https://doi.org/10.18653/v1/2023.findings-acl.797) |  | 0 |  | Yiquan Wu, Weiming Lu, Yating Zhang, Adam Jatowt, Jun Feng, Changlong Sun, Fei Wu, Kun Kuang |  |
| 1140 |  |  [A Hierarchical Explanation Generation Method Based on Feature Interaction Detection](https://doi.org/10.18653/v1/2023.findings-acl.798) |  | 0 |  | Yiming Ju, Yuanzhe Zhang, Kang Liu, Jun Zhao |  |
| 1141 |  |  [Jointly Reparametrized Multi-Layer Adaptation for Efficient and Private Tuning](https://doi.org/10.18653/v1/2023.findings-acl.799) |  | 0 |  | Umang Gupta, Aram Galstyan, Greg Ver Steeg |  |
| 1142 |  |  [A Diffusion Model for Event Skeleton Generation](https://doi.org/10.18653/v1/2023.findings-acl.800) |  | 0 |  | Fangqi Zhu, Lin Zhang, Jun Gao, Bing Qin, Ruifeng Xu, Haiqin Yang |  |
| 1143 |  |  [Nonparametric Decoding for Generative Retrieval](https://doi.org/10.18653/v1/2023.findings-acl.801) |  | 0 |  | Hyunji Lee, Jaeyoung Kim, Hoyeon Chang, Hanseok Oh, Sohee Yang, Vladimir Karpukhin, Yi Lu, Minjoon Seo |  |
| 1144 |  |  [Aspect-aware Unsupervised Extractive Opinion Summarization](https://doi.org/10.18653/v1/2023.findings-acl.802) |  | 0 |  | Haoyuan Li, Somnath Basu Roy Chowdhury, Snigdha Chaturvedi |  |
| 1145 |  |  [GNN-SL: Sequence Labeling Based on Nearest Examples via GNN](https://doi.org/10.18653/v1/2023.findings-acl.803) |  | 0 |  | Shuhe Wang, Yuxian Meng, Rongbin Ouyang, Jiwei Li, Tianwei Zhang, Lingjuan Lyu, Guoyin Wang |  |
| 1146 |  |  [Serial Contrastive Knowledge Distillation for Continual Few-shot Relation Extraction](https://doi.org/10.18653/v1/2023.findings-acl.804) |  | 0 |  | Xinyi Wang, Zitao Wang, Wei Hu |  |
| 1147 |  |  [Revisiting the Architectures like Pointer Networks to Efficiently Improve the Next Word Distribution, Summarization Factuality, and Beyond](https://doi.org/10.18653/v1/2023.findings-acl.805) |  | 0 |  | HawShiuan Chang, Zonghai Yao, Alolika Gon, Hong Yu, Andrew McCallum |  |
| 1148 |  |  [GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective](https://doi.org/10.18653/v1/2023.findings-acl.806) |  | 0 |  | Linyi Yang, Shuibai Zhang, Libo Qin, Yafu Li, Yidong Wang, Hanmeng Liu, Jindong Wang, Xing Xie, Yue Zhang |  |
| 1149 |  |  [Investigating the Saliency of Sentiment Expressions in Aspect-Based Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.807) |  | 0 |  | Joachim Wagner, Jennifer Foster |  |
| 1150 |  |  [DMLM: Descriptive Masked Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.808) |  | 0 |  | Edoardo Barba, Niccolò Campolungo, Roberto Navigli |  |
| 1151 |  |  [Reproducibility in NLP: What Have We Learned from the Checklist?](https://doi.org/10.18653/v1/2023.findings-acl.809) |  | 0 |  | Ian Magnusson, Noah A. Smith, Jesse Dodge |  |
| 1152 |  |  [Domain Generalization via Switch Knowledge Distillation for Robust Review Representation](https://doi.org/10.18653/v1/2023.findings-acl.810) |  | 0 |  | You Zhang, Jin Wang, LiangChih Yu, Dan Xu, Xuejie Zhang |  |
| 1153 |  |  [On Search Strategies for Document-Level Neural Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.811) |  | 0 |  | Christian Herold, Hermann Ney |  |
| 1154 |  |  [Causal Intervention for Mitigating Name Bias in Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.findings-acl.812) |  | 0 |  | Jiazheng Zhu, Shaojuan Wu, Xiaowang Zhang, Yuexian Hou, Zhiyong Feng |  |
| 1155 |  |  [Counterfactual Probing for the Influence of Affect and Specificity on Intergroup Bias](https://doi.org/10.18653/v1/2023.findings-acl.813) |  | 0 |  | Venkata Subrahmanyan Govindarajan, David Beaver, Kyle Mahowald, Junyi Jessy Li |  |
| 1156 |  |  [SongRewriter: A Chinese Song Rewriting System with Controllable Content and Rhyme Scheme](https://doi.org/10.18653/v1/2023.findings-acl.814) |  | 0 |  | Yusen Sun, Liangyou Li, Qun Liu, DitYan Yeung |  |
| 1157 |  |  [Triplet-Free Knowledge-Guided Response Generation](https://doi.org/10.18653/v1/2023.findings-acl.815) |  | 0 |  | Dongming Li, Jianfeng Liu, Baoyuan Wang |  |
| 1158 |  |  [Implicit Memory Transformer for Computationally Efficient Simultaneous Speech Translation](https://doi.org/10.18653/v1/2023.findings-acl.816) |  | 0 |  | Matthew Raffel, Lizhong Chen |  |
| 1159 |  |  [Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance](https://doi.org/10.18653/v1/2023.findings-acl.817) |  | 0 |  | Wanlong Liu, Shaohuan Cheng, Dingyi Zeng, Hong Qu |  |
| 1160 |  |  [Exploring the Impact of Vision Features in News Image Captioning](https://doi.org/10.18653/v1/2023.findings-acl.818) |  | 0 |  | Junzhe Zhang, Xiaojun Wan |  |
| 1161 |  |  [Using Collostructional Analysis to evaluate BERT's representation of linguistic constructions](https://doi.org/10.18653/v1/2023.findings-acl.819) |  | 0 |  | Tim Veenboer, Jelke Bloem |  |
| 1162 |  |  [Selecting Better Samples from Pre-trained LLMs: A Case Study on Question Generation](https://doi.org/10.18653/v1/2023.findings-acl.820) |  | 0 |  | Xingdi Yuan, Tong Wang, YenHsiang Wang, Emery Fine, Rania Abdelghani, Hélène Sauzéon, PierreYves Oudeyer |  |
| 1163 |  |  [Sentiment Knowledge Enhanced Self-supervised Learning for Multimodal Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.821) |  | 0 |  | Fan Qian, Jiqing Han, Yongjun He, Tieran Zheng, Guibin Zheng |  |
| 1164 |  |  [Theory of Mind in Freely-Told Children's Narratives: A Classification Approach](https://doi.org/10.18653/v1/2023.findings-acl.822) |  | 0 |  | Bram van Dijk, Marco Spruit, Max J. van Duijn |  |
| 1165 |  |  [Better Language Models of Code through Self-Improvement](https://doi.org/10.18653/v1/2023.findings-acl.823) |  | 0 |  | Hung Quoc To, Nghi D. Q. Bui, Jin L. C. Guo, Tien N. Nguyen |  |
| 1166 |  |  [Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them](https://doi.org/10.18653/v1/2023.findings-acl.824) |  | 0 |  | Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, Jason Wei |  |
| 1167 |  |  [Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays](https://doi.org/10.18653/v1/2023.findings-acl.825) |  | 0 |  | Yuning Ding, Marie Bexte, Andrea Horbach |  |
| 1168 |  |  [Data Sampling and (In)stability in Machine Translation Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.826) |  | 0 |  | Chikiu Lo, Rebecca Knowles |  |
| 1169 |  |  [Probing Graph Decomposition for Argument Pair Extraction](https://doi.org/10.18653/v1/2023.findings-acl.827) |  | 0 |  | Yang Sun, Bin Liang, Jianzhu Bao, Yice Zhang, Geng Tu, Min Yang, Ruifeng Xu |  |
| 1170 |  |  [DiffuSum: Generation Enhanced Extractive Summarization with Diffusion](https://doi.org/10.18653/v1/2023.findings-acl.828) |  | 0 |  | Haopeng Zhang, Xiao Liu, Jiawei Zhang |  |
| 1171 |  |  [Towards Parameter-Efficient Integration of Pre-Trained Language Models In Temporal Video Grounding](https://doi.org/10.18653/v1/2023.findings-acl.829) |  | 0 |  | Erica Kido Shimomoto, Edison MarreseTaylor, Hiroya Takamura, Ichiro Kobayashi, Hideki Nakayama, Yusuke Miyao |  |
| 1172 |  |  [A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information](https://doi.org/10.18653/v1/2023.findings-acl.830) |  | 0 |  | Vladimir Araujo, Alvaro Soto, MarieFrancine Moens |  |
| 1173 |  |  [Pay Attention to Implicit Attribute Values: A Multi-modal Generative Framework for AVE Task](https://doi.org/10.18653/v1/2023.findings-acl.831) |  | 0 |  | Yupeng Zhang, Shensi Wang, Peiguang Li, Guanting Dong, Sirui Wang, Yunsen Xian, Zhoujun Li, Hongzhi Zhang |  |
| 1174 |  |  [CoRRPUS: Code-based Structured Prompting for Neurosymbolic Story Understanding](https://doi.org/10.18653/v1/2023.findings-acl.832) |  | 0 |  | Yijiang River Dong, Lara J. Martin, Chris CallisonBurch |  |
| 1175 |  |  [Fighting Bias With Bias: Promoting Model Robustness by Amplifying Dataset Biases](https://doi.org/10.18653/v1/2023.findings-acl.833) |  | 0 |  | Yuval Reif, Roy Schwartz |  |
| 1176 |  |  [Context-Aware Document Simplification](https://doi.org/10.18653/v1/2023.findings-acl.834) |  | 0 |  | Liam Cripwell, Joël Legrand, Claire Gardent |  |
| 1177 |  |  [Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering](https://doi.org/10.18653/v1/2023.findings-acl.835) |  | 0 |  | Qianglong Chen, Guohai Xu, Ming Yan, Ji Zhang, Fei Huang, Luo Si, Yin Zhang |  |
| 1178 |  |  [Abstract then Play: A Skill-centric Reinforcement Learning Framework for Text-based Games](https://doi.org/10.18653/v1/2023.findings-acl.836) |  | 0 |  | Anjie Zhu, PengFei Zhang, Yi Zhang, Zi Huang, Jie Shao |  |
| 1179 |  |  [SSP: Self-Supervised Post-training for Conversational Search](https://doi.org/10.18653/v1/2023.findings-acl.837) |  | 0 |  | Quan Tu, Shen Gao, Xiaolong Wu, Zhao Cao, JiRong Wen, Rui Yan |  |
| 1180 |  |  [Towards Reference-free Text Simplification Evaluation with a BERT Siamese Network Architecture](https://doi.org/10.18653/v1/2023.findings-acl.838) |  | 0 |  | Xinran Zhao, Esin Durmus, DitYan Yeung |  |
| 1181 |  |  [Causal interventions expose implicit situation models for commonsense language understanding](https://doi.org/10.18653/v1/2023.findings-acl.839) |  | 0 |  | Takateru Yamakoshi, James L. McClelland, Adele Goldberg, Robert D. Hawkins |  |
| 1182 |  |  [Iterative Nearest Neighbour Machine Translation for Unsupervised Domain Adaptation](https://doi.org/10.18653/v1/2023.findings-acl.840) |  | 0 |  | Hui Huang, Shuangzhi Wu, Xinnian Liang, Zefan Zhou, Muyun Yang, Tiejun Zhao |  |
| 1183 |  |  [PruMUX: Augmenting Data Multiplexing with Model Compression](https://doi.org/10.18653/v1/2023.findings-acl.841) |  | 0 |  | Yushan Su, Vishvak Murahari, Karthik Narasimhan, Kai Li |  |
| 1184 |  |  [With Prejudice to None: A Few-Shot, Multilingual Transfer Learning Approach to Detect Social Bias in Low Resource Languages](https://doi.org/10.18653/v1/2023.findings-acl.842) |  | 0 |  | Nihar Sahoo, Niteesh Mallela, Pushpak Bhattacharyya |  |
| 1185 |  |  [Don't Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness](https://doi.org/10.18653/v1/2023.findings-acl.843) |  | 0 |  | Weixiang Zhao, Yanyan Zhao, Xin Lu, Bing Qin |  |
| 1186 |  |  [Are Layout-Infused Language Models Robust to Layout Distribution Shifts? A Case Study with Scientific Documents](https://doi.org/10.18653/v1/2023.findings-acl.844) |  | 0 |  | Catherine Chen, Zejiang Shen, Dan Klein, Gabriel Stanovsky, Doug Downey, Kyle Lo |  |
| 1187 |  |  [Enhancing Neural Topic Model with Multi-Level Supervisions from Seed Words](https://doi.org/10.18653/v1/2023.findings-acl.845) |  | 0 |  | Yang Lin, Xin Gao, Xu Chu, Yasha Wang, Junfeng Zhao, Chao Chen |  |
| 1188 |  |  [Learning from Children: Improving Image-Caption Pretraining via Curriculum](https://doi.org/10.18653/v1/2023.findings-acl.846) |  | 0 |  | Hammad A. Ayyubi, Rahul Lokesh, Alireza Zareian, Bo Wu, ShihFu Chang |  |
| 1189 |  |  [Discovering Language Model Behaviors with Model-Written Evaluations](https://doi.org/10.18653/v1/2023.findings-acl.847) |  | 0 |  | Ethan Perez, Sam Ringer, Kamile Lukosiute, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, Andy Jones, Anna Chen, Benjamin Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli TranJohnson, Guro Khundadze, Jackson Kernion, James Landis, Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau, Kamal Ndousse, Landon Goldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang, Neerav Kingsland, Nelson Elhage, Nicholas Joseph, Noemí Mercado, Nova DasSarma, Oliver Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec, Sheer El Showk, Tamera Lanham, Timothy TelleenLawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac HatfieldDodds, Jack Clark, Samuel R. Bowman, Amanda Askell, Roger B. Grosse, Danny Hernandez, Deep Ganguli, Evan Hubinger, Nicholas Schiefer, Jared Kaplan |  |
| 1190 |  |  [Cross-Domain Argument Quality Estimation](https://doi.org/10.18653/v1/2023.findings-acl.848) |  | 0 |  | Michael Fromm, Max Berrendorf, Evgeniy Faerman, Thomas Seidl |  |
| 1191 |  |  [DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis](https://doi.org/10.18653/v1/2023.findings-acl.849) |  | 0 |  | Bobo Li, Hao Fei, Fei Li, Yuhan Wu, Jinsong Zhang, Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao, TatSeng Chua, Donghong Ji |  |
| 1192 |  |  [GeoDRL: A Self-Learning Framework for Geometry Problem Solving using Reinforcement Learning in Deductive Reasoning](https://doi.org/10.18653/v1/2023.findings-acl.850) |  | 0 |  | Shuai Peng, Di Fu, Yijun Liang, Liangcai Gao, Zhi Tang |  |
| 1193 |  |  [Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2023.findings-acl.851) |  | 0 |  | Mengting Hu, Yinhao Bai, Yike Wu, Zhen Zhang, Liqi Zhang, Hang Gao, Shiwan Zhao, Minlie Huang |  |
| 1194 |  |  [Adversarial Knowledge Stimulated Contrastive Prompting for Few-shot Language Learners](https://doi.org/10.18653/v1/2023.findings-acl.852) |  | 0 |  | Kai Zheng, Qingfeng Sun, Yaming Yang, Tengchao Lv, Yeyong Pi, Changlin Zhao, Fei Xu, Qi Zhang |  |
| 1195 |  |  [Making Pre-trained Language Models Better Learn Few-Shot Spoken Language Understanding in More Practical Scenarios](https://doi.org/10.18653/v1/2023.findings-acl.853) |  | 0 |  | Yufan Wang, Jie Mei, Bowei Zou, Rui Fan, Tingting He, Ai Ti Aw |  |
| 1196 |  |  [Typology Guided Multilingual Position Representations: Case on Dependency Parsing](https://doi.org/10.18653/v1/2023.findings-acl.854) |  | 0 |  | Tao Ji, Yuanbin Wu, Xiaoling Wang |  |
| 1197 |  |  [Learning Event-aware Measures for Event Coreference Resolution](https://doi.org/10.18653/v1/2023.findings-acl.855) |  | 0 |  | Yao Yao, Zuchao Li, Hai Zhao |  |
| 1198 |  |  [Second Language Acquisition of Neural Language Models](https://doi.org/10.18653/v1/2023.findings-acl.856) |  | 0 |  | Miyu Oba, Tatsuki Kuribayashi, Hiroki Ouchi, Taro Watanabe |  |
| 1199 |  |  [On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection](https://doi.org/10.18653/v1/2023.findings-acl.857) |  | 0 |  | Songyang Gao, Shihan Dou, Qi Zhang, Xuanjing Huang, Jin Ma, Ying Shan |  |
| 1200 |  |  [Exploring the Effectiveness of Prompt Engineering for Legal Reasoning Tasks](https://doi.org/10.18653/v1/2023.findings-acl.858) |  | 0 |  | Fangyi Yu, Lee Quartey, Frank Schilder |  |
| 1201 |  |  [End-to-end Aspect-based Sentiment Analysis with Combinatory Categorial Grammar](https://doi.org/10.18653/v1/2023.findings-acl.859) |  | 0 |  | Yuanhe Tian, Weidong Chen, Bo Hu, Yan Song, Fei Xia |  |
| 1202 |  |  [ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis](https://doi.org/10.18653/v1/2023.findings-acl.860) |  | 0 |  | Yakun Yu, Mingjun Zhao, Shiang Qi, Feiran Sun, Baoxun Wang, Weidong Guo, Xiaoli Wang, Lei Yang, Di Niu |  |
| 1203 |  |  [On Degrees of Freedom in Defining and Testing Natural Language Understanding](https://doi.org/10.18653/v1/2023.findings-acl.861) |  | 0 |  | Saku Sugawara, Shun Tsugita |  |
| 1204 |  |  [AttenWalker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking](https://doi.org/10.18653/v1/2023.findings-acl.862) |  | 0 |  | Yuxiang Nie, Heyan Huang, Wei Wei, XianLing Mao |  |
| 1205 |  |  [Adaptive Ordered Information Extraction with Deep Reinforcement Learning](https://doi.org/10.18653/v1/2023.findings-acl.863) |  | 0 |  | Wenhao Huang, Jiaqing Liang, Zhixu Li, Yanghua Xiao, Chuanjun Ji |  |
| 1206 |  |  [Wasserstein-Fisher-Rao Embedding: Logical Query Embeddings with Local Comparison and Global Transport](https://doi.org/10.18653/v1/2023.findings-acl.864) |  | 0 |  | Zihao Wang, Weizhi Fei, Hang Yin, Yangqiu Song, Ginny Y. Wong, Simon See |  |
| 1207 |  |  [RISE: Leveraging Retrieval Techniques for Summarization Evaluation](https://doi.org/10.18653/v1/2023.findings-acl.865) |  | 0 |  | David C. Uthus, Jianmo Ni |  |
| 1208 |  |  [On the Difference of BERT-style and CLIP-style Text Encoders](https://doi.org/10.18653/v1/2023.findings-acl.866) |  | 0 |  | Zhihong Chen, Guiming Chen, Shizhe Diao, Xiang Wan, Benyou Wang |  |
| 1209 |  |  [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://doi.org/10.18653/v1/2023.findings-acl.867) |  | 0 |  | Marc Felix Brinner, Sina Zarrieß |  |
| 1210 |  |  [NusaCrowd: Open Source Initiative for Indonesian NLP Resources](https://doi.org/10.18653/v1/2023.findings-acl.868) |  | 0 |  | Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata, Bryan Wilie, Fajri Koto, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Jennifer Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Muhammad Satrio Wicaksono, Ivan Halim Parmonangan, Ika Alfina, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Akbar Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid Adilazuarda, Ryan Hadiwijaya, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari, Wenliang Dai, Yan Xu, Dyah Damapuspita, Haryo Akbarianto Wibowo, Cuk Tho, Ichwanul Muslim Karo Karo, Tirana Fatyanosa, Ziwei Ji, Graham Neubig, Timothy Baldwin, Sebastian Ruder, Pascale Fung, Herry Sujaini, Sakriani Sakti, Ayu Purwarianti |  |
| 1211 |  |  [Transcribing Vocal Communications of Domestic Shiba lnu Dogs](https://doi.org/10.18653/v1/2023.findings-acl.869) |  | 0 |  | Jieyi Huang, Chunhao Zhang, Mengyue Wu, Kenny Q. Zhu |  |
| 1212 |  |  [SkillQG: Learning to Generate Question for Reading Comprehension Assessment](https://doi.org/10.18653/v1/2023.findings-acl.870) |  | 0 |  | Xiaoqiang Wang, Bang Liu, Siliang Tang, Lingfei Wu |  |
| 1213 |  |  [Improving Long Dialogue Summarization with Semantic Graph Representation](https://doi.org/10.18653/v1/2023.findings-acl.871) |  | 0 |  | Bobby Yilun Hua, Zhaoyuan Deng, Kathleen R. McKeown |  |
| 1214 |  |  [Model Intrinsic Features of Fine-tuning based Text Summarization Models for Factual Consistency](https://doi.org/10.18653/v1/2023.findings-acl.872) |  | 0 |  | Jongyoon Song, Nohil Park, Bongkyu Hwang, Jaewoong Yun, Seongho Joe, Youngjune Gwon, Sungroh Yoon |  |
| 1215 |  |  [EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning](https://doi.org/10.18653/v1/2023.findings-acl.873) |  | 0 |  | Tiannan Wang, Wangchunshu Zhou, Yan Zeng, Xinsong Zhang |  |
| 1216 |  |  [DP-BART for Privatized Text Rewriting under Local Differential Privacy](https://doi.org/10.18653/v1/2023.findings-acl.874) |  | 0 |  | Timour Igamberdiev, Ivan Habernal |  |
| 1217 |  |  [Robustness of Learning from Task Instructions](https://doi.org/10.18653/v1/2023.findings-acl.875) |  | 0 |  | Jiasheng Gu, Hongyu Zhao, Hanzi Xu, Liangyu Nie, Hongyuan Mei, Wenpeng Yin |  |
| 1218 |  |  [Masked Latent Semantic Modeling: an Efficient Pre-training Alternative to Masked Language Modeling](https://doi.org/10.18653/v1/2023.findings-acl.876) |  | 0 |  | Gábor Berend |  |
| 1219 |  |  [Detection and Mitigation of the Negative Impact of Dataset Extractivity on Abstractive Summarization](https://doi.org/10.18653/v1/2023.findings-acl.877) |  | 0 |  | Yubin Ge, Sullam Jeoung, Ly Dinh, Jana Diesner |  |
| 1220 |  |  [Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering](https://doi.org/10.18653/v1/2023.findings-acl.878) |  | 0 |  | Siwei Wu, Xiangqing Shen, Rui Xia |  |
| 1221 |  |  [Incorporating Factuality Inference to Identify Document-level Event Factuality](https://doi.org/10.18653/v1/2023.findings-acl.879) |  | 0 |  | Heng Zhang, Peifeng Li, Zhong Qian, Xiaoxu Zhu |  |
| 1222 |  |  [Hybrid and Collaborative Passage Reranking](https://doi.org/10.18653/v1/2023.findings-acl.880) |  | 0 |  | Zongmeng Zhang, Wengang Zhou, Jiaxin Shi, Houqiang Li |  |
| 1223 |  |  [Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence](https://doi.org/10.18653/v1/2023.findings-acl.881) |  | 0 |  | Haoran Li, Mingshi Xu, Yangqiu Song |  |
| 1224 |  |  [Learning Query Adaptive Anchor Representation for Inductive Relation Prediction](https://doi.org/10.18653/v1/2023.findings-acl.882) |  | 0 |  | Zhiwen Xie, Yi Zhang, Jin Liu, Guangyou Zhou, Jimmy Xiangji Huang |  |
| 1225 |  |  [Context or Knowledge is Not Always Necessary: A Contrastive Learning Framework for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2023.findings-acl.883) |  | 0 |  | Geng Tu, Bin Liang, Ruibin Mao, Min Yang, Ruifeng Xu |  |
| 1226 |  |  [Exploring Speaker-Related Information in Spoken Language Understanding for Better Speaker Diarization](https://doi.org/10.18653/v1/2023.findings-acl.884) |  | 0 |  | Luyao Cheng, Siqi Zheng, Qinglin Zhang, Hui Wang, Yafeng Chen, Qian Chen |  |
| 1227 |  |  [Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages](https://doi.org/10.18653/v1/2023.findings-acl.885) |  | 0 |  | Shivanshu Gupta, Yoshitomo Matsubara, Ankit Chadha, Alessandro Moschitti |  |
| 1228 |  |  [Run Like a Girl! Sport-Related Gender Bias in Language and Vision](https://doi.org/10.18653/v1/2023.findings-acl.886) |  | 0 |  | Sophia Harrison, Eleonora Gualdoni, Gemma Boleda |  |
| 1229 |  |  [People and Places of Historical Europe: Bootstrapping Annotation Pipeline and a New Corpus of Named Entities in Late Medieval Texts](https://doi.org/10.18653/v1/2023.findings-acl.887) |  | 0 |  | Vit Novotny, Kristina Luger, Michal Stefánik, Tereza Vrabcová, Ales Horák |  |
| 1230 |  |  [Check-COVID: Fact-Checking COVID-19 News Claims with Scientific Evidence](https://doi.org/10.18653/v1/2023.findings-acl.888) |  | 0 |  | Gengyu Wang, Kate Harwood, Lawrence Chillrud, Amith Ananthram, Melanie Subbiah, Kathleen R. McKeown |  |
| 1231 |  |  [Early Exit with Disentangled Representation and Equiangular Tight Frame](https://doi.org/10.18653/v1/2023.findings-acl.889) |  | 0 |  | Yixin Ji, Jikai Wang, Juntao Li, Qiang Chen, Wenliang Chen, Min Zhang |  |
| 1232 |  |  [Tokenization with Factorized Subword Encoding](https://doi.org/10.18653/v1/2023.findings-acl.890) |  | 0 |  | David Samuel, Lilja Øvrelid |  |
| 1233 |  |  [Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers](https://doi.org/10.18653/v1/2023.findings-acl.891) |  | 0 |  | James A. Michaelov, Benjamin K. Bergen |  |
| 1234 |  |  ["A Little is Enough": Few-Shot Quality Estimation based Corpus Filtering improves Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.892) |  | 0 |  | Akshay Batheja, Pushpak Bhattacharyya |  |
| 1235 |  |  [How effective is machine translation on low-resource code-switching? A case study comparing human and automatic metrics](https://doi.org/10.18653/v1/2023.findings-acl.893) |  | 0 |  | Li Nguyen, Christopher Bryant, Oliver Mayeux, Zheng Yuan |  |
| 1236 |  |  [Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks](https://doi.org/10.18653/v1/2023.findings-acl.894) |  | 0 |  | Sherzod Hakimov, David Schlangen |  |
| 1237 |  |  [On the Expressivity Role of LayerNorm in Transformers' Attention](https://doi.org/10.18653/v1/2023.findings-acl.895) |  | 0 |  | Shaked Brody, Uri Alon, Eran Yahav |  |
| 1238 |  |  [DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation](https://doi.org/10.18653/v1/2023.findings-acl.896) |  | 0 |  | ChaeHun Park, Seungil Chad Lee, Daniel Rim, Jaegul Choo |  |
| 1239 |  |  [Fixing MoE Over-Fitting on Low-Resource Languages in Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.findings-acl.897) |  | 0 |  | Maha Elbayad, Anna Y. Sun, Shruti Bhosale |  |
| 1240 |  |  [Intent Discovery with Frame-guided Semantic Regularization and Augmentation](https://doi.org/10.18653/v1/2023.findings-acl.898) |  | 0 |  | Yajing Sun, Rui Zhang, Jingyuan Yang, Wei Peng |  |
| 1241 |  |  [An Empirical Comparison of LM-based Question and Answer Generation Methods](https://doi.org/10.18653/v1/2023.findings-acl.899) |  | 0 |  | Asahi Ushio, Fernando AlvaManchego, José CamachoCollados |  |
| 1242 |  |  [Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding](https://doi.org/10.18653/v1/2023.findings-acl.900) |  | 0 |  | Qian Li, Shafiq Joty, Daling Wang, Shi Feng, Yifei Zhang, Chengwei Qin |  |
| 1243 |  |  [Decouple knowledge from paramters for plug-and-play language modeling](https://doi.org/10.18653/v1/2023.findings-acl.901) |  | 0 |  | Xin Cheng, Yankai Lin, Xiuying Chen, Dongyan Zhao, Rui Yan |  |
| 1244 |  |  [One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems](https://doi.org/10.18653/v1/2023.acl-long.1) |  | 0 |  | Yajiao Liu, Xin Jiang, Yichun Yin, Yasheng Wang, Fei Mi, Qun Liu, Xiang Wan, Benyou Wang |  |
| 1245 |  |  [SafeConv: Explaining and Correcting Conversational Unsafe Behavior](https://doi.org/10.18653/v1/2023.acl-long.2) |  | 0 |  | Mian Zhang, Lifeng Jin, Linfeng Song, Haitao Mi, Wenliang Chen, Dong Yu |  |
| 1246 |  |  [Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better](https://doi.org/10.18653/v1/2023.acl-long.3) |  | 0 |  | David Dale, Elena Voita, Loïc Barrault, Marta R. Costajussà |  |
| 1247 |  |  [Explainable Recommendation with Personalized Review Retrieval and Aspect Learning](https://doi.org/10.18653/v1/2023.acl-long.4) |  | 0 |  | Hao Cheng, Shuo Wang, Wensheng Lu, Wei Zhang, Mingyang Zhou, Kezhong Lu, Hao Liao |  |
| 1248 |  |  [Binary and Ternary Natural Language Generation](https://doi.org/10.18653/v1/2023.acl-long.5) |  | 0 |  | Zechun Liu, Barlas Oguz, Aasish Pappu, Yangyang Shi, Raghuraman Krishnamoorthi |  |
| 1249 |  |  [Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking](https://doi.org/10.18653/v1/2023.acl-long.6) |  | 0 |  | Björn Bebensee, Haejun Lee |  |
| 1250 |  |  [EM Pre-training for Multi-party Dialogue Response Generation](https://doi.org/10.18653/v1/2023.acl-long.7) |  | 0 |  | Yiyang Li, Hai Zhao |  |
| 1251 |  |  [ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER](https://doi.org/10.18653/v1/2023.acl-long.8) |  | 0 |  | Sreyan Ghosh, Utkarsh Tyagi, Manan Suri, Sonal Kumar, Ramaneswaran S., Dinesh Manocha |  |
| 1252 |  |  [Natural Language to Code Generation in Interactive Data Science Notebooks](https://doi.org/10.18653/v1/2023.acl-long.9) |  | 0 |  | Pengcheng Yin, WenDing Li, Kefan Xiao, Abhishek Rao, Yeming Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski, Oleksandr Polozov, Charles Sutton |  |
| 1253 |  |  [Subset Retrieval Nearest Neighbor Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.10) |  | 0 |  | Hiroyuki Deguchi, Taro Watanabe, Yusuke Matsui, Masao Utiyama, Hideki Tanaka, Eiichiro Sumita |  |
| 1254 |  |  [MIL-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning](https://doi.org/10.18653/v1/2023.acl-long.11) |  | 0 |  | Xu Zhang, Xiaojun Wan |  |
| 1255 |  |  [Dependency resolution at the syntax-semantics interface: psycholinguistic and computational insights on control dependencies](https://doi.org/10.18653/v1/2023.acl-long.12) |  | 0 |  | Iria deDiosFlores, Juan Garcia Amboage, Marcos García |  |
| 1256 |  |  [Open-ended Long Text Generation via Masked Language Modeling](https://doi.org/10.18653/v1/2023.acl-long.13) |  | 0 |  | Xiaobo Liang, Zecheng Tang, Juntao Li, Min Zhang |  |
| 1257 |  |  [A Method for Studying Semantic Construal in Grammatical Constructions with Interpretable Contextual Embedding Spaces](https://doi.org/10.18653/v1/2023.acl-long.14) |  | 0 |  | Gabriella Chronis, Kyle Mahowald, Katrin Erk |  |
| 1258 |  |  [Holographic CCG Parsing](https://doi.org/10.18653/v1/2023.acl-long.15) |  | 0 |  | Ryosuke Yamaki, Tadahiro Taniguchi, Daichi Mochihashi |  |
| 1259 |  |  [Prompts Can Play Lottery Tickets Well: Achieving Lifelong Information Extraction via Lottery Prompt Tuning](https://doi.org/10.18653/v1/2023.acl-long.16) |  | 0 |  | Zujie Liang, Feng Wei, Yin Jie, Yuxi Qian, Zhenghong Hao, Bing Han |  |
| 1260 |  |  [Retrieve-and-Sample: Document-level Event Argument Extraction via Hybrid Retrieval Augmentation](https://doi.org/10.18653/v1/2023.acl-long.17) |  | 0 |  | Yubing Ren, Yanan Cao, Ping Guo, Fang Fang, Wei Ma, Zheng Lin |  |
| 1261 |  |  [WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning](https://doi.org/10.18653/v1/2023.acl-long.18) |  | 0 |  | Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li, Yajuan Lyu |  |
| 1262 |  |  [AMR-based Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.acl-long.19) |  | 0 |  | Fukun Ma, Xuming Hu, Aiwei Liu, Yawen Yang, Shuang Li, Philip S. Yu, Lijie Wen |  |
| 1263 |  |  [Text Adversarial Purification as Defense against Adversarial Attacks](https://doi.org/10.18653/v1/2023.acl-long.20) |  | 0 |  | Linyang Li, Demin Song, Xipeng Qiu |  |
| 1264 |  |  [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres](https://doi.org/10.18653/v1/2023.acl-long.21) |  | 0 |  | Shumin Deng, Shengyu Mao, Ningyu Zhang, Bryan Hooi |  |
| 1265 |  |  [Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection](https://doi.org/10.18653/v1/2023.acl-long.22) |  | 0 |  | Christopher Clarke, Matthew Hall, Gaurav Mittal, Ye Yu, Sandra Sajeev, Jason Mars, Mei Chen |  |
| 1266 |  |  [What about "em"? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns](https://doi.org/10.18653/v1/2023.acl-long.23) |  | 0 |  | Anne Lauscher, Debora Nozza, Ehm Miltersen, Archie Crowley, Dirk Hovy |  |
| 1267 |  |  [What Is Overlap Knowledge in Event Argument Extraction? APE: A Cross-datasets Transfer Learning Model for EAE](https://doi.org/10.18653/v1/2023.acl-long.24) |  | 0 |  | Kaihang Zhang, Kai Shuang, Xinyue Yang, Xuyang Yao, Jinyu Guo |  |
| 1268 |  |  [Tailor: A Soft-Prompt-Based Approach to Attribute-Based Controlled Text Generation](https://doi.org/10.18653/v1/2023.acl-long.25) |  | 0 |  | Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Mingfeng Xue, Boxing Chen, Jun Xie |  |
| 1269 |  |  [Knowledge of cultural moral norms in large language models](https://doi.org/10.18653/v1/2023.acl-long.26) |  | 0 |  | Aida Ramezani, Yang Xu |  |
| 1270 |  |  [Songs Across Borders: Singable and Controllable Neural Lyric Translation](https://doi.org/10.18653/v1/2023.acl-long.27) |  | 0 |  | Longshen Ou, Xichu Ma, MinYen Kan, Ye Wang |  |
| 1271 |  |  [Fantastic Expressions and Where to Find Them: Chinese Simile Generation with Multiple Constraints](https://doi.org/10.18653/v1/2023.acl-long.28) |  | 0 |  | Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Xiangpeng Wei, Zhengyuan Liu, Jun Xie |  |
| 1272 |  |  [Revealing Single Frame Bias for Video-and-Language Learning](https://doi.org/10.18653/v1/2023.acl-long.29) |  | 0 |  | Jie Lei, Tamara L. Berg, Mohit Bansal |  |
| 1273 |  |  [Learning with Partial Annotations for Event Detection](https://doi.org/10.18653/v1/2023.acl-long.30) |  | 0 |  | Jian Liu, Dianbo Sui, Kang Liu, Haoyan Liu, Zhe Zhao |  |
| 1274 |  |  [World-to-Words: Grounded Open Vocabulary Acquisition through Fast Mapping in Vision-Language Models](https://doi.org/10.18653/v1/2023.acl-long.31) |  | 0 |  | Ziqiao Ma, Jiayi Pan, Joyce Chai |  |
| 1275 |  |  [A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models](https://doi.org/10.18653/v1/2023.acl-long.32) |  | 0 |  | Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bernhard Schölkopf, Mrinmaya Sachan |  |
| 1276 |  |  [Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information](https://doi.org/10.18653/v1/2023.acl-long.33) |  | 0 |  | Kun Zhao, Bohao Yang, Chenghua Lin, Wenge Rong, Aline Villavicencio, Xiaohui Cui |  |
| 1277 |  |  [Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions](https://doi.org/10.18653/v1/2023.acl-long.34) |  | 0 |  | John Joon Young Chung, Ece Kamar, Saleema Amershi |  |
| 1278 |  |  [Pruning Pre-trained Language Models Without Fine-Tuning](https://doi.org/10.18653/v1/2023.acl-long.35) |  | 0 |  | Ting Jiang, Deqing Wang, Fuzhen Zhuang, Ruobing Xie, Feng Xia |  |
| 1279 |  |  [When Does Translation Require Context? A Data-driven, Multilingual Exploration](https://doi.org/10.18653/v1/2023.acl-long.36) |  | 0 |  | Patrick Fernandes, Kayo Yin, Emmy Liu, André F. T. Martins, Graham Neubig |  |
| 1280 |  |  [Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection](https://doi.org/10.18653/v1/2023.acl-long.37) |  | 0 |  | Ziwei Chen, Linmei Hu, Weixin Li, Yingxia Shao, Liqiang Nie |  |
| 1281 |  |  [LexSym: Compositionality as Lexical Symmetry](https://doi.org/10.18653/v1/2023.acl-long.38) |  | 0 |  | Ekin Akyürek, Jacob Andreas |  |
| 1282 |  |  [Layer-wise Fusion with Modality Independence Modeling for Multi-modal Emotion Recognition](https://doi.org/10.18653/v1/2023.acl-long.39) |  | 0 |  | Jun Sun, Shoukang Han, YuPing Ruan, Xiaoning Zhang, ShuKai Zheng, Yulong Liu, Yuxin Huang, Taihao Li |  |
| 1283 |  |  [CASN: Class-Aware Score Network for Textual Adversarial Detection](https://doi.org/10.18653/v1/2023.acl-long.40) |  | 0 |  | Rong Bao, Rui Zheng, Liang Ding, Qi Zhang, Dacheng Tao |  |
| 1284 |  |  [Do Androids Laugh at Electric Sheep? Humor "Understanding" Benchmarks from The New Yorker Caption Contest](https://doi.org/10.18653/v1/2023.acl-long.41) |  | 0 |  | Jack Hessel, Ana Marasovic, Jena D. Hwang, Lillian Lee, Jeff Da, Rowan Zellers, Robert Mankoff, Yejin Choi |  |
| 1285 |  |  [Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation](https://doi.org/10.18653/v1/2023.acl-long.42) |  | 0 |  | Martijn Bartelds, Nay San, Bradley McDonnell, Dan Jurafsky, Martijn Wieling |  |
| 1286 |  |  [CLCL: Non-compositional Expression Detection with Contrastive Learning and Curriculum Learning](https://doi.org/10.18653/v1/2023.acl-long.43) |  | 0 |  | Jianing Zhou, Ziheng Zeng, Suma Bhat |  |
| 1287 |  |  [Multi-VALUE: A Framework for Cross-Dialectal English NLP](https://doi.org/10.18653/v1/2023.acl-long.44) |  | 0 |  | Caleb Ziems, William Held, Jingfeng Yang, Jwala Dhamala, Rahul Gupta, Diyi Yang |  |
| 1288 |  |  [Self-Edit: Fault-Aware Code Editor for Code Generation](https://doi.org/10.18653/v1/2023.acl-long.45) |  | 0 |  | Kechi Zhang, Zhuo Li, Jia Li, Ge Li, Zhi Jin |  |
| 1289 |  |  [ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning](https://doi.org/10.18653/v1/2023.acl-long.46) |  | 0 |  | Shachar DonYehiya, Elad Venezian, Colin Raffel, Noam Slonim, Leshem Choshen |  |
| 1290 |  |  [Test-time Adaptation for Machine Translation Evaluation by Uncertainty Minimization](https://doi.org/10.18653/v1/2023.acl-long.47) |  | 0 |  | Runzhe Zhan, Xuebo Liu, Derek F. Wong, Cuilian Zhang, Lidia S. Chao, Min Zhang |  |
| 1291 |  |  [Multi-CLS BERT: An Efficient Alternative to Traditional Ensembling](https://doi.org/10.18653/v1/2023.acl-long.48) |  | 0 |  | HawShiuan Chang, RueiYao Sun, Kathryn Ricci, Andrew McCallum |  |
| 1292 |  |  [On-the-fly Cross-lingual Masking for Multilingual Pre-training](https://doi.org/10.18653/v1/2023.acl-long.49) |  | 0 |  | Xi Ai, Bin Fang |  |
| 1293 |  |  [How About Kind of Generating Hedges using End-to-End Neural Models?](https://doi.org/10.18653/v1/2023.acl-long.50) |  | 0 |  | Alafate Abulimiti, Chloé Clavel, Justine Cassell |  |
| 1294 |  |  [DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models](https://doi.org/10.18653/v1/2023.acl-long.51) |  | 0 |  | Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, Duen Horng Chau |  |
| 1295 |  |  [From Key Points to Key Point Hierarchy: Structured and Expressive Opinion Summarization](https://doi.org/10.18653/v1/2023.acl-long.52) |  | 0 |  | Arie Cattan, Lilach Eden, Yoav Kantor, Roy BarHaim |  |
| 1296 |  |  [When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE Systems for Downstream Applications](https://doi.org/10.18653/v1/2023.acl-long.53) |  | 0 |  | Kevin Pei, Ishan Jindal, Kevin ChenChuan Chang, ChengXiang Zhai, Yunyao Li |  |
| 1297 |  |  [Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning](https://doi.org/10.18653/v1/2023.acl-long.54) |  | 0 |  | Tharindu Cyril Weerasooriya, Sarah Luger, Saloni Poddar, Ashiqur R. KhudaBukhsh, Christopher Homan |  |
| 1298 |  |  [Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in QA](https://doi.org/10.18653/v1/2023.acl-long.55) |  | 0 |  | Neeraj Varshney, Chitta Baral |  |
| 1299 |  |  [UniLG: A Unified Structure-aware Framework for Lyrics Generation](https://doi.org/10.18653/v1/2023.acl-long.56) |  | 0 |  | Tao Qian, Fan Lou, Jiatong Shi, Yuning Wu, Shuai Guo, Xiang Yin, Qin Jin |  |
| 1300 |  |  [FC-KBQA: A Fine-to-Coarse Composition Framework for Knowledge Base Question Answering](https://doi.org/10.18653/v1/2023.acl-long.57) |  | 0 |  | Lingxi Zhang, Jing Zhang, Yanling Wang, Shulin Cao, Xinmei Huang, Cuiping Li, Hong Chen, Juanzi Li |  |
| 1301 |  |  [Does GPT-3 Grasp Metaphors? Identifying Metaphor Mappings with Generative Language Models](https://doi.org/10.18653/v1/2023.acl-long.58) |  | 0 |  | Lennart Wachowiak, Dagmar Gromann |  |
| 1302 |  |  [Being Right for Whose Right Reasons?](https://doi.org/10.18653/v1/2023.acl-long.59) |  | 0 |  | Terne Sasha Thorn Jakobsen, Laura Cabello, Anders Søgaard |  |
| 1303 |  |  [ALERT: Adapt Language Models to Reasoning Tasks](https://doi.org/10.18653/v1/2023.acl-long.60) |  | 0 |  | Ping Yu, Tianlu Wang, Olga Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi Ghosh, Mona T. Diab, Asli Celikyilmaz |  |
| 1304 |  |  [Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages](https://doi.org/10.18653/v1/2023.acl-long.61) |  | 0 |  | Ayyoob Imani, Peiqin Lin, Amir Hossein Kargaran, Silvia Severini, Masoud Jalili Sabet, Nora Kassner, Chunlan Ma, Helmut Schmid, André F. T. Martins, François Yvon, Hinrich Schütze |  |
| 1305 |  |  [Joint Constrained Learning with Boundary-adjusting for Emotion-Cause Pair Extraction](https://doi.org/10.18653/v1/2023.acl-long.62) |  | 0 |  | Huawen Feng, Junlong Liu, Junhao Zheng, Haibin Chen, Xichen Shang, Qianli Ma |  |
| 1306 |  |  [Pretrained Bidirectional Distillation for Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.63) |  | 0 |  | Yimeng Zhuang, Mei Tu |  |
| 1307 |  |  [Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.64) |  | 0 |  | Kyuyong Shin, Hanock Kwak, Wonjae Kim, Jisu Jeong, Seungjae Jung, Kyungmin Kim, JungWoo Ha, SangWoo Lee |  |
| 1308 |  |  [Improving Continual Relation Extraction by Distinguishing Analogous Semantics](https://doi.org/10.18653/v1/2023.acl-long.65) |  | 0 |  | Wenzheng Zhao, Yuanning Cui, Wei Hu |  |
| 1309 |  |  [Improving Pretraining Techniques for Code-Switched NLP](https://doi.org/10.18653/v1/2023.acl-long.66) |  | 0 |  | Richeek Das, Sahasra Ranjan, Shreya Pathak, Preethi Jyothi |  |
| 1310 |  |  [A Theory of Unsupervised Speech Recognition](https://doi.org/10.18653/v1/2023.acl-long.67) |  | 0 |  | Liming Wang, Mark HasegawaJohnson, Chang Dong Yoo |  |
| 1311 |  |  [ThinkSum: Probabilistic reasoning over sets using large language models](https://doi.org/10.18653/v1/2023.acl-long.68) |  | 0 |  | Batu Ozturkler, Nikolay Malkin, Zhen Wang, Nebojsa Jojic |  |
| 1312 |  |  [NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist](https://doi.org/10.18653/v1/2023.acl-long.69) |  | 0 |  | Iftitahu Ni'mah, Meng Fang, Vlado Menkovski, Mykola Pechenizkiy |  |
| 1313 |  |  [DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations](https://doi.org/10.18653/v1/2023.acl-long.70) |  | 0 |  | Ang Lv, Jinpeng Li, Yuhan Chen, Gao Xing, Ji Zhang, Rui Yan |  |
| 1314 |  |  [TECHS: Temporal Logical Graph Networks for Explainable Extrapolation Reasoning](https://doi.org/10.18653/v1/2023.acl-long.71) |  | 0 |  | Qika Lin, Jun Liu, Rui Mao, Fangzhi Xu, Erik Cambria |  |
| 1315 |  |  [Consistency Regularization Training for Compositional Generalization](https://doi.org/10.18653/v1/2023.acl-long.72) |  | 0 |  | Yongjing Yin, Jiali Zeng, Yafu Li, Fandong Meng, Jie Zhou, Yue Zhang |  |
| 1316 |  |  [NUWA-XL: Diffusion over Diffusion for eXtremely Long Video Generation](https://doi.org/10.18653/v1/2023.acl-long.73) |  | 0 |  | Shengming Yin, Chenfei Wu, Huan Yang, Jianfeng Wang, Xiaodong Wang, Minheng Ni, Zhengyuan Yang, Linjie Li, Shuguang Liu, Fan Yang, Jianlong Fu, Ming Gong, Lijuan Wang, Zicheng Liu, Houqiang Li, Nan Duan |  |
| 1317 |  |  [Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe](https://doi.org/10.18653/v1/2023.acl-long.74) |  | 0 |  | Xiang Yue, Huseyin A. Inan, Xuechen Li, Girish Kumar, Julia McAnallen, Hoda Shajari, Huan Sun, David Levitan, Robert Sim |  |
| 1318 |  |  [A Close Look into the Calibration of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.75) |  | 0 |  | Yangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu, Heng Ji |  |
| 1319 |  |  [DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization](https://doi.org/10.18653/v1/2023.acl-long.76) |  | 0 |  | Yu Li, Baolin Peng, Pengcheng He, Michel Galley, Zhou Yu, Jianfeng Gao |  |
| 1320 |  |  [MS-DETR: Natural Language Video Localization with Sampling Moment-Moment Interaction](https://doi.org/10.18653/v1/2023.acl-long.77) |  | 0 |  | Jing Wang, Aixin Sun, Hao Zhang, Xiaoli Li |  |
| 1321 |  |  [Diverse Demonstrations Improve In-context Compositional Generalization](https://doi.org/10.18653/v1/2023.acl-long.78) |  | 0 |  | Itay Levy, Ben Bogin, Jonathan Berant |  |
| 1322 |  |  [Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering](https://doi.org/10.18653/v1/2023.acl-long.79) |  | 0 |  | Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, Lingpeng Kong |  |
| 1323 |  |  [On the Efficacy of Sampling Adapters](https://doi.org/10.18653/v1/2023.acl-long.80) |  | 0 |  | Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan Wilcox, Ryan Cotterell |  |
| 1324 |  |  [Cross-Domain Data Augmentation with Domain-Adaptive Language Modeling for Aspect-Based Sentiment Analysis](https://doi.org/10.18653/v1/2023.acl-long.81) |  | 0 |  | Jianfei Yu, Qiankun Zhao, Rui Xia |  |
| 1325 |  |  [Compositional Data Augmentation for Abstractive Conversation Summarization](https://doi.org/10.18653/v1/2023.acl-long.82) |  | 0 |  | Siru Ouyang, Jiaao Chen, Jiawei Han, Diyi Yang |  |
| 1326 |  |  [PMAES: Prompt-mapping Contrastive Learning for Cross-prompt Automated Essay Scoring](https://doi.org/10.18653/v1/2023.acl-long.83) |  | 0 |  | Yuan Chen, Xia Li |  |
| 1327 |  |  [Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models](https://doi.org/10.18653/v1/2023.acl-long.84) |  | 0 |  | Myra Cheng, Esin Durmus, Dan Jurafsky |  |
| 1328 |  |  [On Prefix-tuning for Lightweight Out-of-distribution Detection](https://doi.org/10.18653/v1/2023.acl-long.85) |  | 0 |  | Yawen Ouyang, Yongchang Cao, Yuan Gao, Zhen Wu, Jianbing Zhang, Xinyu Dai |  |
| 1329 |  |  [GEC-DePenD: Non-Autoregressive Grammatical Error Correction with Decoupled Permutation and Decoding](https://doi.org/10.18653/v1/2023.acl-long.86) |  | 0 |  | Konstantin Yakovlev, Alexander Podolskiy, Andrey Bout, Sergey I. Nikolenko, Irina Piontkovskaya |  |
| 1330 |  |  [Measuring Progress in Fine-grained Vision-and-Language Understanding](https://doi.org/10.18653/v1/2023.acl-long.87) |  | 0 |  | Emanuele Bugliarello, Laurent Sartran, Aishwarya Agrawal, Lisa Anne Hendricks, Aida Nematzadeh |  |
| 1331 |  |  [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information](https://doi.org/10.18653/v1/2023.acl-long.88) |  | 0 |  | Sunjae Kwon, Rishabh Garodia, Minhwa Lee, Zhichao Yang, Hong Yu |  |
| 1332 |  |  [Chain-of-Skills: A Configurable Model for Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.acl-long.89) |  | 0 |  | Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao |  |
| 1333 |  |  [Elaboration-Generating Commonsense Question Answering at Scale](https://doi.org/10.18653/v1/2023.acl-long.90) |  | 0 |  | Wenya Wang, Vivek Srikumar, Hannaneh Hajishirzi, Noah A. Smith |  |
| 1334 |  |  [Neural Unsupervised Reconstruction of Protolanguage Word Forms](https://doi.org/10.18653/v1/2023.acl-long.91) |  | 0 |  | Andre He, Nicholas Tomlin, Dan Klein |  |
| 1335 |  |  [DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation](https://doi.org/10.18653/v1/2023.acl-long.92) |  | 0 |  | Menglong Lu, Zhen Huang, Yunxiang Zhao, Zhiliang Tian, Yang Liu, Dongsheng Li |  |
| 1336 |  |  [On Evaluating Multilingual Compositional Generalization with Translated Datasets](https://doi.org/10.18653/v1/2023.acl-long.93) |  | 0 |  | Zi Wang, Daniel Hershcovich |  |
| 1337 |  |  [FAA: Fine-grained Attention Alignment for Cascade Document Ranking](https://doi.org/10.18653/v1/2023.acl-long.94) |  | 0 |  | Zhen Li, Chongyang Tao, Jiazhan Feng, Tao Shen, Dongyan Zhao, Xiubo Geng, Daxin Jiang |  |
| 1338 |  |  [Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.95) |  | 0 |  | Zhong Zhang, Bang Liu, Junming Shao |  |
| 1339 |  |  [Facilitating Multi-turn Emotional Support Conversation with Positive Emotion Elicitation: A Reinforcement Learning Approach](https://doi.org/10.18653/v1/2023.acl-long.96) |  | 0 |  | Jinfeng Zhou, Zhuang Chen, Bo Wang, Minlie Huang |  |
| 1340 |  |  [Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint Modeling](https://doi.org/10.18653/v1/2023.acl-long.97) |  | 0 |  | Mingzhu Cai, Siqi Bao, Xin Tian, Huang He, Fan Wang, Hua Wu |  |
| 1341 |  |  [Why Aren't We NER Yet? Artifacts of ASR Errors in Named Entity Recognition in Spontaneous Speech Transcripts](https://doi.org/10.18653/v1/2023.acl-long.98) |  | 0 |  | Piotr Szymanski, Lukasz Augustyniak, Mikolaj Morzy, Adrian Szymczak, Krzysztof Surdyk, Piotr Zelasko |  |
| 1342 |  |  [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://doi.org/10.18653/v1/2023.acl-long.99) |  | 0 |  | Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan |  |
| 1343 |  |  [White-Box Multi-Objective Adversarial Attack on Dialogue Generation](https://doi.org/10.18653/v1/2023.acl-long.100) |  | 0 |  | Yufei Li, Zexin Li, Yingfan Gao, Cong Liu |  |
| 1344 |  |  [A Cautious Generalization Goes a Long Way: Learning Morphophonological Rules](https://doi.org/10.18653/v1/2023.acl-long.101) |  | 0 |  | Salam Khalifa, Sarah R. B. Payne, Jordan Kodner, Ellen Broselow, Owen Rambow |  |
| 1345 |  |  [Few-shot Adaptation Works with UnpredicTable Data](https://doi.org/10.18653/v1/2023.acl-long.102) |  | 0 |  | Jun Shern Chan, Michael Pieler, Jonathan Jao, Jérémy Scheurer, Ethan Perez |  |
| 1346 |  |  [Cross-lingual Science Journalism: Select, Simplify and Rewrite Summaries for Non-expert Readers](https://doi.org/10.18653/v1/2023.acl-long.103) |  | 0 |  | Mehwish Fatima, Michael Strube |  |
| 1347 |  |  [HuCurl: Human-induced Curriculum Discovery](https://doi.org/10.18653/v1/2023.acl-long.104) |  | 0 |  | Mohamed Elgaar, Hadi Amiri |  |
| 1348 |  |  [kNN-TL: k-Nearest-Neighbor Transfer Learning for Low-Resource Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.105) |  | 0 |  | Shudong Liu, Xuebo Liu, Derek F. Wong, Zhaocong Li, Wenxiang Jiao, Lidia S. Chao, Min Zhang |  |
| 1349 |  |  [Do language models have coherent mental models of everyday things?](https://doi.org/10.18653/v1/2023.acl-long.106) |  | 0 |  | Yuling Gu, Bhavana Dalvi Mishra, Peter Clark |  |
| 1350 |  |  [Rogue Scores](https://doi.org/10.18653/v1/2023.acl-long.107) |  | 0 |  | Max Grusky |  |
| 1351 |  |  [Instruction Induction: From Few Examples to Natural Language Task Descriptions](https://doi.org/10.18653/v1/2023.acl-long.108) |  | 0 |  | Or Honovich, Uri Shaham, Samuel R. Bowman, Omer Levy |  |
| 1352 |  |  [In-Context Analogical Reasoning with Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.109) |  | 0 |  | Xiaoyang Hu, Shane Storks, Richard L. Lewis, Joyce Chai |  |
| 1353 |  |  [Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering](https://doi.org/10.18653/v1/2023.acl-long.110) |  | 0 |  | Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, Arman Cohan |  |
| 1354 |  |  [Tailoring Instructions to Student's Learning Levels Boosts Knowledge Distillation](https://doi.org/10.18653/v1/2023.acl-long.111) |  | 0 |  | Yuxin Ren, Zihan Zhong, Xingjian Shi, Yi Zhu, Chun Yuan, Mu Li |  |
| 1355 |  |  [REV: Information-Theoretic Evaluation of Free-Text Rationales](https://doi.org/10.18653/v1/2023.acl-long.112) |  | 0 |  | Hanjie Chen, Faeze Brahman, Xiang Ren, Yangfeng Ji, Yejin Choi, Swabha Swayamdipta |  |
| 1356 |  |  [ELQA: A Corpus of Metalinguistic Questions and Answers about English](https://doi.org/10.18653/v1/2023.acl-long.113) |  | 0 |  | Shabnam Behzad, Keisuke Sakaguchi, Nathan Schneider, Amir Zeldes |  |
| 1357 |  |  [Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking](https://doi.org/10.18653/v1/2023.acl-long.114) |  | 0 |  | Qingyue Wang, Liang Ding, Yanan Cao, Yibing Zhan, Zheng Lin, Shi Wang, Dacheng Tao, Li Guo |  |
| 1358 |  |  [BIG-C: a Multimodal Multi-Purpose Dataset for Bemba](https://doi.org/10.18653/v1/2023.acl-long.115) |  | 0 |  | Claytone Sikasote, Eunice Mukonde, Md Mahfuz Ibn Alam, Antonios Anastasopoulos |  |
| 1359 |  |  [Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues](https://doi.org/10.18653/v1/2023.acl-long.116) |  | 0 |  | Yue Feng, Yunlong Jiao, Animesh Prasad, Nikolaos Aletras, Emine Yilmaz, Gabriella Kazai |  |
| 1360 |  |  [Robust Multi-bit Natural Language Watermarking through Invariant Features](https://doi.org/10.18653/v1/2023.acl-long.117) |  | 0 |  | KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, Nojun Kwak |  |
| 1361 |  |  [KALM: Knowledge-Aware Integration of Local, Document, and Global Contexts for Long Document Understanding](https://doi.org/10.18653/v1/2023.acl-long.118) |  | 0 |  | Shangbin Feng, Zhaoxuan Tan, Wenqian Zhang, Zhenyu Lei, Yulia Tsvetkov |  |
| 1362 |  |  [AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction](https://doi.org/10.18653/v1/2023.acl-long.119) |  | 0 |  | Yanzeng Li, Bingcong Xue, Ruoyu Zhang, Lei Zou |  |
| 1363 |  |  [Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization](https://doi.org/10.18653/v1/2023.acl-long.120) |  | 0 |  | Shiyue Zhang, David Wan, Mohit Bansal |  |
| 1364 |  |  [Improving Translation Quality Estimation with Bias Mitigation](https://doi.org/10.18653/v1/2023.acl-long.121) |  | 0 |  | Hui Huang, Shuangzhi Wu, Kehai Chen, Hui Di, Muyun Yang, Tiejun Zhao |  |
| 1365 |  |  [Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation](https://doi.org/10.18653/v1/2023.acl-long.122) |  | 0 |  | Josef Jon, Ondrej Bojar |  |
| 1366 |  |  [MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions](https://doi.org/10.18653/v1/2023.acl-long.123) |  | 0 |  | Hao Sun, Zhexin Zhang, Fei Mi, Yasheng Wang, Wei Liu, Jianwei Cui, Bin Wang, Qun Liu, Minlie Huang |  |
| 1367 |  |  [Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion](https://doi.org/10.18653/v1/2023.acl-long.124) |  | 0 |  | Shaoxiang Wu, Damai Dai, Ziwei Qin, Tianyu Liu, Binghuai Lin, Yunbo Cao, Zhifang Sui |  |
| 1368 |  |  [SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval](https://doi.org/10.18653/v1/2023.acl-long.125) |  | 0 |  | Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, Furu Wei |  |
| 1369 |  |  [From Ultra-Fine to Fine: Fine-tuning Ultra-Fine Entity Typing Models to Fine-grained](https://doi.org/10.18653/v1/2023.acl-long.126) |  | 0 |  | Hongliang Dai, Ziqian Zeng |  |
| 1370 |  |  [Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers](https://doi.org/10.18653/v1/2023.acl-long.127) |  | 0 |  | Parikshit Bansal, Amit Sharma |  |
| 1371 |  |  [What Makes Pre-trained Language Models Better Zero-shot Learners?](https://doi.org/10.18653/v1/2023.acl-long.128) |  | 0 |  | Jinghui Lu, Dongsheng Zhu, Weidong Han, Rui Zhao, Brian Mac Namee, Fei Tan |  |
| 1372 |  |  [Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations](https://doi.org/10.18653/v1/2023.acl-long.129) |  | 0 |  | Xinxi Lyu, Sewon Min, Iz Beltagy, Luke Zettlemoyer, Hannaneh Hajishirzi |  |
| 1373 |  |  [Learning Optimal Policy for Simultaneous Machine Translation via Binary Search](https://doi.org/10.18653/v1/2023.acl-long.130) |  | 0 |  | Shoutao Guo, Shaolei Zhang, Yang Feng |  |
| 1374 |  |  [Better Simultaneous Translation with Monotonic Knowledge Distillation](https://doi.org/10.18653/v1/2023.acl-long.131) |  | 0 |  | Shushu Wang, Jing Wu, Kai Fan, Wei Luo, Jun Xiao, Zhongqiang Huang |  |
| 1375 |  |  [StoryARG: a corpus of narratives and personal experiences in argumentative texts](https://doi.org/10.18653/v1/2023.acl-long.132) |  | 0 |  | Neele Falk, Gabriella Lapesa |  |
| 1376 |  |  [Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue](https://doi.org/10.18653/v1/2023.acl-long.133) |  | 0 |  | Maksim Eremeev, Ilya Valmianski, Xavier Amatriain, Anitha Kannan |  |
| 1377 |  |  [Sequence Parallelism: Long Sequence Training from System Perspective](https://doi.org/10.18653/v1/2023.acl-long.134) |  | 0 |  | Shenggui Li, Fuzhao Xue, Chaitanya Baranwal, Yongbin Li, Yang You |  |
| 1378 |  |  [MUSTIE: Multimodal Structural Transformer for Web Information Extraction](https://doi.org/10.18653/v1/2023.acl-long.135) |  | 0 |  | Qifan Wang, Jingang Wang, Xiaojun Quan, Fuli Feng, Zenglin Xu, Shaoliang Nie, Sinong Wang, Madian Khabsa, Hamed Firooz, Dongfang Liu |  |
| 1379 |  |  [Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In](https://doi.org/10.18653/v1/2023.acl-long.136) |  | 0 |  | Zichun Yu, Chenyan Xiong, Shi Yu, Zhiyuan Liu |  |
| 1380 |  |  [TableVLM: Multi-modal Pre-training for Table Structure Recognition](https://doi.org/10.18653/v1/2023.acl-long.137) |  | 0 |  | Leiyuan Chen, Chengsong Huang, Xiaoqing Zheng, Jinshu Lin, Xuanjing Huang |  |
| 1381 |  |  [Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?](https://doi.org/10.18653/v1/2023.acl-long.138) |  | 0 |  | Jiashu Xu, Mingyu Derek Ma, Muhao Chen |  |
| 1382 |  |  [Dynamic Routing Transformer Network for Multimodal Sarcasm Detection](https://doi.org/10.18653/v1/2023.acl-long.139) |  | 0 |  | Yuan Tian, Nan Xu, Ruike Zhang, Wenji Mao |  |
| 1383 |  |  [What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary](https://doi.org/10.18653/v1/2023.acl-long.140) |  | 0 |  | Ori Ram, Liat Bezalel, Adi Zicher, Yonatan Belinkov, Jonathan Berant, Amir Globerson |  |
| 1384 |  |  [Cold-Start Data Selection for Better Few-shot Language Model Fine-tuning: A Prompt-based Uncertainty Propagation Approach](https://doi.org/10.18653/v1/2023.acl-long.141) |  | 0 |  | Yue Yu, Rongzhi Zhang, Ran Xu, Jieyu Zhang, Jiaming Shen, Chao Zhang |  |
| 1385 |  |  [Training-free Neural Architecture Search for RNNs and Transformers](https://doi.org/10.18653/v1/2023.acl-long.142) |  | 0 |  | Aaron Serianni, Jugal Kalita |  |
| 1386 |  |  [CrossSum: Beyond English-Centric Cross-Lingual Summarization for 1, 500+ Language Pairs](https://doi.org/10.18653/v1/2023.acl-long.143) |  | 0 |  | Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ahmad, YuanFang Li, YongBin Kang, Rifat Shahriyar |  |
| 1387 |  |  [Improving Gradient Trade-offs between Tasks in Multi-task Text Classification](https://doi.org/10.18653/v1/2023.acl-long.144) |  | 0 |  | Heyan Chai, Jinhao Cui, Ye Wang, Min Zhang, Binxing Fang, Qing Liao |  |
| 1388 |  |  [Bi-Phone: Modeling Inter Language Phonetic Influences in Text](https://doi.org/10.18653/v1/2023.acl-long.145) |  | 0 |  | Abhirut Gupta, Ananya B. Sai, Richard Sproat, Yuri Vasilevski, James S. Ren, Ambarish Jash, Sukhdeep S. Sodhi, Aravindan Raghuveer |  |
| 1389 |  |  [Cross2StrA: Unpaired Cross-lingual Image Captioning with Cross-lingual Cross-modal Structure-pivoted Alignment](https://doi.org/10.18653/v1/2023.acl-long.146) |  | 0 |  | Shengqiong Wu, Hao Fei, Wei Ji, TatSeng Chua |  |
| 1390 |  |  [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.147) |  | 0 |  | Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy KaWei Lee, EePeng Lim |  |
| 1391 |  |  [RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models](https://doi.org/10.18653/v1/2023.acl-long.148) |  | 0 |  | Zheng Liu, Shitao Xiao, Yingxia Shao, Zhao Cao |  |
| 1392 |  |  [DecompX: Explaining Transformers Decisions by Propagating Token Decomposition](https://doi.org/10.18653/v1/2023.acl-long.149) |  | 0 |  | Ali Modarressi, Mohsen Fayyaz, Ehsan Aghazadeh, Yadollah Yaghoobzadeh, Mohammad Taher Pilehvar |  |
| 1393 |  |  [Symbolic Chain-of-Thought Distillation: Small Models Can Also "Think" Step-by-Step](https://doi.org/10.18653/v1/2023.acl-long.150) |  | 0 |  | Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, KaiWei Chang, Yejin Choi |  |
| 1394 |  |  [Generating EDU Extracts for Plan-Guided Summary Re-Ranking](https://doi.org/10.18653/v1/2023.acl-long.151) |  | 0 |  | Griffin Adams, Alexander R. Fabbri, Faisal Ladhak, Noémie Elhadad, Kathleen R. McKeown |  |
| 1395 |  |  [A Survey on Asking Clarification Questions Datasets in Conversational Systems](https://doi.org/10.18653/v1/2023.acl-long.152) |  | 0 |  | Hossein A. Rahmani, Xi Wang, Yue Feng, Qiang Zhang, Emine Yilmaz, Aldo Lipani |  |
| 1396 |  |  [Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters](https://doi.org/10.18653/v1/2023.acl-long.153) |  | 0 |  | Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, Huan Sun |  |
| 1397 |  |  [Small Data, Big Impact: Leveraging Minimal Data for Effective Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.154) |  | 0 |  | Jean Maillard, Cynthia Gao, Elahe Kalbassi, Kaushik Ram Sadagopan, Vedanuj Goswami, Philipp Koehn, Angela Fan, Francisco Guzmán |  |
| 1398 |  |  [RMLM: A Flexible Defense Framework for Proactively Mitigating Word-level Adversarial Attacks](https://doi.org/10.18653/v1/2023.acl-long.155) |  | 0 |  | Zhaoyang Wang, Zhiyue Liu, Xiaopeng Zheng, Qinliang Su, Jiahai Wang |  |
| 1399 |  |  [Gradient-based Intra-attention Pruning on Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.156) |  | 0 |  | Ziqing Yang, Yiming Cui, Xin Yao, Shijin Wang |  |
| 1400 |  |  [Learning to Substitute Spans towards Improving Compositional Generalization](https://doi.org/10.18653/v1/2023.acl-long.157) |  | 0 |  | Zhaoyi Li, Ying Wei, Defu Lian |  |
| 1401 |  |  [DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation](https://doi.org/10.18653/v1/2023.acl-long.158) |  | 0 |  | Guanqun Bi, Lei Shen, Yanan Cao, Meng Chen, Yuqiang Xie, Zheng Lin, Xiaodong He |  |
| 1402 |  |  [BREAK: Breaking the Dialogue State Tracking Barrier with Beam Search and Re-ranking](https://doi.org/10.18653/v1/2023.acl-long.159) |  | 0 |  | Seungpil Won, Heeyoung Kwak, Joongbo Shin, Janghoon Han, Kyomin Jung |  |
| 1403 |  |  [Faithful Low-Resource Data-to-Text Generation through Cycle Training](https://doi.org/10.18653/v1/2023.acl-long.160) |  | 0 |  | Zhuoer Wang, Marcus D. Collins, Nikhita Vedula, Simone Filice, Shervin Malmasi, Oleg Rokhlenko |  |
| 1404 |  |  [Towards Stable Natural Language Understanding via Information Entropy Guided Debiasing](https://doi.org/10.18653/v1/2023.acl-long.161) |  | 0 |  | Li Du, Xiao Ding, Zhouhao Sun, Ting Liu, Bing Qin, Jingshuo Liu |  |
| 1405 |  |  [Dynamic and Efficient Inference for Text Generation via BERT Family](https://doi.org/10.18653/v1/2023.acl-long.162) |  | 0 |  | Xiaobo Liang, Juntao Li, Lijun Wu, Ziqiang Cao, Min Zhang |  |
| 1406 |  |  [Learning to Generate Equitable Text in Dialogue from Biased Training Data](https://doi.org/10.18653/v1/2023.acl-long.163) |  | 0 |  | Anthony Sicilia, Malihe Alikhani |  |
| 1407 |  |  [Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification](https://doi.org/10.18653/v1/2023.acl-long.164) |  | 0 |  | Ke Ji, Yixin Lian, Jingsheng Gao, Baoyuan Wang |  |
| 1408 |  |  [Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization](https://doi.org/10.18653/v1/2023.acl-long.165) |  | 0 |  | Yunlong Liang, Fandong Meng, Jinan Xu, Jiaan Wang, Yufeng Chen, Jie Zhou |  |
| 1409 |  |  [Helping a Friend or Supporting a Cause? Disentangling Active and Passive Cosponsorship in the U.S. Congress](https://doi.org/10.18653/v1/2023.acl-long.166) |  | 0 |  | Giuseppe Russo, Christoph Gote, Laurence Brandenberger, Sophia Schlosser, Frank Schweitzer |  |
| 1410 |  |  [TREA: Tree-Structure Reasoning Schema for Conversational Recommendation](https://doi.org/10.18653/v1/2023.acl-long.167) |  | 0 |  | Wendi Li, Wei Wei, Xiaoye Qu, XianLing Mao, Ye Yuan, Wenfeng Xie, Dangyang Chen |  |
| 1411 |  |  [CATS: A Pragmatic Chinese Answer-to-Sequence Dataset with Large Scale and High Quality](https://doi.org/10.18653/v1/2023.acl-long.168) |  | 0 |  | Liang Li, Ruiying Geng, Chengyang Fang, Bing Li, Can Ma, Rongyu Cao, Binhua Li, Fei Huang, Yongbin Li |  |
| 1412 |  |  [Multilingual Multifaceted Understanding of Online News in Terms of Genre, Framing, and Persuasion Techniques](https://doi.org/10.18653/v1/2023.acl-long.169) |  | 0 |  | Jakub Piskorski, Nicolas Stefanovitch, Nikolaos Nikolaidis, Giovanni Da San Martino, Preslav Nakov |  |
| 1413 |  |  [Learning Action Conditions from Instructional Manuals for Instruction Understanding](https://doi.org/10.18653/v1/2023.acl-long.170) |  | 0 |  | TeLin Wu, Caiqi Zhang, Qingyuan Hu, Alexander Spangher, Nanyun Peng |  |
| 1414 |  |  [StoryWars: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation](https://doi.org/10.18653/v1/2023.acl-long.171) |  | 0 |  | Yulun Du, Lydia B. Chilton |  |
| 1415 |  |  [Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning](https://doi.org/10.18653/v1/2023.acl-long.172) |  | 0 |  | Fan Yin, Jesse Vig, Philippe Laban, Shafiq Joty, Caiming Xiong, ChienSheng Wu |  |
| 1416 |  |  [Do PLMs Know and Understand Ontological Knowledge?](https://doi.org/10.18653/v1/2023.acl-long.173) |  | 0 |  | Weiqi Wu, Chengyue Jiang, Yong Jiang, Pengjun Xie, Kewei Tu |  |
| 1417 |  |  [CORE: Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection](https://doi.org/10.18653/v1/2023.acl-long.174) |  | 0 |  | Chongyang Tao, Jiazhan Feng, Tao Shen, Chang Liu, Juntao Li, Xiubo Geng, Daxin Jiang |  |
| 1418 |  |  [Exploring How Generative Adversarial Networks Learn Phonological Representations](https://doi.org/10.18653/v1/2023.acl-long.175) |  | 0 |  | Jingyi Chen, Micha Elsner |  |
| 1419 |  |  [Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis](https://doi.org/10.18653/v1/2023.acl-long.176) |  | 0 |  | Mario Giulianelli, Iris Luden, Raquel Fernández, Andrey Kutuzov |  |
| 1420 |  |  [Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing](https://doi.org/10.18653/v1/2023.acl-long.177) |  | 0 |  | Hao Yan, Saurabh Srivastava, Yintao Tai, Sida I. Wang, Wentau Yih, Ziyu Yao |  |
| 1421 |  |  [InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation](https://doi.org/10.18653/v1/2023.acl-long.178) |  | 0 |  | Anwen Hu, Shizhe Chen, Liang Zhang, Qin Jin |  |
| 1422 |  |  [An Invariant Learning Characterization of Controlled Text Generation](https://doi.org/10.18653/v1/2023.acl-long.179) |  | 0 |  | Carolina Zheng, Claudia Shi, Keyon Vafa, Amir Feder, David M. Blei |  |
| 1423 |  |  [HistRED: A Historical Document-Level Relation Extraction Dataset](https://doi.org/10.18653/v1/2023.acl-long.180) |  | 0 |  | Soyoung Yang, Minseok Choi, Youngwoo Cho, Jaegul Choo |  |
| 1424 |  |  [A Critical Evaluation of Evaluations for Long-form Question Answering](https://doi.org/10.18653/v1/2023.acl-long.181) |  | 0 |  | Fangyuan Xu, Yixiao Song, Mohit Iyyer, Eunsol Choi |  |
| 1425 |  |  [HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation](https://doi.org/10.18653/v1/2023.acl-long.182) |  | 0 |  | Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, Songfang Huang |  |
| 1426 |  |  [Generating User-Engaging News Headlines](https://doi.org/10.18653/v1/2023.acl-long.183) |  | 0 |  | Pengshan Cai, Kaiqiang Song, Sangwoo Cho, Hongwei Wang, Xiaoyang Wang, Hong Yu, Fei Liu, Dong Yu |  |
| 1427 |  |  [Word sense extension](https://doi.org/10.18653/v1/2023.acl-long.184) |  | 0 |  | Lei Yu, Yang Xu |  |
| 1428 |  |  [PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism](https://doi.org/10.18653/v1/2023.acl-long.185) |  | 0 |  | Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang, Hinrich Schütze |  |
| 1429 |  |  [Decoding Symbolism in Language Models](https://doi.org/10.18653/v1/2023.acl-long.186) |  | 0 |  | Meiqi Guo, Rebecca Hwa, Adriana Kovashka |  |
| 1430 |  |  [A Survey on Zero Pronoun Translation](https://doi.org/10.18653/v1/2023.acl-long.187) |  | 0 |  | Longyue Wang, Siyou Liu, Mingzhou Xu, Linfeng Song, Shuming Shi, Zhaopeng Tu |  |
| 1431 |  |  [We Understand Elliptical Sentences, and Language Models should Too: A New Dataset for Studying Ellipsis and its Interaction with Thematic Fit](https://doi.org/10.18653/v1/2023.acl-long.188) |  | 0 |  | Davide Testa, Emmanuele Chersoni, Alessandro Lenci |  |
| 1432 |  |  [MPCHAT: Towards Multimodal Persona-Grounded Conversation](https://doi.org/10.18653/v1/2023.acl-long.189) |  | 0 |  | Jaewoo Ahn, Yeda Song, Sangdoo Yun, Gunhee Kim |  |
| 1433 |  |  [DOC: Improving Long Story Coherence With Detailed Outline Control](https://doi.org/10.18653/v1/2023.acl-long.190) |  | 0 |  | Kevin Yang, Dan Klein, Nanyun Peng, Yuandong Tian |  |
| 1434 |  |  [Dual-Alignment Pre-training for Cross-lingual Sentence Embedding](https://doi.org/10.18653/v1/2023.acl-long.191) |  | 0 |  | Ziheng Li, Shaohan Huang, Zihan Zhang, ZhiHong Deng, Qiang Lou, Haizhen Huang, Jian Jiao, Furu Wei, Weiwei Deng, Qi Zhang |  |
| 1435 |  |  [Exploring Better Text Image Translation with Multimodal Codebook](https://doi.org/10.18653/v1/2023.acl-long.192) |  | 0 |  | Zhibin Lan, Jiawei Yu, Xiang Li, Wen Zhang, Jian Luan, Bin Wang, Degen Huang, Jinsong Su |  |
| 1436 |  |  [FEDLEGAL: The First Real-World Federated Learning Benchmark for Legal NLP](https://doi.org/10.18653/v1/2023.acl-long.193) |  | 0 |  | Zhuo Zhang, Xiangjing Hu, Jingyuan Zhang, Yating Zhang, Hui Wang, Lizhen Qu, Zenglin Xu |  |
| 1437 |  |  [A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning](https://doi.org/10.18653/v1/2023.acl-long.194) |  | 0 |  | Naibin Gu, Peng Fu, Xiyu Liu, Zhengxiao Liu, Zheng Lin, Weiping Wang |  |
| 1438 |  |  [History Semantic Graph Enhanced Conversational KBQA with Temporal Information Modeling](https://doi.org/10.18653/v1/2023.acl-long.195) |  | 0 |  | Hao Sun, Yang Li, Liwei Deng, Bowen Li, Binyuan Hui, Binhua Li, Yunshi Lan, Yan Zhang, Yongbin Li |  |
| 1439 |  |  [From the One, Judge of the Whole: Typed Entailment Graph Construction with Predicate Generation](https://doi.org/10.18653/v1/2023.acl-long.196) |  | 0 |  | Zhibin Chen, Yansong Feng, Dongyan Zhao |  |
| 1440 |  |  [Alleviating Over-smoothing for Unsupervised Sentence Representation](https://doi.org/10.18653/v1/2023.acl-long.197) |  | 0 |  | Nuo Chen, Linjun Shou, Jian Pei, Ming Gong, Bowen Cao, Jianhui Chang, Jia Li, Daxin Jiang |  |
| 1441 |  |  [Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model](https://doi.org/10.18653/v1/2023.acl-long.198) |  | 0 |  | Yeskendir Koishekenov, Alexandre Berard, Vassilina Nikoulina |  |
| 1442 |  |  [DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue](https://doi.org/10.18653/v1/2023.acl-long.199) |  | 0 |  | William Held, Christopher Hidey, Fei Liu, Eric Zhu, Rahul Goel, Diyi Yang, Rushin Shah |  |
| 1443 |  |  [From Characters to Words: Hierarchical Pre-trained Language Model for Open-vocabulary Language Understanding](https://doi.org/10.18653/v1/2023.acl-long.200) |  | 0 |  | Li Sun, Florian Luisier, Kayhan Batmanghelich, Dinei A. F. Florêncio, Cha Zhang |  |
| 1444 |  |  [MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling](https://doi.org/10.18653/v1/2023.acl-long.201) |  | 0 |  | Yu Song, Santiago Miret, Bang Liu |  |
| 1445 |  |  [Code4Struct: Code Generation for Few-Shot Event Structure Prediction](https://doi.org/10.18653/v1/2023.acl-long.202) |  | 0 |  | Xingyao Wang, Sha Li, Heng Ji |  |
| 1446 |  |  [GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles](https://doi.org/10.18653/v1/2023.acl-long.203) |  | 0 |  | Tanmay Parekh, IHung Hsu, KuanHao Huang, KaiWei Chang, Nanyun Peng |  |
| 1447 |  |  [Efficient Semiring-Weighted Earley Parsing](https://doi.org/10.18653/v1/2023.acl-long.204) |  | 0 |  | Andreas Opedal, Ran Zmigrod, Tim Vieira, Ryan Cotterell, Jason Eisner |  |
| 1448 |  |  [Tree-Based Representation and Generation of Natural and Mathematical Language](https://doi.org/10.18653/v1/2023.acl-long.205) |  | 0 |  | Alexander Scarlatos, Andrew S. Lan |  |
| 1449 |  |  [ParaLS: Lexical Substitution via Pretrained Paraphraser](https://doi.org/10.18653/v1/2023.acl-long.206) |  | 0 |  | Jipeng Qiang, Kang Liu, Yun Li, Yunhao Yuan, Yi Zhu |  |
| 1450 |  |  [Peer-Label Assisted Hierarchical Text Classification](https://doi.org/10.18653/v1/2023.acl-long.207) |  | 0 |  | Junru Song, Feifei Wang, Yang Yang |  |
| 1451 |  |  [Free Lunch for Efficient Textual Commonsense Integration in Language Models](https://doi.org/10.18653/v1/2023.acl-long.208) |  | 0 |  | Wanyun Cui, Xingran Chen |  |
| 1452 |  |  [A Probabilistic Framework for Discovering New Intents](https://doi.org/10.18653/v1/2023.acl-long.209) |  | 0 |  | Yunhua Zhou, Guofeng Quan, Xipeng Qiu |  |
| 1453 |  |  [MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset](https://doi.org/10.18653/v1/2023.acl-long.210) |  | 0 |  | Leonhard Hennig, Philippe Thomas, Sebastian Möller |  |
| 1454 |  |  [Towards Higher Pareto Frontier in Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.211) |  | 0 |  | YiChong Huang, Xiaocheng Feng, Xinwei Geng, Baohang Li, Bing Qin |  |
| 1455 |  |  [Small Pre-trained Language Models Can be Fine-tuned as Large Models via Over-Parameterization](https://doi.org/10.18653/v1/2023.acl-long.212) |  | 0 |  | ZeFeng Gao, Kun Zhou, Peiyu Liu, Wayne Xin Zhao, JiRong Wen |  |
| 1456 |  |  [Entity Tracking in Language Models](https://doi.org/10.18653/v1/2023.acl-long.213) |  | 0 |  | Najoung Kim, Sebastian Schuster |  |
| 1457 |  |  [A Textual Dataset for Situated Proactive Response Selection](https://doi.org/10.18653/v1/2023.acl-long.214) |  | 0 |  | Naoki Otani, Jun Araki, HyeongSik Kim, Eduard H. Hovy |  |
| 1458 |  |  [DiffusionNER: Boundary Diffusion for Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-long.215) |  | 0 |  | Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang |  |
| 1459 |  |  [WACO: Word-Aligned Contrastive Learning for Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.216) |  | 0 |  | Siqi Ouyang, Rong Ye, Lei Li |  |
| 1460 |  |  [Cross-lingual Continual Learning](https://doi.org/10.18653/v1/2023.acl-long.217) |  | 0 |  | Meryem M'hamdi, Xiang Ren, Jonathan May |  |
| 1461 |  |  [Faithful Question Answering with Monte-Carlo Planning](https://doi.org/10.18653/v1/2023.acl-long.218) |  | 0 |  | Ruixin Hong, Hongming Zhang, Hong Zhao, Dong Yu, Changshui Zhang |  |
| 1462 |  |  [Unbalanced Optimal Transport for Unbalanced Word Alignment](https://doi.org/10.18653/v1/2023.acl-long.219) |  | 0 |  | Yuki Arase, Han Bao, Sho Yokoi |  |
| 1463 |  |  [Guiding Computational Stance Detection with Expanded Stance Triangle Framework](https://doi.org/10.18653/v1/2023.acl-long.220) |  | 0 |  | Zhengyuan Liu, Yong Keong Yap, Hai Leong Chieu, Nancy F. Chen |  |
| 1464 |  |  [Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer with Fine-tuning Slow and Fast](https://doi.org/10.18653/v1/2023.acl-long.221) |  | 0 |  | Yiduo Guo, Yaobo Liang, Dongyan Zhao, Bing Liu, Nan Duan |  |
| 1465 |  |  [Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning](https://doi.org/10.18653/v1/2023.acl-long.222) |  | 0 |  | Ran Zhou, Xin Li, Lidong Bing, Erik Cambria, Chunyan Miao |  |
| 1466 |  |  [MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal Contributions in Vision and Language Models & Tasks](https://doi.org/10.18653/v1/2023.acl-long.223) |  | 0 |  | Letitia Parcalabescu, Anette Frank |  |
| 1467 |  |  [Towards Boosting the Open-Domain Chatbot with Human Feedback](https://doi.org/10.18653/v1/2023.acl-long.224) |  | 0 |  | Hua Lu, Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang |  |
| 1468 |  |  [Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations](https://doi.org/10.18653/v1/2023.acl-long.225) |  | 0 |  | Yang Deng, Wenxuan Zhang, Yifei Yuan, Wai Lam |  |
| 1469 |  |  [UTC-IE: A Unified Token-pair Classification Architecture for Information Extraction](https://doi.org/10.18653/v1/2023.acl-long.226) |  | 0 |  | Hang Yan, Yu Sun, Xiaonan Li, Yunhua Zhou, Xuanjing Huang, Xipeng Qiu |  |
| 1470 |  |  [Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model](https://doi.org/10.18653/v1/2023.acl-long.227) |  | 0 |  | Ali Omrani, Alireza Salkhordeh Ziabari, Charles Yu, Preni Golazizian, Brendan Kennedy, Mohammad Atari, Heng Ji, Morteza Dehghani |  |
| 1471 |  |  [Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation](https://doi.org/10.18653/v1/2023.acl-long.228) |  | 0 |  | Yixin Liu, Alexander R. Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty, ChienSheng Wu, Caiming Xiong, Dragomir Radev |  |
| 1472 |  |  [FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information](https://doi.org/10.18653/v1/2023.acl-long.229) |  | 0 |  | Andrew Zhu, Karmanya Aggarwal, Alexander H. Feng, Lara J. Martin, Chris CallisonBurch |  |
| 1473 |  |  [A fine-grained comparison of pragmatic language understanding in humans and language models](https://doi.org/10.18653/v1/2023.acl-long.230) |  | 0 |  | Jennifer Hu, Sammy Floyd, Olessia Jouravlev, Evelina Fedorenko, Edward Gibson |  |
| 1474 |  |  [Counterfactual Multihop QA: A Cause-Effect Approach for Reducing Disconnected Reasoning](https://doi.org/10.18653/v1/2023.acl-long.231) |  | 0 |  | Wangzhen Guo, Qinkang Gong, Yanghui Rao, Hanjiang Lai |  |
| 1475 |  |  [Causal-Debias: Unifying Debiasing in Pretrained Language Models and Fine-tuning via Causal Invariant Learning](https://doi.org/10.18653/v1/2023.acl-long.232) |  | 0 |  | Fan Zhou, Yuzhou Mao, Liu Yu, Yi Yang, Ting Zhong |  |
| 1476 |  |  [Parameter-Efficient Fine-Tuning without Introducing New Latency](https://doi.org/10.18653/v1/2023.acl-long.233) |  | 0 |  | Baohao Liao, Yan Meng, Christof Monz |  |
| 1477 |  |  [MANNER: A Variational Memory-Augmented Model for Cross Domain Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-long.234) |  | 0 |  | Jinyuan Fang, Xiaobin Wang, Zaiqiao Meng, Pengjun Xie, Fei Huang, Yong Jiang |  |
| 1478 |  |  [MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages](https://doi.org/10.18653/v1/2023.acl-long.235) |  | 0 |  | Jack FitzGerald, Christopher Hench, Charith Peris, Scott Mackie, Kay Rottmann, Ana Sanchez, Aaron Nash, Liam Urbach, Vishesh Kakarala, Richa Singh, Swetha Ranganath, Laurie Crist, Misha Britan, Wouter Leeuwis, Gökhan Tür, Prem Natarajan |  |
| 1479 |  |  [Distilling Script Knowledge from Large Language Models for Constrained Language Planning](https://doi.org/10.18653/v1/2023.acl-long.236) |  | 0 |  | Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang |  |
| 1480 |  |  [REDFM: a Filtered and Multilingual Relation Extraction Dataset](https://doi.org/10.18653/v1/2023.acl-long.237) |  | 0 |  | PereLluís Huguet Cabot, Simone Tedeschi, AxelCyrille Ngonga Ngomo, Roberto Navigli |  |
| 1481 |  |  [Modeling Appropriate Language in Argumentation](https://doi.org/10.18653/v1/2023.acl-long.238) |  | 0 |  | Timon Ziegenbein, Shahbaz Syed, Felix Lange, Martin Potthast, Henning Wachsmuth |  |
| 1482 |  |  [CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels](https://doi.org/10.18653/v1/2023.acl-long.239) |  | 0 |  | Hyunsoo Cho, Youna Kim, Sanggoo Lee |  |
| 1483 |  |  [MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction](https://doi.org/10.18653/v1/2023.acl-long.240) |  | 0 |  | Zhibin Gou, Qingyan Guo, Yujiu Yang |  |
| 1484 |  |  [ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems](https://doi.org/10.18653/v1/2023.acl-long.241) |  | 0 |  | Sarik Ghazarian, Yijia Shao, Rujun Han, Aram Galstyan, Nanyun Peng |  |
| 1485 |  |  [Explanation-based Finetuning Makes Models More Robust to Spurious Cues](https://doi.org/10.18653/v1/2023.acl-long.242) |  | 0 |  | Josh Magnus Ludan, Yixuan Meng, Tai Nguyen, Saurabh Shah, Qing Lyu, Marianna Apidianaki, Chris CallisonBurch |  |
| 1486 |  |  [CAME: Confidence-guided Adaptive Memory Efficient Optimization](https://doi.org/10.18653/v1/2023.acl-long.243) |  | 0 |  | Yang Luo, Xiaozhe Ren, Zangwei Zheng, Zhuo Jiang, Xin Jiang, Yang You |  |
| 1487 |  |  [On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning](https://doi.org/10.18653/v1/2023.acl-long.244) |  | 0 |  | Omar Shaikh, Hongxin Zhang, William Held, Michael S. Bernstein, Diyi Yang |  |
| 1488 |  |  [Solving Math Word Problems via Cooperative Reasoning induced Language Models](https://doi.org/10.18653/v1/2023.acl-long.245) |  | 0 |  | Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang, Yongfeng Huang, Ruyi Gan, Jiaxing Zhang, Yujiu Yang |  |
| 1489 |  |  [Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model](https://doi.org/10.18653/v1/2023.acl-long.246) |  | 0 |  | Chantal Amrhein, Florian Schottmann, Rico Sennrich, Samuel Läubli |  |
| 1490 |  |  [Early Discovery of Disappearing Entities in Microblogs](https://doi.org/10.18653/v1/2023.acl-long.247) |  | 0 |  | Satoshi Akasaki, Naoki Yoshinaga, Masashi Toyoda |  |
| 1491 |  |  [DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models](https://doi.org/10.18653/v1/2023.acl-long.248) |  | 0 |  | Zhengfu He, Tianxiang Sun, Qiong Tang, Kuanning Wang, Xuanjing Huang, Xipeng Qiu |  |
| 1492 |  |  [Lifting the Curse of Capacity Gap in Distilling Language Models](https://doi.org/10.18653/v1/2023.acl-long.249) |  | 0 |  | Chen Zhang, Yang Yang, Jiahao Liu, Jingang Wang, Yunsen Xian, Benyou Wang, Dawei Song |  |
| 1493 |  |  [Towards Faithful Dialogues via Focus Learning](https://doi.org/10.18653/v1/2023.acl-long.250) |  | 0 |  | Yifan Deng, Xingsheng Zhang, Heyan Huang, Yue Hu |  |
| 1494 |  |  [Back Translation for Speech-to-text Translation Without Transcripts](https://doi.org/10.18653/v1/2023.acl-long.251) |  | 0 |  | Qingkai Fang, Yang Feng |  |
| 1495 |  |  [Prompter: Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain Adaptation](https://doi.org/10.18653/v1/2023.acl-long.252) |  | 0 |  | Ibrahim Taha Aksu, MinYen Kan, Nancy F. Chen |  |
| 1496 |  |  [Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation](https://doi.org/10.18653/v1/2023.acl-long.253) |  | 0 |  | Chen Tang, Hongbo Zhang, Tyler Loakman, Chenghua Lin, Frank Guerin |  |
| 1497 |  |  [Multi-modal Action Chain Abductive Reasoning](https://doi.org/10.18653/v1/2023.acl-long.254) |  | 0 |  | Mengze Li, Tianbao Wang, Jiahe Xu, Kairong Han, Shengyu Zhang, Zhou Zhao, Jiaxu Miao, Wenqiao Zhang, Shiliang Pu, Fei Wu |  |
| 1498 |  |  [Exploring the Capacity of Pretrained Language Models for Reasoning about Actions and Change](https://doi.org/10.18653/v1/2023.acl-long.255) |  | 0 |  | Weinan He, Canming Huang, Zhanhao Xiao, Yongmei Liu |  |
| 1499 |  |  [Unified Demonstration Retriever for In-Context Learning](https://doi.org/10.18653/v1/2023.acl-long.256) |  | 0 |  | Xiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei Zhu, Yuan Ni, Guotong Xie, Xiaoling Wang, Xipeng Qiu |  |
| 1500 |  |  [Movie101: A New Movie Understanding Benchmark](https://doi.org/10.18653/v1/2023.acl-long.257) |  | 0 |  | Zihao Yue, Qi Zhang, Anwen Hu, Liang Zhang, Ziheng Wang, Qin Jin |  |
| 1501 |  |  [Enhancing Language Representation with Constructional Information for Natural Language Understanding](https://doi.org/10.18653/v1/2023.acl-long.258) |  | 0 |  | Lvxiaowei Xu, Jianwang Wu, Jiawei Peng, Zhilin Gong, Ming Cai, Tianxiang Wang |  |
| 1502 |  |  [Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs](https://doi.org/10.18653/v1/2023.acl-long.259) |  | 0 |  | Siyuan Wang, Zhongyu Wei, Meng Han, Zhihao Fan, Haijun Shan, Qi Zhang, Xuanjing Huang |  |
| 1503 |  |  [DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships](https://doi.org/10.18653/v1/2023.acl-long.260) |  | 0 |  | Chenzhengyi Liu, Jie Huang, Kerui Zhu, Kevin ChenChuan Chang |  |
| 1504 |  |  [Incorporating Attribution Importance for Improving Faithfulness Metrics](https://doi.org/10.18653/v1/2023.acl-long.261) |  | 0 |  | Zhixue Zhao, Nikolaos Aletras |  |
| 1505 |  |  [Reward Gaming in Conditional Text Generation](https://doi.org/10.18653/v1/2023.acl-long.262) |  | 0 |  | Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P. Parikh, He He |  |
| 1506 |  |  [Hidden Schema Networks](https://doi.org/10.18653/v1/2023.acl-long.263) |  | 0 |  | Ramsés J. Sánchez, Lukas Conrads, Pascal Welke, Kostadin Cvejoski, César Ojeda Marin |  |
| 1507 |  |  [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations](https://doi.org/10.18653/v1/2023.acl-long.264) |  | 0 |  | Linlin Liu, Xingxuan Li, Megh Thakkar, Xin Li, Shafiq Joty, Luo Si, Lidong Bing |  |
| 1508 |  |  [An Ordinal Latent Variable Model of Conflict Intensity](https://doi.org/10.18653/v1/2023.acl-long.265) |  | 0 |  | Niklas Stoehr, Lucas Torroba Hennigen, Josef Valvoda, Robert West, Ryan Cotterell, Aaron Schein |  |
| 1509 |  |  [Multilingual Conceptual Coverage in Text-to-Image Models](https://doi.org/10.18653/v1/2023.acl-long.266) |  | 0 |  | Michael Saxon, William Yang Wang |  |
| 1510 |  |  [Pre-Training to Learn in Context](https://doi.org/10.18653/v1/2023.acl-long.267) |  | 0 |  | Yuxian Gu, Li Dong, Furu Wei, Minlie Huang |  |
| 1511 |  |  [Ethical Considerations for Machine Translation of Indigenous Languages: Giving a Voice to the Speakers](https://doi.org/10.18653/v1/2023.acl-long.268) |  | 0 |  | Manuel Mager, Elisabeth Mager, Katharina Kann, Ngoc Thang Vu |  |
| 1512 |  |  [Revisiting non-English Text Simplification: A Unified Multilingual Benchmark](https://doi.org/10.18653/v1/2023.acl-long.269) |  | 0 |  | Michael J. Ryan, Tarek Naous, Wei Xu |  |
| 1513 |  |  [Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments](https://doi.org/10.18653/v1/2023.acl-long.270) |  | 0 |  | Yu Gu, Xiang Deng, Yu Su |  |
| 1514 |  |  [Privacy-Preserving Domain Adaptation of Semantic Parsers](https://doi.org/10.18653/v1/2023.acl-long.271) |  | 0 |  | Fatemehsadat Mireshghallah, Yu Su, Tatsunori Hashimoto, Jason Eisner, Richard Shin |  |
| 1515 |  |  [Guide the Many-to-One Assignment: Open Information Extraction via IoU-aware Optimal Transport](https://doi.org/10.18653/v1/2023.acl-long.272) |  | 0 |  | Kaiwen Wei, Yiran Yang, Li Jin, Xian Sun, Zequn Zhang, Jingyuan Zhang, Xiao Li, Linhao Zhang, Jintao Liu, Zhi Guo |  |
| 1516 |  |  [Actively Supervised Clustering for Open Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.273) |  | 0 |  | Jun Zhao, Yongxin Zhang, Qi Zhang, Tao Gui, Zhongyu Wei, Minlong Peng, Mingming Sun |  |
| 1517 |  |  [ConvGQR: Generative Query Reformulation for Conversational Search](https://doi.org/10.18653/v1/2023.acl-long.274) |  | 0 |  | Fengran Mo, Kelong Mao, Yutao Zhu, Yihong Wu, Kaiyu Huang, JianYun Nie |  |
| 1518 |  |  [KILM: Knowledge Injection into Encoder-Decoder Language Models](https://doi.org/10.18653/v1/2023.acl-long.275) |  | 0 |  | Yan Xu, Mahdi Namazifar, Devamanyu Hazarika, Aishwarya Padmakumar, Yang Liu, Dilek HakkaniTür |  |
| 1519 |  |  [VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions](https://doi.org/10.18653/v1/2023.acl-long.276) |  | 0 |  | Yuxuan Wang, Zilong Zheng, Xueliang Zhao, Jinpeng Li, Yueqian Wang, Dongyan Zhao |  |
| 1520 |  |  [NLPeer: A Unified Resource for the Computational Study of Peer Review](https://doi.org/10.18653/v1/2023.acl-long.277) |  | 0 |  | Nils Dycke, Ilia Kuznetsov, Iryna Gurevych |  |
| 1521 |  |  [IM-TQA: A Chinese Table Question Answering Dataset with Implicit and Multi-type Table Structures](https://doi.org/10.18653/v1/2023.acl-long.278) |  | 0 |  | Mingyu Zheng, Yang Hao, Wenbin Jiang, Zheng Lin, Yajuan Lyu, Qiaoqiao She, Weiping Wang |  |
| 1522 |  |  [Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization](https://doi.org/10.18653/v1/2023.acl-long.279) |  | 0 |  | Pengcheng He, Baolin Peng, Song Wang, Yang Liu, Ruochen Xu, Hany Hassan, Yu Shi, Chenguang Zhu, Wayne Xiong, Michael Zeng, Jianfeng Gao, Xuedong Huang |  |
| 1523 |  |  [Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models' Memories](https://doi.org/10.18653/v1/2023.acl-long.280) |  | 0 |  | Shizhe Diao, Tianyang Xu, Ruijia Xu, Jiawei Wang, Tong Zhang |  |
| 1524 |  |  [Unsupervised Graph-Text Mutual Conversion with a Unified Pretrained Language Model](https://doi.org/10.18653/v1/2023.acl-long.281) |  | 0 |  | Yi Xu, Shuqian Sheng, Jiexing Qi, Luoyi Fu, Zhouhan Lin, Xinbing Wang, Chenghu Zhou |  |
| 1525 |  |  [Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications](https://doi.org/10.18653/v1/2023.acl-long.282) |  | 0 |  | Han Cheol Moon, Shafiq R. Joty, Ruochen Zhao, Megh Thakkar, Chi Xu |  |
| 1526 |  |  [SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes](https://doi.org/10.18653/v1/2023.acl-long.283) |  | 0 |  | Wenda Xu, Xian Qian, Mingxuan Wang, Lei Li, William Yang Wang |  |
| 1527 |  |  [Tokenization and the Noiseless Channel](https://doi.org/10.18653/v1/2023.acl-long.284) |  | 0 |  | Vilém Zouhar, Clara Meister, Juan Luis Gastaldi, Li Du, Mrinmaya Sachan, Ryan Cotterell |  |
| 1528 |  |  [Contextual Distortion Reveals Constituency: Masked Language Models are Implicit Parsers](https://doi.org/10.18653/v1/2023.acl-long.285) |  | 0 |  | Jiaxi Li, Wei Lu |  |
| 1529 |  |  [MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning](https://doi.org/10.18653/v1/2023.acl-long.286) |  | 0 |  | Zhenrui Yue, Huimin Zeng, Yang Zhang, Lanyu Shang, Dong Wang |  |
| 1530 |  |  [Tackling Modality Heterogeneity with Multi-View Calibration Network for Multimodal Sentiment Detection](https://doi.org/10.18653/v1/2023.acl-long.287) |  | 0 |  | Yiwei Wei, Shaozu Yuan, Ruosong Yang, Lei Shen, Zhangmeizhi Li, Longbiao Wang, Meng Chen |  |
| 1531 |  |  [COLA: Contextualized Commonsense Causal Reasoning from the Causal Inference Perspective](https://doi.org/10.18653/v1/2023.acl-long.288) |  | 0 |  | Zhaowei Wang, Quyet V. Do, Hongming Zhang, Jiayao Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song, Ginny Y. Wong, Simon See |  |
| 1532 |  |  [MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization](https://doi.org/10.18653/v1/2023.acl-long.289) |  | 0 |  | Shivam Sharma, Ramaneswaran S., Udit Arora, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 1533 |  |  [WikiHowQA: A Comprehensive Benchmark for Multi-Document Non-Factoid Question Answering](https://doi.org/10.18653/v1/2023.acl-long.290) |  | 0 |  | Valeria BolotovaBaranova, Vladislav Blinov, Sofya Filippova, Falk Scholer, Mark Sanderson |  |
| 1534 |  |  [Making Language Models Better Reasoners with Step-Aware Verifier](https://doi.org/10.18653/v1/2023.acl-long.291) |  | 0 |  | Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, JianGuang Lou, Weizhu Chen |  |
| 1535 |  |  [Distributed Marker Representation for Ambiguous Discourse Markers and Entangled Relations](https://doi.org/10.18653/v1/2023.acl-long.292) |  | 0 |  | Dongyu Ru, Lin Qiu, Xipeng Qiu, Yue Zhang, Zheng Zhang |  |
| 1536 |  |  [MISGENDERED: Limits of Large Language Models in Understanding Pronouns](https://doi.org/10.18653/v1/2023.acl-long.293) |  | 0 |  | Tamanna Hossain, Sunipa Dev, Sameer Singh |  |
| 1537 |  |  [Reasoning with Language Model Prompting: A Survey](https://doi.org/10.18653/v1/2023.acl-long.294) |  | 0 |  | Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, Huajun Chen |  |
| 1538 |  |  [Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation](https://doi.org/10.18653/v1/2023.acl-long.295) |  | 0 |  | Matthieu Futeral, Cordelia Schmid, Ivan Laptev, Benoît Sagot, Rachel Bawden |  |
| 1539 |  |  [Hybrid Knowledge Transfer for Improved Cross-Lingual Event Detection via Hierarchical Sample Selection](https://doi.org/10.18653/v1/2023.acl-long.296) |  | 0 |  | Luis GuzmanNateras, Franck Dernoncourt, Thien Huu Nguyen |  |
| 1540 |  |  [BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training](https://doi.org/10.18653/v1/2023.acl-long.297) |  | 0 |  | Yiming Yan, Tao Wang, Chengqi Zhao, Shujian Huang, Jiajun Chen, Mingxuan Wang |  |
| 1541 |  |  [Cross-modal Attention Congruence Regularization for Vision-Language Relation Alignment](https://doi.org/10.18653/v1/2023.acl-long.298) |  | 0 |  | Rohan Pandey, Rulin Shao, Paul Pu Liang, Ruslan Salakhutdinov, LouisPhilippe Morency |  |
| 1542 |  |  [Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona](https://doi.org/10.18653/v1/2023.acl-long.299) |  | 0 |  | Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, Ruifang He, Yuexian Hou |  |
| 1543 |  |  [Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge](https://doi.org/10.18653/v1/2023.acl-long.300) |  | 0 |  | Yasumasa Onoe, Michael J. Q. Zhang, Shankar Padmanabhan, Greg Durrett, Eunsol Choi |  |
| 1544 |  |  [Explaining How Transformers Use Context to Build Predictions](https://doi.org/10.18653/v1/2023.acl-long.301) |  | 0 |  | Javier Ferrando, Gerard I. Gállego, Ioannis Tsiamas, Marta R. Costajussà |  |
| 1545 |  |  [DISCO: Distilling Counterfactuals with Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.302) |  | 0 |  | Zeming Chen, Qiyue Gao, Antoine Bosselut, Ashish Sabharwal, Kyle Richardson |  |
| 1546 |  |  [Non-Sequential Graph Script Induction via Multimedia Grounding](https://doi.org/10.18653/v1/2023.acl-long.303) |  | 0 |  | Yu Zhou, Sha Li, Manling Li, Xudong Lin, ShihFu Chang, Mohit Bansal, Heng Ji |  |
| 1547 |  |  [SCOTT: Self-Consistent Chain-of-Thought Distillation](https://doi.org/10.18653/v1/2023.acl-long.304) |  | 0 |  | Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, Xiang Ren |  |
| 1548 |  |  [Clinical Note Owns its Hierarchy: Multi-Level Hypergraph Neural Networks for Patient-Level Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.305) |  | 0 |  | Nayeon Kim, Yinhua Piao, Sun Kim |  |
| 1549 |  |  [Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization](https://doi.org/10.18653/v1/2023.acl-long.306) |  | 0 |  | Dongqi Liu, Yifan Wang, Vera Demberg |  |
| 1550 |  |  [Evaluating Open-Domain Question Answering in the Era of Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.307) |  | 0 |  | Ehsan Kamalloo, Nouha Dziri, Charles L. A. Clarke, Davood Rafiei |  |
| 1551 |  |  [No clues good clues: out of context Lexical Relation Classification](https://doi.org/10.18653/v1/2023.acl-long.308) |  | 0 |  | Lucia Pitarch, Jordi Bernad, Lacramioara Dranca, Carlos Bobed Lisbona, Jorge Gracia |  |
| 1552 |  |  [Won't Get Fooled Again: Answering Questions with False Premises](https://doi.org/10.18653/v1/2023.acl-long.309) |  | 0 |  | Shengding Hu, Yifan Luo, Huadong Wang, Xingyi Cheng, Zhiyuan Liu, Maosong Sun |  |
| 1553 |  |  [What the DAAM: Interpreting Stable Diffusion Using Cross Attention](https://doi.org/10.18653/v1/2023.acl-long.310) |  | 0 |  | Raphael Tang, Linqing Liu, Akshat Pandey, Zhiying Jiang, Gefei Yang, Karun Kumar, Pontus Stenetorp, Jimmy Lin, Ferhan Ture |  |
| 1554 |  |  [Zero-shot Faithful Factual Error Correction](https://doi.org/10.18653/v1/2023.acl-long.311) |  | 0 |  | KungHsiang Huang, Hou Pong Chan, Heng Ji |  |
| 1555 |  |  [Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification](https://doi.org/10.18653/v1/2023.acl-long.312) |  | 0 |  | Sha Li, Ruining Zhao, Manling Li, Heng Ji, Chris CallisonBurch, Jiawei Han |  |
| 1556 |  |  [Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts](https://doi.org/10.18653/v1/2023.acl-long.313) |  | 0 |  | Mohna Chakraborty, Adithya Kulkarni, Qi Li |  |
| 1557 |  |  [Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging](https://doi.org/10.18653/v1/2023.acl-long.314) |  | 0 |  | Fabian David Schmidt, Ivan Vulic, Goran Glavas |  |
| 1558 |  |  [Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training](https://doi.org/10.18653/v1/2023.acl-long.315) |  | 0 |  | Yan Zeng, Wangchunshu Zhou, Ao Luo, Ziming Cheng, Xinsong Zhang |  |
| 1559 |  |  [Unsupervised Discontinuous Constituency Parsing with Mildly Context-Sensitive Grammars](https://doi.org/10.18653/v1/2023.acl-long.316) |  | 0 |  | Songlin Yang, Roger Levy, Yoon Kim |  |
| 1560 |  |  [Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions](https://doi.org/10.18653/v1/2023.acl-long.317) |  | 0 |  | Satwik Bhattamishra, Arkil Patel, Varun Kanade, Phil Blunsom |  |
| 1561 |  |  [Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation](https://doi.org/10.18653/v1/2023.acl-long.318) |  | 0 |  | Rishabh Gupta, Shaily Desai, Manvi Goel, Anil Bandhakavi, Tanmoy Chakraborty, Md. Shad Akhtar |  |
| 1562 |  |  [DITTO: Data-efficient and Fair Targeted Subset Selection for ASR Accent Adaptation](https://doi.org/10.18653/v1/2023.acl-long.319) |  | 0 |  | Suraj Kothawade, Anmol Reddy Mekala, D. Chandra Sekhara Hetha Havya, Mayank Kothyari, Rishabh K. Iyer, Ganesh Ramakrishnan, Preethi Jyothi |  |
| 1563 |  |  [Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework](https://doi.org/10.18653/v1/2023.acl-long.320) |  | 0 |  | Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, Lidong Bing |  |
| 1564 |  |  [Bridging the Domain Gaps in Context Representations for k-Nearest Neighbor Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.321) |  | 0 |  | Zhiwei Cao, Baosong Yang, Huan Lin, Suhang Wu, Xiangpeng Wei, Dayiheng Liu, Jun Xie, Min Zhang, Jinsong Su |  |
| 1565 |  |  [Node Placement in Argument Maps: Modeling Unidirectional Relations in High & Low-Resource Scenarios](https://doi.org/10.18653/v1/2023.acl-long.322) |  | 0 |  | Iman Jundi, Neele Falk, Eva Maria Vecchi, Gabriella Lapesa |  |
| 1566 |  |  [Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review](https://doi.org/10.18653/v1/2023.acl-long.323) |  | 0 |  | Fred Philippy, Siwen Guo, Shohreh Haddadan |  |
| 1567 |  |  [Toward Human-Like Evaluation for Natural Language Generation with Error Analysis](https://doi.org/10.18653/v1/2023.acl-long.324) |  | 0 |  | Qingyu Lu, Liang Ding, Liping Xie, Kanjian Zhang, Derek F. Wong, Dacheng Tao |  |
| 1568 |  |  [Connective Prediction for Implicit Discourse Relation Recognition via Knowledge Distillation](https://doi.org/10.18653/v1/2023.acl-long.325) |  | 0 |  | Hongyi Wu, Hao Zhou, Man Lan, Yuanbin Wu, Yadong Zhang |  |
| 1569 |  |  [What is the best recipe for character-level encoder-only modelling?](https://doi.org/10.18653/v1/2023.acl-long.326) |  | 0 |  | Kris Cao |  |
| 1570 |  |  [Unifying Cross-Lingual and Cross-Modal Modeling Towards Weakly Supervised Multilingual Vision-Language Pre-training](https://doi.org/10.18653/v1/2023.acl-long.327) |  | 0 |  | Zejun Li, Zhihao Fan, Jingjing Chen, Qi Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 1571 |  |  [Learning "O" Helps for Learning More: Handling the Unlabeled Entity Problem for Class-incremental NER](https://doi.org/10.18653/v1/2023.acl-long.328) |  | 0 |  | Ruotian Ma, Xuanting Chen, Zhang Lin, Xin Zhou, Junzhe Wang, Tao Gui, Qi Zhang, Xiang Gao, Yun Wen Chen |  |
| 1572 |  |  [Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination](https://doi.org/10.18653/v1/2023.acl-long.329) |  | 0 |  | Hao Fei, Qian Liu, Meishan Zhang, Min Zhang, TatSeng Chua |  |
| 1573 |  |  [CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-long.330) |  | 0 |  | Tingting Ma, Qianhui Wu, Huiqiang Jiang, Börje Karlsson, Tiejun Zhao, ChinYew Lin |  |
| 1574 |  |  [Dialect-robust Evaluation of Generated Text](https://doi.org/10.18653/v1/2023.acl-long.331) |  | 0 |  | Jiao Sun, Thibault Sellam, Elizabeth Clark, Tu Vu, Timothy Dozat, Dan Garrette, Aditya Siddhant, Jacob Eisenstein, Sebastian Gehrmann |  |
| 1575 |  |  [Understanding and Improving the Robustness of Terminology Constraints in Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.332) |  | 0 |  | Huaao Zhang, Qiang Wang, Bo Qin, Zelin Shi, Haibo Wang, Ming Chen |  |
| 1576 |  |  [Language model acceptability judgements are not always robust to context](https://doi.org/10.18653/v1/2023.acl-long.333) |  | 0 |  | Koustuv Sinha, Jon Gauthier, Aaron Mueller, Kanishka Misra, Keren Fuentes, Roger Levy, Adina Williams |  |
| 1577 |  |  [RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations](https://doi.org/10.18653/v1/2023.acl-long.334) |  | 0 |  | Yilun Zhao, Chen Zhao, Linyong Nan, Zhenting Qi, Wenlin Zhang, Xiangru Tang, Boyu Mi, Dragomir Radev |  |
| 1578 |  |  [Morphological Inflection: A Reality Check](https://doi.org/10.18653/v1/2023.acl-long.335) |  | 0 |  | Jordan Kodner, Sarah R. B. Payne, Salam Khalifa, Zoey Liu |  |
| 1579 |  |  [TOME: A Two-stage Approach for Model-based Retrieval](https://doi.org/10.18653/v1/2023.acl-long.336) |  | 0 |  | Ruiyang Ren, Wayne Xin Zhao, Jing Liu, Hua Wu, JiRong Wen, Haifeng Wang |  |
| 1580 |  |  [Using Neural Machine Translation for Generating Diverse Challenging Exercises for Language Learner](https://doi.org/10.18653/v1/2023.acl-long.337) |  | 0 |  | Frank Palma Gomez, Subhadarshi Panda, Michael Flor, Alla Rozovskaya |  |
| 1581 |  |  [Similarity-weighted Construction of Contextualized Commonsense Knowledge Graphs for Knowledge-intense Argumentation Tasks](https://doi.org/10.18653/v1/2023.acl-long.338) |  | 0 |  | Moritz Plenz, Juri Opitz, Philipp Heinisch, Philipp Cimiano, Anette Frank |  |
| 1582 |  |  [miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings](https://doi.org/10.18653/v1/2023.acl-long.339) |  | 0 |  | Tassilo Klein, Moin Nabi |  |
| 1583 |  |  [Learning Non-linguistic Skills without Sacrificing Linguistic Proficiency](https://doi.org/10.18653/v1/2023.acl-long.340) |  | 0 |  | Mandar Sharma, Nikhil Muralidhar, Naren Ramakrishnan |  |
| 1584 |  |  [Forgotten Knowledge: Examining the Citational Amnesia in NLP](https://doi.org/10.18653/v1/2023.acl-long.341) |  | 0 |  | Janvijay Singh, Mukund Rungta, Diyi Yang, Saif M. Mohammad |  |
| 1585 |  |  [Measuring the Instability of Fine-Tuning](https://doi.org/10.18653/v1/2023.acl-long.342) |  | 0 |  | Yupei Du, Dong Nguyen |  |
| 1586 |  |  [FairPrism: Evaluating Fairness-Related Harms in Text Generation](https://doi.org/10.18653/v1/2023.acl-long.343) |  | 0 |  | Eve Fleisig, Aubrie Amstutz, Chad Atalla, Su Lin Blodgett, Hal Daumé III, Alexandra Olteanu, Emily Sheng, Dan Vann, Hanna M. Wallach |  |
| 1587 |  |  [Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback](https://doi.org/10.18653/v1/2023.acl-long.344) |  | 0 |  | Paul Roit, Johan Ferret, Lior Shani, Roee Aharoni, Geoffrey Cideron, Robert Dadashi, Matthieu Geist, Sertan Girgin, Léonard Hussenot, Orgad Keller, Nikola Momchev, Sabela Ramos Garea, Piotr Stanczyk, Nino Vieillard, Olivier Bachem, Gal Elidan, Avinatan Hassidim, Olivier Pietquin, Idan Szpektor |  |
| 1588 |  |  [SIMMC-VR: A Task-oriented Multimodal Dialog Dataset with Situated and Immersive VR Streams](https://doi.org/10.18653/v1/2023.acl-long.345) |  | 0 |  | TeLin Wu, Satwik Kottur, Andrea Madotto, Mahmoud Azab, Pedro Rodríguez, Babak Damavandi, Nanyun Peng, Seungwhan Moon |  |
| 1589 |  |  [Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment](https://doi.org/10.18653/v1/2023.acl-long.346) |  | 0 |  | Eshaan Tanwar, Subhabrata Dutta, Manish Borthakur, Tanmoy Chakraborty |  |
| 1590 |  |  [APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning](https://doi.org/10.18653/v1/2023.acl-long.347) |  | 0 |  | Soumya Sanyal, Yichong Xu, Shuohang Wang, Ziyi Yang, Reid Pryzant, Wenhao Yu, Chenguang Zhu, Xiang Ren |  |
| 1591 |  |  [MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering](https://doi.org/10.18653/v1/2023.acl-long.348) |  | 0 |  | Vaishali Pal, Andrew Yates, Evangelos Kanoulas, Maarten de Rijke |  |
| 1592 |  |  [To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.acl-long.349) |  | 0 |  | Rui Li, Xu Chen, Chaozhuo Li, Yanming Shen, Jianan Zhao, Yujing Wang, Weihao Han, Hao Sun, Weiwei Deng, Qi Zhang, Xing Xie |  |
| 1593 |  |  [CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation](https://doi.org/10.18653/v1/2023.acl-long.350) |  | 0 |  | Huimin Wang, WaiChung Kwan, KamFai Wong, Yefeng Zheng |  |
| 1594 |  |  [Long-Tailed Question Answering in an Open World](https://doi.org/10.18653/v1/2023.acl-long.351) |  | 0 |  | Yi Dai, Hao Lang, Yinhe Zheng, Fei Huang, Yongbin Li |  |
| 1595 |  |  [Parallel Context Windows for Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.352) |  | 0 |  | Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori Ram, Inbal Magar, Omri Abend, Ehud Karpas, Amnon Shashua, Kevin LeytonBrown, Yoav Shoham |  |
| 1596 |  |  [Efficient Transformers with Dynamic Token Pooling](https://doi.org/10.18653/v1/2023.acl-long.353) |  | 0 |  | Piotr Nawrot, Jan Chorowski, Adrian Lancucki, Edoardo Maria Ponti |  |
| 1597 |  |  [Did the Models Understand Documents? Benchmarking Models for Language Understanding in Document-Level Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.354) |  | 0 |  | Haotian Chen, Bingsheng Chen, Xiangdong Zhou |  |
| 1598 |  |  [ContraCLM: Contrastive Learning For Causal Language Model](https://doi.org/10.18653/v1/2023.acl-long.355) |  | 0 |  | Nihal Jain, Dejiao Zhang, Wasi Uddin Ahmad, Zijian Wang, Feng Nan, Xiaopeng Li, Ming Tan, Ramesh Nallapati, Baishakhi Ray, Parminder Bhatia, Xiaofei Ma, Bing Xiang |  |
| 1599 |  |  [Advancing Multi-Criteria Chinese Word Segmentation Through Criterion Classification and Denoising](https://doi.org/10.18653/v1/2023.acl-long.356) |  | 0 |  | TzuHsuan Chou, ChunYi Lin, HungYu Kao |  |
| 1600 |  |  [Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2023.acl-long.357) |  | 0 |  | Haodong Zhao, Ruifang He, Mengnan Xiao, Jing Xu |  |
| 1601 |  |  [Contrastive Learning with Adversarial Examples for Alleviating Pathology of Language Model](https://doi.org/10.18653/v1/2023.acl-long.358) |  | 0 |  | Pengwei Zhan, Jing Yang, Xiao Huang, Chunlei Jing, Jingying Li, Liming Wang |  |
| 1602 |  |  [Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children's Fairy Tales](https://doi.org/10.18653/v1/2023.acl-long.359) |  | 0 |  | Paulina Toro Isaza, Guangxuan Xu, Toye Oloko, Yufang Hou, Nanyun Peng, Dakuo Wang |  |
| 1603 |  |  [FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue](https://doi.org/10.18653/v1/2023.acl-long.360) |  | 0 |  | Weihao Zeng, Keqing He, Yejie Wang, Chen Zeng, Jingang Wang, Yunsen Xian, Weiran Xu |  |
| 1604 |  |  [LAMBADA: Backward Chaining for Automated Reasoning in Natural Language](https://doi.org/10.18653/v1/2023.acl-long.361) |  | 0 |  | Mehran Kazemi, Najoung Kim, Deepti Bhatia, Xin Xu, Deepak Ramachandran |  |
| 1605 |  |  [PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives](https://doi.org/10.18653/v1/2023.acl-long.362) |  | 0 |  | Silin Gao, Beatriz Borges, Soyoung Oh, Deniz Bayazit, Saya Kanno, Hiromi Wakaki, Yuki Mitsufuji, Antoine Bosselut |  |
| 1606 |  |  [OpenSR: Open-Modality Speech Recognition via Maintaining Multi-Modality Alignment](https://doi.org/10.18653/v1/2023.acl-long.363) |  | 0 |  | Xize Cheng, Tao Jin, Linjun Li, Wang Lin, Xinyu Duan, Zhou Zhao |  |
| 1607 |  |  [Retrieval-free Knowledge Injection through Multi-Document Traversal for Dialogue Models](https://doi.org/10.18653/v1/2023.acl-long.364) |  | 0 |  | Rui Wang, Jianzhu Bao, Fei Mi, Yi Chen, Hongru Wang, Yasheng Wang, Yitong Li, Lifeng Shang, KamFai Wong, Ruifeng Xu |  |
| 1608 |  |  [BERM: Training the Balanced and Extractable Representation for Matching to Improve Generalization Ability of Dense Retrieval](https://doi.org/10.18653/v1/2023.acl-long.365) |  | 0 |  | Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 1609 |  |  [Multiview Identifiers Enhanced Generative Retrieval](https://doi.org/10.18653/v1/2023.acl-long.366) |  | 0 |  | Yongqi Li, Nan Yang, Liang Wang, Furu Wei, Wenjie Li |  |
| 1610 |  |  [Prompting Language Models for Linguistic Structure](https://doi.org/10.18653/v1/2023.acl-long.367) |  | 0 |  | Terra Blevins, Hila Gonen, Luke Zettlemoyer |  |
| 1611 |  |  [Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis](https://doi.org/10.18653/v1/2023.acl-long.368) |  | 0 |  | Agam Shah, Suvan Paturi, Sudheer Chava |  |
| 1612 |  |  [RE-Matching: A Fine-Grained Semantic Matching Method for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.369) |  | 0 |  | Jun Zhao, WenYu Zhan, Xin Zhao, Qi Zhang, Tao Gui, Zhongyu Wei, Junzhe Wang, Minlong Peng, Mingming Sun |  |
| 1613 |  |  [SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration](https://doi.org/10.18653/v1/2023.acl-long.370) |  | 0 |  | Hwaran Lee, Seokhee Hong, Joonsuk Park, Takyoung Kim, Meeyoung Cha, Yejin Choi, Byoung Pil Kim, Gunhee Kim, EunJu Lee, Yong Lim, Alice Oh, Sangchul Park, JungWoo Ha |  |
| 1614 |  |  [Towards standardizing Korean Grammatical Error Correction: Datasets and Annotation](https://doi.org/10.18653/v1/2023.acl-long.371) |  | 0 |  | Soyoung Yoon, Sungjoon Park, Gyuwan Kim, Junhee Cho, Kihyo Park, Gyu Tae Kim, Minjoon Seo, Alice Oh |  |
| 1615 |  |  [FLamE: Few-shot Learning from Natural Language Explanations](https://doi.org/10.18653/v1/2023.acl-long.372) |  | 0 |  | Yangqiaoyu Zhou, Yiming Zhang, Chenhao Tan |  |
| 1616 |  |  [Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning](https://doi.org/10.18653/v1/2023.acl-long.373) |  | 0 |  | Subhajit Chaudhury, Sarathkrishna Swaminathan, Daiki Kimura, Prithviraj Sen, Keerthiram Murugesan, Rosario UcedaSosa, Michiaki Tatsubori, Achille Fokoue, Pavan Kapanipathi, Asim Munawar, Alexander Gray |  |
| 1617 |  |  [Counterfactual Debiasing for Fact Verification](https://doi.org/10.18653/v1/2023.acl-long.374) |  | 0 |  | Weizhi Xu, Qiang Liu, Shu Wu, Liang Wang |  |
| 1618 |  |  [What social attitudes about gender does BERT encode? Leveraging insights from psycholinguistics](https://doi.org/10.18653/v1/2023.acl-long.375) |  | 0 |  | Julia Watson, Barend Beekhuizen, Suzanne Stevenson |  |
| 1619 |  |  [Rethinking Multimodal Entity and Relation Extraction from a Translation Point of View](https://doi.org/10.18653/v1/2023.acl-long.376) |  | 0 |  | Changmeng Zheng, Junhao Feng, Yi Cai, Xiaoyong Wei, Qing Li |  |
| 1620 |  |  [Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization](https://doi.org/10.18653/v1/2023.acl-long.377) |  | 0 |  | Rongxin Zhu, Jianzhong Qi, Jey Han Lau |  |
| 1621 |  |  [Improving the Robustness of Summarization Systems with Dual Augmentation](https://doi.org/10.18653/v1/2023.acl-long.378) |  | 0 |  | Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, Xiangliang Zhang |  |
| 1622 |  |  [Interpretable Math Word Problem Solution Generation via Step-by-step Planning](https://doi.org/10.18653/v1/2023.acl-long.379) |  | 0 |  | Mengxue Zhang, Zichao Wang, Zhichao Yang, Weiqi Feng, Andrew S. Lan |  |
| 1623 |  |  [TemplateGEC: Improving Grammatical Error Correction with Detection Template](https://doi.org/10.18653/v1/2023.acl-long.380) |  | 0 |  | Yinghao Li, Xuebo Liu, Shuo Wang, Peiyuan Gong, Derek F. Wong, Yang Gao, Heyan Huang, Min Zhang |  |
| 1624 |  |  [Deep Model Compression Also Helps Models Capture Ambiguity](https://doi.org/10.18653/v1/2023.acl-long.381) |  | 0 |  | Hancheol Park, Jong C. Park |  |
| 1625 |  |  [Are Experts Needed? On Human Evaluation of Counselling Reflection Generation](https://doi.org/10.18653/v1/2023.acl-long.382) |  | 0 |  | Zixiu Wu, Simone Balloccu, Ehud Reiter, Rim Helaoui, Diego Reforgiato Recupero, Daniele Riboni |  |
| 1626 |  |  [PairSpanBERT: An Enhanced Language Model for Bridging Resolution](https://doi.org/10.18653/v1/2023.acl-long.383) |  | 0 |  | Hideo Kobayashi, Yufang Hou, Vincent Ng |  |
| 1627 |  |  [Compounding Geometric Operations for Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.acl-long.384) |  | 0 |  | Xiou Ge, YunCheng Wang, Bin Wang, C.C. Jay Kuo |  |
| 1628 |  |  [Few-shot In-context Learning on Knowledge Base Question Answering](https://doi.org/10.18653/v1/2023.acl-long.385) |  | 0 |  | Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, Wenhu Chen |  |
| 1629 |  |  [Fact-Checking Complex Claims with Program-Guided Reasoning](https://doi.org/10.18653/v1/2023.acl-long.386) |  | 0 |  | Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang Wang, MinYen Kan, Preslav Nakov |  |
| 1630 |  |  [Patton: Language Model Pretraining on Text-Rich Networks](https://doi.org/10.18653/v1/2023.acl-long.387) |  | 0 |  | Bowen Jin, Wentao Zhang, Yu Zhang, Yu Meng, Xinyang Zhang, Qi Zhu, Jiawei Han |  |
| 1631 |  |  [Soft Language Clustering for Multilingual Model Pre-training](https://doi.org/10.18653/v1/2023.acl-long.388) |  | 0 |  | Jiali Zeng, Yufan Jiang, Yongjing Yin, Yi Jing, Fandong Meng, Binghuai Lin, Yunbo Cao, Jie Zhou |  |
| 1632 |  |  [Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach](https://doi.org/10.18653/v1/2023.acl-long.389) |  | 0 |  | Nidhi Vakil, Hadi Amiri |  |
| 1633 |  |  [When and how to paraphrase for named entity recognition?](https://doi.org/10.18653/v1/2023.acl-long.390) |  | 0 |  | Saket Sharma, Aviral Joshi, Yiyun Zhao, Namrata Mukhija, Hanoz Bhathena, Prateek Singh, Sashank Santhanam |  |
| 1634 |  |  [UniEvent: Unified Generative Model with Multi-Dimensional Prefix for Zero-Shot Event-Relational Reasoning](https://doi.org/10.18653/v1/2023.acl-long.391) |  | 0 |  | Zhengwei Tao, Zhi Jin, Haiyan Zhao, Chengfeng Dou, Yongqiang Zhao, Tao Shen, Chongyang Tao |  |
| 1635 |  |  [Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales](https://doi.org/10.18653/v1/2023.acl-long.392) |  | 0 |  | Brihi Joshi, Ziyi Liu, Sahana Ramnath, Aaron Chan, Zhewei Tong, Shaoliang Nie, Qifan Wang, Yejin Choi, Xiang Ren |  |
| 1636 |  |  [Automatic Annotation of Direct Speech in Written French Narratives](https://doi.org/10.18653/v1/2023.acl-long.393) |  | 0 |  | Noé Durandard, VietAnh Tran, Gaspard Michel, Elena V. Epure |  |
| 1637 |  |  [Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations](https://doi.org/10.18653/v1/2023.acl-long.394) |  | 0 |  | Hyunjae Kim, Jaehyo Yoo, Seunghyun Yoon, Jaewoo Kang |  |
| 1638 |  |  [Dynamic Transformers Provide a False Sense of Efficiency](https://doi.org/10.18653/v1/2023.acl-long.395) |  | 0 |  | Yiming Chen, Simin Chen, Zexin Li, Wei Yang, Cong Liu, Robby T. Tan, Haizhou Li |  |
| 1639 |  |  [Empowering Cross-lingual Behavioral Testing of NLP Models with Typological Features](https://doi.org/10.18653/v1/2023.acl-long.396) |  | 0 |  | Ester Hlavnova, Sebastian Ruder |  |
| 1640 |  |  [Local Byte Fusion for Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.397) |  | 0 |  | Makesh Narsimhan Sreedhar, Xiangpeng Wan, Yu Cheng, Junjie Hu |  |
| 1641 |  |  [Where's the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation](https://doi.org/10.18653/v1/2023.acl-long.398) |  | 0 |  | Benjamin Minixhofer, Jonas Pfeiffer, Ivan Vulic |  |
| 1642 |  |  [Multi-target Backdoor Attacks for Code Pre-trained Models](https://doi.org/10.18653/v1/2023.acl-long.399) |  | 0 |  | Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, Yang Liu |  |
| 1643 |  |  [Learning Better Masking for Better Language Model Pre-training](https://doi.org/10.18653/v1/2023.acl-long.400) |  | 0 |  | Dongjie Yang, Zhuosheng Zhang, Hai Zhao |  |
| 1644 |  |  [VisText: A Benchmark for Semantically Rich Chart Captioning](https://doi.org/10.18653/v1/2023.acl-long.401) |  | 0 |  | Benny J. Tang, Angie W. Boggust, Arvind Satyanarayan |  |
| 1645 |  |  [Byte-Level Grammatical Error Correction Using Synthetic and Curated Corpora](https://doi.org/10.18653/v1/2023.acl-long.402) |  | 0 |  | Svanhvít Lilja Ingólfsdóttir, Petur Orri Ragnarsson, Haukur Páll Jónsson, Haukur Barri Símonarson, Vilhjalmur Thorsteinsson, Vésteinn Snæbjarnarson |  |
| 1646 |  |  [Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text](https://doi.org/10.18653/v1/2023.acl-long.403) |  | 0 |  | Qianhui Wu, Huiqiang Jiang, Haonan Yin, Börje Karlsson, ChinYew Lin |  |
| 1647 |  |  [Peeking inside the black box: A Commonsense-aware Generative Framework for Explainable Complaint Detection](https://doi.org/10.18653/v1/2023.acl-long.404) |  | 0 |  | Apoorva Singh, Raghav Jain, Prince Jha, Sriparna Saha |  |
| 1648 |  |  [MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation](https://doi.org/10.18653/v1/2023.acl-long.405) |  | 0 |  | Jiazhan Feng, Qingfeng Sun, Can Xu, Pu Zhao, Yaming Yang, Chongyang Tao, Dongyan Zhao, Qingwei Lin |  |
| 1649 |  |  [ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models](https://doi.org/10.18653/v1/2023.acl-long.406) |  | 0 |  | Jonas Belouadi, Steffen Eger |  |
| 1650 |  |  [Envisioning Future from the Past: Hierarchical Duality Learning for Multi-Turn Dialogue Generation](https://doi.org/10.18653/v1/2023.acl-long.407) |  | 0 |  | Ang Lv, Jinpeng Li, Shufang Xie, Rui Yan |  |
| 1651 |  |  [DualGATs: Dual Graph Attention Networks for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2023.acl-long.408) |  | 0 |  | Duzhen Zhang, Feilong Chen, Xiuyi Chen |  |
| 1652 |  |  [Consistent Prototype Learning for Few-Shot Continual Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.409) |  | 0 |  | Xiudi Chen, Hui Wu, Xiaodong Shi |  |
| 1653 |  |  [Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.410) |  | 0 |  | Myles Foley, Ambrish Rawat, Taesung Lee, Yufang Hou, Gabriele Picco, Giulio Zizzo |  |
| 1654 |  |  [Large Language Models Meet NL2Code: A Survey](https://doi.org/10.18653/v1/2023.acl-long.411) |  | 0 |  | Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Yongji Wang, JianGuang Lou |  |
| 1655 |  |  [When Does Aggregating Multiple Skills with Multi-Task Learning Work? A Case Study in Financial NLP](https://doi.org/10.18653/v1/2023.acl-long.412) |  | 0 |  | Jingwei Ni, Zhijing Jin, Qian Wang, Mrinmaya Sachan, Markus Leippold |  |
| 1656 |  |  [Enhancing Grammatical Error Correction Systems with Explanations](https://doi.org/10.18653/v1/2023.acl-long.413) |  | 0 |  | Yuejiao Fei, Leyang Cui, Sen Yang, Wai Lam, Zhenzhong Lan, Shuming Shi |  |
| 1657 |  |  [Linguistic representations for fewer-shot relation extraction across domains](https://doi.org/10.18653/v1/2023.acl-long.414) |  | 0 |  | Sireesh Gururaja, Ritam Dutt, Tinglong Liao, Carolyn P. Rosé |  |
| 1658 |  |  [DarkBERT: A Language Model for the Dark Side of the Internet](https://doi.org/10.18653/v1/2023.acl-long.415) |  | 0 |  | Youngjin Jin, Eugene Jang, Jian Cui, JinWoo Chung, Yongjae Lee, Seungwon Shin |  |
| 1659 |  |  [MDACE: MIMIC Documents Annotated with Code Evidence](https://doi.org/10.18653/v1/2023.acl-long.416) |  | 0 |  | Hua Cheng, Rana Jafari, April Russell, Russell Klopfer, Edmond Lu, Benjamin Striner, Matthew Gormley |  |
| 1660 |  |  [Towards Zero-Shot Multilingual Transfer for Code-Switched Responses](https://doi.org/10.18653/v1/2023.acl-long.417) |  | 0 |  | TingWei Wu, Changsheng Zhao, Ernie Chang, Yangyang Shi, Pierce Chuang, Vikas Chandra, BiingHwang Juang |  |
| 1661 |  |  [One Network, Many Masks: Towards More Parameter-Efficient Transfer Learning](https://doi.org/10.18653/v1/2023.acl-long.418) |  | 0 |  | Guangtao Zeng, Peiyuan Zhang, Wei Lu |  |
| 1662 |  |  [Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk](https://doi.org/10.18653/v1/2023.acl-long.419) |  | 0 |  | Jianquan Li, Xiangbo Wu, Xiaokang Liu, Qianqian Xie, Prayag Tiwari, Benyou Wang |  |
| 1663 |  |  [Convergence and Diversity in the Control Hierarchy](https://doi.org/10.18653/v1/2023.acl-long.420) |  | 0 |  | Alexandra Butoi, Ryan Cotterell, David Chiang |  |
| 1664 |  |  [ConFEDE: Contrastive Feature Decomposition for Multimodal Sentiment Analysis](https://doi.org/10.18653/v1/2023.acl-long.421) |  | 0 |  | Jiuding Yang, Yakun Yu, Di Niu, Weidong Guo, Yu Xu |  |
| 1665 |  |  [Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic](https://doi.org/10.18653/v1/2023.acl-long.422) |  | 0 |  | Connor Pryor, Quan Yuan, Jeremiah Z. Liu, Mehran Kazemi, Deepak Ramachandran, Tania BedraxWeiss, Lise Getoor |  |
| 1666 |  |  [Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark](https://doi.org/10.18653/v1/2023.acl-long.423) |  | 0 |  | Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie |  |
| 1667 |  |  [Answering Ambiguous Questions via Iterative Prompting](https://doi.org/10.18653/v1/2023.acl-long.424) |  | 0 |  | Weiwei Sun, Hengyi Cai, Hongshen Chen, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren |  |
| 1668 |  |  [A Dataset of Argumentative Dialogues on Scientific Papers](https://doi.org/10.18653/v1/2023.acl-long.425) |  | 0 |  | Federico Ruggeri, Mohsen Mesgar, Iryna Gurevych |  |
| 1669 |  |  [Massively Multilingual Lexical Specialization of Multilingual Transformers](https://doi.org/10.18653/v1/2023.acl-long.426) |  | 0 |  | Tommaso Green, Simone Paolo Ponzetto, Goran Glavas |  |
| 1670 |  |  [RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs](https://doi.org/10.18653/v1/2023.acl-long.427) |  | 0 |  | Afra Feyza Akyürek, Ekin Akyürek, Ashwin Kalyan, Peter Clark, Derry Tanti Wijaya, Niket Tandon |  |
| 1671 |  |  [WebIE: Faithful and Robust Information Extraction on the Web](https://doi.org/10.18653/v1/2023.acl-long.428) |  | 0 |  | Chenxi Whitehouse, Clara Vania, Alham Fikri Aji, Christos Christodoulopoulos, Andrea Pierleoni |  |
| 1672 |  |  [NormBank: A Knowledge Bank of Situational Social Norms](https://doi.org/10.18653/v1/2023.acl-long.429) |  | 0 |  | Caleb Ziems, Jane DwivediYu, YiChia Wang, Alon Y. Halevy, Diyi Yang |  |
| 1673 |  |  [DIP: Dead code Insertion based Black-box Attack for Programming Language Model](https://doi.org/10.18653/v1/2023.acl-long.430) |  | 0 |  | CheolWon Na, YunSeok Choi, JeeHyong Lee |  |
| 1674 |  |  [Modeling Structural Similarities between Documents for Coherence Assessment with Graph Convolutional Networks](https://doi.org/10.18653/v1/2023.acl-long.431) |  | 0 |  | Wei Liu, Xiyan Fu, Michael Strube |  |
| 1675 |  |  [HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text Classification](https://doi.org/10.18653/v1/2023.acl-long.432) |  | 0 |  | He Zhu, Chong Zhang, Junjie Huang, Junran Wu, Ke Xu |  |
| 1676 |  |  [Contextual Knowledge Learning for Dialogue Generation](https://doi.org/10.18653/v1/2023.acl-long.433) |  | 0 |  | Wen Zheng, Natasa MilicFrayling, Ke Zhou |  |
| 1677 |  |  [Easy Guided Decoding in Providing Suggestions for Interactive Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.434) |  | 0 |  | Ke Wang, Xin Ge, Jiayi Wang, Yuqi Zhang, Yu Zhao |  |
| 1678 |  |  [Discourse-Centric Evaluation of Document-level Machine Translation with a New Densely Annotated Parallel Corpus of Novels](https://doi.org/10.18653/v1/2023.acl-long.435) |  | 0 |  | Yuchen Eleanor Jiang, Tianyu Liu, Shuming Ma, Dongdong Zhang, Mrinmaya Sachan, Ryan Cotterell |  |
| 1679 |  |  [CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.436) |  | 0 |  | Yan Zhou, Qingkai Fang, Yang Feng |  |
| 1680 |  |  [On the Evaluation of Neural Selective Prediction Methods for Natural Language Processing](https://doi.org/10.18653/v1/2023.acl-long.437) |  | 0 |  | Zhengyao Gu, Mark Hopkins |  |
| 1681 |  |  [Speech-Text Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment](https://doi.org/10.18653/v1/2023.acl-long.438) |  | 0 |  | Tianshu Yu, Haoyu Gao, TingEn Lin, Min Yang, Yuchuan Wu, Wentao Ma, Chao Wang, Fei Huang, Yongbin Li |  |
| 1682 |  |  [Text Style Transfer with Contrastive Transfer Pattern Mining](https://doi.org/10.18653/v1/2023.acl-long.439) |  | 0 |  | Jingxuan Han, Quan Wang, Licheng Zhang, Weidong Chen, Yan Song, Zhendong Mao |  |
| 1683 |  |  [Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning](https://doi.org/10.18653/v1/2023.acl-long.440) |  | 0 |  | Zhenrui Yue, Huimin Zeng, Mengfei Lan, Heng Ji, Dong Wang |  |
| 1684 |  |  [Text Style Transfer Back-Translation](https://doi.org/10.18653/v1/2023.acl-long.441) |  | 0 |  | Daimeng Wei, Zhanglin Wu, Hengchao Shang, Zongyao Li, Minghan Wang, Jiaxin Guo, Xiaoyu Chen, Zhengzhe Yu, Hao Yang |  |
| 1685 |  |  [Generating Visual Spatial Description via Holistic 3D Scene Understanding](https://doi.org/10.18653/v1/2023.acl-long.442) |  | 0 |  | Yu Zhao, Hao Fei, Wei Ji, Jianguo Wei, Meishan Zhang, Min Zhang, TatSeng Chua |  |
| 1686 |  |  [Continual Knowledge Distillation for Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.443) |  | 0 |  | Yuanchi Zhang, Peng Li, Maosong Sun, Yang Liu |  |
| 1687 |  |  [Query Refinement Prompts for Closed-Book Long-Form QA](https://doi.org/10.18653/v1/2023.acl-long.444) |  | 0 |  | Reinald Kim Amplayo, Kellie Webster, Michael Collins, Dipanjan Das, Shashi Narayan |  |
| 1688 |  |  [CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding](https://doi.org/10.18653/v1/2023.acl-long.445) |  | 0 |  | Zhijian Hou, Wanjun Zhong, Lei Ji, Difei Gao, Kun Yan, Wing Kwong Chan, ChongWah Ngo, Mike Zheng Shou, Nan Duan |  |
| 1689 |  |  [Few-Shot Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2023.acl-long.446) |  | 0 |  | Xianjun Yang, Yujie Lu, Linda R. Petzold |  |
| 1690 |  |  [ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation](https://doi.org/10.18653/v1/2023.acl-long.447) |  | 0 |  | KuanHao Huang, Varun Iyer, IHung Hsu, Anoop Kumar, KaiWei Chang, Aram Galstyan |  |
| 1691 |  |  [Towards Understanding and Improving Knowledge Distillation for Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.448) |  | 0 |  | Songming Zhang, Yunlong Liang, Shuaibo Wang, Yufeng Chen, Wenjuan Han, Jian Liu, Jinan Xu |  |
| 1692 |  |  [Multi-Row, Multi-Span Distant Supervision For Table+Text Question Answering](https://doi.org/10.18653/v1/2023.acl-long.449) |  | 0 |  | Vishwajeet Kumar, Yash Gupta, Saneem A. Chemmengath, Jaydeep Sen, Soumen Chakrabarti, Samarth Bharadwaj, Feifei Pan |  |
| 1693 |  |  [HAHE: Hierarchical Attention for Hyper-Relational Knowledge Graphs in Global and Local Level](https://doi.org/10.18653/v1/2023.acl-long.450) |  | 0 |  | Haoran Luo, Haihong E, Yuhao Yang, Yikai Guo, Mingzhi Sun, Tianyu Yao, Zichen Tang, Kaiyang Wan, Meina Song, Wei Lin |  |
| 1694 |  |  [ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning](https://doi.org/10.18653/v1/2023.acl-long.451) |  | 0 |  | Wenjun Hou, Kaishuai Xu, Yi Cheng, Wenjie Li, Jiang Liu |  |
| 1695 |  |  [Data Curation Alone Can Stabilize In-context Learning](https://doi.org/10.18653/v1/2023.acl-long.452) |  | 0 |  | TingYun Chang, Robin Jia |  |
| 1696 |  |  [MidMed: Towards Mixed-Type Dialogues for Medical Consultation](https://doi.org/10.18653/v1/2023.acl-long.453) |  | 0 |  | Xiaoming Shi, Zeming Liu, Chuan Wang, Haitao Leng, Kui Xue, Xiaofan Zhang, Shaoting Zhang |  |
| 1697 |  |  [FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning](https://doi.org/10.18653/v1/2023.acl-long.454) |  | 0 |  | Qinyuan Ye, Iz Beltagy, Matthew E. Peters, Xiang Ren, Hannaneh Hajishirzi |  |
| 1698 |  |  [S2ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.455) |  | 0 |  | Benfeng Xu, Quan Wang, Yajuan Lyu, Dai Dai, Yongdong Zhang, Zhendong Mao |  |
| 1699 |  |  [DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.456) |  | 0 |  | Xuxi Chen, Tianlong Chen, Weizhu Chen, Ahmed Hassan Awadallah, Zhangyang Wang, Yu Cheng |  |
| 1700 |  |  [CASE: Aligning Coarse-to-Fine Cognition and Affection for Empathetic Response Generation](https://doi.org/10.18653/v1/2023.acl-long.457) |  | 0 |  | Jinfeng Zhou, Chujie Zheng, Bo Wang, Zheng Zhang, Minlie Huang |  |
| 1701 |  |  [Comparative evaluation of boundary-relaxed annotation for Entity Linking performance](https://doi.org/10.18653/v1/2023.acl-long.458) |  | 0 |  | Gabriel Herman Bernardim Andrade, Shuntaro Yada, Eiji Aramaki |  |
| 1702 |  |  [Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?](https://doi.org/10.18653/v1/2023.acl-long.459) |  | 0 |  | Shuheng Liu, Alan Ritter |  |
| 1703 |  |  [READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises](https://doi.org/10.18653/v1/2023.acl-long.460) |  | 0 |  | Chenglei Si, Zhengyan Zhang, Yingfa Chen, Xiaozhi Wang, Zhiyuan Liu, Maosong Sun |  |
| 1704 |  |  [MAD-TSC: A Multilingual Aligned News Dataset for Target-dependent Sentiment Classification](https://doi.org/10.18653/v1/2023.acl-long.461) |  | 0 |  | Evan Dufraisse, Adrian Popescu, Julien Tourille, Armelle Brun, Jérôme Deshayes |  |
| 1705 |  |  [A New Dataset and Empirical Study for Sentence Simplification in Chinese](https://doi.org/10.18653/v1/2023.acl-long.462) |  | 0 |  | Shiping Yang, Renliang Sun, Xiaojun Wan |  |
| 1706 |  |  [Factual or Contextual? Disentangling Error Types in Entity Description Generation](https://doi.org/10.18653/v1/2023.acl-long.463) |  | 0 |  | Navita Goyal, Ani Nenkova, Hal Daumé III |  |
| 1707 |  |  [Weakly Supervised Vision-and-Language Pre-training with Relative Representations](https://doi.org/10.18653/v1/2023.acl-long.464) |  | 0 |  | Chi Chen, Peng Li, Maosong Sun, Yang Liu |  |
| 1708 |  |  [HermEs: Interactive Spreadsheet Formula Prediction via Hierarchical Formulet Expansion](https://doi.org/10.18653/v1/2023.acl-long.465) |  | 0 |  | Wanrong He, Haoyu Dong, Yihuai Gao, Zhichao Fan, Xingzhuo Guo, Zhitao Hou, Xiao Lv, Ran Jia, Shi Han, Dongmei Zhang |  |
| 1709 |  |  [ArgU: A Controllable Factual Argument Generator](https://doi.org/10.18653/v1/2023.acl-long.466) |  | 0 |  | Sougata Saha, Rohini K. Srihari |  |
| 1710 |  |  [Learning Answer Generation using Supervision from Automatic Question Answering Evaluators](https://doi.org/10.18653/v1/2023.acl-long.467) |  | 0 |  | Matteo Gabburo, Siddhant Garg, Rik KoncelKedziorski, Alessandro Moschitti |  |
| 1711 |  |  [RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation](https://doi.org/10.18653/v1/2023.acl-long.468) |  | 0 |  | Shuai Liu, Hyundong Cho, Marjorie Freedman, Xuezhe Ma, Jonathan May |  |
| 1712 |  |  [Don't Parse, Choose Spans! Continuous and Discontinuous Constituency Parsing via Autoregressive Span Selection](https://doi.org/10.18653/v1/2023.acl-long.469) |  | 0 |  | Songlin Yang, Kewei Tu |  |
| 1713 |  |  [Laziness Is a Virtue When It Comes to Compositionality in Neural Semantic Parsing](https://doi.org/10.18653/v1/2023.acl-long.470) |  | 0 |  | Maxwell Crouse, Pavan Kapanipathi, Subhajit Chaudhury, Tahira Naseem, Ramón Fernandez Astudillo, Achille Fokoue, Tim Klinger |  |
| 1714 |  |  [AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression](https://doi.org/10.18653/v1/2023.acl-long.471) |  | 0 |  | Siyue Wu, Hongzhan Chen, Xiaojun Quan, Qifan Wang, Rui Wang |  |
| 1715 |  |  [(QA)²: Question Answering with Questionable Assumptions](https://doi.org/10.18653/v1/2023.acl-long.472) |  | 0 |  | Najoung Kim, Phu Mon Htut, Samuel R. Bowman, Jackson Petty |  |
| 1716 |  |  [Attributable and Scalable Opinion Summarization](https://doi.org/10.18653/v1/2023.acl-long.473) |  | 0 |  | Tom Hosking, Hao Tang, Mirella Lapata |  |
| 1717 |  |  [Targeted Data Generation: Finding and Fixing Model Weaknesses](https://doi.org/10.18653/v1/2023.acl-long.474) |  | 0 |  | Zexue He, Marco Túlio Ribeiro, Fereshte Khani |  |
| 1718 |  |  [HiFi: High-Information Attention Heads Hold for Parameter-Efficient Model Adaptation](https://doi.org/10.18653/v1/2023.acl-long.475) |  | 0 |  | Anchun Gui, Han Xiao |  |
| 1719 |  |  [CFSum Coarse-to-Fine Contribution Network for Multimodal Summarization](https://doi.org/10.18653/v1/2023.acl-long.476) |  | 0 |  | Min Xiao, Junnan Zhu, Haitao Lin, Yu Zhou, Chengqing Zong |  |
| 1720 |  |  [On "Scientific Debt" in NLP: A Case for More Rigour in Language Model Pre-Training Research](https://doi.org/10.18653/v1/2023.acl-long.477) |  | 0 |  | Made Nindyatama Nityasya, Haryo Akbarianto Wibowo, Alham Fikri Aji, Genta Indra Winata, Radityo Eko Prasojo, Phil Blunsom, Adhiguna Kuncoro |  |
| 1721 |  |  [End-to-end Knowledge Retrieval with Multi-modal Queries](https://doi.org/10.18653/v1/2023.acl-long.478) |  | 0 |  | Man Luo, Zhiyuan Fang, Tejas Gokhale, Yezhou Yang, Chitta Baral |  |
| 1722 |  |  [AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.479) |  | 0 |  | Rongjie Huang, Huadai Liu, Xize Cheng, Yi Ren, Linjun Li, Zhenhui Ye, Jinzheng He, Lichao Zhang, Jinglin Liu, Xiang Yin, Zhou Zhao |  |
| 1723 |  |  [Dual Class Knowledge Propagation Network for Multi-label Few-shot Intent Detection](https://doi.org/10.18653/v1/2023.acl-long.480) |  | 0 |  | Feng Zhang, Wei Chen, Fei Ding, Tengjiao Wang |  |
| 1724 |  |  [VendorLink: An NLP approach for Identifying & Linking Vendor Migrants & Potential Aliases on Darknet Markets](https://doi.org/10.18653/v1/2023.acl-long.481) |  | 0 |  | Vageesh Saxena, Nils Rethmeier, Gijs van Dijck, Gerasimos Spanakis |  |
| 1725 |  |  [Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method](https://doi.org/10.18653/v1/2023.acl-long.482) |  | 0 |  | Yiming Wang, Zhuosheng Zhang, Rui Wang |  |
| 1726 |  |  [Efficient Shapley Values Estimation by Amortization for Text Classification](https://doi.org/10.18653/v1/2023.acl-long.483) |  | 0 |  | Chenghao Yang, Fan Yin, He He, KaiWei Chang, Xiaofei Ma, Bing Xiang |  |
| 1727 |  |  [PeerDA: Data Augmentation via Modeling Peer Relation for Span Identification Tasks](https://doi.org/10.18653/v1/2023.acl-long.484) |  | 0 |  | Weiwen Xu, Xin Li, Yang Deng, Wai Lam, Lidong Bing |  |
| 1728 |  |  [Dynamic Regularization in UDA for Transformers in Multimodal Classification](https://doi.org/10.18653/v1/2023.acl-long.485) |  | 0 |  | Ivonne MonterAldana, Adrián Pastor LópezMonroy, Fernando SánchezVega |  |
| 1729 |  |  [Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing](https://doi.org/10.18653/v1/2023.acl-long.486) |  | 0 |  | Lea Frermann, Jiatong Li, Shima Khanehzar, Gosia Mikolajczak |  |
| 1730 |  |  [bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark](https://doi.org/10.18653/v1/2023.acl-long.487) |  | 0 |  | Momchil Hardalov, Pepa Atanasova, Todor Mihaylov, Galia Angelova, Kiril Simov, Petya Osenova, Veselin Stoyanov, Ivan Koychev, Preslav Nakov, Dragomir Radev |  |
| 1731 |  |  [DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation](https://doi.org/10.18653/v1/2023.acl-long.488) |  | 0 |  | Yuxi Feng, Xiaoyuan Yi, Xiting Wang, Laks V. S. Lakshmanan, Xing Xie |  |
| 1732 |  |  [What does the Failure to Reason with "Respectively" in Zero/Few-Shot Settings Tell Us about Language Models?](https://doi.org/10.18653/v1/2023.acl-long.489) |  | 0 |  | Ruixiang Cui, Seolhwa Lee, Daniel Hershcovich, Anders Søgaard |  |
| 1733 |  |  [BLIND: Bias Removal With No Demographics](https://doi.org/10.18653/v1/2023.acl-long.490) |  | 0 |  | Hadas Orgad, Yonatan Belinkov |  |
| 1734 |  |  [How do humans perceive adversarial text? A reality check on the validity and naturalness of word-based adversarial attacks](https://doi.org/10.18653/v1/2023.acl-long.491) |  | 0 |  | Salijona Dyrmishi, Salah Ghamizi, Maxime Cordy |  |
| 1735 |  |  [Soft Alignment Objectives for Robust Adaptation of Language Generation](https://doi.org/10.18653/v1/2023.acl-long.492) |  | 0 |  | Michal Stefánik, Marek Kadlcík, Petr Sojka |  |
| 1736 |  |  [The CRINGE Loss: Learning what language not to model](https://doi.org/10.18653/v1/2023.acl-long.493) |  | 0 |  | Leonard Adolphs, Tianyu Gao, Jing Xu, Kurt Shuster, Sainbayar Sukhbaatar, Jason Weston |  |
| 1737 |  |  [Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process](https://doi.org/10.18653/v1/2023.acl-long.494) |  | 0 |  | Fanghua Ye, Zhiyuan Hu, Emine Yilmaz |  |
| 1738 |  |  [Towards Identifying Fine-Grained Depression Symptoms from Memes](https://doi.org/10.18653/v1/2023.acl-long.495) |  | 0 |  | Shweta Yadav, Cornelia Caragea, Chenye Zhao, Naincy Kumari, Marvin Solberg, Tanmay Sharma |  |
| 1739 |  |  [SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding Tasks](https://doi.org/10.18653/v1/2023.acl-long.496) |  | 0 |  | Suwon Shon, Siddhant Arora, ChyiJiunn Lin, Ankita Pasad, Felix Wu, Roshan S. Sharma, WeiLun Wu, Hungyi Lee, Karen Livescu, Shinji Watanabe |  |
| 1740 |  |  [My side, your side and the evidence: Discovering aligned actor groups and the narratives they weave](https://doi.org/10.18653/v1/2023.acl-long.497) |  | 0 |  | Pavan Holur, David Chong, Timothy R. Tangherlini, Vwani Roychowdhury |  |
| 1741 |  |  [Characterizing and Measuring Linguistic Dataset Drift](https://doi.org/10.18653/v1/2023.acl-long.498) |  | 0 |  | Tyler A. Chang, Kishaloy Halder, Neha Anna John, Yogarshi Vyas, Yassine Benajiba, Miguel Ballesteros, Dan Roth |  |
| 1742 |  |  [WebCPM: Interactive Web Search for Chinese Long-form Question Answering](https://doi.org/10.18653/v1/2023.acl-long.499) |  | 0 |  | Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan Liu, Maosong Sun, Jie Zhou |  |
| 1743 |  |  [Synthesize, Prompt and Transfer: Zero-shot Conversational Question Generation with Pre-trained Language Model](https://doi.org/10.18653/v1/2023.acl-long.500) |  | 0 |  | Hongwei Zeng, Bifan Wei, Jun Liu, Weiping Fu |  |
| 1744 |  |  [FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction](https://doi.org/10.18653/v1/2023.acl-long.501) |  | 0 |  | ChenYu Lee, ChunLiang Li, Hao Zhang, Timothy Dozat, Vincent Perot, Guolong Su, Xiang Zhang, Kihyuk Sohn, Nikolay Glushnev, Renshen Wang, Joshua Ainslie, Shangbang Long, Siyang Qin, Yasuhisa Fujii, Nan Hua, Tomas Pfister |  |
| 1745 |  |  [MixCE: Training Autoregressive Language Models by Mixing Forward and Reverse Cross-Entropies](https://doi.org/10.18653/v1/2023.acl-long.502) |  | 0 |  | Shiyue Zhang, Shijie Wu, Ozan Irsoy, Steven Lu, Mohit Bansal, Mark Dredze, David S. Rosenberg |  |
| 1746 |  |  [Knowledgeable Parameter Efficient Tuning Network for Commonsense Question Answering](https://doi.org/10.18653/v1/2023.acl-long.503) |  | 0 |  | Ziwang Zhao, Linmei Hu, Hanyu Zhao, Yingxia Shao, Yequan Wang |  |
| 1747 |  |  [BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric](https://doi.org/10.18653/v1/2023.acl-long.504) |  | 0 |  | Mingda Chen, PaulAmbroise Duquenne, Pierre Andrews, Justine Kao, Alexandre Mourachko, Holger Schwenk, Marta R. Costajussà |  |
| 1748 |  |  [NLPositionality: Characterizing Design Biases of Datasets and Models](https://doi.org/10.18653/v1/2023.acl-long.505) |  | 0 |  | Sebastin Santy, Jenny T. Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap |  |
| 1749 |  |  [Backpack Language Models](https://doi.org/10.18653/v1/2023.acl-long.506) |  | 0 |  | John Hewitt, John Thickstun, Christopher D. Manning, Percy Liang |  |
| 1750 |  |  [WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.507) |  | 0 |  | Virginia K. Felkner, HoChun Herbert Chang, Eugene Jang, Jonathan May |  |
| 1751 |  |  [Grounded Multimodal Named Entity Recognition on Social Media](https://doi.org/10.18653/v1/2023.acl-long.508) |  | 0 |  | Jianfei Yu, Ziyan Li, Jieming Wang, Rui Xia |  |
| 1752 |  |  [Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference](https://doi.org/10.18653/v1/2023.acl-long.509) |  | 0 |  | Junhao Zheng, Qianli Ma, Shengjie Qiu, Yue Wu, Peitian Ma, Junlong Liu, Huawen Feng, Xichen Shang, Haibin Chen |  |
| 1753 |  |  [Translation-Enhanced Multilingual Text-to-Image Generation](https://doi.org/10.18653/v1/2023.acl-long.510) |  | 0 |  | Yaoyiran Li, ChingYun Chang, Stephen Rawls, Ivan Vulic, Anna Korhonen |  |
| 1754 |  |  [Benchmarking Large Language Model Capabilities for Conditional Generation](https://doi.org/10.18653/v1/2023.acl-long.511) |  | 0 |  | Joshua Maynez, Priyanka Agrawal, Sebastian Gehrmann |  |
| 1755 |  |  [lilGym: Natural Language Visual Reasoning with Reinforcement Learning](https://doi.org/10.18653/v1/2023.acl-long.512) |  | 0 |  | Anne Wu, Kianté Brantley, Noriyuki Kojima, Yoav Artzi |  |
| 1756 |  |  [Unsupervised Melody-to-Lyrics Generation](https://doi.org/10.18653/v1/2023.acl-long.513) |  | 0 |  | Yufei Tian, Anjali NarayanChen, Shereen Oraby, Alessandra Cervone, Gunnar A. Sigurdsson, Chenyang Tao, Wenbo Zhao, Tagyoung Chung, Jing Huang, Nanyun Peng |  |
| 1757 |  |  [Causality-aware Concept Extraction based on Knowledge-guided Prompting](https://doi.org/10.18653/v1/2023.acl-long.514) |  | 0 |  | Siyu Yuan, Deqing Yang, Jinxi Liu, Shuyu Tian, Jiaqing Liang, Yanghua Xiao, Rui Xie |  |
| 1758 |  |  [Span-level Aspect-based Sentiment Analysis via Table Filling](https://doi.org/10.18653/v1/2023.acl-long.515) |  | 0 |  | Mao Zhang, Yongxin Zhu, Zhen Liu, Zhimin Bao, Yunfei Wu, Xing Sun, Linli Xu |  |
| 1759 |  |  [Limitations of Language Models in Arithmetic and Symbolic Induction](https://doi.org/10.18653/v1/2023.acl-long.516) |  | 0 |  | Jing Qian, Hong Wang, Zekun Li, Shiyang Li, Xifeng Yan |  |
| 1760 |  |  [EEL: Efficiently Encoding Lattices for Reranking](https://doi.org/10.18653/v1/2023.acl-long.517) |  | 0 |  | Prasann Singhal, Jiacheng Xu, Xi Ye, Greg Durrett |  |
| 1761 |  |  [CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-Training](https://doi.org/10.18653/v1/2023.acl-long.518) |  | 0 |  | Zhenhui Ye, Rongjie Huang, Yi Ren, Ziyue Jiang, Jinglin Liu, Jinzheng He, Xiang Yin, Zhou Zhao |  |
| 1762 |  |  [Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation](https://doi.org/10.18653/v1/2023.acl-long.519) |  | 0 |  | Yulong Chen, Huajian Zhang, Yijie Zhou, Xuefeng Bai, Yueguan Wang, Ming Zhong, Jianhao Yan, Yafu Li, Judy Li, Xianchao Zhu, Yue Zhang |  |
| 1763 |  |  [Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation](https://doi.org/10.18653/v1/2023.acl-long.520) |  | 0 |  | Xiaohang Tang, Yi Zhou, Danushka Bollegala |  |
| 1764 |  |  [How poor is the stimulus? Evaluating hierarchical generalization in neural networks trained on child-directed speech](https://doi.org/10.18653/v1/2023.acl-long.521) |  | 0 |  | Aditya Yedetore, Tal Linzen, Robert Frank, R. Thomas McCoy |  |
| 1765 |  |  [GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator](https://doi.org/10.18653/v1/2023.acl-long.522) |  | 0 |  | Jian Yang, Shuming Ma, Li Dong, Shaohan Huang, Haoyang Huang, Yuwei Yin, Dongdong Zhang, Liqun Yang, Furu Wei, Zhoujun Li |  |
| 1766 |  |  [Linear Guardedness and its Implications](https://doi.org/10.18653/v1/2023.acl-long.523) |  | 0 |  | Shauli Ravfogel, Yoav Goldberg, Ryan Cotterell |  |
| 1767 |  |  [Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability](https://doi.org/10.18653/v1/2023.acl-long.524) |  | 0 |  | Eleftheria Briakou, Colin Cherry, George F. Foster |  |
| 1768 |  |  [Open Set Relation Extraction via Unknown-Aware Training](https://doi.org/10.18653/v1/2023.acl-long.525) |  | 0 |  | Jun Zhao, Xin Zhao, WenYu Zhan, Qi Zhang, Tao Gui, Zhongyu Wei, Yun Wen Chen, Xiang Gao, Xuanjing Huang |  |
| 1769 |  |  [Learning to Imagine: Visually-Augmented Natural Language Generation](https://doi.org/10.18653/v1/2023.acl-long.526) |  | 0 |  | Tianyi Tang, Yushuo Chen, Yifan Du, Junyi Li, Wayne Xin Zhao, JiRong Wen |  |
| 1770 |  |  [Generating Hashtags for Short-form Videos with Guided Signals](https://doi.org/10.18653/v1/2023.acl-long.527) |  | 0 |  | Tiezheng Yu, Hanchao Yu, Davis Liang, Yuning Mao, Shaoliang Nie, PoYao Huang, Madian Khabsa, Pascale Fung, YiChia Wang |  |
| 1771 |  |  [NEUROSTRUCTURAL DECODING: Neural Text Generation with Structural Constraints](https://doi.org/10.18653/v1/2023.acl-long.528) |  | 0 |  | Mohaddeseh Bastan, Mihai Surdeanu, Niranjan Balasubramanian |  |
| 1772 |  |  [The Best of Both Worlds: Combining Human and Machine Translations for Multilingual Semantic Parsing with Active Learning](https://doi.org/10.18653/v1/2023.acl-long.529) |  | 0 |  | Zhuang Li, Lizhen Qu, Philip R. Cohen, Raj Tumuluri, Gholamreza Haffari |  |
| 1773 |  |  [Ideology Prediction from Scarce and Biased Supervision: Learn to Disregard the "What" and Focus on the "How"!](https://doi.org/10.18653/v1/2023.acl-long.530) |  | 0 |  | Chen Chen, Dylan Walker, Venkatesh Saligrama |  |
| 1774 |  |  [Unsupervised Extractive Summarization of Emotion Triggers](https://doi.org/10.18653/v1/2023.acl-long.531) |  | 0 |  | Tiberiu Sosea, Hongli Zhan, Junyi Jessy Li, Cornelia Caragea |  |
| 1775 |  |  [Document-Level Event Argument Extraction With a Chain Reasoning Paradigm](https://doi.org/10.18653/v1/2023.acl-long.532) |  | 0 |  | Jian Liu, Chen Liang, Jinan Xu, Haoyan Liu, Zhe Zhao |  |
| 1776 |  |  [Pre-training Multi-party Dialogue Models with Latent Discourse Inference](https://doi.org/10.18653/v1/2023.acl-long.533) |  | 0 |  | Yiyang Li, Xinting Huang, Wei Bi, Hai Zhao |  |
| 1777 |  |  [Interpreting Positional Information in Perspective of Word Order](https://doi.org/10.18653/v1/2023.acl-long.534) |  | 0 |  | Xilong Zhang, Ruochen Liu, Jin Liu, Xuefeng Liang |  |
| 1778 |  |  [I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation](https://doi.org/10.18653/v1/2023.acl-long.535) |  | 0 |  | Chandra Bhagavatula, Jena D. Hwang, Doug Downey, Ronan Le Bras, Ximing Lu, Lianhui Qin, Keisuke Sakaguchi, Swabha Swayamdipta, Peter West, Yejin Choi |  |
| 1779 |  |  [More than Classification: A Unified Framework for Event Temporal Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.536) |  | 0 |  | Quzhe Huang, Yutong Hu, Shengqi Zhu, Yansong Feng, Chang Liu, Dongyan Zhao |  |
| 1780 |  |  [Multi-Source Test-Time Adaptation as Dueling Bandits for Extractive Question Answering](https://doi.org/10.18653/v1/2023.acl-long.537) |  | 0 |  | Hai Ye, Qizhe Xie, Hwee Tou Ng |  |
| 1781 |  |  [Decoupling Pseudo Label Disambiguation and Representation Learning for Generalized Intent Discovery](https://doi.org/10.18653/v1/2023.acl-long.538) |  | 0 |  | Yutao Mou, Xiaoshuai Song, Keqing He, Chen Zeng, Pei Wang, Jingang Wang, Yunsen Xian, Weiran Xu |  |
| 1782 |  |  [DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering](https://doi.org/10.18653/v1/2023.acl-long.539) |  | 0 |  | Pei Ke, Fei Huang, Fei Mi, Yasheng Wang, Qun Liu, Xiaoyan Zhu, Minlie Huang |  |
| 1783 |  |  [Backdooring Neural Code Search](https://doi.org/10.18653/v1/2023.acl-long.540) |  | 0 |  | Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang, Quanjun Zhang, Bin Luo |  |
| 1784 |  |  [Concise Answers to Complex Questions: Summarization of Long-form Answers](https://doi.org/10.18653/v1/2023.acl-long.541) |  | 0 |  | Abhilash Potluri, Fangyuan Xu, Eunsol Choi |  |
| 1785 |  |  [Towards Better Entity Linking with Multi-View Enhanced Distillation](https://doi.org/10.18653/v1/2023.acl-long.542) |  | 0 |  | Yi Liu, Yuan Tian, Jianxun Lian, Xinlong Wang, Yanan Cao, Fang Fang, Wen Zhang, Haizhen Huang, Weiwei Deng, Qi Zhang |  |
| 1786 |  |  [A Measure-Theoretic Characterization of Tight Language Models](https://doi.org/10.18653/v1/2023.acl-long.543) |  | 0 |  | Li Du, Lucas Torroba Hennigen, Tiago Pimentel, Clara Meister, Jason Eisner, Ryan Cotterell |  |
| 1787 |  |  [PAED: Zero-Shot Persona Attribute Extraction in Dialogues](https://doi.org/10.18653/v1/2023.acl-long.544) |  | 0 |  | Luyao Zhu, Wei Li, Rui Mao, Vlad Pandelea, Erik Cambria |  |
| 1788 |  |  [PromptRank: Unsupervised Keyphrase Extraction Using Prompt](https://doi.org/10.18653/v1/2023.acl-long.545) |  | 0 |  | Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xiaoyan Bai |  |
| 1789 |  |  [When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories](https://doi.org/10.18653/v1/2023.acl-long.546) |  | 0 |  | Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, Hannaneh Hajishirzi |  |
| 1790 |  |  [infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information](https://doi.org/10.18653/v1/2023.acl-long.547) |  | 0 |  | Jaehyung Kim, Yekyung Kim, Karin de Langis, Jinwoo Shin, Dongyeop Kang |  |
| 1791 |  |  [SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models](https://doi.org/10.18653/v1/2023.acl-long.548) |  | 0 |  | Akshita Jha, Aida Mostafazadeh Davani, Chandan K. Reddy, Shachi Dave, Vinodkumar Prabhakaran, Sunipa Dev |  |
| 1792 |  |  [Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations](https://doi.org/10.18653/v1/2023.acl-long.549) |  | 0 |  | Lucy Lu Wang, Yulia Otmakhova, Jay DeYoung, Thinh Hung Truong, Bailey Kuehl, Erin Bransom, Byron C. Wallace |  |
| 1793 |  |  [Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge](https://doi.org/10.18653/v1/2023.acl-long.550) |  | 0 |  | Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, Yanghua Xiao |  |
| 1794 |  |  [An Inner Table Retriever for Robust Table Question Answering](https://doi.org/10.18653/v1/2023.acl-long.551) |  | 0 |  | Weizhe Lin, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert, Gonzalo Iglesias |  |
| 1795 |  |  [SIMSUM: Document-level Text Simplification via Simultaneous Summarization](https://doi.org/10.18653/v1/2023.acl-long.552) |  | 0 |  | Sofia Blinova, Xinyu Zhou, Martin Jaggi, Carsten Eickhoff, Seyed Ali Bahrainian |  |
| 1796 |  |  [SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation](https://doi.org/10.18653/v1/2023.acl-long.553) |  | 0 |  | Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 1797 |  |  [NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic](https://doi.org/10.18653/v1/2023.acl-long.554) |  | 0 |  | Zi'ou Zheng, Xiaodan Zhu |  |
| 1798 |  |  [Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction](https://doi.org/10.18653/v1/2023.acl-long.555) |  | 0 |  | Ashish Sharma, Kevin Rushton, Inna E. Lin, David Wadden, Khendra G. Lucas, Adam S. Miner, Theresa Nguyen, Tim Althoff |  |
| 1799 |  |  [Dating Greek Papyri with Text Regression](https://doi.org/10.18653/v1/2023.acl-long.556) |  | 0 |  | John Pavlopoulos, Maria Konstantinidou, Isabelle MarthotSantaniello, Holger Essler, Asimina Paparigopoulou |  |
| 1800 |  |  [Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions](https://doi.org/10.18653/v1/2023.acl-long.557) |  | 0 |  | Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal |  |
| 1801 |  |  [Direct Fact Retrieval from Knowledge Graphs without Entity Linking](https://doi.org/10.18653/v1/2023.acl-long.558) |  | 0 |  | Jinheon Baek, Alham Fikri Aji, Jens Lehmann, Sung Ju Hwang |  |
| 1802 |  |  [DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering](https://doi.org/10.18653/v1/2023.acl-long.559) |  | 0 |  | Ella Neeman, Roee Aharoni, Or Honovich, Leshem Choshen, Idan Szpektor, Omri Abend |  |
| 1803 |  |  [A New Direction in Stance Detection: Target-Stance Extraction in the Wild](https://doi.org/10.18653/v1/2023.acl-long.560) |  | 0 |  | Yingjie Li, Krishna Garg, Cornelia Caragea |  |
| 1804 |  |  [Improved Instruction Ordering in Recipe-Grounded Conversation](https://doi.org/10.18653/v1/2023.acl-long.561) |  | 0 |  | Duong Minh Le, Ruohao Guo, Wei Xu, Alan Ritter |  |
| 1805 |  |  [Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions](https://doi.org/10.18653/v1/2023.acl-long.562) |  | 0 |  | ByungDoh Oh, William Schuler |  |
| 1806 |  |  [Document-Level Multi-Event Extraction with Event Proxy Nodes and Hausdorff Distance Minimization](https://doi.org/10.18653/v1/2023.acl-long.563) |  | 0 |  | Xinyu Wang, Lin Gui, Yulan He |  |
| 1807 |  |  [Dialog-Post: Multi-Level Self-Supervised Objectives and Hierarchical Model for Dialogue Post-Training](https://doi.org/10.18653/v1/2023.acl-long.564) |  | 0 |  | Zhenyu Zhang, Lei Shen, Yuming Zhao, Meng Chen, Xiaodong He |  |
| 1808 |  |  [Language Detoxification with Attribute-Discriminative Latent Space](https://doi.org/10.18653/v1/2023.acl-long.565) |  | 0 |  | Jin Myung Kwak, Minseon Kim, Sung Ju Hwang |  |
| 1809 |  |  [Just Like a Human Would, Direct Access to Sarcasm Augmented with Potential Result and Reaction](https://doi.org/10.18653/v1/2023.acl-long.566) |  | 0 |  | Changrong Min, Ximing Li, Liang Yang, Zhilin Wang, Bo Xu, Hongfei Lin |  |
| 1810 |  |  [Adaptive and Personalized Exercise Generation for Online Language Learning](https://doi.org/10.18653/v1/2023.acl-long.567) |  | 0 |  | Peng Cui, Mrinmaya Sachan |  |
| 1811 |  |  [NLP Reproducibility For All: Understanding Experiences of Beginners](https://doi.org/10.18653/v1/2023.acl-long.568) |  | 0 |  | Shane Storks, Keunwoo Peter Yu, Ziqiao Ma, Joyce Chai |  |
| 1812 |  |  [Why Did the Chicken Cross the Road? Rephrasing and Analyzing Ambiguous Questions in VQA](https://doi.org/10.18653/v1/2023.acl-long.569) |  | 0 |  | Elias StengelEskin, Jimena GuallarBlasco, Yi Zhou, Benjamin Van Durme |  |
| 1813 |  |  [UMRSpell: Unifying the Detection and Correction Parts of Pre-trained Models towards Chinese Missing, Redundant, and Spelling Correction](https://doi.org/10.18653/v1/2023.acl-long.570) |  | 0 |  | Zheyu He, Yujin Zhu, Linlin Wang, Liang Xu |  |
| 1814 |  |  [LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction](https://doi.org/10.18653/v1/2023.acl-long.571) |  | 0 |  | Jeremiah Milbauer, Annie Louis, Mohammad Javad Hosseini, Alex Fabrikant, Donald Metzler, Tal Schuster |  |
| 1815 |  |  [Local Interpretation of Transformer Based on Linear Decomposition](https://doi.org/10.18653/v1/2023.acl-long.572) |  | 0 |  | Sen Yang, Shujian Huang, Wei Zou, Jianbing Zhang, Xinyu Dai, Jiajun Chen |  |
| 1816 |  |  [DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions](https://doi.org/10.18653/v1/2023.acl-long.573) |  | 0 |  | Vijay Viswanathan, Luyu Gao, Tongshuang Wu, Pengfei Liu, Graham Neubig |  |
| 1817 |  |  [Multilingual Event Extraction from Historical Newspaper Adverts](https://doi.org/10.18653/v1/2023.acl-long.574) |  | 0 |  | Nadav Borenstein, Natalia da Silva Perez, Isabelle Augenstein |  |
| 1818 |  |  [BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency](https://doi.org/10.18653/v1/2023.acl-long.575) |  | 0 |  | Zhenyu Lei, Herun Wan, Wenqian Zhang, Shangbin Feng, Zilong Chen, Jundong Li, Qinghua Zheng, Minnan Luo |  |
| 1819 |  |  [Do I have the Knowledge to Answer? Investigating Answerability of Knowledge Base Questions](https://doi.org/10.18653/v1/2023.acl-long.576) |  | 0 |  | Mayur Patidar, Prayushi Faldu, Avinash Kumar Singh, Lovekesh Vig, Indrajit Bhattacharya, Mausam |  |
| 1820 |  |  [Understanding Client Reactions in Online Mental Health Counseling](https://doi.org/10.18653/v1/2023.acl-long.577) |  | 0 |  | Anqi Li, Lizhi Ma, Yaling Mei, Hongliang He, Shuai Zhang, Huachuan Qiu, Zhenzhong Lan |  |
| 1821 |  |  [Nonlinear Structural Equation Model Guided Gaussian Mixture Hierarchical Topic Modeling](https://doi.org/10.18653/v1/2023.acl-long.578) |  | 0 |  | Hegang Chen, Pengbo Mao, Yuyin Lu, Yanghui Rao |  |
| 1822 |  |  [Revisiting Token Dropping Strategy in Efficient BERT Pretraining](https://doi.org/10.18653/v1/2023.acl-long.579) |  | 0 |  | Qihuang Zhong, Liang Ding, Juhua Liu, Xuebo Liu, Min Zhang, Bo Du, Dacheng Tao |  |
| 1823 |  |  [The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers](https://doi.org/10.18653/v1/2023.acl-long.580) |  | 0 |  | Ariel Gera, Roni Friedman, Ofir Arviv, R. Chulaka Gunasekara, Benjamin Sznajder, Noam Slonim, Eyal Shnarch |  |
| 1824 |  |  [FACTIFY-5WQA: 5W Aspect-based Fact Verification through Question Answering](https://doi.org/10.18653/v1/2023.acl-long.581) |  | 0 |  | Anku Rani, S. M. Towhidul Islam Tonmoy, Dwip Dalal, Shreya Gautam, Megha Chakraborty, Aman Chadha, Amit P. Sheth, Amitava Das |  |
| 1825 |  |  [Naamapadam: A Large-Scale Named Entity Annotated Data for Indic Languages](https://doi.org/10.18653/v1/2023.acl-long.582) |  | 0 |  | Arnav Mhaske, Harshit Kedia, Sumanth Doddapaneni, Mitesh M. Khapra, Pratyush Kumar, V. Rudra Murthy, Anoop Kunchukuttan |  |
| 1826 |  |  [CREPE: Open-Domain Question Answering with False Presuppositions](https://doi.org/10.18653/v1/2023.acl-long.583) |  | 0 |  | Xinyan Yu, Sewon Min, Luke Zettlemoyer, Hannaneh Hajishirzi |  |
| 1827 |  |  [Joint Document-Level Event Extraction via Token-Token Bidirectional Event Completed Graph](https://doi.org/10.18653/v1/2023.acl-long.584) |  | 0 |  | Qizhi Wan, Changxuan Wan, Keli Xiao, Dexi Liu, Chenliang Li, Bolong Zheng, Xiping Liu, Rong Hu |  |
| 1828 |  |  [Robust Representation Learning with Reliable Pseudo-labels Generation via Self-Adaptive Optimal Transport for Short Text Clustering](https://doi.org/10.18653/v1/2023.acl-long.585) |  | 0 |  | Xiaolin Zheng, Mengling Hu, Weiming Liu, Chaochao Chen, Xinting Liao |  |
| 1829 |  |  [Multilingual Knowledge Graph Completion with Language-Sensitive Multi-Graph Attention](https://doi.org/10.18653/v1/2023.acl-long.586) |  | 0 |  | Rongchuan Tang, Yang Zhao, Chengqing Zong, Yu Zhou |  |
| 1830 |  |  [What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization](https://doi.org/10.18653/v1/2023.acl-long.587) |  | 0 |  | Griffin Adams, Bichlien Nguyen, Jake Smith, Yingce Xia, Shufang Xie, Anna Ostropolets, Budhaditya Deb, YuanJyue Chen, Tristan Naumann, Noémie Elhadad |  |
| 1831 |  |  [Annotating Mentions Alone Enables Efficient Domain Adaptation for Coreference Resolution](https://doi.org/10.18653/v1/2023.acl-long.588) |  | 0 |  | Nupoor Gandhi, Anjalie Field, Emma Strubell |  |
| 1832 |  |  [A Universal Discriminator for Zero-Shot Generalization](https://doi.org/10.18653/v1/2023.acl-long.589) |  | 0 |  | Haike Xu, Zongyu Lin, Jing Zhou, Yanan Zheng, Zhilin Yang |  |
| 1833 |  |  [Syntax and Geometry of Information](https://doi.org/10.18653/v1/2023.acl-long.590) |  | 0 |  | Raphaël Bailly, Laurent Leblond, Kata Gábor |  |
| 1834 |  |  [GreenKGC: A Lightweight Knowledge Graph Completion Method](https://doi.org/10.18653/v1/2023.acl-long.591) |  | 0 |  | Yuncheng Wang, Xiou Ge, Bin Wang, C.C. Jay Kuo |  |
| 1835 |  |  [Unsupervised Open-domain Keyphrase Generation](https://doi.org/10.18653/v1/2023.acl-long.592) |  | 0 |  | Lam Do, Pritom Saha Akash, Kevin ChenChuan Chang |  |
| 1836 |  |  [A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment](https://doi.org/10.18653/v1/2023.acl-long.593) |  | 0 |  | Jiyue Jiang, Sheng Wang, Qintong Li, Lingpeng Kong, Chuan Wu |  |
| 1837 |  |  [Plug-and-Play Knowledge Injection for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.594) |  | 0 |  | Zhengyan Zhang, Zhiyuan Zeng, Yankai Lin, Huadong Wang, Deming Ye, Chaojun Xiao, Xu Han, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou |  |
| 1838 |  |  [Two Birds One Stone: Dynamic Ensemble for OOD Intent Classification](https://doi.org/10.18653/v1/2023.acl-long.595) |  | 0 |  | Yunhua Zhou, Jianqiang Yang, Pengyu Wang, Xipeng Qiu |  |
| 1839 |  |  [SWiPE: A Dataset for Document-Level Simplification of Wikipedia Pages](https://doi.org/10.18653/v1/2023.acl-long.596) |  | 0 |  | Philippe Laban, Jesse Vig, Wojciech Kryscinski, Shafiq Joty, Caiming Xiong, ChienSheng Wu |  |
| 1840 |  |  [Are Message Passing Neural Networks Really Helpful for Knowledge Graph Completion?](https://doi.org/10.18653/v1/2023.acl-long.597) |  | 0 |  | Juanhui Li, Harry Shomer, Jiayuan Ding, Yiqi Wang, Yao Ma, Neil Shah, Jiliang Tang, Dawei Yin |  |
| 1841 |  |  [A dynamic programming algorithm for span-based nested named-entity recognition in O(n²)](https://doi.org/10.18653/v1/2023.acl-long.598) |  | 0 |  | Caio Corro |  |
| 1842 |  |  [Target-Side Augmentation for Document-Level Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.599) |  | 0 |  | Guangsheng Bao, Zhiyang Teng, Yue Zhang |  |
| 1843 |  |  [Rethinking Masked Language Modeling for Chinese Spelling Correction](https://doi.org/10.18653/v1/2023.acl-long.600) |  | 0 |  | Hongqiu Wu, Shaohua Zhang, Yuchen Zhang, Hai Zhao |  |
| 1844 |  |  [A Multi-Modal Context Reasoning Approach for Conditional Inference on Joint Textual and Visual Clues](https://doi.org/10.18653/v1/2023.acl-long.601) |  | 0 |  | Yunxin Li, Baotian Hu, Xinyu Chen, Yuxin Ding, Lin Ma, Min Zhang |  |
| 1845 |  |  [Simple and Effective Unsupervised Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.602) |  | 0 |  | Changhan Wang, Hirofumi Inaguma, PengJen Chen, Ilia Kulikov, Yun Tang, WeiNing Hsu, Michael Auli, Juan Pino |  |
| 1846 |  |  [Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation](https://doi.org/10.18653/v1/2023.acl-long.603) |  | 0 |  | Xuan Long Do, Bowei Zou, Shafiq R. Joty, Anh Tran Tai, Liangming Pan, Nancy F. Chen, Ai Ti Aw |  |
| 1847 |  |  [CHEER: Centrality-aware High-order Event Reasoning Network for Document-level Event Causality Identification](https://doi.org/10.18653/v1/2023.acl-long.604) |  | 0 |  | Meiqi Chen, Yixin Cao, Yan Zhang, Zhiwei Liu |  |
| 1848 |  |  [f-Divergence Minimization for Sequence-Level Knowledge Distillation](https://doi.org/10.18653/v1/2023.acl-long.605) |  | 0 |  | Yuqiao Wen, Zichao Li, Wenyu Du, Lili Mou |  |
| 1849 |  |  [Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2023.acl-long.606) |  | 0 |  | Dou Hu, Yinan Bao, Lingwei Wei, Wei Zhou, Songlin Hu |  |
| 1850 |  |  [A Novel Table-to-Graph Generation Approach for Document-Level Joint Entity and Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.607) |  | 0 |  | Ruoyu Zhang, Yanzeng Li, Lei Zou |  |
| 1851 |  |  [A Synthetic Data Generation Framework for Grounded Dialogues](https://doi.org/10.18653/v1/2023.acl-long.608) |  | 0 |  | Jianzhu Bao, Rui Wang, Yasheng Wang, Aixin Sun, Yitong Li, Fei Mi, Ruifeng Xu |  |
| 1852 |  |  [MasakhaPOS: Part-of-Speech Tagging for Typologically Diverse African languages](https://doi.org/10.18653/v1/2023.acl-long.609) |  | 0 |  | Cheikh M. Bamba Dione, David Ifeoluwa Adelani, Peter Nabende, Jesujoba O. Alabi, Thapelo Sindane, Happy Buzaaba, Shamsuddeen Hassan Muhammad, Chris Chinenye Emezue, Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau, Derguene Mbaye, Jonathan Mukiibi, Blessing K. Sibanda, Bonaventure F. P. Dossou, Andiswa Bukula, Rooweither Mabuya, Allahsera Auguste Tapo, Edwin MunkohBuabeng, Victoire Memdjokam Koagne, Fatoumata Ouoba Kabore, Amelia V. Taylor, Godson Kalipe, Tebogo Macucwa, Vukosi Marivate, Tajuddeen Gwadabe, Elvis Mboning Tchiaze, Ikechukwu E. Onyenwe, Gratien Atindogbe, Tolulope Anu Adelani, Idris Akinade, Samuel Olanrewaju, Marien Nahimana, Théogène Musabeyezu, Emile Niyomutabazi, Ester Chimhenga, Kudzai Gotosa, Patrick Mizha, Apelete Agbolo, Seydou Traore, Chinedu Uchechukwu, Aliyu Yusuf, Muhammad Abdullahi, Dietrich Klakow |  |
| 1853 |  |  [Semantic Structure Enhanced Event Causality Identification](https://doi.org/10.18653/v1/2023.acl-long.610) |  | 0 |  | Zhilei Hu, Zixuan Li, Xiaolong Jin, Long Bai, Saiping Guan, Jiafeng Guo, Xueqi Cheng |  |
| 1854 |  |  [Weakly-Supervised Spoken Video Grounding via Semantic Interaction Learning](https://doi.org/10.18653/v1/2023.acl-long.611) |  | 0 |  | Ye Wang, Wang Lin, Shengyu Zhang, Tao Jin, Linjun Li, Xize Cheng, Zhou Zhao |  |
| 1855 |  |  [Rehearsal-free Continual Language Learning via Efficient Parameter Isolation](https://doi.org/10.18653/v1/2023.acl-long.612) |  | 0 |  | Zhicheng Wang, Yufang Liu, Tao Ji, Xiaoling Wang, Yuanbin Wu, Congcong Jiang, Ye Chao, Zhencong Han, Ling Wang, Xu Shao, Wenqiu Zeng |  |
| 1856 |  |  [Label-Aware Hyperbolic Embeddings for Fine-grained Emotion Classification](https://doi.org/10.18653/v1/2023.acl-long.613) |  | 0 |  | ChihYao Chen, TunMin Hung, YiLi Hsu, LunWei Ku |  |
| 1857 |  |  [Combo of Thinking and Observing for Outside-Knowledge VQA](https://doi.org/10.18653/v1/2023.acl-long.614) |  | 0 |  | Qingyi Si, Yuchen Mo, Zheng Lin, Huishan Ji, Weiping Wang |  |
| 1858 |  |  [AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model](https://doi.org/10.18653/v1/2023.acl-long.615) |  | 0 |  | IHung Hsu, Zhiyu Xie, KuanHao Huang, Prem Natarajan, Nanyun Peng |  |
| 1859 |  |  [Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships](https://doi.org/10.18653/v1/2023.acl-long.616) |  | 0 |  | David Jurgens, Agrima Seth, Jackson Sargent, Athena Aghighi, Michael Geraci |  |
| 1860 |  |  [TART: Improved Few-shot Text Classification Using Task-Adaptive Reference Transformation](https://doi.org/10.18653/v1/2023.acl-long.617) |  | 0 |  | Shuo Lei, Xuchao Zhang, Jianfeng He, Fanglan Chen, ChangTien Lu |  |
| 1861 |  |  [How Do In-Context Examples Affect Compositional Generalization?](https://doi.org/10.18653/v1/2023.acl-long.618) |  | 0 |  | Shengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, JianGuang Lou, Dongmei Zhang |  |
| 1862 |  |  [Attractive Storyteller: Stylized Visual Storytelling with Unpaired Text](https://doi.org/10.18653/v1/2023.acl-long.619) |  | 0 |  | Dingyi Yang, Qin Jin |  |
| 1863 |  |  [Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation](https://doi.org/10.18653/v1/2023.acl-long.620) |  | 0 |  | Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nallapati, Xiaofei Ma |  |
| 1864 |  |  [WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction](https://doi.org/10.18653/v1/2023.acl-long.621) |  | 0 |  | Qiyu Wu, Masaaki Nagata, Yoshimasa Tsuruoka |  |
| 1865 |  |  [Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models](https://doi.org/10.18653/v1/2023.acl-long.622) |  | 0 |  | Junmo Kang, Wei Xu, Alan Ritter |  |
| 1866 |  |  [OD-RTE: A One-Stage Object Detection Framework for Relational Triple Extraction](https://doi.org/10.18653/v1/2023.acl-long.623) |  | 0 |  | Jinzhong Ning, Zhihao Yang, Yuanyuan Sun, Zhizheng Wang, Hongfei Lin |  |
| 1867 |  |  [I Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons](https://doi.org/10.18653/v1/2023.acl-long.624) |  | 0 |  | Pei Zhou, Andrew Zhu, Jennifer Hu, Jay Pujara, Xiang Ren, Chris CallisonBurch, Yejin Choi, Prithviraj Ammanabrolu |  |
| 1868 |  |  [Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning](https://doi.org/10.18653/v1/2023.acl-long.625) |  | 0 |  | Tianxiang Sun, Zhengfu He, Qin Zhu, Xipeng Qiu, Xuanjing Huang |  |
| 1869 |  |  [Is GPT-3 a Good Data Annotator?](https://doi.org/10.18653/v1/2023.acl-long.626) |  | 0 |  | Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, Lidong Bing |  |
| 1870 |  |  [Multi-Grained Knowledge Retrieval for End-to-End Task-Oriented Dialog](https://doi.org/10.18653/v1/2023.acl-long.627) |  | 0 |  | Fanqi Wan, Weizhou Shen, Ke Yang, Xiaojun Quan, Wei Bi |  |
| 1871 |  |  [Few-shot Event Detection: An Empirical Study and a Unified View](https://doi.org/10.18653/v1/2023.acl-long.628) |  | 0 |  | Yubo Ma, Zehao Wang, Yixin Cao, Aixin Sun |  |
| 1872 |  |  [How to Plant Trees in Language Models: Data and Architectural Effects on the Emergence of Syntactic Inductive Biases](https://doi.org/10.18653/v1/2023.acl-long.629) |  | 0 |  | Aaron Mueller, Tal Linzen |  |
| 1873 |  |  [ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations](https://doi.org/10.18653/v1/2023.acl-long.630) |  | 0 |  | Valentina Pyatkin, Jena D. Hwang, Vivek Srikumar, Ximing Lu, Liwei Jiang, Yejin Choi, Chandra Bhagavatula |  |
| 1874 |  |  [HINT: Hypernetwork Instruction Tuning for Efficient Zero- and Few-Shot Generalisation](https://doi.org/10.18653/v1/2023.acl-long.631) |  | 0 |  | Hamish Ivison, Akshita Bhagia, Yizhong Wang, Hannaneh Hajishirzi, Matthew E. Peters |  |
| 1875 |  |  [Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations](https://doi.org/10.18653/v1/2023.acl-long.632) |  | 0 |  | Chenglei Si, Dan Friedman, Nitish Joshi, Shi Feng, Danqi Chen, He He |  |
| 1876 |  |  [An Inclusive Notion of Text](https://doi.org/10.18653/v1/2023.acl-long.633) |  | 0 |  | Ilia Kuznetsov, Iryna Gurevych |  |
| 1877 |  |  [AlignScore: Evaluating Factual Consistency with A Unified Alignment Function](https://doi.org/10.18653/v1/2023.acl-long.634) |  | 0 |  | Yuheng Zha, Yichi Yang, Ruichen Li, Zhiting Hu |  |
| 1878 |  |  [Multi-source Semantic Graph-based Multimodal Sarcasm Explanation Generation](https://doi.org/10.18653/v1/2023.acl-long.635) |  | 0 |  | Liqiang Jing, Xuemeng Song, Kun Ouyang, Mengzhao Jia, Liqiang Nie |  |
| 1879 |  |  [Counterfactual Active Learning for Out-of-Distribution Generalization](https://doi.org/10.18653/v1/2023.acl-long.636) |  | 0 |  | Xun Deng, Wenjie Wang, Fuli Feng, Hanwang Zhang, Xiangnan He, Yong Liao |  |
| 1880 |  |  [Multi-granularity Temporal Question Answering over Knowledge Graphs](https://doi.org/10.18653/v1/2023.acl-long.637) |  | 0 |  | Ziyang Chen, Jinzhi Liao, Xiang Zhao |  |
| 1881 |  |  [A New Aligned Simple German Corpus](https://doi.org/10.18653/v1/2023.acl-long.638) |  | 0 |  | Vanessa Toborek, Moritz Busch, Malte Boßert, Christian Bauckhage, Pascal Welke |  |
| 1882 |  |  [Introducing Semantics into Speech Encoders](https://doi.org/10.18653/v1/2023.acl-long.639) |  | 0 |  | Derek Xu, Shuyan Dong, Changhan Wang, Suyoun Kim, Zhaojiang Lin, Bing Liu, Akshat Shrivastava, ShangWen Li, LiangHsuan Tseng, GuanTing Lin, Alexei Baevski, Hungyi Lee, Yizhou Sun, Wei Wang |  |
| 1883 |  |  [Constrained Tuple Extraction with Interaction-Aware Network](https://doi.org/10.18653/v1/2023.acl-long.640) |  | 0 |  | Xiaojun Xue, Chunxia Zhang, Tianxiang Xu, Zhendong Niu |  |
| 1884 |  |  [MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning](https://doi.org/10.18653/v1/2023.acl-long.641) |  | 0 |  | Zhiyang Xu, Ying Shen, Lifu Huang |  |
| 1885 |  |  [Single Sequence Prediction over Reasoning Graphs for Multi-hop QA](https://doi.org/10.18653/v1/2023.acl-long.642) |  | 0 |  | Gowtham Ramesh, Makesh Narsimhan Sreedhar, Junjie Hu |  |
| 1886 |  |  [Contrastive Error Attribution for Finetuned Language Models](https://doi.org/10.18653/v1/2023.acl-long.643) |  | 0 |  | Faisal Ladhak, Esin Durmus, Tatsunori Hashimoto |  |
| 1887 |  |  [DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications](https://doi.org/10.18653/v1/2023.acl-long.644) |  | 0 |  | Adam Ivankay, Mattia Rigotti, Pascal Frossard |  |
| 1888 |  |  [Neural Machine Translation for Mathematical Formulae](https://doi.org/10.18653/v1/2023.acl-long.645) |  | 0 |  | Felix Petersen, Moritz Schubotz, André GreinerPetter, Bela Gipp |  |
| 1889 |  |  [Query-Efficient Black-Box Red Teaming via Bayesian Optimization](https://doi.org/10.18653/v1/2023.acl-long.646) |  | 0 |  | Deokjae Lee, JunYeong Lee, JungWoo Ha, JinHwa Kim, SangWoo Lee, Hwaran Lee, Hyun Oh Song |  |
| 1890 |  |  [SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control](https://doi.org/10.18653/v1/2023.acl-long.647) |  | 0 |  | Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov |  |
| 1891 |  |  [Recall, Expand, and Multi-Candidate Cross-Encode: Fast and Accurate Ultra-Fine Entity Typing](https://doi.org/10.18653/v1/2023.acl-long.648) |  | 0 |  | Chengyue Jiang, Wenyang Hui, Yong Jiang, Xiaobin Wang, Pengjun Xie, Kewei Tu |  |
| 1892 |  |  [MIR-GAN: Refining Frame-Level Modality-Invariant Representations with Adversarial Network for Audio-Visual Speech Recognition](https://doi.org/10.18653/v1/2023.acl-long.649) |  | 0 |  | Yuchen Hu, Chen Chen, Ruizhe Li, Heqing Zou, Eng Siong Chng |  |
| 1893 |  |  [Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors](https://doi.org/10.18653/v1/2023.acl-long.650) |  | 0 |  | Liyan Tang, Tanya Goyal, Alexander R. Fabbri, Philippe Laban, Jiacheng Xu, Semih Yavuz, Wojciech Kryscinski, Justin F. Rousseau, Greg Durrett |  |
| 1894 |  |  [GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding](https://doi.org/10.18653/v1/2023.acl-long.651) |  | 0 |  | JiaChen Gu, Zhenhua Ling, Quan Liu, Cong Liu, Guoping Hu |  |
| 1895 |  |  [Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks](https://doi.org/10.18653/v1/2023.acl-long.652) |  | 0 |  | Artem Vazhentsev, Gleb Kuzmin, Akim Tsvigun, Alexander Panchenko, Maxim Panov, Mikhail Burtsev, Artem Shelmanov |  |
| 1896 |  |  [BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting](https://doi.org/10.18653/v1/2023.acl-long.653) |  | 0 |  | Zheng Xin Yong, Hailey Schoelkopf, Niklas Muennighoff, Alham Fikri Aji, David Ifeoluwa Adelani, Khalid Almubarak, M. Saiful Bari, Lintang Sutawika, Jungo Kasai, Ahmed Baruwa, Genta Indra Winata, Stella Biderman, Edward Raff, Dragomir Radev, Vassilina Nikoulina |  |
| 1897 |  |  [Logic-driven Indirect Supervision: An Application to Crisis Counseling](https://doi.org/10.18653/v1/2023.acl-long.654) |  | 0 |  | Mattia Medina Grespan, Meghan Broadbent, Xinyao Zhang, Katherine Axford, Brent Kious, Zac E. Imel, Vivek Srikumar |  |
| 1898 |  |  [Grounding Characters and Places in Narrative Text](https://doi.org/10.18653/v1/2023.acl-long.655) |  | 0 |  | Sandeep Soni, Amanpreet Sihra, Elizabeth F. Evans, Matthew Wilkens, David Bamman |  |
| 1899 |  |  [From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models](https://doi.org/10.18653/v1/2023.acl-long.656) |  | 0 |  | Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov |  |
| 1900 |  |  [SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT](https://doi.org/10.18653/v1/2023.acl-long.657) |  | 0 |  | Aditya Yadavalli, Alekhya Yadavalli, Vera Tobin |  |
| 1901 |  |  [Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.658) |  | 0 |  | Albert Xu, Xiang Ren, Robin Jia |  |
| 1902 |  |  [Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?](https://doi.org/10.18653/v1/2023.acl-long.659) |  | 0 |  | Chengwei Qin, Shafiq R. Joty, Qian Li, Ruochen Zhao |  |
| 1903 |  |  [Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale](https://doi.org/10.18653/v1/2023.acl-long.660) |  | 0 |  | Hritik Bansal, Karthik Gopalakrishnan, Saket Dingliwal, Sravan Bodapati, Katrin Kirchhoff, Dan Roth |  |
| 1904 |  |  [Question-Answering in a Low-resourced Language: Benchmark Dataset and Models for Tigrinya](https://doi.org/10.18653/v1/2023.acl-long.661) |  | 0 |  | Fitsum Gaim, Wonsuk Yang, Hancheol Park, Jong Park |  |
| 1905 |  |  [ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain](https://doi.org/10.18653/v1/2023.acl-long.662) |  | 0 |  | Mike Zhang, Rob van der Goot, Barbara Plank |  |
| 1906 |  |  [CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval](https://doi.org/10.18653/v1/2023.acl-long.663) |  | 0 |  | Minghan Li, ShengChieh Lin, Barlas Oguz, Asish Ghoshal, Jimmy Lin, Yashar Mehdad, Wentau Yih, Xilun Chen |  |
| 1907 |  |  [MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual Captioning](https://doi.org/10.18653/v1/2023.acl-long.664) |  | 0 |  | Bang Yang, Fenglin Liu, Xian Wu, Yaowei Wang, Xu Sun, Yuexian Zou |  |
| 1908 |  |  [Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge](https://doi.org/10.18653/v1/2023.acl-long.665) |  | 0 |  | Vasudha Varadarajan, Swanie Juhng, Syeda Mahwish, Xiaoran Liu, Jonah Luby, Christian C. Luhmann, H. Andrew Schwartz |  |
| 1909 |  |  [In-sample Curriculum Learning by Sequence Completion for Natural Language Generation](https://doi.org/10.18653/v1/2023.acl-long.666) |  | 0 |  | Qi Jia, Yizhu Liu, Haifeng Tang, Kenny Q. Zhu |  |
| 1910 |  |  [Product Question Answering in E-Commerce: A Survey](https://doi.org/10.18653/v1/2023.acl-long.667) |  | 0 |  | Yang Deng, Wenxuan Zhang, Qian Yu, Wai Lam |  |
| 1911 |  |  [Towards Domain-Agnostic and Domain-Adaptive Dementia Detection from Spoken Language](https://doi.org/10.18653/v1/2023.acl-long.668) |  | 0 |  | Shahla Farzana, Natalie Parde |  |
| 1912 |  |  [Generalizing Backpropagation for Gradient-Based Interpretability](https://doi.org/10.18653/v1/2023.acl-long.669) |  | 0 |  | Kevin Du, Lucas Torroba Hennigen, Niklas Stoehr, Alex Warstadt, Ryan Cotterell |  |
| 1913 |  |  [UPPAM: A Unified Pre-training Architecture for Political Actor Modeling based on Language](https://doi.org/10.18653/v1/2023.acl-long.670) |  | 0 |  | Xinyi Mou, Zhongyu Wei, Qi Zhang, Xuanjing Huang |  |
| 1914 |  |  [Generic Temporal Reasoning with Differential Analysis and Explanation](https://doi.org/10.18653/v1/2023.acl-long.671) |  | 0 |  | Yu Feng, Ben Zhou, Haoyu Wang, Helen Jin, Dan Roth |  |
| 1915 |  |  [Model-Based Simulation for Optimising Smart Reply](https://doi.org/10.18653/v1/2023.acl-long.672) |  | 0 |  | Benjamin Towle, Ke Zhou |  |
| 1916 |  |  [Beyond Contrastive Learning: A Variational Generative Model for Multilingual Retrieval](https://doi.org/10.18653/v1/2023.acl-long.673) |  | 0 |  | John Wieting, Jonathan H. Clark, William W. Cohen, Graham Neubig, Taylor BergKirkpatrick |  |
| 1917 |  |  [On the Blind Spots of Model-Based Evaluation Metrics for Text Generation](https://doi.org/10.18653/v1/2023.acl-long.674) |  | 0 |  | Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James R. Glass, Yulia Tsvetkov |  |
| 1918 |  |  [Dealing with Semantic Underspecification in Multimodal NLP](https://doi.org/10.18653/v1/2023.acl-long.675) |  | 0 |  | Sandro Pezzelle |  |
| 1919 |  |  [Trigger Warning Assignment as a Multi-Label Document Classification Problem](https://doi.org/10.18653/v1/2023.acl-long.676) |  | 0 |  | Matti Wiegmann, Magdalena Wolska, Christopher Schröder, Ole Borchardt, Benno Stein, Martin Potthast |  |
| 1920 |  |  [WhitenedCSE: Whitening-based Contrastive Learning of Sentence Embeddings](https://doi.org/10.18653/v1/2023.acl-long.677) |  | 0 |  | Wenjie Zhuo, Yifan Sun, Xiaohan Wang, Linchao Zhu, Yi Yang |  |
| 1921 |  |  [Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms](https://doi.org/10.18653/v1/2023.acl-long.678) |  | 0 |  | Tianshu Zhang, Changchang Liu, WeiHan Lee, Yu Su, Huan Sun |  |
| 1922 |  |  [Causality-Guided Multi-Memory Interaction Network for Multivariate Stock Price Movement Prediction](https://doi.org/10.18653/v1/2023.acl-long.679) |  | 0 |  | Di Luo, Weiheng Liao, Shuqi Li, Xin Cheng, Rui Yan |  |
| 1923 |  |  [DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization](https://doi.org/10.18653/v1/2023.acl-long.680) |  | 0 |  | Songyang Gao, Shihan Dou, Yan Liu, Xiao Wang, Qi Zhang, Zhongyu Wei, Jin Ma, Ying Shan |  |
| 1924 |  |  [A Simple and Flexible Modeling for Mental Disorder Detection by Learning from Clinical Questionnaires](https://doi.org/10.18653/v1/2023.acl-long.681) |  | 0 |  | Hoyun Song, Jisu Shin, Huije Lee, Jong Park |  |
| 1925 |  |  [Downstream Datasets Make Surprisingly Good Pretraining Corpora](https://doi.org/10.18653/v1/2023.acl-long.682) |  | 0 |  | Kundan Krishna, Saurabh Garg, Jeffrey P. Bigham, Zachary C. Lipton |  |
| 1926 |  |  [Towards Open-World Product Attribute Mining: A Lightly-Supervised Approach](https://doi.org/10.18653/v1/2023.acl-long.683) |  | 0 |  | Liyan Xu, Chenwei Zhang, Xian Li, Jingbo Shang, Jinho D. Choi |  |
| 1927 |  |  [XDailyDialog: A Multilingual Parallel Dialogue Corpus](https://doi.org/10.18653/v1/2023.acl-long.684) |  | 0 |  | Zeming Liu, Ping Nie, Jie Cai, Haifeng Wang, ZhengYu Niu, Peng Zhang, Mrinmaya Sachan, Kaiping Peng |  |
| 1928 |  |  [PAL to Lend a Helping Hand: Towards Building an Emotion Adaptive Polite and Empathetic Counseling Conversational Agent](https://doi.org/10.18653/v1/2023.acl-long.685) |  | 0 |  | Kshitij Mishra, Priyanshu Priya, Asif Ekbal |  |
| 1929 |  |  [Bidirectional Generative Framework for Cross-domain Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2023.acl-long.686) |  | 0 |  | Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing |  |
| 1930 |  |  [Contrastive Decoding: Open-ended Text Generation as Optimization](https://doi.org/10.18653/v1/2023.acl-long.687) |  | 0 |  | Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, Mike Lewis |  |
| 1931 |  |  [Resolving Indirect Referring Expressions for Entity Selection](https://doi.org/10.18653/v1/2023.acl-long.688) |  | 0 |  | Mohammad Javad Hosseini, Filip Radlinski, Silvia Pareti, Annie Louis |  |
| 1932 |  |  [Accelerating Transformer Inference for Translation via Parallel Decoding](https://doi.org/10.18653/v1/2023.acl-long.689) |  | 0 |  | Andrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Riccardo Marin, Emanuele Rodolà |  |
| 1933 |  |  [Hard Sample Aware Prompt-Tuning](https://doi.org/10.18653/v1/2023.acl-long.690) |  | 0 |  | Yuanjian Xu, Qi An, Jiahuan Zhang, Peng Li, Zaiqing Nie |  |
| 1934 |  |  [WikiBio: a Semantic Resource for the Intersectional Analysis of Biographical Events](https://doi.org/10.18653/v1/2023.acl-long.691) |  | 0 |  | Marco Antonio Stranisci, Rossana Damiano, Enrico Mensa, Viviana Patti, Daniele Paolo Radicioni, Tommaso Caselli |  |
| 1935 |  |  [Best-k Search Algorithm for Neural Text Generation](https://doi.org/10.18653/v1/2023.acl-long.692) |  | 0 |  | Jiacheng Xu, Caiming Xiong, Silvio Savarese, Yingbo Zhou |  |
| 1936 |  |  [Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages](https://doi.org/10.18653/v1/2023.acl-long.693) |  | 0 |  | Sumanth Doddapaneni, Rahul Aralikatte, Gowtham Ramesh, Shreya Goyal, Mitesh M. Khapra, Anoop Kunchukuttan, Pratyush Kumar |  |
| 1937 |  |  [Transforming Visual Scene Graphs to Image Captions](https://doi.org/10.18653/v1/2023.acl-long.694) |  | 0 |  | Xu Yang, Jiawei Peng, Zihua Wang, Haiyang Xu, Qinghao Ye, Chenliang Li, Songfang Huang, Fei Huang, Zhangzikang Li, Yu Zhang |  |
| 1938 |  |  [Hybrid Transducer and Attention based Encoder-Decoder Modeling for Speech-to-Text Tasks](https://doi.org/10.18653/v1/2023.acl-long.695) |  | 0 |  | Yun Tang, Anna Y. Sun, Hirofumi Inaguma, Xinyue Chen, Ning Dong, Xutai Ma, Paden Tomasello, Juan Pino |  |
| 1939 |  |  [Improving Domain Generalization for Prompt-Aware Essay Scoring via Disentangled Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.696) |  | 0 |  | Zhiwei Jiang, Tianyi Gao, Yafeng Yin, Meng Liu, Hua Yu, Zifeng Cheng, Qing Gu |  |
| 1940 |  |  [What's the Meaning of Superhuman Performance in Today's NLU?](https://doi.org/10.18653/v1/2023.acl-long.697) |  | 0 |  | Simone Tedeschi, Johan Bos, Thierry Declerck, Jan Hajic, Daniel Hershcovich, Eduard H. Hovy, Alexander Koller, Simon Krek, Steven Schockaert, Rico Sennrich, Ekaterina Shutova, Roberto Navigli |  |
| 1941 |  |  [PromptNER: Prompt Locating and Typing for Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-long.698) |  | 0 |  | Yongliang Shen, Zeqi Tan, Shuhui Wu, Wenqi Zhang, Rongsheng Zhang, Yadong Xi, Weiming Lu, Yueting Zhuang |  |
| 1942 |  |  [Hints on the data for language modeling of synthetic languages with transformers](https://doi.org/10.18653/v1/2023.acl-long.699) |  | 0 |  | Rodolfo Zevallos, Núria Bel |  |
| 1943 |  |  [Neural Machine Translation Methods for Translating Text to Sign Language Glosses](https://doi.org/10.18653/v1/2023.acl-long.700) |  | 0 |  | Dele Zhu, Vera Czehmann, Eleftherios Avramidis |  |
| 1944 |  |  [Revisiting Event Argument Extraction: Can EAE Models Learn Better When Being Aware of Event Co-occurrences?](https://doi.org/10.18653/v1/2023.acl-long.701) |  | 0 |  | Yuxin He, Jingyue Hu, Buzhou Tang |  |
| 1945 |  |  [HAUSER: Towards Holistic and Automatic Evaluation of Simile Generation](https://doi.org/10.18653/v1/2023.acl-long.702) |  | 0 |  | Qianyu He, Yikai Zhang, Jiaqing Liang, Yuncheng Huang, Yanghua Xiao, Yunwen Chen |  |
| 1946 |  |  [Large-scale Lifelong Learning of In-context Instructions and How to Tackle It](https://doi.org/10.18653/v1/2023.acl-long.703) |  | 0 |  | Jisoo Mok, Jaeyoung Do, Sungjin Lee, Tara Taghavi, Seunghak Yu, Sungroh Yoon |  |
| 1947 |  |  [Controllable Text Generation via Probability Density Estimation in the Latent Space](https://doi.org/10.18653/v1/2023.acl-long.704) |  | 0 |  | Yuxuan Gu, Xiaocheng Feng, Sicheng Ma, Lingyuan Zhang, Heng Gong, Weihong Zhong, Bing Qin |  |
| 1948 |  |  [Learning Latent Relations for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2023.acl-long.705) |  | 0 |  | Mengqi Zhang, Yuwei Xia, Qiang Liu, Shu Wu, Liang Wang |  |
| 1949 |  |  [DT-Solver: Automated Theorem Proving with Dynamic-Tree Sampling Guided by Proof-level Value Function](https://doi.org/10.18653/v1/2023.acl-long.706) |  | 0 |  | Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen, Yichun Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, Jian Yin, Zhenguo Li, Xiaodan Liang |  |
| 1950 |  |  [Unsupervised Selective Rationalization with Noise Injection](https://doi.org/10.18653/v1/2023.acl-long.707) |  | 0 |  | Adam Storek, Melanie Subbiah, Kathleen R. McKeown |  |
| 1951 |  |  [Understanding In-Context Learning via Supportive Pretraining Data](https://doi.org/10.18653/v1/2023.acl-long.708) |  | 0 |  | Xiaochuang Han, Daniel Simig, Todor Mihaylov, Yulia Tsvetkov, Asli Celikyilmaz, Tianlu Wang |  |
| 1952 |  |  [ETHICIST: Targeted Training Data Extraction Through Loss Smoothed Soft Prompting and Calibrated Confidence Estimation](https://doi.org/10.18653/v1/2023.acl-long.709) |  | 0 |  | Zhexin Zhang, Jiaxin Wen, Minlie Huang |  |
| 1953 |  |  [Effective Contrastive Weighting for Dense Query Expansion](https://doi.org/10.18653/v1/2023.acl-long.710) |  | 0 |  | Xiao Wang, Sean MacAvaney, Craig Macdonald, Iadh Ounis |  |
| 1954 |  |  [Improving the Detection of Multilingual Online Attacks with Rich Social Media Data from Singapore](https://doi.org/10.18653/v1/2023.acl-long.711) |  | 0 |  | Janosch Haber, Bertie Vidgen, Matthew Chapman, Vibhor Agarwal, Roy KaWei Lee, Yong Keong Yap, Paul Röttger |  |
| 1955 |  |  [Reanalyzing L2 Preposition Learning with Bayesian Mixed Effects and a Pretrained Language Model](https://doi.org/10.18653/v1/2023.acl-long.712) |  | 0 |  | Jakob Prange, Man Ho Ivy Wong |  |
| 1956 |  |  [Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization](https://doi.org/10.18653/v1/2023.acl-long.713) |  | 0 |  | Artidoro Pagnoni, Alexander R. Fabbri, Wojciech Kryscinski, ChienSheng Wu |  |
| 1957 |  |  [MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering](https://doi.org/10.18653/v1/2023.acl-long.714) |  | 0 |  | Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos |  |
| 1958 |  |  [MGR: Multi-generator Based Rationalization](https://doi.org/10.18653/v1/2023.acl-long.715) |  | 0 |  | Wei Liu, Haozhao Wang, Jun Wang, Ruixuan Li, Xinyang Li, Yuankai Zhang, Yang Qiu |  |
| 1959 |  |  [BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics](https://doi.org/10.18653/v1/2023.acl-long.716) |  | 0 |  | Liang Ma, Shuyang Cao, Robert L. Logan IV, Di Lu, Shihao Ran, Ke Zhang, Joel R. Tetreault, Alejandro Jaimes |  |
| 1960 |  |  [Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for Out-of-Domain Detection](https://doi.org/10.18653/v1/2023.acl-long.717) |  | 0 |  | Rheeya Uppaal, Junjie Hu, Yixuan Li |  |
| 1961 |  |  [UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization](https://doi.org/10.18653/v1/2023.acl-long.718) |  | 0 |  | Yulong Chen, Yang Liu, Ruochen Xu, Ziyi Yang, Chenguang Zhu, Michael Zeng, Yue Zhang |  |
| 1962 |  |  [RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue](https://doi.org/10.18653/v1/2023.acl-long.719) |  | 0 |  | Zhengliang Shi, Weiwei Sun, Shuo Zhang, Zhen Zhang, Pengjie Ren, Zhaochun Ren |  |
| 1963 |  |  [An AMR-based Link Prediction Approach for Document-level Event Argument Extraction](https://doi.org/10.18653/v1/2023.acl-long.720) |  | 0 |  | Yuqing Yang, Qipeng Guo, Xiangkun Hu, Yue Zhang, Xipeng Qiu, Zheng Zhang |  |
| 1964 |  |  [PuMer: Pruning and Merging Tokens for Efficient Vision Language Models](https://doi.org/10.18653/v1/2023.acl-long.721) |  | 0 |  | Qingqing Cao, Bhargavi Paranjape, Hannaneh Hajishirzi |  |
| 1965 |  |  [Gloss-Free End-to-End Sign Language Translation](https://doi.org/10.18653/v1/2023.acl-long.722) |  | 0 |  | Kezhou Lin, Xiaohan Wang, Linchao Zhu, Ke Sun, Bang Zhang, Yi Yang |  |
| 1966 |  |  [TAGPRIME: A Unified Framework for Relational Structure Extraction](https://doi.org/10.18653/v1/2023.acl-long.723) |  | 0 |  | IHung Hsu, KuanHao Huang, Shuning Zhang, Wenxin Cheng, Prem Natarajan, KaiWei Chang, Nanyun Peng |  |
| 1967 |  |  [Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers](https://doi.org/10.18653/v1/2023.acl-long.724) |  | 0 |  | Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, Alvin Cheung, Jianfeng Gao, Xia Song |  |
| 1968 |  |  [BITE: Textual Backdoor Attacks with Iterative Trigger Injection](https://doi.org/10.18653/v1/2023.acl-long.725) |  | 0 |  | Jun Yan, Vansh Gupta, Xiang Ren |  |
| 1969 |  |  [A Crosslingual Investigation of Conceptualization in 1335 Languages](https://doi.org/10.18653/v1/2023.acl-long.726) |  | 0 |  | Yihong Liu, Haotian Ye, Leonie Weissweiler, Philipp Wicke, Renhao Pei, Robert Zangenfeind, Hinrich Schütze |  |
| 1970 |  |  [Exploring and Verbalizing Academic Ideas by Concept Co-occurrence](https://doi.org/10.18653/v1/2023.acl-long.727) |  | 0 |  | Yi Xu, Shuqian Sheng, Bo Xue, Luoyi Fu, Xinbing Wang, Chenghu Zhou |  |
| 1971 |  |  [mCLIP: Multilingual CLIP via Cross-lingual Transfer](https://doi.org/10.18653/v1/2023.acl-long.728) |  | 0 |  | Guanhua Chen, Lu Hou, Yun Chen, Wenliang Dai, Lifeng Shang, Xin Jiang, Qun Liu, Jia Pan, Wenping Wang |  |
| 1972 |  |  [Distantly Supervised Course Concept Extraction in MOOCs with Academic Discipline](https://doi.org/10.18653/v1/2023.acl-long.729) |  | 0 |  | Mengying Lu, Yuquan Wang, Jifan Yu, Yexing Du, Lei Hou, Juanzi Li |  |
| 1973 |  |  [Extrinsic Evaluation of Machine Translation Metrics](https://doi.org/10.18653/v1/2023.acl-long.730) |  | 0 |  | Nikita Moghe, Tom Sherborne, Mark Steedman, Alexandra Birch |  |
| 1974 |  |  [ExplainMeetSum: A Dataset for Explainable Meeting Summarization Aligned with Human Intent](https://doi.org/10.18653/v1/2023.acl-long.731) |  | 0 |  | Hyun Kim, Minsoo Cho, SeungHoon Na |  |
| 1975 |  |  [A Cross-Modality Context Fusion and Semantic Refinement Network for Emotion Recognition in Conversation](https://doi.org/10.18653/v1/2023.acl-long.732) |  | 0 |  | Xiaoheng Zhang, Yang Li |  |
| 1976 |  |  [CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning](https://doi.org/10.18653/v1/2023.acl-long.733) |  | 0 |  | Weiqi Wang, Tianqing Fang, Baixuan Xu, Chun Yi Louis Bo, Yangqiu Song, Lei Chen |  |
| 1977 |  |  [The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research](https://doi.org/10.18653/v1/2023.acl-long.734) |  | 0 |  | Mohamed Abdalla, Jan Philip Wahle, Terry Lima Ruas, Aurélie Névéol, Fanny Ducel, Saif M. Mohammad, Karën Fort |  |
| 1978 |  |  [Language of Bargaining](https://doi.org/10.18653/v1/2023.acl-long.735) |  | 0 |  | Mourad Heddaya, Solomon Dworkin, Chenhao Tan, Rob Voigt, Alexander Zentefis |  |
| 1979 |  |  [Do Question Answering Modeling Improvements Hold Across Benchmarks?](https://doi.org/10.18653/v1/2023.acl-long.736) |  | 0 |  | Nelson F. Liu, Tony Lee, Robin Jia, Percy Liang |  |
| 1980 |  |  [VLN-Trans: Translator for the Vision and Language Navigation Agent](https://doi.org/10.18653/v1/2023.acl-long.737) |  | 0 |  | Yue Zhang, Parisa Kordjamshidi |  |
| 1981 |  |  [Bridging the Gap between Decision and Logits in Decision-based Knowledge Distillation for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.738) |  | 0 |  | Qinhong Zhou, Zonghan Yang, Peng Li, Yang Liu |  |
| 1982 |  |  [Continual Contrastive Finetuning Improves Low-Resource Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.739) |  | 0 |  | Wenxuan Zhou, Sheng Zhang, Tristan Naumann, Muhao Chen, Hoifung Poon |  |
| 1983 |  |  [KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment](https://doi.org/10.18653/v1/2023.acl-long.740) |  | 0 |  | Lingzhi Wang, Tong Chen, Wei Yuan, Xingshan Zeng, KamFai Wong, Hongzhi Yin |  |
| 1984 |  |  [UniCoRN: Unified Cognitive Signal ReconstructioN bridging cognitive signals and human language](https://doi.org/10.18653/v1/2023.acl-long.741) |  | 0 |  | Nuwa Xi, Sendong Zhao, Haochun Wang, Chi Liu, Bing Qin, Ting Liu |  |
| 1985 |  |  [Dense-ATOMIC: Towards Densely-connected ATOMIC with High Knowledge Coverage and Massive Multi-hop Paths](https://doi.org/10.18653/v1/2023.acl-long.742) |  | 0 |  | Xiangqing Shen, Siwei Wu, Rui Xia |  |
| 1986 |  |  [Shrinking Embeddings for Hyper-Relational Knowledge Graphs](https://doi.org/10.18653/v1/2023.acl-long.743) |  | 0 |  | Bo Xiong, Mojtaba Nayyeri, Shirui Pan, Steffen Staab |  |
| 1987 |  |  [CTC-based Non-autoregressive Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.744) |  | 0 |  | Chen Xu, Xiaoqian Liu, Xiaowen Liu, Qingxuan Sun, Yuhao Zhang, Murun Yang, Qianqian Dong, Tom Ko, Mingxuan Wang, Tong Xiao, Anxiang Ma, Jingbo Zhu |  |
| 1988 |  |  [Attention as a Guide for Simultaneous Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.745) |  | 0 |  | Sara Papi, Matteo Negri, Marco Turchi |  |
| 1989 |  |  [On Complementarity Objectives for Hybrid Retrieval](https://doi.org/10.18653/v1/2023.acl-long.746) |  | 0 |  | Dohyeon Lee, Seungwon Hwang, Kyungjae Lee, Seungtaek Choi, Sunghyun Park |  |
| 1990 |  |  [C-STANCE: A Large Dataset for Chinese Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2023.acl-long.747) |  | 0 |  | Chenye Zhao, Yingjie Li, Cornelia Caragea |  |
| 1991 |  |  [Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding](https://doi.org/10.18653/v1/2023.acl-long.748) |  | 0 |  | Haoli Bai, Zhiguang Liu, Xiaojun Meng, Wentao Li, Shuang Liu, Yifeng Luo, Nian Xie, Rongfu Zheng, Liangwei Wang, Lu Hou, Jiansheng Wei, Xin Jiang, Qun Liu |  |
| 1992 |  |  [PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts](https://doi.org/10.18653/v1/2023.acl-long.749) |  | 0 |  | Yunshui Li, Binyuan Hui, Zhichao Yin, Min Yang, Fei Huang, Yongbin Li |  |
| 1993 |  |  [MVP-Tuning: Multi-View Knowledge Retrieval with Prompt Tuning for Commonsense Reasoning](https://doi.org/10.18653/v1/2023.acl-long.750) |  | 0 |  | Yongfeng Huang, Yanyang Li, Yichong Xu, Lin Zhang, Ruyi Gan, Jiaxing Zhang, Liwei Wang |  |
| 1994 |  |  [PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation](https://doi.org/10.18653/v1/2023.acl-long.751) |  | 0 |  | Shaolin Zhu, Shangjie Li, Yikun Lei, Deyi Xiong |  |
| 1995 |  |  [Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection](https://doi.org/10.18653/v1/2023.acl-long.752) |  | 0 |  | Erik Arakelyan, Arnav Arora, Isabelle Augenstein |  |
| 1996 |  |  [DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles](https://doi.org/10.18653/v1/2023.acl-long.753) |  | 0 |  | Tanishq Gupta, Mohd Zaki, Devanshi Khatsuriya, Kausik Hira, N. M. Anoop Krishnan, Mausam |  |
| 1997 |  |  [Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://doi.org/10.18653/v1/2023.acl-long.754) |  | 0 |  | Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi |  |
| 1998 |  |  [Disentangled Phonetic Representation for Chinese Spelling Correction](https://doi.org/10.18653/v1/2023.acl-long.755) |  | 0 |  | Zihong Liang, Xiaojun Quan, Qifan Wang |  |
| 1999 |  |  [Dissecting Transformer Length Extrapolation via the Lens of Receptive Field Analysis](https://doi.org/10.18653/v1/2023.acl-long.756) |  | 0 |  | TaChung Chi, TingHan Fan, Alexander Rudnicky, Peter J. Ramadge |  |
| 2000 |  |  [CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models](https://doi.org/10.18653/v1/2023.acl-long.757) |  | 0 |  | Jiaxu Zhao, Meng Fang, Zijing Shi, Yitong Li, Ling Chen, Mykola Pechenizkiy |  |
| 2001 |  |  [Learning New Skills after Deployment: Improving open-domain internet-driven dialogue with human feedback](https://doi.org/10.18653/v1/2023.acl-long.758) |  | 0 |  | Jing Xu, Megan Ung, Mojtaba Komeili, Kushal Arora, YLan Boureau, Jason Weston |  |
| 2002 |  |  [Uncovering and Categorizing Social Biases in Text-to-SQL](https://doi.org/10.18653/v1/2023.acl-long.759) |  | 0 |  | Yan Liu, Yan Gao, Zhe Su, Xiaokang Chen, Elliott Ash, JianGuang Lou |  |
| 2003 |  |  [On the Compositional Generalization in Versatile Open-domain Dialogue](https://doi.org/10.18653/v1/2023.acl-long.760) |  | 0 |  | Tingchen Fu, Xueliang Zhao, Lemao Liu, Rui Yan |  |
| 2004 |  |  [What is the Real Intention behind this Question? Dataset Collection and Intention Classification](https://doi.org/10.18653/v1/2023.acl-long.761) |  | 0 |  | Maryam Sadat Mirzaei, Kourosh Meshgi, Satoshi Sekine |  |
| 2005 |  |  [Conjunct Resolution in the Face of Verbal Omissions](https://doi.org/10.18653/v1/2023.acl-long.762) |  | 0 |  | Royi Rassin, Yoav Goldberg, Reut Tsarfaty |  |
| 2006 |  |  [Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts](https://doi.org/10.18653/v1/2023.acl-long.763) |  | 0 |  | Mounica Maddela, Megan Ung, Jing Xu, Andrea Madotto, Heather Foran, YLan Boureau |  |
| 2007 |  |  [Learning In-context Learning for Named Entity Recognition](https://doi.org/10.18653/v1/2023.acl-long.764) |  | 0 |  | Jiawei Chen, Yaojie Lu, Hongyu Lin, Jie Lou, Wei Jia, Dai Dai, Hua Wu, Boxi Cao, Xianpei Han, Le Sun |  |
| 2008 |  |  [Holistic Prediction on a Time-Evolving Attributed Graph](https://doi.org/10.18653/v1/2023.acl-long.765) |  | 0 |  | Shohei Yamasaki, Yuya Sasaki, Panagiotis Karras, Makoto Onizuka |  |
| 2009 |  |  [Modeling Instance Interactions for Joint Information Extraction with Neural High-Order Conditional Random Field](https://doi.org/10.18653/v1/2023.acl-long.766) |  | 0 |  | Zixia Jia, Zhaohui Yan, Wenjuan Han, Zilong Zheng, Kewei Tu |  |
| 2010 |  |  [Training Trajectories of Language Models Across Scales](https://doi.org/10.18653/v1/2023.acl-long.767) |  | 0 |  | Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, Veselin Stoyanov |  |
| 2011 |  |  [A Diverse Set of Freely Available Linguistic Resources for Turkish](https://doi.org/10.18653/v1/2023.acl-long.768) |  | 0 |  | Duygu Altinok |  |
| 2012 |  |  [Measuring Consistency in Text-based Financial Forecasting Models](https://doi.org/10.18653/v1/2023.acl-long.769) |  | 0 |  | Linyi Yang, Yingpeng Ma, Yue Zhang |  |
| 2013 |  |  [Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.770) |  | 0 |  | Nuno Miguel Guerreiro, Pierre Colombo, Pablo Piantanida, André F. T. Martins |  |
| 2014 |  |  [RankCSE: Unsupervised Sentence Representations Learning via Learning to Rank](https://doi.org/10.18653/v1/2023.acl-long.771) |  | 0 |  | Jiduan Liu, Jiahao Liu, Qifan Wang, Jingang Wang, Wei Wu, Yunsen Xian, Dongyan Zhao, Kai Chen, Rui Yan |  |
| 2015 |  |  [Entailment as Robust Self-Learner](https://doi.org/10.18653/v1/2023.acl-long.772) |  | 0 |  | Jiaxin Ge, Hongyin Luo, Yoon Kim, James R. Glass |  |
| 2016 |  |  [ReCode: Robustness Evaluation of Code Generation Models](https://doi.org/10.18653/v1/2023.acl-long.773) |  | 0 |  | Shiqi Wang, Zheng Li, Haifeng Qian, Chenghao Yang, Zijian Wang, Mingyue Shang, Varun Kumar, Samson Tan, Baishakhi Ray, Parminder Bhatia, Ramesh Nallapati, Murali Krishna Ramanathan, Dan Roth, Bing Xiang |  |
| 2017 |  |  [EPIC: Multi-Perspective Annotation of a Corpus of Irony](https://doi.org/10.18653/v1/2023.acl-long.774) |  | 0 |  | Simona Frenda, Alessandro Pedrani, Valerio Basile, Soda Marem Lo, Alessandra Teresa Cignarella, Raffaella Panizzon, Cristina Marco, Bianca Scarlini, Viviana Patti, Cristina Bosco, Davide Bernardi |  |
| 2018 |  |  [Dialogue Summarization with Static-Dynamic Structure Fusion Graph](https://doi.org/10.18653/v1/2023.acl-long.775) |  | 0 |  | Shen Gao, Xin Cheng, Mingzhe Li, Xiuying Chen, Jinpeng Li, Dongyan Zhao, Rui Yan |  |
| 2019 |  |  [Large-Scale Correlation Analysis of Automated Metrics for Topic Models](https://doi.org/10.18653/v1/2023.acl-long.776) |  | 0 |  | Jia Peng Lim, Hady W. Lauw |  |
| 2020 |  |  [U-CREAT: Unsupervised Case Retrieval using Events extrAcTion](https://doi.org/10.18653/v1/2023.acl-long.777) |  | 0 |  | Abhinav Joshi, Akshat Sharma, Sai Kiran Tanikella, Ashutosh Modi |  |
| 2021 |  |  [ArgAnalysis35K : A large-scale dataset for Argument Quality Analysis](https://doi.org/10.18653/v1/2023.acl-long.778) |  | 0 |  | Omkar Joshi, Priya Pitre, Yashodhara Haribhakta |  |
| 2022 |  |  [Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework](https://doi.org/10.18653/v1/2023.acl-long.779) |  | 0 |  | Mingqi Gao, Xiaojun Wan, Jia Su, Zhefeng Wang, Baoxing Huai |  |
| 2023 |  |  [Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker](https://doi.org/10.18653/v1/2023.acl-long.780) |  | 0 |  | Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov |  |
| 2024 |  |  [Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text](https://doi.org/10.18653/v1/2023.acl-long.781) |  | 0 |  | Ashim Gupta, Carter Wood Blum, Temma Choji, Yingjie Fei, Shalin Shah, Alakananda Vempala, Vivek Srikumar |  |
| 2025 |  |  [Aggregating Multiple Heuristic Signals as Supervision for Unsupervised Automated Essay Scoring](https://doi.org/10.18653/v1/2023.acl-long.782) |  | 0 |  | Cong Wang, Zhiwei Jiang, Yafeng Yin, Zifeng Cheng, Shiping Ge, Qing Gu |  |
| 2026 |  |  [Mitigating Label Biases for In-context Learning](https://doi.org/10.18653/v1/2023.acl-long.783) |  | 0 |  | Yu Fei, Yifan Hou, Zeming Chen, Antoine Bosselut |  |
| 2027 |  |  [QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations](https://doi.org/10.18653/v1/2023.acl-long.784) |  | 0 |  | Chaitanya Malaviya, Peter Shaw, MingWei Chang, Kenton Lee, Kristina Toutanova |  |
| 2028 |  |  [Dynamic Heterogeneous-Graph Reasoning with Language Models and Knowledge Representation Learning for Commonsense Question Answering](https://doi.org/10.18653/v1/2023.acl-long.785) |  | 0 |  | Yujie Wang, Hu Zhang, Jiye Liang, Ru Li |  |
| 2029 |  |  [Do You Hear The People Sing? Key Point Analysis via Iterative Clustering and Abstractive Summarisation](https://doi.org/10.18653/v1/2023.acl-long.786) |  | 0 |  | Hao Li, Viktor Schlegel, Riza BatistaNavarro, Goran Nenadic |  |
| 2030 |  |  [Ambiguous Learning from Retrieval: Towards Zero-shot Semantic Parsing](https://doi.org/10.18653/v1/2023.acl-long.787) |  | 0 |  | Shan Wu, Chunlei Xin, Hongyu Lin, Xianpei Han, Cao Liu, Jiansong Chen, Fan Yang, Guanglu Wan, Le Sun |  |
| 2031 |  |  [Explicit Syntactic Guidance for Neural Text Generation](https://doi.org/10.18653/v1/2023.acl-long.788) |  | 0 |  | Yafu Li, Leyang Cui, Jianhao Yan, Yongjing Yin, Wei Bi, Shuming Shi, Yue Zhang |  |
| 2032 |  |  [What does a Text Classifier Learn about Morality? An Explainable Method for Cross-Domain Comparison of Moral Rhetoric](https://doi.org/10.18653/v1/2023.acl-long.789) |  | 0 |  | Enrico Liscio, Oscar Araque, Lorenzo Gatti, Ionut Constantinescu, Catholijn M. Jonker, Kyriaki Kalimeri, Pradeep Kumar Murukannaiah |  |
| 2033 |  |  [Graph-based Relation Mining for Context-free Out-of-vocabulary Word Embedding Learning](https://doi.org/10.18653/v1/2023.acl-long.790) |  | 0 |  | Ziran Liang, Yuyin Lu, Hegang Chen, Yanghui Rao |  |
| 2034 |  |  [Multimodal Persona Based Generation of Comic Dialogs](https://doi.org/10.18653/v1/2023.acl-long.791) |  | 0 |  | Harsh Agrawal, Aditya Mishra, Manish Gupta, Mausam |  |
| 2035 |  |  [LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion](https://doi.org/10.18653/v1/2023.acl-long.792) |  | 0 |  | Dongfu Jiang, Xiang Ren, Bill Yuchen Lin |  |
| 2036 |  |  [Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation](https://doi.org/10.18653/v1/2023.acl-long.793) |  | 0 |  | Weihao Zeng, Lulu Zhao, Keqing He, Ruotong Geng, Jingang Wang, Wei Wu, Weiran Xu |  |
| 2037 |  |  [Generating Structured Pseudo Labels for Noise-resistant Zero-shot Video Sentence Localization](https://doi.org/10.18653/v1/2023.acl-long.794) |  | 0 |  | Minghang Zheng, Shaogang Gong, Hailin Jin, Yuxin Peng, Yang Liu |  |
| 2038 |  |  [IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for Indian Languages](https://doi.org/10.18653/v1/2023.acl-long.795) |  | 0 |  | Ananya B. Sai, Tanay Dixit, Vignesh Nagarajan, Anoop Kunchukuttan, Pratyush Kumar, Mitesh M. Khapra, Raj Dabre |  |
| 2039 |  |  [Weaker Than You Think: A Critical Look at Weakly Supervised Learning](https://doi.org/10.18653/v1/2023.acl-long.796) |  | 0 |  | Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, Dietrich Klakow |  |
| 2040 |  |  [Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases](https://doi.org/10.18653/v1/2023.acl-long.797) |  | 0 |  | Yingji Li, Mengnan Du, Xin Wang, Ying Wang |  |
| 2041 |  |  [Towards Understanding Omission in Dialogue Summarization](https://doi.org/10.18653/v1/2023.acl-long.798) |  | 0 |  | Yicheng Zou, Kaitao Song, Xu Tan, Zhongkai Fu, Qi Zhang, Dongsheng Li, Tao Gui |  |
| 2042 |  |  [Python Code Generation by Asking Clarification Questions](https://doi.org/10.18653/v1/2023.acl-long.799) |  | 0 |  | HaauSing Li, Mohsen Mesgar, André F. T. Martins, Iryna Gurevych |  |
| 2043 |  |  [A Compare-and-contrast Multistage Pipeline for Uncovering Financial Signals in Financial Reports](https://doi.org/10.18653/v1/2023.acl-long.800) |  | 0 |  | JiaHuei Ju, YuShiang Huang, ChengWei Lin, Che Lin, ChuanJu Wang |  |
| 2044 |  |  [Improving the robustness of NLI models with minimax training](https://doi.org/10.18653/v1/2023.acl-long.801) |  | 0 |  | Michalis Korakakis, Andreas Vlachos |  |
| 2045 |  |  [USSA: A Unified Table Filling Scheme for Structured Sentiment Analysis](https://doi.org/10.18653/v1/2023.acl-long.802) |  | 0 |  | Zepeng Zhai, Hao Chen, Ruifan Li, Xiaojie Wang |  |
| 2046 |  |  [PAD-Net: An Efficient Framework for Dynamic Networks](https://doi.org/10.18653/v1/2023.acl-long.803) |  | 0 |  | Shwai He, Liang Ding, Daize Dong, Boan Liu, Fuqiang Yu, Dacheng Tao |  |
| 2047 |  |  [Resolving Ambiguities in Text-to-Image Generative Models](https://doi.org/10.18653/v1/2023.acl-long.804) |  | 0 |  | Ninareh Mehrabi, Palash Goyal, Apurv Verma, Jwala Dhamala, Varun Kumar, Qian Hu, KaiWei Chang, Richard S. Zemel, Aram Galstyan, Rahul Gupta |  |
| 2048 |  |  [Knowledge Unlearning for Mitigating Privacy Risks in Language Models](https://doi.org/10.18653/v1/2023.acl-long.805) |  | 0 |  | Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo |  |
| 2049 |  |  [Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor](https://doi.org/10.18653/v1/2023.acl-long.806) |  | 0 |  | Or Honovich, Thomas Scialom, Omer Levy, Timo Schick |  |
| 2050 |  |  [To Adapt or to Annotate: Challenges and Interventions for Domain Adaptation in Open-Domain Question Answering](https://doi.org/10.18653/v1/2023.acl-long.807) |  | 0 |  | Dheeru Dua, Emma Strubell, Sameer Singh, Pat Verga |  |
| 2051 |  |  [A Survey for Efficient Open Domain Question Answering](https://doi.org/10.18653/v1/2023.acl-long.808) |  | 0 |  | Qin Zhang, Shangsi Chen, Dongkuan Xu, Qingqing Cao, Xiaojun Chen, Trevor Cohn, Meng Fang |  |
| 2052 |  |  [Script Normalization for Unconventional Writing of Under-Resourced Languages in Bilingual Communities](https://doi.org/10.18653/v1/2023.acl-long.809) |  | 0 |  | Sina Ahmadi, Antonios Anastasopoulos |  |
| 2053 |  |  [Compositional Generalization without Trees using Multiset Tagging and Latent Permutations](https://doi.org/10.18653/v1/2023.acl-long.810) |  | 0 |  | Matthias Lindemann, Alexander Koller, Ivan Titov |  |
| 2054 |  |  [ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.811) |  | 0 |  | Xiao Xu, Bei Li, Chenfei Wu, ShaoYen Tseng, Anahita Bhiwandiwalla, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan |  |
| 2055 |  |  [Finding the Pillars of Strength for Multi-Head Attention](https://doi.org/10.18653/v1/2023.acl-long.812) |  | 0 |  | Jinjie Ni, Rui Mao, Zonglin Yang, Han Lei, Erik Cambria |  |
| 2056 |  |  [Jointprop: Joint Semi-supervised Learning for Entity and Relation Extraction with Heterogeneous Graph-based Propagation](https://doi.org/10.18653/v1/2023.acl-long.813) |  | 0 |  | Yandan Zheng, Anran Hao, Anh Tuan Luu |  |
| 2057 |  |  [Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering](https://doi.org/10.18653/v1/2023.acl-long.814) |  | 0 |  | Jiajie Zhang, Shulin Cao, Tingjian Zhang, Xin Lv, Juanzi Li, Lei Hou, Jiaxin Shi, Qi Tian |  |
| 2058 |  |  [Faking Fake News for Real Fake News Detection: Propaganda-Loaded Training Data Generation](https://doi.org/10.18653/v1/2023.acl-long.815) |  | 0 |  | KungHsiang Huang, Kathleen R. McKeown, Preslav Nakov, Yejin Choi, Heng Ji |  |
| 2059 |  |  [A Length-Extrapolatable Transformer](https://doi.org/10.18653/v1/2023.acl-long.816) |  | 0 |  | Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, Furu Wei |  |
| 2060 |  |  [A Survey of Deep Learning for Mathematical Reasoning](https://doi.org/10.18653/v1/2023.acl-long.817) |  | 0 |  | Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, KaiWei Chang |  |
| 2061 |  |  [A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training](https://doi.org/10.18653/v1/2023.acl-long.818) |  | 0 |  | Nitay Calderon, Subhabrata Mukherjee, Roi Reichart, Amir Kantor |  |
| 2062 |  |  [Vision Language Pre-training by Contrastive Learning with Cross-Modal Similarity Regulation](https://doi.org/10.18653/v1/2023.acl-long.819) |  | 0 |  | Chaoya Jiang, Wei Ye, Haiyang Xu, Songfang Huang, Fei Huang, Shikun Zhang |  |
| 2063 |  |  [Tell2Design: A Dataset for Language-Guided Floor Plan Generation](https://doi.org/10.18653/v1/2023.acl-long.820) |  | 0 |  | Sicong Leng, Yang Zhou, Mohammed Haroon Dupty, Wee Sun Lee, Sam Joyce, Wei Lu |  |
| 2064 |  |  [Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations](https://doi.org/10.18653/v1/2023.acl-long.821) |  | 0 |  | Bingsheng Yao, Prithviraj Sen, Lucian Popa, James A. Hendler, Dakuo Wang |  |
| 2065 |  |  [Rethinking Annotation: Can Language Learners Contribute?](https://doi.org/10.18653/v1/2023.acl-long.822) |  | 0 |  | Haneul Yoo, Rifki Afina Putri, Changyoon Lee, Youngin Lee, SoYeon Ahn, Dongyeop Kang, Alice Oh |  |
| 2066 |  |  [Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling](https://doi.org/10.18653/v1/2023.acl-long.823) |  | 0 |  | Shengqiong Wu, Hao Fei, Yixin Cao, Lidong Bing, TatSeng Chua |  |
| 2067 |  |  [MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations](https://doi.org/10.18653/v1/2023.acl-long.824) |  | 0 |  | Tao Shi, ShaoLun Huang |  |
| 2068 |  |  [Learning Language-Specific Layers for Multilingual Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.825) |  | 0 |  | Telmo Pires, Robin M. Schmidt, YiHsiu Liao, Stephan Peitz |  |
| 2069 |  |  [Personality Understanding of Fictional Characters during Book Reading](https://doi.org/10.18653/v1/2023.acl-long.826) |  | 0 |  | Mo Yu, Jiangnan Li, Shunyu Yao, Wenjie Pang, Xiaochen Zhou, Xiao Zhou, Fandong Meng, Jie Zhou |  |
| 2070 |  |  [StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing](https://doi.org/10.18653/v1/2023.acl-long.827) |  | 0 |  | Xuekai Zhu, Jian Guan, Minlie Huang, Juan Liu |  |
| 2071 |  |  [Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.828) |  | 0 |  | Qingyu Tan, Hwee Tou Ng, Lidong Bing |  |
| 2072 |  |  [Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference in Low Resource Settings](https://doi.org/10.18653/v1/2023.acl-long.829) |  | 0 |  | Daniel Rotem, Michael Hassid, Jonathan Mamou, Roy Schwartz |  |
| 2073 |  |  [Large Language Models Are Reasoning Teachers](https://doi.org/10.18653/v1/2023.acl-long.830) |  | 0 |  | Namgyu Ho, Laura Schmid, SeYoung Yun |  |
| 2074 |  |  [Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations](https://doi.org/10.18653/v1/2023.acl-long.831) |  | 0 |  | Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush |  |
| 2075 |  |  [PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification](https://doi.org/10.18653/v1/2023.acl-long.832) |  | 0 |  | YauShian Wang, TaChung Chi, Ruohong Zhang, Yiming Yang |  |
| 2076 |  |  [Visually-augmented pretrained language models for NLP tasks without images](https://doi.org/10.18653/v1/2023.acl-long.833) |  | 0 |  | Hangyu Guo, Kun Zhou, Wayne Xin Zhao, Qinyu Zhang, JiRong Wen |  |
| 2077 |  |  [Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning](https://doi.org/10.18653/v1/2023.acl-long.834) |  | 0 |  | Armineh Nourbakhsh, Sameena Shah, Carolyn P. Rosé |  |
| 2078 |  |  [A Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization](https://doi.org/10.18653/v1/2023.acl-long.835) |  | 0 |  | Lining Zhang, Simon Mille, Yufang Hou, Daniel Deutsch, Elizabeth Clark, Yixin Liu, Saad Mahamood, Sebastian Gehrmann, Miruna Clinciu, Khyathi Raghavi Chandu, João Sedoc |  |
| 2079 |  |  [TAVT: Towards Transferable Audio-Visual Text Generation](https://doi.org/10.18653/v1/2023.acl-long.836) |  | 0 |  | Wang Lin, Tao Jin, Wenwen Pan, Linjun Li, Xize Cheng, Ye Wang, Zhou Zhao |  |
| 2080 |  |  [MeetingQA: Extractive Question-Answering on Meeting Transcripts](https://doi.org/10.18653/v1/2023.acl-long.837) |  | 0 |  | Archiki Prasad, Trung Bui, Seunghyun Yoon, Hanieh Deilamsalehy, Franck Dernoncourt, Mohit Bansal |  |
| 2081 |  |  [FERMAT: An Alternative to Accuracy for Numerical Reasoning](https://doi.org/10.18653/v1/2023.acl-long.838) |  | 0 |  | Jasivan Alex Sivakumar, Nafise Sadat Moosavi |  |
| 2082 |  |  [Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2023.acl-long.839) |  | 0 |  | Sarah E. Finch, James D. Finch, Jinho D. Choi |  |
| 2083 |  |  [Decoder Tuning: Efficient Language Understanding as Decoding](https://doi.org/10.18653/v1/2023.acl-long.840) |  | 0 |  | Ganqu Cui, Wentao Li, Ning Ding, Longtao Huang, Zhiyuan Liu, Maosong Sun |  |
| 2084 |  |  [The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources](https://doi.org/10.18653/v1/2023.acl-long.841) |  | 0 |  | Akshatha Arodi, Martin Pömsl, Kaheer Suleman, Adam Trischler, Alexandra Olteanu, Jackie Chi Kit Cheung |  |
| 2085 |  |  [CREST: A Joint Framework for Rationalization and Counterfactual Text Generation](https://doi.org/10.18653/v1/2023.acl-long.842) |  | 0 |  | Marcos V. Treviso, Alexis Ross, Nuno Miguel Guerreiro, André F. T. Martins |  |
| 2086 |  |  [Towards Unifying Multi-Lingual and Cross-Lingual Summarization](https://doi.org/10.18653/v1/2023.acl-long.843) |  | 0 |  | Jiaan Wang, Fandong Meng, Duo Zheng, Yunlong Liang, Zhixu Li, Jianfeng Qu, Jie Zhou |  |
| 2087 |  |  [On Improving Summarization Factual Consistency from Natural Language Feedback](https://doi.org/10.18653/v1/2023.acl-long.844) |  | 0 |  | Yixin Liu, Budhaditya Deb, Milagro Teruel, Aaron Halfaker, Dragomir Radev, Ahmed Hassan Awadallah |  |
| 2088 |  |  [From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models](https://doi.org/10.18653/v1/2023.acl-long.845) |  | 0 |  | Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap |  |
| 2089 |  |  [Exploring Large Language Models for Classical Philology](https://doi.org/10.18653/v1/2023.acl-long.846) |  | 0 |  | Frederick Riemenschneider, Anette Frank |  |
| 2090 |  |  [LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding](https://doi.org/10.18653/v1/2023.acl-long.847) |  | 0 |  | Yi Tu, Ya Guo, Huan Chen, Jinyang Tang |  |
| 2091 |  |  [Hearing Lips in Noise: Universal Viseme-Phoneme Mapping and Transfer for Robust Audio-Visual Speech Recognition](https://doi.org/10.18653/v1/2023.acl-long.848) |  | 0 |  | Yuchen Hu, Ruizhe Li, Chen Chen, Chengwei Qin, QiuShi Zhu, Eng Siong Chng |  |
| 2092 |  |  [An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation](https://doi.org/10.18653/v1/2023.acl-long.849) |  | 0 |  | Xuancheng Huang, Zijun Liu, Peng Li, Tao Li, Maosong Sun, Yang Liu |  |
| 2093 |  |  [Double-Branch Multi-Attention based Graph Neural Network for Knowledge Graph Completion](https://doi.org/10.18653/v1/2023.acl-long.850) |  | 0 |  | Hongcai Xu, Junpeng Bao, Wenbo Liu |  |
| 2094 |  |  [Dual Cache for Long Document Neural Coreference Resolution](https://doi.org/10.18653/v1/2023.acl-long.851) |  | 0 |  | Qipeng Guo, Xiangkun Hu, Yue Zhang, Xipeng Qiu, Zheng Zhang |  |
| 2095 |  |  [Knowledge Transfer in Incremental Learning for Multilingual Neural Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.852) |  | 0 |  | Kaiyu Huang, Peng Li, Jin Ma, Ting Yao, Yang Liu |  |
| 2096 |  |  [DisorBERT: A Double Domain Adaptation Model for Detecting Signs of Mental Disorders in Social Media](https://doi.org/10.18653/v1/2023.acl-long.853) |  | 0 |  | Mario Ezra Aragón, Adrián Pastor LópezMonroy, Luis Gonzalez, David E. Losada, Manuel Montes |  |
| 2097 |  |  [Toward Interactive Dictation](https://doi.org/10.18653/v1/2023.acl-long.854) |  | 0 |  | Belinda Z. Li, Jason Eisner, Adam Pauls, Sam Thomson |  |
| 2098 |  |  [CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors](https://doi.org/10.18653/v1/2023.acl-long.855) |  | 0 |  | Peng Li, Tianxiang Sun, Qiong Tang, Hang Yan, Yuanbin Wu, Xuanjing Huang, Xipeng Qiu |  |
| 2099 |  |  [Beyond English-Centric Bitexts for Better Multilingual Language Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.856) |  | 0 |  | Barun Patra, Saksham Singhal, Shaohan Huang, Zewen Chi, Li Dong, Furu Wei, Vishrav Chaudhary, Xia Song |  |
| 2100 |  |  [Bridging The Gap: Entailment Fused-T5 for Open-retrieval Conversational Machine Reading Comprehension](https://doi.org/10.18653/v1/2023.acl-long.857) |  | 0 |  | Xiao Zhang, Heyan Huang, Zewen Chi, XianLing Mao |  |
| 2101 |  |  [LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming](https://doi.org/10.18653/v1/2023.acl-long.858) |  | 0 |  | Jingsheng Gao, Yixin Lian, Ziyi Zhou, Yuzhuo Fu, Baoyuan Wang |  |
| 2102 |  |  [Prompting PaLM for Translation: Assessing Strategies and Performance](https://doi.org/10.18653/v1/2023.acl-long.859) |  | 0 |  | David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, George F. Foster |  |
| 2103 |  |  [Exploring Lottery Prompts for Pre-trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.860) |  | 0 |  | Yulin Chen, Ning Ding, Xiaobin Wang, Shengding Hu, Haitao Zheng, Zhiyuan Liu, Pengjun Xie |  |
| 2104 |  |  [A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations](https://doi.org/10.18653/v1/2023.acl-long.861) |  | 0 |  | Wenjie Zheng, Jianfei Yu, Rui Xia, Shijin Wang |  |
| 2105 |  |  [TeAST: Temporal Knowledge Graph Embedding via Archimedean Spiral Timeline](https://doi.org/10.18653/v1/2023.acl-long.862) |  | 0 |  | Jiang Li, Xiangdong Su, Guanglai Gao |  |
| 2106 |  |  [Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition](https://doi.org/10.18653/v1/2023.acl-long.863) |  | 0 |  | Yuwei Bao, Barrett Martin Lattimer, Joyce Chai |  |
| 2107 |  |  [Conjunct Lengths in English, Dependency Length Minimization, and Dependency Structure of Coordination](https://doi.org/10.18653/v1/2023.acl-long.864) |  | 0 |  | Adam Przepiórkowski, Michal Wozniak |  |
| 2108 |  |  [LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development](https://doi.org/10.18653/v1/2023.acl-long.865) |  | 0 |  | Ilias Chalkidis, Nicolas Garneau, Catalina Goanta, Daniel Martin Katz, Anders Søgaard |  |
| 2109 |  |  [Revisiting Commonsense Reasoning in Machine Translation: Training, Evaluation and Challenge](https://doi.org/10.18653/v1/2023.acl-long.866) |  | 0 |  | Xuebo Liu, Yutong Wang, Derek F. Wong, Runzhe Zhan, Liangxuan Yu, Min Zhang |  |
| 2110 |  |  [NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models](https://doi.org/10.18653/v1/2023.acl-long.867) |  | 0 |  | Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma |  |
| 2111 |  |  [Revisiting Relation Extraction in the era of Large Language Models](https://doi.org/10.18653/v1/2023.acl-long.868) |  | 0 |  | Somin Wadhwa, Silvio Amir, Byron C. Wallace |  |
| 2112 |  |  [Pre-trained Language Models Can be Fully Zero-Shot Learners](https://doi.org/10.18653/v1/2023.acl-long.869) |  | 0 |  | Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu, Lei Li |  |
| 2113 |  |  [Can Large Language Models Be an Alternative to Human Evaluations?](https://doi.org/10.18653/v1/2023.acl-long.870) |  | 0 |  | David ChengHan Chiang, Hungyi Lee |  |
| 2114 |  |  [HyperMixer: An MLP-based Low Cost Alternative to Transformers](https://doi.org/10.18653/v1/2023.acl-long.871) |  | 0 |  | Florian Mai, Arnaud Pannatier, Fabio Fehr, Haolin Chen, François Marelli, François Fleuret, James Henderson |  |
| 2115 |  |  [UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units](https://doi.org/10.18653/v1/2023.acl-long.872) |  | 0 |  | Hirofumi Inaguma, Sravya Popuri, Ilia Kulikov, PengJen Chen, Changhan Wang, YuAn Chung, Yun Tang, Ann Lee, Shinji Watanabe, Juan Pino |  |
| 2116 |  |  [Estimating the Uncertainty in Emotion Attributes using Deep Evidential Regression](https://doi.org/10.18653/v1/2023.acl-long.873) |  | 0 |  | Wen Wu, Chao Zhang, Philip C. Woodland |  |
| 2117 |  |  [Annotation-Inspired Implicit Discourse Relation Classification with Auxiliary Discourse Connective Generation](https://doi.org/10.18653/v1/2023.acl-long.874) |  | 0 |  | Wei Liu, Michael Strube |  |
| 2118 |  |  [Plug-and-Play Document Modules for Pre-trained Models](https://doi.org/10.18653/v1/2023.acl-long.875) |  | 0 |  | Chaojun Xiao, Zhengyan Zhang, Xu Han, ChiMin Chan, Yankai Lin, Zhiyuan Liu, Xiangyang Li, Zhonghua Li, Zhao Cao, Maosong Sun |  |
| 2119 |  |  [An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models](https://doi.org/10.18653/v1/2023.acl-long.876) |  | 0 |  | Zhongbin Xie, Thomas Lukasiewicz |  |
| 2120 |  |  [Two-Stage Fine-Tuning for Improved Bias and Variance for Large Pretrained Language Models](https://doi.org/10.18653/v1/2023.acl-long.877) |  | 0 |  | Lijing Wang, Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova |  |
| 2121 |  |  [A Comparative Study on the Impact of Model Compression Techniques on Fairness in Language Models](https://doi.org/10.18653/v1/2023.acl-long.878) |  | 0 |  | Krithika Ramesh, Arnav Chavan, Shrey Pandit, Sunayana Sitaram |  |
| 2122 |  |  [Ranking-Enhanced Unsupervised Sentence Representation Learning](https://doi.org/10.18653/v1/2023.acl-long.879) |  | 0 |  | Yeon Seonwoo, Guoyin Wang, Changmin Seo, Sajal Choudhary, Jiwei Li, Xiang Li, Puyang Xu, Sunghyun Park, Alice Oh |  |
| 2123 |  |  [To Revise or Not to Revise: Learning to Detect Improvable Claims for Argumentative Writing Support](https://doi.org/10.18653/v1/2023.acl-long.880) |  | 0 |  | Gabriella Skitalinskaya, Henning Wachsmuth |  |
| 2124 |  |  [Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments](https://doi.org/10.18653/v1/2023.acl-long.881) |  | 0 |  | Ethan Mendes, Yang Chen, Wei Xu, Alan Ritter |  |
| 2125 |  |  [Composition-contrastive Learning for Sentence Embeddings](https://doi.org/10.18653/v1/2023.acl-long.882) |  | 0 |  | Sachin Chanchani, Ruihong Huang |  |
| 2126 |  |  [Causes and Cures for Interference in Multilingual Translation](https://doi.org/10.18653/v1/2023.acl-long.883) |  | 0 |  | Uri Shaham, Maha Elbayad, Vedanuj Goswami, Omer Levy, Shruti Bhosale |  |
| 2127 |  |  [Understanding and Bridging the Modality Gap for Speech Translation](https://doi.org/10.18653/v1/2023.acl-long.884) |  | 0 |  | Qingkai Fang, Yang Feng |  |
| 2128 |  |  [Few-shot Reranking for Multi-hop QA via Language Model Prompting](https://doi.org/10.18653/v1/2023.acl-long.885) |  | 0 |  | Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang |  |
| 2129 |  |  [DICE: Data-Efficient Clinical Event Extraction with Generative Models](https://doi.org/10.18653/v1/2023.acl-long.886) |  | 0 |  | Mingyu Derek Ma, Alexander Taylor, Wei Wang, Nanyun Peng |  |
| 2130 |  |  [XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations](https://doi.org/10.18653/v1/2023.acl-long.887) |  | 0 |  | Yusen Zhang, Jun Wang, Zhiguo Wang, Rui Zhang |  |
| 2131 |  |  [INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation](https://doi.org/10.18653/v1/2023.acl-long.888) |  | 0 |  | Wenhao Zhu, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen |  |
| 2132 |  |  [Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.889) |  | 0 |  | Qi Sun, Kun Huang, Xiaocui Yang, Pengfei Hong, Kun Zhang, Soujanya Poria |  |
| 2133 |  |  [Cross-Modal Attribute Insertions for Assessing the Robustness of Vision-and-Language Learning](https://doi.org/10.18653/v1/2023.acl-long.890) |  | 0 |  | Shivaen Ramshetty, Gaurav Verma, Srijan Kumar |  |
| 2134 |  |  [Crosslingual Generalization through Multitask Finetuning](https://doi.org/10.18653/v1/2023.acl-long.891) |  | 0 |  | Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M. Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, Colin Raffel |  |
| 2135 |  |  [Evaluate AMR Graph Similarity via Self-supervised Learning](https://doi.org/10.18653/v1/2023.acl-long.892) |  | 0 |  | Ziyi Shou, Fangzhen Lin |  |
| 2136 |  |  [Analyzing Transformers in Embedding Space](https://doi.org/10.18653/v1/2023.acl-long.893) |  | 0 |  | Guy Dar, Mor Geva, Ankit Gupta, Jonathan Berant |  |
| 2137 |  |  [Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning](https://doi.org/10.18653/v1/2023.acl-long.894) |  | 0 |  | Alexander Hanbo Li, Mingyue Shang, Evangelia Spiliopoulou, Jie Ma, Patrick Ng, Zhiguo Wang, Bonan Min, William Yang Wang, Kathleen R. McKeown, Vittorio Castelli, Dan Roth, Bing Xiang |  |
| 2138 |  |  [FactKG: Fact Verification via Reasoning on Knowledge Graphs](https://doi.org/10.18653/v1/2023.acl-long.895) |  | 0 |  | Jiho Kim, Sungjin Park, Yeonsu Kwon, Yohan Jo, James Thorne, Edward Choi |  |
| 2139 |  |  [DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains](https://doi.org/10.18653/v1/2023.acl-long.896) |  | 0 |  | Yanis Labrak, Adrien Bazoge, Richard Dufour, Mickael Rouvier, Emmanuel Morin, Béatrice Daille, PierreAntoine Gourraud |  |
| 2140 |  |  [Discriminative Reasoning with Sparse Event Representation for Document-level Event-Event Relation Extraction](https://doi.org/10.18653/v1/2023.acl-long.897) |  | 0 |  | Changsen Yuan, Heyan Huang, Yixin Cao, Yonggang Wen |  |
| 2141 |  |  [Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks](https://doi.org/10.18653/v1/2023.acl-long.898) |  | 0 |  | Junyu Lu, Bo Xu, Xiaokun Zhang, Changrong Min, Liang Yang, Hongfei Lin |  |
| 2142 |  |  [SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations](https://doi.org/10.18653/v1/2023.acl-long.899) |  | 0 |  | PaulAmbroise Duquenne, Hongyu Gong, Ning Dong, Jingfei Du, Ann Lee, Vedanuj Goswami, Changhan Wang, Juan Pino, Benoît Sagot, Holger Schwenk |  |
| 2143 |  |  [Character-Aware Models Improve Visual Text Rendering](https://doi.org/10.18653/v1/2023.acl-long.900) |  | 0 |  | Rosanne Liu, Dan Garrette, Chitwan Saharia, William Chan, Adam Roberts, Sharan Narang, Irina Blok, RJ Mical, Mohammad Norouzi, Noah Constant |  |
| 2144 |  |  [IDRISI-RA: The First Arabic Location Mention Recognition Dataset of Disaster Tweets](https://doi.org/10.18653/v1/2023.acl-long.901) |  | 0 |  | Reem Suwaileh, Muhammad Imran, Tamer Elsayed |  |
| 2145 |  |  [FSUIE: A Novel Fuzzy Span Mechanism for Universal Information Extraction](https://doi.org/10.18653/v1/2023.acl-long.902) |  | 0 |  | Tianshuo Peng, Zuchao Li, Lefei Zhang, Bo Du, Hai Zhao |  |
| 2146 |  |  [What Do NLP Researchers Believe? Results of the NLP Community Metasurvey](https://doi.org/10.18653/v1/2023.acl-long.903) |  | 0 |  | Julian Michael, Ari Holtzman, Alicia Parrish, Aaron Mueller, Alex Wang, Angelica Chen, Divyam Madaan, Nikita Nangia, Richard Yuanzhe Pang, Jason Phang, Samuel R. Bowman |  |
| 2147 |  |  [Prototype-Guided Pseudo Labeling for Semi-Supervised Text Classification](https://doi.org/10.18653/v1/2023.acl-long.904) |  | 0 |  | Weiyi Yang, Richong Zhang, Junfan Chen, Lihong Wang, Jaein Kim |  |
| 2148 |  |  [LENS: A Learnable Evaluation Metric for Text Simplification](https://doi.org/10.18653/v1/2023.acl-long.905) |  | 0 |  | Mounica Maddela, Yao Dou, David Heineman, Wei Xu |  |
| 2149 |  |  [MeetingBank: A Benchmark Dataset for Meeting Summarization](https://doi.org/10.18653/v1/2023.acl-long.906) |  | 0 |  | Yebowen Hu, Timothy Ganter, Hanieh Deilamsalehy, Franck Dernoncourt, Hassan Foroosh, Fei Liu |  |
| 2150 |  |  [UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective](https://doi.org/10.18653/v1/2023.acl-long.907) |  | 0 |  | Yang Ping, Junyu Lu, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Pingjian Zhang, Jiaxing Zhang |  |
| 2151 |  |  [DEplain: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification](https://doi.org/10.18653/v1/2023.acl-long.908) |  | 0 |  | Regina Stodden, Omar Momen, Laura Kallmeyer |  |
| 2152 |  |  [A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from Linguistically Complex Text](https://doi.org/10.18653/v1/2023.acl-long.909) |  | 0 |  | Yunxin Li, Baotian Hu, Yuxin Ding, Lin Ma, Min Zhang |  |
| 2153 |  |  [RARR: Researching and Revising What Language Models Say, Using Language Models](https://doi.org/10.18653/v1/2023.acl-long.910) |  | 0 |  | Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Y. Zhao, Ni Lao, Hongrae Lee, DaCheng Juan, Kelvin Guu |  |

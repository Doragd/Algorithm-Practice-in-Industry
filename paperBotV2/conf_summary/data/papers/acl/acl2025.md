# ACL2025

## 会议论文列表

本会议共有 3090 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Frontmatter](https://doi.org/10.18653/v1/2025.acl-short.0) |  | 0 |  |  |  |
| 2 |  |  [Towards LLM-powered Attentive Listener: A Pragmatic Approach through Quantity Self-Repair](https://doi.org/10.18653/v1/2025.acl-short.1) |  | 0 | Grice’s Quantity Maxims dictate that human speakers aim for the optimal quantity of information during conversation. To empower LLMs to self-repair their responses toward optimal quantity and improve their attentive listening skills, we propose Q-Tuning and Q-Traveling, which draw on heuristic... | Junlin Li, Bo Peng, YuYin Hsu |  |
| 3 |  |  [MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments](https://doi.org/10.18653/v1/2025.acl-short.2) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in environmental perception, reasoning-based decision-making, and simulating complex human behaviors, particularly in interactive role-playing contexts. This paper introduces the Multiverse Interactive Role-play Ability General... | Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen |  |
| 4 |  |  [Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification](https://doi.org/10.18653/v1/2025.acl-short.3) |  | 0 | Dialogue intent classification aims to identify the underlying purpose or intent of a user’s input in a conversation. Current intent classification systems encounter considerable challenges, primarily due to the vast number of possible intents and the significant semantic overlap among similar... | Gyutae Park, Ingeol Baek, Byeongjeong Kim, Joongbo Shin, Hwanhee Lee |  |
| 5 |  |  [Rethinking KenLM: Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora](https://doi.org/10.18653/v1/2025.acl-short.4) |  | 0 | With the increasing demand for substantial amounts of high-quality data to train large language models (LLMs), efficiently filtering large web corpora has become a critical challenge. For this purpose, KenLM, a lightweight n-gram-based language model that operates on CPUs, is widely used. However,... | Yungi Kim, Hyunsoo Ha, Sukyung Lee, Jihoo Kim, Seonghoon Yang, Chanjun Park |  |
| 6 |  |  [Automatic detection of dyslexia based on eye movements during reading in Russian](https://doi.org/10.18653/v1/2025.acl-short.5) |  | 0 | Dyslexia, a common learning disability, requires an early diagnosis. However, current screening tests are very time- and resource-consuming. We present an LSTM that aims to automatically classify dyslexia based on eye movements recorded during natural readingcombined with basic demographic... | Anna Laurinavichyute, Anastasiya Lopukhina, David Robert Reich |  |
| 7 |  |  [Doc-React: Multi-page Heterogeneous Document Question-answering](https://doi.org/10.18653/v1/2025.acl-short.6) |  | 0 | Answering questions over multi-page, multimodal documents, including text and figures, is a critical challenge for applications that require answers to integrate information across multiple modalities and contextual dependencies. Existing methods, such as single-turn retrieval-augmented generation... | Junda Wu, Yu Xia, Tong Yu, Xiang Chen, Sai Sree Harsha, Akash V. Maharaj, Ruiyi Zhang, Victor S. Bursztyn, Sungchul Kim, Ryan A. Rossi, Julian J. McAuley, Yunyao Li, Ritwik Sinha |  |
| 8 |  |  [ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT](https://doi.org/10.18653/v1/2025.acl-short.7) |  | 0 | Neural Machine Translation (NMT) has improved translation by using Transformer-based models, but it still struggles with word ambiguity and context. This problem is especially important in domain-specific applications, which often have problems with unclear sentences or poor data quality. Our... | Mikolaj Pokrywka, Wojciech Kusa, Mieszko Rutkowski, Mikolaj Koszowski |  |
| 9 |  |  [A Measure of the System Dependence of Automated Metrics](https://doi.org/10.18653/v1/2025.acl-short.8) |  | 0 | Automated metrics for Machine Translation have made significant progress, with the goal of replacing expensive and time-consuming human evaluations. These metrics are typically assessed by their correlation with human judgments, which captures the monotonic relationship between human and metric... | Pius von Däniken, Jan Milan Deriu, Mark Cieliebak |  |
| 10 |  |  [Call for Rigor in Reporting Quality of Instruction Tuning Data](https://doi.org/10.18653/v1/2025.acl-short.9) |  | 0 | Instruction tuning is crucial for adapting large language models (LLMs) to align with user intentions. Numerous studies emphasize the significance of the quality of instruction tuning (IT) data, revealing a strong correlation between IT data quality and the alignment performance of LLMs. In these... | Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim |  |
| 11 |  |  [BQA: Body Language Question Answering Dataset for Video Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.10) |  | 0 | A large part of human communication relies on nonverbal cues such as facial expressions, eye contact, and body language. Unlike language or sign language, such nonverbal communication lacks formal rules, requiring complex reasoning based on commonsense understanding.Enabling current Video Large... | Shintaro Ozaki, Kazuki Hayashi, Miyu Oba, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |  |
| 12 |  |  [Grounded, or a Good Guesser? A Per-Question Balanced Dataset to Separate Blind from Grounded Models for Embodied Question Answering](https://doi.org/10.18653/v1/2025.acl-short.11) |  | 0 | Embodied question answering (EQA) means using \*perception of\* and \*action in\* an environment to answer natural language questions about that environment. However, previous work has demonstrated that blind language models (which do not incorporate perception, but predict an answer based solely... | Miles Shelton, Nate Wingerd, Kritim K. Rijal, Ayush Garg, Adelina Gutic, Brett Barnes, Catherine FineganDollak |  |
| 13 |  |  [Learning Sparsity for Effective and Efficient Music Performance Question Answering](https://doi.org/10.18653/v1/2025.acl-short.12) |  | 0 | Music performances, characterized by dense and continuous audio as well as seamless audio-visual integration, present unique challenges for multimodal scene understanding and reasoning. Recent Music Performance Audio-Visual Question Answering (Music AVQA) datasets have been proposed to reflect... | Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui |  |
| 14 |  |  [Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon](https://doi.org/10.18653/v1/2025.acl-short.13) |  | 0 | Despite substantial research efforts evaluating how well large language models (LLMs) handle global cultural diversity, the mechanisms behind their cultural knowledge acquisition, particularly in multilingual settings, remain unclear. We study this question by investigating how cultural knowledge... | Chen Zhang, Zhiyuan Liao, Yansong Feng |  |
| 15 |  |  [Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility](https://doi.org/10.18653/v1/2025.acl-short.14) |  | 0 | Whether large language models (LLMs) process language similarly to humans has been the subject of much theoretical and practical debate. We examine this question through the lens of the production-interpretation distinction found in human sentence processing and evaluate the extent to which... | SuetYing Lam, Qingcheng Zeng, Jingyi Wu, Rob Voigt |  |
| 16 |  |  [Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution's Characteristics](https://doi.org/10.18653/v1/2025.acl-short.15) |  | 0 | Well-calibrated model confidence scores can improve the usefulness of text generation models. For example, users can be prompted to review predictions with low confidence scores, to prevent models from returning bad or potentially dangerous predictions. However, confidence metrics are not always... | Lorenzo Jaime Yu Flores, Ori Ernst, Jackie CK Cheung |  |
| 17 |  |  [KnowShiftQA: How Robust are RAG Systems when Textbook Knowledge Shifts in K-12 Education?](https://doi.org/10.18653/v1/2025.acl-short.16) |  | 0 | Retrieval-Augmented Generation (RAG) systems show remarkable potential as question answering tools in the K-12 Education domain, where knowledge is typically queried within the restricted scope of authoritative textbooks. However, discrepancies between these textbooks and the parametric knowledge... | Tianshi Zheng, Weihan Li, Jiaxin Bai, Weiqi Wang, Yangqiu Song |  |
| 18 |  |  [Improving Parallel Sentence Mining for Low-Resource and Endangered Languages](https://doi.org/10.18653/v1/2025.acl-short.17) |  | 0 | While parallel sentence mining has been extensively covered for fairly well-resourced languages, pairs involving low-resource languages have received comparatively little attention.To address this gap, we present Belopsem, a benchmark of new datasets for parallel sentence mining on three language... | Shu Okabe, Katharina Hämmerl, Alexander Fraser |  |
| 19 |  |  [Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?](https://doi.org/10.18653/v1/2025.acl-short.18) |  | 0 | As large language models (LLMs) are increasingly used in high-stakes domains, accurately assessing their confidence is crucial. Humans typically express confidence through epistemic markers (e.g., “fairly confident”) instead of numerical values. However, it remains unclear whether LLMs consistently... | Jiayu Liu, Qing Zong, Weiqi Wang, Yangqiu Song |  |
| 20 |  |  [Limited-Resource Adapters Are Regularizers, Not Linguists](https://doi.org/10.18653/v1/2025.acl-short.19) |  | 0 | Cross-lingual transfer from related high-resource languages is a well-established strategy to enhance low-resource language technologies. Prior work has shown that adapters show promise for, e.g., improving low-resource machine translation (MT). In this work, we investigate an adapter souping... | Marcell Fekete, Nathaniel Romney Robinson, Ernests Lavrinovics, E. Djeride JeanBaptiste, Raj Dabre, Johannes Bjerva, Heather C. Lent |  |
| 21 |  |  [LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks](https://doi.org/10.18653/v1/2025.acl-short.20) |  | 0 | There is an increasing trend towards evaluating NLP models with LLMs instead of human judgments, raising questions about the validity of these evaluations, as well as their reproducibility in the case of proprietary models. We provide JUDGE-BENCH, an extensible collection of 20 NLP datasets with... | Anna Bavaresco, Raffaella Bernardi, Leonardo Bertolazzi, Desmond Elliott, Raquel Fernández, Albert Gatt, Esam Ghaleb, Mario Giulianelli, Michael Hanna, Alexander Koller, André F. T. Martins, Philipp Mondorf, Vera Neplenbroek, Sandro Pezzelle, Barbara Plank, David Schlangen, Alessandro Suglia, Aditya K. Surikuchi, Ece Takmaz, Alberto Testoni |  |
| 22 |  |  [FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings](https://doi.org/10.18653/v1/2025.acl-short.21) |  | 0 | Efficient preference optimization algorithms such as Direct Preference Optimization (DPO) have become a popular approach in aligning large language models (LLMs) with human preferences. These algorithms implicitly treat the LLM as a reward model, and focus on training it to correct misranked... | Tong Liu, Xiao Yu, Wenxuan Zhou, Jindong Gu, Volker Tresp |  |
| 23 |  |  [Combining Domain and Alignment Vectors Provides Better Knowledge-Safety Trade-offs in LLMs](https://doi.org/10.18653/v1/2025.acl-short.22) |  | 0 | There is a growing interest in training domain-expert LLMs that excel in specific technical fields compared to their general-purpose instruction-tuned counterparts. However, these expert models are not either explicitly trained to be safe, or experience a loss in their safety abilities in the... | Megh Thakkar, Quentin Fournier, Matthew Riemer, PinYu Chen, Amal Zouaq, Payel Das, Sarath Chandar |  |
| 24 |  |  [Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?](https://doi.org/10.18653/v1/2025.acl-short.23) |  | 0 | While ChatGPT and GPT-based models are able to effectively perform many tasks without additional fine-tuning, they struggle with tasks related to extremely low-resource languages and indigenous languages. Uniform Meaning Representation (UMR), a semantic representation designed to capture the... | Shira Wein |  |
| 25 |  |  [Subword models struggle with word learning, but surprisal hides it](https://doi.org/10.18653/v1/2025.acl-short.24) |  | 0 | We study word learning in subword and character language models with the psycholinguistic lexical decision task. While subword LMs struggle to discern words and non-words with high accuracy, character LMs solve this task easily and consistently. Only when supplied with further contexts do subword... | Bastian Bunzeck, Sina Zarrieß |  |
| 26 |  |  [LLM as Entity Disambiguator for Biomedical Entity-Linking](https://doi.org/10.18653/v1/2025.acl-short.25) |  | 0 | Entity linking involves normalizing a mention in medical text to a unique identifier in a knowledge base, such as UMLS or MeSH. Most entity linkers follow a two-stage process: first, a candidate generation step selects high-quality candidates, and then a named entity disambiguation phase determines... | Christophe Ye, Cassie S. Mitchell |  |
| 27 |  |  [Towards Geo-Culturally Grounded LLM Generations](https://doi.org/10.18653/v1/2025.acl-short.26) |  | 0 | Generative large language models (LLMs) have demonstrated gaps in diverse cultural awareness across the globe. We investigate the effect of retrieval augmented generation and search-grounding techniques on LLMs’ ability to display familiarity with various national cultures. Specifically, we compare... | Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Martin Jr., Sunipa Dev |  |
| 28 |  |  [MUSTS: MUltilingual Semantic Textual Similarity Benchmark](https://doi.org/10.18653/v1/2025.acl-short.27) |  | 0 | Predicting semantic textual similarity (STS) is a complex and ongoing challenge in natural language processing (NLP). Over the years, researchers have developed a variety of supervised and unsupervised approaches to calculate STS automatically. Additionally, various benchmarks, which include STS... | Tharindu Ranasinghe, Hansi Hettiarachchi, Constantin Orasan, Ruslan Mitkov |  |
| 29 |  |  [Can Large Language Models Accurately Generate Answer Keys for Health-related Questions?](https://doi.org/10.18653/v1/2025.acl-short.28) |  | 0 | The evaluation of text generated by LLMs remains a challenge for question answering, retrieval augmented generation (RAG), summarization, and many other natural language processing tasks. Evaluating the factuality of LLM generated responses is particularly important in medical question answering,... | Davis Bartels, Deepak Gupta, Dina DemnerFushman |  |
| 30 |  |  [Literary Evidence Retrieval via Long-Context Language Models](https://doi.org/10.18653/v1/2025.acl-short.29) |  | 0 | How well do modern long-context language models understand literary fiction? We explore this question via the task of literary evidence retrieval, repurposing the RELiC dataset of Thai et al. (2022) to construct a benchmark where the entire text of a primary source (e.g., The Great Gatsby) is... | Katherine Thai, Mohit Iyyer |  |
| 31 |  |  [A Little Human Data Goes A Long Way](https://doi.org/10.18653/v1/2025.acl-short.30) |  | 0 | Faced with an expensive human annotation process, creators of NLP systems increasingly turn to synthetic data generation. While this method shows promise, the extent to which synthetic data can replace human annotation is poorly understood. We investigate the use of synthetic data in Fact... | Dhananjay Ashok, Jonathan May |  |
| 32 |  |  [Seeking Rational Demonstrations for Large Language Models: A Domain Generalization Approach to Unsupervised Cross-Domain Keyphrase Generation](https://doi.org/10.18653/v1/2025.acl-short.31) |  | 0 | Unsupervised cross-domain keyphrase generation is crucial in real-world natural language processing scenarios. However, the accuracy of up-to-date approaches is limited by the distribution shift between source and target domain, which stems from the cross-domain field. Large language models (LLMs)... | Guangzhen Zhao, Yu Yao, Dechang Kong, Zhenjiang Dong |  |
| 33 |  |  [LexKeyPlan: Planning with Keyphrases and Retrieval Augmentation for Legal Text Generation: A Case Study on European Court of Human Rights Cases](https://doi.org/10.18653/v1/2025.acl-short.32) |  | 0 | Large language models excel at legal text generation but often produce hallucinations due to their sole reliance on parametric knowledge. Retrieval-augmented models mitigate this by providing relevant external documents to the model but struggle when retrieval is based only on past context, which... | T. Y. S. S. Santosh, Elvin Quero Hernandez |  |
| 34 |  |  [SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement](https://doi.org/10.18653/v1/2025.acl-short.33) |  | 0 | In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to... | Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen |  |
| 35 |  |  [Enhancing Retrieval Systems with Inference-Time Logical Reasoning](https://doi.org/10.18653/v1/2025.acl-short.34) |  | 0 | Traditional retrieval methods rely on transforming user queries into vector representations and retrieving documents based on cosine similarity within an embedding space. While efficient and scalable, this approach often fails to handle complex queries involving logical constructs such as... | Felix Faltings, Wei Wei, Yujia Bao |  |
| 36 |  |  [Using Subtext to Enhance Generative IDRR](https://doi.org/10.18653/v1/2025.acl-short.35) |  | 0 | Implicit Discourse Relation Recognition (abbr., IDRR) is a NLP task of classifying argument pairs into different types of semantic relations. Arguments contain subtexts, some of which are beneficial to the perception of semantic relations. However, subtexts are connotative. The neural IDRR model... | Zhipang Wang, Yu Hong, Weihao Sun, Guodong Zhou |  |
| 37 |  |  [State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for State Space Models](https://doi.org/10.18653/v1/2025.acl-short.36) |  | 0 | State Space Models (SSMs) have emerged as efficient alternatives to Transformers, mitigating their quadratic computational cost. However, the application of Parameter-Efficient Fine-Tuning (PEFT) methods to SSMs remains largely unexplored. In particular, prompt-based methods like Prompt Tuning and... | Wonjun Kang, Kevin Galim, Yuchen Zeng, Minjae Lee, Hyung Il Koo, Nam Ik Cho |  |
| 38 |  |  [Internal and External Impacts of Natural Language Processing Papers](https://doi.org/10.18653/v1/2025.acl-short.37) |  | 0 | We investigate the impacts of NLP research published in top-tier conferences (i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from research articles and external sources such as patents, media, and policy documents, we examine how different NLP topics are consumed both within... | Yu Zhang |  |
| 39 |  |  [An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling](https://doi.org/10.18653/v1/2025.acl-short.38) |  | 0 | Sequence labeling models often benefit from incorporating external knowledge. However, this practice introduces data heterogeneity and complicates the model with additional modules, leading to increased expenses for training a high-performing model. To address this challenge, we propose a... | Xuemei Tang, Jun Wang, Qi Su, ChuRen Huang, Jinghang Gu |  |
| 40 |  |  [Accelerating Dense LLMs via L0-regularized Mixture-of-Experts](https://doi.org/10.18653/v1/2025.acl-short.39) |  | 0 | Large language models (LLMs) achieve strong performance but suffer from slow and costly inference. Existing acceleration methods often lead to noticeable performance degradation, while Mixture-of-Experts (MoE) models require extensive computational resources. In this paper, we propose L0-MoE, a... | Zhenyu Zhang, JiuDong Yang, Zhaowen Tao, Meng Chen |  |
| 41 |  |  [Do Multimodal Large Language Models Truly See What We Point At? Investigating Indexical, Iconic, and Symbolic Gesture Comprehension](https://doi.org/10.18653/v1/2025.acl-short.40) |  | 0 | Understanding hand gestures is essential for human communication, yet it remains unclear how well multimodal large language models (MLLMs) comprehend them. In this paper, we examine MLLMs’ ability to interpret indexical gestures, which require external referential grounding, in comparison to iconic... | Noriki Nishida, Koji Inoue, Hideki Nakayama, Mayumi Bono, Katsuya Takanashi |  |
| 42 |  |  [Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering](https://doi.org/10.18653/v1/2025.acl-short.41) |  | 0 | Multimodal large language models (MLLMs) still struggle with complex reasoning tasks in Visual Question Answering (VQA). While current methods have advanced by incorporating visual prompts, our study uncovers critical limitations: these approaches indiscriminately annotate all detected objects for... | Songtao Jiang, Chenyi Zhou, Yan Zhang, Yeying Jin, Zuozhu Liu |  |
| 43 |  |  [Can Community Notes Replace Professional Fact-Checkers?](https://doi.org/10.18653/v1/2025.acl-short.42) |  | 0 | Two commonly employed strategies to combat the rise of misinformation on social media are (i) fact-checking by professional organisations and (ii) community moderation by platform users. Policy changes by Twitter/X and, more recently, Meta, signal a shift away from partnerships with fact-checking... | Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein |  |
| 44 |  |  [Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model](https://doi.org/10.18653/v1/2025.acl-short.43) |  | 0 | Sign Language Translation (SLT) aims to convert sign language (SL) videos into spoken language text, thereby bridging the communication gap between the sign and the spoken community. While most existing works focus on translating a single SL into a single spoken language (one-to-one SLT),... | Sihan Tan, Taro Miyazaki, Kazuhiro Nakadai |  |
| 45 |  |  [Advancing Sequential Numerical Prediction in Autoregressive Models](https://doi.org/10.18653/v1/2025.acl-short.44) |  | 0 | Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss(NTIL) to... | Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, AnLan Wang, Jingqun Tang, Can Huang |  |
| 46 |  |  [FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring](https://doi.org/10.18653/v1/2025.acl-short.45) |  | 0 | In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In... | Hyein Seo, Taewook Hwang, Yohan Lee, Sangkeun Jung |  |
| 47 |  |  [ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events](https://doi.org/10.18653/v1/2025.acl-short.46) |  | 0 | Large Language Models (LLMs) still face significant challenges in reasoning and arithmetic. Although temporal reasoning has raised increasing research attention, comprehensive testing of Allen’s interval relations (e.g., before, after, during) —a fundamental framework for temporal relationships—... | Duygu Sezen Islakoglu, JanChristoph Kalo |  |
| 48 |  |  [Human Alignment: How Much Do We Adapt to LLMs?](https://doi.org/10.18653/v1/2025.acl-short.47) |  | 0 | Large Language Models (LLMs) are becoming a common part of our lives, yet few studies have examined how they influence our behavior. Using a cooperative language game in which players aim to converge on a shared word, we investigate how people adapt their communication strategies when paired with... | Tanguy Cazalets, Ruben Janssens, Tony Belpaeme, Joni Dambre |  |
| 49 |  |  [Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis](https://doi.org/10.18653/v1/2025.acl-short.48) |  | 0 | Aspect-based sentiment analysis (ABSA) assesses sentiments towards specific aspects within texts, resulting in detailed sentiment tuples.Previous ABSA models often used static templates to predict all the elements in the tuples, and these models often failed to accurately capture dependencies... | Yonghyun Jun, Hwanhee Lee |  |
| 50 |  |  [That doesn't sound right: Evaluating speech transcription quality in field linguistics corpora](https://doi.org/10.18653/v1/2025.acl-short.49) |  | 0 | Incorporating automatic speech recognition (ASR) into field linguistics workflows for language documentation has become increasingly common. While ASR performance has seen improvements in low-resource settings, obstacles remain when training models on data collected by documentary linguists. One... | Éric Le Ferrand, Bo Jiang, Joshua K. Hartshorne, Emily Prud'hommeaux |  |
| 51 |  |  [Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering](https://doi.org/10.18653/v1/2025.acl-short.50) |  | 0 | Scaling the test-time compute of large language models has demonstrated impressive performance on reasoning benchmarks. However, existing evaluations of test-time scaling make the strong assumption that a reasoning system should always give an answer to any question provided. This overlooks... | William Jurayj, Jeffrey Cheng, Benjamin Van Durme |  |
| 52 |  |  [Acoustic Individual Identification of White-Faced Capuchin Monkeys Using Joint Multi-Species Embeddings](https://doi.org/10.18653/v1/2025.acl-short.51) |  | 0 | Acoustic individual identification of wild animals is an essential task for understanding animal vocalizations within their social contexts, and for facilitating conservation and wildlife monitoring efforts. However, most of the work in this space relies on human efforts, as the development of... | Álvaro VegaHidalgo, Artem Abzaliev, Thore Bergman, Rada Mihalcea |  |
| 53 |  |  [SELF-PERCEPT: Introspection Improves Large Language Models' Detection of Multi-Person Mental Manipulation in Conversations](https://doi.org/10.18653/v1/2025.acl-short.52) |  | 0 | Mental manipulation is a subtle yet pervasive form of abuse in interpersonal communication, making its detection critical for safeguarding potential victims. However, due to manipulation’s nuanced and context-specific nature, identifying manipulative language in complex, multi-turn, and... | Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, Sandeep Chaurasia, Kripabandhu Ghosh |  |
| 54 |  |  [A Variational Approach for Mitigating Entity Bias in Relation Extraction](https://doi.org/10.18653/v1/2025.acl-short.53) |  | 0 | Mitigating entity bias is a critical challenge in Relation Extraction (RE), where models often rely excessively on entities, resulting in poor generalization. This paper presents a novel approach to address this issue by adapting a Variational Information Bottleneck (VIB) framework. Our method... | Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley |  |
| 55 |  |  [GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction](https://doi.org/10.18653/v1/2025.acl-short.54) |  | 0 | Large language models (LLMs) often struggle with zero-shot generalization, and several modular approaches have been proposed to address this challenge. Yet, we hypothesize that a key limitation remains: the entanglement of general knowledge and task-specific adaptations. To overcome this, we... | Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh |  |
| 56 |  |  [The Role of Abstract Representations and Observed Preferences in the Ordering of Binomials in Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.55) |  | 0 | To what extent do large language models learn abstract representations as opposed to more superficial aspects of their very large training corpora? We examine this question in the context of binomial ordering preferences involving two conjoined nouns in English. When choosing a binomial ordering... | Zachary Nicholas Houghton, Kenji Sagae, Emily Morgan |  |
| 57 |  |  [Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs](https://doi.org/10.18653/v1/2025.acl-short.56) |  | 0 | Unvoiced electromyography (EMG) is an effective communication tool for individuals unable to produce vocal speech. However, most prior methods rely on paired voiced and unvoiced EMG signals, along with speech data, for unvoiced EMG-to-text conversion, which is not practical for these individuals.... | Payal Mohapatra, Akash Pandey, Xiaoyuan Zhang, Qi Zhu |  |
| 58 |  |  [Decoder-Only LLMs can be Masked Auto-Encoders](https://doi.org/10.18653/v1/2025.acl-short.57) |  | 0 | Modern NLP workflows (e.g., RAG systems) require different models for generation and embedding tasks, where bidirectional pre-trained encoders and decoder-only Large Language Models (LLMs) dominate respective tasks. Structural differences between models result in extra development costs and limit... | Dan Qiao, Yuan Gao, Zheming Yang, Di Yang, Ziheng Wu, Pengcheng Lu, Minghui Qiu, Juntao Li, Min Zhang |  |
| 59 |  |  [Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding](https://doi.org/10.18653/v1/2025.acl-short.58) |  | 0 | While Large Language Models (LLMs) support long contexts, they struggle with performance degradation within the context window. Current solutions incur prohibitive training costs, leaving statistical behaviors and cost-effective approaches underexplored. From the decoding perspective, we identify... | Zikai Xiao, Ziyang Wang, Wen Ma, Yan Zhang, Wei Shen, WangYan WangYan, Luqi Gong, Zuozhu Liu |  |
| 60 |  |  [Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs](https://doi.org/10.18653/v1/2025.acl-short.59) |  | 0 | Due to the auto-regressive nature of current video large language models (Video-LLMs), the inference latency increases as the input sequence length grows, posing challenges for the efficient processing of video sequences that are usually very long. We observe that during decoding, the attention... | Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu |  |
| 61 |  |  [Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results](https://doi.org/10.18653/v1/2025.acl-short.60) |  | 0 | Uncertainty Quantification (UQ) in Language Models (LMs) is key to improving their safety and reliability. Evaluations often use metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). We show that mutual... | Andrea Santilli, Adam Golinski, Michael Kirchhof, Federico Danieli, Arno Blaas, Miao Xiong, Luca Zappella, Sinead Williamson |  |
| 62 |  |  [Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation](https://doi.org/10.18653/v1/2025.acl-short.61) |  | 0 | In this work, we explore how instance-level memorization in the teacher Neural Machine Translation (NMT) model gets inherited by the student model in sequence-level knowledge distillation (SeqKD). We find that despite not directly seeing the original training data, students memorize more than... | Verna Dankers, Vikas Raunak |  |
| 63 |  |  [CoRet: Improved Retriever for Code Editing](https://doi.org/10.18653/v1/2025.acl-short.62) |  | 0 | In this paper, we introduce CoRet, a dense retrieval model designed for code-editing tasks that integrates code semantics, repository structure, and call-graph dependencies. The model focuses on retrieving relevant portions of a code repository based on natural language queries such as requests to... | Fabio Fehr, Prabhu Teja Sivaprasad, Luca Franceschi, Giovanni Zappella |  |
| 64 |  |  [Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress](https://doi.org/10.18653/v1/2025.acl-short.63) |  | 0 | In Machine Translation (MT) evaluation, metric performance is assessed based on agreement with human judgments. In recent years, automatic metrics have demonstrated increasingly high levels of agreement with humans. To gain a clearer understanding of metric performance and establish an upper bound,... | Lorenzo Proietti, Stefano Perrella, Roberto Navigli |  |
| 65 |  |  [Diffusion Directed Acyclic Transformer for Non-Autoregressive Machine Translation](https://doi.org/10.18653/v1/2025.acl-short.64) |  | 0 | Non-autoregressive transformers (NATs) predict entire sequences in parallel to reduce decoding latency, but they often encounter performance challenges due to the multi-modality problem. A recent advancement, the Directed Acyclic Transformer (DAT), addresses this issue by capturing multiple... | Quan NguyenTri, Cong Dao Tran, Hoang ThanhTung |  |
| 66 |  |  [Efficient Knowledge Editing via Minimal Precomputation](https://doi.org/10.18653/v1/2025.acl-short.65) |  | 0 | Knowledge editing methods like MEMIT are able to make data and compute efficient updates of factual knowledge by using a single sentence to update facts and their consequences. However, what is often overlooked is a “precomputation step”, which requires a one-time but significant computational... | Akshat Gupta, Maochuan Lu, Thomas Hartvigsen, Gopala Anumanchipalli |  |
| 67 |  |  [Meaning Variation and Data Quality in the Corpus of Founding Era American English](https://doi.org/10.18653/v1/2025.acl-short.66) |  | 0 | Legal scholars are increasingly using corpus based methods for assessing historical meaning. Among work focused on the so-called founding era (mid to late 18th century), the majority of such studies use the Corpus of Founding Era American English (COFEA) and rely on methods such as word counting... | Dallas Card |  |
| 68 |  |  [MindRef: Mimicking Human Memory for Hierarchical Reference Retrieval with Fine-Grained Location Awareness](https://doi.org/10.18653/v1/2025.acl-short.67) |  | 0 | When completing knowledge-intensive tasks, humans sometimes need an answer and a corresponding reference passage for auxiliary reading. Previous methods required obtaining pre-segmented article chunks through additional retrieval models. This paper explores leveraging the parameterized knowledge... | Ye Wang, Xinrun Xu, Zhiming Ding |  |
| 69 |  |  [LLMs syntactically adapt their language use to their conversational partner](https://doi.org/10.18653/v1/2025.acl-short.68) |  | 0 | It has been frequently observed that human speakers align their language use with each other during conversations. In this paper, we study empirically whether large language models (LLMs) exhibit the same behavior of conversational adaptation.We construct a corpus of conversations between LLMs and... | Florian Kandra, Vera Demberg, Alexander Koller |  |
| 70 |  |  [TigerLLM - A Family of Bangla Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.69) |  | 0 | The development of Large Language Models (LLMs) remains heavily skewed towards English and a few other high-resource languages. This linguistic disparity is particularly evident for Bangla - the 5th most spoken language. A few initiatives attempted to create open-source Bangla LLMs with performance... | Nishat Raihan, Marcos Zampieri |  |
| 71 |  |  [From Citations to Criticality: Predicting Legal Decision Influence in the Multilingual Swiss Jurisprudence](https://doi.org/10.18653/v1/2025.acl-short.70) |  | 0 | Many court systems are overwhelmed all over the world, leading to huge backlogs of pending cases. Effective triage systems, like those in emergency rooms, could ensure proper prioritization of open cases, optimizing time and resource allocation in the court system. In this work, we introduce the... | Ronja Stern, Ken Kawamura, Matthias Stürmer, Ilias Chalkidis, Joel Niklaus |  |
| 72 |  |  [Revisiting LLMs as Zero-Shot Time Series Forecasters: Small Noise Can Break Large Models](https://doi.org/10.18653/v1/2025.acl-short.71) |  | 0 | Large Language Models (LLMs) have shown remarkable performance across diverse tasks without domain-specific training, fueling interest in their potential for time-series forecasting. While LLMs have shown potential in zero-shot forecasting through prompting alone, recent studies suggest that LLMs... | Junwoo Park, Hyuck Lee, Dohyun Lee, Daehoon Gwak, Jaegul Choo |  |
| 73 |  |  [Transferring Textual Preferences to Vision-Language Understanding through Model Merging](https://doi.org/10.18653/v1/2025.acl-short.72) |  | 0 | Large vision-language models (LVLMs) perform outstandingly across various multimodal tasks. However, their ability to evaluate generated content remains limited, and training vision-language reward models (VLRMs) with preference data is computationally expensive. This paper explores a training-free... | ChenAn Li, TzuHan Lin, YunNung Chen, Hungyi Lee |  |
| 74 |  |  [ProgCo: Program Helps Self-Correction of Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.73) |  | 0 | Self-Correction aims to enable large language models (LLMs) to self-verify and self-refine their initial responses without external feedback. However, LLMs often fail to effectively self-verify and generate correct feedback, further misleading refinement and leading to the failure of... | Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng |  |
| 75 |  |  [Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs](https://doi.org/10.18653/v1/2025.acl-short.74) |  | 0 | The performance of large language models in domain-specific tasks necessitates fine-tuning, which is computationally expensive and technically challenging. This paper focuses on parameter-efficient fine-tuning using soft prompting, a promising approach that adapts pre-trained models to downstream... | Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay |  |
| 76 |  |  [Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar](https://doi.org/10.18653/v1/2025.acl-short.75) |  | 0 | Typical methods for evaluating the performance of language models evaluate their ability to answer questions accurately. These evaluation metrics are acceptable for determining the extent to which language models can understand and reason about text in a general sense, but fail to capture nuanced... | Andrew Gambardella, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo |  |
| 77 |  |  [Unique Hard Attention: A Tale of Two Sides](https://doi.org/10.18653/v1/2025.acl-short.76) |  | 0 | Understanding the expressive power of transformers has recently attracted attention, as it offers insights into their abilities and limitations. Many studies analyze unique hard attention transformers, where attention selects a single position that maximizes the attention scores. When multiple... | Selim Jerad, Anej Svete, Jiaoda Li, Ryan Cotterell |  |
| 78 |  |  [Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding](https://doi.org/10.18653/v1/2025.acl-short.77) |  | 0 | Large language models (LLMs) excel at a range of tasks through in-context learning (ICL), where only a few task examples guide their predictions. However, prior research highlights that LLMs often overlook input-label mapping information in ICL, relying more on their pre-trained knowledge. To... | Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao |  |
| 79 |  |  [Different Speech Translation Models Encode and Translate Speaker Gender Differently](https://doi.org/10.18653/v1/2025.acl-short.78) |  | 0 | Recent studies on interpreting the hidden states of speech models have shown their ability to capture speaker-specific features, including gender. Does this finding also hold for speech translation (ST) models? If so, what are the implications for the speaker’s gender assignment in translation? We... | Dennis Fucci, Marco Gaido, Matteo Negri, Luisa Bentivogli, André F. T. Martins, Giuseppe Attanasio |  |
| 80 |  |  [Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints](https://doi.org/10.18653/v1/2025.acl-short.79) |  | 0 | Semantic Parsing aims to capture the meaning of a sentence and convert it into a logical, structured form. Previous studies show that semantic parsing enhances the performance of smaller models (e.g., BERT) on downstream tasks. However, it remains unclear whether the improvements extend similarly... | Kaikai An, Shuzheng Si, Helan Hu, Haozhe Zhao, Yuchi Wang, Qingyan Guo, Baobao Chang |  |
| 81 |  |  [Quantifying Misattribution Unfairness in Authorship Attribution](https://doi.org/10.18653/v1/2025.acl-short.80) |  | 0 | Authorship misattribution can have profound consequences in real life. In forensic settings simply being considered as one of the potential authors of an evidential piece of text or communication can result in undesirable scrutiny. This raises a fairness question: Is every author in the candidate... | Pegah Alipoormolabashi, Ajay Patel, Niranjan Balasubramanian |  |
| 82 |  |  [Zero-Shot Text-to-Speech for Vietnamese](https://doi.org/10.18653/v1/2025.acl-short.81) |  | 0 | This paper introduces PhoAudiobook, a newly curated dataset comprising 941 hours of high-quality audio for Vietnamese text-to-speech. Using PhoAudiobook, we conduct experiments on three leading zero-shot TTS models: VALL-E, VoiceCraft, and XTTS-V2. Our findings demonstrate that PhoAudiobook... | Thi Vu, Linh The Nguyen, Dat Quoc Nguyen |  |
| 83 |  |  [Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure](https://doi.org/10.18653/v1/2025.acl-short.82) |  | 0 | We introduce TestCase-Eval, a new benchmark for systematic evaluation of LLMs in test-case generation. TestCase-Eval includes 500 algorithm problems and 100,000 human-crafted solutions from the Codeforces platform. It focuses on two pivotal tasks: (1) Fault Coverage, which measures how well... | Zheyuan Yang, Zexi Kuang, Xue Xia, Yilun Zhao |  |
| 84 |  |  [Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching](https://doi.org/10.18653/v1/2025.acl-short.83) |  | 0 | We introduce a novel framework for analyzing sorting algorithms in pairwise ranking prompting (PRP), re-centering the cost model around LLM inferences rather than traditional pairwise comparisons. While classical metrics based on comparison counts have traditionally been used to gauge efficiency,... | Juan Wisznia, Cecilia Bolaños, Juan Tollo, Giovanni Marraffini, Agustín Gianolini, Noe Hsueh, Luciano Del Corro |  |
| 85 |  |  [TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation](https://doi.org/10.18653/v1/2025.acl-short.84) |  | 0 | Large language models (LLMs) now achieve near-human performance on standard math word problem benchmarks (e.g., GSM8K), yet their true reasoning ability remains disputed. A key concern is that models often produce confident, yet unfounded, answers to unanswerable problems. We introduce TreeCut, a... | Jialin Ouyang |  |
| 86 |  |  [WinSpot: GUI Grounding Benchmark with Multimodal Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.85) |  | 0 | Graphical User Interface (GUI) automation relies on accurate GUI grounding. However, obtaining large-scale, high-quality labeled data remains a key challenge, particularly in desktop environments like Windows Operating System (OS). Existing datasets primarily focus on structured web-based elements,... | Zheng Hui, Yinheng Li, Dan Zhao, Colby R. Banbury, Tianyi Chen, Kazuhito Koishida |  |
| 87 |  |  [Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.86) |  | 0 | Social determinants of health (SDOH) extraction from clinical text is critical for downstream healthcare analytics. Although large language models (LLMs) have shown promise, they may rely on superficial cues leading to spurious predictions. Using the MIMIC portion of the SHAC (Social History... | Fardin Ahsan Sakib, Ziwei Zhu, Karen Trister Grace, Meliha Yetisgen, Özlem Uzuner |  |
| 88 |  |  [Enhancing NER by Harnessing Multiple Datasets with Conditional Variational Autoencoders](https://doi.org/10.18653/v1/2025.acl-short.87) |  | 0 | We propose a novel method to integrate a Conditional Variational Autoencoder (CVAE) into a span-based Named Entity Recognition (NER) model to model the shared and unshared information among labels in multiple datasets and ease the training on the datasets. Experimental results using multiple... | Taku Oi, Makoto Miwa |  |
| 89 |  |  [CHEER-Ekman: Fine-grained Embodied Emotion Classification](https://doi.org/10.18653/v1/2025.acl-short.88) |  | 0 | Emotions manifest through physical experiences and bodily reactions, yet identifying such embodied emotions in text remains understudied. We present an embodied emotion classification dataset, CHEER-Ekman, extending the existing binary embodied emotion dataset with Ekman’s six basic emotion... | Phan Anh Duong, Cat Luong, Divyesh Bommana, Tianyu Jiang |  |
| 90 |  |  [ScanEZ: Integrating Cognitive Models with Self-Supervised Learning for Spatiotemporal Scanpath Prediction](https://doi.org/10.18653/v1/2025.acl-short.89) |  | 0 | Accurately predicting human scanpaths during reading is vital for diverse fields and downstream tasks, from educational technologies to automatic question answering. To date, however, progress in this direction remains limited by scarce gaze data. We overcome the issue with ScanEZ, a... | Ekta Sood, Prajit Dhar, Enrica Troiano, Rosy Southwell, Sidney K. D'Mello |  |
| 91 |  |  [Improving Fairness of Large Language Models in Multi-document Summarization](https://doi.org/10.18653/v1/2025.acl-short.90) |  | 0 | Fairness in multi-document summarization (MDS) is crucial for providing comprehensive views across documents with diverse social attribute values, which can significantly impact decision-making. For example, a summarization system that tends to overrepresent negative reviews of products can mislead... | Haoyuan Li, Rui Zhang, Snigdha Chaturvedi |  |
| 92 |  |  [Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning](https://doi.org/10.18653/v1/2025.acl-short.91) |  | 0 | Large language models (LLMs) show potential in healthcare but often generate hallucinations, especially when handling unfamiliar information. In medication, a systematic benchmark to evaluate model capabilities is lacking, which is critical given the high-risk nature of medical information. This... | Yue Wu, Yangmin Huang, Qianyun Du, Lixian Lai, Zhiyang He, Jiaxue Hu, Xiaodong Tao |  |
| 93 |  |  [Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?](https://doi.org/10.18653/v1/2025.acl-short.92) |  | 0 | One of the goals of automatic evaluation metrics in grammatical error correction (GEC) is to rank GEC systems such that it matches human preferences. However, current automatic evaluations are based on procedures that diverge from human evaluation. Specifically, human evaluation derives rankings by... | Takumi Goto, Yusuke Sakai, Taro Watanabe |  |
| 94 |  |  [Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation](https://doi.org/10.18653/v1/2025.acl-short.93) |  | 0 | Hallucination, the generation of factually incorrect information, remains a significant challenge for large language models (LLMs), especially in open-domain long-form generation. Existing approaches for detecting hallucination in long-form tasks either focus on limited domains or rely heavily on... | Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma |  |
| 95 |  |  [WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging](https://doi.org/10.18653/v1/2025.acl-short.94) |  | 0 | We introduce WiCkeD, a simple method to increase the complexity of existing multiple-choice benchmarks by randomly replacing a choice with “None of the above”, a method often used in educational tests. We show that WiCkeD can be automatically applied to any existing benchmark, making it more... | Ahmed Elhady, Eneko Agirre, Mikel Artetxe |  |
| 96 |  |  [Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning](https://doi.org/10.18653/v1/2025.acl-short.95) |  | 0 | Multilingual alignment of sentence representations has mostly required bitexts to bridge the gap between languages. We investigate whether visual information can bridge this gap instead. Image caption datasets are very easy to create without requiring multilingual expertise, so this offers a more... | Nathaniel Krasner, Nicholas Lanuzo, Antonios Anastasopoulos |  |
| 97 |  |  [LAMB: A Training-Free Method to Enhance the Long-Context Understanding of SSMs via Attention-Guided Token Filtering](https://doi.org/10.18653/v1/2025.acl-short.96) |  | 0 | State space models (SSMs) achieve efficient sub-quadratic compute complexity but often exhibit significant performance drops as context length increases. Recent work attributes this deterioration to an exponential decay in hidden-state memory. While token filtering has emerged as a promising... | Zhifan Ye, Zheng Wang, Kejing Xia, Jihoon Hong, Leshu Li, Lexington Whalen, Cheng Wan, Yonggan Fu, Yingyan Celine Lin, Souvik Kundu |  |
| 98 |  |  [Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models](https://doi.org/10.18653/v1/2025.acl-short.97) |  | 0 | Despite the advanced capabilities of large language models (LLMs), their temporal reasoning ability remains underdeveloped. Prior works have highlighted this limitation, particularly in maintaining temporal consistency when understanding event relations. For example, models often confuse mutually... | Jongho Kim, Seungwon Hwang |  |
| 99 |  |  [Findings of the Association for Computational Linguistics, ACL 2025, Vienna, Austria, July 27 - August 1, 2025](https://aclanthology.org/volumes/2025.findings-acl/) |  | 0 |  | Wanxiang Che, Joyce Nabende, Ekaterina Shutova, Mohammad Taher Pilehvar |  |
| 100 |  |  [Frontmatter](https://aclanthology.org/2025.findings-acl.0/) |  | 0 |  |  |  |
| 101 |  |  [Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection](https://aclanthology.org/2025.findings-acl.1/) |  | 0 | Large Language Models (LLMs) have been shown to exhibit various biases and stereotypes in their generated content. While extensive research has investigated biases in LLMs, prior work has predominantly focused on explicit bias, with minimal attention to implicit bias and the relation between these... | Yachao Zhao, Bo Wang, Yan Wang, Dongming Zhao, Ruifang He, Yuexian Hou |  |
| 102 |  |  [Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task](https://aclanthology.org/2025.findings-acl.2/) |  | 0 | Current Multimodal Large Language Models (MLLMs) excel in general visual reasoning but remain underexplored in Abstract Visual Reasoning (AVR), which demands higher-order reasoning to identify abstract rules beyond simple perception. Existing AVR benchmarks focus on single-step reasoning,... | Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger |  |
| 103 |  |  [How Numerical Precision Affects Arithmetical Reasoning Capabilities of LLMs](https://aclanthology.org/2025.findings-acl.3/) |  | 0 | Despite the remarkable success of transformer-based large language models (LLMs) across various domains, understanding and enhancing their mathematical capabilities remains a significant challenge. In this paper, we conduct a rigorous theoretical analysis of LLMs’ mathematical abilities, with a... | Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang |  |
| 104 |  |  [Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts](https://aclanthology.org/2025.findings-acl.4/) |  | 0 | In this work, we address the memory overhead of deploying Mixture-of-Experts (MoE) architectures in Large Language Models (LLMs). While MoE layers improve LLM performance without increasing inference costs, the ever-growing number of experts inflates memory requirements, hindering practical... | Zeliang Zhang, Xiaodong Liu, Hao Cheng, Chenliang Xu, Jianfeng Gao |  |
| 105 |  |  [A Persona-Aware LLM-Enhanced Framework for Multi-Session Personalized Dialogue Generation](https://aclanthology.org/2025.findings-acl.5/) |  | 0 | Multi-session personalized dialogue generation is one of the most important topics in open-domain dialogue. It aims to generate responses consistent with the dialogue history and personality information across multiple sessions to engage users’ interest in the dialogue. Recent approaches focusing... | Dongshuo Liu, Zhijing Wu, Dandan Song, Heyan Huang |  |
| 106 |  |  [Exploring In-Image Machine Translation with Real-World Background](https://aclanthology.org/2025.findings-acl.6/) |  | 0 | In-Image Machine Translation (IIMT) aims to translate texts within images from one language to another. Previous research on IIMT was primarily conducted on simplified scenarios such as images of one-line text with black font in white backgrounds, which is far from reality and impractical for... | Yanzhi Tian, Zeming Liu, Zhengyang Liu, Yuhang Guo |  |
| 107 |  |  [BayesKD: Bayesian Knowledge Distillation for Compact LLMs in Constrained Fine-tuning Scenarios](https://aclanthology.org/2025.findings-acl.7/) |  | 0 | Large language models (LLMs) have revolutionized various domains with their remarkable capabilities, but their massive parameter sizes pose significant challenges for fine-tuning and inference, especially in resource-constrained environments. Conventional compression methods often result in... | Wei Li, Lujun Li, Mark G. Lee, Shengjie Sun, Lei Zhang, Wei Xue, Yike Guo |  |
| 108 |  |  [GOLFer: Smaller LMs-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval](https://aclanthology.org/2025.findings-acl.8/) |  | 0 | Large language models (LLMs)-based query expansion for information retrieval augments queries with generated hypothetical documents with LLMs. However, its performance relies heavily on the scale of the language models (LMs), necessitating larger, more advanced LLMs. This approach is costly,... | Lingyuan Liu, Mengxiang Zhang |  |
| 109 |  |  [Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion](https://aclanthology.org/2025.findings-acl.9/) |  | 0 | Large Language Models (LLMs) have shown potential in generating hypothetical documents for query expansion, thereby enhancing information retrieval performance. However, the efficacy of this method is highly dependent on the quality of the generated documents, which often requires complex prompt... | Lingyuan Liu, Mengxiang Zhang |  |
| 110 |  |  [Emo Pillars: Knowledge Distillation to Support Fine-Grained Context-Aware and Context-Less Emotion Classification](https://aclanthology.org/2025.findings-acl.10/) |  | 0 | Most datasets for sentiment analysis lack context in which an opinion was expressed, often crucial for emotion understanding, and are mainly limited by a few emotion categories. Foundation large language models (LLMs) like GPT-4 suffer from over-predicting emotions and are too resource-intensive.... | Alexander Shvets |  |
| 111 |  |  [Multi-Prompting Decoder Helps Better Language Understanding](https://aclanthology.org/2025.findings-acl.11/) |  | 0 | Recent large Pre-trained Language Models (PLMs) usually only provide users with the inference APIs, namely the emerging Model-as-a-Service (MaaS) setting. To adapt MaaS PLMs to downstream tasks without accessing their parameters and gradients, some existing methods focus on the output-side... | Zifeng Cheng, Zhaoling Chen, Zhiwei Jiang, Yafeng Yin, Cong Wang, Shiping Ge, Qing Gu |  |
| 112 |  |  [Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction](https://aclanthology.org/2025.findings-acl.12/) |  | 0 | Turn-taking is richly multimodal. Predictive turn-taking models (PTTMs) facilitate natural- istic human-robot interaction, yet most rely solely on speech. We introduce MM-VAP, a multimodal PTTM which combines speech with visual cues including facial expression, head pose and gaze. We find that it... | Sam O'Connor Russell, Naomi Harte |  |
| 113 |  |  [The Right Time Matters: Data Arrangement Affects Zero-Shot Generalization in Instruction Tuning](https://aclanthology.org/2025.findings-acl.13/) |  | 0 | Understanding alignment techniques begins with comprehending zero-shot generalization brought by instruction tuning, but little of the mechanism has been understood. Existing work has largely been confined to the task level, without considering that tasks are artificially defined and, to LLMs,... | Bingxiang He, Ning Ding, Cheng Qian, Jia Deng, Ganqu Cui, Lifan Yuan, Haiwen Hong, Huanang Gao, Longtao Huang, Hui Xue, Huimin Chen, Zhiyuan Liu, Maosong Sun |  |
| 114 |  |  [MFinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset](https://aclanthology.org/2025.findings-acl.14/) |  | 0 | Recent breakthroughs in large language models (LLMs) have led to the development of new benchmarks for evaluating their performance in the financial domain. However, current financial benchmarks often rely on news articles, earnings reports, or announcements, making it challenging to capture the... | Jie Zhu, Junhui Li, Yalong Wen, Xiandong Li, Lifan Guo, Feng Chen |  |
| 115 |  |  [ODDA: An OODA-Driven Diverse Data Augmentation Framework for Low-Resource Relation Extraction](https://aclanthology.org/2025.findings-acl.15/) |  | 0 | Data Augmentation (DA) has emerged as a promising solution to address the scarcity of high-quality annotated data in low-resource relation extraction (LRE). Leveraging large language models (LLMs), DA has significantly improved the performance of RE models with considerably fewer parameters.... | Yijie Zhong, Yunfan Gao, Xiaolian Zhang, Haofen Wang |  |
| 116 |  |  [Detecting and Mitigating Challenges in Zero-Shot Video Summarization with Video LLMs](https://aclanthology.org/2025.findings-acl.16/) |  | 0 | Video summarization aims to generate a condensed textual version of an original video. Summaries may consist of either plain text or a shortlist of salient events, possibly including temporal or spatial references. Video Large Language Models (VLLMs) exhibit impressive zero-shot capabilities in... | Luca Cagliero, Lorenzo Vaiani, Eliana Pastor, Alkis Koudounas, Elena Baralis, Vittorio Mazzia, Sandro Pollastrini, Thomas Gueudré, Manuel Giollo, Daniele Amberti, Yue Wu |  |
| 117 |  |  [Entity Framing and Role Portrayal in the News](https://aclanthology.org/2025.findings-acl.17/) |  | 0 | We introduce a novel multilingual and hierarchical corpus annotated for entity framing and role portrayal in news articles. The dataset uses a unique taxonomy inspired by storytelling elements, comprising 22 fine-grained roles, or archetypes, nested within three main categories: protagonist,... | Tarek Mahmoud, Zhuohan Xie, Dimitar Iliyanov Dimitrov, Nikolaos Nikolaidis, Purificação Silvano, Roman Yangarber, Shivam Sharma, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov |  |
| 118 |  |  [Derailer-Rerailer: Adaptive Verification for Efficient and Reliable Language Model Reasoning](https://aclanthology.org/2025.findings-acl.18/) |  | 0 | Large Language Models (LLMs) have shown impressive reasoning capabilities, yet existing prompting methods face a critical trade-off: simple approaches often struggle with complex tasks and reasoning stability, while more sophisticated methods require multiple inferences and substantial... | Guangya Wan, Yuqi Wu, Hao Wang, Shengming Zhao, Jie Chen, Sheng Li |  |
| 119 |  |  [Leveraging Large Language Models for Conversational Multi-Doc Question Answering: The First Place of WSDM Cup 2024](https://aclanthology.org/2025.findings-acl.19/) |  | 0 | Conversational multi-doc question answering aims to answer specific questions based on the retrieved documents as well as the contextual conversations. In this paper, we introduce our winning approach for the “Conversational Multi-Doc QA” challenge in WSDM Cup 2024, which exploits the superior... | Yiming Li, Zhao Zhang |  |
| 120 |  |  [TreeRAG: Unleashing the Power of Hierarchical Storage for Enhanced Knowledge Retrieval in Long Documents](https://aclanthology.org/2025.findings-acl.20/) |  | 0 | When confronting long document information retrieval for Query-Focused Summarization(QFS), Traditional Retrieval-Augmented Generation(RAG) frameworks struggle to retrieve all relevant knowledge points, and the chunking and retrieve strategies of existing frameworks may disrupt the connections... | Wenyu Tao, Xiaofen Xing, Yirong Chen, Linyi Huang, Xiangmin Xu |  |
| 121 |  |  [Attention with Dependency Parsing Augmentation for Fine-Grained Attribution](https://aclanthology.org/2025.findings-acl.21/) |  | 0 | To assist humans in efficiently validating RAG-generated content, developing a fine-grained attribution mechanism that provides supporting evidence from retrieved documents for every answer span is essential. Existing fine-grained attribution methods rely on model-internal similarity metrics... | Qiang Ding, Lvzhou Luo, Yixuan Cao, Ping Luo |  |
| 122 |  |  [ASTRO: Automatic Strategy Optimization For Non-Cooperative Dialogues](https://aclanthology.org/2025.findings-acl.22/) |  | 0 | Non-cooperative dialogues, such as negotiations and persuasion, present significant challenges for large language models (LLMs) due to the lack of inherent cooperation or shared goals. Current methods for optimizing dialogue strategies require substantial human effort for strategy optimization. To... | Yikuan Hu, Chen Huang, Wenqiang Lei |  |
| 123 |  |  [Defensive Prompt Patch: A Robust and Generalizable Defense of Large Language Models against Jailbreak Attacks](https://aclanthology.org/2025.findings-acl.23/) |  | 0 | Safety, security, and compliance are essential requirements when aligning large language models (LLMs). However, many seemingly aligned LLMs are soon shown to be susceptible to jailbreak attacks. These attacks aim to circumvent the models’ safety guardrails and security mechanisms by introducing... | Chen Xiong, Xiangyu Qi, PinYu Chen, TsungYi Ho |  |
| 124 |  |  [GUM-SAGE: A Novel Dataset and Approach for Graded Entity Salience Prediction](https://aclanthology.org/2025.findings-acl.24/) |  | 0 | Determining and ranking the most salient entities in a text is critical for user-facing systems, especially as users increasingly rely on models to interpret long documents they only partially read. Graded entity salience addresses this need by assigning entities scores that reflect their relative... | Jessica Lin, Amir Zeldes |  |
| 125 |  |  [Verifying the Steps of Deductive Reasoning Chains](https://aclanthology.org/2025.findings-acl.25/) |  | 0 | As Large Language Models penetrate everyday life more and more, it becomes essential to measure the correctness of their output. Inthis paper, we propose a novel task: the automatic verification of individual reasoning steps in a logical deductive Chain-of-Thought. Thistask addresses two well-known... | Zacchary Sadeddine, Fabian M. Suchanek |  |
| 126 |  |  [Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations](https://aclanthology.org/2025.findings-acl.26/) |  | 0 | Addressing gender bias and maintaining logical coherence in machine translation remains challenging, particularly when translating between natural gender languages, like English, and genderless languages, such as Persian, Indonesian, and Finnish. We introduce the Translate-with-Care (TWC) dataset,... | Pardis Sadat Zahraei, Ali Emami |  |
| 127 |  |  [Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection](https://aclanthology.org/2025.findings-acl.27/) |  | 0 | Surveys are widely used to collect patient data in healthcare, and there is significant clinical interest in predicting patient outcomes using survey data. However, surveys often include numerous features that lead to high-dimensional inputs for machine learning models. This paper exploits a unique... | Benjamin C. Warner, Ziqi Xu, Simon Haroutounian, Thomas George Kannampallil, Chenyan Lu |  |
| 128 |  |  [Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs](https://aclanthology.org/2025.findings-acl.28/) |  | 0 | Positional bias in large language models hinders their ability to effectively process long inputs. A prominent example is the “lost in the middle” phenomenon, where LLMs struggle to utilize relevant information situated in the middle of the input. While prior research primarily focuses on single... | Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu |  |
| 129 |  |  [Variable Layerwise Quantization: A Simple and Effective Approach to Quantize LLMs](https://aclanthology.org/2025.findings-acl.29/) |  | 0 | We present a simple meta quantization approach that quantizes different layers of a large language model (LLM) at different bit levels, and is independent of the underlying quantization technique. Specifically, we quantize the most important layers to higher bit precision and less important layers... | RazvanGabriel Dumitru, Vikas Yadav, Rishabh Maheshwary, PaulIoan Clotan, Sathwik Tejaswi Madhusudhan, Mihai Surdeanu |  |
| 130 |  |  [Why Are Positional Encodings Nonessential for Deep Autoregressive Transformers? A Petroglyph Revisited](https://aclanthology.org/2025.findings-acl.30/) |  | 0 | Do autoregressive Transformer language models require explicit positional encodings (PEs)? The answer is ‘no’ provided they have more than one layer—they can distinguish sequences with permuted tokens without the need for explicit PEs. This follows from the fact that a cascade of (permutation... | Kazuki Irie |  |
| 131 |  |  [CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation](https://aclanthology.org/2025.findings-acl.31/) |  | 0 | Large language models (LLMs) have shown great potential in natural language processing tasks, but their application to machine translation (MT) remains challenging due to pretraining on English-centric data and the complexity of reinforcement learning from human feedback (RLHF). Direct Preference... | Guofeng Cui, Pichao Wang, Yang Liu, Zemian Ke, Zhu Liu, Vimal Bhat |  |
| 132 |  |  [Talking Point based Ideological Discourse Analysis in News Events](https://aclanthology.org/2025.findings-acl.32/) |  | 0 | Analyzing ideological discourse even in the age of LLMs remains a challenge, as these models often struggle to capture the key elements that shape real-world narratives. Specifically, LLMs fail to focus on characteristic elements driving dominant discourses and lack the ability to integrate... | Nishanth Sridhar Nakshatri, Nikhil Mehta, Siyi Liu, Sihao Chen, Daniel Hopkins, Dan Roth, Dan Goldwasser |  |
| 133 |  |  [FlashBack: Efficient Retrieval-Augmented Language Modeling for Fast Inference](https://aclanthology.org/2025.findings-acl.33/) |  | 0 | Retrieval-Augmented Language Modeling (RALM) by integrating large language models (LLM) with relevant documents from an external corpus is a proven methodology for enabling the LLM to generate information beyond the scope of its pre-training corpus. Previous work by retrieving a set of tokens... | Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu |  |
| 134 |  |  [CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation](https://aclanthology.org/2025.findings-acl.34/) |  | 0 | Medical quality control indicators are essential to assess the qualifications of healthcare institutions for medical services. With the impressive performance of large language models (LLMs) like GPT-4 in the medical field, leveraging these technologies for the Medical Quality Control Indicator... | Guangya Yu, Yanhao Li, Zongying Jiang, Yuxiong Jin, Li Dai, Yupian Lin, Ruihui Hou, Weiyan Zhang, Yongqi Fan, Qi Ye, Jingping Liu, Tong Ruan |  |
| 135 |  |  [ConKE: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning](https://aclanthology.org/2025.findings-acl.35/) |  | 0 | Knowledge Editing (KE) aims to adjust a Large Language Model’s (LLM) internal representations and parameters to correct inaccuracies and improve output consistency without incurring the computational expense of re-training the entire model. However, editing commonsense knowledge still faces... | Liyu Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song |  |
| 136 |  |  [Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery](https://aclanthology.org/2025.findings-acl.36/) |  | 0 | Causal discovery is an imperative foundation for decision-making across domains, such as smart health, AI for drug discovery and AIOps. Traditional statistical causal discovery methods, while well-established, predominantly rely on observational data and often overlook the semantic cues inherent in... | ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni |  |
| 137 |  |  [PARSQL: Enhancing Text-to-SQL through SQL Parsing and Reasoning](https://aclanthology.org/2025.findings-acl.37/) |  | 0 | Large language models (LLMs) have made significant strides in text-to-SQL tasks; however, small language models (SLMs) are crucial due to their low resource consumption and efficient inference for real-world deployment. Due to resource limitations, SLMs struggle to accurately interpret natural... | Yaxun Dai, Haiqin Yang, Hao Mou, Pingfu Chao |  |
| 138 |  |  [Probing the Geometry of Truth: Consistency and Generalization of Truth Directions in LLMs Across Logical Transformations and Question Answering Tasks](https://aclanthology.org/2025.findings-acl.38/) |  | 0 | Large language models (LLMs) are trained on extensive datasets that encapsulate substantial world knowledge. However, their outputs often include confidently stated inaccuracies. Earlier works suggest that LLMs encode truthfulness as a distinct linear feature, termed the “truth direction”, which... | Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Zhengwen Feng, Hao Peng, Jianwei Yin |  |
| 139 |  |  [Comparing Bad Apples to Good Oranges Aligning Large Language Models via Joint Preference Optimization](https://aclanthology.org/2025.findings-acl.39/) |  | 0 | A common technique for aligning large language models (LLMs) relies on acquiring human preferences by comparing multiple generations conditioned on a fixed context. This method, however, relies solely on pairwise comparisons, where the generations are evaluated within an identical context. While... | Hritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, KaiWei Chang, Aditya Grover |  |
| 140 |  |  [TestAgent: An Adaptive and Intelligent Expert for Human Assessment](https://aclanthology.org/2025.findings-acl.40/) |  | 0 | Accurately assessing internal human states is key to understanding preferences, offering personalized services, and identifying challenges in real-world applications. Originating from psychometrics, adaptive testing has become the mainstream method for human measurement and has now been widely... | Junhao Yu, Yan Zhuang, Yuxuan Sun, Weibo Gao, Qi Liu, Mingyue Cheng, Zhenya Huang, Enhong Chen |  |
| 141 |  |  [SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment](https://aclanthology.org/2025.findings-acl.41/) |  | 0 | When different groups’ values differ, one approach to model alignment is to steer models at inference time towards each group’s preferences. However, techniques like in-context learning only consider similarity when drawing few-shot examples and not cross-group differences in values. We propose... | Quan Ze Chen, Kevin Feng, Chan Young Park, Amy X. Zhang |  |
| 142 |  |  [First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning](https://aclanthology.org/2025.findings-acl.42/) |  | 0 | Language models can solve complex reasoning tasks better by learning to generate rationales for their predictions. Often these models know how to solve a task but their auto-regressive decoding nature leads to incorrect results if started incorrectly. We observe that smaller models in particular,... | Kushal Jain, Moritz Miller, Niket Tandon, Kumar Shridhar |  |
| 143 |  |  [Evaluating Instructively Generated Statement by Large Language Models for Directional Event Causality Identification](https://aclanthology.org/2025.findings-acl.43/) |  | 0 | This paper aims to identify directional causal relations between events, including the existence and direction of causality. Previous studies mainly adopt prompt learning paradigm to predict a causal answer word based on a Pre-trained Language Model (PLM) for causality existence identification.... | Wei Xiang, Chuanhong Zhan, Qing Zhang, Bang Wang |  |
| 144 |  |  [CoinMath: Harnessing the Power of Coding Instruction for Math LLM](https://aclanthology.org/2025.findings-acl.44/) |  | 0 | Large Language Models (LLMs) have shown strong performance in solving mathematical problems, with code-based solutions proving particularly effective. However, the best practice to leverage coding instruction data to enhance mathematical reasoning remains underexplored. This study investigates... | Chengwei Wei, Bin Wang, JungJae Kim, Guimei Liu, Nancy F. Chen |  |
| 145 |  |  [Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts](https://aclanthology.org/2025.findings-acl.45/) |  | 0 | In an age characterized by the proliferation of mis- and disinformation online, it is critical to empower readers to understand the content they are reading. Important efforts in this direction rely on manual or automatic fact-checking, which can be challenging for emerging claims with limited... | Zain Muhammad Mujahid, Dilshod Azizov, Maha Tufail Agro, Preslav Nakov |  |
| 146 |  |  [Structured Discourse Representation for Factual Consistency Verification](https://aclanthology.org/2025.findings-acl.46/) |  | 0 | Analysing the differences in how events are represented across texts, or verifying whether the language model generations hallucinate, requires the ability to systematically compare their content. To support such comparison, structured representation that captures fine-grained information plays a... | Kun Zhang, Oana Balalau, Ioana Manolescu |  |
| 147 |  |  [SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing LLMs](https://aclanthology.org/2025.findings-acl.47/) |  | 0 | The advanced role-playing capabilities of Large Language Models (LLMs) have enabled rich interactive scenarios, yet existing research in social interactions neglects hallucination while struggling with poor generalizability and implicit character fidelity judgments. To bridge this gap, motivated by... | Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma |  |
| 148 |  |  [Understanding the Gap: an Analysis of Research Collaborations in NLP and Language Documentation](https://aclanthology.org/2025.findings-acl.48/) |  | 0 | Despite over 20 years of NLP work explicitly intended for application in language documentation (LD), practical use of this work remains vanishingly scarce. This issue has been noted and discussed over the past 10 years, but without the benefit of data to inform the discourse.To address this lack... | Luke Gessler, Alexis Palmer, Katharina von der Wense |  |
| 149 |  |  [PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data](https://aclanthology.org/2025.findings-acl.49/) |  | 0 | Personalization is essential for AI assistants, especially in private AI settings where models are expected to interpret users’ personal data (e.g., conversations, app usage) to understand their background, preferences, and social context. However, due to privacy concerns, existing academic... | Juntao Tan, Liangwei Yang, Zuxin Liu, Zhiwei Liu, Rithesh R. N., Tulika Manoj Awalgaonkar, Jianguo Zhang, Weiran Yao, Ming Zhu, Shirley Kokane, Silvio Savarese, Huan Wang, Caiming Xiong, Shelby Heinecke |  |
| 150 |  |  [Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning](https://aclanthology.org/2025.findings-acl.50/) |  | 0 | Active Learning (AL) allows models to learn interactively from user feedback. However, only annotating existing samples may hardly benefit the model’s generalization. Moreover, AL commonly faces a cold start problem due to insufficient annotated data for effective sample selection. To address this,... | Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby JiaJun Li |  |
| 151 |  |  [ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study](https://aclanthology.org/2025.findings-acl.51/) |  | 0 | Recent advances in language modeling demonstrate the need for high-quality domain-specific training data, especially for tasks that require specialized knowledge. General-purpose models, while versatile, often lack the depth needed for expert-level tasks because of limited domain-specific... | Eric Modesitt, Ke Yang, Spencer Hulsey, Xin Liu, ChengXiang Zhai, Volodymyr V. Kindratenko |  |
| 152 |  |  [Serial Position Effects of Large Language Models](https://aclanthology.org/2025.findings-acl.52/) |  | 0 | We would like to express our gratitude to the Reviewers and the Area Chair for their insightful comments and for recognizing the robustness of our proposed framework for analyzing the serial position effects (SPE) in LLMs. We appreciate the acknowledgment of our work in demonstrating the widespread... | Xiaobo Guo, Soroush Vosoughi |  |
| 153 |  |  [scRAG: Hybrid Retrieval-Augmented Generation for LLM-based Cross-Tissue Single-Cell Annotation](https://aclanthology.org/2025.findings-acl.53/) |  | 0 | In recent years, large language models (LLMs) such as GPT-4 have demonstrated impressive potential in a wide range of fields, including biology, genomics and healthcare. Numerous studies have attempted to apply pre-trained LLMs to single-cell data analysis within one tissue. However, when it comes... | Zhiyin Yu, Chao Zheng, Chong Chen, XianSheng Hua, Xiao Luo |  |
| 154 |  |  [Can Large Language Models Address Open-Target Stance Detection?](https://aclanthology.org/2025.findings-acl.54/) |  | 0 | Stance detection (SD) identifies a text’s position towards a target, typically labeled as favor, against, or none. We introduce Open-Target Stance Detection (OTSD), the most realistic task where targets are neither seen during training nor provided as input. We evaluate Large Language Models (LLMs)... | Abu Ubaida Akash, Ahmed Fahmy, Amine Trabelsi |  |
| 155 |  |  [Improve Language Model and Brain Alignment via Associative Memory](https://aclanthology.org/2025.findings-acl.55/) |  | 0 | Associative memory engages in the integration of relevant information for comprehension in the human cognition system. In this work, we seek to improve alignment between language models and human brain while processing speech information by integrating associative memory. After verifying the... | Congchi Yin, Yongpeng Zhang, Xuyun Wen, Piji Li |  |
| 156 |  |  [Towards Reliable Large Audio Language Model](https://aclanthology.org/2025.findings-acl.56/) |  | 0 | Recent advancements in large audio language models (LALMs) have demonstrated impressive results and promising prospects in universal understanding and reasoning across speech, music, and general sound. However, these models still lack the ability to recognize their knowledge boundaries and refuse... | Ziyang Ma, Xiquan Li, Yakun Song, Wenxi Chen, Chenpeng Du, Jian Wu, Yuanzhe Chen, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen |  |
| 157 |  |  [Large Vocabulary Size Improves Large Language Models](https://aclanthology.org/2025.findings-acl.57/) |  | 0 | This paper empirically investigates the relationship between subword vocabulary size and the performance of large language models (LLMs) to provide insights on how to define the vocabulary size. Experimental results show that larger vocabulary sizes lead to better performance in LLMs. Moreover, we... | Sho Takase, Ryokan Ri, Shun Kiyono, Takuya Kato |  |
| 158 |  |  [MUSE: A Multimodal Conversational Recommendation Dataset with Scenario-Grounded User Profiles](https://aclanthology.org/2025.findings-acl.58/) |  | 0 | Current conversational recommendation systems focus predominantly on text. However, real-world recommendation settings are generally multimodal, causing a significant gap between existing research and practical applications. To address this issue, we propose Muse, the first multimodal... | Zihan Wang, Xiaocui Yang, Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang |  |
| 159 |  |  [Machine Translation Models are Zero-Shot Detectors of Translation Direction](https://aclanthology.org/2025.findings-acl.59/) |  | 0 | Detecting the translation direction of parallel text has applications for machine translation training and evaluation, but also has forensic applications, such as resolving plagiarism or forgery allegations. In this work, we explore an unsupervised approach to translation direction detection based... | Michelle Wastl, Jannis Vamvas, Rico Sennrich |  |
| 160 |  |  [Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination](https://aclanthology.org/2025.findings-acl.60/) |  | 0 | The growth in prominence of large language models (LLMs) in everyday life can be largely attributed to their generative abilities, yet some of this is also owed to the risks and costs associated with their use. On one front is their tendency to hallucinate false or misleading information, limiting... | Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar |  |
| 161 |  |  [GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation](https://aclanthology.org/2025.findings-acl.61/) |  | 0 | Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information. While recent LLMs are typically fine-tuned with tool usage examples during supervised fine-tuning (SFT), questions remain about their... | Jie He, Jennifer Neville, Mengting Wan, Longqi Yang, Hui Liu, Xiaofeng Xu, Xia Song, Jeff Z. Pan, Pei Zhou |  |
| 162 |  |  [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://aclanthology.org/2025.findings-acl.62/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable proficiency across a variety of complex tasks. One significant application of LLMs is in tackling software engineering challenges, particularly in resolving real-world tasks on GitHub by fixing code based on the issues reported by the users.... | Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen |  |
| 163 |  |  [GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models](https://aclanthology.org/2025.findings-acl.63/) |  | 0 | Vision-Language Models (VLMs) have made rapid progress in reasoning across visual and textual data. While VLMs perform well on vision tasks that they are trained on, our results highlight key challenges in abstract pattern recognition. We present GlyphPattern, a 954 item dataset that pairs 318... | Zixuan Wu, Yoolim Kim, Carolyn Jane Anderson |  |
| 164 |  |  [FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation](https://aclanthology.org/2025.findings-acl.64/) |  | 0 | Counterfactual examples are widely used in natural language processing (NLP) as valuable data to improve models, and in explainable artificial intelligence (XAI) to understand model behavior. The automated generation of counterfactual examples remains a challenging task even for large language... | Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe VillaArenas, Sebastian Möller, Vera Schmitt |  |
| 165 |  |  [From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning Method for LLMs](https://aclanthology.org/2025.findings-acl.65/) |  | 0 | Large language models (LLMs) exhibit excellent performance in natural language processing (NLP), but remain highly sensitive to the quality of input queries, especially when these queries contain misleading or inaccurate information. Existing methods focus on correcting the output, but they often... | Guocong Li, Weize Liu, Yihang Wu, Ping Wang, Shuaihan Huang, Hongxia Xu, Jian Wu |  |
| 166 |  |  [Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models](https://aclanthology.org/2025.findings-acl.66/) |  | 0 | Although large language models (LLMs) achieve effective safety alignment at the time of release, they still face various safety challenges. A key issue is that fine-tuning often compromises the safety alignment of LLMs. To address this issue, we propose a method named IRR (Identify, Remove, and... | Di Wu, Xin Lu, Yanyan Zhao, Bing Qin |  |
| 167 |  |  [Nuclear Deployed!: Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents](https://aclanthology.org/2025.findings-acl.67/) |  | 0 | Large language models (LLMs) are evolving into autonomous decision-makers, raising concerns about catastrophic risks in high-stakes scenarios, particularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains. Based on the insight that such risks can originate from trade-offs between... | Rongwu Xu, Xiaojian Li, Shuo Chen, Wei Xu |  |
| 168 |  |  [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://aclanthology.org/2025.findings-acl.68/) |  | 0 | With the rapid development of Large Language Models (LLMs), Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant attention, which aims to achieve efficient fine-tuning of LLMs with fewer parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA) introduces low-rank... | Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei |  |
| 169 |  |  [Lunar Twins: We Choose to Go to the Moon with Large Language Models](https://aclanthology.org/2025.findings-acl.69/) |  | 0 | In recent years, the rapid advancement of large language models (LLMs) has significantly reshaped the landscape of scientific research. While LLMs have achieved notable success across various domains, their application in specialized fields such as lunar exploration remains underdeveloped, and... | XinYu Xiao, Yalei Liu, Xiangyu Liu, Zengrui Li, Erwei Yin, Qianchen Xia |  |
| 170 |  |  [SPHERE: An Evaluation Card for Human-AI Systems](https://aclanthology.org/2025.findings-acl.70/) |  | 0 | In the era of Large Language Models (LLMs), establishing effective evaluation methods and standards for diverse human-AI interaction systems is increasingly challenging. To encourage more transparent documentation and facilitate discussion on human-AI system evaluation design options, we present an... | Dora Zhao, Qianou Ma, Xinran Zhao, Chenglei Si, Chenyang Yang, Ryan Louie, Ehud Reiter, Diyi Yang, Tongshuang Wu |  |
| 171 |  |  [Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling](https://aclanthology.org/2025.findings-acl.71/) |  | 0 | Conversational assistants are increasingly popular across diverse real-world applications, highlighting the need for advanced multimodal speech modeling. Speech, as a natural mode of communication, encodes rich user-specific characteristics such as speaking rate and pitch, making it critical for... | Maximillian Chen, Ruoxi Sun, Sercan Ö. Arik |  |
| 172 |  |  [Question-Aware Knowledge Graph Prompting for Enhancing Large Language Models](https://aclanthology.org/2025.findings-acl.72/) |  | 0 | Large Language Models (LLMs) often struggle with tasks requiring external knowledge, such as knowledge-intensive Multiple Choice Question Answering (MCQA). Integrating Knowledge Graphs (KGs) can enhance reasoning; however, existing methods typically demand costly fine-tuning or retrieve noisy KG... | Haochen Liu, Song Wang, Chen Chen, Jundong Li |  |
| 173 |  |  [UQ-Merge: Uncertainty Guided Multimodal Large Language Model Merging](https://aclanthology.org/2025.findings-acl.73/) |  | 0 | Multimodal Large Language Models (MLLMs) have gained increasing popularity as a promising framework for leveraging the strong language reasoning capabilities in the vision-language domain. Given a wide range of MLLMs, model merging potentially offers a cheap way to aggregate their diverse knowledge... | Huaizhi Qu, Xinyu Zhao, Jie Peng, Kwonjoon Lee, Behzad Dariush, Tianlong Chen |  |
| 174 |  |  [AQuAECHR: Attributed Question Answering for European Court of Human Rights](https://aclanthology.org/2025.findings-acl.74/) |  | 0 | LLMs have become prevalent tools for information seeking across various fields, including law. However, their generated responses often suffer from hallucinations, hindering their widespread adoption in high stakes domains such as law, which can potentially mislead experts and propagate societal... | Korbinian Q. Weidinger, T. Y. S. S. Santosh, Oana Ichim, Matthias Grabmair |  |
| 175 |  |  [Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation](https://aclanthology.org/2025.findings-acl.75/) |  | 0 | The success of building textless speech-to-speech translation (S2ST) models has attracted much attention. However, S2ST still faces two main challenges: 1) extracting linguistic features for various speech signals, called cross-modal (CM), and 2) learning alignment of difference languages in long... | Yuhao Zhang, Xiangnan Ma, Kaiqi Kou, Peizhuo Liu, Weiqiao Shan, Benyou Wang, Tong Xiao, Yuxin Huang, Zhengtao Yu, JingBo Zhu |  |
| 176 |  |  [Ponder & Press: Advancing Visual GUI Agent towards General Computer Control](https://aclanthology.org/2025.findings-acl.76/) |  | 0 | Most existing GUI agents typically depend on non-vision inputs like HTML source code or accessibility trees, limiting flexibility across diverse software environments and platforms. Current multimodal large language models (MLLMs), though excel at using vision to ground real-world objects, often... | Yiqin Wang, Haoji Zhang, Jingqi Tian, Yansong Tang |  |
| 177 |  |  [LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models](https://aclanthology.org/2025.findings-acl.77/) |  | 0 | Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical reasoning and critical for practical LLM agents and... | Jiayi Gui, Yiming Liu, Jiale Cheng, Xiaotao Gu, Xiao Liu, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang |  |
| 178 |  |  [LLM-Based Multi-Agent Systems are Scalable Graph Generative Models](https://aclanthology.org/2025.findings-acl.78/) |  | 0 | The structural properties of naturally arising social graphs are extensively studied to understand their evolution. Prior approaches for modeling network dynamics typically rely on rule-based models, which lack realism and generalizability, or deep learning-based models, which require large-scale... | Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Xu Chen, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding |  |
| 179 |  |  [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://aclanthology.org/2025.findings-acl.79/) |  | 0 | Anomaly detection (AD) is an important machine learning task with many real-world uses, including fraud detection, medical diagnosis, and industrial monitoring. Within natural language processing (NLP), AD helps detect issues like spam, misinformation, and unusual user activity. Although large... | Tiankai Yang, Yi Nian, Li Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan A. Rossi, Kaize Ding, Xia Hu, Yue Zhao |  |
| 180 |  |  [RTADev: Intention Aligned Multi-Agent Framework for Software Development](https://aclanthology.org/2025.findings-acl.80/) |  | 0 | LLM-based Multi-agent frameworks have shown a great potential in solving real-world software development tasks, where the agents of different roles can communicate much more efficiently than humans. Despite their efficiency, LLM-based agents can hardly fully understand each other, which frequently... | Jie Liu, Guohua Wang, Ronghui Yang, Jiajie Zeng, Mengchen Zhao, Yi Cai |  |
| 181 |  |  [TACO-RL: Task Aware Prompt Compression Optimization with Reinforcement Learning](https://aclanthology.org/2025.findings-acl.81/) |  | 0 | The increasing prevalence of large language models (LLMs) such as GPT-4 in various applications has led to a surge in the size of prompts required for optimal performance, leading to challenges in computational efficiency. Prompt compression aims to reduce the inference cost by minimizing input... | Shivam Shandilya, Menglin Xia, Supriyo Ghosh, Huiqiang Jiang, Jue Zhang, Qianhui Wu, Victor Rühle, Saravan Rajmohan |  |
| 182 |  |  [A Character-Centric Creative Story Generation via Imagination](https://aclanthology.org/2025.findings-acl.82/) |  | 0 | Creative story generation has long been a goal of NLP research. While existing methodologies have aimed to generate long and coherent stories, they fall significantly short of human capabilities in terms of diversity and character depth. To address this, we introduce a novel story generation... | Kyeongman Park, Minbeom Kim, Kyomin Jung |  |
| 183 |  |  [Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model](https://aclanthology.org/2025.findings-acl.83/) |  | 0 | Despite achieving remarkable performance, machine translation (MT) research remains underexplored in terms of translating cultural elements in languages, such as idioms, proverbs, and colloquial expressions. This paper investigates the capability of state-of-the-art neural machine translation (NMT)... | Minghan Wang, VietThanh Pham, Farhad Moghimifar, ThuyTrang Vu |  |
| 184 |  |  [Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration](https://aclanthology.org/2025.findings-acl.84/) |  | 0 | Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world. Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans... | Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Zhen Wang, Xuelong Li |  |
| 185 |  |  [UAQFact: Evaluating Factual Knowledge Utilization of LLMs on Unanswerable Questions](https://aclanthology.org/2025.findings-acl.85/) |  | 0 | Handling unanswerable questions (UAQ) is crucial for LLMs, as it helps prevent misleading responses in complex situations. While previous studies have built several datasets to assess LLMs’ performance on UAQ, these datasets lack factual knowledge support, which limits the evaluation of LLMs’... | Chuanyuan Tan, Wenbiao Shao, Hao Xiong, Tong Zhu, Zhenhua Liu, Kai Shi, Wenliang Chen |  |
| 186 |  |  [Exploring Knowledge Filtering for Retrieval-Augmented Discriminative Tasks](https://aclanthology.org/2025.findings-acl.86/) |  | 0 | Retrieval-augmented methods have achieved remarkable advancements in alleviating the hallucination of large language models.Nevertheless, the introduction of external knowledge does not always lead to the expected improvement in model performance, as irrelevant or harmful information present in the... | Minjie Qiang, Zhongqing Wang, Xiaoyi Bao, Haoyuan Ma, Shoushan Li, Guodong Zhou |  |
| 187 |  |  [Group then Scale: Dynamic Mixture-of-Experts Multilingual Language Model](https://aclanthology.org/2025.findings-acl.87/) |  | 0 | The curse of multilinguality phenomenon is a fundamental problem of multilingual Large Language Models (LLMs), where the competition between massive languages results in inferior performance. It mainly comes from limited capacity and negative transfer between dissimilar languages. To address this... | Chong Li, Yingzhuo Deng, Jiajun Zhang, Chengqing Zong |  |
| 188 |  |  [Beyond Verbal Cues: Emotional Contagion Graph Network for Causal Emotion Entailment](https://aclanthology.org/2025.findings-acl.88/) |  | 0 | Emotions are fundamental to conversational understanding. While significant advancements have been achieved in conversational emotion recognition and emotional response generation, recognizing the causes of eliciting emotions is less explored. Previous studies have primarily focused on identifying... | Fangxu Yu, Junjie Guo, Zhen Wu, Xinyu Dai |  |
| 189 |  |  [Critic-CoT: Boosting the Reasoning Abilities of Large Language Model via Chain-of-Thought Critic](https://aclanthology.org/2025.findings-acl.89/) |  | 0 | Self-critic has become a crucial mechanism for enhancing the reasoning performance of LLMs. However, current approaches mainly involve basic prompts for intuitive instance-level feedback, which resembles System-1 processes and limits the reasoning capabilities. Moreover, there is a lack of in-depth... | Xin Zheng, Jie Lou, Boxi Cao, Xueru Wen, Yuqiu Ji, Hongyu Lin, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun |  |
| 190 |  |  [Systematic Generalization in Language Models Scales with Information Entropy](https://aclanthology.org/2025.findings-acl.90/) |  | 0 | Systematic generalization remains challenging for current language models, which are known to be both sensitive to semantically similar permutations of the input and to struggle with known concepts presented in novel contexts. Although benchmarks exist for assessing compositional behavior, it is... | Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon |  |
| 191 |  |  [The Inverse Scaling Effect of Pre-Trained Language Model Surprisal Is Not Due to Data Leakage](https://aclanthology.org/2025.findings-acl.91/) |  | 0 | In psycholinguistic modeling, surprisal from larger pre-trained language models has been shown to be a poorer predictor of naturalistic human reading times. However, it has been speculated that this may be due to data leakage that caused language models to see the text stimuli during training. This... | ByungDoh Oh, Hongao Zhu, William Schuler |  |
| 192 |  |  [Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries](https://aclanthology.org/2025.findings-acl.92/) |  | 0 | Information retrieval plays a crucial role in resource localization. Current dense retrievers retrieve the relevant documents within a corpus via embedding similarities, which compute similarities between dense vectors mainly depending on word co-occurrence between queries and documents, but... | Ganlin Xu, Zhoujia Zhang, Wangyi Mei, Jiaqing Liang, Weijia Lu, Xiaodong Zhang, Zhifei Yang, Xiaofeng Ma, Yanghua Xiao, Deqing Yang |  |
| 193 |  |  ['No' Matters: Out-of-Distribution Detection in Multimodality Multi-Turn Interactive Dialogue Download PDF](https://aclanthology.org/2025.findings-acl.93/) |  | 0 | Out-of-distribution (OOD) detection in multimodal contexts is essential for identifying deviations in different modalities, particularly for interactive dialogue systems in real-life interactions, where the systems are usually infeasible to deploy large language models (LLMs) to generate dialogue... | Rena Wei Gao, Xuetong Wu, Siwen Luo, Caren Han, Feng Liu |  |
| 194 |  |  [Event Pattern-Instance Graph: A Multi-Round Role Representation Learning Strategy for Document-Level Event Argument Extraction](https://aclanthology.org/2025.findings-acl.94/) |  | 0 | For document-level event argument extraction, existing role-based span selection strategies suffer from several limitations: (1) ignoring interrelations among arguments within an event instance; (2) relying on pre-trained language models to capture role semantics at either the event pattern or... | Qizhi Wan, Liu Tao, Changxuan Wan, Rong Hu, Keli Xiao, Yuxin Shuai |  |
| 195 |  |  [EXECUTE: A Multilingual Benchmark for LLM Token Understanding](https://aclanthology.org/2025.findings-acl.95/) |  | 0 | The CUTE benchmark showed that LLMs struggle with character understanding in English. We extend it to more languages with diverse scripts and writing systems, introducing EXECUTE. Our simplified framework allows easy expansion to any language. Tests across multiple LLMs reveal that challenges in... | Lukas Edman, Helmut Schmid, Alexander Fraser |  |
| 196 |  |  [Explainable Hallucination through Natural Language Inference Mapping](https://aclanthology.org/2025.findings-acl.96/) |  | 0 | Large language models (LLMs) often generate hallucinated content, making it crucial to identify and quantify inconsistencies in their outputs. We introduce HaluMap, a post-hoc framework that detects hallucinations by mapping entailment and contradiction relations between source inputs and generated... | WeiFan Chen, Zhixue Zhao, Akbar Karimi, Lucie Flek |  |
| 197 |  |  [HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.97/) |  | 0 | Retrieval-Augmented Generation (RAG) systems often struggle with imperfect retrieval, as traditional retrievers focus on lexical or semantic similarity rather than logical relevance. To address this, we propose HopRAG, a novel RAG framework that augments retrieval with logical reasoning through... | Hao Liu, Zhengren Wang, Xi Chen, Zhiyu Li, Feiyu Xiong, Qinhan Yu, Wentao Zhang |  |
| 198 |  |  [Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion](https://aclanthology.org/2025.findings-acl.98/) |  | 0 | The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either... | Markus Frohmann, Gabriel MeseguerBrocal, Markus Schedl, Elena V. Epure |  |
| 199 |  |  [Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models](https://aclanthology.org/2025.findings-acl.99/) |  | 0 | Large Vision Language Models (LVLMs) demonstrate strong capabilities in visual understanding and description, yet often suffer from hallucinations, attributing incorrect or misleading features to images. We observe that LVLMs disproportionately focus on a small subset of image tokens—termed blind... | Sangmin Woo, Donguk Kim, Jaehyuk Jang, Yubin Choi, Changick Kim |  |
| 200 |  |  [SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](https://aclanthology.org/2025.findings-acl.100/) |  | 0 | Large language models (LLMs) have made significant advancements across various tasks, but their safety alignment remains a major concern. Exploring jailbreak prompts can expose LLMs’ vulnerabilities and guide efforts to secure them. Existing methods primarily design sophisticated instructions for... | Xiaoning Dong, Wenbo Hu, Wei Xu, Tianxing He |  |
| 201 |  |  [Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis](https://aclanthology.org/2025.findings-acl.101/) |  | 0 | Conversational Speech Synthesis (CSS) aims to align synthesized speech with the emotional and stylistic context of user-agent interactions to achieve empathy. Current generative CSS models face interpretability limitations due to insufficient emotional perception and redundant discrete speech... | Yifan Hu, Rui Liu, Yi Ren, Xiang Yin, Haizhou Li |  |
| 202 |  |  [Parameter-Efficient Fine-Tuning via Circular Convolution](https://aclanthology.org/2025.findings-acl.102/) |  | 0 | Low-Rank Adaptation (LoRA) has gained popularity for fine-tuning large foundation models, leveraging low-rank matrices \mathbf A and \mathbf B to represent weight changes (i.e., 𝛥 \mathbf W = \mathbf B \mathbf A). This method reduces trainable parameters and mitigates heavy memory consumption... | Aochuan Chen, Jiashun Cheng, Zijing Liu, Ziqi Gao, Fugee Tsung, Yu Li, Jia Li |  |
| 203 |  |  [Alleviating Hallucinations in Large Language Models via Truthfulness-driven Rank-adaptive LoRA](https://aclanthology.org/2025.findings-acl.103/) |  | 0 | Improving the truthfulness of LLMs to alleviate hallucinations has become critical for promoting the practical deployment of LLMs. Current fine-tuning-based methods ignore the intrinsic discrepancy in the truthfulness correlations across LLM internal modules, and instead treat them equally, which... | Jiahao Li, Zhendong Mao, Quan Wang |  |
| 204 |  |  [ScEdit: Script-based Assessment of Knowledge Editing](https://aclanthology.org/2025.findings-acl.104/) |  | 0 | Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editing methods achieve exceptionally high scores, sometimes nearing perfection. However, few studies integrate KE into real-world application scenarios... | Xinye Li, Zunwen Zheng, Qian Zhang, Dekai Zhuang, Jiabao Kang, Liyan Xu, Qingbin Liu, Xi Chen, Zhiying Tu, Dianhui Chu, Dianbo Sui |  |
| 205 |  |  [SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://aclanthology.org/2025.findings-acl.105/) |  | 0 | Deploying large language models (LLMs) in real-world applications requires robust safety guard models to detect and block harmful user prompts. While large safety guard models achieve strong performance, their computational cost is substantial. To mitigate this, smaller distilled models are used,... | Seanie Lee, Dong Bok Lee, Dominik Wagner, Minki Kang, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang |  |
| 206 |  |  [Moderation Matters: Measuring Conversational Moderation Impact in English as a Second Language Group Discussion](https://aclanthology.org/2025.findings-acl.106/) |  | 0 | English as a Second Language (ESL) speakers often struggle to engage in group discussions due to language barriers. While moderators can facilitate participation, few studies assess conversational engagement and evaluate moderation effectiveness. To address this gap, we develop a dataset comprising... | Rena Wei Gao, MingBin Chen, Lea Frermann, Jey Han Lau |  |
| 207 |  |  [Measuring Bias and Agreement in Large Language Model Presupposition Judgments](https://aclanthology.org/2025.findings-acl.107/) |  | 0 | Identifying linguistic bias in text demands the identification not only of explicitly asserted content but also of implicit content including presuppositions. Large language models (LLMs) offer a promising automated approach to detecting presuppositions, yet the extent to which their judgments... | Katherine Atwell, Mandy Simons, Malihe Alikhani |  |
| 208 |  |  [Harnessing PDF Data for Improving Japanese Large Multimodal Models](https://aclanthology.org/2025.findings-acl.108/) |  | 0 | Large Multimodal Models (LMMs) have demonstrated strong performance in English, but their effectiveness in Japanese remains limited due to the lack of high-quality training data. Current Japanese LMMs often rely on translated English datasets, restricting their ability to capture Japan-specific... | Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa |  |
| 209 |  |  [EnerGIZAr: Leveraging GIZA++ for Effective Tokenizer Initialization](https://aclanthology.org/2025.findings-acl.109/) |  | 0 | Continual pre-training has long been considered the default strategy for adapting models to non-English languages, but struggles with initializing new embeddings, particularly for non-Latin scripts. In this work, we propose EnerGIZAr, a novel methodology that improves continual pre-training by... | Pranaydeep Singh, Eneko Agirre, Gorka Azkune, Orphée De Clercq, Els Lefever |  |
| 210 |  |  [AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents](https://aclanthology.org/2025.findings-acl.110/) |  | 0 | AI agents have drawn increasing attention mostly on their ability to perceive environments, understand tasks, and autonomously achieve goals. To advance research on AI agents in mobile scenarios, we introduce the Android Multi-annotation EXpo (AMEX), a comprehensive, large-scale dataset designed... | Yuxiang Chai, Siyuan Huang, Yazhe Niu, Han Xiao, Liang Liu, Guozhi Wang, Dingyu Zhang, Shuai Ren, Hongsheng Li |  |
| 211 |  |  [Drop Dropout on Single Epoch Language Model Pretraining](https://aclanthology.org/2025.findings-acl.111/) |  | 0 | Originally, dropout was seen as a breakthrough regularization technique that reduced overfitting and improved performance in almost all applications of deep learning by reducing overfitting. Yet, single-epoch pretraining tasks common to modern LLMs yield minimal overfitting, leading to dropout not... | Houjun Liu, John Bauer, Christopher D. Manning |  |
| 212 |  |  [Robust and Minimally Invasive Watermarking for EaaS](https://aclanthology.org/2025.findings-acl.112/) |  | 0 | Embeddings as a Service (EaaS) is emerging as a crucial role in AI applications. Unfortunately, EaaS is vulnerable to model extraction attacks, highlighting the urgent need for copyright protection. Although some preliminary works propose applying embedding watermarks to protect EaaS, recent... | Zongqi Wang, Baoyuan Wu, Jingyuan Deng, Yujiu Yang |  |
| 213 |  |  [Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text](https://aclanthology.org/2025.findings-acl.113/) |  | 0 | Masked language modeling has become a widely adopted unsupervised technique to pre-train large language models (LLMs). However, the process of selecting tokens for masking is random, and the percentage of masked tokens is typically fixed for the entire training process. In this paper, we propose to... | Andrei Jarca, FlorinelAlin Croitoru, Radu Tudor Ionescu |  |
| 214 |  |  [CARMO: Dynamic Criteria Generation for Context Aware Reward Modelling](https://aclanthology.org/2025.findings-acl.114/) |  | 0 | Reward modeling in large language models is known to be susceptible to reward hacking, causing models to latch onto superficial features such as the tendency to generate lists or unnecessarily long responses. In RLHF, and more generally during post-training, flawed reward signals often lead to... | Taneesh Gupta, Shivam Shandilya, Xuchao Zhang, Rahul Madhavan, Supriyo Ghosh, Chetan Bansal, Huaxiu Yao, Saravan Rajmohan |  |
| 215 |  |  [SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training](https://aclanthology.org/2025.findings-acl.115/) |  | 0 | Recent advancements highlight the potential of end-to-end real-time spoken dialogue systems, showcasing their low latency and high quality. In this paper, we introduce SLAM-Omni, a timbre-controllable, end-to-end voice interaction system with single-stage training. SLAM-Omni achieves zero-shot... | Wenxi Chen, Ziyang Ma, Ruiqi Yan, Yuzhe Liang, Xiquan Li, Ruiyang Xu, Zhikang Niu, Yanqiao Zhu, Yifan Yang, Zhanxun Liu, Kai Yu, Yuxuan Hu, Jinyu Li, Yan Lu, Shujie Liu, Xie Chen |  |
| 216 |  |  [C²LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation](https://aclanthology.org/2025.findings-acl.116/) |  | 0 | Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data contamination due to the lack of access to proprietary training data. To address this issue, we present C2LEVA, a comprehensive bilingual benchmark... | Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang |  |
| 217 |  |  [Texts or Images? A Fine-grained Analysis on the Effectiveness of Input Representations and Models for Table Question Answering](https://aclanthology.org/2025.findings-acl.117/) |  | 0 | In table question answering (TQA), tables are encoded as either texts or images. Prior work suggests that passing images of tables to multi-modal large language models (MLLMs) performs comparably to using textual input with large language models (LLMs). However, the lack of controlled setups limits... | Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich |  |
| 218 |  |  [Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training](https://aclanthology.org/2025.findings-acl.118/) |  | 0 | Effective communication training is essential to preparing nurses for high-quality patient care. While standardized patient (SP) simulations provide valuable experiential learning, they are often costly and inflexible. Virtual patient (VP) systems offer a scalable alternative, but most fail to... | Keyeun Lee, Seolhee Lee, Esther Hehsun Kim, Yena Ko, Jinsu Eun, Dahee Kim, Hyewon Cho, Haiyi Zhu, Robert E. Kraut, Eunyoung Suh, Eunmee Kim, Hajin Lim |  |
| 219 |  |  [Enhancing Multimodal Unified Representations for Cross Modal Generalization](https://aclanthology.org/2025.findings-acl.119/) |  | 0 | To enhance the interpretability of multimodal unified representations, many studies have focused on discrete unified representations. These efforts typically start with contrastive learning and gradually extend to the disentanglement of modal information, achieving solid multimodal discrete unified... | Hai Huang, Yan Xia, Shengpeng Ji, Shulei Wang, Hanting Wang, Minghui Fang, Jieming Zhu, Zhenhua Dong, Sashuai Zhou, Zhou Zhao |  |
| 220 |  |  [Domain Regeneration: How well do LLMs match syntactic properties of text domains?](https://aclanthology.org/2025.findings-acl.120/) |  | 0 | Recent improvement in large language model performance have, in all likelihood, been accompanied by improvement in how well they can approximate the distribution of their training data. In this work, we explore the following question: which properties of text domains do LLMs faithfully approximate,... | Da Ju, Hagen Blix, Adina Williams |  |
| 221 |  |  [Structural Deep Encoding for Table Question Answering](https://aclanthology.org/2025.findings-acl.121/) |  | 0 | Although Transformers-based architectures excel at processing textual information, their naive adaptation for tabular data often involves flattening the table structure. This simplification can lead to the loss of essential inter-dependencies between rows, columns, and cells, while also posing... | Raphaël Mouravieff, Benjamin Piwowarski, Sylvain Lamprier |  |
| 222 |  |  [MPL: Multiple Programming Languages with Large Language Models for Information Extraction](https://aclanthology.org/2025.findings-acl.122/) |  | 0 | Recent research in information extraction (IE) focuses on utilizing code-style inputs to enhance structured output generation. The intuition behind this is that the programming languages (PLs) inherently exhibit greater structural organization than natural languages (NLs). This structural advantage... | Bo Li, Gexiang Fang, Wei Ye, Zhenghua Xu, Jinglei Zhang, Hao Cheng, Shikun Zhang |  |
| 223 |  |  [Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering](https://aclanthology.org/2025.findings-acl.123/) |  | 0 | Although large language models (LLMs) have demonstrated remarkable reasoning capabilities, they still face challenges in knowledge-intensive multi-hop reasoning. Recent work explores iterative retrieval to address complex problems. However, the absence of intermediate guidance often leads to... | Zheng Chu, Huiming Fan, Jingchang Chen, Qianyu Wang, Mingda Yang, Jiafeng Liang, Zhongjie Wang, Hao Li, Guo Tang, Ming Liu, Bing Qin |  |
| 224 |  |  [Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions](https://aclanthology.org/2025.findings-acl.124/) |  | 0 | Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have demonstrated considerable success across diverse tasks, including multiple-choice questions (MCQs). However, these models exhibit a positional bias, particularly an even worse “anchored bias” in the GPT-2 family, where they... | Ruizhe Li, Yanjun Gao |  |
| 225 |  |  [Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](https://aclanthology.org/2025.findings-acl.125/) |  | 0 | Generative Error Correction (GEC) has emerged as a powerful post-processing method to boost the performance of Automatic Speech Recognition (ASR) systems. In this paper, we first show that GEC models struggle to generalize beyond the specific types of errors encountered during training, limiting... | Sreyan Ghosh, Mohammad Sadegh Rasooli, Michael Levit, Peidong Wang, Jian Xue, Dinesh Manocha, Jinyu Li |  |
| 226 |  |  [LTRAG: Enhancing Autoformalization and Self-refinement for Logical Reasoning with Thought-Guided RAG](https://aclanthology.org/2025.findings-acl.126/) |  | 0 | Logical reasoning is fundamental to intelligent systems. Large language models (LLMs) have demonstrated promise in natural language (NL) reasoning, especially with techniques like chain-of-thought (CoT) prompting. Neuro-symbolic methods like Logic-LM and LINC further enhance performance on... | Ruikang Hu, Shaoyu Lin, Yeliang Xiu, Yongmei Liu |  |
| 227 |  |  [Eta-WavLM: Efficient Speaker Identity Removal in Self-Supervised Speech Representations Using a Simple Linear Equation](https://aclanthology.org/2025.findings-acl.127/) |  | 0 | Self-supervised learning (SSL) has reduced the reliance on expensive labeling in speech technologies by learning meaningful representations from unannotated data. Since most SSL-based downstream tasks prioritize content information in speech, ideal representations should disentangle content from... | Giuseppe Ruggiero, Matteo Testa, Jurgen Van de Walle, Luigi Di Caro |  |
| 228 |  |  [MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning](https://aclanthology.org/2025.findings-acl.128/) |  | 0 | Natural language image-caption datasets, widely used for training Large Multimodal Models, mainly focus on natural scenarios and overlook the intricate details of mathematical figures that are critical for problem-solving, hindering the advancement of current LMMs in multimodal mathematical... | Ke Wang, Junting Pan, Linda Wei, Aojun Zhou, Weikang Shi, Zimu Lu, Han Xiao, Yunqiao Yang, Houxing Ren, Mingjie Zhan, Hongsheng Li |  |
| 229 |  |  [MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models](https://aclanthology.org/2025.findings-acl.129/) |  | 0 | The tendency of Large Language Models (LLMs) to generate hallucinations raises concerns regarding their reliability. Therefore, confidence estimations indicating the extent of trustworthiness of the generations become essential. However, current LLM confidence estimations in languages other than... | Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Wenxuan Zhang, KamFai Wong |  |
| 230 |  |  [COMPKE: Complex Question Answering under Knowledge Editing](https://aclanthology.org/2025.findings-acl.130/) |  | 0 | Knowledge Editing-Efficiently modifying the knowledge in large language models has gathered great attention. Current benchmarks primarily use multi-hop question answering to assess and analyze newly injected or updated knowledge. However, we argue that these benchmarks fail to effectively evaluate... | Keyuan Cheng, Zijian Kan, Zhuoran Zhang, Muhammad Asif Ali, Lijie Hu, Di Wang |  |
| 231 |  |  [RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning](https://aclanthology.org/2025.findings-acl.131/) |  | 0 | Large Language Models (LLMs) have demonstrated strong capabilities across various domains, with recent advancements in challenging reasoning tasks such as mathematics and programming. However, solving reasoning tasks often requires an LLM to generate long sequences, incurring O(N) time and memory... | Junhao Hu, Wenrui Huang, Weidong Wang, Zhenwen Li, Tiancheng Hu, Zhixia Liu, Xusheng Chen, Tao Xie, Yizhou Shan |  |
| 232 |  |  [One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models](https://aclanthology.org/2025.findings-acl.132/) |  | 0 | Existing pruning methods for large language models (LLMs) focus on achieving high compression rates while maintaining model performance. Although these methods have demonstrated satisfactory performance in handling a single user’s compression request, their processing time increases linearly with... | Rongguang Ye, Ming Tang |  |
| 233 |  |  [CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages](https://aclanthology.org/2025.findings-acl.133/) |  | 0 | CLaMP 3 is a unified framework developed to address challenges of cross-modal and cross-lingual generalization in music information retrieval. Using contrastive learning, it aligns all major music modalities–including sheet music, performance signals, and audio recordings–with multilingual text in... | Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun |  |
| 234 |  |  [PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts](https://aclanthology.org/2025.findings-acl.134/) |  | 0 | Process-driven dialogue systems, which operate under strict predefined process constraints, are essential in customer service and equipment maintenance scenarios. Although Large Language Models (LLMs) have shown remarkable progress in dialogue and reasoning, they still struggle to solve these... | Ming Zhang, Yuhui Wang, Yujiong Shen, Tingyi Yang, Changhao Jiang, Yilong Wu, Shihan Dou, Qinhao Chen, Zhiheng Xi, Zhihao Zhang, Yi Dong, Zhen Wang, Zhihui Fei, Mingyang Wan, Tao Liang, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 235 |  |  [Listening to Patients: Detecting and Mitigating Patient Misreport in Medical Dialogue System](https://aclanthology.org/2025.findings-acl.135/) |  | 0 | Medical Dialogue Systems (MDSs) have emerged as promising tools for automated healthcare support through patient-agent interactions. Previous efforts typically relied on an idealized assumption — patients can accurately report symptoms aligned with their actual health conditions. However, in... | Lang Qin, Yao Zhang, Hongru Liang, Adam Jatowt, Zhenglu Yang |  |
| 236 |  |  [Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm](https://aclanthology.org/2025.findings-acl.136/) |  | 0 | Cognitive tasks originally developed for humans are now increasingly used to study language models. While applying these tasks is often straightforward, interpreting their results can be challenging. In particular, when a model underperforms, it is often unclear whether this results from a... | Xiaoyang Hu, Richard L. Lewis |  |
| 237 |  |  [Graph-guided Cross-composition Feature Disentanglement for Compositional Zero-shot Learning](https://aclanthology.org/2025.findings-acl.137/) |  | 0 | Disentanglement of visual features of primitives (i.e., attributes and objects) has shown exceptional results in Compositional Zero-shot Learning (CZSL). However, due to the feature divergence of an attribute (resp. object) when combined with different objects (resp. attributes), it is challenging... | Yuxia Geng, Runkai Zhu, Jiaoyan Chen, Jintai Chen, Xiang Chen, Zhuo Chen, Shuofei Qiao, Yuxiang Wang, Xiaoliang Xu, ShengJun Huang |  |
| 238 |  |  [Training Long-Context LLMs Efficiently via Chunk-wise Optimization](https://aclanthology.org/2025.findings-acl.138/) |  | 0 | While long-context large language models (LLMs) exhibit remarkable document processing capabilities, their prohibitively high training costs often hinder customized applications. To mitigate this issue, we propose __Sequential Chunk-wise Optimization (SeCO)__, a memory-efficient training paradigm... | Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji |  |
| 239 |  |  [Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps](https://aclanthology.org/2025.findings-acl.139/) |  | 0 | Low-Rank Adaptation (LoRA) has emerged as a prominent technique for fine-tuning large foundation models. Despite its successes, the substantial parameter redundancy, which limits the capacity and efficiency of LoRA, has been recognized as a bottleneck. In this work, we systematically investigate... | Jiashun Cheng, Aochuan Chen, Nuo Chen, Ziqi Gao, Yuhan Li, Jia Li, Fugee Tsung |  |
| 240 |  |  [CODEMENV: Benchmarking Large Language Models on Code Migration](https://aclanthology.org/2025.findings-acl.140/) |  | 0 | Large language models (LLMs) have demonstrated remarkable proficiency in handling a wide range of tasks within the software engineering domain, but their ability to perform code migration—adapting code to different environments—remains underexplored. In this work, we propose a novel benchmark, :... | Keyuan Cheng, Xudong Shen, Yihao Yang, TengyueWang TengyueWang, Yang Cao, Muhammad Asif Ali, Hanbin Wang, Lijie Hu, Di Wang |  |
| 241 |  |  [A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs](https://aclanthology.org/2025.findings-acl.141/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across diverse tasks and languages. In this study, we focus on natural language understanding in three classical languages—Sanskrit, Ancient Greek and Latin—to investigate the factors affecting cross-lingual... | V. S. D. S. Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Vishakha Deulgaonkar, Chaitali Dangarikar, Pralay Manna, Arnab Bhattacharya |  |
| 242 |  |  [BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation](https://aclanthology.org/2025.findings-acl.142/) |  | 0 | Current EEG/MEG-to-text decoding systems suffer from three key limitations: (1) reliance on teacher-forcing methods, which compromises robustness during inference, (2) sensitivity to session-specific noise, hindering generalization across subjects, and (3) misalignment between brain signals and... | Jilong Li, Zhenxi Song, Jiaqi Wang, Meishan Zhang, Honghai Liu, Min Zhang, Zhiguo Zhang |  |
| 243 |  |  [Progressive LoRA for Multimodal Continual Instruction Tuning](https://aclanthology.org/2025.findings-acl.143/) |  | 0 | Multimodal Continual Instruction Tuning (MCIT) empowers Multimodal Large Language Models (MLLMs) to adapt to ever-evolving requirements without continuous costly retraining. However, MCIT faces challenges in mitigating Catastrophic Forgetting (CF) and enhancing Knowledge Transfer (KT). Existing... | Yahan Yu, Duzhen Zhang, Yong Ren, Xuanle Zhao, Xiuyi Chen, Chenhui Chu |  |
| 244 |  |  [ARC 'Challenge' Is Not That Challenging](https://aclanthology.org/2025.findings-acl.144/) |  | 0 | ARC Challenge appears more difficult than ARC Easy for modern LLMs primarily due to an evaluation setup that prevents direct comparison of answer choices rather than inherent complexity. Although some researchers have quietly shifted to a more appropriate scheme over the last year, the implications... | Lukasz Borchmann |  |
| 245 |  |  [Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation](https://aclanthology.org/2025.findings-acl.145/) |  | 0 | Recent generative large language models (LLMs) show remarkable performance in non-English languages, but when prompted in those languages they tend to express higher harmful social biases and toxicity levels. Prior work has shown that finetuning on specialized datasets can mitigate this behavior,... | Vera Neplenbroek, Arianna Bisazza, Raquel Fernández |  |
| 246 |  |  [Tracr-Injection: Distilling Algorithms into Pre-trained Language Models](https://aclanthology.org/2025.findings-acl.146/) |  | 0 | Motivated by the surge of large language models, there has been a push to formally characterize the symbolic abilities intrinsic to the transformer architecture. A programming language, called RASP, has been proposed, which can be directly compiled into transformer weights to implement these... | Tomás Vergara Browne, Alvaro Soto |  |
| 247 |  |  [Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization](https://aclanthology.org/2025.findings-acl.147/) |  | 0 | Optimizing Large Language Model (LLM) performance requires well-crafted prompts, but manual prompt engineering is labor-intensive and often ineffective. Automated prompt optimization techniques address this challenge but the major of them rely on randomly selected evaluation subsets, which fail to... | Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed E. Hassan |  |
| 248 |  |  [Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL](https://aclanthology.org/2025.findings-acl.148/) |  | 0 | As large language models advance toward superhuman performance, ensuring their alignment with human values and abilities grows increasingly complex. Weak-to-strong generalization offers a promising approach by leveraging predictions from weaker models to guide stronger systems, but its... | Wei Yao, Wenkai Yang, Ziqiao Wang, Yankai Lin, Yong Liu |  |
| 249 |  |  [Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups](https://aclanthology.org/2025.findings-acl.149/) |  | 0 | Macroeconomic fluctuations and the narratives that shape them form a mutually reinforcing cycle: public discourse can spur behavioural changes leading to economic shifts, which then result in changes in the stories that propagate. We show that shifts in semantic embedding space can be causally... | Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert |  |
| 250 |  |  [NetSafe: Exploring the Topological Safety of Multi-agent System](https://aclanthology.org/2025.findings-acl.150/) |  | 0 | Large language models (LLMs) have fueled significant progress in intelligent Multi-agent Systems (MAS), with expanding academic and industrial applications. However, safeguarding these systems from malicious queries receives relatively little attention, while methods for single-agent safety are... | Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Kun Wang, Qingsong Wen, Yang Wang |  |
| 251 |  |  [Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation](https://aclanthology.org/2025.findings-acl.151/) |  | 0 | Counterfactual reasoning is crucial for robust video understanding but remains underexplored in existing multimodal benchmarks. In this paper, we introduce \*\*COVER\*\* (\*\*CO\*\*unterfactual \*\*V\*\*id\*\*E\*\*o \*\*R\*\*easoning), a multidimensional multimodal benchmark that systematically... | Qiji Zhou, Yifan Gong, Guangsheng Bao, Hongjie Qiu, Jinqiang Li, Xiangrong Zhu, Huajian Zhang, Yue Zhang |  |
| 252 |  |  [Initializing and Retrofitting Key-Value Adaptors for Traceable Model Editing](https://aclanthology.org/2025.findings-acl.152/) |  | 0 | As the insight of knowledge storage in language models deepens, the ability to perform CRUD (Create, Read, Update, Delete) operations on language models becomes increasingly indispensable for satisfying the demands of managing rapidly updating knowledge. Considering the high cost of fine-tuning... | Hanlun Zhu, Yunshi Lan, Xiang Li, Weining Qian |  |
| 253 |  |  [Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning](https://aclanthology.org/2025.findings-acl.153/) |  | 0 | Large language models (LLMs) demonstrate remarkable capabilities but face challenges from hallucinations, which typically arise from insufficient knowledge or context. While instructing LLMs to acknowledge knowledge limitations by responding with “I don’t know” appears promising, we find that... | Jiaqi Li, Yixuan Tang, Yi Yang |  |
| 254 |  |  [Position-Aware Depth Decay Decoding (D³): Boosting Large Language Model Inference Efficiency](https://aclanthology.org/2025.findings-acl.154/) |  | 0 | Due to the large number of parameters, the inference phase of Large Language Models (LLMs) is resource-intensive. Unlike traditional model compression, which needs retraining, recent dynamic computation methods show that not all components are required for inference, enabling a training-free... | Siqi Fan, Xuezhi Fang, Xingrun Xing, Peng Han, Shuo Shang, Yequan Wang |  |
| 255 |  |  [Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku](https://aclanthology.org/2025.findings-acl.155/) |  | 0 | The success of Large Language Models (LLMs) in human-AI collaborative decision-making hinges on their ability to provide trustworthy, gradual, and tailored explanations. Solving complex puzzles, such as Sudoku, offers a canonical example of this collaboration, where clear and customized... | Anirudh Maiya, Razan Alghamdi, Maria Leonor Pacheco, Ashutosh Trivedi, Fabio Somenzi |  |
| 256 |  |  [Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors](https://aclanthology.org/2025.findings-acl.156/) |  | 0 | Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains... | Andrea Pedrotti, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell'Orletta, Andrea Esuli |  |
| 257 |  |  [InfiniSST: Simultaneous Translation of Unbounded Speech with Large Language Model](https://aclanthology.org/2025.findings-acl.157/) |  | 0 | Simultaneous translation of unbounded streaming speech remains a challenging problem due to the need for effectively processing the historical speech context and past translations so that quality and latency, including computation overhead, can be balanced. Most prior works assume pre-segmented... | Siqi Ouyang, Xi Xu, Lei Li |  |
| 258 |  |  [VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration](https://aclanthology.org/2025.findings-acl.158/) |  | 0 | The rapid advancement of vision-language models (VLMs) has brought a lot of attention to their safety alignment. However, existing methods have primarily focused on model undersafety, where the model responds to hazardous queries, while neglecting oversafety, where the model refuses to answer safe... | Jiahui Geng, Qing Li, Zongxiong Chen, Yuxia Wang, Derui Zhu, Zhuohan Xie, Chenyang Lyu, Xiuying Chen, Preslav Nakov, Fakhri Karray |  |
| 259 |  |  [To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization](https://aclanthology.org/2025.findings-acl.159/) |  | 0 | Recent advances in mathematical problem-solving with language models (LMs) integrate chain-of-thought (CoT) reasoning and code execution to harness their complementary strengths. However, existing hybrid frameworks exhibit a critical limitation: they depend on externally dictated instructions or... | Haozhe Wang, Long Li, Chao Qu, Weidi Xu, Fengming Zhu, Wei Chu, Fangzhen Lin |  |
| 260 |  |  [GOODLIAR: A Reinforcement Learning-Based Deceptive Agent for Disrupting LLM Beliefs on Foundational Principles](https://aclanthology.org/2025.findings-acl.160/) |  | 0 | Large Language Models (LLMs) often succumb to adversarial prompts, a phenomenon popularly known as “jailbreaking.” While jailbreaking primarily targets short-term noncompliance with predefined policies, we argue that a deeper vulnerability lies in altering an LLM’s fundamental axiomatic beliefs,... | Soo Kyung Kim, Hyunsoo Cho |  |
| 261 |  |  [How Does Response Length Affect Long-Form Factuality](https://aclanthology.org/2025.findings-acl.161/) |  | 0 | Large language models (LLMs) are widely used for long-form text generation. However, factual errors in the responses would undermine their reliability. Despite growing attention to LLM factuality, the effect of response length on factuality remains underexplored. In this work, we systematically... | James Xu Zhao, Jimmy Z. J. Liu, Bryan Hooi, SeeKiong Ng |  |
| 262 |  |  [Scaling LLMs' Social Reasoning: Sprinkle Cognitive "Aha Moment" into Fundamental Long-thought Logical Capabilities](https://aclanthology.org/2025.findings-acl.162/) |  | 0 | Humans continually engage in reasoning about others’ mental states, a capability known as Theory of Mind (ToM), is essential for social interactions. While this social reasoning capability emerges naturally in human cognitive development, how has the social reasoning capability of Large Language... | Guiyang Hou, Wenqi Zhang, Zhe Zheng, Yongliang Shen, Weiming Lu |  |
| 263 |  |  [SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.163/) |  | 0 | Recent advancements in large language models (LLMs) have shown impressive versatility across various tasks. To eliminate their hallucinations, retrieval-augmented generation (RAG) has emerged as a powerful approach, leveraging external knowledge sources like knowledge graphs (KGs). In this paper,... | Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng |  |
| 264 |  |  [RuleEdit: Towards Rule-Level Knowledge Generalization to Mitigate Over-Editing in Large Language Models](https://aclanthology.org/2025.findings-acl.164/) |  | 0 | Knowledge editing emerges as a promising approach for updating target knowledge in Large Language Models (LLMs) in a timely manner, thereby preventing undesirable behaviors stemming from outdated, inaccurate, or incomplete knowledge. However, existing methods mainly focus on instance-level editing,... | Bihan Zhou, Haopeng Ren, Li Yuan, Yi Cai, Liuwen Cao, Zikun Deng |  |
| 265 |  |  [Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models](https://aclanthology.org/2025.findings-acl.165/) |  | 0 | Recent advancements in long-context language models (LCLMs) promise to transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With their expanded context windows, LCLMs can process entire knowledge bases and perform retrieval and reasoning directly – a capability we define as... | Yifu Qiu, Varun R. Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han |  |
| 266 |  |  [GeAR: Generation Augmented Retrieval](https://aclanthology.org/2025.findings-acl.166/) |  | 0 | Document retrieval techniques are essential for developing large-scale information systems. The common approach involves using a bi-encoder to compute the semantic similarity between a query and documents. However, the scalar similarity often fail to reflect enough information, hindering the... | Haoyu Liu, Shaohan Huang, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Furu Wei, Qi Zhang |  |
| 267 |  |  [A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion](https://aclanthology.org/2025.findings-acl.167/) |  | 0 | Entity set expansion, taxonomy expansion, and seed-guided taxonomy construction are three representative tasks that can be applied to automatically populate an existing taxonomy with emerging concepts. Previous studies view them as three separate tasks. Therefore, their proposed techniques usually... | Yanzhen Shen, Yu Zhang, Yunyi Zhang, Jiawei Han |  |
| 268 |  |  [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://aclanthology.org/2025.findings-acl.168/) |  | 0 | Stance detection, which aims to identify public opinion towards specific targets using social media data, is an important yet challenging task. With the increasing number of online debates among social media users, conversational stance detection has become a crucial research area. However,... | Yuzhe Ding, Kang He, Bobo Li, Li Zheng, Haijun He, Fei Li, Chong Teng, Donghong Ji |  |
| 269 |  |  [LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data](https://aclanthology.org/2025.findings-acl.169/) |  | 0 | Despite the growing development of long-context large language models (LLMs), data-centric approaches relying on synthetic data have been hindered by issues related to faithfulness, which limit their effectiveness in enhancing model performance on tasks such as long-context reasoning and question... | Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Shengjie Ma, Aofan Liu, Hui Xiong, Jian Guo |  |
| 270 |  |  [SYNTHVERIFY: Enhancing Zero-Shot Claim Verification through Step-by-Step Synthetic Data Generation](https://aclanthology.org/2025.findings-acl.170/) |  | 0 | Claim verification is a fundamental task in natural language processing (NLP), involving the assessment of whether available evidence supports or refutes a given claim. While large language models (LLMs) have shown promise in this area, they continue to struggle with domain-specific knowledge.... | Rongwen Zhao, Jeffrey Flanigan |  |
| 271 |  |  [Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains](https://aclanthology.org/2025.findings-acl.171/) |  | 0 | Large Language Models (LLMs) are widely applied to downstream domains. However, current LLMs for high-stakes domain tasks, such as financial investment and legal QA, typically generate brief answers without reasoning processes and explanations. This limits users’ confidence in making decisions... | Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li |  |
| 272 |  |  [Dynamic Prefix as Instructor for Incremental Named Entity Recognition: A Unified Seq2Seq Generation Framework](https://aclanthology.org/2025.findings-acl.172/) |  | 0 | The Incremental Named Entity Recognition (INER) task aims to update a model to extract entities from an expanding set of entity type candidates due to concerns related to data privacy and scarcity. However, conventional sequence labeling approaches to INER often suffer from the catastrophic... | Zihao Wu, YongXiang Hua, Yongxin Zhu, Fang Zhang, Linli Xu |  |
| 273 |  |  [Who Taught You That? Tracing Teachers in Model Distillation](https://aclanthology.org/2025.findings-acl.173/) |  | 0 | Model distillation – using outputs from a large teacher model to teach a small student model – is a practical means of creating efficient models for a particular task. We ask: Can we identify a students’ teacher based on its outputs? Such “footprints” left by teacher LLMs would be interesting... | Somin Wadhwa, Chantal Shaib, Silvio Amir, Byron C. Wallace |  |
| 274 |  |  [D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Models](https://aclanthology.org/2025.findings-acl.174/) |  | 0 | Evaluating generative models with open-ended generation is challenging due to inconsistencies in response formats. Multiple-choice (MC) evaluation mitigates this issue, but generating high-quality distractors is time-consuming and labor-intensive. We introduce D-GEN, the first open-source... | Grace Byun, Jinho D. Choi |  |
| 275 |  |  [HammerBench: Fine-Grained Function-Calling Evaluation in Real Mobile Assistant Scenarios](https://aclanthology.org/2025.findings-acl.175/) |  | 0 | Evaluating the performance of LLMs in multi-turn human-agent interactions presents significant challenges, particularly due to the complexity and variability of user behavior. In this paper, we introduce HammerBench, a novel benchmark framework for assessing LLMs’ function-calling capabilities in... | Jun Wang, Jiamu Zhou, Xihuai Wang, Xiaoyun Mo, Haoyu Zhang, Qiqiang Lin, Jincheng Jincheng, Muning Wen, Weinan Zhang, Qiuying Peng |  |
| 276 |  |  [Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines](https://aclanthology.org/2025.findings-acl.176/) |  | 0 | In-context learning (ICL) is an important yet not fully understood ability of pre-trained large language models (LLMs). It can greatly enhance task performance using a few examples, termed demonstrations, without fine-tuning. Although effective in question answering, ICL often underperforms in... | Do Xuan Long, Duong Ngoc Yen, Do Xuan Trong, Anh Tuan Luu, Kenji Kawaguchi, Shafiq Joty, MinYen Kan, Nancy F. Chen |  |
| 277 |  |  [GRAMMAR-LLM: Grammar-Constrained Natural Language Generation](https://aclanthology.org/2025.findings-acl.177/) |  | 0 | Large Language Models have achieved impressive performance across various natural language generation tasks. However, their lack of a reliable control mechanism limits their effectiveness in applications that require strict adherence to predefined taxonomies, syntactic structures, or... | Gabriele Tuccio, Luana Bulla, Maria Madonia, Aldo Gangemi, Misael Mongiovì |  |
| 278 |  |  [MANBench: Is Your Multimodal Model Smarter than Human?](https://aclanthology.org/2025.findings-acl.178/) |  | 0 | The rapid advancement of Multimodal Large Language Models (MLLMs) has ignited discussions regarding their potential to surpass human performance in multimodal tasks. In response, we introduce MANBench (Multimodal Ability Norms Benchmark), a bilingual benchmark (English and Chinese) comprising 1,314... | Han Zhou, Qitong Xu, Yiheng Dong, Xin Yang |  |
| 279 |  |  [BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla](https://aclanthology.org/2025.findings-acl.179/) |  | 0 | This study presents \*\*\*BanStereoSet\*\*\*, a dataset designed to evaluate stereotypical social biases in multilingual LLMs for the Bangla language. In an effort to extend the focus of bias research beyond English-centric datasets, we have localized the content from the StereoSet, IndiBias, and... | Mahammed Kamruzzaman, Abdullah Al Monsur, Shrabon Kumar Das, Enamul Hassan, Gene Louis Kim |  |
| 280 |  |  [mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus](https://aclanthology.org/2025.findings-acl.180/) |  | 0 | Multimodal Large Language Models (mLLMs) are trained on a large amount of text-image data. While most mLLMs are trained on caption-like data only, Alayrac et al. (2022) showed that additionally training them on interleaved sequences of text and images can lead to the emergence of in-context... | Matthieu Futeral, Armel Randy Zebaze, Pedro Ortiz Suarez, Julien Abadji, Rémi Lacroix, Cordelia Schmid, Rachel Bawden, Benoît Sagot |  |
| 281 |  |  [NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark](https://aclanthology.org/2025.findings-acl.181/) |  | 0 | This paper introduces NorEval, a new and comprehensive evaluation suite for large-scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets – of which five are created from scratch. In contrast to existing benchmarks... | Vladislav Mikhailov, Tita Ranveig Enstad, David Samuel, Hans Christian Farsethås, Andrey Kutuzov, Erik Velldal, Lilja Øvrelid |  |
| 282 |  |  [Massively Multilingual Instruction-Following Information Extraction](https://aclanthology.org/2025.findings-acl.182/) |  | 0 | The literature on information extraction (IE) has mostly centered around a selected few languages, hindering their applications on multilingual corpora. In this work, we introduce MASSIE - a comprehensive collection for instruction-following multilingual IE that standardizes and unifies 215... | Thang Le, Huy Huu Nguyen, Anh Tuan Luu, Thien Huu Nguyen |  |
| 283 |  |  [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://aclanthology.org/2025.findings-acl.183/) |  | 0 | Previous multimodal sentence representation learning methods have achieved impressive performance. However, most approaches focus on aligning images and text at a coarse level, facing two critical challenges: cross-modal misalignment bias and intra-modal semantic divergence, which significantly... | Kang He, Yuzhe Ding, Haining Wang, Fei Li, Chong Teng, Donghong Ji |  |
| 284 |  |  [Large Language Models in Bioinformatics: A Survey](https://aclanthology.org/2025.findings-acl.184/) |  | 0 | Large Language Models (LLMs) are revolutionizing bioinformatics, enabling advanced analysis of DNA, RNA, proteins, and single-cell data. This survey provides a systematic review of recent advancements, focusing on genomic sequence modeling, RNA structure prediction, protein function inference, and... | Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan Chen, Xiangyu Shi, Yu Li |  |
| 285 |  |  [ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing](https://aclanthology.org/2025.findings-acl.185/) |  | 0 | Although multimodal large language models (MLLMs) show promise in generating chart rendering code, editing charts via code presents a greater challenge. This task demands MLLMs to integrate chart understanding and reasoning capacities, which are labor-intensive. While many MLLMs claim such editing... | Xuanle Zhao, Xuexin Liu, Haoyue Yang, Xianzhen Luo, Fanhu Zeng, Jianling Li, Qi Shi, Chi Chen |  |
| 286 |  |  [Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models](https://aclanthology.org/2025.findings-acl.186/) |  | 0 | The safety alignment ability of Vision-Language Models (VLMs) is prone to be degraded by the integration of the vision module compared to its LLM backbone. We investigate this phenomenon, dubbed as “safety alignment degradation” in this paper, and show that the challenge arises from the... | Qin Liu, Chao Shang, Ling Liu, Nikolaos Pappas, Jie Ma, Neha Anna John, Srikanth Doss, Lluís Màrquez, Miguel Ballesteros, Yassine Benajiba |  |
| 287 |  |  [Turbocharging Web Automation: The Impact of Compressed History States](https://aclanthology.org/2025.findings-acl.187/) |  | 0 | Language models have led to leap forward in web automation. The current web automation approaches take the current web state, history actions, and language instruction as inputs to predict the next action, overlooking the importance of history states. However, the highly verbose nature of web page... | Xiyue Zhu, Peng Tang, Haofu Liao, Srikar Appalaraju |  |
| 288 |  |  [Making RALM Robust to Irrelevant Contexts via Layer Knowledge Guided Attention](https://aclanthology.org/2025.findings-acl.188/) |  | 0 | Retrieval-augmented language models (RALMs) aim to incorporate external knowledge to address the issues of factual hallucination and knowledge obsolescence faced by large language models (LLMs). Inevitably, the retrieved passages based on similarity search may be irrelevant to the given question,... | Weijie Shi, Hao Chen, Jiaming Li, Yao Zhao, Yazhong Zhang, Qijin Chen, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Xiaofang Zhou |  |
| 289 |  |  [Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction](https://aclanthology.org/2025.findings-acl.189/) |  | 0 | As Large Language Models (LLMs) are widely applied in various domains, the safety of LLMs is increasingly attracting attention to avoid their powerful capabilities being misused. Existing jailbreak methods create a forced instruction-following scenario, or search adversarial prompts with prefix or... | Yuting Huang, Chengyuan Liu, Yifeng Feng, Yiquan Wu, Chao Wu, Fei Wu, Kun Kuang |  |
| 290 |  |  [SignAlignLM: Integrating Multimodal Sign Language Processing into Large Language Models](https://aclanthology.org/2025.findings-acl.190/) |  | 0 | Deaf and Hard-of-Hearing (DHH) users increasingly utilize Large Language Models (LLMs), yet face significant challenges due to these models’ limited understanding of sign language grammar, multimodal sign inputs, and Deaf cultural contexts. Further, current approaches that try to address these... | Mert Inan, Anthony Sicilia, Malihe Alikhani |  |
| 291 |  |  [NegVQA: Can Vision Language Models Understand Negation?](https://aclanthology.org/2025.findings-acl.191/) |  | 0 | Negation is a fundamental linguistic phenomenon that can entirely reverse the meaning of a sentence. As vision language models (VLMs) continue to advance and are deployed in high-stakes applications, assessing their ability to comprehend negation becomes essential. To address this, we introduce... | Yuhui Zhang, Yuchang Su, Yiming Liu, Serena YeungLevy |  |
| 292 |  |  [Natural Language Reasoning in Large Language Models: Analysis and Evaluation](https://aclanthology.org/2025.findings-acl.192/) |  | 0 | While Large Language Models (LLMs) have demonstrated promising results on a range of reasoning benchmarks—particularly in formal logic, mathematical tasks, and Chain-of-Thought prompting—less is known about their capabilities in unconstrained natural language reasoning. Argumentative reasoning, a... | Debela Gemechu, Ramon RuizDolz, Henrike Beyer, Chris Reed |  |
| 293 |  |  [SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling](https://aclanthology.org/2025.findings-acl.193/) |  | 0 | Large language models (LLMs) have advanced rapidly from conversational problem solving to addressing real-world tasks involving tool use, such as software engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex and Cursor, have offered end-to-end automation of the software development... | Haoran Wang, Zhenyu Hou, Yao Wei, Jie Tang, Yuxiao Dong |  |
| 294 |  |  [The Two Paradigms of LLM Detection: Authorship Attribution vs Authorship Verification](https://aclanthology.org/2025.findings-acl.194/) |  | 0 | The detection of texts generated by LLMs has quickly become an important research problem. Many supervised and zero-shot detectors have already been proposed, yet their effectiveness and precision remain disputed. Current research therefore focuses on making detectors robust against domain shifts... | Janek Bevendorff, Matti Wiegmann, Emmelie Richter, Martin Potthast, Benno Stein |  |
| 295 |  |  [Unveiling Confirmation Bias in Chain-of-Thought Reasoning](https://aclanthology.org/2025.findings-acl.195/) |  | 0 | Chain-of-thought (CoT) prompting has been widely adopted to enhance the reasoning capabilities of large language models (LLMs). However, the effectiveness of CoT reasoning is inconsistent across tasks with different reasoning types. This work presents a novel perspective to understand CoT behavior... | Yue Wan, Xiaowei Jia, Xiang Lorraine Li |  |
| 296 |  |  [GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory Networks into RNA Foundation Models](https://aclanthology.org/2025.findings-acl.196/) |  | 0 | Foundation models for single-cell RNA sequencing (scRNA-seq) have shown promising capabilities in capturing gene expression patterns. However, current approaches face critical limitations: they ignore biological prior knowledge encoded in gene regulatory relationships and fail to leverage... | Mufan Qiu, Xinyu Hu, Fengwei Zhan, Sukwon Yun, Jie Peng, Ruichen Zhang, Bhavya Kailkhura, Jiekun Yang, Tianlong Chen |  |
| 297 |  |  [RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service](https://aclanthology.org/2025.findings-acl.197/) |  | 0 | Retrieval-augmented generation (RAG) improves the service quality of large language models by retrieving relevant documents from credible literature and integrating them into the context of the user query.Recently, the rise of the cloud RAG service has made it possible for users to query relevant... | Yihang Cheng, Lan Zhang, Junyang Wang, Mu Yuan, Yunhao Yao |  |
| 298 |  |  ["My life is miserable, have to sign 500 autographs everyday": Exposing Humblebragging, the Brags in Disguise](https://aclanthology.org/2025.findings-acl.198/) |  | 0 | Humblebragging is a phenomenon in which individuals present self-promotional statements under the guise of modesty or complaints. For example, a statement like, “Ugh, I can’t believe I got promoted to lead the entire team. So stressful!”, subtly highlights an achievement while pretending to be... | Sharath Naganna, Saprativa Bhattacharjee, Biplab Banerjee, Pushpak Bhattacharyya |  |
| 299 |  |  [SCITAT: A Question Answering Benchmark for Scientific Tables and Text Covering Diverse Reasoning Types](https://aclanthology.org/2025.findings-acl.199/) |  | 0 | Scientific question answering (SQA) is an important task aimed at answering questions based on papers. However, current SQA datasets have limited reasoning types and neglect the relevance between tables and text, creating a significant gap with real scenarios. To address these challenges, we... | Xuanliang Zhang, Dingzirui Wang, Baoxin Wang, Longxu Dou, Xinyuan Lu, Keyan Xu, Dayong Wu, Qingfu Zhu |  |
| 300 |  |  [TokenShapley: Token Level Context Attribution with Shapley Value](https://aclanthology.org/2025.findings-acl.200/) |  | 0 | Large language models (LLMs) demonstrate strong capabilities in in-context learning, but verifying the correctness of their generated responses remains a challenge. Prior work has explored attribution at the sentence level, but these methods fall short when users seek attribution for specific... | Yingtai Xiao, Yuqing Zhu, Sirat Samyoun, Wanrong Zhang, Jiachen T. Wang, Jian Du |  |
| 301 |  |  [Entropy-based Exploration Conduction for Multi-step Reasoning](https://aclanthology.org/2025.findings-acl.201/) |  | 0 | Multi-step processes via large language models (LLMs) have proven effective for solving complex reasoning tasks. However, the depth of exploration of the reasoning procedure can significantly affect the task performance. Existing methods to automatically decide the depth often lead to high cost and... | Jinghan Zhang, Xiting Wang, Fengran Mo, Yeyang Zhou, Wanfu Gao, Kunpeng Liu |  |
| 302 |  |  [Taxonomizing Representational Harms using Speech Act Theory](https://aclanthology.org/2025.findings-acl.202/) |  | 0 | Representational harms are widely recognized among fairness-related harms caused by generative language systems. However, their definitions are commonly under-specified. We make a theoretical contribution to the specification of representational harms by introducing a framework, grounded in speech... | Emily Corvi, Hannah Washington, Stefanie Reed, Chad Atalla, Alexandra Chouldechova, P. Alex Dow, Jean GarciaGathright, Nicholas J. Pangakis, Emily Sheng, Dan Vann, Matthew Vogel, Hanna M. Wallach |  |
| 303 |  |  [Turning Conversations into Workflows: A Framework to Extract and Evaluate Dialog Workflows for Service AI Agents](https://aclanthology.org/2025.findings-acl.203/) |  | 0 | Automated service agents require well-structured workflows to deliver consistent and accurate responses to customer queries. However, such workflows are often undocumented, and their automatic extraction from conversations remains largely unexplored. In this work, we present a novel framework for... | Prafulla Kumar Choubey, Xiangyu Peng, Shilpa Bhagavath, Caiming Xiong, Shiva Kumar Pentyala, ChienSheng Wu |  |
| 304 |  |  [Statistical inference on black-box generative models in the data kernel perspective space](https://aclanthology.org/2025.findings-acl.204/) |  | 0 | Generative models are capable of producing human-expert level content across a variety of topics and domains. As the impact of generative models grows, it is necessary to develop statistical methods to understand collections of available models. These methods are particularly important in settings... | Hayden S. Helm, Aranyak Acharyya, Youngser Park, Brandon Duderstadt, Carey E. Priebe |  |
| 305 |  |  [Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?](https://aclanthology.org/2025.findings-acl.205/) |  | 0 | We evaluate how well Large Language Models (LLMs) latently recall and compose facts to answer multi-hop queries like “In the year Scarlett Johansson was born, the Summer Olympics were hosted in the country of”. One major challenge in such evaluation is that LLMs may have developed shortcuts by... | Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva |  |
| 306 |  |  [AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling](https://aclanthology.org/2025.findings-acl.206/) |  | 0 | In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a... | Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping |  |
| 307 |  |  [WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models](https://aclanthology.org/2025.findings-acl.207/) |  | 0 | Climate change adaptation requires the understanding of disruptive weather impacts on society, where large language models (LLMs) might be applicable. However, their effectiveness is under-explored due to the difficulty of high-quality corpus collection and the lack of available benchmarks. The... | Yongan Yu, Qingchen Hu, Xianda Du, Jiayin Wang, Fengran Mo, Renée Sieber |  |
| 308 |  |  [MeMoTune: A Measure and Moment-Driven Fine-Tuning Framework for Quantized Large Language Models](https://aclanthology.org/2025.findings-acl.208/) |  | 0 | Quantizing large language models (LLMs) is essential for reducing memory and computational costs in natural language processing. Existing methods combine quantization with parameter-efficient fine-tuning but often fail to meet practical performance requirements. This paper introduces MeMoTune, a... | Yun Zhang, Xue Geng, Lizi Liao, Jintong Sun, Minghe Yu, Ge Yu |  |
| 309 |  |  [MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset](https://aclanthology.org/2025.findings-acl.209/) |  | 0 | Language models (LMs) have excelled in various broad domains. However, to ensure their safe and effective integration into real-world educational settings, they must demonstrate proficiency in specific, granular areas of knowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs’... | Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence Hunter, Katharina von der Wense |  |
| 310 |  |  [Sentimental Image Generation for Aspect-based Sentiment Analysis](https://aclanthology.org/2025.findings-acl.210/) |  | 0 | Recent research work on textual Aspect-Based Sentiment Analysis (ABSA) have achieved promising performance. However, a persistent challenge lies in the limited semantics derived from the raw data. To address this issue, researchers have explored enhancing textual ABSA with additional augmentations,... | Xiaoyi Bao, Jinghang Gu, Zhongqing Wang, ChuRen Huang |  |
| 311 |  |  [Long-form Hallucination Detection with Self-elicitation](https://aclanthology.org/2025.findings-acl.211/) |  | 0 | While Large Language Models (LLMs) have exhibited impressive performance in generating long-form content, they frequently present a hazard of producing factual inaccuracies or hallucinations. An effective strategy to mitigate this hazard is to leverage off-the-shelf LLMs to detect hallucinations... | Zihang Liu, Jiawei Guo, Hao Zhang, Hongyang Chen, Jiajun Bu, Haishuai Wang |  |
| 312 |  |  [ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty](https://aclanthology.org/2025.findings-acl.212/) |  | 0 | The rapid development of LLMs has sparked extensive research into their factual knowledge. Current works find that LLMs fall short on questions around low-frequency entities. However, such proofs are unreliable since the questions can differ not only in entity frequency but also in difficulty... | Qing Zong, Zhaowei Wang, Tianshi Zheng, Xiyu Ren, Yangqiu Song |  |
| 313 |  |  [One-Dimensional Object Detection for Streaming Text Segmentation of Meeting Dialogue](https://aclanthology.org/2025.findings-acl.213/) |  | 0 | Dialogue text segmentation aims to partition dialogue content into consecutive paragraphs based on themes or logic, enhancing its comprehensibility and manageability. Current text segmentation models, when applied directly to STS (Streaming Text Segmentation), exhibit numerous limitations, such as... | Rui He, Zhongqing Wang, Minjie Qiang, Hongling Wang, Yifan Zhang, Hua Xu, Shuai Fan, Guodong Zhou |  |
| 314 |  |  [CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts](https://aclanthology.org/2025.findings-acl.214/) |  | 0 | Taxonomies provide structural representations of knowledge and are crucial in various applications. The task of taxonomy expansion involves integrating emerging entities into existing taxonomies by identifying appropriate parent entities for these new query entities. Previous methods rely on... | Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Zhenyu Wu, Shangbin Feng, Meng Jiang |  |
| 315 |  |  [Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings](https://aclanthology.org/2025.findings-acl.215/) |  | 0 | Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is crucial for ensuring the reliability of downstream applications. A recent work applies conformal prediction to KGE methods, providing uncertainty estimates by generating a set of answers that is guaranteed to include the true... | Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab |  |
| 316 |  |  [Autonomous Data Selection with Zero-shot Generative Classifiers for Mathematical Texts](https://aclanthology.org/2025.findings-acl.216/) |  | 0 | We present Autonomous Data Selection (AutoDS), a method that leverages base language models as zero-shot “generative classifiers” to automatically curate high-quality mathematical texts. Unlike prior approaches that require human annotations or training a dedicated data filter, AutoDS relies solely... | Yifan Zhang, Yifan Luo, Yang Yuan, Andrew C. Yao |  |
| 317 |  |  [Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review](https://aclanthology.org/2025.findings-acl.217/) |  | 0 | While reasoning capabilities typically emerge in large language models (LLMs) with tens of billions of parameters, recent research focuses on improving smaller open-source models through knowledge distillation (KD) from commercial LLMs. However, many of these studies rely solely on responses from a... | Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He |  |
| 318 |  |  [Investigating Prosodic Signatures via Speech Pre-Trained Models for Audio Deepfake Source Attribution](https://aclanthology.org/2025.findings-acl.218/) |  | 0 | In this work, we investigate various state-of-the-art (SOTA) speech pre-trained models (PTMs) for their capability to capture prosodic sig-natures of the generative sources for audio deepfake source attribution (ADSD). These prosodic characteristics can be considered oneof major signatures for... | Orchid Chetia Phukan, Drishti Singh, Swarup Ranjan Behera, Arun Balaji Buduru, Rajesh Sharma |  |
| 319 |  |  [Multilingual Retrieval Augmented Generation for Culturally-Sensitive Tasks: A Benchmark for Cross-lingual Robustness](https://aclanthology.org/2025.findings-acl.219/) |  | 0 | The paradigm of retrieval-augmented generated (RAG) helps mitigate hallucinations of large language models (LLMs). However, RAG also introduces biases contained within the retrieved documents. These biases can be amplified in scenarios which are multilingual and culturally-sensitive, such as... | Bryan Li, Fiona Luo, Samar Haider, Adwait Agashe, Siyu Li, Runqi Liu, Miranda Muqing Miao, Shriya Ramakrishnan, Yuan Yuan, Chris CallisonBurch |  |
| 320 |  |  [Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.220/) |  | 0 | The reranker and generator are two critical components in the Retrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking relevant documents and generating responses. However, due to differences in pre-training data and objectives, there is an inevitable gap between the documents... | Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Yichao Wang, Yuhao Wang, Qidong Liu, Maolin Wang, Huifeng Guo, Ruiming Tang, Xiangyu Zhao |  |
| 321 |  |  [Scaling Laws for Multilingual Language Models](https://aclanthology.org/2025.findings-acl.221/) |  | 0 | We propose a novel scaling law for general-purpose decoder-only language models (LMs) trained on multilingual data, tackling the problem of balancing languages during multilingual pretraining. A primary challenge in studying multilingual scaling is the difficulty of analyzing individual language... | Yifei He, Alon Benhaim, Barun Patra, Praneetha Vaddamanu, Sanchit Ahuja, Parul Chopra, Vishrav Chaudhary, Han Zhao, Xia Song |  |
| 322 |  |  [Corpus Poisoning via Approximate Greedy Gradient Descent](https://aclanthology.org/2025.findings-acl.222/) |  | 0 | Dense retrievers are widely used in information retrieval and have also been successfully extended to other knowledge intensive areas such as language models, e.g., Retrieval-Augmented Generation (RAG) systems. Unfortunately, they have recently been shown to be vulnerable to corpus poisoning... | Jinyan Su, Preslav Nakov, Claire Cardie |  |
| 323 |  |  [Taxonomy-Driven Knowledge Graph Construction for Domain-Specific Scientific Applications](https://aclanthology.org/2025.findings-acl.223/) |  | 0 | We present a taxonomy-driven framework for constructing domain-specific knowledge graphs (KGs) that integrates structured taxonomies, Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG). Although we focus on climate science to illustrate its effectiveness, our approach can... | Huitong Pan, Qi Zhang, Mustapha Adamu, Eduard C. Dragut, Longin Jan Latecki |  |
| 324 |  |  [Wanda++: Pruning Large Language Models via Regional Gradients](https://aclanthology.org/2025.findings-acl.224/) |  | 0 | Large Language Models (LLMs) pruning seeks to remove unimportant weights for inference speedup with minimal accuracy impact. However, existing methods often suffer from accuracy degradation without full-model sparsity-aware fine-tuning. This paper presents Wanda++, a novel pruning framework that... | Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar |  |
| 325 |  |  [MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data](https://aclanthology.org/2025.findings-acl.225/) |  | 0 | Human trafficking (HT) remains a critical issue, with traffickers increasingly leveraging online escort advertisements to advertise victims anonymously. Existing detection methods, including text-based Authorship Attribution (AA), overlook the multimodal nature of these ads, which combine text and... | Vageesh Kumar Saxena, Benjamin Bashpole, Gijs van Dijck, Gerasimos Spanakis |  |
| 326 |  |  [Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements](https://aclanthology.org/2025.findings-acl.226/) |  | 0 | With the increasing integration of large language models (LLMs) into real-world applications such as finance, e-commerce, and recommendation systems, their susceptibility to misinformation and adversarial manipulation poses significant risks. Existing fraud detection benchmarks primarily focus on... | Shu Yang, Shenzhe Zhu, Zeyu Wu, Keyu Wang, Junchi Yao, Junchao Wu, Lijie Hu, Mengdi Li, Derek F. Wong, Di Wang |  |
| 327 |  |  [Mitigating Paraphrase Attacks on Machine-Text Detection via Paraphrase Inversion](https://aclanthology.org/2025.findings-acl.227/) |  | 0 | High-quality paraphrases are easy to produce using instruction-tuned language models or specialized paraphrasing models. Although this capability has a variety of benign applications, paraphrasing attacks—paraphrases applied to machine-generated texts—are known to significantly degrade the... | Rafael Alberto Rivera Soto, Barry Y. Chen, Nicholas Andrews |  |
| 328 |  |  [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://aclanthology.org/2025.findings-acl.228/) |  | 0 | Language models (LMs) are indispensable tools shaping modern workflows, but their global effectiveness depends on understanding local socio-cultural contexts. To address this, we introduce SANSKRITI, a benchmark designed to evaluate language models’ comprehension of India’s rich cultural diversity.... | Arijit Maji, Raghvendra Kumar, Akash Ghosh, Anushka, Sriparna Saha |  |
| 329 |  |  [System Prompt Hijacking via Permutation Triggers in LLM Supply Chains](https://aclanthology.org/2025.findings-acl.229/) |  | 0 | LLMs are increasingly developed through distributed supply chains, where model providers create base models that deployers customize with system prompts for task-specific applications and safety alignment. We introduce SHIP, a novel post-deployment attack that bypasses system prompts, enabling... | Lu Yan, Siyuan Cheng, Xuan Chen, Kaiyuan Zhang, Guangyu Shen, Xiangyu Zhang |  |
| 330 |  |  [Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers](https://aclanthology.org/2025.findings-acl.230/) |  | 0 | Over the past decade, various studies have addressed how speakers solve the so-called ‘The Paradigm Cell Filling Problem’ (PCFP) (CITATION) across different languages. The PCFP addresses a fundamental question in morphological processing: how do speakers accurately generate inflected forms of words... | Akhilesh Kakolu Ramarao, Kevin Tang, Dinah BaerHenney |  |
| 331 |  |  [From Heart to Words: Generating Empathetic Responses via Integrated Figurative Language and Semantic Context Signals](https://aclanthology.org/2025.findings-acl.231/) |  | 0 | Although generically expressing empathy is straightforward, effectively conveying empathy in specialized settings presents nuanced challenges. We present a conceptually motivated investigation into the use of figurative language and causal semantic context to facilitate targeted empathetic response... | Gyeongeun Lee, Zhu Wang, Sathya N. Ravi, Natalie Parde |  |
| 332 |  |  [There's No Such Thing as Simple Reasoning for LLMs](https://aclanthology.org/2025.findings-acl.232/) |  | 0 | Large Language Models (LLMs) have been widely found to struggle with logical reasoning, where even fine-tuned models fail dramatically on out-of-distribution problems. However, existing work has focused on relatively complex “many-hop” reasoning problems. In this paper, we analyse the performance... | Nurul Fajrin Ariyani, Zied Bouraoui, Richard Booth, Steven Schockaert |  |
| 333 |  |  [CLIX: Cross-Lingual Explanations of Idiomatic Expressions](https://aclanthology.org/2025.findings-acl.233/) |  | 0 | Automated definition generation systems have been proposed to support vocabulary expansion for language learners. The main barrier to the success of these systems is that learners often struggle to understand definitions due to the presence of potentially unfamiliar words and grammar, particularly... | Aaron Gluck, Katharina von der Wense, Maria Leonor Pacheco |  |
| 334 |  |  [Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity](https://aclanthology.org/2025.findings-acl.234/) |  | 0 | Hallucination in large language models (LLMs) can be detected by assessing the uncertainty of model outputs, typically measured using entropy. Semantic entropy (SE) enhances traditional entropy estimation by quantifying uncertainty at the semantic cluster level. However, as modern LLMs generate... | Dang Nguyen, Ali Payani, Baharan Mirzasoleiman |  |
| 335 |  |  [R³Mem: Bridging Memory Retention and Retrieval via Reversible Compression](https://aclanthology.org/2025.findings-acl.235/) |  | 0 | Memory plays a key role in enhancing LLMs’ performance when deployed to real-world applications. Existing solutions face trade-offs: explicit memory designs based on external storage require complex management and incur storage overhead, while implicit memory designs that store information via... | Xiaoqiang Wang, Suyuchen Wang, Yun Zhu, Bang Liu |  |
| 336 |  |  [Vision Language Model Helps Private Information De-Identification in Vision Data](https://aclanthology.org/2025.findings-acl.236/) |  | 0 | Visual Language Models (VLMs) have gained significant popularity due to their remarkable ability. While various methods exist to enhance privacy in text-based applications, privacy risks associated with visual inputs remain largely overlooked such as Protected Health Information (PHI) in medical... | Tiejin Chen, Pingzhi Li, Kaixiong Zhou, Tianlong Chen, Hua Wei |  |
| 337 |  |  [Unveiling Privacy Risks in Multi-modal Large Language Models: Task-specific Vulnerabilities and Mitigation Challenges](https://aclanthology.org/2025.findings-acl.237/) |  | 0 | Privacy risks in text-only Large Language Models (LLMs) are well studied, particularly their tendency to memorize and leak sensitive information. However, Multi-modal Large Language Models (MLLMs), which process both text and images, introduce unique privacy challenges that remain underexplored.... | Tiejin Chen, Pingzhi Li, Kaixiong Zhou, Tianlong Chen, Hua Wei |  |
| 338 |  |  [DeFine: Decision-Making with Analogical Reasoning over Factor Profiles](https://aclanthology.org/2025.findings-acl.238/) |  | 0 | LLMs are ideal for decision-making thanks to their ability to reason over long contexts. However, challenges arise when processing speech transcripts that describe complex scenarios, as they are verbose and include repetition, hedging, and vagueness. E.g., during a company’s earnings call, an... | Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu |  |
| 339 |  |  [SMART: Self-Aware Agent for Tool Overuse Mitigation](https://aclanthology.org/2025.findings-acl.239/) |  | 0 | Current Large Language Model (LLM) agents demonstrate strong reasoning and tool use capabilities, but often lack self-awareness, failing to balance these approaches effectively. This imbalance leads to \*\*Tool Overuse\*\*, where models unnecessarily rely on external tools for tasks solvable with... | Cheng Qian, Emre Can Acikgoz, Hongru Wang, Xiusi Chen, Avirup Sil, Dilek HakkaniTür, Gokhan Tur, Heng Ji |  |
| 340 |  |  [Continued Pretraining and Interpretability-Based Evaluation for Low-Resource Languages: A Galician Case Study](https://aclanthology.org/2025.findings-acl.240/) |  | 0 | Recent advances in Large Language Models (LLMs) have led to remarkable improvements in language understanding and text generation. However, challenges remain in enhancing their performance for underrepresented languages, ensuring continual learning without catastrophic forgetting, and developing... | Pablo Rodríguez, Silvia Paniagua Suárez, Pablo Gamallo, Susana Sotelo Docío |  |
| 341 |  |  [TC-Bench: Benchmarking Temporal Compositionality in Conditional Video Generation](https://aclanthology.org/2025.findings-acl.241/) |  | 0 | Video generation has many unique challenges beyond those of image generation. The temporal dimension introduces extensive possible variations across frames, over which consistency and continuity may be violated. In this work, we evaluate the emergence of new concepts and relation transitions as... | Weixi Feng, Jiachen Li, Michael Saxon, TsuJui Fu, Wenhu Chen, William Yang Wang |  |
| 342 |  |  [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://aclanthology.org/2025.findings-acl.242/) |  | 0 | Long-context understanding is crucial for many NLP applications, yet transformers struggle with efficiency due to the quadratic complexity of self-attention. Sparse attention methods alleviate this cost but often impose static, predefined masks, failing to capture heterogeneous attention patterns.... | Hanzhi Zhang, Heng Fan, Kewei Sha, Yan Huang, Yunhe Feng |  |
| 343 |  |  [Arbiters of Ambivalence: Challenges of using LLMs in No-Consensus tasks](https://aclanthology.org/2025.findings-acl.243/) |  | 0 | The increasing use of LLMs as substitutes for humans in “aligning” LLMs has raised questions about their ability to replicate human judgments and preferences, especially in ambivalent scenarios where humans disagree. This study examines the biases and limitations of LLMs in three roles: answer... | Bhaktipriya Radharapu, Manon Revel, Megan Ung, Sebastian Ruder, Adina Williams |  |
| 344 |  |  [Beyond Text: Characterizing Domain Expert Needs in Document Research](https://aclanthology.org/2025.findings-acl.244/) |  | 0 | Working with documents is a key part of almost any knowledge work, from contextualizing research in a literature review to reviewing legal precedent. Recently, as their capabilities have expanded, primarily text-based NLP systems have often been billed as able to assist or even automate this kind... | Sireesh Gururaja, Nupoor Gandhi, Jeremiah Milbauer, Emma Strubell |  |
| 345 |  |  [Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack](https://aclanthology.org/2025.findings-acl.245/) |  | 0 | Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions... | Murong Yue, Ziyu Yao |  |
| 346 |  |  [MM-R³: On (In-)Consistency of Vision-Language Models (VLMs)](https://aclanthology.org/2025.findings-acl.246/) |  | 0 | With the advent of LLMs and variants, a flurry of research has emerged, analyzing the performance of such models across an array of tasks. While most studies focus on evaluating the capabilities of state-of-the-art (SoTA) Vision Language Models (VLMs) through task accuracy (e.g., visual question... | ShihHan Chou, Shivam Chandhok, Jim Little, Leonid Sigal |  |
| 347 |  |  [Investigating Context Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style](https://aclanthology.org/2025.findings-acl.247/) |  | 0 | Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by incorporating external information into the response generation process. However, how context-faithful LLMs are and what factors influence LLMs’ context faithfulness remain largely unexplored. In this study, we... | Yuepei Li, Kang Zhou, Qiao Qiao, Bach Nguyen, Qing Wang, Qi Li |  |
| 348 |  |  [Shadow-Activated Backdoor Attacks on Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.248/) |  | 0 | This paper delves into a novel backdoor attack scenario, aiming to uncover potential security risks associated with Multimodal Large Language Models (MLLMs) during multi-round open-ended conversations with users. In the practical use of MLLMs, users have full control over the interaction process... | Ziyi Yin, Muchao Ye, Yuanpu Cao, Jiaqi Wang, Aofei Chang, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma |  |
| 349 |  |  [Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding](https://aclanthology.org/2025.findings-acl.249/) |  | 0 | Vision Language Models (VLMs) have achieved remarkable progress in multimodal tasks, yet they often struggle with visual arithmetic, seemingly simple capabilities like object counting or length comparison, which are essential for relevant complex tasks like chart understanding and geometric... | KungHsiang Huang, Can Qin, Haoyi Qiu, Philippe Laban, Shafiq Joty, Caiming Xiong, ChienSheng Wu |  |
| 350 |  |  [K-order Ranking Preference Optimization for Large Language Models](https://aclanthology.org/2025.findings-acl.250/) |  | 0 | To adapt large language models (LLMs) to ranking tasks, existing list-wise methods, represented by list-wise Direct Preference Optimization (DPO), focus on optimizing partial-order or full-order list ranking consistency for LLMs to enhance their ranking abilities.However, we argue that optimizing... | Shihao Cai, Chongming Gao, Yang Zhang, Wentao Shi, Jizhi Zhang, Keqin Bao, Qifan Wang, Fuli Feng |  |
| 351 |  |  [Spectral Insights into Data-Oblivious Critical Layers in Large Language Models](https://aclanthology.org/2025.findings-acl.251/) |  | 0 | Understanding how feature representations evolve across layers in large language models (LLMs) is key to improving their interpretability and robustness. While recent studies have identified critical layers linked to specific functions or behaviors, these efforts typically rely on data-dependent... | Xuyuan Liu, Lei Hsiung, Yaoqing Yang, Yujun Yan |  |
| 352 |  |  [SynFix: Dependency-Aware Program Repair via RelationGraph Analysis](https://aclanthology.org/2025.findings-acl.252/) |  | 0 | Recent advancements in large language models (LLMs) have significantly improved software development automation, including bug localization, code synthesis, program repair, and test generation. However, most prior work on program repair focuses on isolated elements, such as classes or functions,... | Xunzhu Tang, Jiechao Gao, Jin Xu, Tiezhu Sun, Yewei Song, Saad Ezzini, Wendkûuni C. Ouédraogo, Jacques Klein, Tegawendé F. Bissyandé |  |
| 353 |  |  [EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.253/) |  | 0 | We introduce EXIT, an extractive context compression framework that enhances both the effectiveness and efficiency of retrieval-augmented generation (RAG) in question answering (QA). Current RAG systems often struggle when retrieval models fail to rank the most relevant documents, leading to the... | Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, SeungYoon Han, Jong C. Park |  |
| 354 |  |  [Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives](https://aclanthology.org/2025.findings-acl.254/) |  | 0 | The Chain-of-Thought (CoT) paradigm has become a pivotal method for solving complex problems with large language models (LLMs). However, its application to domain-specific tasks remains challenging, as LLMs often fail to decompose tasks accurately or execute subtasks effectively. This paper... | Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Sitao Xie, Yubo Zhang, Jiaxin Shi, Zhixing Wang, Hongyan Li, Junchi Yan |  |
| 355 |  |  [Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation](https://aclanthology.org/2025.findings-acl.255/) |  | 0 | Parameter-efficient fine-tuning (PEFT) can bridge the gap between large language models (LLMs) and downstream tasks. However, PEFT has been proven vulnerable to malicious attacks. Research indicates that poisoned LLMs, even after PEFT, retain the capability to activate internalized backdoors when... | Shuai Zhao, Xiaobao Wu, CongDuy T. Nguyen, Yanhao Jia, Meihuizi Jia, Yichao Feng, Anh Tuan Luu |  |
| 356 |  |  [Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning](https://aclanthology.org/2025.findings-acl.256/) |  | 0 | Packing, initially utilized in the pre-training phase, is an optimization technique designed to maximize hardware resource efficiency by combining different training sequences to fit the model’s maximum input length. Although it has demonstrated effectiveness during pre-training, there remains a... | Shuhe Wang, Guoyin Wang, Yizhong Wang, Jiwei Li, Eduard H. Hovy, Chen Guo |  |
| 357 |  |  [Better Red Teaming via Searching with Large Language Model](https://aclanthology.org/2025.findings-acl.257/) |  | 0 | The safe deployment of large language models (LLMs) necessitates comprehensive safety evaluations through red teaming. However, existing methods face challenges in managing semantic intricacies and optimizing the efficiency of the search process. To overcome these limitations, we propose Better Red... | Yongkang Chen, Chongyang Zhao, Jianwentian Jianwentian, Guiling Cao, Hu Li, Xiaohui Kuang |  |
| 358 |  |  [AdaV: Adaptive Text-visual Redirection for Vision-Language Models](https://aclanthology.org/2025.findings-acl.258/) |  | 0 | The success of Vision-Language Models (VLMs) often relies on high-resolution schemes that preserve image details, while these approaches also generate an excess of visual tokens, leading to a substantial decrease in model efficiency. A typical VLM includes a visual encoder, a text encoder, and an... | Jiayi Han, Liang Du, Yiwen Wu, Guanming Liang, Xiangguo Zhou, Weibo Zheng, Donghong Han, Zixun Sun |  |
| 359 |  |  [MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs](https://aclanthology.org/2025.findings-acl.259/) |  | 0 | LLM-based multi-agent systems (MAS) have shown promise in tackling complex tasks. However, existing solutions often suffer from limited agent coordination and heavy reliance on predefined Standard Operating Procedures (SOPs), which demand extensive human input. To address these limitations, we... | Qian Wang, Tianyu Wang, Zhenheng Tang, Qinbin Li, Nuo Chen, Jingsheng Liang, Bingsheng He |  |
| 360 |  |  [Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment](https://aclanthology.org/2025.findings-acl.260/) |  | 0 | Aligning language models with human preferences presents significant challenges, particularly in achieving personalization without incurring excessive computational costs. Existing methods rely on reward signals and additional annotated data, limiting their scalability and adaptability to diverse... | Xiaotian Zhang, Ruizhe Chen, Yang Feng, Zuozhu Liu |  |
| 361 |  |  [A Self-Distillation Recipe for Neural Machine Translation](https://aclanthology.org/2025.findings-acl.261/) |  | 0 | Self-distillation distills the deeper sub-networks to the shallower sub-networks without using an extra teacher model, and has been proven effective in improving the performance of a series of computer vision tasks. In this paper, we study the representation-based self-distillation methods for... | Hongfei Xu, Zhuofei Liang, Qiuhui Liu, Lingling Mu |  |
| 362 |  |  [BlockPruner: Fine-grained Pruning for Large Language Models](https://aclanthology.org/2025.findings-acl.262/) |  | 0 | With the rapid growth in the size and complexity of large language models (LLMs), the costs associated with their training and inference have escalated significantly. Research indicates that certain layers in LLMs harbor substantial redundancy, and pruning these layers has minimal impact on the... | Longguang Zhong, Fanqi Wan, Ruijun Chen, Xiaojun Quan, Liangzhi Li |  |
| 363 |  |  [Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective](https://aclanthology.org/2025.findings-acl.263/) |  | 0 | As large language models (LLMs) become an important way of information access, there have been increasing concerns that LLMs may intensify the spread of unethical content, including implicit bias that hurts certain populations without explicit harmful words. In this paper, we conduct a rigorous... | Yuchen Wen, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng |  |
| 364 |  |  [LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-Context QA](https://aclanthology.org/2025.findings-acl.264/) |  | 0 | Though current long-context large language models (LLMs) have demonstrated impressive capacities in answering various questions based on extensive text, the lack of citations in their responses makes user verification difficult, leading to concerns about their trustworthiness due to the potential... | Jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li |  |
| 365 |  |  [An Empirical Study of Group Conformity in Multi-Agent Systems](https://aclanthology.org/2025.findings-acl.265/) |  | 0 | Recent advances in Large Language Models (LLMs) have enabled multi-agent systems that simulate real-world interactions with near-human reasoning. While previous studies have extensively examined biases related to protected attributes such as race, the emergence and propagation of biases on socially... | Min Choi, Keonwoo Kim, Sungwon Chae, Sangyeob Baek |  |
| 366 |  |  [Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation](https://aclanthology.org/2025.findings-acl.266/) |  | 0 | Large language model (LLM) shows promising performances in a variety of downstream tasks, such as machine translation (MT). However, using LLMs for translation suffers from high computational costs and significant latency. Based on our evaluation, in most cases, translations using LLMs are... | Zhanglin Wu, Daimeng Wei, Xiaoyu Chen, Hengchao Shang, Jiaxin Guo, Zongyao Li, Yuanchang Luo, Jinlong Yang, Zhiqiang Rao, Hao Yang |  |
| 367 |  |  [ASPO: Adaptive Sentence-Level Preference Optimization for Fine-Grained Multimodal Reasoning](https://aclanthology.org/2025.findings-acl.267/) |  | 0 | Direct Preference Optimization (DPO) has gained significant attention for its simplicity and computational efficiency in aligning large language models (LLMs). Recent advancements have extended DPO to multimodal scenarios, achieving strong performance. However, traditional DPO relies on binary... | Yeyuan Wang, Dehong Gao, Rujiao Long, Lei Yi, Linbo Jin, Libin Yang, Xiaoyan Cai |  |
| 368 |  |  [NovelCR: A Large-Scale Bilingual Dataset Tailored for Long-Span Coreference Resolution](https://aclanthology.org/2025.findings-acl.268/) |  | 0 | Coreference resolution (CR) endeavors to match pronouns, noun phrases, etc. with their referent entities, acting as an important step for deep text understanding. Presently available CR datasets are either small in scale or restrict coreference resolution to a limited text span. In this paper, we... | Meihan Tong, Shuai Wang |  |
| 369 |  |  [Dynamic Attention-Guided Context Decoding for Mitigating Context Faithfulness Hallucinations in Large Language Models](https://aclanthology.org/2025.findings-acl.269/) |  | 0 | Large language models (LLMs) often exhibit Context Faithfulness Hallucinations, where outputs deviate from retrieved information due to incomplete context integration. Our analysis reveals a strong correlation between token-level uncertainty and hallucinations. We hypothesize that attention... | Huangyw Huangyw, Yong Zhang, Ning Cheng, Zhitao Li, Shaojun Wang, Jing Xiao |  |
| 370 |  |  [Exploring the Choice Behavior of Large Language Models](https://aclanthology.org/2025.findings-acl.270/) |  | 0 | Large Language Models (LLMs) are increasingly deployed as human assistants across various domains where they help to make choices. However, the mechanisms behind LLMs’ choice behavior remain unclear, posing risks in safety-critical situations. Inspired by the intrinsic and extrinsic motivation... | Weidong Wu, Qinlin Zhao, Hao Chen, Lexin Zhou, Defu Lian, Hong Xie |  |
| 371 |  |  [On-Policy Self-Alignment with Fine-grained Knowledge Feedback for Hallucination Mitigation](https://aclanthology.org/2025.findings-acl.271/) |  | 0 | Hallucination occurs when large language models exhibit behavior that deviates from the boundaries of their knowledge during response generation. To address this critical issue, previous learning-based methods attempt to finetune models but are limited by off-policy sampling and coarse-grained... | Xueru Wen, Jie Lou, Xinyu Lu, Yuqiu Ji, Xinyan Guan, Yaojie Lu, Hongyu Lin, Ben He, Xianpei Han, Debing Zhang, Le Sun |  |
| 372 |  |  [From Phrases to Subgraphs: Fine-Grained Semantic Parsing for Knowledge Graph Question Answering](https://aclanthology.org/2025.findings-acl.272/) |  | 0 | The recent emergence of large language models (LLMs) has brought new opportunities to knowledge graph question answering (KGQA), but also introduces challenges such as semantic misalignment and reasoning noise. Semantic parsing (SP), previously a mainstream approach for KGQA, enables precise graph... | Yurun Song, Xiangqing Shen, Rui Xia |  |
| 373 |  |  [StableToolBench-MirrorAPI: Modeling Tool Environments as Mirrors of 7, 000+ Real-World APIs](https://aclanthology.org/2025.findings-acl.273/) |  | 0 | The rapid advancement of large language models (LLMs) has spurred significant interest in tool learning, where LLMs are augmented with external tools to tackle complex tasks. However, existing tool environments face challenges in balancing stability, scale, and realism, particularly for... | Zhicheng Guo, Sijie Cheng, Yuchen Niu, Hao Wang, Sicheng Zhou, Wenbing Huang, Yang Liu |  |
| 374 |  |  [ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM](https://aclanthology.org/2025.findings-acl.274/) |  | 0 | Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of large language models (LLMs) is an emerging research challenge in claim verification. While KGs provide structured, semantically rich representations well-suited for reasoning, most existing verification methods rely on... | Hoang Pham, ThanhDo Nguyen, KhacHoai Nam Bui |  |
| 375 |  |  [TriEmbed: Bridge the Gap between Text and Token Indices with Embedding Reparameterization](https://aclanthology.org/2025.findings-acl.275/) |  | 0 | The current paradigm of language modeling is a two-stage pipeline that first transforms raw text to token indices, where the distribution is then estimated. It inherently discards linguistic relations between tokens during tokenization, creating a fundamental gap. To address this, we propose... | Baizhou Huang, Xiaojun Wan |  |
| 376 |  |  [Chain of Methodologies: Scaling Test Time Computation without Training](https://aclanthology.org/2025.findings-acl.276/) |  | 0 | Large Language Models (LLMs) often struggle with complex reasoning tasks due to insufficient in-depth insights in their training data, which are frequently absent in publicly available documents. This paper introduces the Chain of Methodologies (CoM), a simple and innovative iterative prompting... | Cong Liu, Jie Wu, Weigang Wu, Xu Chen, Liang Lin, WeiShi Zheng |  |
| 377 |  |  [A Survey on Personalized Alignment - The Missing Piece for Large Language Models in Real-World Applications](https://aclanthology.org/2025.findings-acl.277/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities, yet their transition to real-world applications reveals a critical limitation: the inability to adapt to individual preferences while maintaining alignment with universal human values. Current alignment techniques adopt a... | Jian Guan, Junfei Wu, JiaNan Li, Chuanqi Cheng, Wei Wu |  |
| 378 |  |  [SuLoRA: Subspace Low-Rank Adaptation for Parameter-Efficient Fine-Tuning](https://aclanthology.org/2025.findings-acl.278/) |  | 0 | As the scale of large language models (LLMs) grows and natural language tasks become increasingly diverse, Parameter-Efficient Fine-Tuning (PEFT) has become the standard paradigm for fine-tuning LLMs. Among PEFT methods, LoRA is widely adopted for not introducing additional inference overhead.... | Chenhao Ding, Jiangyang Li, Songlin Dong, Xinyuan Gao, Yuhang He, Yihong Gong |  |
| 379 |  |  [MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval](https://aclanthology.org/2025.findings-acl.279/) |  | 0 | Recent multimodal retrieval methods have endowed text-based retrievers with multimodal capabilities by utilizing pre-training strategies for visual-text alignment. They often directly fuse the two modalities for cross-reference during the alignment to understand multimodal queries. However,... | YeongJoon Ju, HoJoong Kim, SeongWhan Lee |  |
| 380 |  |  [Correcting on Graph: Faithful Semantic Parsing over Knowledge Graphs with Large Language Models](https://aclanthology.org/2025.findings-acl.280/) |  | 0 | Complex multi-hop questions often require comprehensive retrieval and reasoning. As a result, effectively parsing such questions and establishing an efficient interaction channel between large language models (LLMs) and knowledge graphs (KGs) is essential for ensuring reliable reasoning. In this... | Ruilin Zhao, Feng Zhao, Hong Zhang |  |
| 381 |  |  [COPR: Continual Human Preference Learning via Optimal Policy Regularization](https://aclanthology.org/2025.findings-acl.281/) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) is effective for aligning Large Language Models (LLMs) with human preferences. However, RLHF’s complex process limits its ability to continually learn human feedback, making it impractical for real-world applications where the deployed model... | Han Zhang, Lin Gui, Yu Lei, Yuanzhao Zhai, Yehong Zhang, Zhuo Zhang, Yulan He, Hui Wang, Yue Yu, KamFai Wong, Bin Liang, Ruifeng Xu |  |
| 382 |  |  [Robust Preference Optimization via Dynamic Target Margins](https://aclanthology.org/2025.findings-acl.282/) |  | 0 | The alignment of Large Language Models (LLMs) is crucial for ensuring their safety and reliability in practical applications. Direct Preference Optimization (DPO) has emerged as an efficient method that directly optimizes models using preference pairs, significantly reducing resource demands.... | Jie Sun, Junkang Wu, Jiancan Wu, Zhibo Zhu, Xingyu Lu, Jun Zhou, Lintao Ma, Xiang Wang |  |
| 383 |  |  [AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for Video-language Understanding](https://aclanthology.org/2025.findings-acl.283/) |  | 0 | Multimodal Large Language Models (MLLMs) have revolutionized video understanding, yet are still limited by context length when processing long videos. Recent methods compress videos by leveraging visual redundancy uniformly, yielding promising results. Nevertheless, our quantitative analysis shows... | Xiao Wang, Qingyi Si, Shiyu Zhu, Jianlong Wu, Li Cao, Liqiang Nie |  |
| 384 |  |  [Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges](https://aclanthology.org/2025.findings-acl.284/) |  | 0 | Existing benchmarks that assess Language Models (LMs) as Language Agents (LAs) for tool use primarily focus on stateless, single-turn interactions or partial evaluations, such as tool selection in a single turn, overlooking the inherent stateful nature of interactions in multi-turn applications. To... | Hongru Wang, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, KamFai Wong |  |
| 385 |  |  [Open-Set Living Need Prediction with Large Language Models](https://aclanthology.org/2025.findings-acl.285/) |  | 0 | Living needs are the needs people generate in their daily lives for survival and well-being. On life service platforms like Meituan, user purchases are driven by living needs, making accurate living need predictions crucial for personalized service recommendations. Traditional approaches treat this... | Xiaochong Lan, Jie Feng, Yizhou Sun, Chen Gao, Jiahuan Lei, Xinleishi Xinleishi, Hengliang Luo, Yong Li |  |
| 386 |  |  [Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate](https://aclanthology.org/2025.findings-acl.286/) |  | 0 | This paper systematically addresses the challenge of rule retrieval, a crucial yet underexplored area. Vanilla retrieval methods using sparse or dense retrievers to directly search for relevant rules to support downstream reasoning, often suffer from low accuracy. This is primarily due to a... | Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu |  |
| 387 |  |  [Beyond Words: Integrating Theory of Mind into Conversational Agents for Human-Like Belief, Desire, and Intention Alignment](https://aclanthology.org/2025.findings-acl.287/) |  | 0 | Natural language interaction has long served as the primary medium through which humans exchange ideas. A key enabler of this communication is the human capacity for Theory of Mind (ToM)—the ability to infer and align with the mental states of others. ToM is usually modeled as components of... | Mehdi Jafari, Yuncheng Hua, Hao Xue, Flora D. Salim |  |
| 388 |  |  [Multimodal Causal Reasoning Benchmark: Challenging Multimodal Large Language Models to Discern Causal Links Across Modalities](https://aclanthology.org/2025.findings-acl.288/) |  | 0 | Multimodal Large Language Models (MLLMs) have showcased exceptional Chain-of-Thought (CoT) reasoning ability in complex textual inference tasks including causal reasoning. However, will these causalities remain straightforward when crucial hints hide in visual details? If not, what factors might... | Zhiyuan Li, Heng Wang, Dongnan Liu, Chaoyi Zhang, Ao Ma, Jieting Long, Weidong Cai |  |
| 389 |  |  [Context-Aware Hierarchical Merging for Long Document Summarization](https://aclanthology.org/2025.findings-acl.289/) |  | 0 | Hierarchical Merging is a technique commonly used to summarize very long texts (>100K tokens) by breaking down the input into smaller sections, summarizing those sections individually, and then merging or combining those summaries into a final coherent summary. Although it helps address the... | Litu Ou, Mirella Lapata |  |
| 390 |  |  [VCD: A Dataset for Visual Commonsense Discovery in Images](https://aclanthology.org/2025.findings-acl.290/) |  | 0 | Visual commonsense plays a vital role in understanding and reasoning about the visual world. While commonsense knowledge bases like ConceptNet provide structured collections of general facts, they lack visually grounded representations. Scene graph datasets like Visual Genome, though rich in... | Xiangqing Shen, Fanfan Wang, Siwei Wu, Rui Xia |  |
| 391 |  |  [Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst](https://aclanthology.org/2025.findings-acl.291/) |  | 0 | Inference-time scaling has attracted much attention which significantly enhance the performance of Large Language Models (LLMs) in complex reasoning tasks by increasing the length of Chain-of-Thought. These longer intermediate reasoning rationales embody various meta-reasoning skills in human... | Hongru Wang, Deng Cai, Wanjun Zhong, Shijue Huang, Jeff Z. Pan, Zeming Liu, KamFai Wong |  |
| 392 |  |  [HyperCRS: Hypergraph-Aware Multi-Grained Preference Learning to Burst Filter Bubbles in Conversational Recommendation System](https://aclanthology.org/2025.findings-acl.292/) |  | 0 | The filter bubble is a notorious issue in Recommender Systems (RSs), characterized by users being confined to a limited corpus of information or content that strengthens and amplifies their pre-established preferences and beliefs. Most existing methods primarily aim to analyze filter bubbles in the... | Yongsen Zheng, Mingjie Qian, Guohua Wang, Yang Liu, Ziliang Chen, Mingzhi Mao, Liang Lin, KwokYan Lam |  |
| 393 |  |  [Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement](https://aclanthology.org/2025.findings-acl.293/) |  | 0 | Large Language Models (LLMs) have become essential for offensive language detection, yet their ability to handle annotation disagreement remains underexplored. Disagreement samples, which arise from subjective interpretations, pose a unique challenge due to their ambiguous nature. Understanding how... | Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy KaWei Lee, Bo Xu, Liang Yang, Hongfei Lin |  |
| 394 |  |  [Language Repository for Long Video Understanding](https://aclanthology.org/2025.findings-acl.294/) |  | 0 | Language has become a prominent modality in computer vision with the rise of LLMs. Despite supporting long context-lengths, their effectiveness in handling long-term information gradually declines with input length. This becomes critical, especially in applications such as long-form video... | Kumara Kahatapitiya, Kanchana Ranasinghe, Jongwoo Park, Michael S. Ryoo |  |
| 395 |  |  [Investigating Language Preference of Multilingual RAG Systems](https://aclanthology.org/2025.findings-acl.295/) |  | 0 | Multilingual Retrieval-Augmented Generation (mRAG) systems enhance language models by integrating external multilingual information to produce context-aware responses. However, mRAG systems struggle with retrieving relevant information due to linguistic variations between queries and documents,... | Jeonghyun Park, Hwanhee Lee |  |
| 396 |  |  [FGDGNN: Fine-Grained Dynamic Graph Neural Network for Rumor Detection on Social Media](https://aclanthology.org/2025.findings-acl.296/) |  | 0 | Detecting rumors on social media has become a crucial issue.Propagation structure-based methods have recently attracted increasing attention.When the propagation structure is represented by the dynamic graph, temporal information is considered.However, existing rumor detection models using dynamic... | Mei Guo, Chen Chen, Chunyan Hou, Yike Wu, Xiaojie Yuan |  |
| 397 |  |  [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](https://aclanthology.org/2025.findings-acl.297/) |  | 0 | Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. To keep LLMs current, existing approaches typically involve continued pre-training on new documents. However, they frequently face... | Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen M. Meng |  |
| 398 |  |  [QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query Language](https://aclanthology.org/2025.findings-acl.298/) |  | 0 | Recent advances in large language models (LLMs) have demonstrated remarkable potential in the field of natural language processing. Unfortunately, LLMs face significant security and ethical risks. Although techniques such as safety alignment are developed for defense, prior researches reveal the... | Qingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, Kuofeng Gao, Ruoyu Li, Yong Jiang |  |
| 399 |  |  [Memory or Reasoning? Explore How LLMs Compute Mixed Arithmetic Expressions](https://aclanthology.org/2025.findings-acl.299/) |  | 0 | Large language models (LLMs) can solve complex multi-step math reasoning problems, but little is known about how these computations are implemented internally. Many recent studies have investigated the mechanisms of LLMs on simple arithmetic tasks (e.g., a+b, a× b), but how LLMs solve mixed... | Chengzhi Li, Heyan Huang, Ping Jian, Zhen Yang, Chenxu Wang, Yifan Wang |  |
| 400 |  |  [PersonaX: A Recommendation Agent-Oriented User Modeling Framework for Long Behavior Sequence](https://aclanthology.org/2025.findings-acl.300/) |  | 0 | User profile embedded in the prompt template of personalized recommendation agents play a crucial role in shaping their decision-making process. High-quality user profiles are essential for aligning agent behavior with real user interests. Typically, these profiles are constructed by leveraging... | Yunxiao Shi, Wujiang Xu, Zeqi Zhang, Xing Zi, Qiang Wu, Min Xu |  |
| 401 |  |  [Judge as A Judge: Improving the Evaluation of Retrieval-Augmented Generation through the Judge-Consistency of Large Language Models](https://aclanthology.org/2025.findings-acl.301/) |  | 0 | Retrieval-Augmented Generation (RAG) has proven its effectiveness in alleviating hallucinations for Large Language Models (LLMs). However, existing automated evaluation metrics cannot fairly evaluate the outputs generated by RAG models during training and evaluation. LLM-based judgment models... | Shuliang Liu, Xinze Li, Zhenghao Liu, Yukun Yan, Cheng Yang, Zheni Zeng, Zhiyuan Liu, Maosong Sun, Ge Yu |  |
| 402 |  |  [Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability](https://aclanthology.org/2025.findings-acl.302/) |  | 0 | Training language models with rationales augmentation has been shown to be beneficial in many existing works. In this paper, we identify that such a prevailing view does not hold consistently. We conduct comprehensive investigations to thoroughly inspect the impact of rationales on model... | Chiwei Zhu, Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Zhendong Mao |  |
| 403 |  |  [CA-GAR: Context-Aware Alignment of LLM Generation for Document Retrieval](https://aclanthology.org/2025.findings-acl.303/) |  | 0 | Information retrieval has evolved from traditional sparse and dense retrieval methods to approaches driven by large language models (LLMs). Recent techniques, such as Generation-Augmented Retrieval (GAR) and Generative Document Retrieval (GDR), leverage LLMs to enhance retrieval but face key... | Heng Yu, Junfeng Kang, Rui Li, Qi Liu, Liyang He, Zhenya Huang, Shuanghong Shen, Junyu Lu |  |
| 404 |  |  [AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents](https://aclanthology.org/2025.findings-acl.304/) |  | 0 | Current research in LLM-based simulation systems lacks comprehensive solutions for modeling real-world court proceedings, while existing legal language models struggle with dynamic courtroom interactions. We present \*\*AgentCourt\*\*, a comprehensive legal simulation framework that addresses these... | Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, Qiang Qu, Hamid AlinejadRokny, Shiwen Ni, Min Yang |  |
| 405 |  |  [MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios](https://aclanthology.org/2025.findings-acl.305/) |  | 0 | Code debugging is a crucial task in software engineering, which attracts increasing attention. While remarkable success has been made in the era of large language models (LLMs), current research still focuses on the simple no-library or single-library setting, ignoring the complex multi-library... | Jinyang Huang, Xiachong Feng, Qiguang Chen, Hanjie Zhao, Zihui Cheng, Jiesong Bai, Jingxuan Zhou, Min Li, Libo Qin |  |
| 406 |  |  [An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4](https://aclanthology.org/2025.findings-acl.306/) |  | 0 | Recently, there has been a growing trend of utilizing Large Language Model (LLM) to evaluate the quality of other LLMs. Many studies have fine-tuned judge models based on open-source LLMs for evaluation. While the fine-tuned judge models are claimed to achieve comparable evaluation capability with... | Hui Huang, Xingyuan Bu, Hongli Zhou, Yingqi Qu, Jing Liu, Muyun Yang, Bing Xu, Tiejun Zhao |  |
| 407 |  |  [Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent](https://aclanthology.org/2025.findings-acl.307/) |  | 0 | Recent advancements in Large Language Models (LLMs) have significantly propelled the development of Conversational Recommendation Agents (CRAs). However, these agents often generate short-sighted responses that fail to sustain user guidance and meet expectations. Although preference optimization... | Xueyang Feng, Jingsen Zhang, Jiakai Tang, Wei Li, Guohao Cai, Xu Chen, Quanyu Dai, Yue Zhu, Zhenhua Dong |  |
| 408 |  |  [ProMedTS: A Self-Supervised, Prompt-Guided Multimodal Approach for Integrating Medical Text and Time Series](https://aclanthology.org/2025.findings-acl.308/) |  | 0 | Large language models (LLMs) have shown remarkable performance in vision-language tasks, but their application in the medical field remains underexplored, particularly for integrating structured time series data with unstructured clinical notes. In clinical practice, dynamic time series data, such... | Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Wei Bi, Richard Yi Da Xu, Guo Li, Xian Yang |  |
| 409 |  |  [CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenge](https://aclanthology.org/2025.findings-acl.309/) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities, especially the recent advancements in reasoning, such as o1 and o3, pushing the boundaries of AI. Despite these impressive achievements in mathematics and coding, the reasoning abilities of LLMs in domains requiring... | Yu Li, Qizhi Pei, Mengyuan Sun, Honglin Lin, Chenlin Ming, Xin Gao, Jiang Wu, Conghui He, Lijun Wu |  |
| 410 |  |  [Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning](https://aclanthology.org/2025.findings-acl.310/) |  | 0 | Large language models (LLMs) risk retaining unauthorized or sensitive information from their training data, which raises privacy concerns. LLM unlearning seeks to mitigate these risks by selectively removing specified data while maintaining overall model performance. However, most existing work... | Hwan Chang, Hwanhee Lee |  |
| 411 |  |  [Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing](https://aclanthology.org/2025.findings-acl.311/) |  | 0 | Role-Playing Agents (RPAs) have shown remarkable performance in various applications, yet they often struggle to recognize and appropriately respond to hard queries that conflict with their role-play knowledge. To investigate RPAs’ performance when faced with different types of conflicting... | Wenhao Liu, Siyu An, Junru Lu, Muling Wu, Tianlong Li, Xiaohua Wang, Changze Lv, Xiaoqing Zheng, Di Yin, Xing Sun, Xuanjing Huang |  |
| 412 |  |  [LR²Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems](https://aclanthology.org/2025.findings-acl.312/) |  | 0 | Recent progress in o1-like models has significantly enhanced the reasoning abilities of Large Language Models (LLMs), empowering them to tackle increasingly complex tasks through reflection capabilities, such as making assumptions, backtracking, and self-refinement. However, effectively evaluating... | Jianghao Chen, Zhenlin Wei, Zhenjiang Ren, Ziyong Li, Jiajun Zhang |  |
| 413 |  |  [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://aclanthology.org/2025.findings-acl.313/) |  | 0 | As large language models (LLMs) are increasingly applied to various NLP tasks, their inherent biases are gradually disclosed. Therefore, measuring biases in LLMs is crucial to mitigate its ethical risks. However, most existing bias evaluation datasets are focus on English andNorth American culture,... | Tian Lan, Xiangdong Su, Xu Liu, Ruirui Wang, Ke Chang, Jiang Li, Guanglai Gao |  |
| 414 |  |  [MARK: Multi-agent Collaboration with Ranking Guidance for Text-attributed Graph Clustering](https://aclanthology.org/2025.findings-acl.314/) |  | 0 | This paper studies the problem of text-attributed graph clustering, which aims to cluster each node into different groups using both textual attributes and structural information. Although graph neural networks (GNNs) have been proposed to solve this problem, their performance is usually limited... | Yiwei Fu, Yuxing Zhang, Chunchun Chen, JianwenMa JianwenMa, Quan Yuan, RongCheng Tu, Xinli Huang, Wei Ye, Xiao Luo, Minghua Deng |  |
| 415 |  |  [Can Language Models Capture Human Writing Preferences for Domain-Specific Text Summarization?](https://aclanthology.org/2025.findings-acl.315/) |  | 0 | With the popularity of large language models and their high-quality text generation capabilities, researchers are using them as auxiliary tools for text summary writing. Although summaries generated by these large language models are smooth and capture key information sufficiently, the quality of... | Jingbao Luo, Ming Liu, Ran Liu, Yongpan Sheng, Xin Hu, Gang Li, Peng Wu |  |
| 416 |  |  [Mitigate Position Bias in LLMs via Scaling a Single Hidden States Channel](https://aclanthology.org/2025.findings-acl.316/) |  | 0 | Long-context language models (LCLMs) can process long context, but still exhibit position bias, also known as “lost in the middle”, which indicates placing key information in the middle of the context will significantly affect performance. To mitigating this, we first explore the micro-level... | Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, ChinYew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu |  |
| 417 |  |  [Self-attention-based Graph-of-Thought for Math Problem Solving](https://aclanthology.org/2025.findings-acl.317/) |  | 0 | Applying Large Language Models (LLM) to solve math problems is one of the hottest research topics at present. Traditional Chain-of-Thought-based methods typically generate the reasoning path in a chain structure, leading to unnecessary interference caused by non-zero self-attention among weakly... | Ruiqiao Bai, Xue Han, Shuo Lei, Junlan Feng, Yanyan Luo, Chao Deng |  |
| 418 |  |  [BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks](https://aclanthology.org/2025.findings-acl.318/) |  | 0 | Large language model (LLM) based agents have shown great potential in following human instructions and automatically completing various tasks. To complete a task, the agent needs to decompose it into easily executed steps by planning. Existing studies mainly conduct the planning by inferring what... | Weihong Du, Wenrui Liao, Binyu Yan, Hongru Liang, Anthony G. Cohn, Wenqiang Lei |  |
| 419 |  |  [KAPA: A Deliberative Agent Framework with Tree-Structured Knowledge Base for Multi-Domain User Intent Understanding](https://aclanthology.org/2025.findings-acl.319/) |  | 0 | Dialogue assistants have become ubiquitous in modern applications, fundamentally reshaping human daily communication patterns and information access behaviors. In real-world conversational interactions, however, user queries are often volatile, ambiguous, and diverse, making it difficult accurately... | Jiakai Tang, Shiqi Shen, Zhipeng Wang, Gong Zhi, Xueyang Feng, Zexu Sun, Haoran Tan, Xu Chen |  |
| 420 |  |  [RASD: Retrieval-Augmented Speculative Decoding](https://aclanthology.org/2025.findings-acl.320/) |  | 0 | Speculative decoding accelerates inference in large language models (LLMs) by generating draft tokens for target model verification. Current approaches for obtaining draft tokens rely on lightweight draft models or additional model structures to generate draft tokens and retrieve context from... | Guofeng Quan, Wenfeng Feng, Chuzhan Hao, Guochao Jiang, Yuewei Zhang, Hao Henry Wang |  |
| 421 |  |  [FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs](https://aclanthology.org/2025.findings-acl.321/) |  | 0 | To mitigate the hallucination and knowledge deficiency in large language models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) has shown promising potential by utilizing KGs as an external resource to enhance LLM reasoning.However, existing KG-RAG approaches struggle with a... | Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, S. Kevin Zhou, Xike Xie |  |
| 422 |  |  [Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.322/) |  | 0 | Hallucination issues continue to affect multimodal large language models (MLLMs), with existing research mainly addressing object-level or attribute-level hallucinations, neglecting the more complex relation hallucinations that require advanced reasoning. Current benchmarks for relation... | Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Huiyu Zhou, Xuming Hu |  |
| 423 |  |  [Blessing of Multilinguality: A Systematic Analysis of Multilingual In-Context Learning](https://aclanthology.org/2025.findings-acl.323/) |  | 0 | While multilingual large language models generally perform adequately, and sometimes even rival English performance on high-resource languages (HRLs), they often significantly underperform on low-resource languages (LRLs). Among several prompting strategies aiming at bridging the gap, multilingual... | Yilei Tu, Andrew Xue, Freda Shi |  |
| 424 |  |  [SEK: Self-Explained Keywords Empower Large Language Models for Code Generation](https://aclanthology.org/2025.findings-acl.324/) |  | 0 | Large language models (LLMs) have achieved impressive performance in code generation. Despite the remarkable success, we observed that LLMs often misunderstand or overlook some problem-specific undertrained keywords during code generation, compromising the accuracy of the generated code. After... | Lishui Fan, Mouxiang Chen, Zhongxin Liu |  |
| 425 |  |  [Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement](https://aclanthology.org/2025.findings-acl.325/) |  | 0 | Large Language Models (LLMs) have shown impressive capabilities across various tasks but remain vulnerable to meticulously crafted jailbreak attacks. In this paper, we identify a critical safety gap: while LLMs are adept at detecting jailbreak prompts, they often produce unsafe responses when... | Peng Ding, Jun Kuang, ZongYu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang |  |
| 426 |  |  [Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents](https://aclanthology.org/2025.findings-acl.326/) |  | 0 | Recent success in large multimodal models (LMMs) has sparked promising applications of agents capable of autonomously completing complex web tasks. While open-source LMM agents have made significant advances in offline evaluation benchmarks, their performance still falls substantially short of... | Vardaan Pahuja, Yadong Lu, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Hassan Awadallah |  |
| 427 |  |  [Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding](https://aclanthology.org/2025.findings-acl.327/) |  | 0 | Vision-language Models (VLMs) have shown remarkable capabilities in advancing general artificial intelligence, yet the irrational encoding of visual positions persists in inhibiting the models’ comprehensive perception performance across different levels of granularity. In this work, we propose... | Zhanpeng Chen, Mingxiao Li, Ziyang Chen, Nan Du, Xiaolong Li, Yuexian Zou |  |
| 428 |  |  [P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts](https://aclanthology.org/2025.findings-acl.328/) |  | 0 | Personalized large language models (LLMs) have attracted great attention in many applications, such as emotional support and role-playing. However, existing works primarily focus on modeling explicit character profiles, while ignoring the underlying personality traits that truly shape behaviors and... | Yuhao Dan, Jie Zhou, Qin Chen, Junfeng Tian, Liang He |  |
| 429 |  |  [EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.329/) |  | 0 | Automated Essay Scoring (AES) plays a crucial role in educational assessment by providing scalable and consistent evaluations of writing tasks. However, traditional AES systems face three major challenges: (i) reliance on handcrafted features that limit generalizability, (ii) difficulty in... | Jiamin Su, Yibo Yan, Fangteng Fu, Zhang Han, Jingheng Ye, Xiang Liu, Jiahao Huo, Huiyu Zhou, Xuming Hu |  |
| 430 |  |  [Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks](https://aclanthology.org/2025.findings-acl.330/) |  | 0 | In Retrieval-Augmented Generation (RAG) and agent-based frameworks, the “Chain of Models” approach is widely used, where multiple specialized models work sequentially on distinct sub-tasks. This approach is effective but increases resource demands as each model must be deployed separately. Recent... | Yuanjie Lyu, Chao Zhang, Yuhao Chen, Yong Chen, Tong Xu |  |
| 431 |  |  [Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks](https://aclanthology.org/2025.findings-acl.331/) |  | 0 | While Vision-Language Models (VLMs) have shown remarkable abilities, they invariably generate flawed responses. Self-correction that instructs models to refine their outputs presents a promising solution to this issue. Previous studies have mainly concentrated on Large Language Models (LLMs), while... | Jiayi He, Hehai Lin, Qingyun Wang, Yi R. Fung, Heng Ji |  |
| 432 |  |  [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://aclanthology.org/2025.findings-acl.332/) |  | 0 | Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions. We propose a proof-of-concept framework that projects how... | Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji |  |
| 433 |  |  [Probability-Consistent Preference Optimization for Enhanced LLM Reasoning](https://aclanthology.org/2025.findings-acl.333/) |  | 0 | Recent advances in preference optimization have demonstrated significant potential for improving mathematical reasoning capabilities in large language models (LLMs). While current approaches leverage high-quality pairwise preference data through outcome-based criteria like answer correctness or... | Yunqiao Yang, Houxing Ren, Zimu Lu, Ke Wang, Weikang Shi, Aojun Zhou, Junting Pan, Mingjie Zhan, Hongsheng Li |  |
| 434 |  |  [IW-Bench: Evaluating Large Multimodal Models for Converting Image-to-Web](https://aclanthology.org/2025.findings-acl.334/) |  | 0 | Recently, advancements in large multimodal models have led to significant strides in image comprehension capabilities. Despite these advancements, there is a lack of a robust benchmark specifically for assessing the image‐to‐web conversion proficiency of these large models. It is essential to... | Hongcheng Guo, Wei Zhang, Junhao Chen, Yaonan Gu, Jian Yang, Junjia Du, Shaosheng Cao, Binyuan Hui, Tianyu Liu, Jianxin Ma, Chang Zhou, Zhoujun Li |  |
| 435 |  |  [TDCSA: LLM-Guided Top-Down Approach for Robust Citation Sentiment Analysis](https://aclanthology.org/2025.findings-acl.335/) |  | 0 | Citation Sentiment Analysis (CSA) plays a crucial role in understanding academic influence and knowledge diffusion. While pre-trained language models (PLMs) and large language models (LLMs) showed remarkable success in general sentiment analysis, they encounter specialized challenges in CSA due to... | Fan Gao, Jieyang Peng, Xiaoming Tao, Youzheng Wang |  |
| 436 |  |  [DeepRTL2: A Versatile Model for RTL-Related Tasks](https://aclanthology.org/2025.findings-acl.336/) |  | 0 | The integration of large language models (LLMs) into electronic design automation (EDA) has significantly advanced the field, offering transformative benefits, particularly in register transfer level (RTL) code generation and understanding. While previous studies have demonstrated the efficacy of... | Yi Liu, Hongji Zhang, Yunhao Zhou, Zhengyuan Shi, Changran Xu, Qiang Xu |  |
| 437 |  |  [The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?](https://aclanthology.org/2025.findings-acl.337/) |  | 0 | Self-improving large language models (LLMs) – i.e., to improve the performance of an LLM by fine-tuning it with synthetic data generated by itself – is a promising way to advance the capabilities of LLMs while avoiding extensive supervision. Existing approaches to self-improvement often rely on... | Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Jianwei Yin |  |
| 438 |  |  [Cross-lingual Multimodal Sentiment Analysis for Low-Resource Languages via Language Family Disentanglement and Rethinking Transfer](https://aclanthology.org/2025.findings-acl.338/) |  | 0 | Existing multimodal sentiment analysis (MSA) methods have achieved significant success, leveraging cross-modal large-scale models (LLMs) and extensive pre-training data. However, these methods struggle to handle MSA tasks in low-resource languages. While multilingual LLMs enable cross-lingual... | Long Chen, Shuoyu Guan, Xiaohua Huang, WenJing Wang, Cai Xu, Ziyu Guan, Wei Zhao |  |
| 439 |  |  [Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?](https://aclanthology.org/2025.findings-acl.339/) |  | 0 | Jailbreak attacks have been observed to largely fail against recent reasoning models enhanced by Chain-of-Thought (CoT) reasoning. However, the underlying mechanism remains underexplored, and relying solely on reasoning capacity may raise security concerns. In this paper, we try to answer the... | Chengda Lu, Xiaoyu Fan, Yu Huang, Rongwu Xu, Jijie Li, Wei Xu |  |
| 440 |  |  [InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model](https://aclanthology.org/2025.findings-acl.340/) |  | 0 | Despite the promising performance of Large Vision Language Models (LVLMs) in visual understanding, they occasionally generate incorrect outputs. While reward models (RMs) with reinforcement learning or test-time scaling offer the potential for improving generation quality, a critical gap remains:... | Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang |  |
| 441 |  |  [RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models](https://aclanthology.org/2025.findings-acl.341/) |  | 0 | Object Navigation (ObjectNav) is a fundamental task in embodied artificial intelligence. Although significant progress has been made in semantic map construction and target direction prediction in current research, redundant exploration and exploration failures remain inevitable. A critical but... | Junjie Li, Nan Zhang, Xiaoyang Qu, Kai Lu, Guokuan Li, Jiguang Wan, Jianzong Wang |  |
| 442 |  |  [RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation](https://aclanthology.org/2025.findings-acl.342/) |  | 0 | Although multi-agent systems based on large language models show strong capabilities on multiple tasks, they are still limited by high computational overhead, information loss, and robustness. Inspired by ResNet’s residual learning, we propose Residual Mixture-of-Agents (RMoA), integrating residual... | Zhentao Xie, Chengcheng Han, Jinxin Shi, Wenjun Cui, Xin Zhao, Xingjiao Wu, Jiabao Zhao |  |
| 443 |  |  [Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction](https://aclanthology.org/2025.findings-acl.343/) |  | 0 | The improvement of LLMs’ instruction-following capabilities depends critically on the availability of high-quality instruction-response pairs. While existing automatic data synthetic methods alleviate the burden of manual curation, they often rely heavily on either the quality of seed data or... | Yuxin Jiang, Yufei Wang, Chuhan Wu, Xinyi Dai, Yan Xu, Weinan Gan, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang |  |
| 444 |  |  [RLKGF: Reinforcement Learning from Knowledge Graph Feedback Without Human Annotations](https://aclanthology.org/2025.findings-acl.344/) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has been shown to effectively align large language models (LLMs) with human knowledge. However, the lack of human preference labels remains a significant bottleneck when applying RLHF to a downstream domain. Humans in RLHF play a critical role in... | Lian Yan, Chen Tang, Yi Guan, Haotian Wang, Songyuan Wang, Haifeng Liu, Yang Yang, Jingchi Jiang |  |
| 445 |  |  [Learning Task Representations from In-Context Learning](https://aclanthology.org/2025.findings-acl.345/) |  | 0 | Large language models (LLMs) have demonstrated remarkable proficiency in in-context learning (ICL), where models adapt to new tasks through example-based prompts without requiring parameter updates. However, understanding how tasks are internally encoded and generalized remains a challenge. To... | Baturay Saglam, Xinyang Hu, Zhuoran Yang, Dionysis Kalogerias, Amin Karbasi |  |
| 446 |  |  [CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](https://aclanthology.org/2025.findings-acl.346/) |  | 0 | Security alignment enables the Large Language Model (LLM) to gain the protection against malicious queries, but various jailbreak attack methods reveal the vulnerability of this security mechanism. Previous studies have isolated LLM jailbreak attacks and defenses. We analyze the security protection... | Xiaohu Li, Yunfeng Ning, Zepeng Bao, Mayi Xu, Jianhao Chen, Tieyun Qian |  |
| 447 |  |  [Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions](https://aclanthology.org/2025.findings-acl.347/) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities across various tasks, but their deployment in high-stake domains requires consistent and coherent behavior across multiple rounds of user interaction. This paper introduces a comprehensive framework for evaluating and improving LLM... | Yubo Li, Yidi Miao, Xueying Ding, Ramayya Krishnan, Rema Padman |  |
| 448 |  |  [OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents](https://aclanthology.org/2025.findings-acl.348/) |  | 0 | Autonomous graphical user interface (GUI) agents powered by multimodal large language models have shown great promise. However, a critical yet underexplored issue persists: over-execution, where the agent executes tasks in a fully autonomous way, without adequate assessment of its action confidence... | Pengzhou Cheng, Zheng Wu, Zongru Wu, Tianjie Ju, Aston Zhang, Zhuosheng Zhang, Gongshen Liu |  |
| 449 |  |  [Red-Teaming LLM Multi-Agent Systems via Communication Attacks](https://aclanthology.org/2025.findings-acl.349/) |  | 0 | Large Language Model-based Multi-Agent Systems (LLM-MAS) have revolutionized complex problem-solving capability by enabling sophisticated agent collaboration through message-based communications. While the communication framework is crucial for agent coordination, it also introduces a critical yet... | Pengfei He, Yuping Lin, Shen Dong, Han Xu, Yue Xing, Hui Liu |  |
| 450 |  |  [Can We Trust AI Doctors? A Survey of Medical Hallucination in Large Language and Large Vision-Language Models](https://aclanthology.org/2025.findings-acl.350/) |  | 0 | Hallucination has emerged as a critical challenge for large language models (LLMs) and large vision-language models (LVLMs), particularly in high-stakes medical applications. Despite its significance, dedicated research on medical hallucination remains unexplored. In this survey, we first provide a... | Zhihong Zhu, Yunyan Zhang, Xianwei Zhuang, Fan Zhang, Zhongwei Wan, Yuyan Chen, Qingqing Long, Yefeng Zheng, Xian Wu |  |
| 451 |  |  [DRT: Deep Reasoning Translation via Long Chain-of-Thought](https://aclanthology.org/2025.findings-acl.351/) |  | 0 | Recently, O1-like models have emerged as representative examples, illustrating the effectiveness of long chain-of-thought (CoT) in reasoning tasks such as math and coding tasks. In this paper, we introduce DRT, an attempt to bring the success of long CoT to neural machine translation (MT).... | Jiaan Wang, Fandong Meng, Yunlong Liang, Jie Zhou |  |
| 452 |  |  [CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis](https://aclanthology.org/2025.findings-acl.352/) |  | 0 | Integrating multimodal clinical records—such as Electronic Health Records (EHR) and free-text clinical reports—has shown great potential in predicting clinical outcomes. However, prior work has primarily focused on capturing temporal interactions within individual samples and fusing multimodal... | Fuying Wang, Feng Wu, Yihan Tang, Lequan Yu |  |
| 453 |  |  [Vision-aided Unsupervised Constituency Parsing with Multi-MLLM Debating](https://aclanthology.org/2025.findings-acl.353/) |  | 0 | This paper presents a novel framework for vision-aided unsupervised constituency parsing (VUCP), leveraging multimodal large language models (MLLMs) pre-trained on diverse image-text or video-text data. Unlike previous methods requiring explicit cross-modal alignment, our approach eliminates this... | Dong Zhang, Haiyan Tian, Qingying Sun, Shoushan Li |  |
| 454 |  |  [Inter-Passage Verification for Multi-evidence Multi-answer QA](https://aclanthology.org/2025.findings-acl.354/) |  | 0 | Multi-answer question answering (QA), where questions can have many valid answers, presents a significant challenge for existing retrieval-augmented generation-based QA systems, as these systems struggle to retrieve and then synthesize a large number of evidence passages. To tackle these... | Bingsen Chen, Shenji Wan, Xi Ye, Chen Zhao |  |
| 455 |  |  [PROMTEC: Fast LLM Inference Decoding using Prompt Multi-Lookup with Template Database and Common Sequences](https://aclanthology.org/2025.findings-acl.355/) |  | 0 | We propose PROMTEC, a novel multi-faceted approach to accelerate the inference of large language models (LLMs) by leveraging three key techniques: Prompt Multi-Lookup, Template Datastore, and Common Sequences methods. Prompt Multi-Lookup enhances the autoregressive decoding efficiency by generating... | Alan ChiMan Lee, WingSun Cheng, Calvin ChunKit Chan |  |
| 456 |  |  [Logical DA: Enhancing Data Augmentation for Logical Reasoning via a Multi-Agent System](https://aclanthology.org/2025.findings-acl.356/) |  | 0 | Recent advancements in large language models (LLMs) have highlighted the importance of improving their reasoning capabilities. A critical challenge lies in the scarcity of high-quality reasoning data—characterized by diversity and rich supervisory signals—necessary for robust model training. While... | Haoqi Zheng, DongWang DongWang, Silin Yang, Yunpeng Qi, Ruochun Jin, Liyang Xu |  |
| 457 |  |  [Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval](https://aclanthology.org/2025.findings-acl.357/) |  | 0 | Text embedding models play a cornerstone role in AI applications, such as retrieval-augmented generation (RAG). While general-purpose text embedding models demonstrate strong performance on generic retrieval benchmarks, their effectiveness diminishes when applied to private datasets (e.g.,... | Yubai Wei, Jiale Han, Yi Yang |  |
| 458 |  |  [SQL Injection Jailbreak: A Structural Disaster of Large Language Models](https://aclanthology.org/2025.findings-acl.358/) |  | 0 | Large Language Models (LLMs) are susceptible to jailbreak attacks that can induce them to generate harmful content.Previous jailbreak methods primarily exploited the internal properties or capabilities of LLMs, such as optimization-based jailbreak methods and methods that leveraged the model’s... | Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu |  |
| 459 |  |  [TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.359/) |  | 0 | Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields... | Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang |  |
| 460 |  |  [Generative Music Models' Alignment with Professional and Amateur Users' Expectations](https://aclanthology.org/2025.findings-acl.360/) |  | 0 | Recent years have witnessed rapid advancements in text-to-music generation using large language models, yielding notable outputs. A critical challenge is understanding users with diverse musical expertise and generating music that meets their expectations, an area that remains underexplored.To... | Zihao Wang, Jiaxing Yu, Haoxuan Liu, Zehui Zheng, Yuhang Jin, Shuyu Li, Shulei Ji, Kejun Zhang |  |
| 461 |  |  [LLM-Forest: Ensemble Learning of LLMs with Graph-Augmented Prompts for Data Imputation](https://aclanthology.org/2025.findings-acl.361/) |  | 0 | Missing data imputation is a critical challenge in various domains, such as healthcare and finance, where data completeness is vital for accurate analysis. Large language models (LLMs), trained on vast corpora, have shown strong potential in data generation, making them a promising tool for data... | Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He |  |
| 462 |  |  [Task Calibration: Calibrating Large Language Models on Inference Tasks](https://aclanthology.org/2025.findings-acl.362/) |  | 0 | Large language models (LLMs) have exhibited impressive zero-shot performance on inference tasks. However, LLMs may suffer from spurious correlations between input texts and output labels, which limits LLMs’ ability to reason based purely on general language understanding. For example, in the... | Yingjie Li, Yun Luo, Xiaotian Xie, Yue Zhang |  |
| 463 |  |  [MiniELM: A Lightweight and Adaptive Query Rewriting Framework for E-Commerce Search Optimization](https://aclanthology.org/2025.findings-acl.363/) |  | 0 | Query rewriting (QR) is a critical technique in e-commerce search, addressing the lexical gap between user queries and product descriptions to enhance search performance. Existing QR approaches typically fall into two categories: discriminative models and generative methods leveraging large... | Duy A. Nguyen, Rishi Kesav Mohan, Shimeng Yang, Pritom Saha Akash, Kevin ChenChuan Chang |  |
| 464 |  |  [Visibility as Survival: Generalizing NLP for Native Alaskan Language Identification](https://aclanthology.org/2025.findings-acl.364/) |  | 0 | Indigenous languages remain largely invisible in commercial language identification (LID) systems, a stark reality exemplified by Google Translate’s LangID tool, which supports over 100 languages but excludes all 150 Indigenous languages of North America. This technological marginalization is... | Ivory Yang, Chunhui Zhang, Yuxin Wang, Zhongyu Ouyang, Soroush Vosoughi |  |
| 465 |  |  [KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding](https://aclanthology.org/2025.findings-acl.365/) |  | 0 | We introduce KodCode, a synthetic dataset that addresses the persistent challenge of acquiring high-quality, verifiable training data across diverse difficulties and domains for training Large Language Models for coding. Existing code-focused resources typically fail to ensure either the breadth of... | Zhangchen Xu, Yang Liu, Yueqin Yin, Mingyuan Zhou, Radha Poovendran |  |
| 466 |  |  [Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation](https://aclanthology.org/2025.findings-acl.366/) |  | 0 | Automatic related work generation (RWG) can save people’s time and effort when writing a draft of related work section (RWS) for further revision. However, existing methods for RWG always suffer from shallow comprehension due to taking the limited portions of references papers as input and isolated... | Xiaochuan Liu, Ruihua Song, Xiting Wang, Xu Chen |  |
| 467 |  |  [Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic languages](https://aclanthology.org/2025.findings-acl.367/) |  | 0 | Translating multi-word expressions (MWEs) and idioms requires a deep understanding of the cultural nuances of both the source and target languages. This challenge is further amplified by the one-to-many nature of idiomatic translations, where a single source idiom can have multiple target-language... | Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik |  |
| 468 |  |  [Question Answering in Climate Adaptation for Agriculture: Model Development and Evaluation with Expert Feedback](https://aclanthology.org/2025.findings-acl.368/) |  | 0 | The generative capabilities of the large language models (LLMs) are deployed for domain-specific question answering systems. However, their ability to answer climate adaptation questions remains unclear. In particular, can they be used by agronomists and climate scientists to answer questions on... | Vincent Nguyen, Sarvnaz Karimi, Willow Hallgren, Mahesh Prakash |  |
| 469 |  |  [AGRec: Adapting Autoregressive Decoders with Graph Reasoning for LLM-based Sequential Recommendation](https://aclanthology.org/2025.findings-acl.369/) |  | 0 | Autoregressive decoders in large language models (LLMs) excel at capturing users’ sequential behaviors for generative recommendations. However, they inherently struggle to leverage graph-structured user-item interactions, which are widely recognized as beneficial. This paper presents AGRec,... | Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki |  |
| 470 |  |  [Causal Denoising Prototypical Network for Few-Shot Multi-label Aspect Category Detection](https://aclanthology.org/2025.findings-acl.370/) |  | 0 | The multi-label aspect category detection (MACD) task has attracted great attention in sentiment analysis. Many recent methods have formulated the MACD task by learning robust prototypes to represent categories with limited support samples. However, few of them address the noise categories in the... | Jin Cui, Xinfeng Wang, Yoshimi Suzuki, Fumiyo Fukumoto |  |
| 471 |  |  [RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis](https://aclanthology.org/2025.findings-acl.371/) |  | 0 | With the rapid advancement of Large Language Models (LLMs), there is an increasing need for challenging benchmarks to evaluate their capabilities in handling complex tabular data. However, existing benchmarks are either based on outdated data setups or focus solely on simple, flat table structures.... | Pengzuo Wu, Yuhang Yang, Guangcheng Zhu, Chao Ye, Hong Gu, Xu Lu, Ruixuan Xiao, Bowen Bao, Yijing He, Liangyu Zha, Wentao Ye, Junbo Zhao, Haobo Wang |  |
| 472 |  |  [A Query-Response Framework for Whole-Page Complex-Layout Document Image Translation with Relevant Regional Concentration](https://aclanthology.org/2025.findings-acl.372/) |  | 0 | Document Image Translation (DIT), which aims at translating documents in images from source language to the target, plays an important role in Document Intelligence. It requires a comprehensive understanding of document multi-modalities and a focused concentration on relevant textual regions during... | Zhiyang Zhang, Yaping Zhang, Yupu Liang, Zhiyuan Chen, Lu Xiang, Yang Zhao, Yu Zhou, Chengqing Zong |  |
| 473 |  |  [DependEval: Benchmarking LLMs for Repository Dependency Understanding](https://aclanthology.org/2025.findings-acl.373/) |  | 0 | While large language models (LLMs) have shown considerable promise in code generation, real-world software development demands advanced repository-level reasoning. This includes understanding dependencies, project structures, and managing multi-file changes. However, the ability of LLMs to... | Junjia Du, Yadi Liu, Hongcheng Guo, Jiawei Wang, Haojian Huang, Yunyi Ni, Zhoujun Li |  |
| 474 |  |  [A General Knowledge Injection Framework for ICD Coding](https://aclanthology.org/2025.findings-acl.374/) |  | 0 | ICD Coding aims to assign a wide range of medical codes to a medical text document, which is a popular and challenging task in the healthcare domain. To alleviate the problems of long-tail distribution and the lack of annotations of code-specific evidence, many previous works have proposed... | Xu Zhang, Kun Zhang, Wenxin Ma, Rongsheng Wang, Chenxu Wu, Yingtai Li, S. Kevin Zhou |  |
| 475 |  |  [MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.375/) |  | 0 | Recent progress in Machine Unlearning (MU) has introduced solutions for the selective removal of private or sensitive information encoded within deep neural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs) remains in its nascent phase. Therefore, we propose to \*\*reformulate... | Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu |  |
| 476 |  |  [Generating Questions, Answers, and Distractors for Videos: Exploring Semantic Uncertainty of Object Motions](https://aclanthology.org/2025.findings-acl.376/) |  | 0 | Video Question-Answer-Distractors (QADs) show promising values for assessing the performance of systems in perceiving and comprehending multimedia content. Given the significant cost and labor demands of manual annotation, existing large-scale Video QADs benchmarks are typically generated... | Wenjian Ding, Yao Zhang, Jun Wang, Adam Jatowt, Zhenglu Yang |  |
| 477 |  |  [DiffSkip: Differential Layer Skipping in Large Language Models](https://aclanthology.org/2025.findings-acl.377/) |  | 0 | Existing Large Language Models (LLMs) enforce uniform computation across all tokens. We analyze the correlation between the input-output difference of self-attention block and Feed-Forward Network (FFN) within the same transformer layer, and find that these two differential vectors are highly... | Xuan Luo, Weizhi Wang, Xifeng Yan |  |
| 478 |  |  [Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework](https://aclanthology.org/2025.findings-acl.378/) |  | 0 | While large language models (LLMs) show great potential in temporal reasoning, most existing work focuses heavily on enhancing performance, often neglecting the explainable reasoning processes underlying the results. To address this gap, we introduce a comprehensive benchmark covering a wide range... | Zihao Jiang, Ben Liu, Miao Peng, Wenjie Xu, Yao Xiao, Zhenyan Shan, Min Peng |  |
| 479 |  |  [A Bounding Box is Worth One Token - Interleaving Layout and Text in a Large Language Model for Document Understanding](https://aclanthology.org/2025.findings-acl.379/) |  | 0 | Recently, many studies have demonstrated that exclusively incorporating OCR-derived text and spatial layouts with large language models (LLMs) can be highly effective for document understanding tasks. However, existing methods that integrate spatial layouts with text have limitations, such as... | Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang |  |
| 480 |  |  [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://aclanthology.org/2025.findings-acl.380/) |  | 0 | Large language models (LLMs) with instruction following capabilities have demonstrated impressive problem-solving abilities. While synthesizing instructional data from unsupervised text has become a common approach for training such models, conventional methods rely heavily on human effort for data... | Mingzhe Li, Xin Lu, Yanyan Zhao |  |
| 481 |  |  [TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning](https://aclanthology.org/2025.findings-acl.381/) |  | 0 | Despite the commendable progress of recent LLM-based data synthesis methods, they face two limitations in generating table instruction tuning data. First, they can not thoroughly explore the vast input space of table understanding tasks, leading to limited data diversity. Second, they ignore the... | Mingyu Zheng, Zhifan Feng, Jia Wang, Lanrui Wang, Zheng Lin, Hao Yang, Weiping Wang |  |
| 482 |  |  [Konooz: Multi-domain Multi-dialect Corpus for Named Entity Recognition](https://aclanthology.org/2025.findings-acl.382/) |  | 0 | We introduce , a novel multi-dimensional corpus covering 16 Arabic dialects across 10 domains, resulting in 160 distinct corpora. The corpus comprises about 777k tokens, carefully collected and manually annotated with 21 entity types using both nested and flat annotation schemes - using the Wojood... | Nagham Hamad, Mohammed Khalilia, Mustafa Jarrar |  |
| 483 |  |  [Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation](https://aclanthology.org/2025.findings-acl.383/) |  | 0 | Text-to-image models are powerful for producing high-quality images based on given text prompts, but crafting these prompts often requires specialized vocabulary. To address this, existing methods train rewriting models with supervision from large amounts of manually annotated data and trained... | Hongji Yang, Yucheng Zhou, Wencheng Han, Jianbing Shen |  |
| 484 |  |  [CodeV: Issue Resolving with Visual Data](https://aclanthology.org/2025.findings-acl.384/) |  | 0 | Large Language Models (LLMs) have advanced rapidly in recent years, with their applications in software engineering expanding to more complex repository-level tasks. GitHub issue resolving is a key challenge among these tasks. While recent approaches have made progress on this task, they focus on... | Linhao Zhang, Daoguang Zan, Quanshun Yang, Zhirong Huang, Dong Chen, Bo Shen, Tianyu Liu, Yongshun Gong, Pengjie Huang, Xudong Lu, Guangtai Liang, Lizhen Cui, Qianxiang Wang |  |
| 485 |  |  [A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions](https://aclanthology.org/2025.findings-acl.385/) |  | 0 | Mental health is increasingly critical in contemporary healthcare, with psychotherapy demanding dynamic, context-sensitive interactions that traditional NLP methods struggle to capture. Large Language Models (LLMs) offer significant potential for addressing this gap due to their ability to handle... | Hongbin Na, Yining Hua, Zimu Wang, Tao Shen, Beibei Yu, Lilin Wang, Wei Wang, John B. Torous, Ling Chen |  |
| 486 |  |  [Breaking the Reasoning Barrier A Survey on LLM Complex Reasoning through the Lens of Self-Evolution](https://aclanthology.org/2025.findings-acl.386/) |  | 0 | The release of OpenAI’s O1 and subsequent projects like DeepSeek R1 has significantly advanced research on complex reasoning in LLMs. This paper systematically analyzes existing reasoning studies from the perspective of self-evolution, structured into three components: data evolution, model... | Tao He, Hao Li, Jingchang Chen, Runxuan Liu, Yixin Cao, Lizi Liao, Zihao Zheng, Zheng Chu, Jiafeng Liang, Ming Liu, Bing Qin |  |
| 487 |  |  [SEE: Continual Fine-tuning with Sequential Ensemble of Experts](https://aclanthology.org/2025.findings-acl.387/) |  | 0 | Continual fine-tuning of large language models (LLMs) suffers from catastrophic forgetting. Rehearsal-based methods mitigate this problem by retaining a small set of old data. Nevertheless, they still suffer inevitable performance loss. Although training separate experts for each task can help... | Zhilin Wang, Yafu Li, Xiaoye Qu, Yu Cheng |  |
| 488 |  |  [Boosting Policy and Process Reward Models with Monte Carlo Tree Search in Open-Domain QA](https://aclanthology.org/2025.findings-acl.388/) |  | 0 | The recent introduction of OpenAI’s O1/O3 model represents a significant milestone in developing strong reasoning capabilities in Large Language Models (LLMs). By introducing more computational budget during test-time, LLMs have the potential to explore more accurate and higher-quality solutions.... | ChiMin Chan, Chunpu Xu, Junqi Zhu, Jiaming Ji, Donghai Hong, Pengcheng Wen, Chunyang Jiang, Zhen Ye, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo |  |
| 489 |  |  [Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models](https://aclanthology.org/2025.findings-acl.389/) |  | 0 | Omnimodal Large Language Models (OLLMs) have shown significant progress in integrating vision and text, but still struggle with integrating vision and audio, often exhibiting suboptimal performance when processing audio queries compared to text queries. This disparity is primarily due to... | Rui Hu, Delai Qiu, Shuyu Wei, Jiaming Zhang, Yining Wang, Shengping Liu, Jitao Sang |  |
| 490 |  |  [OpenHuEval: Evaluating Large Language Model on Hungarian Specifics](https://aclanthology.org/2025.findings-acl.390/) |  | 0 | We introduce OpenHuEval, the first benchmark for LLMs focusing on the Hungarian language and specifics. OpenHuEval is constructed from a vast collection of Hungarian-specific materials sourced from multiple origins. In the construction, we incorporated the latest design principles for evaluating... | Haote Yang, Xingjian Wei, Jiang Wu, Noémi LigetiNagy, Jiaxing Sun, Yinfan Wang, Zijian Gyozo Yang, Junyuan Gao, Jingchao Wang, Bowen Jiang, Shasha Wang, Nanjun Yu, Zihao Zhang, Shixin Hong, Hongwei Liu, Wei Li, Songyang Zhang, Dahua Lin, Lijun Wu, Gábor Prószéky, Conghui He |  |
| 491 |  |  [StructFact: Reasoning Factual Knowledge from Structured Data with Large Language Models](https://aclanthology.org/2025.findings-acl.391/) |  | 0 | Large language models (LLMs) have made significant strides in natural language processing by leveraging their ability to comprehend and reason with factual knowledge. However, a significant amount of factual knowledge is stored in structured data, which has unique characteristics not typically... | Sirui Huang, Yanggan Gu, Zhonghao Li, Xuming Hu, Qing Li, Guandong Xu |  |
| 492 |  |  [From Imitation to Introspection: Probing Self-Consciousness in Language Models](https://aclanthology.org/2025.findings-acl.392/) |  | 0 | Self-consciousness, the introspection of one’s existence and thoughts, represents a high-level cognitive process. As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious? Drawing upon insights from psychological and neural science,... | Sirui Chen, Shu Yu, Shengjie Zhao, Chaochao Lu |  |
| 493 |  |  [DocFusion: A Unified Framework for Document Parsing Tasks](https://aclanthology.org/2025.findings-acl.393/) |  | 0 | Document parsing involves layout element detection and recognition, essential for extracting information. However, existing methods often employ multiple models for these tasks, leading to increased system complexity and maintenance overhead. While some models attempt to unify detection and... | Mingxu Chai, Ziyu Shen, Chong Zhang, Yue Zhang, Xiao Wang, Shihan Dou, Jihua Kang, Jiazheng Zhang, Qi Zhang |  |
| 494 |  |  [Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models](https://aclanthology.org/2025.findings-acl.394/) |  | 0 | With the increasing size of Large Vision-Language Models (LVLMs), network pruning techniques aimed at compressing models for deployment in resource-constrained environments have garnered significant attention. However, we observe that pruning often leads to a degradation in safety performance. To... | Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang |  |
| 495 |  |  [LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information](https://aclanthology.org/2025.findings-acl.395/) |  | 0 | Recent advancements in large language models (LLMs) have markedly improved their capacity to handle long text inputs; however, current models, including GPT-4o, still exhibit unsatisfactory performance in long-form generation. Generating high-quality long-form content still remains a significant... | Bowen Ping, Jiali Zeng, Fandong Meng, Shuo Wang, Jie Zhou, Shanghang Zhang |  |
| 496 |  |  [Reinforcing Compositional Retrieval: Retrieving Step-by-Step for Composing Informative Contexts](https://aclanthology.org/2025.findings-acl.396/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet they often rely on external context to handle complex tasks. While retrieval-augmented frameworks traditionally focus on selecting top-ranked documents in a single pass, many real-world scenarios... | Quanyu Long, Jianda Chen, Zhengyuan Liu, Nancy F. Chen, Wenya Wang, Sinno Jialin Pan |  |
| 497 |  |  [Towards A Better Initial Policy Model For Scalable Long-CoT Reinforcement Learning](https://aclanthology.org/2025.findings-acl.397/) |  | 0 | Long-CoT reasoning combined with reinforcement learning for large language models demonstrates remarkable performance and scalability. However, we observe that the initial policy model could significantly influence the final performance as well as the token efficiency. Additionally, there is a lack... | Bofei Gao, Yejie Wang, Yibo Miao, Ruoyu Wu, Feifan Song, Longhui Yu, Tianyu Liu, Baobao Chang |  |
| 498 |  |  [Topic Modeling for Short Texts via Optimal Transport-Based Clustering](https://aclanthology.org/2025.findings-acl.398/) |  | 0 | Discovering topics and learning document representations in topic space are two crucial aspects of topic modeling, particularly in the short-text setting, where inferring topic proportions for individual documents is highly challenging. Despite significant progress in neural topic modeling,... | Tu Vu, Manh Do, Tung Nguyen, Ngo Van Linh, Sang Dinh, Thien Huu Nguyen |  |
| 499 |  |  [Lemmatisation & Morphological Analysis of Unedited Greek: Do Simple Tasks Need Complex Solutions?](https://aclanthology.org/2025.findings-acl.399/) |  | 0 | Fine-tuning transformer-based models for part-of-speech tagging of unedited Greek text has outperformed traditional systems. However, when applied to lemmatisation or morphological analysis, fine-tuning has not yet achieved competitive results. This paper explores various approaches to combine... | Colin Swaelens, Ilse De Vos, Els Lefever |  |
| 500 |  |  [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://aclanthology.org/2025.findings-acl.400/) |  | 0 | The automation of scientific research through large language models (LLMs) presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance. We introduce Feedback-Refined Agent Methodology (FRAME), a novel framework that enhances medical paper generation... | Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin |  |
| 501 |  |  [Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models](https://aclanthology.org/2025.findings-acl.401/) |  | 0 | Large Language Models (LLMs), especially those accessed via APIs, have demonstrated impressive capabilities across various domains. However, users without technical expertise often turn to (untrustworthy) third-party services, such as prompt engineering, to enhance their LLM experience, creating... | Xi Li, Ruofan Mao, Yusen Zhang, Renze Lou, Chen Wu, Jiaqi Wang |  |
| 502 |  |  [Relevance Scores Calibration for Ranked List Truncation via TMP Adapter](https://aclanthology.org/2025.findings-acl.402/) |  | 0 | The ranked list truncation task involves determining a truncation point to retrieve the relevant items from a ranked list. Despite current advancements, truncation methods struggle with limited capacity, unstable training and inconsistency of selected threshold. To address these problems we... | Pavel Posokhov, Sergei Masliukhin, Skrylnikov Stepan, Danil Tirskikh, Olesia Makhnytkina |  |
| 503 |  |  [Neuron Activation Modulation for Text Style Transfer: Guiding Large Language Models](https://aclanthology.org/2025.findings-acl.403/) |  | 0 | Text style transfer (TST) aims to flexibly adjust the style of text while preserving its core content. Although large language models (LLMs) excel in TST tasks, they often face unidirectional issues due to imbalanced training data and their tendency to generate safer responses. These challenges... | Chaona Kong, Jianyi Liu, Yifan Tang, Ru Zhang |  |
| 504 |  |  [MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering](https://aclanthology.org/2025.findings-acl.404/) |  | 0 | Text-Centric Visual Question Answering (TEC-VQA) in its proper format not only facilitates human-machine interaction in text-centric visual environments but also serves as a de facto gold proxy to evaluate AI models in the domain of text-centric scene understanding. Nonetheless, most existing... | Jingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, AnLan Wang, Chunhui Lin, Hao Feng, Zhen Zhao, Yanjie Wang, Yuliang Liu, Hao Liu, Xiang Bai, Can Huang |  |
| 505 |  |  [HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models](https://aclanthology.org/2025.findings-acl.405/) |  | 0 | Large Language Models (LLMs) often generate hallucinations, producing outputs that are contextually inaccurate or factually incorrect. We introduce HICD, a novel method designed to induce hallucinations for contrastive decoding to mitigate hallucinations. Unlike existing contrastive decoding... | Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong |  |
| 506 |  |  [Understanding the Repeat Curse in Large Language Models from a Feature Perspective](https://aclanthology.org/2025.findings-acl.406/) |  | 0 | Large language models (LLMs) have made remarkable progress in various domains, yet they often suffer from repetitive text generation, a phenomenon we refer to as the ”Repeat Curse”. While previous studies have proposed decoding strategies to mitigate repetition, the underlying mechanism behind this... | Junchi Yao, Shu Yang, Jianhua Xu, Lijie Hu, Mengdi Li, Di Wang |  |
| 507 |  |  [Code-Switching Curriculum Learning for Multilingual Transfer in LLMs](https://aclanthology.org/2025.findings-acl.407/) |  | 0 | Large language models (LLMs) now exhibit near human-level performance in various tasks, but their performance drops drastically after a handful of high-resource languages due to the imbalance in pre-training data. Inspired by the human process of second language acquisition, particularly... | Haneul Yoo, Cheonbok Park, Sangdoo Yun, Alice Oh, Hwaran Lee |  |
| 508 |  |  [A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos](https://aclanthology.org/2025.findings-acl.408/) |  | 0 | Large Reasoning Models (LRMs) have significantly advanced beyond traditional Large Language Models (LLMs) with their exceptional logical reasoning capabilities, yet these improvements introduce heightened safety risks. When subjected to jailbreak attacks, their ability to generate more targeted and... | Yang Yao, Xuan Tong, Ruofan Wang, Yixu Wang, Lujundong Li, Liang Liu, Yan Teng, Yingchun Wang |  |
| 509 |  |  [Tag-Evol: Achieving Efficient Instruction Evolving via Tag Injection](https://aclanthology.org/2025.findings-acl.409/) |  | 0 | Evol-Instruct has made significant improvements as a data synthesis method in several areas. Existing methods typically rely on a fixed set of strategies to evolve, which require manual design and are monolithic in form. In addition, iterative evolution also makes the acquisition of hard samples... | Yixuan Wang, Shiqi Zhou, Chuanzhe Guo, Qingfu Zhu |  |
| 510 |  |  [Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space](https://aclanthology.org/2025.findings-acl.410/) |  | 0 | Large Language Models (LLMs), despite advanced general capabilities, still suffer from numerous safety risks, especially jailbreak attacks that bypass safety protocols. Understanding these vulnerabilities through black-box jailbreak attacks, which better reflect real-world scenarios, offers... | Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei |  |
| 511 |  |  [GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns](https://aclanthology.org/2025.findings-acl.411/) |  | 0 | A significant portion of the textual data used in the field of Natural Language Processing (NLP) exhibits gender biases, particularly due to the use of masculine generics (masculine words that are supposed to refer to mixed groups of men and women), which can perpetuate and amplify stereotypes.... | Enzo Doyen, Amalia Todirascu |  |
| 512 |  |  [LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews](https://aclanthology.org/2025.findings-acl.412/) |  | 0 | The scientific literature is growing rapidly, making it hard to keep track of the state-of-the-art. Systematic literature reviews (SLRs) aim to identify and evaluate all relevant papers on a topic. After retrieving a set of candidate papers, the abstract screening phase determines initial... | Christian Jaumann, Andreas Wiedholz, Annemarie Friedrich |  |
| 513 |  |  [LCHAIM - Investigating Long Context Reasoning in Hebrew](https://aclanthology.org/2025.findings-acl.413/) |  | 0 | Natural Language Inference (NLI) has gained significant attention recently due to its importance in understanding how machines comprehend and reason about language. While English has received tremendous interest, Morphologically Rich Languages (MRLs) like Hebrew, require more research. In this... | Ehud Malul, Oriel Perets, Ziv Mor, Yigal Kassel, Elior Sulem |  |
| 514 |  |  [CLeVeR: Multi-modal Contrastive Learning for Vulnerability Code Representation](https://aclanthology.org/2025.findings-acl.414/) |  | 0 | Automated vulnerability detection has become increasingly important. Many existing methods utilize deep learning models to obtain code representations for vulnerability detection. However, these approaches predominantly capture the overall semantics of the code rather than its intrinsic... | Jiayuan Li, Lei Cui, Sen Zhao, Yun Yang, Lun Li, Hongsong Zhu |  |
| 515 |  |  [MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs](https://aclanthology.org/2025.findings-acl.415/) |  | 0 | As large language models (LLMs) continue to scale up, knowledge editing techniques that modify models’ internal knowledge without full retraining have gained significant attention. MEMIT, a prominent batch editing algorithm, stands out for its capability to perform mass knowledge modifications.... | Zilu Dong, Xiangqing Shen, Rui Xia |  |
| 516 |  |  [Large Language Models for Predictive Analysis: How Far Are They?](https://aclanthology.org/2025.findings-acl.416/) |  | 0 | Predictive analysis is a cornerstone of modern decision-making, with applications in various domains. Large Language Models (LLMs) have emerged as powerful tools in enabling nuanced, knowledge-intensive conversations, thus aiding in complex decision-making tasks. With the burgeoning expectation to... | Qin Chen, Yuanyi Ren, Xiaojun Ma, Yuyang Shi |  |
| 517 |  |  [Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking](https://aclanthology.org/2025.findings-acl.417/) |  | 0 | Large language models (LLMs) demonstrate exceptional capabilities, yet still face the hallucination issue. Typical text generation approaches adopt an auto-regressive generation without deliberate reasoning, often leading to untrustworthy and factually inaccurate responses. In this paper, we... | Xiaoxue Cheng, Junyi Li, Xin Zhao, JiRong Wen |  |
| 518 |  |  [Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.418/) |  | 0 | Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge from external knowledge bases into models, has emerged as a promising approach to enhancing response accuracy while mitigating factual errors and hallucinations. This method has been widely applied in tasks such as... | Qitao Qin, Yucong Luo, Yihang Lu, Zhibo Chu, Xiaoman Liu, Xianwei Meng |  |
| 519 |  |  [Enhancing Cross-Tokenizer Knowledge Distillation with Contextual Dynamical Mapping](https://aclanthology.org/2025.findings-acl.419/) |  | 0 | Knowledge Distillation (KD) has emerged as a prominent technique for model compression. However, conventional KD approaches primarily focus on homogeneous architectures with identical tokenizers, constraining their applicability in cross-architecture scenarios. As for the cross-tokenizer KD, the... | Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou |  |
| 520 |  |  [A Semantic-Aware Layer-Freezing Approach to Computation-Efficient Fine-Tuning of Language Models](https://aclanthology.org/2025.findings-acl.420/) |  | 0 | Finetuning language models (LMs) is crucial for adapting the models to downstream data and tasks. However, full finetuning is usually costly. Existing work, such as parameter-efficient finetuning (PEFT), often focuses on how to finetune but neglects the issue of where to finetune. As a pioneering... | Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang |  |
| 521 |  |  [CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels](https://aclanthology.org/2025.findings-acl.421/) |  | 0 | Large language models (LLMs) have been well-researched in various long-context tasks. However, the scarcity of long-context summarization datasets hinders progress in this area. To address this, we introduce CNNSum, a multi-scale long-context summarization benchmark based on Chinese novels,... | Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang |  |
| 522 |  |  [Document Segmentation Matters for Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.422/) |  | 0 | Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge. A critical yet underexplored challenge in RAG is document segmentation, also known as document chunking. Existing widely-used rule-based chunking methods usually lead to suboptimal splits,... | Zhitong Wang, Cheng Gao, Chaojun Xiao, Yufei Huang, Shuzheng Si, Kangyang Luo, Yuzhuo Bai, Wenhao Li, Tangjian Duan, Chuancheng Lv, Guoshan Lu, Gang Chen, Fanchao Qi, Maosong Sun |  |
| 523 |  |  [UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions](https://aclanthology.org/2025.findings-acl.423/) |  | 0 | Despite recent progress in systematic evaluation frameworks, benchmarking the uncertainty of large language models (LLMs) remains a highly challenging task. Existing methods for benchmarking the uncertainty of LLMs face three key challenges: the need for internal model access, additional training,... | Xunzhi Wang, Zhuowei Zhang, Gaonan Chen, Qiongyu Li, Bitong Luo, Zhixin Han, Haotian Wang, Zhiyu Li, Hang Gao, Mengting Hu |  |
| 524 |  |  [Embracing Large Language Models in Traffic Flow Forecasting](https://aclanthology.org/2025.findings-acl.424/) |  | 0 | Traffic flow forecasting aims to predict future traffic flows based on historical traffic conditions and the road network. It is an important problem in intelligent transportation systems, with a plethora of methods being proposed. Existing efforts mainly focus on capturing and utilizing... | Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang |  |
| 525 |  |  [Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability](https://aclanthology.org/2025.findings-acl.425/) |  | 0 | While large language models (LLMs) show promise in code generation, existing benchmarks neglect the flowchart-based code generation. To promote further research on flowchart-based code generation, this work presents Flow2Code, a novel benchmark for flowchart-based code generation evaluation. The... | Mengliang He, Jiayi Zeng, Yankai Jiang, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou |  |
| 526 |  |  [Smarter, Not Harder: Training-Free Adaptive Computation for Transformers](https://aclanthology.org/2025.findings-acl.426/) |  | 0 | Adaptive Computation in Transformers (ACT) has been pursued in two directions: efficiency- and performance-focused. We study performance-focused ACT, or PACT, which invests more computation on hard steps to improve performance, such as by adding forward passes. We first discuss beam search and... | Romain Storaï, Jaeseong Lee, Seungwon Hwang |  |
| 527 |  |  [UCS-SQL: Uniting Content and Structure for Enhanced Semantic Bridging In Text-to-SQL](https://aclanthology.org/2025.findings-acl.427/) |  | 0 | With the rapid advancement of large language models (LLMs), recent researchers have increasingly focused on the superior capabilities of LLMs in text/code understanding and generation to tackle text-to-SQL tasks. Traditional approaches adopt schema linking to first eliminate redundant tables and... | Zhenhe Wu, Zhongqiu Li, Jie Zhang, Zhongjiang He, Jian Yang, Yu Zhao, Ruiyu Fang, Bing Wang, Hongyan Xie, Shuangyong Song, Zhoujun Li |  |
| 528 |  |  [CodePRM: Execution Feedback-enhanced Process Reward Model for Code Generation](https://aclanthology.org/2025.findings-acl.428/) |  | 0 | Code generation is a critical reasoning task for large language models (LLMs). Recent advancements have focused on optimizing the thought process of code generation, achieving significant improvements. However, such thought process lacks effective process supervision, making it hard to optimize the... | Qingyao Li, Xinyi Dai, Xiangyang Li, Weinan Zhang, Yasheng Wang, Ruiming Tang, Yong Yu |  |
| 529 |  |  [STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing](https://aclanthology.org/2025.findings-acl.429/) |  | 0 | Advances in large language models (LLMs) have spurred research into enhancing their reasoning capabilities, particularly in math-rich STEM (Science, Technology, Engineering, and Mathematics) documents.While LLMs can generate equations or solve math-related queries, their ability to fully understand... | Jiaru Zou, Qing Wang, Pratyush Thakur, Nickvash Kani |  |
| 530 |  |  [Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models](https://aclanthology.org/2025.findings-acl.430/) |  | 0 | Despite significant advancements in Large Vision-Language Models, Object Hallucination (OH) remains a persistent challenge. Building upon prior studies on contrastive decoding that address this issue without requiring additional model training, we introduce RVCD (Retrieval Visual Contrastive... | Jihoon Lee, Min Song |  |
| 531 |  |  [Leveraging LLMs for Bangla Grammar Error Correction: Error Categorization, Synthetic Data, and Model Evaluation](https://aclanthology.org/2025.findings-acl.431/) |  | 0 | Large Language Models (LLMs) perform exceedingly well in Natural Language Understanding (NLU) tasks for many languages including English. However, despite being the fifth most-spoken language globally, Grammatical Error Correction (GEC) in Bangla remains underdeveloped. In this work, we investigate... | Pramit Bhattacharyya, Arnab Bhattacharya |  |
| 532 |  |  [Think Both Ways: Teacher-Student Bidirectional Reasoning Enhances MCQ Generation and Distractor Quality](https://aclanthology.org/2025.findings-acl.432/) |  | 0 | Generating high-quality Multiple Choice Questions (MCQs) remains challenging for educational tools due to the need for contextual relevance and plausible distractors. Existing methods still struggle with these dual requirements, leading to questions that lack depth and distractors that are either... | Yimiao Qiu, Yang Deng, Quanming Yao, Zhimeng Zhang, Zhiang Dong, Chang Yao, Jingyuan Chen |  |
| 533 |  |  [mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data](https://aclanthology.org/2025.findings-acl.433/) |  | 0 | Multimodal embedding models have gained significant attention for their ability to map data from different modalities, such as text and images, into a unified representation space. However, the limited labeled multimodal data often hinders embedding performance. Recent approaches have leveraged... | Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou |  |
| 534 |  |  [Word2Passage: Word-level Importance Re-weighting for Query Expansion](https://aclanthology.org/2025.findings-acl.434/) |  | 0 | Retrieval-augmented generation (RAG) enhances the quality of LLM generation by providing relevant chunks, but retrieving accurately from external knowledge remains challenging due to missing contextually important words in query. We present Word2Passage, a novel approach that improves retrieval... | Jeonghwan Choi, Minjeong Ban, Minseok Kim, Hwanjun Song |  |
| 535 |  |  [MECoT: Markov Emotional Chain-of-Thought for Personality-Consistent Role-Playing](https://aclanthology.org/2025.findings-acl.435/) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in role-playing dialogues, yet they often struggle to maintain emotionally consistent and psychologically plausible character personalities. We present MECoT (Markov Emotional Chain-of-Thought), a framework that enhances LLMs’ ability... | Yangbo Wei, Zhen Huang, Fangzhou Zhao, Qi Feng, Wei W. Xing |  |
| 536 |  |  [FiDeLiS: Faithful Reasoning in Large Language Models for Knowledge Graph Question Answering](https://aclanthology.org/2025.findings-acl.436/) |  | 0 | Large Language Models (LLMs) are often challenged by generating erroneous or hallucinated responses, especially in complex reasoning tasks. Leveraging Knowledge Graphs (KGs) as external knowledge sources has emerged as a viable solution. However, existing KG-enhanced methods, either retrieval-based... | Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi |  |
| 537 |  |  [REALM: A Dataset of Real-World LLM Use Cases](https://aclanthology.org/2025.findings-acl.437/) |  | 0 | Large Language Models (LLMs), such as the GPT series, have driven significant industrial applications, leading to economic and societal transformations. However, a comprehensive understanding of their real-world applications remains limited.To address this, we introduce \*\*REALM\*\*, a dataset of... | Jingwen Cheng, Kshitish Ghate, Wenyue Hua, William Yang Wang, Hong Shen, Fei Fang |  |
| 538 |  |  [BABELEDITS: A Benchmark and a Modular Approach for Robust Cross-lingual Knowledge Editing of Large Language Models](https://aclanthology.org/2025.findings-acl.438/) |  | 0 | With Large Language Models (LLMs) becoming increasingly multilingual, effective knowledge editing (KE) needs to propagate edits across languages. Evaluation of the existing methods for cross-lingual knowledge editing (CKE) is limited both w.r.t. edit effectiveness: benchmarks do not account for... | Tommaso Green, Félix Gaschi, Fabian David Schmidt, Simone Paolo Ponzetto, Goran Glavas |  |
| 539 |  |  [CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory](https://aclanthology.org/2025.findings-acl.439/) |  | 0 | Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models.... | Haokun Zhao, Jinyi Han, Jiaqing Liang, Yanghua Xiao, Xiaojun Meng, Jiansheng Wei |  |
| 540 |  |  [Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning](https://aclanthology.org/2025.findings-acl.440/) |  | 0 | In-context learning (ICL) can significantly enhance the complex reasoning capabilities of large language models (LLMs), with the key lying in the selection and ordering of demonstration examples. Previous methods typically relied on simple features to measure the relevance between examples. We... | Xuetao Ma, Wenbin Jiang, Hua Huang |  |
| 541 |  |  [BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English](https://aclanthology.org/2025.findings-acl.441/) |  | 0 | Despite large language models (LLMs) being known to exhibit bias against non-mainstream varieties, there are no known labeled datasets for sentiment analysis of English. To address this gap, we introduce BESSTIE, a benchmark for sentiment and sarcasm classification for three varieties of English:... | Dipankar Srirag, Aditya Joshi, Jordan Painter, Diptesh Kanojia |  |
| 542 |  |  [NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM](https://aclanthology.org/2025.findings-acl.442/) |  | 0 | Vision-and-Language Navigation (VLN) is an essential skill for embodied agents, allowing them to navigate in 3D environments following natural language instructions. High-performance navigation models require a large amount of training data, the high cost of manually annotating data has seriously... | Zihan Wang, Yaohui Zhu, Gim Hee Lee, Yachun Fan |  |
| 543 |  |  [SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs](https://aclanthology.org/2025.findings-acl.443/) |  | 0 | Large Language models (LLMs) have demonstrated significant potential in text-to-SQL reasoning tasks, yet a substantial performance gap persists between existing open-source models and their closed-source counterparts. In this paper, we introduce SQLForge, a novel approach for synthesizing reliable... | Yu Guo, Dong Jin, Shenghao Ye, Shuangwu Chen, Jianyang Jianyang, Xiaobin Tan |  |
| 544 |  |  [Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning](https://aclanthology.org/2025.findings-acl.444/) |  | 0 | While large language models (LLMs) have significantly advanced mathematical reasoning, Process Reward Models (PRMs) have been developed to evaluate the logical validity of reasoning steps. However, PRMs still struggle with out-of-distribution (OOD) challenges. This paper identifies the OOD issues... | Jiachen Zhu, Congmin Zheng, Jianghao Lin, Kounianhua Du, Ying Wen, Yong Yu, Jun Wang, Weinan Zhang |  |
| 545 |  |  [Contrastive Learning for Task-Independent SpeechLLM-Pretraining](https://aclanthology.org/2025.findings-acl.445/) |  | 0 | Large language models (LLMs) excel in natural language processing but adapting these LLMs to speech processing tasks efficiently is not straightforward. Direct task-specific fine-tuning is limited by overfitting risks, data requirements, and computational costs. To address these challenges, we... | Maike Züfle, Jan Niehues |  |
| 546 |  |  [QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm](https://aclanthology.org/2025.findings-acl.446/) |  | 0 | The attention operator remains a critical performance bottleneck in large language models (LLMs), particularly for long-context scenarios. While FlashAttention is the most widely used and effective GPU-aware acceleration algorithm, it must require time-consuming and hardware-specific manual... | Qirui Zhou, Shaohui Peng, Weiqiang Xiong, Haixin Chen, Yuanbo Wen, Haochen Li, Ling Li, Qi Guo, Yongwei Zhao, Ke Gao, Ruizhi Chen, Yanjun Wu, Zhao Chen, Yunji Chen |  |
| 547 |  |  [ALW: Adaptive Layer-Wise contrastive decoding enhancing reasoning ability in Large Language Models](https://aclanthology.org/2025.findings-acl.447/) |  | 0 | Large language models (LLMs) have achieved remarkable performance across various reasoning tasks. However, many LLMs still encounter challenges in reasoning, especially for LLMs with fewer parameters or insufficient pre-training data. Through our experiments, we identify that noise accumulation... | Yuechi Zhou, Chuyue Zhou, Jianxin Zhang, Juntao Li, Min Zhang |  |
| 548 |  |  [Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models](https://aclanthology.org/2025.findings-acl.448/) |  | 0 | Large Vision-Language Models (LVLMs) have exhibited impressive capabilities across various visual tasks, yet they remain hindered by the persistent challenge of hallucinations. To address this critical issue, we propose Mixture of Decoding (MoD), a novel approach for hallucination mitigation that... | Xinlong Chen, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan |  |
| 549 |  |  [VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation](https://aclanthology.org/2025.findings-acl.449/) |  | 0 | The training of controllable text-to-video (T2V) models relies heavily on the alignment between videos and captions, yet little existing research connects video caption evaluation with T2V generation assessment. This paper introduces VidCapBench, a video caption evaluation scheme specifically... | Xinlong Chen, Yuanxing Zhang, Chongling Rao, Yushuo Guan, Jiaheng Liu, Fuzheng Zhang, Chengru Song, Qiang Liu, Di Zhang, Tieniu Tan |  |
| 550 |  |  [Mitigating Demonstration Bias through Global Coevolutionary Reasoning](https://aclanthology.org/2025.findings-acl.450/) |  | 0 | Recent advances in large language models (LLMs) have demonstrated the effectiveness of chain-of-thought (CoT) prompting. Few-Shot-CoT relies on task-specific, manually labeled demonstrations, limiting its generalization to unseen tasks. While Zero-Shot-CoT eliminates this reliance, it often... | Chuan Gou, Bangwei Li, Jianhua Dai, Xiaoyang Han, Ming Cai |  |
| 551 |  |  [A Representation Level Analysis of NMT Model Robustness to Grammatical Errors](https://aclanthology.org/2025.findings-acl.451/) |  | 0 | Understanding robustness is essential for building reliable NLP systems. Unfortunately, in the context of machine translation, previous work mainly focused on documenting robustness failures or improving robustness. In contrast, we study robustness from a model representation perspective by looking... | Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis |  |
| 552 |  |  [T²DR: A Two-Tier Deficiency-Resistant Framework for Incomplete Multimodal Learning](https://aclanthology.org/2025.findings-acl.452/) |  | 0 | Multimodal learning is garnering significant attention for its capacity to represent diverse human perceptions (e.g., linguistic, acoustic, and visual signals), achieving more natural and intuitive interactions with technology.However, the frequent occurrence of incomplete data, either within a... | Han Lin, Xiu Tang, Huan Li, Wenxue Cao, Sai Wu, Chang Yao, Lidan Shou, Gang Chen |  |
| 553 |  |  [From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities](https://aclanthology.org/2025.findings-acl.453/) |  | 0 | To tackle complex tasks in real-world scenarios, more researchers are focusing on Omni-MLLMs, which aim to achieve omni-modal understanding and generation. Beyond the constraints of any specific non-linguistic modality, Omni-MLLMs map various non-linguistic modalities into the embedding space of... | Shixin Jiang, Jiafeng Liang, Jiyuan Wang, Xuan Dong, Heng Chang, Weijiang Yu, Jinhua Du, Ming Liu, Bing Qin |  |
| 554 |  |  [Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter](https://aclanthology.org/2025.findings-acl.454/) |  | 0 | Cross-lingual transfer is a popular approach to increase the amount of training data for NLP tasks in a low-resource context. However, the best strategy to decide which cross-lingual data to include is unclear. Prior research often focuses on a small set of languages from a few language families... | Verena Blaschke, Masha Fedzechkina, Maartje ter Hoeve |  |
| 555 |  |  [Agents generalize to novel levels of abstraction by using adaptive linguistic strategies](https://aclanthology.org/2025.findings-acl.455/) |  | 0 | We study abstraction in an emergent communication paradigm. In emergent communication, two artificial neural network agents develop a language while solving a communicative task. In this study, the agents play a concept-level reference game. This means that the speaker agent has to describe a... | Kristina Kobrock, Xenia Ohmer, Elia Bruni, Nicole Gotzner |  |
| 556 |  |  [The Linguistic Connectivities Within Large Language Models](https://aclanthology.org/2025.findings-acl.456/) |  | 0 | Large language models (LLMs) have demonstrated remarkable multilingual abilities in various applications. Unfortunately, recent studies have discovered that there exist notable disparities in their performance across different languages. Understanding the underlying mechanisms behind such... | Dan Wang, Boxi Cao, Ning Bian, Xuanang Chen, Yaojie Lu, Hongyu Lin, Jia Zheng, Le Sun, Shanshan Jiang, Bin Dong, Xianpei Han |  |
| 557 |  |  [XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning](https://aclanthology.org/2025.findings-acl.457/) |  | 0 | Solving financial problems demands complex reasoning, multimodal data processing, and a broad technical understanding, presenting unique challenges for current large language models (LLMs). We introduce \*\*XFinBench\*\*, a novel benchmark with 4,235 examples designed to evaluate LLM’s ability in... | Zhihan Zhang, Yixin Cao, Lizi Liao |  |
| 558 |  |  [Align²LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation](https://aclanthology.org/2025.findings-acl.458/) |  | 0 | Recent advances in Multi-modal Large Language Models (MLLMs), such as LLaVA-series models, are driven by massive machine-generated instruction-following data tuning. Such automatic instruction collection pipelines, however, inadvertently introduce significant variability in data quality. This paper... | Hongzhe Huang, Jiang Liu, Zhewen Yu, Li Cai, Dian Jiao, Wenqiao Zhang, Siliang Tang, Juncheng Li, Hao Jiang, Haoyuan Li, Yueting Zhuang |  |
| 559 |  |  [Achieving binary weight and activation for LLMs using Post-Training Quantization](https://aclanthology.org/2025.findings-acl.459/) |  | 0 | Quantizing large language models (LLMs) to 1-bit precision significantly reduces computational costs, but existing quantization techniques suffer from noticeable performance degradation when using weight and activation precisions below 4 bits (W4A4). In this paper, we propose a post-training... | Siqing Song, Chuang Wang, RuiQi Wang, Yi Yang, XuYao Zhang |  |
| 560 |  |  [Mitigating Negative Interference in Multilingual Knowledge Editing through Null-Space Constraints](https://aclanthology.org/2025.findings-acl.460/) |  | 0 | Efficiently updating multilingual knowledge in large language models (LLMs) without disrupting coherent factual representations across languages remains a significant challenge. While deploying separate editing systems for each language might seem viable, this approach incurs substantial costs due... | Wei Sun, Tingyu Qu, Mingxiao Li, Jesse Davis, MarieFrancine Moens |  |
| 561 |  |  [From Awareness to Adaptability: Enhancing Tool Utilization for Scientific Reasoning](https://aclanthology.org/2025.findings-acl.461/) |  | 0 | As large language models (LLMs) are increasingly applied to complex scientific problem-solving, their effectiveness is often limited by unconscious or failed tool usage. To address this issue, we introduce the Tool-Awareness Training (TAT) method, designed to enhance scientific reasoning. This... | Wenjing Xie, Xiaobo Liang, Juntao Li, Wanfu Wang, Kehai Chen, Qiaoming Zhu, Min Zhang |  |
| 562 |  |  [AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models](https://aclanthology.org/2025.findings-acl.462/) |  | 0 | Existing multi-objective preference alignment methods for large language models (LLMs) face limitations: (1) the inability to effectively balance various preference dimensions, and (2) reliance on auxiliary reward/reference models introduces computational complexity. To address these challenges, we... | Qi Liu, Jingqing Ruan, Hao Li, Haodong Zhao, Desheng Wang, Jiansong Chen, Guanglu Wan, Xunliang Cai, Zhi Zheng, Tong Xu |  |
| 563 |  |  [Supervised Optimism Correction: Be Confident When LLMs Are Sure](https://aclanthology.org/2025.findings-acl.463/) |  | 0 | In this work, we establish a novel theoretical connection between supervised fine-tuning and offline reinforcement learning under the token-level Markov decision process, revealing that large language models indeed learn an implicit Q-function for inference.Through this theoretical lens, we... | Junjie Zhang, Rushuai Yang, Shunyu Liu, TingEn Lin, Fei Huang, Yi Chen, Yongbin Li, Dacheng Tao |  |
| 564 |  |  [Offline Reinforcement Learning for LLM Multi-step Reasoning](https://aclanthology.org/2025.findings-acl.464/) |  | 0 | Improving the multi-step reasoning ability of large language models (LLMs) with offline reinforcement learning (RL) is essential for quickly adapting them to complex tasks. While Direct Preference Optimization (DPO) has shown promise in aligning LLMs with human preferences, it is less suitable for... | Huaijie Wang, Shibo Hao, Hanze Dong, Shenao Zhang, Yilin Bao, Ziran Yang, Yi Wu |  |
| 565 |  |  [Sampling-based Pseudo-Likelihood for Membership Inference Attacks](https://aclanthology.org/2025.findings-acl.465/) |  | 0 | Large Language Models (LLMs) are trained on large-scale web data, which makes it difficult to grasp the contribution of each text. This poses the risk of leaking inappropriate data such as benchmarks, personal information, and copyrighted texts in the training data. Membership Inference Attacks... | Masahiro Kaneko, Youmi Ma, Yuki Wata, Naoaki Okazaki |  |
| 566 |  |  [AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant](https://aclanthology.org/2025.findings-acl.466/) |  | 0 | Digital agents capable of automating complex computer tasks have attracted considerable attention. However, existing agent methods exhibit deficiencies in their generalization and specialization capabilities, especially in handling open-ended computer tasks in real-world environments. Inspired by... | Chengyou Jia, Minnan Luo, Zhuohang Dang, Qiushi Sun, Fangzhi Xu, Junlin Hu, Tianbao Xie, Zhiyong Wu |  |
| 567 |  |  [Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data](https://aclanthology.org/2025.findings-acl.467/) |  | 0 | Large language models (LLMs) demonstrate considerable proficiency in numerous coding-related tasks; however, their capabilities in detecting software vulnerabilities remain limited. This limitation primarily stems from two factors: (1) the absence of reasoning data related to vulnerabilities, which... | XinCheng Wen, Yijun Yang, Cuiyun Gao, Yang Xiao, Deheng Ye |  |
| 568 |  |  [GA-S³: Comprehensive Social Network Simulation with Group Agents](https://aclanthology.org/2025.findings-acl.468/) |  | 0 | Social network simulation is developed to provide a comprehensive understanding of social networks in the real world, which can be leveraged for a wide range of applications such as group behavior emergence, policy optimization, and business strategy development. However, billions of individuals... | Yunyao Zhang, Zikai Song, Hang Zhou, Wenfeng Ren, YiPing Phoebe Chen, Junqing Yu, Wei Yang |  |
| 569 |  |  [M-RangeDetector: Enhancing Generalization in Machine-Generated Text Detection through Multi-Range Attention Masks](https://aclanthology.org/2025.findings-acl.469/) |  | 0 | The increasing capability and widespread usage of large language models (LLMs) highlight the desirability of automatic detection of machine-generated text. Existing supervised detectors often overfit within their training domains, as they have primarily learned domain-specific textual features,... | Kaijie Jiao, Quan Wang, Licheng Zhang, Zikang Guo, Zhendong Mao |  |
| 570 |  |  [Does Your Voice Assistant Remember? Analyzing Conversational Context Recall and Utilization in Voice Interaction Models](https://aclanthology.org/2025.findings-acl.470/) |  | 0 | Recent advancements in multi-turn voice interaction models have improved user-model communication. However, while closed-source models effectively retain and recall past utterances, whether open-source models share this ability remains unexplored. To fill this gap, we systematically evaluate how... | Heeseung Kim, Che Hyun Lee, Sangkwon Park, Jiheum Yeom, Nohil Park, Sangwon Yu, Sungroh Yoon |  |
| 571 |  |  [NeuronMerge: Merging Models via Functional Neuron Groups](https://aclanthology.org/2025.findings-acl.471/) |  | 0 | Model merging techniques like task arithmetic, which combines model parameters through weighted averaging, have proven effective. However, the success of task arithmetic relies on the linearity between model weight differences and output feature changes, which is often lacking in conventional... | Wangyun Gu, Qianghua Gao, LiXin Zhang, Xu Shen, Jieping Ye |  |
| 572 |  |  [HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning](https://aclanthology.org/2025.findings-acl.472/) |  | 0 | Large language models (LLMs) have shown remarkable capabilities in commonsense reasoning; however, some variations in questions can trigger incorrect responses. Do these models truly understand commonsense knowledge, or just memorize expression patterns? To investigate this question, we present the... | Xiaoyuan Li, Moxin Li, Rui Men, Yichang Zhang, Keqin Bao, Wenjie Wang, Fuli Feng, Dayiheng Liu, Junyang Lin |  |
| 573 |  |  [Self-Steering Optimization: Autonomous Preference Optimization for Large Language Models](https://aclanthology.org/2025.findings-acl.473/) |  | 0 | The key to effective alignment lies in high-quality preference data. Recent research has focused on automated alignment, which involves developing alignment systems with minimal human intervention. However, prior research has predominantly focused on developing data generation methods, while... | Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Ben He, Le Sun, Jingren Zhou, Junyang Lin |  |
| 574 |  |  [LIME: Less Is More for MLLM Evaluation](https://aclanthology.org/2025.findings-acl.474/) |  | 0 | Multimodal Large Language Models (MLLMs) are measured on numerous benchmarks like image captioning, visual question answer, and reasoning. However, these benchmarks often include overly simple or uninformative samples, making it difficult to effectively distinguish the performance of different... | King Zhu, Qianbo Zang, Shian Jia, Siwei Wu, Feiteng Fang, Yizhi Li, Shuyue Guo, Tianyu Zheng, Jiawei Guo, Bo Li, Haoning Wu, Xingwei Qu, Jian Yang, Ruibo Liu, Xiang Yue, Jiaheng Liu, Chenghua Lin, Hamid AlinejadRokny, Min Yang, Shiwen Ni, Wenhao Huang, Ge Zhang |  |
| 575 |  |  [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](https://aclanthology.org/2025.findings-acl.475/) |  | 0 | Large Language Models (LLMs) continue to set new standards in knowledge-intensive and complex reasoning tasks, yet their high computational demands limit widespread adoption. While distilling large models into smaller ones offers a sustainable solution, current techniques—such as static knowledge... | Xiaofeng Zhou, Heyan Huang, Lizi Liao |  |
| 576 |  |  [CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models](https://aclanthology.org/2025.findings-acl.476/) |  | 0 | State-of-the-art large language models (LLMs) have demonstrated impressive code generation capabilities but struggle with real-world software engineering tasks, such as revising source code to address code reviews, hindering their practical use. Code review comments are often implicit, ambiguous,... | Hong Yi Lin, Chunhua Liu, Haoyu Gao, Patanamon Thongtanunam, Christoph Treude |  |
| 577 |  |  [Narrative Media Framing in Political Discourse](https://aclanthology.org/2025.findings-acl.477/) |  | 0 | Narrative frames are a powerful way of conceptualizing and communicating complex, controversial ideas, however automated frame analysis to date has mostly overlooked this framing device. In this paper, we connect elements of narrativity with fundamental aspects of framing, and present a framework... | Yulia Otmakhova, Lea Frermann |  |
| 578 |  |  [MHALO: Evaluating MLLMs as Fine-grained Hallucination Detectors](https://aclanthology.org/2025.findings-acl.478/) |  | 0 | Hallucination remains a critical challenge for multimodal large language models (MLLMs), undermining their reliability in real-world applications. While fine-grained hallucination detection (FHD) holds promise for enhancing high-quality vision-language data construction and model alignment through... | Yishuo Cai, Renjie Gu, Jiaxu Li, Xuancheng Huang, Junzhe Chen, Xiaotao Gu, Minlie Huang |  |
| 579 |  |  [Semantic Topology: a New Perspective for Communication Style Characterization](https://aclanthology.org/2025.findings-acl.479/) |  | 0 | We introduce semantic topology, a novel framework for discourse analysis that leverages Circuit Topology to quantify the semantic arrangement of sentences in a text. By mapping recurring themes as series, parallel, or cross relationships, we identify statistical differences in communication... | Barbara Scalvini, Alireza Mashaghi |  |
| 580 |  |  [Decoding LLM Personality Measurement: Forced-Choice vs. Likert](https://aclanthology.org/2025.findings-acl.480/) |  | 0 | Recent research has focused on investigating the psychological characteristics of Large Language Models (LLMs), emphasizing the importance of comprehending their behavioral traits. Likert scale personality questionnaires have become the primary tool for assessing these characteristics in LLMs.... | Xiaoyu Li, Haoran Shi, Zengyi Yu, Yukun Tu, Chanjin Zheng |  |
| 581 |  |  [MultiMSD: A Corpus for Multilingual Medical Text Simplification from Online Medical References](https://aclanthology.org/2025.findings-acl.481/) |  | 0 | We release a parallel corpus for medical text simplification, which paraphrases medical terms into expressions easily understood by patients. Medical texts written by medical practitioners contain a lot of technical terms, and patients who are non-experts are often unable to use the information... | Koki Horiguchi, Tomoyuki Kajiwara, Takashi Ninomiya, Shoko Wakamiya, Eiji Aramaki |  |
| 582 |  |  [BadWindtunnel: Defending Backdoor in High-noise Simulated Training with Confidence Variance](https://aclanthology.org/2025.findings-acl.482/) |  | 0 | Current backdoor attack defenders in Natural Language Processing (NLP) typically involve data reduction or model pruning, risking losing crucial information. To address this challenge, we introduce a novel backdoor defender, i.e., BadWindtunnel, in which we build a high-noise simulated training... | Ruyi Zhang, Songlei Jian, Yusong Tan, Heng Gao, Haifang Zhou, Kai Lu |  |
| 583 |  |  [Multimodal Machine Translation with Text-Image In-depth Questioning](https://aclanthology.org/2025.findings-acl.483/) |  | 0 | Multimodal machine translation (MMT) integrates visual information to address ambiguity and contextual limitations in neural machine translation (NMT). Some empirical studies have revealed that many MMT models underutilize visual data during translation. They attempt to enhance cross-modal... | Yue Gao, Jing Zhao, Shiliang Sun, Xiaosong Qiao, Tengfei Song, Hao Yang |  |
| 584 |  |  [ReKG-MCTS: Reinforcing LLM Reasoning on Knowledge Graphs via Training-Free Monte Carlo Tree Search](https://aclanthology.org/2025.findings-acl.484/) |  | 0 | Recent advancements in combining knowledge graphs (KGs) with large language models (LLMs) have demonstrated promising potential in complex KG reasoning tasks, yet existing approaches face limitations in path exploration strategies or excessive computational overhead. We propose ReKG-MCTS, a novel... | Xiaozhuang Song, Shufei Zhang, Tianshu Yu |  |
| 585 |  |  [HTML: Hierarchical Topology Multi-task Learning for Semantic Parsing in Knowledge Base Question Answering](https://aclanthology.org/2025.findings-acl.485/) |  | 0 | Knowledge base question answering (KBQA) aims to answer natural language questions by reasoning over structured knowledge bases. Existing approaches often struggle with the complexity of mapping questions to precise logical forms, particularly when dealing with diverse entities and relations. In... | Aziguli Wulamu, Lyu Zhengyu, Kaiyuan Gong, Yu Han, Zewen Wang, Zhihong Zhu, Bowen Xing |  |
| 586 |  |  [StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following](https://aclanthology.org/2025.findings-acl.486/) |  | 0 | Multi-turn instruction following capability constitutes a core competency of large language models (LLMs) in real-world applications. Existing evaluation benchmarks predominantly focus on fine-grained constraint satisfaction and domain-specific capability assessment, yet overlook the crucial... | Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu |  |
| 587 |  |  [CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection](https://aclanthology.org/2025.findings-acl.487/) |  | 0 | Multimodal large language models (MLLMs) have demonstrated impressive capabilities in visual reasoning and text generation. While previous studies have explored the application of MLLM for detecting out-of-context (OOC) misinformation, our empirical analysis reveals two persisting challenges of... | Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou |  |
| 588 |  |  [EtiCor++: Towards Understanding Etiquettical Bias in LLMs](https://aclanthology.org/2025.findings-acl.488/) |  | 0 | In recent years, researchers have started analyzing the cultural sensitivity of LLMs. In this respect, Etiquettes have been an active area of research. Etiquettes are region-specific and are an essential part of the culture of a region; hence, it is imperative to make LLMs sensitive to etiquettes.... | Ashutosh Dwivedi, Siddhant Singh, Ashutosh Modi |  |
| 589 |  |  [FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness](https://aclanthology.org/2025.findings-acl.489/) |  | 0 | Financial markets exhibit complex dynamics where localized events trigger ripple effects across entities. Previous event studies, constrained by static single-companies analyses and simplistic assumptions, fail to capture these ripple effects. While large language models (LLMs) offer emergent... | Yuanjian Xu, Jianing Hao, Kunsheng Tang, Jingnan Chen, Anxian Liu, Peng Liu, Guang Zhang |  |
| 590 |  |  [Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation](https://aclanthology.org/2025.findings-acl.490/) |  | 0 | The field of neural machine translation (NMT) has changed with the advent of large language models (LLMs). Much of the recent emphasis in natural language processing (NLP) has been on modeling machine translation and many other problems using a single pre-trained Transformer decoder, while... | Yingfeng Luo, Tong Zheng, Yongyu Mu, Bei Li, Qinghong Zhang, Yongqi Gao, Ziqiang Xu, Peinan Feng, Xiaoqian Liu, Tong Xiao, JingBo Zhu |  |
| 591 |  |  [EC-RAFT: Automated Generation of Clinical Trial Eligibility Criteria through Retrieval-Augmented Fine-Tuning](https://aclanthology.org/2025.findings-acl.491/) |  | 0 | Eligibility criteria (EC) are critical components of clinical trial design, defining the parameters for participant inclusion and exclusion. However, designing EC remains a complex, expertise-intensive process. Traditional approaches to EC generation may fail to produce comprehensive, contextually... | Nopporn Lekuthai, Nattawit Pewngam, Supitcha Sokrai, Titipat Achakulvisut |  |
| 592 |  |  [Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models](https://aclanthology.org/2025.findings-acl.492/) |  | 0 | Inverse tasks can uncover potential reasoning gaps as Large Language Models (LLMs) scale up. In this work, we explore the redefinition task, in which we assign alternative values to well-known physical constants and units of measure, prompting LLMs to respond accordingly. Our findings show that not... | Elena Stringli, Maria Lymperaiou, Giorgos Filandrianos, Athanasios Voulodimos, Giorgos Stamou |  |
| 593 |  |  [Implicit Reasoning in Transformers is Reasoning through Shortcuts](https://aclanthology.org/2025.findings-acl.493/) |  | 0 | Test-time compute is emerging as a new paradigm for enhancing language models’ complex multi-step reasoning capabilities, as demonstrated by the success of OpenAI’s o1 and o3, as well as DeepSeek’s R1. Compared to explicit reasoning in test-time compute, implicit reasoning is more... | Tianhe Lin, Jian Xie, Siyu Yuan, Deqing Yang |  |
| 594 |  |  [Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework](https://aclanthology.org/2025.findings-acl.494/) |  | 0 | Large Language Models (LLMs) are being used more and more extensively for automated evaluation in various scenarios. Previous studies have attempted to fine-tune open-source LLMs to replicate the evaluation explanations and judgments of powerful proprietary models, such as GPT-4. However, these... | Kaishuai Xu, Tiezheng Yu, Yi Cheng, Wenjun Hou, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li |  |
| 595 |  |  [CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate](https://aclanthology.org/2025.findings-acl.495/) |  | 0 | Nowadays, single Large Language Model (LLM) struggles with critical issues such as hallucination and inadequate reasoning abilities. To mitigate these issues, Multi-Agent Debate (MAD) has emerged as an effective strategy, where LLM agents engage in in-depth debates with others on tasks. However,... | Yiliu Sun, Zicheng Zhao, Sheng Wan, Chen Gong |  |
| 596 |  |  [PAP2PAT: Benchmarking Outline-Guided Long-Text Patent Generation with Patent-Paper Pairs](https://aclanthology.org/2025.findings-acl.496/) |  | 0 | Dealing with long and highly complex technical text is a challenge for Large Language Models (LLMs), which still have to unfold their potential in supporting expensive and time intensive processes like patent drafting. Within patents, the description constitutes more than 90% of the document on... | Valentin Knappich, Anna Hätty, Simon Razniewski, Annemarie Friedrich |  |
| 597 |  |  [Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent](https://aclanthology.org/2025.findings-acl.497/) |  | 0 | Debt collection negotiations (DCN) are vital for managing non-performing loans (NPLs) and reducing creditor losses. Traditional methods are labor-intensive, while large language models (LLMs) offer promising automation potential. However, prior systems lacked dynamic negotiation and real-time... | Xiaofeng Wang, Zhixin Zhang, Jin Guang Zheng, Yiming Ai, Rui Wang |  |
| 598 |  |  [Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points](https://aclanthology.org/2025.findings-acl.498/) |  | 0 | Code generation models have shown significant potential for automating programming tasks. However, the challenge of generating accurate and reliable code persists due to the highly complex and long-reasoning nature of the task. Even state-of-the-art models often fail in code generation due to small... | Kechi Zhang, Ge Li, Jia Li, Yihong Dong, Zhi Jin |  |
| 599 |  |  [Supervised and Unsupervised Probing of Shortcut Learning: Case Study on the Emergence and Evolution of Syntactic Heuristics in BERT](https://aclanthology.org/2025.findings-acl.499/) |  | 0 | Contemporary language models (LMs) such as BERT (Devlin et al., 2019, T5 (Raffel et al., 2023), GPT-4 (OpenAI, 2023), have exhibited remarkable capabilities, effectively addressing long-standing challenges in the field. However, these models rely on shortcut learning, using a decision rule that... | Elke Vandermeerschen, Miryam de Lhoneux |  |
| 600 |  |  [GIMMICK: Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking](https://aclanthology.org/2025.findings-acl.500/) |  | 0 | Large Vision-Language Models (LVLMs) have recently gained attention due to their distinctive performance and broad applicability. While it has been previously shown that their efficacy in usage scenarios involving non-Western contexts falls short, existing studies are limited in scope, covering... | Florian Schneider, Carolin Holtermann, Chris Biemann, Anne Lauscher |  |
| 601 |  |  [R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding](https://aclanthology.org/2025.findings-acl.501/) |  | 0 | Visual agent models for automating human activities on Graphical User Interfaces (GUIs) have emerged as a promising research direction, driven by advances in large Vision Language Models (VLMs). A critical challenge in GUI automation is the precise grounding of interface elements across diverse... | Joonhyung Park, Peng Tang, Sagnik Das, Srikar Appalaraju, Kunwar Yashraj Singh, R. Manmatha, Shabnam Ghadar |  |
| 602 |  |  [Perspective Transition of Large Language Models for Solving Subjective Tasks](https://aclanthology.org/2025.findings-acl.502/) |  | 0 | Large language models (LLMs) have revolutionized the field of natural language processing, enabling remarkable progress in various tasks. Different from objective tasks such as commonsense reasoning and arithmetic question-answering, the performance of LLMs on subjective tasks is still limited,... | Xiaolong Wang, Yuanchi Zhang, Ziyue Wang, Yuzhuang Xu, Fuwen Luo, Yile Wang, Peng Li, Yang Liu |  |
| 603 |  |  [TripTailor: A Real-World Benchmark for Personalized Travel Planning](https://aclanthology.org/2025.findings-acl.503/) |  | 0 | The continuous evolution and enhanced reasoning capabilities of large language models (LLMs) have elevated their role in complex tasks, notably in travel planning, where demand for personalized, high-quality itineraries is rising. However, current benchmarks often rely on unrealistic simulated... | Kaimin Wang, Yuanzhe Shen, Changze Lv, Xiaoqing Zheng, Xuanjing Huang |  |
| 604 |  |  [Random Splitting Negatively Impacts NER Evaluation: Quantifying and Eliminating the Overestimation of NER Performance](https://aclanthology.org/2025.findings-acl.504/) |  | 0 | In named entity recognition (NER), models are evaluated on their ability to identify entity mentions in text. However, standard evaluation methods often rely on test sets that contain named entities already present in the training data, raising concerns about overestimation of model... | Florian Babl, Moritz Hennen, Jakob Murauer, Michaela Geierhos |  |
| 605 |  |  [Structure-adaptive Adversarial Contrastive Learning for Multi-Domain Fake News Detection](https://aclanthology.org/2025.findings-acl.505/) |  | 0 | The rapid proliferation of fake news across multiple domains poses significant threats to society. Existing multi-domain detection models typically capture domain-shared semantic features to achieve generalized detection. However, they often fail to generalize well due to poor adaptability, which... | Lingwei Wei, Dou Hu, Wei Zhou, Philip S. Yu, Songlin Hu |  |
| 606 |  |  [BiasGuard: A Reasoning-Enhanced Bias Detection Tool for Large Language Models](https://aclanthology.org/2025.findings-acl.506/) |  | 0 | Identifying bias in LLM-generated content is a crucial prerequisite for ensuring fairness in LLMs. Existing methods, such as fairness classifiers and LLM-based judges, face limitations related to difficulties in understanding underlying intentions and the lack of criteria for fairness judgment. In... | Zhiting Fan, Ruizhe Chen, Zuozhu Liu |  |
| 607 |  |  [Qorǵau: Evaluating Safety in Kazakh-Russian Bilingual Contexts](https://aclanthology.org/2025.findings-acl.507/) |  | 0 | Large language models (LLMs) are known to have the potential to generate harmful content, posing risks to users. While significant progress has been made in developing taxonomies for LLM risks and safety evaluation prompts, most studies have focused on monolingual contexts, primarily in English.... | Maiya Goloburda, Nurkhan Laiyk, Diana Turmakhan, Yuxia Wang, Mukhammed Togmanov, Jonibek Mansurov, Askhat Sametov, Nurdaulet Mukhituly, Minghan Wang, Daniil Orel, Zain Muhammad Mujahid, Fajri Koto, Timothy Baldwin, Preslav Nakov |  |
| 608 |  |  [MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression](https://aclanthology.org/2025.findings-acl.508/) |  | 0 | Large vision-language models (LVLMs) have shown great promise in medical applications, particularly in visual question answering (MedVQA) and diagnosis from medical images. However, existing datasets and models often fail to consider critical aspects of medical diagnostics, such as the integration... | Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang |  |
| 609 |  |  [Tree-of-Code: A Self-Growing Tree Framework for End-to-End Code Generation and Execution in Complex Tasks](https://aclanthology.org/2025.findings-acl.509/) |  | 0 | Solving complex reasoning tasks is a key real-world application of agents. Thanks to the pretraining of Large Language Models (LLMs) on code data, recent approaches like CodeAct successfully use code as LLM agents’ action, achieving good results. However, CodeAct greedily generates the next... | Ziyi Ni, Yifan Li, Ning Yang, Dou Shen, Pin Lyu, Daxiang Dong |  |
| 610 |  |  [Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues](https://aclanthology.org/2025.findings-acl.510/) |  | 0 | In this paper, we introduce the Akan Cinematic Emotions (AkaCE) dataset, the first multimodal emotion dialogue dataset for an African language, addressing the significant lack of resources for low-resource languages in emotion recognition research. AkaCE, developed for the Akan language, contains... | David Sasu, Zehui Wu, Ziwei Gong, Run Chen, Pengyuan Shi, Lin Ai, Julia Hirschberg, Natalie Schluter |  |
| 611 |  |  [A Cognitive Writing Perspective for Constrained Long-Form Text Generation](https://aclanthology.org/2025.findings-acl.511/) |  | 0 | Like humans, Large Language Models (LLMs) struggle to generate high-quality long-form text that adheres to strict requirements in a single pass. This challenge is unsurprising, as successful human writing, according to the Cognitive Writing Theory, is a complex cognitive process involving iterative... | Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen |  |
| 612 |  |  [Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.512/) |  | 0 | The recent advancement of Multimodal Large Language Models (MLLMs) has significantly improved their fine-grained perception of single images and general comprehension across multiple images. However, existing MLLMs still face challenges in achieving precise grounding in complex multi-image... | You Li, Heyu Huang, Chi Chen, Kaiyu Huang, Chao Huang, Zonghao Guo, Zhiyuan Liu, Jinan Xu, Yuhua Li, Ruixuan Li, Maosong Sun |  |
| 613 |  |  [SIKeD: Self-guided Iterative Knowledge Distillation for Mathematical Reasoning](https://aclanthology.org/2025.findings-acl.513/) |  | 0 | Large Language Models (LLMs) can transfer their reasoning skills to smaller models by teaching them to generate the intermediate reasoning process required to solve multistep reasoning tasks. While LLMs can accurately solve reasoning tasks through a variety of strategies, even without fine-tuning,... | Shivam Adarsh, Kumar Shridhar, Caglar Gulcehre, Nicholas Monath, Mrinmaya Sachan |  |
| 614 |  |  [Chain of Attack: Hide Your Intention through Multi-Turn Interrogation](https://aclanthology.org/2025.findings-acl.514/) |  | 0 | The latent knowledge of large language models (LLMs) contains harmful or unethical content, which introduces significant security risks upon their widespread deployment. Conducting jailbreak attacks on LLMs can proactively identify vulnerabilities to enhance their security measures. However,... | Xikang Yang, Biyu Zhou, Xuehai Tang, Jizhong Han, Songlin Hu |  |
| 615 |  |  [MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space](https://aclanthology.org/2025.findings-acl.515/) |  | 0 | Data quality and diversity are key to the construction of effective instruction-tuning datasets. With the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. Existing methods... | Yicheng Chen, Yining Li, Kai Hu, Zerun Ma, Haochen Ye, Kai Chen |  |
| 616 |  |  [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://aclanthology.org/2025.findings-acl.516/) |  | 0 | Automatic Term Extraction (ATE) identifies domain-specific expressions that are crucial for downstream tasks such as machine translation and information retrieval. Although large language models (LLMs) have significantly advanced various NLP tasks, their potential for ATE has scarcely been... | Yongchan Chun, Minhyuk Kim, Dongjun Kim, Chanjun Park, Heuiseok Lim |  |
| 617 |  |  [Explainable Depression Detection in Clinical Interviews with Personalized Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.517/) |  | 0 | Depression is a widespread mental health disorder, and clinical interviews are the gold standard for assessment. However, their reliance on scarce professionals highlights the need for automated detection. Current systems mainly employ black-box neural networks, which lack interpretability, which... | Linhai Zhang, Ziyang Gao, Deyu Zhou, Yulan He |  |
| 618 |  |  [EMPEC: A Comprehensive Benchmark for Evaluating Large Language Models Across Diverse Healthcare Professions](https://aclanthology.org/2025.findings-acl.518/) |  | 0 | Recent advancements in Large Language Models (LLMs) show their potential in accurately answering biomedical questions, yet current healthcare benchmarks primarily assess knowledge mastered by medical doctors, neglecting other essential professions. To address this gap, we introduce the Examinations... | Zheheng Luo, Chenhan Yuan, Qianqian Xie, Sophia Ananiadou |  |
| 619 |  |  [Beyond Numeric Rewards: In-Context Dueling Bandits with LLM Agents](https://aclanthology.org/2025.findings-acl.519/) |  | 0 | In-Context Reinforcement Learning (ICRL) is a frontier paradigm to solve Reinforcement Learning (RL) problems in the foundation-model era. While ICRL capabilities have been demonstrated in transformers through task-specific training, the potential of large language models (LLMs) out of the box... | Fanzeng Xia, Hao Liu, Yisong Yue, Tongxin Li |  |
| 620 |  |  ["Well, Keep Thinking": Enhancing LLM Reasoning with Adaptive Injection Decoding](https://aclanthology.org/2025.findings-acl.520/) |  | 0 | Large language models (LLMs) exhibit strong reasoning abilities, often attributed to few-shot or zero-shot Chain-of-Thought (CoT) prompting. While effective, these methods require labor-intensive prompt engineering, raising the question of whether reasoning can be induced without reliance on... | Hyunbin Jin, Je Won Yeom, Seunghyun Bae, Taesup Kim |  |
| 621 |  |  [SpeechT-RAG: Reliable Depression Detection in LLMs with Retrieval-Augmented Generation Using Speech Timing Information](https://aclanthology.org/2025.findings-acl.521/) |  | 0 | Large Language Models (LLMs) have been increasingly adopted for health-related tasks, yet their performance in depression detection remains limited when relying solely on text input. While Retrieval-Augmented Generation (RAG) typically enhances LLM capabilities, our experiments indicate that... | Xiangyu Zhang, Hexin Liu, Qiquan Zhang, Beena Ahmed, Julien Epps |  |
| 622 |  |  [Fine-grained Knowledge Enhancement for Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.522/) |  | 0 | Retrieval-augmented generation (RAG) effectively mitigates hallucinations in large language models (LLMs) by filling knowledge gaps with retrieved external information. Most existing studies primarily retrieve knowledge documents based on semantic similarity to assist in answering questions but... | Jingxuan Han, Zhendong Mao, Yi Liu, Yexuan Che, Zheren Fu, Quan Wang |  |
| 623 |  |  [Bayesian Optimization for Controlled Image Editing via LLMs](https://aclanthology.org/2025.findings-acl.523/) |  | 0 | In the rapidly evolving field of image generation, achieving precise control over generated content and maintaining semantic consistency remain significant limitations, particularly concerning grounding techniques and the necessity for model fine-tuning. To address these challenges, we propose... | Chengkun Cai, Haoliang Liu, Xu Zhao, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, John Lee, JenqNeng Hwang, Lei Li |  |
| 624 |  |  [SPOT: Zero-Shot Semantic Parsing Over Property Graphs](https://aclanthology.org/2025.findings-acl.524/) |  | 0 | Knowledge Graphs (KGs) have gained popularity as a means of storing structured data, with property graphs, in particular, gaining traction in recent years. Consequently, the task of semantic parsing remains crucial in enabling access to the information in these graphs via natural language queries.... | Francesco Cazzaro, Justin Kleindienst, Sofia Márquez Gomez, Ariadna Quattoni |  |
| 625 |  |  [Reasoning Circuits in Language Models: A Mechanistic Interpretation of Syllogistic Inference](https://aclanthology.org/2025.findings-acl.525/) |  | 0 | Recent studies on reasoning in language models (LMs) have sparked a debate on whether they can learn systematic inferential principles or merely exploit superficial patterns in the training data. To understand and uncover the mechanisms adopted for formal reasoning in LMs, this paper presents a... | Geonhee Kim, Marco Valentino, André Freitas |  |
| 626 |  |  [Multi-Hop Question Generation via Dual-Perspective Keyword Guidance](https://aclanthology.org/2025.findings-acl.526/) |  | 0 | Multi-hop question generation (MQG) aims to generate questions that require synthesizing multiple information snippets from documents to derive target answers. The primary challenge lies in effectively pinpointing crucial information snippets related to question-answer (QA) pairs, typically relying... | Maodong Li, Longyin Zhang, Fang Kong |  |
| 627 |  |  [LoRMA: Low-Rank Multiplicative Adaptation for LLMs](https://aclanthology.org/2025.findings-acl.527/) |  | 0 | Large Language Models have shown remarkable capabilities in the NLP domain. Their effectiveness can mainly be attributed to their ability to adapt to an array of downstream tasks. However, generally, full fine-tuning is a computationally expensive job. To mitigate this, many techniques have been... | Harsh Bihany, Shubham Patel, Ashutosh Modi |  |
| 628 |  |  [DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale](https://aclanthology.org/2025.findings-acl.528/) |  | 0 | Large Language Models have advanced automated software development, however, it remains a challenge to correctly infer dependencies, namely, identifying the internal components and external packages required for a repository to successfully run. Existing studies highlight that dependency-related... | Linghao Zhang, Junhao Wang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Jiaheng Wen, Chengxing Xie, Maoquan Wang, Yufan Huang, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang, Qi Zhang |  |
| 629 |  |  [Weak-to-Strong Honesty Alignment via Learning-to-Rank Supervision](https://aclanthology.org/2025.findings-acl.529/) |  | 0 | Honest alignment refers to the ability of a language model to truthfully convey its knowledge limitations by appropriately refusing to answer questions when it lacks sufficient information. Existing solutions, such as prompt engineering and fine-tuning, face limitations: the former provides only... | Yunfan Xie, Lixin Zou, Dan Luo, Min Tang, Chenliang Li |  |
| 630 |  |  [MultiHoax: A Dataset of Multi-hop False-premise questions](https://aclanthology.org/2025.findings-acl.530/) |  | 0 | As Large Language Models are increasingly deployed in high-stakes domains, their ability to detect false assumptions and reason critically is crucial for ensuring reliable outputs. False-premise questions (FPQs) serve as an important evaluation method by exposing cases where flawed assumptions lead... | Mohammadamin Shafiei, Hamidreza Saffari, Nafise Sadat Moosavi |  |
| 631 |  |  [Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games](https://aclanthology.org/2025.findings-acl.531/) |  | 0 | Interactive Fiction games (IF games) are where players interact through natural language commands. While recent advances in Artificial Intelligence agents have reignited interest in IF games as a domain for studying decision-making, existing approaches prioritize task-specific performance metrics... | Jinming Zhang, Yunfei Long |  |
| 632 |  |  [STATE ToxiCN: A Benchmark for Span-level Target-Aware Toxicity Extraction in Chinese Hate Speech Detection](https://aclanthology.org/2025.findings-acl.532/) |  | 0 | The proliferation of hate speech has caused significant harm to society. The intensity and directionality of hate are closely tied to the target and argument it is associated with. However, research on hate speech detection in Chinese has lagged behind, and existing datasets lack span-level... | Zewen Bai, Liang Yang, Shengdi Yin, Junyu Lu, Jingjie Zeng, Haohao Zhu, Yuanyuan Sun, Hongfei Lin |  |
| 633 |  |  [RelEdit: Evaluating Conceptual Knowledge Editing in Language Models via Relational Reasoning](https://aclanthology.org/2025.findings-acl.533/) |  | 0 | The conceptual knowledge in Large Language Models (LLMs) can become outdated over time, and concept editing is often an option. Current evaluations on conceptual knowledge editing primarily focus on whether the definitions of concepts are successfully edited, neglecting the impact on the model’s... | Yifan Niu, Miao Peng, Nuo Chen, Yatao Bian, Tingyang Xu, Jia Li |  |
| 634 |  |  [Unlocking Speech Instruction Data Potential with Query Rewriting](https://aclanthology.org/2025.findings-acl.534/) |  | 0 | End-to-end Large Speech Language Models (\*\*LSLMs\*\*) demonstrate strong potential in response latency and speech comprehension capabilities, showcasing general intelligence across speech understanding tasks. However, the ability to follow speech instructions has not been fully realized due to... | Yonghua Hei, Yibo Yan, Shuliang Liu, Huiyu Zhou, Linfeng Zhang, Xuming Hu |  |
| 635 |  |  [From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs](https://aclanthology.org/2025.findings-acl.535/) |  | 0 | LLM Unlearning plays a crucial role in removing sensitive information from language models to mitigate potential misuse. However, previous approaches often treat nonsensical responses or template-based refusals (e.g., “Sorry, I cannot answer.”) as the unlearning target, which can give the... | Tianle Gu, Kexin Huang, Ruilin Luo, Yuanqi Yao, Xiuying Chen, Yujiu Yang, Yan Teng, Yingchun Wang |  |
| 636 |  |  [Context-DPO: Aligning Language Models for Context-Faithfulness](https://aclanthology.org/2025.findings-acl.536/) |  | 0 | Reliable responses from large language models (LLMs) require adherence to user instructions and retrieved information. While alignment techniques help LLMs align with human intentions and values, improving context-faithfulness through alignment remains underexplored. To address this, we propose... | Baolong Bi, Shaohan Huang, Yiwei Wang, Tianchi Yang, Zihan Zhang, Haizhen Huang, Lingrui Mei, Junfeng Fang, Zehao Li, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Shenghua Liu |  |
| 637 |  |  [Reasoning Does Not Necessarily Improve Role-Playing Ability](https://aclanthology.org/2025.findings-acl.537/) |  | 0 | The application of role-playing large language models (LLMs) is rapidly expanding in both academic and commercial domains, driving an increasing demand for high-precision role-playing models. Simultaneously, the rapid advancement of reasoning techniques has continuously pushed the performance... | Xiachong Feng, Longxu Dou, Lingpeng Kong |  |
| 638 |  |  [TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios](https://aclanthology.org/2025.findings-acl.538/) |  | 0 | We introduce TableLLM, a robust large language model (LLM) with 8 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method... | Xiaokang Zhang, Sijia Luo, Bohan Zhang, Zeyao Ma, Jing Zhang, Yang Li, Guanlin Li, Zijun Yao, Kangli Xu, Jinchang Zhou, Daniel ZhangLi, Jifan Yu, Shu Zhao, Juanzi Li, Jie Tang |  |
| 639 |  |  [A Survey of LLM-based Agents in Medicine: How far are we from Baymax?](https://aclanthology.org/2025.findings-acl.539/) |  | 0 | Large Language Models (LLMs) are transforming healthcare through LLM-based agents that can understand and assist with medical tasks. This survey examines the architectures, applications, and challenges of LLM-based agents in medicine. We analyze key components including system profiles, clinical... | Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Jiaming Ji, Wenting Chen, Xiang Li, Yixuan Yuan |  |
| 640 |  |  [Context-Robust Knowledge Editing for Language Models](https://aclanthology.org/2025.findings-acl.540/) |  | 0 | Knowledge editing (KE) methods offer an efficient way to modify knowledge in large language models. Current KE evaluations typically assess editing success by considering only the edited knowledge without any preceding contexts. In real-world applications, however, preceding contexts often trigger... | Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo |  |
| 641 |  |  [Multi-Agent Collaboration via Cross-Team Orchestration](https://aclanthology.org/2025.findings-acl.541/) |  | 0 | Large Language Models (LLMs) have significantly impacted various domains, especially through organized LLM-driven autonomous agents. A representative scenario is in software development, where agents can collaborate in a team like humans, following predefined phases to complete sub-tasks... | Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, Yifei Wang, Rennai Qiu, Yufan Dang, Weize Chen, Cheng Yang, Ye Tian, Xuantang Xiong, Lei Han |  |
| 642 |  |  [Semantic Evaluation of Multilingual Data-to-Text Generation via NLI Fine-Tuning: Precision, Recall and F1 scores](https://aclanthology.org/2025.findings-acl.542/) |  | 0 | Performance in the KG-to-Text task has improved over the years, particularly in English. However, models are still prone to mistakes like Additions and Omissions. Furthermore, few languages are taken into account since both train and test data are not readily available. In this paper, we hope to... | William Soto Martinez, Yannick Parmentier, Claire Gardent |  |
| 643 |  |  [Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval](https://aclanthology.org/2025.findings-acl.543/) |  | 0 | Neural retrieval methods using transformer-based pre-trained language models have advanced multilingual and cross-lingual retrieval. However, their effectiveness for low-resource, morphologically rich languages such as Amharic remains underexplored due to data scarcity and suboptimal tokenization.... | Kidist Amde Mekonnen, Yosef Worku Alemneh, Maarten de Rijke |  |
| 644 |  |  [Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge](https://aclanthology.org/2025.findings-acl.544/) |  | 0 | Temporal Logic (TL), especially Signal Temporal Logic (STL), enables precise formal specification, making it widely used in cyber-physical systems such as autonomous driving and robotics. Automatically transforming NL into STL is an attractive approach to overcome the limitations of manual... | Yue Fang, Zhi Jin, Jie An, Hongshen Chen, Xiaohong Chen, Naijun Zhan |  |
| 645 |  |  [DAGS: A Dependency-Based Dual-Attention and Global Semantic Improvement Framework for Metaphor Recognition](https://aclanthology.org/2025.findings-acl.545/) |  | 0 | Current metaphor recognition mainly rely on Metaphor Detection Theory (MDT), such as the Metaphor Identification Procedure, which recognizes metaphors by comparing the basic meaning of target word with context meaning. Existing studies have gradually adopted literal annotations to model basic... | Puli Chen, Cheng Yang, Xingmao Zhang, Qingbao Huang |  |
| 646 |  |  [ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models](https://aclanthology.org/2025.findings-acl.546/) |  | 0 | The rapid adoption of large language models (LLMs) in diverse applications has intensified concerns over their security and integrity, especially in cloud environments where internal model parameters are inaccessible to users. Traditional tamper detection methods, designed for deterministic... | Xiaofan Bai, Pingyi Hu, Xiaojing Ma, Linchen Yu, Dongmei Zhang, Qi Zhang, Bin Benjamin Zhu |  |
| 647 |  |  [The Lessons of Developing Process Reward Models in Mathematical Reasoning](https://aclanthology.org/2025.findings-acl.547/) |  | 0 | Process Reward Models (PRMs) aim to identify and mitigate intermediate errors in the reasoning processes in mathematical reasoning of Large Language Models (LLMs).However, the development of effective PRMs faces significant challenges, particularly in data annotation and evaluation methodologies.In... | Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin |  |
| 648 |  |  [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://aclanthology.org/2025.findings-acl.548/) |  | 0 | Open-ended question answering (QA) is a key task for evaluating the capabilities of large language models (LLMs). Compared to closed-ended QA, it demands longer answer statements, more nuanced reasoning processes, and diverse expressions, making refined and interpretable automatic evaluation both... | Yongqi Fan, Yating Wang, Guandong Wang, Jie Zhai, Jingping Liu, Qi Ye, Tong Ruan |  |
| 649 |  |  [Towards Conditioning Clinical Text Generation for User Control](https://aclanthology.org/2025.findings-acl.549/) |  | 0 | Deploying natural language generation systems in clinical settings remains challenging despite advances in Large Language Models (LLMs), which continue to exhibit hallucinations and factual inconsistencies, necessitating human oversight. This paper explores automated dataset augmentation using LLMs... | Osman Alperen Koras, Rabi Bahnan, Jens Kleesiek, Amin Dada |  |
| 650 |  |  [CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings](https://aclanthology.org/2025.findings-acl.550/) |  | 0 | Large Language Models (LLMs) have revolutionized code generation, automating programming with remarkable efficiency. However, this has had important consequences for programming skills, ethics, and assessment integrity, thus making the detection of LLM-generated code essential for maintaining... | Daniil Orel, Dilshod Azizov, Preslav Nakov |  |
| 651 |  |  [Q-Mamba: Towards more efficient Mamba models via post-training quantization](https://aclanthology.org/2025.findings-acl.551/) |  | 0 | State Space Models (SSMs), such as Mamba, have recently demonstrated potential in language understanding tasks, positioning them as competitors to transformer architectures. However, our investigations reveal that the Mamba architecture still has room for further optimization—not only in linear... | Tianqi Chen, Yuanteng Chen, Peisong Wang, Weixiang Xu, Zeyu Zhu, Jian Cheng |  |
| 652 |  |  [P²Net: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts](https://aclanthology.org/2025.findings-acl.552/) |  | 0 | Key Information Extraction (KIE) is a challenging multimodal task aimed at extracting structured value entities from visually rich documents. Despite recent advancements, two major challenges remain. First, existing datasets typically feature fixed layouts and a limited set of entity categories,... | Kaiwen Wei, Jie Yao, Jiang Zhong, Yangyang Kang, Jingyuan Zhang, Changlong Sun, Xin Zhang, Fengmao Lv, Li Jin |  |
| 653 |  |  [Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models](https://aclanthology.org/2025.findings-acl.553/) |  | 0 | Sentence embedding is essential for many NLP tasks, with contrastive learning methods achieving strong performance using annotated datasets like NLI. Yet, the reliance on manual labels limits scalability. Recent studies leverage large language models (LLMs) to generate sentence pairs, reducing... | Liyang He, Chenglong Liu, Rui Li, Zhenya Huang, Shulan Ruan, Jun Zhou, Enhong Chen |  |
| 654 |  |  [RQT: Hierarchical Residual Quantization for Multi-Model Compression](https://aclanthology.org/2025.findings-acl.554/) |  | 0 | Delta compression methods focus on efficiently serving multiple uniquely fine-tuned models, each tailored to specific tasks and user requirements. These approaches decompose a fine-tuned LLM into a base model and corresponding delta weights, which are compressed using low-rank or low-bit... | Tianqi Chen, Peisong Wang, Weixiang Xu, Zeyu Zhu, Jian Cheng |  |
| 655 |  |  [taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades](https://aclanthology.org/2025.findings-acl.555/) |  | 0 | Open-access corpora are essential for advancing natural language processing (NLP) and computational social science (CSS). However,large-scale resources for German remain limited, restricting research on linguistic trends and societal issues such as gender bias. Wepresent taz2024full, the largest... | Stefanie Urchs, Veronika Thurner, Matthias Aßenmacher, Christian Heumann, Stephanie Thiemichen |  |
| 656 |  |  [LCFO: Long Context and Long Form Output Dataset and Benchmarking](https://aclanthology.org/2025.findings-acl.556/) |  | 0 | This paper presents the Long Context and Form Output (LCFO) benchmark, a novel evaluation framework for assessing gradual summarization and summary expansion capabilities across diverse domains. LCFO consists of long input documents (5k words average length), each of which comes with three... | Marta R. Costajussà, Pierre Andrews, Mariano Coria Meglioli, Joy Chen, Joe Chuang, David Dale, Christophe Ropers, Alexandre Mourachko, Eduardo Sánchez, Holger Schwenk, Tuan Tran, Arina Turkatenko, Carleigh Wood |  |
| 657 |  |  [Span-based Semantic Role Labeling as Lexicalized Constituency Tree Parsing](https://aclanthology.org/2025.findings-acl.557/) |  | 0 | Semantic Role Labeling (SRL) is a critical task that focuses on identifying predicate-argument structures in sentences. Span-based SRL, a prominent paradigm, is often tackled using BIO-based or graph-based methods. However, these approaches often fail to capture the inherent relationship between... | Yang Hou, Zhenghua Li |  |
| 658 |  |  [Learning from Negative Samples in Biomedical Generative Entity Linking](https://aclanthology.org/2025.findings-acl.558/) |  | 0 | Generative models have become widely used in biomedical entity linking (BioEL) due to their excellent performance and efficient memory usage. However, these models are usually trained only with positive samples—entities that match the input mention’s identifier—and do not explicitly learn from hard... | Chanhwi Kim, Hyunjae Kim, Sihyeon Park, Jiwoo Lee, Mujeen Sung, Jaewoo Kang |  |
| 659 |  |  [Self-play through Computational Runtimes improves Chart Reasoning](https://aclanthology.org/2025.findings-acl.559/) |  | 0 | Vision-language models (VLMs) achieve impressive zero-shot performance on multimodal reasoning tasks. Typically, best reported performance is achieved with a zero- or a few-shot prompt. We observe that asking the model to take other routes of solving the same task, such as through code generation,... | Tautvydas Misiunas, Hassan Mansoor, Jasper Uijlings, Oriana Riva, Victor Carbune |  |
| 660 |  |  [Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness](https://aclanthology.org/2025.findings-acl.560/) |  | 0 | Chain-of-thought (CoT) prompting demonstrates varying performance under different reasoning tasks.Previous work attempts to evaluate it but falls short in providing an in-depth analysis of patterns that influence the CoT. In this paper, we study the CoT performance from the perspective of... | Jiachun Li, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao |  |
| 661 |  |  [A Couch Potato is not a Potato on a Couch: Prompting Strategies, Image Generation, and Compositionality Prediction for Noun Compounds](https://aclanthology.org/2025.findings-acl.561/) |  | 0 | We explore the role of the visual modality and of vision transformers in predicting the compositionality of English noun compounds. Crucially, we contribute a framework to address the challenge of obtaining adequate images that represent non-compositional compounds (such as “couch potato”), making... | Sinan Kurtyigit, Diego Frassinelli, Carina Silberer, Sabine Schulte im Walde |  |
| 662 |  |  [A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI](https://aclanthology.org/2025.findings-acl.562/) |  | 0 | Disagreement in human labeling is ubiquitous, and can be captured in human judgment distributions (HJDs). Recent research has shown that explanations provide valuable information for understanding human label variation (HLV) and large language models (LLMs) can approximate HJD from a few... | Beiduo Chen, Siyao Peng, Anna Korhonen, Barbara Plank |  |
| 663 |  |  [Measuring What Matters: Evaluating Ensemble LLMs with Label Refinement in Inductive Coding](https://aclanthology.org/2025.findings-acl.563/) |  | 0 | Inductive coding traditionally relies on labor-intensive human efforts, who are prone to inconsistencies and individual biases. Although large language models (LLMs) offer promising automation capabilities, their standalone use often results in inconsistent outputs, limiting their reliability. In... | Angelina Parfenova, Jürgen Pfeffer |  |
| 664 |  |  [Dynamic Evil Score-Guided Decoding: An Efficient Decoding Framework For Red-Team Model](https://aclanthology.org/2025.findings-acl.564/) |  | 0 | Large language models (LLMs) have achieved significant advances but can potentially generate harmful content such as social biases, extremism, and misinformation. Red teaming is a promising approach to enhance model safety by creating adversarial prompts to test and improve model robustness.... | Cong Gao, Bo Zhang, Linkang Yang, Minghao Hu, Zhunchen Luo, Xiaoying Bai, Guotong Geng, Jun Zhang, Yunhua Xue |  |
| 665 |  |  [CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations](https://aclanthology.org/2025.findings-acl.565/) |  | 0 | Discourse parsing is an important task useful for NLU applications such as summarization, machine comprehension, and emotion recognition. The current discourse parsing datasets based on conversations consists of written English dialogues restricted to a single domain. In this resource paper, we... | Divyaksh Shukla, Ritesh Baviskar, Dwijesh Gohil, Aniket Tiwari, Atul Shree, Ashutosh Modi |  |
| 666 |  |  [Multi-word Measures: Modeling Semantic Change in Compound Nouns](https://aclanthology.org/2025.findings-acl.566/) |  | 0 | Compound words (e.g. shower thought) provide a multifaceted challenge for diachronic models of semantic change. Datasets describing noun compound semantics tend to describe only the predominant sense of a compound, which is limiting, especially in diachronic settings where senses may shift over... | Chris W. Jenkins, Filip Miletic, Sabine Schulte im Walde |  |
| 667 |  |  [Bridge-Coder: Transferring Model Capabilities from High-Resource to Low-Resource Programming Language](https://aclanthology.org/2025.findings-acl.567/) |  | 0 | Most LLMs universally excel at generating code for high-resource programming languages (HRPLs) like Python, a capability that has become standard due to the abundance of training data. However, they struggle significantly with low-resource programming languages (LRPLs) such as D, exacerbating the... | Jipeng Zhang, Jianshu Zhang, Yuanzhe Li, Renjie Pi, Rui Pan, Runtao Liu, Ziqiang Zheng, Tong Zhang |  |
| 668 |  |  [ProBench: Judging Multimodal Foundation Models on Open-ended Multi-domain Expert Tasks](https://aclanthology.org/2025.findings-acl.568/) |  | 0 | Solving expert-level multimodal tasks is a key milestone in general intelligence. As the capabilities of multimodal large language models (MLLMs) continue to evolve, evaluation of frontier multimodal intelligence becomes necessary yet challenging. In this work, we introduce ProBench, a benchmark of... | Yan Yang, Dongxu Li, Haoning Wu, Bei Chen, Liu Liu, Liyuan Pan, Junnan Li |  |
| 669 |  |  [2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset Download PDF](https://aclanthology.org/2025.findings-acl.569/) |  | 0 | We introduce the first highly multilingual speech and American Sign Language (ASL) comprehension dataset by extending BELEBELE. Our dataset covers 91 spoken languages at the intersection of BELEBELE and FLEURS, and one sign language (ASL). As a by-product we also extend the Automatic Speech... | Marta R. Costajussà, Bokai Yu, Pierre Andrews, Belen Alastruey, Necati Cihan Camgöz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkatenko, Carleigh Wood |  |
| 670 |  |  [LSC-Eval: A General Framework to Evaluate Methods for Assessing Dimensions of Lexical Semantic Change Using LLM-Generated Synthetic Data](https://aclanthology.org/2025.findings-acl.570/) |  | 0 | Lexical Semantic Change (LSC) provides insight into cultural and social dynamics. Yet, the validity of methods for measuring different kinds of LSC remains unestablished due to the absence of historical benchmark datasets. To address this gap, we propose LSC-Eval, a novel three-stage... | Naomi Baes, Raphaël Merx, Nick Haslam, Ekaterina Vylomova, Haim Dubossarsky |  |
| 671 |  |  [Chain-of-Jailbreak Attack for Image Generation Models via Step by Step Editing](https://aclanthology.org/2025.findings-acl.571/) |  | 0 | Text-based image generation models, such as Stable Diffusion and DALL-E 3, hold significant potential in content creation and publishing workflows, making them the focus in recent years. Despite their remarkable capability to generate diverse and vivid images, considerable efforts are being made to... | Wenxuan Wang, Kuiyi Gao, Youliang Yuan, Jentse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, Zhaopeng Tu |  |
| 672 |  |  [Tokenization is Sensitive to Language Variation](https://aclanthology.org/2025.findings-acl.572/) |  | 0 | Variation in language is ubiquitous and often systematically linked to regional, social, and contextual factors. Tokenizers split texts into smaller units and might behave differently for less common linguistic forms. This might affect downstream LLM performance differently on two types of tasks:... | Anna Wegmann, Dong Nguyen, David Jurgens |  |
| 673 |  |  [WirelessMathBench: A Mathematical Modeling Benchmark for LLMs in Wireless Communications](https://aclanthology.org/2025.findings-acl.573/) |  | 0 | Large Language Models (LLMs) have achieved impressive results across a broad array of tasks, yet their capacity for complex, domain-specific mathematical reasoning—particularly in wireless communications—remains underexplored. In this work, we introduce WirelessMathBench, a novel benchmark... | Xin Li, Mengbing Liu, Li Wei, Jiancheng An, Mérouane Abdelkader Debbah, Chau Yuen |  |
| 674 |  |  [Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment](https://aclanthology.org/2025.findings-acl.574/) |  | 0 | Multi-Objective Alignment (MOA) aims to align LLMs’ responses with multiple human preference objectives, with Direct Preference Optimization (DPO) emerging as a prominent approach. However, we find that DPO-based MOA approaches suffer from widespread preference conflicts in the data, where... | Moxin Li, Yuantao Zhang, Wenjie Wang, Wentao Shi, Zhuo Liu, Fuli Feng, TatSeng Chua |  |
| 675 |  |  [Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training](https://aclanthology.org/2025.findings-acl.575/) |  | 0 | Large language models (LLMs) exhibit remarkable multilingual capabilities despite the extreme language imbalance in the pre-training data. In this paper, we closely examine the reasons behind this phenomenon, focusing on the pre-training corpus. We find that the existence of code-switching,... | Zhijun Wang, Jiahuan Li, Hao Zhou, Rongxiang Weng, Jingang Wang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang |  |
| 676 |  |  [User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs](https://aclanthology.org/2025.findings-acl.576/) |  | 0 | Measuring the generalization ability of Large Language Models (LLMs) is challenging due to data contamination. As models grow and computation becomes cheaper, ensuring tasks and test cases are unseen during training phases will become nearly impossible. We argue that knowledge-retrieval and... | Sougata Saha, Monojit Choudhury |  |
| 677 |  |  [Beyond Browsing: API-Based Web Agents](https://aclanthology.org/2025.findings-acl.577/) |  | 0 | Web browsers are a portal to the internet, where much of human activity is undertaken. Thus, there has been significant research work in AI agents that interact with the internet through web browsing.However, there is also another interface designed specifically for machine interaction with online... | Yueqi Song, Frank F. Xu, Shuyan Zhou, Graham Neubig |  |
| 678 |  |  [MiLiC-Eval: Benchmarking Multilingual LLMs for China's Minority Languages](https://aclanthology.org/2025.findings-acl.578/) |  | 0 | Large language models (LLMs) excel in high-resource languages but struggle with low-resource languages (LRLs), particularly those spoken by minority communities in China, such as Tibetan, Uyghur, Kazakh, and Mongolian. To systematically track the progress in these languages, we introduce... | Chen Zhang, Mingxu Tao, Zhiyuan Liao, Yansong Feng |  |
| 679 |  |  [ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation](https://aclanthology.org/2025.findings-acl.579/) |  | 0 | Training large language models (LLMs) to follow instructions has significantly enhanced their ability to tackle unseen tasks. However, despite their strong generalization capabilities, instruction-following LLMs encounter difficulties when dealing with tasks that require domain knowledge. This work... | Maja Stahl, Timon Ziegenbein, Joonsuk Park, Henning Wachsmuth |  |
| 680 |  |  [Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings](https://aclanthology.org/2025.findings-acl.580/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks yet still are vulnerable to external threats, particularly LLM Denial-of-Service (LLM-DoS) attacks. Specifically, LLM-DoS attacks aim to exhaust computational resources and block services. However, existing... | Yuanhe Zhang, Zhenhong Zhou, Wei Zhang, Xinyue Wang, Xiaojun Jia, Yang Liu, Sen Su |  |
| 681 |  |  [Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.581/) |  | 0 | Large Language Models (LLMs) have shown impressive moral reasoning abilities. Yet they often diverge when confronted with complex, multi-factor moral dilemmas. To address these discrepancies, we propose a framework that synthesizes multiple LLMs’ moral judgments into a collectively formulated moral... | Chenchen Yuan, Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci |  |
| 682 |  |  [Unlocking Recursive Thinking of LLMs: Alignment via Refinement](https://aclanthology.org/2025.findings-acl.582/) |  | 0 | The OpenAI o1-series models have demonstrated that leveraging long-form Chain of Thought (CoT) can substantially enhance performance. However, the recursive thinking capabilities of Large Language Models (LLMs) remain limited, particularly in the absence of expert-curated data for distillation. In... | Haoke Zhang, Xiaobo Liang, Cunxiang Wang, Juntao Li, Min Zhang |  |
| 683 |  |  [CitaLaw: Enhancing LLM with Citations in Legal Domain](https://aclanthology.org/2025.findings-acl.583/) |  | 0 | In this paper, we propose CitaLaw, the first benchmark designed to evaluate LLMs’ ability to produce legally sound responses with appropriate citations. CitaLaw features a diverse set of legal questions for both laypersons and practitioners, paired with a comprehensive corpus of law articles and... | Kepu Zhang, Weijie Yu, Sunhao Dai, Jun Xu |  |
| 684 |  |  [MEGen: Generative Backdoor into Large Language Models via Model Editing](https://aclanthology.org/2025.findings-acl.584/) |  | 0 | Large language models (LLMs) have exhibited remarkable versatility and adaptability, while their widespread adoption across various applications also raises critical safety concerns.This paper focuses on the impact of backdoored LLMs. Traditional backdoor injection methods are primarily limited to... | Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao, Yun Li, Qianren Wang |  |
| 685 |  |  [Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations](https://aclanthology.org/2025.findings-acl.585/) |  | 0 | Measuring social bias in large language models (LLMs) is crucial, but existing bias evaluation methods struggle to assess bias in long-form generation. We propose a Bias Benchmark for Generation (BBG), an adaptation of the Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form... | Jiho Jin, Woosung Kang, Junho Myung, Alice Oh |  |
| 686 |  |  [Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models](https://aclanthology.org/2025.findings-acl.586/) |  | 0 | Visuals are valuable tools for teaching math word problems (MWPs), helping young learners interpret textual descriptions into mathematical expressions before solving them.However, creating such visuals is labor-intensive and there is a lack of automated methods to support this process. In this... | Junling Wang, Anna Rutkiewicz, April Yi Wang, Mrinmaya Sachan |  |
| 687 |  |  [RASPberry: Retrieval-Augmented Monte Carlo Tree Self-Play with Reasoning Consistency for Multi-Hop Question Answering](https://aclanthology.org/2025.findings-acl.587/) |  | 0 | Complex multi-hop question answering requires large language models (LLMs) not only to retrieve external knowledge but also to reason over the retrieved information in order to arrive at the final solution. This involves two key challenges: (i) how to effectively explore the solution space and... | Baixuan Li, Yunlong Fan, Tianyi Ma, Miao Gao, Chuanqi Shi, Zhiqiang Gao |  |
| 688 |  |  [All That Glitters is Not Gold: Improving Robust Retrieval-Augmented Language Models with Fact-Centric Preference Alignment](https://aclanthology.org/2025.findings-acl.588/) |  | 0 | Retrieval-augmented language model (RALM) relies on retrieved external knowledge to generate responses, resulting in vulnerability in the face of retrieval results with noisy documents. Previous works integrate additional filters or finetune Large Language Models (LLMs) to learn adaptive retrieval... | Jia Hao, Chunhong Zhang, Jiarun Liu, Haiyu Zhao, Zhiqiang Zhan, Zheng Hu |  |
| 689 |  |  [FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation Steering](https://aclanthology.org/2025.findings-acl.589/) |  | 0 | Large language models (LLMs) are prone to capturing biases from training corpus, leading to potential negative social impacts. Existing prompt-based debiasing methods exhibit instability due to their sensitivity to prompt changes, while fine-tuning-based techniques incur substantial computational... | Yichen Li, Zhiting Fan, Ruizhe Chen, Xiaotang Gai, Luqi Gong, Yan Zhang, Zuozhu Liu |  |
| 690 |  |  [Listen, Watch, and Learn to Feel: Retrieval-Augmented Emotion Reasoning for Compound Emotion Generation](https://aclanthology.org/2025.findings-acl.590/) |  | 0 | The ability to comprehend human emotion using multimodal large language models (MLLMs) is essential for advancing human-AI interaction and multimodal sentiment analysis. While psychology theory-based human annotations have contributed to multimodal emotion tasks, the subjective nature of emotional... | Zhuofan Wen, Zheng Lian, Shun Chen, Hailiang Yao, Longjiang Yang, Bin Liu, Jianhua Tao |  |
| 691 |  |  [GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion](https://aclanthology.org/2025.findings-acl.591/) |  | 0 | Knowledge Graph Completion (KGC), which aims to infer missing or incomplete facts, is a crucial task for KGs. However, integrating the vital structural information of KGs into Large Language Models (LLMs) and outputting predictions deterministically remains challenging. To address this, we propose... | Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Zhu Liu, Yingli Shen, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun |  |
| 692 |  |  [Learning to Select In-Context Demonstration Preferred by Large Language Model](https://aclanthology.org/2025.findings-acl.592/) |  | 0 | In-context learning (ICL) enables large language models (LLMs) to adapt to new tasks during inference using only a few demonstrations. However, ICL performance is highly dependent on the selection of these demonstrations. Recent work explores retrieval-based methods for selecting query-specific... | Zheng Zhang, Shaocheng Lan, Lei Song, Jiang Bian, Yexin Li, Kan Ren |  |
| 693 |  |  [Beyond the Spelling Miracle: Investigating Substring Awareness in Character-Blind Language Models](https://aclanthology.org/2025.findings-acl.593/) |  | 0 | Correctly identifying characters and substrings of words should be a basic but essential ability of any Language Model that aims to proficiently understand and produce language. Despite so, the majority of Pre-trained Language Models (PLMs) are “character-blind” and struggle in spelling tasks,... | Cristiano Ciaccio, Marta Sartor, Alessio Miaschi, Felice Dell'Orletta |  |
| 694 |  |  [DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling](https://aclanthology.org/2025.findings-acl.594/) |  | 0 | Large language models (LLMs) enabled dialogue systems have become one of the central modes in human-machine interaction, which bring about vast amounts of conversation logs and increasing demand for dialogue generation. The dialogue’s life-cycle spans from Prelude through Interlocution to Epilogue,... | Minzheng Wang, Xinghua Zhang, Kun Chen, Nan Xu, Haiyang Yu, Fei Huang, Wenji Mao, Yongbin Li |  |
| 695 |  |  [InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation](https://aclanthology.org/2025.findings-acl.595/) |  | 0 | In-context learning (ICL) is critical for large language models (LLMs), but its effectiveness is constrained by finite context windows, particularly in ultra-long contexts. To overcome this, we introduce \*\*InfiniteICL\*\*, a framework that parallels context and parameters in LLMs with short- and... | Bowen Cao, Deng Cai, Wai Lam |  |
| 696 |  |  [M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations](https://aclanthology.org/2025.findings-acl.596/) |  | 0 | Emotion Cause Triplet Extraction in Multimodal Conversations (MECTEC) has recently gained significant attention in social media analysis, aiming to extract emotion utterances, cause utterances, and emotion categories simultaneously. However, the scarcity of related datasets, with only one published... | Qiao Liang, Ying Shen, Tiantian Chen, Lin Zhang |  |
| 697 |  |  [Large Language Models Are Natural Video Popularity Predictors](https://aclanthology.org/2025.findings-acl.597/) |  | 0 | Predicting video popularity is often framed as a supervised learning task, relying heavily on meta-information and aggregated engagement data. However, video popularity is shaped by complex cultural and social factors that such approaches often overlook. We argue that Large Language Models (LLMs),... | Pratik Kayal, Pascal Mettes, Nima Dehmamy, Minsu Park |  |
| 698 |  |  [DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](https://aclanthology.org/2025.findings-acl.598/) |  | 0 | Large Language Models (LLMs) are widely applied in decision making, but their deployment is threatened by jailbreak attacks, where adversarial users manipulate model behavior to bypass safety measures. Existing defense mechanisms, such as safety fine-tuning and model editing, either require... | Yi Wang, Fenghua Weng, Sibei Yang, Zhan Qin, Minlie Huang, Wenjie Wang |  |
| 699 |  |  [You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with Multi-Agent Conversations](https://aclanthology.org/2025.findings-acl.599/) |  | 0 | Meeting summarization suffers from limited high-quality data, mainly due to privacy restrictions and expensive collection processes. We address this gap with FAME, a dataset of 500 meetings in English and 300 in German produced by MIMIC, our new multi-agent meeting synthesis framework that... | Frederic Kirstein, Muneeb Khan, Jan Philip Wahle, Terry Ruas, Bela Gipp |  |
| 700 |  |  [Code-Switching and Syntax: A Large-Scale Experiment](https://aclanthology.org/2025.findings-acl.600/) |  | 0 | The theoretical code-switching (CS) literature provides numerous pointwise investigations that aim to explain patterns in CS, i.e. why bilinguals switch language in certain positions in a sentence more often than in others. A resulting consensus is that CS can be explained by the syntax of the... | Igor Sterner, Simone Teufel |  |
| 701 |  |  [Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System](https://aclanthology.org/2025.findings-acl.601/) |  | 0 | Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel... | Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun |  |
| 702 |  |  [Generating Domain-Specific Knowledge Graphs from Large Language Models](https://aclanthology.org/2025.findings-acl.602/) |  | 0 | Knowledge graphs (KGs) have been a cornerstone of search and recommendation due to their ability to store factual knowledge about any domain in a structured form enabling easy search and retrieval. Large language models (LLMs) have shown impressive world knowledge across different benchmarks and... | Marinela Parovic, Ze Li, Jinhua Du |  |
| 703 |  |  [Large Language Models are Miscalibrated In-Context Learners](https://aclanthology.org/2025.findings-acl.603/) |  | 0 | When adapting ICL with or without fine-tuning, we are curious about whether the instruction-tuned language model is able to achieve well-calibrated results without suffering from the problem of overconfidence (i.e., miscalibration) considering its strong instruction following ability, especially in... | Chengzu Li, Han Zhou, Goran Glavas, Anna Korhonen, Ivan Vulic |  |
| 704 |  |  [STeCa: Step-level Trajectory Calibration for LLM Agent Learning](https://aclanthology.org/2025.findings-acl.604/) |  | 0 | Large language model (LLM)-based agents have shown promise in tackling complex tasks by interacting dynamically with the environment. Existing work primarily focuses on behavior cloning from expert demonstrations or preference learning through exploratory trajectory sampling. However, these methods... | Hanlin Wang, Jian Wang, Chak Tou Leong, Wenjie Li |  |
| 705 |  |  [LEMMA: Learning from Errors for MatheMatical Advancement in LLMs](https://aclanthology.org/2025.findings-acl.605/) |  | 0 | Large language models (LLMs) have demonstrated remarkable reasoning capability in solving mathematical problems. However, existing approaches primarily focus on improving the quality of correct training data, e.g., distilling high-quality correct solutions from advanced models, neglecting the value... | Zhuoshi Pan, Yu Li, Honglin Lin, Qizhi Pei, Zinan Tang, Wei Wu, Chenlin Ming, H. Vicky Zhao, Conghui He, Lijun Wu |  |
| 706 |  |  [Voting or Consensus? Decision-Making in Multi-Agent Debate](https://aclanthology.org/2025.findings-acl.606/) |  | 0 | Much of the success of multi-agent debates depends on carefully choosing the right parameters. The decision-making protocol stands out as it can highly impact final model answers, depending on how decisions are reached. Systematic comparison of decision protocols is difficult because many studies... | Lars Benedikt Kaesberg, Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp |  |
| 707 |  |  [Rhetorical Device-Aware Sarcasm Detection with Counterfactual Data Augmentation](https://aclanthology.org/2025.findings-acl.607/) |  | 0 | Sarcasm is a complex form of sentiment expression widely used in human daily life. Previous work primarily defines sarcasm as a form of verbal irony, which covers only a subset of real-world sarcastic expressions. However, sarcasm serves multifaceted functions and manifests itself through various... | Qingqing Hong, Dongyu Zhang, Jiayi Lin, Dapeng Yin, Shuyue Zhu, Junli Wang |  |
| 708 |  |  [Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching](https://aclanthology.org/2025.findings-acl.608/) |  | 0 | In-Context Learning (ICL) empowers Large Language Models (LLMs) for rapid task adaptation without Fine-Tuning (FT), but its reliance on demonstration selection remains a critical challenge. While many-shot ICL shows promising performance through scaled demonstrations, the selection method for... | Jianfei Zhang, Bei Li, Jun Bai, Rumei Li, Yanmeng Wang, Chenghua Lin, Wenge Rong |  |
| 709 |  |  [Cheap Character Noise for OCR-Robust Multilingual Embeddings](https://aclanthology.org/2025.findings-acl.609/) |  | 0 | The large amount of text collections digitized by imperfect OCR systems requires semantic search models that perform robustly on noisy input. Such collections are highly heterogeneous, with varying degrees of OCR quality, spelling conventions and other inconsistencies —all phenomena that are... | Andrianos Michail, Juri Opitz, Yining Wang, Robin Meister, Rico Sennrich, Simon Clematide |  |
| 710 |  |  [Physics: Benchmarking Foundation Models on University-Level Physics Problem Solving](https://aclanthology.org/2025.findings-acl.610/) |  | 0 | We introduce Physics, a comprehensive benchmark for university-level physics problem solving. It contains 1,297 expert-annotated problems covering six core areas: classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, atomic physics, and optics.Each... | Kaiyue Feng, Yilun Zhao, Yixin Liu, Tianyu Yang, Chen Zhao, John Sous, Arman Cohan |  |
| 711 |  |  [DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards Meaningful LLM Evaluation](https://aclanthology.org/2025.findings-acl.611/) |  | 0 | Recent work found that LLMs are sensitive to a wide range of arbitrary prompt dimensions, including the type of delimiters, answer enumerators, instruction wording, and more. This throws into question popular single-prompt evaluation practices. We present DOVE (Dataset Of Variation Evaluation) a... | Eliya Habba, Ofir Arviv, Itay Itzhak, Yotam Perlitz, Elron Bandel, Leshem Choshen, Michal ShmueliScheuer, Gabriel Stanovsky |  |
| 712 |  |  [ALPS: Attention Localization and Pruning Strategy for Efficient Adaptation of Large Language Models](https://aclanthology.org/2025.findings-acl.612/) |  | 0 | Aligning general-purpose large language models (LLMs) to downstream tasks often incurs significant training adjustment costs. Prior research has explored various avenues to enhance alignment efficiency, primarily through minimal-data training or data-driven activations to identify key attention... | Hao Chen, Haoze Li, Zhiqing Xiao, Lirong Gao, Qi Zhang, Xiaomeng Hu, Ningtao Wang, Xing Fu, Junbo Zhao |  |
| 713 |  |  [DeTAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification](https://aclanthology.org/2025.findings-acl.613/) |  | 0 | With the widespread adoption of Large Language Models (LLMs), jailbreak attacks have become an increasingly pressing safety concern. While safety-aligned LLMs can effectively defend against normal harmful queries, they remain vulnerable to such attacks. Existing defense methods primarily rely on... | Yu Li, Han Jiang, Zhihua Wei |  |
| 714 |  |  [A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges](https://aclanthology.org/2025.findings-acl.614/) |  | 0 | Mathematical reasoning, a core aspect of human cognition, is vital across many domains, from educational problem-solving to scientific advancements. As artificial general intelligence (AGI) progresses, integrating large language models (LLMs) with mathematical reasoning tasks is becoming... | Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu |  |
| 715 |  |  [Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors](https://aclanthology.org/2025.findings-acl.615/) |  | 0 | We propose Fast-and-Frugal Text-Graph (FnF-TG) Transformers, a Transformer-based framework that unifies textual and structural information for inductive link prediction in text-attributed knowledge graphs. We demonstrate that, by effectively encoding ego-graphs (1-hop neighbourhoods), we can reduce... | Andrei Catalin Coman, Christos Theodoropoulos, MarieFrancine Moens, James Henderson |  |
| 716 |  |  [NeoQA: Evidence-based Question Answering with Generated News Events](https://aclanthology.org/2025.findings-acl.616/) |  | 0 | Evaluating Retrieval-Augmented Generation (RAG) in large language models (LLMs) is challenging because benchmarks can quickly become stale. Questions initially requiring retrieval may become answerable from pretraining knowledge as newer models incorporate more recent information during... | Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer |  |
| 717 |  |  [ChatMap: Mining Human Thought Processes for Customer Service Chatbots via Multi-Agent Collaboration](https://aclanthology.org/2025.findings-acl.617/) |  | 0 | Leveraging Large Language Models (LLMs) to build domain-specific conversational agents, especially for e-commerce customer service chatbots, is a growing focus. While existing methods enhance dialogue performance by extracting core patterns from dialogue data and integrating them into models, two... | Xinyi Jiang, Tianyi Hu, Yuheng Qin, Guoming Wang, Zhou Huan, Kehan Chen, Gang Huang, Rongxing Lu, Siliang Tang |  |
| 718 |  |  [P3: Prompts Promote Prompting](https://aclanthology.org/2025.findings-acl.618/) |  | 0 | Current large language model (LLM) applications often employ multi-component prompts, comprising both system and user prompts, to guide model behaviors. While recent advancements have demonstrated the efficacy of automatically optimizing either the system or user prompt to boost performance, such... | Xinyu Zhang, Yuanquan Hu, Fangchao Liu, Zhicheng Dou |  |
| 719 |  |  [VAQUUM: Are Vague Quantifiers Grounded in Visual Data?](https://aclanthology.org/2025.findings-acl.619/) |  | 0 | Vague quantifiers such as “a few” and “many” are influenced by various contextual factors, including the number of objects present in a given context. In this work, we evaluate the extent to which vision-and-language models (VLMs) are compatible with humans when producing or judging the... | Hugh Mee Wong, Rick Nouwen, Albert Gatt |  |
| 720 |  |  [Forgotten Polygons: Multimodal Large Language Models are Shape-Blind](https://aclanthology.org/2025.findings-acl.620/) |  | 0 | Despite strong performance on vision-language tasks, Multimodal Large Language Models (MLLMs) struggle with mathematical problem-solving, with both open-source and state-of-the-art models falling short of human performance on visual-math benchmarks. To systematically examine visual-mathematical... | William Rudman, Michal Golovanevsky, Amir Bar, Vedant Palit, Yann LeCun, Carsten Eickhoff, Ritambhara Singh |  |
| 721 |  |  [MindBridge: Scalable and Cross-Model Knowledge Editing via Memory-Augmented Modality](https://aclanthology.org/2025.findings-acl.621/) |  | 0 | Knowledge editing is a technique for efficiently and accurately updating the knowledge of large language models (LLMs) to alleviate obsolescence and correct errors. However, most existing methods overfit to specific models, causing edited knowledge to be discarded during each LLM update and... | Shuaike Li, Kai Zhang, Qi Liu, Enhong Chen |  |
| 722 |  |  [FIHA: Automated Fine-grained Hallucinations Evaluations in Large Vision Language Models with Davidson Scene Graphs](https://aclanthology.org/2025.findings-acl.622/) |  | 0 | The rapid development of Large Vision-Language Models (LVLMs) often comes with widespread hallucination issues, making cost-effective and comprehensive assessments increasingly vital. Current approaches mainly rely on costly annotations and are not comprehensive – in terms of evaluating all... | Bowen Yan, Zhengsong Zhang, Liqiang Jing, Eftekhar Hossain, Xinya Du |  |
| 723 |  |  [On the Role of Semantic Proto-roles in Semantic Analysis: What do LLMs know about agency?](https://aclanthology.org/2025.findings-acl.623/) |  | 0 | Large language models (LLMs) are increasingly used in decision-making contexts, yet their ability to reason over event structure—an important component in the situational awareness needed to make complex decisions—is not well understood. By operationalizing proto-role theory, which characterizes... | Elizabeth Spaulding, Shafiuddin Rehan Ahmed, James H. Martin |  |
| 724 |  |  [GeAR: Graph-enhanced Agent for Retrieval-augmented Generation](https://aclanthology.org/2025.findings-acl.624/) |  | 0 | Retrieval-augmented Generation (RAG) relies on effective retrieval capabilities, yet traditional sparse and dense retrievers inherently struggle with multi-hop retrieval scenarios. In this paper, we introduce G\small{E}\normalsize{AR}, a system that advances RAG performance through two key... | Zhili Shen, Chenxin Diao, Pavlos Vougiouklis, Pascual Merita, Shriram Piramanayagam, Enting Chen, Damien Graux, André Melo, Ruofei Lai, Zeren Jiang, Zhongyang Li, Ye Qi, Yang Ren, Dandan Tu, Jeff Z. Pan |  |
| 725 |  |  [WebNLG-IT: Construction of an aligned RDF-Italian corpus through Machine Translation techniques](https://aclanthology.org/2025.findings-acl.625/) |  | 0 | The main goal of this work is the creation of the Italian version of the WebNLG corpus through the application of Neural Machine Translation (NMT) and post-editing with hand-written rules. To achieve this goal, in a first step, several existing NMT models were analysed and compared in order to... | Michael Oliverio, Pier Felice Balestrucci, Alessandro Mazzei, Valerio Basile |  |
| 726 |  |  [Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation](https://aclanthology.org/2025.findings-acl.626/) |  | 0 | Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have demonstrated promising capabilities in clinical text summarization tasks. However, due to patient data privacy concerns and computational costs, many healthcare providers prefer using small, locally-hosted models over external... | Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Reddy Korsapati, Chuck Outcalt, Jimeng Sun |  |
| 727 |  |  [Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach](https://aclanthology.org/2025.findings-acl.627/) |  | 0 | Despite advancements in Natural Language Processing (NLP), models remain vulnerable to adversarial attacks, such as synonym substitutions. While prior work has focused on improving robustness for feed-forward and convolutional architectures, the robustness of recurrent networks and modern state... | Mohammed Bouri, Adnane Saoud |  |
| 728 |  |  [Neuro-Symbolic Query Compiler](https://aclanthology.org/2025.findings-acl.628/) |  | 0 | Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents \*\*QCompiler\*\*, a neuro-symbolic framework inspired by... | Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Ye Qi, JiRong Wen |  |
| 729 |  |  [Revealing and Mitigating the Local Pattern Shortcuts of Mamba](https://aclanthology.org/2025.findings-acl.629/) |  | 0 | Large language models (LLMs) have advanced significantly due to the attention mechanism, but their quadratic complexity and linear memory demands limit their performance on long-context tasks. Recently, researchers introduced Mamba, an advanced model built upon State Space Models (SSMs) that offers... | Wangjie You, Zecheng Tang, Juntao Li, Lili Yao, Min Zhang |  |
| 730 |  |  [Forget the Token and Pixel: Rethinking Gradient Ascent for Concept Unlearning in Multimodal Generative Models](https://aclanthology.org/2025.findings-acl.630/) |  | 0 | Gradient Ascent (GA) has emerged as a promising approach for concept unlearning in Multimodal Generative Models (MGMs), such as Multimodal Large Language Models (MLLMs) and Stable Diffusion Models (SDMs). Despite its effectiveness in removing undesired knowledge, GA leads to severe utility... | Jiaqi Li, Chuanyi Zhang, Miaozeng Du, Hui Zhang, Yongrui Chen, Qianshan Wei, Junfeng Fang, Ruipeng Wang, Sheng Bi, Guilin Qi |  |
| 731 |  |  [Slamming: Training a Speech Language Model on One GPU in a Day](https://aclanthology.org/2025.findings-acl.631/) |  | 0 | We introduce \*Slam\*, a recipe for training high-quality Speech Language Models (SLMs) on a single academic GPU in 24 hours. We do so through empirical analysis of model initialisation and architecture, synthetic training data, preference optimisation with synthetic data and tweaking all other... | Gallil Maimon, Avishai Elmakies, Yossi Adi |  |
| 732 |  |  [Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation](https://aclanthology.org/2025.findings-acl.632/) |  | 0 | Large Language Models (LLMs) have achieved impressive results across numerous NLP tasks, and fine-tuning them for Machine Translation (MT) has improved their performance. However, vanilla fine-tuning often leads to catastrophic forgetting, compromising the broad general abilities of LLMs and... | Junhong Wu, Yang Zhao, Yangyifan Xu, Bing Liu, Chengqing Zong |  |
| 733 |  |  [Clarifying Underspecified Discourse Relations in Instructional Texts](https://aclanthology.org/2025.findings-acl.633/) |  | 0 | Discourse relations contribute to the structure of a text and can optionally be realized through explicit connectives such as “but” and “while”. But when are these connectives necessary to avoid possible misunderstandings? We investigate this question by first building a corpus of 4,274 text... | Berfin Aktas, Michael Roth |  |
| 734 |  |  [WMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects](https://aclanthology.org/2025.findings-acl.634/) |  | 0 | As large language models (LLM) become more and more capable in languages other than English, it is important to collect benchmark datasets in order to evaluate their multilingual performance, including on tasks like machine translation (MT). In this work, we extend the WMT24 dataset to cover 55... | Daniel Deutsch, Eleftheria Briakou, Isaac Rayburn Caswell, Mara Finkelstein, Rebecca Galor, Juraj Juraska, Geza Kovacs, Alison Lui, Ricardo Rei, Jason Riesa, Shruti Rijhwani, Parker Riley, Elizabeth Salesky, Firas Trabelsi, Stephanie Winkler, Biao Zhang, Markus Freitag |  |
| 735 |  |  [Exploring Graph Representations of Logical Forms for Language Modeling](https://aclanthology.org/2025.findings-acl.635/) |  | 0 | We make the case for language models over logical forms (LFLMs), arguing that such models are more data-efficient than their textual counterparts. To that end, we introduce the ̲Graph-based ̲Formal- ̲Logical ̲Distributional ̲Semantics (GFoLDS) prototype, a pretrained LM over graph representations... | Michael Sullivan |  |
| 736 |  |  [SEA-HELM: Southeast Asian Holistic Evaluation of Language Models](https://aclanthology.org/2025.findings-acl.636/) |  | 0 | With the rapid emergence of novel capabilities in Large Language Models (LLMs), the need for rigorous multilingual and multiculturalbenchmarks that are integrated has become more pronounced. Though existing LLM benchmarks are capable of evaluating specificcapabilities of LLMs in English as well as... | Yosephine Susanto, Adithya Venkatadri Hulagadri, Jann Railey Montalan, Jian Gang Ngui, Xianbin Yong, Wei Qi Leong, Hamsawardhini Rengarajan, Peerat Limkonchotiwat, Yifan Mai, WilliamChandra Tjhi |  |
| 737 |  |  [TRANS-ZERO: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data](https://aclanthology.org/2025.findings-acl.637/) |  | 0 | The rise of Large Language Models (LLMs) has reshaped machine translation (MT), but multilingual MT still relies heavily on parallel data for supervised fine-tuning (SFT), facing challenges like data scarcity for low-resource languages and catastrophic forgetting. To address these issues, we... | Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng |  |
| 738 |  |  [A Conformal Risk Control Framework for Granular Word Assessment and Uncertainty Calibration of CLIPScore Quality Estimates](https://aclanthology.org/2025.findings-acl.638/) |  | 0 | This study explores current limitations of learned image captioning evaluation metrics, specifically the lack of granular assessments for errors within captions, and the reliance on single-point quality estimates without considering uncertainty. To address the limitations, we propose a simple yet... | Gonçalo Emanuel Cavaco Gomes, Bruno Martins, Chrysoula Zerva |  |
| 739 |  |  [SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment](https://aclanthology.org/2025.findings-acl.639/) |  | 0 | Direct Preference Optimization (DPO) is broadly utilized for aligning Large Language Models (LLMs) with human values because of its flexibility. Despite its effectiveness, it has been observed that the capability of DPO to generate human-preferred response is limited and the results of DPO are far... | Wenqiao Zhu, Ji Liu, Lulu Wang, Jun Wu, Yulun Zhang |  |
| 740 |  |  [Socratic Style Chain-of-Thoughts Help LLMs to be a Better Reasoner](https://aclanthology.org/2025.findings-acl.640/) |  | 0 | Synthetic data generation has emerged as a promising approach to enhance the reasoning capabilities of large language models. However, existing methods remain hindered by high costs—either through expensive API access or additional intermediate training—and are limited in their ability to... | Jiangbo Pei, Peiyu Liu, Xin Zhao, Aidong Men, Yang Liu |  |
| 741 |  |  [Quantile Regression with Large Language Models for Price Prediction](https://aclanthology.org/2025.findings-acl.641/) |  | 0 | Large Language Models (LLMs) have shown promise in structured prediction tasks, including regression, but existing approaches primarily focus on point estimates and lack systematic comparison across different methods.We investigate probabilistic regression using LLMs for unstructured inputs,... | Nikhita Vedula, Dushyanta Dhyani, Laleh Jalali, Boris N. Oreshkin, Mohsen Bayati, Shervin Malmasi |  |
| 742 |  |  [Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](https://aclanthology.org/2025.findings-acl.642/) |  | 0 | Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized knowledge in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To... | Jian Wang, Yinpei Dai, Yichi Zhang, Ziqiao Ma, Wenjie Li, Joyce Chai |  |
| 743 |  |  [AIGuard: A Benchmark and Lightweight Detection for E-commerce AIGC Risks](https://aclanthology.org/2025.findings-acl.643/) |  | 0 | Recent advancements in AI-generated content (AIGC) have heightened concerns about harmful outputs, such as misinformation and malicious misuse.Existing detection methods face two key limitations:(1) lacking real-world AIGC scenarios and corresponding risk datasets, and(2) both traditional and... | Wenhua Zhang, Weicheng Li, Xuanrong Rao, Lixin Zou, Xiangyang Luo, Chubin Zhuang, Yongjie Hong, Zhen Qin, Hengyun Chang, Chenliang Li, Bo Zheng |  |
| 744 |  |  [A²ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization](https://aclanthology.org/2025.findings-acl.644/) |  | 0 | Long context large language models (LLMs) pose significant challenges for efficient serving due to the large memory footprint and high access overhead of KV cache.Retrieval-based KV cache reduction methods can mitigate these challenges, typically by offloading the complete KV cache to CPU and... | Junhui He, Junna Xing, Nan Wang, Rui Xu, Shangyu Wu, Peng Zhou, Qiang Liu, Chun Jason Xue, Qingan Li |  |
| 745 |  |  [TransBench: Breaking Barriers for Transferable Graphical User Interface Agents in Dynamic Digital Environments](https://aclanthology.org/2025.findings-acl.645/) |  | 0 | Graphical User Interface (GUI) agents, which autonomously operate on digital interfaces through natural language instructions, hold transformative potential for accessibility, automation, and user experience. A critical aspect of their functionality is grounding — the ability to map linguistic... | Yuheng Lu, Qian Yu, Hongru Wang, Zeming Liu, Wei Su, Yanping Liu, Yuhang Guo, Maocheng Liang, Yunhong Wang, Haifeng Wang |  |
| 746 |  |  [Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following](https://aclanthology.org/2025.findings-acl.646/) |  | 0 | Real-world instructions with multiple constraints pose a significant challenge to existing large language models (LLMs). An observation is that the LLMs exhibit dramatic performance fluctuation when disturbing the order of the incorporated constraints. Yet, none of the existing works has... | Jie Zeng, Qianyu He, Qingyu Ren, Jiaqing Liang, Weikang Zhou, Zeye Sun, Fei Yu, Yanghua Xiao |  |
| 747 |  |  [CoT-VTM: Visual-to-Music Generation with Chain-of-Thought Reasoning](https://aclanthology.org/2025.findings-acl.647/) |  | 0 | The application of visual-to-music generation (VTM) is rapidly growing. However, current VTM methods struggle with capturing the relationship between visuals and music in open-domain settings, mainly due to two challenges: the lack of large-scale, high-quality visual-music paired datasets and the... | Xikang Guan, Zheng Gu, Jing Huo, Tianyu Ding, Yang Gao |  |
| 748 |  |  [A Tale of Evaluating Factual Consistency: Case Study on Long Document Summarization Evaluation](https://aclanthology.org/2025.findings-acl.648/) |  | 0 | Ensuring factual consistency in summarization remains a challenge, especially for long-document evaluation. While automated, reference-free evaluation models are essential given the impracticality of large-scale human assessment for lengthy texts, challenges persist in evaluating different systems... | Yang Zhong, Diane J. Litman |  |
| 749 |  |  [Evaluating Pretrained Causal Language Models for Synonymy](https://aclanthology.org/2025.findings-acl.649/) |  | 0 | The scaling of causal language models in size and training data enabled them to tackle increasingly complex tasks. Despite the development of sophisticated tests to reveal their new capabilities, the underlying basis of these complex skills remains unclear. We argue that complex skills might be... | Ioana Ivan, Carlos Ramisch, Alexis Nasr |  |
| 750 |  |  [MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models](https://aclanthology.org/2025.findings-acl.650/) |  | 0 | The widespread use of Large Multimodal Models (LMMs) has raised concerns about model toxicity. However, current research mainly focuses on explicit toxicity, with less attention to some more implicit toxicity regarding prejudice and discrimination. To address this limitation, we introduce a subtler... | Bohan Jin, Shuhan Qi, Kehai Chen, Xinyi Guo, Xuan Wang |  |
| 751 |  |  [CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems](https://aclanthology.org/2025.findings-acl.651/) |  | 0 | Recommender systems play a pivotal role in providing relevant content to users. With the rapid development of large language models (LLMs), researchers have begun utilizing LLMs to build more powerful recommender systems. However, existing approaches that focus on aligning LLMs with recommendation... | Haochen Zhang, Tianyi Zhang, Junze Yin, Oren Gal, Anshumali Shrivastava, Vladimir Braverman |  |
| 752 |  |  [CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control](https://aclanthology.org/2025.findings-acl.652/) |  | 0 | Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved external knowledge. Adaptive RAG enhances this approach by enabling dynamic retrieval during generation, activating retrieval only when the query... | Huanshuo Liu, Hao Zhang, Zhijiang Guo, Jing Wang, Kuicai Dong, Xiangyang Li, Yi Quan Lee, Cong Zhang, Yong Liu |  |
| 753 |  |  [Maximum Score Routing For Mixture-of-Experts](https://aclanthology.org/2025.findings-acl.653/) |  | 0 | Routing networks in sparsely activated mixture-of-experts (MoE) dynamically allocate input tokens to top-k experts through differentiable sparse transformations, enabling scalable model capacity while preserving computational efficiency. Traditional MoE networks impose an expert capacity constraint... | Bowen Dong, Yilong Fan, Yutao Sun, Zhenyu Li, Tengyu Pan, Zhou Xun, Jianyong Wang |  |
| 754 |  |  [Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models](https://aclanthology.org/2025.findings-acl.654/) |  | 0 | Understanding how large language models (LLMs) acquire and store factual knowledge is crucial for enhancing their interpretability, reliability, and efficiency. In this work, we analyze the evolution of factual knowledge representation in the OLMo-7B model by tracking the roles of its Attention... | Ahmad Dawar Hakimi, Ali Modarressi, Philipp Wicke, Hinrich Schütze |  |
| 755 |  |  [Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding](https://aclanthology.org/2025.findings-acl.655/) |  | 0 | Large Language Models (LLMs) require alignment with human preferences to avoid generating offensive, false, or meaningless content. Recently, low-resource methods for LLM alignment have been popular, while still facing challenges in obtaining both high-quality and aligned content. Motivated by the... | Feifan Song, Shaohang Wei, Wen Luo, Yuxuan Fan, Tianyu Liu, Guoyin Wang, Houfeng Wang |  |
| 756 |  |  [Disentangling Text and Math in Word Problems: Evidence for the Bidimensional Structure of Large Language Models' Reasoning](https://aclanthology.org/2025.findings-acl.656/) |  | 0 | Do LLMs process text and mathematics as a unified skill, or do these components rely on distinct underlying mechanisms? We investigate this question by disentangling the textual interpretation and mathematical solving steps in word problems drawn from Brazil’s largest college entrance exam (ENEM)... | Pedro Calais, Gabriel Franco, Zilu Tang, Themistoklis Nikas, Wagner Meira Jr., Evimaria Terzi, Mark Crovella |  |
| 757 |  |  [Human-LLM Coevolution: Evidence from Academic Writing](https://aclanthology.org/2025.findings-acl.657/) |  | 0 | With a statistical analysis of arXiv paper abstracts, we report a marked drop in the frequency of several words previously identified as overused by ChatGPT, such as “delve”, starting soon after they were pointed out in early 2024. The frequency of certain other words favored by ChatGPT, such as... | Mingmeng Geng, Roberto Trotta |  |
| 758 |  |  [Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning](https://aclanthology.org/2025.findings-acl.658/) |  | 0 | Temporal Knowledge Graphs (TKGs) incorporate the temporal feature to express the transience of knowledge by describing when facts occur. TKG extrapolation aims to infer possible future facts based on known history, which has garnered significant attention in recent years. Some existing methods... | Hao Dong, Ziyue Qiao, Zhiyuan Ning, Qi Hao, Yi Du, Pengyang Wang, Yuanchun Zhou |  |
| 759 |  |  [GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering](https://aclanthology.org/2025.findings-acl.659/) |  | 0 | Pre-trained language models have shown remarkable performance in recent years, setting a new paradigm for natural language processing (NLP) research. The legal domain has received some attention from the NLP community, in part due to its textual nature. Question answering (QA) systems represent... | CristianGeorge Craciun, RazvanAlexandru Smadu, DumitruClementin Cercel, MihaelaClaudia Cercel |  |
| 760 |  |  [Express What You See: Can Multimodal LLMs Decode Visual Ciphers with Intuitive Semiosis Comprehension?](https://aclanthology.org/2025.findings-acl.660/) |  | 0 | Bridging the gap between visual and language remains a pivotal challenge for the multimodal community. Traditional VQA benchmarks encounter a modality gap and over-reliance on language priors, whereas human cognition excels at intuitive semiosis, associating abstract visual symbols to linguistic... | Jiayi Kuang, Yinghui Li, Chen Wang, Haohao Luo, Ying Shen, Wenhao Jiang |  |
| 761 |  |  [ConFit v2: Improving Resume-Job Matching using Hypothetical Resume Embedding and Runner-Up Hard-Negative Mining](https://aclanthology.org/2025.findings-acl.661/) |  | 0 | A reliable resume-job matching system helps a company recommend suitable candidates from a pool of resumes and helps a job seeker find relevant jobs from a list of job posts. However, since job seekers apply only to a few jobs, interaction labels in resume-job datasets are sparse. We introduce... | Xiao Yu, Ruize Xu, Chengyuan Xue, Jinzhong Zhang, Xu Ma, Zhou Yu |  |
| 762 |  |  [Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion](https://aclanthology.org/2025.findings-acl.662/) |  | 0 | We investigate whether the success of a zero-shot Chain-of-Thought (CoT) process can be predicted before completion. Our classifier, based on LLM representations, performs well even before a single token is generated, suggesting that crucial information about the reasoning process is already... | Anum Afzal, Florian Matthes, Gal Chechik, Yftah Ziser |  |
| 763 |  |  [Grounding Task Assistance with Multimodal Cues from a Single Demonstration](https://aclanthology.org/2025.findings-acl.663/) |  | 0 | A person’s demonstration often serves as a key reference for others learning the same task. However, RGB video, the dominant medium for representing these demonstrations, often fails to capture fine-grained contextual cues such as intent, safety-critical environmental factors, and subtle... | Gabriel Herbert Sarch, Balasaravanan Thoravi Kumaravel, Sahithya Ravi, Vibhav Vineet, Andrew D. Wilson |  |
| 764 |  |  [Awes, Laws, and Flaws From Today's LLM Research](https://aclanthology.org/2025.findings-acl.664/) |  | 0 | We perform a critical examination of the scientific methodology behind contemporary large language model (LLM) research. For this we assess over 2,000 research works released between 2020 and 2024 based on criteria typical of what is considered good research (e.g. presence of statistical tests and... | Adrian de Wynter |  |
| 765 |  |  [Dual Debiasing for Noisy In-Context Learning for Text Generation](https://aclanthology.org/2025.findings-acl.665/) |  | 0 | In-context learning (ICL) relies heavily on high-quality demonstrations drawn from large annotated corpora. Existing approaches detect noisy annotations by ranking local perplexities, presuming that noisy samples yield higher perplexities than their clean counterparts. However, this assumption... | Siqi Liang, Sumyeong Ahn, Paramveer Dhillon, Jiayu Zhou |  |
| 766 |  |  [DRS: Deep Question Reformulation With Structured Output](https://aclanthology.org/2025.findings-acl.666/) |  | 0 | Question answering represents a core capability of large language models (LLMs). However, when individuals encounter unfamiliar knowledge in texts, they often formulate questions that the text itself cannot answer due to insufficient understanding of the underlying information. Recent studies... | Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kaiwei Chang |  |
| 767 |  |  [Towards Explainable Hate Speech Detection](https://aclanthology.org/2025.findings-acl.667/) |  | 0 | Recent advancements in deep learning have significantly enhanced the efficiency and accuracy of natural language processing (NLP) tasks. However, these models often require substantial computational resources, which remains a major drawback. Reducing the complexity of deep learning architectures,... | Happy Khairunnisa Sariyanto, Diclehan Ulucan, Oguzhan Ulucan, Marc Ebner |  |
| 768 |  |  [BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain](https://aclanthology.org/2025.findings-acl.668/) |  | 0 | Biomedical reasoning often requires traversing interconnected relationships across entities such as drugs, diseases, and proteins. Despite the increasing prominence of large language models (LLMs), existing benchmarks lack the ability to evaluate multi-hop reasoning in the biomedical domain,... | Yunsoo Kim, Yusuf Abdulle, Honghan Wu |  |
| 769 |  |  [PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding](https://aclanthology.org/2025.findings-acl.669/) |  | 0 | Speculative decoding accelerates large language model inference by using smaller draft models to generate candidate tokens for parallel verification. However, current approaches are limited by sequential stage dependencies that prevent full hardware utilization. We present PipeSpec, a framework... | Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu |  |
| 770 |  |  [LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback](https://aclanthology.org/2025.findings-acl.670/) |  | 0 | Large Action Models (LAMs) for AI Agents offer incredible potential but face challenges due to the need for high-quality training data, especially for multi-steps tasks that involve planning, executing tool calls, and responding to feedback. To address these issues, we present LAM SIMULATOR, a... | Thai Quoc Hoang, KungHsiang Huang, Shirley Kokane, Jianguo Zhang, Zuxin Liu, Ming Zhu, Jake Grigsby, Tian Lan, Michael S. Ryoo, ChienSheng Wu, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles |  |
| 771 |  |  [Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion](https://aclanthology.org/2025.findings-acl.671/) |  | 0 | Taxonomies are hierarchical knowledge graphs crucial for recommendation systems, and web applications. As data grows, expanding taxonomies is essential, but existing methods face key challenges: (1) discriminative models struggle with representation limits and generalization, while (2) generative... | Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty |  |
| 772 |  |  [Probing Subphonemes in Morphology Models](https://aclanthology.org/2025.findings-acl.672/) |  | 0 | Transformers have achieved state-of-the-art performance in morphological inflection tasks, yet their ability to generalize across languages and morphological rules remains limited. One possible explanation for this behavior can be the degree to which these models are able to capture implicit... | Gal Astrach, Yuval Pinter |  |
| 773 |  |  [Exploiting Instruction-Following Retrievers for Malicious Information Retrieval](https://aclanthology.org/2025.findings-acl.673/) |  | 0 | Instruction-following retrievers have been widely adopted alongside LLMs in real-world applications, but little work has investigated the safety risks surrounding their increasing search capabilities. We empirically study the ability of retrievers to satisfy malicious queries, both when used... | Parishad BehnamGhader, Nicholas Meade, Siva Reddy |  |
| 774 |  |  [Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE](https://aclanthology.org/2025.findings-acl.674/) |  | 0 | Amnesic probing is a technique used to examine the influence of specific linguistic information on the behaviour of a model. This involves identifying and removing the relevant information and then assessing whether the model’s performance on the main task changes. If the removed information is... | Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer |  |
| 775 |  |  [The Threat of PROMPTS in Large Language Models: A System and User Prompt Perspective](https://aclanthology.org/2025.findings-acl.675/) |  | 0 | Prompts, especially high-quality ones, play an invaluable role in assisting large language models (LLMs) to accomplish various natural language processing tasks. However, carefully crafted prompts can also manipulate model behavior. Therefore, the security risks that “prompts themselves face” and... | Zixuan Xia, Haifeng Sun, Jingyu Wang, Qi Qi, Huazheng Wang, Xiaoyuan Fu, Jianxin Liao |  |
| 776 |  |  [RoseRAG: Robust Retrieval-augmented Generation with Small-scale LLMs via Margin-aware Preference Optimization](https://aclanthology.org/2025.findings-acl.676/) |  | 0 | Large language models (LLMs) have achieved impressive performance but face high computational costs and latency, limiting their deployment in resource-constrained settings. In contrast, small-scale LLMs (SLMs) are more efficient yet struggle to capture evolving real-world knowledge.... | Tianci Liu, Haoxiang Jiang, Tianze Wang, Ran Xu, Yue Yu, Linjun Zhang, Tuo Zhao, Haoyu Wang |  |
| 777 |  |  [Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines](https://aclanthology.org/2025.findings-acl.677/) |  | 0 | In this work, we study the effect of annotation guidelines–textual descriptions of event types and arguments, when instruction-tuning large language models for event extraction. We conducted a series of experiments with both human-provided and machine-generated guidelines in both full- and low-data... | Saurabh Srivastava, Sweta Pati, Ziyu Yao |  |
| 778 |  |  [mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages](https://aclanthology.org/2025.findings-acl.678/) |  | 0 | Knowledge Graphs represent real-world entities and the relationships between them. Multilingual Knowledge Graph Construction (mKGC) refers to the task of automatically constructing or predicting missing entities and links for knowledge graphs in a multilingual setting. In this work, we reformulate... | Hellina Hailu Nigatu, Min Li, Maartje ter Hoeve, Saloni Potdar, Sarah E. Chasins |  |
| 779 |  |  [Mechanistic Interpretability of Emotion Inference in Large Language Models](https://aclanthology.org/2025.findings-acl.679/) |  | 0 | Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that... | Ala N. Tak, Amin Banayeeanzade, Anahita Bolourani, Mina Kian, Robin Jia, Jonathan Gratch |  |
| 780 |  |  [RL-Guider: Leveraging Historical Decisions and Feedback for Drug Editing with Large Language Models](https://aclanthology.org/2025.findings-acl.680/) |  | 0 | Recent success of large language models (LLMs) in diverse domains showcases their potential to revolutionize scientific fields, including drug editing. Traditional drug editing relies on iterative conversations with domain experts, refining the drug until the desired property is achieved. This... | Xufeng Liu, Yixuan Ding, Jingxiang Qu, Yichi Zhang, Wenhan Gao, Yi Liu |  |
| 781 |  |  [BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs](https://aclanthology.org/2025.findings-acl.681/) |  | 0 | A core part of legal work that has been underexplored in Legal NLP is the writing and editing of legal briefs. This requires not only a thorough understanding of the law of a jurisdiction, from judgments to statutes, but also the ability to make new arguments to try to expand the law in a new... | Jesse Woo, Fateme Hashemi Chaleshtori, Ana Marasovic, Kenneth Marino |  |
| 782 |  |  [I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue](https://aclanthology.org/2025.findings-acl.682/) |  | 0 | In face-to-face interaction, we use multiple modalities, including speech and gestures, to communicate information and resolve references to objects. However, how representational co-speech gestures refer to objects remains understudied from a computational perspective. In this work, we address... | Esam Ghaleb, Bulat Khaertdinov, Asli Özyürek, Raquel Fernández |  |
| 783 |  |  [World Knowledge Resolves Some Aspectual Ambiguity](https://aclanthology.org/2025.findings-acl.683/) |  | 0 | Annotating event descriptions with their aspectual features is often seen as a pre-requisite to temporal reasoning. However, a recent study by Pruś et al. (2024) has shown that non-experts’ annotations of the aspectual class of English verb phrases can disagree with both expert linguistic... | Katarzyna Prus, Mark Steedman, Adam Lopez |  |
| 784 |  |  [ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness](https://aclanthology.org/2025.findings-acl.684/) |  | 0 | Large language models (LLMs) are increasingly becoming valuable to corporate data management due to their ability to process text from various document formats and facilitate user interactions through natural language queries. However, LLMs must consider the sensitivity of information when... | Dren Fazlija, Arkadij Orlov, Sandipan Sikdar |  |
| 785 |  |  [Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis](https://aclanthology.org/2025.findings-acl.685/) |  | 0 | Image mass cytometry (IMC) enables high-dimensional spatial profiling by combining mass cytometry’s analytical power with spatial distributions of cell phenotypes. Recent studies leverage large language models (LLMs) to extract cell states by translating gene or protein expression into biological... | ChiJane Chen, Yuhang Chen, Sukwon Yun, Natalie Stanley, Tianlong Chen |  |
| 786 |  |  [HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation Task](https://aclanthology.org/2025.findings-acl.686/) |  | 0 | In this paper, we present HumanEval Pro and MBPP Pro, a series of benchmarks to evaluate LLMs on self-invoking code generation task. This task involves providing LLMs with a base problem alongside a related, more complex problem. The models must solve the base problem and leverage its solution to... | Zhaojian Yu, Yilun Zhao, Arman Cohan, Xiaoping Zhang |  |
| 787 |  |  [TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis](https://aclanthology.org/2025.findings-acl.687/) |  | 0 | Customizable multilingual zero-shot singing voice synthesis (SVS) has various potential applications in music composition and short video dubbing. However, existing SVS models overly depend on phoneme and note boundary annotations, limiting their robustness in zero-shot scenarios and producing poor... | Yu Zhang, Wenxiang Guo, Changhao Pan, Dongyu Yao, Zhiyuan Zhu, Ziyue Jiang, Yuhan Wang, Tao Jin, Zhou Zhao |  |
| 788 |  |  [Compute Optimal Scaling of Skills: Knowledge vs Reasoning](https://aclanthology.org/2025.findings-acl.688/) |  | 0 | Scaling laws are a critical component of the LLM development pipeline, most famously as a way to forecast training decisions such as ‘compute-optimally’ trading-off parameter count and dataset size, alongside a more recent growing list of other crucial decisions. In this work, we ask whether... | Nicholas Roberts, Niladri S. Chatterji, Sharan Narang, Mike Lewis, Dieuwke Hupkes |  |
| 789 |  |  [PECAN: LLM-Guided Dynamic Progress Control with Attention-Guided Hierarchical Weighted Graph for Long-Document QA](https://aclanthology.org/2025.findings-acl.689/) |  | 0 | Long-document QA presents challenges with large-scale text and long-distance dependencies. Recent advances in Large Language Models (LLMs) enable entire documents to be processed in a single pass. However, their computational cost is significantly high. Retrieval-Augmented Generation (RAG) methods... | Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He |  |
| 790 |  |  [Lifelong Model Editing with Graph-Based External Memory](https://aclanthology.org/2025.findings-acl.690/) |  | 0 | Large language models (LLMs) have revolutionized natural language processing, yet their practical utility is often limited by persistent issues of hallucinations and outdated parametric knowledge. Although post-training model editing offers a pathway for dynamic updates, existing methods frequently... | Yash Kumar Atri, Ahmed M. Alaa, Thomas Hartvigsen |  |
| 791 |  |  [Multi-Sense Embeddings for Language Models and Knowledge Distillation](https://aclanthology.org/2025.findings-acl.691/) |  | 0 | Transformer-based large language models (LLMs) rely on contextual embeddings which generate different (continuous) representations for the same token depending on its surrounding context. Nonetheless, words and tokens typically have a limited number of senses (or meanings). We propose multi-sense... | Qitong Wang, Mohammed J. Zaki, Georgios Kollias, Vasileios Kalantzis |  |
| 792 |  |  [CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation](https://aclanthology.org/2025.findings-acl.692/) |  | 0 | Despite the surge of interest in autonomous scientific discovery (ASD) of software artifacts (e.g., improved ML algorithms), current ASD systems face two key limitations: (1) they largely explore variants of existing codebases or similarly constrained design spaces, and (2) they produce large... | Peter Jansen, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S. Weld, Peter Clark |  |
| 793 |  |  [Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation](https://aclanthology.org/2025.findings-acl.693/) |  | 0 | This paper presents ICAT, an evaluation framework for measuring coverage of diverse factual information in long-form text generation. ICAT breaks down a long output text into a list of atomic claims and not only verifies each claim through retrieval from a (reliable) knowledge source, but also... | Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani |  |
| 794 |  |  [Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?](https://aclanthology.org/2025.findings-acl.694/) |  | 0 | Large language models (LLMs) require immense resources for training and inference. Quantization, a technique that reduces the precision of model parameters, offers a promising solution for improving LLM efficiency and sustainability. While post-training quantization methods typically achieve 4-8... | Jacob Nielsen, Peter SchneiderKamp, Lukas Galke |  |
| 795 |  |  [When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](https://aclanthology.org/2025.findings-acl.695/) |  | 0 | Detecting AI-generated text is a difficult problem to begin with; detecting AI-generated text on social media is made even more difficult due to the short text length and informal, idiosyncratic language of the internet. It is nonetheless important to tackle this problem, as social media represents... | Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko |  |
| 796 |  |  [Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events](https://aclanthology.org/2025.findings-acl.696/) |  | 0 | Can language models reliably predict that possible events are more likely than merely improbable ones? By teasing apart possibility, typicality, and contextual relatedness, we show that despite the results of previous work, language models’ ability to do this is far from robust. In fact, under... | James A. Michaelov, Reeka Estacio, Zhien Zhang, Ben Bergen |  |
| 797 |  |  [The Rotary Position Embedding May Cause Dimension Inefficiency in Attention Heads for Long-Distance Retrieval](https://aclanthology.org/2025.findings-acl.697/) |  | 0 | The Rotary Position Embedding (RoPE) is widely used in the attention heads of many large language models (LLM). It rotates dimensions in the query and the key vectors by different angles according to their positions in the input sequence. For long context modeling, the range of positions may vary a... | TingRui Chiang, Dani Yogatama |  |
| 798 |  |  [IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction](https://aclanthology.org/2025.findings-acl.698/) |  | 0 | While large language models (LLMs) have been thoroughly evaluated for deductive and inductive reasoning, their proficiency in holistic rule learning in interactive environments remains less explored. We introduce RULEARN, a novel benchmark to assess the rule-learning abilities of LLM agents in... | Kaiyu He, Mian Zhang, Shuo Yan, Peilin Wu, Zhiyu Chen |  |
| 799 |  |  [EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States](https://aclanthology.org/2025.findings-acl.699/) |  | 0 | Theory-of-Mind (ToM), the ability to infer others’ perceptions and mental states, is fundamental to human interaction but remains challenging for Large Language Models (LLMs). While existing ToM reasoning methods show promise with reasoning via perceptual perspective-taking, they often rely... | Hainiu Xu, Siya Qi, Jiazheng Li, Yuxiang Zhou, Jinhua Du, Caroline Catmur, Yulan He |  |
| 800 |  |  [ReasonerRank: Redefining Language Model Evaluation with Ground-Truth-Free Ranking Frameworks](https://aclanthology.org/2025.findings-acl.700/) |  | 0 | Large Language Models (LLMs) are increasingly adopted across real-world applications, yet traditional evaluations rely on expensive, domain-specific ground-truth labels that are often unavailable or infeasible. We introduce a ground-truth-free evaluation framework focused on reasoning consistency... | Jiamu Zhang, Jiayi Yuan, Andrew Wen, Hoang Anh Duy Le, YuNeng Chuang, SooHyun Choi, Rui Chen, Xia Hu |  |
| 801 |  |  [HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation](https://aclanthology.org/2025.findings-acl.701/) |  | 0 | Grammar plays a critical role in natural language processing and text/code generation by enabling the definition of syntax, the creation of parsers, and guiding structured outputs. Although large language models (LLMs) demonstrate impressive capabilities across domains, their ability to infer and... | Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle |  |
| 802 |  |  [Can Large Language Models Understand Argument Schemes?](https://aclanthology.org/2025.findings-acl.702/) |  | 0 | Argument schemes represent stereotypical patterns of reasoning that occur in everyday arguments. However, despite their usefulness, argument scheme classification, that is classifying natural language arguments according to the schemes they are instances of, is an under-explored task in NLP. In... | Elfia BezouVrakatseli, Oana Cocarascu, Sanjay Modgil |  |
| 803 |  |  [MMInA: Benchmarking Multihop Multimodal Internet Agents](https://aclanthology.org/2025.findings-acl.703/) |  | 0 | Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present... | Shulin Tian, Ziniu Zhang, Liangyu Chen, Ziwei Liu |  |
| 804 |  |  [ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails](https://aclanthology.org/2025.findings-acl.704/) |  | 0 | Ensuring the safety of large language models (LLMs) is critical as they are deployed in real-world applications. Existing guardrails rely on rule-based filtering or single-pass classification, limiting their ability to handle nuanced safety violations. To address this, we propose ThinkGuard, a... | Xiaofei Wen, Wenxuan Zhou, Wenjie Jacky Mo, Muhao Chen |  |
| 805 |  |  [Neutralizing Bias in LLM Reasoning using Entailment Graphs](https://aclanthology.org/2025.findings-acl.705/) |  | 0 | LLMs are often claimed to be capable of Natural Language Inference (NLI), which is widely regarded as a cornerstone of more complex forms of reasoning. However, recent works show that LLMs still suffer from hallucinations in NLI due to attestation bias, where LLMs overly rely on propositional... | Liang Cheng, Tianyi Li, Zhaowei Wang, Tianyang Liu, Mark Steedman |  |
| 806 |  |  [Dynamic Steering With Episodic Memory For Large Language Models](https://aclanthology.org/2025.findings-acl.706/) |  | 0 | Large Language Models (LLMs) exhibit emergent in-context learning (ICL) capabilities, allowing them to adapt to unseen tasks based on example demonstrations. Traditional ICL embeds examples within the prompt, while activation steering, uses a vector derived from examples to guide the latent states... | Van Dai Do, Quan Hung Tran, Svetha Venkatesh, Hung Le |  |
| 807 |  |  [Eeyore: Realistic Depression Simulation via Expert-in-the-Loop Supervised and Preference Optimization](https://aclanthology.org/2025.findings-acl.707/) |  | 0 | Large Language Models (LLMs) have been previously explored for mental healthcare training and therapy client simulation, but they still fall short in authentically capturing diverse client traits and psychological conditions. We introduce Eeyore , an 8B model optimized for realistic depression... | Siyang Liu, Bianca Brie, Wenda Li, Laura Biester, Andrew Lee, James W. Pennebaker, Rada Mihalcea |  |
| 808 |  |  [Lost in Translation: Benchmarking Commercial Machine Translation Models for Dyslexic-Style Text](https://aclanthology.org/2025.findings-acl.708/) |  | 0 | Dyslexia can affect writing, leading to unique patterns such as letter and homophone swapping. As a result, text produced by people with dyslexia often differs from the text typically used to train natural language processing (NLP) models, raising concerns about their effectiveness for dyslexic... | Gregory Price, Shaomei Wu |  |
| 809 |  |  [Divide-Verify-Refine: Can LLMs Self-align with Complex Instructions?](https://aclanthology.org/2025.findings-acl.709/) |  | 0 | Recent studies show LLMs struggle with complex instructions involving multiple constraints (e.g., length, format, sentiment). Existing research enhances open-source LLMs using closed-source guidance (e.g., GPT-4), but this heavily relies on generated data quality. An alternative is leveraging LLMs’... | Xianren Zhang, Xianfeng Tang, Hui Liu, Zongyu Wu, Qi He, Dongwon Lee, Suhang Wang |  |
| 810 |  |  [LlamaPIE: Proactive In-Ear Conversation Assistants](https://aclanthology.org/2025.findings-acl.710/) |  | 0 | We introduce LlamaPIE, the first real-time proactive assistant designed to enhance human conversations through discreet, concise guidance delivered via hearable devices. Unlike traditional language models that require explicit user invocation, this assistant operates in the background, anticipating... | Tuochao Chen, Nicholas Scott Batchelder, Alisa Liu, Noah A. Smith, Shyamnath Gollakota |  |
| 811 |  |  [Task-Oriented Automatic Fact-Checking with Frame-Semantics](https://aclanthology.org/2025.findings-acl.711/) |  | 0 | We propose a novel paradigm for automatic fact-checking that leverages frame semantics to enhance the structured understanding of claims and guide the process of fact-checking them. To support this, we introduce a pilot dataset of real-world claims extracted from PolitiFact, specifically annotated... | Jacob Daniel Devasier, Akshith Reddy Putta, Rishabh Mediratta, Chengkai Li |  |
| 812 |  |  [Craw4LLM: Efficient Web Crawling for LLM Pretraining](https://aclanthology.org/2025.findings-acl.712/) |  | 0 | Web crawl is a main source of large language models’ (LLMs) pretraining data, but the majority of crawled web pages are discarded in pretraining due to low data quality. This paper presents Craw4LLM, an efficient web crawling method that explores the web graph based on the preference of LLM... | Shi Yu, Zhiyuan Liu, Chenyan Xiong |  |
| 813 |  |  [Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy](https://aclanthology.org/2025.findings-acl.713/) |  | 0 | Model merging is a widespread technology in large language models (LLMs) that integrates multiple task-specific LLMs into a unified one, enabling the merged model to inherit the specialized capabilities of these LLMs. Most task-specific LLMs are sourced from open-source communities and have not... | Zhenyuan Guo, Yi Shi, Wenlong Meng, Chen Gong, Chengkun Wei, Wenzhi Chen |  |
| 814 |  |  [Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews](https://aclanthology.org/2025.findings-acl.714/) |  | 0 | Which large language model (LLM) is better? Every evaluation tells a story, but what do users really think about current LLMs? This paper presents CLUE, an LLM-powered interviewer that conducts in-the-moment user experience interviews, right after users interact with LLMs, and automatically gathers... | Mengqiao Liu, Tevin Wang, Cassandra A. Cohen, Sarah Li, Chenyan Xiong |  |
| 815 |  |  [HiCOT: Improving Neural Topic Models via Optimal Transport and Contrastive Learning](https://aclanthology.org/2025.findings-acl.715/) |  | 0 | Recent advances in neural topic models (NTMs) have improved topic quality but still face challenges: weak document-topic alignment, high inference costs due to large pretrained language models (PLMs), and limited modeling of hierarchical topic structures. To address these issues, we introduce HiCOT... | Hoang Tran Vuong, Tue Le, Tu Vu, Tung Nguyen, Linh Ngo Van, Sang Dinh, Thien Huu Nguyen |  |
| 816 |  |  [FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading](https://aclanthology.org/2025.findings-acl.716/) |  | 0 | Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic... | Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, Mingquan Lin, Kaleb E. Smith, XiaoYang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie |  |
| 817 |  |  [The Silent Saboteur: Imperceptible Adversarial Attacks against Black-Box Retrieval-Augmented Generation Systems](https://aclanthology.org/2025.findings-acl.717/) |  | 0 | We explore adversarial attacks against retrieval-augmented generation (RAG) systems to identify their vulnerabilities. We focus on generating human-imperceptible adversarial examples and introduce a novel imperceptible retrieve-to-generate attack against RAG. This task aims to find imperceptible... | Hongru Song, YuAn Liu, Ruqing Zhang, Jiafeng Guo, Jianming Lv, Maarten de Rijke, Xueqi Cheng |  |
| 818 |  |  [CROSSAGENTIE: Cross-Type and Cross-Task Multi-Agent LLM Collaboration for Zero-Shot Information Extraction](https://aclanthology.org/2025.findings-acl.718/) |  | 0 | Large language models (LLMs) excel in generating unstructured text. However, they struggle with producing structured output while maintaining accuracy in zero-shot information extraction (IE), such as named entity recognition (NER) and relation extraction (RE). To address these challenges, we... | Meng Lu, Yuzhang Xie, Zhenyu Bi, Shuxiang Cao, Xuan Wang |  |
| 819 |  |  [Decoupling Memories, Muting Neurons: Towards Practical Machine Unlearning for Large Language Models](https://aclanthology.org/2025.findings-acl.719/) |  | 0 | Machine Unlearning (MU) has emerged as a promising solution for removing the influence of data that an owner wishes to unlearn from Large Language Models (LLMs). However, existing MU methods, which require tuning the entire model parameters on the unlearned data with random labels or perturbed... | Lishuai Hou, Zixiong Wang, Gaoyang Liu, Chen Wang, Wei Liu, Kai Peng |  |
| 820 |  |  [Assimilation and Accommodation: Task-Adaptive Hierarchical Abstraction for Solving Web Tasks](https://aclanthology.org/2025.findings-acl.720/) |  | 0 | Web tasks, which involve processing data from online resources, challenge agents to generalize beyond fixed knowledge to unseen task contexts. Learning from experience, the ability to derive reusable patterns from past tasks, is crucial for improving generalization. However, existing methods focus... | Xinyu Pang, Ruixin Hong, Hongming Zhang, Changshui Zhang |  |
| 821 |  |  [SafeLawBench: Towards Safe Alignment of Large Language Models](https://aclanthology.org/2025.findings-acl.721/) |  | 0 | With the growing prevalence of large language models (LLMs), the safety of LLMs has raised significant concerns. However, there is still a lack of definitive standards for evaluating their safety due to the subjective nature of current safety benchmarks. To address this gap, we conducted the first... | Chuxue Cao, Han Zhu, Jiaming Ji, Qichao Sun, Zhenghao Zhu, Yinyu Wu, Josef Dai, Yaodong Yang, Sirui Han, Yike Guo |  |
| 822 |  |  [3DM: Distill, Dynamic Drop, and Merge for Debiasing Multi-modal Large Language Models](https://aclanthology.org/2025.findings-acl.722/) |  | 0 | The rapid advancement of Multi-modal Language Models (MLLMs) has significantly enhanced performance in multimodal tasks, yet these models often exhibit inherent biases that compromise their reliability and fairness. Traditional debiasing methods face a trade-off between the need for extensive... | Zhaoxi Zhang, Sanwoo Lee, Zhixiang Wang, Yunfang Wu |  |
| 823 |  |  [CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention](https://aclanthology.org/2025.findings-acl.723/) |  | 0 | Large Language Models (LLMs) often exhibit knowledge disparities across languages. Encouraging LLMs to abstain when faced with knowledge gaps is a promising strategy to reduce hallucinations in multilingual settings. Current abstention strategies for multilingual scenarios primarily rely on... | Yuxi Sun, Aoqi Zuo, Wei Gao, Jing Ma |  |
| 824 |  |  [CapArena: Benchmarking and Analyzing Detailed Image Captioning in the LLM Era](https://aclanthology.org/2025.findings-acl.724/) |  | 0 | Image captioning has been a longstanding challenge in vision-language research. With the rise of LLMs, modern Vision-Language Models (VLMs) generate detailed and comprehensive image descriptions. However, benchmarking the quality of such captions remains unresolved. This paper addresses two key... | Kanzhi Cheng, Wenpo Song, Jiaxin Fan, Zheng Ma, Qiushi Sun, Fangzhi Xu, Chenyang Yan, Nuo Chen, Jianbing Zhang, Jiajun Chen |  |
| 825 |  |  [LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection](https://aclanthology.org/2025.findings-acl.725/) |  | 0 | As the market for illicit drugs remains extremely profitable, major online platforms have become direct-to-consumer intermediaries for illicit drug trafficking participants. These online activities raise significant social concerns that require immediate actions. Existing approaches to combat this... | Tianyi Ma, Yiyue Qian, Zehong Wang, Zheyuan Zhang, Chuxu Zhang, Yanfang Ye |  |
| 826 |  |  [CoLA: Collaborative Low-Rank Adaptation](https://aclanthology.org/2025.findings-acl.726/) |  | 0 | The scaling law of Large Language Models (LLMs) reveals a power-law relationship, showing diminishing return on performance as model scale increases. While training LLMs from scratch is resource-intensive, fine-tuning a pre-trained model for specific tasks has become a practical alternative. Full... | Yiyun Zhou, Chang Yao, Jingyuan Chen |  |
| 827 |  |  [GLiM: Integrating Graph Transformer and LLM for Document-Level Biomedical Relation Extraction with Incomplete Labeling](https://aclanthology.org/2025.findings-acl.727/) |  | 0 | Document-level relation extraction (DocRE) identifies relations between entities across an entire document. However, as the number and complexity of entities and entity-pair relations grow, the problem space expands quadratically, causing incomplete annotations and frequent false negatives,... | Hao Fang, Yuejie Zhang, Rui Feng, Yingwen Wang, Qing Wang, Wen He, Xiaobo Zhang, Tao Zhang, Shang Gao |  |
| 828 |  |  [AnalyticKWS: Towards Exemplar-Free Analytic Class Incremental Learning for Small-footprint Keyword Spotting](https://aclanthology.org/2025.findings-acl.728/) |  | 0 | Keyword spotting (KWS) offers a vital mechanism to identify spoken commands in voice-enabled systems, where user demands often shift, requiring models to learn new keywords continually over time. However, a major problem is catastrophic forgetting, where models lose their ability to recognize... | Yang Xiao, Tianyi Peng, Rohan Kumar Das, Yuchen Hu, Huiping Zhuang |  |
| 829 |  |  [Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions](https://aclanthology.org/2025.findings-acl.729/) |  | 0 | We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes... | Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Douglas Schneider, Isaac R. GalatzerLevy, Yugang Jia, John Canny, Arthur Gretton, Maja J. Mataric |  |
| 830 |  |  [Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models](https://aclanthology.org/2025.findings-acl.730/) |  | 0 | Language models pretrained on text-only corpora often struggle with tasks that require auditory commonsense knowledge.Previous work addresses this problem by augmenting the language model to retrieve knowledge from external audio databases.This approach has several limitations, such as the... | Suho Yoo, Hyunjong Ok, Jaeho Lee |  |
| 831 |  |  [SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning](https://aclanthology.org/2025.findings-acl.731/) |  | 0 | As Multimodal Large Language Models (MLLMs) develop, their potential security issues have become increasingly prominent. \*\*Machine Unlearning (MU)\*\*, as an effective strategy for forgetting specific knowledge in training data, has been widely used in privacy protection. However, \*MU for safety... | Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu, Xuming Hu |  |
| 832 |  |  [Prediction-Augmented Generation for Automatic Diagnosis Tasks](https://aclanthology.org/2025.findings-acl.732/) |  | 0 | Most Large language models (LLMs) adopt an autoregressive architecture, predicting the next word token based on the preceding context. While this approach is robust for language generation tasks such as writing and summarization, it has limitations for high-level reasoning tasks, such as prediction... | ChanYang Ju, DongHo Lee |  |
| 833 |  |  [FedLEKE: Federated Locate-then-Edit Knowledge Editing for Multi-Client Collaboration](https://aclanthology.org/2025.findings-acl.733/) |  | 0 | Locate-then-Edit Knowledge Editing (LEKE) is a key technique for updating large language models (LLMs) without full retraining. However, existing methods assume a single-user setting and become inefficient in real-world multi-client scenarios, where decentralized organizations (e.g., hospitals,... | Zongkai Zhao, Guozeng Xu, Xiuhua Li, Kaiwen Wei, Jiang Zhong |  |
| 834 |  |  [DiSCo: Device-Server Collaborative LLM-based Text Streaming Services](https://aclanthology.org/2025.findings-acl.734/) |  | 0 | The rapid rise of large language models (LLMs) in text streaming services has introduced significant cost and Quality of Experience (QoE) challenges in serving millions of daily requests, especially in meeting Time-To-First-Token (TTFT) and Time-Between-Token (TBT) requirements for real-time... | Ting Sun, Penghan Wang, Fan Lai |  |
| 835 |  |  [Customizing In-context Learning for Dynamic Interest Adaption in LLM-based Recommendation](https://aclanthology.org/2025.findings-acl.735/) |  | 0 | Frequently updating Large Language Model (LLM)-based recommender systems to adapt to dynamic user interests—as done for traditional ones—is impractical due to high training costs, even with acceleration methods. This work explores the possibility of adapting the model to dynamic user interests... | Keqin Bao, Ming Yan, Yang Zhang, Jizhi Zhang, Wenjie Wang, Fuli Feng, Xiangnan He |  |
| 836 |  |  [Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge](https://aclanthology.org/2025.findings-acl.736/) |  | 0 | Data watermarking in language models injects traceable signals, such as specific token sequences or stylistic patterns, into copyrighted text, allowing copyright holders to track and verify training data ownership. Previous data watermarking techniques primarily focus on effective memorization... | Xinyue Cui, Johnny TianZheng Wei, Swabha Swayamdipta, Robin Jia |  |
| 837 |  |  [LLM-Enhanced Query Generation and Retrieval Preservation for Task-Oriented Dialogue](https://aclanthology.org/2025.findings-acl.737/) |  | 0 | Knowledge retrieval and response generation are fundamental to task-oriented dialogue systems. However, dialogue context frequently contains noisy or irrelevant information, leading to sub-optimal result in knowledge retrieval. One possible approach to retrieving knowledge is to manually annotate... | Jiale Chen, Xuelian Dong, Wenxiu Xie, Ru Peng, Kun Zeng, Tianyong Hao |  |
| 838 |  |  [ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations](https://aclanthology.org/2025.findings-acl.738/) |  | 0 | The capabilities of large language models (LLMs) have been enhanced by training on data that reflects human thought processes, such as the Chain-of-Thought format. However, evidence suggests that the conventional scheme of next-word prediction may not fully capture how humans learn to think.... | Quang Hieu Pham, Thuy Duong Nguyen, Tung Pham, Anh Tuan Luu, Dat Quoc Nguyen |  |
| 839 |  |  [Low-Entropy Watermark Detection via Bayes' Rule Derived Detector](https://aclanthology.org/2025.findings-acl.739/) |  | 0 | Text watermarking, which modify tokens to embed watermark, has proven effective in detecting machine-generated texts. Yet its application to low-entropy texts like code and mathematics presents significant challenges. A fair number of tokens in these texts are hardly modifiable without changing the... | Beining Huang, Du Su, Fei Sun, Qi Cao, Huawei Shen, Xueqi Cheng |  |
| 840 |  |  [CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis](https://aclanthology.org/2025.findings-acl.740/) |  | 0 | The field of AI healthcare has undergone a significant transformation with the advent of large language models (LLMs), yet the challenges of interpretability within these models remain largely unaddressed. This study introduces \*\*Chain-of-Diagnosis (CoD)\*\* to enhance the interpretability of... | Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang |  |
| 841 |  |  [DaNet: Dual-Aware Enhanced Alignment Network for Multimodal Aspect-Based Sentiment Analysis](https://aclanthology.org/2025.findings-acl.741/) |  | 0 | Multimodal Aspect-Based Sentiment Analysis (MABSA) aims to extract aspect-sentiment pairs from text and image data. While significant progress has been made in image-aspect alignment, due to the subtlety and complexity of language expressions, there are not always explicit aspect words in the... | Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An |  |
| 842 |  |  [Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings](https://aclanthology.org/2025.findings-acl.742/) |  | 0 | Detecting toxic content using language models is important but challenging. While large language models (LLMs) have demonstrated strong performance in understanding Chinese, recent studies show that simple character substitutions in toxic Chinese text can easily confuse the state-of-the-art (SOTA)... | Shujian Yang, Shiyao Cui, Chuanrui Hu, Haicheng Wang, Tianwei Zhang, Minlie Huang, Jialiang Lu, Han Qiu |  |
| 843 |  |  [LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations](https://aclanthology.org/2025.findings-acl.743/) |  | 0 | Semantic text representation is a fundamental task in the field of natural language processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have demonstrated excellent performance, but the values of each dimension are difficult to trace and interpret. Bag-of-words, as classic sparse... | Yile Wang, Zhanyu Shen, Hui Huang |  |
| 844 |  |  [Ranked Voting based Self-Consistency of Large Language Models](https://aclanthology.org/2025.findings-acl.744/) |  | 0 | Majority voting is considered an effective method to enhance chain-of-thought reasoning, as it selects the answer with the highest ”self-consistency” among different reasoning paths (Wang et al., 2023). However, previous chain-of-thought reasoning methods typically generate only a single answer in... | Weiqin Wang, Yile Wang, Hui Huang |  |
| 845 |  |  [SemanticCamo: Jailbreaking Large Language Models through Semantic Camouflage](https://aclanthology.org/2025.findings-acl.745/) |  | 0 | The rapid development and increasingly widespread applications of Large Language Models (LLMs) have made the safety issues of LLMs more prominent and critical. Although safety training is widely used in LLMs, the mismatch between pre-training and safety training still leads to safety... | Jihui Yan, Xiaocui Yang, Daling Wang, Shi Feng, Yifei Zhang, Yinzhi Zhao |  |
| 846 |  |  [Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition](https://aclanthology.org/2025.findings-acl.746/) |  | 0 | Decomposing weight matrices into quantization and low-rank components ( W≈ Q+LR) is a widely used technique for compressing large language models (LLMs). Existing joint optimization methods iteratively alternate between quantization and low-rank approximation. However, these methods tend to... | Yoonjun Cho, Soeun Kim, Dongjae Jeon, Kyelim Lee, Beomsoo Lee, Albert No |  |
| 847 |  |  [Better Process Supervision with Bi-directional Rewarding Signals](https://aclanthology.org/2025.findings-acl.747/) |  | 0 | Process supervision, i.e., evaluating each step, is critical for complex large language model (LLM) reasoning and test-time searching with increased inference compute. Existing approaches, represented by process reward models (PRMs), primarily focus on rewarding signals up to the current step,... | Wenxiang Chen, Wei He, Zhiheng Xi, Honglin Guo, Boyang Hong, Jiazheng Zhang, Nijun Li, Tao Gui, Yun Li, Qi Zhang, Xuanjing Huang |  |
| 848 |  |  [KnowCoder-X: Boosting Multilingual Information Extraction via Code](https://aclanthology.org/2025.findings-acl.748/) |  | 0 | Empirical evidence indicates that LLMs exhibit spontaneous cross-lingual alignment. However, although LLMs show promising cross-lingual alignment in Information Extraction (IE), a significant imbalance across languages persists, highlighting an underlying deficiency. To address this, we propose... | Yuxin Zuo, Wenxuan Jiang, Wenxuan Liu, Zixuan Li, Long Bai, Hanbin Wang, Yutao Zeng, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng |  |
| 849 |  |  [MEIT: Multimodal Electrocardiogram Instruction Tuning on Large Language Models for Report Generation](https://aclanthology.org/2025.findings-acl.749/) |  | 0 | Electrocardiogram (ECG) is the primary non-invasive diagnostic tool for monitoring cardiac conditions and is crucial in assisting clinicians. Recent studies have concentrated on classifying cardiac conditions using ECG data but have overlooked ECG report generation, which is time-consuming and... | Zhongwei Wan, Che Liu, Xin Wang, Chaofan Tao, Hui Shen, Jing Xiong, Rossella Arcucci, Huaxiu Yao, Mi Zhang |  |
| 850 |  |  [Harnessing Large Language Models for Disaster Management: A Survey](https://aclanthology.org/2025.findings-acl.750/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including their emerging role in mitigating threats to human life, infrastructure, and the environment during natural disasters. Despite increasing research on disaster-focused LLMs, there remains a lack... | Zhenyu Lei, Yushun Dong, Weiyu Li, Rong Ding, Qi R. Wang, Jundong Li |  |
| 851 |  |  [Towards Medical Complex Reasoning with LLMs through Medical Verifiable Problems](https://aclanthology.org/2025.findings-acl.751/) |  | 0 | The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning to improve LLM. Yet, most research in reasoning has focused on mathematical tasks, leaving domains like medicine underexplored. The medical domain, though distinct from mathematics, also demands robust reasoning to... | Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Benyou Wang |  |
| 852 |  |  [Monitoring Decoding: Mitigating Hallucination via Evaluating the Factuality of Partial Response during Generation](https://aclanthology.org/2025.findings-acl.752/) |  | 0 | While large language models have demonstrated exceptional performance across a wide range of tasks, they remain susceptible to hallucinations – generating plausible yet factually incorrect contents. Existing methods to mitigating such risk often rely on sampling multiple full-length generations,... | Yurui Chang, Bochuan Cao, Lu Lin |  |
| 853 |  |  [LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback](https://aclanthology.org/2025.findings-acl.753/) |  | 0 | In recent progress, mathematical verifiers have achieved success in mathematical reasoning tasks by validating the correctness of solutions generated by policy models. However, existing verifiers are trained with binary classification labels, which are not informative enough for the model to... | Bofei Gao, Zefan Cai, Runxin Xu, Peiyi Wang, Ce Zheng, Runji Lin, Keming Lu, Dayiheng Liu, Chang Zhou, Wen Xiao, Tianyu Liu, Baobao Chang |  |
| 854 |  |  [EvoBench: Towards Real-world LLM-Generated Text Detection Benchmarking for Evolving Large Language Models](https://aclanthology.org/2025.findings-acl.754/) |  | 0 | With the widespread of Large Language Models (LLMs), there has been an increasing need to detect LLM-generated texts, prompting extensive research in this area. However, existing detection methods mainly evaluate on static benchmarks, which neglect the evolving nature of LLMs. Relying on existing... | Xiao Yu, Yi Yu, Dongrui Liu, Kejiang Chen, Weiming Zhang, Nenghai Yu, Jing Shao |  |
| 855 |  |  [MMSciBench: Benchmarking Language Models on Chinese Multimodal Scientific Problems](https://aclanthology.org/2025.findings-acl.755/) |  | 0 | Recent advances in large language models (LLMs) and vision-language models (LVLMs) have shown promise across many tasks, yet their scientific reasoning capabilities remain untested, particularly in multimodal settings. We present MMSciBench, a benchmark for evaluating mathematical and physical... | Xinwu Ye, Chengfan Li, Siming Chen, Wei Wei, Robert Tang |  |
| 856 |  |  [Lightweight Query Checkpoint: Classifying Faulty User Queries to Mitigate Hallucinations in Large Language Model Question Answering](https://aclanthology.org/2025.findings-acl.756/) |  | 0 | Question Answering (QA) with large language models has shown impressive performance, yet hallucinations still persist, particularly when user queries carry incorrect premises, insufficient context, or linguistic ambiguity. To address this issue, we propose Lightweight Query Checkpoint (LQC), a... | Minjoo Son, Jonghak Jang, Misuk Kim |  |
| 857 |  |  [Exploring LLM Annotation for Adaptation of Clinical Information Extraction Models under Data-sharing Restrictions](https://aclanthology.org/2025.findings-acl.757/) |  | 0 | In-hospital text data contains valuable clinical information, yet deploying fine-tuned small language models (SLMs) for information extraction remains challenging due to differences in formatting and vocabulary across institutions. Since access to the original in-hospital data (source domain) is... | Seiji Shimizu, Shohei Hisada, Yutaka Uno, Shuntaro Yada, Shoko Wakamiya, Eiji Aramaki |  |
| 858 |  |  [Enhancing the Comprehensibility of Text Explanations via Unsupervised Concept Discovery](https://aclanthology.org/2025.findings-acl.758/) |  | 0 | Concept-based explainable approaches have emerged as a promising method in explainable AI because they can interpret models in a way that aligns with human reasoning. However, their adaption in the text domain remains limited. Most existing methods rely on predefined concept annotations and cannot... | Yifan Sun, Danding Wang, Qiang Sheng, Juan Cao, Jintao Li |  |
| 859 |  |  [RecordTwin: Towards Creating Safe Synthetic Clinical Corpora](https://aclanthology.org/2025.findings-acl.759/) |  | 0 | The scarcity of publicly available clinical corpora hinders developing and applying NLP tools in clinical research. While existing work tackles this issue by utilizing generative models to create high-quality synthetic corpora, their methods require learning from the original in-hospital clinical... | Seiji Shimizu, Ibrahim Baroud, Lisa Raithel, Shuntaro Yada, Shoko Wakamiya, Eiji Aramaki |  |
| 860 |  |  [Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](https://aclanthology.org/2025.findings-acl.760/) |  | 0 | Although Aligned Large Language Models (LLMs) are trained to reject harmful requests, they remain vulnerable to jailbreak attacks. Unfortunately, existing methods often focus on surface-level patterns, overlooking the deeper attack essences. As a result, defenses fail when attack prompts change,... | Shiyu Xiang, Ansen Zhang, Yanfei Cao, Fan Yang, Ronghao Chen |  |
| 861 |  |  [Multimodal Invariant Sentiment Representation Learning](https://aclanthology.org/2025.findings-acl.761/) |  | 0 | Multimodal Sentiment Analysis (MSA) integrates diverse modalities to overcome the limitations of unimodal data. However, existing MSA datasets commonly exhibit significant sentiment distribution imbalances and cross-modal sentiment conflicts, which hinder performance improvement. This paper shows... | Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An |  |
| 862 |  |  [ChuLo: Chunk-Level Key Information Representation for Long Document Understanding](https://aclanthology.org/2025.findings-acl.762/) |  | 0 | Transformer-based models have achieved remarkable success in various Natural Language Processing (NLP) tasks, yet their ability to handle long documents is constrained by computational limitations. Traditional approaches, such as truncating inputs, sparse self-attention, and chunking, attempt to... | Yan Li, Caren Han, Yue Dai, Feiqi Cao |  |
| 863 |  |  [REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space](https://aclanthology.org/2025.findings-acl.763/) |  | 0 | Language models (LMs) risk inadvertently memorizing and divulging sensitive or personally identifiable information (PII) seen in training data, causing privacy concerns. Current approaches to address this issue involve costly dataset scrubbing, or model filtering through unlearning and model... | Tomer Ashuach, Martin Tutek, Yonatan Belinkov |  |
| 864 |  |  [Is External Information Useful for Stance Detection with LLMs?](https://aclanthology.org/2025.findings-acl.764/) |  | 0 | In the stance detection task, a text is classified as either favorable, opposing, or neutral towards a target. Prior work suggests that the use of external information, e.g., excerpts from Wikipedia, improves stance detection performance. However, whether or not such information can benefit large... | Quang Minh Nguyen, Taegyoon Kim |  |
| 865 |  |  [Benchmarking Query-Conditioned Natural Language Inference](https://aclanthology.org/2025.findings-acl.765/) |  | 0 | The growing excitement around the ability of large language models (LLMs) to tackle various tasks has been tempered by their propensity for generating unsubstantiated information (hallucination) and by their inability to effectively handle inconsistent inputs. To detect such issues, we propose the... | Marc E. Canby, Xinchi Chen, Xing Niu, Jifan Chen, Bonan Min, Sergül Aydöre, Vittorio Castelli |  |
| 866 |  |  [Flowchart-Based Decision Making with Large Language Models](https://aclanthology.org/2025.findings-acl.766/) |  | 0 | Large language models (LLMs) are widely used for conversational systems, but they face significant challenges in interpretability of dialogue flow and reproducibility of expert knowledge. To address this, we propose a novel method that extracts flowcharts from dialogue data and incorporates them... | Yuuki Yamanaka, Hiroshi Takahashi, Tomoya Yamashita |  |
| 867 |  |  [NarGINA: Towards Accurate and Interpretable Children's Narrative Ability Assessment via Narrative Graphs](https://aclanthology.org/2025.findings-acl.767/) |  | 0 | The assessment of children’s narrative ability is crucial for diagnosing language disorders and planning interventions. Distinct from the typical automated essay scoring, this task focuses primarily on evaluating the completeness of narrative content and the coherence of expression, as well as the... | Jun Zhong, Longwei Xu, Li Kong, Xianzhuo Li, Dandan Liang, Junsheng Zhou |  |
| 868 |  |  [Improving Efficiency in Large Language Models via Extendable Block Floating Point Representation](https://aclanthology.org/2025.findings-acl.768/) |  | 0 | Large language models (LLMs) have revolutionized natural language processing (NLP) tasks, yet their increasing size poses substantial challenges in terms of computational and memory resources. Block floating-point (BFP) arithmetic offers an effective solution by leveraging the strengths of both... | Dongyang Li, Zeyang Li, Bosheng Liu, Jigang Wu |  |
| 869 |  |  [EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding](https://aclanthology.org/2025.findings-acl.769/) |  | 0 | The remarkable performance of Large language models (LLMs) relies heavily on the availability of abundant high-quality training data. However, the high cost of acquiring annotated data often prevents models from obtaining capabilities to tackle downstream tasks. In this paper, we introduce a novel... | Mingxu Tao, Jie Hu, Mingchuan Yang, Yunhuai Liu, Dongyan Zhao, Yansong Feng |  |
| 870 |  |  [NativQA: Multilingual Culturally-Aligned Natural Query for LLMs](https://aclanthology.org/2025.findings-acl.770/) |  | 0 | Natural Question Answering (QA) datasets play a crucial role in evaluating the capabilities of large language models (LLMs), ensuring their effectiveness in real-world applications. Despite the numerous QA datasets that have been developed and some work done in parallel, there is a notable lack of... | Md. Arid Hasan, Maram Hasanain, Fatema Ahmad, Sahinur Rahman Laskar, Sunaya Upadhyay, Vrunda N. Sukhadia, Mucahid Kutlu, Shammur Absar Chowdhury, Firoj Alam |  |
| 871 |  |  [DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation](https://aclanthology.org/2025.findings-acl.771/) |  | 0 | Document-level context is crucial for handling discourse challenges in text-to-text document-level machine translation (MT). Despite the increased discourse challenges introduced by noise from automatic speech recognition (ASR), the integration of document-level context in speech translation (ST)... | Xinglin Lyu, Wei Tang, Yuang Li, Xiaofeng Zhao, Ming Zhu, Junhui Li, Yunfei Lu, Min Zhang, Daimeng Wei, Hao Yang |  |
| 872 |  |  [RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering](https://aclanthology.org/2025.findings-acl.772/) |  | 0 | Large Language Models (LLMs) excel in many areas but continue to face challenges with complex reasoning tasks, such as Multi-Hop Question Answering (MHQA). MHQA requires integrating evidence from diverse sources while managing intricate logical dependencies, often leads to errors in reasoning.... | Bolei He, Xinran He, Mengke Chen, Xianwei Xue, Ying Zhu, ZhenHua Ling |  |
| 873 |  |  [VADE: Visual Attention Guided Hallucination Detection and Elimination](https://aclanthology.org/2025.findings-acl.773/) |  | 0 | Vision Language Models (VLMs) have achieved significant advancements in complex visual understanding tasks. However, VLMs are prone to hallucinations—generating outputs that lack alignment with visual content. This paper addresses hallucination detection in VLMs by leveraging the visual grounding... | Vishnu Prabhakaran, Purav Aggarwal, Vinay Kumar Verma, Gokul Swamy, Anoop Saladi |  |
| 874 |  |  [PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization](https://aclanthology.org/2025.findings-acl.774/) |  | 0 | Large Language Model (LLM) agents have demonstrated impressive capabilities in handling complex interactive problems. Existing LLM agents mainly generate natural language plans to guide reasoning, which is verbose and inefficient. NL plans are also tailored to specific tasks and restrict agents’... | Zouying Cao, Runze Wang, Yifei Yang, Xinbei Ma, Xiaoyong Zhu, Bo Zheng, Hai Zhao |  |
| 875 |  |  [The Effectiveness of Uncased Tokeniziaion for Clinical Notes](https://aclanthology.org/2025.findings-acl.775/) |  | 0 | The impact of case-sensitive tokenization on clinical notes is not well understood. While clinical notes share similarities with biomedical text in terminology, they often lack the proper casing found in polished publications. Language models, unlike humans, require a fixed vocabulary and case... | Cory Paik, Katharina von der Wense |  |
| 876 |  |  [AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference](https://aclanthology.org/2025.findings-acl.776/) |  | 0 | As large language models (LLMs) grow in parameter size and context length, computation precision has been reduced from 16-bit to 4-bit to improve inference efficiency. However, this reduction causes accuracy degradation due to activation outliers. Rotation-based INT4 methods address this via matrix... | Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi |  |
| 877 |  |  [Improving Continual Pre-training Through Seamless Data Packing](https://aclanthology.org/2025.findings-acl.777/) |  | 0 | Continual pre-training has demonstrated significant potential in enhancing model performance, particularly in domain-specific scenarios. The most common approach for packing data before continual pre-training involves concatenating input texts and splitting them into fixed-length sequences. While... | Ruicheng Yin, Xuan Gao, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang |  |
| 878 |  |  [The Impact of Name Age Perception on Job Recommendations in LLMs](https://aclanthology.org/2025.findings-acl.778/) |  | 0 | Names often carry generational connotations, with certain names stereotypically associated with younger or older age groups. This study examines implicit age-related name bias in LLMs used for job recommendations. Analyzing six LLMs and 117 American names categorized by perceived age across 30... | Mahammed Kamruzzaman, Gene Louis Kim |  |
| 879 |  |  [DAPI: Domain Adaptive Toxicity Probe Vector Intervention, for Fine-Grained Detoxification](https://aclanthology.org/2025.findings-acl.779/) |  | 0 | There have been attempts to utilize linear probe for detoxification, with existing studies relying on a single toxicity probe vector to reduce toxicity. However, toxicity can be fine-grained into various subcategories, making it difficult to remove certain types of toxicity by using a single... | Cho Hyeonsu, Dooyoung Kim, Youngjoong Ko |  |
| 880 |  |  [Task Knowledge Injection via Interpolations and Reinstatement for Large Language Model Generalization](https://aclanthology.org/2025.findings-acl.780/) |  | 0 | Large language models have shown tremendous potential across various NLP tasks, and instruction tuning has been widely adopted to elicit their superior performance. However, instruction tuning may overly tailor the models to task-specific formats, potentially compromising their generalization on... | Yukun Zhao, Lingyong Yan, Zhenyang Li, Shuaiqiang Wang, Zhumin Chen, Zhaochun Ren, Dawei Yin |  |
| 881 |  |  [STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation](https://aclanthology.org/2025.findings-acl.781/) |  | 0 | Recent breakthroughs in singing voice synthesis (SVS) have heightened the demand for high-quality annotated datasets, yet manual annotation remains prohibitively labor-intensive and resource-intensive. Existing automatic singing annotation (ASA) methods, however, primarily tackle isolated aspects... | Wenxiang Guo, Yu Zhang, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, ZheTao Chen, Wenhao Xu, Fei Wu, Zhou Zhao |  |
| 882 |  |  [Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning](https://aclanthology.org/2025.findings-acl.782/) |  | 0 | Large Language Models (LLMs) excel in reasoning tasks through Chain-of-Thought (CoT) prompting. However, CoT prompting greatly increases computational demands, which has prompted growing interest in distilling CoT capabilities into Small Language Models (SLMs). This study systematically examines... | Xinghao Chen, Zhijing Sun, Wenjin Guo, Miaoran Zhang, Yanjun Chen, Yirong Sun, Hui Su, Yijie Pan, Dietrich Klakow, Wenjie Li, Xiaoyu Shen |  |
| 883 |  |  [INT: Establishing Information Transfer for Multilingual Intent Detection and Slot Filling](https://aclanthology.org/2025.findings-acl.783/) |  | 0 | Multilingual spoken language understanding (SLU) involves intent detection (ID) and slot filling (SF) across multiple languages. The inherent linguistic diversity presents significant challenges in achieving performance comparable to traditional SLU. Recent studies have attempted to improve... | Di Wu, Liting Jiang, Bohui Mao, Hongyan Xie, Haoxiang Su, Zhongjiang He, Ruiyu Fang, Shuangyong Song, Hao Huang, Xuelong Li |  |
| 884 |  |  [Enhancing LLM Agent Safety via Causal Influence Prompting](https://aclanthology.org/2025.findings-acl.784/) |  | 0 | As autonomous agents powered by large language models (LLMs) continue to demonstrate potential across various assistive tasks, ensuring their safe and reliable behavior is crucial for preventing unintended consequences. In this work, we introduce CIP, a novel technique that leverages causal... | Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee |  |
| 885 |  |  [Position Paper: MeMo: Towards Language Models with Associative Memory Mechanisms](https://aclanthology.org/2025.findings-acl.785/) |  | 0 | Memorization is a fundamental ability of Transformer-based Large Language Models, achieved through learning. In this position/theory paper, we propose a paradigm shift by designing an architecture to memorize text directly, bearing in mind the principle that memorization precedes learning. We... | Fabio Massimo Zanzotto, Elena Sofia Ruzzetti, Giancarlo A. Xompero, Leonardo Ranaldi, Davide Venditti, Federico Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli |  |
| 886 |  |  [DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction](https://aclanthology.org/2025.findings-acl.786/) |  | 0 | We present DeRAGEC, a method for improving Named Entity (NE) correction in Automatic Speech Recognition (ASR) systems. By extending the Retrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC employs synthetic denoising rationales to filter out noisy NE candidates before... | Solee Im, Wonjun Lee, Jinmyeong An, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee |  |
| 887 |  |  [Rehearse With User: Personalized Opinion Summarization via Role-Playing based on Large Language Models](https://aclanthology.org/2025.findings-acl.787/) |  | 0 | Personalized opinion summarization is crucial as it considers individual user interests while generating product summaries.Recent studies show that although large language models demonstrate powerful text summarization and evaluation capabilities without the need for training data, they face... | Yanyue Zhang, Yulan He, Deyu Zhou |  |
| 888 |  |  [AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset](https://aclanthology.org/2025.findings-acl.788/) |  | 0 | Identifying factors that make ad text attractive is essential for advertising success. This study proposes AdParaphrase v2.0, a dataset for ad text paraphrasing, containing human preference data, to enable the analysis of the linguistic factors and to support the development of methods for... | Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura |  |
| 889 |  |  [Beyond the Average Reader: the Reader Embedding Approach](https://aclanthology.org/2025.findings-acl.789/) |  | 0 | Focus of this work is the prediction of reading times as the task is customarily dealt with in literature: that is, by collecting eye-tracking data that are averaged and employed to train learning models. We start by observing that systems trained on average values are ill-suited for the prediction... | Calogero Jerik Scozzaro, Matteo Delsanto, Daniele Paolo Radicioni |  |
| 890 |  |  [PredictaBoard: Benchmarking LLM Score Predictability](https://aclanthology.org/2025.findings-acl.790/) |  | 0 | Despite possessing impressive skills, Large Language Models (LLMs) often fail unpre-dictably, demonstrating inconsistent success in even basic common sense reasoning tasks. This unpredictability poses a significant challenge to ensuring their safe deployment, as identifying and operating within a... | Lorenzo Pacchiardi, Konstantinos Voudouris, Ben Slater, Fernando MartínezPlumed, José HernándezOrallo, Lexin Zhou, Wout Schellaert |  |
| 891 |  |  [FedDQC: Data Quality Control in Federated Instruction-tuning of Large Language Models](https://aclanthology.org/2025.findings-acl.791/) |  | 0 | Federated Learning (FL) enables privacy-preserving collaborative instruction tuning of large language models (LLMs) by leveraging massively distributed data. However, the decentralized nature of FL exacerbates data quality challenges, as local clients lack global visibility to filter noisy or... | Yaxin Du, Rui Ye, Fengting Yuchi, Wanru Zhao, Jingjing Qu, Yanfeng Wang, Siheng Chen |  |
| 892 |  |  [Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning](https://aclanthology.org/2025.findings-acl.792/) |  | 0 | Parameter-efficient fine-tuning (PEFT) large language models (LLMs) have shown impressive performance in various downstream tasks. However, in many real-world scenarios, the collected training data inevitably contains noisy labels. To learn from noisy labels, most solutions select samples with... | Bo Yuan, Yulin Chen, Yin Zhang |  |
| 893 |  |  ["I understand your perspective": LLM Persuasion through the Lens of Communicative Action Theory](https://aclanthology.org/2025.findings-acl.793/) |  | 0 | Large Language Models (LLMs) can generate high-quality arguments, yet their ability to engage in \*nuanced and persuasive communicative actions\* remains largely unexplored. This work explores the persuasive potential of LLMs through the framework of Jürgen Habermas’ Theory of Communicative Action.... | Esra Dönmez, Agnieszka Falenska |  |
| 894 |  |  [Nunchi-Bench: Benchmarking Language Models on Cultural Reasoning with a Focus on Korean Superstition](https://aclanthology.org/2025.findings-acl.794/) |  | 0 | As large language models (LLMs) become key advisors in various domains, their cultural sensitivity and reasoning skills are crucial in multicultural environments. We introduce Nunchi-Bench, a benchmark designed to evaluate LLMs’ cultural understanding, with a focus on Korean superstitions. The... | Kyuhee Kim, Sangah Lee |  |
| 895 |  |  [Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models](https://aclanthology.org/2025.findings-acl.795/) |  | 0 | While Chain of Thought (CoT) prompting approaches have significantly consolidated the reasoning capabilities of large language models (LLMs), they still face limitations that require extensive human effort or have performance needs to be improved. Existing endeavors have focused on bridging these... | Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu |  |
| 896 |  |  [daDPO: Distribution-Aware DPO for Distilling Conversational Abilities](https://aclanthology.org/2025.findings-acl.796/) |  | 0 | Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation (KD) with Direct... | Zhengze Zhang, Shiqi Wang, Yiqun Shen, Simin Guo, Dahua Lin, Xiaoliang Wang, CamTu Nguyen, Fei Tan |  |
| 897 |  |  [Consultant Decoding: Yet Another Synergistic Mechanism](https://aclanthology.org/2025.findings-acl.797/) |  | 0 | The synergistic mechanism based on Speculative Decoding (SD) has garnered considerable attention as a simple yet effective approach for accelerating the inference of large language models (LLMs). Nonetheless, the high rejection rates require repeated LLMs calls to validate draft tokens, undermining... | Chuanghao Ding, Jiaping Wang, Ziqing Yang, Xiaoliang Wang, Dahua Lin, Nguyen CamTu, Fei Tan |  |
| 898 |  |  [IntelliCockpitBench: A Comprehensive Benchmark to Evaluate VLMs for Intelligent Cockpit](https://aclanthology.org/2025.findings-acl.798/) |  | 0 | The integration of sophisticated Vision-Language Models (VLMs) in vehicular systems is revolutionizing vehicle interaction and safety, performing tasks such as Visual Question Answering (VQA). However, a critical gap persists due to the lack of a comprehensive benchmark for multimodal VQA models in... | Liang Lin, Siyuan Chai, Jiahao Wu, Hongbing Hu, Xiaotao Gu, Hao Hu, Fan Zhang, Wei Wang, Dan Zhang |  |
| 899 |  |  [Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification](https://aclanthology.org/2025.findings-acl.799/) |  | 0 | Political biases encoded by LLMs might have detrimental effects on downstream applications. Existing bias analysis methods rely on small-size intermediate tasks (questionnaire answering or political content generation) and rely on the LLMs themselves for analysis, thus propagating bias. We propose... | Akram Elbouanani, Evan Dufraisse, Adrian Popescu |  |
| 900 |  |  [PISCO: Pretty Simple Compression for Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.800/) |  | 0 | Retrieval-Augmented Generation (RAG) pipelines enhance Large Language Models (LLMs) by retrieving relevant documents, but they face scalability issues due to high inference costs and limited context size. Document compression is a practical solution, but current soft compression methods often... | Maxime Louis, Hervé Déjean, Stéphane Clinchant |  |
| 901 |  |  [AnchorCoT: Anchors Pave the Way for Multi-hop Reasoning](https://aclanthology.org/2025.findings-acl.801/) |  | 0 | Large Language Models (LLMs) have made substantial strides in a broad array of natural language tasks. Recently, LLMs have demonstrated potential reasoning capabilities through prompt design, such as the Chain of Thought (CoT). Despite their superiority in question answering, LLMs still face... | Tianshi Ming, Xian Wu, Yingying Zhang, Zichuan Fu, Dawei Cheng |  |
| 902 |  |  [Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?](https://aclanthology.org/2025.findings-acl.802/) |  | 0 | Multimodal large language models (MLLMs) have shown remarkable performance for cross-modal understanding and generation, yet still suffer from severe inference costs. Recently, abundant works have been proposed to solve this problem with token pruning, which identifies the redundant tokens in MLLMs... | Zichen Wen, Yifeng Gao, Weijia Li, Conghui He, Linfeng Zhang |  |
| 903 |  |  [Federated Data-Efficient Instruction Tuning for Large Language Models](https://aclanthology.org/2025.findings-acl.803/) |  | 0 | Instruction tuning is a crucial step in improving the responsiveness of pretrained large language models (LLMs) to human instructions. Federated learning (FL) helps to exploit the use of vast private instruction data from clients, becoming popular for LLM tuning by improving data diversity.... | Zhen Qin, Zhaomin Wu, Bingsheng He, Shuiguang Deng |  |
| 904 |  |  [They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse](https://aclanthology.org/2025.findings-acl.804/) |  | 0 | Implicit content plays a crucial role in political discourse, where systematically employ pragmatic strategies such as implicatures and presuppositions to influence their audiences. Large Language Models (LLMs) have demonstrated strong performance in tasks requiring complex semantic and pragmatic... | Walter Paci, Alessandro Panunzi, Sandro Pezzelle |  |
| 905 |  |  [ZeroNER: Fueling Zero-Shot Named Entity Recognition via Entity Type Descriptions](https://aclanthology.org/2025.findings-acl.805/) |  | 0 | What happens when a named entity recognition (NER) system encounters entities it has never seen before? In practical applications, models must generalize to unseen entity types where labeled training data is either unavailable or severely limited—a challenge that demands zero-shot learning... | Alessio Cocchieri, Marcos Martínez Galindo, Giacomo Frisoni, Gianluca Moro, Claudio Sartori, Giuseppe Tagliavini |  |
| 906 |  |  [Do Large Language Models Have "Emotion Neurons"? Investigating the Existence and Role](https://aclanthology.org/2025.findings-acl.806/) |  | 0 | This study comprehensively explores whether there actually exist “emotion neurons” within large language models (LLMs) that selectively process and express certain emotions, and what functional role they play. Drawing on the representative emotion theory of the six basic emotions, we focus on six... | Jaewook Lee, Woojin Lee, OhWoog Kwon, Harksoo Kim |  |
| 907 |  |  [Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?](https://aclanthology.org/2025.findings-acl.807/) |  | 0 | Grammar serves as a cornerstone in programming languages and software engineering, providing frameworks to define the syntactic space and program structure. Existing research demonstrates the effectiveness of grammar-based code representations in small-scale models, showing their ability to reduce... | Qingyuan Liang, Zhao Zhang, Zeyu Sun, Zheng Lin, Qi Luo, Yueyi Xiao, Yizhou Chen, Yuqun Zhang, Haotian Zhang, Lu Zhang, Chenbin Chenbin, Yingfei Xiong |  |
| 908 |  |  [Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study](https://aclanthology.org/2025.findings-acl.808/) |  | 0 | Recently, inference-time scaling of chain-of-thought (CoT) has been demonstrated as a promising approach for addressing multi-modal reasoning tasks.While existing studies have predominantly centered on text-based thinking, the integration of both visual and textual modalities within the reasoning... | Yujie Lin, Ante Wang, Moye Chen, Jingyao Liu, Hao Liu, Jinsong Su, Xinyan Xiao |  |
| 909 |  |  [UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis](https://aclanthology.org/2025.findings-acl.809/) |  | 0 | Recent advancements in Large Vision-Language Models are accelerating the development of Graphical User Interface (GUI) agents that utilize human-like vision perception capabilities to enhance productivity on digital devices. Compared to approaches predicated on GUI metadata, which are... | Xinyi Liu, Xiaoyi Zhang, Ziyun Zhang, Yan Lu |  |
| 910 |  |  [A Study into Investigating Temporal Robustness of LLMs](https://aclanthology.org/2025.findings-acl.810/) |  | 0 | Large Language Models (LLMs) encapsulate a surprising amount of factual world knowledge. However, their performance on temporal questions and historical knowledge is limited because they often cannot understand temporal scope and orientation or neglect the temporal aspect altogether.In this study,... | Jonas Wallat, Abdelrahman Abdallah, Adam Jatowt, Avishek Anand |  |
| 911 |  |  [ToolExpNet: Optimizing Multi-Tool Selection in LLMs with Similarity and Dependency-Aware Experience Networks](https://aclanthology.org/2025.findings-acl.811/) |  | 0 | Tool learning enhances Large Language Models’ (LLMs) dynamic interaction with external tools, improving their ability to solve complex problems. However, current empirical methods, which primarily focus on isolated tools learning, still struggle with accurate multi-tool selection due to issues like... | Zijing Zhang, Zhanpeng Chen, He Zhu, Ziyang Chen, Nan Du, Xiaolong Li |  |
| 912 |  |  [SPILL: Domain-Adaptive Intent Clustering based on Selection and Pooling with Large Language Models](https://aclanthology.org/2025.findings-acl.812/) |  | 0 | In this paper, we propose Selection and Pooling with Large Language Models (SPILL), an intuitive, domain-adaptive method for intent clustering without fine-tuning. Existing embeddings-based clustering methods rely on a few labeled examples or unsupervised fine-tuning to optimize results for each... | IFan Lin, Faegheh Hasibi, Suzan Verberne |  |
| 913 |  |  [How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation](https://aclanthology.org/2025.findings-acl.813/) |  | 0 | Recently, LLMs have garnered increasing attention across academic disciplines for their potential as human digital twins, virtual proxies designed to replicate individuals and autonomously perform tasks such as decision-making, problem-solving, and reasoning on their behalf.However, current... | Rui Li, Heming Xia, Xinfeng Yuan, Qingxiu Dong, Lei Sha, Wenjie Li, Zhifang Sui |  |
| 914 |  |  [GRI-QA: a Comprehensive Benchmark for Table Question Answering over Environmental Data](https://aclanthology.org/2025.findings-acl.814/) |  | 0 | Assessing corporate environmental sustainability with Table Question Answering systems is challenging due to complex tables, specialized terminology, and the variety of questions they must handle. In this paper, we introduce GRI-QA, a test benchmark designed to evaluate Table QA approaches in the... | Michele Luca Contalbo, Sara Pederzoli, Francesco Del Buono, Venturelli Valeria, Francesco Guerra, Matteo Paganelli |  |
| 915 |  |  [WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code](https://aclanthology.org/2025.findings-acl.815/) |  | 0 | With the rapid advancement of Generative AI technology, Multimodal Large Language Models(MLLMs) have the potential to act as AI software engineers capable of executing complex web application development. Considering that the model requires a confluence of multidimensional sub-capabilities to... | Zhiyu Lin, Zhengda Zhou, Zhiyuan Zhao, Tianrui Wan, Yilun Ma, Junyu Gao, Xuelong Li |  |
| 916 |  |  [Optimizing Multi-Hop Document Retrieval Through Intermediate Representations](https://aclanthology.org/2025.findings-acl.816/) |  | 0 | Retrieval-augmented generation (RAG) encounters challenges when addressing complex queries, particularly multi-hop questions. While several methods tackle multi-hop queries by iteratively generating internal queries and retrieving external documents, these approaches are computationally expensive.... | Linjiaen Linjiaen, Jingyu Liu, Yingbo Liu |  |
| 917 |  |  [Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments](https://aclanthology.org/2025.findings-acl.817/) |  | 0 | Multi-step reasoning is essential for large language models (LLMs), yet multilingual performance remains challenging. While Chain-of-Thought (CoT) prompting improves reasoning, it struggles with non-English languages due to the entanglement of reasoning and execution. Program-of-Thought (PoT)... | Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 918 |  |  [A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models](https://aclanthology.org/2025.findings-acl.818/) |  | 0 | Recent advances in Large Language Models (LLMs) have shown promise in automating discourse annotation for conversations. While manually designing tree annotation schemes significantly improves annotation quality for humans and models, their creation remains time-consuming and requires expert... | Kseniia Petukhova, Ekaterina Kochmar |  |
| 919 |  |  [Can Language Models Serve as Analogy Annotators?](https://aclanthology.org/2025.findings-acl.819/) |  | 0 | Conceptual abstraction and analogy-making are crucial for human learning, reasoning, and adapting to unfamiliar domains. Recently, large language models (LLMs) have made the synthesis of analogical data possible, which, however, still heavily relies on extensive human efforts to be annotated. This... | Xiaojing Zhang, Bochen Lyu |  |
| 920 |  |  [Reward Generalization in RLHF: A Topological Perspective](https://aclanthology.org/2025.findings-acl.820/) |  | 0 | Existing alignment methods share a common topology of information flow, where reward information is collected from humans, modeled with preference learning, and used to tune language models. However, this shared topology has not been systematically characterized, nor have its alternatives been... | Tianyi Alex Qiu, Fanzhi Zeng, Jiaming Ji, Dong Yan, Kaile Wang, Jiayi Zhou, Yang Han, Josef Dai, Xuehai Pan, Yaodong Yang |  |
| 921 |  |  [Enhanced Data Synthesis for LLM through Reasoning Structures Generated by Hierarchical GFlowNet](https://aclanthology.org/2025.findings-acl.821/) |  | 0 | Large language models (LLMs) excel in problem-solving but require training data with diverse reasoning processes. Existing methods mainly optimize instruction-response pairs but lack a systematic design for the underlying reasoning structure. This paper proposes RSS: a Reasoning Structure driven... | Tianpeng Bu, Minying Zhang, Hongtao Duan, Shurui Li, Lulu Hu, Yu Li |  |
| 922 |  |  [Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models](https://aclanthology.org/2025.findings-acl.822/) |  | 0 | Aligning small language models (SLMs) with human values typically involves distilling preference knowledge from large language models (LLMs). However, existing distillation methods model preference knowledge in teacher LLMs by comparing pairwise responses, overlooking the extent of difference... | Yanggan Gu, Junzhuo Li, Sirui Huang, Xin Zou, Zhenghua Li, Xuming Hu |  |
| 923 |  |  [Token-level Preference Self-Alignment Optimization for Multi-style Outline Controllable Generation](https://aclanthology.org/2025.findings-acl.823/) |  | 0 | Multi-style outline controllable generation is crucial for multiple applications, including document semantic structuring and retrieval-augmented generation.The great success of preference alignment approaches encourages their application in controllable generation tasks.However, these attempts... | Zihao Li, Xuekong Xu, Ziyao Chen, Lixin Zou, Ethanhjwu Ethanhjwu, Qiang Chen, Chenliang Li |  |
| 924 |  |  [HatePRISM: Policies, Platforms, and Research Integration. Advancing NLP for Hate Speech Proactive Mitigation](https://aclanthology.org/2025.findings-acl.824/) |  | 0 | Despite regulations imposed by nations and social media platforms, e.g. (Government of India, 2021; European Parliament and Council of the European Union, 2022), inter alia, hateful content persists as a significant challenge. Existing approaches primarily rely on reactive measures such as blocking... | Naquee Rizwan, Seid Muhie Yimam, Daryna Dementieva, Florian Skupin, Tim Fischer, Daniil Moskovskiy, Aarushi Ajay Borkar, Robert Geislinger, Punyajoy Saha, Sarthak Roy, Martin Semmann, Alexander Panchenko, Chris Biemann, Animesh Mukherjee |  |
| 925 |  |  [Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving](https://aclanthology.org/2025.findings-acl.825/) |  | 0 | The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the LLMs, even for the step-wise rewards, or large quantities of human-annotated trajectory data. The reliance on the rolled-out trajectory renders the... | Sara Rajaee, Kumar Pratik, Gabriele Cesa, Arash Behboodi |  |
| 926 |  |  [Generalizable Cross-Lingual Cognitive Distortion Detection with Standardized Annotations and Multi-Task Learning](https://aclanthology.org/2025.findings-acl.826/) |  | 0 | Cognitive distortion is a critical issue in psychology, with most existing studies based on Burns’ cognitive distortion theory. However, differences in annotation standards lead to variations in building analysis tools, resulting in inconsistent analyses and limiting the generalizability of... | Hongzhi Qi, Nan Bai, Jianqiang Li, Wei Zhai, Qing Zhao, Qi Gao, Bing Xiang Yang, Guanghui Fu |  |
| 927 |  |  [How Do Multilingual Language Models Remember Facts?](https://aclanthology.org/2025.findings-acl.827/) |  | 0 | Large Language Models (LLMs) store and retrieve vast amounts of factual knowledge acquired during pre-training. Prior research has localized and identified mechanisms behind knowledge recall; however, it has only focused on English monolingual models. The question of how these mechanisms generalize... | Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders Søgaard |  |
| 928 |  |  [SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation](https://aclanthology.org/2025.findings-acl.828/) |  | 0 | We present Sequential Policy Optimization for Simultaneous Machine Translation (SeqPO-SiMT), a new policy optimization framework that defines the simultaneous machine translation (SiMT) task as a sequential decision making problem, incorporating a tailored reward to enhance translation quality... | Ting Xu, Zhichao Huang, Jiankai Sun, Shanbo Cheng, Wai Lam |  |
| 929 |  |  [Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales](https://aclanthology.org/2025.findings-acl.829/) |  | 0 | Although Large Language Models (LLMs) have demonstrated strong language understanding and generation abilities across various languages, their cultural knowledge is often limited to English-speaking communities, which can marginalize the cultures of non-English communities. To address the problem,... | Ayuto Tsutsumi, Yuu Jinnai |  |
| 930 |  |  [BOSE: A Systematic Evaluation Method Optimized for Base Models](https://aclanthology.org/2025.findings-acl.830/) |  | 0 | This paper poses two critical issues in evaluating base models (without post-training): (1) Unstable evaluation during training: in the early stages of pre-training, the models lack the capability to answer questions as required, leading to unstable evaluation results. This instability makes it... | Hongzhi Luan, Changxin Tian, Zhaoxin Huan, Xiaolu Zhang, Kunlong Chen, Zhiqiang Zhang, Jun Zhou |  |
| 931 |  |  [DPGA-TextSyn: Differentially Private Genetic Algorithm for Synthetic Text Generation](https://aclanthology.org/2025.findings-acl.831/) |  | 0 | Using large language models (LLMs) has a potential risk of privacy leakage since the data with sensitive information may be used for fine-tuning the LLMs. Differential privacy (DP) provides theoretical guarantees of privacy protection, but its practical application in LLMs still has the problem of... | Zhonghao Sun, Zhiliang Tian, Yiping Song, Yuyi Si, Juhua Zhang, Minlie Huang, Kai Lu, Zeyu Xiong, Xinwang Liu, Dongsheng Li |  |
| 932 |  |  [Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer](https://aclanthology.org/2025.findings-acl.832/) |  | 0 | Large Language Models (LLMs) are increasingly incorporating multilingual capabilities, fueling the demand to transfer them into target language-specific models. However, most approaches, which blend the source model’s embedding by replacing the source vocabulary with the target language-specific... | Seungyoon Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim |  |
| 933 |  |  [Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation](https://aclanthology.org/2025.findings-acl.833/) |  | 0 | To address these limitations, we propose BDC, a novel framework that Boosts reasoning exploration via multi-agent collaboration, Disentangles heterogeneous data into specialized experts, and Customizes solutions through dynamic model composition. BDC integrates a Monte Carlo Tree-of-Agents... | Kounianhua Du, Hanjing Wang, Jianxing Liu, Jizheng Chen, Xinyi Dai, Yasheng Wang, Ruiming Tang, Yong Yu, Jun Wang, Weinan Zhang |  |
| 934 |  |  [On the Consistency of Commonsense in Large Language Models](https://aclanthology.org/2025.findings-acl.834/) |  | 0 | Commonsense, humans’ implicit understanding of everyday situations, is crucial for large language models (LLMs). Existing commonsense evaluations for LLMs primarily focus on downstream knowledge tasks, failing to probe whether LLMs truly understand and utilize knowledge or merely memorize it. They... | Guozheng Li, Peng Wang, Wenjun Ke, Zijie Xu, Jiajun Liu, Ziyu Shang |  |
| 935 |  |  [Statement-Tuning Enables Efficient Cross-lingual Generalization in Encoder-only Models](https://aclanthology.org/2025.findings-acl.835/) |  | 0 | Large Language Models (LLMs) excel in zero-shot and few-shot tasks, but achieving similar performance with encoder-only models like BERT and RoBERTa has been challenging due to their architecture. However, encoders offer advantages such as lower computational and memory costs. Recent work adapts... | Ahmed Elshabrawy, ThanhNhi Nguyen, Yeeun Kang, Lihan Feng, Annant Jain, Faadil Abdullah Shaikh, Jonibek Mansurov, Mohamed Fazli Mohamed Imam, JesúsGermán OrtizBarajas, Rendi Chevi, Alham Fikri Aji |  |
| 936 |  |  [Evaluating Large Language Models for Confidence-based Check Set Selection](https://aclanthology.org/2025.findings-acl.836/) |  | 0 | Large Language Models (LLMs) have shown promise in automating high-labor data tasks, but the adoption of LLMs in high-stake scenarios faces two key challenges: their tendency to answer despite uncertainty and their difficulty handling long input contexts robustly.We investigate commonly used... | Jane Arleth dela Cruz, Iris Hendrickx, Martha A. Larson |  |
| 937 |  |  [Training Multi-Modal LLMs through Dialogue Planning for HRI](https://aclanthology.org/2025.findings-acl.837/) |  | 0 | Grounded natural language understanding in Human-Robot Interaction (HRI) requires integrating linguistic, visual, and world knowledge to ensure effective task execution. We propose an approach that enhances Multi-Modal Large Language Models (MLLMs) with a novel explicit dialogue planning phase,... | Claudiu Daniel Hromei, Federico Borazio, Andrea Sensi, Elisa Passone, Danilo Croce, Roberto Basili |  |
| 938 |  |  [MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching](https://aclanthology.org/2025.findings-acl.838/) |  | 0 | Existing multilingual vision-language (VL) benchmarks often only cover a handful of languages. Consequently, evaluations of large vision-language models (LVLMs) predominantly target high-resource languages, underscoring the need for evaluation data for low-resource languages. To address this... | Fabian David Schmidt, Florian Schneider, Chris Biemann, Goran Glavas |  |
| 939 |  |  [The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue Agents](https://aclanthology.org/2025.findings-acl.839/) |  | 0 | Large Language Models (LLMs) have made remarkable advances in role-playing dialogue agents, demonstrating their utility in character simulations. However, it remains challenging for these agents to balance character portrayal utility with content safety because this essential character simulation... | Yihong Tang, Kehai Chen, Xuefeng Bai, ZhengYu Niu, Bo Wang, Jie Liu, Min Zhang |  |
| 940 |  |  [SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming User Sentiment Modeling](https://aclanthology.org/2025.findings-acl.840/) |  | 0 | User reviews on e-commerce platforms exhibit dynamic sentiment patterns driven by temporal and contextual factors. Traditional sentiment analysis methods focus on static reviews, failing to capture the evolving temporal relationship between user sentiment rating and textual content. Sentiment... | Xin Zhang, Qiyu Wei, Yingjie Zhu, Linhai Zhang, Deyu Zhou, Sophia Ananiadou |  |
| 941 |  |  [Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists](https://aclanthology.org/2025.findings-acl.841/) |  | 0 | Large language models (LLMs) have significantly advanced natural language processing, particularly through the integration of external tools and APIs. However, their effectiveness is frequently hampered by parameter mis-filling during tool calling. In this paper, we propose the Hierarchical Tool... | Yue Cui, Liuyi Yao, Shuchang Tao, Weijie Shi, Yaliang Li, Bolin Ding, Xiaofang Zhou |  |
| 942 |  |  [A Large and Balanced Corpus for Fine-grained Arabic Readability Assessment](https://aclanthology.org/2025.findings-acl.842/) |  | 0 | This paper introduces the Balanced Arabic Readability Evaluation Corpus (BAREC), a large-scale, fine-grained dataset for Arabic readability assessment. BAREC consists of 69,441 sentences spanning 1+ million words, carefully curated to cover 19 readability levels, from kindergarten to postgraduate... | Khalid N. Elmadani, Nizar Habash, Hanada TahaThomure |  |
| 943 |  |  [Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?](https://aclanthology.org/2025.findings-acl.843/) |  | 0 | Medical Vision-Language Pre-training (MedVLP) has made significant progress in enabling zero-shot tasks for medical image understanding. However, training MedVLP models typically requires large-scale datasets with paired, high-quality image-text data, which are scarce in the medical domain. Recent... | Che Liu, Zhongwei Wan, Haozhe Wang, Yinda Chen, Talha Qaiser, Chen Jin, Nikolay Burlutskiy, Fariba Yousefi, Rossella Arcucci |  |
| 944 |  |  [See the World, Discover Knowledge: A Chinese Factuality Evaluation for Large Vision Language Models](https://aclanthology.org/2025.findings-acl.844/) |  | 0 | The evaluation of factual accuracy in large vision language models (LVLMs) has lagged behind their rapid development, making it challenging to fully reflect these models’ knowledge capacity and reliability. In this paper, we introduce the first factuality-based visual question-answering benchmark... | Jihao Gu, Yingyao Wang, Pi Bu, Chen Wang, Ziming Wang, Tengtao Song, Donglai Wei, Jiale Yuan, Yingxiu Zhao, Yancheng He, Shilong Li, Jiaheng Liu, Meng Cao, Jun Song, Yingshui Tan, Xiang Li, Wenbo Su, Xiaoyong Zhu, Bo Zheng |  |
| 945 |  |  [Argus: Benchmarking and Enhancing Vision-Language Models for 3D Radiology Report Generation](https://aclanthology.org/2025.findings-acl.845/) |  | 0 | Automatic radiology report generation holds significant potential to streamline the labor-intensive process of report writing by radiologists, particularly for 3D radiographs such as CT scans. While CT scans are critical for clinical diagnostics, they remain less explored compared to 2D... | Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci |  |
| 946 |  |  [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://aclanthology.org/2025.findings-acl.846/) |  | 0 | Knowledge-intensive multi-hop question answering (QA) tasks, which require integrating evidence from multiple sources to address complex queries, often necessitate multiple rounds of retrieval and iterative generation by large language models (LLMs). However, incorporating many documents and... | Binquan Ji, Haibo Luo, YifeiLu YifeiLu, Lei Hei, Jiaqi Wang, Tingjing Liao, Lingyu Wang, Shichao Wang, Feiliang Ren |  |
| 947 |  |  [Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization](https://aclanthology.org/2025.findings-acl.847/) |  | 0 | With the rapid development of large language models (LLMs), LLM-as-a-judge has emerged as a widely adopted approach for text quality evaluation, including hallucination evaluation. While previous studies have focused exclusively on single-context evaluation (e.g., discourse faithfulness or world... | Siya Qi, Rui Cao, Yulan He, Zheng Yuan |  |
| 948 |  |  [TUBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning](https://aclanthology.org/2025.findings-acl.848/) |  | 0 | The implications of backdoor attacks on English-centric large language models (LLMs) have been widely examined — such attacks can be achieved by embedding malicious behaviors during training and activated under specific conditions that trigger malicious outputs. Despite the increasing support for... | Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn |  |
| 949 |  |  [Eliciting Textual Descriptions from Representations of Continuous Prompts](https://aclanthology.org/2025.findings-acl.849/) |  | 0 | Continuous prompts, or “soft prompts”, are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature. Prior attempts to interpret continuous prompts relied on projecting individual prompt tokens onto the vocabulary space.... | Daniela Gottesman, Mor Geva, Dana Ramati |  |
| 950 |  |  [Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization](https://aclanthology.org/2025.findings-acl.850/) |  | 0 | Multimodal Large Language Models (MLLMs) are known to hallucinate, which limits their practical applications. Recent works have attempted to apply Direct Preference Optimization (DPO) to enhance the performance of MLLMs, but have shown inconsistent improvements in mitigating hallucinations. To... | Yuhan Fu, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Xirong Li |  |
| 951 |  |  [Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models](https://aclanthology.org/2025.findings-acl.851/) |  | 0 | The effectiveness of large language models (LLMs) in conversational AI is hindered by their reliance on single-turn supervised fine-tuning (SFT) data, which limits contextual coherence in multi-turn dialogues. Existing methods for generating multi-turn dialogue data struggle to ensure both... | Jiangxu Wu, Cong Wang, Tianhuang Su, Jun Yang, Haozhi Lin, Chao Zhang, Ming Peng, Kai Shi, Songpan Yang, Binqing Pan, Zixian Li |  |
| 952 |  |  [Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic Analysis](https://aclanthology.org/2025.findings-acl.852/) |  | 0 | Large Language Models (LLMs) are valued for their strong performance across various tasks, but they also produce inaccurate or misleading outputs. Uncertainty Estimation (UE) quantifies the model’s confidence and helps users assess response reliability. However, existing UE methods have not been... | Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi |  |
| 953 |  |  [EuroVerdict: A Multilingual Dataset for Verdict Generation Against Misinformation](https://aclanthology.org/2025.findings-acl.853/) |  | 0 | Misinformation is a global issue that shapes public discourse, influencing opinions and decision-making across various domains. While automated fact-checking (AFC) has become essential in combating misinformation, most work in multilingual settings has focused on claim verification rather than... | Daniel Russo, Fariba Sadeghi, Stefano Menini, Marco Guerini |  |
| 954 |  |  [LoFTI: Localization and Factuality Transfer to Indian Locales](https://aclanthology.org/2025.findings-acl.854/) |  | 0 | Large language models (LLMs) encode vast amounts of world knowledge acquired via training on large web-scale datasets crawled from the internet. However, the datasets used to train the LLMs typically exhibit a geographical bias towards English-speaking Western countries. This results in LLMs... | Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi |  |
| 955 |  |  [Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents](https://aclanthology.org/2025.findings-acl.855/) |  | 0 | Retrieval-augmented generation (RAG) based large language models (LLMs) are widely used in finance for their excellent performance on knowledge-intensive tasks. However, standardized documents (e.g., SEC filing) share similar formats such as repetitive boilerplate texts,and similar table... | Jaeyoung Choe, Jihoon Kim, Woohwan Jung |  |
| 956 |  |  [GNN-RAG: Graph Neural Retrieval for Efficient Large Language Model Reasoning on Knowledge Graphs](https://aclanthology.org/2025.findings-acl.856/) |  | 0 | Retrieval-augmented generation (RAG) in Knowledge Graph Question Answering (KGQA) enhances the context of Large Language Models (LLMs) by incorporating information retrieved from the Knowledge Graph (KG). Most recent approaches rely on costly LLM calls to generate executable relation paths or... | Costas Mavromatis, George Karypis |  |
| 957 |  |  [ASTRID - An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems](https://aclanthology.org/2025.findings-acl.857/) |  | 0 | Large Language Models (LLMs) have shown impressive potential in clinical question answering (QA), with Retrieval Augmented Generation (RAG) emerging as a leading approach for ensuring the factual accuracy of model responses. However, current automated RAG metrics perform poorly in clinical and... | Yajie Vera He, Mohita Chowdhury, Jared Joselowitz, Aisling Higham, Ernest Lim |  |
| 958 |  |  [On Entity Identification in Language Models](https://aclanthology.org/2025.findings-acl.858/) |  | 0 | We analyze the extent to which internal representations of language models (LMs) identify and distinguish mentions of named entities, focusing on the many-to-many correspondence between entities and their mentions.We first formulate two problems of entity mentions — ambiguity and variability — and... | Masaki Sakata, Benjamin Heinzerling, Sho Yokoi, Takumi Ito, Kentaro Inui |  |
| 959 |  |  [RAPID: Efficient Retrieval-Augmented Long Text Generation with Writing Planning and Information Discovery](https://aclanthology.org/2025.findings-acl.859/) |  | 0 | Generating knowledge-intensive and comprehensive long texts, such as encyclopedia articles, remains significant challenges for Large Language Models. It requires not only the precise integration of facts but also the maintenance of thematic coherence throughout the article. Existing methods, such... | Hongchao Gu, Dexun Li, Kuicai Dong, Hao Zhang, Hang Lv, Hao Wang, Defu Lian, Yong Liu, Enhong Chen |  |
| 960 |  |  [CHARPEVAL: Benchmarking Large Language Models' Contextual Reasoning in Knowledge-Grounded Dialogue](https://aclanthology.org/2025.findings-acl.860/) |  | 0 | This paper presents CHARPEVAL, a challenging benchmark specifically designed to evaluate the ability of Large Language Models (LLMs) to perform contextualized reasoning in knowledge-grounded dialogue scenarios. The task involves selecting the correct response from 6 options, including 5 manually... | Abbas Ghaddar, David AlfonsoHermelo, Philippe Langlais, Boxing Chen, Prasanna Parthasarathi |  |
| 961 |  |  [Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.861/) |  | 0 | Large Language Models (LLMs) suffer from hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external dynamic information for improved factual grounding. With advances in multimodal learning,... | Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari |  |
| 962 |  |  [Debate4MATH: Multi-Agent Debate for Fine-Grained Reasoning in Math](https://aclanthology.org/2025.findings-acl.862/) |  | 0 | Large language models (LLMs) have demonstrated impressive performance in reasoning. However, existing data annotation methods usually suffer from high annotation cost and the lack of effective automatic validation. To address these issues, we propose a Fine-grained Multi-Agent Debate framework... | Shaowei Zhang, Deyi Xiong |  |
| 963 |  |  [Disambiguate First, Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing](https://aclanthology.org/2025.findings-acl.863/) |  | 0 | Handling ambiguity and underspecification is an important challenge in natural language interfaces, particularly for tasks like text-to-SQL semantic parsing. We propose a modular approach that resolves ambiguity using natural language interpretations before mapping these to logical forms (e.g., SQL... | Irina Saparina, Mirella Lapata |  |
| 964 |  |  [The Anatomy of Evidence: An Investigation Into Explainable ICD Coding](https://aclanthology.org/2025.findings-acl.864/) |  | 0 | Automatic medical coding has the potential to ease documentation and billing processes. For this task, transparency plays an important role for medical coders and regulatory bodies, which can be achieved using explainability methods. However, the evaluation of these approaches has been mostly... | Katharina Beckh, Elisa Studeny, Sujan Sai Gannamaneni, Dario Antweiler, Stefan Rüping |  |
| 965 |  |  [AVG-LLaVA: An Efficient Large Multimodal Model with Adaptive Visual Granularity](https://aclanthology.org/2025.findings-acl.865/) |  | 0 | Recently, large multimodal models (LMMs) have achieved significant advancements. When dealing with high-resolution images, dominant LMMs typically divide them into multiple local images and a global image, leading to a large number of visual tokens. In this work, we introduce AVG-LLaVA, an LMM that... | Zhibin Lan, Liqiang Niu, Fandong Meng, Wenbo Li, Jie Zhou, Jinsong Su |  |
| 966 |  |  [Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia](https://aclanthology.org/2025.findings-acl.866/) |  | 0 | Human readers can efficiently comprehend scrambled words, a phenomenon known as Typoglycemia, primarily by relying on word form; if word form alone is insufficient, they further utilize contextual cues for interpretation. While advanced large language models (LLMs) exhibit similar abilities, the... | Chenxi Wang, Tianle Gu, Zhongyu Wei, Lang Gao, Zirui Song, Xiuying Chen |  |
| 967 |  |  [LLM-based Translation Inference with Iterative Bilingual Understanding](https://aclanthology.org/2025.findings-acl.867/) |  | 0 | The remarkable understanding and generation capabilities of large language models (LLMs) have greatly improved translation performance. However, incorrect understanding of the sentence to be translated can degrade translation quality. To address this issue, we proposed a novel Iterative Bilingual... | Andong Chen, Kehai Chen, Yang Xiang, Xuefeng Bai, Muyun Yang, Yang Feng, Tiejun Zhao, Min Zhang |  |
| 968 |  |  [Vulnerability of Text-to-Image Models to Prompt Template Stealing: A Differential Evolution Approach](https://aclanthology.org/2025.findings-acl.868/) |  | 0 | Prompt trading has emerged as a significant intellectual property concern in recent years, where vendors entice users by showcasing sample images before selling prompt templates that can generate similar images. This work investigates a critical security vulnerability: attackers can steal prompt... | Yurong Wu, Fangwen Mu, Qiuhong Zhang, Jinjing Zhao, Xinrun Xu, Lingrui Mei, Yang Wu, Lin Shi, Junjie Wang, Zhiming Ding, Yiwei Wang |  |
| 969 |  |  [mStyleDistance: Multilingual Style Embeddings and their Evaluation](https://aclanthology.org/2025.findings-acl.869/) |  | 0 | Style embeddings are useful for stylistic analysis and style transfer, yet they only exist for English. We introduce Multilingual StyleDistance (mStyleDistance), a method that can generate style embeddings in new languages using synthetic data and a contrastive loss. We create style embeddings in... | Justin Qiu, Jiacheng Zhu, Ajay Patel, Marianna Apidianaki, Chris CallisonBurch |  |
| 970 |  |  [SeqMMR: Sequential Model Merging and LLM Routing for Enhanced Batched Sequential Knowledge Editing](https://aclanthology.org/2025.findings-acl.870/) |  | 0 | Model knowledge editing enables the efficient correction of erroneous information and the continuous updating of outdated knowledge within language models. While existing research has demonstrated strong performance in single-instance or few-instance sequential editing and one-time massive editing... | Shanbao Qiao, Xuebing Liu, Akshat Gupta, SeungHoon Na |  |
| 971 |  |  [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://aclanthology.org/2025.findings-acl.871/) |  | 0 | We present a novel pipeline, ReflectEvo, to demonstrate that small language models (SLMs) can enhance meta introspection through reflection learning. This process iteratively generates self-reflection for self-training, fostering a continuous and self-evolving process. Leveraging this pipeline, we... | Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng |  |
| 972 |  |  [MAGIC-VQA: Multimodal And Grounded Inference with Commonsense Knowledge for Visual Question Answering](https://aclanthology.org/2025.findings-acl.872/) |  | 0 | Visual Question Answering (VQA) necessitates models to reason effectively across visual and textual modalities. However, existing Large Vision-Language Models (LVLMs) often fall short in achieving human-like reasoning due to a lack of integrated commonsense knowledge, limiting their robustness and... | Shuo Yang, Caren Han, Siwen Luo, Eduard H. Hovy |  |
| 973 |  |  [Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models](https://aclanthology.org/2025.findings-acl.873/) |  | 0 | LLM providers typically offer multiple LLM tiers, varying in performance and price. As NLP tasks become more complex and modularized, selecting the suitable LLM tier for each subtask is a key challenge to balance between cost and performance. To address the problem, we introduce LLM Automatic... | Injae Na, Keonwoong Noh, Woohwan Jung |  |
| 974 |  |  [Low-Rank Interconnected Adaptation across Layers](https://aclanthology.org/2025.findings-acl.874/) |  | 0 | Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning (PEFT) method that learns weight updates 𝛥 W = AB for pretrained weights W through low-rank adapters A and B. While LoRA ensures hardware efficiency, its low-rank weight updates limit adaptation performance. In this paper,... | Yibo Zhong, Jinman Zhao, Yao Zhou |  |
| 975 |  |  [GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation](https://aclanthology.org/2025.findings-acl.875/) |  | 0 | We present GaRAGe, a large RAG benchmark with human-curated long-form answers and annotations of each grounding passage, allowing a fine-grained evaluation of whether LLMs can identify relevant grounding when generating RAG answers. Our benchmark contains 2366 questions of diverse complexity,... | IonutTeodor Sorodoc, Leonardo F. R. Ribeiro, Rexhina Blloshmi, Christopher Davis, Adrià de Gispert |  |
| 976 |  |  [Change Entity-guided Heterogeneous Representation Disentangling for Change Captioning](https://aclanthology.org/2025.findings-acl.876/) |  | 0 | Change captioning aims to describe differences between a pair of images using natural language. However, learning effective difference representations is highly challenging due to distractors such as illumination and viewpoint changes. To address this, we propose a change-entity-guided... | Yi Li, Yunbin Tu, Liang Li, Li Su, Qingming Huang |  |
| 977 |  |  [RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment](https://aclanthology.org/2025.findings-acl.877/) |  | 0 | Despite the significant progress made by existing retrieval augmented language models (RALMs) in providing trustworthy responses and grounding in reliable sources, they often overlook effective alignment with human preferences. In the alignment process, reward models (RMs) act as a crucial proxy... | Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao |  |
| 978 |  |  [Generate, Discriminate, Evolve: Enhancing Context Faithfulness via Fine-Grained Sentence-Level Self-Evolution](https://aclanthology.org/2025.findings-acl.878/) |  | 0 | Improving context faithfulness in large language models is essential for developing trustworthy retrieval augmented generation systems and mitigating hallucinations, especially in long-form question answering (LFQA) tasks or scenarios involving knowledge conflicts. Existing methods either intervene... | Kun Li, Tianhua Zhang, Yunxiang Li, Hongyin Luo, Abdalla Mohamed Salama Sayed Moustafa, Xixin Wu, James R. Glass, Helen M. Meng |  |
| 979 |  |  [PAM: Paraphrase AMR-Centric Evaluation Metric](https://aclanthology.org/2025.findings-acl.879/) |  | 0 | Paraphrasing is rooted in semantics, which makes evaluating paraphrase generation systems hard. Current paraphrase generators are typically evaluated using borrowed metrics from adjacent text-to-text tasks, like machine translation or text summarization. These metrics tend to have ties to the... | Afonso Sousa, Henrique Lopes Cardoso |  |
| 980 |  |  [VP-MEL: Visual Prompts Guided Multimodal Entity Linking](https://aclanthology.org/2025.findings-acl.880/) |  | 0 | Multimodal entity linking (MEL), a task aimed at linking mentions within multimodal contexts to their corresponding entities in a knowledge base (KB), has attracted much attention due to its wide applications in recent years. However, existing MEL methods often rely on mention words as retrieval... | Hongze Mi, Jinyuan Li, Zhangxuying Zhangxuying, Haoran Cheng, Jiahao Wang, Di Sun, Gang Pan |  |
| 981 |  |  [FADE: Why Bad Descriptions Happen to Good Features](https://aclanthology.org/2025.findings-acl.881/) |  | 0 | Recent advances in mechanistic interpretability have highlighted the potential of automating interpretability pipelines in analyzing the latent representations within LLMs. While this may enhance our understanding of internal mechanisms, the field lacks standardized evaluation methods for assessing... | Bruno Puri, Aakriti Jain, Elena Golimblevskaia, Patrick Kahardipraja, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin |  |
| 982 |  |  [In the LLM era, Word Sense Induction remains unsolved](https://aclanthology.org/2025.findings-acl.882/) |  | 0 | In the absence of sense-annotated data, word sense induction (WSI) is a compelling alternative to word sense disambiguation, particularly in low-resource or domain-specific settings. In this paper, we emphasize methodological problems in current WSI evaluation. We propose an evaluation on a... | Anna Mosolova, Marie Candito, Carlos Ramisch |  |
| 983 |  |  [Navigating the Political Compass: Evaluating Multilingual LLMs across Languages and Nationalities](https://aclanthology.org/2025.findings-acl.883/) |  | 0 | Large Language Models (LLMs) have become ubiquitous in today’s technological landscape, boasting a plethora of applications, and even endangering human jobs in complex and creative fields. One such field is journalism: LLMs are being used for summarization, generation and even fact-checking.... | Chadi Helwe, Oana Balalau, Davide Ceolin |  |
| 984 |  |  [Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Audio-Language Models](https://aclanthology.org/2025.findings-acl.884/) |  | 0 | Adversarial audio attacks pose a significant threat to the growing use of large audio-language models (LALMs) in voice-based human-machine interactions. While existing research focused on model-specific adversarial methods, real-world applications demand a more generalizable and universal approach... | Wanqi Yang, Yanda Li, Meng Fang, Yunchao Wei, Ling Chen |  |
| 985 |  |  [Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models](https://aclanthology.org/2025.findings-acl.885/) |  | 0 | Small language models (SLMs) have become increasingly prominent in the deployment on edge devices due to their high efficiency and low computational cost. While researchers continue to advance the capabilities of SLMs through innovative training strategies and model compression techniques, the... | Sibo Yi, Tianshuo Cong, Xinlei He, Qi Li, Jiaxing Song |  |
| 986 |  |  [EMRs2CSP : Mining Clinical Status Pathway from Electronic Medical Records](https://aclanthology.org/2025.findings-acl.886/) |  | 0 | Many current studies focus on extracting tests or treatments when constructing clinical pathways, often neglecting the patient’s symptoms and diagnosis, leading to incomplete diagnostic and therapeutic logic. Therefore, this paper aims to extract clinical pathways from electronic medical records... | Yifei Chen, Ruihui Hou, Jingping Liu, Tong Ruan |  |
| 987 |  |  [A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences](https://aclanthology.org/2025.findings-acl.887/) |  | 0 | While progress has been made in legal applications, law reasoning, crucial for fair adjudication, remains unexplored. We propose a transparent law reasoning schema enriched with hierarchical factum probandum, evidence, and implicit experience, enabling public scrutiny and preventing bias. Inspired... | Jiaxin Shen, Jinan Xu, Huiqi Hu, Luyi Lin, Guoyang Ma, Fei Zheng, Fandong Meng, Jie Zhou, Wenjuan Han |  |
| 988 |  |  [Libra: Leveraging Temporal Images for Biomedical Radiology Analysis](https://aclanthology.org/2025.findings-acl.888/) |  | 0 | Radiology report generation (RRG) requires advanced medical image analysis, effective temporal reasoning, and accurate text generation. While multimodal large language models (MLLMs) align with pre-trained vision encoders to enhance visual-language understanding, most existing methods rely on... | Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho |  |
| 989 |  |  [Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach](https://aclanthology.org/2025.findings-acl.889/) |  | 0 | Bias and stereotypes in language models can cause harm, especially in sensitive areas like content moderation and decision-making. This paper addresses bias and stereotype detection by exploring how jointly learning these tasks enhances model performance. We introduce StereoBias, a unique dataset... | Aditya Tomar, V. Rudra Murthy, Pushpak Bhattacharyya |  |
| 990 |  |  [Filling the Temporal Void: Recovering Missing Publication Years in the Project Gutenberg Corpus Using LLMs](https://aclanthology.org/2025.findings-acl.890/) |  | 0 | Analysing texts spanning long periods of time is critical for researchers in historical linguistics and related disciplines. However, publicly available corpora suitable for such analyses are scarce. The Project Gutenberg (PG) corpus presents a significant yet underutilized opportunity in this... | Omar Momen, Manuel Schaaf, Alexander Mehler |  |
| 991 |  |  [ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.891/) |  | 0 | Large Language Models (LLMs) are increasingly used in tasks requiring interpretive and inferential accuracy. In this paper, we introduce ExpliCa, a new dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely integrates both causal and temporal relations presented in different... | Martina Miliani, Serena Auriemma, Alessandro Bondielli, Emmanuele Chersoni, Lucia C. Passaro, Irene Sucameli, Alessandro Lenci |  |
| 992 |  |  [Are Dialects Better Prompters? A Case Study on Arabic Subjective Text Classification](https://aclanthology.org/2025.findings-acl.892/) |  | 0 | This paper investigates the effect of dialectal prompting, variations in prompting scrip t and model fine-tuning on subjective classification in Arabic dialects. To this end, we evaluate the performances of 12 widely used open LLMs across four tasks and eight benchmark datasets. Our results reveal... | Leila Moudjari, Farah Benamara |  |
| 993 |  |  [Natural Logic at the Core: Dynamic Rewards for Entailment Tree Generation](https://aclanthology.org/2025.findings-acl.893/) |  | 0 | Entailment trees are essential for enhancing interpretability and transparency in tasks like question answering and natural language understanding. However, existing approaches often lack logical consistency, as they rely on static reward structures or ignore the intricate dependencies within... | Jihao Shi, Xiao Ding, Kai Xiong, Hengwei Zhao, Bing Qin, Ting Liu |  |
| 994 |  |  [R.R.: Unveiling LLM Training Privacy through Recollection and Ranking](https://aclanthology.org/2025.findings-acl.894/) |  | 0 | Large Language Models (LLMs) pose significant privacy risks, potentially leaking training data due to implicit memorization. Existing privacy attacks primarily focus on membership inference attacks (MIAs) or data extraction attacks, but reconstructing specific personally identifiable information... | Wenlong Meng, Guo Zhenyuan, Lenan Wu, Chen Gong, Wenyan Liu, Weixian Li, Chengkun Wei, Wenzhi Chen |  |
| 995 |  |  [Nested-Refinement Metamorphosis: Reflective Evolution for Efficient Optimization of Networking Problems](https://aclanthology.org/2025.findings-acl.895/) |  | 0 | Large Language Models (LLMs) excel in network algorithm design but suffer from inefficient iterative coding and high computational costs. Drawing inspiration from butterfly metamorphosis—where structured developmental phases (Phase I: larval nutrient accumulation → Phase II: pupal transformation)... | Shuhan Guo, Nan Yin, James Kwok, Quanming Yao |  |
| 996 |  |  [MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency](https://aclanthology.org/2025.findings-acl.896/) |  | 0 | Multimodal large language models (MLLMs) are prone to non-factual or outdated knowledge issues, highlighting the importance of knowledge editing. Many benchmark has been proposed for researching multimodal knowledge editing. However, previous benchmarks focus on limited scenarios due to the lack of... | Junzhe Zhang, Huixuan Zhang, Xunjian Yin, Baizhou Huang, Xu Zhang, Xinyu Hu, Xiaojun Wan |  |
| 997 |  |  [Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference Optimisation of Large Language Models](https://aclanthology.org/2025.findings-acl.897/) |  | 0 | Fine-tuning Large Language Models (LLMs) with first-order methods like back-propagation is computationally intensive. Zeroth-Order (ZO) optimisation uses function evaluations instead of gradients, reducing memory usage, but suffers from slow convergence in high-dimensional models. As a result, ZO... | Alessio Galatolo, Zhenbang Dai, Katie Winkle, Meriem Beloucif |  |
| 998 |  |  [Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding](https://aclanthology.org/2025.findings-acl.898/) |  | 0 | This paper presents a comprehensive evaluation of the capabilities of Large Language Models (LLMs) in metaphor interpretation across multiple datasets, tasks, and prompt configurations. Although metaphor processing has gained significant attention in Natural Language Processing (NLP), previous... | Elisa SanchezBayona, Rodrigo Agerri |  |
| 999 |  |  [AskQE: Question Answering as Automatic Evaluation for Machine Translation](https://aclanthology.org/2025.findings-acl.899/) |  | 0 | How can a monolingual English speaker determine whether an automatic translation in French is good enough to be shared? Existing MT error detection and quality estimation (QE) techniques do not address this practical scenario. We introduce AskQE, a question generation and answering framework... | Dayeon Ki, Kevin Duh, Marine Carpuat |  |
| 1000 |  |  [ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation](https://aclanthology.org/2025.findings-acl.900/) |  | 0 | Evaluating personalized text generated by large language models (LLMs) is challenging, as only the LLM user, i.e. prompt author, can reliably assess the output, but re-engaging the same individuals across studies is infeasible. This paper addresses the challenge of evaluating personalized text... | Alireza Salemi, Julian Killingback, Hamed Zamani |  |
| 1001 |  |  [Bridging Intuitive Associations and Deliberate Recall: Empowering LLM Personal Assistant with Graph-Structured Long-term Memory](https://aclanthology.org/2025.findings-acl.901/) |  | 0 | Large language models (LLMs)-based personal assistants may struggle to effectively utilize long-term conversational histories.Despite advances in long-term memory systems and dense retrieval methods, these assistants still fail to capture entity relationships and handle multiple intents... | Yujie Zhang, Weikang Yuan, Zhuoren Jiang |  |
| 1002 |  |  [Each graph is a new language: Graph Learning with LLMs](https://aclanthology.org/2025.findings-acl.902/) |  | 0 | Natural language has been extensively used for modeling text-attributed graphs with LLMs. Natural language is used to describe the graph for LLMs to understand or serve as component of the graph, e.g., textual attributes for embedding generation. However, natural language is inherently redundant... | Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang |  |
| 1003 |  |  [100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?](https://aclanthology.org/2025.findings-acl.903/) |  | 0 | Long-context capability is considered one of the most important abilities of LLMs, as a truly long context-capable LLM shall enable its users to effortlessly process many originally exhausting tasks — e.g., digesting a long-form document to find answers v.s., directly asking an LLM about it.... | Van Yang, Hongye Jin, Shaochen Zhong, Song Jiang, Qifan Wang, Vipin Chaudhary, Xiaotian Han |  |
| 1004 |  |  [Multimodal Fusion and Coherence Modeling for Video Topic Segmentation](https://aclanthology.org/2025.findings-acl.904/) |  | 0 | The video topic segmentation (VTS) task segments videos into intelligible, non-overlapping topics, facilitating efficient comprehension of video content and quick access to specific content. VTS is also critical to various downstream video understanding tasks. Traditional VTS methods using shallow... | Hai Yu, Chong Deng, Qinglin Zhang, Jiaqing Liu, Qian Chen, Wen Wang |  |
| 1005 |  |  [Are Your LLMs Capable of Stable Reasoning?](https://aclanthology.org/2025.findings-acl.905/) |  | 0 | The rapid advancement of large language models (LLMs) has shown remarkable progress in complex reasoning tasks. However, a significant disparity exists between benchmark performances and real-world applications. We attribute this gap primarily to current evaluation protocols and metrics, which... | Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen |  |
| 1006 |  |  [FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only](https://aclanthology.org/2025.findings-acl.906/) |  | 0 | Instruction tuning stands as a crucial advancement in leveraging large language models (LLMs) for enhanced task performance. However, the annotation of instruction datasets has traditionally been expensive and laborious, often relying on manual annotations or costly proprietary LLMs. Recent works... | He Zhu, Yifan Ding, Yicheng Tao, Zhiwen Ruan, Yixia Li, Wenjia Zhang, Yun Chen, Guanhua Chen |  |
| 1007 |  |  [JEBS: A Fine-grained Biomedical Lexical Simplification Task](https://aclanthology.org/2025.findings-acl.907/) |  | 0 | Though online medical literature has made health information more available than ever, the barrier of complex medical jargon prevents the general public from understanding it. Though parallel and comparable corpora for Biomedical Text Simplification have been introduced, these conflate the many... | William Xia, Ishita Unde, Brian David Ondov, Dina DemnerFushman |  |
| 1008 |  |  [Multi-Hop Reasoning for Question Answering with Hyperbolic Representations](https://aclanthology.org/2025.findings-acl.908/) |  | 0 | Hyperbolic representations are effective in modeling knowledge graph data which is prevalently used to facilitate multi-hop reasoning. However, a rigorous and detailed comparison of the two spaces for this task is lacking. In this paper, through a simple integration of hyperbolic representations... | Simon Welz, Lucie Flek, Akbar Karimi |  |
| 1009 |  |  [Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation](https://aclanthology.org/2025.findings-acl.909/) |  | 0 | Recent advancements in multimodal Large Language Models (LLMs) have significantly enhanced the automation of medical image analysis, particularly in generating radiology reports from chest X-rays (CXR). However, these models still suffer from hallucinations and clinically significant errors,... | Yunsoo Kim, Jinge Wu, Su Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu |  |
| 1010 |  |  [Hatevolution: What Static Benchmarks Don't Tell Us](https://aclanthology.org/2025.findings-acl.910/) |  | 0 | Language changes over time, including in the hate speech domain, which evolves quickly following social dynamics and cultural shifts. While NLP research has investigated the impact of language evolution on model training and has proposed several solutions for it, its impact on model benchmarking... | Chiara Di Bonaventura, Barbara McGillivray, Yulan He, Albert MeroñoPeñuela |  |
| 1011 |  |  [Tag-Instruct: Controlled Instruction Complexity Enhancement through Structure-based Augmentation](https://aclanthology.org/2025.findings-acl.911/) |  | 0 | High-quality instruction data is crucial for developing large language models (LLMs), yet existing approaches struggle to effectively control instruction complexity. We present Tag-Instruct, a novel framework that enhances instruction complexity through structured semantic compression and... | He Zhu, Zhiwen Ruan, Junyou Su, Xingwei He, Yun Chen, Wenjia Zhang, Guanhua Chen |  |
| 1012 |  |  [Code-SPA: Style Preference Alignment to Large Language Models for Effective and Robust Code Debugging](https://aclanthology.org/2025.findings-acl.912/) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities in coding tasks like code generation and debugging. However, code from real-world users is often poorly styled, containing various types of noise, such as structural inconsistencies, stylistic deviations and flawed test cases.... | Tengfei Wen, Xuanang Chen, Ben He, Le Sun |  |
| 1013 |  |  [Open-World Authorship Attribution](https://aclanthology.org/2025.findings-acl.913/) |  | 0 | Recent years have witnessed rapid advancements in Large Language Models (LLMs). Nevertheless, it remains unclear whether state-of-the-art LLMs can infer the author of an anonymous research paper solely from the text, without any additional information. To investigate this novel challenge, which we... | Xinhao Tan, Songhua Liu, Xia Cong, Kunjun Li, Xinchao Wang |  |
| 1014 |  |  [What is in a name? Mitigating Name Bias in Text Embedding Similarity via Anonymization](https://aclanthology.org/2025.findings-acl.914/) |  | 0 | Text-embedding models often exhibit biases arising from the data on which they are trained. In this paper, we examine a hitherto unexplored bias in text-embeddings: bias arising from the presence of names such as persons, locations, organizations etc. in the text. Our study shows how the presence... | Sahil Manchanda, Pannaga Shivaswamy |  |
| 1015 |  |  [BenNumEval: A Benchmark to Assess LLMs' Numerical Reasoning Capabilities in Bengali](https://aclanthology.org/2025.findings-acl.915/) |  | 0 | Large Language Models (LLMs) demonstrate exceptional proficiency in general-purpose tasks but struggle with numerical reasoning, particularly in low-resource languages like Bengali. Despite advancements, limited research has explored their numerical reasoning capabilities in these languages. To... | Kawsar Ahmed, Md Osama, Omar Sharif, Eftekhar Hossain, Mohammed Moshiul Hoque |  |
| 1016 |  |  [LLM Agents for Coordinating Multi-User Information Gathering](https://aclanthology.org/2025.findings-acl.916/) |  | 0 | This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated collaborative problem solving. Given a user request, PeopleJoin agents must identify teammates who might be able to assist, converse with these teammates to gather information, and finally compile a useful answer or summary... | Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme |  |
| 1017 |  |  [C2KD: Cross-layer and Cross-head Knowledge Distillation for Small Language Model-based Recommendation](https://aclanthology.org/2025.findings-acl.917/) |  | 0 | Sequential recommenders predict users’ next interactions based on historical behavior and are essential in modern recommendation systems. While Large Language Models (LLMs) show promise, their size and high inference costs limit deployment on resource-constrained devices. Small Language Models... | Xiao Chen, Changyi Ma, Wenqi Fan, Zhaoxiang Zhang, Qing Li |  |
| 1018 |  |  [Sign2Vis: Automated Data Visualization from Sign Language](https://aclanthology.org/2025.findings-acl.918/) |  | 0 | Data visualizations, such as bar charts and histograms, are essential for analyzing and exploring data, enabling the effective communication of insights. While existing methods have been proposed to translate natural language descriptions into visualization queries, they focus solely on spoken... | Yao Wan, Yang Wu, Zhen Li, Guobiao Zhang, Hongyu Zhang, Zhou Zhao, Hai Jin, April Wang |  |
| 1019 |  |  [Transparentize the Internal and External Knowledge Utilization in LLMs with Trustworthy Citation](https://aclanthology.org/2025.findings-acl.919/) |  | 0 | While hallucinations of large language models could be alleviated through retrieval-augmented generation and citation generation, how the model utilizes internal knowledge is still opaque, and the trustworthiness of its generated answers remains questionable. In this work, we introduce... | Jiajun Shen, Tong Zhou, Yubo Chen, Delai Qiu, Shengping Liu, Kang Liu, Jun Zhao |  |
| 1020 |  |  [JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse](https://aclanthology.org/2025.findings-acl.920/) |  | 0 | Recently, action-based decision-making in open-world environments has gained significant attention. Visual Language Action (VLA) models, pretrained on large-scale web datasets, have shown promise in decision-making tasks. However, previous work has primarily focused on action post-training, often... | Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang |  |
| 1021 |  |  [Generative Frame Sampler for Long Video Understanding](https://aclanthology.org/2025.findings-acl.921/) |  | 0 | Despite recent advances in Video Large Language Models (VideoLLMs), effectively understanding long-form videos remains a significant challenge. Perceiving lengthy videos containing thousands of frames poses substantial computational burden. To mitigate this issue, this paper introduces Generative... | Linli Yao, Haoning Wu, Kun Ouyang, Yuanxing Zhang, Caiming Xiong, Bei Chen, Xu Sun, Junnan Li |  |
| 1022 |  |  [Annotating the Annotators: Analysis, Insights and Modelling from an Annotation Campaign on Persuasion Techniques Detection](https://aclanthology.org/2025.findings-acl.922/) |  | 0 | Persuasion (or propaganda) techniques detection is a relatively novel task in Natural Language Processing (NLP). While there have already been a number of annotation campaigns, they have been based on heuristic guidelines, which have never been thoroughly discussed. Here, we present the first... | Davide Bassi, Dimitar Iliyanov Dimitrov, Bernardo D'Auria, Firoj Alam, Maram Hasanain, Christian Moro, Luisa Orrù, Gian Piero Turchi, Preslav Nakov, Giovanni Da San Martino |  |
| 1023 |  |  [On the Generalization vs Fidelity Paradox in Knowledge Distillation](https://aclanthology.org/2025.findings-acl.923/) |  | 0 | Knowledge distillation (KD) is a key technique for compressing large language models into smaller ones while preserving performance. Despite the recent traction of KD research, its effectiveness for smaller language models (LMs) and the mechanisms driving knowledge transfer remain underexplored. In... | Suhas Kamasetty Ramesh, Ayan Sengupta, Tanmoy Chakraborty |  |
| 1024 |  |  [BEDAA: Bayesian Enhanced DeBERTa for Uncertainty-Aware Authorship Attribution](https://aclanthology.org/2025.findings-acl.924/) |  | 0 | Authorship Attribution (AA) seeks to identify the author of a given text, yet existing methods often struggle with trustworthiness and interpretability, particularly across different domains, languages, and stylistic variations. These challenges arise from the absence of uncertainty quantification... | Iqra Zahid, Youcheng Sun, Riza BatistaNavarro |  |
| 1025 |  |  [Benchmarking the Benchmarks: Reproducing Climate-Related NLP Tasks](https://aclanthology.org/2025.findings-acl.925/) |  | 0 | Significant efforts have been made in the NLP community to facilitate the automatic analysis of climate-related corpora by tasks such as climate-related topic detection, climate risk classification, question answering over climate topics, and many more. In this work, we perform a reproducibility... | Tom Calamai, Oana Balalau, Fabian M. Suchanek |  |
| 1026 |  |  [Exploring Supervised Approaches to the Detection of Anthropomorphic Language in the Reporting of NLP Venues](https://aclanthology.org/2025.findings-acl.926/) |  | 0 | We investigate the prevalence of anthropomorphic language in the reporting of AI technology, focussed on NLP and LLMs. We undertake a corpus annotation focussing on one year of ACL long-paper abstracts and news articles from the same period. We find that 74% of ACL abstracts and 88% of news... | Matthew Shardlow, Ashley Williams, Charlie Roadhouse, Filippos Ventirozos, Piotr Przybyla |  |
| 1027 |  |  [PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants](https://aclanthology.org/2025.findings-acl.927/) |  | 0 | Large language models (LLMs) have advanced conversational AI assistants. However, systematically evaluating how well these assistants apply personalization—adapting to individual user preferences while completing tasks—remains challenging. Existing personalization benchmarks focus on chit-chat,... | Zheng Zhao, Clara Vania, Subhradeep Kayal, Naila Khan, Shay B. Cohen, Emine Yilmaz |  |
| 1028 |  |  [iAgent: LLM Agent as a Shield between User and Recommender Systems](https://aclanthology.org/2025.findings-acl.928/) |  | 0 | Traditional recommender systems usually take the user-platform paradigm, where users are directly exposed under the control of the platform’s recommendation algorithms. However, the defect of recommendation algorithms may put users in very vulnerable positions under this paradigm. First, many... | Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang |  |
| 1029 |  |  [FactLens: Benchmarking Fine-Grained Fact Verification](https://aclanthology.org/2025.findings-acl.929/) |  | 0 | Large Language Models (LLMs) have shown impressive capability in language generation and understanding, but their tendency to hallucinate and produce factually incorrect information remains a key limitation. To verify LLM-generated contents and claims from other sources, traditional verification... | Kushan Mitra, Dan Zhang, Sajjadur Rahman, Estevam Hruschka |  |
| 1030 |  |  [Process-based Self-Rewarding Language Models](https://aclanthology.org/2025.findings-acl.930/) |  | 0 | Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs’ performance, which is constrained by the upper limit of human... | Shimao Zhang, Xiao Liu, Xin Zhang, Junxiao Liu, Zheheng Luo, Shujian Huang, Yeyun Gong |  |
| 1031 |  |  [The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks](https://aclanthology.org/2025.findings-acl.931/) |  | 0 | Translation-based strategies for cross-lingual transfer XLT such as translate-train—training on noisy target language data translated from the source language—and translate-test—evaluating on noisy source language data translated from the target language—are competitive XLT baselines. In XLT for... | Benedikt Ebing, Goran Glavas |  |
| 1032 |  |  [ShieldHead: Decoding-time Safeguard for Large Language Models](https://aclanthology.org/2025.findings-acl.932/) |  | 0 | In light of the widespread deployment of Large Language Models (LLMs), the responsibility for safeguarding and regulating LLM-generated content has taken on heightened significance. Recent advancements in LLM-based moderation methods, e.g., LlamaGuard, have demonstrated remarkable promise in... | Zitao Xuan, Xiaofeng Mao, Da Chen, Xin Zhang, Yuhan Dong, Jun Zhou |  |
| 1033 |  |  [A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models](https://aclanthology.org/2025.findings-acl.933/) |  | 0 | The widespread deployment of large language models (LLMs) across critical domains has amplified the societal risks posed by algorithmically generated misinformation. Unlike traditional false content, LLM-generated misinformation can be self-reinforcing, highly plausible, and capable of rapid... | Shuliang Liu, Hongyi Liu, Aiwei Liu, Bingchen Duan, Zheng Qi, Yibo Yan, He Geng, Peijie Jiang, Jia Liu, Xuming Hu |  |
| 1034 |  |  [Smotrom tvoja på ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study](https://aclanthology.org/2025.findings-acl.934/) |  | 0 | Russenorsk, a pidgin language historically used in trade interactions between Russian and Norwegian speakers, represents a unique linguistic phenomenon. In this paper, we attempt to analyze its lexicon using modern large language models (LLMs), based on surviving literary sources. We construct a... | Alexey Tikhonov, Sergei Shteiner, Anna Bykova, Ivan P. Yamshchikov |  |
| 1035 |  |  [PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.935/) |  | 0 | The ability of large language models to solve complex mathematical problems has progressed significantly, particularly for tasks requiring advanced reasoning. However, the scarcity of sufficiently challenging problems, particularly at the Olympiad level, hinders further advancements. In this work,... | Xueliang Zhao, Wei Wu, Jian Guan, Lingpeng Kong |  |
| 1036 |  |  [Speculative Sampling via Exponential Races](https://aclanthology.org/2025.findings-acl.936/) |  | 0 | Speculative decoding accelerates large language model inference using a smaller draft model. In this paper, we establish a surprising connection between speculative sampling and the concept of channel simulation from information theory, which aims at simulating a noisy channel using as few bits as... | Szymon Kobus, Deniz Gündüz |  |
| 1037 |  |  [Going Beyond Your Expectations in Latency Metrics for Simultaneous Speech Translation](https://aclanthology.org/2025.findings-acl.937/) |  | 0 | Current evaluation practices in Simultaneous Speech Translation (SimulST) systems typically involve segmenting the input audio and corresponding translations, calculating quality and latency metrics for each segment, and averaging the results. Although this approach may provide a reliable... | Jorge IranzoSánchez, Javier IranzoSánchez, Adrià Giménez, Jorge Civera |  |
| 1038 |  |  [Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents](https://aclanthology.org/2025.findings-acl.938/) |  | 0 | Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks. However, evaluating RPAs is challenging due to diverse task requirements and agent designs.This paper proposes an evidence-based, actionable, and generalizable evaluation... | Chaoran Chen, Bingsheng Yao, Ruishi Zou, Wenyue Hua, Weimin Lyu, Toby JiaJun Li, Dakuo Wang |  |
| 1039 |  |  [Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data](https://aclanthology.org/2025.findings-acl.939/) |  | 0 | Question answering over mixed sources, like text and tables, has been advanced by verbalizing all contents and encoding it with a language model. A prominent case of such heterogeneous data is personal information: user devices log vast amounts of data every day, such as calendar entries, workout... | Philipp Christmann, Gerhard Weikum |  |
| 1040 |  |  [PreSumm: Predicting Summarization Performance Without Summarizing](https://aclanthology.org/2025.findings-acl.940/) |  | 0 | Despite recent advancements in automatic summarization, state-of-the-art models do not summarize all documents equally well, raising the question: why? While prior research has extensively analyzed summarization models, little attention has been given to the role of document characteristics in... | Steven Koniaev, Ori Ernst, Jackie CK Cheung |  |
| 1041 |  |  [Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases](https://aclanthology.org/2025.findings-acl.941/) |  | 0 | Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and existing... | Yongjia Lei, Haoyu Han, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka, Mahantesh M. Halappanavar, Jiliang Tang, Yu Wang |  |
| 1042 |  |  [Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion](https://aclanthology.org/2025.findings-acl.942/) |  | 0 | Language models (LMs) can make a correct prediction based on many possible signals in a prompt, not all corresponding to recall of factual associations. However, current interpretations of LMs fail to take this into account. For example, given the query “Astrid Lindgren was born in” with the... | Denitsa Saynova, Lovisa Hagström, Moa Johansson, Richard Johansson, Marco Kuhlmann |  |
| 1043 |  |  [FPE2M2: Approaching Lossless and Efficient Quantization with Native Floating Point](https://aclanthology.org/2025.findings-acl.943/) |  | 0 | Auto-regressive decoding is a memory-bound job, meaning decoding inference performance is limited by the bandwidth rather than the computational capabilities of the GPU. Weight-only quantization is a promising method to address the memory-bound limitations. Previous studies have followed one of two... | Ke Yi, Jianwei Zhang, Zhiying Xu, Xinlong Yang, Yang Zhou, Minmin Sun, Zengke Liu, Tong Zhang, Junyang Lin, Jingren Zhou |  |
| 1044 |  |  [Asymmetric Conflict and Synergy in Post-training for LLM-based Multilingual Machine Translation](https://aclanthology.org/2025.findings-acl.944/) |  | 0 | The emergence of Large Language Models (LLMs) has advanced the multilingual machine translation (MMT), yet the Curse of Multilinguality (CoM) remains a major challenge. Existing work in LLM-based MMT typically mitigates this issue via scaling up training and computation budget, which raises a... | Tong Zheng, Yan Wen, Huiwen Bao, Junfeng Guo, Heng Huang |  |
| 1045 |  |  [VISIAR: Empower MLLM for Visual Story Ideation](https://aclanthology.org/2025.findings-acl.945/) |  | 0 | Ideation, the process of forming ideas from concepts, is a big part of the content creation process. However, the noble goal of helping visual content creators by suggesting meaningful sequences of visual assets from a limited collection is challenging. It requires a nuanced understanding of visual... | Zhaoyang Xia, Somdeb Sarkhel, Md. Mehrab Tanjim, Stefano Petrangeli, Ishita Dasgupta, Yuxiao Chen, Jinxuan Xu, Di Liu, Saayan Mitra, Dimitris N. Metaxas |  |
| 1046 |  |  [Same Company, Same Signal: The Role of Identity in Earnings Call Transcripts](https://aclanthology.org/2025.findings-acl.946/) |  | 0 | Post-earnings volatility prediction is critical for investors, with previous works often leveraging earnings call transcripts under the assumption that their rich semantics contribute significantly. To further investigate how transcripts impact volatility, we introduce DEC, a dataset featuring... | Ding Yu, Zhuo Liu, Hangfeng He |  |
| 1047 |  |  [Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems](https://aclanthology.org/2025.findings-acl.947/) |  | 0 | The NLP research community has made publicly available numerous instruments for measuring representational harms caused by large language model (LLM)-based systems. These instruments have taken the form of datasets, metrics, tools, and more. In this paper, we examine the extent to which such... | Emma Harvey, Emily Sheng, Su Lin Blodgett, Alexandra Chouldechova, Jean GarciaGathright, Alexandra Olteanu, Hanna M. Wallach |  |
| 1048 |  |  [Mind the (Belief) Gap: Group Identity in the World of LLMs](https://aclanthology.org/2025.findings-acl.948/) |  | 0 | Social biases and belief-driven behaviors can significantly impact Large Language Models’ (LLMs’) decisions on several tasks. As LLMs are increasingly used in multi-agent systems for societal simulations, their ability to model fundamental group psychological characteristics remains critical yet... | Angana Borah, Marwa Houalla, Rada Mihalcea |  |
| 1049 |  |  [A General Framework to Enhance Fine-tuning-based LLM Unlearning](https://aclanthology.org/2025.findings-acl.949/) |  | 0 | Unlearning has been proposed to remove copyrighted and privacy-sensitive data from Large Language Models (LLMs). Existing approaches primarily rely on fine-tuning-based methods, which can be categorized into gradient ascent-based (GA-based) and suppression-based methods. However, they often degrade... | Jie Ren, Zhenwei Dai, Xianfeng Tang, Hui Liu, Jingying Zeng, Zhen Li, Rahul Goutam, Suhang Wang, Yue Xing, Qi He |  |
| 1050 |  |  [Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering](https://aclanthology.org/2025.findings-acl.950/) |  | 0 | One of the most widely used tasks for evaluating Large Language Models (LLMs) is Multiple-Choice Question Answering (MCQA). While open-ended question answering tasks are more challenging to evaluate, MCQA tasks are, in principle, easier to assess, as the model’s answer is thought to be simple to... | Francesco Maria Molfese, Luca Moroni, Luca Gioffrè, Alessandro Scirè, Simone Conia, Roberto Navigli |  |
| 1051 |  |  [Machine Theory of Mind Needs Machine Validation](https://aclanthology.org/2025.findings-acl.951/) |  | 0 | In the last couple years, there has been a flood of interest in studying the extent to which language models (LMs) have a theory of mind (ToM) — the ability to ascribe mental states to themselves and others. The results provide an unclear picture of the current state of the art, with some finding... | Adil Soubki, Owen Rambow |  |
| 1052 |  |  [MiniKV: Pushing the Limits of 2-Bit KV Cache via Compression and System Co-Design for Efficient Long Context Inference](https://aclanthology.org/2025.findings-acl.952/) |  | 0 | State-of-the-art 2-bit KV cache quantization techniques achieve excellent results in accelerating LLM inference while retaining accuracy on long context tasks. However, further pushing the compression ratio fails to deliver performance gains. In this work, we revisit these approaches by... | Akshat Sharma, Hangliang Ding, Jianping Li, Neel Dani, Minjia Zhang |  |
| 1053 |  |  [Sci-LoRA: Mixture of Scientific LoRAs for Cross-Domain Lay Paraphrasing](https://aclanthology.org/2025.findings-acl.953/) |  | 0 | Lay paraphrasing aims to make scientific information accessible to audiences without technical backgrounds. However, most existing studies focus on a single domain, such as biomedicine. With the rise of interdisciplinary research, it is increasingly necessary to comprehend knowledge spanning... | Ming Cheng, Jiaying Gong, Hoda Eldardiry |  |
| 1054 |  |  [Trick or Neat: Adversarial Ambiguity and Language Model Evaluation](https://aclanthology.org/2025.findings-acl.954/) |  | 0 | Detecting ambiguity is important for language understanding, including uncertainty estimation, humour detection, and processing garden path sentences. We assess language models’ sensitivity to ambiguity by introducing an adversarial ambiguity dataset that includes syntactic, lexical, and... | Antonia Karamolegkou, Oliver Eberle, Phillip Rust, Carina Kauf, Anders Søgaard |  |
| 1055 |  |  [Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes](https://aclanthology.org/2025.findings-acl.955/) |  | 0 | To build fair AI systems we need to understand how social-group biases intrinsic to foundational encoder-based vision-language models (VLMs) manifest in biases in downstream tasks. In this study, we demonstrate that intrinsic biases in VLM representations systematically “carry over” or propagate... | Kshitish Ghate, Tessa Charlesworth, Mona T. Diab, Aylin Caliskan |  |
| 1056 |  |  [Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.956/) |  | 0 | Chain-of-Thought (CoT) reasoning, which breaks down complex tasks into intermediate reasoning steps, has significantly enhanced the performance of large language models (LLMs) on challenging tasks. However, the detailed reasoning process in CoT often incurs long generation times and high... | Yingqian Cui, Pengfei He, Jingying Zeng, Hui Liu, Xianfeng Tang, Zhenwei Dai, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Yue Xing, Jiliang Tang, Qi He |  |
| 1057 |  |  [Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers](https://aclanthology.org/2025.findings-acl.957/) |  | 0 | This paper introduces MISS-QA, the first benchmark specifically designed to evaluate the ability of models to interpret schematic diagrams within scientific literature. MISS-QA comprises 3,000 expert-annotated examples over 983 scientific papers. In this benchmark, models are tasked with... | Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan |  |
| 1058 |  |  [MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs](https://aclanthology.org/2025.findings-acl.958/) |  | 0 | We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that... | Kaustubh Deshpande, Ved Sirdeshmukh, Johannes Baptist Mols, Lifeng Jin, EdYeremai HernandezCardona, Dean Lee, Jeremy Kritz, Willow E. Primack, Summer Yue, Chen Xing |  |
| 1059 |  |  [Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training](https://aclanthology.org/2025.findings-acl.959/) |  | 0 | Due to the sensitive nature of personally identifiable information (PII), its owners may have the authority to control its inclusion or request its removal from large-language model (LLM) training. Beyond this, PII may be added or removed from training datasets due to evolving dataset curation... | Jaydeep Borkar, Matthew Jagielski, Katherine Lee, Niloofar Mireshghallah, David A. Smith, Christopher A. ChoquetteChoo |  |
| 1060 |  |  [Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety](https://aclanthology.org/2025.findings-acl.960/) |  | 0 | Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit weaknesses in traditional safety alignment, which often relies on rigid refusal heuristics or representation engineering to block harmful outputs. While they are effective for direct adversarial attacks, they fall short... | Yuyou Zhang, Miao Li, William Han, Yihang Yao, Zhepeng Cen, Ding Zhao |  |
| 1061 |  |  [Is a cute puyfred cute? Context-dependent form-meaning systematicity in LLMs](https://aclanthology.org/2025.findings-acl.961/) |  | 0 | We investigate static and contextualized embeddings for English pseudowords across a variety of Large Language Models (LLMs), to study (i) how these models represent semantic attributes of strings they encounter for the very first time and how (ii) these representations interact with sentence... | Jaïr A Waal, Giovanni Cassani |  |
| 1062 |  |  [MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation](https://aclanthology.org/2025.findings-acl.962/) |  | 0 | Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively... | Haris Riaz, Sourav Sanjukta Bhabesh, Vinayak Arannil, Miguel Ballesteros, Graham Horwood |  |
| 1063 |  |  [MVTamperBench: Evaluating Robustness of Vision-Language Models](https://aclanthology.org/2025.findings-acl.963/) |  | 0 | Multimodal Large Language Models (MLLMs), are recent advancement of Vision-Language Models (VLMs) that have driven major advances in video understanding. However, their vulnerability to adversarial tampering and manipulations remains underexplored. To address this gap, we introduce MVTamperBench, a... | Amit Agarwal, Srikant Panda, Angeline Charles, Hitesh Laxmichand Patel, Bhargava Kumar, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Hansa Meghwani, Karan Gupta, DongKyu Chae |  |
| 1064 |  |  [Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models](https://aclanthology.org/2025.findings-acl.964/) |  | 0 | Existing Multimodal Large Language Models (MLLMs) are predominantly trained and tested on consistent visual-textual inputs, leaving open the question of whether they can handle inconsistencies in real-world, layout-rich content. To bridge this gap, we propose the Multimodal Inconsistency Reasoning... | Qianqi Yan, Yue Fan, Hongquan Li, Shan Jiang, Yang Zhao, Xinze Guan, ChingChen Kuo, Xin Eric Wang |  |
| 1065 |  |  [Vision-Language Models Struggle to Align Entities across Modalities](https://aclanthology.org/2025.findings-acl.965/) |  | 0 | Cross-modal entity linking refers to the ability to align entities and their attributes across different modalities. While cross-modal entity linking is a fundamental skill needed for real-world applications such as multimodal code generation, fake news detection, or scene understanding, it has not... | Iñigo Alonso, Gorka Azkune, Ander Salaberria, Jeremy Barnes, Oier Lopez de Lacalle |  |
| 1066 |  |  [A Multi-Labeled Dataset for Indonesian Discourse: Examining Toxicity, Polarization, and Demographics Information](https://aclanthology.org/2025.findings-acl.966/) |  | 0 | Online discourse is increasingly trapped in a vicious cycle where polarizing language fuelstoxicity and vice versa. Identity, one of the most divisive issues in modern politics, oftenincreases polarization. Yet, prior NLP research has mostly treated toxicity and polarization asseparate problems. In... | Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Zilu Tang, Fariz Akyas, Traci Hong, Ika Karlina Idris, Alham Fikri Aji, Derry Tanti Wijaya |  |
| 1067 |  |  [MedCite: Can Language Models Generate Verifiable Text for Medicine?](https://aclanthology.org/2025.findings-acl.967/) |  | 0 | Existing LLM-based medical question answering systems lack citation generation and evaluation capabilities, raising concerns about their adoption in practice. In this work, we introduce MedCite, the first end-to-end framework that facilitates the design and evaluation of LLM citations for medical... | Xiao Wang, Mengjue Tan, Qiao Jin, Guangzhi Xiong, Yu Hu, Aidong Zhang, Zhiyong Lu, Minjia Zhang |  |
| 1068 |  |  [Let The Jury Decide: Fair Demonstration Selection for In-Context Learning through Incremental Greedy Evaluation](https://aclanthology.org/2025.findings-acl.968/) |  | 0 | Large Language Models (LLMs) are powerful in-context learners, achieving strong performance with just a few high-quality demonstrations. However, fairness concerns arise in many in-context classification tasks, especially when predictions involve sensitive attributes. To address this, we propose... | Sadaf Md. Halim, Chen Zhao, Xintao Wu, Latifur Khan, Christan Grant, Fariha Ishrat Rahman, Feng Chen |  |
| 1069 |  |  [The Lies Characters Tell: Utilizing Large Language Models to Normalize Adversarial Unicode Perturbations](https://aclanthology.org/2025.findings-acl.969/) |  | 0 | Homoglyphs, Unicode characters that are visually homogeneous to Latin letters, are widely used to mask offensive content. Dynamic strategies are needed to combat homoglyphs as the Unicode library is ever-expanding and new substitution possibilities for Latin letters continuously emerge. The present... | Portia Cooper, Eduardo Blanco, Mihai Surdeanu |  |
| 1070 |  |  [Speech Act Patterns for Improving Generalizability of Explainable Politeness Detection Models](https://aclanthology.org/2025.findings-acl.970/) |  | 0 | The lack of explainability in state-of-the-art Natural Language Understanding (NLU) classification models has increased interest in developing techniques for improving explainable linear feature-based models (e.g., Logistic Regression/SVM). Politeness detection is a task that exemplifies this... | Ahmad Aljanaideh |  |
| 1071 |  |  [Systematic Evaluation of Auto-Encoding and Large Language Model Representations for Capturing Author States and Traits](https://aclanthology.org/2025.findings-acl.971/) |  | 0 | Large Language Models (LLMs) are increasingly used in human-centered applications, yet their ability to model diverse psychological constructs is not well understood. In this study, we systematically evaluate a range of Transformer-LMs to predict psychological variables across five major... | Khushboo Singh, Vasudha Varadarajan, Adithya V. Ganesan, August Håkan Nilsson, Nikita Soni, Syeda Mahwish, Pranav Chitale, Ryan L. Boyd, Lyle H. Ungar, Richard N. Rosenthal, H. Andrew Schwartz |  |
| 1072 |  |  [TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues](https://aclanthology.org/2025.findings-acl.972/) |  | 0 | Temporal reasoning in multi-session dialogues presents a significant challenge which has been under-studied in previous temporal reasoning benchmarks. To bridge this gap, we propose a new evaluation task for temporal reasoning in multi-session dialogues and introduce an approach to construct a new... | Yubin Ge, Salvatore Romeo, Jason Cai, Raphael Shu, Yassine Benajiba, Monica Sunkara, Yi Zhang |  |
| 1073 |  |  [Conservative Bias in Large Language Models: Measuring Relation Predictions](https://aclanthology.org/2025.findings-acl.973/) |  | 0 | Large language models (LLMs) exhibit pronounced conservative bias in relation extraction tasks, frequently defaulting to no_relation label when an appropriate option is unavailable. While this behavior helps prevent incorrect relation assignments, our analysis reveals that it also leads to... | Toyin Aguda, Erik Wilson, Allan Anzagira, Simerjot Kaur, Charese Smiley |  |
| 1074 |  |  [Mitigating Bias in RAG: Controlling the Embedder](https://aclanthology.org/2025.findings-acl.974/) |  | 0 | In retrieval augmented generation (RAG) systems, each individual component—the LLM, embedder, and corpus—could introduce biases in the form of skews towards certain genders or political leanings. In this work, we study the conflict between biases of each component and their relationship to the... | Taeyoun Kim, Jacob Mitchell Springer, Aditi Raghunathan, Maarten Sap |  |
| 1075 |  |  [V-ALPHASOCIAL: Benchmark and Self-Reflective Chain-of-Thought Generation for Visual Social Commonsense Reasoning](https://aclanthology.org/2025.findings-acl.975/) |  | 0 | Social commonsense reasoning naturally involves both the verbal and non-verbal cues of a social interaction. It is important for Large Vision-Language Models (VLMs) to leverage both textual and visual information in performing tasks like social understanding and reasoning. However, while current... | Zongyu Lin, Zhikun Xu, Xiaohan Song, Yixin Wan, Xingcheng Yao, TsungHan Lin, Selina Song, Pranav Subbaraman, Ben Zhou, KaiWei Chang, Yizhou Sun |  |
| 1076 |  |  [AfroBench: How Good are Large Language Models on African Languages?](https://aclanthology.org/2025.findings-acl.976/) |  | 0 | Large-scale multilingual evaluations, such as MEGA, often include only a handful of African languages due to the scarcity of high-qualityevaluation data and the limited discoverability of existing African datasets. This lack of representation hinders comprehensive LLM evaluation across a diverse... | Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, David Ifeoluwa Adelani |  |
| 1077 |  |  [Training Bilingual LMs with Data Constraints in the Targeted Language](https://aclanthology.org/2025.findings-acl.977/) |  | 0 | Large language models are trained on massive scrapes of the web, as required by current scaling laws. Most progress is made for English, given its abundance of high-quality pretraining data. For most other languages, however, such high quality pretraining data is unavailable. In this work, we study... | Skyler Seto, Maartje ter Hoeve, Richard He Bai, Natalie Schluter, David Grangier |  |
| 1078 |  |  [ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering](https://aclanthology.org/2025.findings-acl.978/) |  | 0 | Charts are ubiquitous, as people often use them to analyze data, answer questions, and discover critical insights. However, performing complex analytical tasks with charts requires significant perceptual and cognitive effort. Chart Question Answering (CQA) systems automate this process by enabling... | Ahmed Masry, Mohammed Saidul Islam, Mahir Ahmed, Aayush Bajaj, Firoz Kabir, Aaryaman Kartha, Md. Tahmid Rahman Laskar, Mizanur Rahman, Shadikur Rahman, Mehrad Shahmohammadi, Megh Thakkar, Md. Rizwan Parvez, Enamul Hoque, Shafiq Joty |  |
| 1079 |  |  [From Observation to Understanding: Front-Door Adjustments with Uncertainty Calibration for Enhancing Egocentric Reasoning in LVLMs](https://aclanthology.org/2025.findings-acl.979/) |  | 0 | Recent progress in large vision-language models (LVLMs) has shown substantial potential across a broad spectrum of third-person tasks. However, adapting these LVLMs to egocentric scenarios remains challenging due to their third-person training bias. Existing methods that adapt LVLMs for... | Shenshen Li, Wenxin Meng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Jingkuan Song, Heng Tao Shen, Xing Xu |  |
| 1080 |  |  [Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion](https://aclanthology.org/2025.findings-acl.980/) |  | 0 | Query expansion methods powered by large language models (LLMs) have demonstrated effectiveness in zero-shot retrieval tasks. These methods assume that LLMs can generate hypothetical documents that, when incorporated into a query vector, enhance the retrieval of real evidence. However, we challenge... | Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park |  |
| 1081 |  |  [Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA](https://aclanthology.org/2025.findings-acl.981/) |  | 0 | Large Multimodal Models (LMMs) have demonstrated impressive performance on existing medical Visual Question Answering (Med-VQA) benchmarks. However, high reported accuracy does not necessarily reflect their true diagnostic reliability in clinical settings. This study reveals that state-of-the-art... | Qianqi Yan, Xuehai He, Xiang Yue, Xin Eric Wang |  |
| 1082 |  |  [Optimizing Reasoning for Text-to-SQL with Execution Feedback](https://aclanthology.org/2025.findings-acl.982/) |  | 0 | Text-to-SQL demands precise reasoning to convert natural language questions into structured queries. While large language models (LLMs) excel in many reasoning tasks, their ability to leverage Chain-of-Thought (CoT) reasoning for text-to-SQL remains underexplored. We identify critical limitations:... | Bohan Zhai, Canwen Xu, Yuxiong He, Zhewei Yao |  |
| 1083 |  |  [Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities](https://aclanthology.org/2025.findings-acl.983/) |  | 0 | This study intends to systematically disentangle pure logic reasoning and text understanding by investigating the contrast across abstract and contextualized logical problems from a comprehensive set of domains. We explore whether LLMs demonstrate genuine reasoning capabilities across various... | Wenyue Hua, Kaijie Zhu, Lingyao Li, Lizhou Fan, Mingyu Jin, Shuhang Lin, Haochen Xue, Zelong Li, Jindong Wang, Yongfeng Zhang |  |
| 1084 |  |  [Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language Models](https://aclanthology.org/2025.findings-acl.984/) |  | 0 | Recent advances in large language models have led to numerous task-specialized fine-tuned variants, creating a need for efficient model merging techniques that preserve specialized capabilities while avoiding costly retraining. While existing task vector-based merging methods show promise, they... | Shuqi Liu, Han Wu, Bowei He, Xiongwei Han, Mingxuan Yuan, Linqi Song |  |
| 1085 |  |  [EgoNormia: Benchmarking Physical-Social Norm Understanding](https://aclanthology.org/2025.findings-acl.985/) |  | 0 | Human activity is moderated by norms; however, supervision for normative reasoning is sparse, particularly where norms are physically- or socially-grounded. We thus present EgoNormia \lVert 𝜖 \rVert, comprising 1,853 (200 for EgoNormia-verified) multiple choice questions (MCQs) grounded within... | MohammadHossein Rezaei, Yicheng Fu, Phil Cuvin, Caleb Ziems, Yanzhe Zhang, Hao Zhu, Diyi Yang |  |
| 1086 |  |  [Large Language Models as Neurolinguistic Subjects: Discrepancy between Performance and Competence](https://aclanthology.org/2025.findings-acl.986/) |  | 0 | This study investigates the linguistic understanding of Large Language Models (LLMs) regarding signifier (form) and signified (meaning) by distinguishing two LLM assessment paradigms: psycholinguistic and neurolinguistic. Traditional psycholinguistic evaluations often reflect statistical rules that... | Linyang He, Ercong Nie, Helmut Schmid, Hinrich Schütze, Nima Mesgarani, Jonathan Brennan |  |
| 1087 |  |  [The Impact of Large Language Models in Academia: from Writing to Speaking](https://aclanthology.org/2025.findings-acl.987/) |  | 0 | Large language models (LLMs) are increasingly impacting human society, particularly in textual information. Based on more than 30,000 papers and 1,000 presentations from machine learning conferences, we examined and compared the words used in writing and speaking, representing the first large-scale... | Mingmeng Geng, Caixi Chen, Yanru Wu, Yao Wan, Pan Zhou, Dongping Chen |  |
| 1088 |  |  [X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System](https://aclanthology.org/2025.findings-acl.988/) |  | 0 | Recently, large language model (LLM)-based agents have achieved significant success in interactive environments, attracting significant academic and industrial attention. Despite these advancements, current research predominantly focuses on English scenarios. In reality, there are over 7,000... | Peng Wang, Ruihan Tao, Qiguang Chen, Mengkang Hu, Libo Qin |  |
| 1089 |  |  [MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents](https://aclanthology.org/2025.findings-acl.989/) |  | 0 | Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the... | Haoran Tan, Zeyu Zhang, Chen Ma, Xu Chen, Quanyu Dai, Zhenhua Dong |  |
| 1090 |  |  [Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation](https://aclanthology.org/2025.findings-acl.990/) |  | 0 | This study proposes a simple yet effective LoRA merge method to achieve LLM adaptation for low-resource language generation tasks. The LoRA merge technique, which integrates multiple LoRA modules trained on different tasks, has gained attention as an effective and efficient approach for adapting... | Ryota Miyano, Yuki Arase |  |
| 1091 |  |  [LongAttn: Selecting Long-context Training Data via Token-level Attention](https://aclanthology.org/2025.findings-acl.991/) |  | 0 | With the development of large language models (LLMs), there has been an increasing need for significant advancements in handling long contexts. To enhance long-context capabilities, constructing high-quality training data with \*\*long-range dependencies\*\* is crucial. Existing methods to select... | Longyun Wu, Dawei Zhu, Guangxiang Zhao, Zhuocheng Yu, Junfeng Ran, Xiangyu Wong, Lin Sun, Sujian Li |  |
| 1092 |  |  [CoRE: Condition-based Reasoning for Identifying Outcome Variance in Complex Events](https://aclanthology.org/2025.findings-acl.992/) |  | 0 | Knowing which latent conditions lead to a particular outcome is useful for critically examining claims made about complex event outcomes. Identifying implied conditions and examining their influence on an outcome is challenging. We handle this by combining and augmenting annotations from two... | Sai P. Vallurupalli, Francis Ferraro |  |
| 1093 |  |  [FaVe: Factored and Verified Search Rationale for Long-form Answer](https://aclanthology.org/2025.findings-acl.993/) |  | 0 | Targeting long-form question-answering, chain-of-query (CoQ) has been studied, integrating chain-of-thought (CoT) with retrieval-augmented generation. CoQ answers the complex question step-by-step, through simpler subquestions (SQs) from which relevant knowledge is retrieved. By doing so, CoQ aims... | Jihyuk Kim, Sungjin Lee, Seungwon Hwang, Yang Liu |  |
| 1094 |  |  [UnrealLLM: Towards Highly Controllable and Interactable 3D Scene Generation by LLM-powered Procedural Content Generation](https://aclanthology.org/2025.findings-acl.994/) |  | 0 | The creation of high-quality 3D scenes is essential for applications like video games and simulations, yet automating this process while retaining the benefits of Procedural Content Generation (PCG) remains challenging. In this paper, we introduce UnrealLLM, a novel multi-agent framework that... | SongTang SongTang, Kaiyong Zhao, Lei Wang, Yuliang Li, Xuebo Liu, Junyi Zou, Qiang Wang, Xiaowen Chu |  |
| 1095 |  |  [Tree-of-Prompts: Abstracting Control-Flow for Prompt Optimization](https://aclanthology.org/2025.findings-acl.995/) |  | 0 | Prompt optimization (PO) generates prompts to guide Large Language Models (LLMs) in performing tasks. Existing methods, such as PromptAgent, rely on a single static prompt, which struggles with disjoint cases in complex tasks. Although MoP uses multiple prompts, it fails to account for variations... | Jihyuk Kim, Shubham Garg, Lahari Poddar, Seungwon Hwang, Chris Hench |  |
| 1096 |  |  [Outlier-weighed Layerwise Sampling for LLM Fine-tuning](https://aclanthology.org/2025.findings-acl.996/) |  | 0 | The rapid advancements in Large Language Models (LLMs) have revolutionized various natural language processing tasks. However, the substantial size of LLMs presents significant challenges in training or fine-tuning. While parameter-efficient approaches such as low-rank adaptation (LoRA) have gained... | Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu |  |
| 1097 |  |  [KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation](https://aclanthology.org/2025.findings-acl.997/) |  | 0 | Inference for Large Language Models (LLMs) is computationally demanding. To reduce the cost of auto-regressive decoding, Key-Value (KV) cache is used to store intermediate activations, which significantly lowers the computational overhead for token generation. However, the memory required for the... | Chaoyi Jiang, Lei Gao, Hossein Entezari Zarch, Murali Annavaram |  |
| 1098 |  |  [Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs](https://aclanthology.org/2025.findings-acl.998/) |  | 0 | Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized models designed to run efficiently on consumer-grade hardware, offering significant advantages in resource efficiency, cost-effectiveness, and data privacy. However, these models often struggle with limited inference and... | Hongming Yang, Shi Lin, Jun Shao, Changting Lin, Donghai Zhu, Meng Han, Qinglei Kong |  |
| 1099 |  |  [Whether LLMs Know If They Know: Identifying Knowledge Boundaries via Debiased Historical In-Context Learning](https://aclanthology.org/2025.findings-acl.999/) |  | 0 | In active retrieval (AR), large language models (LLMs) need first assess whether they possess knowledge to answer a given query, to decide whether to invoke a retrieval module. Existing methods primarily rely on training classification models or using the confidence of the model’s answer to... | Bo Lv, Nayu Liu, Yang Shen, Xin Liu, Ping Luo, Yue Yu |  |
| 1100 |  |  [How do LLMs' Preferences Affect Event Argument Extraction? CAT: Addressing Preference Traps in Unsupervised EAE](https://aclanthology.org/2025.findings-acl.1000/) |  | 0 | Large Language Models (LLMs) have significantly improved the performance of unsupervised Event Argument Extraction (EAE) tasks. However, LLMs’ inherent preferences severely hinder their effectiveness in EAE, leading to what we term preference traps, namely, the Prior Knowledge Trap, the Sycophancy... | Yunhao Wei, Kai Shuang, Zhiyi Li, Chenrui Mao |  |
| 1101 |  |  [Out-of-Distribution Detection via LLM-Guided Outlier Generation for Text-attributed Graph](https://aclanthology.org/2025.findings-acl.1001/) |  | 0 | Text-Attributed Graphs (TAGs), which are characterized with text attributes, are widely used in the real world. When evaluating fully trained models designed for TAG predictions, they may perform significantly unsatisfactory on samples outside the In-Distribution (ID) data, which may raise serious... | Xiangwei Lv, Mengze Li, Jingyuan Chen, Zhiang Dong, Sirui Han, Beishui Liao |  |
| 1102 |  |  [Document-Level Relation Extraction with Global Relations and Entity Pair Reasoning](https://aclanthology.org/2025.findings-acl.1002/) |  | 0 | Document-level relation extraction (DocRE) aims to extract structured relational triples from unstructured text based on given entities. Existing methods are mainly categorized into transformer-based models and graph-based models. While transformer-based models capture global contextual... | Fu Zhang, Yi Yan, Jingwei Cheng |  |
| 1103 |  |  [Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings](https://aclanthology.org/2025.findings-acl.1003/) |  | 0 | Despite the strong performance of ColPali/ColQwen2 in Visualized Document Retrieval (VDR), its patch-level embedding approach leads to excessive memory usage. This empirical study investigates methods to reduce patch embeddings per page while minimizing performance degradation. We evaluate two... | Yubo Ma, Jinsong Li, Yuhang Zang, Xiaobao Wu, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Haodong Duan, Jiaqi Wang, Yixin Cao, Aixin Sun |  |
| 1104 |  |  [Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models](https://aclanthology.org/2025.findings-acl.1004/) |  | 0 | It is crucial for large language models (LLMs) to follow instructions that involve multiple constraints. In real-world scenarios, user instructions often contain soft constraints, which are semantically related and cannot be rule-based verified, posing challenges for LLMs. To enhance the soft... | Qingyu Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu |  |
| 1105 |  |  [ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models](https://aclanthology.org/2025.findings-acl.1005/) |  | 0 | The advancements in large language models (LLMs) have brought significant progress in NLP tasks. However, if a task cannot be fully described in prompts, the models could fail to carry out the task. In this paper, we propose a simple yet effective method to contextualize a task toward a LLM. The... | Hwiyeol Jo, Hyunwoo Lee, Kang Min Yoo, Taiwoo Park |  |
| 1106 |  |  [Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations](https://aclanthology.org/2025.findings-acl.1006/) |  | 0 | Inductive reasoning, a cornerstone of human cognition, enables generalization from limited data but hasn’t yet been fully achieved by large language models (LLMs). While modern LLMs excel at reasoning tasks, their ability to maintain stable and consistent rule abstraction under imperfect... | Chunyang Li, Weiqi Wang, Tianshi Zheng, Yangqiu Song |  |
| 1107 |  |  [LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of Factual Claims from Social Media](https://aclanthology.org/2025.findings-acl.1007/) |  | 0 | With the rapid expansion of content on social media platforms, analyzing and comprehending online discourse has become increasingly complex. This paper introduces LLMTaxo, a novel framework leveraging large language models for the automated construction of taxonomies of factual claims from social... | Haiqi Zhang, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li |  |
| 1108 |  |  [AnCast++: Document-Level Evaluation of Graph-based Meaning Representations](https://aclanthology.org/2025.findings-acl.1008/) |  | 0 | Uniform Meaning Representation (UMR) is a cross-lingual document-level graph-based representation that is based on Abstract Meaning Representation (AMR) but extends it to include document-level semantic annotations such as coreference, modal and temporal dependencies.With recent advancements in UMR... | Haibo Sun, Jayeol Chun, Nianwen Xue |  |
| 1109 |  |  [MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct](https://aclanthology.org/2025.findings-acl.1009/) |  | 0 | The development of Multimodal Large Language Models (MLLMs) has seen significant progress, driven by increasing demands across various fields (e.g., multimodal agents, embodied intelligence). While model-driven approaches aim to enhance MLLM capabilities through diverse architectures, their... | Run Luo, Haonan Zhang, Longze Chen, TingEn Lin, Xiong Liu, Yuchuan Wu, Min Yang, Yongbin Li, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Hamid AlinejadRokny, Xiaobo Xia, Jingkuan Song, Fei Huang |  |
| 1110 |  |  [SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems](https://aclanthology.org/2025.findings-acl.1010/) |  | 0 | The rapid advancement of Large Multi-modal Models (LMMs) has enabled their application in scientific problem-solving, yet their fine-grained capabilities remain under-explored. In this paper, we introduce SciVerse, a multi-modal scientific evaluation benchmark to thoroughly assess LMMs across 5,735... | Ziyu Guo, Renrui Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, PhengAnn Heng |  |
| 1111 |  |  [Exploring Layer-wise Representations of English and Chinese Homonymy in Pre-trained Language Models](https://aclanthology.org/2025.findings-acl.1011/) |  | 0 | Homonymy can easily raise lexical ambiguity due to the misunderstanding of its multiple senses. Correct recognition of homonym sense greatly relies on its surrounding context. This ambiguous nature makes homonyms an appropriate testbed for examining the contextualization capability of pre-trained... | Matthew KingHang Ma, Chenwei Xie, Wenbo Wang, William ShiYuan Wang |  |
| 1112 |  |  [DocMEdit: Towards Document-Level Model Editing](https://aclanthology.org/2025.findings-acl.1012/) |  | 0 | Model editing aims to correct errors and outdated knowledge in the Large language models (LLMs) with minimal cost. Prior research has proposed a variety of datasets to assess the effectiveness of these model editing methods. However, most existing datasets only require models to output short... | Li Zeng, Zeming Liu, Chong Feng, Heyan Huang, Yuhang Guo |  |
| 1113 |  |  [Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing](https://aclanthology.org/2025.findings-acl.1013/) |  | 0 | Large language models (LLMs) exhibit impressive language capabilities but remain vulnerable to malicious prompts and jailbreaking attacks. Existing knowledge editing methods for LLM detoxification face two major challenges. First, they often rely on entity-specific localization, making them... | Yifan Lu, Jing Li, Yigeng Zhou, Yihui Zhang, Wenya Wang, Xiucheng Li, Meishan Zhang, Fangming Liu, Jun Yu, Min Zhang |  |
| 1114 |  |  [Evaluating the Long-Term Memory of Large Language Models](https://aclanthology.org/2025.findings-acl.1014/) |  | 0 | In applications such as dialogue systems, personalized recommendations, and personal assistants, large language models (LLMs) need to retain and utilize historical information over the long term to provide more accurate and consistent responses. Although long-term memory capability is crucial,... | Zixi Jia, Qinghua Liu, Hexiao Li, Yuyan Chen, Jiqiang Liu |  |
| 1115 |  |  [Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments](https://aclanthology.org/2025.findings-acl.1015/) |  | 0 | Large language models (LLMs) can explain grammatical rules, yet they often fail to apply those rules when judging sentence acceptability. We present grammar prompting, an explain-then-process paradigm: a large LLM first produces a concise explanation of the relevant syntactic phenomenon, then that... | Russell Scheinberg, Ameeta Agrawal, Amber Shore, So Young Lee |  |
| 1116 |  |  [Data Interpreter: An LLM Agent for Data Science](https://aclanthology.org/2025.findings-acl.1016/) |  | 0 | Large Language Model (LLM)-based agents have excelled in various domains but face significant challenges when applied to data science workflows due to their complex, multi-stage nature. Current LLM-based agents struggle with non-linear relationships, recursive dependencies, implicit data- and... | Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Ceyao Zhang, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, Lingyao Zhang, Min Yang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Robert Tang, Xiangtao Lu, Xiawu Zheng, Xinbing Liang, Yaying Fei, Yuheng Cheng, Yongxin Ni, Zhibin Gou, Zongze Xu, Yuyu Luo, Chenglin Wu |  |
| 1117 |  |  [DReSD: Dense Retrieval for Speculative Decoding](https://aclanthology.org/2025.findings-acl.1017/) |  | 0 | Speculative decoding (SD) accelerates Large Language Model (LLM) generation by using an efficient draft model to propose the next few tokens, which are verified by the LLM in a single forward call, reducing latency while preserving its outputs. We focus on retrieval-based SD where the draft model... | Milan Gritta, Huiyin Xue, Gerasimos Lampouras |  |
| 1118 |  |  [Core: Robust Factual Precision with Informative Sub-Claim Identification](https://aclanthology.org/2025.findings-acl.1018/) |  | 0 | Hallucinations pose a challenge to the application of large language models (LLMs) thereby motivating the development of metrics to evaluate factual precision. We observe that popular metrics using the Decompose-Then-Verify framework, such as FActScore, can be manipulated by adding obvious or... | Zhengping Jiang, Jingyu Zhang, Nathaniel Weir, Seth Ebner, Miriam Wanner, Kate Sanders, Daniel Khashabi, Anqi Liu, Benjamin Van Durme |  |
| 1119 |  |  [Rethinking Diverse Human Preference Learning through Principal Component Analysis](https://aclanthology.org/2025.findings-acl.1019/) |  | 0 | Understanding human preferences is crucial for improving foundation models and building personalized AI systems. However, preferences are inherently diverse and complex, making it difficult for traditional reward models to capture their full range. While fine-grained preference data can help,... | Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen |  |
| 1120 |  |  [Improving Word Alignment Using Semi-Supervised Learning](https://aclanthology.org/2025.findings-acl.1020/) |  | 0 | Word alignment plays a crucial role in various natural language processing tasks, such as serving as cross-lingual signals for sentence embedding, reducing hallucination and omission in machine translation, and facilitating the construction of training data for simultaneous speech... | Zhongtao Miao, Qiyu Wu, Masaaki Nagata, Yoshimasa Tsuruoka |  |
| 1121 |  |  [How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training](https://aclanthology.org/2025.findings-acl.1021/) |  | 0 | Despite exceptional capabilities in knowledge-intensive tasks, Large Language Models (LLMs) face a critical gap in understanding how they internalize new knowledge, particularly how acquired knowledge becomes structurally embedded in their neural computations. We address this issue through the lens... | Yixin Ou, Yunzhi Yao, Ningyu Zhang, Hui Jin, Jiacheng Sun, Shumin Deng, Zhenguo Li, Huajun Chen |  |
| 1122 |  |  [LLM-Symbolic Integration for Robust Temporal Tabular Reasoning](https://aclanthology.org/2025.findings-acl.1022/) |  | 0 | Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data—a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and... | Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta |  |
| 1123 |  |  [Multimodal Large Language Models for Text-rich Image Understanding: A Comprehensive Review](https://aclanthology.org/2025.findings-acl.1023/) |  | 0 | The recent emergence of Multi-modal Large Language Models (MLLMs) has introduced a new dimension to the Text-rich Image Understanding (TIU) field, with models demonstrating impressive and inspiring performance. However, their rapid evolution and widespread adoption have made it increasingly... | Pei Fu, Tongkun Guan, Zining Wang, Zhentao Guo, Chen Duan, Hao Sun, Boming Chen, Qianyi Jiang, Jiayao Ma, Kai Zhou, Junfeng Luo |  |
| 1124 |  |  [PruneVid: Visual Token Pruning for Efficient Video Large Language Models](https://aclanthology.org/2025.findings-acl.1024/) |  | 0 | We introduce PruneVid, a training-free visual token pruning method designed to enhance the efficiency of multimodal video understanding. While Large Language Models (LLMs) have shown promising performance on video tasks due to their advanced visual comprehension capabilities, the substantial... | Xiaohu Huang, Hao Zhou, Kai Han |  |
| 1125 |  |  [PromptWizard: Optimizing Prompts via Task-Aware, Feedback-Driven Self-Evolution](https://aclanthology.org/2025.findings-acl.1025/) |  | 0 | Large language models (LLMs) have transformed AI across diverse domains, with prompting being central to their success in guiding model outputs. However, manual prompt engineering is both labor-intensive and domain-specific, necessitating the need for automated solutions. We introduce PromptWizard,... | Eshaan Agarwal, Raghav Magazine, Joykirat Singh, Vivek Dani, Tanuja Ganu, Akshay Uttama Nambi |  |
| 1126 |  |  [Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models](https://aclanthology.org/2025.findings-acl.1026/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in natural language processing tasks, such as text generation and semantic understanding. However, their performance on numerical reasoning tasks, such as basic arithmetic, numerical retrieval, and magnitude comparison, remains... | Haoyang Li, Xuejia Chen, Zhanchao Xu, Darian Li, Nicole Hu, Fei Teng, Yiming Li, Luyu Qiu, Chen Jason Zhang, Qing Li, Lei Chen |  |
| 1127 |  |  [TABGEN-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation](https://aclanthology.org/2025.findings-acl.1027/) |  | 0 | Large Language models (LLMs) have achieved encouraging results in tabular data generation. However, existing approaches require fine-tuning, which is computationally expensive. This paper explores an alternative: prompting a fixed LLM with in-context examples. We observe that using randomly... | Liancheng Fang, Aiwei Liu, Hengrui Zhang, Henry Peng Zou, Weizhi Zhang, Philip S. Yu |  |
| 1128 |  |  [Benchmarking Multi-National Value Alignment for Large Language Models](https://aclanthology.org/2025.findings-acl.1028/) |  | 0 | Do Large Language Models (LLMs) hold positions that conflict with your country’s values? Occasionally they do! However, existing works primarily focus on ethical reviews, failing to capture the diversity of national values, which encompass broader policy, legal, and moral considerations.... | Chengyi Ju, Weijie Shi, Chengzhong Liu, Jiaming Ji, Jipeng Zhang, Ruiyuan Zhang, Jiajie Xu, Yaodong Yang, Sirui Han, Yike Guo |  |
| 1129 |  |  [MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?](https://aclanthology.org/2025.findings-acl.1029/) |  | 0 | Large language models (LLMs) have been widely adopted as the core of agent frameworks in various scenarios, such as social simulations and AI companions. However, the extent to which they can replicate human-like motivations remains an underexplored question. Existing benchmarks are constrained by... | Xixian Yong, Jianxun Lian, Xiaoyuan Yi, Xiao Zhou, Xing Xie |  |
| 1130 |  |  [Confidence Improves Self-Consistency in LLMs](https://aclanthology.org/2025.findings-acl.1030/) |  | 0 | Self-consistency decoding enhances LLMs’ performance on reasoning tasks by sampling diverse reasoning paths and selecting the most frequent answer. However, it is computationally expensive, as sampling many of these (lengthy) paths is required to increase the chances that the correct answer emerges... | Amir Taubenfeld, Tom Sheffer, Eran Ofek, Amir Feder, Ariel Goldstein, Zorik Gekhman, Gal Yona |  |
| 1131 |  |  [None of the Above, Less of the Right Parallel Patterns in Human and LLM Performance on Multi-Choice Questions Answering](https://aclanthology.org/2025.findings-acl.1031/) |  | 0 | Multiple-choice exam questions with “None of the above” (NA) options have been extensively studied in educational testing, in which existing research suggests that they better assess true knowledge. However, their impact on Large Language Models (LLMs) evaluation remains underexplored. Through... | Zhi Rui Tam, ChengKuang Wu, ChiehYen Lin, YunNung Chen |  |
| 1132 |  |  [In Search of the Lost Arch in Dialogue: A Dependency Dialogue Acts Corpus for Multi-Party Dialogues](https://aclanthology.org/2025.findings-acl.1032/) |  | 0 | Understanding the structure of multi-party conversation and the intentions and dialogue acts of each speaker remains a significant challenge in NLP. While a number of corpora annotated using theoretical frameworks of dialogue have been proposed, these typically focus on either utterance-level... | Jon Z. Cai, Brendan King, Peyton Cameron, Susan Windisch Brown, Miriam Eckert, Dananjay Srinivas, George Arthur Baker, V. Kate Everson, Martha Palmer, James H. Martin, Jeffrey Flanigan |  |
| 1133 |  |  [ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data](https://aclanthology.org/2025.findings-acl.1033/) |  | 0 | Mental health risk is a critical global public health challenge, necessitating innovative and reliable assessment methods. With the development of large language models (LLMs), they stand out to be a promising tool for explainable mental health care applications. Nevertheless, existing approaches... | Xinzhe Zheng, Sijie Ji, Jiawei Sun, Renqi Chen, Wei Gao, Mani Srivastava |  |
| 1134 |  |  [Debiasing Online Preference Learning via Preference Feature Preservation](https://aclanthology.org/2025.findings-acl.1034/) |  | 0 | Recent preference learning frameworks for large language models (LLMs) simplify human preferences with binary pairwise comparisons and scalar rewards. This simplification could make LLMs’ responses biased to mostly preferred features, and would be exacerbated during the iterations of online... | Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim |  |
| 1135 |  |  [ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](https://aclanthology.org/2025.findings-acl.1035/) |  | 0 | As Large Language Models (LLMs) continue to advance, their computational overhead has increased significantly. In this study, we identify notable redundancy across the layers of LLMs, where some layers contribute minimally to the overall network functionality. To quantify this, we introduce a... | Xin Men, Mingyu Xu, Qingyu Zhang, Qianhao Yuan, Bingning Wang, Hongyu Lin, Yaojie Lu, Xianpei Han, Weipeng Chen |  |
| 1136 |  |  [ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation](https://aclanthology.org/2025.findings-acl.1036/) |  | 0 | Recently, LLM agents have made rapid progress in improving their programming capabilities. However, existing benchmarks lack the ability to automatically evaluate from users’ perspective, and also lack the explainability of the results of LLM agents’ code generation capabilities. Thus, we introduce... | Kaiyuan Liu, Youcheng Pan, Yang Xiang, Daojing He, Jing Li, Yexing Du, Tianrun Gao |  |
| 1137 |  |  [Unveiling the Lack of LVLM Robustness to Fundamental Visual Variations: Why and Path Forward](https://aclanthology.org/2025.findings-acl.1037/) |  | 0 | Large Vision Language Models (LVLMs) have shown impressive performance on various vision-language tasks. However, while objects in natural scenes inevitably exhibit visual variations in position, scale, orientation, and context due to changes in viewpoint and environment, the robustness of LVLMs to... | Zhiyuan Fan, Yumeng Wang, Sandeep Polisetty, Yi R. Fung |  |
| 1138 |  |  [DYNTEXT: Semantic-Aware Dynamic Text Sanitization for Privacy-Preserving LLM Inference](https://aclanthology.org/2025.findings-acl.1038/) |  | 0 | LLMs face privacy risks when handling sensitive data. To ensure privacy, researchers use differential privacy (DP) to provide protection by adding noise during LLM training. However, users may be hesitant to share complete data with LLMs. Researchers follow local DP to sanitize the text on the user... | Juhua Zhang, Zhiliang Tian, Minghang Zhu, Yiping Song, Taishu Sheng, Siyi Yang, Qiunan Du, Xinwang Liu, Minlie Huang, Dongsheng Li |  |
| 1139 |  |  [InImageTrans: Multimodal LLM-based Text Image Machine Translation](https://aclanthology.org/2025.findings-acl.1039/) |  | 0 | Multimodal large language models (MLLMs) have shown remarkable capabilities across various downstream tasks. However, when MLLMs are transferred to the text image machine translation (TiMT) task, preliminary experiments reveal that MLLMs suffer from serious repetition and omission hallucinations.... | Fei Zuo, Kehai Chen, Yu Zhang, Zhengshan Xue, Min Zhang |  |
| 1140 |  |  [FRAME: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy](https://aclanthology.org/2025.findings-acl.1040/) |  | 0 | Large language models (LLMs) have significantly advanced human language understanding and generation, with pretraining data quality and organization being crucial to their performance. Multi-stage pretraining is a promising approach, but existing methods often lack quantitative criteria for data... | Xuemiao Zhang, Feiyu Duan, Liangyu Xu, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai |  |
| 1141 |  |  [When Large Language Models Meet Speech: A Survey on Integration Approaches](https://aclanthology.org/2025.findings-acl.1041/) |  | 0 | Recent advancements in large language models (LLMs) have spurred interest in expanding their application beyond text-based tasks. A large number of studies have explored integrating other modalities with LLMs, notably speech modality, which is naturally related to text. This paper surveys the... | Zhengdong Yang, Shuichiro Shimizu, Yahan Yu, Chenhui Chu |  |
| 1142 |  |  [KE-MHISTO: Towards a Multilingual Historical Knowledge Extraction Benchmark for Addressing the Long-Tail Problem](https://aclanthology.org/2025.findings-acl.1042/) |  | 0 | Large Language Models (LLMs) face significant challenges when queried about long-tail knowledge, i.e., information that is rarely encountered during their training process. These difficulties arise due to the inherent sparsity of such data. Furthermore, LLMs often lack the ability to verify or... | Arianna Graciotti, Leonardo Piano, Nicolas Lazzari, Enrico Daga, Rocco Tripodi, Valentina Presutti, Livio Pompianu |  |
| 1143 |  |  [TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization](https://aclanthology.org/2025.findings-acl.1043/) |  | 0 | The Key-Value (KV) cache in generative large language models (LLMs) introduces substantial memory overhead. Existing works mitigate this burden by offloading or compressing the KV cache. However, loading the entire cache incurs significant latency due to PCIe bandwidth bottlenecks in CPU-GPU... | Dingyu Yao, Bowen Shen, Zheng Lin, Wei Liu, Jian Luan, Bin Wang, Weiping Wang |  |
| 1144 |  |  [The Elephant in the Room: Exploring the Role of Neutral Words in Language Model Group-Agnostic Debiasing](https://aclanthology.org/2025.findings-acl.1044/) |  | 0 | Large Language Models (LLMs) are increasingly integrated into our daily lives, raising significant ethical concerns, especially about perpetuating stereotypes.While group-specific debiasing methods have made progress, they often fail to address multiple biases simultaneously. In contrast,... | Xinwei Guo, Jiashi Gao, Junlei Zhou, Jiaxin Zhang, Guanhua Chen, Xiangyu Zhao, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei |  |
| 1145 |  |  [LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline](https://aclanthology.org/2025.findings-acl.1045/) |  | 0 | When the complete source sentence is provided, Large Language Models (LLMs) perform excellently in offline machine translation even with a simple prompt “Translate the following sentence from [src lang] into [tgt lang]:”. However, in many real scenarios, the source tokens arrive in a streaming... | Biao Fu, Minpeng Liao, Kai Fan, Chengxi Li, Liang Zhang, Yidong Chen, Xiaodong Shi |  |
| 1146 |  |  [Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning](https://aclanthology.org/2025.findings-acl.1046/) |  | 0 | In natural language processing (NLP) and computer vision (CV), the successful application of foundation models across diverse tasks has demonstrated their remarkable potential. However, despite the rich structural and textual information embedded in knowledge graphs (KGs), existing research of... | Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, ChiMan Vong, Huajun Chen, Wen Zhang |  |
| 1147 |  |  [Generative Error Correction for Emotion-aware Speech-to-text Translation](https://aclanthology.org/2025.findings-acl.1047/) |  | 0 | This paper explores emotion-aware speech-to-text translation (ST) using generative error correction (GER) by large language models (LLMs). Despite recent advancements in ST, the impact of the emotional content has been overlooked. First, we enhance the translation of emotional speech by adopting... | Zhengdong Yang, Sheng Li, Chenhui Chu |  |
| 1148 |  |  [SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms](https://aclanthology.org/2025.findings-acl.1048/) |  | 0 | Existing retrieval methods in Large Language Models show degradation in accuracy when handling temporally distributed conversations, primarily due to their reliance on simple similarity-based retrieval. Unlike existing memory retrieval methods that rely solely on semantic similarity, we propose... | Yuki Hou, Haruki Tamoto, Qinghua Zhao, Homei Miyashita |  |
| 1149 |  |  [Localizing and Mitigating Errors in Long-form Question Answering](https://aclanthology.org/2025.findings-acl.1049/) |  | 0 | Long-form question answering (LFQA) aims to provide thorough and in-depth answers to complex questions, enhancing comprehension. However, such detailed responses are prone to hallucinations and factual inconsistencies, challenging their faithful evaluation. This work introduces HaluQuestQA, the... | Rachneet Singh Sachdeva, Yixiao Song, Mohit Iyyer, Iryna Gurevych |  |
| 1150 |  |  [EMGLLM: Data-to-Text Alignment for Electromyogram Diagnosis Generation with Medical Numerical Data Encoding](https://aclanthology.org/2025.findings-acl.1050/) |  | 0 | Electromyography (EMG) tables are crucial for diagnosing muscle and nerve disorders, and advancing the automation of EMG diagnostics is significant for improving medical efficiency. EMG tables contain extensive continuous numerical data, which current Large Language Models (LLMs) often struggle to... | Zefei Long, Zhenbiao Cao, Wei Chen, Zhongyu Wei |  |
| 1151 |  |  [LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM](https://aclanthology.org/2025.findings-acl.1051/) |  | 0 | Recent advancements in speech-to-speech dialogue systems leverage LLMs for multimodal interactions, yet they remain hindered by fine-tuning requirements, high computational overhead, and text-speech misalignment. Existing speech-enabled LLMs often degrade conversational quality by modifying the... | Sambal Shikhar, Mohammed Irfan Kurpath, Sahal Shaji Mullappilly, Jean Lahoud, Fahad Shahbaz Khan, Rao Muhammad Anwer, Salman H. Khan, Hisham Cholakkal |  |
| 1152 |  |  [Act2P: LLM-Driven Online Dialogue Act Classification for Power Analysis](https://aclanthology.org/2025.findings-acl.1052/) |  | 0 | In team communication, dialogue acts play a crucial role in helping team members understand each other’s intentions and revealing the roles and communication patterns within interactions. Although existing studies have focused on using Dialogue Act classification to capture the speaker’s... | Zhangwenbo Zhangwenbo, Wang Yuhan |  |
| 1153 |  |  [MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP](https://aclanthology.org/2025.findings-acl.1053/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance across various Natural Language Processing (NLP) tasks, largely due to their generalisability and ability to perform tasks without additional training. However, their effectiveness for low-resource languages remains limited. In... | Kurt Micallef, Claudia Borg |  |
| 1154 |  |  [TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring](https://aclanthology.org/2025.findings-acl.1054/) |  | 0 | Research on holistic Automated Essay Scoring (AES) is long-dated; yet, there is a notable lack of attention for assessing essays according to individual traits. In this work, we propose TRATES, a novel trait-specific and rubric-based cross-prompt AES framework that is generic yet specific to the... | Sohaila Eltanbouly, Salam Albatarni, Tamer Elsayed |  |
| 1155 |  |  [DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens](https://aclanthology.org/2025.findings-acl.1055/) |  | 0 | Large Language Models (LLMs) face computational inefficiencies and redundant processing when handling long context inputs, prompting a focus on compression techniques. While existing semantic vector-based compression methods achieve promising performance, these methods fail to account for the... | Shaoshen Chen, Yangning Li, Zishan Xu, Yongqin Zeng, Shunlong Wu, Xinshuo Hu, Zifei Shan, Xin Su, Jiwei Tang, Yinghui Li, HaiTao Zheng |  |
| 1156 |  |  [A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs](https://aclanthology.org/2025.findings-acl.1056/) |  | 0 | Temporal knowledge graph reasoning aims to predict future events with knowledge of existing facts and plays a key role in various downstream tasks. Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives to handle different... | Yimin Deng, Yuxia Wu, Yejing Wang, Guoshuai Zhao, Li Zhu, Qidong Liu, Derong Xu, Zichuan Fu, Xian Wu, Yefeng Zheng, Xiangyu Zhao, Xueming Qian |  |
| 1157 |  |  [MWPO: Enhancing LLMs Performance through Multi-Weight Preference Strength and Length Optimization](https://aclanthology.org/2025.findings-acl.1057/) |  | 0 | Direct Preference Optimization (DPO) have proposed offline alternatives to Reinforcement Learning from Human Feedback (RLHF). In DPO, each preference pair, which serves as the foundation for learning, is typically constructed by first generating multiple responses to the same instruction and then... | Shiyue Xu, Fu Zhang, Jingwei Cheng, Linfeng Zhou |  |
| 1158 |  |  [CLEAR: Character Unlearning in Textual and Visual Modalities](https://aclanthology.org/2025.findings-acl.1058/) |  | 0 | Machine Unlearning (MU) is critical for removing private or hazardous information from deep learning models. While MU has advanced significantly in unimodal (text or vision) settings, multimodal unlearning (MMU) remains underexplored due to the lack of open benchmarks for evaluating cross-modal... | Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Rogov, Ivan V. Oseledets, Elena Tutubalina |  |
| 1159 |  |  [Assessing the Reasoning Capabilities of LLMs in the context of Evidence-based Claim Verification](https://aclanthology.org/2025.findings-acl.1059/) |  | 0 | Although LLMs have shown great performance on Mathematics and Coding related reasoning tasks, the reasoning capabilities of LLMs regarding other forms of reasoning are still an open problem. Here, we examine the issue of reasoning from the perspective of claim verification. We propose a framework... | John DougrezLewis, Mahmud Elahi Akhter, Federico Ruggeri, Sebastian Löbbers, Yulan He, Maria Liakata |  |
| 1160 |  |  [Language Models Lack Temporal Generalization and Bigger is Not Better](https://aclanthology.org/2025.findings-acl.1060/) |  | 0 | This paper presents elaborate testing of various LLMs on their generalization capacities. We finetune six encoder models that have been pretrained with very different data (varying in size, language, and period) on a challenging event detection task in Early Modern Dutch archival texts. Each model... | Stella Verkijk, Piek Vossen, Pia Sommerauer |  |
| 1161 |  |  [DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models](https://aclanthology.org/2025.findings-acl.1061/) |  | 0 | Recent advancements in large language models (LLMs) have significantly enhanced their knowledge and generative capabilities, leading to a surge of interest in leveraging LLMs for high-quality data synthesis. However, synthetic data generation via prompting LLMs remains challenging due to LLMs’... | Ying Zhou, Xinyao Wang, Yulei Niu, Yaojie Shen, Lexin Tang, Fan Chen, Ben He, Le Sun, Longyin Wen |  |
| 1162 |  |  [Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?](https://aclanthology.org/2025.findings-acl.1062/) |  | 0 | Recent advances in handling long sequences have unlocked new possibilities for long-context in-context learning (ICL). While existing research predominantly focuses on performance gains driven by additional in-context examples, the impact on the trustworthiness of generated responses remains... | Yifei Wang, Yu Sheng, Linjing Li, Daniel Dajun Zeng |  |
| 1163 |  |  [ToolSpectrum: Towards Personalized Tool Utilization for Large Language Models](https://aclanthology.org/2025.findings-acl.1063/) |  | 0 | While integrating external tools into large language models (LLMs) enhances their ability to access real-time information and domain-specific services, existing approaches focus narrowly on functional tool selection following user instructions while overlooking the critical role of context-aware... | Zihao Cheng, Hongru Wang, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang |  |
| 1164 |  |  [Reverse Preference Optimization for Complex Instruction Following](https://aclanthology.org/2025.findings-acl.1064/) |  | 0 | Instruction following (IF) is a critical capability for large language models (LLMs). However, handling complex instructions with multiple constraints remains challenging. Previous methods typically select preference pairs based on the number of constraints they satisfy, introducing noise where... | Xiang Huang, TingEn Lin, Feiteng Fang, Yuchuan Wu, Hangyu Li, Yuzhong Qu, Fei Huang, Yongbin Li |  |
| 1165 |  |  [MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens](https://aclanthology.org/2025.findings-acl.1065/) |  | 0 | Audio-Visual Speech Recognition (AVSR) achieves robust speech recognition in noisy environments by combining auditory and visual information. However, recent Large Language Model (LLM) based AVSR systems incur high computational costs due to the high temporal resolution of audio-visual speech... | Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro |  |
| 1166 |  |  [Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation](https://aclanthology.org/2025.findings-acl.1066/) |  | 0 | Dialogue Topic Segmentation (DTS) aims to divide dialogues into coherent segments. DTS plays a crucial role in various NLP downstream tasks, but suffers from chronic problems: data shortage, labeling ambiguity, and incremental complexity of recently proposed solutions. On the other hand, Despite... | Seungmin Lee, Yongsang Yoo, Minhwa Jung, Min Song |  |
| 1167 |  |  [Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion](https://aclanthology.org/2025.findings-acl.1067/) |  | 0 | Although large language models (LLMs) have achieved remarkable advancements, their security remains a pressing concern. One major threat is jailbreak attacks, where adversarial prompts bypass model safeguards to generate harmful or objectionable content. Researchers study jailbreak attacks to... | Tiehan Cui, Yanxu Mao, Peipei Liu, Congying Liu, Datao You |  |
| 1168 |  |  [Verbosity-Aware Rationale Reduction: Sentence-Level Rationale Reduction for Efficient and Effective Reasoning](https://aclanthology.org/2025.findings-acl.1068/) |  | 0 | Large Language Models (LLMs) rely on generating extensive intermediate reasoning units (e.g., tokens, sentences) to enhance final answer quality across a wide range of complex tasks. While this approach has proven effective, it inevitably increases substantial inference costs. Previous methods... | Joonwon Jang, Jaehee Kim, Wonbin Kweon, Seonghyeon Lee, Hwanjo Yu |  |
| 1169 |  |  [Exploring the Role of Mental Health Conversational Agents in Training Medical Students and Professionals: A Systematic Literature Review](https://aclanthology.org/2025.findings-acl.1069/) |  | 0 | The integration of Artificial Intelligence (AI) into mental health education and training (MHET) has become a promising solution to meet the increasing demand for skilled mental health professionals. This systematic review analyses 38 studies on AI-powered conversational agents (CAs) in MHET,... | Thushari Atapattu, Menasha Thilakaratne, Duc Nhan Do, Mahen Herath, Katrina E. Falkner |  |
| 1170 |  |  [Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers](https://aclanthology.org/2025.findings-acl.1070/) |  | 0 | Prompt optimization aims to search for effective prompts that enhance the performance of large language models (LLMs). Although existing prompt optimization methods have discovered effective prompts, they often differ from sophisticated prompts carefully designed by human experts. Prompt design... | Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari, Kento Uchida, Shinichi Shirakawa |  |
| 1171 |  |  [STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation](https://aclanthology.org/2025.findings-acl.1071/) |  | 0 | Stories are central to human culture, serving to share ideas, preserve traditions, and foster connections. Automatic story generation, a key advancement in artificial intelligence (AI), offers new possibilities for creating personalized content, exploring creative ideas, and enhancing interactive... | Jiaming Li, Yukun Chen, Ziqiang Liu, Minghuan Tan, Lei Zhang, Yunshui Li, Run Luo, Longze Chen, Jing Luo, Ahmadreza Argha, Hamid AlinejadRokny, Wei Zhou, Min Yang |  |
| 1172 |  |  [SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models](https://aclanthology.org/2025.findings-acl.1072/) |  | 0 | Large language models (LLMs) have been widely adopted due to their remarkable performance across various applications, driving the accelerated development of a large number of diverse models. However, these individual LLMs show limitations in generalization and performance on complex tasks due to... | Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar |  |
| 1173 |  |  [SkyLLM: Cross-LLM-APIs Federation for Cost-effective Query Processing](https://aclanthology.org/2025.findings-acl.1073/) |  | 0 | Large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks, from text generation to complex problem-solving. LLM APIs provide easy access to these models by streamlining deployment and usage. Combining LLMs with complementary strengths has been shown to... | Heng Zhao, Yifei Zhu |  |
| 1174 |  |  [Matina: A Culturally-Aligned Persian Language Model Using Multiple LoRA Experts](https://aclanthology.org/2025.findings-acl.1074/) |  | 0 | Large language models (LLMs) are powerful tools for a variety of applications, but to interact effectively with users, they must align with the cultural values and linguistic nuances of their audience. However, existing LLMs often fall short in adequately modeling underrepresented languages and... | Sara Bourbour Hosseinbeigi, Mohammad Ali Seif Kashani, Javad Seraj, Fatemeh Taherinezhad, Ali Nafisi, Fatemeh Nadi, Iman Barati, Hosein Hasani, Mostafa Amiri, Mostafa Masoudi |  |
| 1175 |  |  [PM3-KIE: A Probabilistic Multi-Task Meta-Model for Document Key Information Extraction](https://aclanthology.org/2025.findings-acl.1075/) |  | 0 | Key Information Extraction (KIE) from visually rich documents is commonly approached as either fine-grained token classification or coarse-grained entity extraction. While token-level models capture spatial and visual cues, entity-level models better represent logical dependencies and align with... | Birgit Kirsch, Héctor AllendeCid, Stefan Rüping |  |
| 1176 |  |  [TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text](https://aclanthology.org/2025.findings-acl.1076/) |  | 0 | Accurately identifying adversarial techniques in security texts is critical for effective cyber defense. However, existing methods face a fundamental trade-off: they either rely on generic models with limited domain precision or require resource-intensive pipelines that depend on large labeled... | Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md. Rizwan Parvez |  |
| 1177 |  |  [G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models](https://aclanthology.org/2025.findings-acl.1077/) |  | 0 | Forecasting over Temporal Knowledge Graphs (TKGs) which predicts future facts based on historical ones has received much attention. Recent studies have introduced Large Language Models (LLMs) for this task to enhance the models’ generalization abilities. However, these models perform forecasting... | Long Bai, Zixuan Li, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng, TatSeng Chua |  |
| 1178 |  |  [Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning](https://aclanthology.org/2025.findings-acl.1078/) |  | 0 | When using agent-task datasets to enhance agent capabilities for Large Language Models (LLMs), current methodologies often treat all tokens within a sample equally. However, we argue that tokens serving different roles—specifically, reasoning tokens versus boilerplate tokens (e.g., those governing... | Ziang Ye, Zhenru Zhang, Yang Zhang, Jianxin Ma, Junyang Lin, Fuli Feng |  |
| 1179 |  |  [APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training](https://aclanthology.org/2025.findings-acl.1079/) |  | 0 | Large Language Models (LLMs) often require domain-specific fine-tuning to address targeted tasks, which risks degrading their general capabilities. Maintaining a balance between domain-specific enhancements and general model utility is a key challenge. This paper proposes a novel approach named APT... | Jun Rao, Zepeng Lin, Xuebo Liu, Xiaopeng Ke, Lian Lian, Dong Jin, Shengjun Cheng, Jun Yu, Min Zhang |  |
| 1180 |  |  [EasyEA: Large Language Model is All You Need in Entity Alignment Between Knowledge Graphs](https://aclanthology.org/2025.findings-acl.1080/) |  | 0 | Entity alignment (EA) aims to identify entities in different knowledge graphs (KGs) that represent the same real-world objects. Traditional EA methods typically embed entity information into vector space under the guidance of seed entity pairs, and align entities by calculating and comparing the... | Jingwei Cheng, Chenglong Lu, Linyan Yang, Guoqing Chen, Fu Zhang |  |
| 1181 |  |  [An Adaptive Multi-Threshold Loss and a General Framework for Collaborating Losses in Document-Level Relation Extraction](https://aclanthology.org/2025.findings-acl.1081/) |  | 0 | The goal of document-level relation extraction (DocRE) is to identify relations for a given entity pair within a document. As a multilabel classification task, the most commonly employed method involves introducing an adaptive threshold. Specifically, for an entity pair, if the scores of predicted... | Huangming Xu, Fu Zhang, Jingwei Cheng |  |
| 1182 |  |  [RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following](https://aclanthology.org/2025.findings-acl.1082/) |  | 0 | Role-playing is important for Large Language Models (LLMs) to follow diverse instructions while maintaining role identity and the role’s pre-defined ability limits. Existing role-playing datasets mostly contribute to controlling role style and knowledge boundaries, but overlook role-playing in... | Junru Lu, Jiazheng Li, Guodong Shen, Lin Gui, Siyu An, Yulan He, Di Yin, Xing Sun |  |
| 1183 |  |  [C²RBench: A Chinese Complex Reasoning Benchmark for Large Language Models](https://aclanthology.org/2025.findings-acl.1083/) |  | 0 | Large language models (LLMs) have achieved remarkable progress in autonomous reasoning, evolving from basic text processing to sophisticated multimodal reasoning, a critical capability for general-purpose AI assistants. However, existing benchmarks usually fail to adequately capture the intricate... | Junru Wu, Tianhao Shen, Linxi Su, Deyi Xiong |  |
| 1184 |  |  [Unlocking LLMs' Self-Improvement Capacity with Autonomous Learning for Domain Adaptation](https://aclanthology.org/2025.findings-acl.1084/) |  | 0 | Self-supervised pre-training and instruction fine-tuning demonstrate the potential of large language models (LLMs) for domain adaptation (DA). In pursuit of superhuman performance, LLMs have demonstrated significant potential in math and coding through self-improvement algorithms that rely on... | Ke Ji, Junying Chen, Anningzhe Gao, Wenya Xie, Xiang Wan, Benyou Wang |  |
| 1185 |  |  [How Personality Traits Shape LLM Risk-Taking Behaviour](https://aclanthology.org/2025.findings-acl.1085/) |  | 0 | Large Language Models (LLMs) are increasingly deployed as autonomous agents for simulation and decision-making, necessitating a deeper understanding of their decision-making behaviour under risk. We investigate the relationship between LLMs’ personality traits and risk-propensity, applying... | John Hartley, Conor Brian Hamill, Dale Seddon, Devesh Batra, Ramin Okhrati, Raad Khraishi |  |
| 1186 |  |  [Word-Level Detection of Code-Mixed Hate Speech with Multilingual Domain Transfer](https://aclanthology.org/2025.findings-acl.1086/) |  | 0 | The exponential growth of offensive language on social media tends to fuel online harassment and challenges detection mechanisms. Hate speech detection is commonly treated as a monolingual or multilingual sentence-level classification task. However, profane language tends to contain code-mixing, a... | Karin Niederreiter, Dagmar Gromann |  |
| 1187 |  |  [Evaluation of Attribution Bias in Generator-Aware Retrieval-Augmented Large Language Models](https://aclanthology.org/2025.findings-acl.1087/) |  | 0 | Attributing answers to source documents is an approach used to enhance the verifiability of a model’s output in retrieval-augmented generation (RAG). Prior work has mainly focused on improving and evaluating the attribution quality of large language models (LLMs) in RAG, but this may come at the... | Amin Abolghasemi, Leif Azzopardi, Seyyed Hadi Hashemi, Maarten de Rijke, Suzan Verberne |  |
| 1188 |  |  [Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment](https://aclanthology.org/2025.findings-acl.1088/) |  | 0 | Direct Preference Optimization (DPO) has become a prominent method for aligning Large Language Models (LLMs) with human preferences. While DPO has enabled significant progress in aligning English LLMs, multilingual preference alignment is hampered by data scarcity. To address this, we propose a... | Wen Yang, Junhong Wu, Chen Wang, Chengqing Zong, Jiajun Zhang |  |
| 1189 |  |  [Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework](https://aclanthology.org/2025.findings-acl.1089/) |  | 0 | With the widespread application of Large Language Models (LLMs) in various tasks, the mainstream LLM platforms generate massive user-model interactions daily. In order to efficiently analyze the performance of models and diagnose failures in their answers, it is essential to develop an automated... | Zishan Xu, Shuyi Xie, Qingsong Lv, Shupei Xiao, Linlin Song, Sui Wenjuan, Fan Lin |  |
| 1190 |  |  [Encode Errors: Representational Retrieval of In-Context Demonstrations for Multilingual Grammatical Error Correction](https://aclanthology.org/2025.findings-acl.1090/) |  | 0 | Grammatical Error Correction (GEC) involves detecting and correcting the wrong usage of grammar. While large language models (LLMs) with in-context learning (ICL) capabilities have shown significant progress on various natural language processing (NLP) tasks, their few-shot performance on GEC... | Guangyue Peng, Wei Li, Wen Luo, Houfeng Wang |  |
| 1191 |  |  [Preference Curriculum: LLMs Should Always Be Pretrained on Their Preferred Data](https://aclanthology.org/2025.findings-acl.1091/) |  | 0 | Large language models (LLMs) generally utilize a consistent data distribution throughout the pretraining process. However, as the model’s capability improves, it is intuitive that its data preferences dynamically change, indicating the need for pretraining with different data at various training... | Xuemiao Zhang, Liangyu Xu, Feiyu Duan, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai |  |
| 1192 |  |  [Can Input Attributions Explain Inductive Reasoning in In-Context Learning?](https://aclanthology.org/2025.findings-acl.1092/) |  | 0 | Interpreting the internal process of neural models has long been a challenge. This challenge remains relevant in the era of large language models (LLMs) and in-context learning (ICL); for example, ICL poses a new issue of interpreting which example in the few-shot examples contributed to... | Mengyu Ye, Tatsuki Kuribayashi, Goro Kobayashi, Jun Suzuki |  |
| 1193 |  |  [Modal Dependency Parsing via Biaffine Attention with Self-Loop](https://aclanthology.org/2025.findings-acl.1093/) |  | 0 | A modal dependency structure represents a web of connections between events and sources of information in a document that allows for tracing of who-said-what with what levels of certainty, thereby establishing factuality in an event-centric approach. Obtaining such graphs defines the task of modal... | Jayeol Chun, Nianwen Xue |  |
| 1194 |  |  [Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs](https://aclanthology.org/2025.findings-acl.1094/) |  | 0 | Previous approaches to persona simulation large language models (LLMs) have typically relied on learning basic biographical information, or using limited role-play dialogue datasets to capture a character’s responses. However, a holistic representation of an individual goes beyond surface-level... | Zixiao Wang, Duzhen Zhang, Ishita Agrawal, Shen Gao, Le Song, Xiuying Chen |  |
| 1195 |  |  [Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization](https://aclanthology.org/2025.findings-acl.1095/) |  | 0 | Personalizing Large Language Models (LLMs) has become a critical step in facilitating their widespread application to enhance individual life experiences. In pursuit of personalization, distilling key preference information from an individual’s historical data as instructional preference context to... | Yilun Qiu, Xiaoyan Zhao, Yang Zhang, Yimeng Bai, Wenjie Wang, Hong Cheng, Fuli Feng, TatSeng Chua |  |
| 1196 |  |  [VideoRAG: Retrieval-Augmented Generation over Video Corpus](https://aclanthology.org/2025.findings-acl.1096/) |  | 0 | Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the factual accuracy of models by retrieving external knowledge relevant to queries and incorporating it into the generation process. However, existing approaches primarily focus on text, with some recent advancements... | Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang |  |
| 1197 |  |  [Synergistic Augmentation: Enhancing Cross-Domain Zero-Shot Slot Filling with Small Model-Assisted Large Language Models](https://aclanthology.org/2025.findings-acl.1097/) |  | 0 | In real-world scenarios, cross-domain slot filling in spoken language understanding remains a significant challenge due to data scarcity. Previous works exhibit limited generalization ability in the target domain, demonstrating effective knowledge transfer only on seen slots while performing poorly... | Weizhen Li, Junbao Huang, Peijie Huang, Yuhong Xu, Jiekun Fan |  |
| 1198 |  |  [A Classifier of Word-Level Variants in Witnesses of Biblical Hebrew Manuscripts](https://aclanthology.org/2025.findings-acl.1098/) |  | 0 | The current project is inscribed within the field of stemmatology or the study and/or reconstruction of textual transmission based on the relationship between the available witnesses of given texts. In particular, the variants (differences) at the word-level in manuscripts written in Biblical... | Iglika NikolovaStoupak, Maxime Amblard, Sophie RobertHayek, Frédérique Rey |  |
| 1199 |  |  [NOVA: An Iterative Planning Framework for Enhancing Scientific Innovation with Large Language Models](https://aclanthology.org/2025.findings-acl.1099/) |  | 0 | Scientific innovation is pivotal for humanity, and harnessing large language models (LLMs) to generate research ideas could transform discovery. However, existing LLMs often produce simplistic and repetitive suggestions due to their limited ability in acquiring external knowledge for innovation. To... | Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan |  |
| 1200 |  |  [Query-Driven Multimodal GraphRAG: Dynamic Local Knowledge Graph Construction for Online Reasoning](https://aclanthology.org/2025.findings-acl.1100/) |  | 0 | An increasing adoption of Large Language Models (LLMs) in complex reasoning tasks necessitates their interpretability and reliability. Recent advances to that end include retrieval-augmented generation (RAG) and knowledge graph-enhanced RAG (GraphRAG), whereas they are constrained by static... | Chenyang Bu, Guojie Chang, Zihao Chen, CunYuan Dang, Zhize Wu, Yi He, Xindong Wu |  |
| 1201 |  |  [A Survey of Uncertainty Estimation Methods on Large Language Models](https://aclanthology.org/2025.findings-acl.1101/) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, these models could offer biased, hallucinated, or non-factual responses camouflaged by their fluency and realistic appearance. Uncertainty estimation is the key method to address this challenge.... | Zhiqiu Xia, Jinxuan Xu, Yuqian Zhang, Hang Liu |  |
| 1202 |  |  [Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis](https://aclanthology.org/2025.findings-acl.1102/) |  | 0 | Due to the widespread use of LLMs and the rising critical ethical and safety concerns, LLM unlearning methods have been developed to remove harmful knowledge and undesirable capabilities. In this context, evaluations are mostly based on single-value metrics such as QA accuracy. However, these... | Yicheng Lang, Kehan Guo, Yue Huang, Yujun Zhou, Haomin Zhuang, Tianyu Yang, Yao Su, Xiangliang Zhang |  |
| 1203 |  |  [Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review](https://aclanthology.org/2025.findings-acl.1103/) |  | 0 | Evidence-based medicine (EBM) is at the forefront of modern healthcare, emphasizing the use of the best available scientific evidence to guide clinical decisions. Due to the sheer volume and rapid growth of medical literature and the high cost of curation, there is a critical need to investigate... | Zihan Xu, Haotian Ma, Yihao Ding, Gongbo Zhang, Chunhua Weng, Yifan Peng |  |
| 1204 |  |  [How do Transformer Embeddings Represent Compositions? A Functional Analysis](https://aclanthology.org/2025.findings-acl.1104/) |  | 0 | Compositionality is a key aspect of human intelligence, essential for reasoning and generalization. While transformer-based models have become the de facto standard for many language modeling tasks, little is known about how they represent compound words, and whether these representations are... | Aishik Nagar, Ishaan Singh Rawal, Mansi Dhanania, Cheston Tan |  |
| 1205 |  |  [Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems](https://aclanthology.org/2025.findings-acl.1105/) |  | 0 | The retriever, which retrieves relevant knowledge pieces from a knowledge base given a context, is an important component in many natural language processing (NLP) tasks. Retrievers have been introduced in knowledge-grounded dialog systems to improve knowledge acquisition. In knowledge-grounded... | Yucheng Cai, Ke Li, Yi Huang, Junlan Feng, Zhijian Ou |  |
| 1206 |  |  [MONTROSE: LLM-driven Monte Carlo Tree Search Self-Refinement for Cross-Domain Rumor Detection](https://aclanthology.org/2025.findings-acl.1106/) |  | 0 | With the emergence of new topics on social media as sources of rumor dissemination, addressing the distribution shifts between source and target domains remains a crucial task in cross-domain rumor detection. Existing feature alignment methods, which aim to reduce the discrepancies between domains,... | Shanshan Liu, Menglong Lu, Zhen Huang, Zejiang He, Liu Liu, Zhigang Sun, Dongsheng Li |  |
| 1207 |  |  [PEToolLLM: Towards Personalized Tool Learning in Large Language Models](https://aclanthology.org/2025.findings-acl.1107/) |  | 0 | Tool learning has emerged as a promising direction by extending Large Language Models’ (LLMs) capabilities with external tools. Existing tool learning studies primarily focus on the general-purpose tool-use capability, which addresses explicit user requirements in instructions. However, they... | Qiancheng Xu, Yongqi Li, Heming Xia, Fan Liu, Min Yang, Wenjie Li |  |
| 1208 |  |  [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://aclanthology.org/2025.findings-acl.1108/) |  | 0 | Recent advancements in retrieval-augmented generation (RAG) have enhanced large language models in question answering by integrating external knowledge. However, challenges persist in achieving global understanding and aligning responses with human ethical and quality preferences. To address these... | Quanwei Tang, Sophia Yat Mei Lee, Junshuang Wu, Dong Zhang, Shoushan Li, Erik Cambria, Guodong Zhou |  |
| 1209 |  |  [A MISMATCHED Benchmark for Scientific Natural Language Inference](https://aclanthology.org/2025.findings-acl.1109/) |  | 0 | Scientific Natural Language Inference (NLI) is the task of predicting the semantic relation between a pair of sentences extracted from research articles. Existing datasets for this task are derived from various computer science (CS) domains, whereas non-CS domains are completely ignored. In this... | Firoz Shaik, Mobashir Sadat, Nikita Gautam, Doina Caragea, Cornelia Caragea |  |
| 1210 |  |  [TagRouter: Learning Route to LLMs through Tags for Open-Domain Text Generation Tasks](https://aclanthology.org/2025.findings-acl.1110/) |  | 0 | Model routing allocates queries to the suitable model, improving system performance while reducing costs. However, existing routing methods face practical limitations that hinder scalability in large-scale applications and struggle to keep up with the rapid growth of the large language model (LLM)... | Zhou Chen, Zhiqiang Wei, Yuqi Bai, Xue Xiong, Jianmin Wu |  |
| 1211 |  |  [The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction](https://aclanthology.org/2025.findings-acl.1111/) |  | 0 | Large language models (LLMs) excel on a variety of reasoning benchmarks, but previous studies suggest they sometimes struggle to generalize to unseen questions, potentially due to over-reliance on memorized training examples. However, the precise conditions under which LLMs switch between reasoning... | Yihuai Hong, Meng Cao, Dian Zhou, Lei Yu, Zhijing Jin |  |
| 1212 |  |  [MPBench: A Comprehensive Multimodal Reasoning Benchmark for Process Errors Identification](https://aclanthology.org/2025.findings-acl.1112/) |  | 0 | Reasoning is an essential capacity for large language models (LLMs) to address complex tasks, whereas the identification of process errors is vital for improving this ability. Recently, process-level reward models (PRMs) were proposed to provide step-wise rewards that facilitate reinforcement... | Xu Zhao Pan, Pengfei Zhou, Jiaxin Ai, Wangbo Zhao, Kai Wang, Xiaojiang Peng, Wenqi Shao, Hongxun Yao, Kaipeng Zhang |  |
| 1213 |  |  [CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents](https://aclanthology.org/2025.findings-acl.1113/) |  | 0 | The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by... | Tianqi Xu, Linyao Chen, DaiJie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Anjie Yang, Zhaoxuan Jin, Jianbo Deng, Philip Torr, Bernard Ghanem, Guohao Li |  |
| 1214 |  |  [Towards A "Novel" Benchmark: Evaluating Literary Fiction with Large Language Models](https://aclanthology.org/2025.findings-acl.1114/) |  | 0 | Current exploration on creative generation focuses mainly on short stories, poetry, and scripts. With the expansion of Large Language Models (LLMs) context windows, “novel” avenues emerge. This study aims to extend the boundaries of Natural Language Generation (NLG) evaluation by exploring LLMs’... | Wenqing Wang, Mingqi Gao, Xinyu Hu, Xiaojun Wan |  |
| 1215 |  |  [A Reinforcement Learning Framework for Cross-Lingual Stance Detection Using Chain-of-Thought Alignment](https://aclanthology.org/2025.findings-acl.1115/) |  | 0 | Cross-lingual stance detection identifies users’ attitudes toward specific targets in texts by transferring knowledge from source languages to target languages. Previous studies have typically facilitated this transfer by translating and aligning labels or targets. However, these methods cannot... | Binghui Li, Minghui Zou, Xiaowang Zhang, Shizhan Chen, Zhiyong Feng |  |
| 1216 |  |  [CARE-STaR: Constraint-aware Self-taught Reasoner](https://aclanthology.org/2025.findings-acl.1116/) |  | 0 | In real-world applications, large language models (LLMs) often need to handle diverse and complex instructions. Specifically, when instructions are subject to multiple constraints, some of which are somewhat ambiguous, LLMs often fail to produce answers that satisfy all constraints, limiting their... | Zhiliang Li, Bo Tang, Yijun Niu, Beihong Jin, Qiwen Shi, Yuchen Feng, Zhiyu Li, Jie Hu, Mingchuan Yang, Feiyu Xiong |  |
| 1217 |  |  [Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs](https://aclanthology.org/2025.findings-acl.1117/) |  | 0 | Discourse particles are crucial elements that subtly shape the meaning of text. These words, often polyfunctional, give rise to nuanced and often quite disparate semantic/discourse effects,as exemplified by the diverse uses of the particle \*just\* (e.g., exclusive, temporal, emphatic). This work... | William Berkeley Sheffield, Kanishka Misra, Valentina Pyatkin, Ashwini Deo, Kyle Mahowald, Junyi Jessy Li |  |
| 1218 |  |  [War of Thoughts: Competition Stimulates Stronger Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.1118/) |  | 0 | Recent advances in Large Language Models (LLMs) have reshaped the landscape of reasoning tasks, particularly through test-time scaling (TTS) to enhance LLM reasoning. Prior research has used structures such as trees or graphs to guide LLMs in searching for optimal solutions. These methods are... | Yibin Chen, Jinyi Liu, Yan Zheng, Yifu Yuan, Jianye Hao |  |
| 1219 |  |  [Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective Reasoning Distillation](https://aclanthology.org/2025.findings-acl.1119/) |  | 0 | The detection of mental health problems from social media and the interpretation of these results have been extensively explored. Research has shown that incorporating clinical symptom information into a model enhances domain expertise, improving its detection and interpretation performance. While... | Hoyun Song, Huije Lee, Jisu Shin, Sukmin Cho, Changgeon Ko, Jong C. Park |  |
| 1220 |  |  [Rethinking Table Instruction Tuning](https://aclanthology.org/2025.findings-acl.1120/) |  | 0 | Recent advances in table understanding have focused on instruction-tuning large language models (LLMs) for table-related tasks. However, existing research has overlooked the impact of hyperparameter choices, and also lacks a comprehensive evaluation of the out-of-domain table understanding ability... | Naihao Deng, Rada Mihalcea |  |
| 1221 |  |  [CliniDial: A Naturally Occurring Multimodal Dialogue Dataset for Team Reflection in Action During Clinical Operation](https://aclanthology.org/2025.findings-acl.1121/) |  | 0 | In clinical operations, teamwork can be the crucial factor that determines the final outcome. Prior studies have shown that sufficient collaboration is the key factor that determines the outcome of an operation. To understand how the team practices teamwork during the operation, we collected... | Naihao Deng, Kapotaksha Das, Rada Mihalcea, Vitaliy Popov, Mohamed Abouelenien |  |
| 1222 |  |  [Chumor 2.0: Towards Better Benchmarking Chinese Humor Understanding from (Ruo Zhi Ba)](https://aclanthology.org/2025.findings-acl.1122/) |  | 0 | Existing humor datasets and evaluations predominantly focus on English, leaving limited resources for culturally nuanced humor in non-English languages like Chinese. To address this gap, we construct \*\*Chumor\*\*, the first and the largest Chinese humor explanation dataset. \*\*Chumor\*\* is... | Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, Rada Mihalcea, Naihao Deng |  |
| 1223 |  |  [Explicit Bayesian Inference to Uncover the Latent Themes of Large Language Models](https://aclanthology.org/2025.findings-acl.1123/) |  | 0 | Large language models (LLMs) have demonstrated impressive generative capabilities, yet their inner mechanisms remain largely opaque. In this work, we introduce a novel approach to interpret LLMs generation process through the lens of an explicit Bayesian framework by inferring latent topic... | Raymond Li, Chuyuan Li, Gabriel Murray, Giuseppe Carenini |  |
| 1224 |  |  [Improving Occupational ISCO Classification of Multilingual Swiss Job Postings with LLM-Refined Training Data](https://aclanthology.org/2025.findings-acl.1124/) |  | 0 | Classifying occupations in multilingual job postings is challenging due to noisy labels, language variation, and domain-specific terminology. We present a method that refines silver-standard ISCO labels by consolidating them with predictions from pre-fine-tuned models, using large language model... | AnnSophie Gnehm, Simon Clematide |  |
| 1225 |  |  [Brevity is the soul of sustainability: Characterizing LLM response lengths](https://aclanthology.org/2025.findings-acl.1125/) |  | 0 | A significant portion of the energy consumed by Large Language Models (LLMs) arises from their inference processes; hence developing energy-efficient methods for inference is crucial. While several techniques exist for inference optimization, output compression remains relatively unexplored, with... | Soham Poddar, Paramita Koley, Janardan Misra, Niloy Ganguly, Saptarshi Ghosh |  |
| 1226 |  |  [Adversarial Preference Learning for Robust LLM Alignment](https://aclanthology.org/2025.findings-acl.1126/) |  | 0 | Modern language models often rely on Reinforcement Learning from Human Feedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to adversarial attacks due to three key limitations: (1) the inefficiency and high cost of human annotation, (2) the vast diversity of potential... | Yuanfu Wang, Pengyu Wang, Chenyang Xi, Bo Tang, Junyi Zhu, Wenqiang Wei, Chen Chen, Chao Yang, Jingfeng Zhang, Chaochao Lu, Yijun Niu, Keming Mao, Zhiyu Li, Feiyu Xiong, Jie Hu, Mingchuan Yang |  |
| 1227 |  |  [gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures](https://aclanthology.org/2025.findings-acl.1127/) |  | 0 | Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by converting programs into forms that are more complex to analyze. However, MBA has been increasingly exploited by malware developers to evade detection and cause significant real-world problems. Traditional MBA... | Youjeong Noh, JoonYoung Paik, Jingun Kwon, EunSun Cho |  |
| 1228 |  |  [READoc: A Unified Benchmark for Realistic Document Structured Extraction](https://aclanthology.org/2025.findings-acl.1128/) |  | 0 | Document Structured Extraction (DSE) aims to extract structured content from raw documents. Despite the emergence of numerous DSE systems, their unified evaluation remains inadequate, significantly hindering the field’s advancement. This problem is largely attributed to existing benchmark... | Zichao Li, Aizier Abulaiti, Yaojie Lu, Xuanang Chen, Jia Zheng, Hongyu Lin, Xianpei Han, Shanshan Jiang, Bin Dong, Le Sun |  |
| 1229 |  |  [TicTac: Time-aware Supervised Fine-tuning for Automatic Text Dating](https://aclanthology.org/2025.findings-acl.1129/) |  | 0 | Pre-trained langauge models have achieved success in many natural language processing tasks, whereas they are trapped by the time-agnostic setting, impacting the performance in automatic text dating. This paper introduces TicTac, a supervised fine-tuning model for automatic text dating. Unlike the... | Han Ren, Minna Peng |  |
| 1230 |  |  [Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting](https://aclanthology.org/2025.findings-acl.1130/) |  | 0 | Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Current approaches either assemble specialized expert models or directly generate page-level content autoregressively, facing integration overhead, efficiency... | Hao Feng, Shu Wei, Xiang Fei, Wei Shi, Yingdong Han, Lei Liao, Jinghui Lu, Binghong Wu, Qi Liu, Chunhui Lin, Jingqun Tang, Hao Liu, Can Huang |  |
| 1231 |  |  [FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis](https://aclanthology.org/2025.findings-acl.1131/) |  | 0 | Parody is an emerging phenomenon on social media, where individuals imitate a role or position opposite to their own, often for humor, provocation, or controversy. Detecting and analyzing parody can be challenging and is often reliant on context, yet it plays a crucial role in understanding... | Yilun Zheng, Sha Li, Fangkun Wu, Yang Ziyi, Lin Hongchao, Zhichao Hu, Cai Xinjun, Ziming Wang, Jinxuan Chen, Sitao Luan, Jiahao Xu, Lihui Chen |  |
| 1232 |  |  [P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs](https://aclanthology.org/2025.findings-acl.1132/) |  | 0 | This study explores the potential of phonological reasoning within text-based large language models (LLMs). Utilizing the PhonologyBench benchmark, we assess tasks like rhyme word generation, g2p conversion, and syllable counting. Our evaluations across 12 LLMs reveal that while few-shot learning... | Dongjun Jang, Youngchae Ahn, Hyopil Shin |  |
| 1233 |  |  [DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation](https://aclanthology.org/2025.findings-acl.1133/) |  | 0 | The rapid advancement of large language models (LLMs) has significantly improved their performance in code generation tasks. However, existing code benchmarks remain static, consisting of fixed datasets with predefined problems. This makes them vulnerable to memorization during training, where LLMs... | Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, Kaidi Xu |  |
| 1234 |  |  [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://aclanthology.org/2025.findings-acl.1134/) |  | 0 | Augmenting large language models (LLMs) with external context significantly improves their performance in natural language processing (NLP) tasks. However, LLMs struggle to answer queries reliably when the provided context lacks information, often resorting to ungrounded speculation or internal... | Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar |  |
| 1235 |  |  [KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding](https://aclanthology.org/2025.findings-acl.1135/) |  | 0 | With the growing adoption of Retrieval-Augmented Generation (RAG) in document processing, robust text recognition has become increasingly critical for knowledge extraction. While OCR (Optical Character Recognition) for English and other languages benefits from large datasets and well-established... | Ahmed Heakl, Muhammad Abdullah Sohail, Mukul Ranjan, Rania Elbadry, Ghazi Shazan Ahmad, Mohamed ElGeish, Omar Maher, Zhiqiang Shen, Fahad Shahbaz Khan, Salman H. Khan |  |
| 1236 |  |  [Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness](https://aclanthology.org/2025.findings-acl.1136/) |  | 0 | Despite a growing literature finding that large language models (LLMs) exhibit demographic biases, reports with whom they align best are hard to generalize or even contradictory. In this work, we examine the alignment of LLMs with human annotations in five offensive language datasets, comprising... | Shayan Alipour, Indira Sen, Mattia Samory, Tanushree Mitra |  |
| 1237 |  |  [AL-QASIDA: Analyzing LLM Quality and Accuracy Systematically in Dialectal Arabic](https://aclanthology.org/2025.findings-acl.1137/) |  | 0 | Dialectal Arabic (DA) varieties are under-served by language technologies, particularly large language models (LLMs). This trend threatens to exacerbate existing social inequalities and limits LLM applications, yet the research community lacks operationalized performance measurements in DA. We... | Nathaniel Romney Robinson, Shahd Abdelmoneim, Kelly Marchisio, Sebastian Ruder |  |
| 1238 |  |  [Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?](https://aclanthology.org/2025.findings-acl.1138/) |  | 0 | Large Language Models (LLMs) have been evaluated using diverse question types, e.g., multiple-choice, true/false, and short/long answers. This study answers an unexplored question about the impact of different question types on LLM accuracy on reasoning tasks. We investigate the performance of five... | Seok Hwan Song, Mohna Chakraborty, Qi Li, Wallapak Tavanapong |  |
| 1239 |  |  [MutantPrompt: Prompt Optimization via Mutation Under a Budget on Modest-sized LMs](https://aclanthology.org/2025.findings-acl.1139/) |  | 0 | Prompts serve as a critical instruction interface to unlock the diverse capabilities of Large Language Models (LLMs), thus directly influencing the quality of their outputs. While prompt engineering has shown great promise, identifying optimal prompts remains a significant challenge, particularly... | Arijit Nag, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti |  |
| 1240 |  |  [Heuristic-based Search Algorithm in Automatic Instruction-focused Prompt Optimization: A Survey](https://aclanthology.org/2025.findings-acl.1140/) |  | 0 | Recent advances in Large Language Models(LLMs) have led to remarkable achievements across a variety of Natural Language Processing(NLP) tasks, making prompt engineering increasingly central to guiding model outputs. While manual methods (e.g., “chain-of-thought,” “step-by-step” prompts) can be... | Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A. Malin, Kumar Sricharan |  |
| 1241 |  |  [CONSENSAGENT: Towards Efficient and Effective Consensus in Multi-Agent LLM Interactions Through Sycophancy Mitigation](https://aclanthology.org/2025.findings-acl.1141/) |  | 0 | Multi-agent large language model (LLM) systems have shown remarkable performance in tasks such as reasoning, planning, and decision-making. However, their applicability is limited by challenges such as high computational costs and robustness issues. In this work, we identify and systematically... | Priya Pitre, Naren Ramakrishnan, Xuan Wang |  |
| 1242 |  |  [The Structural Safety Generalization Problem](https://aclanthology.org/2025.findings-acl.1142/) |  | 0 | LLM jailbreaks are a widespread safety challenge. Given this problem has not yet been tractable, we suggest targeting a key failure mechanism: the failure of safety to generalize across semantically equivalent inputs. We further focus the target by requiring desirable tractability properties of... | Julius Broomfield, Tom Gibbs, George Ingebretsen, Ethan KosakHine, Tia Nasir, Jason Zhang, Reihaneh Iranmanesh, Sara Pieri, Reihaneh Rabbany, Kellin Pelrine |  |
| 1243 |  |  [DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization](https://aclanthology.org/2025.findings-acl.1143/) |  | 0 | The rapid advancement of large language models (LLMs) has revolutionized numerous applications, but presents significant challenges in aligning these models with diverse human values, ethical standards, and specific user preferences. Direct Preference Optimization (DPO) has become a cornerstone for... | Amitava Das, Suranjana Trivedy, Danush Khanna, Yaswanth Narsupalli, Basab Ghosh, Rajarshi Roy, Gurpreet Singh, Vinija Jain, Vasu Sharma, Aishwarya Naresh Reganti, Aman Chadha |  |
| 1244 |  |  [Model-Dependent Moderation: Inconsistencies in Hate Speech Detection Across LLM-based Systems](https://aclanthology.org/2025.findings-acl.1144/) |  | 0 | Content moderation systems powered by large language models (LLMs) are increasingly deployed to detect hate speech; however, no systematic comparison exists between different systems. If different systems produce different outcomes for the same content, it undermines consistency and predictability,... | Neil Fasching, Yphtach Lelkes |  |
| 1245 |  |  [Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification](https://aclanthology.org/2025.findings-acl.1145/) |  | 0 | The explosion of textual data has made manual document classification increasingly challenging. To address this, we introduce a robust, efficient domain-agnostic generative model framework for multi-label text classification. Instead of treating labels as mere atomic symbols, our approach utilizes... | Subhendu Khatuya, Shashwat Naidu, Saptarshi Ghosh, Pawan Goyal, Niloy Ganguly |  |
| 1246 |  |  [Unsupervised Morphological Tree Tokenizer](https://aclanthology.org/2025.findings-acl.1146/) |  | 0 | As a cornerstone in language modeling, tokenization involves segmenting text inputs into pre-defined atomic units. Conventional statistical tokenizers often disrupt constituent boundaries within words, thereby corrupting semantic information. To address this drawback, we introduce morphological... | Qingyang Zhu, Xiang Hu, Pengyu Ji, Wei Wu, Kewei Tu |  |
| 1247 |  |  [CausalLink: An Interactive Evaluation Framework for Causal Reasoning](https://aclanthology.org/2025.findings-acl.1147/) |  | 0 | We present CausalLink, an innovative evaluation framework that interactively assesses thecausal reasoning skill to identify the correct intervention in conversational language models. Each CausalLink test case creates a hypothetical environment in which the language models are instructed to apply... | Jinyue Feng, Frank Rudzicz |  |
| 1248 |  |  [Toward Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)](https://aclanthology.org/2025.findings-acl.1148/) |  | 0 | The field of machine translation has achieved significant advancements, yet domain-specific terminology translation, particularly in AI, remains challenging. This work introduces GIST, a large-scale multilingual AI terminology dataset containing 5K terms extracted from top AI conference papers... | Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona T. Diab |  |
| 1249 |  |  [A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in LLM Agents](https://aclanthology.org/2025.findings-acl.1149/) |  | 0 | Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex problem solving. Existing efforts for tool utilization typically involve an LLM agent that contains instructions on using the description of the available tools to determine and call the... | Bin Wu, Edgar Meij, Emine Yilmaz |  |
| 1250 |  |  [When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits](https://aclanthology.org/2025.findings-acl.1150/) |  | 0 | Online misinformation remains a critical challenge, and fact-checkers increasingly rely on claim matching systems that use sentence embedding models to retrieve relevant fact-checks. However, as users interact with claims online, they often introduce edits, and it remains unclear whether current... | Jabez Magomere, Emanuele La Malfa, Manuel Tonneau, Ashkan Kazemi, Scott A. Hale |  |
| 1251 |  |  [Splintering Nonconcatenative Languages for Better Tokenization](https://aclanthology.org/2025.findings-acl.1151/) |  | 0 | Common subword tokenization algorithms like BPE and UnigramLM assume that text can be split into meaningful units by concatenative measures alone. This is not true for languages such as Hebrew and Arabic, where morphology is encoded in root-template patterns, or Malay and Georgian, where split... | Bar Gazit, Shaltiel Shmidman, Avi Shmidman, Yuval Pinter |  |
| 1252 |  |  [Aria-UI: Visual Grounding for GUI Instructions](https://aclanthology.org/2025.findings-acl.1152/) |  | 0 | Digital agents for automating tasks across different platforms by directly manipulating the GUIs are increasingly important. For these agents, grounding from language instructions to target elements remains a significant challenge due to reliance on HTML or AXTree inputs. In this paper, we... | Yuhao Yang, Yue Wang, Dongxu Li, Ziyang Luo, Bei Chen, Chao Huang, Junnan Li |  |
| 1253 |  |  [Revealing Hidden Mechanisms of Cross-Country Content Moderation with Natural Language Processing](https://aclanthology.org/2025.findings-acl.1153/) |  | 0 | The ability of Natural Language Processing (NLP) methods to categorize text into multiple classes has motivated their use in online content moderation tasks, such as hate speech and fake news detection. However, there is limited understanding of how or why these methods make such decisions, or why... | Neemesh Yadav, Jiarui Liu, Francesco Ortu, Roya Ensafi, Zhijing Jin, Rada Mihalcea |  |
| 1254 |  |  [Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation](https://aclanthology.org/2025.findings-acl.1154/) |  | 0 | This paper introduces Unilogit, a novel self-distillation method for machine unlearning in Large Language Models. Unilogit addresses the challenge of selectively forgetting specific information while maintaining overall model utility, a critical task in compliance with data privacy regulations like... | Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz |  |
| 1255 |  |  [Creating a Lens of Chinese Culture: A Multimodal Dataset for Chinese Pun Rebus Art Understanding](https://aclanthology.org/2025.findings-acl.1155/) |  | 0 | Large vision-language models (VLMs) have demonstrated remarkable abilities in understanding everyday content. However, their performance in the domain of art, particularly culturally rich art forms, remains less explored. As a pearl of human wisdom and creativity, art encapsulates complex cultural... | Tuo Zhang, Tiantian Feng, Yibin Ni, Mengqin Cao, Ruying Liu, Kiana Avestimehr, Katharine Butler, Yanjun Weng, Mi Zhang, Shrikanth Narayanan, Salman Avestimehr |  |
| 1256 |  |  [FastDraft: How to Train Your Draft](https://aclanthology.org/2025.findings-acl.1156/) |  | 0 | Speculative Decoding has gained popularity as an effective technique for accelerating the auto-regressive inference process of Large Language Models. However, Speculative Decoding entirely relies on the availability of efficient draft models, which are often lacking for many existing language... | Ofir Zafrir, Igor Margulis, Dorin Shteyman, Shira Guskin, Guy Boudoukh |  |
| 1257 |  |  [SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale](https://aclanthology.org/2025.findings-acl.1157/) |  | 0 | A persistent challenge in sign language video processing, including the task of sign language to written language translation, is how we train efficient model given the nature of videos. Informed by the nature and linguistics of signed languages, our proposed method focuses on just the most... | Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu |  |
| 1258 |  |  [GUI Agents: A Survey](https://aclanthology.org/2025.findings-acl.1158/) |  | 0 | Graphical User Interface (GUI) agents, powered by Large Foundation Models, have emerged as a transformative approach to automating human-computer interaction. These agents autonomously interact with digital systems via GUIs, emulating human actions such as clicking, typing, and navigating visual... | Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zhengmian Hu, Hanjia Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie Chen, Viet Dac Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Md. Mehrab Tanjim, Nesreen K. Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav Kveton, Jihyung Kil, Thien Huu Nguyen, Trung Bui, Tianyi Zhou, Ryan A. Rossi, Franck Dernoncourt |  |
| 1259 |  |  [MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes](https://aclanthology.org/2025.findings-acl.1159/) |  | 0 | Several studies have shown that Large Language Models (LLMs) can answer medical questions correctly, even outperforming the average human score in some medical exams. However, to our knowledge, no study has been conducted to assess the ability of language models to validate existing or generated... | Asma Ben Abacha, Wenwai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin |  |
| 1260 |  |  [Understanding the Influence of Synthetic Data for Text Embedders](https://aclanthology.org/2025.findings-acl.1160/) |  | 0 | Recent progress in developing general purpose text embedders has been driven by training on ever-growing corpora of synthetic LLM-generated data. Nonetheless, no publicly available synthetic dataset exists, posing a barrier to studying its role for generalization. To address this issue, we first... | Jacob Mitchell Springer, Vaibhav Adlakha, Siva Reddy, Aditi Raghunathan, Marius Mosbach |  |
| 1261 |  |  [Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models](https://aclanthology.org/2025.findings-acl.1161/) |  | 0 | This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially non-factual responses highlights the need for... | Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri |  |
| 1262 |  |  [Tell, Don't Show: Leveraging Language Models' Abstractive Retellings to Model Literary Themes](https://aclanthology.org/2025.findings-acl.1162/) |  | 0 | Conventional bag-of-words approaches for topic modeling, like latent Dirichlet allocation (LDA), struggle with literary text. Literature challenges lexical methods because narrative language focuses on immersive sensory details instead of abstractive description or exposition: writers are advised... | Li Lucy, Camilla Griffiths, Sarah Levine, Jennifer L. Eberhardt, Dorottya Demszky, David Bamman |  |
| 1263 |  |  [BottleHumor: Self-Informed Humor Explanation using the Information Bottleneck Principle](https://aclanthology.org/2025.findings-acl.1163/) |  | 0 | Humor is prevalent in online communications and it often relies on more than one modality (e.g., cartoons and memes).Interpreting humor in multimodal settings requires drawing on diverse types of knowledge, including metaphorical, sociocultural, and commonsense knowledge. However, identifying the... | Eunjeong Hwang, Peter West, Vered Shwartz |  |
| 1264 |  |  [Financial Language Model Evaluation (FLaME)](https://aclanthology.org/2025.findings-acl.1164/) |  | 0 | Language Models (LMs) have demonstrated impressive capabilities with core Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly specialized knowledge-intensive tasks in finance remains difficult to assess due to major gaps in the methodologies of existing evaluation... | Glenn Matlin, Mika Okamoto, Huzaifa Pardawala, Yang Yang, Sudheer Chava |  |
| 1265 |  |  [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://aclanthology.org/2025.findings-acl.1165/) |  | 0 | Large language models (LLMs) have revolutionized natural language processing (NLP), particularly through Retrieval-Augmented Generation (RAG), which enhances LLM capabilities by integrating external knowledge. However, traditional RAG systems face critical limitations, including disrupted... | Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary |  |
| 1266 |  |  [Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation](https://aclanthology.org/2025.findings-acl.1166/) |  | 0 | Safety reasoning is a recent paradigm where LLMs reason over safety policies before generating responses, thereby mitigating limitations in existing safety measures such as over-refusal and jailbreak vulnerabilities. However, implementing this paradigm is challenging due to the resource-intensive... | Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard S. Zemel, KaiWei Chang, Aram Galstyan, Rahul Gupta, Charith Peris |  |
| 1267 |  |  [Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from LLMs](https://aclanthology.org/2025.findings-acl.1167/) |  | 0 | In search settings, calibrating the scores during the ranking process to quantities such as click-through rates or relevance levels enhances a system’s usefulness and trustworthiness for downstream users. While previous research has improved this notion of calibration for low complexity... | Puxuan Yu, Daniel Cohen, Hemank Lamba, Joel R. Tetreault, Alejandro Jaimes |  |
| 1268 |  |  [Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models](https://aclanthology.org/2025.findings-acl.1168/) |  | 0 | Dense embeddings are fundamental to modern machine learning systems, powering Retrieval-Augmented Generation (RAG), information retrieval, and representation learning. While instruction-conditioning has become the dominant approach for embedding specialization, its direct application to... | Miguel Romero Calvo, Shuoyang Ding, Corey D. Barrett, Georgiana Dinu, George Karypis |  |
| 1269 |  |  [Metagent-P: A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds](https://aclanthology.org/2025.findings-acl.1169/) |  | 0 | The challenge of developing agents capable of open-world planning remains fundamental to artificial general intelligence (AGI). While large language models (LLMs) have made progress with their vast world knowledge, their limitations in perception, memory, and reliable reasoning still hinder... | Yanfang Zhou, Yuntao Liu, Xiaodong Li, Yongqiang Zhao, Xintong Wang, Jinlong Tian, Zhenyu Li, Xinhai Xu |  |
| 1270 |  |  [Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison](https://aclanthology.org/2025.findings-acl.1170/) |  | 0 | Query-driven recommendation with unknown items poses a challenge for users to understand why certain items are appropriate for their needs. Query-driven Contrastive Summarization (QCS) is a methodology designed to address this issue by leveraging language-based item descriptions to clarify... | GeorgeKirollos Saad, Scott Sanner |  |
| 1271 |  |  [Inductive Linguistic Reasoning with Large Language Models](https://aclanthology.org/2025.findings-acl.1171/) |  | 0 | Evaluating large language models (LLMs) on their linguistic reasoning capabilities is an important task to understand the gaps in their skills that may surface during large-scale adoption. In this work, we investigate the abilities of such models to perform abstract multilingual reasoning through... | Raghav Ramji, Keshav Ramji |  |
| 1272 |  |  [Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions](https://aclanthology.org/2025.findings-acl.1172/) |  | 0 | Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness in reasoning tasks remains an open question. To this end, in... | Pengfei Hong, Navonil Majumder, Deepanway Ghosal, Somak Aditya, Rada Mihalcea, Soujanya Poria |  |
| 1273 |  |  [Exploiting Phonetics and Glyph Representation at Radical-level for Classical Chinese Understanding](https://aclanthology.org/2025.findings-acl.1173/) |  | 0 | The diachronic gap between classical and modern Chinese arises from century-scale language evolution through cumulative changes in phonological, syntactic, and lexical systems, resulting in substantial semantic variation that poses significant challenges for the computational modeling of historical... | Junyi Xiang, Maofu Liu |  |
| 1274 |  |  [Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training](https://aclanthology.org/2025.findings-acl.1174/) |  | 0 | Large language models (LLMs) have become the backbone of modern natural language processing but pose privacy concerns about leaking sensitive training data. Membership inference attacks (MIAs), which aim to infer whether a sample is included in a model’s training dataset, can serve as a foundation... | Toan Tran, Ruixuan Liu, Li Xiong |  |
| 1275 |  |  [Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics](https://aclanthology.org/2025.findings-acl.1175/) |  | 0 | Improvements in large language models have led to increasing optimism that they can serve as reliable evaluators of natural language generation outputs. In this paper, we challenge this optimism in regards to factuality evaluation.We re-evaluate five state-of-the-art factuality metrics on a... | Ameya Godbole, Robin Jia |  |
| 1276 |  |  [TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation](https://aclanthology.org/2025.findings-acl.1176/) |  | 0 | Evaluating tables qualitatively and quantitatively poses a significant challenge, as standard metrics often overlook subtle structural and content-level discrepancies. To address this, we propose a rubric-based evaluation framework that integrates multi-level structural descriptors with... | Vihang Pancholi, Jainit Sushil Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta |  |
| 1277 |  |  [LADDER: Language-Driven Slice Discovery and Error Rectification in Vision Classifiers](https://aclanthology.org/2025.findings-acl.1177/) |  | 0 | Slice discovery refers to identifying systematic biases in the mistakes of pre-trained vision models. Current slice discovery methods in computer vision rely on converting input images into sets of attributes and then testing hypotheses about configurations of these pre-computed attributes... | Shantanu Ghosh, Rayan Syed, Chenyu Wang, Vaibhav Choudhary, Binxu Li, Clare B. Poynton, Shyam Visweswaran, Kayhan Batmanghelich |  |
| 1278 |  |  [GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning](https://aclanthology.org/2025.findings-acl.1178/) |  | 0 | Large Language Models (LLMs) fine-tuning technologies have achieved remarkable results. However, traditional LLM fine-tuning approaches face significant challenges: they require large Floating Point(FP) computation, raising privacy concerns when handling sensitive data, and are impractical for... | Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang |  |
| 1279 |  |  [Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings](https://aclanthology.org/2025.findings-acl.1179/) |  | 0 | Large Language Models (LLMs) recently achieved great success in medical text summarization by simply using in-context learning. However, these recent efforts do not perform fine-grained evaluations under difficult settings where LLMs might fail. They typically report performance scores over the... | Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly |  |
| 1280 |  |  [UniT: One Document, Many Revisions, Too Many Edit Intention Taxonomies](https://aclanthology.org/2025.findings-acl.1180/) |  | 0 | Writing is inherently iterative, each revision enhancing information representation. One revision may contain many edits. Examination of the intentions behind edits provides valuable insights into an editor’s expertise, the dynamics of collaborative writing, and the evolution of a document. Current... | Fangping Lan, Abdullah Aljebreen, Eduard C. Dragut |  |
| 1281 |  |  [Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration](https://aclanthology.org/2025.findings-acl.1181/) |  | 0 | Automatic depression detection provides cues for early clinical intervention by clinicians. Clinical interviews for depression detection involve dialogues centered around multiple themes. Existing studies primarily design end-to-end neural network models to capture the hierarchical structure of... | Xianbing Zhao, Yiqing Lyu, Di Wang, Buzhou Tang |  |
| 1282 |  |  [Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training](https://aclanthology.org/2025.findings-acl.1182/) |  | 0 | Large Language Models (LLMs) have demonstrated strong reasoning capabilities across various tasks. However, even minor variations in query phrasing, despite preserving the underlying semantic meaning, can significantly affect their performance. To address this, we focus on enhancing LLMs’ awareness... | Yihang Yao, Zhepeng Cen, Miao Li, William Han, Yuyou Zhang, Emerson Liu, Zuxin Liu, Chuang Gan, Ding Zhao |  |
| 1283 |  |  [TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators](https://aclanthology.org/2025.findings-acl.1183/) |  | 0 | Triton, a high-level Python-like language designed for building efficient GPU kernels, is widely adopted in deep learning frameworks due to its portability, flexibility, and accessibility. However, programming and parallel optimization still require considerable trial and error from Triton... | Jianling Li, Shangzhan Li, Zhenye Gao, Qi Shi, Yuxuan Li, Zefan Wang, Jiacheng Huang, WangHaojie WangHaojie, Jianrong Wang, Xu Han, Zhiyuan Liu, Maosong Sun |  |
| 1284 |  |  [Just KIDDIN' : Knowledge Infusion and Distillation for Detection of INdecent Memes](https://aclanthology.org/2025.findings-acl.1184/) |  | 0 | Detecting toxicity in online multimodal environments, such as memes, remains a challenging task due to the complex contextual connections across modalities (e.g., text and visual), which demand both common-sense reasoning and contextual awareness. To bridge this gap, we propose a hybrid... | Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru |  |
| 1285 |  |  [Dynamic Personality in LLM Agents: A Framework for Evolutionary Modeling and Behavioral Analysis in the Prisoner's Dilemma](https://aclanthology.org/2025.findings-acl.1185/) |  | 0 | Using Large Language Model agents to simulate human game behaviors offers valuable insights for human social psychology in anthropomorphic AI research. While current models rely on static personality traits, real-world evidence shows personality evolves through environmental feedback. Recent work... | Weiqi Zeng, Bo Wang, Dongming Zhao, Zongfeng Qu, Ruifang He, Yuexian Hou, Qinghua Hu |  |
| 1286 |  |  [Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarcity](https://aclanthology.org/2025.findings-acl.1186/) |  | 0 | Existing LMs struggle with proof-oriented programming due to data scarcity, which manifest in two key ways: (1) a lack of sufficient corpora for proof-oriented programming languages such as F\*, and (2) the absence of large-scale, project-level proof-oriented implementations that can teach the... | Dylan Zhang, Justin Wang, Tianran Sun |  |
| 1287 |  |  [On the Robust Approximation of ASR Metrics](https://aclanthology.org/2025.findings-acl.1187/) |  | 0 | Recent advances in speech foundation models are largely driven by scaling both model size and data, enabling them to perform a wide range of tasks, including speech recognition. Traditionally, ASR models are evaluated using metrics like Word Error Rate (WER) and Character Error Rate (CER), which... | Abdul Waheed, Hanin Atwany, Rita Singh, Bhiksha Raj |  |
| 1288 |  |  [Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective](https://aclanthology.org/2025.findings-acl.1188/) |  | 0 | As large language models (LLMs) become increasingly integrated into critical applications, aligning their behavior with human values presents significant challenges. Current methods, such as Reinforcement Learning from Human Feedback (RLHF), typically focus on a limited set of coarse-grained values... | Yipeng Kang, Junqi Wang, Yexin Li, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Tingjun Wu, Xue Feng, Fangwei Zhong, Zilong Zheng |  |
| 1289 |  |  [LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models](https://aclanthology.org/2025.findings-acl.1189/) |  | 0 | Semantic role labeling (SRL) is a crucial task of natural language processing (NLP). Although generative decoder-based large language models (LLMs) have achieved remarkable success across various NLP tasks, they still lag behind state-of-the-art encoder-decoder (BERT-like) models in SRL. In this... | Xinxin Li, Huiyao Chen, Chengjun Liu, Jing Li, Meishan Zhang, Jun Yu, Min Zhang |  |
| 1290 |  |  [Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models](https://aclanthology.org/2025.findings-acl.1190/) |  | 0 | Speech foundation models trained at a massive scale, both in terms of model and data size, result in robust systems capable of performing multiple speech tasks, including automatic speech recognition (ASR). These models transcend language and domain barriers, yet effectively measuring their... | Hanin Atwany, Abdul Waheed, Rita Singh, Monojit Choudhury, Bhiksha Raj |  |
| 1291 |  |  [M2PA: A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory](https://aclanthology.org/2025.findings-acl.1191/) |  | 0 | Open-world planning poses a significant challenge for general artificial intelligence due to environmental complexity and task diversity, especially in long-term tasks and lifelong learning. Inspired by cognitive theories, we propose M2PA, an open-world multi-memory planning agent. M2PA innovates... | Yanfang Zhou, Xiaodong Li, Yuntao Liu, Yongqiang Zhao, Xintong Wang, Zhenyu Li, Jinlong Tian, Xinhai Xu |  |
| 1292 |  |  [AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation](https://aclanthology.org/2025.findings-acl.1192/) |  | 0 | Constrained by the cost and ethical concerns of involving real seekers in AI-driven mental health, researchers develop LLM-based conversational agents (CAs) with tailored configurations, such as profiles, symptoms, and scenarios, to simulate seekers. While these efforts advance AI in mental health,... | Ming Wang, Peidong Wang, Lin Wu, Xiaocui Yang, Daling Wang, Shi Feng, Yuxin Chen, Bixuan Wang, Yifei Zhang |  |
| 1293 |  |  [Diversification Catalyzes Language Models' Instruction Generalization To Unseen Semantics](https://aclanthology.org/2025.findings-acl.1193/) |  | 0 | Instruction-tuned language models excel in knowledge, reasoning, and instruction-following. While knowledge and reasoning are well-explored, the factors enabling generalization to unseen instructions remain underexplored due to challenges in isolating instruction-following dynamics.In this work, we... | Dylan Zhang, Justin Wang, François Charton |  |
| 1294 |  |  [DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios](https://aclanthology.org/2025.findings-acl.1194/) |  | 0 | Decompilers are fundamental tools for critical security tasks, from vulnerability discovery to malware analysis, yet their evaluation remains fragmented. Existing approaches primarily focus on syntactic correctness through synthetic micro-benchmarks or subjective human ratings, failing to address... | Zeyu Gao, Yuxin Cui, Hao Wang, Siliang Qin, Yuanda Wang, Bolun Zhang, Chao Zhang |  |
| 1295 |  |  [Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement](https://aclanthology.org/2025.findings-acl.1195/) |  | 0 | Code generation is crucial in software engineering for automating the coding process efficiently. While test-time computation methods show promise, they suffer from high latency due to multiple computation rounds.To overcome this, we introduce ThinkCoder, a framework that combines thorough... | Xiaoqing Zhang, Yuhan Liu, Flood Sung, Xiuying Chen, Shuo Shang, Rui Yan |  |
| 1296 |  |  [Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs](https://aclanthology.org/2025.findings-acl.1196/) |  | 0 | Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual editing, failing to achieve true cross-linguistic... | Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao |  |
| 1297 |  |  [SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities](https://aclanthology.org/2025.findings-acl.1197/) |  | 0 | Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently guarantee safe outputs, potentially leading to harmful... | Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, Radha Poovendran |  |
| 1298 |  |  [ETRQA: A Comprehensive Benchmark for Evaluating Event Temporal Reasoning Abilities of Large Language Models](https://aclanthology.org/2025.findings-acl.1198/) |  | 0 | Event temporal reasoning (ETR) aims to model and reason about the relationships between events and time, as well as between events in the real world. Proficiency in ETR is a significant indicator that a large language model (LLM) truly understands the physical world. Previous question-answering... | Sigang Luo, Yinan Liu, Dongying Lin, Yingying Zhai, Bin Wang, Xiaochun Yang, Junpeng Liu |  |
| 1299 |  |  [The Law of Knowledge Overshadowing: Towards Understanding, Predicting and Preventing LLM Hallucination](https://aclanthology.org/2025.findings-acl.1199/) |  | 0 | Hallucination is a persistent challenge in large language models (LLMs), where even with rigorous quality control, models often generate distorted facts. This paradox, in which error generation continues despite high-quality training data, calls for a deeper understanding of the underlying LLM... | Yuji Zhang, Sha Li, Cheng Qian, Jiateng Liu, Pengfei Yu, Chi Han, Yi R. Fung, Kathleen McKeown, ChengXiang Zhai, Manling Li, Heng Ji |  |
| 1300 |  |  [LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation](https://aclanthology.org/2025.findings-acl.1200/) |  | 0 | It is a critical challenge to learn a single model for massive languages. Prior methods focus on increasing the model size and training data size. However, large models are difficult to optimize efficiently even with distributed parallel training and translation capacity can interfere among... | Fei Yuan, Yinquan Lu, Lei Li, Jingjing Xu |  |
| 1301 |  |  [Pruning General Large Language Models into Customized Expert Models](https://aclanthology.org/2025.findings-acl.1201/) |  | 0 | Large Language Models (LLMs) have transformed natural language processing, yet their substantial model sizes often demand significant computational resources. To preserve computing resources and accelerate inference speed, it is crucial to prune redundant parameters, especially for experienced... | Yiran Zhao, Guizhen Chen, Kenji Kawaguchi, Lidong Bing, Wenxuan Zhang |  |
| 1302 |  |  [Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation](https://aclanthology.org/2025.findings-acl.1202/) |  | 0 | People get informed of a daily task plan through diverse media involving both texts and images. However, most prior research only focuses on LLM’s capability of textual plan generation. The potential of large-scale models in providing text-image plans remains understudied. Generating high-quality... | Xiaoxin Lu, Ranran Haoran Zhang, Yusen Zhang, Rui Zhang |  |
| 1303 |  |  [Un-considering Contextual Information: Assessing LLMs' Understanding of Indexical Elements](https://aclanthology.org/2025.findings-acl.1203/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive performances in tasks related to coreference resolution. However, previous studies mostly assessed LLM performance on coreference resolution with nouns and third person pronouns. This study evaluates LLM performance on coreference resolution... | Metehan Oguz, Yavuz Faruk Bakman, Duygu Nur Yaldiz |  |
| 1304 |  |  [Behavioral Analysis of Information Salience in Large Language Models](https://aclanthology.org/2025.findings-acl.1204/) |  | 0 | Large Language Models (LLMs) excel at text summarization, a task that requires models to select content based on its importance. However, the exact notion of salience that LLMs have internalized remains unclear. To bridge this gap, we introduce an explainable framework to systematically derive and... | Jan Trienes, Jörg Schlötterer, Junyi Jessy Li, Christin Seifert |  |
| 1305 |  |  [The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs](https://aclanthology.org/2025.findings-acl.1205/) |  | 0 | Large Language Model (LLM)-based agents have significantly impacted Task-Oriented Dialog Systems (TODS) but continue to face notable performance challenges, especially in zero-shot scenarios. While prior work has noted this performance gap, the behavioral factors driving the performance gap remain... | Avinash Baidya, Kamalika Das, Xiang Gao |  |
| 1306 |  |  [Task Facet Learning: A Structured Approach To Prompt Optimization](https://aclanthology.org/2025.findings-acl.1206/) |  | 0 | Given a task in the form of a basic description and its training examples, prompt optimization is the problem of synthesizing the given information into a text prompt for a large language model. Humans solve this problem by also considering the different facets that define a task (e.g.,... | Gurusha Juneja, Gautam Jajoo, Hua Li, Jian Jiao, Nagarajan Natarajan, Amit Sharma |  |
| 1307 |  |  [LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding](https://aclanthology.org/2025.findings-acl.1207/) |  | 0 | Large Language Models (LLMs) are primarily designed for batch processing. Existing methods for adapting LLMs to streaming rely either on expensive re-encoding or specialized architectures with limited scalability. This work identifies three key mismatches in adapting batch-oriented LLMs to... | Junlong Tong, Jinlan Fu, Zixuan Lin, Yingqi Fan, Anhao Zhao, Hui Su, Xiaoyu Shen |  |
| 1308 |  |  [YinYang-Align: A new Benchmark for Competing Objectives and Introducing Multi-Objective Preference based Text-to-Image Alignment](https://aclanthology.org/2025.findings-acl.1208/) |  | 0 | Precise alignment in Text-to-Image (T2I) systems is crucial for generating visuals that reflect user intent while adhering to ethical and policy standards. Recent controversies, such as the Google Gemini-generated Pope image backlash, highlight the urgent need for robust alignment mechanisms.... | Amitava Das, Yaswanth Narsupalli, Gurpreet Singh, Vinija Jain, Vasu Sharma, Suranjana Trivedy, Aman Chadha, Amit P. Sheth |  |
| 1309 |  |  [FREE: Fast and Robust Vision Language Models with Early Exits](https://aclanthology.org/2025.findings-acl.1209/) |  | 0 | In recent years, Vision-Language Models (VLMs) have shown remarkable performance improvements in Vision-Language tasks. However, their large size poses challenges for real-world applications where inference latency is a concern. To tackle this issue, we propose employing Early Exit (EE) strategies... | Divya Jyoti Bajpai, Manjesh Kumar Hanawal |  |
| 1310 |  |  [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://aclanthology.org/2025.findings-acl.1210/) |  | 0 | Assessing the reproducibility of social science papers is essential for promoting rigor in research processes, but manual assessment is costly. With recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate their capability to automate this process. However, existing benchmarks... | Chuxuan Hu, Liyun Zhang, Yeji Lim, Aum Wadhwani, Austin Peters, Daniel Kang |  |
| 1311 |  |  [Time Travel: A Comprehensive Benchmark to Evaluate LMMs on Historical and Cultural Artifacts](https://aclanthology.org/2025.findings-acl.1211/) |  | 0 | Understanding historical and cultural artifacts demands human expertise and advanced computational techniques, yet the process remains complex and time-intensive. While large multimodal models offer promising support, their evaluation and improvement require a standardized benchmark. To address... | Sara Ghaboura, Ketan Pravin More, Ritesh Thawkar, Wafa Al Ghallabi, Omkar Thawakar, Fahad Shahbaz Khan, Hisham Cholakkal, Salman H. Khan, Rao Muhammad Anwer |  |
| 1312 |  |  [Unveiling and Addressing Pseudo Forgetting in Large Language Models](https://aclanthology.org/2025.findings-acl.1212/) |  | 0 | Although substantial efforts have been made to mitigate catastrophic forgetting in continual learning, the intrinsic mechanisms are not well understood. In this work, we demonstrate the existence of “pseudo forgetting”: the performance degradation in previous tasks is not attributed to a loss of... | Huashan Sun, Yizhe Yang, Yinghao Li, Jiawei Li, Yang Gao |  |
| 1313 |  |  [Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency](https://aclanthology.org/2025.findings-acl.1213/) |  | 0 | Multimodal Large Language Models (MLLMs) have shown strong performance in document image tasks, especially Optical Character Recognition (OCR). However, they struggle with Document Image Machine Translation (DIMT), which requires handling both cross-modal and cross-lingual challenges. Previous... | Yupu Liang, Yaping Zhang, Zhiyang Zhang, Zhiyuan Chen, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou |  |
| 1314 |  |  [HG-InsightLog: Context Prioritization and Reduction for Question Answering with Non-Natural Language Construct Log Data](https://aclanthology.org/2025.findings-acl.1214/) |  | 0 | Modern IT systems generate vast amounts of log data, which pose challenges for Large Language Models (LLMs) due to their large size, irrelevant entries, and non-Natural Language (non-NL) construct (e.g., domain-specific jargon, error codes, file paths, and abbreviations). Traditional methods like... | Supriya Bajpai, Athira Gopal, Chandrakant Harjpal, Niraj Kumar |  |
| 1315 |  |  [Dialect Normalization using Large Language Models and Morphological Rules](https://aclanthology.org/2025.findings-acl.1215/) |  | 0 | Natural language understanding systems struggle with low-resource languages, including many dialects of high-resource ones. Dialect-to-standard normalization attempts to tackle this issue by transforming dialectal text so that it can be used by standard-language tools downstream. In this study, we... | Antonios Dimakis, John Pavlopoulos, Antonios Anastasopoulos |  |
| 1316 |  |  [USDC: A Dataset of \underlineUser \underlineStance and \underlineDogmatism in Long \underlineConversations](https://aclanthology.org/2025.findings-acl.1216/) |  | 0 | Analyzing user opinion changes in long conversation threads is extremely critical for applications like enhanced personalization, market research, political campaigns, customer service, targeted advertising, and content moderation. Unfortunately, previous studies on stance and dogmatism in user... | Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek |  |
| 1317 |  |  [Learning to Insert [PAUSE] Tokens for Better Reasoning](https://aclanthology.org/2025.findings-acl.1217/) |  | 0 | To enhance reasoning capabilities, previous works have explored incorporating special-purpose tokens into the training process. These strategies strengthen the learning mechanism of transformer-based large language models (LLMs). Building on prior research, in which inserting dummy tokens... | Eunki Kim, Sangryul Kim, James Thorne |  |
| 1318 |  |  [Understand the Implication: Learning to Think for Pragmatic Understanding](https://aclanthology.org/2025.findings-acl.1218/) |  | 0 | Pragmatics, the ability to infer meaning beyond literal interpretation, is crucial for social cognition and communication. While LLMs have been benchmarked for their pragmatic understanding, improving their performance remains underexplored. Existing methods rely on annotated labels but overlook... | Settaluri Lakshmi Sravanthi, Kishan Maharaj, Sravani Gunnu, Abhijit Mishra, Pushpak Bhattacharyya |  |
| 1319 |  |  [WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data](https://aclanthology.org/2025.findings-acl.1219/) |  | 0 | The impressive performances of Large Language Models (LLMs) and their immense potential for commercialization have given rise to serious concerns over the Intellectual Property (IP) of their training data. In particular, the synthetic texts generated by LLMs may infringe the IP of the data being... | Xinyang Lu, Jingtan Wang, Zitong Zhao, Zhongxiang Dai, ChuanSheng Foo, SeeKiong Ng, Bryan Kian Hsiang Low |  |
| 1320 |  |  [Dense Retrieval with Quantity Comparison Intent](https://aclanthology.org/2025.findings-acl.1220/) |  | 0 | Pre-trained language models (PLMs) fragment numerals and units that express quantities in arbitrary ways, depending on their subword vocabulary. Consequently, they are unable to contextualize the fragment embeddings well enough to be proficient with dense retrieval in domains like e-commerce and... | Prayas Agrawal, Nandeesh Kumar, Muthusamy Chelliah, Surender Kumar, Soumen Chakrabarti |  |
| 1321 |  |  [Reflection on Knowledge Graph for Large Language Models Reasoning](https://aclanthology.org/2025.findings-acl.1221/) |  | 0 | Recent research shows that supplementing Large Language Models (LLMs) with knowledge graphs can enhance their performance. However, existing methods often introduce noise in the retrieval and reasoning pipeline, hindering LLMs’ ability to effectively integrate external knowledge for complex... | Yigeng Zhou, Wu Li, Yifan Lu, Jing Li, Fangming Liu, Meishan Zhang, Yequan Wang, Daojing He, Honghai Liu, Min Zhang |  |
| 1322 |  |  [Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?](https://aclanthology.org/2025.findings-acl.1222/) |  | 0 | In this work, we identify the “2D-Cheating” problem in 3D LLM evaluation, where these tasks might be easily solved by VLMs with rendered images of point clouds, exposing ineffective evaluation of 3D LLMs’ unique 3D capabilities. We test VLM performance across multiple 3D LLM benchmarks and, using... | Jiahe Jin, Yanheng He, Mingyan Yang |  |
| 1323 |  |  [DIESEL: A Lightweight Inference-Time Safety Enhancement for Language Models](https://aclanthology.org/2025.findings-acl.1223/) |  | 0 | Large language models (LLMs) have demonstrated impressive performance across a wide range of tasks, including open-ended dialogue, driving advancements in virtual assistants and other interactive systems. However, these models often generate outputs misaligned with human values, such as ethical... | Ben Ganon, Alon Zolfi, Omer Hofman, Inderjeet Singh, Hisashi Kojima, Yuval Elovici, Asaf Shabtai |  |
| 1324 |  |  [Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](https://aclanthology.org/2025.findings-acl.1224/) |  | 0 | Large language models (LLMs) achieve strong performance on plain text tasks but underperform on structured data like tables and databases. Potential challenges arise from their underexposure during pre-training and rigid text-to-structure transfer mechanisms. Unlike humans who seamlessly apply... | Jiawei Gu, Ziting Xian, Yuanzhen Xie, Ye Liu, Enjie Liu, Ruichao Zhong, Mochi Gao, Yunzhi Tan, Bo Hu, Zang Li |  |
| 1325 |  |  [Structured Pruning for Diverse Best-of-N Reasoning Optimization](https://aclanthology.org/2025.findings-acl.1225/) |  | 0 | Model pruning in transformer-based language models, traditionally seen as a means of computational savings, can enhance the model’s reasoning capabilities. In this work, we uncover the surprising phenomenon that the selective pruning of certain attention heads leads to improvements in reasoning... | Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen |  |
| 1326 |  |  [PodAgent: A Comprehensive Framework for Podcast Generation](https://aclanthology.org/2025.findings-acl.1226/) |  | 0 | Existing automatic audio generation methods struggle to generate podcast-like audio programs effectively. The key challenges lie in in-depth content generation, appropriate and expressive voice production. This paper proposed PodAgent, a comprehensive framework for creating audio programs. PodAgent... | Yujia Xiao, Lei He, Haohan Guo, Fenglong Xie, Tan Lee |  |
| 1327 |  |  [STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework](https://aclanthology.org/2025.findings-acl.1227/) |  | 0 | High-quality math datasets are crucial for advancing the reasoning abilities of large language models (LLMs). However, existing datasets often suffer from three key issues: outdated and insufficient challenging content, neglecting human-like reasoning, and limited reliability due to single-LLM... | Wenhao Liu, Zhenyi Lu, Xinyu Hu, Jerry Zhang, Dailin Li, Jiacheng Cen, Huilin Cao, Haiteng Wang, Yuhan Li, Kun Xie, Dandan Li, Pei Zhang, Chengbo Zhang, Yuxiang Ren, Xiaohong Huang, Yan Ma |  |
| 1328 |  |  [iMOVE : Instance-Motion-Aware Video Understanding](https://aclanthology.org/2025.findings-acl.1228/) |  | 0 | Enhancing the fine-grained instance spatiotemporal motion perception capabilities of Video Large Language Models is crucial for improving their temporal and general video understanding. However, current models struggle to perceive detailed and complex instance motions. To address these challenges,... | Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Yandong Bai, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di Zhang |  |
| 1329 |  |  [SceneGram: Conceptualizing and Describing Tangrams in Scene Context](https://aclanthology.org/2025.findings-acl.1229/) |  | 0 | Research on reference and naming suggests that humans can come up with very different ways of conceptualizing and referring to the same object, e.g. the same abstract tangram shape can be a “crab”, “sink” or “space ship”. Another common assumption in cognitive science is that scene context... | Simeon Junker, Sina Zarrieß |  |
| 1330 |  |  [Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?](https://aclanthology.org/2025.findings-acl.1230/) |  | 0 | Analogical reasoning is a unique ability of humans to address unfamiliar challenges by transferring strategies from relevant past experiences. One key finding in psychology is that compared with irrelevant past experiences, recalling relevant ones can help humans better handle new tasks.... | Chengwei Qin, Wenhan Xia, Tan Wang, Fangkai Jiao, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty |  |
| 1331 |  |  [MERIT: Multi-Agent Collaboration for Unsupervised Time Series Representation Learning](https://aclanthology.org/2025.findings-acl.1231/) |  | 0 | This paper studies the problem of unsupervised time series representation learning, which aims to map unlabeled time series data into a low-dimensional latent space for various downstream tasks. Previous works usually combine a range of augmentation strategies with contrastive learning to generate... | Shu Zhou, Yunyang Xuan, Yuxuan Ao, Xin Wang, Tao Fan, Hao Wang |  |
| 1332 |  |  [JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning](https://aclanthology.org/2025.findings-acl.1232/) |  | 0 | Instruction tuning is vital for enhancing the performance of large language models (LLMs), but existing text-to-text methods, referred to as TextTuning, struggle with issues such as generalization, robustness, and controllability due to their lack of explicit task structures. We introduce... | Chang Gao, Wenxuan Zhang, Guizhen Chen, Wai Lam |  |
| 1333 |  |  [RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs](https://aclanthology.org/2025.findings-acl.1233/) |  | 0 | Current Multimodal Large Language Model (MLLM) architectures face a critical tradeoff between performance and efficiency: decoder-only architectures achieve higher performance but lower efficiency, while cross-attention-based architectures offer greater efficiency but lower performance. The key... | Hongliang Li, Jiaxin Zhang, Wenhui Liao, Dezhi Peng, Kai Ding, Lianwen Jin |  |
| 1334 |  |  [Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning](https://aclanthology.org/2025.findings-acl.1234/) |  | 0 | Large language models (LLMs) have achieved remarkable performance on knowledge graph question answering (KGQA) tasks by planning and interacting with knowledge graphs. However, existing methods often confuse tool utilization with knowledge reasoning, harming readability of model outputs and giving... | Mufan Xu, Gewen Liang, Kehai Chen, Wei Wang, Xun Zhou, Muyun Yang, Tiejun Zhao, Min Zhang |  |
| 1335 |  |  [KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance](https://aclanthology.org/2025.findings-acl.1235/) |  | 0 | Supervised fine-tuning (SFT) is a common approach to improve the domain-specific question-answering (QA) performance of large language models (LLMs). However, recent literature reveals that due to the conflicts between LLMs’ internal knowledge and the context knowledge of training data, vanilla SFT... | Qihuang Zhong, Liang Ding, Xiantao Cai, Juhua Liu, Bo Du, Dacheng Tao |  |
| 1336 |  |  [Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?](https://aclanthology.org/2025.findings-acl.1236/) |  | 0 | We investigate the linguistic abilities of multimodal large language models in reference resolution tasks featuring simple yet abstract visual stimuli, such as color patches and color grids. Although the task may not seem challenging for today’s language models, being straightforward for human... | Simeon Junker, Manar Ali, Larissa Koch, Sina Zarrieß, Hendrik Buschmeier |  |
| 1337 |  |  [Removing Prompt-template Bias in Reinforcement Learning from Human Feedback](https://aclanthology.org/2025.findings-acl.1237/) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has become an essential technique for enhancing pre-trained large language models (LLMs) to generate responses that align with human preferences and societal values. Although RLHF has shown promise, the training of reward models (RMs) still faces... | Chaojie Wang, Haonan Shi, Long Tian, Bo An, Shuicheng Yan |  |
| 1338 |  |  [Latent Distribution Decouple for Uncertain-Aware Multimodal Multi-label Emotion Recognition](https://aclanthology.org/2025.findings-acl.1238/) |  | 0 | Multimodal multi-label emotion recognition (MMER) aims to identify the concurrent presence of multiple emotions in multimodal data. Existing studies primarily focus on improving fusion strategies and modeling modality-to-label dependencies. However, they often overlook the impact of aleatoric... | Jingwang Huang, Jiang Zhong, Qin Lei, Gaojinpeng Gaojinpeng, Ymyang Ymyang, Sirui Wang, PeiguangLi PeiguangLi, Kaiwen Wei |  |
| 1339 |  |  [Are LLMs Rational Investors? A Study on the Financial Bias in LLMs](https://aclanthology.org/2025.findings-acl.1239/) |  | 0 | Large language models (LLMs) excel in natural language generation but also exhibit biases, particularly in gender, race, and religion, which can be amplified with widespread use. However, research on biases in specific domains, such as finance, remains limited. To address this gap, we conducted a... | Yuhang Zhou, Yuchen Ni, Zhiheng Xi, Zhangyue Yin, Yu He, Gan Yunhui, Xiang Liu, Zhang Jian, Sen Liu, Xipeng Qiu, Yixin Cao, Guangnan Ye, Hongfeng Chai |  |
| 1340 |  |  [Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era](https://aclanthology.org/2025.findings-acl.1240/) |  | 0 | Human learning and conceptual representation is grounded in sensorimotor experience, in contrast to state-of-the-art foundation models. In this paper, we investigate how well such large-scale models, trained on vast quantities of data, represent the semantic feature norms of concrete object... | Dan Oneata, Desmond Elliott, Stella Frank |  |
| 1341 |  |  [Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models](https://aclanthology.org/2025.findings-acl.1241/) |  | 0 | Parameter-efficient fine-tuning (PEFT) methods typically assume that Large Language Models (LLMs) are trained on data from a single device or client. However, real-world scenarios often require fine-tuning these models on private data distributed across multiple devices. Federated Learning (FL)... | Sajjad Ghiasvand, Yifan Yang, Zhiyu Xue, Mahnoosh Alizadeh, Zheng Zhang, Ramtin Pedarsani |  |
| 1342 |  |  [A rebuttal of two common deflationary stances against LLM cognition](https://aclanthology.org/2025.findings-acl.1242/) |  | 0 | Large language models (LLMs) are arguably the most predictive models of human cognition available. Despite their impressive human-alignment, LLMs are often labeled as "\*just\* next-token predictors” that purportedly fall short of genuine cognition. We argue that these deflationary claims need... | Zak Hussain, Rui Mata, Dirk U. Wulff |  |
| 1343 |  |  [COVER: Context-Driven Over-Refusal Verification in LLMs](https://aclanthology.org/2025.findings-acl.1243/) |  | 0 | We introduce the concept of context-driven over-refusal, an abstention arising when model’s safety guardrails are triggered by the grounding knowledge provided alongside the user’s request. Distinct from question-driven over-refusal, this occurs in both retrieval-augmented generation (RAG) and... | Giovanni Sullutrone, Riccardo Amerigo Vigliermo, Sonia Bergamaschi, Luca Sala |  |
| 1344 |  |  [MOSAIC: Multiple Observers Spotting AI Content](https://aclanthology.org/2025.findings-acl.1244/) |  | 0 | The dissemination of Large Language Models (LLMs), trained at scale, and endowed with powerful text-generating abilities, has made it easier for all to produce harmful, toxic, faked or forged content. In response, various proposals have been made to automatically discriminate artificially generated... | Matthieu Dubois, François Yvon, Pablo Piantanida |  |
| 1345 |  |  [GUIDEX: Guided Synthetic Data Generation for Zero-Shot Information Extraction](https://aclanthology.org/2025.findings-acl.1245/) |  | 0 | Information Extraction (IE) systems are traditionally domain-specific, requiring costlyadaptation that involves expert schema design,data annotation, and model training. WhileLarge Language Models have shown promisein zero-shot IE, performance degrades significantly in unseen domains where label... | Neil De La Fuente, Oscar Sainz, Iker GarcíaFerrero, Eneko Agirre |  |
| 1346 |  |  [Missing the Margins: A Systematic Literature Review on the Demographic Representativeness of LLMs](https://aclanthology.org/2025.findings-acl.1246/) |  | 0 | Many applications of Large Language Models (LLMs) require them to either simulate people or offer personalized functionality, making the demographic representativeness of LLMs crucial for equitable utility. At the same time, we know little about the extent to which these models actually reflect the... | Indira Sen, Marlene Lutz, Elisa Rogers, David García, Markus Strohmaier |  |
| 1347 |  |  [LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs](https://aclanthology.org/2025.findings-acl.1247/) |  | 0 | Step-by-step reasoning is crucial for solving complex visual tasks, yet existing approaches lack a comprehensive framework for evaluating this capability and do not emphasize step-wise problem-solving. To this end, we propose a comprehensive framework for advancing multi-step visual reasoning in... | Omkar Thawakar, Dinura Dissanayake, Ketan Pravin More, Ritesh Thawkar, Ahmed Heakl, Noor Ahsan, Yuhao Li, Mohammed Zumri, Jean Lahoud, Rao Muhammad Anwer, Hisham Cholakkal, Ivan Laptev, Mubarak Shah, Fahad Shahbaz Khan, Salman H. Khan |  |
| 1348 |  |  [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://aclanthology.org/2025.findings-acl.1248/) |  | 0 | This paper introduces the TempVS benchmark, which focuses on temporal grounding and reasoning capabilities of Multimodal Large Language Models (MLLMs) in image sequences. TempVS consists of three main tests (i.e., event relation inference, sentence ordering and image ordering), each accompanied... | Yingjin Song, Yupei Du, Denis Paperno, Albert Gatt |  |
| 1349 |  |  [Full-Step-DPO: Self-Supervised Preference Optimization with Step-wise Rewards for Mathematical Reasoning](https://aclanthology.org/2025.findings-acl.1249/) |  | 0 | Direct Preference Optimization (DPO) often struggles with long-chain mathematical reasoning. Existing approaches, such as Step-DPO, typically improve this by focusing on the first erroneous step in the reasoning chain. However, they overlook all other steps and rely heavily on humans or GPT-4 to... | Huimin Xu, Xin Mao, FengLin Li, Xiaobao Wu, Wang Chen, Wei Zhang, Anh Tuan Luu |  |
| 1350 |  |  [Do Emotions Really Affect Argument Convincingness? A Dynamic Approach with LLM-based Manipulation Checks](https://aclanthology.org/2025.findings-acl.1250/) |  | 0 | Emotions have been shown to play a role in argument convincingness, yet this aspect is underexplored in the natural language processing (NLP) community. Unlike prior studies that use static analyses, focus on a single text domain or language, or treat emotion as just one of many factors, we... | Yanran Chen, Steffen Eger |  |
| 1351 |  |  [SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation](https://aclanthology.org/2025.findings-acl.1251/) |  | 0 | Process Reward Models (PRMs) have demonstrated promising results in mathematical reasoning, but existing process annotation approaches, whether through human annotations or Monte Carlo simulations, remain computationally expensive. In this paper, we introduce Step COmpression for Process Estimation... | Huimin Xu, Xin Mao, FengLin Li, Xiaobao Wu, Wang Chen, Wei Zhang, Anh Tuan Luu |  |
| 1352 |  |  [Compositional Syntactico-SemBanking for English as a Second or Foreign Language](https://aclanthology.org/2025.findings-acl.1252/) |  | 0 | Despite the widespread use of English as a Second or Foreign Language (ESFL), developing syntactico-semantic representations for it is limited — the irregularities in ESFL complicate systematic composition and subsequently the derivation of its semantics.This paper draws on constructivism and... | Wenxi Li, Xihao Wang, Weiwei Sun |  |
| 1353 |  |  [Semantics-aware prompting for translating NOtices To AirMen](https://aclanthology.org/2025.findings-acl.1253/) |  | 0 | A NOTAM or NOtice To AirMen is a crucial notice for different aviation stakeholders, particularly flight crews. It delivers essential notifications about abnormal conditions of Aviation System components such as changes to facilities, hazards, service, procedure that are not known far enough in... | Minal Nitin Dani, Aishwarya Maheswaran, Maunendra Sankar Desarkar |  |
| 1354 |  |  [Stereotype or Personalization? User Identity Biases Chatbot Recommendations](https://aclanthology.org/2025.findings-acl.1254/) |  | 0 | While personalized recommendations are often desired by users, it can be difficult in practice to distinguish cases of bias from cases of personalization: we find that models generate racially stereotypical recommendations regardless of whether the user revealed their identity intentionally through... | Anjali Kantharuban, Jeremiah Milbauer, Maarten Sap, Emma Strubell, Graham Neubig |  |
| 1355 |  |  [Automated main concept generation for narrative discourse assessment in aphasia](https://aclanthology.org/2025.findings-acl.1255/) |  | 0 | We present an interesting application of narrative understanding in the clinical assessment of aphasia, where story retelling tasks are used to evaluate a patient’s communication abilities. This clinical setting provides a framework to help operationalize narrative discourse analysis and an... | Ankita Gupta, Marisa Hudspeth, Polly Stokes, Jacquie Kurland, Brendan T. O'Connor |  |
| 1356 |  |  [Can VLMs Actually See and Read? A Survey on Modality Collapse in Vision-Language Models](https://aclanthology.org/2025.findings-acl.1256/) |  | 0 | Vision-language models (VLMs) integrate textual and visual information, enabling the model to process visual inputs and leverage visual information to generate predictions. Such models are demanding for tasks such as visual question answering, image captioning, and visual grounding. However, some... | Mong Yuan Sim, Wei Emma Zhang, Xiang Dai, Biaoyan Fang |  |
| 1357 |  |  ["You are Beautiful, Body Image Stereotypes are Ugly!" BIStereo: A Benchmark to Measure Body Image Stereotypes in Language Models](https://aclanthology.org/2025.findings-acl.1257/) |  | 0 | While a few high-quality bias benchmark datasets exist to address stereotypes in Language Models (LMs), a notable lack of focus remains on body image stereotypes. To bridge this gap, we propose BIStereo, a suite to uncover LMs’ biases towards people of certain physical appearance characteristics,... | Narjis Asad, Nihar Ranjan Sahoo, Rudra Murthy, Swaprava Nath, Pushpak Bhattacharyya |  |
| 1358 |  |  [Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models](https://aclanthology.org/2025.findings-acl.1258/) |  | 0 | Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical... | Zhengliang Shi, Yuhan Wang, Lingyong Yan, Pengjie Ren, Shuaiqiang Wang, Dawei Yin, Zhaochun Ren |  |
| 1359 |  |  [FineCite: A Novel Approach For Fine-Grained Citation Context Analysis](https://aclanthology.org/2025.findings-acl.1259/) |  | 0 | Citation context analysis (CCA) is a field of research studying the role and purpose of citation in scientific discourse. While most of the efforts in CCA have been focused on elaborate characterization schemata to assign function or intent labels to individual citations, the citation context as... | Lasse M. Jantsch, DongJae Koh, Seonghwan Yoon, Jisu Lee, Anne Lauscher, YoungKyoon Suh |  |
| 1360 |  |  [Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing](https://aclanthology.org/2025.findings-acl.1260/) |  | 0 | Knowledge editing enables efficient updates to Large Language Models (LLMs) by modifying specific knowledge without full-model retraining. Among knowledge editing approaches, in-context editing (ICE) stands out for its ability to inject knowledge without modifying the model’s parameters. However,... | Changyue Wang, Weihang Su, Qingyao Ai, Yujia Zhou, Yiqun Liu |  |
| 1361 |  |  [Entrospect: Information-Theoretic Self-Reflection Elicits Better Response Refinement of Small Language Models](https://aclanthology.org/2025.findings-acl.1261/) |  | 0 | Self-reflection helps de-hallucinate Large Language Models (LLMs). However, the effectiveness of self-reflection remains insufficiently validated in the context of Small Language Models (SLMs), which exhibit limited semantic capacities. In particular, we demonstrate that the conventional... | Tianqiang Yan, Ziqiao Lin, Lin Zhang, Zhenglong Sun, Yuan Gao |  |
| 1362 |  |  [Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability](https://aclanthology.org/2025.findings-acl.1262/) |  | 0 | Real-world applications of KBQA require models to detect different types of unanswerable questions with a limited volume of in-domain labeled training data. We propose the novel task of few-shot transfer for KBQA with unanswerable questions. The state-of-the-art KBQA few-shot transfer model... | Riya Sawhney, Samrat Yadav, Indrajit Bhattacharya, Mausam |  |
| 1363 |  |  [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://aclanthology.org/2025.findings-acl.1263/) |  | 0 | Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by providing external knowledge for accurate and up-to-date responses. However, this reliance on external sources exposes a security risk; attackers can inject poisoned documents into the knowledge base to steer the... | San Kim, Jonghwi Kim, Yejin Jeon, Gary Geunbae Lee |  |
| 1364 |  |  [EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance](https://aclanthology.org/2025.findings-acl.1264/) |  | 0 | Small large language models (sLLMs) offer the advantage of being lightweight and efficient, which makes them suitable for resource-constrained environments. However, sLLMs often struggle to maintain topic consistency in task-oriented dialogue systems, which is critical for scenarios such as service... | Heejae Suh, Yejin Jeon, Deokhyung Kang, Taehee Park, Yejin Min, Gary Geunbae Lee |  |
| 1365 |  |  [MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation](https://aclanthology.org/2025.findings-acl.1265/) |  | 0 | Natural language interfaces for NoSQL databases are increasingly vital in the big data era, enabling users to interact with complex, unstructured data without deep technical expertise. However, most recent advancements focus on English, leaving a gap for multilingual support. This paper introduces... | Zhiqian Qin, Yuanfeng Song, Jinwei Lu, Yuanwei Song, Shuaimin Li, Chen Jason Zhang |  |
| 1366 |  |  [Tool learning via Inference-time Scaling and Cycle Verifier](https://aclanthology.org/2025.findings-acl.1266/) |  | 0 | In inference-time scaling, Chain-of-Thought (CoT) plays a crucial role in enabling large language models (LLMs) to exhibit reasoning capabilities. However, in many scenarios, high-quality CoT data is scarce or even unavailable. In such cases, STaR-like methods can help LLMs synthesize CoT based on... | Xiaobo Liang, Wenjin Xie, Juntao Li, Wanfu Wang, Yibin Chen, Kehai Chen, Min Zhang |  |
| 1367 |  |  [When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback](https://aclanthology.org/2025.findings-acl.1267/) |  | 0 | Programming with a coding assistant is a fundamentally interactive process, yet existing static benchmarks fail to capture key features of model-user collaboration. We introduce an interactive evaluation pipeline to examine how LLMs incorporate different types of feedback in a collaborative... | Jane Pan, Ryan Shar, Jacob Pfau, Ameet Talwalkar, He He, Valerie Chen |  |
| 1368 |  |  [Reranking-based Generation for Unbiased Perspective Summarization](https://aclanthology.org/2025.findings-acl.1268/) |  | 0 | Generating unbiased summaries in real-world settings such as political perspective summarization remains a crucial application of Large Language Models (LLMs). Yet, existing evaluation frameworks rely on traditional metrics for measuring key attributes such as coverage and faithfulness without... | Narutatsu Ri, Nicholas Deas, Kathleen McKeown |  |
| 1369 |  |  [KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation](https://aclanthology.org/2025.findings-acl.1269/) |  | 0 | Large language models (LLMs) demonstrate exceptional performance across a variety of tasks, yet they are often affected by hallucinations and the timeliness of knowledge. Leveraging knowledge graphs (KGs) as external knowledge sources has emerged as a viable solution, but existing methods for... | Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xeron Du, Ningxuan Lu, Ge Zhang, Qingkun Tang |  |
| 1370 |  |  [Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph](https://aclanthology.org/2025.findings-acl.1270/) |  | 0 | The rapid growth of social media platforms has raised significant concerns regarding online content toxicity. When Large Language Models (LLMs) are used for toxicity detection, two key challenges emerge: 1) the absence of domain-specific toxicity knowledge leads to false negatives; 2) the excessive... | Yibo Zhao, Jiapeng Zhu, Can Xu, Yao Liu, Xiang Li |  |
| 1371 |  |  [Mixture-of-Personas Language Models for Population Simulation](https://aclanthology.org/2025.findings-acl.1271/) |  | 0 | Advances in Large Language Models (LLMs) paved the way for their emerging applications in various domains, such as human behavior simulations, where LLMs could augment human-generated data in social science research and machine learning model training. However, pretrained LLMs often fail to capture... | Ngoc Bui, Hieu Trung Nguyen, Shantanu Kumar, Julian Theodore, Weikang Qiu, Viet Anh Nguyen, Rex Ying |  |
| 1372 |  |  [ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning](https://aclanthology.org/2025.findings-acl.1272/) |  | 0 | As large language models (LLMs) scale, model compression is crucial for edge deployment and accessibility. Weight-only quantization reduces model size but suffers from performance degradation at lower bit widths. Moreover, standard finetuning is incompatible with quantized models, and alternative... | Baohao Liao, Christian Herold, Seyyed Hadi Hashemi, Stefan Vasilev, Shahram Khadivi, Christof Monz |  |
| 1373 |  |  [Decomposed Opinion Summarization with Verified Aspect-Aware Modules](https://aclanthology.org/2025.findings-acl.1273/) |  | 0 | Opinion summarization plays a key role in deriving meaningful insights from large-scale online reviews. To make the process more explainable and grounded, we propose a domain-agnostic modular approach guided by review aspects (e.g., cleanliness for hotel reviews) which separates the tasks of aspect... | Miao Li, Jey Han Lau, Eduard H. Hovy, Mirella Lapata |  |
| 1374 |  |  [Token-Budget-Aware LLM Reasoning](https://aclanthology.org/2025.findings-acl.1274/) |  | 0 | Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning and enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs.... | Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen |  |
| 1375 |  |  [HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference](https://aclanthology.org/2025.findings-acl.1275/) |  | 0 | Large Language Models (LLMs) have emerged as a pivotal research area, yet the attention module remains a critical bottleneck in LLM inference, even with techniques like KVCache to mitigate redundant computations. While various top-k attention mechanisms have been proposed to accelerate LLM... | Ping Gong, Jiawei Yi, Shengnan Wang, Juncheng Zhang, Zewen Jin, Ouxiang Zhou, Ruibo Liu, Guanbin Xu, Youhui Bai, Bowen Ye, Kun Yuan, Tong Yang, Gong Zhang, Renhai Chen, Feng Wu, Cheng Li |  |
| 1376 |  |  [Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning](https://aclanthology.org/2025.findings-acl.1276/) |  | 0 | As large language models (LLMs) are applied across diverse domains, the ability to selectively unlearn specific information is becoming increasingly essential. For instance, LLMs are expected to selectively provide confidential information to authorized internal users, such as employees or trusted... | Shota Takashiro, Takeshi Kojima, Andrew Gambardella, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo |  |
| 1377 |  |  [LIST: Linearly Incremental SQL Translator for Single-Hop Reasoning, Generation and Verification](https://aclanthology.org/2025.findings-acl.1277/) |  | 0 | SQL languages often feature nested structures that require robust interaction with databases. Aside from the well-validated schema linking methods on PLMs and LLMs, we introduce the Linearly Incremental SQL Translator (LIST), a novel algorithmic toolkit designed to leverage the notable reasoning... | Kaiyuan Guan, Ruoxin Li, Xudong Guo, Zhenning Huang, Xudong Weng, Hehuan Liu, Zheng Wei, Zang Li |  |
| 1378 |  |  [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://aclanthology.org/2025.findings-acl.1278/) |  | 0 | Automating structured clinical interviews could revolutionize mental healthcare accessibility, yet existing large language models (LLMs) approaches fail to align with psychiatric diagnostic protocols. We present MAGI, the first framework that transforms the gold-standard Mini International... | Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Minlie Huang |  |
| 1379 |  |  [TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking](https://aclanthology.org/2025.findings-acl.1279/) |  | 0 | In this paper, we present TituLLMs, the first large pretrained Bangla LLMs, available in 1b and 3b parameter sizes. Due to computational constraints during both training and inference, we focused on smaller models. To train TituLLMs, we collected a pretraining dataset of approximately ∼ 37 billion... | Shahriar Kabir Nahin, Rabindra Nath Nandi, Sagor Sarker, Quazi Sarwar Muhtaseem, Md. Kowsher, Apu Chandraw Shill, Md Ibrahim, Mehadi Hasan Menon, Tareq Al Muntasir, Firoj Alam |  |
| 1380 |  |  [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://aclanthology.org/2025.findings-acl.1280/) |  | 0 | Documents are fundamental to preserving and disseminating information, often incorporating complex layouts, tables, and charts that pose significant challenges for automatic document understanding (DU). While vision-language large models (VLLMs) have demonstrated improvements across various tasks,... | Negar Foroutan, Angelika Romanou, Matin Ansaripour, Julian Martin Eisenschlos, Karl Aberer, Rémi Lebret |  |
| 1381 |  |  [Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Robust and Instruction-Aware ASR and OCR](https://aclanthology.org/2025.findings-acl.1281/) |  | 0 | We introduce “Generative Fusion Decoding” (GFD), a novel shallow fusion framework, utilized to integrate large language models(LLMs) into cross-modal text recognition systems inlculding automatic speech recognition (ASR) and optical character recognition (OCR). We derive the formulas necessary to... | ChanJan Hsu, YiChang Chen, FengTing Liao, PeiChen Ho, YuHsiang Wang, PoChun Hsu, Dashan Shiu |  |
| 1382 |  |  [HPSS: Heuristic Prompting Strategy Search for LLM Evaluators](https://aclanthology.org/2025.findings-acl.1282/) |  | 0 | Since the adoption of large language models (LLMs) for text evaluation has become increasingly prevalent in the field of natural language processing (NLP), a series of existing works attempt to optimize the prompts for LLM evaluators to improve their alignment with human judgment. However, their... | Bosi Wen, Pei Ke, Yufei Sun, Cunxiang Wang, Xiaotao Gu, Jinfeng Zhou, Jie Tang, Hongning Wang, Minlie Huang |  |
| 1383 |  |  [A Fully Generative Motivational Interviewing Counsellor Chatbot for Moving Smokers Towards the Decision to Quit](https://aclanthology.org/2025.findings-acl.1283/) |  | 0 | The conversational capabilities of Large Language Models (LLMs) suggest that they may be able to perform as automated talk therapists. It is crucial to know if these systems would be effective and adhere to known standards. We present a counsellor chatbot that focuses on motivating tobacco smokers... | Zafarullah Mahmood, Soliman Ali, Jiading Zhu, Mohamed Abdelwahab, Michelle Yu Collins, Sihan Chen, Yi Cheng Zhao, Jodi Wolff, Osnat C. Melamed, Nadia Minian, Marta Maslej, Carolynne Cooper, Matt Ratto, Peter Selby, Jonathan Rose |  |
| 1384 |  |  [LegalCore: A Dataset for Event Coreference Resolution in Legal Documents](https://aclanthology.org/2025.findings-acl.1284/) |  | 0 | Recognizing events and their coreferential mentions in a document is essential for understanding semantic meanings of text. The existing research on event coreference resolution is mostly limited to news articles. In this paper, we present the first dataset for the legal domain, LegalCore, which... | Kangda Wei, Xi Shi, Jonathan Tong, Sai Ramana Reddy, Anandhavelu Natarajan, Rajiv Jain, Aparna Garimella, Ruihong Huang |  |
| 1385 |  |  [Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning](https://aclanthology.org/2025.findings-acl.1285/) |  | 0 | Large Language Models (LLMs) exhibit sophisticated reasoning yet still generate incorrect answers. We attribute these errors to \*\*Spurious Beliefs\*\*, defined as propositions the model internally considers as true despite being factually false. To reduce reasoning errors, we propose a belief... | Ayana Niwa, Masahiro Kaneko, Kentaro Inui |  |
| 1386 |  |  [MemeDetoxNet: Balancing Toxicity Reduction and Context Preservation](https://aclanthology.org/2025.findings-acl.1286/) |  | 0 | Toxic memes often spread harmful and offensive content and pose a significant challenge in online environments. In this paper, we present MemeDetoxNet, a robust framework designed to mitigate toxicity in memes by leveraging fine-tuned pre-trained models. Our approach utilizes the interpretability... | Gitanjali Kumari, Jitendra Solanki, Asif Ekbal |  |
| 1387 |  |  [Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL](https://aclanthology.org/2025.findings-acl.1287/) |  | 0 | An increasingly common socio-technical problem is people being taken in by offers that sound “too good to be true”, where persuasion and trust shape decision-making. This paper investigates how AI can help detect these deceptive scenarios. We analyze how humans strategically deceive each other in... | Wichayaporn Wongkamjan, Yanze Wang, Feng Gu, Denis Peskoff, Jonathan K. Kummerfeld, Jonathan May, Jordan Lee BoydGraber |  |
| 1388 |  |  [Multi-matrix Factorization Attention](https://aclanthology.org/2025.findings-acl.1288/) |  | 0 | We propose novel attention architectures, Multi-matrix Factorization Attention (MFA) and MFA-Key-Reuse (MFA-KR). Existing variants for standard Multi-Head Attention (MHA), including SOTA methods like MLA, fail to maintain as strong performance under stringent Key-Value cache (KV cache) constraints.... | Jingcheng Hu, Houyi Li, Yinmin Zhang, Zili Wang, Shuigeng Zhou, Xiangyu Zhang, HeungYeung Shum |  |
| 1389 |  |  [Self-Training Elicits Concise Reasoning in Large Language Models](https://aclanthology.org/2025.findings-acl.1289/) |  | 0 | Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens, incurring extraneous inference costs. Upon examination of... | Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, SeYoung Yun |  |
| 1390 |  |  [Reason from Future: Reverse Thought Chain Enhances LLM Reasoning](https://aclanthology.org/2025.findings-acl.1290/) |  | 0 | It has been demonstrated that carefully designed reasoning paradigms, like Chain-of-Thought(CoT) and Tree-of-Thought(ToT), can enhance the reasoning capabilities of small language models by detailed thinking and extensive thought searching, unbounded branching factors in the searching space create... | Yinlong Xu, Yanzhao Zheng, Shuoshuo Sun, Shuaihan Huang, Baohua Dong, Hangcheng Zhu, Ruohui Huang, Gang Yu, Hongxia Xu, Jian Wu |  |
| 1391 |  |  [LLMs as Planning Formalizers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models](https://aclanthology.org/2025.findings-acl.1291/) |  | 0 | Large Language Models (LLMs) excel in various natural language tasks but often struggle with long-horizon planning problems requiring structured reasoning. This limitation has drawn interest in integrating neuro-symbolic approaches within the Automated Planning (AP) and Natural Language Processing... | Marcus Tantakoun, Christian Muise, Xiaodan Zhu |  |
| 1392 |  |  [From Conversation to Automation: Leveraging LLMs for Problem-Solving Therapy Analysis](https://aclanthology.org/2025.findings-acl.1292/) |  | 0 | Problem-Solving Therapy (PST) is a structured psychological approach that helps individuals manage stress and resolve personal issues by guiding them through problem identification, solution brainstorming, decision-making, and outcome evaluation. As mental health care increasingly adopts... | Elham Aghakhani, Lu Wang, Karla T. Washington, George Demiris, Jina HuhYoo, Rezvaneh Rezapour |  |
| 1393 |  |  [Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation](https://aclanthology.org/2025.findings-acl.1293/) |  | 0 | Self-consistency improves reasoning by aggregating diverse stochastic samples, yet the dynamics behind its efficacy remain underexplored. We reframe self-consistency as a dynamic distributional alignment problem, revealing that decoding temperature not only governs sampling randomness but also... | Yiwei Li, Ji Zhang, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Jiayi Shi, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li |  |
| 1394 |  |  [Don't Say No: Jailbreaking LLM by Suppressing Refusal](https://aclanthology.org/2025.findings-acl.1294/) |  | 0 | Ensuring the safety alignment of Large Language Models (LLMs) is critical for generating responses consistent with human values. However, LLMs remain vulnerable to jailbreaking attacks, where carefully crafted prompts manipulate them into producing toxic content. One category of such attacks... | Yukai Zhou, Jian Lou, Zhijie Huang, Zhan Qin, Sibei Yang, Wenjie Wang |  |
| 1395 |  |  [From Perception to Reasoning: Enhancing Vision-Language Models for Mobile UI Understanding](https://aclanthology.org/2025.findings-acl.1295/) |  | 0 | Accurately grounding visual and textual elements within mobile user interfaces (UIs) remains a significant challenge for Vision-Language Models (VLMs). Visual grounding, a critical task in this domain, involves identifying the most relevant UI element or region based on a natural language query—a... | Settaluri Lakshmi Sravanthi, Ankit Mishra, Debjyoti Mondal, Subhadarshi Panda, Rituraj Singh, Pushpak Bhattacharyya |  |
| 1396 |  |  [Lemmas Matter, But Not Like That: Predictors of Lemma-Based Generalization in Morphological Inflection](https://aclanthology.org/2025.findings-acl.1296/) |  | 0 | Recent work has suggested that overlap –whether a given lemma or feature set is attested independently in train – drives model performance on morphological inflection tasks. The impact of lemma overlap, however, is debated, with recent work reporting accuracy drops from 0% to 30% between seen and... | Sarah Ruth Brogden Payne, Jordan Kodner |  |
| 1397 |  |  [Mosaic-IT: Cost-Free Compositional Data Synthesis for Instruction Tuning](https://aclanthology.org/2025.findings-acl.1297/) |  | 0 | Finetuning large language models with a variety of instruction-response pairs has enhanced their capability to understand and follow instructions. Current instruction tuning primarily relies on teacher models or human intervention to generate and refine the instructions and responses for training,... | Ming Li, Pei Chen, Chenguang Wang, Hongyu Zhao, Yijun Liang, Yupeng Hou, Fuxiao Liu, Tianyi Zhou |  |
| 1398 |  |  [MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration](https://aclanthology.org/2025.findings-acl.1298/) |  | 0 | Recent advancements in medical Large Language Models (LLMs) have showcased their powerful reasoning and diagnostic capabilities. Despite their success, current unified multimodal medical LLMs face limitations in knowledge update costs, comprehensiveness, and flexibility. To address these... | Yucheng Zhou, Lingran Song, Jianbing Shen |  |
| 1399 |  |  [ATLAS: Agent Tuning via Learning Critical Steps](https://aclanthology.org/2025.findings-acl.1299/) |  | 0 | Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and... | Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou |  |
| 1400 |  |  [Syntactic Control of Language Models by Posterior Inference](https://aclanthology.org/2025.findings-acl.1300/) |  | 0 | Controlling the syntactic structure of text generated by language models is valuable for applications requiring clarity, stylistic consistency, or interpretability, yet it remains a challenging task. In this paper, we argue that sampling algorithms based on the posterior inference can effectively... | Vicky Xefteri, Tim Vieira, Ryan Cotterell, Afra Amini |  |
| 1401 |  |  [Small Models Struggle to Learn from Strong Reasoners](https://aclanthology.org/2025.findings-acl.1301/) |  | 0 | Large language models (LLMs) excel in complex reasoning tasks, and distilling their reasoning capabilities into smaller models has shown promise. However, we uncover an interesting phenomenon, which we term the Small Model Learnability Gap: small models (3B parameters) do not consistently benefit... | Yuetai Li, Xiang Yue, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Bhaskar Ramasubramanian, Radha Poovendran |  |
| 1402 |  |  [Sparse Rewards Can Self-Train Dialogue Agents](https://aclanthology.org/2025.findings-acl.1302/) |  | 0 | Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has... | Barrett Martin Lattimer, Varun Prashant Gangal, Ryan McDonald, Yi Yang |  |
| 1403 |  |  [Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing](https://aclanthology.org/2025.findings-acl.1303/) |  | 0 | The growing use of large language models (LLMs) for text generation has led to widespread concerns about AI-generated content detection. However, an overlooked challenge is AI-polished text, where human-written content undergoes subtle refinements using AI tools. This raises a critical question:... | Shoumik Saha, Soheil Feizi |  |
| 1404 |  |  [The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing](https://aclanthology.org/2025.findings-acl.1304/) |  | 0 | Recent studies comparing AI-generated and human-authored literary texts have produced conflicting results: some suggest AI already surpasses human quality, while others argue it still falls short. We start from the hypothesis that such divergences can be largely explained by genuine differences in... | Guillermo Marco, Julio Gonzalo, Víctor Fresno |  |
| 1405 |  |  [Summary Factual Inconsistency Detection Based on LLMs Enhanced by Universal Information Extraction](https://aclanthology.org/2025.findings-acl.1305/) |  | 0 | Automatic text summarization has a potential flaw that affects the factuality of summaries. Recently, Large Language Models (LLMs) have been introduced as detectors for factual inconsistencies in summaries. However, LLM-based methods rely on reasoning capabilities and face challenges in terms of... | Anguo Li, Lei Yu |  |
| 1406 |  |  [ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations](https://aclanthology.org/2025.findings-acl.1306/) |  | 0 | Language models today are widely used in education, yet their ability to tailor responses for learners with varied informational needs and knowledge backgrounds remains under-explored. To this end, we introduce ELI-Why, a benchmark of 13.4K “Why” questions to evaluate the pedagogical capabilities... | Brihi Joshi, Keyu He, Sahana Ramnath, Sadra Sabouri, Kaitlyn Zhou, Souti Chattopadhyay, Swabha Swayamdipta, Xiang Ren |  |
| 1407 |  |  [Beyond Generation: Leveraging LLM Creativity to Overcome Label Bias in Classification](https://aclanthology.org/2025.findings-acl.1307/) |  | 0 | Large Language Models (LLMs) exhibit impressive capabilities in In-Context Learning (ICL) but are prone to label bias—an undesirable tendency to favor certain answers. Existing calibration methods mitigate bias by leveraging in-domain data, yet such data is often unavailable in real-world... | Xiaoyue Wang, Xin Liu |  |
| 1408 |  |  [CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models](https://aclanthology.org/2025.findings-acl.1308/) |  | 0 | Large Language Models (LLMs) achieve remarkable performance through pretraining on extensive data. This enables efficient adaptation to diverse downstream tasks. However, the lack of interpretability in their underlying mechanisms limits the ability to effectively steer LLMs for specific... | Xintong Wang, Jingheng Pan, Liang Ding, Longyue Wang, Longqin Jiang, Xingshan Li, Chris Biemann |  |
| 1409 |  |  [PASTEL : Polarity-Aware Sentiment Triplet Extraction with LLM-as-a-Judge](https://aclanthology.org/2025.findings-acl.1309/) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) is a subtask of Aspect-Based Sentiment Analysis (ABSA) that aims to extract aspect terms, corresponding opinion terms, and their associated sentiment polarities from text. Current end-to-end approaches, whether employing Large Language Models (LLMs) or... | Aaditya Bodke, Avinoor Singh Kohli, Hemant Subhash Pardeshi, Prathamesh Bhosale |  |
| 1410 |  |  [COSMIC: Generalized Refusal Direction Identification in LLM Activations](https://aclanthology.org/2025.findings-acl.1310/) |  | 0 | Large Language Models encode behaviors like refusal within their activation space, but identifying these behaviors remains challenging. Existing methods depend on predefined refusal templates detectable in output tokens or manual review. We introduce \*\*COSMIC\*\* (Cosine Similarity Metrics for... | Vincent Siu, Nicholas Crispino, Zihao Yu, Sam Pan, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang |  |
| 1411 |  |  [Red Queen: Exposing Latent Multi-Turn Risks in Large Language Models](https://aclanthology.org/2025.findings-acl.1311/) |  | 0 | The rapid advancement of large language models (LLMs) has unlocked diverse opportunities across domains and applications but has also raised concerns about their tendency to generate harmful responses under jailbreak attacks. However, most existing jailbreak strategies are single-turn with explicit... | Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee |  |
| 1412 |  |  [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://aclanthology.org/2025.findings-acl.1312/) |  | 0 | Natural language processing evaluation has made significant progress, largely driven by the proliferation of powerful large language mod-els (LLMs). New evaluation benchmarks are of increasing priority as the reasoning capabilities of LLMs are expanding at a rapid pace. In particular, while... | Joseph J. Peper, Wenzhao Qiu, Ali Payani, Lu Wang |  |
| 1413 |  |  [DiaLLMs: EHR-Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://aclanthology.org/2025.findings-acl.1313/) |  | 0 | Recent advances in Large Language Models (LLMs) have led to remarkable progresses in medical consultation.However, existing medical LLMs overlook the essential role of Electronic Health Records (EHR) and focus primarily on diagnosis recommendation, limiting their clinical applicability. We propose... | Weijieying Ren, Tianxiang Zhao, Lei Wang, Tianchun Wang, Vasant G. Honavar |  |
| 1414 |  |  [Can Hallucination Correction Improve Video-Language Alignment?](https://aclanthology.org/2025.findings-acl.1314/) |  | 0 | Large Vision-Language Models often generate hallucinated content that is not grounded in its visual inputs. While prior work focuses on mitigating hallucinations, we instead explore leveraging hallucination correction as a training objective to improve video-language alignment. We introduce HACA, a... | Lingjun Zhao, Mingyang Xie, Paola CascanteBonilla, Hal Daumé III, Kwonjoon Lee |  |
| 1415 |  |  [IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator](https://aclanthology.org/2025.findings-acl.1315/) |  | 0 | We propose IMPARA-GED, a novel reference-free automatic grammatical error correction (GEC) evaluation method with grammatical error detection (GED) capabilities. We focus on the quality estimator of IMPARA, an existing automatic GEC evaluation method, and construct that of IMPARA-GED using a... | Yusuke Sakai, Takumi Goto, Taro Watanabe |  |
| 1416 |  |  [Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs](https://aclanthology.org/2025.findings-acl.1316/) |  | 0 | Psychology research has shown that humans are poor at estimating their performance on tasks, tending towards underconfidence on easy tasks and overconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct, Claude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty,... | Chenjun Xu, Bingbing Wen, Bin Han, Robert Wolfe, Lucy Lu Wang, Bill Howe |  |
| 1417 |  |  [Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System](https://aclanthology.org/2025.findings-acl.1317/) |  | 0 | Unfairness is a well-known challenge in Recommender Systems (RSs), often resulting in biased outcomes that disadvantage users or items based on attributes such as gender, race, age, or popularity. Although some approaches have started to improve fairness recommendation in offline or static... | Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, KwokYan Lam |  |
| 1418 |  |  [Cautious Next Token Prediction](https://aclanthology.org/2025.findings-acl.1318/) |  | 0 | Next token prediction paradigm has been prevailing for autoregressive models in the era of LLMs. The current default sampling choice for popular LLMs is temperature scaling together with nucleus sampling to balance diversity and coherence. Nevertheless, such approach leads to inferior performance... | Yizhou Wang, Lingzhi Zhang, Yue Bai, Mang Tik Chiu, Zhengmian Hu, Mingyuan Zhang, Qihua Dong, Yu Yin, Sohrab Amirghodsi, Yun Fu |  |
| 1419 |  |  [Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning](https://aclanthology.org/2025.findings-acl.1319/) |  | 0 | Large language models (LLMs) have demonstrated remarkable success across a wide range of tasks; however, they still encounter challenges in reasoning tasks that require understanding and inferring relationships between distinct pieces of information within text sequences. This challenge is... | Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang |  |
| 1420 |  |  [Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment](https://aclanthology.org/2025.findings-acl.1320/) |  | 0 | Medical dialogue systems (MDS) have emerged as crucial online platforms for enabling multi-turn, context-aware conversations with patients. However, existing MDS often struggle to (1) identify relevant medical knowledge and (2) generate personalized, medically accurate responses. To address these... | Hongda Sun, Jiaren Peng, Wenzhong Yang, Liang He, Bo Du, Rui Yan |  |
| 1421 |  |  [Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders](https://aclanthology.org/2025.findings-acl.1321/) |  | 0 | Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs). Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or guarantees effective generalization to new LLMs.... | Kristian Kuznetsov, Laida Kushnareva, Anton Razzhigaev, Polina Druzhinina, Anastasia Voznyuk, Irina Piontkovskaya, Evgeny Burnaev, Serguei Barannikov |  |
| 1422 |  |  [Low-Resource Grammatical Error Correction: Selective Data Augmentation with Round-Trip Machine Translation](https://aclanthology.org/2025.findings-acl.1322/) |  | 0 | Supervised state-of-the-art methods for grammatical error correction require large amounts of parallel data for training. Due to lack of gold-labeled data, techniques that create synthetic training data have become popular. We show that models trained on synthetic data tend tocorrect a limited... | Frank Palma Gomez, Alla Rozovskaya |  |
| 1423 |  |  [Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks](https://aclanthology.org/2025.findings-acl.1323/) |  | 0 | LLM use in annotation is becoming widespread, and given LLMs’ overall promising performance and speed, putting humans in the loop to simply “review” LLM annotations can be tempting. In subjective tasks with multiple plausible answers, this can impact both evaluation of LLM performance, and analysis... | Hope Schroeder, Deb Roy, Jad Kabbara |  |
| 1424 |  |  [Research Community Perspectives on "Intelligence" and Large Language Models](https://aclanthology.org/2025.findings-acl.1324/) |  | 0 | Despite the widespread use of ‘artificial intelligence’ (AI) framing in Natural Language Processing (NLP) research, it is not clear what researchers mean by ”intelligence”. To that end, we present the results of a survey on the notion of ”intelligence” among researchers and its role in the research... | Bertram Højer, Terne Sasha Thorn Jakobsen, Anna Rogers, Stefan Heinrich |  |
| 1425 |  |  [LEMONADE: A Large Multilingual Expert-Annotated Abstractive Event Dataset for the Real World](https://aclanthology.org/2025.findings-acl.1325/) |  | 0 | This paper presents LEMONADE, a large-scale conflict event dataset comprising 39,786 events across 20 languages and 171 countries, with extensive coverage of region-specific entities. LEMONADE is based on a partially reannotated subset of the Armed Conflict Location & Event Data (ACLED), which has... | Sina J. Semnani, Pingyue Zhang, Wanyue Zhai, Haozhuo Li, Ryan Beauchamp, Trey Billing, Katayoun Kishi, Manling Li, Monica S. Lam |  |
| 1426 |  |  [Memorization vs. Reasoning: Updating LLMs with New Knowledge](https://aclanthology.org/2025.findings-acl.1326/) |  | 0 | Large language models (LLMs) encode vast amounts of pre-trained knowledge in their parameters, but updating them as real-world information evolves remains a challenge. Existing methodologies and benchmarks primarily target entity substitutions, failing to capture the full breadth of complex... | Aochong Oliver Li, Tanya Goyal |  |
| 1427 |  |  [CourtEval: A Courtroom-Based Multi-Agent Evaluation Framework](https://aclanthology.org/2025.findings-acl.1327/) |  | 0 | Automated evaluation is crucial for assessing the quality of natural language text, especially in open-ended generation tasks, given the costly and time-consuming nature of human evaluation. Existing automatic evaluation metrics like ROUGE and BLEU often show low correlation with human judgments.... | Sandeep Kumar, Abhijit A. Nargund, Vivek Sridhar |  |
| 1428 |  |  [Multilingual Definition Modeling](https://aclanthology.org/2025.findings-acl.1328/) |  | 0 | In this paper, we propose the first multilingual study on definition modeling. We use monolingual dictionary data for four new languages (Spanish, French, Portuguese, and German) and perform an in-depth empirical study to test the performance of pre-trained multilingual language models on... | Edison MarreseTaylor, Erica K. Shimomoto, Alfredo Solano, Enrique Reid |  |
| 1429 |  |  [Human Bias in the Face of AI: Examining Human Judgment Against Text Labeled as AI Generated](https://aclanthology.org/2025.findings-acl.1329/) |  | 0 | As Al advances in text generation, human trust in Al generated content remains constrained by biases that go beyond concerns of accuracy. This study explores how bias shapes the perception of AI versus human generated content. Through three experiments involving text rephrasing, news article... | Tiffany Zhu, Iain Weissburg, Kexun Zhang, William Yang Wang |  |
| 1430 |  |  [Redundancy, Isotropy, and Intrinsic Dimensionality of Prompt-based Text Embeddings](https://aclanthology.org/2025.findings-acl.1330/) |  | 0 | Prompt-based text embedding models, which generate task-specific embeddings upon receiving tailored prompts, have recently demonstrated remarkable performance. However, their resulting embeddings often have thousands of dimensions, leading to high storage costs and increased computational costs of... | Hayato Tsukagoshi, Ryohei Sasano |  |
| 1431 |  |  [Harnessing Whisper for Prosodic Stress Analysis](https://aclanthology.org/2025.findings-acl.1331/) |  | 0 | Prosody affects how people produce and understand language, yet studies of how it does so have been hindered by the lack of efficient tools for analyzing prosodic stress. We fine-tune OpenAI Whisper large-v2, a state-of-the-art speech recognition model, to recognize phrasal, lexical, and... | Samuel S. Sohn, Sten Knutsen, Karin Stromswold |  |
| 1432 |  |  [Can You Share Your Story? Modeling Clients' Metacognition and Openness for LLM Therapist Evaluation](https://aclanthology.org/2025.findings-acl.1332/) |  | 0 | Understanding clients’ thoughts and beliefs is fundamental in counseling, yet current evaluations of LLM therapists often fail to assess this ability. Existing evaluation methods rely on client simulators that clearly disclose internal states to the therapist, making it difficult to determine... | Minju Kim, Dongje Yoo, Yeonjun Hwang, Minseok Kang, Namyoung Kim, Minju Gwak, Beongwoo Kwak, Hyungjoo Chae, Harim Kim, Yunjoong Lee, Min Hee Kim, Dayi Jung, KyongMee Chung, Jinyoung Yeo |  |
| 1433 |  |  [Dictionaries to the Rescue: Cross-Lingual Vocabulary Transfer for Low-Resource Languages Using Bilingual Dictionaries](https://aclanthology.org/2025.findings-acl.1333/) |  | 0 | Cross-lingual vocabulary transfer plays a promising role in adapting pre-trained language models to new languages, including low-resource languages.Existing approaches that utilize monolingual or parallel corpora face challenges when applied to languages with limited resources.In this work, we... | Haruki Sakajo, Yusuke Ide, Justin Vasselli, Yusuke Sakai, Yingtao Tian, Hidetaka Kamigaito, Taro Watanabe |  |
| 1434 |  |  [When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR](https://aclanthology.org/2025.findings-acl.1334/) |  | 0 | Dense retrievers encode texts into embeddings to efficiently retrieve relevant documents from large databases in response to user queries. However, real-world corpora continually evolve, leading to a shift from the original training distribution of the retriever. Without timely updates or... | Dayoon Ko, Jinyoung Kim, Sohyeon Kim, Jinhyuk Kim, Jaehoon Lee, Seonghak Song, Minyoung Lee, Gunhee Kim |  |
| 1435 |  |  [The Million Authors Corpus: A Cross-Lingual and Cross-Domain Wikipedia Dataset for Authorship Verification](https://aclanthology.org/2025.findings-acl.1335/) |  | 0 | Authorship verification (AV) is a crucial task for applications like identity verification, plagiarism detection, and AI-generated text identification. However, datasets for training and evaluating AV models are primarily in English and primarily in a single domain. This precludes analysis of AV... | Abraham Israeli, Shuai Liu, Jonathan May, David Jurgens |  |
| 1436 |  |  [BridG MT: Enhancing LLMs' Machine Translation Capabilities with Sentence Bridging and Gradual MT](https://aclanthology.org/2025.findings-acl.1336/) |  | 0 | Recent Large Language Models (LLMs) have demonstrated impressive translation performance without requiring fine-tuning on additional parallel corpora. However, they still face significant challenges in certain scenarios, particularly when translating low-resource languages. A common approach to... | Seungwoo Choi, Gahyun Yoo, JayYoon Lee |  |
| 1437 |  |  [Text2World: Benchmarking Large Language Models for Symbolic World Model Generation](https://aclanthology.org/2025.findings-acl.1337/) |  | 0 | Recently, there has been growing interest in leveraging large language models (LLMs) to generate symbolic world models from textual descriptions. Although LLMs have been extensively explored in the context of world modeling, prior studies encountered several challenges, including evaluation... | Mengkang Hu, Tianxing Chen, Yude Zou, Yuheng Lei, Qiguang Chen, Ming Li, Yao Mu, Hongyuan Zhang, Wenqi Shao, Ping Luo |  |
| 1438 |  |  [Blinded by Context: Unveiling the Halo Effect of MLLM in AI Hiring](https://aclanthology.org/2025.findings-acl.1338/) |  | 0 | This study investigates the halo effect in AI-driven hiring evaluations using Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Through experiments with hypothetical job applications, we examined how these models’ evaluations are influenced by non-job-related information,... | Kyusik Kim, Jeongwoo Ryu, Hyeonseok Jeon, Bongwon Suh |  |
| 1439 |  |  [CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought](https://aclanthology.org/2025.findings-acl.1339/) |  | 0 | Large language models (LLMs) excel in many tasks but struggle to accurately quantify uncertainty in their generated responses. This limitation makes it challenging to detect misinformation and ensure reliable decision-making. Existing uncertainty quantification (UQ) methods for LLMs are primarily... | Boxuan Zhang, Ruqi Zhang |  |
| 1440 |  |  [ADO: Automatic Data Optimization for Inputs in LLM Prompts](https://aclanthology.org/2025.findings-acl.1340/) |  | 0 | This study explores a novel approach to enhance the performance of Large Language Models (LLMs) through the optimization of input data within prompts. While previous research has primarily focused on refining instruction components and augmenting input data with in-context examples, our work... | Sam Lin, Wenyue Hua, Lingyao Li, Zhenting Wang, Yongfeng Zhang |  |
| 1441 |  |  [Large Language Models Still Exhibit Bias in Long Text](https://aclanthology.org/2025.findings-acl.1341/) |  | 0 | Existing fairness benchmarks for large language models (LLMs) primarily focus on simple tasks, such as multiple-choice questions, overlooking biases that may arise in more complex scenarios like long-text generation. To address this gap, we introduce the Long Text Fairness Test (LTF-TEST), a... | Wonje Jeung, Dongjae Jeon, Ashkan Yousefpour, Jonghyun Choi |  |
| 1442 |  |  [Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation](https://aclanthology.org/2025.findings-acl.1342/) |  | 0 | Internal world models (WMs) enable agents to understand the world’s state and predict transitions, serving as the basis for advanced deliberative reasoning.Recent large Vision-Language Models (VLMs), such as GPT-4o and Gemini, exhibit potential as general-purpose WMs. While the latest studies have... | Qiyue Gao, Xinyu Pi, Kevin Liu, Junrong Chen, Ruolan Yang, Xinqi Huang, Xinyu Fang, Lu Sun, Gautham Kishore, Bo Ai, Stone Tao, Mengyang Liu, Jiaxi Yang, ChaoJung Lai, Chuanyang Jin, Jiannan Xiang, Benhao Huang, Zeming Chen, David Danks, Hao Su, Tianmin Shu, Ziqiao Ma, Lianhui Qin, Zhiting Hu |  |
| 1443 |  |  [Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents](https://aclanthology.org/2025.findings-acl.1343/) |  | 0 | Conversational agents are increasingly woven into individuals’ personal lives, yet users often underestimate the privacy risks associated with them. The moment users share information with these agents —such as large language models (LLMs)— their private information becomes vulnerable to exposure.... | Ivoline C. Ngong, Swanand Ravindra Kadhe, Hao Wang, Keerthiram Murugesan, Justin D. Weisz, Amit Dhurandhar, Karthikeyan Natesan Ramamurthy |  |
| 1444 |  |  [Enhancing Persona Consistency for LLMs' Role-Playing using Persona-Aware Contrastive Learning](https://aclanthology.org/2025.findings-acl.1344/) |  | 0 | In recent years, large language models (LLMs) have achieved breakthrough progress in many dialogue generation tasks. However, their lack of emotion and fine-grained role awareness limits the model’s ability to provide personalized and diverse interactions further. Current methods face high costs in... | Ke Ji, Yixin Lian, Linxu Li, Jingsheng Gao, Weiyuan Li, Bin Dai |  |
| 1445 |  |  [M²-TabFact: Multi-Document Multi-Modal Fact Verification with Visual and Textual Representations of Tabular Data](https://aclanthology.org/2025.findings-acl.1345/) |  | 0 | Tabular data is used to store information in many real-world systems ranging from finance to healthcare. However, such structured data is often communicated to humans in visually interpretable formats (e.g. charts and textual paragraphs), making it imperative that fact-checking models should be... | Mingyang Zhou, Lingyu Zhang, Sophia Horng, Maximillian Chen, KungHsiang Huang, ShihFu Chang |  |
| 1446 |  |  [Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff](https://aclanthology.org/2025.findings-acl.1346/) |  | 0 | Speculative Decoding (SD) enforces strict distributional equivalence to the target model when accepting candidate tokens. While it maintains the target model’s generation quality, this strict equivalence limits the speedup achievable by SD and prevents users from trading deviations from the target... | Maximilian Holsman, Yukun Huang, Bhuwan Dhingra |  |
| 1447 |  |  [PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play](https://aclanthology.org/2025.findings-acl.1347/) |  | 0 | Large language models (LLMs) are increasingly integrated with specialized external tools, yet many tasks demand zero-shot tool usage with minimal or noisy documentation. Existing solutions rely on manual rewriting or labeled data for validation, making them inapplicable in true zero-shot settings.... | Wei Fang, Yang Zhang, Kaizhi Qian, James R. Glass, Yada Zhu |  |
| 1448 |  |  [Towards the Pedagogical Steering of Large Language Models for Tutoring: A Case Study with Modeling Productive Failure](https://aclanthology.org/2025.findings-acl.1348/) |  | 0 | One-to-one tutoring is one of the most efficient methods of teaching. With the growing popularity of Large Language Models (LLMs), there have been efforts to create LLM-based conversational tutors which can expand the benefits of one-to-one tutoring to everyone. However, current LLMs are trained... | Romain Puech, Jakub Macina, Julia Chatain, Mrinmaya Sachan, Manu Kapur |  |
| 1449 |  |  [Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation](https://aclanthology.org/2025.findings-acl.1349/) |  | 0 | Ensuring persona fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions. However, LLMs often exhibit Out-of-Character (OOC) behavior, where generated responses deviate from an assigned persona, leading to inconsistencies that affect model... | Jisu Shin, Juhyun Oh, Eunsu Kim, Hoyun Song, Alice Oh |  |
| 1450 |  |  [What Language Do Non-English-Centric Large Language Models Think in?](https://aclanthology.org/2025.findings-acl.1350/) |  | 0 | In this study, we investigate whether non-English-centric large language models, ‘think’ in their specialized language. Specifically, we analyze how intermediate layer representations, when projected into the vocabulary space, favor certain languages during generation—termed as latent languages. We... | Chengzhi Zhong, Qianying Liu, Fei Cheng, Junfeng Jiang, Zhen Wan, Chenhui Chu, Yugo Murawaki, Sadao Kurohashi |  |
| 1451 |  |  [T⁵Score: A Methodology for Automatically Assessing the Quality of LLM Generated Multi-Document Topic Sets](https://aclanthology.org/2025.findings-acl.1351/) |  | 0 | Using LLMs for Multi-Document Topic Extraction has recently gained popularity due to their apparent high-quality outputs, expressiveness, and ease of use. However, most existing evaluation practices are not designed for LLM-generated topics and result in low inter-annotator agreement scores,... | Itamar Trainin, Omri Abend |  |
| 1452 |  |  [Uncertainty-Aware Contrastive Decoding](https://aclanthology.org/2025.findings-acl.1352/) |  | 0 | Large language models excel in a wide range of natural language processing tasks, but generating factually accurate and consistent outputs remains a challenge. To improve text reliability, Contrastive Decoding (CD) refines token selection by leveraging differences between an expert and base model,... | Hakyung Lee, Subeen Park, Joowang Kim, Sungjun Lim, Kyungwoo Song |  |
| 1453 |  |  [GEMS: Generation-Based Event Argument Extraction via Multi-perspective Prompts and Ontology Steering](https://aclanthology.org/2025.findings-acl.1353/) |  | 0 | Generative methods significantly advance event argument extraction by probabilistically generating event argument sequences in a structured format. However, existing approaches primarily rely on a single prompt to generate event arguments in a fixed, predetermined order. Such a rigid approach... | Run Lin, Yao Liu, Yanglei Gan, Yuxiang Cai, Tian Lan, Qiao Liu |  |
| 1454 |  |  [RomanLens: The Role Of Latent Romanization In Multilinguality In LLMs](https://aclanthology.org/2025.findings-acl.1354/) |  | 0 | Large Language Models (LLMs) exhibit strong multilingual performance despite being predominantly trained on English-centric corpora. This raises a fundamental question: How do LLMs achieve such multilingual capabilities? Focusing on languages written in non-Roman scripts, we investigate the role of... | Alan Saji, Jaavid Aktar Husain, Thanmay Jayakumar, Raj Dabre, Anoop Kunchukuttan, Ratish Puduppully |  |
| 1455 |  |  [7 Points to Tsinghua but 10 Points to ? Assessing Large Language Models in Agentic Multilingual National Bias](https://aclanthology.org/2025.findings-acl.1355/) |  | 0 | Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain... | Qianying Liu, Katrina Qiyao Wang, Fei Cheng, Sadao Kurohashi |  |
| 1456 |  |  [Search-in-Context: Efficient Multi-Hop QA over Long Contexts via Monte Carlo Tree Search with Dynamic KV Retrieval](https://aclanthology.org/2025.findings-acl.1356/) |  | 0 | Recent advancements in large language models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, such as math problem-solving and code generation. However, multi-hop question answering (MHQA) over long contexts, which demands both robust knowledge-intensive reasoning and... | Jiabei Chen, Guang Liu, Shizhu He, Kun Luo, Yao Xu, Jun Zhao, Kang Liu |  |
| 1457 |  |  [LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation](https://aclanthology.org/2025.findings-acl.1357/) |  | 0 | We introduce LLM-as-an-Interviewer, a novel paradigm for evaluating large language models (LLMs). This approach leverages multi-turn interactions where the LLM interviewer actively provides feedback on responses and poses follow-up questions to the evaluated LLM. At the start of the interview, the... | Eunsu Kim, Juyoung Suk, Seungone Kim, Niklas Muennighoff, Dongkwan Kim, Alice Oh |  |
| 1458 |  |  [IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems](https://aclanthology.org/2025.findings-acl.1358/) |  | 0 | In emotional support conversations, unclear intentions can lead supporters to employ inappropriate strategies, inadvertently imposing their expectations or solutions on the seeker. Clearly defined intentions are essential for guiding both the supporter’s motivations and the overall emotional... | Xinjie Zhang, Wenxuan Wang, Qin Jin |  |
| 1459 |  |  [Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models](https://aclanthology.org/2025.findings-acl.1359/) |  | 0 | Datasets used for emotion recognition tasks typically contain overt cues that can be used in predicting the emotions expressed in a text. However, one challenge is that texts sometimes contain covert contextual cues that are rich in affective semantics, which warrant higher-order reasoning... | Gerard Christopher Yeo, Kokil Jaidka |  |
| 1460 |  |  [CSTRL: Context-Driven Sequential Transfer Learning for Abstractive Radiology Report Summarization](https://aclanthology.org/2025.findings-acl.1360/) |  | 0 | A radiology report comprises several sections, including the Findings and Impression of the diagnosis. Automatically generating the Impression from the Findings is crucial for reducing radiologists’ workload and improving diagnostic accuracy. Pretrained models that excel in common abstractive... | Mst. Fahmida Sultana Naznin, Adnan Ibney Faruq, Mostafa Rifat Tazwar, Md Jobayer, Md. Mehedi Hasan Shawon, Md. Rakibul Hasan |  |
| 1461 |  |  [Rethinking Prompt-based Debiasing in Large Language Model](https://aclanthology.org/2025.findings-acl.1361/) |  | 0 | Investigating bias in large language models (LLMs) is crucial for developing trustworthy AI. While prompt-based through prompt engineering is common, its effectiveness relies on the assumption that models inherently understand biases. Our study systematically analyzed this assumption using the BBQ... | Xinyi Yang, Runzhe Zhan, Shu Yang, Junchao Wu, Lidia S. Chao, Derek F. Wong |  |
| 1462 |  |  [Exploring In-context Example Generation for Machine Translation](https://aclanthology.org/2025.findings-acl.1362/) |  | 0 | Large language models (LLMs) have demonstrated strong performance across various tasks, leveraging their exceptional in-context learning ability with only a few examples.Accordingly, the selection of optimal in-context examples has been actively studied in the field of machine translation.However,... | Dohyun Lee, Seungil Chad Lee, Chanwoo Yang, Yujin Baek, Jaegul Choo |  |
| 1463 |  |  [Knowledge Base Construction for Knowledge-Augmented Text-to-SQL](https://aclanthology.org/2025.findings-acl.1363/) |  | 0 | Text-to-SQL aims to translate natural language queries into SQL statements, which is practical as it enables anyone to easily retrieve the desired information from databases. Recently, many existing approaches tackle this problem with Large Language Models (LLMs), leveraging their strong capability... | Jinheon Baek, Horst Samulowitz, Oktie Hassanzadeh, Dharmashankar Subramanian, Sola Shirai, Alfio Gliozzo, Debarun Bhattacharjya |  |
| 1464 |  |  [NBDESCRIB: A Dataset for Text Description Generation from Tables and Code in Jupyter Notebooks with Guidelines](https://aclanthology.org/2025.findings-acl.1364/) |  | 0 | Generating cell-level descriptions for Jupyter Notebooks, which is a major resource consisting of codes, tables, and descriptions, has been attracting increasing research attention. However, existing methods for Jupyter Notebooks mostly focus on generating descriptions from code snippets or table... | Xuye Liu, Tengfei Ma, Yimu Wang, Fengjie Wang, Jian Zhao |  |
| 1465 |  |  [ECoRAG: Evidentiality-guided Compression for Long Context RAG](https://aclanthology.org/2025.findings-acl.1365/) |  | 0 | Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do... | Yeonseok Jeong, Jinsu Kim, Dohyeon Lee, Seungwon Hwang |  |
| 1466 |  |  [From Complexity to Clarity: AI/NLP's Role in Regulatory Compliance](https://aclanthology.org/2025.findings-acl.1366/) |  | 0 | Regulatory data compliance is a cornerstone of trust and accountability in critical sectors like finance, healthcare, and technology, yet its complexity poses significant challenges for organizations worldwide. Recent advances in natural language processing, particularly large language models, have... | Jivitesh Jain, Nivedhitha Dhanasekaran, Mona T. Diab |  |
| 1467 |  |  [EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](https://aclanthology.org/2025.findings-acl.1367/) |  | 0 | Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains... | Hyunjong Kim, Sangyeop Kim, Jongheon Jeong, Yeongjae Cho, Sungzoon Cho |  |
| 1468 |  |  [Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning](https://aclanthology.org/2025.findings-acl.1368/) |  | 0 | Theory of Mind (ToM) capabilities in LLMs have recently become a central object of investigation, sparking debates and discussions. In this position paper, we explore many lines of work in different communities in AI and cognitive science. Inspired by cognitive work, we view ToM tasks as a two-step... | Eitan Wagner, Nitay Alon, Joseph M. Barnby, Omri Abend |  |
| 1469 |  |  [LLMs are Biased Evaluators But Not Biased for Fact-Centric Retrieval Augmented Generation](https://aclanthology.org/2025.findings-acl.1369/) |  | 0 | Recent studies have demonstrated that large language models (LLMs) exhibit significant biases in evaluation tasks, particularly in preferentially rating and favoring self-generated content. However, the extent to which this bias manifests in fact-oriented tasks, especially within... | YenShan Chen, Jing Jin, PengTing Kuo, ChaoWei Huang, YunNung Chen |  |
| 1470 |  |  [Standard Quality Criteria Derived from Current NLP Evaluations for Guiding Evaluation Design and Grounding Comparability and AI Compliance Assessments](https://aclanthology.org/2025.findings-acl.1370/) |  | 0 | Research shows that two evaluation experiments reporting results for the same quality criterion name (e.g. Fluency) do not necessarily evaluate the same aspect of quality. Not knowing when two evaluations are comparable in this sense means we currently lack the ability to draw conclusions based on... | Anya Belz, Simon Mille, Craig Thomson |  |
| 1471 |  |  [skLEP: A Slovak General Language Understanding Benchmark](https://aclanthology.org/2025.findings-acl.1371/) |  | 0 | In this work, we introduce skLEP, the first comprehensive benchmark specifically designed for evaluating Slovak natural language understanding (NLU) models. We have compiled skLEP to encompass nine diverse tasks that span token-level, sentence-pair, and document-level challenges, thereby offering a... | Marek Suppa, Andrej Ridzik, Daniel Hládek, Tomas Javurek, Viktoria Ondrejova, Kristína Sásiková, Martin Tamajka, Marián Simko |  |
| 1472 |  |  [Can Vision Language Models Understand Mimed Actions?](https://aclanthology.org/2025.findings-acl.1372/) |  | 0 | Non-verbal communication (NVC) is an integral part of human language, but it has been overlooked in natural language processing research. Studying NVC in general is challenging because of its high variance in interpretation among individuals and cultures, but mime—the theatrical technique of... | Hyundong Justin Cho, Spencer Lin, Tejas Srinivasan, Michael Saxon, Deuksin Kwon, Natali T. Chavez, Jonathan May |  |
| 1473 |  |  [Training Language Model to Critique for Better Refinement](https://aclanthology.org/2025.findings-acl.1373/) |  | 0 | Large language models (LLMs) have demonstrated remarkable evaluation and critique capabilities, providing insightful feedback and identifying flaws in various tasks. However, limited research has explored which types of critiques are most effective for improving model responses or how to generate... | Tianshu Yu, Chao Xiang, Mingchuan Yang, Pei Ke, Bosi Wen, Cunxiang Wang, Jiale Cheng, Li Zhang, Xinyu Mu, Chuxiong Sun, Minlie Huang |  |
| 1474 |  |  [Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning](https://aclanthology.org/2025.findings-acl.1374/) |  | 0 | Multi-task prompt tuning utilizes multiple high-resource source tasks to improve performance on low-source target tasks. Existing approaches transfer the soft prompt trained by combining all source tasks or a single “high-similar” source task one-time-only. However, we find that the optimal... | Peiyi Zhang, Richong Zhang, Zhijie Nie, Ziqiao Wang |  |
| 1475 |  |  [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://aclanthology.org/2025.findings-acl.1375/) |  | 0 | Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such... | Kyochul Jang, Donghyeon Lee, Kyusik Kim, Dongseok Heo, Taewhoo Lee, Woojeong Kim, Bongwon Suh |  |
| 1476 |  |  [HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation](https://aclanthology.org/2025.findings-acl.1376/) |  | 0 | Retrieval-Augmented Generation (RAG) encounters efficiency challenges when scaling to massive knowledge bases while preserving contextual relevance. We propose Hash-RAG, a framework that integrates deep hashing techniques with systematic optimizations to address these limitations. Our queries... | Jinyu Guo, Xunlei Chen, Qiyang Xia, Zhaokun Wang, Jie Ou, Libo Qin, Shunyu Yao, Wenhong Tian |  |
| 1477 |  |  [A Constrained Text Revision Agent via Iterative Planning and Searching](https://aclanthology.org/2025.findings-acl.1377/) |  | 0 | Existing text revision systems are capable of generating fluent and coherent text, but struggle with constrained text revision (CTR), which requires adherence to specific constraints. Furthermore, adapting these systems to diverse constraints is challenging. To bridge this gap, we introduce TRIPS,... | Hannan Cao, Hwee Tou Ng |  |
| 1478 |  |  [MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models](https://aclanthology.org/2025.findings-acl.1378/) |  | 0 | This paper introduces MMRefine, a MultiModal Refinement benchmark designed to evaluate the error refinement capabilities of Multimodal Large Language Models (MLLMs). As the emphasis shifts toward enhancing reasoning during inference, MMRefine provides a framework that evaluates MLLMs’ abilities to... | Gio Paik, Geewook Kim, Jinbae Im |  |
| 1479 |  |  [How Programming Concepts and Neurons Are Shared in Code Language Models](https://aclanthology.org/2025.findings-acl.1379/) |  | 0 | Several studies have explored the mechanisms of large language models (LLMs) in coding tasks, but most have focused on programming languages (PLs) in a monolingual setting. In this paper, we investigate the relationship between multiple PLs and English in the concept space of LLMs. We perform a... | Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schütze |  |
| 1480 |  |  [DynaQuest: A Dynamic Question Answering Dataset Reflecting Real-World Knowledge Updates](https://aclanthology.org/2025.findings-acl.1380/) |  | 0 | The rapidly changing nature of real-world information presents challenges for large language models (LLMs), which are typically trained on static datasets. This limitation makes it difficult for LLMs to accurately perform tasks that require up-to-date knowledge, such as time-sensitive question... | Qian Lin, Junyi Li, Hwee Tou Ng |  |
| 1481 |  |  [ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations](https://aclanthology.org/2025.findings-acl.1381/) |  | 0 | Large language models (LLMs) demonstrate impressive results in natural language processing tasks but require a significant amount of computational and memory resources. Structured matrix representations are a promising way for reducing the number of parameters of these models. However, it seems... | Ekaterina Grishina, Mikhail Gorbunov, Maxim Rakhuba |  |
| 1482 |  |  [Revisiting In-Context Learning with Long Context Language Models](https://aclanthology.org/2025.findings-acl.1382/) |  | 0 | In-Context Learning (ICL) is a technique by which language models make predictions based on examples provided in their input context. Previously, their context window size imposed a limit on the number of examples that can be shown, making example selection techniques crucial for identifying the... | Jinheon Baek, Sun Jae Lee, Prakhar Gupta, Geunseob Oh, Siddharth Dalmia, Prateek Kolhar |  |
| 1483 |  |  [Rationalize and Align: Enhancing Writing Assistance with Rationale via Self-Training for Improved Alignment](https://aclanthology.org/2025.findings-acl.1383/) |  | 0 | A Writing Assistant (WA) is a system that offers writing suggestions based on user instructions. Existing WAs are typically built by training large language models (LLMs) on domain-specific instruction data through supervised fine-tuning (SFT) only. However, SFT optimizes models to match a single... | Hannan Cao, Hai Ye, Hwee Tou Ng |  |
| 1484 |  |  [Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps](https://aclanthology.org/2025.findings-acl.1384/) |  | 0 | Retrieval-augmented generation (RAG) has emerged as a pivotal method for expanding the knowledge of large language models. To handle complex queries more effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the generated quality through multiple interactions with external knowledge... | Jie Ou, Jinyu Guo, Shuaihong Jiang, Zhaokun Wang, Libo Qin, Shunyu Yao, Wenhong Tian |  |
| 1485 |  |  [MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment](https://aclanthology.org/2025.findings-acl.1385/) |  | 0 | English-centric large language models (LLMs) often show strong multilingual capabilities. However, their multilingual performance remains unclear and is under-evaluated for many other languages. Most benchmarks for multilinguality focus on classic NLP tasks or cover a minimal number of languages.... | Amir Hossein Kargaran, Ali Modarressi, Nafiseh Nikeghbal, Jana Diesner, François Yvon, Hinrich Schütze |  |
| 1486 |  |  [Automated Fine-Grained Mixture-of-Experts Quantization](https://aclanthology.org/2025.findings-acl.1386/) |  | 0 | The Mixture of Experts (MoE) architecture enables efficient model scaling through conditional computation, where only subset of parameters are activated per input. However, this distributed architecture poses unprecedented challenges for model compression, as conventional quantization methods... | Zhanhao Xie, Yuexiao Ma, Xiawu Zheng, Fei Chao, Wanchen Sui, Yong Li, Shen Li, Rongrong Ji |  |
| 1487 |  |  [Enhancing Complex Reasoning in Knowledge Graph Question Answering through Query Graph Approximation](https://aclanthology.org/2025.findings-acl.1387/) |  | 0 | Knowledge-grounded Question Answering (QA) aims to provide answers to structured queries or natural language questions by leveraging Knowledge Graphs (KGs). Existing approaches are mainly divided into Knowledge Graph Question Answering (KGQA) and Complex Query Answering (CQA). Both approaches have... | Hongjun Jeong, Minji Kim, Heesoo Jung, Ko Keun Kim, Hogun Park |  |
| 1488 |  |  [Frontmatter](https://aclanthology.org/2025.acl-long.0/) |  | 0 |  |  |  |
| 1489 |  |  [EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association](https://aclanthology.org/2025.acl-long.1/) |  | 0 | Goal-oriented script planning, or the ability to devise coherent sequences of actions toward specific goals, is commonly employed by humans to plan for typical activities. In e-commerce, customers increasingly seek LLM-based assistants to generate scripts and recommend products at each step,... | Weiqi Wang, Limeng Cui, Xin Liu, Sreyashi Nag, Wenju Xu, Chen Luo, Sheikh Muhammad Sarwar, Yang Li, Hansu Gu, Hui Liu, Changlong Yu, Jiaxin Bai, Yifan Gao, Haiyang Zhang, Qi He, Shuiwang Ji, Yangqiu Song |  |
| 1490 |  |  [GraphNarrator: Generating Textual Explanations for Graph Neural Networks](https://aclanthology.org/2025.acl-long.2/) |  | 0 | Graph representation learning has garnered significant attention due to its broad applications in various domains, such as recommendation systems and social network analysis. Despite advancements in graph learning methods, challenges still remain in explainability when graphs are associated with... | Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Yuntong Hu, Liang Zhao |  |
| 1491 |  |  [M-RewardBench: Evaluating Reward Models in Multilingual Settings](https://aclanthology.org/2025.acl-long.3/) |  | 0 | Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling the integration of human feedback into the language modeling process. However, RMs are primarily trained and evaluated in English, and their capabilities in multilingual settings remain largely understudied.... | Srishti Gureja, Lester James Validad Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti Sharma, Gusti Triandi Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee |  |
| 1492 |  |  [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://aclanthology.org/2025.acl-long.4/) |  | 0 | While recent research increasingly emphasizes the value of human-LLM collaboration in competitive programming and proposes numerous empirical methods, a comprehensive understanding remains elusive due to the fragmented nature of existing studies and their use of diverse, application-specific human... | Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei |  |
| 1493 |  |  [The Impossibility of Fair LLMs](https://aclanthology.org/2025.acl-long.5/) |  | 0 | The rise of general-purpose artificial intelligence (AI) systems, particularly large language models (LLMs), has raised pressing moral questions about how to reduce bias and ensure fairness at scale. Researchers have documented a sort of “bias” in the significant correlations between demographics... | Jacy Reese Anthis, Kristian Lum, Michael D. Ekstrand, Avi Feller, Chenhao Tan |  |
| 1494 |  |  [Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process](https://aclanthology.org/2025.acl-long.6/) |  | 0 | Supervised Fine-Tuning (SFT) and Preference Optimization (PO) are key processes for aligning Language Models (LMs) with human preferences post pre-training. While SFT excels in efficiency and PO in effectiveness, they are often combined sequentially without integrating their optimization... | Ermo Hua, Biqing Qi, Kaiyan Zhang, Kai Tian, Xingtai Lv, Ning Ding, Bowen Zhou |  |
| 1495 |  |  [Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation](https://aclanthology.org/2025.acl-long.7/) |  | 0 | Standard bias benchmarks used for large language models (LLMs) measure the association between social attributes in model inputs and single-word model outputs. We test whether these benchmarks are robust to lengthening the model outputs via a more realistic user prompt, in the commonly studied... | Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander Nicholas D'Amour |  |
| 1496 |  |  [Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models](https://aclanthology.org/2025.acl-long.8/) |  | 0 | Large Language Models (LLMs) have shown exciting performance in listwise passage ranking. Due to the limited input length, existing methods often adopt the sliding window strategy. Such a strategy, though effective, is inefficient as it involves repetitive and serialized processing, which usually... | Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou |  |
| 1497 |  |  [The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It](https://aclanthology.org/2025.acl-long.9/) |  | 0 | This study investigates the integration of diverse patient data sources into multimodal language models for automated chest X-ray (CXR) report generation. Traditionally, CXR report generation relies solely on data from a patient’s CXR exam, overlooking valuable information from patient electronic... | Aaron Nicolson, Shengyao Zhuang, Jason Dowling, Bevan Koopman |  |
| 1498 |  |  [CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction](https://aclanthology.org/2025.acl-long.10/) |  | 0 | The paper focuses on the interpretability of Grammatical Error Correction (GEC) evaluation metrics, which received little attention in previous studies. To bridge the gap, we introduce \*\*CLEME2.0\*\*, a reference-based metric describing four fundamental aspects of GEC systems: hit-correction,... | Jingheng Ye, Zishan Xu, Yinghui Li, Linlin Song, Qingyu Zhou, HaiTao Zheng, Ying Shen, Wenhao Jiang, HongGee Kim, Ruitong Liu, Xin Su, Zifei Shan |  |
| 1499 |  |  [StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in Structure-Rich Text](https://aclanthology.org/2025.acl-long.11/) |  | 0 | The effective utilization of structured data, integral to corporate data strategies, has been challenged by the rise of large language models (LLMs) capable of processing unstructured information. This shift prompts the question: can LLMs interpret structured data directly in its unstructured form?... | Zhouhong Gu, Haoning Ye, Xingzhou Chen, Zeyang Zhou, Hongwei Feng, Yanghua Xiao |  |
| 1500 |  |  [Literature Meets Data: A Synergistic Approach to Hypothesis Generation](https://aclanthology.org/2025.acl-long.12/) |  | 0 | AI holds promise for transforming scientific processes, including hypothesis generation. Prior work on hypothesis generation can be broadly categorized into theory-driven and data-driven approaches. While both have proven effective in generating novel and plausible hypotheses, it remains an open... | Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan |  |
| 1501 |  |  [GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization](https://aclanthology.org/2025.acl-long.13/) |  | 0 | Recent advances in large language models have highlighted the critical need for precise control over model outputs through predefined constraints. While existing methods attempt to achieve this through either direct instruction-response synthesis or preferential response optimization, they often... | Zhouhong Gu, Xingzhou Chen, Xiaoran Shi, Tao Wang, Suhang Zheng, Tianyu Li, Hongwei Feng, Yanghua Xiao |  |
| 1502 |  |  [Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models](https://aclanthology.org/2025.acl-long.14/) |  | 0 | Data synthesis has become a crucial research area in large language models (LLMs), especially for generating high-quality instruction fine-tuning data to enhance downstream performance. In code generation, a key application of LLMs, manual annotation of code instruction data is costly. Recent... | Ziyang Luo, Kaixin Li, Hongzhan Lin, Yuchen Tian, Mohan S. Kankanhalli, Jing Ma |  |
| 1503 |  |  [Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models](https://aclanthology.org/2025.acl-long.15/) |  | 0 | Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing... | Seunguk Yu, Juhwan Choi, YoungBin Kim |  |
| 1504 |  |  [ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision](https://aclanthology.org/2025.acl-long.16/) |  | 0 | Multi-hop question answering (MHQA) involves reasoning across multiple documents to answer complex questions. Dense retrievers typically outperform sparse methods like BM25 by leveraging semantic embeddings in many tasks; however, they require labeled query-document pairs for fine-tuning, which... | Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo |  |
| 1505 |  |  [FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models](https://aclanthology.org/2025.acl-long.17/) |  | 0 | Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations... | Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, SeeKiong Ng, TatSeng Chua |  |
| 1506 |  |  [Statistical Deficiency for Task Inclusion Estimation](https://aclanthology.org/2025.acl-long.18/) |  | 0 | Tasks are central in machine learning, as they are the most natural objects to assess the capabilities of current models. The trend is to build general models able to address any task. Even though transfer learning and multitask learning try to leverage the underlying task space, no well-founded... | Loïc Fosse, Frédéric Béchet, Benoît Favre, Géraldine Damnati, Gwénolé Lecorvé, Maxime Darrin, Philippe Formont, Pablo Piantanida |  |
| 1507 |  |  [Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients](https://aclanthology.org/2025.acl-long.19/) |  | 0 | Federated fine-tuning for Large Language Models (LLMs) has recently gained attention due to the heavy communication overhead of transmitting large model updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its application in federated learning is complicated by discordance in... | Jabin Koo, Minwoo Jang, Jungseul Ok |  |
| 1508 |  |  [LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs](https://aclanthology.org/2025.acl-long.20/) |  | 0 | Detecting tricky bugs in plausible programs, those that pass existing test suites yet still contain bugs, remains a significant challenge in software testing. To address this problem, we propose TrickCatcher, an LLM-powered approach to generating test cases for uncovering bugs in plausible... | Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie M. Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, Ge Li, Gang Huang |  |
| 1509 |  |  [Capture the Key in Reasoning to Enhance CoT Distillation Generalization](https://aclanthology.org/2025.acl-long.21/) |  | 0 | As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts (CoTs) reasoning abilities, practical resource constraints drive efforts to distill these capabilities into more compact Smaller Language Models (SLMs). We find that CoTs consist mainly of simple reasoning forms, with a... | Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu |  |
| 1510 |  |  [How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond](https://aclanthology.org/2025.acl-long.22/) |  | 0 | With the advancement of large language models (LLMs), intelligent models have evolved from mere tools to autonomous agents with their own goals and strategies for cooperating with humans. This evolution has birthed a novel paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable... | Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, TatSeng Chua, Jimmy Huang |  |
| 1511 |  |  [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://aclanthology.org/2025.acl-long.23/) |  | 0 | Text-based hyperbole and metaphor detection are of great significance for natural language processing (NLP) tasks. However, due to their semantic obscurity and expressive diversity, it is rather challenging to identify them. Existing methods mostly focus on superficial text features, ignoring the... | Li Zheng, Sihang Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, Donghong Ji |  |
| 1512 |  |  [UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation](https://aclanthology.org/2025.acl-long.24/) |  | 0 | In-context learning (ICL) enhances the reasoning abilities of Large Language Models (LLMs) by prepending a few demonstrations. It motivates researchers to introduce more examples to provide additional contextual information for the generation. However, existing methods show a significant limitation... | Jun Gao, Qi Lv, Zili Wang, Tianxiang Wu, Ziqiang Cao, Wenjie Li |  |
| 1513 |  |  [BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian](https://aclanthology.org/2025.acl-long.25/) |  | 0 | In the epoch of multilingual large language models (LLMs), it is still challenging to evaluate the models’ understanding of lower-resourced languages, which motivates further development of expert-crafted natural language understanding benchmarks. We introduce BelarusianGLUE — a natural language... | Maksim Aparovich, Volha Harytskaya, Vladislav Poritski, Oksana Volchek, Pavel Smrz |  |
| 1514 |  |  [A Survey on Foundation Language Models for Single-cell Biology](https://aclanthology.org/2025.acl-long.26/) |  | 0 | The recent advancements in language models have significantly catalyzed progress in computational biology. A growing body of research strives to construct unified foundation models for single-cell biology, with language models serving as the cornerstone. In this paper, we systematically review the... | Fan Zhang, Hao Chen, Zhihong Zhu, Ziheng Zhang, Zhenxi Lin, Ziyue Qiao, Yefeng Zheng, Xian Wu |  |
| 1515 |  |  [RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios](https://aclanthology.org/2025.acl-long.27/) |  | 0 | This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning. Covering three practical domains – airline baggage fees, NBA transactions, and tax regulations – RuleArena assesses... | Ruiwen Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang |  |
| 1516 |  |  [Extending LLM Context Window with Adaptive Grouped Positional Encoding: A Training-Free Method](https://aclanthology.org/2025.acl-long.28/) |  | 0 | Processing long input remains a significant challenge for large language models (LLMs) due to the scarcity of large-scale long-context training data and the high computational cost of training models for extended context windows. In this paper, we propose \*\*Ada\*\*ptive \*\*Gro\*\*uped... | Xinhao Xu, Jiaxin Li, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding |  |
| 1517 |  |  [Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models](https://aclanthology.org/2025.acl-long.29/) |  | 0 | Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer from computational inefficiency and redundancy. First, they... | Sungjae Lee, Hyejin Park, Jaechang Kim, Jungseul Ok |  |
| 1518 |  |  [HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval](https://aclanthology.org/2025.acl-long.30/) |  | 0 | We present HotelMatch-LLM, a multimodal dense retrieval model for the travel domain that enables natural language property search, addressing the limitations of traditional travel search engines which require users to start with a destination and editing search parameters. HotelMatch-LLM features... | Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev |  |
| 1519 |  |  [Can Multimodal Large Language Models Understand Spatial Relations?](https://aclanthology.org/2025.acl-long.31/) |  | 0 | Spatial relation reasoning is a crucial task for multimodal large language models (MLLMs) to understand the objective world. However, current benchmarks have issues like relying on bounding boxes, ignoring perspective substitutions, or allowing questions to be answered using only the model’s prior... | Jingping Liu, Ziyan Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan |  |
| 1520 |  |  [S³ - Semantic Signal Separation](https://aclanthology.org/2025.acl-long.32/) |  | 0 | Topic models are useful tools for discovering latent semantic structures in large textual corpora. Recent efforts have been oriented at incorporating contextual representations in topic modeling and have been shown to outperform classical topic models. These approaches are typically slow, volatile,... | Márton Kardos, Jan Kostkan, Kenneth C. Enevoldsen, ArnaultQuentin Vermillet, Kristoffer L. Nielbo, Roberta Rocca |  |
| 1521 |  |  [TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs](https://aclanthology.org/2025.acl-long.33/) |  | 0 | Specializing large language models (LLMs) for local deployment in domain-specific use cases is necessary for strong performance while meeting latency and privacy constraints. However, conventional task-specific adaptation approaches do not show simultaneous memory saving and inference speedup at... | Lanxiang Hu, Tajana Rosing, Hao Zhang |  |
| 1522 |  |  [JuStRank: Benchmarking LLM Judges for System Ranking](https://aclanthology.org/2025.acl-long.34/) |  | 0 | Given the rapid progress of generative AI, there is a pressing need to systematically compare and choose between the numerous models and configurations available. The scale and versatility of such evaluations make the use of LLM-based judges a compelling solution for this challenge. Crucially, this... | Ariel Gera, Odellia Boni, Yotam Perlitz, Roy BarHaim, Lilach Eden, Asaf Yehudai |  |
| 1523 |  |  [Generating Diverse Training Samples for Relation Extraction with Large Language Models](https://aclanthology.org/2025.acl-long.35/) |  | 0 | Using Large Language Models (LLMs) to generate training data can potentially be a preferable way to improve zero or few-shot NLP tasks. However, many problems remain to be investigated for this direction. For the task of Relation Extraction (RE), we find that samples generated by directly prompting... | Zexuan Li, Hongliang Dai, Piji Li |  |
| 1524 |  |  [MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts](https://aclanthology.org/2025.acl-long.36/) |  | 0 | Recent LLMs are able to generate high-quality multilingual texts, indistinguishable for humans from authentic human-written ones. Research in machine-generated text detection is however mostly focused on the English language and longer texts, such as news articles, scientific papers or student... | Dominik Macko, Jakub Kopal, Róbert Móro, Ivan Srba |  |
| 1525 |  |  [Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection](https://aclanthology.org/2025.acl-long.37/) |  | 0 | Automatic prompt engineering aims to enhance the generation quality of large language models (LLMs). Recent works utilize feedbacks generated from erroneous cases to guide the prompt optimization. During inference, they may further retrieve several semantically-related exemplars and concatenate... | Cilin Yan, Jingyun Wang, Lin Zhang, Ruihui Zhao, Xiaopu Wu, Kai Xiong, Qingsong Liu, Guoliang Kang, Yangyang Kang |  |
| 1526 |  |  [Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation](https://aclanthology.org/2025.acl-long.38/) |  | 0 | The capabilities of recent large language models (LLMs) to generate high-quality content indistinguishable by humans from human-written texts raises many concerns regarding their misuse. Previous research has shown that LLMs can be effectively misused for generating disinformation news articles... | Aneta Zugecova, Dominik Macko, Ivan Srba, Róbert Móro, Jakub Kopál, Katarina Marcincinova, Matús Mesarcík |  |
| 1527 |  |  [EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents](https://aclanthology.org/2025.acl-long.39/) |  | 0 | Language model agents excel in long-session planning and reasoning, but existing benchmarks primarily focus on goal-oriented tasks with explicit objectives, neglecting creative adaptation in unfamiliar environments. To address this, we introduce EscapeBench—a benchmark suite of room escape game... | Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji |  |
| 1528 |  |  [BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving](https://aclanthology.org/2025.acl-long.40/) |  | 0 | LLMs exhibit advanced reasoning capabilities, offering the potential to transform natural language questions into mathematical models. However, existing open-source datasets in operations research domain lack detailed annotations of the modeling process, such as variable definitions, focusing... | Teng Wang, Wing Yin Yu, Zhenqi He, Zehua Liu, HaileiGong HaileiGong, Han Wu, Xiongwei Han, Wei Shi, Ruifeng She, Fangzhou Zhu, Tao Zhong |  |
| 1529 |  |  [LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation](https://aclanthology.org/2025.acl-long.41/) |  | 0 | Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed sentiment analysis in a target language by transferring knowledge from a source language with available annotated data. Most existing methods depend heavily on often unreliable translation tools to bridge the language gap. In... | Jakub Smíd, Pavel Pribán, Pavel Král |  |
| 1530 |  |  [Fusing Highly Specialized Language Models for Comprehensive Expertise](https://aclanthology.org/2025.acl-long.42/) |  | 0 | Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for... | Ning Ding, Yulin Chen, Ganqu Cui, Xingtai Lv, Weilin Zhao, Kaiyan Zhang, Ruobing Xie, Bowen Zhou, Zhiyuan Liu, Maosong Sun |  |
| 1531 |  |  [HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases](https://aclanthology.org/2025.acl-long.43/) |  | 0 | Given a semi-structured knowledge base (SKB), where text documents are interconnected by relations, how can we effectively retrieve relevant information to answer user questions?Retrieval-Augmented Generation (RAG) retrieves documents to assist large language models (LLMs) in question answering;... | MengChieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos |  |
| 1532 |  |  [Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms](https://aclanthology.org/2025.acl-long.44/) |  | 0 | Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated... | Rajvardhan Oak, Muhammad Haroon, Claire Wonjeong Jo, Magdalena Wojcieszak, Anshuman Chhabra |  |
| 1533 |  |  [Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review](https://aclanthology.org/2025.acl-long.45/) |  | 0 | Clinical coding is crucial for healthcare billing and data analysis. Manual clinical coding is labour-intensive and error-prone, which has motivated research towards full automation of the process. However, our analysis, based on US English electronic health records and automated coding research... | Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld |  |
| 1534 |  |  [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://aclanthology.org/2025.acl-long.46/) |  | 0 | The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we... | Ziyan Liu, Chunxiao Fan, Haoran Lou, Yuexin Wu, Kaiwei Deng |  |
| 1535 |  |  [EvoWiki: Evaluating LLMs on Evolving Knowledge](https://aclanthology.org/2025.acl-long.47/) |  | 0 | Knowledge utilization is a critical aspect of LLMs, and understanding how they adapt to evolving knowledge is essential for their effective deployment. However, existing benchmarks are predominantly static, failing to capture the evolving nature of LLMs and knowledge, leading to inaccuracies and... | Wei Tang, Yixin Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, YuGang Jiang, Yong Liao |  |
| 1536 |  |  [Rethinking Repetition Problems of LLMs in Code Generation](https://aclanthology.org/2025.acl-long.48/) |  | 0 | With the advent of neural language models, the performance of code generation has been significantly boosted. However, the problem of repetitions during the generation process continues to linger. Previous work has primarily focused on content repetition, which is merely a fraction of the broader... | Yihong Dong, Yuchen Liu, Xue Jiang, Bin Gu, Zhi Jin, Ge Li |  |
| 1537 |  |  [PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension](https://aclanthology.org/2025.acl-long.49/) |  | 0 | Multimodal punchlines, which involve humor or sarcasm conveyed in image-caption pairs, are a popular way of communication on online multimedia platforms. With the rapid development of multimodal large language models (MLLMs), it is essential to assess their ability to effectively comprehend these... | Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun |  |
| 1538 |  |  [ProcessBench: Identifying Process Errors in Mathematical Reasoning](https://aclanthology.org/2025.acl-long.50/) |  | 0 | As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in... | Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin |  |
| 1539 |  |  [Model Extrapolation Expedites Alignment](https://aclanthology.org/2025.acl-long.51/) |  | 0 | Given the high computational cost of preference alignment training of large language models (LLMs), exploring efficient methods to reduce the training overhead remains an important and compelling research problem. Motivated by the observation that alignment training typically involves only small... | Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng |  |
| 1540 |  |  [ATLANTIS: Weak-to-Strong Learning via Importance Sampling](https://aclanthology.org/2025.acl-long.52/) |  | 0 | Supervised fine-tuning (SFT) enables large language models to align with training data for better performance in many aspects. Nevertheless, the gap between the distribution of current datasets from human annotations or model generations and the real-world data distribution heavily limits the... | Yi Liu, Guoyin Wang, Shicheng Li, Feifan Song, Xu Sun |  |
| 1541 |  |  [MPVStance: Mitigating Hallucinations in Stance Detection with Multi-Perspective Verification](https://aclanthology.org/2025.acl-long.53/) |  | 0 | Stance detection is a pivotal task in Natural Language Processing (NLP), identifying textual attitudes toward various targets. Despite advances in using Large Language Models (LLMs), challenges persist due to hallucination-models generating plausible yet inaccurate content. Addressing these... | Zhaodan Zhang, Zhao Zhang, Jin Zhang, Hui Xu, Xueqi Cheng |  |
| 1542 |  |  [Personality-Guided Code Generation Using Large Language Models](https://aclanthology.org/2025.acl-long.54/) |  | 0 | Code generation, the automatic creation of source code from natural language descriptions, has garnered significant attention due to its potential to streamline software development. Inspired by research that links task-personality alignment with improved development outcomes, we conduct an... | Yaoqi Guo, Zhenpeng Chen, Jie M. Zhang, Yang Liu, Yun Ma |  |
| 1543 |  |  [PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling](https://aclanthology.org/2025.acl-long.55/) |  | 0 | Currently, large language models (LLMs) have made significant progress in the field of psychological counseling. However, existing mental health LLMs overlook a critical issue where they do not consider the fact that different psychological counselors exhibit different personal styles, including... | Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu |  |
| 1544 |  |  [BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework](https://aclanthology.org/2025.acl-long.56/) |  | 0 | Recently, generative pre-trained models have made significant strides, particularly highlighted by the release of ChatGPT and GPT-4, which exhibit superior cross-domain capabilities. However, these models still face challenges on constrained writing tasks like poem generation under open-domain... | Xu Zou |  |
| 1545 |  |  [LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating](https://aclanthology.org/2025.acl-long.57/) |  | 0 | Large vision language models (LVLMs) have improved the document understanding capabilities remarkably, enabling the handling of complex document elements, longer contexts, and a wider range of tasks. However, existing document understanding benchmarks have been limited to handling only a small... | Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, ZhongZhi Li, Jian Xu, XiaoHui Li, Yuan Gao, Jun Song, Bo Zheng, ChengLin Liu |  |
| 1546 |  |  [ObfusLM: Privacy-preserving Language Model Service against Embedding Inversion Attacks](https://aclanthology.org/2025.acl-long.58/) |  | 0 | As the rapid expansion of Machine Learning as a Service (MLaaS) for language models, concerns over the privacy of client inputs during inference or fine-tuning have correspondingly escalated. Recently, solutions have been proposed to safeguard client privacy by obfuscation techniques. However, the... | Yu Lin, Ruining Yang, Yunlong Mao, Qizhi Zhang, Jue Hong, Quanwei Cai, Ye Wu, Huiqi Liu, Zhiyu Chen, Bing Duan, Sheng Zhong |  |
| 1547 |  |  [Interlocking-free Selective Rationalization Through Genetic-based Learning](https://aclanthology.org/2025.acl-long.59/) |  | 0 | A popular end-to-end architecture for selective rationalization is the select-then-predict pipeline, comprising a generator to extract highlights fed to a predictor. Such a cooperative system suffers from suboptimal equilibrium minima due to the dominance of one of the two modules, a phenomenon... | Federico Ruggeri, Gaetano Signorelli |  |
| 1548 |  |  [Re-identification of De-identified Documents with Autoregressive Infilling](https://aclanthology.org/2025.acl-long.60/) |  | 0 | Documents revealing sensitive information about individuals must typically be de-identified. This de-identification is often done by masking all mentions of personally identifiable information (PII), thereby making it more difficult to uncover the identity of the person(s) in question. To... | Lucas Georges Gabriel Charpentier, Pierre Lison |  |
| 1549 |  |  [Modeling Uncertainty in Composed Image Retrieval via Probabilistic Embeddings](https://aclanthology.org/2025.acl-long.61/) |  | 0 | Composed Image Retrieval (CIR) enables users to search for images using multimodal queries that combine text and reference images. While metric learning methods have shown promise, they rely on deterministic point embeddings that fail to capture the inherent uncertainty in the input data, in which... | Haomiao Tang, Jinpeng Wang, Yuang Peng, Guanghao Meng, Ruisheng Luo, Bin Chen, Long Chen, Yaowei Wang, Shutao Xia |  |
| 1550 |  |  [Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models](https://aclanthology.org/2025.acl-long.62/) |  | 0 | Large language models (LLM) have prioritized expanding the context window from which models can incorporate more information. However, training models to handle long contexts presents significant challenges. These include the scarcity of high-quality natural long-context data, the potential for... | Junfeng Tian, Da Zheng, Yang Chen, Rui Wang, Colin Zhang, Debing Zhang |  |
| 1551 |  |  [APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts](https://aclanthology.org/2025.acl-long.63/) |  | 0 | Large Language Models (LLMs) have become increasingly capable of handling diverse tasks with the aid of well-crafted prompts and integration of external tools, but as task complexity rises, the workflow involving LLMs can be complicated and thus challenging to implement and maintain. To address... | Honghua Dong, Qidong Su, Yubo Gao, Zhaoyu Li, Yangjun Ruan, Gennady Pekhimenko, Chris J. Maddison, Xujie Si |  |
| 1552 |  |  [Evaluating Lexical Proficiency in Neural Language Models](https://aclanthology.org/2025.acl-long.64/) |  | 0 | We present a novel evaluation framework designed to assess the lexical proficiency and linguistic creativity of Transformer-based Language Models (LMs). We validate the framework by analyzing the performance of a set of LMs of different sizes, in both mono- and multilingual configuration, across... | Cristiano Ciaccio, Alessio Miaschi, Felice Dell'Orletta |  |
| 1553 |  |  [Autoregressive Speech Synthesis without Vector Quantization](https://aclanthology.org/2025.acl-long.65/) |  | 0 | We present MELLE, a novel continuous-valued token based language modeling approach for text-to-speech synthesis (TTS). MELLE autoregressively generates continuous mel-spectrogram frames directly from text condition, bypassing the need for vector quantization, which is typically designed for audio... | Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing Liu, Jinyu Li, Sheng Zhao, Xixin Wu, Helen M. Meng, Furu Wei |  |
| 1554 |  |  [Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest](https://aclanthology.org/2025.acl-long.66/) |  | 0 | Massive high-quality data, both pre-training raw texts and post-training annotations, have been carefully prepared to incubate advanced large language models (LLMs). In contrast, for information extraction (IE), pre-training data, such as BIO-tagged sequences, are hard to scale up. We show that IE... | Letian Peng, Zilong Wang, Feng Yao, Jingbo Shang |  |
| 1555 |  |  [FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Large Language Models](https://aclanthology.org/2025.acl-long.67/) |  | 0 | Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning of foundation models. However, applying LoRA in federated learning environments, where data is distributed across multiple clients, presents unique challenges. Existing methods rely on traditional federated averaging of... | Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma |  |
| 1556 |  |  [Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality](https://aclanthology.org/2025.acl-long.68/) |  | 0 | Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases... | Rahul Zalkikar, Kanchan Chandra |  |
| 1557 |  |  [Capturing Author Self Beliefs in Social Media Language](https://aclanthology.org/2025.acl-long.69/) |  | 0 | Measuring the prevalence and dimensions of self beliefs is essential for understanding human self-perception and various psychological outcomes. In this paper, we develop a novel task for classifying language that contains explicit or implicit mentions of the author’s self beliefs. We contribute a... | Siddharth Mangalik, Adithya V. Ganesan, Abigail B. Wheeler, Nicholas Kerry, Jeremy D. W. Clifton, H. Andrew Schwartz, Ryan L. Boyd |  |
| 1558 |  |  [Neural Topic Modeling with Large Language Models in the Loop](https://aclanthology.org/2025.acl-long.70/) |  | 0 | Topic modeling is a fundamental task in natural language processing, allowing the discovery of latent thematic structures in text corpora. While Large Language Models (LLMs) have demonstrated promising capabilities in topic discovery, their direct application to topic modeling suffers from issues... | Xiaohao Yang, He Zhao, Weijie Xu, Yuanyuan Qi, Jueqing Lu, Dinh Phung, Lan Du |  |
| 1559 |  |  [HALoGEN: Fantastic LLM Hallucinations and Where to Find Them](https://aclanthology.org/2025.acl-long.71/) |  | 0 | Despite their impressive ability to generate high-quality and fluent text, generative large language models (LLMs) also produce hallucinations: statements that are misaligned with established world knowledge or provided input context. However, measuring hallucination can be challenging, as having... | Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi |  |
| 1560 |  |  [Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection](https://aclanthology.org/2025.acl-long.72/) |  | 0 | Large Language Models (LLMs) can assist multimodal fake news detection by predicting pseudo labels. However, LLM-generated pseudo labels alone demonstrate poor performance compared to traditional detection methods, making their effective integration non-trivial. In this paper, we propose Global... | Shuguo Hu, Jun Hu, Huaiwen Zhang |  |
| 1561 |  |  ["Yes, My LoRD." Guiding Language Model Extraction with Locality Reinforced Distillation](https://aclanthology.org/2025.acl-long.73/) |  | 0 | Model extraction attacks (MEAs) on large language models (LLMs) have received increasing attention in recent research. However, existing attack methods typically adapt the extraction strategies originally developed for deep neural networks (DNNs). They neglect the underlying inconsistency between... | Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu |  |
| 1562 |  |  [Jailbreak Large Vision-Language Models Through Multi-Modal Linkage](https://aclanthology.org/2025.acl-long.74/) |  | 0 | With the rapid advancement of Large Vision-Language Models (VLMs), concerns about their ‌potential misuse and abuse have grown rapidly. Prior research has exposed VLMs’ vulnerability to jailbreak attacks, where carefully crafted inputs can lead the model to produce content that violates ethical and... | Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He |  |
| 1563 |  |  [Wait, that's not an option: LLMs Robustness with Incorrect Multiple-Choice Options](https://aclanthology.org/2025.acl-long.75/) |  | 0 | This work introduces a novel framework for evaluating LLMs’ capacity to balance instruction-following with critical reasoning when presented with multiple-choice questions containing no valid answers. Through systematic evaluation across arithmetic, domain-specific knowledge, and high-stakes... | Gracjan Góral, Emilia Wisnios, Piotr Sankowski, Pawel Budzianowski |  |
| 1564 |  |  [The Hidden Attention of Mamba Models](https://aclanthology.org/2025.acl-long.76/) |  | 0 | The Mamba layer offers an efficient selective state-space model (SSM) that is highly effective in modeling multiple domains, includingNLP, long-range sequence processing, and computer vision. Selective SSMs are viewed as dual models, in which one trains in parallel on the entire sequence via an... | Ameen Ali, Itamar Zimerman, Lior Wolf |  |
| 1565 |  |  [KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding](https://aclanthology.org/2025.acl-long.77/) |  | 0 | Large language models (LLMs) based on Transformer Decoders have become the preferred choice for conversational generative AI. Despite the overall superiority of the Decoder architecture, the gradually increasing Key-Value (KV) cache during inference has emerged as a primary efficiency bottleneck,... | Luohe Shi, Zuchao Li, Lefei Zhang, Baoyuan Qi, Liu Guoming, Hai Zhao |  |
| 1566 |  |  [LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models](https://aclanthology.org/2025.acl-long.78/) |  | 0 | Large Language Models for code often entail significant computational complexity, which grows significantly with the length of the input code sequence. We propose LeanCode for code simplification to reduce training and prediction time, leveraging code contexts in utilizing attention scores to... | Yan Wang, Ling Ding, Tien N. Nguyen, Shaohua Wang, Yanan Zheng |  |
| 1567 |  |  [MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset](https://aclanthology.org/2025.acl-long.79/) |  | 0 | To enable Large Language Models (LLMs) to function as conscious agents with generalizable reasoning capabilities, it is crucial that they possess the ability to \*\*\*comprehend situational changes (transitions) in distribution\*\*\* triggered by environmental factors or actions from other agents.... | Weiqi Wang, Yangqiu Song |  |
| 1568 |  |  [Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions](https://aclanthology.org/2025.acl-long.80/) |  | 0 | The rise of large language models (LLMs) offers new opportunities for automatic error detection in education, particularly for math word problems (MWPs). While prior studies demonstrate the promise of LLMs as error detectors, they overlook the presence of multiple valid solutions for a single MWP.... | Hang Li, Tianlong Xu, Kaiqi Yang, Yucheng Chu, Yanling Chen, Yichi Song, Qingsong Wen, Hui Liu |  |
| 1569 |  |  [Real-time Factuality Assessment from Adversarial Feedback](https://aclanthology.org/2025.acl-long.81/) |  | 0 | We show that existing evaluations for assessing the factuality of news from conventional sources, such as claims on fact-checking websites, result in high accuracies over time for LLM-based detectors—even after their knowledge cutoffs. This suggests that recent popular false information from such... | Sanxing Chen, Yukun Huang, Bhuwan Dhingra |  |
| 1570 |  |  [Improve Vision Language Model Chain-of-thought Reasoning](https://aclanthology.org/2025.acl-long.82/) |  | 0 | Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial for improving interpretability and trustworthiness. However, current training recipes often relying on datasets dominated by short annotations with minimal rationales. In this work, we show that training VLM on short... | Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang |  |
| 1571 |  |  [On the Mutual Influence of Gender and Occupation in LLM Representations](https://aclanthology.org/2025.acl-long.83/) |  | 0 | We examine LLM representations of gender for first names in various occupational contexts to study how occupations and the gender perception of first names in LLMs influence each other mutually. We find that LLMs’ first-name gender representations correlate with real-world gender statistics... | Haozhe An, Connor Baumler, Abhilasha Sancheti, Rachel Rudinger |  |
| 1572 |  |  [Disentangling Memory and Reasoning Ability in Large Language Models](https://aclanthology.org/2025.acl-long.84/) |  | 0 | Large Language Models (LLMs) have demonstrated strong performance in handling complex tasks that require both extensive knowledge and reasoning abilities. However, the existing LLM inference pipeline operates as an opaque process without explicit separation between knowledge retrieval and reasoning... | Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang |  |
| 1573 |  |  [Open-World Attribute Mining for E-Commerce Products with Multimodal Self-Correction Instruction Tuning](https://aclanthology.org/2025.acl-long.85/) |  | 0 | In e-commerce, effective product Attribute Mining (AM) is essential for improving product features and aiding consumer decisions. However, current AM methods often focus on extracting attributes from unimodal text, underutilizing multimodal data. In this paper, we propose a novel framework called... | Jiaqi Li, Yanming Li, Xiaoli Shen, Chuanyi Zhang, Guilin Qi, Sheng Bi |  |
| 1574 |  |  [Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attributions Explainability](https://aclanthology.org/2025.acl-long.86/) |  | 0 | Deep neural network predictions are notoriously difficult to interpret. Feature attribution methods aim to explain these predictions by identifying the contribution of each input feature. Faithfulness, often evaluated using the area over the perturbation curve (AOPC), reflects feature attributions’... | Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maaløe, Maria Maistro |  |
| 1575 |  |  [Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling](https://aclanthology.org/2025.acl-long.87/) |  | 0 | Expressive zero-shot voice conversion (VC) is a critical and challenging task that aims to transform the source timbre into an arbitrary unseen speaker while preserving the original content and expressive qualities. Despite recent progress in zero-shot VC, there remains considerable potential for... | Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao |  |
| 1576 |  |  [LangSAMP: Language-Script Aware Multilingual Pretraining](https://aclanthology.org/2025.acl-long.88/) |  | 0 | Recent multilingual pretrained language models (mPLMs) often avoid using language embeddings – learnable vectors assigned to individual languages. However, this places a significant burden on token representations to encode all language-specific information, which may hinder language neutrality. To... | Yihong Liu, Haotian Ye, Chunlan Ma, Mingyang Wang, Hinrich Schütze |  |
| 1577 |  |  [RelationalCoder: Rethinking Complex Tables via Programmatic Relational Transformation](https://aclanthology.org/2025.acl-long.89/) |  | 0 | Semi-structured tables, with their varied layouts and formatting artifacts, remain a major obstacle for automated data processing and analytics. To address these challenges, we propose RelationalCoder, which uniformly converts semi-structured tables into relational data, enabling smooth integration... | Haoyu Dong, Yue Hu, Huailiang Peng, Yanan Cao |  |
| 1578 |  |  [Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study](https://aclanthology.org/2025.acl-long.90/) |  | 0 | In recent research, large language models (LLMs) have been increasingly used to investigate public opinions. This study investigates the algorithmic fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and nuanced opinions of human participants. Using open-ended survey data... | Bolei Ma, Berk Yoztyurk, AnnaCarolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Aßenmacher |  |
| 1579 |  |  [TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos](https://aclanthology.org/2025.acl-long.91/) |  | 0 | Videos are unique in their integration of temporal elements, including camera, scene, action, and attribute, along with their dynamic relationships over time. However, existing benchmarks for video understanding often treat these properties separately or narrowly focus on specific aspects,... | Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian, Victoria W., Fuzheng Zhang |  |
| 1580 |  |  [Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs](https://aclanthology.org/2025.acl-long.92/) |  | 0 | Improving prompt quality is crucial for enhancing the performance of large language models (LLMs), particularly for Black-Box models like GPT4. Existing prompt refinement methods, while effective, often suffer from semantic inconsistencies between refined and original prompts, and fail to maintain... | Zhuo Li, Yuhao Du, Jinpeng Hu, Xiang Wan, Anningzhe Gao |  |
| 1581 |  |  [Binary Classifier Optimization for Large Language Model Alignment](https://aclanthology.org/2025.acl-long.93/) |  | 0 | In real-world services such as ChatGPT, aligning models based on user feedback is crucial for improving model performance. However, due to the simplicity and convenience of providing feedback, users typically offer only basic binary signals, such as ‘thumbs-up’ or ‘thumbs-down’. Most existing... | Seungjae Jung, Gunsoo Han, Daniel Wontae Nam, KyoungWoon On |  |
| 1582 |  |  [UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization](https://aclanthology.org/2025.acl-long.94/) |  | 0 | This paper introduces UnSeenTimeQA, a novel data contamination-free time-sensitive question-answering (TSQA) benchmark. It differs from existing TSQA benchmarks by avoiding web-searchable queries grounded in the real world. We present a series of time-sensitive event scenarios based on... | Md Nayem Uddin, Amir Saeidi, Divij Handa, Agastya Seth, Tran Cao Son, Eduardo Blanco, Steven R. Corman, Chitta Baral |  |
| 1583 |  |  [From Information to Insight: Leveraging LLMs for Open Aspect-Based Educational Summarization](https://aclanthology.org/2025.acl-long.95/) |  | 0 | This paper addresses the challenge of aspect-based summarization in education by introducing Reflective ASPect-based summarization (ReflectASP), a novel dataset that summarizes student reflections on STEM lectures. Despite the promising performance of large language models in general summarization,... | Yang Zhong, Diane J. Litman |  |
| 1584 |  |  [AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset](https://aclanthology.org/2025.acl-long.96/) |  | 0 | Recent advancements in large language model (LLM) performance on medical multiplechoice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-andmiddle-income countries (LMICs) facing acute physician shortages and lack of... | Charles Nimo, Tobi Olatunji, Abraham Toluwase Owodunni, Tassallah Abdullahi, Emmanuel Ayodele, Mardhiyah Sanni, Ezinwanne C. Aka, Folafunmi Omofoye, Foutse Yuehgoh, Timothy Faniran, Bonaventure F. P. Dossou, Moshood O. Yekini, Jonas Kemp, Katherine A. Heller, Jude Chidubem Omeke, Chidi Asuzu MD, Naome A. Etori, Aimérou Ndiaye, Ifeoma Okoh, Evans Doe Ocansey, Wendy Kinara, Michael L. Best, Irfan Essa, Stephen Edward Moore, Chris Fourie, Mercy Nyamewaa Asiedu |  |
| 1585 |  |  [Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level](https://aclanthology.org/2025.acl-long.97/) |  | 0 | Large language models (LLMs) have demonstrated immense utility across various industries. However, as LLMs advance, the risk of harmful outputs increases due to incorrect or malicious prompts. While current methods effectively address jailbreak risks, they share common limitations: 1) Judging... | Xinyi Zeng, Yuying Shang, Jiawei Chen, Jingyuan Zhang, Yu Tian |  |
| 1586 |  |  [In-the-wild Audio Spatialization with Flexible Text-guided Localization](https://aclanthology.org/2025.acl-long.98/) |  | 0 | Binaural audio enriches immersive experiences by enabling the perception of the spatial locations of sounding objects in AR, VR, and embodied AI applications. While existing audio spatialization methods can generally map any available monaural audio to binaural audio signals, they often lack the... | Tianrui Pan, Jie Liu, Zewen Huang, Jie Tang, Gangshan Wu |  |
| 1587 |  |  [L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models](https://aclanthology.org/2025.acl-long.99/) |  | 0 | Due to the high memory and computational costs associated with large language models (LLMs), model compression techniques such as quantization, which reduces inference costs, and parameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaptation (LoRA), which reduce training costs, have gained... | Hyesung Jeon, Yulhwa Kim, JaeJoon Kim |  |
| 1588 |  |  [Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion](https://aclanthology.org/2025.acl-long.100/) |  | 0 | This paper addresses the critical need for democratizing large language models (LLM) in the Arab world, a region that has seen slower progress in developing models comparable to state-of-the-art offerings like GPT-4 or GPT-3.5, due to a predominant focus on mainstream languages (e.g., English and... | Jianqing Zhu, Huang Huang, Zhihang Lin, Juhao Liang, Zhengyang Tang, Khalid Almubarak, Mosen Alharthi, Bang An, Juncai He, Xiangbo Wu, Fei Yu, Junying Chen, Zhuoheng Ma, Yuhao Du, He Zhang, Saied Alshahrani, Emad A. Alghamdi, Lian Zhang, Ruoyu Sun, Haizhou Li, Benyou Wang, Jinchao Xu |  |
| 1589 |  |  [What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs](https://aclanthology.org/2025.acl-long.101/) |  | 0 | We investigate long-context vulnerabilities in Large Language Models (LLMs) through Many-Shot Jailbreaking (MSJ). Our experiments utilize context length of up to 128K tokens. Through comprehensive analysis with various many-shot attack settings with different instruction styles, shot density,... | Sangyeop Kim, Yohan Lee, Yongwoo Song, Kimin Lee |  |
| 1590 |  |  [ECERC: Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation](https://aclanthology.org/2025.acl-long.102/) |  | 0 | Multi-modal Emotion Recognition in Conversation (MMERC) aims to identify speakers’ emotional states using multi-modal conversational data, significant for various domains. MMERC requires addressing emotional causes: contextual factors that influence emotions, alongside emotional evidence directly... | Tao Zhang, Zhenhua Tan |  |
| 1591 |  |  [CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System](https://aclanthology.org/2025.acl-long.103/) |  | 0 | With open-source projects growing in size and complexity, manual compilation becomes tedious and error-prone, highlighting the need for automation to improve efficiency and accuracy. However, the complexity of compilation instruction search and error resolution makes automatic compilation... | Li Hu, Guoqiang Chen, Xiuwei Shang, Shaoyin Cheng, Benlong Wu, LiGangyang LiGangyang, Xu Zhu, Weiming Zhang, Nenghai Yu |  |
| 1592 |  |  [Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals' Subjective Text Perceptions](https://aclanthology.org/2025.acl-long.104/) |  | 0 | People naturally vary in their annotations for subjective questions and some of this variation is thought to be due to the person’s sociodemographic characteristics. LLMs have also been used to label data, but recent work has shown that models perform poorly when prompted with sociodemographic... | Matthias Orlikowski, Jiaxin Pei, Paul Röttger, Philipp Cimiano, David Jurgens, Dirk Hovy |  |
| 1593 |  |  [Exploring Forgetting in Large Language Model Pre-Training](https://aclanthology.org/2025.acl-long.105/) |  | 0 | Catastrophic forgetting remains a formidable obstacle to building an omniscient model in large language models (LLMs). Despite the pioneering research on task-level forgetting in LLM fine-tuning, there is scant focus on forgetting during pre-training. We systematically explored the existence and... | Chonghua Liao, Ruobing Xie, Xingwu Sun, Haowen Sun, Zhanhui Kang |  |
| 1594 |  |  [Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks](https://aclanthology.org/2025.acl-long.106/) |  | 0 | Large language models (LLMs) inherit biases from their training data and alignment processes, influencing their responses in subtle ways. While many studies have examined these biases, little work has explored their robustness during interactions. In this paper, we introduce a novel approach where... | Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis |  |
| 1595 |  |  [AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents](https://aclanthology.org/2025.acl-long.107/) |  | 0 | Autonomous agents have become increasingly important for interacting with the real world. Android agents, in particular, have been a frequently-mentioned interaction method. However, existing studies for training and evaluating Android agents lack systematic research on both open-source and... | Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, Yuxiao Dong |  |
| 1596 |  |  [Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment](https://aclanthology.org/2025.acl-long.108/) |  | 0 | Multilingual sentence encoders (MSEs) are commonly obtained by training multilingual language models to map sentences from different languages into a shared semantic space. As such, they are subject to curse of multilinguality, a loss of monolingual representational accuracy due to parameter... | Yongxin Huang, Kexin Wang, Goran Glavas, Iryna Gurevych |  |
| 1597 |  |  [Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs](https://aclanthology.org/2025.acl-long.109/) |  | 0 | Multimodal Sentiment Analysis (MSA) is a rapidly developing field that integrates multimodal information to recognize sentiments, and existing models have made significant progress in this area. The central challenge in MSA is multimodal fusion, which is predominantly addressed by Multimodal... | Yijie Jin, Junjie Peng, Xuanchao Lin, Haochen Yuan, Lan Wang, Cangzhi Zheng |  |
| 1598 |  |  [Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking](https://aclanthology.org/2025.acl-long.110/) |  | 0 | Large language models (LLMs) have demonstrated exceptional performance in text generation within current NLP research. However, the lack of factual accuracy is still a dark cloud hanging over the LLM skyscraper. Structural knowledge prompting (SKP) is a prominent paradigm to integrate external... | Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Shaokai Chen, Mengshu Sun, Binbin Hu, Zhiqiang Zhang, Lei Liang, Wen Zhang, Huajun Chen |  |
| 1599 |  |  [LLäMmlein: Transparent, Compact and Competitive German-Only Language Models from Scratch](https://aclanthology.org/2025.acl-long.111/) |  | 0 | We transparently create two German-only decoder models, LLäMmlein 120M and 1B, from scratch and publish them, along with the training data, for the (German) NLP research community to use. The model training involved several key steps, including data preprocessing/filtering, the creation of a German... | Jan Pfister, Julia Wunderle, Andreas Hotho |  |
| 1600 |  |  [Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues](https://aclanthology.org/2025.acl-long.112/) |  | 0 | Nonverbal communication is integral to human interaction, with gestures, facial expressions, and body language conveying critical aspects of intent and emotion. However, existing large language models (LLMs) fail to effectively incorporate these nonverbal elements, limiting their capacity to create... | Youngmin Kim, Jiwan Chung, Jisoo Kim, Sunghyun Lee, Sangkyu Lee, Junhyeok Kim, Cheoljong Yang, Youngjae Yu |  |
| 1601 |  |  [How Much Do Encoder Models Know About Word Senses?](https://aclanthology.org/2025.acl-long.113/) |  | 0 | Word Sense Disambiguation (WSD) is a key task in Natural Language Processing (NLP), involving selecting the correct meaning of a word based on its context. With Pretrained Language Models (PLMs) like BERT and DeBERTa now well established, significant progress has been made in understanding... | Simone Teglia, Simone Tedeschi, Roberto Navigli |  |
| 1602 |  |  [When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations](https://aclanthology.org/2025.acl-long.114/) |  | 0 | Large Language Models (LLMs) are known to be vulnerable to backdoor attacks, where triggers embedded in poisoned samples can maliciously alter LLMs’ behaviors. In this paper, we move beyond attacking LLMs and instead examine backdoor attacks through the novel lens of natural language explanations.... | Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang |  |
| 1603 |  |  [HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter](https://aclanthology.org/2025.acl-long.115/) |  | 0 | To address the global challenge of online hate speech, prior research has developed detection models to flag such content on social media. However, due to systematic biases in evaluation datasets, the real-world effectiveness of these models remains unclear, particularly across geographies. We... | Manuel Tonneau, Diyi Liu, Niyati Malhotra, Scott A. Hale, Samuel Fraiberger, Víctor OrozcoOlvera, Paul Röttger |  |
| 1604 |  |  [LegalAgentBench: Evaluating LLM Agents in Legal Domain](https://aclanthology.org/2025.acl-long.116/) |  | 0 | With the increasing intelligence and autonomy of LLM Agents, their potential applications in the legal domain are becoming increasingly apparent. However, existing general-domain benchmarks are unable to fully capture the complexity and subtle nuances inherent in real-world judicial cognition and... | Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Wei Jia, Youfeng Liu, Kai Lin, Yueyue Wu, Guozhi Yuan, Yiran Hu, Wuyue Wang, Yiqun Liu, Minlie Huang |  |
| 1605 |  |  [Inference Compute-Optimal Video Vision Language Models](https://aclanthology.org/2025.acl-long.117/) |  | 0 | This work investigates the optimal allocation of inference compute across three key scaling factors in video vision language models: language model size, frame count, and the number of visual tokens per frame. While prior works typically focuses on optimizing model efficiency or improving... | Peiqi Wang, ShengYun Peng, Xuewen Zhang, Hanchao Yu, Yibo Yang, Lifu Huang, Fujun Liu, Qifan Wang |  |
| 1606 |  |  [Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models](https://aclanthology.org/2025.acl-long.118/) |  | 0 | Aligned representations across languages is a desired property in multilingual large language models (mLLMs), as alignment can improve performance in cross-lingual tasks. Typically alignment requires fine-tuning a model, which is computationally expensive, and sizable language data, which often may... | Anirudh Sundar, Sinead Williamson, Katherine Metcalf, BarryJohn Theobald, Skyler Seto, Masha Fedzechkina |  |
| 1607 |  |  [Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits](https://aclanthology.org/2025.acl-long.119/) |  | 0 | Search engines play a crucial role as digital gatekeepers, shaping the visibility of Web and social media content through algorithmic curation. This study investigates how search engines like Google selectively promotes or suppresses certain hashtags and subreddits, impacting the information users... | Amrit Poudel, Yifan Ding, Tim Weninger, Jürgen Pfeffer |  |
| 1608 |  |  [Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse](https://aclanthology.org/2025.acl-long.120/) |  | 0 | The surge in online content has created an urgent demand for robust detection systems, especially in non-English contexts where current tools demonstrate significant limitations. We introduce forePLay, a novel Polish-language dataset for erotic content detection, comprising over 24,000 annotated... | Anna Kolos, Katarzyna Lorenc, Emilia Wisnios, Agnieszka Karlinska |  |
| 1609 |  |  [Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales](https://aclanthology.org/2025.acl-long.121/) |  | 0 | Human-like personality traits have recently been discovered in large language models, raising the hypothesis that their (known and as yet undiscovered) biases conform with human latent psychological constructs. While large conversational models may be tricked into answering psychometric... | Maor Reuben, Ortal Slobodin, IdanChaim Cohen, Aviad Elyashar, Orna BraunLewensohn, Odeya Cohen, Rami Puzis |  |
| 1610 |  |  [Did Translation Models Get More Robust Without Anyone Even Noticing?](https://aclanthology.org/2025.acl-long.122/) |  | 0 | Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to “noisy” inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent... | Ben Peters, André F. T. Martins |  |
| 1611 |  |  [Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset](https://aclanthology.org/2025.acl-long.123/) |  | 0 | Recent English Common Crawl datasets like FineWeb-Edu and DCLM achieved significant benchmark gains via aggressive model-based filtering, but at the cost of removing 90% of data. This limits their suitability for long token horizon training, such as 15T tokens for Llama 3.1. In this paper, we show... | Dan Su, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro |  |
| 1612 |  |  [Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings](https://aclanthology.org/2025.acl-long.124/) |  | 0 | Contextual large language model embeddings are increasingly utilized for topic modeling and clustering. However, current methods often scale poorly, rely on opaque similarity metrics, and struggle in multilingual settings. In this work, we present a novel, scalable, interpretable, hierarchical, and... | Hans William Alexander Hanley, Zakir Durumeric |  |
| 1613 |  |  [Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models](https://aclanthology.org/2025.acl-long.125/) |  | 0 | The generation of toxic content by large language models (LLMs) remains a critical challenge for the safe deployment of language technology. We propose a novel framework for implicit knowledge editing and controlled text generation by fine-tuning LLMs with a prototype-based contrastive perplexity... | Tassilo Klein, Moin Nabi |  |
| 1614 |  |  [INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent](https://aclanthology.org/2025.acl-long.126/) |  | 0 | Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and... | Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K. P. Subbalakshmi, Jimin Huang, Lingfei Qian, Xueqing Peng, Jordan W. Suchow, Qianqian Xie |  |
| 1615 |  |  [Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference](https://aclanthology.org/2025.acl-long.127/) |  | 0 | Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models. Despite being the workhorse of numerous production pipelines, there have been limited Pareto improvements to BERT since its... | Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Griffin Thomas Adams, Jeremy Howard, Iacopo Poli |  |
| 1616 |  |  [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://aclanthology.org/2025.acl-long.128/) |  | 0 | We present a comprehensive evaluation of gender fairness in large language models (LLMs), focusing on their ability to handle both binary and non-binary genders. While previous studies primarily focus on binary gender distinctions, we introduce the Gender Inclusivity Fairness Index (GIFI), a novel... | Zhengyang Shan, Emily Diana, Jiawei Zhou |  |
| 1617 |  |  [D.Va: Validate Your Demonstration First Before You Use It](https://aclanthology.org/2025.acl-long.129/) |  | 0 | In-context learning (ICL) has demonstrated significant potential in enhancing the capabilities of large language models (LLMs) during inference. It’s well-established that ICL heavily relies on selecting effective demonstrations to achieve outputs that better align with the expected results. As for... | Qi Zhang, Zhiqing Xiao, Ruixuan Xiao, Lirong Gao, Junbo Zhao |  |
| 1618 |  |  [Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?](https://aclanthology.org/2025.acl-long.130/) |  | 0 | Any-to-any generative models aim to enable seamless interpretation and generation across multiple modalities within a unified framework, yet their ability to preserve relationships across modalities remains uncertain. Do unified models truly achieve cross-modal coherence, or is this coherence... | Jiwan Chung, Janghan Yoon, Junhyeong Park, Sangeyl Lee, Joowon Yang, Sooyeon Park, Youngjae Yu |  |
| 1619 |  |  [MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.131/) |  | 0 | Large Language Models (LLMs) are becoming essential tools for various natural language processing tasks but often suffer from generating outdated or incorrect information. Retrieval-Augmented Generation (RAG) addresses this issue by incorporating external, real-time information retrieval to ground... | ChiaYuan Chang, Zhimeng Jiang, Vineeth Rakesh, Menghai Pan, ChinChia Michael Yeh, Guanchu Wang, Mingzhi Hu, Zhichao Xu, Yan Zheng, Mahashweta Das, Na Zou |  |
| 1620 |  |  [Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning](https://aclanthology.org/2025.acl-long.132/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities from few-shot demonstration exemplars. Recent learning-based demonstration selection methods have proven beneficial to ICL by choosing more useful exemplars. While these methods generally assume they... | Hui Liu, Wenya Wang, Hao Sun, Chris Xing Tian, Chenqi Kong, Xin Dong, Haoliang Li |  |
| 1621 |  |  [Direct Prompt Optimization with Continuous Representations](https://aclanthology.org/2025.acl-long.133/) |  | 0 | Prompt optimization for language models faces challenges due to the large discrete search space, the reliance on continuous gradient updates, and the need to round continuous representations into discrete prompts, which causes inflexibility and instability. Existing methods attempt to address these... | Yangkun Wang, Zihan Wang, Jingbo Shang |  |
| 1622 |  |  [uMedSum: A Unified Framework for Clinical Abstractive Summarization](https://aclanthology.org/2025.acl-long.134/) |  | 0 | Clinical abstractive summarization struggles to balance faithfulness and informativeness, sacrificing key information or introducing confabulations. Techniques like in-context learning and fine-tuning have improved overall summary quality orthogonally, without considering the above issue.... | Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, ArunKumar KaliyaPerumal, Guna Pratheep Kalanchiam, Yili Tang, Robby T. Tan |  |
| 1623 |  |  [GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement](https://aclanthology.org/2025.acl-long.135/) |  | 0 | The evolution of speech technology has been spurred by the rapid increase in dataset sizes. Traditional speech models generally depend on a large amount of labeled training data, which is scarce for low-resource languages. This paper presents GigaSpeech 2, a large-scale, multi-domain, multilingual... | Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, WeiQiang Zhang, Guoguo Chen, Xie Chen |  |
| 1624 |  |  [Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents](https://aclanthology.org/2025.acl-long.136/) |  | 0 | User sentiment on social media reveals underlying social trends, crises, and needs. Researchers have analyzed users’ past messages to track the evolution of sentiments and reconstruct sentiment dynamics. However, predicting the imminent sentiment response of users to ongoing events remains... | Fanhang Man, Huandong Wang, Jianjie Fang, Zhaoyi Deng, Baining Zhao, Xinlei Chen, Yong Li |  |
| 1625 |  |  [TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data](https://aclanthology.org/2025.acl-long.137/) |  | 0 | Semantic parsing, which converts natural language queries into logic forms, plays a crucial role in reasoning within structured environments. However, existing methods encounter two significant challenges: reliance on extensive manually annotated datasets and limited generalization capability to... | Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu |  |
| 1626 |  |  [AndroidGen: Building an Android Language Agent under Data Scarcity](https://aclanthology.org/2025.acl-long.138/) |  | 0 | Large language models have opened up a world of possibilities for various NLP tasks, sparking optimism for the future. Despite their potential, LLMs have yet to be widely used as agents on real mobile devices. The main challenge is the need for high-quality data sources. Time constraints and labor... | Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Jie Tang |  |
| 1627 |  |  [Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation](https://aclanthology.org/2025.acl-long.139/) |  | 0 | Recently, Large Language Models (LLMs) have demonstrated significant potential for data annotation, markedly reducing the labor costs associated with downstream applications. However, existing methods mostly adopt an aggressive strategy by prompting LLM to determine a single gold label for each... | Mingxuan Xia, Haobo Wang, Yixuan Li, Zewei Yu, Jindong Wang, Junbo Zhao, Runze Wu |  |
| 1628 |  |  [A Survey of Post-Training Scaling in Large Language Models](https://aclanthology.org/2025.acl-long.140/) |  | 0 | Large language models (LLMs) have achieved remarkable proficiency in understanding and generating human natural languages, mainly owing to the “scaling law” that optimizes relationships among language modeling loss, model parameters, and pre-trained tokens. However, with the exhaustion of... | Hanyu Lai, Xiao Liu, Junjie Gao, Jiale Cheng, Zehan Qi, Yifan Xu, Shuntian Yao, Dan Zhang, Jinhua Du, Zhenyu Hou, Xin Lv, Minlie Huang, Yuxiao Dong, Jie Tang |  |
| 1629 |  |  [Position-aware Automatic Circuit Discovery](https://aclanthology.org/2025.acl-long.141/) |  | 0 | A widely used strategy to discover and understand language model mechanisms is circuit analysis. A circuit is a minimal subgraph of a model’s computation graph that executes a specific task. We identify a gap in existing circuit discovery methods: they assume circuits are position-invariant,... | Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov |  |
| 1630 |  |  [HyperFM: Fact-Centric Multimodal Fusion for Link Prediction over Hyper-Relational Knowledge Graphs](https://aclanthology.org/2025.acl-long.142/) |  | 0 | With the ubiquity of hyper-relational facts in modern Knowledge Graphs (KGs), existing link prediction techniques mostly focus on learning the sophisticated relationships among multiple entities and relations contained in a fact, while ignoring the multimodal information, which often provides... | Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang |  |
| 1631 |  |  [Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model](https://aclanthology.org/2025.acl-long.143/) |  | 0 | Most Large Vision-Language Models (LVLMs) to date are trained predominantly on English data, which makes them struggle to understand non-English input and fail to generate output in the desired target language. Existing efforts mitigate these issues by adding multilingual training data, but do so... | Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran Glavas |  |
| 1632 |  |  [Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation](https://aclanthology.org/2025.acl-long.144/) |  | 0 | Scientific language models drive research innovation but require extensive fine-tuning on large datasets. This work enhances such models by improving their inference and evaluation capabilities with minimal or no additional training. Focusing on molecule caption generation, we explore post-training... | Dimitris Gkoumas, Maria Liakata |  |
| 1633 |  |  [Ensemble Watermarks for Large Language Models](https://aclanthology.org/2025.acl-long.145/) |  | 0 | As large language models (LLMs) reach human-like fluency, reliably distinguishing AI-generated text from human authorship becomes increasingly difficult. While watermarks already exist for LLMs, they often lack flexibility and struggle with attacks such as paraphrasing. To address these issues, we... | Georg Niess, Roman Kern |  |
| 1634 |  |  [\mathsfCon Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities](https://aclanthology.org/2025.acl-long.146/) |  | 0 | Existing attacks against multimodal language models often communicate instruction through text, either as an explicit malicious instruction or a crafted generic prompt, and accompanied by a toxic image. In contrast, here we exploit the capabilities of MLLMs in following non-textual instruction,... | Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych |  |
| 1635 |  |  [TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge](https://aclanthology.org/2025.acl-long.147/) |  | 0 | The LLM-as-a-judge paradigm uses large language models (LLMs) for automated text evaluation, assigning a score to the input based on scoring rubrics. Existing methods for fine-tuning LLM-as-a-judge use cross-entropy (CE) loss, which neglects the numeric nature of score prediction. Recent work... | ChengHan Chiang, Hungyi Lee, Michal Lukasik |  |
| 1636 |  |  [DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.148/) |  | 0 | Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval... | Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu |  |
| 1637 |  |  [Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation](https://aclanthology.org/2025.acl-long.149/) |  | 0 | Maximum a posteriori decoding, a commonly used method for neural machine translation (NMT), aims to maximize the estimated posterior probability. However, high estimated probability does not always lead to high translation quality. Minimum Bayes Risk (MBR) decoding offers an alternative by seeking... | Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura |  |
| 1638 |  |  [ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use](https://aclanthology.org/2025.acl-long.150/) |  | 0 | Effective evaluation of multi-hop tool use is critical for analyzing the understanding, reasoning, and function-calling capabilities of large language models (LLMs). However, progress has been hindered by a lack of reliable evaluation datasets. To address this, we present ToolHop, a dataset... | Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen |  |
| 1639 |  |  [Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment](https://aclanthology.org/2025.acl-long.151/) |  | 0 | As the capabilities of large language models (LLMs) continue to expand, aligning these models with human values remains a significant challenge. Recent studies show that reasoning abilities contribute significantly to model safety, while integrating Mixture-of-Experts (MoE) architectures can... | Zhili Liu, Yunhao Gou, Kai Chen, Lanqing Hong, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James T. Kwok |  |
| 1640 |  |  [MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment](https://aclanthology.org/2025.acl-long.152/) |  | 0 | Personalized product search aims to retrieve and rank items that match users’ preferences and search intent. Despite their effectiveness, existing approaches typically assume that users’ query fully captures their real motivation. However, our analysis of a real-world e-commerce platform reveals... | Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Ming He, Jianping Fan, Xiao Zhang, Jun Xu |  |
| 1641 |  |  [Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework](https://aclanthology.org/2025.acl-long.153/) |  | 0 | In the context of large language models (LLMs), current advanced reasoning methods have made impressive strides in various reasoning tasks. However, when it comes to logical reasoning tasks, significant challenges remain in both efficacy and efficiency. This is rooted in the fact that these systems... | Jundong Xu, Hao Fei, Meng Luo, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, MongLi Lee, Wynne Hsu |  |
| 1642 |  |  [LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs](https://aclanthology.org/2025.acl-long.154/) |  | 0 | Long-context modeling has drawn more and more attention in the area of Large Language Models (LLMs). Continual training with long-context data becomes the de-facto method to equip LLMs with the ability to process long inputs. However, it still remains an open challenge to measure the quality of... | Jianghao Chen, Junhong Wu, Yangyifan Xu, Jiajun Zhang |  |
| 1643 |  |  [Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training](https://aclanthology.org/2025.acl-long.155/) |  | 0 | Machine-generated Text (MGT) detection is crucial for regulating and attributing online texts. While the existing MGT detectors achieve strong performance, they remain vulnerable to simple perturbations and adversarial attacks. To build an effective defense against malicious perturbations, we view... | Yuanfan Li, Zhaohan Zhang, Chengzhengxu Li, Chao Shen, Xiaoming Liu |  |
| 1644 |  |  [Cultural Learning-Based Culture Adaptation of Language Models](https://aclanthology.org/2025.acl-long.156/) |  | 0 | Adapting large language models (LLMs) to diverse cultural values is a challenging task, as existing LLMs often reflect the values of specific groups by default, and potentially cause harm to others. In this paper, we present CLCA, a novel framework for enhancing LLM alignment with cultural values... | Chen Cecilia Liu, Anna Korhonen, Iryna Gurevych |  |
| 1645 |  |  [A-TASC: Asian TED-Based Automatic Subtitling Corpus](https://aclanthology.org/2025.acl-long.157/) |  | 0 | Subtitles play a crucial role in improving the accessibility of the vast amount of audiovisual content available on the Internet, allowing audiences worldwide to comprehend and engage with this content in various languages. Automatic subtitling (AS) systems are essential for alleviating the... | Yuhan Zhou, Naoki Yoshinaga |  |
| 1646 |  |  [Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training](https://aclanthology.org/2025.acl-long.158/) |  | 0 | This study addresses a critical gap in safety tuning practices for Large Language Models (LLMs) by identifying and tackling a refusal position bias within safety tuning data, which compromises the models’ ability to appropriately refuse generating unsafe content. We introduce a novel approach,... | Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jentse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu |  |
| 1647 |  |  [Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs](https://aclanthology.org/2025.acl-long.159/) |  | 0 | Extracting sentence embeddings from large language models (LLMs) is a promising direction, as LLMs have demonstrated stronger semantic understanding capabilities. Previous studies typically focus on prompt engineering to elicit sentence embeddings from LLMs by prompting the model to encode sentence... | Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu |  |
| 1648 |  |  [No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions](https://aclanthology.org/2025.acl-long.160/) |  | 0 | Questions help unlock information to satisfy users’ information needs. However, when the question is poorly posed, answerers (whether human or computer) may struggle to answer the question in a way that satisfies the asker, despite possibly knowing everything necessary to address the asker’s latent... | Neha Srikanth, Rachel Rudinger, Jordan Lee BoydGraber |  |
| 1649 |  |  [Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs](https://aclanthology.org/2025.acl-long.161/) |  | 0 | While it is commonly accepted that maintaining common ground plays a role in conversational success, little prior research exists connecting conversational grounding to success in task-oriented conversations. We study failures of grounding in the Ubuntu IRC dataset, where participants use text-only... | Rupak Sarkar, Neha Srikanth, Taylor Pellegrin, Rachel Rudinger, Claire Bonial, Philip Resnik |  |
| 1650 |  |  [Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models](https://aclanthology.org/2025.acl-long.162/) |  | 0 | Evaluating Video Language Models (VLMs) is a challenging task. Due to its transparency, Multiple-Choice Question Answering (MCQA) is widely used to measure the performance of these models through accuracy. However, existing MCQA benchmarks fail to capture the full reasoning capabilities of VLMs due... | Olga Loginova, Oleksandr Bezrukov, Ravi Shekhar, Alexey Kravets |  |
| 1651 |  |  [Towards Reward Fairness in RLHF: From a Resource Allocation Perspective](https://aclanthology.org/2025.acl-long.163/) |  | 0 | Rewards serve as proxies for human preferences and play a crucial role in Reinforcement Learning from Human Feedback (RLHF). However, if these rewards are inherently imperfect, exhibiting various biases, they can adversely affect the alignment of large language models (LLMs). In this paper, we... | Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu |  |
| 1652 |  |  [Taming LLMs with Gradient Grouping](https://aclanthology.org/2025.acl-long.164/) |  | 0 | Training large language models (LLMs) poses challenges due to their massive scale and heterogeneous architectures. While adaptive optimizers like AdamW help address gradient variations, they still struggle with efficient and effective parameter-wise learning rate estimation, resulting in training... | Siyuan Li, Juanxi Tian, Zedong Wang, Xin Jin, Zicheng Liu, Wentao Zhang, Dan Xu |  |
| 1653 |  |  [LazyReview: A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews](https://aclanthology.org/2025.acl-long.165/) |  | 0 | Peer review is a cornerstone of quality control in scientific publishing. With the increasing workload, the unintended use of ‘quick’ heuristics, referred to as lazy thinking, has emerged as a recurring issue compromising review quality. Automated methods to detect such heuristics can help improve... | Sukannya Purkayastha, Zhuang Li, Anne Lauscher, Lizhen Qu, Iryna Gurevych |  |
| 1654 |  |  [Revisiting Common Assumptions about Arabic Dialects in NLP](https://aclanthology.org/2025.acl-long.166/) |  | 0 | Arabic has diverse dialects, where one dialect can be substantially different from the others. In the NLP literature, some assumptions about these dialects are widely adopted (e.g., “Arabic dialects can be grouped into distinguishable regional dialects”) and are manifested in different... | Amr Keleg, Sharon Goldwater, Walid Magdy |  |
| 1655 |  |  [Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification](https://aclanthology.org/2025.acl-long.167/) |  | 0 | Language models hold incredible promise for enabling scientific discovery by synthesizing massive research corpora. Many complex scientific research questions have multiple plausible answers, each supported by evidence of varying strength. However, existing language models lack the capability to... | Ravi Patel, Angus Brayne, Rogier Hintzen, Daniel Jaroslawicz, Georgiana Neculae, Dane S. Corneil |  |
| 1656 |  |  [Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas](https://aclanthology.org/2025.acl-long.168/) |  | 0 | LLMs are aligned to follow input instructions by learning which of two responses users prefer for a prompt. However, such preference data do not convey \*why\* users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To... | Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee BoydGraber |  |
| 1657 |  |  [Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above](https://aclanthology.org/2025.acl-long.169/) |  | 0 | Multiple choice question answering (MCQA) is popular for LLM evaluation due to its simplicity and human-like testing, but we argue for its reform. We first reveal flaws in MCQA’s format, as it struggles to: 1) test generation/subjectivity; 2) match LLM use cases; and 3) fully test knowledge. We... | Nishant Balepur, Rachel Rudinger, Jordan Lee BoydGraber |  |
| 1658 |  |  [Detection of Human and Machine-Authored Fake News in Urdu](https://aclanthology.org/2025.acl-long.170/) |  | 0 | The rise of social media has amplified the spread of fake news, now further complicated by large language models (LLMs) like ChatGPT, which ease the generation of highly convincing, error-free misinformation, making it increasingly challenging for the public to discern truth from falsehood.... | Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony C. Smith |  |
| 1659 |  |  [An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals](https://aclanthology.org/2025.acl-long.171/) |  | 0 | Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue systems to optimize dialogue policy, but it struggles to balance exploration and exploitation due to the high dimensionality of state and action spaces. This challenge often results in local optima or poor convergence.... | Yangyang Zhao, Ben Niu, Libo Qin, Shihan Wang |  |
| 1660 |  |  [SR-LLM: Rethinking the Structured Representation in Large Language Model](https://aclanthology.org/2025.acl-long.172/) |  | 0 | Structured representations, exemplified by Abstract Meaning Representation (AMR), have long been pivotal in computational linguistics. However, their role remains ambiguous in the Large Language Models (LLMs) era. Initial attempts to integrate structured representation into LLMs via a zero-shot... | Jiahuan Zhang, Tianheng Wang, Ziyi Huang, Yulong Wu, Hanqing Wu, DongbaiChen DongbaiChen, Linfeng Song, Yue Zhang, Guozheng Rao, Kaicheng Yu |  |
| 1661 |  |  [Taming Language Models for Text-attributed Graph Learning with Decoupled Aggregation](https://aclanthology.org/2025.acl-long.173/) |  | 0 | Text-attributed graphs (TAGs) are prevalent in various real-world applications, including academic networks, e-commerce platforms, and social networks. Effective learning on TAGs requires leveraging both textual node features and structural graph information. While language models (LMs) excel at... | Chuang Zhou, Zhu Wang, Shengyuan Chen, Jiahe Du, Qiyuan Zheng, Zhaozhuo Xu, Xiao Huang |  |
| 1662 |  |  [Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering](https://aclanthology.org/2025.acl-long.174/) |  | 0 | Extracting sentence embeddings from large language models (LLMs) is a practical direction, as it requires neither additional data nor fine-tuning. Previous studies usually focus on prompt engineering to guide LLMs to encode the core semantic information of the sentence into the embedding of the... | Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu |  |
| 1663 |  |  [Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence](https://aclanthology.org/2025.acl-long.175/) |  | 0 | Large vision-language models (LVLMs) have made substantial progress in integrating large language models (LLMs) with visual inputs, enabling advanced multimodal reasoning. Despite their success, a persistent challenge is hallucination—where generated text fails to accurately reflect visual... | Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, TatSeng Chua, Jinqiao Wang |  |
| 1664 |  |  [Hierarchical Document Refinement for Long-context Retrieval-augmented Generation](https://aclanthology.org/2025.acl-long.176/) |  | 0 | Real-world RAG applications often encounter long-context input scenarios, where redundant information and noise results in higher inference costs and reduced performance. To address these challenges, we propose LongRefiner, an efficient plug-and-play refiner that leverages the inherent structural... | Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Ye Qi, Zhicheng Dou |  |
| 1665 |  |  [Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations](https://aclanthology.org/2025.acl-long.177/) |  | 0 | As the impact of large language models increases, understanding the moral values they encode becomes ever more important. Assessing moral values encoded in these models via direct prompting is challenging due to potential leakage of human norms into model training data, and their sensitivity to... | Chaoyi Xiang, Chunhua Liu, Simon De Deyne, Lea Frermann |  |
| 1666 |  |  [TEACH: A Contrastive Knowledge Adaptive Distillation Framework for Classical Chinese Understanding](https://aclanthology.org/2025.acl-long.178/) |  | 0 | Traditional methods for processing classical Chinese typically segment language understanding into discrete tasks, which overlook crucial background information and reduce user engagement. Large language models (LLMs) provide integrated solutions, yet they entail high computational costs and risks... | Yuting Wei, Qi Meng, Yuanxing Xu, Bin Wu |  |
| 1667 |  |  [RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.179/) |  | 0 | Retrieval-augmented generation (RAG) has emerged as a pivotal technology in natural language processing, owing to its efficacy in generating factual content. However, its informative inputs and complex paradigms often lead to a greater variety of errors. Consequently, achieving automated on-policy... | Guanting Dong, Jiajie Jin, Xiaoxi Li, Yutao Zhu, Zhicheng Dou, JiRong Wen |  |
| 1668 |  |  [Progressive Multimodal Reasoning via Active Retrieval](https://aclanthology.org/2025.acl-long.180/) |  | 0 | Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively... | Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, JiRong Wen |  |
| 1669 |  |  [Pre-training Distillation for Large Language Models: A Design Space Exploration](https://aclanthology.org/2025.acl-long.181/) |  | 0 | Knowledge distillation (KD) aims to transfer knowledge from a large teacher model to a smaller student model. Previous work applying KD in the field of large language models (LLMs) typically focused on the post-training phase, where the student LLM learns directly from instructions and... | Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li |  |
| 1670 |  |  [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://aclanthology.org/2025.acl-long.182/) |  | 0 | In visual question answering (VQA) context, users often pose ambiguous questions to visual language models (VLMs) due to varying expression habits. Existing research addresses such ambiguities primarily by rephrasing questions. These approaches neglect the inherently interactive nature of user... | Pu Jian, Donglei Yu, Wen Yang, Shuo Ren, Jiajun Zhang |  |
| 1671 |  |  [LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks](https://aclanthology.org/2025.acl-long.183/) |  | 0 | This paper introduces LongBench v2, a benchmark designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 consists of 503 challenging multiple-choice questions, with contexts ranging from 8k to 2M... | Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li |  |
| 1672 |  |  [Battling against Tough Resister: Strategy Planning with Adversarial Game for Non-collaborative Dialogues](https://aclanthology.org/2025.acl-long.184/) |  | 0 | Non-collaborative dialogue involves two participants with conflicting interests engaging in a multi-round dialogue to achieve their own goals. Strategy planning is the key to guiding both participants towards a consensus. Most LLMs-based methods use stimulus prompts or external strategy planners... | Haiyang Wang, Zhiliang Tian, Yuchen Pan, Xin Song, Xin Niu, Minlie Huang, Bin Zhou |  |
| 1673 |  |  [Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts](https://aclanthology.org/2025.acl-long.185/) |  | 0 | Understanding the inner workings of Large Language Models (LLMs) is a critical research frontier. Prior research has shown that a single LLM’s concept representations can be captured as steering vectors (SVs), enabling the control of LLM behavior (e.g., towards generating harmful content). Our work... | Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv |  |
| 1674 |  |  [FoldMoE: Efficient Long Sequence MoE Training via Attention-MoE Pipelining](https://aclanthology.org/2025.acl-long.186/) |  | 0 | Training LLMs with Mixture-of-Experts (MoE) architecture on long sequences poses significant challenges due to the all-to-all communication bottleneck of expert parallelism. While existing approaches attempt to hide the communication costs in computation through token-level pipelining within MoE... | Guichao Zhu, Lintian Lei, Yuhao Qing, Yichao Fu, Fanxin Li, Dong Huang, Zekai Sun, Heming Cui |  |
| 1675 |  |  [LongReward: Improving Long-context Large Language Models with AI Feedback](https://aclanthology.org/2025.acl-long.187/) |  | 0 | Though significant advancements have been achieved in developing long-context large language models (LLMs), the compromised quality of LLM-synthesized data for supervised fine-tuning (SFT) often affects the long-context performance of SFT models and leads to inherent limitations. In principle,... | Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li |  |
| 1676 |  |  [Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles](https://aclanthology.org/2025.acl-long.188/) |  | 0 | Calibration, the alignment between model confidence and prediction accuracy, is critical for the reliable deployment of large language models (LLMs). Existing works neglect to measure the generalization of their methods to other prompt styles and different sizes of LLMs. To address this, we define... | Yuxi Xia, Pedro Henrique Luz de Araujo, Klim Zaporojets, Benjamin Roth |  |
| 1677 |  |  [UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench](https://aclanthology.org/2025.acl-long.189/) |  | 0 | The advent of Large Language Models (LLMs) has spurred the development of coding agents for real-world code generation.As a widely used benchmark for evaluating the code generation capabilities of these agents, SWE-Bench uses real-world problems based on GitHub issues and their corresponding pull... | Boxi Yu, Yuxuan Zhu, Pinjia He, Daniel Kang |  |
| 1678 |  |  [Towards Better Evaluation for Generated Patent Claims](https://aclanthology.org/2025.acl-long.190/) |  | 0 | Patent claims define the scope of protection and establish the legal boundaries of an invention. Drafting these claims is a complex and time-consuming process that usually requires the expertise of skilled patent attorneys, which can form a large access barrier for many small enterprises. To solve... | Lekang Jiang, Pascal A. Scherz, Stefan Goetz |  |
| 1679 |  |  [Fine-Tuning on Diverse Reasoning Chains Drives Within-Inference CoT Refinement in LLMs](https://aclanthology.org/2025.acl-long.191/) |  | 0 | Requiring a large language model (LLM) to generate intermediary reasoning steps, known as Chain of Thought (CoT), has been shown to be an effective way of boosting performance. Previous approaches have focused on generating multiple independent CoTs, combining them through ensembling or other... | Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych |  |
| 1680 |  |  [Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis](https://aclanthology.org/2025.acl-long.192/) |  | 0 | The development of large language models (LLMs) depends on \*\*trustworthy evaluation\*\*. However, most current evaluations rely on public benchmarks, which are prone to data contamination issues that significantly compromise fairness. Previous researches have focused on constructing dynamic... | Kejian Zhu, Shangqing Tu, Zhuoran Jin, Lei Hou, Juanzi Li, Jun Zhao |  |
| 1681 |  |  [Do Large Language Models have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs](https://aclanthology.org/2025.acl-long.193/) |  | 0 | Current Large Language Models (LLMs) are predominantly designed with English as the primary language, and even the few that are multilingual tend to exhibit strong English-centric biases. Much like speakers who might produce awkward expressions when learning a second language, LLMs often generate... | Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao |  |
| 1682 |  |  [Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning](https://aclanthology.org/2025.acl-long.194/) |  | 0 | Tokenization methods like Byte-Pair Encoding (BPE) enhance computational efficiency in large language models (LLMs) but often obscure internal character structures within tokens. This limitation hinders LLMs’ ability to predict precise character positions, which is crucial in tasks like Chinese... | Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang, Jian He, Conglin Liu |  |
| 1683 |  |  [Conformity in Large Language Models](https://aclanthology.org/2025.acl-long.195/) |  | 0 | The conformity effect describes the tendency of individuals to align their responses with the majority. Studying this bias in large language models (LLMs) is crucial, as LLMs are increasingly used in various information-seeking and decision-making tasks as conversation partners to improve... | Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos |  |
| 1684 |  |  [Interpret and Improve In-Context Learning via the Lens of Input-Label Mappings](https://aclanthology.org/2025.acl-long.196/) |  | 0 | Large language models (LLMs) excel at downstream NLP tasks through in-context learning (ICL) with a few demonstrations of input–label pairs. However, the internal mechanisms behind ICL remain under-explored, particularly the mappings between inputs and labels. In this work, we reverse-engineer ICL... | Chenghao Sun, Zhen Huang, Yonggang Zhang, Le Lu, Houqiang Li, Xinmei Tian, Xu Shen, Jieping Ye |  |
| 1685 |  |  [Positional Overload: Positional Debiasing and Context Window Extension for Large Language Models using Set Encoding](https://aclanthology.org/2025.acl-long.197/) |  | 0 | Large Language Models (LLMs) typically track the order of tokens using positional encoding, which causes the following problems: positional bias, where the model is influenced by an ordering within the prompt, and a fixed context window, as models struggle to generalize to positions beyond those... | Lukas Kinder, Lukas Edman, Alexander Fraser, Tobias Käfer |  |
| 1686 |  |  [FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling](https://aclanthology.org/2025.acl-long.198/) |  | 0 | Speculative sampling has emerged as an important technique for accelerating the auto-regressive generation process of large language models (LLMs) by utilizing a draft-then-verify mechanism to produce multiple tokens per forward pass. While state-of-the-art speculative sampling methods use only a... | Weilin Zhao, Tengyu Pan, Xu Han, Yudi Zhang, Sun Ao, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jie Zhou, Hao Zhou, Jianyong Wang, Maosong Sun, Zhiyuan Liu |  |
| 1687 |  |  [VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism](https://aclanthology.org/2025.acl-long.199/) |  | 0 | Large Vision-Language Models (LVLMs) have shown exceptional performance in multimodal tasks, but their effectiveness in complex visual reasoning is still constrained, especially when employing Chain-of-Thought prompting techniques. In this paper, we propose VReST, a novel training-free approach... | Congzhi Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Haowen Sun, Heng Chang, Fei Ma, Weijiang Yu |  |
| 1688 |  |  [Past Meets Present: Creating Historical Analogy with Large Language Models](https://aclanthology.org/2025.acl-long.200/) |  | 0 | Historical analogies, which compare known past events with contemporary but unfamiliar events, are important abilities that help people make decisions and understand the world. However, research in applied history suggests that people have difficulty finding appropriate analogies. And previous... | Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao |  |
| 1689 |  |  [Meta-Reflection: A Feedback-Free Reflection Learning Framework](https://aclanthology.org/2025.acl-long.201/) |  | 0 | Despite the remarkable capabilities of large language models (LLMs) in natural language understanding and reasoning, they often display undesirable behaviors, such as generating hallucinations and unfaithful reasoning. A prevalent strategy to mitigate these issues is the use of reflection, which... | Yaoke Wang, Yun Zhu, XintongBao XintongBao, Wenqiao Zhang, Suyang Dai, Kehan Chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang |  |
| 1690 |  |  [Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books](https://aclanthology.org/2025.acl-long.202/) |  | 0 | While large language models (LLMs) have shown promise in translating extremely low-resource languages using resources like dictionaries, the effectiveness of grammar books remains debated. This paper investigates the role of grammar books in translating extremely low-resource languages by... | Chen Zhang, Jiuheng Lin, Xiao Liu, Zekai Zhang, Yansong Feng |  |
| 1691 |  |  [Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs](https://aclanthology.org/2025.acl-long.203/) |  | 0 | Large Language Models (LLMs) can correct their self-generated responses, but a decline in accuracy after self-correction is also witnessed. To have a deeper understanding of self-correction, we endeavor to decompose, evaluate, and analyze the self-correction behaviors of LLMs. By enumerating and... | Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui |  |
| 1692 |  |  [Automating Legal Interpretation with LLMs: Retrieval, Generation, and Evaluation](https://aclanthology.org/2025.acl-long.204/) |  | 0 | Interpreting the law is always essential for the law to adapt to the ever-changing society. It is a critical and challenging task even for legal practitioners, as it requires meticulous and professional annotations and summarizations by legal experts, which are admittedly time-consuming and... | Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng |  |
| 1693 |  |  [Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models](https://aclanthology.org/2025.acl-long.205/) |  | 0 | Large Vision-Language Models (LVLMs) have shown impressive progress by integrating visual perception with linguistic understanding to produce contextually grounded outputs. Despite these advancements achieved, LVLMs still suffer from the hallucination problem, e.g., they tend to produce content... | Wei Li, Zhen Huang, Houqiang Li, Le Lu, Yang Lu, Xinmei Tian, Xu Shen, Jieping Ye |  |
| 1694 |  |  [Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration](https://aclanthology.org/2025.acl-long.206/) |  | 0 | Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without... | Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen |  |
| 1695 |  |  [TokAlign: Efficient Vocabulary Adaptation via Token Alignment](https://aclanthology.org/2025.acl-long.207/) |  | 0 | Tokenization serves as a foundational step for Large Language Models (LLMs) to process text. In new domains or languages, the inefficiency of the tokenizer will slow down the training and generation of LLM. The mismatch in vocabulary also hinders deep knowledge transfer between LLMs like... | Chong Li, Jiajun Zhang, Chengqing Zong |  |
| 1696 |  |  [AdaEdit: Advancing Continuous Knowledge Editing For Large Language Models](https://aclanthology.org/2025.acl-long.208/) |  | 0 | Knowledge editing (KE) has emerged as a prominent alternative that enables efficient and precise information modification inside language models. However, a critical challenge arises in continuous language models editing — a significant performance decline both in knowledge update and retention... | Qi Li, Xiaowen Chu |  |
| 1697 |  |  [The Impact of Token Granularity on the Predictive Power of Language Model Surprisal](https://aclanthology.org/2025.acl-long.209/) |  | 0 | Word-by-word language model surprisal is often used to model the incremental processing of human readers, which raises questions about how various choices in language modeling influence its predictive power. One factor that has been overlooked in cognitive modeling is the granularity of subword... | ByungDoh Oh, William Schuler |  |
| 1698 |  |  [Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models](https://aclanthology.org/2025.acl-long.210/) |  | 0 | Diffusion models have shown promise in text generation, but often struggle with generating long, coherent, and contextually accurate text. Token-level diffusion doesn’t model word-order dependencies explicitly and operates on short, fixed output windows, while passage-level diffusion struggles with... | Xiaochen Zhu, Georgi Karadzhov, Chenxi Whitehouse, Andreas Vlachos |  |
| 1699 |  |  [BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering](https://aclanthology.org/2025.acl-long.211/) |  | 0 | Multi-hop question answering (QA) involves finding multiple relevant passages and performing step-by-step reasoning to answer complex questions. Previous works on multi-hop QA employ specific methods from different modeling perspectives based on large language models (LLMs), regardless of the... | Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He |  |
| 1700 |  |  [Dynamic and Generalizable Process Reward Modeling](https://aclanthology.org/2025.acl-long.212/) |  | 0 | Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense reward signals. However, existing PRMs primarily rely on heuristic approaches, which struggle with cross-domain generalization. While LLM-as-judge has been proposed to provide... | Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang |  |
| 1701 |  |  [AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness](https://aclanthology.org/2025.acl-long.213/) |  | 0 | The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static... | Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma |  |
| 1702 |  |  [Towards Text-Image Interleaved Retrieval](https://aclanthology.org/2025.acl-long.214/) |  | 0 | Current multimodal information retrieval studies mainly focus on single-image inputs, which limits real-world applications involving multiple images and text-image interleaved content. In this work, we introduce the text-image interleaved retrieval (TIIR) task, where the query and document are... | Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang |  |
| 1703 |  |  [Large Margin Representation Learning for Robust Cross-lingual Named Entity Recognition](https://aclanthology.org/2025.acl-long.215/) |  | 0 | Cross-lingual named entity recognition (NER) aims to build an NER model that generalizes to the low-resource target language with labeled data from the high-resource source language. Current state-of-the-art methods typically combine self-training mechanism with contrastive learning paradigm, in... | Guangcheng Zhu, Ruixuan Xiao, Haobo Wang, Zhen Zhu, Gengyu Lyu, Junbo Zhao |  |
| 1704 |  |  [An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning](https://aclanthology.org/2025.acl-long.216/) |  | 0 | Enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) is of great scientific and practical significance. Researchers typically employ process-supervised reward models (PRMs) to guide the reasoning process, effectively improving the models’ reasoning abilities. However,... | Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang |  |
| 1705 |  |  [QAEncoder: Towards Aligned Representation Learning in Question Answering Systems](https://aclanthology.org/2025.acl-long.217/) |  | 0 | Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents hinders precise matching. We introduce QAEncoder, a training-free approach to bridge this gap. Specifically, QAEncoder... | Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang |  |
| 1706 |  |  [Game Development as Human-LLM Interaction](https://aclanthology.org/2025.acl-long.218/) |  | 0 | Game development is a highly specialized task that relies on a complex game engine powered by complex programming languages, preventing many gaming enthusiasts from handling it. This paper introduces the Chat Game Engine (ChatGE) powered by LLM, which allows everyone to develop a custom game using... | Jiale Hong, Hongqiu Wu, Hai Zhao |  |
| 1707 |  |  [Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases](https://aclanthology.org/2025.acl-long.219/) |  | 0 | This study evaluates Large Language Models’ (LLMs) ability to simulate non-native-like English use observed in human second language (L2) learners interfered with by their native first language (L1). In dialogue-based interviews, we prompt LLMs to mimic L2 English learners with specific L1s (e.g.,... | Rena Wei Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Yuanxing Liu, Zheng Yuan, Jey Han Lau |  |
| 1708 |  |  [DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking](https://aclanthology.org/2025.acl-long.220/) |  | 0 | Designing solutions for complex engineering challenges is crucial in human production activities. However, previous research in the retrieval-augmented generation (RAG) field has not sufficiently addressed tasks related to the design of complex engineering solutions. To fill this gap, we introduce... | Zhuoqun Li, Haiyang Yu, Xuanang Chen, Hongyu Lin, Yaojie Lu, Fei Huang, Xianpei Han, Yongbin Li, Le Sun |  |
| 1709 |  |  [SurveyPilot: an Agentic Framework for Automated Human Opinion Collection from Social Media](https://aclanthology.org/2025.acl-long.221/) |  | 0 | Opinion survey research is a crucial method used by social scientists for understanding societal beliefs and behaviors. Traditional methodologies often entail high costs and limited scalability, while current automated methods such as opinion synthesis exhibit severe biases and lack traceability.... | Viet Thanh Pham, Lizhen Qu, Zhuang Li, Suraj Sharma, Gholamreza Haffari |  |
| 1710 |  |  [Sharper and Faster mean Better: Towards More Efficient Vision-Language Model for Hour-scale Long Video Understanding](https://aclanthology.org/2025.acl-long.222/) |  | 0 | Despite existing multimodal language models showing impressive performance on the video understanding task, extremely long videos still pose significant challenges to language model’s context length, memory consumption, and computational complexity. To address these issues, we propose a... | Daoze Zhang, Yuze Zhao, Jintao Huang, Yingda Chen |  |
| 1711 |  |  [Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions](https://aclanthology.org/2025.acl-long.223/) |  | 0 | As LLMs continuously evolve, there is an urgent need for a reliable evaluation method that delivers trustworthy results promptly. Currently, static benchmarks suffer from inflexibility and unreliability, leading users to prefer human voting platforms like Chatbot Arena. However, human evaluations... | Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Weiwen Xu, Deli Zhao, Lidong Bing |  |
| 1712 |  |  [How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian](https://aclanthology.org/2025.acl-long.224/) |  | 0 | People can categorize the same entity at multiple taxonomic levels, such as basic (bear), superordinate (animal), and subordinate (grizzly bear). While prior research has focused on basic-level categories, this study is the first attempt to examine the organization of categories by analyzing... | Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi |  |
| 1713 |  |  [PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models](https://aclanthology.org/2025.acl-long.225/) |  | 0 | Large Language Models (LLMs) suffer severe performance degradation when facing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bit post-training quantization (PTQ) methods utilize a mix-precision scheme by leveraging an unstructured fine-grained mask to explicitly distinguish... | Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang |  |
| 1714 |  |  [ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification](https://aclanthology.org/2025.acl-long.226/) |  | 0 | In this work, we propose ProtoLens, a novel prototype-based model that provides fine-grained, sub-sentence level interpretability for text classification. ProtoLens uses a Prototype-aware Span Extraction module to identify relevant text spans associated with learned prototypes and a Prototype... | Bowen Wei, Ziwei Zhu |  |
| 1715 |  |  [Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization](https://aclanthology.org/2025.acl-long.227/) |  | 0 | Video dubbing aims to translate original speech in visual media programs from the source language to the target language, relying on neural machine translation and text-to-speech technologies. Due to varying information densities across languages, target speech often mismatches the source speech... | Chaoqun Cui, Liangbin Huang, Shijing Wang, Zhe Tong, Zhaolong Huang, Xiao Zeng, Xiaofeng Liu |  |
| 1716 |  |  [Sparse Latents Steer Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.228/) |  | 0 | Understanding the mechanisms underlying Large Language Model (LLM) behavior in Retrieval-Augmented Generation (RAG) systems is critical for enhancing reliability. In this paper, we leverage Sparse Autoencoders (SAEs) within the LLaMA Scope to uncover sparse, interpretable latents that govern RAG... | Chunlei Xin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Xuanang Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun |  |
| 1717 |  |  [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://aclanthology.org/2025.acl-long.229/) |  | 0 | The mechanisms behind multilingual capabilities in Large Language Models (LLMs) have been examined using neuron-based or internal-activation-based methods. However, these methods often face challenges such as superposition and layer-wise activation variance, which limit their reliability. Sparse... | Boyi Deng, Yu Wan, Baosong Yang, Yidan Zhang, Fuli Feng |  |
| 1718 |  |  [SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model](https://aclanthology.org/2025.acl-long.230/) |  | 0 | The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the... | Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Jason Zhaoxin Fan, Bo Tang, Jihao Zhao, Jiawei Yang, Shichao Song, Mengwei Wang |  |
| 1719 |  |  [AnRe: Analogical Replay for Temporal Knowledge Graph Forecasting](https://aclanthology.org/2025.acl-long.231/) |  | 0 | Temporal Knowledge Graphs (TKGs) are vital for event prediction, yet current methods face limitations. Graph neural networks mainly depend on structural information, often overlooking semantic understanding and requiring high computational costs. Meanwhile, Large Language Models (LLMs) support... | Guo Tang, Zheng Chu, Wenxiang Zheng, Junjia Xiang, Yizhuo Li, Weihao Zhang, Ming Liu, Bing Qin |  |
| 1720 |  |  [Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?](https://aclanthology.org/2025.acl-long.232/) |  | 0 | The advent of test-time scaling in large language models (LLMs), exemplified by OpenAI’s o1 series, has advanced reasoning capabilities by scaling computational resource allocation during inference. While successors like QwQ, Deepseek-R1 (R1) and LIMO replicate these advancements, whether these... | Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Yunhua Zhou, Xipeng Qiu |  |
| 1721 |  |  [Text is All You Need: LLM-enhanced Incremental Social Event Detection](https://aclanthology.org/2025.acl-long.233/) |  | 0 | Social event detection (SED) is the task of identifying, categorizing, and tracking events from social data sources such as social media posts, news articles, and online discussions. Existing state-of-the-art (SOTA) SED models predominantly rely on graph neural networks (GNNs), which involve... | Zitai Qiu, Congbo Ma, Jia Wu, Jian Yang |  |
| 1722 |  |  [Multimodal Pragmatic Jailbreak on Text-to-image Models](https://aclanthology.org/2025.acl-long.234/) |  | 0 | Diffusion models have recently achieved remarkable advancements in terms of image quality and fidelity to textual prompts. Concurrently, the safety of such generative models has become an area of growing concern. This work introduces a novel type of jailbreak, which triggers T2I models to generate... | Tong Liu, Zhixin Lai, Jiawen Wang, Gengyuan Zhang, Shuo Chen, Philip Torr, Vera Demberg, Volker Tresp, Jindong Gu |  |
| 1723 |  |  [Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks](https://aclanthology.org/2025.acl-long.235/) |  | 0 | Transformer-based models excel in various tasks but their generalization capabilities, especially in arithmetic reasoning, remain incompletely understood. Arithmetic tasks provide a controlled framework to explore these capabilities, yet performance anomalies persist, such as inconsistent... | Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang |  |
| 1724 |  |  [Discourse Relation-Enhanced Neural Coherence Modeling](https://aclanthology.org/2025.acl-long.236/) |  | 0 | Discourse coherence theories posit relations between text spans as a key feature of coherent texts. However, existing work on coherence modeling has paid little attention to discourse relations. In this paper, we provide empirical evidence to demonstrate that relation features are correlated with... | Wei Liu, Michael Strube |  |
| 1725 |  |  [Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models](https://aclanthology.org/2025.acl-long.237/) |  | 0 | Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked audio dialogue capabilities, enabling direct spoken exchanges with humans. The potential of LALMs broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these... | Kuofeng Gao, Shutao Xia, Ke Xu, Philip Torr, Jindong Gu |  |
| 1726 |  |  [from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors](https://aclanthology.org/2025.acl-long.238/) |  | 0 | Current studies have exposed the risk of Large Language Models (LLMs) generating harmful content by jailbreak attacks. However, they overlook that the direct generation of harmful content from scratch is more difficult than inducing LLM to calibrate benign content into harmful forms.In our study,... | Yu Yan, Sheng Sun, Zenghao Duan, Teli Liu, Min Liu, Zhiyi Yin, LeiJingyu LeiJingyu, Qi Li |  |
| 1727 |  |  [ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Multilingual Contrastive Framework](https://aclanthology.org/2025.acl-long.239/) |  | 0 | Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To... | Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Yiyao Yu, Feng Yao, Renliang Sun, Yujiu Yang, Furu Wei |  |
| 1728 |  |  [MorphMark: Flexible Adaptive Watermarking for Large Language Models](https://aclanthology.org/2025.acl-long.240/) |  | 0 | Watermarking by altering token sampling probabilities based on red-green list is a promising method for tracing the origin of text generated by large language models (LLMs). However, existing watermark methods often struggle with a fundamental dilemma: improving watermark effectiveness (the... | Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang |  |
| 1729 |  |  [A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression](https://aclanthology.org/2025.acl-long.241/) |  | 0 | In this work, we provide an empirical investigation of gist-based context compression methods to improve context processing in large language models. We focus on two key questions: (1) How well can these methods replace full attention models? and (2) What potential failure patterns arise due to... | Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou |  |
| 1730 |  |  [On the Limit of Language Models as Planning Formalizers](https://aclanthology.org/2025.acl-long.242/) |  | 0 | Large Language Models have been found to create plans that are neither executable nor verifiable in grounded environments. An emerging line of work demonstrates success in using the LLM as a formalizer to generate a formal representation of the planning domain in some language, such as Planning... | Cassie Huang, Li Zhang |  |
| 1731 |  |  [Learning to Generate Structured Output with Schema Reinforcement Learning](https://aclanthology.org/2025.acl-long.243/) |  | 0 | This study investigates the structured generation capabilities of large language models (LLMs), focusing on producing valid JSON outputs against a given schema. Despite the widespread use of JSON in integrating language models with programs, there is a lack of comprehensive analysis and... | Yaxi Lu, Haolun Li, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Zhiyuan Liu, Fangming Liu, Maosong Sun |  |
| 1732 |  |  [Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning](https://aclanthology.org/2025.acl-long.244/) |  | 0 | Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained... | Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui |  |
| 1733 |  |  [Improve Safety Training of Large Language Models with Safety-Critical Singular Vectors Localization](https://aclanthology.org/2025.acl-long.245/) |  | 0 | The rapid advancement of large language models (LLMs) has brought about increased concerns regarding their safety, especially as adversaries develop jailbreak techniques to bypass LLMs’ safety mechanism. Although recent work on safety training with modules such as low-rank adaptation (LoRA) to... | Peijian Gu, Quan Wang, Zhendong Mao |  |
| 1734 |  |  [WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models](https://aclanthology.org/2025.acl-long.246/) |  | 0 | Despite recent progress achieved by code large language models (LLMs), their remarkable abilities are largely dependent on fine-tuning on the high-quality data, posing challenges for data collection and annotation. To address this, current methods often design various data flywheels to collect... | Huawen Feng, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang |  |
| 1735 |  |  [A Triple-View Framework for Fine-Grained Emotion Classification with Clustering-Guided Contrastive Learning](https://aclanthology.org/2025.acl-long.247/) |  | 0 | Fine-grained emotion classification (FEC) aims to analyze speakers’ utterances and distinguish dozens of emotions with subtle differences, allowing for a more nuanced understanding of human emotional states. However, compared to traditional coarse-grained emotion classification, two difficulties... | Junqing Gong, Binhan Yang, Wei Shen |  |
| 1736 |  |  [Quantification of Large Language Model Distillation](https://aclanthology.org/2025.acl-long.248/) |  | 0 | Model distillation is a fundamental technique in building large language models (LLMs), transferring knowledge from a teacher model to a student model. However, distillation can lead to model homogenization, reducing diversity among models and impairing their ability to robustly handle complex or... | Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xeron Du, Sirui He, Haihong Wu, Tianci Liu, Jiaheng Liu, Hamid AlinejadRokny, Min Yang, Yitao Liang, Zhoufutu Wen, Shiwen Ni |  |
| 1737 |  |  [Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models](https://aclanthology.org/2025.acl-long.249/) |  | 0 | This paper revisits the implementation of Load-Balancing-Loss (LBL) when training Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as NE ∑i=1NE fipi, where NE is the total number of experts, fi represents the frequency of expert i being selected, and pi denotes the average... | Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin |  |
| 1738 |  |  [Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models](https://aclanthology.org/2025.acl-long.250/) |  | 0 | Retrieval-Augmented Generation (RAG) has emerged as a crucial method for addressing hallucinations in large language models (LLMs). While recent research has extended RAG models to complex noisy scenarios, these explorations often confine themselves to limited noise types and presuppose that noise... | Jinyang Wu, Shuai Zhang, Feihu Che, Mingkuan Feng, Pengpeng Shao, Jianhua Tao |  |
| 1739 |  |  [Stepwise Reasoning Disruption Attack of LLMs](https://aclanthology.org/2025.acl-long.251/) |  | 0 | Large language models (LLMs) have made remarkable strides in complex reasoning tasks, but their safety and robustness in reasoning processes remain unexplored, particularly in third-party platforms that facilitate user interactions via APIs. Existing attacks on LLM reasoning are constrained by... | Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu |  |
| 1740 |  |  [Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge](https://aclanthology.org/2025.acl-long.252/) |  | 0 | LLM-as-a-Judge, which generates chain-of-thought (CoT) judgments, has become a widely adopted auto-evaluation method. However, its reliability is compromised by the CoT reasoning’s inability to capture comprehensive and deeper details, often leading to incomplete outcomes. Existing methods mainly... | Qiyuan Zhang, Yufei Wang, Yuxin Jiang, Liangyou Li, Chuhan Wu, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma |  |
| 1741 |  |  [Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models](https://aclanthology.org/2025.acl-long.253/) |  | 0 | Multilingual language models (MLMs) store factual knowledge across languages but often struggle to provide consistent responses to semantically equivalent prompts in different languages. While previous studies point out this cross-lingual inconsistency issue, the underlying causes remain... | Mingyang Wang, Heike Adel, Lukas Lange, Yihong Liu, Ercong Nie, Jannik Strötgen, Hinrich Schütze |  |
| 1742 |  |  [Optimizing Decomposition for Optimal Claim Verification](https://aclanthology.org/2025.acl-long.254/) |  | 0 | Current research on the Decompose-Then-Verify paradigm for evaluating the factuality of long-form text typically treats decomposition and verification in isolation, overlooking their interactions and potential misalignment. We find that existing decomposition policies, typically hand-crafted... | Yining Lu, Noah Ziems, Hy Dang, Meng Jiang |  |
| 1743 |  |  [GradOT: Training-free Gradient-preserving Offsite-tuning for Large Language Models](https://aclanthology.org/2025.acl-long.255/) |  | 0 | The rapid growth of large language models (LLMs) with traditional centralized fine-tuning emerges as a key technique for adapting these models to domain-specific challenges, yielding privacy risks for both model and data owners. One promising solution, called offsite-tuning (OT), is proposed to... | Kai Yao, Zhaorui Tan, Penglei Gao, Lichun Li, Kaixin Wu, Yinggui Wang, Yuan Zhao, Yixin Ji, Jianke Zhu, Wei Wang |  |
| 1744 |  |  [Knowledge Boundary of Large Language Models: A Survey](https://aclanthology.org/2025.acl-long.256/) |  | 0 | Although large language models (LLMs) store vast amount of knowledge in their parameters, they still have limitations in the memorization and utilization of certain knowledge, leading to undesired behaviors such as generating untruthful and inaccurate responses. This highlights the critical need to... | Moxin Li, Yong Zhao, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, SeeKiong Ng, TatSeng Chua, Yang Deng |  |
| 1745 |  |  [Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning](https://aclanthology.org/2025.acl-long.257/) |  | 0 | Recent advancements in Large Language Models (LLMs) have demonstrated enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting to advanced, product-oriented solutions like OpenAI o1. During our re-implementation of this model, we noticed that in multimodal tasks requiring... | HaiLong Sun, Zhun Sun, Houwen Peng, HanJia Ye |  |
| 1746 |  |  [MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System](https://aclanthology.org/2025.acl-long.258/) |  | 0 | Retrieval-Augmented Generation (RAG), while serving as a viable complement to large language models (LLMs), often overlooks the crucial aspect of text chunking within its pipeline. This paper initially introduces a dual-metric evaluation method, comprising Boundary Clarity and Chunk Stickiness, to... | Jihao Zhao, Zhiyuan Ji, Zhaoxin Fan, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li |  |
| 1747 |  |  [Mitigating Selection Bias with Node Pruning and Auxiliary Options](https://aclanthology.org/2025.acl-long.259/) |  | 0 | Large language models (LLMs) often exhibit systematic preferences for certain answer choices when responding to multiple-choice questions—a behavior known as selection bias. This bias reduces the accuracy and reliability of LLM outputs, limiting their usefulness in decision-critical applications.... | Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy |  |
| 1748 |  |  [Dually Self-Improved Counterfactual Data Augmentation Using Large Language Model](https://aclanthology.org/2025.acl-long.260/) |  | 0 | Counterfactual data augmentation, which generates minimally edited tokens to alter labels, has become a key approach to improving model robustness in natural language processing (NLP). It is usually implemented by first identifying the causal terms and then modifying these terms to create... | Luhao Zhang, Xinyu Zhang, Linmei Hu, Dandan Song, Liqiang Nie |  |
| 1749 |  |  [RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.261/) |  | 0 | While Retrieval-Augmented Generation (RAG) has exhibited promise in utilizing external knowledge, its generation process heavily depends on the quality and accuracy of the retrieved context. Large language models (LLMs) struggle to evaluate the correctness of non-parametric knowledge retrieved... | ShiQi Yan, Quan Liu, ZhenHua Ling |  |
| 1750 |  |  [Learning to Reason from Feedback at Test-Time](https://aclanthology.org/2025.acl-long.262/) |  | 0 | Solving complex tasks in a single attempt is challenging for large language models (LLMs). Iterative interaction with the environment and feedback is often required to achieve success, making effective feedback utilization a critical topic. Existing approaches either struggle with length... | Yanyang Li, Michael R. Lyu, Liwei Wang |  |
| 1751 |  |  [L-CiteEval: A Suite for Evaluating Fidelity of Long-context Models](https://aclanthology.org/2025.acl-long.263/) |  | 0 | Long-context models(LCMs) have witnessed remarkable advancements in recent years, facilitating real-world tasks like long-document QA. The success of LCMs is founded on the hypothesis that the model demonstrates strong fidelity, enabling it to respond based on the provided long context rather than... | Zecheng Tang, Keyan Zhou, Juntao Li, Baibei Ji, Jianye Hou, Min Zhang |  |
| 1752 |  |  [SECRET: Semi-supervised Clinical Trial Document Similarity Search](https://aclanthology.org/2025.acl-long.264/) |  | 0 | Clinical trials are vital for evaluation of safety and efficacy of new treatments. However, clinical trials are resource-intensive, time-consuming and expensive to conduct, where errors in trial design, reduced efficacy, and safety events can result in significant delays, financial losses, and... | Trisha Das, Afrah Shafquat, Mandis Beigi, Jacob Aptekar, Jimeng Sun |  |
| 1753 |  |  [Geometric Signatures of Compositionality Across a Language Model's Lifetime](https://aclanthology.org/2025.acl-long.265/) |  | 0 | By virtue of linguistic compositionality, few syntactic rules and a finite lexicon can generate an unbounded number of sentences. That is, language, though seemingly high-dimensional, can be explained using relatively few degrees of freedom. An open question is whether contemporary language models... | Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng |  |
| 1754 |  |  [Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine](https://aclanthology.org/2025.acl-long.266/) |  | 0 | Large Language Models (LLMs) such as ChatGPT demonstrate significant potential in the medical domain and are often evaluated using multiple-choice questions (MCQs) modeled on exams like the USMLE. However, such benchmarks may overestimate true clinical understanding by rewarding pattern recognition... | Maxime Griot, Jean Vanderdonckt, Demet Yüksel, Coralie Hemptinne |  |
| 1755 |  |  [People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text](https://aclanthology.org/2025.acl-long.267/) |  | 0 | In this paper, we study how well humans can detect text generated by commercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300 non-fiction English articles, label them as either human-written or AI-generated, and provide paragraph-length explanations for their decisions. Our experiments... | Jenna Russell, Marzena Karpinska, Mohit Iyyer |  |
| 1756 |  |  [YuLan-Mini: Pushing the Limits of Open Data-efficient Language Model](https://aclanthology.org/2025.acl-long.268/) |  | 0 | Due to the immense resource demands and the involved complex techniques, it is still challenging for successfully pre-training a large language models (LLMs) with state-of-the-art performance. In this paper, we explore the key bottlenecks and designs during pre-training, and make the following... | Yiwen Hu, Huatong Song, Jie Chen, Jia Deng, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Zican Dong, Yang Lu, Xu Miao, Xin Zhao, JiRong Wen |  |
| 1757 |  |  [Your Model is Overconfident, and Other Lies We Tell Ourselves](https://aclanthology.org/2025.acl-long.269/) |  | 0 | The difficulty intrinsic to a given example, rooted in its inherent ambiguity, is a key yet often overlooked factor in evaluating neural NLP models. We investigate the interplay and divergence among various metrics for assessing intrinsic difficulty, including annotator dissensus, training... | Timothee Mickus, Aman Sinha, Raúl Vázquez |  |
| 1758 |  |  [Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention](https://aclanthology.org/2025.acl-long.270/) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in natural language processing but exhibit significant performance gaps among different languages. Most existing approaches to address these disparities rely on pretraining or fine-tuning, which are resource-intensive. To overcome... | Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch |  |
| 1759 |  |  [Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models](https://aclanthology.org/2025.acl-long.271/) |  | 0 | Large language models (LLMs) are renowned for their extensive linguistic knowledge and strong generalization capabilities, but their high computational demands make them unsuitable for resource-constrained environments. In contrast, small language models (SLMs) are computationally efficient but... | Kyeonghyun Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, YoungBin Kim |  |
| 1760 |  |  [What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma](https://aclanthology.org/2025.acl-long.272/) |  | 0 | Mental-health stigma remains a pervasive social problem that hampers treatment-seeking and recovery. Existing resources for training neural models to finely classify such stigma are limited, relying primarily on social-media or synthetic data without theoretical underpinnings. To remedy this gap,... | Han Meng, Yancan Chen, Yunan Li, Yitian Yang, Jungup Lee, Renwen Zhang, YiChieh Lee |  |
| 1761 |  |  [ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors](https://aclanthology.org/2025.acl-long.273/) |  | 0 | Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. To address the inconsistency issue in multilingual... | Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou |  |
| 1762 |  |  [Enhancing Transformers for Generalizable First-Order Logical Entailment](https://aclanthology.org/2025.acl-long.274/) |  | 0 | Transformers, as the fundamental deep learning architecture, have demonstrated great capability in reasoning. This paper studies the generalizable first-order logical reasoning ability of transformers with their \*parameterized\* knowledge and how to improve it. Transformers’ capability of... | Tianshi Zheng, Jiazheng Wang, Zihao Wang, Jiaxin Bai, Hang Yin, Zheye Deng, Yangqiu Song, Jianxin Li |  |
| 1763 |  |  [Self-Taught Agentic Long Context Understanding](https://aclanthology.org/2025.acl-long.275/) |  | 0 | Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM’s understanding of such... | Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum |  |
| 1764 |  |  [Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training](https://aclanthology.org/2025.acl-long.276/) |  | 0 | As large language models (LLMs) become increasingly prevalent, concerns about their reliability, particularly due to hallucinations - factually inaccurate or irrelevant outputs - have grown. Our research investigates the relationship between the uncertainty in training dynamics and the emergence of... | Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi |  |
| 1765 |  |  [OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis](https://aclanthology.org/2025.acl-long.277/) |  | 0 | Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, the development of such agents faces a critical bottleneck: collecting high-quality trajectory data for... | Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu |  |
| 1766 |  |  [CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter](https://aclanthology.org/2025.acl-long.278/) |  | 0 | Speculative decoding is a powerful technique that accelerates Large Language Model (LLM) inference by leveraging a lightweight speculative draft model. However, existing designs suffers in performance due to misalignment between training and inference. Recent methods have tried to solve this issue... | Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi |  |
| 1767 |  |  [ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability](https://aclanthology.org/2025.acl-long.279/) |  | 0 | Concept-based explanations work by mapping complex model computations to human-understandable concepts. Evaluating such explanations is very difficult, as it includes not only the quality of the induced space of possible concepts but also how effectively the chosen concepts are communicated to... | Antonin Poché, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan |  |
| 1768 |  |  [Decoding Reading Goals from Eye Movements](https://aclanthology.org/2025.acl-long.280/) |  | 0 | Readers can have different goals with respect to the text that they are reading. Can these goals be decoded from their eye movements over the text? In this work, we examine for the first time whether it is possible to distinguish between two types of common reading goals: information seeking and... | Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak |  |
| 1769 |  |  [Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Space](https://aclanthology.org/2025.acl-long.281/) |  | 0 | Imageability (potential of text to evoke a mental image) and concreteness (perceptibility of text) are two psycholinguistic properties that link visual and semantic spaces. It is little surprise that computational methods that estimate them do so using parallel visual and semantic spaces, such as... | Si Wu, Sebastian Bruch |  |
| 1770 |  |  [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://aclanthology.org/2025.acl-long.282/) |  | 0 | GUI automation faces critical challenges in dynamic environments. MLLMs suffer from two key issues: misinterpreting UI components and outdated knowledge. Traditional fine-tuning methods are costly for app-specific knowledge updates. We propose GUI-explorer, a training-free GUI agent that... | Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie |  |
| 1771 |  |  [P² Law: Scaling Law for Post-Training After Model Pruning](https://aclanthology.org/2025.acl-long.283/) |  | 0 | Pruning has become a widely adopted technique for reducing the hardware requirements of large language models (LLMs). To recover model performance after pruning, post-training is commonly employed to mitigate the resulting performance degradation. While post-training benefits from larger datasets,... | Xiaodong Chen, Yuxuan Hu, Xiaokang Zhang, Yanling Wang, Cuiping Li, Hong Chen, Jing Zhang |  |
| 1772 |  |  [Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats](https://aclanthology.org/2025.acl-long.284/) |  | 0 | Dog whistles are coded expressions with dual meanings: one intended for the general public (outgroup) and another that conveys a specific message to an intended audience (ingroup). Often, these expressions are used to convey controversial political opinions while maintaining plausible deniability... | Kuleen Sasse, Carlos Alejandro Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze |  |
| 1773 |  |  [Lost in the Context: Insufficient and Distracted Attention to Contexts in Preference Modeling](https://aclanthology.org/2025.acl-long.285/) |  | 0 | In Reinforcement Learning from Human Feedback (RLHF), the reward model (RM) evaluates the response quality based on the given context and assigns a reward. It plays a crucial role in aligning RLHF with human preferences. Although the current RM training paradigm concatenates the context and... | Shihan Dou, Jiayi Chen, Chenhao Huang, Feng Chen, Wei Chengzhi, Huiyuan Zheng, Shichun Liu, Yan Liu, Chenxiao Liu, Chao Xin, Lin Yan, Zongzhang Zhang, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1774 |  |  [Entailment-Preserving First-order Logic Representations in Natural Language Entailment](https://aclanthology.org/2025.acl-long.286/) |  | 0 | First-order logic (FOL) is often used to represent logical entailment, but determining natural language (NL) entailment using FOL remains a challenge. To address this, we propose the Entailment-Preserving FOL representations (EPF) task and introduce reference-free evaluation metrics for EPF... | Jinu Lee, Qi Liu, Runzhi Ma, Vincent Han, Ziqi Wang, Heng Ji, Julia Hockenmaier |  |
| 1775 |  |  [Enhancing Multimodal Continual Instruction Tuning with BranchLoRA](https://aclanthology.org/2025.acl-long.287/) |  | 0 | Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal Large Language Models (MLLMs) to continually align with human intent across sequential tasks. Existing approaches often rely on the Mixture-of-Experts (MoE) LoRA framework to preserve previous instruction alignments.... | Duzhen Zhang, Yong Ren, ZhongZhi Li, Yahan Yu, Jiahua Dong, Chenxing Li, Zhilong Ji, Jinfeng Bai |  |
| 1776 |  |  [Enhancing Automated Interpretability with Output-Centric Feature Descriptions](https://aclanthology.org/2025.acl-long.288/) |  | 0 | Automated interpretability pipelines generate natural language descriptions for the concepts represented by features in large language models (LLMs), such as “plants” or “the first word in a sentence”. These descriptions are derived using inputs that activate the feature, which may be a dimension... | Yoav GurArieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva |  |
| 1777 |  |  [Towards Effective and Efficient Continual Pre-training of Large Language Models](https://aclanthology.org/2025.acl-long.289/) |  | 0 | Continual pre-training (CPT) has been an important approach for adapting language models to specific domains or tasks. In this paper, we comprehensively study its key designs to balance the new abilities while retaining the original abilities, and present an effective CPT method that can greatly... | Jie Chen, Zhipeng Chen, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, JiRong Wen |  |
| 1778 |  |  [Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization](https://aclanthology.org/2025.acl-long.290/) |  | 0 | Universal goal hijacking is a kind of prompt injection attack that forces LLMs to return a target malicious response for arbitrary normal user prompts. The previous methods achieve high attack performance while being too cumbersome and time-consuming. Also, they have concentrated solely on... | Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix JuefeiXu, Jian Zhang, Yang Liu, Geguang Pu |  |
| 1779 |  |  [mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding](https://aclanthology.org/2025.acl-long.291/) |  | 0 | Multimodel Large Language Models(MLLMs) have achieved promising OCR-free Document Understanding performance by increasing the supported resolution of document images. However, this comes at the cost of generating thousands of visual tokens for a single document image, leading to excessive GPU... | Anwen Hu, Haiyang Xu, Liang Zhang, Jiabo Ye, Ming Yan, Ji Zhang, Qin Jin, Fei Huang, Jingren Zhou |  |
| 1780 |  |  [What Makes a Good Natural Language Prompt?](https://aclanthology.org/2025.acl-long.292/) |  | 0 | As large language models (LLMs) have progressed towards more human-like and human–AI communications prevalent, prompting has emerged as a decisive component. However, there is limited conceptual consensus on what exactly quantifies natural language prompts. We attempt to address this question by... | Do Xuan Long, Duy Dinh, NgocHai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, MinYen Kan |  |
| 1781 |  |  [X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents](https://aclanthology.org/2025.acl-long.293/) |  | 0 | The Turing test examines whether AIs exhibit human-like behaviour in natural language conversations. The traditional setting limits each participant to one message at a time and requires constant human participation. This fails to reflect a natural conversational style and hinders the evaluation of... | Weiqi Wu, Hongqiu Wu, Hai Zhao |  |
| 1782 |  |  [Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral](https://aclanthology.org/2025.acl-long.294/) |  | 0 | Moral reasoning is a complex cognitive process shaped by individual experiences and cultural contexts and presents unique challenges for computational analysis. While natural language processing (NLP) offers promising tools for studying this phenomenon, current research lacks cohesion, employing... | Shivani Kumar, David Jurgens |  |
| 1783 |  |  [Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models](https://aclanthology.org/2025.acl-long.295/) |  | 0 | Generative models such as Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) trained on massive datasets can lead them to memorize and inadvertently reveal sensitive information, raising ethical and privacy concerns. While some prior works have explored this issue in the... | Zheyuan Liu, Guangyao Dou, Xiangchi Yuan, Chunhui Zhang, Zhaoxuan Tan, Meng Jiang |  |
| 1784 |  |  [NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning](https://aclanthology.org/2025.acl-long.296/) |  | 0 | Diet plays a critical role in human health, yet tailoring dietary reasoning to individual health conditions remains a major challenge. Nutrition Question Answering (QA) has emerged as a popular method for addressing this problem. However, current research faces two critical limitations. On one... | Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V. Chawla, Chuxu Zhang, Yanfang Ye |  |
| 1785 |  |  [ReLearn: Unlearning via Learning for Large Language Models](https://aclanthology.org/2025.acl-long.297/) |  | 0 | Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities. However, this paradigm disrupts the subsequent tokens prediction, degrading model performance and linguistic coherence. Moreover, existing evaluation metrics overemphasize... | Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang |  |
| 1786 |  |  [Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling](https://aclanthology.org/2025.acl-long.298/) |  | 0 | Topic modeling plays a vital role in uncovering hidden semantic structures within text corpora, but existing models struggle in low-resource settings where limited target-domain data leads to unstable and incoherent topic inference. We address this challenge by formally introducing domain... | Pritom Saha Akash, Kevin ChenChuan Chang |  |
| 1787 |  |  [UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models](https://aclanthology.org/2025.acl-long.299/) |  | 0 | Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs’ knowledge boundaries are ambiguous. To improve LLMs’ factual expressions, we propose the UAlign framework,... | Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, KamFai Wong |  |
| 1788 |  |  [CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://aclanthology.org/2025.acl-long.300/) |  | 0 | Chain-of-Thought significantly enhances a model’s reasoning capability, but it also comes with a considerable increase in inference costs due to long chains. With the observation that the reasoning path can be easily compressed under easy tasks but struggle on hard tasks, we explore the feasibility... | Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang |  |
| 1789 |  |  [HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.301/) |  | 0 | While Retrieval-Augmented Generation (RAG) has emerged as an effective approach for addressing the knowledge outdating problem in Large Language Models (LLMs), it still faces a critical challenge: the prevalence of outdated information in knowledge bases. Current research primarily focuses on... | Jie Ouyang, Tingyue Pan, Mingyue Cheng, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu |  |
| 1790 |  |  [Uncertainty Propagation on LLM Agent](https://aclanthology.org/2025.acl-long.302/) |  | 0 | Large language models (LLMs) integrated into multi-step agent systems enable complex decision-making processes across various applications. However, their outputs often lack reliability, making uncertainty estimation crucial. Existing uncertainty estimation methods primarily focus on final-step... | Qiwei Zhao, Dong Li, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Chen Zhao, Haifeng Chen, Xujiang Zhao |  |
| 1791 |  |  [Beyond Position: the emergence of wavelet-like properties in Transformers](https://aclanthology.org/2025.acl-long.303/) |  | 0 | This paper studies how Transformer models with Rotary Position Embeddings (RoPE) develop emergent, wavelet-like properties that compensate for the positional encoding’s theoretical limitations. Through an analysis spanning model scales, architectures, and training checkpoints, we show that... | Valeria Ruscio, Umberto Nanni, Fabrizio Silvestri |  |
| 1792 |  |  [Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs](https://aclanthology.org/2025.acl-long.304/) |  | 0 | Factual hallucinations are a major challenge for Large Language Models (LLMs). They undermine reliability and user trust by generating inaccurate or fabricated content. Recent studies suggest that when generating false statements, the internal states of LLMs encode information about truthfulness.... | Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia |  |
| 1793 |  |  [Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning](https://aclanthology.org/2025.acl-long.305/) |  | 0 | The rapid development of Large Language Models (LLMs) has led to their widespread adoption across various domains, leveraging vast pre-training knowledge and impressive generalization capabilities. However, these models often inherit biased knowledge, resulting in unfair decisions in sensitive... | Zheyuan Liu, Suraj Maharjan, Fanyou Wu, Rahil Parikh, Belhassen Bayar, Srinivasan H. Sengamedu, Meng Jiang |  |
| 1794 |  |  [LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing](https://aclanthology.org/2025.acl-long.306/) |  | 0 | Large Language Models (LLMs) have rapidly become central to NLP, demonstrating their ability to adapt to various tasks through prompting techniques, including sentiment analysis. However, we still have a limited understanding of how these models capture sentiment-related information. This study... | Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia |  |
| 1795 |  |  [CxGGEC: Construction-Guided Grammatical Error Correction](https://aclanthology.org/2025.acl-long.307/) |  | 0 | The grammatical error correction (GEC) task aims to detect and correct grammatical errors in text to enhance its accuracy and readability. Current GEC methods primarily rely on grammatical labels for syntactic information, often overlooking the inherent usage patterns of language. In this work, we... | Yayu Cao, Tianxiang Wang, Lvxiaowei Xu, Zhenyao Wang, Ming Cai |  |
| 1796 |  |  [Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation](https://aclanthology.org/2025.acl-long.308/) |  | 0 | The advent of large language models has significantly advanced automatic code generation, transforming the way programmers writing code. Inspired by natural language processing, mainstream code generation approaches represent code as a linear sequence of tokens. In this paper, we propose to... | Xiangyu Zhang, Yu Zhou, Guang Yang, Wei Cheng, Taolue Chen |  |
| 1797 |  |  [HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs](https://aclanthology.org/2025.acl-long.309/) |  | 0 | In recent years, large language models (LLMs) have made remarkable advancements, yet hallucination, where models produce inaccurate or non-factual statements, remains a significant challenge for real-world deployment. Although current classification-based methods, such as SAPLMA, are highly... | Qing Li, Jiahui Geng, Zongxiong Chen, Derui Zhu, Yuxia Wang, Congbo Ma, Chenyang Lyu, Fakhri Karray |  |
| 1798 |  |  [What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations](https://aclanthology.org/2025.acl-long.310/) |  | 0 | Transforming recorded videos into concise and accurate textual summaries is a growing challenge in multimodal learning. This paper introduces VISTA, a dataset specifically designed for video-to-text summarization in scientific domains. VISTA contains 18,599 recorded AI conference presentations... | Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg |  |
| 1799 |  |  [NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering](https://aclanthology.org/2025.acl-long.311/) |  | 0 | The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic... | Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuxin Zhang, Liangtai Sun, Hanqi Li, Yuxun Miao, Shuai Fan, Lu Chen, Kai Yu |  |
| 1800 |  |  [ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing](https://aclanthology.org/2025.acl-long.312/) |  | 0 | Contract review is a critical process to protect the rights and interests of the parties involved. However, this process is time-consuming, labor-intensive, and costly, especially when a contract faces multiple rounds of review. To accelerate the contract review and promote the completion of... | Xiuxuan Shen, Zhongyuan Jiang, Junsan Zhang, Junxiao Han, Yao Wan, Chengjie Guo, Bingcheng Liu, Jie Wu, Renxiang Li, Philip S. Yu |  |
| 1801 |  |  [F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching](https://aclanthology.org/2025.acl-long.313/) |  | 0 | This paper introduces F5-TTS, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT). Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same... | Yushen Chen, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, Jian Zhao, Kai Yu, Xie Chen |  |
| 1802 |  |  [AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation](https://aclanthology.org/2025.acl-long.314/) |  | 0 | With the proliferation of large language models (LLMs) in the medical domain, there is increasing demand for improved evaluation techniques to assess their capabilities. However, traditional metrics like F1 and ROUGE, which rely on token overlaps to measure quality, significantly overlook the... | Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He |  |
| 1803 |  |  [CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis](https://aclanthology.org/2025.acl-long.315/) |  | 0 | Current inference scaling methods, such as Self-consistency and Best-of-N, have proven effective in improving the accuracy of LLMs on complex reasoning tasks. However, these methods rely heavily on the quality of candidate responses and are unable to produce correct answers when all candidates are... | Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang |  |
| 1804 |  |  [Efficiently Identifying Watermarked Segments in Mixed-Source Texts](https://aclanthology.org/2025.acl-long.316/) |  | 0 | Text watermarks in large language models (LLMs) are increasingly used to detect synthetic text, mitigating misuse cases like fake news and academic dishonesty. While existing watermarking detection techniques primarily focus on classifying entire documents as watermarked or not, they often neglect... | Xuandong Zhao, Chenwen Liao, Yuxiang Wang, Lei Li |  |
| 1805 |  |  [Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks](https://aclanthology.org/2025.acl-long.317/) |  | 0 | Language is not monolithic. While benchmarks, including those designed for multiple languages, are often used as proxies to evaluate the performance of Large Language Models (LLMs), they tend to overlook the nuances of within-language variation and thus fail to model the experience of speakers of... | Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Xun Wang, SiQing Chen, Michael J. Wooldridge, Janet B. Pierrehumbert, Furu Wei |  |
| 1806 |  |  [Towards a More Generalized Approach in Open Relation Extraction](https://aclanthology.org/2025.acl-long.318/) |  | 0 | Open Relation Extraction (OpenRE) seeks to identify and extract novel relational facts between named entities from unlabeled data without pre-defined relation schemas. Traditional OpenRE methods typically assume that the unlabeled data consists solely of novel relations or is pre-divided into known... | Qing Wang, Yuepei Li, Qiao Qiao, Kang Zhou, Qi Li |  |
| 1807 |  |  [Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home](https://aclanthology.org/2025.acl-long.319/) |  | 0 | Retrieval Augmented Generation (RAG) improves correctness of Question Answering (QA) and addresses hallucinations in Large Language Models (LLMs), yet greatly increase computational costs. Besides, RAG is not always needed as may introduce irrelevant information. Recent adaptive retrieval methods... | Viktor Moskvoretskii, Maria Marina, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko |  |
| 1808 |  |  [Evaluating Language Models as Synthetic Data Generators](https://aclanthology.org/2025.acl-long.320/) |  | 0 | Given the increasing use of synthetic data in language model (LM) post-training, an LM’s ability to generate high-quality data has become nearly as crucial as its ability to solve problems directly. While prior works have focused on developing effective data generation methods, they lack systematic... | Seungone Kim, Juyoung Suk, Xiang Yue, Vijay Viswanathan, Seongyun Lee, Yizhong Wang, Kiril Gashteovski, Carolin Lawrence, Sean Welleck, Graham Neubig |  |
| 1809 |  |  [Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?](https://aclanthology.org/2025.acl-long.321/) |  | 0 | Large language models (LLMs) have achieved significant success in reasoning tasks, including mathematical reasoning and logical deduction. Among these reasoning tasks, graph problems stand out due to their complexity and unique structural characteristics, attracting considerable attention from... | Yuyao Ge, Shenghua Liu, Baolong Bi, Yiwei Wang, Lingrui Mei, Wenjie Feng, Lizhe Chen, Xueqi Cheng |  |
| 1810 |  |  [Learning to Rewrite: Generalized LLM-Generated Text Detection](https://aclanthology.org/2025.acl-long.322/) |  | 0 | Detecting text generated by Large Language Models (LLMs) is crucial, yet current detectors often struggle to generalize in open-world settings. We introduce Learning2Rewrite, a novel framework to detect LLM-generated text with exceptional generalization to unseen domains. Capitalized on the finding... | Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao |  |
| 1811 |  |  [Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search](https://aclanthology.org/2025.acl-long.323/) |  | 0 | Video captioning can be used to assess the video understanding capabilities of Multimodal Large Language Models (MLLMs).However, existing benchmarks and evaluation protocols suffer from crucial issues, such as inadequate or homogeneous creation of key points, exorbitant cost of data creation, and... | Linhao Yu, Xingguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, Victoria W., Fuzheng Zhang, Deyi Xiong |  |
| 1812 |  |  [GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs](https://aclanthology.org/2025.acl-long.324/) |  | 0 | Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and democratized the usage of Large Language Models (LLMs). Recent studies have shown that a small subset of weights significantly impacts performance. Based on this observation, we introduce a novel PEFT method, called Gaussian... | Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Mariya Krylova, Egor Venediktov, Aleksandr Zuev, Evgeny Burnaev |  |
| 1813 |  |  [Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis](https://aclanthology.org/2025.acl-long.325/) |  | 0 | Large language models (LLMs) have made exciting achievements across various domains, yet their deployment on resource-constrained personal devices remains hindered by the prohibitive computational and memory demands of task-specific fine-tuning. While quantization offers a pathway to efficiency,... | Hong Huang, Dapeng Wu |  |
| 1814 |  |  [Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models](https://aclanthology.org/2025.acl-long.326/) |  | 0 | This paper introduces a novel task to evaluate the robust understanding capability of Large Multimodal Models (LMMs), termed Unsolvable Problem Detection (UPD). Multiple-choice question answering (MCQA) is widely used to assess the understanding capability of LMMs, but it does not guarantee that... | Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Helen Li, Ziwei Liu, Kiyoharu Aizawa |  |
| 1815 |  |  [AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models](https://aclanthology.org/2025.acl-long.327/) |  | 0 | Evaluating the alignment capabilities of large Vision-Language Models (VLMs) is essential for determining their effectiveness as helpful assistants. However, existing benchmarks primarily focus on basic abilities using nonverbal methods, such as yes-no and multiple-choice questions. In this paper,... | Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong |  |
| 1816 |  |  [Biased LLMs can Influence Political Decision-Making](https://aclanthology.org/2025.acl-long.328/) |  | 0 | As modern large language models (LLMs) become integral to everyday tasks, concerns about their inherent biases and their potential impact on human decision-making have emerged. While bias in models are well-documented, less is known about how these biases influence human decisions. This paper... | Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W. Fisher, Jennifer Pan, Yulia Tsvetkov, Katharina Reinecke |  |
| 1817 |  |  [LexTempus: Enhancing Temporal Generalizability of Legal Language Models Through Dynamic Mixture of Experts](https://aclanthology.org/2025.acl-long.329/) |  | 0 | The rapid evolution of legal concepts over time necessitates that legal language models adapt swiftly accounting for the temporal dynamics. However, prior works have largely neglected this crucial dimension, treating legal adaptation as a static problem rather than a continuous process. To address... | T. Y. S. S. Santosh, TuanQuang Vuong |  |
| 1818 |  |  [That is Unacceptable: the Moral Foundations of Canceling](https://aclanthology.org/2025.acl-long.330/) |  | 0 | Canceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring the... | Soda Marem Lo, Oscar Araque, Rajesh Sharma, Marco Antonio Stranisci |  |
| 1819 |  |  [FloorPlan-LLaMa: Aligning Architects' Feedback and Domain Knowledge in Architectural Floor Plan Generation](https://aclanthology.org/2025.acl-long.331/) |  | 0 | Floor plans serve as a graphical language through which architects sketch and communicate their design ideas. Actually, in the Architecture, Engineering, and Construction (AEC) design stages, generating floor plans is a complex task requiring domain expertise and alignment with user requirements.... | Jun Yin, Pengyu Zeng, Haoyuan Sun, Yuqin Dai, Han Zheng, Miao Zhang, Yachao Zhang, Shuai Lu |  |
| 1820 |  |  [TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding](https://aclanthology.org/2025.acl-long.332/) |  | 0 | Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their... | Max Ku, Cheuk Hei Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen |  |
| 1821 |  |  [FineReason: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving](https://aclanthology.org/2025.acl-long.333/) |  | 0 | Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach. Recent progress in large language models (LLMs) highlights an important shift from the “System 1” way of quick reactions to the “System 2” style of reflection-and-correction... | Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong |  |
| 1822 |  |  [The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs](https://aclanthology.org/2025.acl-long.334/) |  | 0 | We present a novel class of jailbreak adversarial attacks on LLMs, termed Task-in-Prompt (TIP) attacks. Our approach embeds sequence-to-sequence tasks (e.g., cipher decoding, riddles, code execution) into the model’s prompt to indirectly generate prohibited inputs. To systematically assess the... | Sergey Berezin, Reza Farahbakhsh, Noël Crespi |  |
| 1823 |  |  [Identifying Reliable Evaluation Metrics for Scientific Text Revision](https://aclanthology.org/2025.acl-long.335/) |  | 0 | Evaluating text revision in scientific writing remains a challenge, as traditional metrics such as ROUGE and BERTScore primarily focus on similarity rather than capturing meaningful improvements. In this work, we analyse and identify the limitations of these metrics and explore alternative... | Léane Jourdan, Nicolas Hernandez, Florian Boudin, Richard Dufour |  |
| 1824 |  |  [Can Language Models Reason about Individualistic Human Values and Preferences?](https://aclanthology.org/2025.acl-long.336/) |  | 0 | Recent calls for pluralistic alignment emphasize that AI systems should address the diverse needs of all people. Yet, efforts in this space often require sorting people into fixed buckets of pre-specified diversity-defining dimensions (e.g., demographics), risking smoothing out individualistic... | Liwei Jiang, Taylor Sorensen, Sydney Levine, Yejin Choi |  |
| 1825 |  |  [BERT-like Models for Slavic Morpheme Segmentation](https://aclanthology.org/2025.acl-long.337/) |  | 0 | Automatic morpheme segmentation algorithms are applicable in various tasks, such as building tokenizers and language education. For Slavic languages, the development of such algorithms is complicated by the rich derivational capabilities of these languages. Previous research has shown that, on... | Dmitry Morozov, Lizaveta Astapenka, Anna V. Glazkova, Timur Garipov, Olga Lyashevskaya |  |
| 1826 |  |  [Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling](https://aclanthology.org/2025.acl-long.338/) |  | 0 | The rapid growth in the parameters of LLMs has made inference latency a fundamental bottleneck. Speculative decoding represents a lossless approach to accelerate inference through a guess-and-verify paradigm. Some methods rely on additional architectures to guess draft tokens, which need extra... | Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu |  |
| 1827 |  |  [Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering](https://aclanthology.org/2025.acl-long.339/) |  | 0 | Recent advancements in long chain-of-thoughts (long CoTs) have significantly improved the reasoning capabilities of large language models (LLMs). Existing work finds that the capability of long CoT reasoning can be efficiently elicited by tuning on only a few examples and can easily transfer to... | Xinyu Tang, Xiaolei Wang, Zhihao Lv, Yingqian Min, Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang |  |
| 1828 |  |  [Drift: Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference](https://aclanthology.org/2025.acl-long.340/) |  | 0 | As Large Language Models (LLMs) are increasingly applied to complex reasoning tasks, achieving both accurate task performance and faithful explanations becomes crucial. However, LLMs often generate unfaithful explanations, partly because they do not consistently adhere closely to the provided... | Jiazheng Li, Hanqi Yan, Yulan He |  |
| 1829 |  |  [Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs](https://aclanthology.org/2025.acl-long.341/) |  | 0 | Algorithmic fairness has conventionally adopted the mathematically convenient perspective of racial color-blindness (i.e., difference unaware treatment). However, we contend that in a range of important settings, group difference awareness matters. For example, differentiating between groups may be... | Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo |  |
| 1830 |  |  [MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models](https://aclanthology.org/2025.acl-long.342/) |  | 0 | Protecting the intellectual property of Large Language Models (LLMs) has become increasingly critical due to the high cost of training. Model merging, which integrates multiple expert models into a single multi-task model, introduces a novel risk of unauthorized use of LLMs due to its efficient... | Shojiro Yamabe, Futa Kai Waseda, Tsubasa Takahashi, Koki Wataoka |  |
| 1831 |  |  [Dynamic Scaling of Unit Tests for Code Reward Modeling](https://aclanthology.org/2025.acl-long.343/) |  | 0 | Current large language models (LLMs) often struggle to produce accurate responses on the first attempt for complex reasoning tasks like code generation. Prior research tackles this challenge by generating multiple candidate solutions and validating them with LLM-generated unit tests. The execution... | Zeyao Ma, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang |  |
| 1832 |  |  [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://aclanthology.org/2025.acl-long.344/) |  | 0 | The rapid advancement of conversational search systems revolutionizes how information is accessed by enabling the multi-turn interaction between the user and the system. Existing conversational search systems are usually built with two different models. This separation restricts the system from... | Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang |  |
| 1833 |  |  [Tracking Life's Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis](https://aclanthology.org/2025.acl-long.345/) |  | 0 | Social media platforms possess considerable potential in the realm of exploring mental health. Previous research has indicated that major life events can greatly impact individuals’ mental health. However, due to the complexity and ambiguity nature of life events, shedding its light on social media... | Minghao Lv, Siyuan Chen, Haoan Jin, Minghao Yuan, Qianqian Ju, Yujia Peng, Kenny Q. Zhu, Mengyue Wu |  |
| 1834 |  |  [ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control](https://aclanthology.org/2025.acl-long.346/) |  | 0 | In this paper, we present ControlSpeech, a text-to-speech (TTS) system capable of fully cloning the speaker’s voice and enabling arbitrary control and adjustment of speaking style. Prior zero-shot TTS models only mimic the speaker’s voice without further control and adjustment capabilities while... | Shengpeng Ji, Qian Chen, Wen Wang, Jialong Zuo, Minghui Fang, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Siqi Zheng, Zhou Zhao |  |
| 1835 |  |  [PIC: Unlocking Long-Form Text Generation Capabilities of Large Language Models via Position ID Compression](https://aclanthology.org/2025.acl-long.347/) |  | 0 | Long-context understanding is crucial for large language models (LLMs) and has become a fundamental capability for most LLMs. However, beyond the focus on “input-long”, the ability to “output-long” is equally significant, yet it remains underexplored. To address this limitation, we propose a... | Haoran Que, Wenge Rong |  |
| 1836 |  |  [Towards Effective Extraction and Evaluation of Factual Claims](https://aclanthology.org/2025.acl-long.348/) |  | 0 | A common strategy for fact-checking long-form content generated by Large Language Models (LLMs) is extracting simple claims that can be verified independently. Since inaccurate or incomplete claims compromise fact-checking results, ensuring claim quality is critical. However, the lack of a... | Dasha Metropolitansky, Jonathan Larson |  |
| 1837 |  |  [Beyond Facts: Evaluating Intent Hallucination in Large Language Models](https://aclanthology.org/2025.acl-long.349/) |  | 0 | When exposed to complex queries containing multiple conditions, today’s large language models (LLMs) tend to produce responses that only partially satisfy the query while neglecting certain conditions. We, therefore, introduce the concept of Intent Hallucination, a phenomenon where LLMs either omit... | Yijie Hao, Haofei Yu, Jiaxuan You |  |
| 1838 |  |  [A Systematic Study of Compositional Syntactic Transformer Language Models](https://aclanthology.org/2025.acl-long.350/) |  | 0 | Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up... | Yida Zhao, Hao Xve, Xiang Hu, Kewei Tu |  |
| 1839 |  |  [M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation](https://aclanthology.org/2025.acl-long.351/) |  | 0 | Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In... | Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu |  |
| 1840 |  |  [SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition](https://aclanthology.org/2025.acl-long.352/) |  | 0 | Creating lyrics and melodies for the vocal track in a symbolic format, known as song composition, demands expert musical knowledge of melody, an advanced understanding of lyrics, and precise alignment between them. Despite achievements in sub-tasks such as lyric generation, lyric-to-melody, and... | Shuangrui Ding, Zihan Liu, Xiaoyi Dong, Pan Zhang, Rui Qian, Junhao Huang, Conghui He, Dahua Lin, Jiaqi Wang |  |
| 1841 |  |  [Personalized Text Generation with Contrastive Activation Steering](https://aclanthology.org/2025.acl-long.353/) |  | 0 | Personalized text generation aims to infer users’ writing style preferences from their historical texts and generate outputs that faithfully reflect these stylistic characteristics. Existing solutions primarily adopt two paradigms: retrieval-augmented generation (RAG) and parameter-efficient... | Jinghao Zhang, Yuting Liu, Wenjie Wang, Qiang Liu, Shu Wu, Liang Wang, TatSeng Chua |  |
| 1842 |  |  [Gumbel Reranking: Differentiable End-to-End Reranker Optimization](https://aclanthology.org/2025.acl-long.354/) |  | 0 | RAG systems rely on rerankers to identify relevant documents. However, fine-tuning these models remains challenging due to the scarcity of annotated query-document pairs. Existing distillation-based approaches suffer from training-inference misalignment and fail to capture interdependencies among... | Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Jingwen Leng, Minyi Guo, Zhouhan Lin |  |
| 1843 |  |  [Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback](https://aclanthology.org/2025.acl-long.355/) |  | 0 | Learning from human feedback has enabled the alignment of language models (LMs) with human preferences. However, collecting human preferences is expensive and time-consuming, with highly variable annotation quality. An appealing alternative is to distill preferences from LMs as a source of... | Lester James Validad Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi |  |
| 1844 |  |  [SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection](https://aclanthology.org/2025.acl-long.356/) |  | 0 | Automatic evaluation for Open Domain Event Detection (ODED) is a highly challenging task, because ODED is characterized by a vast diversity of un-constrained output labels from various domains. Nearly all existing evaluation methods for ODED usually first construct evaluation benchmarks with... | YiFan Lu, XianLing Mao, Tian Lan, Tong Zhang, YuShi Zhu, Heyan Huang |  |
| 1845 |  |  [The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project](https://aclanthology.org/2025.acl-long.357/) |  | 0 | This paper presents UD-NewsCrawl, the largest Tagalog treebank to date, containing 15.6k trees manually annotated according tothe Universal Dependencies framework. We detail our treebank development process, including data collection, pre-processing, manual annotation, and quality assurance... | Angelina Aspra Aquino, Lester James Validad Miranda, Elsie Marie T. Or |  |
| 1846 |  |  [DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation](https://aclanthology.org/2025.acl-long.358/) |  | 0 | Retrieval-Augmented Generation (RAG) methods have proven highly effective for tasks requiring factual consistency and robust knowledge retrieval. However, large-scale RAG systems consume significant computational resources and are prone to generating “hallucinated” content from Humans. In this... | Jennifer Chen, Aidar Myrzakhan, Yaxin Luo, Hassaan Muhammad Khan, Sondos Mahmoud Bsharat, Zhiqiang Shen |  |
| 1847 |  |  [G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems](https://aclanthology.org/2025.acl-long.359/) |  | 0 | Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstrated remarkable capabilities in various complex tasks, ranging from collaborative problem-solving to autonomous decision-making. However, as these systems become increasingly integrated into critical applications, their... | Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, Chongye Guo, Kun Wang, Yang Wang |  |
| 1848 |  |  [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://aclanthology.org/2025.acl-long.360/) |  | 0 | Large language models (LLMs) are increasingly engaging in moral and ethical reasoning, where criteria for judgment are often unclear, even for humans. While LLM alignment studies cover many areas, one important yet underexplored area is how LLMs make judgments about obligations. This work reveals a... | Bumjin Park, Leejinsil Leejinsil, Jaesik Choi |  |
| 1849 |  |  [LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning](https://aclanthology.org/2025.acl-long.361/) |  | 0 | Legal judgment prediction (LJP) aims to function as a judge by making final rulings based on case claims and facts, which plays a vital role in the judicial domain for supporting court decision-making and improving judicial efficiency. However, existing methods often struggle with logical errors... | Weijie Shi, Han Zhu, Jiaming Ji, Mengze Li, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Sirui Han, Yike Guo |  |
| 1850 |  |  [Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context](https://aclanthology.org/2025.acl-long.362/) |  | 0 | Human processing of idioms heavily depends on interpreting the surrounding context in which they appear. While large language models (LLMs) have achieved impressive performance on idiomaticity detection benchmarks, this success may be driven by reasoning shortcuts present in existing datasets. To... | Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi |  |
| 1851 |  |  [ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation](https://aclanthology.org/2025.acl-long.363/) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts... | Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Zhiyuan Liu, Maosong Sun |  |
| 1852 |  |  [The Cross-linguistic Role of Animacy in Grammar Structures](https://aclanthology.org/2025.acl-long.364/) |  | 0 | Animacy is a semantic feature of nominals and follows a hierarchy: personal pronouns > human > animate > inanimate. In several languages, animacy imposes hard constraints on grammar. While it has been argued that these constraints may emerge from universal soft tendencies, it has been difficult to... | Nina Gregorio, Matteo Gay, Sharon Goldwater, Edoardo M. Ponti |  |
| 1853 |  |  [LexGen: Domain-aware Multilingual Lexicon Generation](https://aclanthology.org/2025.acl-long.365/) |  | 0 | Lexicon or dictionary generation across domains has the potential for societal impact, as it can potentially enhance information accessibility for a diverse user base while preserving language identity. Prior work in the field primarily focuses on bilingual lexical induction, which deals with word... | Ayush Maheshwari, Atul Kumar Singh, N. J. Karthika, Krishnakant Bhatt, Preethi Jyothi, Ganesh Ramakrishnan |  |
| 1854 |  |  [How to Train Long-Context Language Models (Effectively)](https://aclanthology.org/2025.acl-long.366/) |  | 0 | We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development—instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set... | Tianyu Gao, Alexander Wettig, Howard Yen, Danqi Chen |  |
| 1855 |  |  [MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion](https://aclanthology.org/2025.acl-long.367/) |  | 0 | Large Language Models (LLMs) have shown impressive progress in mathematical reasoning. While data augmentation is promising to enhance mathematical problem-solving ability, current approaches are predominantly limited to instance-level modifications—such as rephrasing or generating syntactic... | Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan |  |
| 1856 |  |  [Mining Complex Patterns of Argumentative Reasoning in Natural Language Dialogue](https://aclanthology.org/2025.acl-long.368/) |  | 0 | Argumentation scheme mining is the task of automatically identifying reasoning mechanisms behind argument inferences. These mechanisms provide insights into underlying argument structures and guide the assessment of natural language arguments. Research on argumentation scheme mining, however, has... | Ramon RuizDolz, Zlata Kikteva, John Lawrence |  |
| 1857 |  |  [OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use](https://aclanthology.org/2025.acl-long.369/) |  | 0 | The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution of multi-modal large language models ((M)LLMs), this dream is closer to reality, as (M)LLM-based Agents using computers, mobile phones and web... | Xueyu Hu, Tao Xiong, Biao Yi, Zishu Wei, Ruixuan Xiao, Yurun Chen, Jiasheng Ye, Meiling Tao, Xiangxin Zhou, Ziyu Zhao, Yuhuai Li, Shengze Xu, Shenzhi Wang, Xinchen Xu, Shuofei Qiao, Zhaokai Wang, Kun Kuang, Tieyong Zeng, Liang Wang, Jiwei Li, Yuchen Eleanor Jiang, Wangchunshu Zhou, Guoyin Wang, Keting Yin, Zhou Zhao, Hongxia Yang, Fan Wu, Shengyu Zhang, Fei Wu |  |
| 1858 |  |  [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://aclanthology.org/2025.acl-long.370/) |  | 0 | Our quality audit for three widely used public multilingual speech datasets Mozilla Common Voice 17.0, FLEURS, and VoxPopuli shows that in some languages, these datasets suffer from significant quality issues. We believe addressing these issues will make these datasets more useful as evaluation... | Mingfei Lau, Qian Chen, Yeming Fang, Tingting Xu, Tongzhou Chen, Pavel Golik |  |
| 1859 |  |  [LLM as a Broken Telephone: Iterative Generation Distorts Information](https://aclanthology.org/2025.acl-long.371/) |  | 0 | As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs.Inspired by the “broken telephone” effect in chained human communication, this study investigates whether LLMs similarly distort information through... | Amr Mohamed, Mingmeng Geng, Michalis Vazirgiannis, Guokan Shang |  |
| 1860 |  |  [VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues](https://aclanthology.org/2025.acl-long.372/) |  | 0 | Visually linking matching cues is a crucial ability in daily life, such as identifying the same person in multiple photos based on their cues, even without knowing who they are. Despite the extensive knowledge that vision-language models (VLMs) possess, it remains largely unexplored whether they... | Jianshu Zhang, Dongyu Yao, Renjie Pi, Paul Pu Liang, Yi R. Fung |  |
| 1861 |  |  [Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation](https://aclanthology.org/2025.acl-long.373/) |  | 0 | Quality Estimation (QE) models evaluate the quality of machine translations without reference translations, serving as the reward models for the translation task.Due to the data scarcity, synthetic data generation has emerged as a promising solution.However, synthetic QE data often suffers from... | Xiang Geng, Zhejian Lai, Jiajun Chen, Hao Yang, Shujian Huang |  |
| 1862 |  |  [Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models](https://aclanthology.org/2025.acl-long.374/) |  | 0 | Recent advancements in visual generative models have enabled high-quality image and video generation, opening diverse applications. However, evaluating these models often demands sampling hundreds or thousands of images or videos, making the process computationally expensive, especially for... | Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu |  |
| 1863 |  |  [Large Language Models Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models](https://aclanthology.org/2025.acl-long.375/) |  | 0 | A common use of NLP is to facilitate the understanding of large document collections, with models based on Large Language Models (LLMs) replacing probabilistic topic models. Yet the effectiveness of LLM-based approaches in real-world applications remains under explored. This study measures the... | Zongxia Li, Lorena CalvoBartolomé, Alexander Miserlis Hoyle, Paiheng Xu, Daniel Kofi Stephens, Juan Francisco Fung, Alden Dima, Jordan Lee BoydGraber |  |
| 1864 |  |  [ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models](https://aclanthology.org/2025.acl-long.376/) |  | 0 | Active perception, a crucial human capability, involves setting a goal based on the current understanding of the environment and performing actions to achieve that goal. Despite significant efforts in evaluating Multimodal Large Language Models (MLLMs), active perception has been largely... | Ziyue Wang, Chi Chen, Fuwen Luo, Yurui Dong, Yuanchi Zhang, Yuzhuang Xu, Xiaolong Wang, Peng Li, Yang Liu |  |
| 1865 |  |  [Enough Coin Flips Can Make LLMs Act Bayesian](https://aclanthology.org/2025.acl-long.377/) |  | 0 | Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs use ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely... | Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan |  |
| 1866 |  |  [GAMEBoT: Transparent Assessment of LLM Reasoning in Games](https://aclanthology.org/2025.acl-long.378/) |  | 0 | Large Language Models (LLMs) are increasingly deployed in real-world applications that demand complex reasoning. To track progress, robust benchmarks are required to evaluate their capabilities beyond superficial pattern recognition. However, current LLM reasoning benchmarks often face challenges... | Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han |  |
| 1867 |  |  [A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens](https://aclanthology.org/2025.acl-long.379/) |  | 0 | Text embeddings from large language models (LLMs) have achieved excellent results in tasks such as information retrieval, semantic textual similarity, etc. In this work, we show an interesting finding: when feeding a text into the LLM-based embedder, the obtained text embedding will be able to be... | Zhijie Nie, Richong Zhang, Zhanyu Wu |  |
| 1868 |  |  [Commonsense Reasoning in Arab Culture](https://aclanthology.org/2025.acl-long.380/) |  | 0 | Despite progress in Arabic large language models, such as Jais and AceGPT, their evaluation on commonsense reasoning has largely relied on machine-translated datasets, which lack cultural depth and may introduce Anglocentric biases. Commonsense reasoning is shaped by geographical and cultural... | Abdelrahman Boda Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, Fajri Koto |  |
| 1869 |  |  [AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents](https://aclanthology.org/2025.acl-long.381/) |  | 0 | Multimodal large language models (MLLMs) have enabled LLM-based agents to directly interact with application user interfaces (UIs), enhancing agents’ performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential UI... | Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang |  |
| 1870 |  |  [Translation and Fusion Improves Cross-lingual Information Extraction](https://aclanthology.org/2025.acl-long.382/) |  | 0 | Large language models (LLMs) combined with instruction tuning have shown significant progress in information extraction (IE) tasks, exhibiting strong generalization capabilities to unseen datasets by following annotation guidelines. However, their applicability to low-resource languages remains... | Yang Chen, Vedaant Shah, Alan Ritter |  |
| 1871 |  |  [Conditional Dichotomy Quantification via Geometric Embedding](https://aclanthology.org/2025.acl-long.383/) |  | 0 | Conditional dichotomy, the contrast between two outputs conditioned on the same context, is vital for applications such as debate, defeasible inference, and causal reasoning. Existing methods that rely on semantic similarity often fail to capture the nuanced oppositional dynamics essential for... | Shaobo Cui, Wenqing Liu, Yiyang Feng, Jiawei Zhou, Boi Faltings |  |
| 1872 |  |  [Aligning Large Language Models with Implicit Preferences from User-Generated Content](https://aclanthology.org/2025.acl-long.384/) |  | 0 | Learning from preference feedback is essential for aligning large language models (LLMs) with human values and improving the quality of generated responses. However, existing preference learning methods rely heavily on curated data from humans or advanced LLMs, which is costly and difficult to... | Zhaoxuan Tan, Zheng Li, Tianyi Liu, Haodong Wang, Hyokun Yun, Ming Zeng, Pei Chen, Zhihan Zhang, Yifan Gao, Ruijie Wang, Priyanka Nigam, Bing Yin, Meng Jiang |  |
| 1873 |  |  [VQAGuider: Guiding Multimodal Large Language Models to Answer Complex Video Questions](https://aclanthology.org/2025.acl-long.385/) |  | 0 | Complex video question-answering (VQA) requires in-depth understanding of video contents including object and action recognition as well as video classification and summarization, which exhibits great potential in emerging applications in education and entertainment, etc. Multimodal large language... | Yuyan Chen, Jiyuan Jia, Jiaxin Lu, Siyue Li, Yu Guan, Ming Yang, Qingpei Guo |  |
| 1874 |  |  [Large Language Models are Good Relational Learners](https://aclanthology.org/2025.acl-long.386/) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured... | Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec |  |
| 1875 |  |  [SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data](https://aclanthology.org/2025.acl-long.387/) |  | 0 | Vision-language models (VLMs) work well in tasks ranging from image captioning to visual question answering (VQA), yet they struggle with spatial reasoning, a key skill for understanding our physical world that humans excel at. We find that spatial relations are generally rare in widely used VL... | Michael Ogezi, Freda Shi |  |
| 1876 |  |  [Distilling an End-to-End Voice Assistant Without Instruction Training Data](https://aclanthology.org/2025.acl-long.388/) |  | 0 | Voice assistants, such as Siri and Google Assistant, typically model audio and text separately, resulting in lost speech information and increased complexity. Recent efforts to address this with end-to-end Speech Large Language Models (speech-in, text-out) trained with supervised finetuning (SFT)... | William Barr Held, Yanzhe Zhang, Weiyan Shi, Minzhi Li, Michael J. Ryan, Diyi Yang |  |
| 1877 |  |  [CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](https://aclanthology.org/2025.acl-long.389/) |  | 0 | Metaphors are a crucial way for humans to express complex or subtle ideas by comparing one concept to another, often from a different domain. However, many large language models (LLMs) struggle to interpret and apply metaphors in multi-agent language games, hindering their ability to engage in... | Shuhang Xu, Fangwei Zhong |  |
| 1878 |  |  [CER: Confidence Enhanced Reasoning in LLMs](https://aclanthology.org/2025.acl-long.390/) |  | 0 | Ensuring the reliability of Large Language Models (LLMs) in complex reasoning tasks remains a formidable challenge, particularly in scenarios that demand precise mathematical calculations and knowledge-intensive open-domain generation. In this work, we introduce an uncertainty-aware framework... | Ali Razghandi, Seyed Mohammad Hadi Hosseini, Mahdieh Soleymani Baghshah |  |
| 1879 |  |  [Watermarking Large Language Models: An Unbiased and Low-risk Method](https://aclanthology.org/2025.acl-long.391/) |  | 0 | Recent advancements in large language models (LLMs) have highlighted the risk of misusing them, raising the need for accurate detection of LLM-generated content. In response, a viable solution is to inject imperceptible identifiers into LLMs, known as watermarks. Our research extends the existing... | Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau |  |
| 1880 |  |  [On Synthetic Data Strategies for Domain-Specific Generative Retrieval](https://aclanthology.org/2025.acl-long.392/) |  | 0 | This paper investigates synthetic data generation strategies in developing generative retrieval models for domain-specific corpora, thereby addressing the scalability challenges inherent in manually annotating in-domain queries. We study the data strategies for a two-stage training framework: in... | Haoyang Wen, Jiang Guo, Yi Zhang, Jiarong Jiang, Zhiguo Wang |  |
| 1881 |  |  [LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates](https://aclanthology.org/2025.acl-long.393/) |  | 0 | Recent findings reveal that much of the knowledge in a Transformer-based Large Language Model (LLM) is encoded in its feed-forward (FFN) layers, where each FNN layer can be interpreted as the summation of sub-updates, each corresponding to a weighted column vector from the FFN’s value parameter... | Ying Shen, Lifu Huang |  |
| 1882 |  |  [CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions](https://aclanthology.org/2025.acl-long.394/) |  | 0 | We introduce Conversational Function-Calling Evaluation Through Turn-Level Interactions (CONFETTI), a conversational benchmark designed to evaluate the function-calling capabilities and response quality of large language models (LLMs). Current benchmarks lack comprehensive assessment of LLMs in... | Tamer Alkhouli, Katerina Margatina, James Gung, Raphael Shu, Claudia Zaghi, Monica Sunkara, Yi Zhang |  |
| 1883 |  |  [Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others from Conversational Cues](https://aclanthology.org/2025.acl-long.395/) |  | 0 | Typically, when evaluating Theory of Mind, we consider the beliefs of others to be binary: held or not held. But what if someone is unsure about their own beliefs? How can we quantify this uncertainty? We propose a new suite of tasks, challenging language models (LMs) to model the uncertainty of... | Anthony B. Sicilia, Malihe Alikhani |  |
| 1884 |  |  [Uncertainty in Causality: A New Frontier](https://aclanthology.org/2025.acl-long.396/) |  | 0 | Understanding uncertainty in causality is vital in various domains, including core NLP tasks like event causality extraction, commonsense reasoning, and counterfactual text generation. However, existing literature lacks a comprehensive examination of this area. This survey aims to fill this gap by... | Shaobo Cui, Luca Mouchel, Boi Faltings |  |
| 1885 |  |  [SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs](https://aclanthology.org/2025.acl-long.397/) |  | 0 | Recent calls for pluralistic alignment of Large Language Models (LLMs) encourage adapting models to diverse user preferences. However, most prior work on personalized reward models heavily rely on additional identity information, such as demographic details or a predefined set of preference... | Michael J. Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William Barr Held, Diyi Yang |  |
| 1886 |  |  [When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models](https://aclanthology.org/2025.acl-long.398/) |  | 0 | Metaphor, discussing one concept in terms of another, is abundant in politics and can shape how people understand important issues. We develop a computational approach to measure metaphorical language, focusing on immigration discourse on social media. Grounded in qualitative social science... | Julia Mendelsohn, Ceren Budak |  |
| 1887 |  |  [AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection](https://aclanthology.org/2025.acl-long.399/) |  | 0 | The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments. These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios. However, their use as agents also... | Weidi Luo, Shenghong Dai, Xiaogeng Liu, Suman Banerjee, Huan Sun, Muhao Chen, Chaowei Xiao |  |
| 1888 |  |  [Improving Model Factuality with Fine-grained Critique-based Evaluator](https://aclanthology.org/2025.acl-long.400/) |  | 0 | Factuality evaluation aims to detect factual errors produced by language models (LMs) and hence guide the development of more factual models. Towards this goal, we train a factuality evaluator, FenCE, that provides LM generators with claim-level factuality feedback. In particular, we train FenCE to... | Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn P. Rosé, Daniel Fried, Hejia Zhang |  |
| 1889 |  |  [Building a Long Text Privacy Policy Corpus with Multi-Class Labels](https://aclanthology.org/2025.acl-long.401/) |  | 0 | Legal text poses distinctive challenges for natural language processing. The legal import of a term may depend on omissions, cross-references, or silence, Further, legal text is often susceptible to multiple valid, conflicting interpretations; as the saying goes: a good lawyer’s answer to any... | Florencia MarottaWurgler, David Stein |  |
| 1890 |  |  [R2-MultiOmnia: Leading Multilingual Multimodal Reasoning via Self-Training](https://aclanthology.org/2025.acl-long.402/) |  | 0 | Reasoning is an intricate process that transcends both language and vision; yet, despite its inherently modality-agnostic nature, develop-ing effective multilingual and multimodal reasoning capabilities remains a substantial challenge for Multimodal Large Language Models (MLLMs). They struggle to... | Leonardo Ranaldi, Federico Ranaldi, Giulia Pucci |  |
| 1891 |  |  [When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models](https://aclanthology.org/2025.acl-long.403/) |  | 0 | Modern Large Language Models (LLMs) have shown human-like abilities in many language tasks, sparking interest in comparing LLMs’ and humans’ language processing. In this paper, we try to answer two questions: 1. What makes garden-path sentences hard to understand for humans? 2. Do the same reasons... | Samuel Joseph Amouyal, Aya MeltzerAsscher, Jonathan Berant |  |
| 1892 |  |  [Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models](https://aclanthology.org/2025.acl-long.404/) |  | 0 | Large Language Models (LLMs) have achieved remarkable success in Natural Language Processing (NLP), yet their cross-lingual consistency remains a significant challenge. This paper introduces a novel methodology for efficiently identifying inherent cross-lingual weaknesses in LLMs. Our approach... | Zixiang Xu, Yanbo Wang, Yue Huang, Xiuying Chen, Jieyu Zhao, Meng Jiang, Xiangliang Zhang |  |
| 1893 |  |  [VLSBench: Unveiling Visual Leakage in Multimodal Safety](https://aclanthology.org/2025.acl-long.405/) |  | 0 | Safety concerns of Multimodal large language models (MLLMs) have gradually become an important problem in various applications. Surprisingly, previous works indicate a counterintuitive phenomenon that using textual unlearning to align MLLMs achieves comparable safety performances with MLLMs aligned... | Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao |  |
| 1894 |  |  [Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning](https://aclanthology.org/2025.acl-long.406/) |  | 0 | We introduce Browsing Lost Unformed Recollections, a tip-of-the-tongue known-item search and reasoning benchmark for general AI assistants. BLUR introduces a set of 573 real-world validated questions that demand searching and reasoning across multimodal and multilingual inputs, as well as... | Sky CHWang, Darshan Girish Deshpande, Smaranda Muresan, Anand Kannappan, Rebecca Qian |  |
| 1895 |  |  [Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation](https://aclanthology.org/2025.acl-long.407/) |  | 0 | In this paper, we show that knowledge distillation can be subverted to manipulate language model benchmark scores, revealing a critical vulnerability in current evaluation practices. We introduce “Data Laundering,” a process that enables the covert transfer of benchmark-specific knowledge through... | Jonibek Mansurov, Akhmed Sakip, Alham Fikri Aji |  |
| 1896 |  |  [Conspiracy Theories and Where to Find Them on TikTok](https://aclanthology.org/2025.acl-long.408/) |  | 0 | TikTok has skyrocketed in popularity over recent years, especially among younger audiences. However, there are public concerns about the potential of this platform to promote and amplify harmful content. This study presents the first systematic analysis of conspiracy theories on TikTok. By... | Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales |  |
| 1897 |  |  [Growing Through Experience: Scaling Episodic Grounding in Language Models](https://aclanthology.org/2025.acl-long.409/) |  | 0 | Language models (LMs) require effective episodic grounding—the ability to learn from and apply past experiences—to perform well at physical planning tasks. While current approaches struggle with scalability and integration of episodic memory, which is particularly limited for medium-sized LMs (7B... | Chunhui Zhang, Sirui Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi |  |
| 1898 |  |  [Exploiting the Shadows: Unveiling Privacy Leaks through Lower-Ranked Tokens in Large Language Models](https://aclanthology.org/2025.acl-long.410/) |  | 0 | Large language models (LLMs) play a crucial role in modern applications but face vulnerabilities related to the extraction of sensitive information. This includes unauthorized accesses to internal prompts and retrieval of personally identifiable information (PII) (e.g., in Retrieval-Augmented... | Yuan Zhou, Zhuo Zhang, Xiangyu Zhang |  |
| 1899 |  |  [Attacking Vision-Language Computer Agents via Pop-ups](https://aclanthology.org/2025.acl-long.411/) |  | 0 | Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces. Despite such visual inputs... | Yanzhe Zhang, Tao Yu, Diyi Yang |  |
| 1900 |  |  [Explicit and Implicit Data Augmentation for Social Event Detection](https://aclanthology.org/2025.acl-long.412/) |  | 0 | Social event detection involves identifying and categorizing important events from social media, which relies on labeled data, but annotation is costly and labor-intensive. To address this problem, we propose Augmentation framework for Social Event Detection (SED-Aug), a plug-and-play dual... | Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li, Hu Wang, Preslav Nakov |  |
| 1901 |  |  [In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents](https://aclanthology.org/2025.acl-long.413/) |  | 0 | Large Language Models (LLMs) have made significant progress in open-ended dialogue, yet their inability to retain and retrieve relevant information from long-term interactions limits their effectiveness in applications requiring sustained personalization. External memory mechanisms have been... | Zhen Tan, Jun Yan, IHung Hsu, Rujun Han, Zifeng Wang, Long T. Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, Anand Rajan Iyer, Tianlong Chen, Huan Liu, ChenYu Lee, Tomas Pfister |  |
| 1902 |  |  [Revisiting Classical Chinese Event Extraction with Ancient Literature Information](https://aclanthology.org/2025.acl-long.414/) |  | 0 | The research on classical Chinese event extraction trends to directly graft the complex modeling from English or modern Chinese works, neglecting the utilization of the unique characteristic of this language. We argue that, compared with grafting the sophisticated methods from other languages,... | Xiaoyi Bao, Zhongqing Wang, Jinghang Gu, ChuRen Huang |  |
| 1903 |  |  [Unanswerability Evaluation for Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.415/) |  | 0 | Existing evaluation frameworks for retrieval-augmented generation (RAG) systems focus on answerable queries, but they overlook the importance of appropriately rejecting unanswerable requests. In this paper, we introduce UAEval4RAG, a comprehensive evaluation framework designed to evaluate whether... | Xiangyu Peng, Prafulla Kumar Choubey, Caiming Xiong, ChienSheng Wu |  |
| 1904 |  |  [SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention](https://aclanthology.org/2025.acl-long.416/) |  | 0 | Content analysis breaks down complex and unstructured texts into theory-informed numerical categories. Particularly, in social science, this process usually relies on multiple rounds of manual annotation, domain expert discussion, and rule-based refinement. In this paper, we introduce SCALE, a... | Chengshuai Zhao, Zhen Tan, ChauWai Wong, Xinyan Zhao, Tianlong Chen, Huan Liu |  |
| 1905 |  |  [Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning](https://aclanthology.org/2025.acl-long.417/) |  | 0 | Although large language models demonstrate strong performance across various domains, they still struggle with numerous bad cases in mathematical reasoning. Previous approaches to learning from errors synthesize training data by solely extrapolating from isolated bad cases, thereby failing to... | Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang Xue, Minghui Xu, Baojun Wang, Lanqing Hong, Fei Mi, Lifeng Shang |  |
| 1906 |  |  [RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework](https://aclanthology.org/2025.acl-long.418/) |  | 0 | Retrieval-Augmented Generation (RAG) is a powerful approach that enables large language models (LLMs) to incorporate external knowledge. However, evaluating the effectiveness of RAG systems in specialized scenarios remains challenging due to the high costs of data construction and the lack of... | Kunlun Zhu, Yifan Luo, Dingling Xu, Yukun Yan, Zhenghao Liu, Shi Yu, Ruobing Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun |  |
| 1907 |  |  [A Survey on Patent Analysis: From NLP to Multimodal AI](https://aclanthology.org/2025.acl-long.419/) |  | 0 | Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to... | Homaira Huda Shomee, Zhu Wang, Sathya N. Ravi, Sourav Medya |  |
| 1908 |  |  [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://aclanthology.org/2025.acl-long.420/) |  | 0 | We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context.SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common... | Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao |  |
| 1909 |  |  [MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents](https://aclanthology.org/2025.acl-long.421/) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents; yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce... | Kunlun Zhu, Hongyi Du, Zhaochen Hong, Xiaocheng Yang, Shuyi Guo, Zhe Wang, Zhenhailong Wang, Cheng Qian, Robert Tang, Heng Ji, Jiaxuan You |  |
| 1910 |  |  [Sinhala Encoder-only Language Models and Evaluation](https://aclanthology.org/2025.acl-long.422/) |  | 0 | Recently, language models (LMs) have produced excellent results in many natural language processing (NLP) tasks. However, their effectiveness is highly dependent on available pre-training resources, which is particularly challenging for low-resource languages such as Sinhala. Furthermore, the... | Tharindu Ranasinghe, Hansi Hettiarachchi, Nadeesha Chathurangi Naradde Vidana Pathirana, Damith Premasiri, Lasitha Uyangodage, Isuri Anuradha Nanomi Arachchige, Alistair Plum, Paul Rayson, Ruslan Mitkov |  |
| 1911 |  |  [LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing](https://aclanthology.org/2025.acl-long.423/) |  | 0 | The paper explores the performance of LLMs in the context of multi-dimensional analytic writing assessments, i.e. their ability to provide both scores and comments based on multiple assessment criteria. Using a corpus of literature reviews written by L2 graduate students and assessed by human... | Zhengxiang Wang, Veronika Makarova, Zhi Li, Jordan Kodner, Owen Rambow |  |
| 1912 |  |  [SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?](https://aclanthology.org/2025.acl-long.424/) |  | 0 | Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model’s utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs–a key subset of the LLM family–have remained unexplored in the... | Haomin Zhuang, Yihua Zhang, Kehan Guo, Jinghan Jia, Gaowen Liu, Sijia Liu, Xiangliang Zhang |  |
| 1913 |  |  [Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges](https://aclanthology.org/2025.acl-long.425/) |  | 0 | Understanding pragmatics—the use of language in context—is crucial for developing NLP systems capable of interpreting nuanced language use. Despite recent advances in language technologies, including large language models, evaluating their ability to handle pragmatic phenomena such as implicatures... | Bolei Ma, Yuting Li, Wei Zhou, Ziwei Gong, Yang Janet Liu, Katja Jasinskaja, Annemarie Friedrich, Julia Hirschberg, Frauke Kreuter, Barbara Plank |  |
| 1914 |  |  [LocAgent: Graph-Guided LLM Agents for Code Localization](https://aclanthology.org/2025.acl-long.426/) |  | 0 | Code localization–identifying precisely where in a codebase changes need to be made–is a fundamental yet challenging task in software maintenance. Existing approaches struggle to efficiently navigate complex codebases when identifying relevant code snippets.The challenge lies in bridging natural... | Zhaoling Chen, Robert Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor K. Prasanna, Arman Cohan, Xingyao Wang |  |
| 1915 |  |  [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://aclanthology.org/2025.acl-long.427/) |  | 0 | Despite progress in comment-aware multimodal and multilingual summarization for English and Chinese, research in Indian languages remains limited. This study addresses this gap by introducing COSMMIC, a pioneering comment-sensitive multimodal, multilingual dataset featuring nine major Indian... | Raghvendra Kumar, Mohammed Salman S. A, Aryan Sahu, Tridib Nandi, Pragathi Y. P., Sriparna Saha, José G. Moreno |  |
| 1916 |  |  [Mind the Gap: Static and Interactive Evaluations of Large Audio Models](https://aclanthology.org/2025.acl-long.428/) |  | 0 | As AI chatbots become ubiquitous, voice interaction presents a compelling way to enable rapid, high-bandwidth communication for both semantic and social signals. This has driven research into Large Audio Models (LAMs) to power voice-native experiences. However, aligning LAM development with user... | Minzhi Li, William Barr Held, Michael J. Ryan, Kunat Pipatanakul, Potsawee Manakul, Hao Zhu, Diyi Yang |  |
| 1917 |  |  [Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu](https://aclanthology.org/2025.acl-long.429/) |  | 0 | In-context machine translation (MT) with large language models (LLMs) is a promising approach for low-resource MT, as it can readily take advantage of linguistic resources such as grammar books and dictionaries.Such resources are usually selectively integrated into the prompt so that LLMs can... | Renhao Pei, Yihong Liu, Peiqin Lin, François Yvon, Hinrich Schütze |  |
| 1918 |  |  [CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs](https://aclanthology.org/2025.acl-long.430/) |  | 0 | Chinese, as a linguistic system rich in depth and complexity, is characterized by distinctive elements such as ancient poetry, proverbs, idioms, and other cultural constructs. However, current Large Language Models (LLMs) face limitations in these specialized domains, highlighting the need for the... | Jizhan Fang, Tianhe Lu, Yunzhi Yao, Ziyan Jiang, Xin Xu, Huajun Chen, Ningyu Zhang |  |
| 1919 |  |  [TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection](https://aclanthology.org/2025.acl-long.431/) |  | 0 | The proliferation of large language models (LLMs) has introduced unprecedented challenges in fake news detection due to benchmark data contamination (BDC), where evaluation benchmarks are inadvertently memorized during the pre-training, leading to the inflated performance metrics. Traditional... | Cheng Xu, Nan Yan |  |
| 1920 |  |  [Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility](https://aclanthology.org/2025.acl-long.432/) |  | 0 | We present a hierarchy of natural language understanding abilities and argue for the importance of moving beyond assessments of understanding at the lexical and sentence levels to the discourse level. We propose the task of anaphora accessibility as a diagnostic for assessing discourse... | Xiaomeng Zhu, Zhenghao Zhou, Simon Charlow, Robert Frank |  |
| 1921 |  |  [Large Language and Reasoning Models are Shallow Disjunctive Reasoners](https://aclanthology.org/2025.acl-long.433/) |  | 0 | Large Language Models (LLMs) have been found to struggle with systematic reasoning. Even on tasks where they appear to perform well, their performance often depends on shortcuts, rather than on genuine reasoning abilities, leading them to collapse on out-of-distribution (OOD) examples.... | Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert |  |
| 1922 |  |  [Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation](https://aclanthology.org/2025.acl-long.434/) |  | 0 | Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence tasks often train models to directly generate the target output. Recent work has shown that guiding models with intermediate steps—such as keywords, outlines, or reasoning chains—can significantly improve performance,... | Senyu Li, Zipeng Sun, Jiayi Wang, Xue Liu, Pontus Stenetorp, Siva Reddy, David Ifeoluwa Adelani |  |
| 1923 |  |  [Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce](https://aclanthology.org/2025.acl-long.435/) |  | 0 | Language is a form of symbolic capital that affects people’s lives in many ways (Bourdieu1977,1991). As a powerful means of communication, it reflects identities, cultures, traditions, and societies more broadly. Therefore, data in a given language should be regarded as more than just a collection... | Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad |  |
| 1924 |  |  [BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages](https://aclanthology.org/2025.acl-long.436/) |  | 0 | People worldwide use language in subtle and complex ways to express emotions. Although emotion recognition–an umbrella term for several NLP tasks–impacts various applications within NLP and beyond, most work in this area has focused on high-resource languages. This has led to significant... | Shamsuddeen Hassan Muhammad, Nedjma Ousidhoum, Idris Abdulmumin, Jan Philip Wahle, Terry Ruas, Meriem Beloucif, Christine de Kock, Nirmal Surange, Daniela Teodorescu, Ibrahim Said Ahmad, David Ifeoluwa Adelani, Alham Fikri Aji, Felermino D. M. A. Ali, Ilseyar Alimova, Vladimir Araujo, Nikolay Babakov, Naomi Baes, AnaMaria Bucur, Andiswa Bukula, Guanqun Cao, Rodrigo Tufino Cardenas, Rendi Chevi, Chiamaka Ijeoma Chukwuneke, Alexandra Ciobotaru, Daryna Dementieva, Murja Sani Gadanya, Robert Geislinger, Bela Gipp, Oumaima Hourrane, Oana Ignat, Falalu Ibrahim Lawan, Rooweither Mabuya, Rahmad Mahendra, Vukosi Marivate, Alexander Panchenko, Andrew Piper, Charles Henrique Porto Ferreira, Vitaly Protasov, Samuel Rutunda, Manish Shrivastava, Aura Cristina Udrea, Lilian Diana Awuor Wanzare, Sophie Wu, Florian Valentin Wunderlich, Hanif Muhammad Zhafran, Tianhui Zhang, Yi Zhou, Saif M. Mohammad |  |
| 1925 |  |  [SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation](https://aclanthology.org/2025.acl-long.437/) |  | 0 | As language models evolve to tackle complex, multifaceted tasks, their evaluation must adapt to capture this intricacy. A granular, skill-specific understanding of model capabilities can empower researchers to make informed model development plans. In this paper, we introduce SkillVerse, an... | Yufei Tian, Jiao Sun, Nanyun Peng, Zizhao Zhang |  |
| 1926 |  |  [CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era](https://aclanthology.org/2025.acl-long.438/) |  | 0 | Retrieval from graph data is crucial for augmenting large language models (LLM) with both open-domain knowledge and private enterprise data, and it is also a key component in the recent GraphRAG system (CITATION). Despite decades of research on knowledge graphs and knowledge base question... | Yanlin Feng, Simone Papicchio, Sajjadur Rahman |  |
| 1927 |  |  [Empathy Prediction from Diverse Perspectives](https://aclanthology.org/2025.acl-long.439/) |  | 0 | A person’s perspective on a topic can influence their empathy towards a story. To investigate the use of personal perspective in empathy prediction, we collected a dataset, EmpathyFromPerspectives, where a user rates their empathy towards a story by a person with a different perspective on a... | Francine Chen, Scott A. Carter, Tatiana Lau, Nayeli Suseth Bravo, Sumanta Bhattacharyya, Kate A. Sieck, Charlene C. Wu |  |
| 1928 |  |  [Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice](https://aclanthology.org/2025.acl-long.440/) |  | 0 | In psychological practice, standardized questionnaires serve as essential tools for assessing mental health through structured, clinically-validated questions (i.e., items). While social media platforms offer rich data for mental health screening, computational approaches often bypass these... | Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando |  |
| 1929 |  |  [INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models](https://aclanthology.org/2025.acl-long.441/) |  | 0 | Large language models (LLMs) excel at answering questions but remain passive learners—absorbing static data without the ability to question and refine knowledge. This paper explores how LLMs can transition to interactive, question-driven learning through student-teacher dialogues. We introduce... | Aum Kendapadi, Kerem Zaman, Rakesh R. Menon, Shashank Srivastava |  |
| 1930 |  |  [Circuit Stability Characterizes Language Model Generalization](https://aclanthology.org/2025.acl-long.442/) |  | 0 | Extensively evaluating the capabilities of (large) language models is difficult. Rapid development of state-of-the-art models induce benchmark saturation, while creating more challenging datasets is labor-intensive. Inspired by the recent developments in mechanistic interpretability, we introduce... | Alan Sun |  |
| 1931 |  |  [Comparing LLM-generated and human-authored news text using formal syntactic theory](https://aclanthology.org/2025.acl-long.443/) |  | 0 | This study provides the first comprehensive comparison of New York Times-style text generated by six large language models against real, human-authored NYT writing. The comparison is based on a formal syntactic theory. We use Head-driven Phrase Structure Grammar (HPSG) to analyze the grammatical... | Olga Zamaraeva, Dan Flickinger, Francis Bond, Carlos GómezRodríguez |  |
| 1932 |  |  [Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes](https://aclanthology.org/2025.acl-long.444/) |  | 0 | Large Language Models (LLMs) are often used as automated judges to evaluate text, but their effectiveness can be hindered by various unintentional biases. We propose using linear classifying probes, trained by leveraging differences between contrasting pairs of prompts, to directly access LLMs’... | Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen |  |
| 1933 |  |  [White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs](https://aclanthology.org/2025.acl-long.445/) |  | 0 | Social biases can manifest in language agency. However, very limited research has investigated such biases in Large Language Model (LLM)-generated content. In addition, previous works often rely on string-matching techniques to identify agentic and communal words within texts, falling short of... | Yixin Wan, KaiWei Chang |  |
| 1934 |  |  [AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions](https://aclanthology.org/2025.acl-long.446/) |  | 0 | Modern Slavery Acts mandate that corporations disclose their efforts to combat modern slavery, aiming to enhance transparency and strengthen practices for its eradication. However, verifying these statements remains challenging due to their complex, diversified language and the sheer number of... | Adriana Eufrosina Bora, Akshatha Arodi, Duoyi Zhang, Jordan Bannister, Mirko Bronzi, Arsène Fansi Tchango, Md. Abul Bashar, Richi Nayak, Kerrie L. Mengersen |  |
| 1935 |  |  [Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence](https://aclanthology.org/2025.acl-long.447/) |  | 0 | Dense retrieval models are commonly used in Information Retrieval (IR) applications, such as Retrieval-Augmented Generation (RAG). Since they often serve as the first step in these systems, their robustness is critical to avoid downstream failures. In this work, we repurpose a relation extraction... | Mohsen Fayyaz, Ali Modarressi, Hinrich Schütze, Nanyun Peng |  |
| 1936 |  |  [SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence](https://aclanthology.org/2025.acl-long.448/) |  | 0 | Providing Language Models (LMs) with relevant evidence in the context (either via retrieval or user-provided) can significantly improve their ability to provide better-grounded responses. However, recent studies have found that LMs often struggle to fully comprehend and utilize key evidence from... | Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong |  |
| 1937 |  |  [The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects](https://aclanthology.org/2025.acl-long.449/) |  | 0 | Recent large-scale T2I models like DALLE-3 have made progress in reducing gender stereotypes when generating single-person images. However, significant biases remain when generating images with more than one person. To systematically evaluate this, we propose the \*\*Paired Stereotype Test... | Yixin Wan, KaiWei Chang |  |
| 1938 |  |  [Mitigating Shortcut Learning with InterpoLated Learning](https://aclanthology.org/2025.acl-long.450/) |  | 0 | Empirical risk minimization (ERM) incentivizes models to exploit shortcuts, i.e., spurious correlations between input attributes and labels that are prevalent in the majority of the training data but unrelated to the task at hand. This reliance hinders generalization on minority examples, where... | Michalis Korakakis, Andreas Vlachos, Adrian Weller |  |
| 1939 |  |  [Toward Automatic Discovery of a Canine Phonetic Alphabet](https://aclanthology.org/2025.acl-long.451/) |  | 0 | Dogs communicate intelligently but little is known about the phonetic properties of their vocalization communication. For the first time, this paper presents an iterative algorithm inspired by human phonetic discovery, which is based on minimal pairs that determine phonemes by distinguishing... | Theron S. Wang, Xingyuan Li, Hridayesh Lekhak, Tuan Minh Dang, Mengyue Wu, Kenny Q. Zhu |  |
| 1940 |  |  [DavIR: Data Selection via Implicit Reward for Large Language Models](https://aclanthology.org/2025.acl-long.452/) |  | 0 | We introduce DavIR, a model-based data selection method for post-training Large Language Models. DavIR generalizes Reducible Holdout Loss to core-set selection problem of causal language modeling, and quantifies the learnability of a given datum with respect to a pre-trained LLM based on relative... | Haotian Zhou, Tingkai Liu, Qianli Ma, Yufeng Zhang, Jianbo Yuan, Pengfei Liu, Yang You, Hongxia Yang |  |
| 1941 |  |  [Byte Latent Transformer: Patches Scale Better Than Tokens](https://aclanthology.org/2025.acl-long.453/) |  | 0 | We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the... | Artidoro Pagnoni, Ramakanth Pasunuru, Pedro Rodríguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu, Jason E. Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srini Iyer |  |
| 1942 |  |  [DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising](https://aclanthology.org/2025.acl-long.454/) |  | 0 | Pretrained language models have significantly advanced performance across various natural language processing tasks. However, adversarial attacks continue to pose a critical challenge to system built using these models, as they can be exploited with carefully crafted adversarial texts. Inspired by... | Zhenhao Li, Huichi Zhou, Marek Rei, Lucia Specia |  |
| 1943 |  |  [Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models](https://aclanthology.org/2025.acl-long.455/) |  | 0 | Spatial transcriptomic technologies enable measuring gene expression profile and spatial information of cells in tissues simultaneously. Clustering of captured cells/spots in the spatial transcriptomic data is crucial for understanding tissue niches and uncovering disease-related changes.Current... | Huanhuan Wei, Xiao Luo, Hongyi Yu, Jinping Liang, Luning Yang, Lixing Lin, Alexandra Popa, Xiting Yan |  |
| 1944 |  |  [Culture Matters in Toxic Language Detection in Persian](https://aclanthology.org/2025.acl-long.456/) |  | 0 | Toxic language detection is crucial for creating safer online environments and limiting the spread of harmful content. While toxic language detection has been under-explored in Persian, the current work compares different methods for this task, including fine-tuning, data enrichment, zero-shot and... | Zahra Bokaei, Walid Magdy, Bonnie Webber |  |
| 1945 |  |  [Bitnet.cpp: Efficient Edge Inference for Ternary LLMs](https://aclanthology.org/2025.acl-long.457/) |  | 0 | The advent of 1-bit large language models (LLMs), led by BitNet b1.58, has spurred interest in ternary LLMs. Despite this, research and practical applications focusing on efficient edge inference for ternary LLMs remain scarce. To bridge this gap, we introduce Bitnet.cpp, an inference system... | Jinheng Wang, Hansong Zhou, Ting Song, Shijie Cao, Yan Xia, Ting Cao, Jianyu Wei, Shuming Ma, Hongyu Wang, Furu Wei |  |
| 1946 |  |  [Instance-Selection-Inspired Undersampling Strategies for Bias Reduction in Small and Large Language Models for Binary Text Classification](https://aclanthology.org/2025.acl-long.458/) |  | 0 | Skewness in imbalanced datasets affects Automatic Text Classification (ATC), leading to classifier bias toward the majority classes. This work examines undersampling methods to mitigate such bias in Small and Large Language Model (SLMs and LLMs) classifiers. Based on the limitations found in... | Guilherme Fonseca, Washington Cunha, Gabriel Prenassi, Marcos André Gonçalves, Leonardo Chaves Dutra da Rocha |  |
| 1947 |  |  [Forward Knows Efficient Backward Path: Saliency-Guided Memory-Efficient Fine-tuning of Large Language Models](https://aclanthology.org/2025.acl-long.459/) |  | 0 | Fine-tuning is widely recognized as a crucial process for aligning large language models (LLMs) with human intentions. However, the substantial memory requirements associated with fine-tuning pose a significant barrier to extending the applicability of LLMs. While parameter-efficient fine-tuning... | Yeachan Kim, SangKeun Lee |  |
| 1948 |  |  [Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning](https://aclanthology.org/2025.acl-long.460/) |  | 0 | Medical Large Vision-Language Models (Med-LVLMs) often exhibit suboptimal attention distribution on visual inputs, leading to hallucinated or inaccurate outputs. Existing methods primarily rely on inference-time interventions, which are limited in attention adaptation or require additional... | Aofei Chang, Le Huang, Alex James Boyd, Parminder Bhatia, Taha A. KassHout, Cao Xiao, Fenglong Ma |  |
| 1949 |  |  [LLMs + Persona-Plug = Personalized LLMs](https://aclanthology.org/2025.acl-long.461/) |  | 0 | Personalization plays a critical role in numerous language tasks and applications, since users with the same requirements may prefer diverse outputs based on their interests. This has led to the development of various personalized approaches aimed at adapting large language models (LLMs) to... | Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou |  |
| 1950 |  |  [Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition](https://aclanthology.org/2025.acl-long.462/) |  | 0 | Large language models possess general linguistic abilities but acquire language less efficiently than humans. This study proposes a method for integrating the developmental characteristics of working memory during the critical period, a stage when human language acquisition is particularly... | Masato Mita, Ryo Yoshida, Yohei Oseki |  |
| 1951 |  |  [IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data](https://aclanthology.org/2025.acl-long.463/) |  | 0 | Causal discovery is fundamental to scientific research, yet traditional statistical algorithms face significant challenges, including expensive data collection, redundant computation for known relations, and unrealistic assumptions. While recent LLM-based methods excel at identifying commonly known... | Tao Feng, Lizhen Qu, Niket Tandon, Gholamreza Haffari |  |
| 1952 |  |  [INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages](https://aclanthology.org/2025.acl-long.464/) |  | 0 | Slot-filling and intent detection are well-established tasks in Conversational AI. However, current large-scale benchmarks for these tasks often exclude evaluations of low-resource languages and rely on translations from English benchmarks, thereby predominantly reflecting Western-centric concepts.... | Hao Yu, Jesujoba Oluwadara Alabi, Andiswa Bukula, Jian Yun Zhuang, EnShiun Annie Lee, Tadesse Kebede Guge, Israel Abebe Azime, Happy Buzaaba, Blessing Kudzaishe Sibanda, Godson Koffi Kalipe, Jonathan Mukiibi, Salomon Kabongo Kabenamualu, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Dietrich Klakow, David Ifeoluwa Adelani |  |
| 1953 |  |  [Boosting Long-Context Information Seeking via Query-Guided Activation Refilling](https://aclanthology.org/2025.acl-long.465/) |  | 0 | Processing long contexts poses a significant challenge for large language models (LLMs) due to their inherent context window limitations and the computational burden of extensive key-value (KV) activations, which severely impact efficiency. For information-seeking tasks, full context perception is... | Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian |  |
| 1954 |  |  [Efficient Pretraining Data Selection for Language Models via Multi-Actor Collaboration](https://aclanthology.org/2025.acl-long.466/) |  | 0 | Efficient data selection is crucial to accelerate the pretraining of language model (LMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LM pretraining. To... | Tianyi Bai, Ling Yang, Zhen Hao Wong, Fupeng Sun, Xinlin Zhuang, Jiahui Peng, Chi Zhang, Lijun Wu, Jiantao Qiu, Wentao Zhang, Binhang Yuan, Conghui He |  |
| 1955 |  |  [AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection](https://aclanthology.org/2025.acl-long.467/) |  | 0 | With the continuously expanding parameters, efficiently adapting large language models to downstream tasks is crucial in resource-limited conditions. Many parameter-efficient fine-tuning methods have emerged to address this challenge. However, they lack flexibility, like LoRA requires manually... | Han Liu, Changya Li, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Wei Wang, Hong Yu |  |
| 1956 |  |  [KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph](https://aclanthology.org/2025.acl-long.468/) |  | 0 | In this paper, we aim to improve the reasoning ability of large language models(LLMs) over knowledge graphs(KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent,... | Jinhao Jiang, Kun Zhou, Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, JiRong Wen |  |
| 1957 |  |  [Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases](https://aclanthology.org/2025.acl-long.469/) |  | 0 | Parameter-efficient fine-tuning (PEFT) addresses the memory footprint issue of full fine-tuning by modifying only a subset of model parameters. However, on datasets exhibiting spurious correlations, we observed that PEFT slows down the model’s convergence on unbiased examples, while the convergence... | Mingyu Lee, Yeachan Kim, WingLam Mok, SangKeun Lee |  |
| 1958 |  |  [Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings](https://aclanthology.org/2025.acl-long.470/) |  | 0 | The large language model (LLM)-as-judge paradigm has been used to meet the demand for a cheap, reliable, and fast evaluation of model outputs during AI system development and post-deployment monitoring. While judge models—LLMs finetuned to specialize in assessing and critiquing model outputs—have... | Austin Xu, Srijan Bansal, Yifei Ming, Semih Yavuz, Shafiq Joty |  |
| 1959 |  |  [On the Reliability of Large Language Models for Causal Discovery](https://aclanthology.org/2025.acl-long.471/) |  | 0 | This study investigates the efficacy of Large Language Models (LLMs) in causal discovery. Using newly available open-source LLMs, OLMo and BLOOM, which provide access to their pre-training corpora, we investigate how LLMs address causal discovery through three research questions. We examine: (i)... | Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari |  |
| 1960 |  |  [Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts](https://aclanthology.org/2025.acl-long.472/) |  | 0 | The recent progress in Vision-Language Models (VLMs) has broadened the scope of multimodal applications. However, evaluations often remain limited to functional tasks, neglecting abstract dimensions such as personality traits and human values. To address this gap, we introduce Value-Spectrum, a... | Jingxuan Li, Yuning Yang, Shengqi Yang, Linfan Zhang, Ying Nian Wu |  |
| 1961 |  |  [TeRDy: Temporal Relation Dynamics through Frequency Decomposition for Temporal Knowledge Graph Completion](https://aclanthology.org/2025.acl-long.473/) |  | 0 | Temporal knowledge graph completion aims to predict missing facts in a knowledge graph by leveraging temporal information. Existing methods often struggle to capture both the long-term changes and short-term variability of relations, which are crucial for accurate prediction. In this paper, we... | Ziyang Liu, Chaokun Wang |  |
| 1962 |  |  [Incorporating Domain Knowledge into Materials Tokenization](https://aclanthology.org/2025.acl-long.474/) |  | 0 | While language models are increasingly utilized in materials science, typical models rely on frequency-centric tokenization methods originally developed for natural language processing. However, these methods frequently produce excessive fragmentation and semantic loss, failing to maintain the... | Yerim Oh, JunHyung Park, Junho Kim, SungHo Kim, SangKeun Lee |  |
| 1963 |  |  [PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](https://aclanthology.org/2025.acl-long.475/) |  | 0 | Large Language Models (LLMs) excel in various domains but pose inherent privacy risks. Existing methods to evaluate privacy leakage in LLMs often use memorized prefixes or simple instructions to extract data, both of which well-alignment models can easily block. Meanwhile, Jailbreak attacks bypass... | Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang |  |
| 1964 |  |  [Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](https://aclanthology.org/2025.acl-long.476/) |  | 0 | Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking... | Rana Muhammad Shahroz, Zhen Tan, Sukwon Yun, Charles Fleming, Tianlong Chen |  |
| 1965 |  |  [Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training](https://aclanthology.org/2025.acl-long.477/) |  | 0 | With the increasing prominence of large language models (LLMs), evaluating their text-generation capabilities has become an essential research challenge. Although LLM-based evaluation methods exhibit robust performance, the inherent stochastic nature of the LLM generation process introduces a... | Shusheng Li, Jiale Li, Yifei Qu, Xinwei Shi, Yanliang Guo, Ziyi He, Yubo Wang, Wenjun Tan |  |
| 1966 |  |  [Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases](https://aclanthology.org/2025.acl-long.478/) |  | 0 | Pretraining language models on formal language can improve their acquisition of natural language. Which features of the formal language impart an inductive bias that leads to effective transfer? Drawing on insights from linguistics and complexity theory, we hypothesize that effective transfer... | Michael Y. Hu, Jackson Petty, Chuan Shi, William Merrill, Tal Linzen |  |
| 1967 |  |  [When to Speak, When to Abstain: Contrastive Decoding with Abstention](https://aclanthology.org/2025.acl-long.479/) |  | 0 | Large Language Models (LLMs) demonstrate exceptional performance across diverse tasks by leveraging pre-trained (i.e., parametric) and external (i.e., contextual) knowledge. While substantial efforts have been made to enhance the utilization of both forms of knowledge, situations in which models... | Hyuhng Joon Kim, Youna Kim, Sanggoo Lee, Taeuk Kim |  |
| 1968 |  |  [On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs](https://aclanthology.org/2025.acl-long.480/) |  | 0 | Evidence-enhanced detectors present remarkable abilities in identifying malicious social text. However, the rise of large language models (LLMs) brings potential risks of evidence pollution to confuse detectors. This paper explores potential manipulation scenarios including basic pollution, and... | Herun Wan, Minnan Luo, Zhixiong Su, Guang Dai, Xiang Zhao |  |
| 1969 |  |  [Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents](https://aclanthology.org/2025.acl-long.481/) |  | 0 | Homans’ Social Exchange Theory (SET) is widely recognized as a basic framework for understanding the formation and emergence of human civilizations and social structures. In social science, this theory is typically studied based on simple simulation experiments or real-world human studies, both of... | Lei Wang, Zheqing Zhang, Xu Chen |  |
| 1970 |  |  [A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models](https://aclanthology.org/2025.acl-long.482/) |  | 0 | Large Language Models (LLMs) are cutting-edge generative AI models built on transformer architecture, which tend to be highly memory-intensive when performing real-time inference. Various strategies have been developed to enhance the end-to-end inference speed for LLMs, one of which is speculative... | Jiesong Liu, Brian Park, Xipeng Shen |  |
| 1971 |  |  [If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?](https://aclanthology.org/2025.acl-long.483/) |  | 0 | Recent work in computational psycholinguistics has revealed intriguing parallels between attention mechanisms and human memory retrieval, focusing primarily on vanilla Transformers that operate on token-level representations. However, computational psycholinguistic research has also established... | Ryo Yoshida, Shinnosuke Isono, Kohei Kajikawa, Taiga Someya, Yushi Sugimoto, Yohei Oseki |  |
| 1972 |  |  [Aligning VLM Assistants with Personalized Situated Cognition](https://aclanthology.org/2025.acl-long.484/) |  | 0 | Vision-language models (VLMs) aligned with general human objectives, such as being harmless and hallucination-free, have become valuable assistants of humans in managing visual tasks. However, people with diversified backgrounds have different cognition even in the same situation. Consequently,... | Yongqi Li, Shen Zhou, Xiaohu Li, Xin Miao, Jintao Wen, Mayi Xu, Jianhao Chen, Birong Pan, Hankun Kang, Yuanyuan Zhu, Ming Zhong, Tieyun Qian |  |
| 1973 |  |  [Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models](https://aclanthology.org/2025.acl-long.485/) |  | 0 | Large language models have shown remarkable performance across a wide range of language tasks, owing to their exceptional capabilities in context modeling. The most commonly used method of context modeling is full self-attention, as seen in standard decoder-only Transformers. Although powerful,... | Zhisong Zhang, Yan Wang, Xinting Huang, Tianqing Fang, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu |  |
| 1974 |  |  [Faster Speculative Decoding via Effective Draft Decoder with Pruned Candidate Tree](https://aclanthology.org/2025.acl-long.486/) |  | 0 | Speculative Decoding (SD) is a promising method for reducing the inference latency of large language models (LLMs). A well-designed draft model and an effective draft candidate tree construction method are key to enhancing the acceleration effect of SD. In this paper, we first propose the Effective... | Huanran Zheng, Xiaoling Wang |  |
| 1975 |  |  [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://aclanthology.org/2025.acl-long.487/) |  | 0 | Supervised fine-tuning (SFT) is widely used to align large language models (LLMs) with information extraction (IE) tasks, such as named entity recognition (NER). However, annotating such fine-grained labels and training domain-specific models is costly. Existing works typically train a unified... | Zhuojun Ding, Wei Wei, Chenghao Fan |  |
| 1976 |  |  [Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents](https://aclanthology.org/2025.acl-long.488/) |  | 0 | Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as... | Tao Wu, Jingyuan Chen, Wang Lin, Mengze Li, Yumeng Zhu, Ang Li, Kun Kuang, Fei Wu |  |
| 1977 |  |  [CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction](https://aclanthology.org/2025.acl-long.489/) |  | 0 | Computer-aided design (CAD) is crucial in prototyping 3D objects through geometric instructions (i.e., CAD programs). In practical design workflows, designers often engage in time-consuming reviews and refinements of these prototypes by comparing them with reference images. To bridge this gap, we... | Jiali Chen, Xusen Hei, Hongfei Liu, Yuancheng Wei, Zikun Deng, Jiayuan Xie, Yi Cai, Qing Li |  |
| 1978 |  |  [Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling](https://aclanthology.org/2025.acl-long.490/) |  | 0 | Despite their outstanding capabilities, large language models (LLMs) are prone to hallucination and producing factually incorrect information. This challenge has spurred efforts in attributed text generation, which prompts LLMs to generate content with supporting evidence. In this paper, we propose... | Junyi Li, Hwee Tou Ng |  |
| 1979 |  |  [The Lawyer That Never Thinks: Consistency and Fairness as Keys to Reliable AI](https://aclanthology.org/2025.acl-long.491/) |  | 0 | Large Language Models (LLMs) are increasingly used in high-stakes domains like law and research, yet their inconsistencies and response instability raise concerns about trustworthiness. This study evaluates six leading LLMs—GPT-3.5, GPT-4, Claude, Gemini, Mistral, and LLaMA 2—on rationality,... | Dana R. Alsagheer, Abdulrahman Kamal, Mohammad Kamal, Cosmo Yang Wu, Weidong Shi |  |
| 1980 |  |  [Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean](https://aclanthology.org/2025.acl-long.492/) |  | 0 | We introduce the ̲Korean ̲Grammar ̲Evaluation Bench ̲Mark (KoGEM), designed to assess the linguistic competence of LLMs and humans in Korean. KoGEM consists of 1.5k multiple-choice QA pairs covering five main categories and 16 subcategories. The zero-shot evaluation of 27 LLMs of various sizes and... | SungHo Kim, Nayeon Kim, Taehee Jeon, SangKeun Lee |  |
| 1981 |  |  [SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods](https://aclanthology.org/2025.acl-long.493/) |  | 0 | As speech generation technology advances, the risk of misuse through deepfake audio has become a pressing concern, which underscores the critical need for robust detection systems. However, many existing speech deepfake datasets are limited in scale and diversity, making it challenging to train... | Wen Huang, Yanmei Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian |  |
| 1982 |  |  [ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation](https://aclanthology.org/2025.acl-long.494/) |  | 0 | Code generation plays a crucial role in various tasks, such as code auto-completion and mathematical reasoning. Previous work has proposed numerous methods to enhance code generation performance, including integrating feedback from the compiler. Inspired by this, we present ReflectionCoder, a novel... | Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li |  |
| 1983 |  |  [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior](https://aclanthology.org/2025.acl-long.495/) |  | 0 | Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between... | Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao |  |
| 1984 |  |  [Enhancing Neural Machine Translation Through Target Language Data: A kNN-LM Approach for Domain Adaptation](https://aclanthology.org/2025.acl-long.496/) |  | 0 | Neural machine translation (NMT) has advanced significantly, yet challenges remain in adapting to new domains . In scenarios where bilingual data is limited, this issue is further exacerbated. To address this, we propose kNN-LM-NMT, a method that leverages semantically similar target language... | Abudurexiti Reheman, Hongyu Liu, Junhao Ruan, Abudukeyumu Abudula, Yingfeng Luo, Tong Xiao, JingBo Zhu |  |
| 1985 |  |  [Multi-level Relevance Document Identifier Learning for Generative Retrieval](https://aclanthology.org/2025.acl-long.497/) |  | 0 | Generative Retrieval (GR) introduces a new information retrieval paradigm that directly generates unique document identifiers (DocIDs). The key challenge of GR lies in creating effective yet discrete DocIDs that preserve semantic relevance for similar documents while differentiating dissimilar... | Fuwei Zhang, Xiaoyu Liu, Xinyu Jia, Yingfei Zhang, Shuai Zhang, Xiang Li, Fuzhen Zhuang, Wei Lin, Zhao Zhang |  |
| 1986 |  |  [EfficientQAT: Efficient Quantization-Aware Training for Large Language Models](https://aclanthology.org/2025.acl-long.498/) |  | 0 | Large language models (LLMs) are crucial in modern natural language processing and artificial intelligence. However, they face challenges in managing their significant memory requirements. Although quantization-aware training (QAT) offers a solution by reducing memory consumption through low-bit... | Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo |  |
| 1987 |  |  [Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder](https://aclanthology.org/2025.acl-long.499/) |  | 0 | Recent research has shown that CLIP models struggle with visual reasoning tasks that require grounding compositionality, understanding spatial relationships, or capturing fine-grained details. One natural hypothesis is that the CLIP vision encoder does not embed essential information for these... | Siting Li, Pang Wei Koh, Simon Shaolei Du |  |
| 1988 |  |  [NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization](https://aclanthology.org/2025.acl-long.500/) |  | 0 | Summarizing long-form narratives—such as books, movies, and TV scripts—requires capturing intricate plotlines, character interactions, and thematic coherence, a task that remains challenging for existing LLMs. We introduce NexusSum, a multi-agent LLM framework for narrative summarization that... | Hyuntak Kim, ByungHak Kim |  |
| 1989 |  |  [HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models](https://aclanthology.org/2025.acl-long.501/) |  | 0 | Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design... | Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di Zhang, Liqiang Nie |  |
| 1990 |  |  [Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education](https://aclanthology.org/2025.acl-long.502/) |  | 0 | In AI-facilitated teaching, leveraging various query styles to interpret abstract text descriptions is crucial for ensuring high-quality teaching. However, current retrieval models primarily focus on natural text-image retrieval, making them insufficiently tailored to educational scenarios due to... | Yanhao Jia, Xinyi Wu, Li Hao, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan |  |
| 1991 |  |  [DenseLoRA: Dense Low-Rank Adaptation of Large Language Models](https://aclanthology.org/2025.acl-long.503/) |  | 0 | Low-rank adaptation (LoRA) has been developed as an efficient approach for adapting large language models (LLMs) by fine-tuning two low-rank matrices, thereby reducing the number of trainable parameters. However, prior research indicates that many of the weights in these matrices are redundant,... | Lin Mu, Xiaoyu Wang, Li Ni, Yang Li, Zhize Wu, Peiquan Jin, Yiwen Zhang |  |
| 1992 |  |  [Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis](https://aclanthology.org/2025.acl-long.504/) |  | 0 | Personalized AI assistants, a hallmark of the human-like capabilities of Large Language Models (LLMs), are a challenging application that intertwines multiple problems in LLM research. Despite the growing interest in the development of personalized assistants, the lack of an open-source... | Jisoo Mok, Ikhwan Kim, Sangkwon Park, Sungroh Yoon |  |
| 1993 |  |  [Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models](https://aclanthology.org/2025.acl-long.505/) |  | 0 | Knowledge neuron theory provides a key approach to understanding the mechanisms of factual knowledge in Large Language Models (LLMs), which suggests that facts are stored within multi-layer perceptron neurons. This paper further explores \*\*Degenerate Knowledge Neurons\*\* (DKNs), where distinct... | Yuheng Chen, Pengfei Cao, Yubo Chen, Yining Wang, Shengping Liu, Kang Liu, Jun Zhao |  |
| 1994 |  |  [Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach](https://aclanthology.org/2025.acl-long.506/) |  | 0 | Large Language Models (LLMs) enhanced with external contexts, such as through retrieval-augmented generation (RAG), often face challenges in handling imperfect evidence. They tend to over-rely on external knowledge, making them vulnerable to misleading and unhelpful contexts. To address this, we... | Shenglai Zeng, Pengfei He, Kai Guo, Tianqi Zheng, Hanqing Lu, Yue Xing, Hui Liu |  |
| 1995 |  |  [On Support Samples of Next Word Prediction](https://aclanthology.org/2025.acl-long.507/) |  | 0 | Language models excel in various tasks by making complex decisions, yet understanding the rationale behind these decisions remains a challenge. This paper investigates data-centric interpretability in language models, focusing on the next-word prediction task. Using representer theorem, we identify... | Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, Mou Xiao Feng, Yuanbin Wu |  |
| 1996 |  |  [WebWalker: Benchmarking LLMs in Web Traversal](https://aclanthology.org/2025.acl-long.508/) |  | 0 | Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address this, we introduce... | Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Yulan He, Deyu Zhou, Pengjun Xie, Fei Huang |  |
| 1997 |  |  [From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models](https://aclanthology.org/2025.acl-long.509/) |  | 0 | The rise of Large Language Models (LLMs) has heightened concerns about the misuse of AI-generated text, making watermarking a promising solution. Mainstream watermarking schemes for LLMs fall into two categories: logits-based and sampling-based. However, current schemes entail trade-offs among... | Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang |  |
| 1998 |  |  [AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs](https://aclanthology.org/2025.acl-long.510/) |  | 0 | User interface understanding with vision-language models (VLMs) has received much attention due to its potential for enhancing software automation.However, existing datasets used to build UI-VLMs either only contain large-scale context-free element annotations or contextualized functional... | Hongxin Li, Jingfan Chen, Jingran Su, Yuntao Chen, Qing Li, Zhaoxiang Zhang |  |
| 1999 |  |  [Introducing Graph Context into Language Models through Parameter-Efficient Fine-Tuning for Lexical Relation Mining](https://aclanthology.org/2025.acl-long.511/) |  | 0 | Lexical relation refers to the way words are related within a language. Prior work has demonstrated that pretrained language models (PLMs) can effectively mine lexical relations between word pairs. However, they overlook the potential of graph structures composed of lexical relations, which can be... | Jingwen Sun, Zhiyi Tian, Yu He, Jingwei Sun, Guangzhong Sun |  |
| 2000 |  |  [S-RAG: A Novel Audit Framework for Detecting Unauthorized Use of Personal Data in RAG Systems](https://aclanthology.org/2025.acl-long.512/) |  | 0 | Retrieval-Augmented Generation (RAG) systems combine external data retrieval with text generation and have become essential in applications requiring accurate and context-specific responses. However, their reliance on external data raises critical concerns about unauthorized collection and usage of... | Zhirui Zeng, Jiamou Liu, MengFen Chiang, Jialing He, Zijian Zhang |  |
| 2001 |  |  [Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria](https://aclanthology.org/2025.acl-long.513/) |  | 0 | With the increasing capability of large language models (LLMs), LLM-as-a-judge has emerged as a new evaluation paradigm. Compared with traditional automatic and manual evaluation, LLM evaluators exhibit better interpretability and efficiency. Despite this, existing LLM evaluators suffer from... | Yongqi Leng, Renren Jin, Yue Chen, Zhuowen Han, Ling Shi, Jianxiang Peng, Lei Yang, Juesi Xiao, Deyi Xiong |  |
| 2002 |  |  [Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking](https://aclanthology.org/2025.acl-long.514/) |  | 0 | Deep transformer models have been used to detect linguistic anomalies in patient transcripts for early Alzheimer’s disease (AD) screening. While pre-trained neural language models (LMs) fine-tuned on AD transcripts perform well, little research has explored the effects of the gender of the speakers... | Zhecheng Sheng, Xiruo Ding, Brian Hur, Changye Li, Trevor Cohen, Serguei V. S. Pakhomov |  |
| 2003 |  |  [MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies](https://aclanthology.org/2025.acl-long.515/) |  | 0 | With the rapid development of Multimodal Large Language Models (MLLMs), their potential in Chinese Classical Studies (CCS), a field which plays a vital role in preserving and promoting China’s rich cultural heritage, remains largely unexplored due to the absence of specialized benchmarks. To bridge... | Yang Liu, Jiahuan Cao, Hiuyi Cheng, Yongxin Shi, Kai Ding, Lianwen Jin |  |
| 2004 |  |  [The Knowledge Microscope: Features as Better Analytical Lenses than Neurons](https://aclanthology.org/2025.acl-long.516/) |  | 0 | We demonstrate that features, rather than neurons, serve as superior analytical units for understanding the mechanisms of factual knowledge in Language Models (LMs). Previous studies primarily utilize MLP neurons as units of analysis; however, neurons suffer from polysemanticity, leading to limited... | Yuheng Chen, Pengfei Cao, Kang Liu, Jun Zhao |  |
| 2005 |  |  [From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding](https://aclanthology.org/2025.acl-long.517/) |  | 0 | The pursuit of diverse, complex, and large-scale instruction data is crucial for automatically aligning large language models (LLMs). While there are methods capable of generating synthetic instructions at scale, they either suffer from limited grounding sources, leading to a narrow distribution,... | Chiwei Zhu, Benfeng Xu, Xiaorui Wang, Zhendong Mao |  |
| 2006 |  |  [PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance](https://aclanthology.org/2025.acl-long.518/) |  | 0 | Recent advancements in generative large language models (LLMs) have enabled wider applicability, accessibility, and flexibility. However, their reliability and trustworthiness are still in doubt, especially for concerns regarding individuals’ data privacy. Great efforts have been made on privacy by... | Haoran Li, Wenbin Hu, Huihao Jing, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song |  |
| 2007 |  |  [Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View](https://aclanthology.org/2025.acl-long.519/) |  | 0 | Large language models (LLMs) offer powerful capabilities but come with significant environmental impact, particularly in carbon emissions. Existing studies benchmark carbon emissions but lack a standardized basis for comparison across different model configurations. To address this, we introduce... | Yanran Wu, Inez Hua, Yi Ding |  |
| 2008 |  |  [ExpeTrans: LLMs Are Experiential Transfer Learners](https://aclanthology.org/2025.acl-long.520/) |  | 0 | Recent studies provide large language models (LLMs) with textual task-solving experiences via prompts to improve their performance.However, previous methods rely on substantial human labor or time to gather such experiences for each task, which is impractical given the growing variety of task types... | Jinglong Gao, Xiao Ding, Lingxiao Zou, Bibo Cai, Bing Qin, Ting Liu |  |
| 2009 |  |  [Cool-Fusion: Fuse Large Language Models without Training](https://aclanthology.org/2025.acl-long.521/) |  | 0 | We focus on the problem of fusing two or more heterogeneous large language models (LLMs) to leverage their complementary strengths. One of the challenges of model fusion is high computational load, specifically in fine-tuning or aligning vocabularies. To address this, we propose Cool-Fusion, a... | Cong Liu, Xiaojun Quan, Yan Pan, Weigang Wu, Xu Chen, Liang Lin |  |
| 2010 |  |  [DAPE V2: Process Attention Score as Feature Map for Length Extrapolation](https://aclanthology.org/2025.acl-long.522/) |  | 0 | The attention mechanism is a fundamental component of the Transformer model, contributing to interactions among distinct tokens. In general, the attention scores are determined simply by the key-query products. However, this work’s occasional trial (combining DAPE and NoPE) of including additional... | Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li |  |
| 2011 |  |  [MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training](https://aclanthology.org/2025.acl-long.523/) |  | 0 | Complex instruction-following with elaborate constraints is imperative for Large Language Models (LLMs). While existing methods have constructed data for complex instruction alignment, they all rely on a more advanced model, especially GPT-4, limiting their application. In this paper, we propose a... | Hui Huang, Jiaheng Liu, Yancheng He, Shilong Li, Bing Xu, Conghui Zhu, Muyun Yang, Tiejun Zhao |  |
| 2012 |  |  [LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation](https://aclanthology.org/2025.acl-long.524/) |  | 0 | Large language models (LLMs) have gained extended context windows through scaling positional encodings and lightweight continual pre-training. However, this often leads to degraded performance on short-text tasks, while the reasons for this degradation remain insufficiently explored. In this work,... | Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Xin Zhao, Bingning Wang, Weipeng Chen |  |
| 2013 |  |  [APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs](https://aclanthology.org/2025.acl-long.525/) |  | 0 | While long-context inference is crucial for advancing large language model (LLM) applications, its prefill speed remains a significant bottleneck. Current approaches, including sequence parallelism strategies and compute reduction through approximate attention mechanisms, still fall short of... | Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Sun Ao, Hao Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun |  |
| 2014 |  |  [PPT: A Minor Language News Recommendation Model via Cross-Lingual Preference Pattern Transfer](https://aclanthology.org/2025.acl-long.526/) |  | 0 | Rich user-item interactions are essential for building reliable recommender systems, as they reflect user preference patterns. However, minor language news recommendation platforms suffer from limited interactions due to a small user base. A natural solution is to apply well-established English... | Yiyang Zhang, Nan Chen |  |
| 2015 |  |  [GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis](https://aclanthology.org/2025.acl-long.527/) |  | 0 | The Retrieval-Augmented Generation (RAG) framework introduces a retrieval module to dynamicaslly inject retrieved information into the input context of large language models (LLMs), and has demonstrated significant success in various NLP tasks. However, the current study points out that there is a... | Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin |  |
| 2016 |  |  [Top-nσ: Eliminating Noise in Logit Space for Robust Token Sampling of LLM](https://aclanthology.org/2025.acl-long.528/) |  | 0 | Large language models (LLMs) rely heavily on sampling methods to generate diverse and high-quality text.While existing sampling methods like top-p and min-p have identified the detrimental effects of low-probability tails in LLMs’ outputs, they still fail to effectively distinguish between... | Chenxia Tang, Jianchun Liu, Hongli Xu, Liusheng Huang |  |
| 2017 |  |  [SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation](https://aclanthology.org/2025.acl-long.529/) |  | 0 | Key-Value (KV) cache has become a bottleneck of LLMs for long-context generation. Despite the numerous efforts in this area, the optimization for the decoding phase is generally ignored. However, we believe such optimization is crucial, especially for long-output generation tasks based on the... | Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou |  |
| 2018 |  |  [Mitigating Non-Representative Prototypes and Representation Bias in Few-Shot Continual Relation Extraction](https://aclanthology.org/2025.acl-long.530/) |  | 0 | To address the phenomenon of similar classes, existing methods in few-shot continual relation extraction (FCRE) face two main challenges: non-representative prototypes and representation bias, especially when the number of available samples is limited. In our work, we propose Minion to address... | Thanh Duc Pham, Nam Le Hai, Linh Ngo Van, Nguyen Thi Ngoc Diep, Sang Dinh, Thien Huu Nguyen |  |
| 2019 |  |  [MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts](https://aclanthology.org/2025.acl-long.531/) |  | 0 | One of the primary challenges in optimizing large language models (LLMs) for long-context inference lies in the high memory consumption of the Key-Value (KV) cache. Existing approaches, such as quantization, have demonstrated promising results in reducing memory usage. However, current quantization... | Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang |  |
| 2020 |  |  [PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration](https://aclanthology.org/2025.acl-long.532/) |  | 0 | The widespread usage of online Large Language Models (LLMs) inference services has raised significant privacy concerns about the potential exposure of private information in user inputs. Existing privacy protection methods for LLMs suffer from either insufficient privacy protection with performance... | Ziqian Zeng, Jianwei Wang, Junyao Yang, Zhengdong Lu, Haoran Li, Huiping Zhuang, Cen Chen |  |
| 2021 |  |  [Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models](https://aclanthology.org/2025.acl-long.533/) |  | 0 | The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality—a critical driver of model performance. Current data selection methods, such as natural language quality assessments, diversity-based... | Xinlin Zhuang, Jiahui Peng, Ren Ma, Yinfan Wang, Tianyi Bai, Xingjian Wei, Jiantao Qiu, Chi Zhang, Ying Qian, Conghui He |  |
| 2022 |  |  [GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning](https://aclanthology.org/2025.acl-long.534/) |  | 0 | The evaluation of large language models (LLMs) has traditionally relied on static benchmarks, a paradigm that poses two major limitations: (1) predefined test sets lack adaptability to diverse application domains, and (2) standardized evaluation protocols often fail to capture fine-grained... | Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li |  |
| 2023 |  |  [Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition](https://aclanthology.org/2025.acl-long.535/) |  | 0 | The past years have witnessed a proliferation of large language models (LLMs). Yet, reliable evaluation of LLMs is challenging due to the inaccuracy of standard metrics in human perception of text quality and the inefficiency in sampling informative test examples for human evaluation. This paper... | Kehua Feng, Keyan Ding, Hongzhi Tan, Kede Ma, Zhihua Wang, Shuangquan Guo, Yuzhou Cheng, Ge Sun, Guozhou Zheng, Qiang Zhang, Huajun Chen |  |
| 2024 |  |  [DTCRS: Dynamic Tree Construction for Recursive Summarization](https://aclanthology.org/2025.acl-long.536/) |  | 0 | Retrieval-Augmented Generation (RAG) mitigates the hallucination problem of Large Language Models (LLMs) by incorporating external knowledge. Recursive summarization constructs a hierarchical summary tree by clustering text chunks, integrating information from multiple parts of a document to... | Guanran Luo, Zhongquan Jian, Wentao Qiu, Meihong Wang, Qingqiang Wu |  |
| 2025 |  |  [A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning](https://aclanthology.org/2025.acl-long.537/) |  | 0 | Recent Continual Learning (CL)-based Temporal Knowledge Graph Reasoning (TKGR) methods focus on significantly reducing computational cost and mitigating catastrophic forgetting caused by fine-tuning models with new data. However, existing CL-based TKGR methods still face two key limitations: (1)... | Zhiyu Zhang, Wei Chen, Youfang Lin, Huaiyu Wan |  |
| 2026 |  |  [ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search](https://aclanthology.org/2025.acl-long.538/) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities and are receiving increasing attention to enhance their reasoning through scaling test-time compute. However, their application in open-ended, knowledge-intensive, complex reasoning scenarios is still limited. Reasoning-oriented... | Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu |  |
| 2027 |  |  [PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation](https://aclanthology.org/2025.acl-long.539/) |  | 0 | Drug-drug interactions (DDIs) arise when multiple drugs are administered concurrently. Accurately predicting the specific mechanisms underlying DDIs (named DDI events or DDIEs) is critical for the safe clinical use of drugs. DDIEs are typically represented as textual descriptions. However, most... | Ziyan Wang, Zhankun Xiong, Feng Huang, Wen Zhang |  |
| 2028 |  |  [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://aclanthology.org/2025.acl-long.540/) |  | 0 | Interpretation is critical for disease diagnosis, but existing models struggle to balance predictive accuracy with human-understandable rationales. While large language models (LLMs) offer strong reasoning abilities, their clinical use is limited by high computational costs and restricted... | Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Richard Yi Da Xu, Yunya Song, Xian Yang |  |
| 2029 |  |  [TWIST: Text-encoder Weight-editing for Inserting Secret Trojans in Text-to-Image Models](https://aclanthology.org/2025.acl-long.541/) |  | 0 | Text-to-image (T2I) models excel at generating high-quality images from text via powerful text encoders but training these encoders demands substantial computational resources. Consequently, many users seek pre-trained text encoders from model plugin-sharing platforms like Civitai and Hugging Face,... | Xindi Li, Zhe Liu, Tong Zhang, Jiahao Chen, Qingming Li, Jinbao Li, Shouling Ji |  |
| 2030 |  |  [Frictional Agent Alignment Framework: Slow Down and Don't Break Things](https://aclanthology.org/2025.acl-long.542/) |  | 0 | AI support of collaborative interactions entails mediating potential misalignment between interlocutor beliefs. Common preference alignment methods like DPO excel in static settings, but struggle in dynamic collaborative tasks where the explicit signals of interlocutor beliefs are sparse and... | Abhijnan Nath, Carine Graff, Andrei Bachinin, Nikhil Krishnaswamy |  |
| 2031 |  |  [Powerformer: Efficient and High-Accuracy Privacy-Preserving Language Model with Homomorphic Encryption](https://aclanthology.org/2025.acl-long.543/) |  | 0 | We propose Powerformer, an efficient homomorphic encryption (HE)-based privacy-preserving language model (PPLM) designed to reduce computation overhead while maintaining model performance. Powerformer incorporates three key techniques to optimize encrypted computations:1. A novel distillation... | Dongjin Park, Eunsang Lee, JoonWoo Lee |  |
| 2032 |  |  [Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play Fine-Tuning of LLMs](https://aclanthology.org/2025.acl-long.544/) |  | 0 | Role-playing enables large language models (LLMs) to engage users in immersive and personalized interactions, but it also introduces significant safety risks. Existing role-play fine-tuning techniques improve role adaptability but may degrade safety performance, particularly for villainous... | Weixiang Zhao, Yulin Hu, Yang Deng, Jiahe Guo, Xingyu Sui, Xinyang Han, An Zhang, Yanyan Zhao, Bing Qin, TatSeng Chua, Ting Liu |  |
| 2033 |  |  [Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?](https://aclanthology.org/2025.acl-long.545/) |  | 0 | While great success has been achieved in building vision models with Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is challenging because of the scarcity of labeled data and text... | Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han |  |
| 2034 |  |  [Towards Enhanced Immersion and Agency for LLM-based Interactive Drama](https://aclanthology.org/2025.acl-long.546/) |  | 0 | LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two... | Hongqiu Wu, Weiqi Wu, Tianyang Xu, Jiameng Zhang, Hai Zhao |  |
| 2035 |  |  [Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures](https://aclanthology.org/2025.acl-long.547/) |  | 0 | Multimodal reference resolution, including phrase grounding, aims to understand the semantic relations between mentions and real-world objects. Phrase grounding between images and their captions is a well-established task. In contrast, for real-world applications, it is essential to integrate... | Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino |  |
| 2036 |  |  [Improving Factuality with Explicit Working Memory](https://aclanthology.org/2025.acl-long.548/) |  | 0 | Large language models can generate factually inaccurate content, a problem known as hallucination. Recent works have built upon retrieved-augmented generation to improve factuality through iterative prompting but these methods are limited by the traditional RAG design. To address these challenges,... | Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Yi Sun, Luke Zettlemoyer, Gargi Ghosh, Wentau Yih |  |
| 2037 |  |  [Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models](https://aclanthology.org/2025.acl-long.549/) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address... | Chengao Li, Hanyu Zhang, Yunkun Xu, Hongyan Xue, Xiang Ao, Qing He |  |
| 2038 |  |  [Dynamic Parallel Tree Search for Efficient LLM Reasoning](https://aclanthology.org/2025.acl-long.550/) |  | 0 | Tree of Thoughts (ToT) enhances Large Language Model (LLM) reasoning by structuring problem-solving as a spanning tree. However, recent methods focus on search accuracy while overlooking computational efficiency. The challenges of accelerating the ToT lie in the frequent switching of reasoning... | Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao |  |
| 2039 |  |  [Pre³: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation](https://aclanthology.org/2025.acl-long.551/) |  | 0 | Extensive LLM applications demand efficient structured generations, particularly for LR(1) grammars, to produce outputs in specified formats (e.g., JSON). Existing methods primarily parse LR(1) grammars into a pushdown automaton (PDA), leading to runtime execution overhead for context-dependent... | Junyi Chen, Shihao Bai, Zaijun Wang, Siyu Wu, Chuheng Du, Hailong Yang, Ruihao Gong, Shengzhong Liu, Fan Wu, Guihai Chen |  |
| 2040 |  |  [SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL](https://aclanthology.org/2025.acl-long.552/) |  | 0 | Current self-correction approaches in text-to-SQL face two critical limitations: 1) Conventional self-correction methods rely on recursive self-calls of LLMs, resulting in multiplicative computational overhead, and 2) LLMs struggle to implement effective error detection and correction for... | Ge Qu, Jinyang Li, Bowen Qin, Xiaolong Li, Nan Huo, Chenhao Ma, Reynold Cheng |  |
| 2041 |  |  [GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models](https://aclanthology.org/2025.acl-long.553/) |  | 0 | Large Language Models (LLMs) are prone to generating content that exhibits gender biases, raising significant ethical concerns. Alignment, the process of fine-tuning LLMs to better align with desired behaviors, is recognized as an effective approach to mitigate gender biases. Although proprietary... | Tao Zhang, Ziqian Zeng, YuxiangXiao YuxiangXiao, Huiping Zhuang, Cen Chen, James R. Foulds, Shimei Pan |  |
| 2042 |  |  [Large Language and Protein Assistant for Protein-Protein Interactions Prediction](https://aclanthology.org/2025.acl-long.554/) |  | 0 | Predicting the types and affinities of protein-protein interactions (PPIs) is crucial for understanding biological processes and developing novel therapeutic approaches. While encoding proteins themselves is essential, PPI networks can also provide rich prior knowledge for these predictive tasks.... | Peng Zhou, Pengsen Ma, Jianmin Wang, Xibao Cai, Haitao Huang, Wei Liu, Longyue Wang, Lai Hou Tim, Xiangxiang Zeng |  |
| 2043 |  |  [An Empirical Study of Many-to-Many Summarization with Large Language Models](https://aclanthology.org/2025.acl-long.555/) |  | 0 | Many-to-many summarization (M2MS) aims to process documents in any language and generate the corresponding summaries also in any language. Recently, large language models (LLMs) have shown strong multi-lingual abilities, giving them the potential to perform M2MS in real applications. This work... | Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, Haoxiang Shi, Jie Zhou |  |
| 2044 |  |  [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://aclanthology.org/2025.acl-long.556/) |  | 0 | Direct speech translation (ST) has garnered increasing attention nowadays, yet the accurate translation of terminology within utterances remains a great challenge. In this regard, current studies mainly concentrate on leveraging various translation knowledge into ST models. However, these methods... | Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Junfeng Yao, Min Zhang, Jinsong Su |  |
| 2045 |  |  [GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents](https://aclanthology.org/2025.acl-long.557/) |  | 0 | Large language models (LLMs) have been widely deployed as autonomous agents capable of following user instructions and making decisions in real-world applications. Previous studies have made notable progress in benchmarking the instruction following capabilities of LLMs in general domains, with a... | Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang |  |
| 2046 |  |  [TC-RAG: Turing-Complete RAG's Case study on Medical LLM Systems](https://aclanthology.org/2025.acl-long.558/) |  | 0 | In the pursuit of enhancing domain-specific Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) emerges as a promising solution to mitigate issues such as hallucinations, outdated knowledge, and limited expertise in highly specialized queries. However, existing approaches to RAG fall... | Xinke Jiang, Yue Fang, Rihong Qiu, Haoyu Zhang, Yongxin Xu, Hao Chen, Wentao Zhang, Ruizhe Zhang, Yuchen Fang, Xinyu Ma, Xu Chu, Junfeng Zhao, Yasha Wang |  |
| 2047 |  |  [SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning](https://aclanthology.org/2025.acl-long.559/) |  | 0 | Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose... | Zexiong Ma, Chao Peng, Pengfei Gao, Xiangxin Meng, Yanzhen Zou, Bing Xie |  |
| 2048 |  |  [MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models](https://aclanthology.org/2025.acl-long.560/) |  | 0 | Long Context Understanding (LCU) is a critical area for exploration in current large language models (LLMs). However, due to the inherently lengthy nature of long-text data, existing LCU benchmarks for LLMs often result in prohibitively high evaluation costs, like testing time and inference... | Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin |  |
| 2049 |  |  [Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG](https://aclanthology.org/2025.acl-long.561/) |  | 0 | Large language models (LLMs) augmented with retrieval systems have significantly advanced natural language processing tasks by integrating external knowledge sources, enabling more accurate and contextually rich responses. To improve the robustness of such systems against noisy retrievals,... | Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Zilei Wang, Weiqiang Wang, Liang Wang |  |
| 2050 |  |  [PwnGPT: Automatic Exploit Generation Based on Large Language Models](https://aclanthology.org/2025.acl-long.562/) |  | 0 | Automatic exploit generation (AEG) refers to the automatic discovery and exploitation of vulnerabilities against unknown targets. Traditional AEG often targets a single type of vulnerability and still relies on templates built from expert experience. To achieve intelligent exploit generation, we... | Wanzong Peng, Lin Ye, Xuetao Du, Hongli Zhang, Dongyang Zhan, Yunting Zhang, Yicheng Guo, Chen Zhang |  |
| 2051 |  |  [VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs](https://aclanthology.org/2025.acl-long.563/) |  | 0 | The evolution of Large Language Models (LLMs) has underscored the necessity for benchmarks designed for various languages and cultural contexts. To address this need for Vietnamese, we present the first Vietnamese Multitask Language Understanding (VMLU) Benchmarks. The VMLU benchmarks consist of... | Cuc Thi Bui, Nguyen Truong Son, Trang Van Truong, Viet Lam Phung, Pham Nhut Huy, Hoang Anh Le, Quoc Huu Van, Phong NguyenThuan Do, Van Le Tran Truc, Duc Thanh Chau, LeMinh Nguyen |  |
| 2052 |  |  [Scaling up the State Size of RNN LLMs for Long-Context Scenarios](https://aclanthology.org/2025.acl-long.564/) |  | 0 | The Transformer architecture has become the standard LLM architecture due to its powerful self-attention mechanism. However, it suffers from quadratic computational complexity and linear memory complexity. RNN-based LLMs have been proposed as alternatives. Yet, RNN models struggle in long-context... | Kai Liu, Jianfei Gao, Kai Chen |  |
| 2053 |  |  [Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes](https://aclanthology.org/2025.acl-long.565/) |  | 0 | Diffusion models have emerged as a promising approach for text generation, with recent works falling into two main categories: discrete and continuous diffusion models. Discrete diffusion models apply token corruption independently using categorical distributions, allowing for different diffusion... | Bocheng Li, Zhujin Gao, Linli Xu |  |
| 2054 |  |  [A Strategic Coordination Framework of Small LMs Matches Large LMs in Data Synthesis](https://aclanthology.org/2025.acl-long.566/) |  | 0 | While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In... | Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Lijun Wu, Conghui He |  |
| 2055 |  |  [Defining and Evaluating Visual Language Models' Basic Spatial Abilities: A Perspective from Psychometrics](https://aclanthology.org/2025.acl-long.567/) |  | 0 | The Theory of Multiple Intelligences underscores the hierarchical nature of cognitive capabilities. To advance Spatial Artificial Intelligence, we pioneer a psychometric framework defining five Basic Spatial Abilities (BSAs) in Visual Language Models (VLMs): Spatial Perception, Spatial Relation,... | Wenrui Xu, Dalin Lyu, Weihang Wang, Jie Feng, Chen Gao, Yong Li |  |
| 2056 |  |  [SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation](https://aclanthology.org/2025.acl-long.568/) |  | 0 | Current vision-language models may grasp basic spatial cues and simple directions (e.g. left, right, front, back), but struggle with the multi-dimensional spatial reasoning necessary for human-like understanding and real-world applications. To address this gap, we develop SPHERE (Spatial Perception... | Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Junqi Zhao, Allison Koenecke, Boyang Li, Lu Wang |  |
| 2057 |  |  [User-side Model Consistency Monitoring for Open Source Large Language Models Inference Services](https://aclanthology.org/2025.acl-long.569/) |  | 0 | With the continuous advancement in the performance of open-source large language models (LLMs), their inference services have attracted a substantial user base by offering quality comparable to closed-source models at a significantly lower cost. However, it has also given rise to trust issues... | Qijun Miao, Zhixuan Fang |  |
| 2058 |  |  [Jailbreaking? One Step Is Enough!](https://aclanthology.org/2025.acl-long.570/) |  | 0 | Large language models (LLMs) excel in various tasks but remain vulnerable to jailbreak attacks, where adversaries manipulate prompts to generate harmful outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs. However, current jailbreak methods and the target model’s defenses... | Weixiong Zheng, Peijian Zeng, Yiwei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou |  |
| 2059 |  |  [Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning](https://aclanthology.org/2025.acl-long.571/) |  | 0 | Retrieval-Augmented Generation (RAG) offers an effective solution to the issues faced by Large Language Models (LLMs) in hallucination generation and knowledge obsolescence by incorporating externally retrieved knowledge. However, existing methods lack effective control mechanisms for integrating... | Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang |  |
| 2060 |  |  [PaSa: An LLM Agent for Comprehensive Academic Paper Search](https://aclanthology.org/2025.acl-long.572/) |  | 0 | We introduce PaSa, an advanced Paper Search agent powered by large language models. PaSa can autonomously make a series of decisions, including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate results for complex scholar... | Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Hang Li, Weinan E |  |
| 2061 |  |  [Less Mature is More Adaptable for Sentence-level Language Modeling](https://aclanthology.org/2025.acl-long.573/) |  | 0 | This work investigates sentence-level models (i.e., models that operate at the sentence-level) to study how sentence representations from various encoders influence downstream task performance, and which syntactic, semantic, and discourse-level properties are essential for strong performance. Our... | Abhilasha Sancheti, David Dale, Artyom Kozhevnikov, Maha Elbayad |  |
| 2062 |  |  [EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts](https://aclanthology.org/2025.acl-long.574/) |  | 0 | Recent advances in Large Language Models (LLMs) have yielded impressive successes on many language tasks. However, efficient processing of long contexts using LLMs remains a significant challenge. We introduce \*\*EpMAN\*\* – a method for processing long contexts in an episodic memory module while... | Subhajit Chaudhury, Payel Das, Sarathkrishna Swaminathan, Georgios Kollias, Elliot Nelson, Khushbu Pahwa, Tejaswini Pedapati, Igor Melnyk, Matthew Riemer |  |
| 2063 |  |  [UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://aclanthology.org/2025.acl-long.575/) |  | 0 | This paper introduces UoRA, a novel parameter-efficient fine-tuning (PEFT) approach for large language models (LLMs). UoRA achieves state-of-the-art efficiency by leveraging a low-rank approximation method that reduces the number of trainable parameters without compromising performance. Unlike... | Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang |  |
| 2064 |  |  [Agri-CM³: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning](https://aclanthology.org/2025.acl-long.576/) |  | 0 | Multi-modal Large Language Models (MLLMs) integrating images, text, and speech can provide farmers with accurate diagnoses and treatment of pests and diseases, enhancing agricultural efficiency and sustainability. However, existing benchmarks lack comprehensive evaluations, particularly in... | Haotian Wang, Yi Guan, Fanshu Meng, Chao Zhao, Lian Yan, Yang Yang, Jingchi Jiang |  |
| 2065 |  |  [TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification](https://aclanthology.org/2025.acl-long.577/) |  | 0 | LLMs have achieved remarkable fluency and coherence in text generation, yet their widespread adoption has raised concerns about content reliability and accountability. In high-stakes domains, it is crucial to understand where and how the content is created. To address this, we introduce the Text... | Junnan Zhu, Min Xiao, Yining Wang, Feifei Zhai, Yu Zhou, Chengqing Zong |  |
| 2066 |  |  [CaLMQA: Exploring culturally specific long-form question answering across 23 languages](https://aclanthology.org/2025.acl-long.578/) |  | 0 | Despite rising global usage of large language models (LLMs), their ability to generate \*long-form\* answers to \*culturally specific\* questions remains unexplored in many languages. To fill this gap, we perform the first study of textual multilingual long-form QA by creating CaLMQA, a dataset of... | Shane Arora, Marzena Karpinska, HungTing Chen, Ipsita Bhattacharjee, Mohit Iyyer, Eunsol Choi |  |
| 2067 |  |  [Croppable Knowledge Graph Embedding](https://aclanthology.org/2025.acl-long.579/) |  | 0 | Knowledge Graph Embedding (KGE) is a common approach for Knowledge Graphs (KGs) in AI tasks. Embedding dimensions depend on application scenarios. Requiring a new dimension means training a new KGE model from scratch, increasing cost and limiting efficiency and flexibility. In this work, we propose... | Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen |  |
| 2068 |  |  [HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses](https://aclanthology.org/2025.acl-long.580/) |  | 0 | In this paper, we investigate the retrieval-augmented generation (RAG) based on Knowledge Graphs (KGs) to improve the accuracy and reliability of Large Language Models (LLMs). Recent approaches suffer from insufficient and repetitive knowledge retrieval, tedious and time-consuming query parsing,... | Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan Wang, Jinyi Tang, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang |  |
| 2069 |  |  [LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models](https://aclanthology.org/2025.acl-long.581/) |  | 0 | Large language models (LLMs) face significant challenges in handling long-context tasks because of their limited effective context window size during pretraining, which restricts their ability to generalize over extended sequences. Meanwhile, extending the context window in LLMs through... | Zhiyuan Hu, Yuliang Liu, Jinman Zhao, Suyuchen Wang, WangYan WangYan, Wei Shen, Qing Gu, Anh Tuan Luu, SeeKiong Ng, Zhiwei Jiang, Bryan Hooi |  |
| 2070 |  |  [BeamLoRA: Beam-Constraint Low-Rank Adaptation](https://aclanthology.org/2025.acl-long.582/) |  | 0 | Due to the demand for efficient fine-tuning of large language models, Low-Rank Adaptation (LoRA) has been widely adopted as one of the most effective parameter-efficient fine-tuning methods. Nevertheless, while LoRA improves efficiency, there remains room for improvement in accuracy. Herein, we... | Naibin Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang |  |
| 2071 |  |  [GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art](https://aclanthology.org/2025.acl-long.583/) |  | 0 | \*\*\*Video Comment Art\*\*\* enhances user engagement by providing creative content that conveys humor, satire, or emotional resonance, requiring a nuanced and comprehensive grasp of cultural and contextual subtleties. Although Multimodal Large Language Models (MLLMs) and Chain-of-Thought (CoT)... | Yiming Lei, Chenkai Zhang, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang |  |
| 2072 |  |  [UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever](https://aclanthology.org/2025.acl-long.584/) |  | 0 | Despite the impressive capabilities of LLMs, they often generate content with factual inaccuracies in LegalAI, which may lead to serious legal consequences. Retrieval-Augmented Generation (RAG), a promising approach, can conveniently integrate specialized knowledge into LLMs. In practice, there are... | Ang Li, Yiquan Wu, Yifei Liu, Ming Cai, Lizhi Qing, Shihang Wang, Yangyang Kang, Chengyuan Liu, Fei Wu, Kun Kuang |  |
| 2073 |  |  [Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models](https://aclanthology.org/2025.acl-long.585/) |  | 0 | Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz’s Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics.... | Haoran Ye, Tianze Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song |  |
| 2074 |  |  [Beyond Dialogue: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model](https://aclanthology.org/2025.acl-long.586/) |  | 0 | The rapid advancement of large language models (LLMs) has revolutionized role-playing, enabling the development of general role-playing models. However, current role-playing training has two significant issues: (I) Using a predefined role profile to prompt dialogue training for specific scenarios... | Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian |  |
| 2075 |  |  [ACECODER: Acing Coder RL via Automated Test-Case Synthesis](https://aclanthology.org/2025.acl-long.587/) |  | 0 | Most progress in recent coder models has been driven by supervised fine-tuning (SFT), while the potential of reinforcement learning (RL) remains largely unexplored, primarily due to the lack of reliable reward data/model in the code domain. In this paper, we address this challenge by leveraging... | Huaye Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen |  |
| 2076 |  |  [Quantifying Semantic Emergence in Language Models](https://aclanthology.org/2025.acl-long.588/) |  | 0 | Large language models (LLMs) are widely recognized for their exceptional capacity to capture semantics meaning. Yet, there remains no established metric to quantify this capability. In this work, we introduce a quantitative metric, Information Emergence (IE), designed to measure LLMs’ ability to... | Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang |  |
| 2077 |  |  [DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation](https://aclanthology.org/2025.acl-long.589/) |  | 0 | With the impressive reasoning and text generation capabilities of large language models (LLMs), methods leveraging multiple LLMs to debate each other have garnered increasing attention. However, existing debate-based approaches remain limited in effectiveness in structured and detailed domains... | Jizheng Chen, Kounianhua Du, Xinyi Dai, Weiming Zhang, Xihuai Wang, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu |  |
| 2078 |  |  [The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models](https://aclanthology.org/2025.acl-long.590/) |  | 0 | Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is critical. Interestingly, we discover a counter-intuitive trade-off phenomenon that enhancing an LLM’s privacy awareness through Supervised Fine-Tuning (SFT) methods significantly decreases its fairness awareness with... | Chen Qian, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao |  |
| 2079 |  |  [GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding](https://aclanthology.org/2025.acl-long.591/) |  | 0 | Although Large Language Models (LLMs) have demonstrated potential in processing graphs, they struggle with comprehending graphical structure information through prompts of graph description sequences, especially as the graph size increases. We attribute this challenge to the uneven memory... | Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou |  |
| 2080 |  |  [Phonotomizer: A Compact, Unsupervised, Online Training Approach to Real-Time, Multilingual Phonetic Segmentation](https://aclanthology.org/2025.acl-long.592/) |  | 0 | Phonetic transcription requires significant time and expert training. Automated, state-of-the-art text-dependent methods still involve substantial pre-training annotation labor and may not generalize to multiple languages. Hallucination of speech amid silence or non-speech noise can also plague... | Michael S. Yantosca, Albert M. K. Cheng |  |
| 2081 |  |  [A Multi-persona Framework for Argument Quality Assessment](https://aclanthology.org/2025.acl-long.593/) |  | 0 | Argument quality assessment faces inherent challenges due to its subjective nature, where different evaluators may assign varying quality scores for an argument based on personal perspectives. Although existing datasets collect opinions from multiple annotators to model subjectivity, most existing... | Bojun Jin, Jianzhu Bao, Yufang Hou, Yang Sun, Yice Zhang, Huajie Wang, Bin Liang, Ruifeng Xu |  |
| 2082 |  |  [Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification](https://aclanthology.org/2025.acl-long.594/) |  | 0 | Chain-of-Thought (CoT) prompting has become the de facto method to elicit reasoning capabilities from large language models (LLMs). However, to mitigate hallucinations in CoT that are notoriously difficult to detect, current methods such as process reward models (PRMs) or self-consistency operate... | Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Yasheng Wang, Lifeng Shang, Qun Liu, Ming Zhang |  |
| 2083 |  |  [SAM Decoding: Speculative Decoding via Suffix Automaton](https://aclanthology.org/2025.acl-long.595/) |  | 0 | Speculative decoding (SD) has been demonstrated as an effective technique for lossless LLM inference acceleration.Retrieval-based SD methods, one kind of model-free method, have yielded promising speedup, but they often rely on single retrieval resources, inefficient retrieval methods, and are... | Yuxuan Hu, Ke Wang, Xiaokang Zhang, Fanjin Zhang, Cuiping Li, Hong Chen, Jing Zhang |  |
| 2084 |  |  [PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations](https://aclanthology.org/2025.acl-long.596/) |  | 0 | Proactive questioning is essential in psychological conversations as it helps uncover deeper issues and unspoken concerns. Current psychological LLMs are constrained by passive response mechanisms, limiting their capacity to deploy proactive strategies for psychological counseling. To bridge this... | Yuxin Hu, Danni Liu, Bo Liu, Yida Chen, Jiuxin Cao, Yan Liu |  |
| 2085 |  |  [HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices](https://aclanthology.org/2025.acl-long.597/) |  | 0 | Large language models (LLMs) have the potential to revolutionize smart home assistants by enhancing their ability to accurately understand user needs and respond appropriately, which is extremely beneficial for building a smarter home environment. While recent studies have explored integrating LLMs... | Silin Li, Yuhang Guo, Jiashu Yao, Zeming Liu, Haifeng Wang |  |
| 2086 |  |  [Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment](https://aclanthology.org/2025.acl-long.598/) |  | 0 | Modern zero-shot text-to-speech (TTS) systems, despite using extensive pre-training, often struggle in challenging scenarios such as tongue twisters, repeated words, code-switching, and cross-lingual synthesis, leading to intelligibility issues. To address these limitations, this paper leverages... | Xueyao Zhang, Yuancheng Wang, Chaoren Wang, Ziniu Li, Zhuo Chen, Zhizheng Wu |  |
| 2087 |  |  [GiFT: Gibbs Fine-Tuning for Code Generation](https://aclanthology.org/2025.acl-long.599/) |  | 0 | Training Large Language Models (LLMs) with synthetic data is a prevalent practice in code generation. A key approach is self-training, where LLMs are iteratively trained on self-generated correct code snippets. In this case, the self-generated codes are drawn from a conditional distribution,... | Haochen Li, Wanjin Feng, Xin Zhou, Zhiqi Shen |  |
| 2088 |  |  [Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models](https://aclanthology.org/2025.acl-long.600/) |  | 0 | Concept Bottleneck Models (CBMs) decompose image classification into a process governed by interpretable, human-readable concepts. Recent advances in CBMs have used Large Language Models (LLMs) to generate candidate concepts. However, a critical question remains: What is the optimal number of... | Yiwen Jiang, Deval Mehta, Wei Feng, Zongyuan Ge |  |
| 2089 |  |  [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://aclanthology.org/2025.acl-long.601/) |  | 0 | The rapid advancement of large language models has raised significant concerns regarding their potential misuse by malicious actors. As a result, developing effective detectors to mitigate these risks has become a critical priority. However, most existing detection methods focus excessively on... | Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li |  |
| 2090 |  |  [RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph](https://aclanthology.org/2025.acl-long.602/) |  | 0 | In knowledge graph embedding, leveraging relation specific entity transformation has markedly enhanced performance. However, the consistency of embedding differences before and after transformation remains unaddressed, risking the loss of valuable inductive bias inherent in the embeddings. This... | Junsik Kim, Jinwook Park, Kangil Kim |  |
| 2091 |  |  [RolePlot: A Systematic Framework for Evaluating and Enhancing the Plot-Progression Capabilities of Role-Playing Agents](https://aclanthology.org/2025.acl-long.603/) |  | 0 | Role-playing agents (RPAs) are garnering increasing interests as a novel form of conversational AI. While previous research has predominantly concentrated on their ability to portray specified characters, we argue from a user-centered perspective that RPAs’ capability to advance the plot requires... | Pinyi Zhang, Siyu An, Lingfeng Qiao, Yifei Yu, Jingyang Chen, Jie Wang, Di Yin, Xing Sun, Kai Zhang |  |
| 2092 |  |  [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://aclanthology.org/2025.acl-long.604/) |  | 0 | Reinforcement learning (RL) with tree search has demonstrated superior performance in traditional reasoning tasks. Compared to conventional independent chain sampling strategies with outcome supervision, tree search enables better exploration of the reasoning space and provides dense, on-policy... | Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong |  |
| 2093 |  |  [Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model](https://aclanthology.org/2025.acl-long.605/) |  | 0 | Large Language Models (LLMs) with API-calling capabilities enabled building effective Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm. However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of... | Emre Can Acikgoz, Jeremiah Greer, Akul Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek HakkaniTür, Gokhan Tur |  |
| 2094 |  |  [Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation](https://aclanthology.org/2025.acl-long.606/) |  | 0 | Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix Modality... | Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou |  |
| 2095 |  |  [SDPO: Segment-Level Direct Preference Optimization for Social Agents](https://aclanthology.org/2025.acl-long.607/) |  | 0 | Social agents powered by large language models (LLMs) can simulate human social behaviors but fall short in handling complex social dialogues. Direct Preference Optimization (DPO) has proven effective in aligning LLM behavior with human preferences across various agent tasks. However, standard DPO... | Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang |  |
| 2096 |  |  [KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors](https://aclanthology.org/2025.acl-long.608/) |  | 0 | Generating psychological counseling responses with language models relies heavily on high-quality datasets. Crowdsourced data collection methods require strict worker training, and data from real-world counseling environments may raise privacy and ethical concerns. While recent studies have... | Zhiyang Qi, Takumasa Kaneko, Keiko Takamizo, Mariko Ukiyo, Michimasa Inaba |  |
| 2097 |  |  [SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing](https://aclanthology.org/2025.acl-long.609/) |  | 0 | Survey paper plays a crucial role in scientific research, especially given the rapid growth of research publications. Recently, researchers have begun using LLMs to automate survey generation for better efficiency. However, the quality gap between LLM-generated surveys and those written by human... | Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, Lei Bai, Bo Zhang |  |
| 2098 |  |  [Making LLMs Better Many-to-Many Speech-to-Text Translators with Curriculum Learning](https://aclanthology.org/2025.acl-long.610/) |  | 0 | Multimodal Large Language Models (MLLMs) have achieved significant success in Speech-to-Text Translation (S2TT) tasks. While most existing research has focused on English-centric translation directions, the exploration of many-to-many translation is still limited by the scarcity of parallel data.... | Yexing Du, Youcheng Pan, Ziyang Ma, Bo Yang, Yifan Yang, Keqi Deng, Xie Chen, Yang Xiang, Ming Liu, Bing Qin |  |
| 2099 |  |  [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://aclanthology.org/2025.acl-long.611/) |  | 0 | We introduce AbGen, the first benchmark designed to evaluate the capabilities of LLMs in designing ablation studies for scientific research. AbGen consists of 2,000 expert-annotated examples derived from 677 NLP papers. In this benchmark, LLMs are tasked with generating detailed ablation study... | Yilun Zhao, Weiyuan Chen, Zhijian Xu, Manasi Patwardhan, Chengye Wang, Yixin Liu, Lovekesh Vig, Arman Cohan |  |
| 2100 |  |  [Redundancy Principles for MLLMs Benchmarks](https://aclanthology.org/2025.acl-long.612/) |  | 0 | With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant redundancy among benchmarks. Therefore, it is crucial to take a... | Zicheng Zhang, Xiangyu Zhao, Xinyu Fang, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Haodong Duan, Kai Chen, Guangtao Zhai |  |
| 2101 |  |  [WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models](https://aclanthology.org/2025.acl-long.613/) |  | 0 | Retrieval Augmented Generation (RAG) has gained widespread adoption owing to its capacity to empower large language models (LLMs) to integrate external knowledge. However, existing RAG frameworks are primarily designed for text-based LLMs and rely on Automatic Speech Recognition to process speech... | Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao |  |
| 2102 |  |  [ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5](https://aclanthology.org/2025.acl-long.614/) |  | 0 | Automatic speech recognition (ASR) systems have advanced significantly with models like Whisper, Conformer, and self-supervised frameworks such as Wav2vec 2.0 and HuBERT. However, developing robust ASR models for young children’s speech remains challenging due to differences in pronunciation, tone,... | Jiaming Zhou, Shiyao Wang, Shiwan Zhao, Jiabei He, Haoqin Sun, Hui Wang, Cheng Liu, Aobo Kong, Yujie Guo, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin |  |
| 2103 |  |  [Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization](https://aclanthology.org/2025.acl-long.615/) |  | 0 | Iterative data generation and model retraining are widely used to align large language models (LLMs).It typically involves a policy model to generate on-policy responses and a reward model to guide training data selection. Direct Preference Optimization (DPO) further enhances this process by... | Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy KaWei Lee |  |
| 2104 |  |  [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://aclanthology.org/2025.acl-long.616/) |  | 0 | Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and \*denovo\* design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral... | Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen |  |
| 2105 |  |  [SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection](https://aclanthology.org/2025.acl-long.617/) |  | 0 | In the era of rapidly evolving large language models (LLMs), state-of-the-art rumor detection systems, particularly those based on Message Propagation Trees (MPTs), which represent a conversation tree with the post as its root and the replies as its descendants, are facing increasing threats from... | Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang |  |
| 2106 |  |  [Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models](https://aclanthology.org/2025.acl-long.618/) |  | 0 | Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce... | Jungwoo Park, Taewhoo Lee, Chanwoong Yoon, Hyeon Hwang, Jaewoo Kang |  |
| 2107 |  |  [Agentic Knowledgeable Self-awareness](https://aclanthology.org/2025.acl-long.619/) |  | 0 | Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional approaches adopt a “flood irrigation” methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice... | Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen |  |
| 2108 |  |  [A Unified Agentic Framework for Evaluating Conditional Image Generation](https://aclanthology.org/2025.acl-long.620/) |  | 0 | Conditional image generation has gained significant attention for its ability to personalize content. However, the field faces challenges in developing task-agnostic, reliable, and explainable evaluation metrics. This paper introduces CIGEval, a unified agentic framework for comprehensive... | Jifang Wang, Yangxue Yangxue, Longyue Wang, Zhenran Xu, Yiyu Wang, Yaowei Wang, Weihua Luo, Kaifu Zhang, Baotian Hu, Min Zhang |  |
| 2109 |  |  [Planning-Driven Programming: A Large Language Model Programming Workflow](https://aclanthology.org/2025.acl-long.621/) |  | 0 | The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs’... | Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger |  |
| 2110 |  |  [Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering](https://aclanthology.org/2025.acl-long.622/) |  | 0 | Recent works integrating Knowledge Graphs (KGs) have shown promising improvements in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing benchmarks primarily focus on closed-ended tasks, leaving a gap in evaluating performance on more complex, real-world... | Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi |  |
| 2111 |  |  [Nudging: Inference-time Alignment of LLMs via Guided Decoding](https://aclanthology.org/2025.acl-long.623/) |  | 0 | Large language models (LLMs) require alignment to effectively and safely follow user instructions. This process necessitates training an aligned version for every base model, resulting in significant computational overhead. In this work, we propose NUDGING, a simple, training-free algorithm that... | Yu Fei, Yasaman Razeghi, Sameer Singh |  |
| 2112 |  |  [Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing](https://aclanthology.org/2025.acl-long.624/) |  | 0 | Dynamical systems theory provides a framework for analyzing iterative processes and evolution over time. Within such systems, repetitive transformations can lead to stable configurations, known as attractors, including fixed points and limit cycles. Applying this perspective to large language... | Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang |  |
| 2113 |  |  [SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models](https://aclanthology.org/2025.acl-long.625/) |  | 0 | Recent studies emphasize that manually ensuring a consistent response style and maintaining high data quality in training sets can significantly improve the performance of fine-tuned Large Language Models (LLMs) while reducing the number of training examples needed. However, the precise definition... | Zhuang Li, Yuncheng Hua, ThuyTrang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari |  |
| 2114 |  |  [HFT: Half Fine-Tuning for Large Language Models](https://aclanthology.org/2025.acl-long.626/) |  | 0 | Large language models (LLMs) with one or more fine-tuning phases have become necessary to unlock various capabilities, enabling LLMs to follow natural language instructions and align with human preferences. However, it carries the risk of catastrophic forgetting during sequential training, the... | Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Weiran Xu, Yu Sun, Hua Wu |  |
| 2115 |  |  [Beyond Surface Simplicity: Revealing Hidden Reasoning Attributes for Precise Commonsense Diagnosis](https://aclanthology.org/2025.acl-long.627/) |  | 0 | Commonsense question answering (QA) are widely used to evaluate the commonsense abilities of large language models. However, answering commonsense questions correctly requires not only knowledge but also reasoning—even for seemingly simple questions. We demonstrate that such hidden reasoning... | Huijun Lian, Zekai Sun, Keqi Chen, Yingming Gao, Ya Li |  |
| 2116 |  |  [From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation](https://aclanthology.org/2025.acl-long.628/) |  | 0 | Automatically generating high-quality mathematical problems that align with educational objectives is a crucial task in NLP-based educational technology. Traditional generation methods focus primarily on textual quality, but they often overlook educational objectives. Moreover, these methods... | Cheng Cheng, Zhenya Huang, Guanhao Zhao, Yuxiang Guo, Xin Lin, Jinze Wu, Xin Li, Shijin Wang |  |
| 2117 |  |  [RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts](https://aclanthology.org/2025.acl-long.629/) |  | 0 | Retrieval-Augmented Generation (RAG) enhances the performance of Large Language Models (LLMs) by incorporating external knowledge. However, LLMs still encounter challenges in effectively utilizing the knowledge from retrieved documents, often being misled by irrelevant or noisy information. To... | Mingyan Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shi Yu, Zheni Zeng, Yu Gu, Ge Yu |  |
| 2118 |  |  [Lost in Literalism: How Supervised Training Shapes Translationese in LLMs](https://aclanthology.org/2025.acl-long.630/) |  | 0 | Large language models (LLMs) have achieved remarkable success in machine translation, demonstrating impressive performance across diverse languages. However, translationese—characterized by overly literal and unnatural translations—remains a persistent challenge in LLM-based translation systems.... | Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, Yongjing Yin, Tong Xiao, Yue Zhang |  |
| 2119 |  |  [Accurate KV Cache Quantization with Outlier Tokens Tracing](https://aclanthology.org/2025.acl-long.631/) |  | 0 | The impressive capabilities of Large Language Models (LLMs) come at the cost of substantial computational resources during deployment. While KV Cache can significantly reduce recomputation during inference, it also introduces additional memory overhead. KV Cache quantization presents a promising... | Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang |  |
| 2120 |  |  [Can Large Language Models Understand Internet Buzzwords Through User-Generated Content](https://aclanthology.org/2025.acl-long.632/) |  | 0 | The massive user-generated content (UGC) available in Chinese social media is giving rise to the possibility of studying internet buzzwords. In this paper, we study if large language models (LLMs) can generate accurate definitions for these buzzwords based on UGC as examples. Our work serves a... | Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv |  |
| 2121 |  |  [EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models](https://aclanthology.org/2025.acl-long.633/) |  | 0 | Mixture-of-Experts (MoE) has demonstrated promising potential in scaling LLMs. However, it is hindered by two critical challenges: (1) substantial GPU memory consumption to load all experts; (2) low activated parameters cannot be equivalently translated into inference acceleration effects. In this... | Yuanteng Chen, Yuantian Shao, Peisong Wang, Jian Cheng |  |
| 2122 |  |  [Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention](https://aclanthology.org/2025.acl-long.634/) |  | 0 | Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities in multimodal understanding, but they frequently suffer from hallucination - generating content inconsistent with visual inputs. In this work, we explore a novel perspective on hallucination mitigation by examining the... | Jingran Su, Jingfan Chen, Hongxin Li, Yuntao Chen, Li Qing, Zhaoxiang Zhang |  |
| 2123 |  |  [Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models](https://aclanthology.org/2025.acl-long.635/) |  | 0 | One of the primary driving forces contributing to the superior performance of Large Language Models (LLMs) is the extensive availability of human-annotated natural language data, which is used for alignment fine-tuning. This inspired researchers to investigate self-training methods to mitigate the... | Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu |  |
| 2124 |  |  [Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback](https://aclanthology.org/2025.acl-long.636/) |  | 0 | Existing Medical Large Vision-Language Models (Med-LVLMs), encapsulating extensive medical knowledge, demonstrate excellent capabilities in understanding medical images. However, there remain challenges in visual localization in medical images, which is crucial for abnormality detection and... | Yucheng Zhou, Lingran Song, Jianbing Shen |  |
| 2125 |  |  [Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging](https://aclanthology.org/2025.acl-long.637/) |  | 0 | Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and demonstrates outstanding performance in plentiful natural language processing tasks. However, existing methods transforming LLMs from dense to MoE face significant data requirements and typically rely on large-scale... | Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su |  |
| 2126 |  |  [MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation](https://aclanthology.org/2025.acl-long.638/) |  | 0 | Vision-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to... | Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu |  |
| 2127 |  |  [Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging](https://aclanthology.org/2025.acl-long.639/) |  | 0 | Medical imaging provides essential visual insights for diagnosis, and multimodal large language models (MLLMs) are increasingly utilized for its analysis due to their strong generalization capabilities; however, the underlying factors driving this generalization remain unclear. Current research... | Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang |  |
| 2128 |  |  [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://aclanthology.org/2025.acl-long.640/) |  | 0 | Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal abilities but remain prone to multilingual object hallucination, with a higher likelihood of generating responses inconsistent with the visual input when utilizing queries in non-English languages compared to English. Most... | Zekai Ye, Qiming Li, Xiaocheng Feng, Libo Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin |  |
| 2129 |  |  [Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching](https://aclanthology.org/2025.acl-long.641/) |  | 0 | The goal of conversational product search (CPS) is to develop an intelligent, chat-based shopping assistant that can directly interact with customers to understand shopping intents, ask clarification questions, and find relevant products. However, training such assistants is hindered mainly due to... | Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi |  |
| 2130 |  |  [Qwen2.5-xCoder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning](https://aclanthology.org/2025.acl-long.642/) |  | 0 | Recent advancement in code understanding and generation demonstrates that code LLMs fine-tuned on a high-quality instruction dataset can gain powerful capabilities to address wide-ranging code-related tasks. However, most previous existing methods mainly view each programming language in isolation... | Jian Yang, Wei Zhang, Yibo Miao, Shanghaoran Quan, Zhenhe Wu, Qiyao Peng, Liqun Yang, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin |  |
| 2131 |  |  [Cultivating Gaming Sense for Yourself: Making VLMs Gaming Experts](https://aclanthology.org/2025.acl-long.643/) |  | 0 | Developing agents capable of fluid gameplay in first/third-person games without API access remains a critical challenge in Artificial General Intelligence (AGI). Recent efforts leverage Vision Language Models (VLMs) as direct controllers, frequently pausing the game to analyze screens and plan... | Wenxuan Lu, Jiangyang He, Zhanqiu Zhang, Steven Y. Guo, Tianning Zang |  |
| 2132 |  |  [Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning](https://aclanthology.org/2025.acl-long.644/) |  | 0 | Advancing LLM reasoning skills has captivated wide interest. However, current post-training techniques rely heavily on supervisory signals, such as outcome supervision or auxiliary reward models, which face the problem of scalability and high annotation costs. This motivates us to enhance LLM... | Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Qiushi Sun, Kanzhi Cheng, Junxian He, Jun Liu, Zhiyong Wu |  |
| 2133 |  |  [Extending Complex Logical Queries on Uncertain Knowledge Graphs](https://aclanthology.org/2025.acl-long.645/) |  | 0 | The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world,... | Weizhi Fei, Zihao Wang, Hang Yin, Yang Duan, Yangqiu Song |  |
| 2134 |  |  [Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models](https://aclanthology.org/2025.acl-long.646/) |  | 0 | As large language models (LLMs) require continuous knowledge updates and the mitigation of hallucination issues in generated content, lifelong model editing has become a prominent research area. A mainstream knowledge editing method usually freezes LLM’s original parameters and adds extra trainable... | Haoyu Xu, Pengxiang Lan, Enneng Yang, Guibing Guo, Jianzhe Zhao, Linying Jiang, Xingwei Wang |  |
| 2135 |  |  [φ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation](https://aclanthology.org/2025.acl-long.647/) |  | 0 | Inference-time optimization scales computation to derive deliberate reasoning steps for effective performance. While previous search-based strategies address the short-sightedness of auto-regressive generation, the vast search space leads to excessive exploration and insufficient exploitation. To... | Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu |  |
| 2136 |  |  [Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?](https://aclanthology.org/2025.acl-long.648/) |  | 0 | The radioactive nature of Large Language Model (LLM) watermarking enables the detection of watermarks inherited by student models when trained on the outputs of watermarked teacher models, making it a promising tool for preventing unauthorized knowledge distillation. However, the robustness of... | Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian Lu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu |  |
| 2137 |  |  [Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization](https://aclanthology.org/2025.acl-long.649/) |  | 0 | Reward models (RMs) play a crucial role in reinforcement learning from human feedback (RLHF), aligning model behavior with human preferences. However, existing benchmarks for reward models show a weak correlation with the performance of optimized policies, suggesting that they fail to accurately... | Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo |  |
| 2138 |  |  [Inducing lexicons of in-group language with socio-temporal context](https://aclanthology.org/2025.acl-long.650/) |  | 0 | In-group language is an important signifier of group dynamics. This paper proposes a novel method for inducing lexicons of in-group language, which incorporates its socio-temporal context. Existing methods for lexicon induction do not capture the evolving nature of in-group language, nor the social... | Christine de Kock |  |
| 2139 |  |  [LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement](https://aclanthology.org/2025.acl-long.651/) |  | 0 | Recent advancements in language models (LMs) have demonstrated strong capabilities in semantic understanding and contextual modeling, which have flourished in generative speech enhancement (SE). However, many LM-based SE approaches primarily focus on semantic information, often neglecting the... | Boyi Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, Chao Weng, Wei Xue, Lei Xie |  |
| 2140 |  |  [MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference](https://aclanthology.org/2025.acl-long.652/) |  | 0 | This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting... | Kunxi Li, Zhonghua Jiang, Zhouzhou Shen, Zhaode Wang, Chengfei Lv, Shengyu Zhang, Fan Wu, Fei Wu |  |
| 2141 |  |  [Efficient OpAmp Adaptation for Zoom Attention to Golden Contexts](https://aclanthology.org/2025.acl-long.653/) |  | 0 | Large language models (LLMs) have shown significant promise in question-answering (QA) tasks, particularly in retrieval-augmented generation (RAG) scenarios and long-context applications. However, their performance is hindered by noisy reference documents, which often distract from essential... | Haoyuan Wu, Rui Ming, Haisheng Zheng, Zhuolun He, Bei Yu |  |
| 2142 |  |  [Language-Codec: Bridging Discrete Codec Representations and Speech Language Models](https://aclanthology.org/2025.acl-long.654/) |  | 0 | In recent years, large language models have achieved significant success in generative tasks (e.g., speech cloning and audio generation) related to speech, audio, music, and other signal domains. A crucial element of these models is the discrete acoustic codecs, which serve as an intermediate... | Shengpeng Ji, Minghui Fang, Jialong Zuo, Ziyue Jiang, Dingdong Wang, Hanting Wang, Hai Huang, Zhou Zhao |  |
| 2143 |  |  [Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger](https://aclanthology.org/2025.acl-long.655/) |  | 0 | Large language models (LLMs) have shown remarkable emergent capabilities, transforming the execution of functional tasks by leveraging external tools for complex problems that require specialized processing or up-to-date data. While existing research expands LLMs access to diverse tools (e.g.,... | Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu |  |
| 2144 |  |  [MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark](https://aclanthology.org/2025.acl-long.656/) |  | 0 | Multiple-choice question (MCQ) datasets like Massive Multitask Language Understanding (MMLU) are widely used to evaluate the commonsense, understanding, and problem-solving abilities of large language models (LLMs). However, the open-source nature of these benchmarks and the broad sources of... | Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei |  |
| 2145 |  |  [Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](https://aclanthology.org/2025.acl-long.657/) |  | 0 | As large language models (LLMs) have advanced rapidly, concerns regarding their safety have become prominent. In this paper, we discover that code-switching in red-teaming queries can effectively elicit undesirable behaviors of LLMs, which are common practices in natural language. We introduce a... | Haneul Yoo, Yongjin Yang, Hwaran Lee |  |
| 2146 |  |  [Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch](https://aclanthology.org/2025.acl-long.658/) |  | 0 | Improving the mathematical reasoning capabilities of Large Language Models (LLMs) is critical for advancing artificial intelligence. However, access to extensive, diverse, and high-quality reasoning datasets remains a significant challenge, particularly for the open-source community. In this paper,... | Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Zhaopeng Tu, Qiaoming Zhu, Min Zhang |  |
| 2147 |  |  [DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing](https://aclanthology.org/2025.acl-long.659/) |  | 0 | Automated essay scoring (AES) is a useful tool in English as a Foreign Language (EFL) writing education, offering real-time essay scores for students and instructors. However, previous AES models were trained on essays and scores irrelevant to the practical scenarios of EFL writing education and... | Haneul Yoo, Jieun Han, SoYeon Ahn, Alice Oh |  |
| 2148 |  |  [PQR: Improving Dense Retrieval via Potential Query Modeling](https://aclanthology.org/2025.acl-long.660/) |  | 0 | Dense retrieval has now become the mainstream paradigm in information retrieval. The core idea of dense retrieval is to align document embeddings with their corresponding query embeddings by maximizing their dot product. The current training data is quite sparse, with each document typically... | Junfeng Kang, Rui Li, Qi Liu, Yanjiang Chen, Zheng Zhang, Junzhe Jiang, Heng Yu, Yu Su |  |
| 2149 |  |  [Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons](https://aclanthology.org/2025.acl-long.661/) |  | 0 | Multilingual language models (MLLMs) have demonstrated remarkable abilities to transfer knowledge across languages, despite being trained without explicit cross-lingual supervision. We analyze the parameter spaces of three MLLMs to study how their representations evolve during pre-training,... | Frederick Riemenschneider, Anette Frank |  |
| 2150 |  |  [SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework](https://aclanthology.org/2025.acl-long.662/) |  | 0 | The rapid advancement of large language models (LLMs) in recent years has made it feasible to establish domain-specific LLMs for specialized fields. However, in practical development, acquiring domain-specific knowledge often requires a significant amount of professional expert manpower. Moreover,... | Cheng Guo, Hu Kai, Shuxian Liang, Yiyang Jiang, Yi Gao, XianSheng Hua, Wei Dong |  |
| 2151 |  |  [ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents](https://aclanthology.org/2025.acl-long.663/) |  | 0 | Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in... | Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang |  |
| 2152 |  |  [Lexical Recall or Logical Reasoning: Probing the Limits of Reasoning Abilities in Large Language Models](https://aclanthology.org/2025.acl-long.664/) |  | 0 | Despite the increasing interest in the reasoning abilities of Large Language Models (LLMs), existing work shows limitations in assessing logic abilities independently from lexical memory. We address this gap with Mystery-Zebra. This robust two-part benchmark (4,290 puzzles) challenges the logic... | Henrike Beyer, Chris Reed |  |
| 2153 |  |  [ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains](https://aclanthology.org/2025.acl-long.665/) |  | 0 | Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable... | Zilu Dong, Xiangqing Shen, Zinong Yang, Rui Xia |  |
| 2154 |  |  [HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model](https://aclanthology.org/2025.acl-long.666/) |  | 0 | Instruction tuning is widely used to enhance a pre-trained Multimodal Large Language Model (MLLM) to understand and follow human instructions by training it on a curated set of task-specific dataset. However, it is infeasible to collect all possible instruction datasets simultaneously in real-world... | Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, DaHan Wang, XuYao Zhang, ChengLin Liu |  |
| 2155 |  |  [Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models](https://aclanthology.org/2025.acl-long.667/) |  | 0 | Due to the presence of the natural gap between Knowledge Graph (KG) structures and the natural language, the effective integration of holistic structural information of KGs with Large Language Models (LLMs) has emerged as a significant question. To this end, we propose a two-stage framework to... | Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng |  |
| 2156 |  |  [Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking](https://aclanthology.org/2025.acl-long.668/) |  | 0 | Chain-of-thought (CoT) significantly enhances the performance of large language models (LLMs) across a wide range of tasks, and prior research shows that CoT can theoretically increase expressiveness. However, there is limited mechanistic understanding of the algorithms that Transformer+CoT can... | Yifan Zhang, Wenyu Du, Dongming Jin, Jie Fu, Zhi Jin |  |
| 2157 |  |  [TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition](https://aclanthology.org/2025.acl-long.669/) |  | 0 | While Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA) effectively address resource constraints during fine-tuning, their performance often falls short, especially in multidimensional task scenarios. To address this issue, one straightforward solution is to introduce... | Tianwei Lin, Jiang Liu, Wenqiao Zhang, Yang Dai, Haoyuan Li, Zhelun Yu, Wanggui He, Juncheng Li, Jiannan Guo, Hao Jiang, Siliang Tang, Yueting Zhuang |  |
| 2158 |  |  [CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models](https://aclanthology.org/2025.acl-long.670/) |  | 0 | Large language models (LLMs) are possessed of numerous beneficial capabilities, yet their potential inclination harbors unpredictable risks that may materialize in the future. We hence propose CRiskEval, a Chinese dataset meticulously designed for gauging the risk proclivities inherent in LLMs such... | Ling Shi, Deyi Xiong |  |
| 2159 |  |  [STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning](https://aclanthology.org/2025.acl-long.671/) |  | 0 | Mixture-of-experts (MoEs) have been adopted for reducing inference costs by sparsely activating experts in large language models (LLMs). Despite these reductions, the massive number of parameters in MoEs still makes them expensive to serve. Conventionally, unstructured or structured pruning has... | Jaeseong Lee, Seungwon Hwang, Aurick Qiao, Daniel F. Campos, Zhewei Yao, Yuxiong He |  |
| 2160 |  |  [Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System](https://aclanthology.org/2025.acl-long.672/) |  | 0 | Information theft attacks pose a significant risk to Large Language Model (LLM) tool-learning systems. Adversaries can inject malicious commands through compromised tools, manipulating LLMs to send sensitive information to these tools, which leads to potential privacy breaches. However, existing... | Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang |  |
| 2161 |  |  [FlashAudio: Rectified Flow for Fast and High-Fidelity Text-to-Audio Generation](https://aclanthology.org/2025.acl-long.673/) |  | 0 | Recent advancements in latent diffusion models (LDMs) have markedly enhanced text-to-audio generation, yet their iterative sampling processes impose substantial computational demands, limiting practical deployment. While recent methods utilizing consistency-based distillation aim to achieve... | Huadai Liu, Jialei Wang, Rongjie Huang, Yang Liu, Heng Lu, Zhou Zhao, Wei Xue |  |
| 2162 |  |  [How does Misinformation Affect Large Language Model Behaviors and Preferences?](https://aclanthology.org/2025.acl-long.674/) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in knowledge-intensive tasks, while they remain vulnerable when encountering misinformation. Existing studies have explored the role of LLMs in combating misinformation, but there is still a lack of fine-grained analysis on the... | Miao Peng, Nuo Chen, Jianheng Tang, Jia Li |  |
| 2163 |  |  [YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering](https://aclanthology.org/2025.acl-long.675/) |  | 0 | Large Language Models (LLMs) drive scientific question-answering on modern search engines, yet their evaluation robustness remains underexplored. We introduce YESciEval, an open-source framework that combines fine-grained rubric-based assessment with reinforcement learning to mitigate optimism bias... | Jennifer D'Souza, Hamed Babaei Giglou, Quentin Münch |  |
| 2164 |  |  [GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding](https://aclanthology.org/2025.acl-long.676/) |  | 0 | Programming languages possess rich semantic information - such as data flow - that is represented by graphs and not available from the surface form of source code. Recent code language models have scaled to billions of parameters, but model source code solely as text tokens while ignoring any other... | Ziyin Zhang, Hang Yu, Sage Lee, Peng Di, Jianguo Li, Rui Wang |  |
| 2165 |  |  [MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis](https://aclanthology.org/2025.acl-long.677/) |  | 0 | Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical decision-making, in which physicians iteratively refine a ranked list of possible diseases based on symptoms, antecedents, and medical knowledge. While recent advances in large language models (LLMs) have shown promise in... | Daniel Philip Rose, ChiaChien Hung, Marco Lepri, Israa Alqassem, Kiril Gashteovski, Carolin Lawrence |  |
| 2166 |  |  [A Training-free LLM-based Approach to General Chinese Character Error Correction](https://aclanthology.org/2025.acl-long.678/) |  | 0 | Chinese spelling correction (CSC) is a crucial task that aims to correct character errors in Chinese text. While conventional CSC focuses on character substitution errors caused by mistyping, two other common types of character errors, missing and redundant characters, have received less attention.... | Houquan Zhou, Bo Zhang, Zhenghua Li, Ming Yan, Min Zhang |  |
| 2167 |  |  [HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models](https://aclanthology.org/2025.acl-long.679/) |  | 0 | Medical Vision-Language Models (Med-VLMs) have achieved success across various tasks, yet most existing methods overlook the modality misalignment issue that can lead to untrustworthy responses in clinical settings. In this paper, we propose Hierarchical Self-Contrastive Rewarding (HSCR), a novel... | Songtao Jiang, Yan Zhang, Yeying Jin, Zhihang Tang, Yangyang Wu, Yang Feng, Jian Wu, Zuozhu Liu |  |
| 2168 |  |  [MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale](https://aclanthology.org/2025.acl-long.680/) |  | 0 | Open-source multimodal large language models (MLLMs) have shown significant potential in a broad range of tasks. However, their reasoning capabilities remain constrained by existing instruction-tuning datasets, which were predominately repurposed from academic datasets such as VQA, AI2D, and... | Jiawei Guo, Tianyu Zheng, Yizhi Li, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Graham Neubig, Wenhu Chen, Xiang Yue |  |
| 2169 |  |  [SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning](https://aclanthology.org/2025.acl-long.681/) |  | 0 | We introduce SIFT (Speech Instruction Fine-Tuning), a 50M-example dataset designed for instruction fine-tuning and pre-training of speech-text large language models (LLMs). SIFT-50M is built from publicly available speech corpora, which collectively contain 14K hours of speech, and leverages LLMs... | Prabhat Pandey, Rupak Vignesh Swaminathan, K. V. Vijay Girish, Arunasish Sen, Jian Xie, Grant P. Strimel, Andreas Schwarz |  |
| 2170 |  |  [Recent Advances in Speech Language Models: A Survey](https://aclanthology.org/2025.acl-long.682/) |  | 0 | Text-based Large Language Models (LLMs) have recently gained significant attention, primarily for their capabilities in text-based interactions. However, natural human interaction often relies on speech, highlighting the need for voice-based models. In this context, Speech Language Models... | Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Steven Y. Guo, Irwin King |  |
| 2171 |  |  [LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments](https://aclanthology.org/2025.acl-long.683/) |  | 0 | Efficient retrieval of pinpointed information from case law is crucial for legal professionals but challenging due to the length and complexity of legal judgments. Existing works mostly often focus on retrieving entire cases rather than precise, paragraph-level information. Moreover, multilingual... | Rohit Upadhya, T. Y. S. S. Santosh |  |
| 2172 |  |  [Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries](https://aclanthology.org/2025.acl-long.684/) |  | 0 | Current multi-task adversarial text attacks rely on abundant access to shared internal features and numerous queries, often limited to a single task type. As a result, these attacks are less effective against practical scenarios involving black-box feedback APIs, limited queries, or multiple task... | Wenqiang Wang, Yan Xiao, Hao Lin, Yangshijie Zhang, Xiaochun Cao |  |
| 2173 |  |  [SPECTRA: Faster Large Language Model Inference with Optimized Internal and External Speculation](https://aclanthology.org/2025.acl-long.685/) |  | 0 | Inference with modern Large Language Models (LLMs) is both computationally expensive and time-consuming. Speculative decoding has emerged as a promising solution, but existing approaches face key limitations: training-based methods require a draft model that is challenging to obtain and lacks... | NguyenKhang Le, Truong Dinh Do, LeMinh Nguyen |  |
| 2174 |  |  [Multi-level Association Refinement Network for Dialogue Aspect-based Sentiment Quadruple Analysis](https://aclanthology.org/2025.acl-long.686/) |  | 0 | Dialogue Aspect-based Sentiment Quadruple (DiaASQ) analysis aims to identify all quadruples (i.e., target, aspect, opinion, sentiment) from the dialogue. This task is challenging as different elements within a quadruple may manifest in different utterances, requiring precise handling of... | Zeliang Tong, Wei Wei, Xiaoye Qu, Rikui Huang, Zhixin Chen, Xingyu Yan |  |
| 2175 |  |  [Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs](https://aclanthology.org/2025.acl-long.687/) |  | 0 | The financial industry faces a substantial workload in verifying document images. Existing methods based on visual features struggle to identify fraudulent document images due to the lack of visual clues on the tampering region. This paper proposes CSIAD (Cross-Sample Image Anomaly Detection) by... | Qiwen Wang, Junqi Yang, Zhenghao Lin, Zhenzhe Ying, Weiqiang Wang, Chen Lin |  |
| 2176 |  |  [Cooperative or Competitive? Understanding the Interaction between Attention Heads From A Game Theory Perspective](https://aclanthology.org/2025.acl-long.688/) |  | 0 | Despite the remarkable success of attention-based large language models (LLMs), the precise interaction mechanisms between attention heads remain poorly understood. In contrast to prevalent methods that focus on individual head contributions, we rigorously analyze the intricate interplay among... | Xiaoye Qu, Zengqi Yu, Dongrui Liu, Wei Wei, Daizong Liu, Jianfeng Dong, Yu Cheng |  |
| 2177 |  |  [MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification](https://aclanthology.org/2025.acl-long.689/) |  | 0 | According to the Test-Time Scaling, the integration of External Slow-Thinking with the Verify mechanism has been demonstrated to enhance multi-round reasoning in large language models (LLMs). However, in the multimodal (MM) domain, there is still a lack of a strong MM-Verifier. In this paper, we... | Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, Wentao Zhang |  |
| 2178 |  |  [Graph-Structured Trajectory Extraction from Travelogues](https://aclanthology.org/2025.acl-long.690/) |  | 0 | Human traveling trajectories play a central role in characterizing each travelogue, and automatic trajectory extraction from travelogues is highly desired for tourism services, such as travel planning and recommendation. This work addresses the extraction of human traveling trajectories from... | Aitaro Yamamoto, Hiroyuki Otomo, Hiroki Ouchi, Shohei Higashiyama, Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe |  |
| 2179 |  |  [Learning First-Order Logic Rules for Argumentation Mining](https://aclanthology.org/2025.acl-long.691/) |  | 0 | Argumentation Mining (AM) aims to extract argumentative structures from texts by identifying argumentation components (ACs) and their argumentative relations (ARs). While previous works focus on representation learning to encode ACs and AC pairs, they fail to explicitly model the underlying... | Yang Sun, Guanrong Chen, Hamid AlinejadRokny, Jianzhu Bao, Yuqi Huang, Bin Liang, KamFai Wong, Min Yang, Ruifeng Xu |  |
| 2180 |  |  [Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency](https://aclanthology.org/2025.acl-long.692/) |  | 0 | Large Multimodal Models (LMMs) have recently demonstrated impressive performance on general video comprehension benchmarks. Nevertheless, for broader applications, the robustness of their temporal analysis capability needs to be thoroughly investigated yet predominantly ignored. Motivated by this,... | Jiafeng Liang, Shixin Jiang, Xuan Dong, Ning Wang, Zheng Chu, Hui Su, Jinlan Fu, Ming Liu, SeeKiong Ng, Bing Qin |  |
| 2181 |  |  [UniRAG: Unified Query Understanding Method for Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.693/) |  | 0 | Retrieval-Augmented Generation (RAG) technology effectively addresses the issues of knowledge update lag and hallucinations in large language models (LLMs) by integrating internal and external knowledge. Existing query augmentation methods improve RAG’s performance in handling complex queries but... | Rui Li, Liyang He, Qi Liu, Zheng Zhang, Heng Yu, Yuyang Ye, Linbo Zhu, Yu Su |  |
| 2182 |  |  [Contextual Experience Replay for Self-Improvement of Language Agents](https://aclanthology.org/2025.acl-long.694/) |  | 0 | Large language model (LLM) agents have been applied to sequential decision-making tasks such as web navigation, but without any environment-specific experiences, they often fail in these complex tasks. Moreover, current LLM agents are not designed to continually learn from past experiences during... | Yitao Liu, Chenglei Si, Karthik R. Narasimhan, Shunyu Yao |  |
| 2183 |  |  [Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning](https://aclanthology.org/2025.acl-long.695/) |  | 0 | Traditional reinforcement learning-based robotic control methods are often task-specific and fail to generalize across diverse environments or unseen objects and instructions. Visual Language Models (VLMs) demonstrate strong scene understanding and planning capabilities but lack the ability to... | Qi Sun, Pengfei Hong, Pala Tej Deep, Vernon Toh, UXuan Tan, Deepanway Ghosal, Soujanya Poria |  |
| 2184 |  |  [Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method](https://aclanthology.org/2025.acl-long.696/) |  | 0 | Argument mining has garnered increasing attention over the years, with the recent advancement of Large Language Models (LLMs) further propelling this trend. However, current argument relations remain relatively simplistic and foundational, struggling to capture the full scope of argument... | Yupei Ren, Xinyi Zhou, Ning Zhang, Shangqing Zhao, Man Lan, Xiaopeng Bai |  |
| 2185 |  |  [Browsing Like Human: A Multimodal Web Agent with Experiential Fast-and-Slow Thinking](https://aclanthology.org/2025.acl-long.697/) |  | 0 | Automating web navigation which aims to build a web agent that follows user instructions to complete tasks like booking flights by interacting with websites, has received increasing attention due to its practical value. Although existing web agents are mostly equipped with visual perception,... | Haohao Luo, Jiayi Kuang, Wei Liu, Ying Shen, Jian Luan, Yang Deng |  |
| 2186 |  |  [MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation](https://aclanthology.org/2025.acl-long.698/) |  | 0 | With the rapid adoption of large language models (LLMs) in natural language processing, the ability to follow instructions has emerged as a key metric for evaluating their practical utility. However, existing evaluation methods often focus on single-language scenarios, overlooking the challenges... | Yile Liu, Ziwei Ma, Xiu Jiang, Jinglu Hu, ChangJing ChangJing, Liang Li |  |
| 2187 |  |  [Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning](https://aclanthology.org/2025.acl-long.699/) |  | 0 | Scaling pre-training compute has proven effective for achieving multilinguality, but does the same hold for test-time scaling? In this work, we introduce \*\*MCLM\*\*, a multilingual math benchmark featuring competition-level problems in 55 languages. We then compare three test-time scaling... | Guijin Son, Jiwoo Hong, Hyunwoo Ko, James Thorne |  |
| 2188 |  |  [Can MLLMs Understand the Deep Implication Behind Chinese Images?](https://aclanthology.org/2025.acl-long.700/) |  | 0 | As the capabilities of Multimodal Large Language Models (MLLMs) improve, the need for higher-order evaluation of them is increasing. However, there is a lack of work evaluating MLLM for higher-order perception and understanding of Chinese visual content. To address this, we introduce the CII-Bench,... | Chenhao Zhang, Xi Feng, Yuelin Bai, Xeron Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni |  |
| 2189 |  |  [KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan](https://aclanthology.org/2025.acl-long.701/) |  | 0 | Despite having a population of twenty million, Kazakhstan’s culture and language remain underrepresented in the field of natural language processing. Although large language models (LLMs) continue to advance worldwide, progress in Kazakh language has been limited, as seen in the scarcity of... | Mukhammed Togmanov, Nurdaulet Mukhituly, Diana Turmakhan, Jonibek Mansurov, Maiya Goloburda, Akhmed Sakip, Zhuohan Xie, Yuxia Wang, Bekassyl Syzdykov, Nurkhan Laiyk, Alham Fikri Aji, Ekaterina Kochmar, Preslav Nakov, Fajri Koto |  |
| 2190 |  |  [Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages](https://aclanthology.org/2025.acl-long.702/) |  | 0 | Evaluation frameworks for text summarization have evolved in terms of both domain coverage and metrics. However, existing benchmarks still lack domain-specific assessment criteria, remain predominantly English-centric, and face challenges with human annotation due to the complexity of reasoning. To... | Hyangsuk Min, Yuho Lee, Minjeong Ban, Jiaqi Deng, Nicole HeeYeon Kim, Taewon Yun, Hang Su, Jason Cai, Hwanjun Song |  |
| 2191 |  |  [ClusterAttn: KV Cache Compression under Intrinsic Attention Clustering](https://aclanthology.org/2025.acl-long.703/) |  | 0 | Sparse attention can effectively alleviate the significant demands on memory when large language models (LLMs) process long contexts. Existing methods typically apply the same sparse pattern across different attention heads and inputs. However, this uniform approach fails to capture the inherent... | Minwei Zhang, Haifeng Sun, Jingyu Wang, Shaolong Li, Wanyi Ning, Qi Qi, Zirui Zhuang, Jianxin Liao |  |
| 2192 |  |  [SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script](https://aclanthology.org/2025.acl-long.704/) |  | 0 | Shared memories between two individuals strengthen their bond and are crucial for facilitating their ongoing conversations. This study aims to make long-term dialogue more engaging by leveraging these shared memories. To this end, we introduce a new long-term dialogue dataset named SHARE,... | Eunwon Kim, Chanho Park, Buru Chang |  |
| 2193 |  |  [Incongruity-aware Tension Field Network for Multi-modal Sarcasm Detection](https://aclanthology.org/2025.acl-long.705/) |  | 0 | Multi-modal sarcasm detection (MSD) identifies sarcasm and accurately understands users’ real attitudes from text-image pairs. Most MSD researches explore the incongruity of text-image pairs as sarcasm information through consistency preference methods. However, these methods prioritize consistency... | Jiecheng Zhang, C. L. Philip Chen, Shuzhen Li, Tong Zhang |  |
| 2194 |  |  [Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh](https://aclanthology.org/2025.acl-long.706/) |  | 0 | Instruction tuning in low-resource languages remains underexplored due to limited text data, particularly in government and cultural domains. To address this, we introduce and open-source a large-scale (10,600 samples) instruction-following (IFT) dataset, covering key institutional and cultural... | Nurkhan Laiyk, Daniil Orel, Rituraj Joshi, Maiya Goloburda, Yuxia Wang, Preslav Nakov, Fajri Koto |  |
| 2195 |  |  [Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack](https://aclanthology.org/2025.acl-long.707/) |  | 0 | Decentralized training has become a resource-efficient framework to democratize the training of large language models (LLMs). However, the privacy risks associated with this framework, particularly due to the potential inclusion of sensitive data in training datasets, remain unexplored. This paper... | Chenxi Dai, Lin Lu, Pan Zhou |  |
| 2196 |  |  [From Selection to Generation: A Survey of LLM-based Active Learning](https://aclanthology.org/2025.acl-long.708/) |  | 0 | Active Learning (AL) has been a powerful paradigm for improving model efficiency and performance by selecting the most informative data points for labeling and training. In recent active learning frameworks, Large Language Models (LLMs) have been employed not only for selection but also for... | Yu Xia, Subhojyoti Mukherjee, Zhouhang Xie, Junda Wu, Xintong Li, Ryan Aponte, Hanjia Lyu, Joe Barrow, Hongjie Chen, Franck Dernoncourt, Branislav Kveton, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Sungchul Kim, Zhengmian Hu, Yue Zhao, Nedim Lipka, Seunghyun Yoon, TingHao Kenneth Huang, Zichao Wang, Puneet Mathur, Soumyabrata Pal, Koyel Mukherjee, Zhehao Zhang, Namyong Park, Thien Huu Nguyen, Jiebo Luo, Ryan A. Rossi, Julian J. McAuley |  |
| 2197 |  |  [OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation](https://aclanthology.org/2025.acl-long.709/) |  | 0 | Full-duplex spoken dialogue systems significantly surpass traditional turn-based dialogue systems, as they allow simultaneous bidirectional communication, closely mirroring human-human interactions. However, achieving low latency and natural interactions in full-duplex dialogue systems remains a... | Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, ChaoHong Tan, Zhihao Du, Shiliang Zhang |  |
| 2198 |  |  [DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning](https://aclanthology.org/2025.acl-long.710/) |  | 0 | Domain-Adaptive Pre-training (DAP) has recently gained attention for its effectiveness in fine-tuning pre-trained models. Building on this, continual DAP has been explored to develop pre-trained models capable of incrementally incorporating different domain datasets. However, existing continual DAP... | Dohoon Kim, Donghun Kang, Taesup Moon |  |
| 2199 |  |  [EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model](https://aclanthology.org/2025.acl-long.711/) |  | 0 | Recent advancements in Large Vision Language Models (LVLMs) show promise for pathological diagnosis, yet their application in clinical settings faces critical challenges of multimodal hallucination and biased responses. While preference alignment methods have proven effective in general domains,... | Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoqin Wang, Xinheng Lyu, Wenting Chen, Linlin Shen |  |
| 2200 |  |  [CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations](https://aclanthology.org/2025.acl-long.712/) |  | 0 | We introduce CoT-ICL Lab, a framework and methodology to generate synthetic tokenized datasets and systematically study chain-of thought (CoT) in-context learning (ICL) in language models. CoT-ICL Lab allows fine grained control over the complexity of in-context examples by decoupling (1) the... | Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi |  |
| 2201 |  |  [Flexora: Flexible Low-Rank Adaptation for Large Language Models](https://aclanthology.org/2025.acl-long.713/) |  | 0 | Large language models (LLMs) have revolutionized artificial intelligence, but their performance on specific tasks is often limited by knowledge boundaries. While fine-tuning techniques like low-rank adaptation (LoRA) aim to address this, they can suffer from overfitting. We propose flexible... | Chenxing Wei, Yao Shu, Ying Tiffany He, Fei Yu |  |
| 2202 |  |  [QDTSynth: Quality-Driven Formal Theorem Synthesis for Enhancing Proving Performance of LLMs](https://aclanthology.org/2025.acl-long.714/) |  | 0 | Automated Theorem Proving is an important and challenging task. Although large language models (LLMs) have demonstrated remarkable potential in mathematical reasoning, their performance in formal theorem proving remains constrained by the scarcity of high-quality supervised fine-tuning (SFT) data.... | Lei Wang, Ruobing Zuo, Gaolei He, Jianlin Wang, Zhengfeng Yang |  |
| 2203 |  |  [RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought](https://aclanthology.org/2025.acl-long.715/) |  | 0 | Multi-modal Large Language Models (MLLMs) have demonstrated remarkable reasoning capability while lack explicit mechanisms for visual grounding and segmentation, creating a gap between cognitive reasoning and visual perception. To bridge this gap, we introduce Reasoning Segmentation via Visual... | Yi Lu, Jiawang Cao, Yongliang Wu, Bozheng Li, Licheng Tang, Yangguang Ji, Chong Wu, Jay Wu, Wenbo Zhu |  |
| 2204 |  |  [QAEval: Mixture of Evaluators for Question-Answering Task Evaluation](https://aclanthology.org/2025.acl-long.716/) |  | 0 | Question answering (QA) tasks serve as a key benchmark for evaluating generation systems. Traditional rule-based metrics, such as accuracy and relaxed-accuracy, struggle with open-ended and unstructured responses. LLM-based evaluation methods offer greater flexibility but suffer from sensitivity to... | Tan Yue, Rui Mao, Xuzhao Shi, Shuo Zhan, Zuhao Yang, Dongyan Zhao |  |
| 2205 |  |  [Debiasing the Fine-Grained Classification Task in LLMs with Bias-Aware PEFT](https://aclanthology.org/2025.acl-long.717/) |  | 0 | Fine-grained classification via LLMs is susceptible to more complex label biases compared to traditional classification tasks. Existing bias mitigation strategies, such as retraining, post-hoc adjustment, and parameter-efficient fine-tuning (PEFT) are primarily effective for simple classification... | Daiying Zhao, Xinyu Yang, Hang Chen |  |
| 2206 |  |  [Demystifying Small Language Models for Edge Deployment](https://aclanthology.org/2025.acl-long.718/) |  | 0 | Small language models (SLMs) have emerged as a promising solution for deploying resource-constrained devices, such as smartphones and Web of Things. This work presents the first comprehensive study of over 60 SLMs such as Microsoft Phi and Google Gemma that are publicly accessible. Our findings... | Zhenyan Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Wei Liu, Jian Luan, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu |  |
| 2207 |  |  [Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models](https://aclanthology.org/2025.acl-long.719/) |  | 0 | Parameter-efficient fine-tuning (PEFT) has become a common method for fine-tuning large language models, where a base model can serve multiple users through PEFT module switching. To enhance user experience, base models require periodic updates. However, once updated, PEFT modules fine-tuned on... | Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang |  |
| 2208 |  |  [Can Vision-Language Models Evaluate Handwritten Math?](https://aclanthology.org/2025.acl-long.720/) |  | 0 | Recent advancements in Vision-Language Models (VLMs) have opened new possibilities in automatic grading of handwritten student responses, particularly in mathematics. However, a comprehensive study to test the ability of VLMs to evaluate and reason over handwritten content remains absent. To... | Oikantik Nath, Hanani Bathina, Mohammed Safi Ur Rahman Khan, Mitesh M. Khapra |  |
| 2209 |  |  [Continual Gradient Low-Rank Projection Fine-Tuning for LLMs](https://aclanthology.org/2025.acl-long.721/) |  | 0 | Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model’s ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit... | Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing |  |
| 2210 |  |  [Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?](https://aclanthology.org/2025.acl-long.722/) |  | 0 | Fine-tuned Large Language Models (LLMs) often demonstrate poor calibration, with their confidence scores misaligned with actual performance. While calibration has been extensively studied in models trained from scratch, the impact of LLMs’ prior knowledge on calibration during fine-tuning remains... | Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li |  |
| 2211 |  |  [Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization](https://aclanthology.org/2025.acl-long.723/) |  | 0 | Sustainability reports are key for evaluating companies’ environmental, social and governance (ESG) performance. To analyze these reports, NLP approaches can efficiently extract ESG insights at scale. However, even the most advanced NLP methods lack robustness against ESG content that is... | Keane Ong, Rui Mao, Deeksha Varshney, Erik Cambria, Gianmarco Mengaldo |  |
| 2212 |  |  [HiddenDetect: Detecting Jailbreak Attacks against Multimodal Large Language Models via Monitoring Hidden States](https://aclanthology.org/2025.acl-long.724/) |  | 0 | The integration of additional modalities increases the susceptibility of large vision-language models (LVLMs) to safety risks, such as jailbreak attacks, compared to their language-only counterparts. While existing research primarily focuses on post-hoc alignment techniques, the underlying safety... | Yilei Jiang, Xinyan Gao, Tianshuo Peng, Yingshui Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue |  |
| 2213 |  |  [SwiLTra-Bench: The Swiss Legal Translation Benchmark](https://aclanthology.org/2025.acl-long.725/) |  | 0 | In Switzerland legal translation is uniquely important due to the country’s four official languages and requirements for multilingual legal documentation. However, this process traditionally relies on professionals who must be both legal experts and skilled translators—creating bottlenecks and... | Joel Niklaus, Jakob Merane, Luka Nenadic, Sina Ahmadi, Yingqiang Gao, Cyrill A. H. Chevalley, Claude Humbel, Christophe Gösken, Lorenzo Tanzi, Thomas Lüthi, Stefan Palombo, Spencer Poff, Boling Yang, Nan Wu, Matthew Guillod, Robin Mamié, Daniel Brunner, Julio Pereyra, Niko Grupen |  |
| 2214 |  |  [Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement](https://aclanthology.org/2025.acl-long.726/) |  | 0 | Recent research has shown that large language models (LLMs) can enhance translation quality through self-refinement. In this paper, we build on this idea by extending the refinement from sentence-level to document-level translation, specifically focusing on document-to-document (Doc2Doc)... | Yichen Dong, Xinglin Lyu, Junhui Li, Daimeng Wei, Min Zhang, Shimin Tao, Hao Yang |  |
| 2215 |  |  [Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models](https://aclanthology.org/2025.acl-long.727/) |  | 0 | A fundamental question in interpretability research is to what extent neural networks, particularly language models, implement reusable functions through subnetworks that can be composed to perform more complex tasks. Recent advances in mechanistic interpretability have made progress in identifying... | Philipp Mondorf, Sondre Wold, Barbara Plank |  |
| 2216 |  |  [Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions](https://aclanthology.org/2025.acl-long.728/) |  | 0 | Communication among humans relies on conversational grounding, allowing interlocutors to reach mutual understanding even when they do not have perfect knowledge and must resolve discrepancies in each other’s beliefs. This paper investigates how large language models (LLMs) manage common ground in... | Clara Lachenmaier, Judith Sieker, Sina Zarrieß |  |
| 2217 |  |  [GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking](https://aclanthology.org/2025.acl-long.729/) |  | 0 | Large language models (LLMs) are widely used, but they often generate subtle factual errors, especially in long-form text. These errors are fatal in some specialized domains such as medicine. Existing fact-checking with grounding documents methods face two main challenges: (1) they struggle to... | Yingjian Chen, Haoran Liu, Yinhong Liu, Jinxiang Xie, Rui Yang, Han Yuan, Yanran Fu, Peng Yuan Zhou, Qingyu Chen, James Caverlee, Irene Li |  |
| 2218 |  |  [SCULPT: Systematic Tuning of Long Prompts](https://aclanthology.org/2025.acl-long.730/) |  | 0 | Prompt optimization is essential for effective utilization of large language models (LLMs) across diverse tasks. While existing optimization methods are effective in optimizing short prompts, they struggle with longer, more complex ones, often risking information loss and being sensitive to small... | Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta |  |
| 2219 |  |  [Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark](https://aclanthology.org/2025.acl-long.731/) |  | 0 | This study introduces Crab, a novel Configurable Role-Playing (RP) LLM with Assessing Benchmark, which consists of Role-Centric Dataset Curation, Persona-Embodying LLM Construction, and Comprehensive Benchmark Creation for RP dialogue generation. Distinct from traditional RP models that employ only... | Kai He, Yucheng Huang, Wenqing Wang, Delong Ran, Dongming Sheng, Junxuan Huang, Qika Lin, Jiaxing Xu, Wenqiang Liu, Mengling Feng |  |
| 2220 |  |  [Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models](https://aclanthology.org/2025.acl-long.732/) |  | 0 | With the rapid advancement of Large Language Models (LLMs), significant safety concerns have emerged. Fundamentally, the safety of large language models is closely linked to the accuracy, comprehensiveness, and clarity of their understanding of safety knowledge, particularly in domains such as law,... | Yingshui Tan, Boren Zheng, Baihui Zheng, Kerui Cao, Huiyun Jing, Jincheng Wei, Jiaheng Liu, Yancheng He, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang |  |
| 2221 |  |  [TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis](https://aclanthology.org/2025.acl-long.733/) |  | 0 | Large Language Models (LLMs) excel in various natural language processing tasks but remain vulnerable to generating harmful content or being exploited for malicious purposes. Although safety alignment datasets have been introduced to mitigate such risks through supervised fine-tuning (SFT), these... | Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xuanhong Li, Chong Teng, Donghong Ji, Zhuang Li |  |
| 2222 |  |  [Cross-Lingual Optimization for Language Transfer in Large Language Models](https://aclanthology.org/2025.acl-long.734/) |  | 0 | Adapting large language models to other languages typically employs supervised fine-tuning (SFT) as a standard approach. However, it often suffers from an overemphasis on English performance, a phenomenon that is especially pronounced in data-constrained environments. To overcome these challenges,... | Jungseob Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim |  |
| 2223 |  |  [CART: A Generative Cross-Modal Retrieval Framework With Coarse-To-Fine Semantic Modeling](https://aclanthology.org/2025.acl-long.735/) |  | 0 | Cross-modal retrieval aims to search for instances, which are semantically related to the query through the interaction of different modal data. Traditional solutions utilize a single-tower or dual-tower framework to explicitly compute the score between queries and candidates, which is challenged... | Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao |  |
| 2224 |  |  [MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark](https://aclanthology.org/2025.acl-long.736/) |  | 0 | This paper introduces MMMU-Pro, a robust version of the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark. MMMU-Pro rigorously assesses multimodal models’ true understanding and reasoning capabilities through a three-step process based on MMMU: (1) filtering out... | Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig |  |
| 2225 |  |  [Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch](https://aclanthology.org/2025.acl-long.737/) |  | 0 | Reward models (RMs) are crucial for aligning large language models (LLMs) with human preferences. However, most RM research is centered on English and relies heavily on synthetic resources, which leads to limited and less reliable datasets and benchmarks for Chinese. To address this gap, we... | Xueru Wen, Jie Lou, Zichao Li, Yaojie Lu, XingYu, Yuqiu Ji, Guohai Xu, Hongyu Lin, Ben He, Xianpei Han, Le Sun, Debing Zhang |  |
| 2226 |  |  [Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://aclanthology.org/2025.acl-long.738/) |  | 0 | The safety alignment of large language models (LLMs) remains vulnerable, as their initial behavior can be easily jailbroken by even relatively simple attacks. Since infilling a fixed template between the input instruction and initial model output is a common practice for existing LLMs, we... | Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li |  |
| 2227 |  |  [LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering](https://aclanthology.org/2025.acl-long.739/) |  | 0 | Multimodal Large Language Models (MLLMs) enhance visual tasks by integrating visual representations into large language models (LLMs). The textual modality, inherited from LLMs, enables instruction following and in-context learning, while the visual modality boosts downstream task performance... | Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma |  |
| 2228 |  |  [Efficient Long Context Language Model Retrieval with Compression](https://aclanthology.org/2025.acl-long.740/) |  | 0 | Long Context Language Models (LCLMs) have emerged as a new paradigm to perform Information Retrieval (IR), which enables the direct ingestion and retrieval of information by processing an entire corpus in their single context, showcasing the potential to surpass traditional sparse and dense... | Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang |  |
| 2229 |  |  [Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering](https://aclanthology.org/2025.acl-long.741/) |  | 0 | Large language models (LLMs) have shown remarkable capabilities in natural language processing. However, in knowledge graph question answering tasks (KGQA), there remains the issue of answering questions that require multi-hop reasoning. Existing methods rely on entity vector matching, but the... | Runxuan Liu, Luobei Luobei, Jiaqi Li, Baoxin Wang, Ming Liu, Dayong Wu, Shijin Wang, Bing Qin |  |
| 2230 |  |  [Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications](https://aclanthology.org/2025.acl-long.742/) |  | 0 | Large language models hold promise for addressing medical challenges, such as medical diagnosis reasoning, research knowledge acquisition, clinical decision-making, and consumer health inquiry support. However, they often generate hallucinations due to limited medical knowledge. Incorporating... | Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, Yiqiu Guo, Yanfeng Wang, Yu Wang |  |
| 2231 |  |  [Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals](https://aclanthology.org/2025.acl-long.743/) |  | 0 | This paper addresses the gap in predicting turn-taking and backchannel actions in human-machine conversations using multi-modal signals (linguistic, acoustic, and visual). To overcome the limitation of existing datasets, we propose an automatic data collection pipeline that allows us to collect and... | Yuxin Lin, Yinglin Zheng, Ming Zeng, Wangzheng Shi |  |
| 2232 |  |  [A New Formulation of Zipf's Meaning-Frequency Law through Contextual Diversity](https://aclanthology.org/2025.acl-long.744/) |  | 0 | This paper proposes formulating Zipf’s meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. The proposed formulation quantifies meaning counts as contextual diversity, which is based on the... | Ryo Nagata, Kumiko TanakaIshii |  |
| 2233 |  |  [The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://aclanthology.org/2025.acl-long.745/) |  | 0 | Despite near-perfect results reported in the literature, the effectiveness of model editing in real-world applications remains unclear. To bridge this gap, we introduce QAEdit, a new benchmark aligned with widely used question answering (QA) datasets, and WILD, a task-agnostic evaluation framework... | Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng |  |
| 2234 |  |  [LAQuer: Localized Attribution Queries in Content-grounded Generation](https://aclanthology.org/2025.acl-long.746/) |  | 0 | Grounded text generation models often produce content that deviates from their source material, requiring user verification to ensure accuracy. Existing attribution methods associate entire sentences with source documents, which can be overwhelming for users seeking to fact-check specific claims.... | Eran Hirsch, Aviv Slobodkin, David Wan, Elias StengelEskin, Mohit Bansal, Ido Dagan |  |
| 2235 |  |  [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://aclanthology.org/2025.acl-long.747/) |  | 0 | Large Language Models (LLMs) have shown impressive reasoning capabilities in well-defined problems with clear solutions, such as mathematics and coding. However, they still struggle with complex real-world scenarios like business negotiations, which require strategic reasoning—an ability to... | Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang |  |
| 2236 |  |  [DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph](https://aclanthology.org/2025.acl-long.748/) |  | 0 | Text-to-SQL, which translates a natural language question into an SQL query, has advanced with in-context learning of Large Language Models (LLMs). However, existing methods show little improvement in performance compared to randomly chosen demonstrations, and significant performance drops when... | Jihyung Lee, JinSeop Lee, Jaehoon Lee, YunSeok Choi, JeeHyong Lee |  |
| 2237 |  |  [PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy](https://aclanthology.org/2025.acl-long.749/) |  | 0 | This paper introduces PreP-OCR, a two-stage pipeline that combines document image restoration with semantic-aware post-OCR correction to enhance both visual clarity and textual consistency, thereby improving text extraction from degraded historical documents.First, we synthesize document-image... | Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene |  |
| 2238 |  |  [Digest the Knowledge: Large Language Models empowered Message Passing for Knowledge Graph Question Answering](https://aclanthology.org/2025.acl-long.750/) |  | 0 | Despite their success, large language models (LLMs) suffer from notorious hallucination issue. By introducing external knowledge stored in knowledge graphs (KGs), existing methods use paths as the medium to represent the graph information that send into LLMs. However, paths only contain limited... | Junhong Wan, Tao Yu, Kunyu Jiang, Yao Fu, Weihao Jiang, Jiang Zhu |  |
| 2239 |  |  [RecLM: Recommendation Instruction Tuning](https://aclanthology.org/2025.acl-long.751/) |  | 0 | Modern recommender systems aim to deeply understand users’ complex preferences through their past interactions. While deep collaborative filtering approaches using Graph Neural Networks (GNNs) excel at capturing user-item relationships, their effectiveness is limited when handling sparse data or... | Yangqin Jiang, Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang |  |
| 2240 |  |  [DS²-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis](https://aclanthology.org/2025.acl-long.752/) |  | 0 | Recently developed large language models (LLMs) have presented promising new avenues to address data scarcity in low-resource scenarios. In few-shot aspect-based sentiment analysis (ABSA), previous efforts have explored data augmentation techniques, which prompt LLMs to generate new samples by... | Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu |  |
| 2241 |  |  [MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization](https://aclanthology.org/2025.acl-long.753/) |  | 0 | We introduce MISP-Meeting, a new real-world, multimodal dataset that covers subject-oriented long-form content. MISP-Meeting integrates information from speech, vision, and text modalities to facilitate automatic meeting transcription and summarization (AMTS). Challenging conditions in human... | HangChen HangChen, ChaoHan Huck Yang, JiaChen Gu, Sabato Marco Siniscalchi, Jun Du |  |
| 2242 |  |  [Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning](https://aclanthology.org/2025.acl-long.754/) |  | 0 | LLMs such as GPT-4 have shown a remarkable ability to solve complex questions by generating step-by-step rationales. Prior works have utilized this capability to improve smaller and cheaper LMs (say, with 7B parameters). However, various practical constraints, such as copyright and legal issues,... | Sohan Patnaik, Milan Aggarwal, Sumit Bhatia, Balaji Krishnamurthy |  |
| 2243 |  |  [MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction](https://aclanthology.org/2025.acl-long.755/) |  | 0 | Recent LLMs exhibit limited effectiveness on molecular property prediction task due to the semantic gap between molecular representations and natural language, as well as the lack of domain-specific knowledge. To address these challenges, we propose MolRAG, a Retrieval-Augmented Generation... | Ziting Xian, Jiawei Gu, Lingbo Li, Shangsong Liang |  |
| 2244 |  |  [SkillAggregation: Reference-free LLM-Dependent Aggregation](https://aclanthology.org/2025.acl-long.756/) |  | 0 | Large Language Models (LLMs) are increasingly used to assess NLP tasks due to their ability to generate human-like judgments. Single LLMs were used initially, however, recent work suggests using multiple LLMs as judges yields improved performance. An important step in exploiting multiple judgements... | Guangzhi Sun, Anmol Kagrecha, Potsawee Manakul, Philip C. Woodland, Mark J. F. Gales |  |
| 2245 |  |  [MasRouter: Learning to Route LLMs for Multi-Agent Systems](https://aclanthology.org/2025.acl-long.757/) |  | 0 | Multi-agent systems (MAS) powered by Large Language Models (LLMs) have been demonstrated to push the boundaries of LLM capabilities, yet they often incur significant costs and face challenges in dynamic LLM selection. Current LLM routing methods effectively reduce overhead in single-agent scenarios... | Yanwei Yue, Guibin Zhang, Boyang Liu, Guancheng Wan, Kun Wang, Dawei Cheng, Yiyan Qi |  |
| 2246 |  |  [Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation](https://aclanthology.org/2025.acl-long.758/) |  | 0 | Conversational recommender systems (CRSs) enhance recommendation quality by engaging users in multi-turn dialogues, capturing nuanced preferences through natural language interactions. However, these systems often face the false negative issue, where items that a user might like are incorrectly... | Haozhe Xu, Xiaohua Wang, Changze Lv, Xiaoqing Zheng |  |
| 2247 |  |  [Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation](https://aclanthology.org/2025.acl-long.759/) |  | 0 | Evaluating models on large benchmarks can be very resource-intensive, especially during a period of rapid model evolution. Existing efficient evaluation methods estimate the performance of target models by testing them on a small, static coreset derived from the publicly available evaluation... | Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li |  |
| 2248 |  |  [iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering](https://aclanthology.org/2025.acl-long.760/) |  | 0 | While Large Language Models (LLMs) excel at many natural language processing tasks, they often suffer from factual inaccuracies in knowledge-intensive scenarios. Integrating external knowledge resources, particularly knowledge graphs (KGs), provides a transparent and updatable foundation for more... | Shuai Wang, Yinan Yu |  |
| 2249 |  |  [IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory](https://aclanthology.org/2025.acl-long.761/) |  | 0 | Large language models (LLMs) have demonstrated exceptional performance across a wide range of natural language tasks. However, selecting the optimal LLM to respond to a user query often necessitates a delicate balance between performance and cost. While powerful models deliver better results, they... | Wei Song, Zhenya Huang, Cheng Cheng, Weibo Gao, Bihan Xu, Guanhao Zhao, Fei Wang, Runze Wu |  |
| 2250 |  |  [MLAS-LoRA: Language-Aware Parameters Detection and LoRA-Based Knowledge Transfer for Multilingual Machine Translation](https://aclanthology.org/2025.acl-long.762/) |  | 0 | Large language models (LLMs) have achieved remarkable progress in multilingual machine translation (MT), demonstrating strong performance even with limited parallel data. However, effectively fine-tuning LLMs for MT is challenging due to parameter interference, which arises from the conflicting... | Tianyu Dong, Bo Li, Jinsong Liu, Shaolin Zhu, Deyi Xiong |  |
| 2251 |  |  [M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation](https://aclanthology.org/2025.acl-long.763/) |  | 0 | Repository-level code completion has drawn great attention in software engineering, and several benchmarks have been introduced. However, existing repository-level code completion benchmarks usually focus on a limited number of languages (<5), which cannot evaluate the general code intelligence... | Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ke Jin, Ge Zhang, Zekun Moore Wang, Guoan Zhang, Yingshui Tan, Bangyu Xiang, Zhaoxiang Zhang, Wenbo Su, Bo Zheng |  |
| 2252 |  |  [Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation](https://aclanthology.org/2025.acl-long.764/) |  | 0 | Entity disambiguation (ED) is the task of linking mentions in text to corresponding entries in a knowledge base. Dual Encoders address this by embedding mentions and label candidates in a shared embedding space and applying a similarity metric to predict the correct label. In this work, we focus on... | Susanna Rücker, Alan Akbik |  |
| 2253 |  |  [How to Compare Things Properly? A Study of Argument Relevance in Comparative Question Answering](https://aclanthology.org/2025.acl-long.765/) |  | 0 | Comparative Question Answering (CQA) lies at the intersection of Question Answering, Argument Mining, and Summarization. It poses unique challenges due to the inherently subjective nature of many questions and the need to integrate diverse perspectives. Although the CQA task can be addressed using... | Irina Nikishina, Saba Anwar, Nikolay Dolgov, Maria Manina, Daria Ignatenko, Artem Shelmanov, Chris Biemann |  |
| 2254 |  |  [FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging](https://aclanthology.org/2025.acl-long.766/) |  | 0 | We introduce \*\*FinanceReasoning\*\*, a novel benchmark designed to evaluate the reasoning capabilities of large reasoning models (LRMs) in financial numerical reasoning problems. Compared to existing benchmarks, our work provides three key advancements. (1) \*\*Credibility\*\*: We update 15.6% of... | Zichen Tang, Haihong E, Ziyan Ma, Haoyang He, Jiacheng Liu, Zhongjun Yang, Zihua Rong, Rongjin Li, Kun Ji, Qing Huang, Xinyang Hu, Yang Liu, Qianhe Zheng |  |
| 2255 |  |  [Controllable Style Arithmetic with Language Models](https://aclanthology.org/2025.acl-long.767/) |  | 0 | Language models have shown remarkable capabilities in text generation, but precisely controlling their linguistic style remains challenging. Existing methods either lack fine-grained control, require extensive computation, or introduce significant latency. We propose Style Arithmetic (SA), a novel... | Weiqi Wang, Wengang Zhou, Zongmeng Zhang, Jie Zhao, Houqiang Li |  |
| 2256 |  |  [Masks Can be Learned as an Alternative to Experts](https://aclanthology.org/2025.acl-long.768/) |  | 0 | In this work, we investigate how to sparsify a pre-trained dense large language model into a mixture-of-experts (MoE) architecture for faster inference. Our approach applies mask matrix to the activations for each expert, constrained by L0 regularization to minimize the number of activated... | Peiyu Liu, Tianwen Wei, Bo Zhu, Xin Zhao, Shuicheng Yan |  |
| 2257 |  |  [Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment](https://aclanthology.org/2025.acl-long.769/) |  | 0 | Large language and multimodal models have shown remarkable success on various benchmarks focused on specific skills such as general-purpose programming, math word problem-solving, and visual question answering. However, it is unclear how well these models perform on tasks that require a combination... | Chao Wen, Jacqueline Staub, Adish Singla |  |
| 2258 |  |  [Removal of Hallucination on Hallucination: Debate-Augmented RAG](https://aclanthology.org/2025.acl-long.770/) |  | 0 | Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external knowledge, yet it introduces a critical issue: erroneous or biased retrieval can mislead generation, compounding hallucinations, a phenomenon we term Hallucination on Hallucination. To address this, we propose... | Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Qing Li |  |
| 2259 |  |  [CodeDPO: Aligning Code Models with Self Generated and Verified Source Code](https://aclanthology.org/2025.acl-long.771/) |  | 0 | Code generation models have shown significant potential for programming tasks. However, existing training methods like supervised fine-tuning face key limitations: they do not effectively teach models to prioritize correct over incorrect solutions in ambiguous situations, nor do they effectively... | Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin |  |
| 2260 |  |  [ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering](https://aclanthology.org/2025.acl-long.772/) |  | 0 | Topic models and document-clustering evaluations either use automated metrics that align poorly with human preferences, or require expert labels that are intractable to scale. We design a scalable human evaluation protocol and a corresponding automated approximation that reflect practitioners’... | Alexander Miserlis Hoyle, Lorena CalvoBartolomé, Jordan Lee BoydGraber, Philip Resnik |  |
| 2261 |  |  [BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation](https://aclanthology.org/2025.acl-long.773/) |  | 0 | Recent advances in large language models (LLMs) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely... | Yiting Ran, Xintao Wang, Tian Qiu, Jiaqing Liang, Yanghua Xiao, Deqing Yang |  |
| 2262 |  |  [Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport](https://aclanthology.org/2025.acl-long.774/) |  | 0 | Lexical semantic change detection aims to identify shifts in word meanings over time. While existing methods using embeddings from a diachronic corpus pair estimate the degree of change for target words, they offer limited insight into changes at the level of individual usage instances. To address... | Ryo Kishino, Hiroaki Yamagiwa, Ryo Nagata, Sho Yokoi, Hidetoshi Shimodaira |  |
| 2263 |  |  [Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems](https://aclanthology.org/2025.acl-long.775/) |  | 0 | Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs). However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs. In this paper, we... | Hao Peng, Yunjia Qi, Xiaozhi Wang, Zijun Yao, Bin Xu, Lei Hou, Juanzi Li |  |
| 2264 |  |  [Adaptive and Robust Translation from Natural Language to Multi-model Query Languages](https://aclanthology.org/2025.acl-long.776/) |  | 0 | Multi-model databases and polystore systems are increasingly studied for managing multi-model data holistically. As their primary interface, multi-model query languages (MMQLs) often exhibit complex grammars, highlighting the need for effective Text-to-MMQL translation methods. Despite advances in... | Gengyuan Shi, Chaokun Wang, Yabin Liu, Jiawei Ren |  |
| 2265 |  |  [SAKE: Steering Activations for Knowledge Editing](https://aclanthology.org/2025.acl-long.777/) |  | 0 | As Large Langue Models have been shown to memorize real-world facts, the need to update this knowledge in a controlled and efficient manner arises. Designed with these constraints in mind, Knowledge Editing (KE) approaches propose to alter specific facts in pretrained models. However, they have... | Marco Scialanga, Thibault Laugel, Vincent Grari, Marcin Detyniecki |  |
| 2266 |  |  [Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs](https://aclanthology.org/2025.acl-long.778/) |  | 0 | While large language models demonstrate remarkable capabilities at task-specific applications through fine-tuning, extending these benefits across diverse languages is essential for broad accessibility. However, effective cross-lingual transfer is hindered by LLM performance gaps across languages... | Danni Liu, Jan Niehues |  |
| 2267 |  |  [Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?](https://aclanthology.org/2025.acl-long.779/) |  | 0 | Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the “better” response. This approach can provide feedback for domains where other... | Arduin Findeis, Floris Weers, Guoli Yin, Ke Ye, Ruoming Pang, Tom Gunter |  |
| 2268 |  |  [One for All: Update Parameterized Knowledge Across Multiple Models with Once Edit](https://aclanthology.org/2025.acl-long.780/) |  | 0 | Large language models (LLMs) encode vast world knowledge but struggle to stay up-to-date, often leading to errors and hallucinations. Knowledge editing offers an efficient alternative to retraining, enabling targeted modifications by updating specific model parameters. However, existing methods... | Weitao Ma, Xiyuan Du, Xiaocheng Feng, Lei Huang, Yichong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin |  |
| 2269 |  |  [VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service](https://aclanthology.org/2025.acl-long.781/) |  | 0 | Vision-Language Models (VLMs) have demonstrated great potential in real-world applications. While existing research primarily focuses on improving their accuracy, the efficiency remains underexplored. Given the real-time demands of many applications and the high inference overhead of VLMs,... | Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei Ye, Kuofeng Gao, Yi Huang, Yuan Yao |  |
| 2270 |  |  [The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs](https://aclanthology.org/2025.acl-long.782/) |  | 0 | The “LLM-as-an-annotator” and “LLM-as-a-judge” paradigms employ Large Language Models (LLMs) as annotators, judges, and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science.... | Nitay Calderon, Roi Reichart, Rotem Dror |  |
| 2271 |  |  [CrisisTS: Coupling Social Media Textual Data and Meteorological Time Series for Urgency Classification](https://aclanthology.org/2025.acl-long.783/) |  | 0 | This paper proposes CrisisTS, the first multimodal and multilingual dataset for urgency classification composed of benchmark crisis datasets from French and English social media about various expected (e.g., flood, storm) and sudden (e.g., earthquakes, explosions) crises that have been mapped with... | Romain Meunier, Farah Benamara, Véronique Moriceau, Zhongzheng Qiao, Savitha Ramasamy |  |
| 2272 |  |  [How to Mitigate Overfitting in Weak-to-strong Generalization?](https://aclanthology.org/2025.acl-long.784/) |  | 0 | Aligning powerful AI models on tasks that surpass human evaluation capabilities is the central problem of \*\*superalignment\*\*. To address this problem, weak-to-strong generalization aims to elicit the capabilities of strong models through weak supervisors and ensure that the behavior of strong... | Junhao Shi, Qinyuan Cheng, Zhaoye Fei, Yining Zheng, Qipeng Guo, Xipeng Qiu |  |
| 2273 |  |  [Com² : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models](https://aclanthology.org/2025.acl-long.785/) |  | 0 | Large language models (LLMs) have mastered abundant simple and explicit commonsense knowledge through pre-training, enabling them to achieve human-like performance in simple commonsense reasoning. Nevertheless, LLMs struggle to reason with complex and implicit commonsense knowledge that is derived... | Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu |  |
| 2274 |  |  [Dynamic Head Selection for Neural Lexicalized Constituency Parsing](https://aclanthology.org/2025.acl-long.786/) |  | 0 | Lexicalized parsing, which associates constituent nodes with lexical heads, has historically played a crucial role in constituency parsing by bridging constituency and dependency structures. Nevertheless, with the advent of neural networks, lexicalized structures have generally been neglected in... | Yang Hou, Zhenghua Li |  |
| 2275 |  |  [My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis](https://aclanthology.org/2025.acl-long.787/) |  | 0 | The subtlety of emotional expressions makes implicit emotion analysis (IEA) particularly sensitive to user-specific characteristics. Current studies personalize emotion analysis by focusing on the author but neglect the impact of the intended reader on implicit emotional feedback. In this paper, we... | Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, Jianxing Zheng |  |
| 2276 |  |  [EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge](https://aclanthology.org/2025.acl-long.788/) |  | 0 | Large language models (LLMs) are trained on extensive historical corpora, but their ability to understand time and maintain temporal awareness of time-evolving factual knowledge remains limited. Previous studies often neglect the critical aspect of utilizing knowledge from various sources. To... | Zhiyuan Zhu, Yusheng Liao, Zhe Chen, Yuhao Wang, Yunfeng Guan, Yanfeng Wang, Yu Wang |  |
| 2277 |  |  [Enabling LLM Knowledge Analysis via Extensive Materialization](https://aclanthology.org/2025.acl-long.789/) |  | 0 | Large language models (LLMs) have majorly advanced NLP and AI, and next to their ability to perform a wide range of procedural tasks, a major success factor is their internalized factual knowledge. Since (Petroni et al., 2019), analyzing this knowledge has gained attention. However, most approaches... | Yujia Hu, TuanPhong Nguyen, Shrestha Ghosh, Simon Razniewski |  |
| 2278 |  |  [Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching](https://aclanthology.org/2025.acl-long.790/) |  | 0 | Zero-Shot Voice Conversion (VC) aims to transform the source speaker’s timbre into an arbitrary unseen one while retaining speech content. Most prior work focuses on preserving the source’s prosody, while fine-grained timbre information may leak through prosody, and transferring target prosody to... | Jialong Zuo, Shengpeng Ji, Minghui Fang, Mingze Li, Ziyue Jiang, Xize Cheng, Xiaoda Yang, Feiyang Chen, Xinyu Duan, Zhou Zhao |  |
| 2279 |  |  [Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs](https://aclanthology.org/2025.acl-long.791/) |  | 0 | We observe a novel phenomenon, \*contextual entrainment\*, across a wide range of language models (LMs) and prompt settings, providing a new mechanistic perspective on how LMs become distracted by “irrelevant” contextual information in the input prompt. Specifically, LMs assign significantly higher... | Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi |  |
| 2280 |  |  [CritiQ: Mining Data Quality Criteria from Human Preferences](https://aclanthology.org/2025.acl-long.792/) |  | 0 | Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, orcareful prompt engineering, which require significant expert experience and human annotation effort while... | Honglin Guo, Kai Lv, Qipeng Guo, Tianyi Liang, Zhiheng Xi, Demin Song, Qiuyinzhe Zhang, Yu Sun, Kai Chen, Xipeng Qiu, Tao Gui |  |
| 2281 |  |  [Theoretical Guarantees for Minimum Bayes Risk Decoding](https://aclanthology.org/2025.acl-long.793/) |  | 0 | Minimum Bayes Risk (MBR) decoding optimizes output selection by maximizing the expected utility value of an underlying human distribution. While prior work has shown the effectiveness of MBR decoding through empirical evaluation, few studies have analytically investigated why the method is... | Yuki Ichihara, Yuu Jinnai, Kaito Ariu, Tetsuro Morimura, Eiji Uchibe |  |
| 2282 |  |  [Mutual-Taught for Co-adapting Policy and Reward Models](https://aclanthology.org/2025.acl-long.794/) |  | 0 | During the preference optimization of large language models (LLMs), distribution shifts may arise between newly generated model samples and the data used to train the reward model (RM). This shift reduces the efficacy of the RM, which in turn negatively impacts the performance of the policy model... | Tianyuan Shi, Canbin Huang, Fanqi Wan, Longguang Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan |  |
| 2283 |  |  [Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages](https://aclanthology.org/2025.acl-long.795/) |  | 0 | As large language models (LLMs) are trained on increasingly diverse and extensive multilingual corpora, they demonstrate cross-lingual transfer capabilities. However, these capabilities often fail to effectively extend to low-resource languages, particularly those utilizing non-Latin scripts. While... | Wenhao Zhuang, Yuan Sun, Xiaobing Zhao |  |
| 2284 |  |  [Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models](https://aclanthology.org/2025.acl-long.796/) |  | 0 | Natural language processing applications are increasingly prevalent, but social biases in their outputs remain a critical challenge. While various bias evaluation methods have been proposed, these assessments show unexpected instability when input texts undergo minor stylistic changes. This paper... | Jiaxu Zhao, Meng Fang, Kun Zhang, Mykola Pechenizkiy |  |
| 2285 |  |  [MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines](https://aclanthology.org/2025.acl-long.797/) |  | 0 | In simultaneous interpreting, an interpreter renders the speech into another language with a very short lag, much sooner than sentences are finished. In order to understand and later reproduce this dynamic and complex task automatically, we need specialized datasets and tools for analysis,... | Dávid Javorský, Ondrej Bojar, François Yvon |  |
| 2286 |  |  [BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning](https://aclanthology.org/2025.acl-long.798/) |  | 0 | This paper introduces BMIKE-53, a comprehensive benchmark for cross-lingual in-context knowledge editing (IKE), spanning 53 languages and three KE datasets: zsRE, CounterFact, and WikiFactDiff. Cross-lingual KE, which requires knowledge edited in one language to generalize across diverse languages... | Ercong Nie, Bo Shao, Mingyang Wang, Zifeng Ding, Helmut Schmid, Hinrich Schütze |  |
| 2287 |  |  [What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation](https://aclanthology.org/2025.acl-long.799/) |  | 0 | In this work, we conduct systematic research in a challenging area: the automatic evaluation of book-length stories (>100K tokens). Our study focuses on two key questions: (1) understanding which evaluation aspects matter most to readers, and (2) exploring effective methods for evaluating lengthy... | Dingyi Yang, Qin Jin |  |
| 2288 |  |  [PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation](https://aclanthology.org/2025.acl-long.800/) |  | 0 | Personalized large language models (LLMs) aim to tailor their outputs to user preferences. Recent advances in parameter-efficient fine-tuning (PEFT) methods have highlighted the effectiveness of adapting population-level LLMs to personalized LLMs by fine-tuning user-specific parameters with user... | Linhai Zhang, Jialong Wu, Deyu Zhou, Yulan He |  |
| 2289 |  |  [Enhancing Event-centric News Cluster Summarization via Data Sharpening and Localization Insights](https://aclanthology.org/2025.acl-long.801/) |  | 0 | This paper tackles the challenges of clustering news articles by main events (MEs) and summarizing these clusters, focusing on diverse languages and localized contexts. Our approach consists of four key contributions. First, we investigate the role of dynamic clustering and the integration of... | Longyin Zhang, Bowei Zou, AiTi Aw |  |
| 2290 |  |  [MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration](https://aclanthology.org/2025.acl-long.802/) |  | 0 | In recent years, multimodal large language models (MLLMs) have made significant progress but continue to face inherent challenges in multimodal reasoning, which requires multi-level (e.g., perception, reasoning) and multi-granular (e.g., multi-step reasoning chain) advanced inferencing. Prior work... | Zhitao He, Sandeep Polisetty, Zhiyuan Fan, Yuchen Huang, Shujin Wu, Yi R. Fung |  |
| 2291 |  |  [LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios](https://aclanthology.org/2025.acl-long.803/) |  | 0 | As Large Language Models (LLMs) evolve in natural language processing (NLP), their ability to stably follow instructions in long-context inputs has become critical for real-world applications. However, existing benchmarks seldom focus on instruction-following in long-context scenarios or stability... | Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Xiangju Li, Junmin Zhu, Wei Zhang |  |
| 2292 |  |  [Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering](https://aclanthology.org/2025.acl-long.804/) |  | 0 | Training LLMs on data containing unfamiliar knowledge during the instruction tuning stage can encourage hallucinations. To address this challenge, we introduce NOVA, a novel framework designed to identify high-quality data that aligns well with the LLM’s learned knowledge to reduce hallucinations.... | Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun |  |
| 2293 |  |  [One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs](https://aclanthology.org/2025.acl-long.805/) |  | 0 | We introduce a novel framework for consolidating multi-turn adversarial “jailbreak” prompts into single-turn queries, significantly reducing the manual overhead required for adversarial testing of large language models (LLMs). While multi-turn human jailbreaks have been shown to yield high attack... | Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim |  |
| 2294 |  |  [RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information](https://aclanthology.org/2025.acl-long.806/) |  | 0 | Misinformation is prevalent in various fields such as education, politics, health, etc., causing significant harm to society. However, current methods for cross-domain misinformation detection rely on effort- and resource-intensive fine-tuning and complex model structures. With the outstanding... | Zhiwei Liu, Kailai Yang, Qianqian Xie, Christine de Kock, Sophia Ananiadou, Eduard H. Hovy |  |
| 2295 |  |  [Task-Specific Information Decomposition for End-to-End Dense Video Captioning](https://aclanthology.org/2025.acl-long.807/) |  | 0 | Dense video captioning aims to localize events within input videos and generate concise descriptive texts for each event. Advanced end-to-end methods require both tasks to share the same intermediate features that serve as event queries, thereby enabling the mutual promotion of two tasks. However,... | Zhiyue Liu, Xinru Zhang, Jinyuan Liu |  |
| 2296 |  |  [CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges](https://aclanthology.org/2025.acl-long.808/) |  | 0 | The use of large language models (LLMs) as automated evaluation tools to assess the quality of generated natural language, known as ”LLMs-as-Judges”, has demonstrated promising capabilities and is rapidly gaining widespread attention. However, when applied to pairwise comparisons of candidate... | Haitao Li, Junjie Chen, Qingyao Ai, Zhumin Chu, Yujia Zhou, Qian Dong, Yiqun Liu |  |
| 2297 |  |  [Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection](https://aclanthology.org/2025.acl-long.809/) |  | 0 | The detection of sexism in online content remains an open problem, as harmful language disproportionately affects women and marginalized groups. While automated systems for sexism detection have been developed, they still face two key challenges: data sparsity and the nuanced nature of sexist... | Sahrish Khan, Arshad Jhumka, Gabriele Pergola |  |
| 2298 |  |  [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://aclanthology.org/2025.acl-long.810/) |  | 0 | Large Language Models (LLMs) memorize, and thus, among huge amounts of uncontrolled data, may memorize Personally Identifiable Information (PII), which should not be stored and, consequently, not leaked. In this paper, we introduce Private Memorization Editing (PME), an approach for preventing... | Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto |  |
| 2299 |  |  [PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning](https://aclanthology.org/2025.acl-long.811/) |  | 0 | Large language models demonstrate remarkable capabilities across various domains, especially mathematics and logic reasoning. However, current evaluations overlook physics-based reasoning - a complex task requiring physics theorems and constraints. We present PhysReason, a 1,200-problem benchmark... | Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu |  |
| 2300 |  |  [Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information](https://aclanthology.org/2025.acl-long.812/) |  | 0 | While the ability of language models to elicit facts has been widely investigated, how they handle temporally changing facts remains underexplored. We discover Temporal Heads, specific attention heads that primarily handle temporal knowledge, through circuit analysis. We confirm that these heads... | Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang |  |
| 2301 |  |  [Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training](https://aclanthology.org/2025.acl-long.813/) |  | 0 | It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains. In general, previous efforts resort to either sampling training data from different domains with static proportions or dynamically adjusting... | Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Qi Chen, Peng Cheng |  |
| 2302 |  |  [Sheep's Skin, Wolf's Deeds: Are LLMs Ready for Metaphorical Implicit Hate Speech?](https://aclanthology.org/2025.acl-long.814/) |  | 0 | Implicit hate speech has become a significant challenge for online platforms, as it often avoids detection by large language models (LLMs) due to its indirectly expressed hateful intent. This study identifies the limitations of LLMs in detecting implicit hate speech, particularly when disguised as... | Jingjie Zeng, Liang Yang, Zekun Wang, Yuanyuan Sun, Hongfei Lin |  |
| 2303 |  |  [Neuron-Level Sequential Editing for Large Language Models](https://aclanthology.org/2025.acl-long.815/) |  | 0 | This work explores sequential model editing in large language models (LLMs), a critical task that involves modifying internal knowledge within LLMs continuously through multi-round editing, each incorporating updates or corrections to adjust the model’s outputs without the need for costly... | Houcheng Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Tao Liang, Xiang Wang |  |
| 2304 |  |  [Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts](https://aclanthology.org/2025.acl-long.816/) |  | 0 | We present Sparse Interpolated Mixture-of-Experts (SIMoE) instruction-tuning, an end-to-end algorithm designed to fine-tune a dense pre-trained Large Language Model (LLM) into a MoE-style model that possesses capabilities in multiple specialized domains. During instruction-tuning, SIMoE... | Shengzhuang Chen, Ying Wei, Jonathan Richard Schwarz |  |
| 2305 |  |  [SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation](https://aclanthology.org/2025.acl-long.817/) |  | 0 | Simultaneous speech translation (SST) outputs translations in parallel with streaming speech input, balancing translation quality and latency. While large language models (LLMs) have been extended to handle the speech modality, streaming remains challenging as speech is pre-pended as a prompt for... | Keqi Deng, Wenxi Chen, Xie Chen, Philip C. Woodland |  |
| 2306 |  |  [VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models](https://aclanthology.org/2025.acl-long.818/) |  | 0 | With the rising need for speech-based interaction models, end-to-end Spoken Language Models (SLMs) have emerged as a promising solution. While these models require comprehensive world knowledge for meaningful and reliable human interactions, existing question-answering (QA) benchmarks fall short in... | Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King |  |
| 2307 |  |  [RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation](https://aclanthology.org/2025.acl-long.819/) |  | 0 | Large language models (LLMs) exhibit remarkable generative capabilities but often suffer from hallucinations. Retrieval-augmented generation (RAG) offers an effective solution by incorporating external knowledge, but existing methods still face several limitations: additional deployment costs of... | Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Ye Qi, Zhicheng Dou |  |
| 2308 |  |  [The Role of Deductive and Inductive Reasoning in Large Language Models](https://aclanthology.org/2025.acl-long.820/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning tasks, yet their reliance on static prompt structures and limited adaptability to complex scenarios remains a major challenge. In this paper, we propose the \*\*Deductive and Inductive (DID)\*\* method, a novel... | Chengkun Cai, Xu Zhao, Haoliang Liu, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, JenqNeng Hwang, Lei Li |  |
| 2309 |  |  [Disentangling the Roles of Representation and Selection in Data Pruning](https://aclanthology.org/2025.acl-long.821/) |  | 0 | Data pruning—selecting small but impactful subsets—offers a promising way to efficiently scale NLP model training. However, existing methods often involve many different design choices, which have not been systematically studied. This limits future developments. In this work, we decompose data... | Yupei Du, Yingjin Song, Hugh Mee Wong, Daniil Ignatev, Albert Gatt, Dong Nguyen |  |
| 2310 |  |  [FRACTAL: Fine-Grained Scoring from Aggregate Text Labels](https://aclanthology.org/2025.acl-long.822/) |  | 0 | Fine-Tuning of LLMs using RLHF / RLAIF has been shown as a critical step to improve the performance of LLMs in complex generation tasks. These methods typically use response-level human or model feedback for alignment. Recent works indicate that finer sentence or span-level labels provide more... | Yukti Makhija, Priyanka Agrawal, Rishi Saket, Aravindan Raghuveer |  |
| 2311 |  |  [ACT: Knowledgeable Agents to Design and Perform Complex Tasks](https://aclanthology.org/2025.acl-long.823/) |  | 0 | Large language models enhance collaborative task execution in multi-agent systems. Current studies break complex task into manageable tasks, but agents lack understanding of the overall task and how others approach their tasks, hindering synergy and integration.We propose a method called... | Makoto Nakatsuji, Shuhei Tateishi, Yasuhiro Fujiwara, Ayaka Matsumoto, Narichika Nomoto, Yoshihide Sato |  |
| 2312 |  |  [Logical forms complement probability in understanding language model (and human) performance](https://aclanthology.org/2025.acl-long.824/) |  | 0 | With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs’ ability to perform logical reasoning in natural language. We introduce a... | Yixuan Wang, Freda Shi |  |
| 2313 |  |  [Length Controlled Generation for Black-box LLMs](https://aclanthology.org/2025.acl-long.825/) |  | 0 | Large language models (LLMs) have demonstrated impressive instruction following capabilities, while still struggling to accurately manage the length of the generated text, which is a fundamental requirement in many real-world applications. Existing length control methods involve fine-tuning the... | Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei Huang, Ting Liu, Bing Qin, TatSeng Chua |  |
| 2314 |  |  [Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization](https://aclanthology.org/2025.acl-long.826/) |  | 0 | Ensuring contextual faithfulness in retrieval-augmented large language models (LLMs) is crucial for building trustworthy information-seeking systems, particularly in long-form question-answering (LFQA) scenarios. In this work, we identify a salient correlation between LFQA faithfulness and... | Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin |  |
| 2315 |  |  [Global Eye: Breaking the "Fixed Thinking Pattern" during the Instruction Expansion Process](https://aclanthology.org/2025.acl-long.827/) |  | 0 | An extensive high-quality instruction dataset is crucial for the instruction tuning process of Large Language Models (LLMs). Recent instruction expansion methods have demonstrated their capability to improve the quality and quantity of existing datasets, by prompting high-performance LLM to... | Wenxuan Lu, Wei Liu, Jian Luan, Bin Wang, Songhao Jiang, Tianning Zang |  |
| 2316 |  |  [On Synthesizing Data for Context Attribution in Question Answering](https://aclanthology.org/2025.acl-long.828/) |  | 0 | Question Answering (QA) accounts for a significant portion of LLM usage in the wild”. However, LLMs sometimes produce false or misleading responses, also known as hallucinations”. Therefore, grounding the generated answers in contextually provided information—i.e., providing evidence for the... | Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sebastien Nicolas, ChiaChien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavas, Carolin Lawrence |  |
| 2317 |  |  [TST: A Schema-Based Top-Down and Dynamic-Aware Agent of Text-to-Table Tasks](https://aclanthology.org/2025.acl-long.829/) |  | 0 | As a bridge between natural texts and information systems like structured storage, statistical analysis, retrieving, and recommendation, the text-to-table task has received widespread attention recently. Existing researches have gone through a paradigm shift from traditional bottom-up IE... | Peiwen Jiang, Haitong Jiang, Ruhui Ma, Yvonne Jie Chen, Jinhua Cheng |  |
| 2318 |  |  [EventRAG: Enhancing LLM Generation with Event Knowledge Graphs](https://aclanthology.org/2025.acl-long.830/) |  | 0 | Retrieval-augmented generation (RAG) systems often struggle with narrative-rich documents and event-centric reasoning, particularly when synthesizing information across multiple sources. We present EventRAG, a novel framework that enhances text generation through structured event representations.... | Zairun Yang, Yilin Wang, Zhengyan Shi, Yuan Yao, Lei Liang, Keyan Ding, Emine Yilmaz, Huajun Chen, Qiang Zhang |  |
| 2319 |  |  [Analyzing the Rapid Generalization of SFT via the Perspective of Attention Head Activation Patterns](https://aclanthology.org/2025.acl-long.831/) |  | 0 | LLMs’ performance on complex tasks is still unsatisfactory. A key issue is that presently LLMs learn in a data-driven schema, while the instructions about these complex tasks are both scarce and hard to collect or construct. On the contrary, a prominent phenomenon is that LLMs can learn rather fast... | Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin |  |
| 2320 |  |  [Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs](https://aclanthology.org/2025.acl-long.832/) |  | 0 | Multimodal Large Language Models (MLLMs) have expanded the capabilities of traditional language models by enabling interaction through both text and images. However, ensuring the safety of these models remains a significant challenge, particularly in accurately identifying whether multimodal... | Wenxuan Wang, Xiaoyuan Liu, Kuiyi Gao, Jentse Huang, Youliang Yuan, Pinjia He, Shuai Wang, Zhaopeng Tu |  |
| 2321 |  |  [Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling](https://aclanthology.org/2025.acl-long.833/) |  | 0 | Large language models (LLMs) have demonstrated significant advancements in error handling. Current error-handling works are performed in a passive manner, with explicit error-handling instructions. However, in real-world scenarios, explicit error-handling instructions are usually unavailable. In... | Jiayi Zeng, Yizhe Feng, Mengliang He, Wenhui Lei, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou |  |
| 2322 |  |  [TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning](https://aclanthology.org/2025.acl-long.834/) |  | 0 | Recent advancements in probing Large Language Models (LLMs) have explored their latent potential as personalized travel planning agents, though this remains a rather nascent field. Existing benchmarks, such as TravelPlanner and TravelPlanner+, rely on semi-synthetic data as well ignoring several... | Soumyabrata Chaudhuri, Pranav Purkar, Ritwik Raghav, Shubhojit Mallick, Manish Gupta, Abhik Jana, Shreya Ghosh |  |
| 2323 |  |  [DualGuard: A Parameter Space Transformation Approach for Bidirectional Defense in Split-Based LLM Fine-Tuning](https://aclanthology.org/2025.acl-long.835/) |  | 0 | Integrating split learning with large language model fine-tuning (LLM-FT) enables secure collaboration between a trusted local client and a well-equipped remote server, but it is vulnerable to data reconstruction attacks (DRAs) that exploit transmitted activations and gradients. Current defense... | Zihan Liu, Yizhen Wang, Rui Wang, Sai Wu |  |
| 2324 |  |  [Movie101v2: Improved Movie Narration Benchmark](https://aclanthology.org/2025.acl-long.836/) |  | 0 | Automatic movie narration aims to generate video-aligned plot descriptions to assist visually impaired audiences. Unlike standard video captioning, it involves not only describing key visual details but also inferring plots that unfold across multiple movie shots, presenting distinct and complex... | Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin |  |
| 2325 |  |  [Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs](https://aclanthology.org/2025.acl-long.837/) |  | 0 | Attributed Question Answering (AQA) has attracted wide attention, but there are still several limitations in evaluating the attributions, including lacking fine-grained attribution categories, relying on manual annotations, and failing to compare attributions with only subtle differences. To bridge... | Nan Hu, Jiaoyan Chen, Yike Wu, Guilin Qi, Hongru Wang, Sheng Bi, Yongrui Chen, Tongtong Wu, Jeff Z. Pan |  |
| 2326 |  |  [Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items](https://aclanthology.org/2025.acl-long.838/) |  | 0 | The importance of benchmarks for assessing the values of language models has been pronounced due to the growing need of more authentic, human-aligned responses. However, existing benchmarks rely on human or machine annotations that are vulnerable to value-related biases. Furthermore, the tested... | Jongwook Han, Dongmin Choi, Woojung Song, EunJu Lee, Yohan Jo |  |
| 2327 |  |  [FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation](https://aclanthology.org/2025.acl-long.839/) |  | 0 | Implementing new features in repository-level codebases is a crucial application of code generation models. However, current benchmarks lack a dedicated evaluation framework for this capability. To fill this gap, we introduce FEA-Bench, a benchmark designed to assess the ability of large language... | Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, Scarlett Li |  |
| 2328 |  |  [Do not Abstain! Identify and Solve the Uncertainty](https://aclanthology.org/2025.acl-long.840/) |  | 0 | Despite the widespread application of Large Language Models (LLMs) across various domains, they frequently exhibit overconfidence when encountering uncertain scenarios, yet existing solutions primarily rely on evasive responses (e.g., “I don’t know”) overlooks the opportunity of identifying and... | Jingyu Liu, JingquanPeng JingquanPeng, Xiaopeng Wu, Xubin Li, Tiezheng Ge, Bo Zheng, Yong Liu |  |
| 2329 |  |  [Decoding by Contrasting Knowledge: Enhancing Large Language Model Confidence on Edited Facts](https://aclanthology.org/2025.acl-long.841/) |  | 0 | The knowledge within large language models (LLMs) may become outdated quickly. While in-context editing (ICE) is currently the most effective method for knowledge editing (KE), it is constrained by the black-box modeling of LLMs and thus lacks interpretability. Our work aims to elucidate the... | Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Junfeng Fang, Pengliang Ji, Xueqi Cheng |  |
| 2330 |  |  [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://aclanthology.org/2025.acl-long.842/) |  | 0 | The existing research has primarily focused on text and image-based hate speech detection, video-based approaches remain underexplored. In this work, we introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate speech detection in videos. ImpliHateVid consists of 2,009 videos... | Mohammad Zia Ur Rehman, Anukriti Bhatnagar, Omkar Kabde, Shubhi Bansal, Nagendra Kumar |  |
| 2331 |  |  [Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions](https://aclanthology.org/2025.acl-long.843/) |  | 0 | Chain-of-Though (CoT) represents a common strategy for reasoning in Large Language Models (LLMs) by decomposing complex tasks into intermediate inference steps. However, explanations generated via CoT are susceptible to content biases that negatively affect their robustness and faithfulness. To... | Leonardo Ranaldi, Marco Valentino, André Freitas |  |
| 2332 |  |  [Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments](https://aclanthology.org/2025.acl-long.844/) |  | 0 | Information extraction (IE) from Visually Rich Documents (VRDs) containing layout features along with text is a critical and well-studied task. Specialized non-LLM NLP-based solutions typically involve training models using both textual and geometric information to label sequences/tokens as named... | Aniket Bhattacharyya, Anurag Tripathi, Ujjal Das, Archan Karmakar, Amit Pathak, Maneesh Gupta |  |
| 2333 |  |  [Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub](https://aclanthology.org/2025.acl-long.845/) |  | 0 | Large Language Models (LLMs) excel in traditional natural language processing tasks but struggle with problems that require complex domain-specific calculations or simulations. While equipping LLMs with external tools to build LLM-based agents can enhance their capabilities, existing approaches... | Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Cheng Qian, Zihe Wang, Yujia Qin, Yining Ye, Yaxi Lu, Chen Qian, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 2334 |  |  [LLMs Can Simulate Standardized Patients via Agent Coevolution](https://aclanthology.org/2025.acl-long.846/) |  | 0 | Training medical personnel using standardized patients (SPs) remains a complex challenge, requiring extensive domain expertise and role-specific practice. Most research on Large Language Model (LLM)-based simulated patients focuses on improving data retrieval accuracy or adjusting prompts through... | Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haochao Ying |  |
| 2335 |  |  [Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts](https://aclanthology.org/2025.acl-long.847/) |  | 0 | Accurate modeling of subjective phenomena such as emotion expression requires data annotated with authors’ intentions. Commonly such data is collected by asking study participants to donate and label genuine content produced in the real world, or create content fitting particu- lar labels during... | Christopher Bagdon, Aidan Combs, Carina Silberer, Roman Klinger |  |
| 2336 |  |  [Which Demographics do LLMs Default to During Annotation?](https://aclanthology.org/2025.acl-long.848/) |  | 0 | Demographics and cultural background of annotators influence the labels they assign in text annotation – for instance, an elderly woman might find it offensive to read a message addressed to a “bro”, but a male teenager might find it appropriate. It is therefore important to acknowledge label... | Johannes Schäfer, Aidan Combs, Christopher Bagdon, Jiahui Li, Nadine Probol, Lynn Greschner, Sean Papay, Yarik Menchaca Resendiz, Aswathy Velutharambath, Amelie Wührl, Sabine Weber, Roman Klinger |  |
| 2337 |  |  [Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective](https://aclanthology.org/2025.acl-long.849/) |  | 0 | Code security and usability are both essential for various coding assistant applications driven by large language models (LLMs). Current code security benchmarks focus solely on single evaluation task and paradigm, such as code completion and generation, lacking comprehensive assessment across... | Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye |  |
| 2338 |  |  [From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MarkerGen](https://aclanthology.org/2025.acl-long.850/) |  | 0 | Despite the rapid progress of large language models (LLMs), their length-controllable text generation (LCTG) ability remains below expectations, posing a major limitation for practical applications. Existing methods mainly focus on end-to-end training to reinforce adherence to length constraints.... | Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li |  |
| 2339 |  |  [AGD: Adversarial Game Defense Against Jailbreak Attacks in Large Language Models](https://aclanthology.org/2025.acl-long.851/) |  | 0 | LLMs demonstrate remarkable utility but remain vulnerable to jailbreak attacks that aim to elicit harmful responses. Existing defenses, including post-training alignment and prompt engineering, rely on training on safety-annotated datasets and safe prompt templates, struggling with adaptability to... | Shilong Pan, Zhiliang Tian, Zhen Huang, Wanlong Yu, Zhihua Wen, Xinwang Liu, Kai Lu, Minlie Huang, Dongsheng Li |  |
| 2340 |  |  [SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View](https://aclanthology.org/2025.acl-long.852/) |  | 0 | Despite the great potential of large language models (LLMs) in machine comprehension, it is still disturbing to fully count on them in real-world scenarios. This is probably because there is no rational explanation for whether the comprehension process of LLMs is aligned with that of experts. In... | Yongjie Xiao, Hongru Liang, Peixin Qin, Yao Zhang, Wenqiang Lei |  |
| 2341 |  |  [Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://aclanthology.org/2025.acl-long.853/) |  | 0 | Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition... | Peiying Yu, Guoxin Chen, Jingjing Wang |  |
| 2342 |  |  [An Expanded Massive Multilingual Dataset for High-Performance Language Technologies (HPLT)](https://aclanthology.org/2025.acl-long.854/) |  | 0 | Training state-of-the-art large language models requires vast amounts of clean and diverse textual data. However, building suitable multilingual datasets remains a challenge. In this work, we present HPLT v2, a collection of high-quality multilingual monolingual and parallel corpora, extending... | Laurie Burchell, Ona De Gibert Bonet, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, Pinzhen Chen, Mariia Fedorova, Liane Guillou, Barry Haddow, Jan Hajic, Jindrich Helcl, Erik Henriksson, Mateusz Klimaszewski, Ville Komulainen, Andrey Kutuzov, Joona Kytöniemi, Veronika Laippala, Petter Mæhlum, Bhavitvya Malik, Farrokh Mehryary, Vladislav Mikhailov, Nikita Moghe, Amanda Myntti, Dayyán O'Brien, Stephan Oepen, Proyag Pal, Jousia Piha, Sampo Pyysalo, Gema RamírezSánchez, David Samuel, Pavel Stepachev, Jörg Tiedemann, Dusan Varis, Tereza Vojtechová, Jaume ZaragozaBernabeu |  |
| 2343 |  |  [Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation](https://aclanthology.org/2025.acl-long.855/) |  | 0 | Reasoning about images with rich text, such as charts and documents, is a critical application of vision-language models (VLMs). However, VLMs often struggle in these domains due to the scarcity of diverse text-rich vision-language data. To address this challenge, we present CoSyn, a framework that... | Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris CallisonBurch, Ranjay Krishna, Aniruddha Kembhavi, Christopher Clark |  |
| 2344 |  |  [Hierarchical Attention Generates Better Proofs](https://aclanthology.org/2025.acl-long.856/) |  | 0 | Large language models (LLMs) have shown promise in formal theorem proving, but their token-level processing often fails to capture the inherent hierarchical nature of mathematical proofs. We introduce Hierarchical Attention, a regularization method that aligns LLMs’ attention mechanisms with... | Jianlong Chen, Chao Li, Yang Yuan, Andrew C. Yao |  |
| 2345 |  |  [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://aclanthology.org/2025.acl-long.857/) |  | 0 | As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is... | Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 2346 |  |  [It's Not Bragging If You Can Back It Up: Can LLMs Understand Braggings?](https://aclanthology.org/2025.acl-long.858/) |  | 0 | Bragging, as a pervasive social-linguistic phenomenon, reflects complex human interaction patterns. However, the understanding and generation of appropriate bragging behavior in large language models (LLMs) remains underexplored. In this paper, we propose a comprehensive study that combines... | Jingjie Zeng, Huayang Li, Liang Yang, Yuanyuan Sun, Hongfei Lin |  |
| 2347 |  |  [A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns](https://aclanthology.org/2025.acl-long.859/) |  | 0 | With the development of large language models, they are widely used as agents in various fields. A key component of agents is memory, which stores vital information but is susceptible to jailbreak attacks. Existing research mainly focuses on single-agent attacks and shared memory attacks. However,... | Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao |  |
| 2348 |  |  [Meta-Learning Neural Mechanisms rather than Bayesian Priors](https://aclanthology.org/2025.acl-long.860/) |  | 0 | Children acquire language despite being exposed to several orders of magnitude less data than large language models require. Meta-learning has been proposed as a way to integrate human-like learning biases into neural-network architectures, combining both the structured generalizations of symbolic... | Michael Eric Goodale, Salvador Mascarenhas, Yair Lakretz |  |
| 2349 |  |  [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.861/) |  | 0 | Retrieval in Retrieval-Augmented Generation (RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set.Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information... | Dahyun Lee, Yongrae Jo, Haeju Park, Moontae Lee |  |
| 2350 |  |  [Understanding Large Language Model Vulnerabilities to Social Bias Attacks](https://aclanthology.org/2025.acl-long.862/) |  | 0 | Large Language Models (LLMs) have become foundational in human-computer interaction, demonstrating remarkable linguistic capabilities across various tasks. However, there is a growing concern about their potential to perpetuate social biases present in their training data. In this paper, we... | Jiaxu Zhao, Meng Fang, Fanghua Ye, Ke Xu, Qin Zhang, Joey Tianyi Zhou, Mykola Pechenizkiy |  |
| 2351 |  |  [ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents](https://aclanthology.org/2025.acl-long.863/) |  | 0 | Dialogue agents powered by Large Language Models (LLMs) show superior performance in various tasks. Despite the better user understanding and human-like responses, their \*\*lack of controllability\*\* remains a key challenge, often leading to unfocused conversations or task failure. To address... | Zhigen Li, Jianxiang Peng, Yanmeng Wang, Yong Cao, Tianhao Shen, Minghui Zhang, Linxi Su, Shang Wu, Yihang Wu, Yuqian Wang, Ye Wang, Wei Hu, Jianfeng Li, Shaojun Wang, Jing Xiao, Deyi Xiong |  |
| 2352 |  |  [Pixel-Level Reasoning Segmentation via Multi-turn Conversations](https://aclanthology.org/2025.acl-long.864/) |  | 0 | Existing visual perception systems focus on region-level segmentation in single-turn dialogues, relying on complex and explicit query instructions. Such systems cannot reason at the pixel level and comprehend dynamic user intent that changes over interaction. Our work tackles this issue by... | Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria |  |
| 2353 |  |  [Fixing Distribution Shifts of LLM Self-Critique via On-Policy Self-Play Training](https://aclanthology.org/2025.acl-long.865/) |  | 0 | Self-critique mechanisms significantly improve the performance of language models in complex reasoning tasks by giving them the ability to correct errors, conduct induction and deduction, and switch thinking insights. However, synthetic data methods often require human-introduced errors or sampling... | Rong Bao, Donglei Yu, Kai Fan, Minpeng Liao |  |
| 2354 |  |  [Inferring Functionality of Attention Heads from their Parameters](https://aclanthology.org/2025.acl-long.866/) |  | 0 | Attention heads are one of the building blocks of large language models (LLMs). Prior work on investigating their operation mostly focused on analyzing their behavior during inference for specific circuits or tasks. In this work, we seek a comprehensive mapping of the operations they implement in a... | Amit Elhelo, Mor Geva |  |
| 2355 |  |  [Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations](https://aclanthology.org/2025.acl-long.867/) |  | 0 | Natural language explanations play a fundamental role in Natural Language Inference (NLI) by revealing how premises logically entail hypotheses. Recent work has shown that the interaction of large language models (LLMs) with theorem provers (TPs) can help verify and improve the validity of NLI... | Xin Quan, Marco Valentino, Louise A. Dennis, André Freitas |  |
| 2356 |  |  [Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing](https://aclanthology.org/2025.acl-long.868/) |  | 0 | Knowledge editing, which aims to update the knowledge encoded in language models, can be deceptive. Despite the fact that many existing knowledge editing algorithms achieve near-perfect performance on conventional metrics, the models edited by them are still prone to generating original knowledge.... | Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 2357 |  |  [Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation](https://aclanthology.org/2025.acl-long.869/) |  | 0 | Multi-hop Question Answering (MHQA) adds layers of complexity to question answering, making it more challenging. When Language Models (LMs) are prompted with multiple search results, they are tasked not only with retrieving relevant information but also employing multi-hop reasoning across the... | Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan |  |
| 2358 |  |  [From Human Reading to NLM Understanding: Evaluating the Role of Eye-Tracking Data in Encoder-Based Models](https://aclanthology.org/2025.acl-long.870/) |  | 0 | Cognitive signals, particularly eye-tracking data, offer valuable insights into human language processing. Leveraging eye-gaze data from the Ghent Eye-Tracking Corpus, we conducted a series of experiments to examine how integrating knowledge of human reading behavior impacts Neural Language Models... | Luca Dini, Lucia Domenichelli, Dominique Brunato, Felice Dell'Orletta |  |
| 2359 |  |  [Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering](https://aclanthology.org/2025.acl-long.871/) |  | 0 | Retrieval-augmented generation (RAG) is usually integrated into large language models (LLMs) to mitigate hallucinations and knowledge obsolescence. Whereas, conventional one-step retrieve-and-read methods are insufficient for multi-hop question answering, facing challenges of retrieval semantic... | Linhao Ye, Lang Yu, Zhikai Lei, Qin Chen, Jie Zhou, Liang He |  |
| 2360 |  |  [Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs](https://aclanthology.org/2025.acl-long.872/) |  | 0 | This paper explores the problem of commonsense level vision-knowledge conflict in Multimodal Large Language Models (MLLMs), where visual information contradicts model’s internal commonsense knowledge. To study this issue, we introduce an automated framework, augmented with human-in-the-loop quality... | Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jentse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu |  |
| 2361 |  |  [SceneGenAgent: Precise Industrial Scene Generation with Coding Agent](https://aclanthology.org/2025.acl-long.873/) |  | 0 | The modeling of industrial scenes is essential for simulations in industrial manufacturing. While large language models (LLMs) have shown significant progress in generating general 3D scenes from textual descriptions, generating industrial scenes with LLMs poses a unique challenge due to their... | Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong |  |
| 2362 |  |  [ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models](https://aclanthology.org/2025.acl-long.874/) |  | 0 | Tool learning has emerged as a crucial capability for large language models (LLMs) to solve complex real-world tasks through interaction with external tools. Existing approaches face significant challenges, including reliance on hand-crafted prompts, difficulty in multi-step planning, and lack of... | Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Cheng |  |
| 2363 |  |  [Enhancing Text Editing for Grammatical Error Correction: Arabic as a Case Study](https://aclanthology.org/2025.acl-long.875/) |  | 0 | Text editing frames grammatical error correction (GEC) as a sequence tagging problem, where edit tags are assigned to input tokens, and applying these edits results in the corrected text. This approach has gained attention for its efficiency and interpretability. However, while extensively explored... | Bashar Alhafni, Nizar Habash |  |
| 2364 |  |  [From Isolates to Families: Using Neural Networks for Automated Language Affiliation](https://aclanthology.org/2025.acl-long.876/) |  | 0 | In historical linguistics, the affiliation of languages to a common language family is traditionally carried out using a complex workflow that relies on manually comparing individual languages. Large-scale standardized collections of multilingual wordlists and grammatical language structures might... | Frederic Blum, Steffen Herbold, JohannMattis List |  |
| 2365 |  |  [ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models](https://aclanthology.org/2025.acl-long.877/) |  | 0 | Generative large language models are crucial in natural language processing, but they are vulnerable to backdoor attacks, where subtle triggers compromise their behavior. Although backdoor attacks against LLMs are constantly emerging, existing benchmarks remain limited in terms of sufficient... | Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao |  |
| 2366 |  |  [Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts](https://aclanthology.org/2025.acl-long.878/) |  | 0 | Continually expanding new languages for existing large language models (LLMs) is a promising yet challenging approach to building powerful multilingual LLMs.The biggest challenge is to make the model continuously learn new languages while preserving the proficient ability of old languages.To... | Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou |  |
| 2367 |  |  [When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation](https://aclanthology.org/2025.acl-long.879/) |  | 0 | Endowing dialogue agents with persona information has proven to significantly improve the consistency and diversity of their generations. While much focus has been placed on aligning dialogues with provided personas, the adaptation to the interlocutor’s profile remains largely underexplored. In... | Daniela Occhipinti, Marco Guerini, Malvina Nissim |  |
| 2368 |  |  [ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs](https://aclanthology.org/2025.acl-long.880/) |  | 0 | Large language models (LLMs) excel at various natural language processing tasks, but their tendency to generate hallucinations undermines their reliability. Existing hallucination detection methods leveraging hidden states predominantly focus on static and isolated representations, overlooking... | Zhenliang Zhang, Xinyu Hu, Huixuan Zhang, Junzhe Zhang, Xiaojun Wan |  |
| 2369 |  |  [Revisit Self-Debugging with Self-Generated Tests for Code Generation](https://aclanthology.org/2025.acl-long.881/) |  | 0 | Large language models (LLMs) have demonstrated significant advancements in code generation, yet they still face challenges when tackling tasks that extend beyond their basic capabilities. Recently, the concept of self-debugging has been proposed as a way to enhance code generation performance by... | Xiancai Chen, Zhengwei Tao, Kechi Zhang, Changzhi Zhou, Xinyu Zhang, Wanli Gu, Yuanpeng He, Mengdi Zhang, Xunliang Cai, Haiyan Zhao, Zhi Jin |  |
| 2370 |  |  [InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training](https://aclanthology.org/2025.acl-long.882/) |  | 0 | Recent advancements in speech large language models (SpeechLLMs) have attracted considerable attention. Nonetheless, current methods exhibit suboptimal performance in adhering to speech instructions. Notably, the intelligence of models significantly diminishes when processing speech-form input as... | Dingdong Wang, Jin Xu, Ruihang Chu, Zhifang Guo, Xiong Wang, Jincenzi Wu, Dongchao Yang, Shengpeng Ji, Junyang Lin |  |
| 2371 |  |  [Exploring LLMs' Ability to Spontaneously and Conditionally Modify Moral Expressions through Text Manipulation](https://aclanthology.org/2025.acl-long.883/) |  | 0 | Morality serves as the foundation of societal structure, guiding legal systems, shaping cultural values, and influencing individual self-perception. With the rise and pervasiveness of generative AI tools, and particularly Large Language Models (LLMs), concerns arise regarding how these tools... | Candida Maria Greco, Lucio La Cava, Lorenzo Zangari, Andrea Tagarelli |  |
| 2372 |  |  [Mixture of Ordered Scoring Experts for Cross-prompt Essay Trait Scoring](https://aclanthology.org/2025.acl-long.884/) |  | 0 | Automated Essay Scoring (AES) plays a crucial role in language assessment. In particular, cross-prompt essay trait scoring provides learners with valuable feedback to improve their writing skills. However, due to the scarcity of prompts, most existing methods overlook critical information, such as... | PoKai Chen, BoWei Tsai, ShaoKuan Wei, ChienYao Wang, JiaChing Wang, YiTing Huang |  |
| 2373 |  |  [Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs](https://aclanthology.org/2025.acl-long.885/) |  | 0 | Knowledge distillation can be a cost-effective technique to distill knowledge in Large Language Models, if the teacher output logits can be pre-computed and cached. However, successfully applying this to pre-training remains largely unexplored. In this work, we prove that naive approaches for... | Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jinwoo Ahn, Taehwak Kwon, Kangwook Lee, Haejun Lee, Joohyung Lee |  |
| 2374 |  |  [Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues](https://aclanthology.org/2025.acl-long.886/) |  | 0 | Research in linguistics shows that non-verbal cues, such as gestures, play a crucial role in spoken discourse. For example, speakers perform hand gestures to indicate topic shifts, helping listeners identify transitions in discourse. In this work, we investigate whether the joint modeling of... | Varsha Suresh, Muhammad Hamza Mughal, Christian Theobalt, Vera Demberg |  |
| 2375 |  |  [ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration](https://aclanthology.org/2025.acl-long.887/) |  | 0 | Large language models face intrinsic limitations in coding with APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving programming problems which require... | Yunkun Wang, Yue Zhang, Zhen Qin, Chen Zhi, Binhua Li, Fei Huang, Yongbin Li, Shuiguang Deng |  |
| 2376 |  |  [Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models](https://aclanthology.org/2025.acl-long.888/) |  | 0 | Word segmentation stands as a cornerstone of Natural Language Processing (NLP). Based on the concept of “comprehend first, segment later”, we propose a new framework to explore the limit of unsupervised word segmentation with Large Language Models (LLMs) and evaluate the semantic understanding... | Zihong Zhang, Liqi He, Zuchao Li, Lefei Zhang, Hai Zhao, Bo Du |  |
| 2377 |  |  [RUBY: An Effective Framework for Multi-Constraint Multi-Hop Question Generation](https://aclanthology.org/2025.acl-long.889/) |  | 0 | Inspired by theories in language psychology, it is natural to consider more constraints, such as intentions, logic, knowledge, etc., when a complex or multi-hop question is generated. As the subtask of Multi-Hop Question Generation (MHQG), the task of Multi-Constraint Multi-Hop Question Generation... | Wenzhuo Zhao, Shuangyin Li |  |
| 2378 |  |  [Can Indirect Prompt Injection Attacks Be Detected and Removed?](https://aclanthology.org/2025.acl-long.890/) |  | 0 | Prompt injection attacks manipulate large language models (LLMs) by misleading them to deviate from the original input instructions and execute maliciously injected instructions, because of their instruction-following capabilities and inability to distinguish between the original input instructions... | Yulin Chen, Haoran Li, Yuan Sui, Yufei He, Yue Liu, Yangqiu Song, Bryan Hooi |  |
| 2379 |  |  [Identifying Open Challenges in Language Identification](https://aclanthology.org/2025.acl-long.891/) |  | 0 | Automatic language identification is a core problem of many Natural LanguageProcessing (NLP) pipelines. A wide variety of architectures and benchmarks havebeen proposed with often near-perfect performance. Although previousstudies have focused on certain challenging setups (i.e. cross-domain,... | Rob van der Goot |  |
| 2380 |  |  [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://aclanthology.org/2025.acl-long.892/) |  | 0 | A well-known issue with Retrieval Augmented Generation (RAG) is that retrieved passages that are irrelevant to the query sometimes distract the answer-generating LLM, causing it to provide an incorrect response. In this paper, we shed light on this core issue and formulate the distracting effect of... | Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar S. Karnin |  |
| 2381 |  |  [Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages](https://aclanthology.org/2025.acl-long.893/) |  | 0 | While multilingual language models like XLM-R have advanced multilingualism in NLP, they still perform poorly in extremely low-resource languages. This situation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen support far fewer languages than XLM-R, making text generation models... | Zeli Su, Ziyin Zhang, Guixian Xu, Jianing Liu, Xu Han, Ting Zhang, Yushuang Dong |  |
| 2382 |  |  [Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights](https://aclanthology.org/2025.acl-long.894/) |  | 0 | Detecting abusive language in social media conversations poses significant challenges, as identifying abusiveness often depends on the conversational context, characterized by the content and topology of preceding comments. Traditional Abusive Language Detection (ALD) models often overlook this... | Célia Nouri, Chloé Clavel, JeanPhilippe Cointet |  |
| 2383 |  |  [CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision](https://aclanthology.org/2025.acl-long.895/) |  | 0 | Tool invocation significantly enhances the capabilities of Large Language Models (LLMs), yet challenges persist, particularly in complex task scenarios. Current methods, such as instruction-enhanced reasoning and supervised fine-tuning, often result in unnecessarily long reasoning paths and face... | Yifei Lu, Fanghua Ye, Jian Li, Qiang Gao, Cheng Liu, Haibo Luo, Nan Du, Xiaolong Li, Feiliang Ren |  |
| 2384 |  |  [RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models](https://aclanthology.org/2025.acl-long.896/) |  | 0 | This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a versatile extension to the mutual reasoning framework (rStar), aimed at enhancing reasoning accuracy and factual integrity across large language models (LLMs) for complex, knowledge-intensive tasks such as medical and... | Hieu Tran, Zonghai Yao, Zhichao Yang, Junda Wang, Yifan Zhang, Shuo Han, Feiyun Ouyang, Hong Yu |  |
| 2385 |  |  [Defense Against Prompt Injection Attack by Leveraging Attack Techniques](https://aclanthology.org/2025.acl-long.897/) |  | 0 | With the advancement of technology, large language models (LLMs) have achieved remarkable performance across various natural language processing (NLP) tasks, powering LLM-integrated applications like Microsoft Copilot. However, as LLMs continue to evolve, new vulnerabilities, especially prompt... | Yulin Chen, Haoran Li, Zihao Zheng, Dekai Wu, Yangqiu Song, Bryan Hooi |  |
| 2386 |  |  [Acquisition and Application of Novel Knowledge in Large Language Models](https://aclanthology.org/2025.acl-long.898/) |  | 0 | Recent advancements in large language models (LLMs) have demonstrated their impressive generative capabilities, primarily due to their extensive parameterization, which enables them to encode vast knowledge. However, effectively integrating new knowledge into LLMs remains a major challenge. Current... | Ziyu Shang, Jianghan Liu, Zhizhao Luo, Peng Wang, Wenjun Ke, Jiajun Liu, Zijie Xu, Guozheng Li |  |
| 2387 |  |  [DNCASR: End-to-End Training for Speaker-Attributed ASR](https://aclanthology.org/2025.acl-long.899/) |  | 0 | This paper introduces DNCASR, a novel end-to-end trainable system designed for joint neural speaker clustering and automatic speech recognition (ASR), enabling speaker-attributed transcription of long multi-party meetings. DNCASR uses two separate encoders to independently encode global speaker... | Xianrui Zheng, Chao Zhang, Philip C. Woodland |  |
| 2388 |  |  [Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation](https://aclanthology.org/2025.acl-long.900/) |  | 0 | Personalized dialogue systems have advanced considerably with the integration of user-specific personas into large language models (LLMs). However, while LLMs can effectively generate personalized responses, the influence of persona sentiment on dialogue quality remains underexplored. In this work,... | Yonghyun Jun, Hwanhee Lee |  |
| 2389 |  |  [AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge](https://aclanthology.org/2025.acl-long.901/) |  | 0 | Data contamination hinders fair LLM evaluation by introducing test data into newer models’ training sets. Existing studies solve this challenge by updating benchmarks with newly collected data. However, they fail to guarantee contamination-free evaluation as the newly collected data may contain... | Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang |  |
| 2390 |  |  [LLM-Guided Semantic-Aware Clustering for Topic Modeling](https://aclanthology.org/2025.acl-long.902/) |  | 0 | Topic modeling aims to discover the distribution of topics within a corpus. The advanced comprehension and generative capabilities of large language models (LLMs) have introduced new avenues for topic modeling, particularly by prompting LLMs to generate topics and refine them by merging similar... | Jianghan Liu, Ziyu Shang, Wenjun Ke, Peng Wang, Zhizhao Luo, Jiajun Liu, Guozheng Li, Yining Li |  |
| 2391 |  |  [Hierarchical Bracketing Encodings for Dependency Parsing as Tagging](https://aclanthology.org/2025.acl-long.903/) |  | 0 | We present a family of encodings for sequence labeling dependency parsing, based on the concept of hierarchical bracketing. We show that the existing 4-bit projective encoding belongs to this family, but it is suboptimal in the number of labels used to encode a tree. We derive an optimal... | Ana Ezquerro, David Vilares, Anssi YliJyrä, Carlos GómezRodríguez |  |
| 2392 |  |  [OASIS: Order-Augmented Strategy for Improved Code Search](https://aclanthology.org/2025.acl-long.904/) |  | 0 | Code embeddings capture the semantic representations of code and are crucial for various code-related large language model (LLM) applications, such as code search. Previous training primarily relies on optimizing the InfoNCE loss by comparing positive natural language (NL)-code pairs with in-batch... | Zuchen Gao, Zizheng Zhan, Xianming Li, Erxin Yu, Haotian Zhang, Chenbin Chenbin, Yuqun Zhang, Jing Li |  |
| 2393 |  |  [Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?](https://aclanthology.org/2025.acl-long.905/) |  | 0 | Recently, o1-like models have drawn significant attention, where these models produce the long Chain-of-Thought (CoT) reasoning steps to improve the reasoning abilities of existing Large Language Models (LLMs). In this paper, to understand the qualities of these long CoTs and measure the critique... | Yancheng He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge Zhang, Z. Y. Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, Bo Zheng |  |
| 2394 |  |  [OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference](https://aclanthology.org/2025.acl-long.906/) |  | 0 | Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment. This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples... | Xiangyu Zhao, Shengyuan Ding, Zicheng Zhang, Haian Huang, Maosongcao Maosongcao, Jiaqi Wang, Weiyun Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Hua Yang, Haodong Duan, Kai Chen |  |
| 2395 |  |  [Tree-KG: An Expandable Knowledge Graph Construction Framework for Knowledge-intensive Domains](https://aclanthology.org/2025.acl-long.907/) |  | 0 | In knowledge-intensive domains like scientific research, effective decisions rely on organizing and retrieving intricate data. Knowledge graphs (KGs) help by structuring entities, relations, and contextual dependencies, but building KGs in such domains is challenging due to inherent complexity,... | Songjie Niu, Kaisen Yang, Rui Zhao, Yichao Liu, Zonglin Li, Hongning Wang, Wenguang Chen |  |
| 2396 |  |  [Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric](https://aclanthology.org/2025.acl-long.908/) |  | 0 | Data diversity is crucial for the instruction tuning of large language models. Existing studies have explored various diversity-aware data selection methods to construct high-quality datasets and enhance model performance. However, the fundamental problem of precisely defining and measuring data... | Yuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 2397 |  |  [Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning](https://aclanthology.org/2025.acl-long.909/) |  | 0 | Retrieval-Augmented Generation (RAG) systems commonly suffer from \*\*Knowledge Conflicts\*\*, where retrieved external knowledge contradicts the inherent, parametric knowledge of large language models (LLMs). It adversely affects performance on downstream tasks such as question answering (QA).... | Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng |  |
| 2398 |  |  [Minimal Pair-Based Evaluation of Code-Switching](https://aclanthology.org/2025.acl-long.910/) |  | 0 | There is a lack of an evaluation methodology that estimates the extent to which large language models (LLMs) use code-switching (CS) in the same way as bilinguals. Existing methods do not have wide language coverage, fail to account for the diverse range of CS phenomena, or do not scale. We propose... | Igor Sterner, Simone Teufel |  |
| 2399 |  |  [DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions](https://aclanthology.org/2025.acl-long.911/) |  | 0 | In this paper, we propose contextualized and situated text-to-speech (CS-TTS), a novel TTS task to promote more accurate and customized speech generation using prompts with Dialogues, Narratives, and Actions (DNA). While prompt-based TTS methods facilitate controllable speech generation, existing... | Chuanqi Cheng, Hongda Sun, Bo Du, Shuo Shang, Xinrong Hu, Rui Yan |  |
| 2400 |  |  [LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://aclanthology.org/2025.acl-long.912/) |  | 0 | Real-time, intelligent, and natural speech interaction is an essential part of the next-generation human-computer interaction. Recent advancements have showcased the potential of building intelligent spoken chatbots based on large language models (LLMs). In this paper, we introduce LLaMA-Omni 2, a... | Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng |  |
| 2401 |  |  [Error Comparison Optimization for Large Language Models on Aspect-Based Sentiment Analysis](https://aclanthology.org/2025.acl-long.913/) |  | 0 | Supervised fine-tuning (SFT) has enabled large language models (LLMs) to exhibit promising performance on various tasks. However, this fine-tuning process only compares current predictions and labels on each sample, yet fails to perceive and understand its error outputs from different degrees,... | Qianlong Wang, Keyang Ding, Hengxin Gao, Hui Wang, Ruifeng Xu |  |
| 2402 |  |  [The AI Gap: How Socioeconomic Status Affects Language Technology Interactions](https://aclanthology.org/2025.acl-long.914/) |  | 0 | Socioeconomic status (SES) fundamentally influences how people interact with each other and, more recently, with digital technologies like large language models (LLMs). While previous research has highlighted the interaction between SES and language technology, it was limited by reliance on proxy... | Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy |  |
| 2403 |  |  [Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set](https://aclanthology.org/2025.acl-long.915/) |  | 0 | Discourse understanding is essential for many NLP tasks, yet most existing work remains constrained by framework-dependent discourse representations. This work investigates whether large language models (LLMs) capture discourse knowledge that generalizes across languages and frameworks. We address... | Florian Eichin, Yang Janet Liu, Barbara Plank, Michael A. Hedderich |  |
| 2404 |  |  [Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia](https://aclanthology.org/2025.acl-long.916/) |  | 0 | Despite Southeast Asia’s (SEA) extraordinary linguistic and cultural diversity, the region remains significantly underrepresented in vision-language (VL) research, resulting in AI models that inadequately capture SEA cultural nuances. To fill this gap, we present SEA-VL, an open-source initiative... | Samuel Cahyawijaya, Holy Lovenia, Joel Ruben Antony Moniz, Tack Hwa Wong, Mohammad Rifqi Farhansyah, Thant Thiri Maung, Frederikus Hudi, David Anugraha, Muhammad Ravi Shulthan Habibi, Muhammad Reza Qorib, Amit Agarwal, Joseph Marvin Imperial, Hitesh Laxmichand Patel, Vicky Feliren, Bahrul Ilmi Nasution, Manuel Antonio Rufino, Genta Indra Winata, Rian Adam Rajagede, Carlos Rafael Catalan, Mohamed Fazli Mohamed Imam, Priyaranjan Pattnayak, Salsabila Zahirah Pranida, Kevin Pratama, Yeshil Bangera, Adisai NaThalang, Patricia Nicole Monderin, Yueqi Song, Christian Simon, Lynnette Hui Xian Ng, Richardy Lobo' Sapan, Taki Hasan Rafi, Bin Wang, Supryadi, Kanyakorn Veerakanjana, Piyalitt Ittichaiwong, Matthew Theodore Roque, Karissa Vincentio, Takdanai Kreangphet, Phakphum Artkaew, Kadek Hendrawan Palgunadi, Yanzhi Yu, Rochana Prih Hastuti, William Nixon, Mithil Bangera, Adrian Xuan Wei Lim, Aye Hninn Khine, Hanif Muhammad Zhafran, Teddy Ferdinan, Audra Aurora Izzani, Ayushman Singh, Evan, Jauza Akbar Krito, Michael Anugraha, Fenal Ashokbhai Ilasariya, Haochen Li, John Amadeo Daniswara, Filbert Aurelian Tjiaranata, Eryawan Presma Yulianrifat, Can Udomcharoenchaikit, Fadil Risdian Ansori, Mahardika Krisna Ihsani, Giang Nguyen, Anab Maulana Barik, Dan John Velasco, Rifo Ahmad Genadi, Saptarshi Saha, Chengwei Wei, Isaiah Edri W. Flores, Kenneth Ko Han Chen, Anjela Gail Santos, Wan Shen Lim, Kaung Si Phyo, Tim Santos, Meisyarah Dwiastuti, Jiayun Luo, Jan Christian Blaise Cruz, Ming Shan Hee, Ikhlasul Akmal Hanif, M. Alif Al Hakim, Muhammad Rizky Sya'ban, Kun Kerdthaisong, Lester James Validad Miranda, Fajri Koto, Tirana Noor Fatyanosa, Alham Fikri Aji, Jostin Jerico Rosal, Jun Kevin, Robert Wijaya, Onno P. Kampman, Ruochen Zhang, Börje F. Karlsson, Peerat Limkonchotiwat |  |
| 2405 |  |  [Soundwave: Less is More for Speech-Text Alignment in LLMs](https://aclanthology.org/2025.acl-long.917/) |  | 0 | Existing end-to-end speech large language models (LLMs) usually rely on large-scale annotated data for training, while data-efficient training has not been discussed in depth. We focus on two fundamental problems between speech and text: the representation space gap and sequence length... | Yuhao Zhang, Zhiheng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li |  |
| 2406 |  |  [RoToR: Towards More Reliable Responses for Order-Invariant Inputs](https://aclanthology.org/2025.acl-long.918/) |  | 0 | Mitigating positional bias of language models (LMs) for listwise inputs is a well-known and important problem (e.g., lost-in-the-middle). While zero-shot order-invariant LMs have been proposed to solve this issue, their success on practical listwise problems has been limited. In this work, as a... | Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, Seungwon Hwang |  |
| 2407 |  |  [Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation](https://aclanthology.org/2025.acl-long.919/) |  | 0 | Reliable multilingual evaluation is difficult, and culturally appropriate evaluation is even harder to achieve.A common practice to fill this gap is to machine-translate English evaluation sets. However, translation introduces language bias and carries over cultural and regional assumptions from... | Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David Ifeoluwa Adelani, Jian Gang Ngui, Daniel VilaSuero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Sebastian Ruder, WeiYin Ko, Antoine Bosselut, Alice Oh, André F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, Sara Hooker |  |
| 2408 |  |  [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://aclanthology.org/2025.acl-long.920/) |  | 0 | Dialogue discourse parsing aims to identify and analyze discourse relations between the utterances within dialogues. However, linguistic features in dialogues, such as omission and idiom, frequently introduce ambiguities that obscure the intended discourse relations, posing significant challenges... | Yaxin Fan, Peifeng Li, Qiaoming Zhu |  |
| 2409 |  |  [ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs](https://aclanthology.org/2025.acl-long.921/) |  | 0 | With the proliferation of task-specific large language models, delta compression has emerged as a method to mitigate the resource challenges of deploying numerous such models by effectively compressing the delta model parameters. Previous delta-sparsification methods either remove parameters... | Yan Yang, Yixia Li, Hongru Wang, Xuetao Wei, James Jianqiao Yu, Yun Chen, Guanhua Chen |  |
| 2410 |  |  [Words of Warmth: Trust and Sociability Norms for over 26k English Words](https://aclanthology.org/2025.acl-long.922/) |  | 0 | Social psychologists have shown that Warmth (W) and Competence (C) are the primary dimensions along which we assess other people and groups. These dimensions impact various aspects of our lives from social competence and emotion regulation to success in the work place and how we view the world.... | Saif M. Mohammad |  |
| 2411 |  |  [BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models](https://aclanthology.org/2025.acl-long.923/) |  | 0 | Language model evaluation is a daunting task: prompts are brittle, corpus-level perplexities are vague, and the choice of benchmarks are endless. Finding examples that show meaningful, generalizable differences between two LMs is crucial to understanding where one model succeeds and another fails.... | Lindia Tjuatja, Graham Neubig |  |
| 2412 |  |  [HAF-RM: A Hybrid Alignment Framework for Reward Model Training](https://aclanthology.org/2025.acl-long.924/) |  | 0 | The reward model has become increasingly important in alignment, assessment, and data construction for large language models (LLMs). Most existing researchers focus on enhancing reward models through data improvements, following the conventional training framework for reward models that directly... | Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, Shengbin Yue, Zengfeng Huang, Xuanjing Huang, Zhongyu Wei |  |
| 2413 |  |  [CULEMO: Cultural Lenses on Emotion - Benchmarking LLMs for Cross-Cultural Emotion Understanding](https://aclanthology.org/2025.acl-long.925/) |  | 0 | NLP research has increasingly focused on subjective tasks such as emotion analysis. However, existing emotion benchmarks suffer fromtwo major shortcomings: (1) they largely rely on keyword-based emotion recognition, overlooking crucial cultural dimensions required fordeeper emotion understanding,... | Tadesse Destaw Belay, Ahmed Haj Ahmed, Alvin Grissom II, Iqra Ameer, Grigori Sidorov, Olga Kolesnikova, Seid Muhie Yimam |  |
| 2414 |  |  [DiffPO: Diffusion-styled Preference Optimization for Inference Time Alignment of Large Language Models](https://aclanthology.org/2025.acl-long.926/) |  | 0 | Inference-time alignment provides an efficient alternative for aligning LLMs with humans. However, these approaches still face challenges, such as limited scalability due to policy-specific value functions and latency during the inference phase. In this paper, we propose a novel approach,... | Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Ziyang Wang, Tony Q. S. Quek, Joey Tianyi Zhou, Soujanya Poria, Zuozhu Liu |  |
| 2415 |  |  [MemeQA: Holistic Evaluation for Meme Understanding](https://aclanthology.org/2025.acl-long.927/) |  | 0 | Automated meme understanding requires systems to demonstrate fine-grained visual recognition, commonsense reasoning, and extensive cultural knowledge. However, existing benchmarks for meme understanding only concern narrow aspects of meme semantics. To fill this gap, we present MemeQA, a dataset of... | Khoi P. N. Nguyen, Terrence Li, Derek Lou Zhou, Gabriel Xiong, Pranav Balu, Nandhan Alahari, Alan Huang, Tanush Chauhan, Harshavardhan Bala, Emre Guzelordu, Affan Kashfi, Aaron Xu, Suyesh Shrestha, Megan Kim Vu, Jerry Yining Wang, Vincent Ng |  |
| 2416 |  |  [LoGU: Long-form Generation with Uncertainty Expressions](https://aclanthology.org/2025.acl-long.928/) |  | 0 | While Large Language Models (LLMs) demonstrate impressive capabilities, they still struggle with generating factually incorrect content (i.e., hallucinations). A promising approach to mitigate this issue is enabling models to express uncertainty when unsure. Previous research on uncertainty... | Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang |  |
| 2417 |  |  [KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.929/) |  | 0 | Iterative retrieval-augmented generation (iRAG) models offer an effective approach for multihop question answering (QA). However, their retrieval processes face two key challenges: (1) they can be disrupted by irrelevant documents or factually inaccurate chain-of-thoughts; (2) their retrievers are... | Jinyuan Fang, Zaiqiao Meng, Craig MacDonald |  |
| 2418 |  |  [Enhancing Lexicon-Based Text Embeddings with Large Language Models](https://aclanthology.org/2025.acl-long.930/) |  | 0 | Recent large language models (LLMs) have demonstrated exceptional performance on general-purpose text embedding tasks. While dense embeddings have dominated related research, we introduce the first lexicon-based embeddings (LENS) leveraging LLMs that achieve competitive performance on these tasks.... | Yibin Lei, Tao Shen, Yu Cao, Andrew Yates |  |
| 2419 |  |  [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://aclanthology.org/2025.acl-long.931/) |  | 0 | Due to their ability to process long and complex contexts, LLMs can offer key benefits to the Legal domain, but their adoption has been hindered by their tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While Retrieval-Augmented Generation offers a promising solution by... | T. Y. S. S. Santosh, Youssef Tarek Elkhayat, Oana Ichim, Pranav Shetty, Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu |  |
| 2420 |  |  [Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization](https://aclanthology.org/2025.acl-long.932/) |  | 0 | Automatic N-gram based metrics such as ROUGE are widely used for evaluating generative tasks such as summarization. While these metrics are considered indicative (even if imperfect), of human evaluation for English, their suitability for other languages remains unclear. To address this, in this... | Itai Mondshine, Tzuf PazArgaman, Reut Tsarfaty |  |
| 2421 |  |  [CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning](https://aclanthology.org/2025.acl-long.933/) |  | 0 | Current large language models (LLMs) often exhibit imbalanced multilingual capabilities due to their English-centric training corpora. To address this, existing fine-tuning approaches operating at the data-level (e.g., through data augmentation or distillation) typically introduce implicit... | Yangfan Ye, Xiaocheng Feng, Zekun Yuan, Xiachong Feng, Libo Qin, Lei Huang, Weitao Ma, Yichong Huang, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin |  |
| 2422 |  |  [SConU: Selective Conformal Uncertainty in Large Language Models](https://aclanthology.org/2025.acl-long.934/) |  | 0 | As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer... | Zhiyuan Wang, Qingni Wang, Yue Zhang, Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu |  |
| 2423 |  |  [MegaPairs: Massive Data Synthesis for Universal Multimodal Retrieval](https://aclanthology.org/2025.acl-long.935/) |  | 0 | Despite the rapidly growing demand for multimodal retrieval, progress in this field remains severely constrained by a lack of training data. In this paper, we introduce MegaPairs, a novel data synthesis method that leverages vision language models (VLMs) and open-domain images, together with a... | Junjie Zhou, Yongping Xiong, Zheng Liu, Ze Liu, Shitao Xiao, Yueze Wang, Bo Zhao, Chen Jason Zhang, Defu Lian |  |
| 2424 |  |  [When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs](https://aclanthology.org/2025.acl-long.936/) |  | 0 | Knowledge files have been widely used in large language model (LLM)-powered agents, such as GPTs, to improve response quality. However, concerns over the potential leakage of knowledge files have grown significantly. Existing studies demonstrate that adversarial prompts can induce GPTs to leak... | Xinyue Shen, Yun Shen, Michael Backes, Yang Zhang |  |
| 2425 |  |  [UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook](https://aclanthology.org/2025.acl-long.937/) |  | 0 | The emergence of audio language models is empowered by neural audio codecs, which establish critical mappings between continuous waveforms and discrete tokens compatible with language model paradigms. The evolutionary trends from multi-layer residual vector quantizer to single-layer quantizer are... | Yidi Jiang, Qian Chen, Shengpeng Ji, Yu Xi, Wen Wang, Chong Zhang, Xianghu Yue, Shiliang Zhang, Haizhou Li |  |
| 2426 |  |  [KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models](https://aclanthology.org/2025.acl-long.938/) |  | 0 | Recent advances in large language models (LLMs) and the abundance of food data have resulted in studies to improve food understanding using LLMs. Despite several recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there has been limited research on integrating food related KGs with... | Fnu Mohbat, Mohammed J. Zaki |  |
| 2427 |  |  [Multilingual Arbitration: Optimizing Data Pools to Accelerate Multilingual Progress](https://aclanthology.org/2025.acl-long.939/) |  | 0 | Synthetic data has driven recent state-of-the-art advancements, but reliance on a single oracle teacher model can lead to model collapse and bias propagation. These issues are particularly severe in multilingual settings, where no single model excels across all languages. In this study, we propose... | Ayomide Odumakinde, Daniel D'souza, Pat Verga, Beyza Ermis, Sara Hooker |  |
| 2428 |  |  [Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models](https://aclanthology.org/2025.acl-long.940/) |  | 0 | Large language models (LLMs) exhibit remarkable capabilities in natural language processing but face catastrophic forgetting when learning new tasks, where adaptation to a new domain leads to a substantial decline in performance on previous tasks. In this paper, we propose Controlled LoRA (CLoRA),... | Yuheng Lu, Bingshuo Qian, Caixia Yuan, Huixing Jiang, Xiaojie Wang |  |
| 2429 |  |  [Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models](https://aclanthology.org/2025.acl-long.941/) |  | 0 | New LLM benchmarks are important to align with the rapid development of Large Language Models (LLMs). In this work, we present Chinese SimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality ability of LLMs to answer short questions, and Chinese SimpleQA mainly has five... | Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Weixun Wang, Hui Huang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Zhuoran Lin, Dekai Sun, Zhicheng Zheng, Wenbo Su, Bo Zheng |  |
| 2430 |  |  [PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings](https://aclanthology.org/2025.acl-long.942/) |  | 0 | Visual persuasion, which uses visual elements to influence cognition and behaviors, is crucial in fields such as advertising and politicalcommunication. With recent advancements in artificial intelligence, there is growing potential to develop persuasive systems that automatically generate... | Junseo Kim, Jongwook Han, Dongmin Choi, Jongwook Yoon, EunJu Lee, Yohan Jo |  |
| 2431 |  |  [Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval](https://aclanthology.org/2025.acl-long.943/) |  | 0 | With the popularity of multimodal techniques, it receives growing interests to acquire useful information in visual forms. In this work, we formally define an emerging IR paradigm called Visualized Information Retrieval, or Vis-IR, where multimodal information, such as texts, images, tables and... | Zheng Liu, Ze Liu, Zhengyang Liang, Junjie Zhou, Shitao Xiao, Chao Gao, Chen Jason Zhang, Defu Lian |  |
| 2432 |  |  [Tunable LLM-based Proactive Recommendation Agent](https://aclanthology.org/2025.acl-long.944/) |  | 0 | Recommender systems are indispensable on various digital platforms. However, traditional methods often reinforce existing user interests, which leads to echo chambers and limits diversity. Proactive Recommendation Systems (PRS) aim to address this issue by cultivating users’ latent interests... | Mingze Wang, Chongming Gao, Wenjie Wang, Yangyang Li, Fuli Feng |  |
| 2433 |  |  [AgentRM: Enhancing Agent Generalization with Reward Modeling](https://aclanthology.org/2025.acl-long.945/) |  | 0 | Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward... | Yu Xia, Jingru Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yaxi Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 2434 |  |  [From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment](https://aclanthology.org/2025.acl-long.946/) |  | 0 | Inference-time alignment methods have gained significant attention for their efficiency and effectiveness in aligning large language models (LLMs) with human preferences. However, existing dominant approaches using reward-guided search (RGS) primarily rely on outcome reward models (ORMs), which... | Bin Xie, Bingbing Xu, Yige Yuan, Shengmao Zhu, Huawei Shen |  |
| 2435 |  |  [Segment-Based Attention Masking for GPTs](https://aclanthology.org/2025.acl-long.947/) |  | 0 | Causal masking is a fundamental component in Generative Pre-Trained Transformer (GPT) models, playing a crucial role during training. Although GPTs can process the entire user prompt at once, the causal masking is applied to all input tokens step-by-step, mimicking the generation process. This... | Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf |  |
| 2436 |  |  [Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity](https://aclanthology.org/2025.acl-long.948/) |  | 0 | A range of recent works addresses the problem of compression of sequence of tokens into a shorter sequence of real-valued vectors to be used as inputs instead of token embeddings or key-value cache. These approaches are focused on reduction of the amount of compute in existing language models... | Yuri Kuratov, Mikhail Arkhipov, Aydar Bulatov, Mikhail Burtsev |  |
| 2437 |  |  [Bi-Tuning with Collaborative Information for Controllable LLM-based Sequential Recommendation](https://aclanthology.org/2025.acl-long.949/) |  | 0 | Sequential recommender systems, which leverage historical interactions to deliver targeted recommendations, have been significantly advanced by large language models (LLMs). However, LLM-based generative sequential recommendation often faces two key challenges: the lack of collaborative knowledge... | Xinyu Zhang, Linmei Hu, Luhao Zhang, Wentao Cheng, Yashen Wang, Ge Shi, Chong Feng, Liqiang Nie |  |
| 2438 |  |  [A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment](https://aclanthology.org/2025.acl-long.950/) |  | 0 | High computation costs and latency of large language models such as GPT-4 have limited their deployment in clinical settings. Small language models (SLMs) offer a cost-effective alternative, but their limited capacity requires biomedical domain adaptation, which remains challenging. An additional... | JeanPhilippe Corbeil, Amin Dada, JeanMichel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, François Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila |  |
| 2439 |  |  [DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts](https://aclanthology.org/2025.acl-long.951/) |  | 0 | Large language models (LLMs) with the Mixture-of-Experts (MoE) architecture achieve high cost-efficiency by selectively activating a subset of the parameters. Despite the inference efficiency of MoE LLMs, the training of extensive experts from scratch incurs substantial overhead, whereas... | Yuchen Feng, Bowen Shen, Naibin Gu, Jiaxuan Zhao, Peng Fu, Zheng Lin, Weiping Wang |  |
| 2440 |  |  [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://aclanthology.org/2025.acl-long.952/) |  | 0 | Task-agnostic prompt compression leverages the redundancy in natural language to reduce computational overhead and enhance information density within prompts, especially in long-context scenarios. Existing methods predominantly rely on information entropy as the metric to compress lexical units,... | Yi Zhao, Zuchao Li, Hai Zhao, Baoyuan Qi, Liu Guoming |  |
| 2441 |  |  [Computation Mechanism Behind LLM Position Generalization](https://aclanthology.org/2025.acl-long.953/) |  | 0 | Most written natural languages are composed of sequences of words and sentences. Similar to humans, large language models (LLMs) exhibit flexibility in handling textual positions - a phenomenon we term Position Generalization. They can understand texts with position perturbations and generalize to... | Chi Han, Heng Ji |  |
| 2442 |  |  [IPO: Your Language Model is Secretly a Preference Classifier](https://aclanthology.org/2025.acl-long.954/) |  | 0 | Reinforcement learning from human feedback (RLHF) has emerged as the primary method for aligning large language models (LLMs) with human preferences. While it enables LLMs to achieve human-level alignment, it often incurs significant computational and financial costs due to its reliance on training... | Shivank Garg, Ayush Singh, Shweta Singh, Paras Chopra |  |
| 2443 |  |  [Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up](https://aclanthology.org/2025.acl-long.955/) |  | 0 | Large language models (LLMs) have shown remarkable performance in reasoning tasks but face limitations in mathematical and complex logical reasoning. Existing methods to improve LLMs’ logical capabilities either involve traceable or verifiable logical sequences that generate more reliable responses... | Jiahao Yuan, Dehui Du, Hao Zhang, Zixiang Di, Usman Naseem |  |
| 2444 |  |  [Déjà Vu? Decoding Repeated Reading from Eye Movements](https://aclanthology.org/2025.acl-long.956/) |  | 0 | Be it your favorite novel, a newswire article, a cooking recipe or an academic paper – in many daily situations we read the same text more than once. In this work, we ask whether it is possible to automatically determine whether the reader has previously encountered a text based on their eye... | Yoav Meiri, Omer Shubi, Cfir Avraham Hadar, Ariel Kreisberg Nitzav, Yevgeni Berzak |  |
| 2445 |  |  [LLMs can be easily Confused by Instructional Distractions](https://aclanthology.org/2025.acl-long.957/) |  | 0 | Despite the fact that large language models (LLMs) show exceptional skill in instruction following tasks, this strength can turn into a vulnerability when the models are required to disregard certain instructions. Instruction following tasks typically involve a clear task description and input text... | Yerin Hwang, Yongil Kim, Jahyun Koo, Taegwan Kang, Hyunkyung Bae, Kyomin Jung |  |
| 2446 |  |  [PlanGenLLMs: A Modern Survey of LLM Planning Capabilities](https://aclanthology.org/2025.acl-long.958/) |  | 0 | LLMs have immense potential for generating plans, transforming an initial world state into a desired goal state. A large body of research has explored the use of LLMs for various planning tasks, from web navigation to travel planning and database querying. However, many of these systems are... | Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, Shijia Pan, Fei Liu |  |
| 2447 |  |  [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://aclanthology.org/2025.acl-long.959/) |  | 0 | LLMs encounter significant challenges in resource consumption nowadays, especially with long contexts. Despite extensive efforts dedicate to enhancing inference efficiency, these methods primarily exploit internal sparsity within the models, without leveraging external information for optimization.... | Yi Zhao, Zuchao Li, Hai Zhao |  |
| 2448 |  |  [nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow](https://aclanthology.org/2025.acl-long.960/) |  | 0 | \*Natural Language to Visualization\* (NL2Vis) seeks to convert natural-language descriptions into visual representations of given tables, empowering users to derive insights from large-scale data. Recent advancements in \*Large Language Models\* (LLMs) show promise in automating code generation to... | Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen |  |
| 2449 |  |  [ZIPA: A family of efficient models for multilingual phone recognition](https://aclanthology.org/2025.acl-long.961/) |  | 0 | We present ZIPA, a family of efficient speech models that advances the state-of-the-art performance of crosslinguistic phone recognition. We first curated IPA PACK++, a large-scale multilingual speech corpus with 17,000+ hours of normalized phone transcriptions and a novel evaluation set capturing... | Jian Zhu, Farhan Samir, Eleanor Chodroff, David R. Mortensen |  |
| 2450 |  |  [GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration](https://aclanthology.org/2025.acl-long.962/) |  | 0 | Language models are often miscalibrated, leading to confidently incorrect answers. We introduce GRACE, a benchmark for language model calibration that incorporates comparison with human calibration. GRACE consists of question-answer pairs, in which each question contains a series of clues that... | Yoo Yeon Sung, Eve Fleisig, Yu Hou, Ishan Upadhyay, Jordan Lee BoydGraber |  |
| 2451 |  |  [Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models](https://aclanthology.org/2025.acl-long.963/) |  | 0 | The rapid advancement of Large Language Models (LLMs) poses significant challenges for safety evaluation. Current static datasets struggle to identify emerging vulnerabilities due to three limitations: (1) they risk being exposed in model training data, leading to evaluation bias; (2) their limited... | Lanxue Zhang, Yanan Cao, Yuqiang Xie, Fang Fang, Yangxi Li |  |
| 2452 |  |  [From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions](https://aclanthology.org/2025.acl-long.964/) |  | 0 | Large Language Models (LLMs) are increasingly used in working environments for a wide range of tasks, excelling at solving individual problems in isolation. However, are they also able to effectively collaborate over long-term interactions? To investigate this, we introduce MemoryCode, a synthetic... | Nathanaël Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Lucas Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici |  |
| 2453 |  |  [Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints](https://aclanthology.org/2025.acl-long.965/) |  | 0 | Jailbreaking attacks can effectively induce unsafe behaviors in Large Language Models (LLMs); however, the transferability of these attacks across different models remains limited. This study aims to understand and enhance the transferability of gradient-based jailbreaking methods, which are among... | Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang |  |
| 2454 |  |  [Multilingual Text-to-Image Generation Magnifies Gender Stereotypes](https://aclanthology.org/2025.acl-long.966/) |  | 0 | Text-to-image (T2I) generation models have achieved great results in image quality, flexibility, and text alignment, leading to widespread use. Through improvements in multilingual abilities, a larger community can access this technology. Yet, we show that multilingual models suffer from... | Felix Friedrich, Katharina Hämmerl, Patrick Schramowski, Manuel Brack, Jindrich Libovický, Alexander Fraser, Kristian Kersting |  |
| 2455 |  |  [Adversarial Alignment with Anchor Dragging Drift (A³D²): Multimodal Domain Adaptation with Partially Shifted Modalities](https://aclanthology.org/2025.acl-long.967/) |  | 0 | Multimodal learning has celebrated remarkable success across diverse areas, yet faces the challenge of prohibitively expensive data collection and annotation when adapting models to new environments. In this context, domain adaptation has gained growing popularity as a technique for knowledge... | Jun Sun, Xinxin Zhang, Simin Hong, Jian Zhu, Lingfang Zeng |  |
| 2456 |  |  [A Reality Check on Context Utilisation for Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.968/) |  | 0 | Retrieval-augmented generation (RAG) helps address the limitations of parametric knowledge embedded within a language model (LM). In real world settings, retrieved information can vary in complexity, yet most investigations of LM utilisation of context has been limited to synthetic text. We... | Lovisa Hagström, Sara Vera Marjanovic, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein |  |
| 2457 |  |  [CU-MAM: Coherence-Driven Unified Macro-Structures for Argument Mining](https://aclanthology.org/2025.acl-long.969/) |  | 0 | Argument Mining (AM) involves the automatic identification of argument structure in natural language. Traditional AM methods rely on micro-structural features derived from the internal properties of individual Argumentative Discourse Units (ADUs). However, argument structure is shaped by a... | Debela Gemechu, Chris Reed |  |
| 2458 |  |  [Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts](https://aclanthology.org/2025.acl-long.970/) |  | 0 | Large Language Models (LLMs) are increasingly employed as automated evaluators to assess the safety of generated content, yet their reliability in this role remains uncertain. This study evaluates a diverse set of 11 LLM judge models across critical safety domains, examining three key aspects:... | Hongyu Chen, Seraphina GoldfarbTarrant |  |
| 2459 |  |  [Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query](https://aclanthology.org/2025.acl-long.971/) |  | 0 | Elasticsearch (ES) is a distributed RESTful search engine optimized for large-scale and long-text search scenarios. Recent research on text-to-Query has explored using large language models (LLMs) to convert user query intent to executable code, making it an increasingly popular research topic. To... | Dongge Xue, Zhili Pu, Zhentao Xia, Hongli Sun, Ruihui Hou, Guangya Yu, Yupian Lin, Yongqi Fan, Jingping Liu, Tong Ruan |  |
| 2460 |  |  [AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation](https://aclanthology.org/2025.acl-long.972/) |  | 0 | In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the... | Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu |  |
| 2461 |  |  [DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal](https://aclanthology.org/2025.acl-long.973/) |  | 0 | Large Language Models (LLMs) have revolutionized various domains, including natural language processing, data analysis, and software development, by enabling automation. In software engineering, LLM-powered coding agents have garnered significant attention due to their potential to automate complex... | Vaibhav Aggarwal, Ojasv Kamal, Abhinav Japesh, Zhijing Jin, Bernhard Schölkopf |  |
| 2462 |  |  [Steering off Course: Reliability Challenges in Steering Language Models](https://aclanthology.org/2025.acl-long.974/) |  | 0 | Steering methods for language models (LMs) have gained traction as lightweight alternatives to fine-tuning, enabling targeted modifications to model activations. However, prior studies primarily report results on a few models, leaving critical gaps in understanding the robustness of these methods.... | Patrick Queiroz Da Silva, Hari Sethuraman, Dheeraj Rajagopal, Hannaneh Hajishirzi, Sachin Kumar |  |
| 2463 |  |  [Impartial Multi-task Representation Learning via Variance-invariant Probabilistic Decoding](https://aclanthology.org/2025.acl-long.975/) |  | 0 | Multi-task learning (MTL) enhances efficiency by sharing representations across tasks, but task dissimilarities often cause partial learning, where some tasks dominate while others are neglected. Existing methods mainly focus on balancing loss or gradients but fail to fundamentally address this... | Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu |  |
| 2464 |  |  [If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World](https://aclanthology.org/2025.acl-long.976/) |  | 0 | \*\*Warning: this paper discusses content related, but not limited to, violence, sex, and suicide.\*\*Loneliness, or the lack of fulfilling relationships, significantly impacts a person’s mental and physical well-being and is prevalent worldwide. Previous research suggests that large language... | Adrian de Wynter |  |
| 2465 |  |  [Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization on Multi-party Conversation](https://aclanthology.org/2025.acl-long.977/) |  | 0 | Speaker diarization aims to segment an audio stream into homogeneous partitions based on speaker identity, playing a crucial role in speech comprehension and analysis. Mainstream speaker diarization systems rely only on acoustic information, making the task particularly challenging in complex... | Luyao Cheng, Hui Wang, Chong Deng, Siqi Zheng, Yafeng Chen, Rongjie Huang, Qinglin Zhang, Qian Chen, Xihao Li, Wen Wang |  |
| 2466 |  |  [Vulnerability of LLMs to Vertically Aligned Text Manipulations](https://aclanthology.org/2025.acl-long.978/) |  | 0 | Vertical text input is commonly encountered in various real-world applications, such as mathematical computations and word-based Sudoku puzzles. While current large language models (LLMs) have excelled in natural language tasks, they remain vulnerable to variations in text formatting.Recent... | Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Zhen Xiong, Nanyun Peng, KaiWei Chang |  |
| 2467 |  |  [AutoMixer: Checkpoint Artifacts as Automatic Data Mixers](https://aclanthology.org/2025.acl-long.979/) |  | 0 | In language model training, it is desirable to equip models with capabilities from various tasks. However, it is not clear how to directly obtain the right data mixtures for these capabilities as the relationship between data and tasks is difficult to be modeled. In this work, we observe that... | Ernie Chang, Yang Li, Patrick Huber, Vish Vogeti, David Kant, Yangyang Shi, Vikas Chandra |  |
| 2468 |  |  [Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow](https://aclanthology.org/2025.acl-long.980/) |  | 0 | This paper introduces Generalized Attention Flow (GAF), a novel feature attribution method for Transformer-based models to address the limitations of current approaches. By extending Attention Flow and replacing attention weights with the generalized Information Tensor, GAF integrates attention... | Behrooz Azarkhalili, Maxwell W. Libbrecht |  |
| 2469 |  |  [Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering](https://aclanthology.org/2025.acl-long.981/) |  | 0 | Large language models (LLMs) have recently pushed open-domain question answering (ODQA) to new frontiers. However, prevailing retriever–reader pipelines often depend on multiple rounds of prompt-level instructions, leading to high computational overhead, instability, and suboptimal retrieval... | Zhanghao Hu, Hanqi Yan, Qinglin Zhu, Zhenyi Shen, Yulan He, Lin Gui |  |
| 2470 |  |  [AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark](https://aclanthology.org/2025.acl-long.982/) |  | 0 | Evaluation plays a crucial role in the advancement of information retrieval (IR) models. However, current benchmarks, which are based on predefined domains and human-labeled data, face limitations in addressing evaluation needs for emerging domains both cost-effectively and efficiently. To address... | Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu |  |
| 2471 |  |  [We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?](https://aclanthology.org/2025.acl-long.983/) |  | 0 | Visual mathematical reasoning, as a fundamental visual reasoning ability, has received widespread attention from the Large Multimodal Models (LMMs) community. Existing benchmarks mainly focus more on the end-to-end performance, but neglect the underlying principles of knowledge acquisition and... | Runqi Qiao, Qiuna Tan, Guanting Dong, Minhui Wu, Chong Sun, Xiaoshuai Song, Jiapeng Wang, Zhuoma Gongque, Shanglin Lei, Yifan Zhang, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Xiao Zong, Yida Xu, Peiqing Yang, Zhimin Bao, Muxi Diao, Chen Li, Honggang Zhang |  |
| 2472 |  |  [Modeling the Evolution of English Noun Compounds with Feature-Rich Diachronic Compositionality Prediction](https://aclanthology.org/2025.acl-long.984/) |  | 0 | We analyze the evolution of English noun compounds, which we represent as vectors of time-specific values. We implement a wide array of methods to create a rich set of features, using them to classify compounds for present-day compositionality and to assess the informativeness of the corresponding... | Filip Miletic, Sabine Schulte im Walde |  |
| 2473 |  |  [What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns](https://aclanthology.org/2025.acl-long.985/) |  | 0 | Prompt engineering for large language models is challenging, as even small prompt perturbations or model changes can significantly impact the generated output texts. Existing evaluation methods of LLM outputs, either automated metrics or human evaluation, have limitations, such as providing limited... | Michael A. Hedderich, Anyi Wang, Raoyuan Zhao, Florian Eichin, Jonas Fischer, Barbara Plank |  |
| 2474 |  |  [V-Oracle: Making Progressive Reasoning in Deciphering Oracle Bones for You and Me](https://aclanthology.org/2025.acl-long.986/) |  | 0 | Oracle Bone Script (OBS) is a vital treasure of human civilization, rich in insights from ancient societies. However, the evolution of written language over millennia complicates its decipherment. In this paper, we propose V-Oracle, an innovative framework that utilizes Large Multi-modal Models... | Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu MinhuiWu, Jiapeng Wang, Yifan Zhang, Zhuoma Gongque, Chong Sun, Yida Xu, Yadong Xue, Ye Tian, Zhimin Bao, Lan Yang, Chen Li, Honggang Zhang |  |
| 2475 |  |  [Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension](https://aclanthology.org/2025.acl-long.987/) |  | 0 | Despite the impressive performance of multilingual large language models (mLLMs) in various natural language processing tasks, their ability to understand procedural texts, particularly those with culture-specific content, remains largely unexplored. Texts describing cultural procedures, including... | Amir Hossein Yari, Fajri Koto |  |
| 2476 |  |  [Improving Language and Modality Transfer in Translation by Character-level Modeling](https://aclanthology.org/2025.acl-long.988/) |  | 0 | Current translation systems, despite being highly multilingual, cover only 5% of the world’s languages. Expanding language coverage to the long-tail of low-resource languages requires data-efficient methods that rely on cross-lingual and cross-modal knowledge transfer. To this end, we propose a... | Ioannis Tsiamas, David Dale, Marta R. Costajussà |  |
| 2477 |  |  [DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models](https://aclanthology.org/2025.acl-long.989/) |  | 0 | Most of the world’s languages and dialects are low-resource, and lack support in mainstream machine translation (MT) models. However, many of them have a closely-related high-resource language (HRL) neighbor, and differ in linguistically regular ways from it. This underscores the importance of... | Niyati Bafna, Emily Chang, Nathaniel Romney Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin |  |
| 2478 |  |  [AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs](https://aclanthology.org/2025.acl-long.990/) |  | 0 | When aligning large language models (LLMs), their performance across various tasks (such as being helpful, harmless, and honest) is heavily influenced by the composition of the training data. However, it is difficult to determine what mixture of data should be used to produce a model with strong... | Nicholas E. Corrado, Julian KatzSamuels, Adithya M. Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi |  |
| 2479 |  |  [Modeling Complex Semantics Relation with Contrastively Fine-Tuned Relational Encoders](https://aclanthology.org/2025.acl-long.991/) |  | 0 | Modeling relationships between concepts and entities is essential for many applications. While Large Language Models (LLMs) capture relational and commonsense knowledge effectively, they are computationally expensive and often underperform in tasks requiring efficient relational encoding, such as... | Naïm EsSebbani, Esteban Marquer, Zied Bouraoui |  |
| 2480 |  |  [Error-driven Data-efficient Large Multimodal Model Tuning](https://aclanthology.org/2025.acl-long.992/) |  | 0 | Large Multimodal Models (LMMs) have demonstrated impressive performance across numerous academic benchmarks. However, fine-tuning still remains essential to achieve satisfactory performance on downstream tasks, while the task-specific tuning samples are usually not readily available or expensive... | Barry Menglong Yao, Qifan Wang, Lifu Huang |  |
| 2481 |  |  [Planning with Diffusion Models for Target-Oriented Dialogue Systems](https://aclanthology.org/2025.acl-long.993/) |  | 0 | Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM era, where strategic dialogue planning is crucial for directing conversations toward specific targets. However, existing dialogue planning methods generate dialogue plans in a step-by-step sequential manner, and may suffer... | Hanwen Du, Bo Peng, Xia Ning |  |
| 2482 |  |  [Interactive and Expressive Code-Augmented Planning with Large Language Models](https://aclanthology.org/2025.acl-long.994/) |  | 0 | Large Language Models (LLMs) demonstrate strong abilities in common-sense reasoning and interactive decision-making, but often struggle with complex, long-horizon planning tasks. Recent techniques have sought to structure LLM outputs using control flow and code to improve planning performance.... | Anthony Zhe Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee |  |
| 2483 |  |  [Synergistic Weak-Strong Collaboration by Aligning Preferences](https://aclanthology.org/2025.acl-long.995/) |  | 0 | Current Large Language Models excel in general reasoning yet struggle with specialized tasks requiring proprietary or domain-specific knowledge. Fine-tuning large models for every niche application is often infeasible due to black-box constraints and high computational overhead. To address this, we... | Yizhu Jiao, Xuchao Zhang, Zhaoyang Wang, Yubo Ma, Zhun Deng, Rujia Wang, Chetan Bansal, Saravan Rajmohan, Jiawei Han, Huaxiu Yao |  |
| 2484 |  |  [Understanding Silent Data Corruption in LLM Training](https://aclanthology.org/2025.acl-long.996/) |  | 0 | As the scale of training large language models (LLMs) increases, one emergent failure is silent data corruption (SDC), where hardware produces incorrect computations without explicit failure signals. In this work, we are the first to investigate the impact of real-world SDCs on LLM training by... | Jeffrey Jian Ma, Hengzhi Pei, Leonard Lausen, George Karypis |  |
| 2485 |  |  [Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback](https://aclanthology.org/2025.acl-long.997/) |  | 0 | While textless Spoken Language Models (SLMs) have shown potential in end-to-end speech-to-speech modeling, they still lag behind text-based Large Language Models (LLMs) in terms of semantic coherence and relevance. This work introduces the Align-SLM framework, which leverages preference... | GuanTing Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hungyi Lee, Ivan Bulyko |  |
| 2486 |  |  [Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs](https://aclanthology.org/2025.acl-long.998/) |  | 0 | The surge of LLM studies makes synthesizing their findings challenging. Analysis of experimental results from literature can uncover important trends across studies, but the time-consuming nature of manual data extraction limits its use.Our study presents a semi-automated approach for literature... | Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter |  |
| 2487 |  |  [BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data](https://aclanthology.org/2025.acl-long.999/) |  | 0 | In this work, we tackle the challenge of embedding realistic human personality traits into LLMs. Previous approaches have primarily focused on prompt-based methods that describe the behavior associated with the desired personality traits, suffering from realism and validity issues. To address these... | Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona T. Diab, Maarten Sap |  |
| 2488 |  |  [Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times](https://aclanthology.org/2025.acl-long.1000/) |  | 0 | Human perception of events is intrinsically tied to distinguishing between completed (perfect and telic) and ongoing (durative) actions, a process mediated by both linguistic structure and visual cues. In this work, we introduce the Perfect Times dataset, a novel, quadrilingual (English, Italian,... | Olga Loginova, Sofía Ortega Loguinova |  |
| 2489 |  |  [Amplifying Trans and Nonbinary Voices: A Community-Centred Harm Taxonomy for LLMs](https://aclanthology.org/2025.acl-long.1001/) |  | 0 | We explore large language model (LLM) responses that may negatively impact the transgender and nonbinary (TGNB) community and introduce the Transing Transformers Toolkit, T3, which provides resources for identifying such harmful response behaviors. The heart of T3 is a community-centred taxonomy of... | Eddie L. Ungless, Sunipa Dev, Cynthia L. Bennett, Rebecca Gulotta, Jasmijn Bastings, Remi Denton |  |
| 2490 |  |  [Enhancing Human Evaluation in Machine Translation with Comparative Judgement](https://aclanthology.org/2025.acl-long.1002/) |  | 0 | Human evaluation is crucial for assessing rapidly evolving language models but is influenced by annotator proficiency and task design. This study explores the integration of comparative judgment into human annotation for machine translation (MT) and evaluates three annotation setups—point-wise... | Yixiao Song, Parker Riley, Daniel Deutsch, Markus Freitag |  |
| 2491 |  |  [Infogen: Generating Complex Statistical Infographics from Documents](https://aclanthology.org/2025.acl-long.1003/) |  | 0 | Statistical infographics are powerful tools that simplify complex data into visually engaging and easy-to-understand formats. Despite advancements in AI, particularly with LLMs, existing efforts have been limited to generating simple charts, with no prior work addressing the creation of complex... | Akash Ghosh, Aparna Garimella, Pritika Ramu, Sambaran Bandyopadhyay, Sriparna Saha |  |
| 2492 |  |  [Partial Colexifications Improve Concept Embeddings](https://aclanthology.org/2025.acl-long.1004/) |  | 0 | While the embedding of words has revolutionized the field of Natural Language Processing, the embedding of concepts has received much less attention so far. A dense and meaningful representation of concepts, however, could prove useful for several tasks in computational linguistics, especially... | Arne Rubehn, JohannMattis List |  |
| 2493 |  |  [Improved Unbiased Watermark for Large Language Models](https://aclanthology.org/2025.acl-long.1005/) |  | 0 | As artificial intelligence surpasses human capabilities in text generation, the necessity to authenticate the origins of AI-generated content has become paramount. Unbiased watermarks offer a powerful solution by embedding statistical signals into language model-generated text without distorting... | Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang |  |
| 2494 |  |  [MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection](https://aclanthology.org/2025.acl-long.1006/) |  | 0 | We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine Projection, that achieves exceptional performance while requiring minimal parameters and memory for fine-tuning large foundation models.Its general idea is to exploit the superior energy compaction and decorrelation... | Yixian Shen, Qi Bi, JiaHong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania |  |
| 2495 |  |  [Multi-Attribute Steering of Language Models via Targeted Intervention](https://aclanthology.org/2025.acl-long.1007/) |  | 0 | Inference-time intervention (ITI) has emerged as a promising method for steering large language model (LLM) behavior in a particular direction (e.g., improving helpfulness) by intervening on token representations without costly updates to the LLM’s parameters. However, existing ITI approaches fail... | Duy Nguyen, Archiki Prasad, Elias StengelEskin, Mohit Bansal |  |
| 2496 |  |  [AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations](https://aclanthology.org/2025.acl-long.1008/) |  | 0 | State-of-the-art multimodal web agents, powered by Multimodal Large Language Models (MLLMs), can autonomously execute many web tasks by processing user instructions and interacting with graphical user interfaces (GUIs). Current strategies for building web agents rely on (i) the generalizability of... | Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso |  |
| 2497 |  |  [Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers](https://aclanthology.org/2025.acl-long.1009/) |  | 0 | Peer review is fundamental to scientific research, but the growing volume of publications has intensified the challenges of this expertise-intensive process. While LLMs show promise in various scientific tasks, their potential to assist with peer review, particularly in identifying paper... | Zhijian Xu, Yilun Zhao, Manasi Patwardhan, Lovekesh Vig, Arman Cohan |  |
| 2498 |  |  [On the Acquisition of Shared Grammatical Representations in Bilingual Language Models](https://aclanthology.org/2025.acl-long.1010/) |  | 0 | Crosslingual transfer is crucial to contemporary language models’ multilingual capabilities, but how it occurs is not well understood. Weask what happens to a monolingual language model when it begins to be trained on a second language. Specifically, we train small bilingual models for which we... | Catherine Arnett, Tyler A. Chang, James A. Michaelov, Ben Bergen |  |
| 2499 |  |  [Using Shapley interactions to understand how models use structure](https://aclanthology.org/2025.acl-long.1011/) |  | 0 | Language is an intricately structured system, and a key goal of NLP interpretability is to provide methodological insights for understanding how language models internally represent this structure. In this paper, we use Shapley Taylor interaction indices (STII) in order to examine how language and... | Divyansh Singhvi, Diganta Misra, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra |  |
| 2500 |  |  [Adversarial Tokenization](https://aclanthology.org/2025.acl-long.1012/) |  | 0 | Current LLM pipelines account for only one possible tokenization for a given string, ignoring exponentially many alternative tokenizations during training and inference. For example, the Llama3 standard tokenization of penguin is [p,enguin], yet [peng,uin] is another perfectly valid alternative. In... | Renato Lui Geh, Zilei Shao, Guy Van den Broeck |  |
| 2501 |  |  [Classifying Unreliable Narrators with Large Language Models](https://aclanthology.org/2025.acl-long.1013/) |  | 0 | Often when we interact with a first-person account of events, we consider whether or not the narrator, the primary speaker of the text, is reliable. In this paper, we propose using computational methods to identify unreliable narrators, i.e. those who unintentionally misrepresent information.... | Anneliese Brei, Katharine Henry, Abhisheik Sharma, Shashank Srivastava, Snigdha Chaturvedi |  |
| 2502 |  |  [ConceptCarve: Dynamic Realization of Evidence](https://aclanthology.org/2025.acl-long.1014/) |  | 0 | Finding evidence for human opinion and behavior at scale is a challenging task, often requiring an understanding of sophisticated thought patterns among vast online communities found on social media. For example, studying how ‘gun ownership’ is related to the perception of ‘Freedom’, requires a... | Eylon Caplan, Dan Goldwasser |  |
| 2503 |  |  [QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering](https://aclanthology.org/2025.acl-long.1015/) |  | 0 | Review-based Product Question Answering (PQA) allows e-commerce platforms to automatically address customer queries by leveraging insights from user reviews. However, existing PQA systems generate answers with only a single perspective, failing to capture the diversity of customer opinions. In this... | An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Zhuang Li |  |
| 2504 |  |  [Navigating Rifts in Human-LLM Grounding: Study and Benchmark](https://aclanthology.org/2025.acl-long.1016/) |  | 0 | Language models excel at following instructions but often struggle with the collaborative aspects of conversation that humans naturally employ. This limitation in grounding—the process by which conversation participants establish mutual understanding—can lead to outcomes ranging from frustrated... | Omar Shaikh, Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz |  |
| 2505 |  |  [Substance over Style: Evaluating Proactive Conversational Coaching Agents](https://aclanthology.org/2025.acl-long.1017/) |  | 0 | While NLP research has made strides in conversational tasks, many approaches focus on single-turn responses with well-defined objectives or evaluation criteria. In contrast, coaching presents unique challenges with initially undefined goals that evolve through multi-turn interactions, subjective... | Vidya Srinivas, Xuhai Xu, Xin Liu, Kumar Ayush, Isaac R. GalatzerLevy, Shwetak N. Patel, Daniel McDuff, Tim Althoff |  |
| 2506 |  |  [Open-World Planning via Lifted Regression with LLM-Inferred Affordances for Embodied Agents](https://aclanthology.org/2025.acl-long.1018/) |  | 0 | Open-world planning with incomplete knowledge is crucial for real-world embodied AI tasks. Despite that, existing LLM-based planners struggle with long chains of sequential reasoning, while symbolic planners face combinatorial explosion of states and actions for complex domains due to reliance on... | Xiaotian Liu, Ali Pesaranghader, Hanze Li, Punyaphat Sukcharoenchaikul, Jaehong Kim, Tanmana Sadhu, Hyejeong Jeon, Scott Sanner |  |
| 2507 |  |  [(RSA)²: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding](https://aclanthology.org/2025.acl-long.1019/) |  | 0 | Figurative language (e.g., irony, hyperbole, understatement) is ubiquitous in human communication, resulting in utterances where the literal and the intended meanings do not match. The Rational Speech Act (RSA) framework, which explicitly models speaker intentions, is the most widespread theory of... | Cesare Spinoso Di Piano, David Eric Austin, Pablo Piantanida, Jackie CK Cheung |  |
| 2508 |  |  [SYNTHIA: Novel Concept Design with Affordance Composition](https://aclanthology.org/2025.acl-long.1020/) |  | 0 | Text-to-image (T2I) models enable rapid concept design, making them widely used in AI-driven design. While recent studies focus on generating semantic and stylistic variations of given design concepts, –the integration of multiple affordances into a single coherent concept–remains largely... | Hyeonjeong Ha, Xiaomeng Jin, Jeonghwan Kim, Jiateng Liu, Zhenhailong Wang, Khanh Duy Nguyen, Ansel Blume, Nanyun Peng, KaiWei Chang, Heng Ji |  |
| 2509 |  |  [Consistent Client Simulation for Motivational Interviewing-based Counseling](https://aclanthology.org/2025.acl-long.1021/) |  | 0 | Simulating human clients in mental health counseling is crucial for training and evaluating counselors (both human or simulated) in a scalable manner. Nevertheless, past research on client simulation did not focus on complex conversation tasks such as mental health counseling. In these tasks, the... | Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Phey Ling Kit, Jenny Giam Xiuhui, John Pinto, EePeng Lim |  |
| 2510 |  |  [AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context](https://aclanthology.org/2025.acl-long.1022/) |  | 0 | As our awareness of autism and ableism continues to increase, so does our understanding of ableist language towards autistic people. Such language poses a significant challenge in NLP research due to its subtle and context-dependent nature. Yet, detecting anti-autistic ableist language remains... | Naba Rizvi, Harper Strickland, Daniel Gitelman, Alexis Morales Flores, Tristan Cooper, Aekta Kallepalli, Akshat Alurkar, Haaset Owens, Saleha Ahmedi, Isha Khirwadkar, Imani N. S. Munyaka, Nedjma Ousidhoum |  |
| 2511 |  |  [Structural Reasoning Improves Molecular Understanding of LLM](https://aclanthology.org/2025.acl-long.1023/) |  | 0 | Recently, large language models (LLMs) have shown significant progress, approaching human perception levels. In this work, we demonstrate that despite these advances, LLMs still struggle to reason using molecular structural information. This gap is critical because many molecular properties,... | Yunhui Jang, Jaehyung Kim, Sungsoo Ahn |  |
| 2512 |  |  [CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration](https://aclanthology.org/2025.acl-long.1024/) |  | 0 | Conversational counselor agents have become essential tools for addressing the rising demand for scalable and accessible mental health support. This paper introduces CAMI, a novel automated counselor agent grounded in Motivational Interviewing (MI) – a client-centered counseling approach designed... | Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Phey Ling Kit, Nicholas Gabriel Lim, Cameron Tan Shi Ern, EePeng Lim |  |
| 2513 |  |  [Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles](https://aclanthology.org/2025.acl-long.1025/) |  | 0 | User simulators are crucial for replicating human interactions with dialogue systems, supporting both collaborative training and automatic evaluation, especially for large language models (LLMs). However, current role-playing methods face challenges such as a lack of utterance-level authenticity... | Kuang Wang, Xianfei Li, Shenghao Yang, Li Zhou, Feng Jiang, Haizhou Li |  |
| 2514 |  |  [Targeted Syntactic Evaluation for Grammatical Error Correction](https://aclanthology.org/2025.acl-long.1026/) |  | 0 | Language learners encounter a wide range of grammar items across the beginner, intermediate, and advanced levels.To develop grammatical error correction (GEC) models effectively, it is crucial to identify which grammar items are easier or more challenging for models to correct. However,... | Aomi Koyama, Masato Mita, SuYoun Yoon, Yasufumi Takama, Mamoru Komachi |  |
| 2515 |  |  [VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos](https://aclanthology.org/2025.acl-long.1027/) |  | 0 | Recently, multimodal large language models (MLLMs) have been extensively explored in video question answering. However, most existing assessments focus on natural videos, overlooking synthetic videos (e.g., AI-generated content). Meanwhile, some works in video generation rely on MLLMs to evaluate... | Tingyu Song, Tongyan Hu, Guo Gan, Yilun Zhao |  |
| 2516 |  |  [Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions](https://aclanthology.org/2025.acl-long.1028/) |  | 0 | Large language models (LLMs) present novel opportunities in public opinion research by predicting survey responses in advance during the early stages of survey design. Prior methods steer LLMs via descriptions of subpopulations as LLMs’ input prompt, yet such prompt engineering approaches have... | Joseph Suh, Erfan Jahanparast, Suhong Moon, Minwoo Kang, Serina Chang |  |
| 2517 |  |  [TESS 2: A Large-Scale Generalist Diffusion Language Model](https://aclanthology.org/2025.acl-long.1029/) |  | 0 | We introduce TESS 2, a general instruction-following diffusion language model that outperforms contemporary instruction-tuned diffusion models, as well as matches and sometimes exceeds strong autoregressive (AR) models. We train TESS 2 by first adapting a strong AR model via continued pretraining... | Jaesung Tae, Hamish Ivison, Sachin Kumar, Arman Cohan |  |
| 2518 |  |  [KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis](https://aclanthology.org/2025.acl-long.1030/) |  | 0 | The rapid advancement of large language models (LLMs) increases the difficulty of distinguishing between human-written and LLM-generated text. Detecting LLM-generated text is crucial for upholding academic integrity, preventing plagiarism, protecting copyrights, and ensuring ethical research... | Shinwoo Park, Shubin Kim, DoKyung Kim, YoSub Han |  |
| 2519 |  |  [Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL](https://aclanthology.org/2025.acl-long.1031/) |  | 0 | Direct Preference Optimization (DPO) has proven effective in complex reasoning tasks like math word problems and code generation. However, when applied to Text-to-SQL datasets, it often fails to improve performance and can even degrade it. Our investigation reveals the root cause: unlike math and... | Hanbing Liu, Haoyang Li, Xiaokang Zhang, Ruotong Chen, Haiyong Xu, Tian Tian, Qi Qi, Jing Zhang |  |
| 2520 |  |  [On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures](https://aclanthology.org/2025.acl-long.1032/) |  | 0 | Measurement systems (e.g., currencies) differ across cultures, but the conversions between them are well defined so that humans can state using any measurement system of their choice. Being available to users from diverse cultural backgrounds, Large Language Models (LLMs) should also be able to... | Minh Duc Bui, Kyung Eun Park, Goran Glavas, Fabian David Schmidt, Katharina von der Wense |  |
| 2521 |  |  [CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?](https://aclanthology.org/2025.acl-long.1033/) |  | 0 | Multimodal Large Language Models (MLLMs) are renowned for their superior instruction-following and reasoning capabilities across diverse problem domains. However, existing benchmarks primarily focus on assessing factual and logical correctness in downstream tasks, with limited emphasis on... | Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee |  |
| 2522 |  |  [Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning](https://aclanthology.org/2025.acl-long.1034/) |  | 0 | Despite LLMs’ explicit alignment against demographic stereotypes, they have been shown to exhibit biases under various social contexts. In this work, we find that LLMs exhibit concerning biases in how they associate solution veracity with demographics. Through experiments across five human... | Yue Zhou, Barbara Di Eugenio |  |
| 2523 |  |  [Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization](https://aclanthology.org/2025.acl-long.1035/) |  | 0 | Direct Preference Optimization (DPO) has emerged as a promising framework for aligning Large Language Models (LLMs) with human preferences by directly optimizing the log-likelihood difference between chosen and rejected responses. However, existing methods assign equal importance to all tokens in... | Meng Li, Guangda Huzhang, Haibo Zhang, Xiting Wang, Anxiang Zeng |  |
| 2524 |  |  [LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study](https://aclanthology.org/2025.acl-long.1036/) |  | 0 | The remarkable reasoning and generalization capabilities of Large Language Models (LLMs) have paved the way for their expanding applications in embodied AI, robotics, and other real-world tasks. To effectively support these applications, grounding in spatial and temporal understanding in multimodal... | Dongil Yang, Minjin Kim, Sunghwan Kim, Beongwoo Kwak, Minjun Park, Jinseok Hong, Woontack Woo, Jinyoung Yeo |  |
| 2525 |  |  [Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems](https://aclanthology.org/2025.acl-long.1037/) |  | 0 | Multi-agent collaboration has emerged as a pivotal paradigm for addressing complex, distributed tasks in large language model (LLM)-driven applications. While prior research has focused on high-level architectural frameworks, the granular mechanisms governing agents—critical to performance and... | Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu |  |
| 2526 |  |  [The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation](https://aclanthology.org/2025.acl-long.1038/) |  | 0 | Large Language Models (LLMs) have emerged as the new recommendation engines, surpassing traditional methods in both capability and scope, particularly in code generation. In this paper, we reveal a novel \*\*provider bias\*\* in LLMs: without explicit directives, these models show systematic... | Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu |  |
| 2527 |  |  [K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean](https://aclanthology.org/2025.acl-long.1039/) |  | 0 | Language detoxification involves removing toxicity from offensive language. While a neutral-toxic paired dataset provides a straightforward approach for training detoxification models, creating such datasets presents several challenges: i) the need for human annotation to build paired data, and ii)... | Minkyeong Jeon, Hyemin Jeong, Yerang Kim, Jiyoung Kim, Jae Hyeon Cho, ByungJun Lee |  |
| 2528 |  |  [THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation](https://aclanthology.org/2025.acl-long.1040/) |  | 0 | The sparse Mixture-of-Experts (MoE) has achieved significant progress for neural machine translation (NMT). However, there exist two limitations in current MoE solutions which may lead to sub-optimal performance: 1) they directly use the task knowledge of NMT into MoE (e.g.,... | Yunlong Liang, Fandong Meng, Jie Zhou |  |
| 2529 |  |  [Neuron Empirical Gradient: Discovering and Quantifying Neurons' Global Linear Controllability](https://aclanthology.org/2025.acl-long.1041/) |  | 0 | While feed-forward neurons in pre-trained language models (PLMs) can encode knowledge, past research targeted a small subset of neurons that heavily influence outputs.This leaves the broader role of neuron activations unclear, limiting progress in areas like knowledge editing.We uncover a global... | Xin Zhao, Zehui Jiang, Naoki Yoshinaga |  |
| 2530 |  |  [Can Third Parties Read Our Emotions?](https://aclanthology.org/2025.acl-long.1042/) |  | 0 | Natural Language Processing tasks that aim to infer an author’s private states, e.g., emotions and opinions, from their written text, typically rely on datasets annotated by third-party annotators. However, the assumption that third-party annotators can accurately capture authors’ private states... | Jiayi Li, Yingfan Zhou, Pranav Narayanan Venkit, Halima Binte Islam, Sneha Arya, Shomir Wilson, Sarah Rajtmajer |  |
| 2531 |  |  [OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching](https://aclanthology.org/2025.acl-long.1043/) |  | 0 | Text-to-speech (TTS) systems have seen significant advancements in recent years, driven by improvements in deep learning and neural network architectures. Viewing the output speech as a data distribution, previous approaches often employ traditional speech representations, such as waveforms or... | NghiaHuynh NguyenHieu, Ngoc Son Nguyen, Huynh Nguyen Dang, Thieu Vo, TruongSon Hy, Van Nguyen |  |
| 2532 |  |  [World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning](https://aclanthology.org/2025.acl-long.1044/) |  | 0 | Recent advances in large vision-language models (LVLMs) have shown promise for embodied task planning, yet they struggle with fundamental challenges like dependency constraints and efficiency. Existing approaches either solely optimize action selection or directly leverage pre-trained models as... | Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu |  |
| 2533 |  |  [JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs](https://aclanthology.org/2025.acl-long.1045/) |  | 0 | Jailbreak attacks aim to bypass the LLMs’ safeguards. While researchers have proposed different jailbreak attacks in depth, they have done so in isolation—either with unaligned settings or comparing a limited range of methods. To fill this gap, we present a large-scale evaluation of various... | Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang |  |
| 2534 |  |  [CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models](https://aclanthology.org/2025.acl-long.1046/) |  | 0 | Faithfulness hallucinations are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standards, existing benchmarks focus on “factual statements” that rephrase source materials while overlooking “cognitive statements” that involve making... | Xiaqiang Tang, Jian Li, Keyu Hu, Nan Du, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie |  |
| 2535 |  |  [Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models](https://aclanthology.org/2025.acl-long.1047/) |  | 0 | Large Language Models (LLMs) offer a transparent brain with accessible parameters that encode extensive knowledge, which can be analyzed, located and transferred. Consequently, a key research challenge is to transcend traditional knowledge transfer paradigms rooted in symbolic language and achieve... | Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao |  |
| 2536 |  |  [Enhancing Mathematical Reasoning in LLMs by Stepwise Correction](https://aclanthology.org/2025.acl-long.1048/) |  | 0 | Best-of-N decoding methods instruct large language models (LLMs) to generate multiple solutions, score each using a scoring function, and select the highest scored as the final answer to mathematical reasoning problems. However, this repeated independent process often leads to the same mistakes,... | Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang |  |
| 2537 |  |  [PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support](https://aclanthology.org/2025.acl-long.1049/) |  | 0 | Dialogue systems for mental health counseling aim to alleviate client distress and assist individuals in navigating personal challenges. Developing effective conversational agents for psychotherapy requires access to high-quality, real-world, long-term client-counselor interaction data, which is... | Huachuan Qiu, Zhenzhong Lan |  |
| 2538 |  |  [Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction](https://aclanthology.org/2025.acl-long.1050/) |  | 0 | Goal-oriented proactive dialogue systems are designed to guide user conversations seamlessly towards specific objectives by planning a goal-oriented path. However, previous research has focused predominantly on optimizing these paths while neglecting the inconsistencies that may arise between... | Didi Zhang, Yaxin Fan, Peifeng Li, Qiaoming Zhu |  |
| 2539 |  |  [Exclusion of Thought: Mitigating Cognitive Load in Large Language Models for Enhanced Reasoning in Multiple-Choice Tasks](https://aclanthology.org/2025.acl-long.1051/) |  | 0 | Multiple-choice questions (MCQs) are a widely used and vital assessment format for evaluating large language models (LLMs). This study reveals that LLMs are susceptible to “cognitive load” caused by distractor options in MCQs, leading to excessive attention to distractors and consequent vacillation... | Qihang Fu, Yongbin Qin, Ruizhang Huang, Yanping Chen, Yulin Zhou, Lintao Long |  |
| 2540 |  |  [Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation](https://aclanthology.org/2025.acl-long.1052/) |  | 0 | The multilingual neural machine translation (MNMT) aims for arbitrary translations across multiple languages.Although MNMT-specific models trained on parallel data offer low costs in training and deployment, their performance consistently lags behind that of large language models (LLMs).In this... | Zhi Qu, Yiran Wang, Jiannan Mao, Chenchen Ding, Hideki Tanaka, Masao Utiyama, Taro Watanabe |  |
| 2541 |  |  [VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search](https://aclanthology.org/2025.acl-long.1053/) |  | 0 | Recent advancements in Large Vision-Language Models have showcased remarkable capabilities. However, they often falter when confronted with complex reasoning tasks that humans typically address through visual aids and deliberate, step-by-step thinking. While existing methods have explored... | Yikun Wang, Siyin Wang, Qinyuan Cheng, Zhaoye Fei, Liang Ding, Qipeng Guo, Dacheng Tao, Xipeng Qiu |  |
| 2542 |  |  [Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models](https://aclanthology.org/2025.acl-long.1054/) |  | 0 | Designing complex computer-aided design (CAD) models is often time-consuming due to challenges such as computational inefficiency and the difficulty of generating precise models. We propose a novel language-guided framework for industrial design automation to address these issues, integrating large... | Jianxing Liao, Junyan Xu, Yatao Sun, Maowen Tang, Sicheng He, Jingxian Liao, Shui Yu, Yun Li, Xiaohong Guan |  |
| 2543 |  |  [LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint](https://aclanthology.org/2025.acl-long.1055/) |  | 0 | Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks incurs substantial computational and data costs. While model merging offers a training-free solution to integrate multiple task-specific models, existing methods suffer from safety-utility conflicts where enhanced general... | Qianli Ma, Dongrui Liu, Qian Chen, Linfeng Zhang, Jing Shao |  |
| 2544 |  |  [Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback](https://aclanthology.org/2025.acl-long.1056/) |  | 0 | The scientific research paradigm is undergoing a profound transformation owing to the development of Artificial Intelligence (AI). Recent works demonstrate that various AI-assisted research methods can largely improve research efficiency by improving data analysis, accelerating computation, and... | Jiakang Yuan, Xiangchao Yan, Bo Zhang, Tao Chen, Botian Shi, Wanli Ouyang, Yu Qiao, Lei Bai, Bowen Zhou |  |
| 2545 |  |  [PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization](https://aclanthology.org/2025.acl-long.1057/) |  | 0 | As online platforms and recommendation algorithms evolve, people are increasingly trapped in echo chambers, leading to biased understandings of various issues. To combat this issue, we have introduced PerSphere, a benchmark designed to facilitate multi-faceted perspective retrieval and... | Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang |  |
| 2546 |  |  [Prompt-Guided Internal States for Hallucination Detection of Large Language Models](https://aclanthology.org/2025.acl-long.1058/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of tasks in different domains. However, they sometimes generate responses that are logically coherent but factually incorrect or misleading, which is known as LLM hallucinations. Data-driven supervised methods... | Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu |  |
| 2547 |  |  [Typology-Guided Adaptation in Multilingual Models](https://aclanthology.org/2025.acl-long.1059/) |  | 0 | Multilingual models often treat language diversity as a problem of data imbalance, overlooking structural variation. We introduce the \*Morphological Index\* (MoI), a typologically grounded metric that quantifies how strongly a language relies on surface morphology for noun classification. Building... | Ndapa Nakashole |  |
| 2548 |  |  [Don't Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections](https://aclanthology.org/2025.acl-long.1060/) |  | 0 | Cultural Heritage (CH) data hold invaluable knowledge, reflecting the history, traditions, and identities of societies, and shaping our understanding of the past and present. However, many CH collections contain outdated or offensive descriptions that reflect historical biases. CH Institutions... | Orfeas MenisMastromichalakis, Jason Liartis, Kristina Rose, Antoine Isaac, Giorgos Stamou |  |
| 2549 |  |  [ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent](https://aclanthology.org/2025.acl-long.1061/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in language generation and general task performance. However, their application to spoken language understanding (SLU) remains challenging, particularly for token-level tasks, where the autoregressive nature of LLMs often leads... | Shangjian Yin, Peijie Huang, Jiatian Chen, Haojing Huang, Yuhong Xu |  |
| 2550 |  |  [FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.1062/) |  | 0 | Large language models (LLMs) augmented with retrieval systems have demonstrated significant potential in handling knowledge-intensive tasks. However, these models often struggle with unfaithfulness issues, generating outputs that either ignore the retrieved context or inconsistently blend it with... | Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Xinrun Wang, Jinsong Su |  |
| 2551 |  |  [Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models](https://aclanthology.org/2025.acl-long.1063/) |  | 0 | We revisit knowledge-based visual reasoning (KB-VR) in light of modern advances in multimodal large language models (MLLMs), and make the following contributions: (i) We propose Visual Knowledge Card (VKC) – a novel image that incorporates not only internal visual knowledge (e.g., scene-aware... | Guanghui Ye, Huan Zhao, Zhixue Zhao, Xupeng Zha, Yang Liu, Zhihua Jiang |  |
| 2552 |  |  [Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity](https://aclanthology.org/2025.acl-long.1064/) |  | 0 | Personalized tool utilization is essential for aligning large language models (LLMs) with user preference in interaction scenarios with various tools. However, most of the current benchmarks primarily focus on either personalization of text generation or direct tool-utilizing, without considering... | Yupu Hao, Pengfei Cao, Zhuoran Jin, Huanxuan Liao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 2553 |  |  [GUICourse: From General Vision Language Model to Versatile GUI Agent](https://aclanthology.org/2025.acl-long.1065/) |  | 0 | Utilizing Graphic User Interfaces (GUIs) for human-computer interaction is essential for accessing various digital tools. Recent advancements in Vision Language Models (VLMs) reveal significant potential for developing versatile agents that assist humans in navigating GUIs. However, current VLMs... | Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, Yuan Yao, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 2554 |  |  [Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration](https://aclanthology.org/2025.acl-long.1066/) |  | 0 | To create culturally inclusive vision-language models (VLMs), developing a benchmark that tests their ability to address culturally relevant questions is essential. Existing approaches typically rely on human annotators, making the process labor-intensive and creating a cognitive burden in... | ChaeHun Park, Yujin Baek, Jaeseok Kim, YuJung Heo, DuSeong Chang, Jaegul Choo |  |
| 2555 |  |  [Maximizing the Effectiveness of Larger BERT Models for Compression](https://aclanthology.org/2025.acl-long.1067/) |  | 0 | Knowledge distillation (KD) is a widely used approach for BERT compression, where a larger BERT model serves as a teacher to transfer knowledge to a smaller student model. Prior works have found that distilling a larger BERT with superior performance may degrade student’s performance than a smaller... | WenShu Fan, Su Lu, Shangyu Xing, XinChun Li, DeChuan Zhan |  |
| 2556 |  |  [Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference](https://aclanthology.org/2025.acl-long.1068/) |  | 0 | Large Language Models (LLMs) are increasingly being used to automate programming tasks. However, the capabilities of LLMs in reasoning about program semantics are still inadequately studied, leaving substantial potential for further exploration. This paper introduces FormalBench, a comprehensive... | Thanh LeCong, Bach Le, Toby Murray |  |
| 2557 |  |  [HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring](https://aclanthology.org/2025.acl-long.1069/) |  | 0 | The misuse of large language models (LLMs) poses potential risks, motivating the development of machine-generated text (MGT) detection. Existing literature primarily concentrates on binary, document-level detection, thereby neglecting texts that are composed jointly by human and LLM contributions.... | Zhixiong Su, Yichen Wang, Herun Wan, Zhaohan Zhang, Minnan Luo |  |
| 2558 |  |  [IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages](https://aclanthology.org/2025.acl-long.1070/) |  | 0 | Recent advances in synthetic speech generation technology have facilitated the generation of high-quality synthetic (fake) speech that emulates human voices. These technologies pose a threat of misuse for identity theft and the spread of misinformation. Consequently, the misuse of such powerful... | Divya V. Sharma, Vijval Ekbote, Anubha Gupta |  |
| 2559 |  |  [Reinforced IR: A Self-Boosting Framework For Domain-Adapted Information Retrieval](https://aclanthology.org/2025.acl-long.1071/) |  | 0 | While retrieval techniques are widely used in practice, they still face significant challenges in cross-domain scenarios. Recently, generation-augmented methods have emerged as a promising solution to this problem. These methods enhance raw queries by incorporating additional information from an... | Chaofan Li, Jianlyu Chen, Yingxia Shao, Chaozhuo Li, Quanqing Xu, Defu Lian, Zheng Liu |  |
| 2560 |  |  [CoIR: A Comprehensive Benchmark for Code Information Retrieval Models](https://aclanthology.org/2025.acl-long.1072/) |  | 0 | Despite the substantial success of Information Retrieval (IR) in various NLP tasks, most IR systems predominantly handle queries and corpora in natural language, neglecting the domain of code retrieval. Code retrieval is critically important yet remains under-explored, with existing methods and... | Xiangyang Li, Kuicai Dong, Yi Quan Lee, Wei Xia, Hao Zhang, Xinyi Dai, Yasheng Wang, Ruiming Tang |  |
| 2561 |  |  [Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment](https://aclanthology.org/2025.acl-long.1073/) |  | 0 | Multimodal retrieval has emerged as a promising yet challenging research direction in recent years. Most existing studies in multimodal retrieval focus on capturing information in multimodal data that is similar to their paired texts, but often ignores the complementary information contained in... | Delong Zeng, Yuexiang Xie, Yaliang Li, Ying Shen |  |
| 2562 |  |  [JoPA: Explaining Large Language Model's Generation via Joint Prompt Attribution](https://aclanthology.org/2025.acl-long.1074/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive performances in complex text generation tasks. However, the contribution of the input prompt to the generated content still remains obscure to humans, underscoring the necessity of understanding the causality between input and output pairs.... | Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin |  |
| 2563 |  |  [Proxy-Driven Robust Multimodal Sentiment Analysis with Incomplete Data](https://aclanthology.org/2025.acl-long.1075/) |  | 0 | Multimodal Sentiment Analysis (MSA) with incomplete data has gained significant attention recently. Existing studies focus on optimizing model structures to handle modality missingness, but models still face challenges in robustness when dealing with uncertain missingness. To this end, we propose a... | Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An |  |
| 2564 |  |  [Not All Terms Matter: Recall-Oriented Adaptive Learning for PLM-aided Query Expansion in Open-Domain Question Answering](https://aclanthology.org/2025.acl-long.1076/) |  | 0 | The effectiveness of open-domain question answering (ODQA), particularly those employing a retriever-reader architecture, depends on the ability to recall relevant documents - a critical step that enables the reader to accurately extract answers. To enhance this retrieval phase, current query... | Xinran Chen, Ben He, Xuanang Chen, Le Sun |  |
| 2565 |  |  [A Mutual Information Perspective on Knowledge Graph Embedding](https://aclanthology.org/2025.acl-long.1077/) |  | 0 | Knowledge graph embedding techniques have emerged as a critical approach for addressing the issue of missing relations in knowledge graphs. However, existing methods often suffer from limitations, including high intra-group similarity, loss of semantic information, and insufficient inference... | Jiang Li, Xiangdong Su, Zehua Duo, Tian Lan, Xiaotao Guo, Guanglai Gao |  |
| 2566 |  |  [Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race](https://aclanthology.org/2025.acl-long.1078/) |  | 0 | Although value-aligned language models (LMs) appear unbiased in explicit bias evaluations, they often exhibit stereotypes in implicit word association tasks, raising concerns about their fair usage. We investigate the mechanisms behind this discrepancy and find that alignment surprisingly amplifies... | Lihao Sun, Chengzhi Mao, Valentin Hofmann, Xuechunzi Bai |  |
| 2567 |  |  [IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://aclanthology.org/2025.acl-long.1079/) |  | 0 | In the realm of large language models (LLMs), the ability of models to accurately follow instructions is paramount as more agents and applications leverage LLMs for construction, where the complexity of instructions are rapidly increasing. However, on the one hand, there is only a certain amount of... | Xinghua Zhang, Haiyang Yu, Cheng Fu, Fei Huang, Yongbin Li |  |
| 2568 |  |  [ProMALex: Progressive Modular Adapters for Multi-Jurisdictional Legal Language Modeling](https://aclanthology.org/2025.acl-long.1080/) |  | 0 | This paper addresses the challenge of adapting language models to the jurisdiction-specific nature of legal corpora. Existing approaches—training separate models for each jurisdiction or using a single shared model—either fail to leverage common legal principles beneficial for low-resource settings... | T. Y. S. S. Santosh, Mohamed Hesham Elganayni |  |
| 2569 |  |  [Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching](https://aclanthology.org/2025.acl-long.1081/) |  | 0 | Knowledge distillation typically involves transferring knowledge from a Large Language Model (LLM) to a Smaller Language Model (SLM). However, in tasks like text matching, smaller fine-tuned models often produce more effective domain-specific representations as they focus on optimizing the... | Mingzhe Li, Jing Xiang, Qishen Zhang, Kaiyang Wan, Xiuying Chen |  |
| 2570 |  |  [Disentangling Language and Culture for Evaluating Multilingual Large Language Models](https://aclanthology.org/2025.acl-long.1082/) |  | 0 | This paper introduces a Dual Evaluation Framework to comprehensively assess the multilingual capabilities of LLMs. By decomposing the evaluation along the dimensions of linguistic medium and cultural context, this framework enables a nuanced analysis of LLMs’ ability to process questions within... | Jiahao Ying, Wei Tang, Yiran Zhao, Yixin Cao, Yu Rong, Wenxuan Zhang |  |
| 2571 |  |  [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://aclanthology.org/2025.acl-long.1083/) |  | 0 | Malicious sockpuppet detection on Wikipedia is critical to preserving access to reliable information on the internet and preventing the spread of disinformation. Prior machine learning approaches rely on stylistic and meta-data features, but do not prioritise adaptability to author-specific... | Luc Raszewski, Christine de Kock |  |
| 2572 |  |  [Diversity-oriented Data Augmentation with Large Language Models](https://aclanthology.org/2025.acl-long.1084/) |  | 0 | Data augmentation is an essential technique in natural language processing (NLP) for enriching training datasets by generating diverse samples. This process is crucial for improving the robustness and generalization capabilities of NLP models. However, a significant challenge remains: Insufficient... | Zaitian Wang, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu, Pengfei Wang, Yuanchun Zhou |  |
| 2573 |  |  [CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation](https://aclanthology.org/2025.acl-long.1085/) |  | 0 | Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training.Current studies mitigate this issue by modifying existing datasets or generating new ones from freshly collected... | Jingqian Zhao, Bingbing Wang, Geng Tu, Yice Zhang, Qianlong Wang, Bin Liang, Jing Li, Ruifeng Xu |  |
| 2574 |  |  [RiOT: Efficient Prompt Refinement with Residual Optimization Tree](https://aclanthology.org/2025.acl-long.1086/) |  | 0 | Recent advancements in large language models (LLMs) have highlighted their potential across a variety of tasks, but their performance still heavily relies on the design of effective prompts. Existing methods for automatic prompt optimization face two challenges: lack of diversity, limiting the... | Chenyi Zhou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang |  |
| 2575 |  |  [Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions](https://aclanthology.org/2025.acl-long.1087/) |  | 0 | This paper investigates the faithfulness of multimodal large language model (MLLM) agents in a graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context. A general scenario is proposed where both... | Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, Hai Zhao |  |
| 2576 |  |  [Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark](https://aclanthology.org/2025.acl-long.1088/) |  | 0 | Driven by the remarkable progress in diffusion models, text-to-image generation has achieved substantial advancements, underscoring the urgent need for robust automatic quality assessment. This task is inherently complex, requiring evaluations that range from object presence and attribute... | RongCheng Tu, ZiAo Ma, Tian Lan, Yuehao Zhao, Heyan Huang, XianLing Mao |  |
| 2577 |  |  [Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering](https://aclanthology.org/2025.acl-long.1089/) |  | 0 | In this paper, we identify a critical problem, “lost-in-retrieval”, in retrieval-augmented multi-hop question answering (QA): the key entities are missed in LLMs’ sub-question decomposition. “Lost-in-retrieval” significantly degrades the retrieval performance, which disrupts the reasoning chain and... | Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu |  |
| 2578 |  |  [TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models](https://aclanthology.org/2025.acl-long.1090/) |  | 0 | Tabular data are crucial in many fields and their understanding by large language models (LLMs) under high parameter efficiency paradigm is important. However, directly applying parameter-efficient fine-tuning (PEFT) techniques to tabular tasks presents significant challenges, particularly in terms... | Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, Shi Han, Zejian Yuan, Dongmei Zhang |  |
| 2579 |  |  [Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement](https://aclanthology.org/2025.acl-long.1091/) |  | 0 | The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, the availability of high-quality human-annotated SFT data has become a significant bottleneck for LLMs, necessitating a greater reliance on... | Maosongcao Maosongcao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Conghui He, Haodong Duan, Songyang Zhang, Kai Chen |  |
| 2580 |  |  [CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis](https://aclanthology.org/2025.acl-long.1092/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they often exhibit a specific cultural bias, neglecting the values and linguistic diversity of low-resource regions. This cultural bias not only undermines universal equality but also risks reinforcing... | Ruixiang Feng, Shen Gao, Xiuying Chen, Lisi Chen, Shuo Shang |  |
| 2581 |  |  [Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis](https://aclanthology.org/2025.acl-long.1093/) |  | 0 | The interpretability of Mixture-of-Experts (MoE) models, especially those with heterogeneous designs, remains underexplored. Existing attribution methods for dense models fail to capture dynamic routing-expert interactions in sparse MoE architectures. To address this issue, we propose a cross-level... | Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu |  |
| 2582 |  |  [ChartLens: Fine-grained Visual Attribution in Charts](https://aclanthology.org/2025.acl-long.1094/) |  | 0 | The growing capabilities of multimodal large language models (MLLMs) have advanced tasks like chart understanding. However, these models often suffer from hallucinations, where generated text sequences conflict with the provided visual data. To address this, we introduce Post-Hoc Visual Attribution... | Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha |  |
| 2583 |  |  [LESA: Learnable LLM Layer Scaling-Up](https://aclanthology.org/2025.acl-long.1095/) |  | 0 | Training Large Language Models (LLMs) from scratch requires immense computational resources, making it prohibitively expensive. Model scaling-up offers a promising solution by leveraging the parameters of smaller models to create larger ones. However, existing depth scaling-up methods rely on... | Yifei Yang, Zouying Cao, Xinbei Ma, Yao Yao, Zhi Chen, Libo Qin, Hai Zhao |  |
| 2584 |  |  [MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation](https://aclanthology.org/2025.acl-long.1096/) |  | 0 | Recent multimodal large language models (MLLMs) have demonstrated significant potential in open-ended conversation, generating more accurate and personalized responses. However, their abilities to memorize, recall, and reason in sustained interactions within real-world scenarios remain... | Haochen Xue, Feilong Tang, Ming Hu, Yexin Liu, Qidong Huang, Yulong Li, Chengzhi Liu, Zhongxing Xu, Chong Zhang, ChunMei Feng, Yutong Xie, Imran Razzak, Zongyuan Ge, Jionglong Su, Junjun He, Yu Qiao |  |
| 2585 |  |  [Towards the Law of Capacity Gap in Distilling Language Models](https://aclanthology.org/2025.acl-long.1097/) |  | 0 | Language model (LM) distillation aims at distilling the knowledge in a large teacher LM to a small student one. As a critical issue facing LM distillation, a superior student often arises from a teacher of a relatively small scale instead of a larger one, especially in the presence of substantial... | Chen Zhang, Qiuchi Li, Dawei Song, Zheyu Ye, Yan Gao, Yao Hu |  |
| 2586 |  |  [WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning](https://aclanthology.org/2025.acl-long.1098/) |  | 0 | Current speech encoding pipelines often rely on an additional text-based LM to get robust representations of human communication, even though SotA speech-to-text models often have a LM within. This work proposes an approach to improve the LM within an audio model such that the subsequent text-LM is... | Rajath Rao, Adithya V. Ganesan, Oscar N. E. Kjell, Jonah Luby, Akshay Raghavan, Scott M. Feltman, Whitney Ringwald, Ryan L. Boyd, Benjamin J. Luft, Camilo J. Ruggero, Neville Ryant, Roman Kotov, H. Andrew Schwartz |  |
| 2587 |  |  [Keys to Robust Edits: From Theoretical Insights to Practical Advances](https://aclanthology.org/2025.acl-long.1099/) |  | 0 | Large language models (LLMs) struggle with maintaining accurate knowledge due to conflicting/outdated parametric memories. While locate-and-edit methods address this, their reliance on models’ internal representations leads to robustness failures in long-context reasoning and paraphrased queries.... | Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang |  |
| 2588 |  |  [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://aclanthology.org/2025.acl-long.1100/) |  | 0 | Molecular structure elucidation involves deducing a molecule’s structure from various types of spectral data, which is crucial in chemical experimental analysis. While large language models (LLMs) have shown remarkable proficiency in analyzing and reasoning through complex tasks, they still... | Xiang Zhuang, Bin Wu, Jiyu Cui, Kehua Feng, Xiaotong Li, Huabin Xing, Keyan Ding, Qiang Zhang, Huajun Chen |  |
| 2589 |  |  [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.1101/) |  | 0 | Automatic evaluation of retrieval augmented generation (RAG) systems relies on fine-grained dimensions like faithfulness and relevance, as judged by expert human annotators. Meta-evaluation benchmarks support the development of automatic evaluators that correlate well with human judgement. However,... | María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico |  |
| 2590 |  |  [The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights](https://aclanthology.org/2025.acl-long.1102/) |  | 0 | Recent research has increasingly focused on multimodal mathematical reasoning, particularly emphasizing the creation of relevant datasets and benchmarks. Despite this, the role of visual information in reasoning has been underexplored. Our findings show that existing multimodal mathematical models... | Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang, Xunliang Cai |  |
| 2591 |  |  [The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters](https://aclanthology.org/2025.acl-long.1103/) |  | 0 | Theory-of-Mind (ToM) is a fundamental psychological capability that allows humans to understand and interpret the mental states of others. Humans infer others’ thoughts by integrating causal cues and indirect clues from broad contextual information, often derived from past interactions. In other... | Chulun Zhou, Qiujing Wang, Mo Yu, Xiaoqian Yue, Rui Lu, Jiangnan Li, Yifan Zhou, Shunchi Zhang, Jie Zhou, Wai Lam |  |
| 2592 |  |  [S²R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning](https://aclanthology.org/2025.acl-long.1104/) |  | 0 | Recent studies have demonstrated the effectiveness of LLM test-time scaling. However, existing approaches to incentivize LLMs’ deep thinking abilities generally require large-scale data or significant training efforts. Meanwhile, it remains unclear how to improve the thinking abilities of less... | Ruotian Ma, Peisong Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, Nan Du, Jia Li |  |
| 2593 |  |  [Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning](https://aclanthology.org/2025.acl-long.1105/) |  | 0 | Multi-agent collaborative tasks exhibit exceptional capabilities in natural language applications and generation. By prompting agents to assign clear roles, it is possible to facilitate cooperation and achieve complementary capabilities among LLMs. A common strategy involves adopting a relatively... | Haoran Li, Ziyi Su, Yun Xue, Zhiliang Tian, Yiping Song, Minlie Huang |  |
| 2594 |  |  [Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation](https://aclanthology.org/2025.acl-long.1106/) |  | 0 | Visual programming languages (VPLs) allow users to create programs through graphical interfaces, which results in easier accessibility and their widespread usage in various domains. To further enhance this accessibility, recent research has focused on generating VPL code from user instructions... | Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee |  |
| 2595 |  |  [STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond](https://aclanthology.org/2025.acl-long.1107/) |  | 0 | Critical text assessment is at the core of many expert activities, such as fact-checking, peer review, and essay grading. Yet, existing work treats critical text assessment as a black box problem, limiting interpretability and human-AI collaboration. To close this gap, we introduce Structured... | Nils Dycke, Matej Zecevic, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych |  |
| 2596 |  |  [XDAC: XAI-Driven Detection and Attribution of LLM-Generated News Comments in Korean](https://aclanthology.org/2025.acl-long.1108/) |  | 0 | Large language models (LLMs) generate human-like text, raising concerns about their misuse in creating deceptive content. Detecting LLM-generated comments (LGC) in online news is essential for preserving online discourse integrity and preventing opinion manipulation. However, effective detection... | Wooyoung Go, Hyoungshick Kim, Alice Oh, Yongdae Kim |  |
| 2597 |  |  [CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference](https://aclanthology.org/2025.acl-long.1109/) |  | 0 | With the growing deployment of pre-trained models like Transformers on cloud platforms, privacy concerns about model parameters and inference data are intensifying. Existing Privacy-Preserving Transformer Inference (PPTI) frameworks face the “impossible trinity” of balancing privacy, efficiency,... | Jinglong Luo, Guanzhong Chen, Yehong Zhang, Shiyu Liu, Hui Wang, Yue Yu, Xun Zhou, Yuan Qi, Zenglin Xu |  |
| 2598 |  |  [Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch](https://aclanthology.org/2025.acl-long.1110/) |  | 0 | To meet the demands of content moderation, online platforms have resorted to automated systems. Newer forms of real-time engagement (e.g., users commenting on live streams) on platforms like Twitch exert additional pressures on the latency expected of such moderation systems. Despite their... | Prarabdh Shukla, Wei Yin Chong, Yash Patel, Brennan Schaffner, Danish Pruthi, Arjun Nitin Bhagoji |  |
| 2599 |  |  [EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models](https://aclanthology.org/2025.acl-long.1111/) |  | 0 | We propose EdiText, a controllable text editing method that modifies the reference text to desired attributes at various scales. We integrate an SDEdit-based editing technique that allows for broad adjustments in the degree of text editing. Additionally, we introduce a novel fine-level editing... | Che Hyun Lee, Heeseung Kim, Jiheum Yeom, Sungroh Yoon |  |
| 2600 |  |  [TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages](https://aclanthology.org/2025.acl-long.1112/) |  | 0 | Being able to thoroughly assess massive multi-task language understanding (MMLU) capabilities is essential for advancing the applicability of multilingual language models. However, preparing such benchmarks in high quality native language is often costly and therefore limits the representativeness... | Jafar Isbarov, Arofat Akhundjanova, Mammad Hajili, Kavsar Huseynova, Dmitry Gaynullin, Anar Rzayev, Osman Tursun, Aizirek Turdubaeva, Ilshat Saetov, Rinat Kharisov, Saule Belginova, Ariana Kenbayeva, Amina Alisheva, Abdullatif Köksal, Samir Rustamov, Duygu Ataman |  |
| 2601 |  |  [Look Both Ways and No Sink: Converting LLMs into Text Encoders without Training](https://aclanthology.org/2025.acl-long.1113/) |  | 0 | Recent advancements have demonstrated the advantage of converting pretrained large language models into powerful text encoders by enabling bidirectional attention in transformer layers. However, existing methods often require extensive training on large-scale datasets, posing challenges in... | Ziyong Lin, Haoyi Wu, Shu Wang, Kewei Tu, Zilong Zheng, Zixia Jia |  |
| 2602 |  |  [A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models](https://aclanthology.org/2025.acl-long.1114/) |  | 0 | The lack of data transparency in Large Language Models (LLMs) has highlighted the importance of Membership Inference Attack (MIA), which differentiates trained (member) and untrained (non-member) data. Though it shows success in previous studies, recent research reported a near-random performance... | Bowen Chen, Namgi Han, Yusuke Miyao |  |
| 2603 |  |  [Around the World in 24 Hours: Probing LLM Knowledge of Time and Place](https://aclanthology.org/2025.acl-long.1115/) |  | 0 | Reasoning over time and space is essential for understanding our world. However, the abilities of language models in this area are largely unexplored as previous work has tested their abilities for logical reasoning in terms of time and space in isolation or only in simple or artificial... | Carolin Holtermann, Paul Röttger, Anne Lauscher |  |
| 2604 |  |  [Mining the uncertainty patterns of humans and models in the annotation of moral foundations and human values](https://aclanthology.org/2025.acl-long.1116/) |  | 0 | The NLP community has converged on considering disagreement in annotation (or human label variation, HLV) as a constitutive feature of subjective tasks. This paper makes a further step by investigating the relationship between HLV and model uncertainty, and the impact of linguistic features of the... | Neele Falk, Gabriella Lapesa |  |
| 2605 |  |  ["What do you call a dog that is incontrovertibly true? Dogma": Testing LLM Generalization through Humor](https://aclanthology.org/2025.acl-long.1117/) |  | 0 | Humor, requiring creativity and contextual understanding, is a hallmark of human intelligence, showcasing adaptability across linguistic scenarios. While recent advances in large language models (LLMs) demonstrate strong reasoning on various benchmarks, it remains unclear whether they truly adapt... | Alessio Cocchieri, Luca Ragazzi, Paolo Italiani, Giuseppe Tagliavini, Gianluca Moro |  |
| 2606 |  |  [Towards Harmonized Uncertainty Estimation for Large Language Models](https://aclanthology.org/2025.acl-long.1118/) |  | 0 | To facilitate robust and trustworthy deployment of large language models (LLMs), it is essential to quantify the reliability of their generations through uncertainty estimation. While recent efforts have made significant advancements by leveraging the internal logic and linguistic features of LLMs... | Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui |  |
| 2607 |  |  [VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare](https://aclanthology.org/2025.acl-long.1119/) |  | 0 | Alignment techniques have become central to ensuring that Large Language Models (LLMs) generate outputs consistent with human values. However, existing alignment paradigms often model an averaged or monolithic preference, failing to account for the diversity of perspectives across cultures,... | Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem |  |
| 2608 |  |  [Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media](https://aclanthology.org/2025.acl-long.1120/) |  | 0 | Social media platforms are experiencing a growing presence of AI-Generated Texts (AIGTs). However, the misuse of AIGTs could have profound implications for public opinion, such as spreading misinformation and manipulating narratives. Despite its importance, it remains unclear how prevalent AIGTs... | Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He |  |
| 2609 |  |  [From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continued Instruction Tuning](https://aclanthology.org/2025.acl-long.1121/) |  | 0 | Supervised Fine-Tuning (SFT) with translated instruction data effectively adapts Large Language Models (LLMs) from English to non-English languages. We introduce Cross-Lingual Continued Instruction Tuning (X-CIT), which fully leverages translation-based parallel instruction data to enhance... | Linjuan Wu, Haoran Wei, Baosong Yang, Weiming Lu |  |
| 2610 |  |  [WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks](https://aclanthology.org/2025.acl-long.1122/) |  | 0 | Embeddings-as-a-Service (EaaS) is a service offered by large language model (LLM) developers to supply embeddings generated by LLMs. Previous research suggests that EaaS is prone to imitation attacks—attacks that clone the underlying EaaS model by training another model on the queried embeddings.... | Anudeex Shetty, Qiongkai Xu, Jey Han Lau |  |
| 2611 |  |  [HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation](https://aclanthology.org/2025.acl-long.1123/) |  | 0 | Many positional encodings (PEs) are designed to exhibit long-term decay, based on an entrenched and long-standing inductive opinion: tokens farther away from the current position carry less relevant information. We argue that long-term decay is outdated in the era of LLMs, as LLMs are now applied... | Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu |  |
| 2612 |  |  [One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments](https://aclanthology.org/2025.acl-long.1124/) |  | 0 | Large Language Models (LLMs) have advanced rapidly but face significant memory demands. While quantization has shown promise for LLMs, current methods typically require lengthy training to alleviate the performance degradation from quantization loss. However, deploying LLMs across diverse scenarios... | Ke Yi, Yuhui Xu, Heng Chang, Yuan Meng, Tong Zhang, Jia Li |  |
| 2613 |  |  [Beyond Logits: Aligning Feature Dynamics for Effective Knowledge Distillation](https://aclanthology.org/2025.acl-long.1125/) |  | 0 | Knowledge distillation (KD) compresses large language models (LLMs), known as teacher models, into lightweight versions called student models, enabling efficient inference and downstream applications. However, prevailing approaches accomplish this by predominantly focusing on matching the final... | Guoqiang Gong, Jiaxing Wang, Jin Xu, Deping Xiang, Zicheng Zhang, Leqi Shen, Yifeng Zhang, JunhuaShu JunhuaShu, ZhaolongXing ZhaolongXing, Zhen Chen, Pengzhang Liu, Ke Zhang |  |
| 2614 |  |  [Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention](https://aclanthology.org/2025.acl-long.1126/) |  | 0 | Long-context modeling is crucial for next-generation language models, yet the high computational cost of standard attention mechanisms poses significant computational challenges. Sparse attention offers a promising direction for improving efficiency while maintaining model capabilities. We present... | Jingyang Yuan, Huazuo Gao, Damai Dai, Junyu Luo, Liang Zhao, Zhengyan Zhang, Zhenda Xie, Yuxing Wei, Lean Wang, Zhiping Xiao, Yuqing Wang, Chong Ruan, Ming Zhang, Wenfeng Liang, Wangding Zeng |  |
| 2615 |  |  [DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics](https://aclanthology.org/2025.acl-long.1127/) |  | 0 | We introduce Dynamic Retrieval-Augmented Expert Networks (DRAE), a groundbreaking architecture that addresses the challenges of lifelong learning, catastrophic forgetting, and task adaptation by combining the dynamic routing capabilities of Mixture-of-Experts (MoE); leveraging the... | Yayu Long, Kewei Chen, Long Jin, Mingsheng Shang |  |
| 2616 |  |  [MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables](https://aclanthology.org/2025.acl-long.1128/) |  | 0 | Recent advancements in table-based reasoning have expanded beyond factoid-level QA to address insight-level tasks, where systems should synthesize implicit knowledge in the table to provide explainable analyses. Although effective, existing studies remain confined to scenarios where a single gold... | Kwangwook Seo, Donguk Kwon, Dongha Lee |  |
| 2617 |  |  [Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning](https://aclanthology.org/2025.acl-long.1129/) |  | 0 | Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient Fine-Tuning (PEFT) method, has attracted widespread attention for significantly improving parameter efficiency by editing representation space alone. In this work, we investigate applying ReFT to complex reasoning tasks.... | Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, Yue Xin, Deng Cai, Chen Shen, Jieping Ye |  |
| 2618 |  |  [Does the Emotional Understanding of LVLMs Vary Under High-Stress Environments and Across Different Demographic Attributes?](https://aclanthology.org/2025.acl-long.1130/) |  | 0 | According to psychological and neuroscientific research, a high-stress environment can restrict attentional resources and intensify negative affect, thereby impairing the ability to understand emotions. Furthermore, demographic attributes such as race, gender, and age group have been repeatedly... | Jaewook Lee, Yeajin Jang, OhWoog Kwon, Harksoo Kim |  |
| 2619 |  |  [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://aclanthology.org/2025.acl-long.1131/) |  | 0 | Modeling latent representations in a hyperspherical space has proven effective for capturing directional similarities in high-dimensional text data, benefiting topic modeling. Variational autoencoder-based neural topic models (VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode... | Suman Adhya, Debarshi Kumar Sanyal |  |
| 2620 |  |  [Learning to Look at the Other Side: A Semantic Probing Study of Word Embeddings in LLMs with Enabled Bidirectional Attention](https://aclanthology.org/2025.acl-long.1132/) |  | 0 | Autoregressive Large Language Models (LLMs) demonstrate exceptional performance in language understanding and generation. However, their application in text embedding tasks has been relatively slow, along with the analysis of their semantic representation in probing tasks, due to the constraints of... | Zhaoxin Feng, Jianfei Ma, Emmanuele Chersoni, Xiaojing Zhao, Xiaoyi Bao |  |
| 2621 |  |  [Tracing and Dissecting How LLMs Recall Factual Knowledge for Real World Questions](https://aclanthology.org/2025.acl-long.1133/) |  | 0 | Recent advancements in large language models (LLMs) have shown promising ability to perform commonsense reasoning, bringing machines closer to human-like understanding. However, deciphering the internal reasoning processes of LLMs remains challenging due to the complex interdependencies among... | Yiqun Wang, Chaoqun Wan, Sile Hu, Yonggang Zhang, Xiang Tian, Yaowu Chen, Xu Shen, Jieping Ye |  |
| 2622 |  |  [Employing Discourse Coherence Enhancement to Improve Cross-Document Event and Entity Coreference Resolution](https://aclanthology.org/2025.acl-long.1134/) |  | 0 | Cross-Document Coreference Resolution (CDCR) aims to identify and group together mentions of a specific event or entity that occur across multiple documents. In contrast to the within-document tasks, in which event and entity mentions are linked by rich and coherent contexts, cross-document... | Xinyu Chen, Peifeng Li, Qiaoming Zhu |  |
| 2623 |  |  [Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning](https://aclanthology.org/2025.acl-long.1135/) |  | 0 | Fine-tuning large language models (LLMs) on task-specific data is essential for their effective deployment. As dataset sizes grow, efficiently selecting optimal subsets for training becomes crucial to balancing performance and computational costs. Traditional data selection methods often require... | Shaobo Wang, Xiangqi Jin, Ziming Wang, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang |  |
| 2624 |  |  [Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation](https://aclanthology.org/2025.acl-long.1136/) |  | 0 | Post-training is essential for enabling large language models (LLMs) to follow human instructions. However, its effectiveness depends on high-quality instruction data, which is challenging to obtain in the real world due to privacy concerns, data scarcity, and high annotation costs. To fill this... | Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, Siheng Chen |  |
| 2625 |  |  [SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs](https://aclanthology.org/2025.acl-long.1137/) |  | 0 | Chain-of-Thought (CoT) reasoning enables Large Language Models (LLMs) to solve complex reasoning tasks by generating intermediate reasoning steps. However, most existing approaches focus on hard token decoding, which constrains reasoning within the discrete vocabulary space and may not always be... | Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao |  |
| 2626 |  |  [FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning](https://aclanthology.org/2025.acl-long.1138/) |  | 0 | Real-world decision-making often requires integrating and reasoning over information from multiple modalities. While recent multimodal large language models (MLLMs) have shown promise in such tasks, their ability to perform multi-hop reasoning across diverse sources remains insufficiently... | Seunghee Kim, Changhyeon Kim, Taeuk Kim |  |
| 2627 |  |  [Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms](https://aclanthology.org/2025.acl-long.1139/) |  | 0 | Precise control over language model generation is vital for ensuring both safety and reliability. Although prompt engineering and steering are commonly used to intervene in model behaviors, the vast number of parameters in models often results in highly intertwined internal representations. This... | Mengru Wang, Ziwen Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Huajun Chen, Ningyu Zhang |  |
| 2628 |  |  [MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization](https://aclanthology.org/2025.acl-long.1140/) |  | 0 | Deploying large language models (LLMs) with low-rank adaptation (LoRA) on mobile devices is promising due to their capability to complete diverse domain-specific tasks while ensuring privacy and accessibility. In this paper, we introduce MobiLoRA to accelerate LoRA-based LLM inference on mobile... | Borui Li, Yitao Wang, Haoran Ma, Ligeng Chen, Jun Xiao, Shuai Wang |  |
| 2629 |  |  [Language Models Resist Alignment: Evidence From Data Compression](https://aclanthology.org/2025.acl-long.1141/) |  | 0 | Large language models (LLMs) may exhibit unintended or undesirable behaviors. Recent works have concentrated on aligning LLMs to mitigate harmful outputs. Despite these efforts, some anomalies indicate that even a well-conducted alignment process can be easily circumvented, whether intentionally or... | Jiaming Ji, Kaile Wang, Tianyi Alex Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Josef Dai, Yunhuai Liu, Yaodong Yang |  |
| 2630 |  |  [Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation](https://aclanthology.org/2025.acl-long.1142/) |  | 0 | Recent advancements in large language models (LLMs) have significantly improved the performance of multi-hop question answering (MHQA) systems. Despite the success of MHQA systems, the evaluation of MHQA is not deeply investigated. Existing evaluations mainly focus on comparing the final answers of... | Qichuan Liu, Chentao Zhang, Chenfeng Zheng, Guosheng Hu, Xiaodong Li, Zhihong Zhang |  |
| 2631 |  |  [Mamba Knockout for Unraveling Factual Information Flow](https://aclanthology.org/2025.acl-long.1143/) |  | 0 | This paper investigates the flow of factual information in Mamba State-Space Model (SSM)-based language models. We rely on theoretical and empirical connections to Transformer-based architectures and their attention mechanisms. Exploiting this relationship, we adapt attentional interpretability... | Nir Endy, Idan Daniel Grosbard, Yuval RanMilo, Yonatan Slutzky, Itay Tshuva, Raja Giryes |  |
| 2632 |  |  [Small Changes, Big Impact: How Manipulating a Few Neurons Can Drastically Alter LLM Aggression](https://aclanthology.org/2025.acl-long.1144/) |  | 0 | Recent remarkable advances in Large Language Models (LLMs) have led to innovations in various domains such as education, healthcare, and finance, while also raising serious concerns that they can be easily misused for malicious purposes. Most previous research has focused primarily on observing how... | Jaewook Lee, Junseo Jang, OhWoog Kwon, Harksoo Kim |  |
| 2633 |  |  [Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning Models](https://aclanthology.org/2025.acl-long.1145/) |  | 0 | Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown remarkable reasoning capabilities by scaling test-time compute and generating long Chain-of-Thought (CoT). Distillation post-training on LRMs-generated data is a straightforward yet effective method to enhance the reasoning... | Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, Hao Wang, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang |  |
| 2634 |  |  [Curiosity-Driven Reinforcement Learning from Human Feedback](https://aclanthology.org/2025.acl-long.1146/) |  | 0 | Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences, but often at the cost of reduced output diversity. This trade-off between diversity and alignment quality remains a significant challenge. Drawing inspiration from... | Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang |  |
| 2635 |  |  [T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback](https://aclanthology.org/2025.acl-long.1147/) |  | 0 | Text-to-audio (T2A) generation has achieved remarkable progress in generating a variety of audio outputs from language prompts. However, current state-of-the-art T2A models still struggle to satisfy human preferences for prompt-following and acoustic quality when generating complex multi-event... | Zehan Wang, Ke Lei, Chen Zhu, Jiawei Huang, Sashuai Zhou, Luping Liu, Xize Cheng, Shengpeng Ji, Zhenhui Ye, Tao Jin, Zhou Zhao |  |
| 2636 |  |  [CoE: A Clue of Emotion Framework for Emotion Recognition in Conversations](https://aclanthology.org/2025.acl-long.1148/) |  | 0 | Emotion Recognition in Conversations (ERC) is crucial for machines to understand dynamic human emotions. While Large Language Models (LLMs) show promise, their performance is often limited by challenges in interpreting complex conversational streams. We introduce a Clue of Emotion (CoE) framework,... | Zhiyu Shen, Yunhe Pang, Yanghui Rao, Jianxing Yu |  |
| 2637 |  |  [MPO: Multilingual Safety Alignment via Reward Gap Optimization](https://aclanthology.org/2025.acl-long.1149/) |  | 0 | Large language models (LLMs) have become increasingly central to AI applications worldwide, necessitating robust multilingual safety alignment to ensure secure deployment across diverse linguistic contexts. Existing preference learning methods for safety alignment, such as RLHF and DPO, are... | Weixiang Zhao, Yulin Hu, Yang Deng, Tongtong Wu, Wenxuan Zhang, Jiahe Guo, An Zhang, Yanyan Zhao, Bing Qin, TatSeng Chua, Ting Liu |  |
| 2638 |  |  [QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions](https://aclanthology.org/2025.acl-long.1150/) |  | 0 | This paper explores a novel perspective to speech quality assessment by leveraging natural language descriptions, offering richer, more nuanced insights than traditional numerical scoring methods. Natural language feedback provides instructive recommendations and detailed evaluations, yet existing... | Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang |  |
| 2639 |  |  [On the Relation Between Fine-Tuning, Topological Properties, and Task Performance in Sense-Enhanced Embeddings](https://aclanthology.org/2025.acl-long.1151/) |  | 0 | Topological properties of embeddings, such as isotropy and uniformity, are closely linked to their expressiveness, and improving these properties enhances the embeddings’ ability to capture nuanced semantic distinctions. However, fine-tuning can reduce the expressiveness of the embeddings of... | Deniz Ekin Yavas, Timothée Bernard, Benoît Crabbé, Laura Kallmeyer |  |
| 2640 |  |  [Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?](https://aclanthology.org/2025.acl-long.1152/) |  | 0 | While Multi-modal Large Language Models (MLLMs) have shown impressive capabilities in document understanding tasks, their ability to locate and reason about fine-grained details within complex documents remains understudied. Consider searching a restaurant menu for a specific nutritional detail or... | Parth Thakkar, Ankush Agarwal, Prasad Kasu, Pulkit Bansal, Chaitanya Devaguptapu |  |
| 2641 |  |  [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](https://aclanthology.org/2025.acl-long.1153/) |  | 0 | Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned... | Yongquan He, Wenyuan Zhang, Xuancheng Huang, Peng Zhang, Lingxun Meng, Xiang Zhou, Ke Zeng, Xunliang Cai |  |
| 2642 |  |  [Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction](https://aclanthology.org/2025.acl-long.1154/) |  | 0 | In designing multiple-choice questions (MCQs) in education, creating plausible distractors is crucial for identifying students’ misconceptions and gaps in knowledge and accurately assessing their understanding. However, prior studies on distractor generation have not paid sufficient attention to... | Yooseop Lee, Suin Kim, Yohan Jo |  |
| 2643 |  |  [Exploring Explanations Improves the Robustness of In-Context Learning](https://aclanthology.org/2025.acl-long.1155/) |  | 0 | In-context learning (ICL) has emerged as a successful paradigm for leveraging large language models (LLMs). However, it often struggles to generalize beyond the distribution of the provided demonstrations. A recent advancement in enhancing robustness is ICL with explanations (X-ICL), which improves... | Ukyo Honda, Tatsushi Oka |  |
| 2644 |  |  [Prediction Hubs are Context-Informed Frequent Tokens in LLMs](https://aclanthology.org/2025.acl-long.1156/) |  | 0 | Hubness, the tendency for a few points to be among the nearest neighbours of a disproportionate number of other points, commonly arises when applying standard distance measures to high-dimensional data, often negatively impacting distance-based analysis. As autoregressive large language models... | Beatrix Miranda Ginn Nielsen, Iuri Macocco, Marco Baroni |  |
| 2645 |  |  [Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law](https://aclanthology.org/2025.acl-long.1157/) |  | 0 | Scaling law builds the relationship between training computation and validation loss, enabling researchers to effectively predict the loss trending of models across different levels of computation. However, a gap still remains between validation loss and the model’s downstream capabilities, making... | Qiming Ge, Shuhao Xing, Songyang Gao, Yunhua Zhou, Yicheng Zou, Songyang Zhang, Zhi Chen, Hang Yan, Qi Zhang, Qipeng Guo, Kai Chen |  |
| 2646 |  |  [CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution](https://aclanthology.org/2025.acl-long.1158/) |  | 0 | Code benchmarks such as HumanEval are widely adopted to evaluate Large Language Models’ (LLMs) coding capabilities. However, there is an unignorable programming language bias in existing code benchmarks – over 95% code generation benchmarks are dominated by Python, leaving the LLMs’ capabilities in... | Ruiyang Xu, Jialun Cao, Yaojie Lu, Ming Wen, Hongyu Lin, Xianpei Han, Ben He, ShingChi Cheung, Le Sun |  |
| 2647 |  |  [Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs](https://aclanthology.org/2025.acl-long.1159/) |  | 0 | Retrieval-augmented generation (RAG) has revitalized Large Language Models (LLMs) by injecting non-parametric factual knowledge. Compared with long-context LLMs, RAG is considered an effective summarization tool in a more concise and lightweight manner, which can interact with LLMs multiple times... | Haozhen Zhang, Tao Feng, Jiaxuan You |  |
| 2648 |  |  [Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset](https://aclanthology.org/2025.acl-long.1160/) |  | 0 | The performance and usability of Large-Language Models (LLMs) are driving their use in explanation generation tasks. However, despite their widespread adoption, LLM explanations have been found to be unreliable, making it difficult for users to distinguish good from bad explanations. To address... | Diana GalvánSosa, Gabrielle Gaudeau, Pride Kavumba, Yunmeng Li, Hongyi Gu, Zheng Yuan, Keisuke Sakaguchi, Paula Buttery |  |
| 2649 |  |  [A Dual-Mind Framework for Strategic and Expressive Negotiation Agent](https://aclanthology.org/2025.acl-long.1161/) |  | 0 | Negotiation agents need to influence the attitudes or intentions of users to reach a consensus. Strategy planning and expressive optimization are crucial aspects of effective negotiations. However, previous studies have typically focused on only one of these aspects, neglecting the fact that their... | Yutong Liu, Lida Shi, Rui Song, Hao Xu |  |
| 2650 |  |  [Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models](https://aclanthology.org/2025.acl-long.1162/) |  | 0 | Long-context language models (LCLMs) have exhibited impressive capabilities in long-context understanding tasks. Among these, long-context referencing—a crucial task that requires LCLMs to attribute items of interest to specific parts of long-context data—remains underexplored. To bridge this gap,... | Junjie Wu, Gefei Gu, Yanan Zheng, DitYan Yeung, Arman Cohan |  |
| 2651 |  |  [Revisiting Scaling Laws for Language Models: The Role of Data Quality and Training Strategies](https://aclanthology.org/2025.acl-long.1163/) |  | 0 | Traditional scaling laws in natural language processing suggest that increasing model size and training data enhances performance. However, recent studies reveal deviations, particularly in large language models, where performance improvements decelerate—a phenomenon known as sub-scaling. This... | Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang |  |
| 2652 |  |  [Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments](https://aclanthology.org/2025.acl-long.1164/) |  | 0 | Identifying arguments is a necessary prerequisite for various tasks in automated discourse analysis, particularly within contexts such as political debates, online discussions, and scientific reasoning. In addition to theoretical advances in understanding the constitution of arguments, a... | Marc Feger, Katarina Boland, Stefan Dietze |  |
| 2653 |  |  [Enhancing Machine Translation with Self-Supervised Preference Data](https://aclanthology.org/2025.acl-long.1165/) |  | 0 | Model alignment methods like Direct Preference Optimization and Contrastive Preference Optimization have enhanced machine translation performance by leveraging preference data to enable models to reject suboptimal outputs. During preference data construction, previous approaches primarily rely on... | Haoxiang Sun, Ruize Gao, Pei Zhang, Baosong Yang, Rui Wang |  |
| 2654 |  |  [Unveil: Unified Visual-Textual Integration and Distillation for Multi-modal Document Retrieval](https://aclanthology.org/2025.acl-long.1166/) |  | 0 | Document retrieval in real-world scenarios faces significant challenges due to diverse document formats and modalities. Traditional text-based approaches rely on tailored parsing techniques that disregard layout information and are prone to errors, while recent parsing-free visual methods often... | Hao Sun, Yingyan Hou, Jiayan Guo, Bo Wang, Chunyu Yang, Jinsong Ni, Yan Zhang |  |
| 2655 |  |  [Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls](https://aclanthology.org/2025.acl-long.1167/) |  | 0 | Recent advancements in tree search algorithms guided by verifiers have significantly enhanced the reasoning capabilities of large language models (LLMs), but at the cost of increased computational resources. In this work, we identify two key challenges contributing to this inefficiency:... | Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, Dong Yu |  |
| 2656 |  |  [MEXMA: Token-level objectives improve sentence representations](https://aclanthology.org/2025.acl-long.1168/) |  | 0 | Cross-lingual sentence encoders (CLSE) create fixed-size sentence representations with aligned translations. Current pre-trained CLSE approaches use sentence-level objectives only. This can lead to loss of information, especially for tokens, which then degrades the sentence representation. We... | João Maria Janeiro, Benjamin Piwowarski, Patrick Gallinari, Loïc Barrault |  |
| 2657 |  |  [Uncertainty-Aware Iterative Preference Optimization for Enhanced LLM Reasoning](https://aclanthology.org/2025.acl-long.1169/) |  | 0 | Direct Preference Optimization (DPO) has recently emerged as an efficient and effective method for aligning large language models with human preferences. However, constructing high-quality preference datasets remains challenging, often necessitating expensive manual or powerful LM annotations.... | Lei Li, Hehuan Liu, Yaxin Zhou, ZhaoYang Gui, Xudong Weng, Yi Yuan, Zheng Wei, Zang Li |  |
| 2658 |  |  [AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration](https://aclanthology.org/2025.acl-long.1170/) |  | 0 | Multi-agent systems (MAS) based on large language models (LLMs) have demonstrated significant potential in collaborative problem-solving. However, they still face substantial challenges of low communication efficiency and suboptimal task performance, making the careful design of the agents’... | Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang |  |
| 2659 |  |  [Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States](https://aclanthology.org/2025.acl-long.1171/) |  | 0 | As Large Language Models (LLMs) increasingly participate in human-AI interactions, evaluating their Theory of Mind (ToM) capabilities - particularly their ability to track dynamic mental states - becomes crucial. While existing benchmarks assess basic ToM abilities, they predominantly focus on... | Yang Xiao, Jiashuo Wang, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu |  |
| 2660 |  |  [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language](https://aclanthology.org/2025.acl-long.1172/) |  | 0 | Instruction-following capability has become a major ability to be evaluated for Large Language Models. However, existing datasets, such as IFEval, are either predominantly monolingual and centered on English or simply machine translated to other languages, limiting their applicability in... | Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Ruizhe Li, Jiahui Geng, Qing Li, Yu Tong, Longyue Wang, Weihua Luo, Kaifu Zhang |  |
| 2661 |  |  [Representation Bending for Large Language Model Safety](https://aclanthology.org/2025.acl-long.1173/) |  | 0 | Large Language Models (LLMs) have emerged as powerful tools, but their inherent safety risks – ranging from harmful content generation to broader societal harms – pose significant challenges. These risks can be amplified by the recent adversarial attacks, fine-tuning vulnerabilities, and the... | Ashkan Yousefpour, Taeheon Kim, Ryan Sungmo Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, Harrison Ngan, Youngjae Yu, Jonghyun Choi |  |
| 2662 |  |  [Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations](https://aclanthology.org/2025.acl-long.1174/) |  | 0 | While understanding the knowledge boundaries of LLMs is crucial to prevent hallucination, research on the knowledge boundaries of LLMs has predominantly focused on English. In this work, we present the first study to analyze how LLMs recognize knowledge boundaries across different languages by... | Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong |  |
| 2663 |  |  [Enhancing Retrieval-Augmented Generation via Evidence Tree Search](https://aclanthology.org/2025.acl-long.1175/) |  | 0 | Retrieval-Augmented Generation (RAG) is widely used to enhance Large Language Models (LLMs) by grounding responses in external knowledge. However, in real-world applications, retrievers often return lengthy documents with redundant or irrelevant content, confusing downstream readers. While evidence... | Hao Sun, Hengyi Cai, Yuchen Li, Xuanbo Fan, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin |  |
| 2664 |  |  [HalluLens: LLM Hallucination Benchmark](https://aclanthology.org/2025.acl-long.1176/) |  | 0 | Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as “hallucination.” These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is important for the advancement of LLMs.... | Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung |  |
| 2665 |  |  [DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling](https://aclanthology.org/2025.acl-long.1177/) |  | 0 | To advance personalized applications such as recommendation systems and user behavior prediction, recent research increasingly adopts large language models (LLMs) for human-readable persona modeling. In dynamic real-world scenarios, effective persona modeling necessitates leveraging streaming... | Aili Chen, Chengyu Du, Jiangjie Chen, Jinghan Xu, Yikai Zhang, Siyu Yuan, Zulong Chen, Liangyue Li, Yanghua Xiao |  |
| 2666 |  |  [Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models](https://aclanthology.org/2025.acl-long.1178/) |  | 0 | The significant breakthroughs of Medical Multi-Modal Large Language Models (Med-MLLMs) renovate modern healthcare with robust information synthesis and medical decision support. However, these models are often evaluated on benchmarks that are unsuitable for the Med-MLLMs due to the intricate nature... | Jie Liu, Wenxuan Wang, Yihang Su, Jingyuan Huang, Yudi Zhang, ChengYi Li, Wenting Chen, Xiaohan Xing, KaoJung Chang, Linlin Shen, Michael R. Lyu |  |
| 2667 |  |  [InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning](https://aclanthology.org/2025.acl-long.1179/) |  | 0 | Large multimodal foundation models, particularly in the domains of language and vision, have significantly advanced various tasks, including robotics, autonomous driving, information retrieval, and grounding. However, many of these models perceive objects as indivisible, overlooking the components... | Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia P. Sycara |  |
| 2668 |  |  [GRaMPa: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting Markov Model](https://aclanthology.org/2025.acl-long.1180/) |  | 0 | Stochastically sampling word segmentations from a subword tokeniser, also called subword regularisation, is a known way to increase robustness of language models to out-of-distribution inputs, such as text containing spelling errors. Recent work has observed that usual augmentations that make... | Thomas Bauwens, David Kaczér, Miryam de Lhoneux |  |
| 2669 |  |  [Evaluating the Evaluation of Diversity in Commonsense Generation](https://aclanthology.org/2025.acl-long.1181/) |  | 0 | In commonsense generation, given a set of input concepts, a model must generate a response that is not only commonsense bearing, but also capturing multiple diverse viewpoints. Numerous evaluation metrics based on form- and content-level overlap have been proposed in prior work for evaluating the... | Tianhui Zhang, Bei Peng, Danushka Bollegala |  |
| 2670 |  |  [Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling](https://aclanthology.org/2025.acl-long.1182/) |  | 0 | The spread of fake news on online platforms has long been a pressing concern. Considering this, extensive efforts have been made to develop fake news detectors. However, a major drawback of these models is their relatively low performance—lagging by more than 20%—in identifying \*fake\* news... | Zhao Tong, Yimeng Gu, Huidong Liu, Qiang Liu, Shu Wu, Haichao Shi, XiaoYu Zhang |  |
| 2671 |  |  [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://aclanthology.org/2025.acl-long.1183/) |  | 0 | With the increasing interest in robotic synthesis in the context of organic chemistry, the automated extraction of chemical procedures from literature is critical. However, this task remains challenging due to the inherent ambiguity of chemical language and the high cost of human annotation... | Yu Zhang, Ruijie Yu, Jidong Tian, Feng Zhu, Jiapeng Liu, Xiaokang Yang, Yaohui Jin, Yanyan Xu |  |
| 2672 |  |  [Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception](https://aclanthology.org/2025.acl-long.1184/) |  | 0 | Large language models (LLMs) exhibit impressive performance across diverse tasks but often struggle to accurately gauge their knowledge boundaries, leading to confident yet incorrect responses. This paper explores leveraging LLMs’ internal states to enhance their perception of knowledge boundaries... | Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, Baolong Bi, Xueqi Cheng |  |
| 2673 |  |  [ALGEN: Few-shot Inversion Attacks on Textual Embeddings via Cross-Model Alignment and Generation](https://aclanthology.org/2025.acl-long.1185/) |  | 0 | With the growing popularity of Large Language Models (LLMs) and vector databases, private textual data is increasingly processed and stored as numerical embeddings. However, recent studies have proven that such embeddings are vulnerable to inversion attacks, where original text is reconstructed to... | Yiyi Chen, Qiongkai Xu, Johannes Bjerva |  |
| 2674 |  |  [Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains](https://aclanthology.org/2025.acl-long.1186/) |  | 0 | Knowledge Graphs (KGs) can serve as reliable knowledge sources for question answering (QA) due to their structured representation of knowledge. Existing research on the utilization of KG for large language models (LLMs) prevalently relies on subgraph retriever or iterative prompting, overlooking... | Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James R. Glass, Helen M. Meng |  |
| 2675 |  |  [STaR-SQL: Self-Taught Reasoner for Text-to-SQL](https://aclanthology.org/2025.acl-long.1187/) |  | 0 | Generating step-by-step “chain-of-thought” rationales has proven effective for improving the performance of large language models on complex reasoning tasks. However, applying such techniques to structured tasks, such as text-to-SQL, remains largely unexplored. In this paper, we introduce... | Mingqian He, Yongliang Shen, Wenqi Zhang, Qiuying Peng, Jun Wang, Weiming Lu |  |
| 2676 |  |  [Fairness Beyond Performance: Revealing Reliability Disparities Across Groups in Legal NLP](https://aclanthology.org/2025.acl-long.1188/) |  | 0 | Fairness in NLP must extend beyond performance parity to encompass equitable reliability across groups. This study exposes a criticalblind spot: models often make less reliable or overconfident predictions for marginalized groups, even when overall performance appearsfair. Using the FairLex... | T. Y. S. S. Santosh, Irtiza Chowdhury |  |
| 2677 |  |  [Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection](https://aclanthology.org/2025.acl-long.1189/) |  | 0 | Large language models (LLMs) have shown great potential across various industries due to their remarkable ability to generalize through instruction tuning. However, the limited availability of domain-specific data significantly hampers their performance on specialized tasks. While existing methods... | Yang Zhao, Li Du, Xiao Ding, Yangou Ouyang, Hepeng Wang, Kai Xiong, Jinglong Gao, Zhouhao Sun, Dongliang Xu, Qing Yang, Dongchen Li, Bing Qin, Ting Liu |  |
| 2678 |  |  [FastMCTS: A Simple Sampling Strategy for Data Synthesis](https://aclanthology.org/2025.acl-long.1190/) |  | 0 | Synthetic high-quality multi-step reasoning data can significantly enhance the performance of large language models on various tasks. However, most existing methods rely on rejection sampling, which generates trajectories independently and suffers from inefficiency and imbalanced sampling across... | Peiji Li, Kai Lv, Yunfan Shao, Yichuan Ma, Linyang Li, Xiaoqing Zheng, Xipeng Qiu, Qipeng Guo |  |
| 2679 |  |  [Dialogue-RAG: Enhancing Retrieval for LLMs via Node-Linking Utterance Rewriting](https://aclanthology.org/2025.acl-long.1191/) |  | 0 | Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) methods have demonstrated significant potential on tasks across multiple domains. However, ellipses and coreferences, as common phenomena in dialogue scenes, pose challenges to LLMs’ understanding and RAG’s retrieval accuracy.... | Qiwei Li, Teng Xiao, Zuchao Li, Ping Wang, Mengjia Shen, Hai Zhao |  |
| 2680 |  |  [Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent](https://aclanthology.org/2025.acl-long.1192/) |  | 0 | This paper argues that the relationship between lexical identity and prosody—one well-studied parameter of linguistic variation—can be characterized using information theory. We predict that languages that use prosody to make lexical distinctions should exhibit a higher mutual information between... | Ethan Wilcox, Cui Ding, Giovanni Acampa, Tiago Pimentel, Alex Warstadt, Tamar I. Regev |  |
| 2681 |  |  [Evaluating LLMs for Portuguese Sentence Simplification with Linguistic Insights](https://aclanthology.org/2025.acl-long.1193/) |  | 0 | Sentence simplification (SS) focuses on adapting sentences to enhance their readability and accessibility. While large language models (LLMs) match task-specific baselines in English SS, their performance in Portuguese remains underexplored. This paper presents a comprehensive performance... | Arthur Mariano Rocha De Azevedo Scalercio, Elvis A. De Souza, Maria José Bocorny Finatto, Aline Paes |  |
| 2682 |  |  [LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models](https://aclanthology.org/2025.acl-long.1194/) |  | 0 | State space models (SSMs), such as Mamba, have emerged as an efficient alternative to transformers for long-context sequence modeling. However, despite their growing adoption, SSMs lack the interpretability tools that have been crucial for understanding and improving attention-based architectures.... | Hugo Pitorro, Marcos Vinícius Treviso |  |
| 2683 |  |  [Improving Low-Resource Morphological Inflection via Self-Supervised Objectives](https://aclanthology.org/2025.acl-long.1195/) |  | 0 | Self-supervised objectives have driven major advances in NLP by leveraging large-scale unlabeled data, but such resources are scarce for many of the world’s languages. Surprisingly, they have not been explored much for character-level tasks, where smaller amounts of data have the potential to be... | Adam Wiemerslage, Katharina von der Wense |  |
| 2684 |  |  [Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation](https://aclanthology.org/2025.acl-long.1196/) |  | 0 | In this work, we investigate an important task named instruction-following text embedding, which generates dynamic text embeddings that adapt to user instructions, highlighting specific attributes of text. Despite recent advancements, existing approaches suffer from significant computational... | Yingchaojie Feng, Yiqun Sun, Yandong Sun, Minfeng Zhu, Qiang Huang, Anthony Kum Hoe Tung, Wei Chen |  |
| 2685 |  |  [BOOKCOREF: Coreference Resolution at Book Scale](https://aclanthology.org/2025.acl-long.1197/) |  | 0 | Coreference Resolution systems are typically evaluated on benchmarks containing small- to medium-scale documents.When it comes to evaluating long texts, however, existing benchmarks, such as LitBank, remain limited in length and do not adequately assess system capabilities at the book scale, i.e.,... | Giuliano Martinelli, Tommaso Bonomo, PereLluís Huguet Cabot, Roberto Navigli |  |
| 2686 |  |  [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://aclanthology.org/2025.acl-long.1198/) |  | 0 | Vision-language retrieval-augmented generation (RAG) has become an effective approach for tackling Knowledge-Based Visual Question Answering (KB-VQA), which requires external knowledge beyond the visual content presented in images. The effectiveness of Vision-language RAG systems hinges on... | Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian |  |
| 2687 |  |  [Alleviating Hallucinations from Knowledge Misalignment in Large Language Models via Selective Abstention Learning](https://aclanthology.org/2025.acl-long.1199/) |  | 0 | Large language models (LLMs) are known to suffer from severe hallucination issues. One of the main causes lies in the knowledge misalignment between the pre-training stage and the supervised fine-tuning stage. The unfamiliar knowledge encountered during fine-tuning may encourage LLMs to generate... | Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yuxuan Gu, Yangfan Ye, Liang Zhao, Weihong Zhong, Baoxin Wang, Dayong Wu, Guoping Hu, Lingpeng Kong, Tong Xiao, Ting Liu, Bing Qin |  |
| 2688 |  |  [Retrospective Learning from Interactions](https://aclanthology.org/2025.acl-long.1200/) |  | 0 | Multi-turn interactions between large language models (LLMs) and users naturally include implicit feedback signals. If an LLM responds in an unexpected way to an instruction, the user is likely to signal it by rephrasing the request, expressing frustration, or pivoting to an alternative task. Such... | Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi |  |
| 2689 |  |  [Personalized Generation In Large Model Era: A Survey](https://aclanthology.org/2025.acl-long.1201/) |  | 0 | In the era of large models, content generation is gradually shifting to Personalized Generation (PGen), tailoring content to individual preferences and needs. This paper presents the first comprehensive survey on PGen, investigating existing research in this rapidly growing field. We conceptualize... | Yiyan Xu, Jinghao Zhang, Alireza Salemi, Xinting Hu, Wenjie Wang, Fuli Feng, Hamed Zamani, Xiangnan He, TatSeng Chua |  |
| 2690 |  |  [Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning](https://aclanthology.org/2025.acl-long.1202/) |  | 0 | Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external knowledge integration capabilities by explicitly modeling knowledge relationships, thereby improving the factual accuracy and generation quality of Large Language Models (LLMs) in specialized domains. However, existing... | Junqi Gao, Xiang Zou, Ying Ai, Dong Li, Yichen Niu, Biqing Qi, Jianxing Liu |  |
| 2691 |  |  [SOTOPIA-: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents](https://aclanthology.org/2025.acl-long.1203/) |  | 0 | Despite the abundance of prior social strategies possessed by humans, there remains a paucity of research dedicated to their transfer and integration into social agents. Our proposed SOTOPIA-Ω framework aims to address and bridge this gap, with a particular focus on enhancing the social... | Wenyuan Zhang, Tianyun Liu, Mengxiao Song, Xiaodong Li, Tingwen Liu |  |
| 2692 |  |  [Can Language Models Replace Programmers for Coding? REPOCOD Says 'Not Yet'](https://aclanthology.org/2025.acl-long.1204/) |  | 0 | Recently, a number of repository-level code generation benchmarks–such as CoderEval, DevEval, RepoEval, RepoBench, and LongCode-Arena–have emerged to evaluate the capabilities of large language models (LLMs) beyond standalone benchmarks like HumanEval and MBPP. Thus, a natural question is, would... | Shanchao Liang, Nan Jiang, Yiran Hu, Lin Tan |  |
| 2693 |  |  [Leveraging In-Context Learning for Political Bias Testing of LLMs](https://aclanthology.org/2025.acl-long.1205/) |  | 0 | A growing body of work has been querying LLMs with political questions to evaluate their potential biases. However, this probing method has limited stability, making comparisons between models unreliable. In this paper, we argue that LLMs need more context. We propose a new probing task,... | Patrick Haller, Jannis Vamvas, Rico Sennrich, Lena Ann Jäger |  |
| 2694 |  |  [ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting](https://aclanthology.org/2025.acl-long.1206/) |  | 0 | Contract clause retrieval is foundational to contract drafting because lawyers rarely draft contracts from scratch; instead, they locate and revise the most relevant precedent clauses. We introduce the Atticus Clause Retrieval Dataset (ACORD), the first expert-annotated benchmark specifically... | Steven H. Wang, Maksim Zubkov, Kexin Fan, Sarah Harrell, Yuyang Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer |  |
| 2695 |  |  [LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts](https://aclanthology.org/2025.acl-long.1207/) |  | 0 | Safety concerns in large language models (LLMs) have gained significant attention due to their exposure to potentially harmful data during pre-training. In this paper, we identify a new safety vulnerability in LLMs: their susceptibility to natural distribution shifts between attack prompts and... | Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao |  |
| 2696 |  |  [WAFFLE: Fine-tuning Multi-Modal Model for Automated Front-End Development](https://aclanthology.org/2025.acl-long.1208/) |  | 0 | Web development involves turning UI designs into functional webpages, which can be difficult for both beginners and experienced developers due to the complexity of HTML’s hierarchical structures and styles. While Large Language Models (LLMs) have shown promise in generating source code, two major... | Shanchao Liang, Nan Jiang, Shangshu Qian, Lin Tan |  |
| 2697 |  |  [Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes](https://aclanthology.org/2025.acl-long.1209/) |  | 0 | Math reasoning is an active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence and has implications in several domains, including math education. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill... | Bryan R. Christ, Zachary Gottesman, Jonathan Kropko, Thomas Hartvigsen |  |
| 2698 |  |  [Multiple LLM Agents Debate for Equitable Cultural Alignment](https://aclanthology.org/2025.acl-long.1210/) |  | 0 | Large Language Models (LLMs) need to adapt their predictions to diverse cultural contexts to benefit diverse communities across the world. While previous efforts have focused on single-LLM, single-turn approaches, we propose to exploit the complementary strengths of multiple LLMs to promote... | Dayeon Ki, Rachel Rudinger, Tianyi Zhou, Marine Carpuat |  |
| 2699 |  |  [RefreshKV: Updating Small KV Cache During Long-form Generation](https://aclanthology.org/2025.acl-long.1211/) |  | 0 | Generating long sequences of tokens given a long-context input is a very compute-intensive inference scenario for large language models (LLMs). One prominent inference speed-up approach is constructing a smaller key-value (KV) cache, relieving LLMs from computing attention over a long sequence of... | Fangyuan Xu, Tanya Goyal, Eunsol Choi |  |
| 2700 |  |  [SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings](https://aclanthology.org/2025.acl-long.1212/) |  | 0 | Multimodal Large Language Models (MLLMs) have serious security vulnerabilities. While safety alignment using multimodal datasets consisting of text and data of additional modalities can effectively enhance MLLM’s security, it is costly to construct these datasets. Existing low-resource security... | Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng |  |
| 2701 |  |  [Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective](https://aclanthology.org/2025.acl-long.1213/) |  | 0 | Large Language Models (LLMs) have made notable progress in mathematical reasoning, yet they often rely on single-paradigm reasoning that limits their effectiveness across diverse tasks. In this paper, we introduce Chain-of-Reasoning (CoR), a novel unified framework that integrates multiple... | Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Hassan Awadalla, Junjie Wang, Yujiu Yang, Furu Wei |  |
| 2702 |  |  [Language Models Grow Less Humanlike beyond Phase Transition](https://aclanthology.org/2025.acl-long.1214/) |  | 0 | LMs’ alignment with human reading behavior (i.e. psychometric predictive power; PPP) is known to improve during pretraining up to a tipping point, beyond which it either plateaus or degrades. Various factors, such as word frequency, recency bias in attention, and context size, have been theorized... | Tatsuya Aoyama, Ethan Wilcox |  |
| 2703 |  |  [PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation](https://aclanthology.org/2025.acl-long.1215/) |  | 0 | Disinformation detection is a key aspect of media literacy. Psychological studies have shown that knowledge of persuasive fallacies helps individuals detect disinformation. Inspired by these findings, we experimented with large language models (LLMs) to test whether infusing persuasion knowledge... | Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino |  |
| 2704 |  |  [Coordinating Chaos: A Structured Review of Linguistic Coordination Methodologies](https://aclanthology.org/2025.acl-long.1216/) |  | 0 | Linguistic coordination—a phenomenon where conversation partners end up having similar patterns of language use—has been established across a variety of contexts and for multiple linguistic features. However, the study of language coordination has been accompanied by a diverse and inconsistently... | Benjamin Roger Litterer, David Jurgens, Dallas Card |  |
| 2705 |  |  [iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News](https://aclanthology.org/2025.acl-long.1217/) |  | 0 | Understanding how individuals perceive and react to information is fundamental for advancing social and behavioral sciences and developing human-centered AI systems. Current approaches often lack the granular data needed to model these personalized responses, relying instead on aggregated labels... | Tiancheng Hu, Nigel Collier |  |
| 2706 |  |  [Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures](https://aclanthology.org/2025.acl-long.1218/) |  | 0 | Gestures are an integral part of non-verbal communication, with meanings that vary across cultures, and misinterpretations that can have serious social and diplomatic consequences. As AI systems become more integrated into global applications, ensuring they do not inadvertently perpetuate cultural... | Akhila Yerukola, Saadia Gabriel, Nanyun Peng, Maarten Sap |  |
| 2707 |  |  [500xCompressor: Generalized Prompt Compression for Large Language Models](https://aclanthology.org/2025.acl-long.1219/) |  | 0 | Prompt compression is important for large language models (LLMs) to increase inference speed, reduce costs, and improve user experience. However, current methods face challenges such as low compression ratios and potential training-test overlap during evaluation. To address these issues, we propose... | Zongqian Li, Yixuan Su, Nigel Collier |  |
| 2708 |  |  [Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models](https://aclanthology.org/2025.acl-long.1220/) |  | 0 | Language models (LMs) rely on their parametric knowledge augmented with relevant contextual knowledge for certain tasks, such as question answering. However, the contextual knowledge can contain private information that may be leaked when answering queries, and estimating this privacy leakage is... | James Flemings, Bo Jiang, Wanrong Zhang, Zafar Takhirov, Murali Annavaram |  |
| 2709 |  |  [Document-Level Event-Argument Data Augmentation for Challenging Role Types](https://aclanthology.org/2025.acl-long.1221/) |  | 0 | Event Argument Extraction (EAE) is a daunting information extraction problem — with significant limitations in few-shot cross-domain (FSCD) settings. A common solution to FSCD modeling is data augmentation. Unfortunately, existing augmentation methods are not well-suited to a variety of real-world... | Joseph Gatto, Omar Sharif, Parker Seegmiller, Sarah Masud Preum |  |
| 2710 |  |  [Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus](https://aclanthology.org/2025.acl-long.1222/) |  | 0 | Podcasts provide highly diverse content to a massive listener base through a unique on-demand modality. However, limited data has prevented large-scale computational analysis of the podcast ecosystem. To fill this gap, we introduce a massive dataset of over 1.1M podcast transcripts that is largely... | Benjamin Roger Litterer, David Jurgens, Dallas Card |  |
| 2711 |  |  [Unravelling the Logic: Investigating the Generalisation of Transformers in Numerical Satisfiability Problems](https://aclanthology.org/2025.acl-long.1223/) |  | 0 | Transformer models have achieved remarkable performance in many formal reasoning tasks. Nonetheless, the extent of their comprehension pertaining to logical semantics and rules of inference remains somewhat uncertain. Evaluating such understanding necessitates a rigorous examination of these... | Tharindu Madusanka, Marco Valentino, Iqra Zahid, Ian PrattHartmann, Riza BatistaNavarro |  |
| 2712 |  |  [The Nature of NLP: Analyzing Contributions in NLP Papers](https://aclanthology.org/2025.acl-long.1224/) |  | 0 | Natural Language Processing (NLP) is an established and dynamic field. Despite this, what constitutes NLP research remains debated. In this work, we address the question by quantitatively examining NLP research papers. We propose a taxonomy of research contributions and introduce... | Aniket Pramanick, Yufang Hou, Saif M. Mohammad, Iryna Gurevych |  |
| 2713 |  |  [\mathttGeLLM³O: Generalizing Large Language Models for Multi-property Molecule Optimization](https://aclanthology.org/2025.acl-long.1225/) |  | 0 | Despite recent advancements, most computational methods for molecule optimization are constrained to single- or double-property optimization tasks and suffer from poor scalability and generalizability to novel optimization tasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable... | Vishal Dey, Xiao Hu, Xia Ning |  |
| 2714 |  |  [Follow-up Question Generation For Enhanced Patient-Provider Conversations](https://aclanthology.org/2025.acl-long.1226/) |  | 0 | Follow-up question generation is an essential feature of dialogue systems as it can reduce conversational ambiguity and enhance modeling complex interactions. Conversational contexts often pose core NLP challenges such as (i) extracting relevant information buried in fragmented data sources, and... | Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Inas S. Khayal, Sarah DeLozier, Sarah Masud Preum |  |
| 2715 |  |  [Unveiling Privacy Risks in LLM Agent Memory](https://aclanthology.org/2025.acl-long.1227/) |  | 0 | Large Language Model (LLM) agents have become increasingly prevalent across various real-world applications. They enhance decision-making by storing private user-agent interactions in the memory module for demonstrations, introducing new privacy risks for LLM agents. In this work, we systematically... | Bo Wang, Weiyi He, Shenglai Zeng, Zhen Xiang, Yue Xing, Jiliang Tang, Pengfei He |  |
| 2716 |  |  [Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation](https://aclanthology.org/2025.acl-long.1228/) |  | 0 | Quality estimation (QE)—the automatic assessment of translation quality—has recently become crucial across several stages of the translation pipeline, from data curation to training and decoding. While QE metrics have been optimized to align with human judgments, whether they encode social biases... | Emmanouil Zaranis, Giuseppe Attanasio, Sweta Agrawal, André F. T. Martins |  |
| 2717 |  |  [Language Constrained Multimodal Hyper Adapter For Many-to-Many Multimodal Summarization](https://aclanthology.org/2025.acl-long.1229/) |  | 0 | Multimodal summarization (MS) combines text and visuals to generate summaries. Recently, many-to-many multimodal summarization (M3S) garnered interest as it enables a unified model for multilingual and cross-lingual MS. Existing methods have made progress by facilitating the transfer of common... | Nayu Liu, Fanglong Yao, Haoran Luo, Yong Yang, Chen Tang, Bo Lv |  |
| 2718 |  |  [PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models](https://aclanthology.org/2025.acl-long.1230/) |  | 0 | Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess... | Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng |  |
| 2719 |  |  [Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets](https://aclanthology.org/2025.acl-long.1231/) |  | 0 | This paper develops an ensemble method for fine-tuning a language model to multiple datasets. Existing methods, such as quantized LoRA (QLoRA), are efficient when adapting to a single dataset. When training on multiple datasets of different tasks, a common setup in practice, it remains unclear how... | Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang |  |
| 2720 |  |  [Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles](https://aclanthology.org/2025.acl-long.1232/) |  | 0 | We introduce the concept of the self-referencing causal cycle (abbreviated ReCall )—a mechanism that enables large language models (LLMs) to bypass the limitations of unidirectional causality, which underlies a phenomenon known as the reversal curse. When an LLM is prompted with sequential data, it... | Munachiso Nwadike, Zangir Iklassov, Toluwani Aremu, Tatsuya Hiraoka, Benjamin Heinzerling, Velibor Bojkovic, Hilal AlQuabeh, Martin Takác, Kentaro Inui |  |
| 2721 |  |  [Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models](https://aclanthology.org/2025.acl-long.1233/) |  | 0 | Jailbreaking in Large Language Models (LLMs) is a major security concern as it can deceive LLMs into generating harmful text. However, understanding of how jailbreaking works remains limited, hindering the development of effective defense strategies. To address this issue, we conduct a large-scale... | Lang Gao, Jiahui Geng, Xiangliang Zhang, Preslav Nakov, Xiuying Chen |  |
| 2722 |  |  [ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution](https://aclanthology.org/2025.acl-long.1234/) |  | 0 | This work evaluates the potential of large language models (LLMs) to power digital assistants capable of complex action execution. Such assistants rely on pre-trained programming knowledge to execute multi-step goals by composing objects and functions defined in assistant libraries into action... | Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, BoHsiang Tseng, Peter Boothroyd, Héctor Martínez Alonso, Diarmuid Ó Séaghdha, Anders Johannsen |  |
| 2723 |  |  [ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework](https://aclanthology.org/2025.acl-long.1235/) |  | 0 | Empathetic response generation necessitates the integration of emotional and intentional dynamics to foster meaningful interactions. Existing research either neglects the intricate interplay between emotion and intent, leading to suboptimal controllability of empathy, or resorts to large language... | Jiahao Yuan, Zixiang Di, Zhiqing Cui, Guisong Yang, Usman Naseem |  |
| 2724 |  |  [SARA: Salience-Aware Reinforced Adaptive Decoding for Large Language Models in Abstractive Summarization](https://aclanthology.org/2025.acl-long.1236/) |  | 0 | LLMs have improved the fluency and informativeness of abstractive summarization but remain prone to hallucinations, where generated content deviates from the source document. Recent PMI decoding strategies mitigate over-reliance on prior knowledge by comparing output probabilities with and without... | Nayu Liu, Junnan Zhu, Yiming Ma, Zhicong Lu, Wenlei Xu, Yong Yang, Jiang Zhong, Kaiwen Wei |  |
| 2725 |  |  [Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation](https://aclanthology.org/2025.acl-long.1237/) |  | 0 | Embedding models play a crucial role in machine learning. However, the continuous development of new models presents a major challenge: migrating to a potentially superior model often requires the computationally expensive process of re-embedding entire datasets—without any guarantee of performance... | Jinsung Yoon, Sercan Ö. Arik |  |
| 2726 |  |  [Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge](https://aclanthology.org/2025.acl-long.1238/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive performance in biomedical relation extraction, even in zero-shot scenarios. However, evaluating LLMs in this task remains challenging due to their ability to generate human-like text, often producing synonyms or abbreviations of... | Md. Tahmid Rahman Laskar, Israt Jahan, Elham Dolatabadi, Chun Peng, Enamul Hoque, Jimmy Huang |  |
| 2727 |  |  [Answering Complex Geographic Questions by Adaptive Reasoning with Visual Context and External Commonsense Knowledge](https://aclanthology.org/2025.acl-long.1239/) |  | 0 | This paper focuses on a new task of answering geographic reasoning questions based on the given image (called GeoVQA). Unlike traditional VQA tasks, GeoVQA asks for details about the image-related culture, landscape, etc. This requires not only the identification of the objects in the image, their... | Fan Li, Jianxing Yu, Jielong Tang, Wenqing Chen, Hanjiang Lai, Yanghui Rao, Jian Yin |  |
| 2728 |  |  [Safety Alignment via Constrained Knowledge Unlearning](https://aclanthology.org/2025.acl-long.1240/) |  | 0 | Despite significant progress in safety alignment, large language models (LLMs) remain susceptible to jailbreak attacks. Existing defense mechanisms have not fully deleted harmful knowledge in LLMs, which allows such attacks to bypass safeguards and produce harmful outputs. To address this... | Zesheng Shi, Yucheng Zhou, Jing Li, Yuxin Jin, Yu Li, Daojing He, Fangming Liu, Saleh Alharbi, Jun Yu, Min Zhang |  |
| 2729 |  |  [Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities](https://aclanthology.org/2025.acl-long.1241/) |  | 0 | Vision-language Models (VLMs) have emerged as general-purpose tools for addressing a variety of complex computer vision problems. Such models have been shown to be highly capable, but, at the same time, lacking some basic visual understanding skills. In this paper, we set out to understand the... | Shivam Chandhok, WanCyuan Fan, Vered Shwartz, Vineeth N. Balasubramanian, Leonid Sigal |  |
| 2730 |  |  [EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models](https://aclanthology.org/2025.acl-long.1242/) |  | 0 | Large Vision-Language Models (LVLMs) have achieved remarkable success, yet their significant computational demands hinder practicaldeployment. While efforts to improve LVLM efficiency are growing, existing methods lack comprehensive evaluation across diverse backbones, benchmarks, and metrics. In... | Zekun Wang, Minghua Ma, Zexin Wang, Rongchuan Mu, Liping Shan, Ming Liu, Bing Qin |  |
| 2731 |  |  [Pre-Training Curriculum for Multi-Token Prediction in Language Models](https://aclanthology.org/2025.acl-long.1243/) |  | 0 | Multi-token prediction (MTP) is a recently proposed pre-training objective for language models. Rather than predicting only the next token (NTP), MTP predicts the next \*k\* tokens at each prediction step, using multiple prediction heads. MTP has shown promise in improving downstream performance,... | Ansar Aynetdinov, Alan Akbik |  |
| 2732 |  |  [Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks](https://aclanthology.org/2025.acl-long.1244/) |  | 0 | Large language models excel at problem-solving but often struggle with complex reasoning and factual accuracy. While chain-of-thought and retrieval-augmented generation help break down problems and retrieve knowledge, they still falter on challenging tasks like competitive programming due to... | Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing |  |
| 2733 |  |  [On Many-Shot In-Context Learning for Long-Context Evaluation](https://aclanthology.org/2025.acl-long.1245/) |  | 0 | Many-shot in-context learning (ICL) has emerged as a unique setup to both utilize and test the ability of large language models to handle long context. This paper delves into long-context language model (LCLM) evaluation through many-shot ICL. We first ask: what types of ICL tasks benefit from... | Kaijian Zou, Muhammad Khalifa, Lu Wang |  |
| 2734 |  |  [HelpSteer3: Human-Annotated Feedback and Edit Data to Empower Inference-Time Scaling in Open-Ended General-Domain Tasks](https://aclanthology.org/2025.acl-long.1246/) |  | 0 | Inference-Time Scaling has been critical to the success of recent models such as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for inference-time scaling require tasks to have answers that can be verified, limiting their application to domains such as math, coding and... | Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, HooChang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev |  |
| 2735 |  |  [CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs' Cultural Knowledge Through Human-AI Red-Teaming](https://aclanthology.org/2025.acl-long.1247/) |  | 0 | Robust, diverse, and challenging cultural knowledge benchmarks are essential for measuring our progress towards making LMs that are helpful across diverse cultures. We introduce CulturalBench: a set of 1,696 human-written and human-verified questions to assess LMs’ cultural knowledge, covering 45... | Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, Yejin Choi |  |
| 2736 |  |  [Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning](https://aclanthology.org/2025.acl-long.1248/) |  | 0 | Post-training of Large Language Models often involves a pipeline of Supervised Finetuning (SFT) followed by Preference Finetuning (PFT) using methods like Direct Preference Optimization. Both stages require annotated data that are very different in structure and costs. We study how to optimally... | Mohit Raghavendra, Junmo Kang, Alan Ritter |  |
| 2737 |  |  [All That Glitters is Not Novel: Plagiarism in AI Generated Research](https://aclanthology.org/2025.acl-long.1249/) |  | 0 | Automating scientific research is considered the final frontier of science. Recently, several papers claim autonomous research agents can generate novel research ideas. Amidst the prevailing optimism, we document a critical concern: a considerable fraction of such research documents are smartly... | Tarun Gupta, Danish Pruthi |  |
| 2738 |  |  [Writing Like the Best: Exemplar-Based Expository Text Generation](https://aclanthology.org/2025.acl-long.1250/) |  | 0 | We introduce the Exemplar-Based Expository Text Generation task, aiming to generate an expository text on a new topic using an exemplar on a similar topic. Current methods fall short due to their reliance on extensive exemplar data, difficulty in adapting topic-specific content, and issues with... | Yuxiang Liu, Kevin ChenChuan Chang |  |
| 2739 |  |  [Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach](https://aclanthology.org/2025.acl-long.1251/) |  | 0 | Temporal information extraction from unstructured text is essential for contextualizing events and deriving actionable insights, particularly in the medical domain. We address the task of extracting clinical events and their temporal relations using the well-studied I2B2 2012 Temporal Relations... | Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio |  |
| 2740 |  |  [Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots](https://aclanthology.org/2025.acl-long.1252/) |  | 0 | As chatbots become integral to daily life, personalizing systems is key for fostering trust, engagement, and inclusivity. This study examines how linguistic similarity affects chatbot performance, focusing on integrating African American English (AAE) into virtual agents to better serve the African... | Sarah E. Finch, Ellie S. Paek, Ikseon Choi, Jinho D. Choi |  |
| 2741 |  |  [Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection](https://aclanthology.org/2025.acl-long.1253/) |  | 0 | Alzheimer’s Disease (AD) is a progressive neurodegenerative disorder that leads to dementia, and early intervention can greatly benefit from analyzing linguistic abnormalities. In this work, we explore the potential of Large Language Models as health assistants for AD diagnosis from... | Chuyuan Li, Raymond Li, Thalia Shoshana Field, Giuseppe Carenini |  |
| 2742 |  |  [Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback](https://aclanthology.org/2025.acl-long.1254/) |  | 0 | Can LLMs provide support to creative writers by giving meaningful writing feedback? In this paper, we explore the challenges and limitations of model-generated writing feedback by defining a new task, dataset, and evaluation frameworks. To study model performance in a controlled manner, we present... | Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata |  |
| 2743 |  |  [Language Fusion for Parameter-Efficient Cross-lingual Transfer](https://aclanthology.org/2025.acl-long.1255/) |  | 0 | Limited availability of multilingual text corpora for training language models often leads to poor performance on downstream tasks due to undertrained representation spaces for languages other than English. This ‘under-representation’ has motivated recent cross-lingual transfer methods to leverage... | Philipp Borchert, Ivan Vulic, MarieFrancine Moens, Jochen De Weerdt |  |
| 2744 |  |  [Culture is Not Trivia: Sociocultural Theory for Cultural NLP](https://aclanthology.org/2025.acl-long.1256/) |  | 0 | The field of cultural NLP has recently experienced rapid growth, driven by a pressing need to ensure that language technologies are effective and safe across a pluralistic user base. This work has largely progressed without a shared conception of culture, instead choosing to rely on a wide array of... | Naitian Zhou, David Bamman, Isaac L. Bleaman |  |
| 2745 |  |  [AAD-LLM: Neural Attention-Driven Auditory Scene Understanding](https://aclanthology.org/2025.acl-long.1257/) |  | 0 | Auditory foundation models, including auditory large language models (LLMs), process all sound inputs equally, independent of listener perception. However, human auditory perception is inherently selective: listeners focus on specific speakers while ignoring others in complex auditory scenes.... | Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh D. Mehta, Guy M. McKhann II, Daniel Friedman, Adeen Flinker, Nima Mesgarani |  |
| 2746 |  |  [Do Language Models Have Semantics? On the Five Standard Positions](https://aclanthology.org/2025.acl-long.1258/) |  | 0 | We identify five positions on whether large language models (LLMs) and chatbots can be said to exhibit semantic understanding. These positions differ in whether they attribute semantics to LLMs and/or chatbots trained on feedback, what kind of semantics they attribute (inferential or referential),... | Anders Søgaard |  |
| 2747 |  |  [Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems](https://aclanthology.org/2025.acl-long.1259/) |  | 0 | As text generation systems’ outputs are increasingly anthropomorphic—perceived as human-like—scholars have also increasingly raised concerns about how such outputs can lead to harmful outcomes, such as users over-relying or developing emotional dependence on these systems. How to intervene on such... | Myra Cheng, Su Lin Blodgett, Alicia DeVrio, Lisa Egede, Alexandra Olteanu |  |
| 2748 |  |  [Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users](https://aclanthology.org/2025.acl-long.1260/) |  | 0 | This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models,... | Antonia Karamolegkou, Malvina Nikandrou, Georgios Pantazopoulos, Danae Sanchez Villegas, Phillip Rust, Ruchira Dhar, Daniel Hershcovich, Anders Søgaard |  |
| 2749 |  |  [HumT DumT: Measuring and controlling human-like language in LLMs](https://aclanthology.org/2025.acl-long.1261/) |  | 0 | Should LLMs generate language that makes them seem human? Human-like language might improve user experience, but might also lead to deception, overreliance, and stereotyping. Assessing these potential impacts requires a systematic way to measure human-like tone in LLM outputs. We introduce HumT and... | Myra Cheng, Sunny Yu, Dan Jurafsky |  |
| 2750 |  |  [ChatBench: From Static Benchmarks to Human-AI Evaluation](https://aclanthology.org/2025.acl-long.1262/) |  | 0 | With the rapid adoption of LLM-based chat-bots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e., “AI-alone”). Here, we design and conduct a user study to convert MMLU questions... | Serina Chang, Ashton Anderson, Jake M. Hofman |  |
| 2751 |  |  [Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences](https://aclanthology.org/2025.acl-long.1263/) |  | 0 | LLM generated code often contains security issues. We address two key challenges in improving secure code generation. First, obtaining high quality training data covering a broad set of security issues is critical. To address this, we introduce a method for distilling a preference dataset of... | Mohammad Saqib Hasan, Saikat Chakraborty, Santu Karmaker, Niranjan Balasubramanian |  |
| 2752 |  |  [Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs](https://aclanthology.org/2025.acl-long.1264/) |  | 0 | Do language models (LMs) offer insights into human language learning? A common argument against this idea is that because their architecture and training paradigm are so vastly different from humans, LMs can learn arbitrary inputs as easily as natural languages. We test this claim by training LMs... | Xiulin Yang, Tatsuya Aoyama, Yuekun Yao, Ethan Wilcox |  |
| 2753 |  |  [Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat](https://aclanthology.org/2025.acl-long.1265/) |  | 0 | Evaluating large language model (LLM) is a complex task. Pairwise ranking has emerged as state-of-the-art method to evaluate human preferences by having humans compare pairs of LLM outputs based on predefined criteria, enabling ranking across multiple LLMs by aggregating pairwise results through... | Roland Daynauth, Christopher Clarke, Krisztián Flautner, Lingjia Tang, Jason Mars |  |
| 2754 |  |  [LLM Agents Making Agent Tools](https://aclanthology.org/2025.acl-long.1266/) |  | 0 | Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains... | Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelovic, Jakob Nikolas Kather |  |
| 2755 |  |  [CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World](https://aclanthology.org/2025.acl-long.1267/) |  | 0 | Following instructions in real-world conditions requires a capability to adapt to the world’s volatility and entanglement: the environment is dynamic and unpredictable, instructions can be linguistically complex with diverse vocabulary, and the number of possible goals an agent may encounter is... | Zoya Volovikova, Gregory Gorbov, Petr Kuderov, Aleksandr Panov, Alexey Skrynnik |  |
| 2756 |  |  [QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation](https://aclanthology.org/2025.acl-long.1268/) |  | 0 | While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators... | Bang Nguyen, Tingting Du, Mengxia Yu, Lawrence Angrave, Meng Jiang |  |
| 2757 |  |  [Causal Graph based Event Reasoning using Semantic Relation Experts](https://aclanthology.org/2025.acl-long.1269/) |  | 0 | Understanding how events in a scenario causally connect with each other is important for effectively modeling and reasoning about events. But event reasoning remains a difficult challenge, and despite recent advances, Large Language Models (LLMs) still struggle to accurately identify causal... | Mahnaz Koupaee, Xueying Bai, Mudan Chen, Greg Durrett, Nathanael Chambers, Niranjan Balasubramanian |  |
| 2758 |  |  [LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning](https://aclanthology.org/2025.acl-long.1270/) |  | 0 | In this paper, we propose a new data synthesis method called LogicPro, which leverages LeetCode-style algorithm Problems and their corresponding Program solutions to synthesize Complex Logical Reasoning data in text format. First, we synthesize complex reasoning problems through source algorithm... | Jin Jiang, Yuchen Yan, Yang Liu, Jianing Wang, Shuai Peng, Xunliang Cai, Yixin Cao, Mengdi Zhang, Liangcai Gao |  |
| 2759 |  |  [Do LLMs Understand Dialogues? A Case Study on Dialogue Acts](https://aclanthology.org/2025.acl-long.1271/) |  | 0 | Recent advancements in NLP, largely driven by Large Language Models (LLMs), have significantly improved performance on an array of tasks. However, Dialogue Act (DA) classification remains challenging, particularly in the fine-grained 50-class, multiparty setting. This paper investigates the root... | Ayesha Qamar, Jonathan Tong, Ruihong Huang |  |
| 2760 |  |  [Research Borderlands: Analysing Writing Across Research Cultures](https://aclanthology.org/2025.acl-long.1272/) |  | 0 | Improving cultural competence of language technologies is important. However most recent works rarely engage with the communities they study, and instead rely on synthetic setups and imperfect proxies of culture. In this work, we take a human-centered approach to discover and measure language-based... | Shaily Bhatt, Tal August, Maria Antoniak |  |
| 2761 |  |  [CEAES: Bidirectional Reinforcement Learning Optimization for Consistent and Explainable Essay Assessment](https://aclanthology.org/2025.acl-long.1273/) |  | 0 | Most current automated essay quality assessment systems treat score prediction and feedback generation as separate tasks, overlooking the fact that scores provide a quantitative evaluation of quality, while feedback offers a qualitative assessment. Both aspects reflect essay quality from different... | Xia Li, Wenjing Pan |  |
| 2762 |  |  [DeAL: Decoding-time Alignment for Large Language Models](https://aclanthology.org/2025.acl-long.1274/) |  | 0 | Large Language Models (LLMs) are nowadays expected to generate content aligned with human preferences. Current work focuses on alignment at model training time, through techniques such as Reinforcement Learning with Human Feedback (RLHF). However, it is unclear if such methods are an effective... | James Y. Huang, Sailik Sengupta, Daniele Bonadiman, YiAn Lai, Arshit Gupta, Nikolaos Pappas, Saab Mansour, Katrin Kirchhoff, Dan Roth |  |
| 2763 |  |  [Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors](https://aclanthology.org/2025.acl-long.1275/) |  | 0 | Metaphors are pervasive in communication, making them crucial for natural language processing (NLP). Previous research on automatic metaphor processing predominantly relies on training data consisting of English samples, which often reflect Western European or North American biases. This cultural... | Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia |  |
| 2764 |  |  [OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction](https://aclanthology.org/2025.acl-long.1276/) |  | 0 | Role-Playing Agents (RPAs), benefiting from large language models, is an emerging interactive AI system that simulates roles or characters with diverse personalities. However, existing methods primarily focus on mimicking dialogues among roles in textual form, neglecting the role’s voice traits... | Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, TingEn Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li |  |
| 2765 |  |  [Mixtures of In-Context Learners](https://aclanthology.org/2025.acl-long.1277/) |  | 0 | In-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters; however, it is very sensitive to the choice of in-context demonstrations, and processing many demonstrations can be computationally demanding. We propose Mixtures of In-Context Learners... | Giwon Hong, Emile van Krieken, Edoardo Maria Ponti, Nikolay Malkin, Pasquale Minervini |  |
| 2766 |  |  [Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation](https://aclanthology.org/2025.acl-long.1278/) |  | 0 | Sampling-based decoding strategies have been widely adopted for Large Language Models (LLMs) in numerous applications, targeting a balance between diversity and quality via temperature tuning and tail truncation. Considering the strong dependency of the candidate next tokens on different prefixes,... | Yuxuan Zhou, Margret Keuper, Mario Fritz |  |
| 2767 |  |  [RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection](https://aclanthology.org/2025.acl-long.1279/) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities in various domains, including radiology report generation. Previous approaches have attempted to utilize multimodal LLMs for this task, enhancing their performance through the integration of domain-specific knowledge retrieval.... | Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu |  |
| 2768 |  |  [Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](https://aclanthology.org/2025.acl-long.1280/) |  | 0 | While pre-trained multimodal representations (e.g., CLIP) have shown impressive capabilities, they exhibit significant compositional vulnerabilities leading to counterintuitive judgments. We introduce Multimodal Adversarial Compositionality (MAC), a benchmark that leverages large language models... | Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim |  |
| 2769 |  |  [Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models](https://aclanthology.org/2025.acl-long.1281/) |  | 0 | We believe that analyzing attention is crucial for understanding bias in large language models (LLMs); in ambiguous comparative prompting frameworks, it provides insight into how the LLM distributes its focus across different entities, and how this contributes to biased decisions. To this end, we... | Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran |  |
| 2770 |  |  [MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming](https://aclanthology.org/2025.acl-long.1282/) |  | 0 | The proliferation of jailbreak attacks against large language models (LLMs) highlights the need for robust security measures. However, in multi-round dialogues, malicious intentions may be hidden in interactions, leading LLMs to be more prone to produce harmful responses. In this paper, we propose... | Weiyang Guo, Jing Li, Wenya Wang, Yu Li, Daojing He, Jun Yu, Min Zhang |  |
| 2771 |  |  [The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit](https://aclanthology.org/2025.acl-long.1283/) |  | 0 | The deployment of Large Language Models (LLMs) in recommender systems for Click-Through Rate (CTR) prediction requires a careful balance between computational efficiency and predictive accuracy. This paper introduces OptiRAG-Rec, a comprehensive framework that integrates Retrieval-Augmented... | Huixue Zhou, Hengrui Gu, Zaifu Zhan, Xi Liu, Kaixiong Zhou, Yongkang Xiao, Mingfu Liang, Srinivas Prasad Govindan, Piyush Chawla, Jiyan Yang, Xiangfei Meng, Huayu Li, Buyun Zhang, Liang Luo, WenYen Chen, Yiping Han, Bo Long, Rui Zhang, Tianlong Chen |  |
| 2772 |  |  [Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging](https://aclanthology.org/2025.acl-long.1284/) |  | 0 | Fine-tuning large language models (LMs) for individual tasks yields strong performance but is expensive for deployment and storage. Recent works explore model merging to combine multiple task-specific models into a single multi-task model without additional training. However, existing merging... | Haobo Zhang, Jiayu Zhou |  |
| 2773 |  |  [BIG-Bench Extra Hard](https://aclanthology.org/2025.acl-long.1285/) |  | 0 | Current benchmarks for large language model (LLM) reasoning predominantly focus on mathematical and coding abilities, leaving a gap in evaluating broader reasoning proficiencies. One particular exception is the BIG-Bench dataset, which has served as a crucial benchmark for evaluating the general... | Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K. Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Firat |  |
| 2774 |  |  [CSTree-SRI: Introspection-Driven Cognitive Semantic Tree for Multi-Turn Question Answering over Extra-Long Contexts](https://aclanthology.org/2025.acl-long.1286/) |  | 0 | Large Language Models (LLMs) have achieved remarkable success in natural language processing (NLP), particularly in single-turn question answering (QA) on short-text. However, their performance significantly declines when applied to multi-turn QA over extra-long context (ELC), as they struggle to... | Zhaowen Wang, Xiang Wei, Kangshao Du, Yiting Zhang, Libo Qin, Yingjie Xia, Li Kuang |  |
| 2775 |  |  [InductionBench: LLMs Fail in the Simplest Complexity Class](https://aclanthology.org/2025.acl-long.1287/) |  | 0 | Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in... | Wenyue Hua, Tyler Wong, Fei Sun, Liangming Pan, Adam Jardine, William Yang Wang |  |
| 2776 |  |  [RATIONALYST: Pre-training Process-Supervision for Improving Reasoning](https://aclanthology.org/2025.acl-long.1288/) |  | 0 | The reasoning steps generated by LLMs might be incomplete, as they mimic logical leaps common in everyday communication found in their pre-training data: underlying rationales are frequently left implicit (unstated). To address this challenge, we introduce RATIONALYST, a model for... | Dongwei Jiang, Guoxuan Wang, Yining Lu, Andrew Wang, Jingyu Zhang, Chuyu Liu, Benjamin Van Durme, Daniel Khashabi |  |
| 2777 |  |  [Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation](https://aclanthology.org/2025.acl-long.1289/) |  | 0 | Visual information has been introduced for enhancing machine translation (MT), and its effectiveness heavily relies on the availability of large amounts of bilingual parallel sentence pairs with manual image annotations. In this paper, we introduce a stable diffusion-based imagination network into... | Andong Chen, Yuchen Song, Kehai Chen, Xuefeng Bai, Muyun Yang, Liqiang Nie, Jie Liu, Tiejun Zhao, Min Zhang |  |
| 2778 |  |  [Advancing SMoE for Continuous Domain Adaptation of MLLMs: Adaptive Router and Domain-Specific Loss](https://aclanthology.org/2025.acl-long.1290/) |  | 0 | Recent studies have explored Continual Instruction Tuning (CIT) in Multimodal Large Language Models (MLLMs), with a primary focus on Task-incremental CIT, where MLLMs are required to continuously acquire new tasks. However, the more practical and challenging Domain-incremental CIT, focused on the... | Liang Zhang, Ziyao Lu, Fandong Meng, Hui Li, Jie Zhou, Jinsong Su |  |
| 2779 |  |  [Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation](https://aclanthology.org/2025.acl-long.1291/) |  | 0 | Media outlets are becoming more partisan and polarized nowadays. Most previous work focused on detecting media bias. In this paper, we aim to mitigate media bias by generating a neutralized summary given multiple articles presenting different ideological views. Motivated by the critical role of... | Yuanyuan Lei, Ruihong Huang |  |
| 2780 |  |  [Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection](https://aclanthology.org/2025.acl-long.1292/) |  | 0 | The rise of Large Language Models (LLMs) necessitates accurate AI-generated text detection. However, current approaches largely overlook the influence of author characteristics. We investigate how sociolinguistic attributes—gender, CEFR proficiency, academic field, and language environment—impact... | Jiatao Li, Xiaojun Wan |  |
| 2781 |  |  [RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates](https://aclanthology.org/2025.acl-long.1293/) |  | 0 | We propose Row-Column Fine-Tuning(RoCoFT), a parameter-efficient fine-tuning method for large language models based on updating only a few rows and columns of the weight matrices in transformers. Through extensive experiments with medium-sized LMs like RoBERTa and DeBERTa, and larger LMs like... | Md. Kowsher, Tara Esmaeilbeig, ChunNam Yu, Chen Chen, Mojtaba Soltanalian, Niloofar Yousefi |  |
| 2782 |  |  [Scaling Laws and Efficient Inference for Ternary Language Models](https://aclanthology.org/2025.acl-long.1294/) |  | 0 | Large language models (LLMs) are increasingly used across research and industry applications, yet their inference efficiency remains a significant challenge. As the computational power of modern GPU architectures continuously improves, their memory bandwidth and capacity have not scaled... | Tejas Vaidhya, Ayush Kaushal, Vineet Jain, Francis Couture Harpin, Prashant Shishodia, Majid Behbahani, Yuriy Nevmyvaka, Irina Rish |  |
| 2783 |  |  [Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation](https://aclanthology.org/2025.acl-long.1295/) |  | 0 | Instruction-tuning enhances the ability of large language models (LLMs) to follow user instructions more accurately, improving usability while reducing harmful outputs. However, this process may increase the model’s dependence on user input, potentially leading to the unfiltered acceptance of... | Kyubeen Han, Junseo Jang, Hongjin Kim, Geunyeong Jeong, Harksoo Kim |  |
| 2784 |  |  [Do Language Models Understand Honorific Systems in Javanese?](https://aclanthology.org/2025.acl-long.1296/) |  | 0 | The Javanese language features a complex system of honorifics that vary according to the social status of the speaker, listener, and referent. Despite its cultural and linguistic significance, there has been limited progress in developing a comprehensive corpus to capture these variations for... | Mohammad Rifqi Farhansyah, Iwan Darmawan, Adryan Kusumawardhana, Genta Indra Winata, Alham Fikri Aji, Derry Tanti Wijaya |  |
| 2785 |  |  [Generative Reward Modeling via Synthetic Criteria Preference Learning](https://aclanthology.org/2025.acl-long.1297/) |  | 0 | Generative Reward Models (GenRMs) leverage synthesized Chains of Thought (CoT) to reduce the need for massive labeled data, but this approach introduces risks of overoptimization due to the inability to guarantee the correctness of the CoTs. Identifying and optimizing unexpected behaviors within... | Xiaobo Liang, Haoke Zhang, Juntao Li, Kehai Chen, Qiaoming Zhu, Min Zhang |  |
| 2786 |  |  [Exploring Multimodal Relation Extraction of Hierarchical Tabular Data with Multi-task Learning](https://aclanthology.org/2025.acl-long.1298/) |  | 0 | Relation Extraction (RE) is a key task in table understanding, aiming to extract semantic relations between columns. However, complex tables with hierarchical headers are hard to obtain high-quality textual formats (e.g., Markdown) for input under practical scenarios like webpage screenshots and... | Xinyu Zhang, Aibo Song, Jingyi Qiu, Jiahui Jin, Tianbo Zhang, Xiaolin Fang |  |
| 2787 |  |  [A Self-Denoising Model for Robust Few-Shot Relation Extraction](https://aclanthology.org/2025.acl-long.1299/) |  | 0 | The few-shot relation extraction (FSRE) aims at enhancing the model’s generalization to new relations with very few labeled instances (support instances). Most existing studies use prototype networks (ProtoNets) for FSRE and assume that the support set, adapting the model to new relations, only... | Liang Zhang, Yang Zhang, Ziyao Lu, Fandong Meng, Jie Zhou, Jinsong Su |  |
| 2788 |  |  [QuASAR: A Question-Driven Structure-Aware Approach for Table-to-Text Generation](https://aclanthology.org/2025.acl-long.1300/) |  | 0 | Table-to-text generation aims to automatically produce natural language descriptions from structured or semi-structured tabular data. Unlike traditional text generation tasks, it requires models to accurately understand and represent table structures. Existing approaches typically process tables by... | WeiJie Liu, Yibin Zheng, Fang Kong |  |
| 2789 |  |  [Automated Structured Radiology Report Generation](https://aclanthology.org/2025.acl-long.1301/) |  | 0 | Automated radiology report generation from chest X-ray (CXR) images has the potential to improve clinical efficiency and reduce radiologists’ workload. However, most datasets, including the publicly available MIMIC-CXR and CheXpert Plus, consist entirely of free-form reports, which are inherently... | JeanBenoit Delbrouck, Justin Xu, Johannes Moll, Alois Thomas, Zhihong Chen, Sophie Ostmeier, Asfandyar Azhar, Kelvin Zhenghao Li, Andrew Johnston, Christian Bluethgen, Eduardo Pontes Reis, Mohamed S. Muneer, Maya Varma, Curtis P. Langlotz |  |
| 2790 |  |  [LPOI: Listwise Preference Optimization for Vision Language Models](https://aclanthology.org/2025.acl-long.1302/) |  | 0 | Aligning large VLMs with human preferences is a challenging task, as methods like RLHF and DPO often overfit to textual information or exacerbate hallucinations. Although augmenting negative image samples partially addresses these pitfalls, no prior work has employed listwise preference... | Fatemeh Pesaran Zadeh, Yoojin Oh, Gunhee Kim |  |
| 2791 |  |  [Predicting Through Generation: Why Generation Is Better for Prediction](https://aclanthology.org/2025.acl-long.1303/) |  | 0 | This paper argues that generating output tokens is more effective than using pooled representations for prediction tasks because token-level generation retains more mutual information. Since LLMs are trained on massive text corpora using next-token prediction, generation aligns naturally with their... | Md. Kowsher, Nusrat Jahan Prottasha, Prakash Bhat, ChunNam Yu, Mojtaba Soltanalian, Ivan Garibay, Ozlem O. Garibay, Chen Chen, Niloofar Yousefi |  |
| 2792 |  |  ["Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization](https://aclanthology.org/2025.acl-long.1304/) |  | 0 | Despite the popularity of large language model (LLM) quantization for inference acceleration, significant uncertainty remains regarding the accuracy-performance trade-offs associated with various quantization formats. We present a comprehensive empirical study of quantized accuracy, evaluating... | Eldar Kurtic, Alexandre Noll Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh |  |
| 2793 |  |  [StitchLLM: Serving LLMs, One Block at a Time](https://aclanthology.org/2025.acl-long.1305/) |  | 0 | The rapid evolution of large language models (LLMs) has revolutionized natural language processing (NLP) tasks such as text generation, translation, and comprehension. However, the increasing computational demands and inference costs of these models present significant challenges. This study... | Bodun Hu, Shuozhe Li, Saurabh Agarwal, Myungjin Lee, Akshay Jajoo, Jiamin Li, Le Xu, GeonWoo Kim, Donghyun Kim, Hong Xu, Amy Zhang, Aditya Akella |  |
| 2794 |  |  [Walk in Others' Shoes with a Single Glance: Human-Centric Visual Grounding with Top-View Perspective Transformation](https://aclanthology.org/2025.acl-long.1306/) |  | 0 | Visual perspective-taking, an ability to envision others’ perspectives from a single self-perspective, is vital in human-robot interactions. Thus, we introduce a human-centric visual grounding task and a dataset to evaluate this ability. Recent advances in vision-language models (VLMs) have shown... | Yuqi Bu, Xin Wu, Zirui Zhao, Yi Cai, David Hsu, Qiong Liu |  |
| 2795 |  |  [Is linguistically-motivated data augmentation worth it?](https://aclanthology.org/2025.acl-long.1307/) |  | 0 | Data augmentation, a widely-employed technique for addressing data scarcity, involves generating synthetic data examples which are then used to augment available training data. Researchers have seen surprising success from simple methods, such as random perturbations from natural examples, where... | Ray Groshan, Michael Ginn, Alexis Palmer |  |
| 2796 |  |  [From Lists to Emojis: How Format Bias Affects Model Alignment](https://aclanthology.org/2025.acl-long.1308/) |  | 0 | In this paper, we study format biases in reinforcement learning from human feedback (RLHF). We observe that many widely-used preference models—including human evaluators, GPT-4, and top-ranking models on the RewardBench benchmark—exhibit strong biases towards specific format patterns, such as... | Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang |  |
| 2797 |  |  [Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control](https://aclanthology.org/2025.acl-long.1309/) |  | 0 | Colloquial Singaporean English (Singlish) is an informal English marked by a unique blend of languages reflecting Singapore’s multicultural identity. Style transfer between Singlish and Standard (formal) English is vital for various applications, yet existing methods often lack explainability and... | Jinggui Liang, Dung Vo, Yap Hong Xian, Hai Leong Chieu, Kian Ming Adam Chai, Jing Jiang, Lizi Liao |  |
| 2798 |  |  [From Informal to Formal - Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs](https://aclanthology.org/2025.acl-long.1310/) |  | 0 | The research in AI-based formal mathematical reasoning has shown an unstoppable growth trend. These studies have excelled in mathematical competitions like IMO and have made significant progress. However, these studies intertwined multiple skills simultaneously—problem-solving, reasoning, and... | Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, ShingChi Cheung, Cong Tian |  |
| 2799 |  |  [CoAM: Corpus of All-Type Multiword Expressions](https://aclanthology.org/2025.acl-long.1311/) |  | 0 | Multiword expressions (MWEs) refer to idiomatic sequences of multiple words.MWE identification, i.e., detecting MWEs in text, can play a key role in downstream tasks such as machine translation, but existing datasets for the task are inconsistently annotated, limited to a single type of MWE, or... | Yusuke Ide, Joshua Tanner, Adam Nohejl, Jacob Hoffman, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe |  |
| 2800 |  |  [SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation](https://aclanthology.org/2025.acl-long.1312/) |  | 0 | Adaptive Retrieval-Augmented Generation (RAG) is an effective strategy to alleviate hallucination of large language models (LLMs). It dynamically determines whether LLMs need external knowledge for generation and invokes retrieval accordingly. This paper introduces Self-aware Knowledge Retrieval... | Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, Juanzi Li |  |
| 2801 |  |  [Exposing the Achilles' Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning](https://aclanthology.org/2025.acl-long.1313/) |  | 0 | Large Language Models (LLMs) have significantly impacted the field of Math Word Problems (MWPs), transforming how these problems are approached and solved, particularly in educational contexts. However, existing evaluations often focus on final accuracy, neglecting the critical aspect of reasoning... | Joykirat Singh, Akshay Uttama Nambi, Vibhav Vineet |  |
| 2802 |  |  [Understanding the Dark Side of LLMs' Intrinsic Self-Correction](https://aclanthology.org/2025.acl-long.1314/) |  | 0 | Intrinsic self-correction was initially proposed to improve LLMs’ responses via feedback solely based on their inherent capability. However, recent works show that LLMs’ intrinsic self-correction fails without oracle labels as feedback. In this paper, our research goal is to \*interpret LLMs’... | Qingjie Zhang, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang, Ke Xu, Hewu Li, Liu Yan, Han Qiu |  |
| 2803 |  |  [VideoVista-CulturalLingo: 360° Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension](https://aclanthology.org/2025.acl-long.1315/) |  | 0 | Assessing the video comprehension capabilities of multimodal AI systems can effectively measure their understanding and reasoning abilities. Most video evaluation benchmarks are limited to a single language, typically English, and predominantly feature videos rooted in Western cultural contexts. In... | Xinyu Chen, Yunxin Li, Haoyuan Shi, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang |  |
| 2804 |  |  [What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices](https://aclanthology.org/2025.acl-long.1316/) |  | 0 | Recent advancements in large language models (LLMs) with extended context windows have significantly improved various tasks. To improve long-context capabilities, much work focuses on augmenting LLM’s capabilities with synthetic data. Existing methods often leverage the Self-Instruct framework to... | Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Hang Yan, Kai Chen, Dahua Lin |  |
| 2805 |  |  [Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation](https://aclanthology.org/2025.acl-long.1317/) |  | 0 | Recommender systems have become increasingly vital in our daily lives, helping to alleviate the problem of information overload across various user-oriented online services. The emergence of Large Language Models (LLMs) has yielded remarkable achievements, demonstrating their potential for the... | Shijie Wang, Wenqi Fan, Yue Feng, Shanru Lin, Xinyu Ma, Shuaiqiang Wang, Dawei Yin |  |
| 2806 |  |  [SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment](https://aclanthology.org/2025.acl-long.1318/) |  | 0 | Existing preference alignment is a one-size-fits-all alignment mechanism, where the part of the large language model (LLM) parametric knowledge with non-preferred features is uniformly blocked to all the users. However, this part of knowledge can be useful to advanced users whose expertise... | Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen |  |
| 2807 |  |  [I0T: Embedding Standardization Method Towards Zero Modality Gap](https://aclanthology.org/2025.acl-long.1319/) |  | 0 | Contrastive Language-Image Pretraining (CLIP) enables zero-shot inference in downstream tasks such as image-text retrieval and classification. However, recent works extending CLIP suffer from the issue of \*modality gap\*, which arises when the image and text embeddings are projected to disparate... | Na Min An, Eunki Kim, James Thorne, Hyunjung Shim |  |
| 2808 |  |  [Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation](https://aclanthology.org/2025.acl-long.1320/) |  | 0 | Large Language Models (LLMs) are increasingly required to generate text that is both factually accurate and diverse across various open-ended applications. However, current stochastic decoding methods struggle to balance such objectives. We introduce Dynamic Focus Decoding (DFD), a novel... | Wen Luo, Feifan Song, Wei Li, Guangyue Peng, Shaohang Wei, Houfeng Wang |  |
| 2809 |  |  [Better Embeddings with Coupled Adam](https://aclanthology.org/2025.acl-long.1321/) |  | 0 | Despite their remarkable capabilities, LLMs learn word representations that exhibit the undesirable yet poorly understood feature of anisotropy. In this paper, we argue that the second moment in Adam is a cause of anisotropic embeddings, and suggest a modified optimizer called Coupled Adam to... | Felix Stollenwerk, Tobias Stollenwerk |  |
| 2810 |  |  [Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation](https://aclanthology.org/2025.acl-long.1322/) |  | 0 | User information needs are often highly diverse and varied. A key challenge in current research is how to achieve controllable multi-objective generation while enabling rapid adaptation to accommodate diverse user demands during test time. Existing solutions, such as Rewarded Soup, focus on merging... | Guofu Xie, Xiao Zhang, Ting Yao, Yunsheng Shi |  |
| 2811 |  |  [Controllable and Reliable Knowledge-Intensive Task-Oriented Conversational Agents with Declarative Genie Worksheets](https://aclanthology.org/2025.acl-long.1323/) |  | 0 | Large Language Models are capable of carrying out human-like conversations in diverse settings in response to user requests for tasks and knowledge. However, existing conversational agents implemented with LLMs often struggle with hallucination, following instructions with conditional logic, and... | Harshit Joshi, Shicheng Liu, James Chen, Larsen Weigle, Monica S. Lam |  |
| 2812 |  |  [Benchmarking Long-Context Language Models on Long Code Understanding](https://aclanthology.org/2025.acl-long.1324/) |  | 0 | Current advanced long-context language models offer great potential for real-world software engineering applications. However, progress in this critical domain remains hampered by a fundamental limitation: the absence of a rigorous evaluation framework for long code understanding. To gap this... | Jia Li, Xuyuan Guo, Lei Li, Kechi Zhang, Ge Li, Zhengwei Tao, Fang Liu, Chongyang Tao, Yuqi Zhu, Zhi Jin |  |
| 2813 |  |  [MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities](https://aclanthology.org/2025.acl-long.1325/) |  | 0 | While originally designed for unidirectional generative modeling, decoder-only large language models (LLMs) are increasingly being adapted for bidirectional modeling. However, unidirectional and bidirectional models are typically trained separately with distinct objectives (generation and... | Savya Khosla, Aditi Tiwari, Kushal Kafle, Simon Jenni, Handong Zhao, John P. Collomosse, Jing Shi |  |
| 2814 |  |  [Internal Value Alignment in Large Language Models through Controlled Value Vector Activation](https://aclanthology.org/2025.acl-long.1326/) |  | 0 | Aligning Large Language Models (LLMs) with human values has attracted increasing attention since it provides clarity, transparency, and the ability to adapt to evolving scenarios. In this paper, we introduce a Controlled Value Vector Activation (ConVA) method that directly aligns the internal... | Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian |  |
| 2815 |  |  [A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability](https://aclanthology.org/2025.acl-long.1327/) |  | 0 | In NLG meta-evaluation, evaluation metrics are typically assessed based on their consistency with humans. However, we identify some limitations in traditional NLG meta-evaluation approaches, such as issues in handling human ratings and ambiguous selections of correlation measures, which undermine... | Xinyu Hu, Mingqi Gao, Li Lin, Zhenghan Yu, Xiaojun Wan |  |
| 2816 |  |  [Recurrent Knowledge Identification and Fusion for Language Model Continual Learning](https://aclanthology.org/2025.acl-long.1328/) |  | 0 | Continual learning (CL) is crucial for deploying large language models (LLMs) in dynamic real-world environments without costly retraining. While recent model ensemble and model merging methods guided by parameter importance have gained popularity, they often struggle to balance knowledge transfer... | Yujie Feng, Xujia Wang, Zexin Lu, Shenghong Fu, Guangyuan Shi, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, XiaoMing Wu |  |
| 2817 |  |  [Data-Constrained Synthesis of Training Data for De-Identification](https://aclanthology.org/2025.acl-long.1329/) |  | 0 | Many sensitive domains — such as the clinical domain — lack widely available datasets due to privacy risks. The increasing generative capabilities of large language models (LLMs) have made synthetic datasets a viable path forward. In this study, we domain-adapt LLMs to the clinical domain and... | Thomas Vakili, Aron Henriksson, Hercules Dalianis |  |
| 2818 |  |  [Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation](https://aclanthology.org/2025.acl-long.1330/) |  | 0 | Self-harm detection on social media is critical for early intervention and mental health support, yet remains challenging due to the subtle, context-dependent nature of such expressions. Identifying self-harm intent aids suicide prevention by enabling timely responses, but current large language... | Soumitra Ghosh, Gopendra Vikram Singh, Shambhavi, Sabarna Choudhury, Asif Ekbal |  |
| 2819 |  |  [Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing](https://aclanthology.org/2025.acl-long.1331/) |  | 0 | Cross-domain constituency parsing is still an unsolved challenge in computational linguistics since the available multi-domain constituency treebank is limited. We investigate automatic treebank generation by large language models (LLMs) in this paper. The performance of LLMs on constituency... | Peiming Guo, Meishan Zhang, Jianling Li, Min Zhang, Yue Zhang |  |
| 2820 |  |  [MMDEND: Dendrite-Inspired Multi-Branch Multi-Compartment Parallel Spiking Neuron for Sequence Modeling](https://aclanthology.org/2025.acl-long.1332/) |  | 0 | Vanilla spiking neurons are simplified from complex biological neurons with dendrites, soma, and synapses, into single somatic compartments. Due to limitations in performance and training efficiency, vanilla spiking neurons face significant challenges in modeling long sequences. In terms of... | Kexin Wang, Yuhong Chou, Di Shang, Shijie Mei, Jiahong Zhang, Yanbin Huang, Man Yao, Bo Xu, Guoqi Li |  |
| 2821 |  |  [Understanding Impact of Human Feedback via Influence Functions](https://aclanthology.org/2025.acl-long.1333/) |  | 0 | In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn suitable reward models from human feedback to align large language models (LLMs) with human intentions. However, human feedback can often be noisy, inconsistent, or biased, especially when evaluating complex responses.... | Taywon Min, Haeone Lee, Yongchan Kwon, Kimin Lee |  |
| 2822 |  |  [T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts](https://aclanthology.org/2025.acl-long.1334/) |  | 0 | Most existing studies on evaluating text-to-image (T2I) models primarily focus on evaluating text-image alignment, image quality, and object composition capabilities, with comparatively fewer studies addressing the evaluation of the factuality of the synthesized images, particularly when the images... | Ziwei Huang, Wanggui He, Quanyu Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Weilong Dai, Hao Jiang, Fei Wu, Leilei Gan |  |
| 2823 |  |  [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://aclanthology.org/2025.acl-long.1335/) |  | 0 | With the rapid advancements in large language models (LLMs), debating tasks, such as argument quality assessment and debate process simulation, have made significant progress. However, existing LLM-based debating systems focus on responding to specific arguments while neglecting objective... | Fuyu Wang, Jiangtong Li, Kun Zhu, Changjun Jiang |  |
| 2824 |  |  [OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization](https://aclanthology.org/2025.acl-long.1336/) |  | 0 | The advancement of foundation models has laid the groundwork for building autonomous agents for complex tasks such as web navigation. Recent efforts have also tried to equip the agent with the ability to explore environments and continuously improve over time. However, existing works only focused... | Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu |  |
| 2825 |  |  [FOCUS: Evaluating Pre-trained Vision-Language Models on Underspecification Reasoning](https://aclanthology.org/2025.acl-long.1337/) |  | 0 | Humans possess a remarkable ability to interpret underspecified ambiguous statements by inferring their meanings from contexts such as visual inputs. This ability, however, may not be as developed in recent pre-trained vision-language models (VLMs). In this paper, we introduce a novel probing... | Kankan Zhou, Eason Lai, Kyriakos Mouratidis, Jing Jiang |  |
| 2826 |  |  [Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions](https://aclanthology.org/2025.acl-long.1338/) |  | 0 | Often, the needs and visual abilities differ between the annotator group and the end user group. Generating detailed diagram descriptions for blind and low-vision (BLV) users is one such challenging domain. Sighted annotators could describe visuals with ease, but existing studies have shown that... | Wan Ju Kang, Eunki Kim, Na Min An, Sangryul Kim, Haemin Choi, Ki Hoon Kwak, James Thorne |  |
| 2827 |  |  [Personal Travel Solver: A Preference-Driven LLM-Solver System for Travel Planning](https://aclanthology.org/2025.acl-long.1339/) |  | 0 | Personal travel planning is a challenging task that aims to find a feasible plan that not only satisfies diverse constraints but also meets the demands of the user’s explicit and implicit preferences. In this paper, we study how to integrate the user’s implicit preference into the progress of... | Zijian Shao, Jiancan Wu, Weijian Chen, Xiang Wang |  |
| 2828 |  |  [Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning](https://aclanthology.org/2025.acl-long.1340/) |  | 0 | Counterspeech has proven to be a powerful tool to combat hate speech online. Previous studies have focused on generating counterspeech conditioned only on specific intents (single attributed). However, a holistic approach considering multiple attributes simultaneously can yield more nuanced and... | Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty |  |
| 2829 |  |  [LLM×MapReduce: Simplified Long-Sequence Processing using Large Language Models](https://aclanthology.org/2025.acl-long.1341/) |  | 0 | We propose a training-free framework that enables large language models (LLMs) to effectively process long texts, using a divide-and-conquer strategy for comprehensive document understanding.The proposed LLM×MapReduce framework splits the entire document into several chunks for LLMs to read and... | Zihan Zhou, Chong Li, Xinyi Chen, Shuo Wang, Yu Chao, Zhili Li, Haoyu Wang, Qi Shi, Zhixing Tan, Xu Han, Xiaodong Shi, Zhiyuan Liu, Maosong Sun |  |
| 2830 |  |  [CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback](https://aclanthology.org/2025.acl-long.1342/) |  | 0 | Radiologists play a crucial role in translating medical images into actionable reports. However, the field faces staffing shortages and increasing workloads. While automated approaches using vision-language models (VLMs) show promise as assistants, they require exceptionally high accuracy. Most... | Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, Eduardo Pontes Reis, Arne Edward Michalson, Christian Bluethgen, Hyun Joo Shin, Curtis P. Langlotz, Akshay S. Chaudhari |  |
| 2831 |  |  [Knowledge Tracing in Programming Education Integrating Students' Questions](https://aclanthology.org/2025.acl-long.1343/) |  | 0 | Knowledge tracing (KT) in programming education presents unique challenges due to the complexity of coding tasks and the diverse methods students use to solve problems. Although students’ questions often contain valuable signals about their understanding and misconceptions, traditional KT models... | Doyoun Kim, Suin Kim, Yohan Jo |  |
| 2832 |  |  [PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder](https://aclanthology.org/2025.acl-long.1344/) |  | 0 | Semantic Text Embedding is a fundamental NLP task that encodes textual content into vector representations, where proximity in the embedding space reflects semantic similarity. While existing embedding models excel at capturing general meaning, they often overlook ideological nuances, limiting... | Yiqun Sun, Qiang Huang, Anthony Kum Hoe Tung, Jun Yu |  |
| 2833 |  |  [Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes](https://aclanthology.org/2025.acl-long.1345/) |  | 0 | Rational speakers are supposed to know what they know and what they do not know, and to generate expressions matching the strength of evidence. In contrast, it is still a challenge for current large language models to generate corresponding utterances based on the assessment of facts and confidence... | Meng Li, Michael Vrazitulis, David Schlangen |  |
| 2834 |  |  [Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.1346/) |  | 0 | Retrieval-Augmented Generation (RAG) has proven effective in enhancing the factuality of LLMs’ generation, making them a focal point of research. However, previous RAG approaches overlook the lexical diversity of queries, hindering their ability to achieve a granular relevance assessment between... | Zhange Zhang, Yuqing Ma, Yulong Wang, Shan He, Tianbo Wang, Siqi He, Jiakai Wang, Xianglong Liu |  |
| 2835 |  |  [Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains](https://aclanthology.org/2025.acl-long.1347/) |  | 0 | Vision-language models (VLMs) achieve remarkable success in single-image tasks. However, real-world scenarios often involve intricate multi-image inputs, leading to a notable performance decline as models struggle to disentangle critical information scattered across complex visual features. In this... | Juntian Zhang, Chuanqi Cheng, Yuhan Liu, Wei Liu, Jian Luan, Rui Yan |  |
| 2836 |  |  [Online Iterative Self-Alignment for Radiology Report Generation](https://aclanthology.org/2025.acl-long.1348/) |  | 0 | Radiology Report Generation (RRG) is an important research topic for relieving radiologists’ heavy workload. Existing RRG models mainly rely on supervised fine-tuning (SFT) based on different model architectures using data pairs of radiological images and corresponding radiologist-annotated... | Ting Xiao, Lei Shi, Yang Zhang, HaoFeng Yang, Zhe Wang, Chenjia Bai |  |
| 2837 |  |  [Chinese Inertial GAN for Handwriting Signal Generation and Recognition](https://aclanthology.org/2025.acl-long.1349/) |  | 0 | Keyboard-based interaction may not accommodate various needs, especially for individuals with disabilities. While inertial sensor-based writing recognition is promising due to the sensors’ small size, wearability, and low cost, accurate recognition in the Chinese context is hampered by the... | Yifeng Wang, Yi Zhao |  |
| 2838 |  |  [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://aclanthology.org/2025.acl-long.1350/) |  | 0 | The widespread adoption of Large Language Models (LLMs) has heightened concerns about their security, particularly their vulnerability to jailbreak attacks that leverage crafted prompts to generate malicious outputs. While prior research has been conducted on general security capabilities of LLMs,... | Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Junyu Gao, Xuelong Li |  |
| 2839 |  |  [Evaluating Sequence Labeling on the basis of Information Theory](https://aclanthology.org/2025.acl-long.1351/) |  | 0 | Various metrics exist for evaluating sequence labeling problems (strict span matching, token oriented metrics, token concurrence in sequences, etc.), each of them focusing on certain aspects of the task. In this paper, we define a comprehensive set of formal properties that captures the strengths... | Enrique Amigó, Elena Álvarez Mellado, Julio Gonzalo, Jorge CarrillodeAlbornoz |  |
| 2840 |  |  [GRAT: Guiding Retrieval-Augmented Reasoning through Process Rewards Tree Search](https://aclanthology.org/2025.acl-long.1352/) |  | 0 | Enhancing large models for complex multi-hop question-answering has become a research focus in the Retrieval-augmented generation (RAG) area. Many existing approaches aim to mimic human thought processes by enabling large models to perform retrieval-augmented generation step by step. However, these... | Xianshu Peng, Wei Wei |  |
| 2841 |  |  [T-REG: Preference Optimization with Token-Level Reward Regularization](https://aclanthology.org/2025.acl-long.1353/) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has been pivotal in enabling Large Language Models (LLMs) to effectively follow instructions and produce meaningful alignment by leveraging human preference data. Traditionally, RLHF involves generating responses to a query and using a separate... | Wenxuan Zhou, Shujian Zhang, Lingxiao Zhao, Tao Meng |  |
| 2842 |  |  [Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement](https://aclanthology.org/2025.acl-long.1354/) |  | 0 | The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to... | Xunjian Yin, Xinyi Wang, Liangming Pan, Li Lin, Xiaojun Wan, William Yang Wang |  |
| 2843 |  |  [AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments](https://aclanthology.org/2025.acl-long.1355/) |  | 0 | Large language models (LLMs) have emerged as a promising foundation to build generally-capable agents (LLM-based agents) that can handle multi-turn decision-making tasks across various environments. However, the community lacks a unified interactive framework that covers diverse environments for... | Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, YuGang Jiang |  |
| 2844 |  |  [Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory](https://aclanthology.org/2025.acl-long.1356/) |  | 0 | Recently, scaling test-time compute on Large Language Models (LLM) has garnered wide attention. However, there has been limited investigation of how various reasoning prompting strategies perform as scaling. In this paper, we focus on a standard and realistic scaling setting: majority voting. We... | Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan |  |
| 2845 |  |  [Information Locality as an Inductive Bias for Neural Language Models](https://aclanthology.org/2025.acl-long.1357/) |  | 0 | Inductive biases are inherent in every machine learning system, shaping how models generalize from finite data. In the case of neural language models (LMs), debates persist as to whether these biases align with or diverge from human processing constraints. To address this issue, we propose a... | Taiga Someya, Anej Svete, Brian DuSell, Timothy J. O'Donnell, Mario Giulianelli, Ryan Cotterell |  |
| 2846 |  |  [Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models](https://aclanthology.org/2025.acl-long.1358/) |  | 0 | Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information such as event sequencing, durations, and inter-temporal... | Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert |  |
| 2847 |  |  [Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies](https://aclanthology.org/2025.acl-long.1359/) |  | 0 | Extracting scientific evidence from biomedical studies for clinical research questions (e.g., Does stem cell transplantation improve quality of life in patients with medically refractory Crohn’s disease compared to placebo?) is a crucial step in synthesising biomedical evidence. In this paper, we... | Massimiliano Pronesti, Joao H. BettencourtSilva, Paul Flanagan, Alessandra Pascale, Oisin Redmond, Anya Belz, Yufang Hou |  |
| 2848 |  |  [Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution](https://aclanthology.org/2025.acl-long.1360/) |  | 0 | In this paper, we aim to enhance the robustness of Universal Information Extraction (UIE) by introducing a new benchmark dataset, a comprehensive evaluation, and a feasible solution. Existing robust benchmark datasets have two key limitations: 1) They generate only a limited range of perturbations... | Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng |  |
| 2849 |  |  [Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation](https://aclanthology.org/2025.acl-long.1361/) |  | 0 | Neural machine translation (NMT) systems amplify lexical biases present in their training data, leading to artificially impoverished language in output translations. These language-level characteristics render automatic translations different from text originally written in a language and human... | Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral |  |
| 2850 |  |  [Temporal reasoning for timeline summarisation in social media](https://aclanthology.org/2025.acl-long.1362/) |  | 0 | This paper explores whether enhancing temporal reasoning capabilities in Large Language Models (LLMs) can improve the quality of timeline summarisation, the task of summarising long texts containing sequences of events, such as social media threads. We first introduce NarrativeReason, a novel... | Jiayu Song, Mahmud Elahi Akhter, Dana AtzilSlonim, Maria Liakata |  |
| 2851 |  |  [Beyond Negative Stereotypes - Non-Negative Abusive Utterances about Identity Groups and Their Semantic Variants](https://aclanthology.org/2025.acl-long.1363/) |  | 0 | We study a subtype of implicitly abusive language, namely non-negative sentences about identity groups (e.g. “Women make good cooks”), and introduce a novel dataset of such utterances. Not only do we profile such abusive sentences, but since our dataset includes different semantic variants of the... | Tina Lommel, Elisabeth Eder, Josef Ruppenhofer, Michael Wiegand |  |
| 2852 |  |  [Persistent Homology of Topic Networks for the Prediction of Reader Curiosity](https://aclanthology.org/2025.acl-long.1364/) |  | 0 | Reader curiosity, the drive to seek information, is crucial for textual engagement, yet remains relatively underexplored in NLP. Building on Loewenstein’s Information Gap Theory, we introduce a framework that models reader curiosity by quantifying semantic information gaps within a text’s semantic... | Manuel D. S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley K. Jach, Kou Murayama |  |
| 2853 |  |  [Tokenisation is NP-Complete](https://aclanthology.org/2025.acl-long.1365/) |  | 0 | In this work, we prove the NP-completeness of two variants of tokenisation, defined here as the problem of compressing a dataset to at most 𝛿 symbols by either finding a vocabulary directly (_direct_ tokenisation), or selecting a sequence of merge operations (_bottom-up_ tokenisation). | Philip Whittington, Gregor Bachmann, Tiago Pimentel |  |
| 2854 |  |  [Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning](https://aclanthology.org/2025.acl-long.1366/) |  | 0 | This work aims to understand how scaling improves language models, specifically in terms of training dynamics. We find that language models undergo loss deceleration early in training—an abrupt slowdown in the rate of loss improvement, resulting in piecewise linear behaviour of the loss curve in... | Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva |  |
| 2855 |  |  [Parameter-Aware Contrastive Knowledge Editing: Tracing and Rectifying based on Critical Transmission Paths](https://aclanthology.org/2025.acl-long.1367/) |  | 0 | Large language models (LLMs) have encoded vast amounts of knowledge in their parameters, but the acquired knowledge can sometimes be incorrect or outdated over time, necessitating rectification after pre-training. Traditional localized methods in knowledge-based model editing (KME) typically assume... | Songlin Zhai, Yuan Meng, Yuxin Zhang, Guilin Qi |  |
| 2856 |  |  [Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System](https://aclanthology.org/2025.acl-long.1368/) |  | 0 | The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating... | Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong |  |
| 2857 |  |  [Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking](https://aclanthology.org/2025.acl-long.1369/) |  | 0 | Large language models (LLMs) face inherent performance bottlenecks under parameter constraints, particularly in processing critical tokens that demand complex reasoning. Empirical analysis reveals challenging tokens induce abrupt gradient spikes across layers, exposing architectural stress points... | Yilong Chen, Junyuan Shang, Zhenyu Zhang, Yanxi Xie, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang |  |
| 2858 |  |  [Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport](https://aclanthology.org/2025.acl-long.1370/) |  | 0 | Document-level text generation tasks are known to be more difficult than sentence-level text generation tasks as they require an understanding of longer context to generate high-quality texts. In this paper, we investigate the adaptation of Minimum Bayes Risk (MBR) decoding for document-level text... | Yuu Jinnai |  |
| 2859 |  |  [Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport](https://aclanthology.org/2025.acl-long.1371/) |  | 0 | Instruction-following large language models (LLMs), such as ChatGPT, have become widely popular among everyday users. However, these models inadvertently disclose private, sensitive information to their users, underscoring the need for machine unlearning techniques to remove selective information... | Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo |  |
| 2860 |  |  [Mixture of Small and Large Models for Chinese Spelling Check](https://aclanthology.org/2025.acl-long.1372/) |  | 0 | In the era of large language models (LLMs), the Chinese Spelling Check (CSC) task has seen various LLM methods developed, yet their performance remains unsatisfactory. In contrast, fine-tuned BERT-based models, relying on high-quality in-domain data, show excellent performance but suffer from edit... | Ziheng Qiao, Houquan Zhou, Zhenghua Li |  |
| 2861 |  |  [DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check](https://aclanthology.org/2025.acl-long.1373/) |  | 0 | One key characteristic of the Chinese spelling check (CSC) task is that incorrect characters are usually similar to the correct ones in either phonetics or glyph. To accommodate this, previous works usually leverage confusion sets, which suffer from two problems, i.e., difficulty in determining... | Ziheng Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang |  |
| 2862 |  |  [Causal Estimation of Tokenisation Bias](https://aclanthology.org/2025.acl-long.1374/) |  | 0 | Modern language models are typically trained over subword sequences, but ultimately define probabilities over character-strings. Ideally, the choice of the tokeniser—which maps character-strings to subwords—should not affect the probability assigned to the underlying character-string; in practice,... | Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel |  |
| 2863 |  |  [Value Residual Learning](https://aclanthology.org/2025.acl-long.1375/) |  | 0 | While Transformer models have achieved remarkable success in various domains, the effectiveness of information propagation through deep networks remains a critical challenge. Standard hidden state residuals often fail to adequately preserve initial token-level information in deeper layers. This... | Zhanchao Zhou, Tianyi Wu, Zhiyun Jiang, Fares Obeid, Zhenzhong Lan |  |
| 2864 |  |  [SGIC: A Self-Guided Iterative Calibration Framework for RAG](https://aclanthology.org/2025.acl-long.1376/) |  | 0 | Recent research in retrieval-augmented generation (RAG) has concentrated on retrieving useful information from candidate documents. However, numerous methodologies frequently neglect the calibration capabilities of large language models (LLMs), which capitalize on their robust in-context reasoning... | Guanhua Chen, Yutong Yao, Lidia S. Chao, Xuebo Liu, Derek F. Wong |  |
| 2865 |  |  [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://aclanthology.org/2025.acl-long.1377/) |  | 0 | Indonesia is rich in languages and scripts. However, most NLP progress has been made using romanized text. In this paper, we present NusaAksara, a novel public benchmark for Indonesian languages that includes their original scripts. Our benchmark covers both text and image modalities and... | Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur'aini, Derry Tanti Wijaya, Alham Fikri Aji |  |
| 2866 |  |  [LLM-based Rumor Detection via Influence Guided Sample Selection and Game-based Perspective Analysis](https://aclanthology.org/2025.acl-long.1378/) |  | 0 | Rumor detection on social media has become an emerging topic. Traditional deep learning-based methods model rumors based on content, propagation structure, or user behavior, but these approaches are constrained by limited modeling capacity and insufficient training corpora. Recent studies have... | Zhiliang Tian, Jingyuan Huang, Zejiang He, Zhen Huang, Menglong Lu, Linbo Qiao, Songzhu Mei, Yijie Wang, Dongsheng Li |  |
| 2867 |  |  [Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning](https://aclanthology.org/2025.acl-long.1379/) |  | 0 | Previous continual learning setups for embodied intelligence focused on executing low-level actions based on human commands, neglecting the ability to learn high-level planning and multi-level knowledge. To address these issues, we propose the Hierarchical Embodied Continual Learning Setups (HEC)... | Ziqi Jia, Anmin Wang, Xiaoyang Qu, Xiaowen Yang, Jianzong Wang |  |
| 2868 |  |  [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://aclanthology.org/2025.acl-long.1380/) |  | 0 | Large Language Models (LLMs) have achieved impressive accomplishments in recent years. However, the increasing memory consumption of KV cache has possessed a significant challenge to the inference system. Eviction methods have revealed the inherent redundancy within the KV cache, demonstrating its... | Zicong Tang, Luohe Shi, Zuchao Li, Baoyuan Qi, Liu Guoming, Lefei Zhang, Ping Wang |  |
| 2869 |  |  [Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.1381/) |  | 0 | We introduce MedGraphRAG, a novel graph-based Retrieval-Augmented Generation (RAG) framework designed to enhance LLMs in generating evidence-based medical responses, improving safety and reliability with private medical data. We introduce Triple Graph Construction and U-Retrieval to enhance... | Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau |  |
| 2870 |  |  [Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models](https://aclanthology.org/2025.acl-long.1382/) |  | 0 | How can we quantize large language models while preserving accuracy? Quantization is essential for deploying large language models (LLMs) efficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are promising quantization schemes that have strong expressiveness and... | Seungcheol Park, Jeongin Bae, Beomseok Kwon, Minjun Kim, Byeongwook Kim, Se Jung Kwon, U Kang, Dongsoo Lee |  |
| 2871 |  |  [Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools](https://aclanthology.org/2025.acl-long.1383/) |  | 0 | We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents. Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research. A key innovation... | Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin |  |
| 2872 |  |  [Probing Relative Interaction and Dynamic Calibration in Multi-modal Entity Alignment](https://aclanthology.org/2025.acl-long.1384/) |  | 0 | Multi-modal entity alignment aims to identify equivalent entities between two different multi-modal knowledge graphs. Current methods have made significant progress by improving embedding and cross-modal fusion. However, most of them depend on using loss functions to capture the relationship... | Chenxiao Li, Jingwei Cheng, Qiang Tong, Fu Zhang, Cairui Wang |  |
| 2873 |  |  [Learn to Memorize: Scalable Continual Learning in Semiparametric Models with Mixture-of-Neighbors Induction Memory](https://aclanthology.org/2025.acl-long.1385/) |  | 0 | Semiparametric language models (LMs) have shown promise in various Natural Language Processing (NLP) tasks. However, they utilize non-parametric memory as static storage, which lacks learning capability and remains disconnected from the internal information flow of the parametric models, limiting... | Guangyue Peng, Tao Ge, Wen Luo, Wei Li, Houfeng Wang |  |
| 2874 |  |  [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://aclanthology.org/2025.acl-long.1386/) |  | 0 | In this work, we present a manually annotated corpus for Adverse Event (AE) extraction from discharge summaries of elderly patients, a population often underrepresented in clinical NLP resources. The dataset includes 14 clinically significant AEs—such as falls, delirium, and intracranial... | Imane Guellil, Salomé Andres, Atul Anand, Bruce Guthrie, Huayu Zhang, Abul Hasan, Honghan Wu, Beatrice Alex |  |
| 2875 |  |  [Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing](https://aclanthology.org/2025.acl-long.1387/) |  | 0 | Large language models (LLMs) have made significant strides in code acceleration (CA) tasks. Current works typically fine-tune LLMs using slow-fast code pairs mined from online programming platforms. Although these methods are widely recognized for their effectiveness, the training data often lack... | Longhui Zhang, Jiahao Wang, Meishan Zhang, GaoXiong Cao, Ensheng Shi, Mayuchi Mayuchi, Jun Yu, Honghai Liu, Jing Li, Min Zhang |  |
| 2876 |  |  [Multi-Facet Blending for Faceted Query-by-Example Retrieval](https://aclanthology.org/2025.acl-long.1388/) |  | 0 | With the growing demand to fit fine-grained user intents, faceted query-by-example (QBE), which retrieves similar documents conditioned on specific facets, has gained recent attention. However, prior approaches mainly depend on document-level comparisons using basic indicators like citations due to... | Heejin Do, Sangwon Ryu, Jonghwi Kim, Gary Lee |  |
| 2877 |  |  [PIPER: Benchmarking and Prompting Event Reasoning Boundary of LLMs via Debiasing-Distillation Enhanced Tuning](https://aclanthology.org/2025.acl-long.1389/) |  | 0 | While Large Language Models (LLMs) excel in diverse domains, their validity in event reasoning remains underexplored. Most existing works merely stagnate at assessing LLMs’ event reasoning with a single event relational type or reasoning format, failing to conduct a complete evaluation and provide... | Zhicong Lu, Changyuan Tian, PeiguangLi PeiguangLi, Li Jin, Sirui Wang, Wei Jia, Ying Shen, Guangluan Xu |  |
| 2878 |  |  [MIR: Methodology Inspiration Retrieval for Scientific Research Problems](https://aclanthology.org/2025.acl-long.1390/) |  | 0 | There has been a surge of interest in harnessing the reasoning capabilities of Large Language Models (LLMs) to accelerate scientific discovery. While existing approaches rely on grounding the discovery process within the relevant literature, effectiveness varies significantly with the quality and... | Aniketh Garikaparthi, Manasi Patwardhan, Aditya Sanjiv Kanade, Aman Hassan, Lovekesh Vig, Arman Cohan |  |
| 2879 |  |  [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://aclanthology.org/2025.acl-long.1391/) |  | 0 | Despite the widespread use of Transformer-based text embedding models in NLP tasks, surprising “sticky tokens” can undermine the reliability of embeddings. These tokens, when repeatedly inserted into sentences, pull sentence similarity toward a certain value, disrupting the normal distribution of... | Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang |  |
| 2880 |  |  [Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning](https://aclanthology.org/2025.acl-long.1392/) |  | 0 | Although large language models (LLMs) excel in knowledge recall and reasoning, their static nature leads to outdated information as the real world evolves or when adapting to domain-specific knowledge, highlighting the need for effective knowledge injection. However, current research on knowledge... | Ruoxi Xu, Yunjie Ji, Boxi Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Yingfei Sun, Xiangang Li, Le Sun |  |
| 2881 |  |  [Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples](https://aclanthology.org/2025.acl-long.1393/) |  | 0 | In dialogue state tracking (DST), in-context learning comprises a retriever that selects labeled dialogues as in-context examples and a DST model that uses these examples to infer the dialogue state of the query dialogue. Existing methods for constructing training data for retrievers suffer from... | Haesung Pyun, Yoonah Park, Yohan Jo |  |
| 2882 |  |  [Pretraining Context Compressor for Large Language Models with Embedding-Based Memory](https://aclanthology.org/2025.acl-long.1394/) |  | 0 | Efficient processing of long contexts in large language models (LLMs) is essential for real-world applications like retrieval-augmented generation and in-context learning, especially in resource-constrained environments such as edge computing. This paper explores the embedding-based context... | Yuhong Dai, Jianxun Lian, Yitian Huang, Wei Zhang, Mingyang Zhou, Mingqi Wu, Xing Xie, Hao Liao |  |
| 2883 |  |  [Dialogue Systems for Emotional Support via Value Reinforcement](https://aclanthology.org/2025.acl-long.1395/) |  | 0 | Emotional support dialogue systems aim to reduce help-seekers’ distress and help them overcome challenges. While human values—core beliefs that shape an individual’s priorities—are increasingly emphasized in contemporary psychological therapy for their role in fostering internal transformation and... | Juhee Kim, Chunghu Mok, Jisun Lee, Hyang Sook Kim, Yohan Jo |  |
| 2884 |  |  [Length-Induced Embedding Collapse in PLM-based Models](https://aclanthology.org/2025.acl-long.1396/) |  | 0 | Text embeddings from PLM-based models enable a wide range of applications, yet their performance often degrades on longer texts. In this paper, we introduce a phenomenon we call Length Collapse, where embeddings of longer texts tend to cluster together. This clustering results in a distributional... | Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu |  |
| 2885 |  |  [SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction](https://aclanthology.org/2025.acl-long.1397/) |  | 0 | Sign language processing has traditionally relied on task-specific models, limiting the potential for transfer learning across tasks. Pre-training methods for sign language have typically focused on either supervised pre-training, which cannot take advantage of unlabeled data, or... | Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu |  |
| 2886 |  |  [ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation](https://aclanthology.org/2025.acl-long.1398/) |  | 0 | Unsupervised keyphrase prediction has gained growing interest in recent years. However, existing methods typically rely on heuristically defined importance scores, which may lead to inaccurate informativeness estimation. In addition, they lack consideration for time efficiency. To solve these... | Lam Thanh Do, Aaditya Bodke, Pritom Saha Akash, Kevin ChenChuan Chang |  |
| 2887 |  |  [Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling](https://aclanthology.org/2025.acl-long.1399/) |  | 0 | Recent LLMs have enabled significant advancements for conversational agents. However, they are also well known to hallucinate, producing responses that seem plausible but are factually incorrect. On the other hand, users tend to over-rely on LLM-based AI agents, accepting AI’s suggestion even when... | Suvodip Dey, YiJyun Sun, Gokhan Tur, Dilek HakkaniTür |  |
| 2888 |  |  [LLMs Trust Humans More, That's a Problem! Unveiling and Mitigating the Authority Bias in Retrieval-Augmented Generation](https://aclanthology.org/2025.acl-long.1400/) |  | 0 | Retrieval-Augmented Generation (RAG) has been proven to be an effective approach to address the hallucination problem in large language models (LLMs). In current RAG systems, LLMs typically need to synthesize knowledge provided by two main external sources (user prompts and an external database) to... | Yuxuan Li, Xinwei Guo, Jiashi Gao, Guanhua Chen, Xiangyu Zhao, Jiaxin Zhang, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei |  |
| 2889 |  |  [Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation](https://aclanthology.org/2025.acl-long.1401/) |  | 0 | While Large Language Models (LLMs) demonstrate remarkable capabilities, their ability to autonomously execute complex real-world tasks remains limited. Accordingly, tool learning has emerged to enable LLMs to effectively leverage external tools to extend their capabilities. Current tool-learning... | Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin |  |
| 2890 |  |  [Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration](https://aclanthology.org/2025.acl-long.1402/) |  | 0 | Historical documents represent an invaluable cultural heritage, yet have undergone significant degradation over time through tears, water erosion, and oxidation. Existing Historical Document Restoration (HDR) methods primarily focus on single modality or limited-size restoration, failing to meet... | Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin |  |
| 2891 |  |  [PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment](https://aclanthology.org/2025.acl-long.1403/) |  | 0 | Alignment of large language models (LLMs) involves training models on preference-contrastive output pairs to adjust their responses according to human preferences. To obtain such contrastive pairs, traditional methods like RLHF and RLAIF rely on limited contrasting patterns, such as varying model... | Zekun Moore Wang, Shenzhi Wang, King Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang |  |
| 2892 |  |  [Robust Utility-Preserving Text Anonymization Based on Large Language Models](https://aclanthology.org/2025.acl-long.1404/) |  | 0 | Anonymizing text that contains sensitive information is crucial for a wide range of applications. Existing techniques face the emerging challenges of the re-identification ability of large language models (LLMs), which have shown advanced capability in memorizing detailed information and reasoning... | Tianyu Yang, Xiaodan Zhu, Iryna Gurevych |  |
| 2893 |  |  [SEAL: Scaling to Emphasize Attention for Long-Context Retrieval](https://aclanthology.org/2025.acl-long.1405/) |  | 0 | While many advanced LLMs are designed to handle long sequence data, we can still observe notable quality degradation even within the sequence limit. In this work, we introduce a novel approach called Scaling to Emphasize Attention for Long-context retrieval (SEAL), which enhances the retrieval... | Changhun Lee, Minsang Seok, Jungyu Jin, Younghyun Cho, Eunhyeok Park |  |
| 2894 |  |  [From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment](https://aclanthology.org/2025.acl-long.1406/) |  | 0 | Large language models (LLMs) have demonstrated remarkable multilingual capabilities, however, how to evaluate cross-lingual alignment remains underexplored. Existing alignment benchmarks primarily focus on sentence embeddings, but prior research has shown that neural models tend to induce a... | Chongxuan Huang, Yongshi Ye, Biao Fu, Qifeng Su, Xiaodong Shi |  |
| 2895 |  |  [\mathcalA³: Automatic Alignment Framework for Attributed Text Generation](https://aclanthology.org/2025.acl-long.1407/) |  | 0 | Attributed text generation aims to enhance the reliability of content generated from large language models by providing citations for each claim, which thereby enables users to easily verify the correctness of the responses.However, the scarcity of high-quality training samples presents a... | Yue Wang, Haoke Zhang, Juntao Li, Jinxiong Chang, Min Zhang |  |
| 2896 |  |  [Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement](https://aclanthology.org/2025.acl-long.1408/) |  | 0 | As Large Language Models (LLMs) advance, aligning them with human values is critical for their responsible development. Value principles serve as the foundation for clarifying alignment goals.Multiple sets of value principles have been proposed, such as HHH (helpful, honest, harmless) and... | Bingbing Xu, Jing Yao, Xiaoyuan Yi, Aishan Maoliniyazi, Xing Xie, Xiaofeng Meng |  |
| 2897 |  |  [Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More](https://aclanthology.org/2025.acl-long.1409/) |  | 0 | This work concerns the path-star task, a minimal example of searching over a graph. The graph, G, is star-shaped with D arms radiating from a start node, s. A language model (LM) is given G, s, and a target node, t, which ends one of the arms and is tasked with generating the arm containing t. The... | Arvid Frydenlund |  |
| 2898 |  |  [Diversity Explains Inference Scaling Laws: Through a Case Study of Minimum Bayes Risk Decoding](https://aclanthology.org/2025.acl-long.1410/) |  | 0 | Inference methods play an important role in eliciting the performance of large language models (LLMs). Currently, LLMs use inference methods utilizing generated multiple samples, which can be derived from Minimum Bayes Risk (MBR) Decoding. Previous studies have conducted empirical analyses to... | Hidetaka Kamigaito, Hiroyuki Deguchi, Yusuke Sakai, Katsuhiko Hayashi, Taro Watanabe |  |
| 2899 |  |  [Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models](https://aclanthology.org/2025.acl-long.1411/) |  | 0 | Vision-language models (VLMs) excel at extracting and reasoning about information from images. Yet, their capacity to leverage internal knowledge about specific entities remains underexplored. This work investigates the disparity in model performance when answering factual questions about an entity... | Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes |  |
| 2900 |  |  [SDD: Self-Degraded Defense against Malicious Fine-tuning](https://aclanthology.org/2025.acl-long.1412/) |  | 0 | Open-source Large Language Models (LLMs) often employ safety alignment methods to resist harmful instructions. However, recent research shows that maliciously fine-tuning these LLMs on harmful data can easily bypass these safeguards. To counter this, we theoretically uncover why malicious... | Zixuan Chen, Weikai Lu, Xin Lin, Ziqian Zeng |  |
| 2901 |  |  [CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model](https://aclanthology.org/2025.acl-long.1413/) |  | 0 | Motion instruction is a crucial task that helps athletes refine their technique by analyzing movements and providing corrective guidance. Although recent advances in multimodal models have improved motion understanding,generating precise and sport-specific instruction remains challenging due to the... | WeiHsin Yeh, YuAn Su, ChihNing Chen, YiHsueh Lin, Calvin Ku, Wenhsin Chiu, MinChun Hu, LunWei Ku |  |
| 2902 |  |  [DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization](https://aclanthology.org/2025.acl-long.1414/) |  | 0 | Large language models (LLMs) deliver impressive results but face challenges from increasing model sizes and computational costs. Structured pruning reduces model size and speeds up inference but often causes uneven degradation across domains, leading to biased performance. To address this, we... | Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu |  |
| 2903 |  |  [How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs](https://aclanthology.org/2025.acl-long.1415/) |  | 0 | Large language models (LLMs) exihibit increasingly sophisticated linguistic capabilities, yet the extent to which these behaviors reflect human-like cognition versus advanced pattern recognition remains an open question.In this study, we investigate how LLMs process the temporal meaning of... | Karin de Langis, Jong Inn Park, Andreas Schramm, Bin Hu, Khanh Chi Le, Dongyeop Kang |  |
| 2904 |  |  [Data Caricatures: On the Representation of African American Language in Pretraining Corpora](https://aclanthology.org/2025.acl-long.1416/) |  | 0 | With a combination of quantitative experiments, human judgments, and qualitative analyses, we evaluate the quantity and quality of African American Language (AAL) representation in 12 predominantly English, open-source pretraining corpora. We specifically focus on the sources, variation, and... | Nicholas Deas, Blake Vente, Amith Ananthram, Jessica Grieser, Desmond Upton Patton, Shana Kleiner, James R. Shepard III, Kathleen McKeown |  |
| 2905 |  |  [Language Model Probabilities are Not Calibrated in Numeric Contexts](https://aclanthology.org/2025.acl-long.1417/) |  | 0 | Some statements have one well-defined continuation (e.g., “the Eiffel Tower is in [Paris]"), whereas others have a natural distribution over multiple options (e.g., “the weighted coin flip was [Heads/Tails].") We argue that language model (LM) outputs should capture these natural distributions. Our... | Charles Lovering, Michael Krumdick, Viet Dac Lai, Varshini Reddy, Seth Ebner, Nilesh Kumar, Rik KoncelKedziorski, Chris Tanner |  |
| 2906 |  |  [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://aclanthology.org/2025.acl-long.1418/) |  | 0 | Multi-document (MD) processing is crucial for LLMs to handle real-world tasks such as summarization and question-answering across large sets of documents. While LLMs have improved at processing long inputs, MD contexts still present unique difficulties, including management of inter-document... | Gabrielle KailiMay Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan |  |
| 2907 |  |  [Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs](https://aclanthology.org/2025.acl-long.1419/) |  | 0 | Evaluating machine-generated text remains a significant challenge in NLP, especially for non-English languages. Current methodologies, including automated metrics, human assessments, and LLM-based evaluations, predominantly focus on English, revealing a significant gap in multilingual evaluation... | Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M. Khapra |  |
| 2908 |  |  [DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process](https://aclanthology.org/2025.acl-long.1420/) |  | 0 | Large Language Models (LLMs) are increasingly utilized in scientific research assessment, particularly in automated paper review. However, existing LLM-based review systems face significant challenges, including limited domain expertise, hallucinated reasoning, and a lack of structured evaluation.... | Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang |  |
| 2909 |  |  [Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient](https://aclanthology.org/2025.acl-long.1421/) |  | 0 | Recent Large-Language Models (LLMs) pruning methods typically operate at the post-training phase without the expensive weight finetuning, however, their pruning criteria often rely on \*\*heuristically hand-crafted metrics\*\*, potentially leading to suboptimal performance. We instead propose a... | Yuan Gao, Zujing Liu, Weizhong Zhang, Bo Du, GuiSong Xia |  |
| 2910 |  |  [Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis](https://aclanthology.org/2025.acl-long.1422/) |  | 0 | With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between... | Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han |  |
| 2911 |  |  [Hierarchical Memory Organization for Wikipedia Generation](https://aclanthology.org/2025.acl-long.1423/) |  | 0 | Generating Wikipedia articles autonomously is a challenging task requiring the integration of accurate, comprehensive, and well-structured information from diverse sources. This paper introduces the Memory Organization-based Generation (MOG) framework, a novel approach to address these challenges... | Eugene J. Yu, Dawei Zhu, Yifan Song, Xiangyu Wong, Jiebin Zhang, Wenxuan Shi, Xiaoguang Li, Qun Liu, Sujian Li |  |
| 2912 |  |  [Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks](https://aclanthology.org/2025.acl-long.1424/) |  | 0 | Detecting deviant language such as sexism, or nuanced language such as metaphors or sarcasm, is crucial for enhancing the safety, clarity, and interpretation of social interactions. While existing classifiers deliver strong results on these tasks, they often come with significant computational cost... | Chenlu Wang, Weimin Lyu, Ritwik Banerjee |  |
| 2913 |  |  [Structure-aware Domain Knowledge Injection for Large Language Models](https://aclanthology.org/2025.acl-long.1425/) |  | 0 | This paper introduces a pioneering methodology, termed StructTuning, to efficiently transform foundation Large Language Models (LLMs) into domain specialists. It significantly reduces the training corpus needs to a mere 5% while achieving an impressive 100% of traditional knowledge injection... | Kai Liu, Ze Chen, Zhihang Fu, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye |  |
| 2914 |  |  [FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation](https://aclanthology.org/2025.acl-long.1426/) |  | 0 | Multimodal Large Language Models (MLLMs) have experienced rapid development in recent years. However, in the financial domain, there is a notable lack of effective and specialized multimodal evaluation datasets. To advance the development of MLLMs in the finance domain, we introduce FinMME,... | Junyu Luo, Zhizhuo Kou, Liming Yang, Xiao Luo, Jinsheng Huang, Zhiping Xiao, Jingshu Peng, Chengzhong Liu, Jiaming Ji, Xuanzhe Liu, Sirui Han, Ming Zhang, Yike Guo |  |
| 2915 |  |  [Dialectal Coverage And Generalization in Arabic Speech Recognition](https://aclanthology.org/2025.acl-long.1427/) |  | 0 | Developing robust automatic speech recognition (ASR) systems for Arabic requires effective strategies to manage its diversity. Existing ASR systems mainly cover the modern standard Arabic (MSA) variety and few high-resource dialects, but fall short in coverage and generalization across the... | Amirbek Djanibekov, Hawau Olamide Toyin, Raghad Alshalan, Abdullah Alatir, Hanan Aldarmaki |  |
| 2916 |  |  [EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits](https://aclanthology.org/2025.acl-long.1428/) |  | 0 | Text-guided image editing, fueled by recent advancements in generative AI, is becoming increasingly widespread. This trend highlights the need for a comprehensive framework to verify text-guided edits and assess their quality. To address this need, we introduce EditInspector, a novel benchmark for... | Ron Yosef, Yonatan Bitton, Dani Lischinski, Moran Yanuka |  |
| 2917 |  |  [Reconsidering LLM Uncertainty Estimation Methods in the Wild](https://aclanthology.org/2025.acl-long.1429/) |  | 0 | Large Language Model (LLM) Uncertainty Estimation (UE) methods have become a crucial tool for detecting hallucinations in recent years. While numerous UE methods have been proposed, most existing studies evaluate them in isolated short-form QA settings using threshold-independent metrics such as... | Yavuz Faruk Bakman, Duygu Nur Yaldiz, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Salman Avestimehr, Sai Praneeth Karimireddy |  |
| 2918 |  |  [Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms](https://aclanthology.org/2025.acl-long.1430/) |  | 0 | We propose a novel discriminative model for sequence labeling called Bregman conditional random fields (BCRF).Contrary to standard linear-chain conditional random fields,BCRF allows fast parallelizable inference algorithms based on iterative Bregman projections.We show how such models can be... | Caio Corro, Mathieu Lacroix, Joseph Le Roux |  |
| 2919 |  |  [SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization](https://aclanthology.org/2025.acl-long.1431/) |  | 0 | Designing optimal prompts for Large Language Models (LLMs) is a complex and resource-intensive task, often requiring substantial human expertise. Existing approaches typically separate the optimization of prompt instructions and in-context learning examples, leading to incohesive, suboptimal... | Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A. Malin, Kumar Sricharan |  |
| 2920 |  |  [Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction](https://aclanthology.org/2025.acl-long.1432/) |  | 0 | Historical linguists have long written “programs” that convert reconstructed words in an ancestor language into their attested descendants via ordered string rewrite functions (called sound laws) However, writing these programs is time-consuming, motivating the development of automated Sound Law... | Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel Romney Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn P. Rosé, David R. Mortensen |  |
| 2921 |  |  [Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events](https://aclanthology.org/2025.acl-long.1433/) |  | 0 | State-of-the-art automatic event detection struggles with interpretability and adaptability to evolving large-scale key events—unlike episodic structures, which excel in these areas. Often overlooked, episodes represent cohesive clusters of core entities performing actions at a specific time and... | Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han |  |
| 2922 |  |  [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://aclanthology.org/2025.acl-long.1434/) |  | 0 | Claims made by individuals or entities are oftentimes nuanced and cannot be clearly labeled as entirely “true” or “false”—as is frequently the case with scientific and political claims. However, a claim (e.g., “vaccine A is better than vaccine B”) can be dissected into its integral aspects and... | Priyanka Kargupta, Runchu Tian, Jiawei Han |  |
| 2923 |  |  [The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents](https://aclanthology.org/2025.acl-long.1435/) |  | 0 | Large Language Model (LLM) agents are increasingly being deployed as conversational assistants capable of performing complex real-world tasks through tool integration. This enhanced ability to interact with external systems and process various data sources, while powerful, introduces significant... | Feiran Jia, Tong Wu, Xin Qin, Anna Cinzia Squicciarini |  |
| 2924 |  |  [Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://aclanthology.org/2025.acl-long.1436/) |  | 0 | Watermarking AI-generated text is critical for combating misuse. Yet recent theoretical work argues that any watermark can be erased via random walk attacks that perturb text while preserving quality. However, such attacks rely on two key assumptions: (1) rapid mixing (watermarks dissolve quickly... | Fabrice HarelCanada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai |  |
| 2925 |  |  [Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement](https://aclanthology.org/2025.acl-long.1437/) |  | 0 | Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a... | Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen |  |
| 2926 |  |  [From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs](https://aclanthology.org/2025.acl-long.1438/) |  | 0 | Evacuation decision prediction is critical for efficient and effective wildfire response by helping emergency management anticipate traffic congestion and bottlenecks, allocate resources, and minimize negative impacts. Traditional statistical methods for evacuation decision prediction fail to... | Ruxiao Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu |  |
| 2927 |  |  [GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning](https://aclanthology.org/2025.acl-long.1439/) |  | 0 | Publicly significant images from events carry valuable contextual information with applications in domains such as journalism and education. However, existing methodologies often struggle to accurately extract this contextual relevance from images. To address this challenge, we introduce GETREASON... | Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta |  |
| 2928 |  |  [Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations](https://aclanthology.org/2025.acl-long.1440/) |  | 0 | During a conversation, there can come certain moments where its outcome hangs in the balance. In these pivotal moments, how one responds can put the conversation on substantially different trajectories leading to significantly different outcomes. Systems that can detect when such moments arise... | Vivian Nguyen, Lillian Lee, Cristian DanescuNiculescuMizil |  |
| 2929 |  |  [Unveiling the Potential of BERT-family: A New Recipe for Building Scalable, General and Competitive Large Language Models](https://aclanthology.org/2025.acl-long.1441/) |  | 0 | BERT-family have been increasingly explored for adaptation to scenarios beyond language understanding tasks, with more recent efforts focused on enabling them to become good instruction followers. These explorations have endowed BERT-family with new roles and human expectations, showcasing their... | Yisheng Xiao, Juntao Li, Wenpeng Hu, Zhunchen Luo, Min Zhang |  |
| 2930 |  |  [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://aclanthology.org/2025.acl-long.1442/) |  | 0 | The rapid evolution of scientific fields introduces challenges in organizing and retrieving scientific literature. While expert-curated taxonomies have traditionally addressed this need, the process is time-consuming and expensive. Furthermore, recent automatic taxonomy construction methods either... | Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han |  |
| 2931 |  |  [An Empirical Study of Iterative Refinements for Non-autoregressive Translation](https://aclanthology.org/2025.acl-long.1443/) |  | 0 | Iterative non-autoregressive (NAR) models share a spirit of mixed autoregressive (AR) and fully NAR models, seeking a balance between generation quality and inference efficiency. These models have recently demonstrated impressive performance in varied generation tasks, surpassing the autoregressive... | Yisheng Xiao, Pei Guo, Zechen Sun, Juntao Li, Kai Song, Min Zhang |  |
| 2932 |  |  [Retrofitting Large Language Models with Dynamic Tokenization](https://aclanthology.org/2025.acl-long.1444/) |  | 0 | Current language models (LMs) use a fixed, static subword tokenizer. This default choice typically results in degraded efficiency and language capabilities, especially in languages other than English. To address this issue, we challenge the static design and propose retrofitting LMs with dynamic... | Darius Feher, Ivan Vulic, Benjamin Minixhofer |  |
| 2933 |  |  [Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries](https://aclanthology.org/2025.acl-long.1445/) |  | 0 | While large language models (LLMs) are increasingly capable of handling longer contexts, recent work has demonstrated that they exhibit the _”lost in the middle”_ phenomenon (Liu et al., 2024) of unevenly attending to different parts of the provided context. This hinders their ability to cover... | Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey |  |
| 2934 |  |  [Bilingual Zero-Shot Stance Detection](https://aclanthology.org/2025.acl-long.1446/) |  | 0 | Zero-shot stance detection (ZSSD) aims to determine whether the author of a text is in support, against, or neutral toward a target that is unseen during training. In this paper, we investigate ZSSD within a bilingual framework and compare it with cross-lingual and monolingual scenarios, in... | Chenye Zhao, Cornelia Caragea |  |
| 2935 |  |  [GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning](https://aclanthology.org/2025.acl-long.1447/) |  | 0 | We introduce GrammaMT, a grammatically-aware prompting approach for machine translation that uses Interlinear Glossed Text (IGT), a common form of linguistic description providing morphological and lexical annotations for source sentences. GrammaMT proposes three prompting strategies: gloss-shot,... | Rita Ramos, Everlyn Asiko Chimoto, Maartje ter Hoeve, Natalie Schluter |  |
| 2936 |  |  [Theorem Prover as a Judge for Synthetic Data Generation](https://aclanthology.org/2025.acl-long.1448/) |  | 0 | The demand for synthetic data in mathematical reasoning has increased due to its potential to enhance the mathematical capabilities of large language models (LLMs). However, ensuring the validity of intermediate reasoning steps remains a significant challenge, affecting data quality. While formal... | Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen |  |
| 2937 |  |  [Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks](https://aclanthology.org/2025.acl-long.1449/) |  | 0 | With the increasing prevalence of recorded human speech, spoken language understanding (SLU) is essential for its efficient processing. In order to process the speech, it is commonly transcribed using automatic speech recognition technology. This speech-to-text transition introduces errors into the... | Ori Shapira, Shlomo E. Chazan, Amir David Nissan Cohen |  |
| 2938 |  |  [Assessing Reliability and Political Bias In LLMs' Judgements of Formal and Material Inferences With Partisan Conclusions](https://aclanthology.org/2025.acl-long.1450/) |  | 0 | This article examines LLMs’ ability to correctly label simple inferences with partisan conclusions. For this, we develop a dataset with both formal and material inferences, containing logically equivalent pairs of inferences with conclusions that favor either the political left or the political... | Reto Gubelmann, Ghassen Karray |  |
| 2939 |  |  [PARME: Parallel Corpora for Low-Resourced Middle Eastern Languages](https://aclanthology.org/2025.acl-long.1451/) |  | 0 | The Middle East is characterized by remarkable linguistic diversity, with over 400 million inhabitants speaking more than 60 languages across multiple language families. This study presents a pioneering work in developing the first parallel corpora for eight severely under-resourced varieties in... | Sina Ahmadi, Rico Sennrich, Erfan Karami, Ako Marani, Parviz Fekrazad, Gholamreza Akbarzadeh Baghban, Hanah Hadi, Semko Heidari, Mahîr Dogan, Pedram Asadi, Dashne Bashir, Mohammad Amin Ghodrati, Kourosh Amini, Zeynab Ashourinezhad, Mana Baladi, Farshid Ezzati, Alireza Ghasemifar, Daryoush Hosseinpour, Behrooz Abbaszadeh, Amin Hassanpour, Bahaddin Jalal Hamaamin, Saya Kamal Hama, Ardeshir Mousavi, Sarko Nazir Hussein, Isar Nejadgholi, Mehmet Ölmez, Horam Osmanpour, Rashid Roshan Ramezani, Aryan Sediq Aziz, Ali Salehi, Mohammadreza Yadegari, Kewyar Yadegari, Sedighe Zamani Roodsari |  |
| 2940 |  |  [METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling](https://aclanthology.org/2025.acl-long.1452/) |  | 0 | Chart generation aims to generate code to produce charts satisfying the desired visual properties, e.g., texts, layout, color, and type. It has great potential to empower the automatic professional report generation in financial analysis, research presentation, education, and healthcare. In this... | Bingxuan Li, Yiwei Wang, Jiuxiang Gu, KaiWei Chang, Nanyun Peng |  |
| 2941 |  |  [ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords](https://aclanthology.org/2025.acl-long.1453/) |  | 0 | Lexical borrowing, the adoption of words from one language into another, is a ubiquitous linguistic phenomenon influenced by geopolitical, societal, and technological factors. This paper introduces ConLoan–a novel contrastive dataset comprising sentences with and without loanwords across 10... | Sina Ahmadi, Micha David Hess, Elena Álvarez Mellado, Alessia Battisti, Cui Ding, Anne Göhring, Yingqiang Gao, Zifan Jiang, Andrianos Michail, Peshmerge Morad, Joel Niklaus, Maria Christina Panagiotopoulou, Stefano Perrella, Juri Opitz, Anastassia Shaitarova, Rico Sennrich |  |
| 2942 |  |  [A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive](https://aclanthology.org/2025.acl-long.1454/) |  | 0 | Large Language Models (LLMs) are increasingly utilized in autonomous decision-making, where they sample options from vast action spaces. However, the heuristics that guide this sampling process remain under-explored. We study this sampling behavior and show that this underlying heuristics resembles... | Sarath Sivaprasad, Pramod Kaushik, Sahar Abdelnabi, Mario Fritz |  |
| 2943 |  |  [MEraser: An Effective Fingerprint Erasure Approach for Large Language Models](https://aclanthology.org/2025.acl-long.1455/) |  | 0 | Large Language Models (LLMs) have become increasingly prevalent across various sectors, raising critical concerns about model ownership and intellectual property protection. Although backdoor-based fingerprinting has emerged as a promising solution for model authentication, effective attacks for... | Jingxuan Zhang, Zhenhua Xu, Rui Hu, Wenpeng Xing, Xuhong Zhang, Meng Han |  |
| 2944 |  |  [VISA: Retrieval Augmented Generation with Visual Source Attribution](https://aclanthology.org/2025.acl-long.1456/) |  | 0 | Generation with source attribution is important for enhancing the verifiability of retrieval-augmented generation (RAG) systems. However, existing approaches in RAG primarily link generated content to document-level references, making it challenging for users to locate evidence among multiple... | Xueguang Ma, Shengyao Zhuang, Bevan Koopman, Guido Zuccon, Wenhu Chen, Jimmy Lin |  |
| 2945 |  |  [DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers](https://aclanthology.org/2025.acl-long.1457/) |  | 0 | Large language models (LLMs) have demonstrated strong effectiveness and robustness when fine-tuned as dense retrievers.However, their large parameter size presents significant computational challenges at inference time.While smaller retrievers offer better efficiency, they often fail to generalize... | Xueguang Ma, Xi Victoria Lin, Barlas Oguz, Jimmy Lin, Wentau Yih, Xilun Chen |  |
| 2946 |  |  [Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs](https://aclanthology.org/2025.acl-long.1458/) |  | 0 | The widespread success of LLMs on NLP benchmarks has been accompanied by concerns that LLMs function primarily as stochastic parrots that reproduce texts similar to what they saw during pre-training, often erroneously. But what is the nature of their errors, and do these errors exhibit any... | Ziling Cheng, Meng Cao, MarcAntoine Rondeau, Jackie CK Cheung |  |
| 2947 |  |  [MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning](https://aclanthology.org/2025.acl-long.1459/) |  | 0 | Leveraging multi-agentic frameworks to enhance large language models (LLMs) has demonstrated significant potential recently, with most existing studies focusing on prompting and developing workflows with frozen LLMs. In this paper, we aim to further unleash the power of such multi-agentic... | Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman E. Ozdaglar, Kaiqing Zhang, JooKyung Kim |  |
| 2948 |  |  [Map&Make: Schema Guided Text to Table Generation](https://aclanthology.org/2025.acl-long.1460/) |  | 0 | Transforming dense, unstructured text into interpretable tables—commonly referred to as Text-to-Table generation—is a key task in information extraction. Existing methods often overlook what complex information to extract and how to infer it from text. We present Map&Make, a versatile approach that... | Naman Ahuja, Fenil Denish Bardoliya, Chitta Baral, Vivek Gupta |  |
| 2949 |  |  [IRIS: Interpretable Retrieval-Augmented Classification for Long Interspersed Document Sequences](https://aclanthology.org/2025.acl-long.1461/) |  | 0 | Transformer-based models have achieved state-of-the-art performance in document classification but struggle with long-text processing due to the quadratic computational complexity in the self-attention module. Existing solutions, such as sparse attention, hierarchical models, and key sentence... | Fengnan Li, Elliot D. Hill, Jiang Shu, Jiaxin Gao, Matthew M. Engelhard |  |
| 2950 |  |  [Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images](https://aclanthology.org/2025.acl-long.1462/) |  | 0 | Recent studies have shown that Large Vision-Language Models (VLMs) tend to neglect image content and over-rely on language-model priors, resulting in errors in visually grounded tasks and hallucinations. We hypothesize that this issue arises because existing VLMs are not explicitly trained to... | Shengguang Wu, FanYun Sun, Kaiyue Wen, Nick Haber |  |
| 2951 |  |  [Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method](https://aclanthology.org/2025.acl-long.1463/) |  | 0 | Real-world open-domain questions can be complex, especially when answering them requires integrating information from multiple sources. Effectively identifying the necessary information involves \*aligning\* it with the available data and its organization. However, existing RAG solutions address... | Peter Baile Chen, Yi Zhang, Mike Cafarella, Dan Roth |  |
| 2952 |  |  [R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory](https://aclanthology.org/2025.acl-long.1464/) |  | 0 | The proliferation of web agents necessitates advanced navigation and interaction strategies within complex web environments. Current models often struggle with efficient navigation and action execution due to limited visibility and understanding of web structures. Our proposed R2D2 framework... | Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, Pavan Kapanipathi, Jonathan May, Muhao Chen |  |
| 2953 |  |  [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://aclanthology.org/2025.acl-long.1465/) |  | 0 | Existing studies on fairness are largely Western-focused, making them inadequate for culturally diverse countries such as India. To address this gap, we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to evaluate fairness of LLMs across 85 identity groups encompassing diverse... | Janki Atul Nawale, Mohammed Safi Ur Rahman Khan, Janani D, Mansi Gupta, Danish Pruthi, Mitesh M. Khapra |  |
| 2954 |  |  [SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models](https://aclanthology.org/2025.acl-long.1466/) |  | 0 | We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human cognition-inspired evaluation pipeline for voice understanding large language models (LLM_Voice), designed to assess their voice understanding ability. Moving beyond popular voice understanding metrics such as word error... | Zhen Wan, ChaoHan Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Sadao Kurohashi |  |
| 2955 |  |  [Predicting Implicit Arguments in Procedural Video Instructions](https://aclanthology.org/2025.acl-long.1467/) |  | 0 | Procedural texts help AI enhance reasoning about context and action sequences. Transforming these into Semantic Role Labeling (SRL) improves understanding of individual steps by identifying predicate-argument structure like verb,what,where/with. Procedural instructions are highly elliptic, for... | Anil Batra, Laura SevillaLara, Marcus Rohrbach, Frank Keller |  |
| 2956 |  |  [PIGuard: Prompt Injection Guardrail via Mitigating Overdefense for Free](https://aclanthology.org/2025.acl-long.1468/) |  | 0 | Prompt injection attacks pose a critical threat to large language models (LLMs), enabling goal hijacking and data leakage. Prompt guard models, though effective in defense, suffer from over-defense—falsely flagging benign inputs as malicious due to trigger word bias. To address this issue, we... | Hao Li, Xiaogeng Liu, Ning Zhang, Chaowei Xiao |  |
| 2957 |  |  [CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP](https://aclanthology.org/2025.acl-long.1469/) |  | 0 | Machine unlearning (MU) has gained significant attention as a means to remove the influence of specific data from a trained model without requiring full retraining. While progress has been made in unimodal domains like text and image classification, unlearning in multimodal models remains... | Tianyu Yang, Lisen Dai, Xiangqi Wang, Minhao Cheng, Yapeng Tian, Xiangliang Zhang |  |
| 2958 |  |  [ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding](https://aclanthology.org/2025.acl-long.1470/) |  | 0 | 3D visual grounding (3DVG) involves localizing entities in a 3D scene referred to by natural language text. Such models are useful for embodied AI and scene retrieval applications, which involve searching for objects or patterns using natural language descriptions. While recent works have focused... | Austin T. Wang, ZeMing Gong, Angel X. Chang |  |
| 2959 |  |  [The time scale of redundancy between prosody and linguistic context](https://aclanthology.org/2025.acl-long.1471/) |  | 0 | In spoken communication, information is transmitted not only via words, but also through a rich array of non-verbal signals, including prosody—the non-segmental auditory features of speech. Do these different communication channels carry distinct information? Prior work has shown that the... | Tamar I. Regev, Chiebuka Ohams, Shaylee Xie, Lukas Wolf, Evelina Fedorenko, Alex Warstadt, Ethan Wilcox, Tiago Pimentel |  |
| 2960 |  |  [Basic Reading Distillation](https://aclanthology.org/2025.acl-long.1472/) |  | 0 | Large language models (LLMs) have demonstrated remarkable abilities in various natural language processing areas, but they demand high computation resources which limits their deployment in real-world. Distillation is one technique to solve this problem through either knowledge distillation or task... | Zhi Zhou, Sirui Miao, Xiangyu Duan, Hao Yang, Min Zhang |  |
| 2961 |  |  [Quantized Can Still Be Calibrated: A Unified Framework to Calibration in Quantized Large Language Models](https://aclanthology.org/2025.acl-long.1473/) |  | 0 | Although weight quantization helps large language models (LLMs) in resource-constrained environments, its influence on the uncertainty calibration remains unexplored. To bridge this gap, we presents a comprehensive investigation of uncertainty calibration for quantized LLMs in this work.... | Mingyu Zhong, Guanchu Wang, YuNeng Chuang, Na Zou |  |
| 2962 |  |  [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://aclanthology.org/2025.acl-long.1474/) |  | 0 | Reading is a process that unfolds across space and time, alternating between fixations where a reader focuses on a specific point in space, and saccades where a reader rapidly shifts their focus to a new point. An ansatz of psycholinguistics is that modeling a reader's fixations and saccades yields... | Francesco Ignazio Re, Andreas Opedal, Glib Manaiev, Mario Giulianelli, Ryan Cotterell |  |
| 2963 |  |  [More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives](https://aclanthology.org/2025.acl-long.1475/) |  | 0 | Large language models (LLMs) excel at few-shot in-context learning (ICL) without requiring parameter updates. However, as ICL demonstrations increase from a few to many, performance tends to plateau and eventually decline. We identify two primary causes for this trend: the suboptimal negative... | Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Jian Luan, Shuo Shang, Xiuying Chen, Rui Yan |  |
| 2964 |  |  [Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models](https://aclanthology.org/2025.acl-long.1476/) |  | 0 | Retrieval augmented generation (RAG), while effectively integrating external knowledge to address the inherent limitations of large language models (LLMs), can be hindered by imperfect retrieval that contain irrelevant, misleading, or even malicious information. Previous studies have rarely... | Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, Sercan Ö. Arik |  |
| 2965 |  |  [SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation](https://aclanthology.org/2025.acl-long.1477/) |  | 0 | The rapid expansion of Large Language Models (LLMs) and natural language processing datasets has made exhaustive benchmark evaluations computationally prohibitive. Inspired by high-stakes competitions like the International Mathematical Olympiad-where a few well-chosen problems suffice to... | Gayathri Saranathan, Cong Xu, Mahammad Parwez Alam, Tarun Kumar, Martin Foltin, Soon Yee Wong, Suparna Bhattacharya |  |
| 2966 |  |  [M³GQA: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark](https://aclanthology.org/2025.acl-long.1478/) |  | 0 | Recently, GraphRAG systems have achieved remarkable progress in enhancing the performance and reliability of large language models (LLMs). However, most previous benchmarks are template-based and primarily focus on few-entity queries, which are monotypic and simplistic, failing to offer... | Boci Peng, Yongchao Liu, Xiaohe Bo, Jiaxin Guo, Yun Zhu, Xuanbo Fan, Chuntao Hong, Yan Zhang |  |
| 2967 |  |  [LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion](https://aclanthology.org/2025.acl-long.1479/) |  | 0 | The safety mechanisms of large language models (LLMs) exhibit notable fragility, as even fine-tuning on datasets without harmful content may still undermine their safety capabilities. Meanwhile, existing safety alignment methods predominantly rely on the fine-tuning process, which inadvertently... | Guanghao Zhou, Panjia Qiu, Cen Chen, Hongyu Li, Jason Chu, Xin Zhang, Jun Zhou |  |
| 2968 |  |  [ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries](https://aclanthology.org/2025.acl-long.1480/) |  | 0 | Recent advancements in large language models (LLMs) have significantly enhanced their ability to understand both natural language and code, driving their use in tasks like natural language-to-code (NL2Code) and code summarisation. However, LLMs are prone to hallucination—outputs that stray from... | Kishan Maharaj, Vitobha Munigala, Srikanth G. Tamilselvam, Prince Kumar, Sayandeep Sen, Palani Kodeswaran, Abhijit Mishra, Pushpak Bhattacharyya |  |
| 2969 |  |  [Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models](https://aclanthology.org/2025.acl-long.1481/) |  | 0 | Large language models (LLMs) have showcased remarkable capabilities as autonomous agents when augmented with external tools. Equipped with fixed tool sets, LLMs struggle with addressing diverse user inquiries in open-world tasks. To evaluate and boost the performance of LLMs in dealing with complex... | Shengqian Qin, Yakun Zhu, Linjie Mu, Shaoting Zhang, Xiaofan Zhang |  |
| 2970 |  |  [Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning](https://aclanthology.org/2025.acl-long.1482/) |  | 0 | Large Vision-Language Models (LVLMs) have demonstrated remarkable performance across diverse tasks. Despite great success, recent studies show that LVLMs encounter substantial limitations when engaging with visual graphs. To study the reason behind these limitations, we propose VGCure, a... | Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang |  |
| 2971 |  |  [ISR: Self-Refining Referring Expressions for Entity Grounding](https://aclanthology.org/2025.acl-long.1483/) |  | 0 | Entity grounding, a crucial task in constructing multimodal knowledge graphs, aims to align entities from knowledge graphs with their corresponding images. Unlike conventional visual grounding tasks that use referring expressions (REs) as inputs, entity grounding relies solely on entity names and... | Zhuocheng Yu, Bingchan Zhao, Yifan Song, Sujian Li, Zhonghui He |  |
| 2972 |  |  [Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference](https://aclanthology.org/2025.acl-long.1484/) |  | 0 | Large Vision-Language Models (LVLMs) typically learn visual capacity through visual instruction tuning, involving updates to both a projector and their LLM backbones. Inspired by the concept of a visual region in the human brain, we investigate the existence of an analogous visual region within... | Siyuan Wang, Dianyi Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, Zhongyu Wei |  |
| 2973 |  |  [CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models](https://aclanthology.org/2025.acl-long.1485/) |  | 0 | Investigating hallucination issues in large language models (LLMs) within cross-lingual and cross-modal scenarios can greatly advance the large-scale deployment in real-world applications. Nevertheless, the current studies are limited to a single scenario, either cross-lingual or cross-modal,... | Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lu, Libo Qin |  |
| 2974 |  |  [TestNUC: Enhancing Test-Time Computing Approaches and Scaling through Neighboring Unlabeled Data Consistency](https://aclanthology.org/2025.acl-long.1486/) |  | 0 | Test-time computing approaches, which leverage additional computational resources during inference, have been proven effective in enhancing large language model performance. This work introduces a novel, linearly scaling approach, TestNUC, that improves test-time predictions by leveraging the local... | Henry Peng Zou, Zhengyao Gu, Yue Zhou, Yankai Chen, Weizhi Zhang, Liancheng Fang, Yibo Wang, Yangning Li, Kay Liu, Philip S. Yu |  |
| 2975 |  |  [The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages](https://aclanthology.org/2025.acl-long.1487/) |  | 0 | This paper presents the Esethu Framework, a sustainable data curation framework specifically designed to empower local communities and ensure equitable benefit-sharing from their linguistic resource. This framework is supported by the Esethu license, a novel community-centric data license. As a... | Jenalea Rajab, Anuoluwapo Aremu, Everlyn Asiko Chimoto, Dale Dunbar, Graham Morrissey, Fadel Thior, Luandrie Potgieter, Jessica Ojo, Atnafu Lambebo Tonja, Wilhelmina Ndapewa Onyothi Nekoto, Pelonomi Moiloa, Jade Z. Abbott, Vukosi Marivate, Benjamin Rosman |  |
| 2976 |  |  [Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding](https://aclanthology.org/2025.acl-long.1488/) |  | 0 | In this study, we provide constructive proof that Transformers can recognize and generate hierarchical language efficiently with respect to model size, even without the need for a specific positional encoding.Specifically, we show that causal masking and a starting token enable Transformers to... | Daichi Hayakawa, Issei Sato |  |
| 2977 |  |  [Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities](https://aclanthology.org/2025.acl-long.1489/) |  | 0 | Clinical coding, assigning standardized codes to medical notes, is critical for epidemiological research, hospital planning, and reimbursement. Neural coding models generally process entire discharge summaries, which are often lengthy and contain information that is not relevant to coding. We... | James C. Douglas, Yidong Gan, Ben Hachey, Jonathan K. Kummerfeld |  |
| 2978 |  |  [Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories](https://aclanthology.org/2025.acl-long.1490/) |  | 0 | Large Language Models (LLMs) have shown promise in software vulnerability detection, particularly on function-level benchmarks like Devign and BigVul. However, real-world detection requires interprocedural analysis, as vulnerabilities often emerge through multi-hop function calls rather than... | Alperen Yildiz, Sin G. Teo, Yiling Lou, Yebo Feng, Chong Wang, Dinil Mon Divakaran |  |
| 2979 |  |  [Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling](https://aclanthology.org/2025.acl-long.1491/) |  | 0 | Fine-tuning Large Language Models (LLMs) with multimodal encoders on modality-specific data expands the modalities that LLMs can handle, leading to the formation of Multimodal LLMs (MLLMs). However, this paradigm heavily relies on resource-intensive and inflexible fine-tuning from scratch with new... | Junlin Li, Guodong Du, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, HoKin Tang, Saleh Alharbi, Daojing He, Min Zhang |  |
| 2980 |  |  [Serial Lifelong Editing via Mixture of Knowledge Experts](https://aclanthology.org/2025.acl-long.1492/) |  | 0 | It is challenging to update Large language models (LLMs) since real-world knowledge evolves. While existing Lifelong Knowledge Editing (LKE) methods efficiently update sequentially incoming edits, they often struggle to precisely overwrite the outdated knowledge with the latest one, resulting in... | YuJu Cheng, YuChu Yu, KaiPo Chang, YuChiang Frank Wang |  |
| 2981 |  |  [A Survey on Efficient Large Language Model Training: From Data-centric Perspectives](https://aclanthology.org/2025.acl-long.1493/) |  | 0 | Post-training of Large Language Models (LLMs) is crucial for unlocking their task generalization potential and domain-specific capabilities. However, the current LLM post-training paradigm faces significant data challenges, including the high costs of manual annotation and diminishing marginal... | Junyu Luo, Bohan Wu, Xiao Luo, Zhiping Xiao, Yiqiao Jin, RongCheng Tu, Nan Yin, Yifan Wang, Jingyang Yuan, Wei Ju, Ming Zhang |  |
| 2982 |  |  [IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection](https://aclanthology.org/2025.acl-long.1494/) |  | 0 | While recent advances in fake news video detection have shown promising potential, existing approaches typically (1) focus on a specific domain (e.g., politics) and (2) assume the availability of multiple modalities, including video, audio, description texts, and related images. However, these... | Zhi Zeng, Jiaying Wu, Minnan Luo, Herun Wan, Xiangzheng Kong, Zihan Ma, Guang Dai, Qinghua Zheng |  |
| 2983 |  |  [DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning](https://aclanthology.org/2025.acl-long.1495/) |  | 0 | Clinical diagnosis education requires students to master both systematic reasoning processes and comprehensive medical knowledge. While recent advances in Large Language Models (LLMs) have enabled various medical educational applications, these systems often provide direct answers that could reduce... | Qian Wu, Zheyao Gao, Longfei Gou, Qi Dou |  |
| 2984 |  |  [SocialEval: Evaluating Social Intelligence of Large Language Models](https://aclanthology.org/2025.acl-long.1496/) |  | 0 | LLMs exhibit promising Social Intelligence (SI) in modeling human behavior, raising the need to evaluate LLMs’ SI and their discrepancy with humans. SI equips humans with interpersonal abilities to behave wisely in navigating social interactions to achieve social goals. This presents an operational... | Jinfeng Zhou, Yuxuan Chen, Yihan Shi, Xuanming Zhang, Leqi Lei, Yi Feng, Zexuan Xiong, Miao Yan, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang |  |
| 2985 |  |  [Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings](https://aclanthology.org/2025.acl-long.1497/) |  | 0 | Detecting deception in an increasingly digital world is both a critical and challenging task. In this study, we present a comprehensive evaluation of the automated deception detection capabilities of Large Language Models (LLMs) and Large Multimodal Models (LMMs) across diverse domains. We assess... | Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang |  |
| 2986 |  |  [Analyzing and Mitigating Inconsistency in Discrete Speech Tokens for Neural Codec Language Models](https://aclanthology.org/2025.acl-long.1498/) |  | 0 | Building upon advancements in Large Language Models (LLMs), the field of audio processing has seen increased interest in training speech generation tasks with discrete speech token sequences. However, directly discretizing speech by neural audio codecs often results in sequences that fundamentally... | Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zemin Liu, Junyang Lin |  |
| 2987 |  |  [PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning](https://aclanthology.org/2025.acl-long.1499/) |  | 0 | One of the research focuses of large language models (LLMs) is the ability to generate action plans. Recent studies have revealed that the performance of LLMs can be significantly improved by integrating external tools. Based on this, we propose a benchmark framework called PlanningArena, which... | Zihan Zheng, Tianle Cui, Chuwen Xie, Jiahui Pan, Qianglong Chen, Lewei He |  |
| 2988 |  |  [FocusLLM: Precise Understanding of Long Context by Dynamic Condensing](https://aclanthology.org/2025.acl-long.1500/) |  | 0 | Empowering LLMs with the ability to precisely understand long contexts is crucial for many downstream applications. However, handling long contexts with conventional transformer architecture requires substantial training and inference resources. Existing context condensing methods cannot accurately... | Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang |  |
| 2989 |  |  [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://aclanthology.org/2025.acl-long.1501/) |  | 0 | Text embedding models are essential for various natural language processing tasks, enabling the effective encoding of semantic information into dense vector representations. These models are typically optimized using triplets of (query, positive, negative) data pairs for contrastive learning, where... | Tengyu Pan, Zhichao Duan, Zhenyu Li, Bowen Dong, Ning Liu, Xiuxing Li, Jianyong Wang |  |
| 2990 |  |  [GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes](https://aclanthology.org/2025.acl-long.1502/) |  | 0 | This work contributes to the scarce empirical literature on LLM-based interactive homework in real-world educational settings and offers a practical, scalable solution to improve homework in schools. Homework is an important part of education in schools across the world, but to maximize benefit, it... | Alessandro Vanzo, Sankalan Pal Chowdhury, Mrinmaya Sachan |  |
| 2991 |  |  [Diffusion Models Through a Global Lens: Are They Culturally Inclusive?](https://aclanthology.org/2025.acl-long.1503/) |  | 0 | Text-to-image diffusion models have recently enabled the creation of visually compelling, detailed images from textual prompts. However, their ability to accurately represent various cultural nuances remains an open question. In our work, we introduce CULTDIFF benchmark, evaluating whether... | Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh |  |
| 2992 |  |  [Efficient Safety Alignment of Large Language Models via Preference Re-ranking and Representation-based Reward Modeling](https://aclanthology.org/2025.acl-long.1504/) |  | 0 | Reinforcement Learning (RL) algorithms for safety alignment of Large Language Models (LLMs), such as Direct Preference Optimization (DPO), encounter the challenge of distribution shift. Current approaches typically address this issue through online sampling from the target policy, which requires... | Qiyuan Deng, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang |  |
| 2993 |  |  [English-based acoustic models perform well in the forced alignment of two English-based Pacific Creoles](https://aclanthology.org/2025.acl-long.1505/) |  | 0 | Expanding the breadth languages used to study sociophonetic variation and change is an important step in the theoretical development of sociophonetics. As data archives grow, forced alignment can accelerate the study of sociophonetic variation in minority languages. This paper examines the... | Sam Passmore, Lila San Roque, Kirsty Gillespie, Saurabh Nath, Kira Davey, Keira Mullan, Tim Cawley, Jennifer Biggs, Rosey Billington, Bethwyn Evans, Nick Thieberger, Danielle Barth |  |
| 2994 |  |  [Subtle Errors in Reasoning: Preference Learning via Error-injected Self-editing](https://aclanthology.org/2025.acl-long.1506/) |  | 0 | Large Language Models (LLMs) have exhibited strong mathematical reasoning prowess, tackling tasks ranging from basic arithmetic to advanced competition-level problems. However, frequently occurring subtle yet critical errors, such as miscalculations or incorrect substitutions, limit the LLMs’ full... | Kaishuai Xu, Tiezheng Yu, Wenjun Hou, Yi Cheng, Chak Tou Leong, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li |  |
| 2995 |  |  [Truth Knows No Language: Evaluating Truthfulness Beyond English](https://aclanthology.org/2025.acl-long.1507/) |  | 0 | We introduce a professionally translated extension of the TruthfulQA benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and Spanish. Truthfulness evaluations of large language models (LLMs) have primarily been focused on English. However, the ability of LLMs to maintain... | Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria deDiosFlores, Rodrigo Agerri |  |
| 2996 |  |  [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://aclanthology.org/2025.acl-long.1508/) |  | 0 | In generative commonsense reasoning tasks such as CommonGen, generative large language models (LLMs) compose sentences that include all given concepts. However, when focusing on instruction-following capabilities, if a prompt specifies a concept order, LLMs must generate sentences that adhere to... | Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |  |
| 2997 |  |  [Batayan: A Filipino NLP benchmark for evaluating Large Language Models](https://aclanthology.org/2025.acl-long.1509/) |  | 0 | Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs... | Jann Railey Montalan, Jimson Paulo Layacan, David Demitri Africa, Richell Isaiah Flores, Michael Tuscano Lopez II, Theresa Denise Magsajo, Anjanette Cayabyab, WilliamChandra Tjhi |  |
| 2998 |  |  [HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims](https://aclanthology.org/2025.acl-long.1510/) |  | 0 | Misinformation can be countered with fact-checking, but the process is costly and slow. Identifying checkworthy claims is the first step, where automation can help scale fact-checkers’ efforts. However, detection methods struggle with content that is (1) multimodal, (2) from diverse domains, and... | Michiel van der Meer, Pavel Korshunov, Sébastien Marcel, Lonneke van der Plas |  |
| 2999 |  |  [CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](https://aclanthology.org/2025.acl-long.1511/) |  | 0 | Aerial vision-and-language navigation (VLN) — requiring drones to interpret natural language instructions and navigate complex urban environments — emerges as a critical embodied AI challenge that bridges human-robot interaction, 3D spatial reasoning, and real-world deployment. Although existing... | Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li |  |
| 3000 |  |  [It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems](https://aclanthology.org/2025.acl-long.1512/) |  | 0 | Idioms are defined as a group of words with a figurative meaning not deducible from their individual components. Although modern machine translation systems have made remarkable progress, translating idioms remains a major challenge, especially for speech-to-text systems, where research on this... | Iuliia Zaitova, Badr M. Abdullah, Wei Xue, Dietrich Klakow, Bernd Möbius, Tania Avgustinova |  |
| 3001 |  |  [PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles](https://aclanthology.org/2025.acl-long.1513/) |  | 0 | We present polyNarrative, a new multilingual dataset of news articles, annotated for narratives. Narratives are overt or implicit claims, recurring across articles and languages, promoting a specific interpretation or viewpoint on an ongoing topic, often propagating mis/disinformation. We developed... | Nikolaos Nikolaidis, Nicolas Stefanovitch, Purificação Silvano, Dimitar Iliyanov Dimitrov, Roman Yangarber, Nuno Guimarães, Elisa Sartori, Ion Androutsopoulos, Preslav Nakov, Giovanni Da San Martino, Jakub Piskorski |  |
| 3002 |  |  [A Parameter-Efficient and Fine-Grained Prompt Learning for Vision-Language Models](https://aclanthology.org/2025.acl-long.1514/) |  | 0 | Current vision-language models (VLMs) understand complex vision-text tasks by extracting overall semantic information from large-scale cross-modal associations. However, extracting from large-scale cross-modal associations often smooths out semantic details and requires large computations, limiting... | Yongbin Guo, Shuzhen Li, Zhulin Liu, Tong Zhang, C. L. Philip Chen |  |
| 3003 |  |  [Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games](https://aclanthology.org/2025.acl-long.1515/) |  | 0 | Artificial agents are increasingly central to complex interactions and decision-making tasks, yet aligning their behaviors with desired human values remains an open challenge. In this work, we investigate how human-like personality traits influence agent behavior and performance within text-based... | Seungwon Lim, Seungbeen Lee, Dongjun Min, Youngjae Yu |  |
| 3004 |  |  [SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science](https://aclanthology.org/2025.acl-long.1516/) |  | 0 | Seed science is essential for modern agriculture, directly influencing crop yields and global food security. However, challenges such as interdisciplinary complexity and high costs with limited returns hinder progress, leading to a shortage of experts and insufficient technological support. While... | Jie Ying, Zihong Chen, Zhefan Wang, Wanli Jiang, Chenyang Wang, Zhonghang Yuan, Haoyang Su, Huanjun Kong, Fan Yang, Nanqing Dong |  |
| 3005 |  |  [-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation](https://aclanthology.org/2025.acl-long.1517/) |  | 0 | We present 𝛿-Stance, a large-scale dataset of stances involved in legal argumentation. 𝛿-Stance contains stance-annotated argument pairs, semi-automatically mined from millions of examples of U.S. judges citing precedent in context using citation signals. The dataset aims to facilitate work on the... | Ankita Gupta, Douglas Rice, Brendan T. O'Connor |  |
| 3006 |  |  [Re³Syn: A Dependency-Based Data Synthesis Framework for Long-Context Post-training](https://aclanthology.org/2025.acl-long.1518/) |  | 0 | An important trend in the realm of large language models (LLMs) is the development of longer context windows. However, training LLMs with long context windows to acquire the capability of effectively modeling lengthy inputs is often hindered by the scarcity of naturally long-context data. Existing... | Zhiyang Zhang, Ziqiang Liu, Huiming Wang, Renke Shan, Li Kuang, Lu Wang, De Wen Soh |  |
| 3007 |  |  [Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions](https://aclanthology.org/2025.acl-long.1519/) |  | 0 | As chatbots continue to evolve toward human-like, real-world, interactions, multimodality remains an active area of research and exploration. So far, efforts to integrate multimodality into chatbots have primarily focused on image-centric tasks, such as visual dialogue and image-based instructions,... | Jihyoung Jang, Minwook Bae, Minji Kim, Dilek HakkaniTür, Hyounghun Kim |  |
| 3008 |  |  [Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach](https://aclanthology.org/2025.acl-long.1520/) |  | 0 | Multimodal coreference resolution (MCR) aims to identify mentions referring to the same entity across different modalities, such as text and visuals, and is essential for understanding multimodal content. In the era of rapidly growing multimodal content and social media, MCR is particularly crucial... | Xingyu Li, Chen Gong, Guohong Fu |  |
| 3009 |  |  [TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification](https://aclanthology.org/2025.acl-long.1521/) |  | 0 | Product Attribute Value Identification (PAVI) involves identifying attribute values from product profiles, a key task for improving product search, recommendation, and business analytics on e-commerce platforms.However, existing PAVI methods face critical challenges, such as inferring implicit... | Yindu Su, Huike Zou, Lin Sun, Ting Zhang, Haiyang Yang, Chen Li Yu, David Lo, Qingheng Zhang, Shuguang Han, Jufeng Chen |  |
| 3010 |  |  [Theory of Mind in Large Language Models: Assessment and Enhancement](https://aclanthology.org/2025.acl-long.1522/) |  | 0 | Theory of Mind (ToM)—the ability to reason about the mental states of oneself and others—is a cornerstone of human social intelligence. As Large Language Models (LLMs) become increasingly integrated into daily life, understanding their ability to interpret and respond to human mental states is... | Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan |  |
| 3011 |  |  [Completing A Systematic Review in Hours instead of Months with Interactive AI Agents](https://aclanthology.org/2025.acl-long.1523/) |  | 0 | Systematic reviews (SRs) are vital for evidence-based practice in high stakes disciplines, such as healthcare, but are often impeded by intensive labors and lengthy processes that can take months to complete. Due to the high demand for domain expertise, existing automatic summarization methods fail... | Rui Qiu, Shijie Chen, Yu Su, PoYin Yen, HanWei Shen |  |
| 3012 |  |  [CMHKF: Cross-Modality Heterogeneous Knowledge Fusion for Weakly Supervised Video Anomaly Detection](https://aclanthology.org/2025.acl-long.1524/) |  | 0 | Weakly supervised video anomaly detection (WSVAD) presents a challenging task focused on detecting frame-level anomalies using only video-level labels. However, existing methods focus mainly on visual modalities, neglecting rich multi-modality information. This paper proposes a novel framework,... | Guohua Wang, Shengping Song, Wuchun He, Yongsen Zheng |  |
| 3013 |  |  [CLaSp: In-Context Layer Skip for Self-Speculative Decoding](https://aclanthology.org/2025.acl-long.1525/) |  | 0 | Speculative decoding (SD) is a promising method for accelerating the decoding process of Large Language Models (LLMs). The efficiency of SD primarily hinges on the consistency between the draft model and the verify model. However, existing drafting approaches typically require additional modules to... | Longze Chen, Renke Shan, Huiming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid AlinejadRokny, Min Yang |  |
| 3014 |  |  [Teaching Text Agents to Learn Sequential Decision Making from Failure](https://aclanthology.org/2025.acl-long.1526/) |  | 0 | Text-based reinforcement-learning agents improve their policies by interacting with their environments to collect more training data. However, these self-collected data inevitably contain intermediate failed actions caused by attempting physically infeasible behaviors and/or hallucinations.... | Canasai Kruengkrai, Koichiro Yoshino |  |
| 3015 |  |  [The Harmonic Structure of Information Contours](https://aclanthology.org/2025.acl-long.1527/) |  | 0 | The uniform information density (UID) hypothesis proposes that speakers aim to distribute information evenly throughout a text, balancing production effort and listener comprehension difficulty. However, language typically does not maintain a strictly uniform information rate; instead, it... | Eleftheria Tsipidi, Samuel Kiegeland, Franz Nowak, Tianyang Xu, Ethan Wilcox, Alex Warstadt, Ryan Cotterell, Mario Giulianelli |  |
| 3016 |  |  [REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark](https://aclanthology.org/2025.acl-long.1528/) |  | 0 | Accurate multi-modal document retrieval is crucial for Retrieval-Augmented Generation (RAG), yet existing benchmarks do not fully capture real-world challenges with their current design. We introduce REAL-MM-RAG, an automatically generated benchmark designed to address four key properties essential... | Navve Wasserman, Roi Pony, Oshri Naparstek, Adi Raz Goldfarb, Eli Schwartz, Udi Barzelay, Leonid Karlinsky |  |
| 3017 |  |  [Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models](https://aclanthology.org/2025.acl-long.1529/) |  | 0 | Prompt-based language models like GPT4 and LLaMa have been used for a wide variety of use cases such as simulating agents, searching for information, or for content analysis. For all of these applications and others, political biases in these models can affect their performance. Several researchers... | Mats Faulborn, Indira Sen, Max Pellert, Andreas Spitz, David García |  |
| 3018 |  |  [LongSafety: Evaluating Long-Context Safety of Large Language Models](https://aclanthology.org/2025.acl-long.1530/) |  | 0 | As Large Language Models (LLMs) continue to advance in understanding and generating long sequences, new safety concerns have been introduced through the long context. However, the safety of LLMs in long-context tasks remains under-explored, leaving a significant gap in both evaluation and... | Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang |  |
| 3019 |  |  [Exploiting Contextual Knowledge in LLMs through V-usable Information based Layer Enhancement](https://aclanthology.org/2025.acl-long.1531/) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, yet they often struggle with context-faithfulness generations that properly reflect contextual knowledge. While existing approaches focus on enhancing the decoding strategies, they ignore the fundamental... | Xiaowei Yuan, Zhao Yang, Ziyang Huang, Yequan Wang, Siqi Fan, Yiming Ju, Jun Zhao, Kang Liu |  |
| 3020 |  |  [Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights](https://aclanthology.org/2025.acl-long.1532/) |  | 0 | The application scope of Large Language Models (LLMs) continues to expand, leading to increasing interest in personalized LLMs that align with human values. However, aligning these models with individual values raises significant safety concerns, as certain values may correlate with harmful... | Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak |  |
| 3021 |  |  [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://aclanthology.org/2025.acl-long.1533/) |  | 0 | Cross-modal image-text retrieval is challenging because of the diverse possible associations between content from different modalities. Traditional methods learn a single-vector embedding to represent semantics of each sample, but struggle to capture nuanced and diverse relationships that can exist... | Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas |  |
| 3022 |  |  [The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research](https://aclanthology.org/2025.acl-long.1534/) |  | 0 | Academic citations are widely used for evaluating research and tracing knowledge flows. Such uses typically rely on raw citation counts and neglect variability in citation types. In particular, citations can vary in their fidelity as original knowledge from cited studies may be paraphrased,... | Hong Chen, Misha Teplitskiy, David Jurgens |  |
| 3023 |  |  [MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation](https://aclanthology.org/2025.acl-long.1535/) |  | 0 | Explainable Recommendation task is designed to receive a pair of user and item and output explanations to justify why an item is recommended to a user. Many models approach review generation as a proxy for explainable recommendations. While these models can produce fluent and grammatically correct... | ChingWen Yang, ZhiQuan Feng, YingJia Lin, Che Wei Chen, Kunda Wu, Hao Xu, JuiFeng Yao, HungYu Kao |  |
| 3024 |  |  [Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers](https://aclanthology.org/2025.acl-long.1536/) |  | 0 | A central question in multilingual language modeling is whether large language models (LLMs) develop a universal concept representation, disentangled from specific languages. In this paper, we address this question by analyzing latent representations (latents) during a word-translation task in... | Clément Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West |  |
| 3025 |  |  [Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey](https://aclanthology.org/2025.acl-long.1537/) |  | 0 | A core aspect of compositionality, systematicity is a desirable property in ML models as it enables strong generalization to novel contexts. This has led to numerous studies proposing benchmarks to assess systematic generalization, as well as models and training regimes designed to enhance it. Many... | Ivan Vegner, Sydelle de Souza, Valentin Forch, Martha Lewis, Leonidas A. A. Doumas |  |
| 3026 |  |  [Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models](https://aclanthology.org/2025.acl-long.1538/) |  | 0 | Large language models (LLMs) often struggle to accurately read and comprehend extremely long texts. Current methods for improvement typically rely on splitting long contexts into fixed-length chunks. However, fixed truncation risks separating semantically relevant content, leading to ambiguity and... | Boheng Sheng, Jiacheng Yao, Meicong Zhang, Guoxiu He |  |
| 3027 |  |  [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://aclanthology.org/2025.acl-long.1539/) |  | 0 | Multi-Hop Question Answering (MHQA) tasks permeate real-world applications, posing challenges in orchestrating multi-step reasoning across diverse knowledge domains. While existing approaches have been improved with iterative retrieval, they still struggle to identify and organize dynamic... | Rong Cheng, Jinyi Liu, Yan Zheng, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye Hao |  |
| 3028 |  |  [Deliberate Reasoning in Language Models as Structure-Aware Planning with an Accurate World Model](https://aclanthology.org/2025.acl-long.1540/) |  | 0 | Enhancing the reasoning capabilities of language models (LMs) remains a key challenge, especially for tasks that require complex, multi-step decision-making where existing Chain-of-Thought (CoT) approaches struggle with consistency and verification. In this paper, we propose a novel reasoning... | Siheng Xiong, Ali Payani, Yuan Yang, Faramarz Fekri |  |
| 3029 |  |  [Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models](https://aclanthology.org/2025.acl-long.1541/) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank adaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT (SPEFT), which introduces trainable sparse adaptations to the weight matrices in the model, offering greater flexibility in selecting fine-tuned... | Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao |  |
| 3030 |  |  [Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention](https://aclanthology.org/2025.acl-long.1542/) |  | 0 | Many-shot in-context learning has recently shown promise as an alternative to finetuning, with the major advantage that the same model can be served for multiple tasks. However, this shifts the computational burden from training-time to inference-time, making deployment of many-shot ICL challenging... | Emily Xiao, ChinJou Li, Yilin Zhang, Graham Neubig, Amanda Bertsch |  |
| 3031 |  |  [ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting](https://aclanthology.org/2025.acl-long.1543/) |  | 0 | Bilevel optimization has shown its utility across various machine learning settings, yet most algorithms in practice require second-order information, making it challenging to scale them up. Only recently, a paradigm of first-order algorithms has emerged in the theoretical literature, capable of... | Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang |  |
| 3032 |  |  [PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference](https://aclanthology.org/2025.acl-long.1544/) |  | 0 | In this work, we introduce the PKU-SafeRLHF dataset, designed to promote research on safety alignment in large language models (LLMs). As a sibling project to SafeRLHF and BeaverTails, we separate annotations of helpfulness and harmlessness for question-answering pairs, providing distinct... | Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Alex Qiu, Jiayi Zhou, Kaile Wang, Boxun Li, Sirui Han, Yike Guo, Yaodong Yang |  |
| 3033 |  |  [What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective](https://aclanthology.org/2025.acl-long.1545/) |  | 0 | What makes a difference in the post-training of LLMs? We investigate the training patterns of different layers in large language models (LLMs) through the lens of the gradient. We are specifically interested in how fast vs. slow thinking affects the layer-wise gradients, given the recent popularity... | Ming Li, Yanhong Li, Tianyi Zhou |  |
| 3034 |  |  [Beyond Text Compression: Evaluating Tokenizers Across Scales](https://aclanthology.org/2025.acl-long.1546/) |  | 0 | The choice of tokenizer can profoundly impact language model performance, yet accessible and reliable evaluations of tokenizer quality remain an open challenge. Inspired by scaling consistency, we show that smaller models can accurately predict significant differences in tokenizer impact on larger... | Jonas F. Lotz, António Vilarinho Lopes, Stephan Peitz, Hendra Setiawan, Leonardo Emili |  |
| 3035 |  |  [Emergent Abilities of Large Language Models under Continued Pre-training for Language Adaptation](https://aclanthology.org/2025.acl-long.1547/) |  | 0 | Continued pretraining (CPT) is a popular approach to adapt existing large language models (LLMs) to new languages. When doing so, it is common practice to include a portion of English data in the mixture, but its role has not been carefully studied to date. In this work, we show that including... | Ahmed Elhady, Eneko Agirre, Mikel Artetxe |  |
| 3036 |  |  [R-Fairness: Assessing Fairness of Ranking in Subjective Data](https://aclanthology.org/2025.acl-long.1548/) |  | 0 | Subjective data, reflecting individual opinions, permeates platforms like Yelp and Amazon, influencing everyday decisions. Upon a user query, collaborative rating platforms return a collection of items ranked in an order that is often not transparent to the users. Then, each item is presented with... | Lorenzo Balzotti, Donatella Firmani, Jerin George Mathew, Riccardo Torlone, Sihem AmerYahia |  |
| 3037 |  |  [RePanda: Pandas-powered Tabular Verification and Reasoning](https://aclanthology.org/2025.acl-long.1549/) |  | 0 | Fact-checking tabular data is essential for ensuring the accuracy of structured information in domains such as journalism, finance, and scientific research. However, existing methods often rely on black-box models with opaque reasoning. We introduce RePanda, a structured fact verification approach... | Atoosa Malemir Chegini, Keivan Rezaei, Hamid Eghbalzadeh, Soheil Feizi |  |
| 3038 |  |  [Towards Style Alignment in Cross-Cultural Translation](https://aclanthology.org/2025.acl-long.1550/) |  | 0 | Successful communication depends on the speaker’s intended style (i.e., what the speaker is trying to convey) aligning with the listener’s interpreted style (i.e., what the listener perceives). However, cultural differences often lead to misalignment between the two; for example, politeness is... | Shreya Havaldar, Adam Stein, Eric Wong, Lyle H. Ungar |  |
| 3039 |  |  [TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining](https://aclanthology.org/2025.acl-long.1551/) |  | 0 | Large Language Models (LLMs) trained on historical web data inevitably become outdated. We investigate evaluation strategies and update methods for LLMs as new data becomes available. We introduce a web-scale dataset for time-continual pretraining of LLMs derived from 114 dumps of Common Crawl (CC)... | Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri |  |
| 3040 |  |  [Entailed Between the Lines: Incorporating Implication into NLI](https://aclanthology.org/2025.acl-long.1552/) |  | 0 | Much of human communication depends on implication, conveying meaning beyond literal words to express a wider range of thoughts, intentions, and feelings. For models to better understand and facilitate human communication, they must be responsive to the text’s implicit meaning. We focus on Natural... | Shreya Havaldar, Hamidreza Alvari, John Palowitch, Mohammad Javad Hosseini, Senaka Buthpitiya, Alex Fabrikant |  |
| 3041 |  |  [Multi-Level Explanations for Generative Language Models](https://aclanthology.org/2025.acl-long.1553/) |  | 0 | Despite the increasing use of large language models (LLMs) for context-grounded tasks like summarization and question-answering, understanding what makes an LLM produce a certain response is challenging. We propose Multi-Level Explanations for Generative Language Models (MExGen), a technique to... | Lucas Monteiro Paes, Dennis Wei, Hyo Jin Do, Hendrik Strobelt, Ronny Luss, Amit Dhurandhar, Manish Nagireddy, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Werner Geyer, Soumya Ghosh |  |
| 3042 |  |  [A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems](https://aclanthology.org/2025.acl-long.1554/) |  | 0 | Privacy policies inform users about data collection and usage, yet their complexity limits accessibility for diverse populations. Existing Privacy Policy Question Answering (QA) systems exhibit performance disparities across English dialects, disadvantaging speakers of non-standard varieties. We... | Dorde Klisura, Astrid R. Bernaga Torres, Anna Karen GárateEscamilla, Rajesh Roshan Biswal, Ke Yang, Hilal Pataci, Anthony Rios |  |
| 3043 |  |  [Low-Bit Quantization Favors Undertrained LLMs](https://aclanthology.org/2025.acl-long.1555/) |  | 0 | Low-bit quantization improves machine learning model efficiency but surprisingly favors undertrained large language models (LLMs). Larger models or those trained on fewer tokens exhibit less quantization-induced degradation (QiD), while smaller, well-trained models face significant performance... | Xu Ouyang, Tao Ge, Thomas Hartvigsen, Zhisong Zhang, Haitao Mi, Dong Yu |  |
| 3044 |  |  [LETS-C: Leveraging Text Embedding for Time Series Classification](https://aclanthology.org/2025.acl-long.1557/) |  | 0 | Recent advancements in language modeling have shown promising results when applied to time series data. In particular, fine-tuning pre-trained large language models (LLMs) for time series classification tasks has achieved state-of-the-art (SOTA) performance on standard benchmarks. However, these... | Rachneet Kaur, Zhen Zeng, Tucker Balch, Manuela Veloso |  |
| 3045 |  |  [UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces](https://aclanthology.org/2025.acl-long.1558/) |  | 0 | Large multimodal models exhibit remarkable intelligence, yet their embodied cognitive abilities during motion in open-ended urban aerial spaces remain to be explored. We introduce a benchmark to evaluate whether video-large language models (Video-LLMs) can naturally process continuous first-person... | Baining Zhao, Jianjie Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang, Jinqiang Cui, Xinlei Chen, Yong Li |  |
| 3046 |  |  [HELIOS: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval](https://aclanthology.org/2025.acl-long.1559/) |  | 0 | Table-text retrieval aims to retrieve relevant tables and text to support open-domain question answering. Existing studies use either early or late fusion, but face limitations. Early fusion pre-aligns a table row with its associated passages, forming “stars,” which often include irrelevant... | Sungho Park, Joohyung Yun, Jongwuk Lee, WookShin Han |  |
| 3047 |  |  [ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities](https://aclanthology.org/2025.acl-long.1560/) |  | 0 | Traditional fixed test datasets fall short in evaluating the open-ended capabilities of foundation models. To address this, we propose ONEBench (OpeN-Ended Benchmarking), a new paradigm that consolidates individual evaluation datasets into a unified, ever-expanding sample pool. ONEBench enables... | Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge |  |
| 3048 |  |  [La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America](https://aclanthology.org/2025.acl-long.1561/) |  | 0 | Leaderboards showcase the current capabilities and limitations of Large Language Models (LLMs). To motivate the development of LLMs that represent the linguistic and cultural diversity of the Spanish-speaking community, we present La Leaderboard, the first open-source leaderboard to evaluate... | María Grandury, Javier AulaBlasco, Júlia Falcão, Clémentine Fourrier, Miguel González Saiz, Gonzalo Martínez, Gonzalo Santamaría Gómez, Rodrigo Agerri, Nuria AldamaGarcía, Luis Chiruzzo, Javier Conde, Helena GómezAdorno, Marta Guerrero Nieto, Guido Ivetta, Natàlia López Fuertes, Flor Miriam Plaza del Arco, María Teresa MartínValdivia, Helena Montoro Zamorano, Carmen Muñoz Sanz, Pedro Reviriego, Leire Rosado Plaza, Alejandro Vaca Serrano, María Estrella Vallecillo Rodríguez, Jorge Vallego, Irune Zubiaga |  |
| 3049 |  |  [Why Prompt Design Matters and Works: A Complexity Analysis of Prompt Search Space in LLMs](https://aclanthology.org/2025.acl-long.1562/) |  | 0 | Despite the remarkable successes of Large Language Models (LLMs), the underlying Transformer architecture has inherent limitations in handling complex reasoning tasks. Chain-of-Thought (CoT) prompting has emerged as a practical workaround, but most CoT-based methods rely on a single generic prompt... | Xiang Zhang, Juntai Cao, Chenyu You, Dujian Ding |  |
| 3050 |  |  [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://aclanthology.org/2025.acl-long.1563/) |  | 0 | As large language models (LLMs) scale in size and adoption, their computational and environmental costs continue to rise. Prior benchmarking efforts have primarily focused on latency reduction in idealized settings, often overlooking the diverse real-world inference workloads that shape energy use.... | Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell |  |
| 3051 |  |  [Optimizing Pre-Training Data Mixtures with Mixtures of Data Expert Models](https://aclanthology.org/2025.acl-long.1564/) |  | 0 | We propose a method to optimize language model pre-training data mixtures through efficient approximation of the cross-entropy loss corresponding to each candidate mixture via a Mixture of Data Experts (MDE). We use this approximation as a source of additional features in a regression model,... | Lior Belenki, Alekh Agarwal, Tianze Shi, Kristina Toutanova |  |
| 3052 |  |  [BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving](https://aclanthology.org/2025.acl-long.1565/) |  | 0 | Recent advancements in large language models (LLMs) have spurred growing interest in automatic theorem proving using Lean4, where effective tree search methods are crucial for navigating the underlying large proof search spaces. While the existing approaches primarily rely on value functions and/or... | Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Ming Ding |  |
| 3053 |  |  [Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation](https://aclanthology.org/2025.acl-long.1566/) |  | 0 | Large language models (LLMs) have exhibited the ability to effectively utilize external tools to address user queries. However, their performance may be limited in complex, multi-turn interactions involving users and multiple tools. To address this, we propose Magnet, a principled framework for... | Fan Yin, Zifeng Wang, IHung Hsu, Jun Yan, Ke Jiang, Yanfei Chen, Jindong Gu, Long T. Le, KaiWei Chang, ChenYu Lee, Hamid Palangi, Tomas Pfister |  |
| 3054 |  |  [Logic-Regularized Verifier Elicits Reasoning from LLMs](https://aclanthology.org/2025.acl-long.1567/) |  | 0 | Verifiers are crucial components for enhancing modern LLMs’ reasoning capability. Typical verifiers require resource-intensive supervised dataset construction, which is costly and faces limitations in data diversity. In this paper, we propose LOVER, an unsupervised verifier regularized by logical... | Xinyu Wang, Changzhi Sun, Lian Cheng, Yuanbin Wu, Dell Zhang, Xiaoling Wang, Xuelong Li |  |
| 3055 |  |  [Squeezed Attention: Accelerating Long Context Length LLM Inference](https://aclanthology.org/2025.acl-long.1568/) |  | 0 | Emerging Large Language Model (LLM) applications require long input context in order to perform complex tasks like document analysis and code generation.For these long context length applications, the length of the input prompt poses a significant challenge in terms of inference efficiency since... | Coleman Richard Charles Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, Sebastian Zhao, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami |  |
| 3056 |  |  [LangMark: A Multilingual Dataset for Automatic Post-Editing](https://aclanthology.org/2025.acl-long.1569/) |  | 0 | Automatic post-editing (APE) aims to correct errors in machine-translated text, enhancing translation quality, while reducing the need for human intervention. Despite advances in neural machine translation (NMT), the development of effective APE systems has been hindered by the lack of large-scale... | Diego Velazquez, Mikaela Grace, Konstantinos Karageorgos, Lawrence Carin, Aaron Schliem, Dimitrios Zaikis, Roger Wechsler |  |
| 3057 |  |  [Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer](https://aclanthology.org/2025.acl-long.1570/) |  | 0 | Foundation models and their checkpoints have significantly advanced deep learning, boosting performance across various applications. However, fine-tuned models often struggle outside their specific domains and exhibit considerable redundancy. Recent studies suggest that combining a pruned... | Guodong Du, Zitao Fang, Jing Li, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, HoKin Tang, Daojing He, Honghai Liu, Min Zhang |  |
| 3058 |  |  [Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models](https://aclanthology.org/2025.acl-long.1571/) |  | 0 | Model merging for Large Language Models (LLMs) directly fuses the parameters of different models finetuned on various tasks, creating a unified model for multi-domain tasks. However, due to potential vulnerabilities in models available on open-source platforms, model merging is susceptible to... | Zenghui Yuan, Yangming Xu, Jiawen Shi, Pan Zhou, Lichao Sun |  |
| 3059 |  |  [Where Are We? Evaluating LLM Performance on African Languages](https://aclanthology.org/2025.acl-long.1572/) |  | 0 | Africa’s rich linguistic heritage remains underrepresented in NLP, largely due to historical policies that favor foreign languages and create significant data inequities. In this paper, we integrate theoretical insights on Africa’s language landscape with an empirical evaluation using Sahara— a... | Ife Adebara, Hawau Olamide Toyin, Nahom Tesfu Ghebremichael, AbdelRahim A. Elmadany, Muhammad AbdulMageed |  |
| 3060 |  |  [Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning](https://aclanthology.org/2025.acl-long.1573/) |  | 0 | Large language models (LLMs) have shown impressive few-shot generalization on many tasks via in-context learning (ICL). Despite their success in showing such emergent abilities, the scale and complexity of larger models also lead to unprecedentedly high computational demands and deployment... | Chengwei Qin, Wenhan Xia, Fangkai Jiao, Chen Chen, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty |  |
| 3061 |  |  [CiteEval: Principle-Driven Citation Evaluation for Source Attribution](https://aclanthology.org/2025.acl-long.1574/) |  | 0 | Citation quality is crucial in information-seeking systems, directly influencing trust and the effectiveness of information access. Current evaluation frameworks, both human and automatic, mainly rely on Natural Language Inference (NLI) to assess binary or ternary supportiveness from cited sources,... | Yumo Xu, Peng Qi, Jifan Chen, Kunlun Liu, Rujun Han, Lan Liu, Bonan Min, Vittorio Castelli, Arshit Gupta, Zhiguo Wang |  |
| 3062 |  |  [HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model](https://aclanthology.org/2025.acl-long.1575/) |  | 0 | Large Language Model (LLM)-based agents exhibit significant potential across various domains, operating as interactive systems that process environmental observations to generate executable actions for target tasks. The effectiveness of these agents is significantly influenced by their memory... | Mengkang Hu, Tianxing Chen, Qiguang Chen, Yao Mu, Wenqi Shao, Ping Luo |  |
| 3063 |  |  [EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework](https://aclanthology.org/2025.acl-long.1576/) |  | 0 | Large Language Models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue... | Yao Shi, Rongkeng Liang, Yong Xu |  |
| 3064 |  |  [KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning](https://aclanthology.org/2025.acl-long.1577/) |  | 0 | Each year, tens of millions of essays are written and graded in college-level English courses. Students are asked to analyze literary and cultural texts through a process known as close reading, where they gather textual details from which to formulate evidence-based arguments. Despite being viewed... | Peiqi Sui, Juan Diego Rodriguez, Philippe Laban, Dean Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri |  |
| 3065 |  |  [Efficient Domain Continual pretraining by Mitigating the Stability Gap](https://aclanthology.org/2025.acl-long.1578/) |  | 0 | Continual pretraining enables Large Language Models (LLMs) to adapt to specialized domains like medicine and law. However, we observe a consistent phenomenon across different model sizes and domains: a temporary performance drop at the start of the continual pretraining process, followed by a... | Yiduo Guo, Jie Fu, Huishuai Zhang, Dongyan Zhao |  |
| 3066 |  |  [Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs](https://aclanthology.org/2025.acl-long.1579/) |  | 0 | As large language models (LLMs) become increasingly integrated into daily life, ensuring their cultural sensitivity and inclusivity is paramount. We introduce PALM, a year-long community-driven project covering all 22 Arab countries. The dataset contains instruction–response pairs in both Modern... | Fakhraddin Alwajih, Abdellah El Mekki, Samar Mohamed Magdy, AbdelRahim A. Elmadany, Omer Nacar, El Moatez Billah Nagoudi, Reem AbdelSalam, Hanin Atwany, Youssef Nafea, Abdulfattah Mohammed Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir EchChammakhy, Walid AlDhabyani, Marwa Mohamed Ali, Imen Jarraya, Ahmed Oumar ElShangiti, Aisha Alraeesi, Mohammed Anwar AlGhrawi, Abdulrahman S. AlBatati, Elgizouli Mohamed, Noha Taha Elgindi, Muhammed Saeed, Houdaifa Atou, Issam Ait Yahia, Abdelhak Bouayad, Mohammed Machrouh, Amal Makouar, Dania Alkawi, Mukhtar Mohamed, Safaa Taher Abdelfadil, Amine Ziad Ounnoughene, Rouabhia Anfel, Rwaa Assi, Ahmed Sorkatti, Mohamedou Cheikh Tourad, Anis Koubaa, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad AbdulMageed |  |
| 3067 |  |  [NewsInterview: a Dataset and a Playground to Evaluate LLMs' Grounding Gap via Informational Interviews](https://aclanthology.org/2025.acl-long.1580/) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities in generating coherent text but often struggle with grounding language and strategic dialogue. To address this gap, we focus on journalistic interviews, a domain rich in grounding communication and abundant in data. We curate a... | Alexander Spangher, Michael Lu, Sriya Kalyan, Hyundong Justin Cho, Tenghao Huang, Weiyan Shi, Jonathan May |  |
| 3068 |  |  [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://aclanthology.org/2025.acl-long.1581/) |  | 0 | The adeptness of Large Language Models (LLMs) in comprehending and following natural language instructions is critical for their deployment in sophisticated real-world applications. Existing evaluations mainly focus on fragmented constraints or narrow scenarios, but they overlook the... | Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou |  |
| 3069 |  |  [Towards Building Large Scale Datasets and State-of-the-Art Automatic Speech Translation Systems for 14 Indian Languages](https://aclanthology.org/2025.acl-long.1582/) |  | 0 | Speech translation for Indian languages remains a challenging task due to the scarcity of large-scale, publicly available datasets that capture the linguistic diversity and domain coverage essential for real-world applications. Existing datasets cover a fraction of Indian languages and lack the... | Ashwin Sankar, Sparsh Jain, Nikhil Narasimhan, Devilal Choudhary, Dhairya Suman, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M. Khapra, Raj Dabre |  |
| 3070 |  |  [CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG](https://aclanthology.org/2025.acl-long.1583/) |  | 0 | Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to enhance Multimodal Large Language Models by incorporating externally retrieved multimodal knowledge, but it introduces two challenges: Parametric-Retrieved Knowledge Inconsistency (PRKI), where discrepancies between parametric... | Yang Tian, Fan Liu, Jingyuan Zhang, Victoria W., Yupeng Hu, Liqiang Nie |  |
| 3071 |  |  [Mapping 1, 000+ Language Models via the Log-Likelihood Vector](https://aclanthology.org/2025.acl-long.1584/) |  | 0 | To compare autoregressive language models at scale, we propose using log-likelihood vectors computed on a predefined text set as model features. This approach has a solid theoretical basis: when treated as model coordinates, their squared Euclidean distance approximates the Kullback-Leibler... | Momose Oyama, Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira |  |
| 3072 |  |  [ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities](https://aclanthology.org/2025.acl-long.1585/) |  | 0 | Evaluating Large Language Models (LLMs) requires effective methods to assess semantic consistency across multiple reversible transformations. Traditional self-consistency methods often fail to capture subtle semantic errors in multi-step tasks. We introduce ConsistencyChecker, a tree-based... | Zhaochen Hong, Haofei Yu, Jiaxuan You |  |
| 3073 |  |  [Robust Estimation of Population-Level Effects in Repeated-Measures NLP Experimental Designs](https://aclanthology.org/2025.acl-long.1586/) |  | 0 | NLP research frequently grapples with multiple sources of variability—spanning runs, datasets, annotators, and more—yet conventional analysis methods often neglect these hierarchical structures, threatening the reproducibility of findings. To address this gap, we contribute a case study... | Alejandro BenitoSantos, Adrián Ghajari, Víctor Fresno |  |
| 3074 |  |  [FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation](https://aclanthology.org/2025.acl-long.1587/) |  | 0 | The rapid adoption of language models (LMs) across diverse applications has raised concerns about their factuality, i.e., their consistency with real-world facts. We introduce VERIFY, an evidence-based evaluation pipeline that measures LMs’ factuality in real-world user interactions. VERIFY... | Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang |  |
| 3075 |  |  [Training-free LLM Merging for Multi-task Learning](https://aclanthology.org/2025.acl-long.1588/) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse natural language processing (NLP) tasks. The release of open-source LLMs like LLaMA and Qwen has triggered the development of numerous fine-tuned models tailored for various tasks and languages. In this paper, we... | Zichuan Fu, Xian Wu, Yejing Wang, Wanyu Wang, Shanshan Ye, Hongzhi Yin, Yi Chang, Yefeng Zheng, Xiangyu Zhao |  |
| 3076 |  |  [Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection](https://aclanthology.org/2025.acl-long.1589/) |  | 0 | Generative Language Models rely on autoregressive decoding to produce the output sequence token by token. Many tasks such as preference optimization, require the model to produce task-level output consisting of multiple tokens directly by selecting candidates from a pool as predictions. Determining... | Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang |  |
| 3077 |  |  [Comparison-based Active Preference Learning for Multi-dimensional Personalization](https://aclanthology.org/2025.acl-long.1590/) |  | 0 | Large language models (LLMs) have shown remarkable success, but aligning them with human preferences remains a core challenge. As individuals have their own, multi-dimensional preferences, recent studies have explored \*multi-dimensional personalization\*, which aims to enable models to generate... | Minhyeon Oh, Seungjoon Lee, Jungseul Ok |  |
| 3078 |  |  [OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models](https://aclanthology.org/2025.acl-long.1591/) |  | 0 | Code LLMs have been widely used in various domains, including code generation, logical reasoning, and agent systems. However, open-access code LLMs mostly only release weights, lacking key features such as reproducible data pipelines and transparent training protocols, which are crucial for... | Siming Huang, Tianhao Cheng, Jason Klein Liu, Weidi Xu, Jiaran Hao, Liuyihan Song, Yang Xu, Jian Yang, Jiaheng Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Xianzhen Luo, Qiufeng Wang, YuanTao Fan, Qingfu Zhu, Zhaoxiang Zhang, Yang Gao, Jie Fu, Qian Liu, Houyi Li, Ge Zhang, Yuan Qi, Yinghui Xu, Wei Chu, Zili Wang |  |
| 3079 |  |  [LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs](https://aclanthology.org/2025.acl-long.1592/) |  | 0 | The widespread adoption of cloud-based proprietary large language models (LLMs) has introduced significant challenges, including operational dependencies, privacy concerns, and the necessity of continuous internet connectivity. In this work, we introduce an LLMOps pipeline, “LlamaDuo”, for the... | Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jing Tang |  |
| 3080 |  |  [AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment](https://aclanthology.org/2025.acl-long.1593/) |  | 0 | As a part of an embodied agent, Large Language Models (LLMs) are typically used for behavior planning given natural language instructions from the user. However, dealing with ambiguous instructions in real-world environments remains a challenge for LLMs. Various methods for task ambiguity detection... | Anastasiia Ivanova, Eva Bakaeva, Zoya Volovikova, Alexey K. Kovalev, Aleksandr Panov |  |
| 3081 |  |  [SocialCC: Interactive Evaluation for Cultural Competence in Language Agents](https://aclanthology.org/2025.acl-long.1594/) |  | 0 | Large Language Models (LLMs) are increasingly deployed worldwide, yet their ability to navigate cultural nuances remains underexplored. Misinterpreting cultural content can lead to AI-generated responses that are offensive or inappropriate, limiting their usability in global applications such as... | Jincenzi Wu, Jianxun Lian, Dingdong Wang, Helen M. Meng |  |
| 3082 |  |  [Scalable Vision Language Model Training via High Quality Data Curation](https://aclanthology.org/2025.acl-long.1595/) |  | 0 | In this paper, we introduce SAIL-VL ( ScAlable Vision Language Model TraIning via High QuaLity Data Curation), an open-source vision language model (VLM) series achieving state-of-the-art (SOTA) performance in 2B and 8B parameters. The following three key improvements contribute to SAIL-VL’s... | Hongyuan Dong, Zijian Kang, Weijie Yin, LiangXiao LiangXiao, ChaoFeng ChaoFeng, Ran Jiao |  |
| 3083 |  |  [GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion](https://aclanthology.org/2025.acl-long.1596/) |  | 0 | Generative recommendation is an emerging paradigm that leverages the extensive knowledge of large language models by formulating recommendations into a text-to-text generation task. However, existing studies face two key limitations in (i) incorporating implicit item relationships and (ii)... | Sunkyung Lee, Minjin Choi, Eunseong Choi, Hyeyoung Kim, Jongwuk Lee |  |
| 3084 |  |  [Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs](https://aclanthology.org/2025.acl-long.1597/) |  | 0 | Multi-head Latent Attention (MLA) is an innovative architecture proposed by DeepSeek, designed to ensure efficient and economical inference by significantly compressing the Key-Value (KV) cache into a latent vector. Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its... | Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Shenlixing Shenlixing, Chenzhan Chenzhan, Xipeng Qiu, Qi Zhang, Tao Gui |  |
| 3085 |  |  [TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding](https://aclanthology.org/2025.acl-long.1598/) |  | 0 | We propose TETRIS, a novel method that optimizes the total throughput of batch speculative decoding in multi-request settings. Unlike existing methods that optimize for a single request or a group of requests as a whole, TETRIS actively selects the most promising draft tokens (for every request in... | Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low |  |
| 3086 |  |  [Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks](https://aclanthology.org/2025.acl-long.1599/) |  | 0 | Examining logical inconsistencies among multiple statements (such as collections of sentences or question-answer pairs) is a crucial challenge in machine learning, particularly for ensuring the safety and reliability of models. Traditional methods that rely on 1:1 pairwise comparisons often fail to... | Mooho Song, Hye Ryung Son, JayYoon Lee |  |
| 3087 |  |  [Language Models can Subtly Deceive Without Lying: A Case Study on Strategic Phrasing in Legislation](https://aclanthology.org/2025.acl-long.1600/) |  | 0 | We explore the ability of large language models (LLMs) to engage in subtle deception through strategically phrasing and intentionally manipulating information. This harmful behavior can be hard to detect, unlike blatant lying or unintentional hallucination. We build a simple testbed mimicking a... | Atharvan Dogra, Krishna Pillutla, Ameet Deshpande, Ananya B. Sai, John J. Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran |  |
| 3088 |  |  [AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages](https://aclanthology.org/2025.acl-long.1601/) |  | 0 | Code-switching is prevalent in multilingual communities but lacks adequate high-quality data for model development, especially for African languages. To address this, we present AfroCS-xs, a small human-validated synthetic code-switched dataset for four African languages (Afrikaans, Sesotho,... | Kayode Olaleye, Arturo Oncevay, Mathieu Sibue, Nombuyiselo Zondi, Michelle Terblanche, Sibongile Mapikitla, Richard Lastrucci, Charese Smiley, Vukosi Marivate |  |
| 3089 |  |  [Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models](https://aclanthology.org/2025.acl-long.1602/) |  | 0 | Large language models (LLMs) have demonstrated impressive translation capabilities even without being explicitly trained on parallel data. This remarkable property has led some to believe that parallel data is no longer necessary for building multilingual language models. While some attribute this... | Muhammad Reza Qorib, Junyi Li, Hwee Tou Ng |  |
| 3090 |  |  [Design Choices for Extending the Context Length of Visual Language Models](https://aclanthology.org/2025.acl-long.1603/) |  | 0 | Visual Language Models (VLMs) demonstrate impressive capabilities in processing multimodal inputs, yet applications such as visual agents, which require handling multiple images and high-resolution videos, demand enhanced long-range modeling. Moreover, existing open-source VLMs lack systematic... | Mukai Li, Lei Li, Shansan Gong, Qi Liu |  |

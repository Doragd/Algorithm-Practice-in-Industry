# ACL2024

## 会议论文列表

本会议共有 1960 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Feriji: A French-Zarma Parallel Corpus, Glossary & Translator](https://doi.org/10.18653/v1/2024.acl-srw.1) |  | 0 | Machine translation (MT) is a rapidly expanding field that has experienced significant advancements in recent years with the development of models capable of translating multiple languages with remarkable accuracy. However, the representation of African languages in this field still needs... | Mamadou Keita, Elysabhete Amadou Ibrahim, Habibatou Abdoulaye Alfari, Christopher Homan |  |
| 2 |  |  [Pragmatic inference of scalar implicature by LLMs](https://doi.org/10.18653/v1/2024.acl-srw.2) |  | 0 | This study investigates how Large Language Models (LLMs), particularly BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic inference of scalar implicature, such as some. Two sets of experiments were conducted using cosine similarity and next sentence/token prediction as... | Yeeun Cho, Seong mook Kim |  |
| 3 |  |  [Topic Modeling for Short Texts with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.3) |  | 0 | As conventional topic models rely on word co-occurrence to infer latent topics, topic modeling for short texts has been a long-standing challenge. Large Language Models (LLMs) can potentially overcome this challenge by contextually learning the meanings of words via pretraining. In this paper, we... | Tomoki Doi, Masaru Isonuma, Hitomi Yanaka |  |
| 4 |  |  [Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases](https://doi.org/10.18653/v1/2024.acl-srw.4) |  | 0 |  | Xiang Zhang, Khatoon Khedri, Reza Rawassizadeh |  |
| 5 |  |  [Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer](https://doi.org/10.18653/v1/2024.acl-srw.5) |  | 0 | Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer... | Yongqi Wang, Jionghao Bai, Rongjie Huang, Ruiqi Li, Zhiqing Hong, Zhou Zhao |  |
| 6 |  |  [InstructCoder: Instruction Tuning Large Language Models for Code Editing](https://doi.org/10.18653/v1/2024.acl-srw.6) |  | 0 |  | Kaixin Li, Qisheng Hu, James Xu Zhao, Hui Chen, Yuxi Xie, Tiedong Liu, Michael Shieh, Junxian He |  |
| 7 |  |  [BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization](https://doi.org/10.18653/v1/2024.acl-srw.7) |  | 0 | Large Language Models (LLMs) have become pivotal in advancing natural language processing, yet their potential to perpetuate biases poses significant concerns. This paper introduces a new framework employing Direct Preference Optimization (DPO) to mitigate gender, racial, and religious biases in... | Ahmed Allam |  |
| 8 |  |  [MoExtend: Tuning New Experts for Modality and Task Extension](https://doi.org/10.18653/v1/2024.acl-srw.8) |  | 0 |  | Shanshan Zhong, Shanghua Gao, Zhongzhan Huang, Wushao Wen, Marinka Zitnik, Pan Zhou |  |
| 9 |  |  [On the Interpretability of Deep Learning Models for Collaborative Argumentation Analysis in Classrooms](https://doi.org/10.18653/v1/2024.acl-srw.9) |  | 0 |  | Deliang Wang, Gaowei Chen |  |
| 10 |  |  [Document Alignment based on Overlapping Fixed-Length Segments](https://doi.org/10.18653/v1/2024.acl-srw.10) |  | 0 | Acquiring large-scale parallel corpora is crucial for NLP tasks such as Neural Machine Translation, and web crawling has become a popular methodology for this purpose. Previous studies have been conducted based on sentence-based segmentation (SBS) when aligning documents in various languages which... | Xiaotian Wang, Takehito Utsuro, Masaaki Nagata |  |
| 11 |  |  [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.acl-srw.11) |  | 0 |  | Enrico Benedetti, Akiko Aizawa, Florian Boudin |  |
| 12 |  |  [Z-coref: Thai Coreference and Zero Pronoun Resolution](https://doi.org/10.18653/v1/2024.acl-srw.12) |  | 0 |  | Poomphob Suwannapichat, Sansiri Tarnpradab, Santitham Promon |  |
| 13 |  |  [ReMAG-KR: Retrieval and Medically Assisted Generation with Knowledge Reduction for Medical Question Answering](https://doi.org/10.18653/v1/2024.acl-srw.13) |  | 0 | Large Language Models (LLMs) have significant potential for facilitating intelligent end-user applications in healthcare. However, hallucinations remain an inherent problem with LLMs, making it crucial to address this issue with extensive medical knowledge and data. In this work, we propose a... | Sidhaarth Murali, Sowmya S., Supreetha R. |  |
| 14 |  |  [Plot Retrieval as an Assessment of Abstract Semantic Association](https://doi.org/10.18653/v1/2024.acl-srw.14) |  | 0 |  | Shicheng Xu, Liang Pang, Jiangnan Li, Mo Yu, Fandong Meng, Huawei Shen, Xueqi Cheng, Jie Zhou |  |
| 15 |  |  [Demystifying Instruction Mixing for Fine-tuning Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.15) |  | 0 | Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP... | Renxi Wang, Haonan Li, Minghao Wu, Yuxia Wang, Xudong Han, Chiyu Zhang, Timothy Baldwin |  |
| 16 |  |  [Fine-Tuning ASR models for Very Low-Resource Languages: A Study on Mvskoke](https://doi.org/10.18653/v1/2024.acl-srw.16) |  | 0 | Recent advancements in multilingual models for automatic speech recognition (ASR) have been able to achieve a high accuracy for languages with extremely limited resources. This study examines ASR modeling for the Mvskoke language, an indigenous language of America. The parameter efficiency of... | Julia Mainzinger, GinaAnne Levow |  |
| 17 |  |  [Automating Qualitative Data Analysis with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.17) |  | 0 | This PhD proposal aims to investigate ways of automating qualitative data analysis, specifically the thematic coding of texts. Despite existing methods vastly covered in literature, they mainly use Topic Modeling and other quantitative approaches which are far from resembling a human’s analysis... | Angelina Parfenova, Alexander Denzler, Jörgen Pfeffer |  |
| 18 |  |  [ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection](https://doi.org/10.18653/v1/2024.acl-srw.18) |  | 0 | Research on token-level reference-free hallucination detection has predominantly focused on English, primarily due to the scarcity of robust datasets in other languages. This has hindered systematic investigations into the effectiveness of cross-lingual transfer for this important NLP application.... | Janek Herrlein, ChiaChien Hung, Goran Glavas |  |
| 19 |  |  [Label-Aware Automatic Verbalizer for Few-Shot Text Classification in Mid-To-Low Resource Languages](https://doi.org/10.18653/v1/2024.acl-srw.19) |  | 0 | Prompt-based learning has shown its effectiveness in few-shot text classification. A key factor in its success is a verbalizer, which translates output from a language model into a predicted class. Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the... | Thanakorn Thaminkaew, Piyawat Lertvittayakumjorn, Peerapon Vateekul |  |
| 20 |  |  [Vector Spaces for Quantifying Disparity of Multiword Expressions in Annotated Text](https://doi.org/10.18653/v1/2024.acl-srw.20) |  | 0 | Multiword Expressions (MWEs) make a goodcase study for linguistic diversity due to theiridiosyncratic nature. Defining MWE canonicalforms as types, diversity may be measurednotably through disparity, based on pairwisedistances between types. To this aim, wetrain static MWE-aware word embeddings... | Louis Estève, Agata Savary, Thomas Lavergne |  |
| 21 |  |  [Narratives at Conflict: Computational Analysis of News Framing in Multilingual Disinformation Campaigns](https://doi.org/10.18653/v1/2024.acl-srw.21) |  | 0 | Any report frames issues to favor a particular interpretation by highlighting or excluding certain aspects of a story. Despite the widespread use of framing in disinformation, framing properties and detection methods remain underexplored outside the English-speaking world. We explore how... | Antonina Sinelnik, Dirk Hovy |  |
| 22 |  |  [Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data](https://doi.org/10.18653/v1/2024.acl-srw.22) |  | 0 | Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages. Automated scalable methods are necessary due to the impracticality of manual labeling. In this paper, we model... | Julian Schelb, Andreas Spitz, Roberto Ulloa |  |
| 23 |  |  [Knowledge Editing of Large Language Models Unconstrained by Word Order](https://doi.org/10.18653/v1/2024.acl-srw.23) |  | 0 | Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves. To address this issue, a method called local modification-based knowledge... | Ryoma Ishigaki, Jundai Suzuki, Masaki Shuzo, Eisaku Maeda |  |
| 24 |  |  [Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning](https://doi.org/10.18653/v1/2024.acl-srw.24) |  | 0 | Identifying beneficial tasks to transfer from is a critical step toward successful intermediate-task transfer learning. In this work, we experiment with 130 source-target task combinations and demonstrate that the transfer performance exhibits severe variance across different source tasks and... | PinJie Lin, Miaoran Zhang, Marius Mosbach, Dietrich Klakow |  |
| 25 |  |  [Does the structure of textual content have an impact on language models for automatic summarization?](https://doi.org/10.18653/v1/2024.acl-srw.25) |  | 0 | The processing of long sequences with models remains a subject in its own right, including automatic summary, despite recent improvements. In this work, we present experiments on the automatic summarization of scientific articles using BART models, taking into account textual information coming... | Eve Sauvage, Sabrina Campano, Lydia Ould Ouali, Cyril Grouin |  |
| 26 |  |  [Action Inference for Destination Prediction in Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-srw.26) |  | 0 | Vision-and-Language Navigation (VLN) encompasses interacting with autonomous vehicles using language and visual input from the perspective of mobility.Most of the previous work in this field focuses on spatial reasoning and the semantic grounding of visual information.However, reasoning based on... | Anirudh Reddy Kondapally, Kentaro Yamada, Hitomi Yanaka |  |
| 27 |  |  [A Computational Analysis and Exploration of Linguistic Borrowings in French Rap Lyrics](https://doi.org/10.18653/v1/2024.acl-srw.27) |  | 0 | In France, linguistic borrowings in the relatively conservative French language are an important site of cultural debate, and rap in particular is a hotspot for borrowings. In this work, we use computational methods to understand the factors that affect the prominence and prevalence of a borrowing.... | Lucas Zurbuchen, Rob Voigt |  |
| 28 |  |  [On Improving Repository-Level Code QA for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.28) |  | 0 | Large Language Models (LLMs) such as ChatGPT, GitHub Copilot, Llama, or Mistral assist programmers as copilots and knowledge sources to make the coding process faster and more efficient. This paper aims to improve the copilot performance by implementing different self-alignment processes and... | Jan Strich, Florian Schneider, Irina Nikishina, Chris Biemann |  |
| 29 |  |  [Compromesso! Italian Many-Shot Jailbreaks undermine the safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.29) |  | 0 | As diverse linguistic communities and users adopt Large Language Models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to align these models with safe and ethical guidelines, they can still be induced into unsafe behavior with jailbreaking, a technique in... | Fabio Pernisi, Dirk Hovy, Paul Röttger |  |
| 30 |  |  [Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.30) |  | 0 |  | Yunsoo Kim |  |
| 31 |  |  [ViMedAQA: A Vietnamese Medical Abstractive Question-Answering Dataset and Findings of Large Language Model](https://doi.org/10.18653/v1/2024.acl-srw.31) |  | 0 | Question answering involves creating answers to questions. With the growth of large language models, the ability of question-answering systems has dramatically improved. However, there is a lack of Vietnamese abstractive question-answering datasets, especially in the medical domain. Therefore, this... | MinhNam Tran, PhuVinh Nguyen, Long Nguyen, Dien Dinh |  |
| 32 |  |  [Rescue: Ranking LLM Responses with Partial Ordering to Improve Response Generation](https://doi.org/10.18653/v1/2024.acl-srw.32) |  | 0 | Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert-annotated data is costly for most tasks. In this paper,... | Yikun Wang, Rui Zheng, Haoming Li, Qi Zhang, Tao Gui, Fei Liu |  |
| 33 |  |  [Basreh or Basra? Geoparsing Historical Locations in the Svoboda Diaries](https://doi.org/10.18653/v1/2024.acl-srw.33) |  | 0 | Geoparsing, the task of assigning coordinates to locations extracted from free text, is invaluable in enabling us to place locations in time and space. In the historical domain, many geoparsing corpora are from large news collections. We examine the Svoboda Diaries, a small historical corpus... | Jolie Zhou, Camille Cole, Annie Chen |  |
| 34 |  |  [Homophone2Vec: Embedding Space Analysis for Empirical Evaluation of Phonological and Semantic Similarity](https://doi.org/10.18653/v1/2024.acl-srw.34) |  | 0 | This paper introduces a novel method for empirically evaluating the relationship between the phonological and semantic similarity of linguistic units using embedding spaces. Chinese character homophones are used as a proof-of-concept. We employ cosine similarity as a proxy for semantic similarity... | Sophie Wu, Anita Zheng, Joey Chuang |  |
| 35 |  |  [Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition](https://doi.org/10.18653/v1/2024.acl-srw.35) |  | 0 | Knowledge distillation allows smaller neural networks to emulate the performance of larger, teacher models with reduced computational demands. Traditional methods for Large Language Models (LLMs) often necessitate extensive fine-tuning, which limits their accessibility. To address this, we... | Tyler McDonald, Ali Emami |  |
| 36 |  |  [Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges](https://doi.org/10.18653/v1/2024.acl-srw.36) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply common sense. A relevant application is to use them for creating high-quality synthetic datasets for downstream tasks. In this work, we probe... | Vinay Samuel, Houda Aynaou, Arijit Ghosh Chowdhury, Karthik Venkat Ramanan, Aman Chadha |  |
| 37 |  |  [Automatic Derivation of Semantic Representations for Thai Serial Verb Constructions: A Grammar-Based Approach](https://doi.org/10.18653/v1/2024.acl-srw.37) |  | 0 | Deep semantic representations are useful for many NLU tasks (Droganova and Zeman 2019; Schuster and Manning-2016). Manual annotation to build these representations is time-consuming, and so automatic approaches are preferred (Droganova and Zeman 2019; Bender et al. 2015). This paper demonstrates... | Vipasha Bansal |  |
| 38 |  |  [Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai](https://doi.org/10.18653/v1/2024.acl-srw.38) |  | 0 |  | Parinthapat Pengpun, Can Udomcharoenchaikit, Weerayut Buaphet, Peerat Limkonchotiwat |  |
| 39 |  |  [Bridging Distribution Gap via Semantic Rewriting with LLMs to Enhance OOD Robustness](https://doi.org/10.18653/v1/2024.acl-srw.39) |  | 0 | This paper investigates the robustness of Large Language Models (LLMs) against Out-Of-Distribution (OOD) data within the context of sentiment analysis. Traditional fine-tuning approaches often fail to generalize effectively across different data distributions, limiting the practical deployment of... | Manas Madine |  |
| 40 |  |  [CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units](https://doi.org/10.18653/v1/2024.acl-srw.40) |  | 0 | Multilingual code-switching research is often hindered by the lack and linguistically biased status of available datasets. To expand language representation, we synthesize code-switching data by replacing intonation units detected through PSST, a speech segmentation model fine-tuned from OpenAI’s... | Yeeun Kang |  |
| 41 |  |  [An Analysis under a Unified Formulation of Learning Algorithms with Output Constraints](https://doi.org/10.18653/v1/2024.acl-srw.41) |  | 0 |  | Mooho Song, JayYoon Lee |  |
| 42 |  |  [Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation](https://doi.org/10.18653/v1/2024.acl-srw.42) |  | 0 | The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but... | James O'Doherty, Cian Nolan, Yufang Hou, Anya Belz |  |
| 43 |  |  [Improving Sentence Embeddings with Automatic Generation of Training Data Using Few-shot Examples](https://doi.org/10.18653/v1/2024.acl-srw.43) |  | 0 | Decoder-based large language models (LLMs) have shown high performance on many tasks in natural language processing. This is also true for sentence embedding learning, where a decoder-based model, PromptEOL, has achieved the best performance on semantic textual similarity (STS) tasks. However,... | Soma Sato, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda |  |
| 44 |  |  [Curriculum Learning for Small Code Language Models](https://doi.org/10.18653/v1/2024.acl-srw.44) |  | 0 | Code language models have emerged as useful tools for various programming tasks, yet they often struggle when it comes to complex ones. In this paper, we explore the potential of curriculum learning in enhancing the performance of these models. While prior research has suggested that curriculum... | Marwa Naïr, Kamel Mohammed Yamani, Lynda Said L'Hadj, Riyadh Baghdadi |  |
| 45 |  |  [Question-Analysis Prompting Improves LLM Performance in Reasoning Tasks](https://doi.org/10.18653/v1/2024.acl-srw.45) |  | 0 | Although LLMs have the potential to transform many fields, they still underperform humans in reasoning tasks. Existing methods induce the model to produce step-by-step calculations, but this research explores the question: Does making the LLM analyze the question improve its performance? We propose... | Dharunish Yugeswardeenoo, Kevin Zhu, Sean O'Brien |  |
| 46 |  |  [An Individualized News Affective Response Dataset](https://doi.org/10.18653/v1/2024.acl-srw.46) |  | 0 |  | Tiancheng Hu, Nigel Collier |  |
| 47 |  |  [How Well Do Vision Models Encode Diagram Attributes?](https://doi.org/10.18653/v1/2024.acl-srw.47) |  | 0 |  | Haruto Yoshida, Keito Kudo, Yoichi Aoki, Ryota Tanaka, Itsumi Saito, Keisuke Sakaguchi, Kentaro Inui |  |
| 48 |  |  [CheckersGPT: Learning World Models through Language Modeling](https://doi.org/10.18653/v1/2024.acl-srw.48) |  | 0 | Although Large Language Models (LLMs) have been trained using just the next token prediction objective, these have shown impressive performance on various tasks. Consequently, it has attracted research interests in this regard. While one line of work in the past has suggested that LLMs learn... | Abhinav Joshi, Vaibhav Sharma, Ashutosh Modi |  |
| 49 |  |  [In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery](https://doi.org/10.18653/v1/2024.acl-srw.49) |  | 0 | State of the art Symbolic Regression (SR) methods currently build specialized models, while the application of Large Language Models (LLMs) remains largely unexplored. In this work, we introduce the first comprehensive framework that utilizes LLMs for the task of SR.We propose In-Context Symbolic... | Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen |  |
| 50 |  |  [STEP: Staged Parameter-Efficient Pre-training for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.50) |  | 0 | We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity,... | Kazuki Yano, Takumi Ito, Jun Suzuki |  |
| 51 |  |  [Can Language Models Serve as Text-Based World Simulators?](https://doi.org/10.18653/v1/2024.acl-short.1) |  | 0 | Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus... | Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, MarcAlexandre Côté, Peter Clark, Peter A. Jansen |  |
| 52 |  |  [FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.2) |  | 0 | One type of question that is commonly found in day-to-day scenarios is “fan-out” questions, complex multi-hop, multi-document reasoning questions that require finding information about a large number of entities. However, there exist few resources to evaluate this type of question-answering... | Andrew Zhu, Alyssa Hwang, Liam Dugan, Chris CallisonBurch |  |
| 53 |  |  [Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance](https://doi.org/10.18653/v1/2024.acl-short.3) |  | 0 | This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity... | Yewei Song, Cedric Lothritz, Xunzhu Tang, Tegawendé F. Bissyandé, Jacques Klein |  |
| 54 |  |  [Resisting the Lure of the Skyline: Grounding Practices in Active Learning for Morphological Inflection](https://doi.org/10.18653/v1/2024.acl-short.4) |  | 0 | Active learning (AL) aims to lower the demand of annotation by selecting informative unannotated samples for the model building. In this paper, we explore the importance of conscious experimental design in the language documentation and description setting, particularly the distribution of the... | Saliha Muradoglu, Michael Ginn, Miikka Silfverberg, Mans Hulden |  |
| 55 |  |  [Speculative Contrastive Decoding](https://doi.org/10.18653/v1/2024.acl-short.5) |  | 0 | Large language models (LLMs) exhibit exceptional performance in language tasks, yet their auto-regressive inference is limited due to high computational requirements and is sub-optimal due to the exposure bias. Inspired by speculative decoding and contrastive decoding, we introduce Speculative... | Hongyi Yuan, Keming Lu, Fei Huang, Zheng Yuan, Chang Zhou |  |
| 56 |  |  [RDRec: Rationale Distillation for LLM-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.6) |  | 0 | Large language model (LLM)-based recommender models that bridge users and items through textual prompts for effective semantic reasoning have gained considerable attention. However, few methods consider the underlying rationales behind interactions, such as user preferences and item attributes,... | Xinfeng Wang, Jin Cui, Yoshimi Suzuki, Fumiyo Fukumoto |  |
| 57 |  |  [Isotropy, Clusters, and Classifiers](https://doi.org/10.18653/v1/2024.acl-short.7) |  | 0 | Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the... | Timothee Mickus, StigArne Grönroos, Joseph Attieh |  |
| 58 |  |  [Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks](https://doi.org/10.18653/v1/2024.acl-short.8) |  | 0 | The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate. We show that LLMs are frequently able to correctly and confidently predict the first digit of n-digit by m-digit multiplication tasks without using... | Andrew Gambardella, Yusuke Iwasawa, Yutaka Matsuo |  |
| 59 |  |  [Simpson's Paradox and the Accuracy-Fluency Tradeoff in Translation](https://doi.org/10.18653/v1/2024.acl-short.9) |  | 0 | A good translation should be faithful to the source and should respect the norms of the target language. We address a theoretical puzzle about the relationship between these objectives. On one hand, intuition and some prior work suggest that accuracy and fluency should trade off against each other,... | Zheng Wei Lim, Ekaterina Vylomova, Trevor Cohn, Charles Kemp |  |
| 60 |  |  [UltraSparseBERT: 99% Conditionally Sparse Language Modelling](https://doi.org/10.18653/v1/2024.acl-short.10) |  | 0 | We present UltraSparseBERT, a BERT variant that uses 0.3% of its neurons during inference while performing on par with similar BERT models. UltraSparseBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by reorganizing feedforward networks into fast... | Peter Belcak, Roger Wattenhofer |  |
| 61 |  |  [SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark](https://doi.org/10.18653/v1/2024.acl-short.11) |  | 0 | The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including... | Zhenwen Liang, Kehan Guo, Gang Liu, Taicheng Guo, Yujun Zhou, Tianyu Yang, Jiajun Jiao, Renjie Pi, Jipeng Zhang, Xiangliang Zhang |  |
| 62 |  |  [On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.12) |  | 0 | Retrieval augmented generation (RAG) exhibits outstanding performance in promoting the knowledge capabilities of large language models (LLMs) with retrieved documents related to user queries. However, RAG only focuses on improving the response quality of LLMs via enhancing queries indiscriminately... | Dongyang Li, Junbing Yan, Taolin Zhang, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue, Jun Huang |  |
| 63 |  |  [IEPile: Unearthing Large Scale Schema-Conditioned Information Extraction Corpus](https://doi.org/10.18653/v1/2024.acl-short.13) |  | 0 | Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE... | Honghao Gui, Lin Yuan, Hongbin Ye, Ningyu Zhang, Mengshu Sun, Lei Liang, Huajun Chen |  |
| 64 |  |  [Bi-Directional Multi-Granularity Generation Framework for Knowledge Graph-to-Text with Large Language Model](https://doi.org/10.18653/v1/2024.acl-short.14) |  | 0 | The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. Existing methods generate the whole target text based on all KG triples at once and may incorporate... | Haowei Du, Chen Li, Dinghao Zhang, Dongyan Zhao |  |
| 65 |  |  [Code-Switching Can be Better Aligners: Advancing Cross-Lingual SLU through Representation-Level and Prediction-Level Alignment](https://doi.org/10.18653/v1/2024.acl-short.15) |  | 0 | Zero-shot cross-lingual spoken language understanding (SLU) can promote the globalization application of dialog systems, which has attracted increasing attention. While current code-switching based cross-lingual SLU frameworks have shown promising results, they (i) predominantly utilize contrastive... | Zhihong Zhu, Xuxin Cheng, Zhanpeng Chen, Xianwei Zhuang, Zhiqi Huang, Yuexian Zou |  |
| 66 |  |  [AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://doi.org/10.18653/v1/2024.acl-short.16) |  | 0 | We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low-Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each... | Zeyu Liu, Souvik Kundu, Anni Li, Junrui Wan, Lianghao Jiang, Peter A. Beerel |  |
| 67 |  |  [DDPrompt: Differential Diversity Prompting in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.17) |  | 0 | Large Language Models (LLMs) have shown that their reasoning ability could be enhanced through approaches like Chain-of-Thought (CoT) prompting. However, these methods use single prompts for different types of questions and do not design appropriate prompts for questions with different... | Lin Mu, Wenhao Zhang, Yiwen Zhang, Peiquan Jin |  |
| 68 |  |  [Monotonic Representation of Numeric Attributes in Language Models](https://doi.org/10.18653/v1/2024.acl-short.18) |  | 0 | Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model’s internal representations is not understood well. Here, we introduce a method for finding and editing representations of... | Benjamin Heinzerling, Kentaro Inui |  |
| 69 |  |  [Two Issues with Chinese Spelling Correction and A Refinement Solution](https://doi.org/10.18653/v1/2024.acl-short.19) |  | 0 | The Chinese Spelling Correction (CSC) task aims to detect and correct misspelled characters in Chinese text, and has received lots of attention in the past few years. Most recent studies adopt a Transformer-based model and leverage different features of characters such as pronunciation, glyph and... | Changxuan Sun, Linlin She, Xuesong Lu |  |
| 70 |  |  [DynaSemble: Dynamic Ensembling of Textual and Structure-Based Models for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-short.20) |  | 0 | We consider two popular approaches to KnowledgeGraph Completion (KGC): textual modelsthat rely on textual entity descriptions, andstructure-based models that exploit the connectivitystructure of the Knowledge Graph(KG). Preliminary experiments show that theseapproaches have complementary... | Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam |  |
| 71 |  |  [Fine-Tuning Pre-Trained Language Models with Gaze Supervision](https://doi.org/10.18653/v1/2024.acl-short.21) |  | 0 | Human gaze data provide cognitive information that reflect human language comprehension and has been effectively integrated into a variety of natural language processing (NLP) tasks, demonstrating improved performance over corresponding plain text-based models. In this work, we propose to integrate... | Shuwen Deng, Paul Prasse, David R. Reich, Tobias Scheffer, Lena A. Jäger |  |
| 72 |  |  [Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech](https://doi.org/10.18653/v1/2024.acl-short.22) |  | 0 | Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task (Pupier et al. 2022), as a way of incorporating prosodic information in the parsing system and bypassing the limitations of a pipeline approach that would consist of... | Adrien Pupier, Maximin Coavoux, Jérôme Goulian, Benjamin Lecouteux |  |
| 73 |  |  [Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access](https://doi.org/10.18653/v1/2024.acl-short.23) |  | 0 | Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually... | Saibo Geng, Berkay Döner, Chris Wendler, Martin Josifoski, Robert West |  |
| 74 |  |  [On the Semantic Latent Space of Diffusion-Based Text-To-Speech Models](https://doi.org/10.18653/v1/2024.acl-short.24) |  | 0 | The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized... | Miri VarshavskyHassid, Roy Hirsch, Regev Cohen, Tomer Golany, Daniel Freedman, Ehud Rivlin |  |
| 75 |  |  [Learnable Privacy Neurons Localization in Language Models](https://doi.org/10.18653/v1/2024.acl-short.25) |  | 0 | Concerns regarding Large Language Models (LLMs) to memorize and disclose private information, particularly Personally Identifiable Information (PII), become prominent within the community. Many efforts have been made to mitigate the privacy risks.However, the mechanism through which LLMs memorize... | Ruizhe Chen, Tianxiang Hu, Yang Feng, Zuozhu Liu |  |
| 76 |  |  [Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs](https://doi.org/10.18653/v1/2024.acl-short.26) |  | 0 | Humans often express their communicative intents indirectly or non-literally, which requires their interlocutors—human or AI—to understand beyond the literal meaning of words. While most existing work has focused on discriminative evaluations, we present a new approach to generatively evaluate... | Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap |  |
| 77 |  |  [Generating Harder Cross-document Event Coreference Resolution Datasets using Metaphoric Paraphrasing](https://doi.org/10.18653/v1/2024.acl-short.27) |  | 0 | The most popular Cross-Document Event Coreference Resolution (CDEC) datasets fail to convey the true difficulty of the task, due to the lack of lexical diversity between coreferring event triggers (words or phrases that refer to an event). Furthermore, there is a dearth of event datasets for... | Shafiuddin Rehan Ahmed, Zhiyong Eric Wang, George Baker, Kevin Stowe, James H. Martin |  |
| 78 |  |  [Soft Self-Consistency Improves Language Models Agents](https://doi.org/10.18653/v1/2024.acl-short.28) |  | 0 | Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current “sample and select” methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers,... | Han Wang, Archiki Prasad, Elias StengelEskin, Mohit Bansal |  |
| 79 |  |  [RecGPT: Generative Pre-training for Text-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.29) |  | 0 | We present the first domain-adapted and fully-trained large language model, RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for text-based recommendation. Experimental results on rating prediction and sequential recommendation tasks show that our model, RecGPT-7B-Instruct,... | Hoang Ngo, Dat Quoc Nguyen |  |
| 80 |  |  [MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations](https://doi.org/10.18653/v1/2024.acl-short.30) |  | 0 | Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a... | GiaBao Dinh Ho, Chang Wei Tan, Zahra Zamanzadeh Darban, Mahsa Salehi, Reza Haffari, Wray L. Buntine |  |
| 81 |  |  [What Does Parameter-free Probing Really Uncover?](https://doi.org/10.18653/v1/2024.acl-short.31) |  | 0 | Supervised approaches to probing large language models (LLMs) have been criticized of using pre-defined theory-laden target labels. As an alternative, parameter-free probing constructs structural representations bottom-up via information derived from the LLM alone. This has been suggested to... | Tommi BuderGröndahl |  |
| 82 |  |  [ATLAS: Improving Lay Summarisation with Attribute-based Control](https://doi.org/10.18653/v1/2024.acl-short.32) |  | 0 | Lay summarisation aims to produce summaries of scientific articles that are comprehensible to non-expert audiences. However, previous work assumes a one-size-fits-all approach, where the content and style of the produced summary are entirely dependent on the data used to train the model. In... | Zhihao Zhang, Tomas Goldsack, Carolina Scarton, Chenghua Lin |  |
| 83 |  |  [EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-short.33) |  | 0 | The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated, leaving the gap between current LVLMs and qualified embodied... | Mengfei Du, Binhao Wu, Zejun Li, Xuanjing Huang, Zhongyu Wei |  |
| 84 |  |  [Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark](https://doi.org/10.18653/v1/2024.acl-short.34) |  | 0 | Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of noise,... | Niklas Wretblad, Fredrik Gordh Riseby, Rahul Biswas, Amin Ahmadi, Oskar Holmström |  |
| 85 |  |  [Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-short.35) |  | 0 | This study investigates the existence of positional biases in Transformer-based language models for text representation learning, particularly in the context of web document retrieval. We build on previous research that demonstrated loss of information in the middle of input sequences for causal... | João Coelho, Bruno Martins, João Magalhães, Jamie Callan, Chenyan Xiong |  |
| 86 |  |  [That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses](https://doi.org/10.18653/v1/2024.acl-short.36) |  | 0 | The Uniform Information Density (UID) hypothesis posits that speakers optimize the communicative properties of their utterances by avoiding spikes in information, thereby maintaining a relatively uniform information profile over time. This paper investigates the impact of UID principles on... | Ella Rabinovich |  |
| 87 |  |  [Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?](https://doi.org/10.18653/v1/2024.acl-short.37) |  | 0 | We examine whether large language models (LLMs) exhibit race- and gender-based name discrimination in hiring decisions, similar to classic findings in the social sciences (Bertrand and Mullainathan, 2004). We design a series of templatic prompts to LLMs to write an email to a named job applicant... | Haozhe An, Christabel Acquaye, Colin Wang, Zongxia Li, Rachel Rudinger |  |
| 88 |  |  [Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster](https://doi.org/10.18653/v1/2024.acl-short.38) |  | 0 | Content moderators play a key role in keeping the conversation on social media healthy. While the high volume of content they need to judge represents a bottleneck to the moderation pipeline, no studies have explored how models could support them to make faster decisions. There is, by now, a vast... | Agostina Calabrese, Leonardo Neves, Neil Shah, Maarten W. Bos, Björn Ross, Mirella Lapata, Francesco Barbieri |  |
| 89 |  |  [Born Differently Makes a Difference: Counterfactual Study of Bias in Biography Generation from a Data-to-Text Perspective](https://doi.org/10.18653/v1/2024.acl-short.39) |  | 0 | How do personal attributes affect biography generation? Addressing this question requires an identical pair of biographies where only the personal attributes of interest are different. However, it is rare in the real world. To address this, we propose a counterfactual methodology from a... | Biaoyan Fang, Ritvik Dinesh, Xiang Dai, Sarvnaz Karimi |  |
| 90 |  |  [Sign Language Translation with Sentence Embedding Supervision](https://doi.org/10.18653/v1/2024.acl-short.40) |  | 0 | State-of-the-art sign language translation (SLT) systems facilitate the learning process through gloss annotations, either in an end2end manner or by involving an intermediate step. Unfortunately, gloss labelled sign language data is usually not available at scale and, when available, gloss... | Yasser Hamidullah, Josef van Genabith, Cristina EspañaBonet |  |
| 91 |  |  [STREAM: Simplified Topic Retrieval, Exploration, and Analysis Module](https://doi.org/10.18653/v1/2024.acl-short.41) |  | 0 | Topic modeling is a widely used technique to analyze large document corpora. With the ever-growing emergence of scientific contributions in the field, non-technical users may often use the simplest available software module, independent of whether there are potentially better models available. We... | Anton Thielmann, Arik Reuter, Christoph Weisser, Gillian Kant, Manish Kumar, Benjamin Säfken |  |
| 92 |  |  [DocFinQA: A Long-Context Financial Reasoning Dataset](https://doi.org/10.18653/v1/2024.acl-short.42) |  | 0 | For large language models (LLMs) to be effective in the financial domain – where each decision can have a significant impact – it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents spanning hundreds of pages, but most financial research... | Varshini Reddy, Rik KoncelKedziorski, Viet Dac Lai, Michael Krumdick, Charles Lovering, Chris Tanner |  |
| 93 |  |  [MaskLID: Code-Switching Language Identification through Iterative Masking](https://doi.org/10.18653/v1/2024.acl-short.43) |  | 0 | We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single... | Amir Hossein Kargaran, François Yvon, Hinrich Schütze |  |
| 94 |  |  [An Empirical Analysis on Large Language Models in Debate Evaluation](https://doi.org/10.18653/v1/2024.acl-short.44) |  | 0 | In this study, we investigate the capabilities and inherent biases of advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context of debate evaluation. We discover that LLM’s performance exceeds humans and surpasses the performance of state-of-the-art methods fine-tuned on... | Xinyi Liu, Pinxin Liu, Hangfeng He |  |
| 95 |  |  [Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains](https://doi.org/10.18653/v1/2024.acl-short.45) |  | 0 | We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain... | Vilém Zouhar, Shuoyang Ding, Anna Currey, Tatyana Badeka, Jenyuan Wang, Brian Thompson |  |
| 96 |  |  [IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages](https://doi.org/10.18653/v1/2024.acl-short.46) |  | 0 | In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include... | Saiful Haq, Ashutosh Sharma, Omar Khattab, Niyati Chhaya, Pushpak Bhattacharyya |  |
| 97 |  |  [AGR: Reinforced Causal Agent-Guided Self-explaining Rationalization](https://doi.org/10.18653/v1/2024.acl-short.47) |  | 0 | Most existing rationalization approaches are susceptible to degeneration accumulation due to a lack of effective control over the learning direction of the model during training. To address this issue, we propose a novel approach AGR (Agent-Guided Rationalization), guiding the next action of the... | Yunxiao Zhao, Zhiqiang Wang, Xiaoli Li, Jiye Liang, Ru Li |  |
| 98 |  |  [Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research](https://doi.org/10.18653/v1/2024.acl-short.48) |  | 0 | We analysed a sample of NLP research papers archived in ACL Anthology as an attempt to quantify the degree of openness and the benefit of such an open culture in the NLP community. We observe that papers published in different NLP venues show different patterns related to artefact reuse. We also... | Surangika Ranathunga, Nisansa de Silva, Dilith Jayakody, Aloka Fernando |  |
| 99 |  |  [The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.49) |  | 0 | In order to oversee advanced AI systems, it is important to understand their reasons for generating a given output. When prompted, large language models (LLMs) can provide natural language explanations or reasoning traces that sound plausible and receive high ratings from human annotators. However,... | Noah Y. Siegel, OanaMaria Camburu, Nicolas Heess, María PérezOrtiz |  |
| 100 |  |  [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](https://doi.org/10.18653/v1/2024.acl-short.50) |  | 0 | While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision & Language Large Language Models (VLLMs) can mimic this crucial feature of... | Alberto Testoni, Juell Sprott, Sandro Pezzelle |  |
| 101 |  |  [Are LLMs classical or nonmonotonic reasoners? Lessons from generics](https://doi.org/10.18653/v1/2024.acl-short.51) |  | 0 | Recent scholarship on reasoning in LLMs has supplied evidence of impressive performance and flexible adaptation to machine generated or human critique. Nonmonotonic reasoning, crucial to human cognition for navigating the real world, remains a challenging, yet understudied task. In this work, we... | Alina Leidinger, Robert van Rooij, Ekaterina Shutova |  |
| 102 |  |  [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](https://doi.org/10.18653/v1/2024.acl-short.52) |  | 0 | Large language models (LLMs) are highly capable at a variety of tasks given the right prompt, but writing one is still a difficult and tedious process. In this work, we introduce ConstitutionalExperts, a method for learning a prompt consisting of constitutional principles (i.e. rules), given a... | Savvas Petridis, Ben Wedin, Ann Yuan, James Wexler, Nithum Thain |  |
| 103 |  |  [Time Sensitive Knowledge Editing through Efficient Finetuning](https://doi.org/10.18653/v1/2024.acl-short.53) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capability in different tasks and are bringing transformative changes to many domains. However, keeping the knowledge in LLMs up-to-date remains a challenge once pretraining is complete. It is thus essential to design effective methods to... | Xiou Ge, Ali Mousavi, Edouard Grave, Armand Joulin, Kun Qian, Benjamin Han, Mostafa Arefiyan, Yunyao Li |  |
| 104 |  |  [PRewrite: Prompt Rewriting with Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-short.54) |  | 0 | Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a “trial and error” fashion that can be time consuming, ineffective, and sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the... | Weize Kong, Spurthi Amba Hombaiah, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky |  |
| 105 |  |  [Paraphrasing in Affirmative Terms Improves Negation Understanding](https://doi.org/10.18653/v1/2024.acl-short.55) |  | 0 | Negation is a common linguistic phenomenon. Yet language models face challenges with negation in many natural language understanding tasks such as question answering and natural language inference. In this paper, we experiment with seamless strategies that incorporate affirmative interpretations... | MohammadHossein Rezaei, Eduardo Blanco |  |
| 106 |  |  [Exploring Conditional Variational Mechanism to Pinyin Input Method for Addressing One-to-Many Mappings in Low-Resource Scenarios](https://doi.org/10.18653/v1/2024.acl-short.56) |  | 0 | Pinyin input method engine (IME) refers to the transformation tool from pinyin sequence to Chinese characters, which is widely used on mobile phone applications. Due to the homophones, Pinyin IME suffers from the one-to-many mapping problem in the process of pinyin sequences to Chinese characters.... | Bin Sun, Jianfeng Li, Hao Zhou, Fandong Meng, Kan Li, Jie Zhou |  |
| 107 |  |  [Consistency Training by Synthetic Question Generation for Conversational Question Answering](https://doi.org/10.18653/v1/2024.acl-short.57) |  | 0 | Efficiently modeling historical information is a critical component in addressing user queries within a conversational question-answering (QA) context, as historical context plays a vital role in clarifying the user’s questions. However, irrelevant history induces noise in the reasoning process,... | Hamed Hematian Hemati, Hamid Beigy |  |
| 108 |  |  [How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?](https://doi.org/10.18653/v1/2024.acl-short.58) |  | 0 | While machine translation evaluation has been studied primarily for high-resource languages, there has been a recent interest in evaluation for low-resource languages due to the increasing availability of data and models. In this paper, we focus on a zero-shot evaluation setting focusing on... | Anushka Singh, Ananya Sai, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Mitesh M. Khapra |  |
| 109 |  |  [Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-short.59) |  | 0 | Large language models (LLMs) as listwise rerankers have shown impressive zero-shot capabilities in various passage ranking tasks. Despite their success, there is still a gap in existing literature on their effectiveness in reranking low-resource languages. To address this, we investigate how LLMs... | Mofetoluwa Adeyemi, Akintunde Oladipo, Ronak Pradeep, Jimmy Lin |  |
| 110 |  |  [Cross-Modal Projection in Multimodal LLMs Doesn't Really Project Visual Attributes to Textual Space](https://doi.org/10.18653/v1/2024.acl-short.60) |  | 0 | Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock... | Gaurav Verma, Minje Choi, Kartik Sharma, Jamelle WatsonDaniels, Sejoon Oh, Srijan Kumar |  |
| 111 |  |  [Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-short.61) |  | 0 | While the abundance of rich and vast datasets across numerous fields has facilitated the advancement of natural language processing, sectors in need of specialized data types continue to struggle with the challenge of finding quality data. Our study introduces a novel guidance data augmentation... | Hyeonseok Kang, Hyein Seo, Jeesu Jung, Sangkeun Jung, DuSeong Chang, Riwoo Chung |  |
| 112 |  |  [Aligning Large Language Models via Fine-grained Supervision](https://doi.org/10.18653/v1/2024.acl-short.62) |  | 0 | Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by... | Dehong Xu, Liang Qiu, Minseok Kim, Faisal Ladhak, Jaeyoung Do |  |
| 113 |  |  [Annotating FrameNet via Structure-Conditioned Language Generation](https://doi.org/10.18653/v1/2024.acl-short.63) |  | 0 | Despite the remarkable generative capabilities of language models in producing naturalistic language, their effectiveness on explicit manipulation and generation of linguistic structures remain understudied. In this paper, we investigate the task of generating new sentences preserving a given... | Xinyue Cui, Swabha Swayamdipta |  |
| 114 |  |  [DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms](https://doi.org/10.18653/v1/2024.acl-short.64) |  | 0 | Recently, large language models (LLMs) enhanced by self-reflection have achieved promising performance on machine transla004 tion. The key idea is guiding LLMs to generate translation with human-like feedback. However, existing self-reflection methods lack effective feedback information, limiting... | Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang |  |
| 115 |  |  [Towards Artwork Explanation in Large-scale Vision Language Models](https://doi.org/10.18653/v1/2024.acl-short.65) |  | 0 | Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships... | Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe |  |
| 116 |  |  [On the Hallucination in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-short.66) |  | 0 | It is widely known that hallucination is a critical issue in Simultaneous Machine Translation (SiMT) due to the absence of source-side information. While many efforts have been made to enhance performance for SiMT, few of them attempt to understand and analyze hallucination in SiMT.Therefore, we... | Meizhi Zhong, Kehai Chen, Zhengshan Xue, Lemao Liu, Mingming Yang, Min Zhang |  |
| 117 |  |  [Self-Augmented In-Context Learning for Unsupervised Word Translation](https://doi.org/10.18653/v1/2024.acl-short.67) |  | 0 | Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of ‘traditional’ mapping-based approaches in the unsupervised scenario where no seed... | Yaoyiran Li, Anna Korhonen, Ivan Vulic |  |
| 118 |  |  [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://doi.org/10.18653/v1/2024.acl-short.68) |  | 0 | We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy... | Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Bowen Jin, May Dongmei Wang, Joyce C. Ho, Carl Yang |  |
| 119 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.acl-long.0) |  | 0 |  |  |  |
| 120 |  |  [Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.1) |  | 0 | Finetuning large language models (LLMs) has been empirically effective on a variety of downstream tasks. Existing approaches to finetuning an LLM either focus on parameter-efficient finetuning, which only updates a small number of trainable parameters, or attempt to reduce the memory footprint... | Zhengxin Zhang, Dan Zhao, Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Qing Li, Yong Jiang, Zhihao Jia |  |
| 121 |  |  [Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances](https://doi.org/10.18653/v1/2024.acl-long.2) |  | 0 | Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions. Existing methods manifest limitations in leveraging nonverbal information for discerning complex semantics in unsupervised scenarios. This paper introduces a... | Hanlei Zhang, Hua Xu, Fei Long, Xin Wang, Kai Gao |  |
| 122 |  |  [MAGE: Machine-generated Text Detection in the Wild](https://doi.org/10.18653/v1/2024.acl-long.3) |  | 0 | Large language models (LLMs) have achieved human-level text generation, emphasizing the need for effective deepfake text detection to mitigate risks like the spread of fake news and plagiarism. Existing research has been constrained by evaluating detection methods o specific domains or particular... | Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Zhilin Wang, Longyue Wang, Linyi Yang, Shuming Shi, Yue Zhang |  |
| 123 |  |  [PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models](https://doi.org/10.18653/v1/2024.acl-long.4) |  | 0 | The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model... | Haoran Li, Dadi Guo, Donghao Li, Wei Fan, Qi Hu, Xin Liu, Chunkit Chan, Duanyi Yao, Yuan Yao, Yangqiu Song |  |
| 124 |  |  [GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators](https://doi.org/10.18653/v1/2024.acl-long.5) |  | 0 | Recent advances in large language models (LLMs) have stepped forward the development of multilingual speech and machine translation by its reduced representation errors and incorporated external knowledge. However, both translation tasks typically utilize beam search decoding and top-1 hypothesis... | Yuchen Hu, Chen Chen, ChaoHan Huck Yang, Ruizhe Li, Dong Zhang, Zhehuai Chen, Engsiong Chng |  |
| 125 |  |  [Exploring Chain-of-Thought for Multi-modal Metaphor Detection](https://doi.org/10.18653/v1/2024.acl-long.6) |  | 0 | Metaphors are commonly found in advertising and internet memes. However, the free form of internet memes often leads to a lack of high-quality textual data. Metaphor detection demands a deep interpretation of both textual and visual elements, requiring extensive common-sense knowledge, which poses... | Yanzhi Xu, Yueying Hua, Shichen Li, Zhongqing Wang |  |
| 126 |  |  [BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation](https://doi.org/10.18653/v1/2024.acl-long.7) |  | 0 | The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges. Weight quantization has emerged as a widely embraced solution to reduce memory and computational demands. This paper introduces... | Dayou Du, Yijia Zhang, Shijie Cao, Jiaqi Guo, Ting Cao, Xiaowen Chu, Ningyi Xu |  |
| 127 |  |  [A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation](https://doi.org/10.18653/v1/2024.acl-long.8) |  | 0 | Temporal knowledge graph (TKG) reasoning has two settings: interpolation reasoning and extrapolation reasoning. Both of them draw plenty of research interest and have great significance. Methods of the former de-emphasize the temporal correlations among facts sequences, while methods of the latter... | Kai Chen, Ye Wang, Yitong Li, Aiping Li, Han Yu, Xin Song |  |
| 128 |  |  [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.9) |  | 0 | Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignore it or be misled by it. The key reason is that... | Shicheng Xu, Liang Pang, Mo Yu, Fandong Meng, Huawei Shen, Xueqi Cheng, Jie Zhou |  |
| 129 |  |  [CSCD-NS: a Chinese Spelling Check Dataset for Native Speakers](https://doi.org/10.18653/v1/2024.acl-long.10) |  | 0 | In this paper, we present CSCD-NS, the first Chinese spelling check (CSC) dataset designed for native speakers, containing 40,000 samples from a Chinese social platform. Compared with existing CSC datasets aimed at Chinese learners, CSCD-NS is ten times larger in scale and exhibits a distinct error... | Yong Hu, Fandong Meng, Jie Zhou |  |
| 130 |  |  [Evaluating Dynamic Topic Models](https://doi.org/10.18653/v1/2024.acl-long.11) |  | 0 | There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension... | Charu James, Mayank Nagda, Nooshin Haji Ghassemi, Marius Kloft, Sophie Fellenz |  |
| 131 |  |  [How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition](https://doi.org/10.18653/v1/2024.acl-long.12) |  | 0 | Large language models (LLMs) with enormous pre-training tokens and parameters emerge diverse abilities, including math reasoning, codegeneration, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). While the open-source community has explored ad-hoc SFT... | Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou |  |
| 132 |  |  [Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification](https://doi.org/10.18653/v1/2024.acl-long.13) |  | 0 | In legal decisions, split votes (SV) occur when judges cannot reach a unanimous decision, posing a difficulty for lawyers who must navigate diverse legal arguments and opinions. In high-stakes domains, %as human-AI interaction systems become increasingly important, understanding the alignment of... | Shanshan Xu, T. Y. S. S. Santosh, Oana Ichim, Barbara Plank, Matthias Grabmair |  |
| 133 |  |  [Inference to the Best Explanation in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.14) |  | 0 | While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process is still poorly understood. This paper proposes IBE-Eval, a framework inspired by philosophical accounts on Inference to the Best Explanation (IBE) to advance the interpretation... | Dhairya Dalal, Marco Valentino, André Freitas, Paul Buitelaar |  |
| 134 |  |  [A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus](https://doi.org/10.18653/v1/2024.acl-long.15) |  | 0 | Natural language inference (NLI), the task of recognizing the entailment relationship in sentence pairs, is an actively studied topic serving as a proxy for natural language understanding. Despite the relevance of the task in building conversational agents and improving text classification, machine... | Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu |  |
| 135 |  |  [MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering](https://doi.org/10.18653/v1/2024.acl-long.16) |  | 0 | Recent advances in few-shot question answering (QA) mostly rely on the power of pre-trained large language models (LLMs) and fine-tuning in specific settings. Although the pre-training stage has already equipped LLMs with powerful reasoning capabilities, LLMs still need to be fine-tuned to adapt to... | Xiusi Chen, JyunYu Jiang, WeiCheng Chang, ChoJui Hsieh, HsiangFu Yu, Wei Wang |  |
| 136 |  |  [SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs](https://doi.org/10.18653/v1/2024.acl-long.17) |  | 0 | Large language models hold significant potential for integrating various data types, such as text documents and database records, for advanced analytics. However, blending text and numerical data presents substantial challenges. LLMs need to process and cross-reference entities and numbers, handle... | Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, Dong Yu, Fei Liu |  |
| 137 |  |  [SciMON: Scientific Inspiration Machines Optimized for Novelty](https://doi.org/10.18653/v1/2024.acl-long.18) |  | 0 | We explore and enhance the ability of neural language models to generate novel scientific directions grounded in literature. Work on literature-based hypothesis generation has traditionally focused on binary link prediction—severely limiting the expressivity of hypotheses. This line of work also... | Qingyun Wang, Doug Downey, Heng Ji, Tom Hope |  |
| 138 |  |  [Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction](https://doi.org/10.18653/v1/2024.acl-long.19) |  | 0 | We introduce EVLGen, a streamlined framework designed for the pre-training of visually conditioned language generation models with high computational demands, utilizing frozen pre-trained large language models (LLMs). The conventional approach in vision-language pre-training (VLP) typically... | Yiren Jian, Tingkai Liu, Yunzhe Tao, Chunhui Zhang, Soroush Vosoughi, Hongxia Yang |  |
| 139 |  |  [Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.20) |  | 0 | As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models. We introduce the concept of Confidence-Probability... | Abhishek Kumar, Robert Morabito, Sanzhar Umbet, Jad Kabbara, Ali Emami |  |
| 140 |  |  [Retrieval-Augmented Multilingual Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.21) |  | 0 | Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time. Updating knowledge via fine-tuning is computationally resource-hungry and not reliable, and so knowledge editing (KE) has developed as an effective and economical alternative to... | Weixuan Wang, Barry Haddow, Alexandra Birch |  |
| 141 |  |  [Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge](https://doi.org/10.18653/v1/2024.acl-long.22) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable success in tasks like the Winograd Schema Challenge (WSC), showcasing advanced textual common-sense reasoning. However, applying this reasoning to multimodal domains, where understanding text and images together is essential, remains a... | Brendan Park, Madeline Janecek, Naser EzzatiJivan, Yifeng Li, Ali Emami |  |
| 142 |  |  [Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.23) |  | 0 | Research on Large Language Models (LLMs) has often neglected subtle biases that, although less apparent, can significantly influence the models’ outputs toward particular social narratives. This study addresses two such biases within LLMs: representative bias, which denotes a tendency of LLMs to... | Abhishek Kumar, Sarfaroz Yunusov, Ali Emami |  |
| 143 |  |  [Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News](https://doi.org/10.18653/v1/2024.acl-long.24) |  | 0 | The mainstream media has much leeway in what it chooses to cover and how it covers it. These choices have real-world consequences on what people know and their subsequent behaviors. However, the lack of objective measures to evaluate editorial choices makes research in this area particularly... | Alexandria Leto, Elliot Pickens, Coen D. Needell, David Rothschild, Maria Leonor Pacheco |  |
| 144 |  |  [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences](https://doi.org/10.18653/v1/2024.acl-long.25) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate... | Xiyao Wang, Yuhang Zhou, Xiaoyu Liu, Hongjin Lu, Yuancheng Xu, Feihong He, Jaehong Yoon, Taixi Lu, Fuxiao Liu, Gedas Bertasius, Mohit Bansal, Huaxiu Yao, Furong Huang |  |
| 145 |  |  [TTM-RE: Memory-Augmented Document-Level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.26) |  | 0 | Document-level relation extraction aims to categorize the association between any two entities within a document.We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels. For... | Chufan Gao, Xuan Wang, Jimeng Sun |  |
| 146 |  |  [Answer is All You Need: Instruction-following Text Embedding via Answering the Question](https://doi.org/10.18653/v1/2024.acl-long.27) |  | 0 | This work aims to build a text embedder that can capture characteristics of texts specified by user instructions clarifying the similarity criterion. While previous methods improve general task awareness by injecting the instruction information into encoding, they fail to be sensitive to clearer... | Letian Peng, Yuwei Zhang, Zilong Wang, Jayanth Srinivasa, Gaowen Liu, Zihan Wang, Jingbo Shang |  |
| 147 |  |  [Explore Spurious Correlations at the Concept Level in Language Models for Text Classification](https://doi.org/10.18653/v1/2024.acl-long.28) |  | 0 | Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label... | Yuhang Zhou, Paiheng Xu, Xiaoyu Liu, Bang An, Wei Ai, Furong Huang |  |
| 148 |  |  [Every Answer Matters: Evaluating Commonsense with Probabilistic Measures](https://doi.org/10.18653/v1/2024.acl-long.29) |  | 0 | Large language models have demonstrated impressive performance on commonsense tasks; however, these tasks are often posed as multiple-choice questions, allowing models to exploit systematic biases. Commonsense is also inherently probabilistic with multiple correct answers. The purpose of “boiling... | Qi Cheng, Michael Boratko, Pranay Kumar Yelugam, Tim O'Gorman, Nalini Singh, Andrew McCallum, Xiang Li |  |
| 149 |  |  [GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis](https://doi.org/10.18653/v1/2024.acl-long.30) |  | 0 | Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study,... | Yueqi Xie, Minghong Fang, Renjie Pi, Neil Gong |  |
| 150 |  |  [Pouring Your Heart Out: Investigating the Role of Figurative Language in Online Expressions of Empathy](https://doi.org/10.18653/v1/2024.acl-long.31) |  | 0 | Empathy is a social mechanism used to support and strengthen emotional connection with others, including in online communities. However, little is currently known about the nature of these online expressions, nor the particular factors that may lead to their improved detection. In this work, we... | Gyeongeun Lee, Christina Wong, Meghan Guo, Natalie Parde |  |
| 151 |  |  [An Information-Theoretic Approach to Analyze NLP Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.32) |  | 0 | Understanding the contribution of the inputs on the output is useful across many tasks. This work provides an information-theoretic framework to analyse the influence of inputs for text classification tasks. Natural language processing (NLP) tasks take either a single or multiple text elements to... | Luran Wang, Mark J. F. Gales, Vatsal Raina |  |
| 152 |  |  [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](https://doi.org/10.18653/v1/2024.acl-long.33) |  | 0 | Conversational systems often rely on embedding models for intent classification and intent clustering tasks. The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for... | Yuwei Zhang, Siffi Singh, Sailik Sengupta, Igor Shalyminov, Hang Su, Hwanjun Song, Saab Mansour |  |
| 153 |  |  [Wav2Gloss: Generating Interlinear Glossed Text from Speech](https://doi.org/10.18653/v1/2024.acl-long.34) |  | 0 | Thousands of the world’s languages are in danger of extinction—a tremendous threat to cultural identities and human language diversity. Interlinear Glossed Text (IGT) is a form of linguistic annotation that can support documentation and resource creation for these languages’ communities. IGT... | Taiqi He, Kwanghee Choi, Lindia Tjuatja, Nathaniel R. Robinson, Jiatong Shi, Shinji Watanabe, Graham Neubig, David R. Mortensen, Lori S. Levin |  |
| 154 |  |  [Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification](https://doi.org/10.18653/v1/2024.acl-long.35) |  | 0 | Is it possible accurately classify political relations within evolving event ontologies without extensive annotations? This study investigates zero-shot learning methods that use expert knowledge from existing annotation codebook, and evaluates the performance of advanced ChatGPT (GPT-3.5/4) and a... | Yibo Hu, Erick Skorupa Parolin, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito D'Orazio |  |
| 155 |  |  [SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.36) |  | 0 | Compositional generalization is an important ability of language models and has many different manifestations. For data-to-text generation, previous research on this ability is limited to a single manifestation called Systematicity and lacks consideration of large language models (LLMs), which... | Ziyao Xu, Houfeng Wang |  |
| 156 |  |  [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.37) |  | 0 | Embodied Instruction Following (EIF) is a crucial task in embodied learning, requiring agents to interact with their environment through egocentric observations to fulfill natural language instructions. Recent advancements have seen a surge in employing large language models (LLMs) within a... | Haochen Shi, Zhiyuan Sun, Xingdi Yuan, MarcAlexandre Côté, Bang Liu |  |
| 157 |  |  [Multimodal Instruction Tuning with Conditional Mixture of LoRA](https://doi.org/10.18653/v1/2024.acl-long.38) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in diverse tasks across different domains, with an increasing focus on improving their zero-shot generalization capabilities for unseen multimodal tasks. Multimodal instruction tuning has emerged as a successful... | Ying Shen, Zhiyang Xu, Qifan Wang, Yu Cheng, Wenpeng Yin, Lifu Huang |  |
| 158 |  |  [DocLens: Multi-aspect Fine-grained Medical Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.39) |  | 0 | Medical text generation aims to assist with administrative work and highlight salient information to support decision-making.To reflect the specific requirements of medical text, in this paper, we propose a set of metrics to evaluate the completeness, conciseness, and attribution of the generated... | Yiqing Xie, Sheng Zhang, Hao Cheng, Pengfei Liu, Zelalem Gero, Cliff Wong, Tristan Naumann, Hoifung Poon, Carolyn P. Rosé |  |
| 159 |  |  [FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability](https://doi.org/10.18653/v1/2024.acl-long.40) |  | 0 | This paper presents FoFo, a pioneering benchmark for evaluating large language models’ (LLMs) ability to follow complex, domain-specific formats, a crucial yet under-examined capability for their application as AI agents. Despite LLMs’ advancements, existing benchmarks fail to assess their... | Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang, Yihao Feng, Ran Xu, Wenpeng Yin, Caiming Xiong |  |
| 160 |  |  [Hyper-CL: Conditioning Sentence Representations with Hypernetworks](https://doi.org/10.18653/v1/2024.acl-long.41) |  | 0 | While the introduction of contrastive learning frameworks in sentence representation learning has significantly contributed to advancements in the field, it still remains unclear whether state-of-the-art sentence embeddings can capture the fine-grained semantics of sentences, particularly when... | Young Hyun Yoo, Jii Cha, Changhyeon Kim, Taeuk Kim |  |
| 161 |  |  [Analysis of Multi-Source Language Training in Cross-Lingual Transfer](https://doi.org/10.18653/v1/2024.acl-long.42) |  | 0 | The successful adaptation of multilingual language models (LMs) to a specific language-task pair critically depends on the availability of data tailored for that condition. While cross-lingual transfer (XLT) methods have contributed to addressing this data scarcity problem, there still exists... | Seong Hoon Lim, Taejun Yun, Jinhyeon Kim, Jihun Choi, Taeuk Kim |  |
| 162 |  |  [ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions](https://doi.org/10.18653/v1/2024.acl-long.43) |  | 0 | We present ABEX, a novel and effective generative data augmentation methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms of an input document – we first convert a document into its concise,... | Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, Chandra Kiran Reddy Evuru, Ramaneswaran S., S. Sakshi, Dinesh Manocha |  |
| 163 |  |  [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants](https://doi.org/10.18653/v1/2024.acl-long.44) |  | 0 | We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource... | Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel Artetxe, Satya Narayan Shukla, Donald Husa, Naman Goyal, Abhinandan Krishnan, Luke Zettlemoyer, Madian Khabsa |  |
| 164 |  |  [Learn from Failure: Fine-tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving](https://doi.org/10.18653/v1/2024.acl-long.45) |  | 0 | Recent advances in Automated Theorem Proving have shown the effectiveness of leveraging a (large) language model that generates tactics (i.e. proof steps) to search through proof states. The current model, while trained solely on successful proof paths, faces a discrepancy at the inference stage,... | Chenyang An, Zhibo Chen, Qihao Ye, Emily First, Letian Peng, Jiayun Zhang, Zihan Wang, Sorin Lerner, Jingbo Shang |  |
| 165 |  |  [Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach](https://doi.org/10.18653/v1/2024.acl-long.46) |  | 0 | In this paper, we primarily address the issue of dialogue-form context query within the interactive text-to-image retrieval task. Our methodology, PlugIR, actively utilizes the general instruction-following capability of LLMs in two ways. First, by reformulating the dialogue-form context, we... | Saehyung Lee, Sangwon Yu, Junsung Park, Jihun Yi, Sungroh Yoon |  |
| 166 |  |  [IMBUE: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction](https://doi.org/10.18653/v1/2024.acl-long.47) |  | 0 | Navigating certain communication situations can be challenging due to individuals’ lack of skills and the interference of strong emotions. However, effective learning opportunities are rarely accessible. In this work, we conduct a human-centered study that uses language models to simulate bespoke... | Inna W. Lin, Ashish Sharma, Christopher Michael Rytting, Adam S. Miner, Jina Suh, Tim Althoff |  |
| 167 |  |  [Token-wise Influential Training Data Retrieval for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.48) |  | 0 | Given a Large Language Model (LLM) generation, how can we identify which training data led to this generation? In this paper, we proposed RapidIn, a scalable framework adapting to LLMs for estimating the influence of each training data. The proposed framework consists of two stages: caching and... | Huawei Lin, Jikai Long, Zhaozhuo Xu, Weijie Zhao |  |
| 168 |  |  [Tree-of-Counterfactual Prompting for Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.49) |  | 0 | Stance detection enables the inference of attitudes from human communications. Automatic stance identification was mostly cast as a classification problem. However, stance decisions involve complex judgments, which can be nowadays generated by prompting Large Language Models (LLMs). In this paper... | Maxwell A. Weinzierl, Sanda M. Harabagiu |  |
| 169 |  |  [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://doi.org/10.18653/v1/2024.acl-long.50) |  | 0 | Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively... | Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, PoYu Huang, Graham Neubig, Shuyan Zhou, Russ Salakhutdinov, Daniel Fried |  |
| 170 |  |  [FineSurE: Fine-grained Summarization Evaluation using LLMs](https://doi.org/10.18653/v1/2024.acl-long.51) |  | 0 | Automated evaluation is crucial for streamlining text summarization benchmarking and model development, given the costly and time-consuming nature of human evaluation. Traditional methods like ROUGE do not correlate well with human judgment, while recently proposed LLM-based metrics provide only... | Hwanjun Song, Hang Su, Igor Shalyminov, Jason Cai, Saab Mansour |  |
| 171 |  |  [Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback](https://doi.org/10.18653/v1/2024.acl-long.52) |  | 0 | Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). Previous approaches for VLMMs involve Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and additional learnable parameters. Here,... | Daechul Ahn, Yura Choi, Youngjae Yu, Dongyeop Kang, Jonghyun Choi |  |
| 172 |  |  [Prompt Refinement with Image Pivot for Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.53) |  | 0 | For text-to-image generation, automatically refining user-provided natural language prompts into the keyword-enriched prompts favored by systems is essential for the user experience. Such a prompt refinement process is analogous to translating the prompt from “user languages” into “system... | Jingtao Zhan, Qingyao Ai, Yiqun Liu, Yingwei Pan, Ting Yao, Jiaxin Mao, Shaoping Ma, Tao Mei |  |
| 173 |  |  [Striking Gold in Advertising: Standardization and Exploration of Ad Text Generation](https://doi.org/10.18653/v1/2024.acl-long.54) |  | 0 | In response to the limitations of manual ad creation, significant research has been conducted in the field of automatic ad text generation (ATG). However, the lack of comprehensive benchmarks and well-defined problem sets has made comparing different methods challenging. To tackle these challenges,... | Masato Mita, Soichiro Murakami, Akihiko Kato, Peinan Zhang |  |
| 174 |  |  [AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation](https://doi.org/10.18653/v1/2024.acl-long.55) |  | 0 | Abstraction ability is crucial in human intelligence, which can also benefit various tasks in NLP study. Existing work shows that LLMs are deficient in abstract ability, and how to improve it remains unexplored. In this work, we design the framework AbsInstruct to enhance LLMs’ abstraction ability... | Zhaowei Wang, Wei Fan, Qing Zong, Hongming Zhang, Sehyun Choi, Tianqing Fang, Xin Liu, Yangqiu Song, Ginny Y. Wong, Simon See |  |
| 175 |  |  [Reflect-RL: Two-Player Online RL Fine-Tuning for LMs](https://doi.org/10.18653/v1/2024.acl-long.56) |  | 0 | As language models (LMs) demonstrate their capabilities in various fields, their application to tasks requiring multi-round interactions has become increasingly popular. These tasks usually have complex dynamics, so supervised fine-tuning (SFT) on a limited offline dataset does not yield good... | Runlong Zhou, Simon S. Du, Beibin Li |  |
| 176 |  |  [Can ChatGPT's Performance be Improved on Verb Metaphor Detection Tasks? Bootstrapping and Combining Tacit Knowledge](https://doi.org/10.18653/v1/2024.acl-long.57) |  | 0 | Metaphors detection, as an important task in the field of NLP, has been receiving sustained academic attention in recent years. Current researches focus supervised metaphors detection systems, which usually require large-scale, high-quality labeled data support. The emerge of large language models... | Cheng Yang, Puli Chen, Qingbao Huang |  |
| 177 |  |  [Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.58) |  | 0 | The surge in Large Language Models (LLMs) has revolutionized natural language processing, but fine-tuning them for specific tasks often encounters challenges in balancing performance and preserving general instruction-following abilities. In this paper, we posit that the distribution gap between... | Zhaorui Yang, Tianyu Pang, Haozhe Feng, Han Wang, Wei Chen, Minfeng Zhu, Qian Liu |  |
| 178 |  |  [An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.59) |  | 0 | Retrieval-augmented generation integrates the capabilities of large language models with relevant information retrieved from an extensive corpus, yet encounters challenges when confronted with real-world noisy data. One recent solution is to train a filter module to find relevant content but only... | Kun Zhu, Xiaocheng Feng, Xiyuan Du, Yuxuan Gu, Weijiang Yu, Haotian Wang, Qianglong Chen, Zheng Chu, Jingchang Chen, Bing Qin |  |
| 179 |  |  [RORA: Robust Free-Text Rationale Evaluation](https://doi.org/10.18653/v1/2024.acl-long.60) |  | 0 | Free-text rationales play a pivotal role in explainable NLP, bridging the knowledge and reasoning gaps behind a model’s decision-making. However, due to the diversity of potential reasoning paths and a corresponding lack of definitive ground truth, their evaluation remains a challenge. Existing... | Zhengping Jiang, Yining Lu, Hanjie Chen, Daniel Khashabi, Benjamin Van Durme, Anqi Liu |  |
| 180 |  |  [Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents](https://doi.org/10.18653/v1/2024.acl-long.61) |  | 0 | Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise... | Cheng Qian, Bingxiang He, Zhong Zhuang, Jia Deng, Yujia Qin, Xin Cong, Zhong Zhang, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 181 |  |  [InstructProtein: Aligning Human and Protein Language via Knowledge Instruction](https://doi.org/10.18653/v1/2024.acl-long.62) |  | 0 | Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in... | Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen |  |
| 182 |  |  [ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.63) |  | 0 | In this position paper, we argue that human evaluation of generative large language models (LLMs) should be a multidisciplinary undertaking that draws upon the insights from disciplines such as user experience research and human behavioral psychology to ensure that the experimental design and... | Aparna Elangovan, Ling Liu, Lei Xu, Sravan Babu Bodapati, Dan Roth |  |
| 183 |  |  [Linguistically Conditioned Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.64) |  | 0 | Semantic textual similarity (STS) is a fundamental NLP task that measures the semantic similarity between a pair of sentences. In order to reduce the inherent ambiguity posed from the sentences, a recent work called Conditional STS (C-STS) has been proposed to measure the sentences’ similarity... | Jingxuan Tu, Keer Xu, Liulu Yue, Bingyang Ye, Kyeongmin Rim, James Pustejovsky |  |
| 184 |  |  [Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future](https://doi.org/10.18653/v1/2024.acl-long.65) |  | 0 | Reasoning, a fundamental cognitive process integral to human intelligence, has garnered substantial interest within artificial intelligence.Notably, recent studies have revealed that chain-of-thought prompting significantly enhances LLM’s reasoning capabilities, which attracts widespread attention... | Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, Ting Liu |  |
| 185 |  |  [TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.66) |  | 0 | Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world.Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark.To address this, we propose TimeBench, a... | Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, Bing Qin |  |
| 186 |  |  [BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.67) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning capabilities.Nevertheless, they still suffer from factual errors when tackling knowledge-intensive tasks.Retrieval-augmented reasoning represents a promising approach.However, significant challenges still persist, including inaccurate... | Zheng Chu, Jingchang Chen, Qianglong Chen, Haotian Wang, Kun Zhu, Xiyuan Du, Weijiang Yu, Ming Liu, Bing Qin |  |
| 187 |  |  [ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base](https://doi.org/10.18653/v1/2024.acl-long.68) |  | 0 | Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a... | Siyu Yuan, Jiangjie Chen, Changzhi Sun, Jiaqing Liang, Yanghua Xiao, Deqing Yang |  |
| 188 |  |  [TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation](https://doi.org/10.18653/v1/2024.acl-long.69) |  | 0 | A practical dialogue system requires the capacity for ongoing skill acquisition and adaptability to new tasks while preserving prior knowledge. However, current methods for Continual Dialogue State Tracking (DST), a crucial function of dialogue systems, struggle with the catastrophic forgetting... | Yujie Feng, Xu Chu, Yongxin Xu, Guangyuan Shi, Bo Liu, XiaoMing Wu |  |
| 189 |  |  [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://doi.org/10.18653/v1/2024.acl-long.70) |  | 0 | In the era of large language models, Mixture-of-Experts (MoE) is a promising architecture for managing computational costs when scaling up model parameters. However, conventional MoE architectures like GShard, which activate the top-K out of N experts, face challenges in ensuring expert... | Damai Dai, Chengqi Deng, Chenggang Zhao, R. X. Xu, Huazuo Gao, Deli Chen, Jiashi Li, Wangding Zeng, Xingkai Yu, Y. Wu, Zhenda Xie, Y. K. Li, Panpan Huang, Fuli Luo, Chong Ruan, Zhifang Sui, Wenfeng Liang |  |
| 190 |  |  [Grounding Language Model with Chunking-Free In-Context Retrieval](https://doi.org/10.18653/v1/2024.acl-long.71) |  | 0 | This paper presents a novel Chunking-Free In-Context (CFIC) retrieval approach, specifically tailored for Retrieval-Augmented Generation (RAG) systems. Traditional RAG systems often struggle with grounding responses using precise evidence text due to the challenges of processing lengthy documents... | Hongjin Qian, Zheng Liu, Kelong Mao, Yujia Zhou, Zhicheng Dou |  |
| 191 |  |  [Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation](https://doi.org/10.18653/v1/2024.acl-long.72) |  | 0 | Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains... | Jiaxin Bai, Yicheng Wang, Tianshi Zheng, Yue Guo, Xin Liu, Yangqiu Song |  |
| 192 |  |  [Active Prompting with Chain-of-Thought for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.73) |  | 0 | The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs’ ability to produce high-quality answers. In... | Shizhe Diao, Pengcheng Wang, Yong Lin, Rui Pan, Xiang Liu, Tong Zhang |  |
| 193 |  |  [EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs](https://doi.org/10.18653/v1/2024.acl-long.74) |  | 0 | We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample... | Xiangyu Zhao, Bo Liu, Qijiong Liu, Guangyuan Shi, XiaoMing Wu |  |
| 194 |  |  [Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search](https://doi.org/10.18653/v1/2024.acl-long.75) |  | 0 | In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the... | Haochen Li, Xin Zhou, Zhiqi Shen |  |
| 195 |  |  [A Multidimensional Framework for Evaluating Lexical Semantic Change with Social Science Applications](https://doi.org/10.18653/v1/2024.acl-long.76) |  | 0 | Historical linguists have identified multiple forms of lexical semantic change. We present a three-dimensional framework for integrating these forms and a unified computational methodology for evaluating them concurrently. The dimensions represent increases or decreases in semantic 1) sentiment... | Naomi Baes, Nick Haslam, Ekaterina Vylomova |  |
| 196 |  |  [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](https://doi.org/10.18653/v1/2024.acl-long.77) |  | 0 | Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model’s ability, which may not be feasible in real-world applications. When conducting continual learning based on a... | Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, Jinsong Su |  |
| 197 |  |  [Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency](https://doi.org/10.18653/v1/2024.acl-long.78) |  | 0 | Large language models (LLMs) have exhibited remarkable ability in code generation. However, generating the correct solution in a single attempt still remains a challenge. Prior works utilize verification properties in software engineering to verify and re-rank solutions in a majority voting manner.... | Baizhou Huang, Shuai Lu, Xiaojun Wan, Nan Duan |  |
| 198 |  |  [Citation-Enhanced Generation for LLM-based Chatbots](https://doi.org/10.18653/v1/2024.acl-long.79) |  | 0 | Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability.... | Weitao Li, Junkai Li, Weizhi Ma, Yang Liu |  |
| 199 |  |  [Transitive Consistency Constrained Learning for Entity-to-Entity Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.80) |  | 0 | Entity-to-entity stance detection identifies the stance between a pair of entities with a directed link that indicates the source, target and polarity. It is a streamlined task without the complex dependency structure for structural sentiment analysis, while it is more informative compared to most... | Haoyang Wen, Eduard H. Hovy, Alexander Hauptmann |  |
| 200 |  |  [Feature-Adaptive and Data-Scalable In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.81) |  | 0 | In-context learning (ICL), which promotes inference with several demonstrations, has become a widespread paradigm to stimulate LLM capabilities for downstream tasks. Due to context length constraints, it cannot be further improved in spite of more training data, and general features directly from... | Jiahao Li, Quan Wang, Licheng Zhang, Guoqing Jin, Zhendong Mao |  |
| 201 |  |  [Probing the Multi-turn Planning Capabilities of LLMs via 20 Question Games](https://doi.org/10.18653/v1/2024.acl-long.82) |  | 0 | Large language models (LLMs) are effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification... | Yizhe Zhang, Jiarui Lu, Navdeep Jaitly |  |
| 202 |  |  [WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.83) |  | 0 | To mitigate the potential misuse of large language models (LLMs), recent research has developed watermarking algorithms, which restrict the generation process to leave an invisible trace for watermark detection. Due to the two-stage nature of the task, most studies evaluate the generation and... | Shangqing Tu, Yuliang Sun, Yushi Bai, Jifan Yu, Lei Hou, Juanzi Li |  |
| 203 |  |  [Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models](https://doi.org/10.18653/v1/2024.acl-long.84) |  | 0 | Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences. While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of... | Yida Zhao, Chao Lou, Kewei Tu |  |
| 204 |  |  [A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation](https://doi.org/10.18653/v1/2024.acl-long.85) |  | 0 | Simultaneous translation models play a crucial role in facilitating communication. However, existing research primarily focuses on text-to-text or speech-to-text models, necessitating additional cascade components to achieve speech-to-speech translation. These pipeline methods suffer from error... | Zhengrui Ma, Qingkai Fang, Shaolei Zhang, Shoutao Guo, Yang Feng, Min Zhang |  |
| 205 |  |  [Probing Language Models for Pre-training Data Detection](https://doi.org/10.18653/v1/2024.acl-long.86) |  | 0 | Large Language Models (LLMs) have shown their impressive capabilities, while also raising concerns about the data contamination problems due to privacy issues and leakage of benchmark datasets in the pre-training phase. Therefore, it is vital to detect the contamination by checking whether an LLM... | Zhenhua Liu, Tong Zhu, Chuanyuan Tan, Bing Liu, Haonan Lu, Wenliang Chen |  |
| 206 |  |  [Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.87) |  | 0 | The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for swift and precise analysis of complex events.We refer to the complex events composed of many news articles over an extended period as Temporal Complex Event (TCE). This paper proposes a... | Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, TatSeng Chua |  |
| 207 |  |  [IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation](https://doi.org/10.18653/v1/2024.acl-long.88) |  | 0 | Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. Current language model agents mainly focus on reasonable behaviors from the level of individuals, and their behaviors might be hard to constraint on the level of the whole... | Senyu Han, Lu Chen, LiMin Lin, Zhengshan Xu, Kai Yu |  |
| 208 |  |  [Language Model Adaption for Reinforcement Learning with Natural Language Action Space](https://doi.org/10.18653/v1/2024.acl-long.89) |  | 0 | Reinforcement learning with natural language action space often suffers from the curse of dimensionality due to the combinatorial nature of the natural language. Previous research leverages pretrained language models to capture action semantics and reduce the size of the action space. However,... | Jiangxing Wang, Jiachen Li, Xiao Han, Deheng Ye, Zongqing Lu |  |
| 209 |  |  [Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues](https://doi.org/10.18653/v1/2024.acl-long.90) |  | 0 | We investigate intention detection in persuasive multi-turn dialogs employing the largest available Large Language Models (LLMs).Much of the prior research measures the intention detection capability of machine learning models without considering the conversational history.To evaluate LLMs’... | Hiromasa Sakurai, Yusuke Miyao |  |
| 210 |  |  [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://doi.org/10.18653/v1/2024.acl-long.91) |  | 0 | In long context scenarios, large language models (LLMs) face three main challenges: higher computational cost, performance reduction, and position bias. Research indicates that LLM performance hinges on the density and position of key information in the input prompt. Inspired by these findings, we... | Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, ChinYew Lin, Yuqing Yang, Lili Qiu |  |
| 211 |  |  [Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.92) |  | 0 | Persuasive dialogue requires multi-turn following and planning abilities to achieve the goal of persuading users, which is still challenging even for state-of-the-art large language models (LLMs). Previous works focus on retrieval-based models or generative models in a specific domain due to a lack... | Chuhao Jin, Kening Ren, Lingzhen Kong, Xiting Wang, Ruihua Song, Huan Chen |  |
| 212 |  |  [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://doi.org/10.18653/v1/2024.acl-long.93) |  | 0 | Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative... | Mengxi Xiao, Qianqian Xie, Ziyan Kuang, Zhicheng Liu, Kailai Yang, Min Peng, Weiguang Han, Jimin Huang |  |
| 213 |  |  [Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.94) |  | 0 | The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, in real-world applications, the presence of various missing modality cases often leads to a degradation in the model’s performance. In this work, we propose a novel... | Zirun Guo, Tao Jin, Zhou Zhao |  |
| 214 |  |  [An Effective Pronunciation Assessment Approach Leveraging Hierarchical Transformers and Pre-training Strategies](https://doi.org/10.18653/v1/2024.acl-long.95) |  | 0 | Automatic pronunciation assessment (APA) manages to quantify a second language (L2) learner’s pronunciation proficiency in a target language by providing fine-grained feedback with multiple pronunciation aspect scores at various linguistic levels. Most existing efforts on APA typically parallelize... | BiCheng Yan, JiunTing Li, YiCheng Wang, HsinWei Wang, TienHong Lo, YungChang Hsu, WeiCheng Chao, Berlin Chen |  |
| 215 |  |  [Detection-Correction Structure via General Language Model for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.acl-long.96) |  | 0 | Grammatical error correction (GEC) is a task dedicated to rectifying texts with minimal edits, which can be decoupled into two components: detection and correction. However, previous works have predominantly focused on direct correction, with no prior efforts to integrate both into a single model.... | Wei Li, Houfeng Wang |  |
| 216 |  |  [Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer](https://doi.org/10.18653/v1/2024.acl-long.97) |  | 0 | While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper, we introduce Generative Pre-trained Speech Transformer (GPST), a hierarchical transformer designed... | Yongxin Zhu, Dan Su, Liqiang He, Linli Xu, Dong Yu |  |
| 217 |  |  [Selene: Pioneering Automated Proof in Software Verification](https://doi.org/10.18653/v1/2024.acl-long.98) |  | 0 | Ensuring correctness is a pivotal aspect of software engineering. Among the various strategies available, software verification offers a definitive assurance of correctness. Nevertheless, writing verification proofs is resource-intensive and manpower-consuming, and there is a great need to automate... | Lichen Zhang, Shuai Lu, Nan Duan |  |
| 218 |  |  [Dissecting Human and LLM Preferences](https://doi.org/10.18653/v1/2024.acl-long.99) |  | 0 | As a relative quality comparison of model responses, human and Large Language Model (LLM) preferences serve as common alignment goals in model fine-tuning and criteria in evaluation. Yet, these preferences merely reflect broad tendencies, resulting in less explainable and controllable models with... | Junlong Li, Fan Zhou, Shichao Sun, Yikai Zhang, Hai Zhao, Pengfei Liu |  |
| 219 |  |  [UniCoder: Scaling Code Large Language Model via Universal Code](https://doi.org/10.18653/v1/2024.acl-long.100) |  | 0 | Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks.When applying LLMs for code generation, recent works mainly focus on directing the models to articulate intermediate... | Tao Sun, Linzheng Chai, Jian Yang, Yuwei Yin, Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun Yang, Zhoujun Li |  |
| 220 |  |  [AoE: Angle-optimized Embeddings for Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.101) |  | 0 | Text embedding is pivotal in semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. STS learning largely relies on the cosine function as the optimization objective to reflect semantic similarity. However, the cosine has saturation zones... | Xianming Li, Jing Li |  |
| 221 |  |  [InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews](https://doi.org/10.18653/v1/2024.acl-long.102) |  | 0 | Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether RPAs accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the... | Xintao Wang, Yunze Xiao, Jentse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, Yanghua Xiao |  |
| 222 |  |  [Does DetectGPT Fully Utilize Perturbation? Bridging Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better](https://doi.org/10.18653/v1/2024.acl-long.103) |  | 0 | The burgeoning generative capabilities of large language models (LLMs) have raised growing concerns about abuse, demanding automatic machine-generated text detectors. DetectGPT, a zero-shot metric-based detector, first introduces perturbation and shows great performance improvement. However, in... | Shengchao Liu, Xiaoming Liu, Yichen Wang, Zehua Cheng, Chengzhengxu Li, Zhaohan Zhang, Yu Lan, Chao Shen |  |
| 223 |  |  [AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators](https://doi.org/10.18653/v1/2024.acl-long.104) |  | 0 | With the rise of generative AI, automated fact-checking methods to combat misinformation are becoming more and more important. However, factual claim detection, the first step in a fact-checking pipeline, suffers from two key issues that limit its scalability and generalizability: (1) inconsistency... | Jingwei Ni, Minjing Shi, Dominik Stammbach, Mrinmaya Sachan, Elliott Ash, Markus Leippold |  |
| 224 |  |  [Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering](https://doi.org/10.18653/v1/2024.acl-long.105) |  | 0 | Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for various research and practical endeavors. One avenue in reaching this goal is basing the answers on reliable sources. However, this Evidence-Based QA has proven to work insufficiently with LLMs in... | Tobias Schimanski, Jingwei Ni, Mathias Kraus, Elliott Ash, Markus Leippold |  |
| 225 |  |  [LoRAMoE: Alleviating World Knowledge Forgetting in Large Language Models via MoE-Style Plugin](https://doi.org/10.18653/v1/2024.acl-long.106) |  | 0 | Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to align with human instructions and enhance their capabilities in downstream tasks. Substantially increasing instruction data is a direct solution to align the model with a broader range of downstream... | Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Wei Shen, Limao Xiong, Yuhao Zhou, Xiao Wang, Zhiheng Xi, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 226 |  |  [Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation](https://doi.org/10.18653/v1/2024.acl-long.107) |  | 0 | Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., ”hallucinations”, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this... | Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Lifeng Jin, Linfeng Song, Haitao Mi, Helen Meng |  |
| 227 |  |  [M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions](https://doi.org/10.18653/v1/2024.acl-long.108) |  | 0 | Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant memories from an external database. However, existing RAG methods typically organize all memories in a whole database, potentially limiting focus on crucial memories and introducing noise. In this... | Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi |  |
| 228 |  |  [AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension](https://doi.org/10.18653/v1/2024.acl-long.109) |  | 0 | Recently, instruction-following audio-language models have received broad attention for human-audio interaction. However, the absence of benchmarks capable of evaluating audio-centric interaction capabilities has impeded advancements in this field. Previous models primarily focus on assessing... | Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, Jingren Zhou |  |
| 229 |  |  [Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies](https://doi.org/10.18653/v1/2024.acl-long.110) |  | 0 | Ten years ago a single metric, BLEU, governed progress in machine translation research. For better or worse, there is no such consensus today, and consequently it is difficult for researchers to develop and retain intuitions about metric deltas that drove earlier research and deployment decisions.... | Tom Kocmi, Vilém Zouhar, Christian Federmann, Matt Post |  |
| 230 |  |  [ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.111) |  | 0 | Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. This development underscores the urgent need for evaluating value orientations and understanding of LLMs to ensure their responsible integration into public-facing applications. This work... | Yuanyi Ren, Haoran Ye, Hanjun Fang, Xin Zhang, Guojie Song |  |
| 231 |  |  [DM-BLI: Dynamic Multiple Subspaces Alignment for Unsupervised Bilingual Lexicon Induction](https://doi.org/10.18653/v1/2024.acl-long.112) |  | 0 | Unsupervised bilingual lexicon induction (BLI) task aims to find word translations between languages and has achieved great success in similar language pairs. However, related works mostly rely on a single linear mapping for language alignment and fail on distant or low-resource language pairs,... | Ling Hu, Yuemei Xu |  |
| 232 |  |  [SparseFit: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.113) |  | 0 | Models that generate natural language explanations (NLEs) for their predictions have recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers at training time, which can be expensive and potentially infeasible for... | Jesus Solano, Mardhiyah Sanni, OanaMaria Camburu, Pasquale Minervini |  |
| 233 |  |  [Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation](https://doi.org/10.18653/v1/2024.acl-long.114) |  | 0 | The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper... | Wen Wu, Bo Li, Chao Zhang, ChungCheng Chiu, Qiujia Li, Junwen Bai, Tara N. Sainath, Philip C. Woodland |  |
| 234 |  |  [REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation](https://doi.org/10.18653/v1/2024.acl-long.115) |  | 0 | Open domain question answering (ODQA) aims to answer questions with knowledge from an external corpus. Fusion-in-Decoder (FiD) is an effective retrieval-augmented reader model to address this task. Given that FiD independently encodes passages, which overlooks the semantic relationships between... | Jinyuan Fang, Zaiqiao Meng, Craig MacDonald |  |
| 235 |  |  [Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks](https://doi.org/10.18653/v1/2024.acl-long.116) |  | 0 | Disentangled latent spaces usually have better semantic separability and geometrical properties, which leads to better interpretability and more controllable data generation. While this has been well investigated in Computer Vision, in tasks such as image disentanglement, in the NLP domain,... | Yingji Zhang, Danilo S. Carvalho, André Freitas |  |
| 236 |  |  [MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation](https://doi.org/10.18653/v1/2024.acl-long.117) |  | 0 | A story premise succinctly defines a story’s main idea, foundation, and trajectory. It serves as the initial trigger in automatic story generation. Existing sources of story premises are limited by a lack of diversity, uneven quality, and high costs that make them difficult to scale. In response,... | Yan Ma, Yu Qiao, Pengfei Liu |  |
| 237 |  |  [Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization](https://doi.org/10.18653/v1/2024.acl-long.118) |  | 0 | Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited set of labeled texts, alongside plenty of unlabeled texts that include both in-distribution and out-of-distribution examples. In this paper, we revisit the main challenge in OSTC, i.e., outlier... | Junfan Chen, Richong Zhang, Junchi Chen, Chunming Hu |  |
| 238 |  |  [ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages](https://doi.org/10.18653/v1/2024.acl-long.119) |  | 0 | Tool learning is widely acknowledged as a foundational approach or deploying large language models (LLMs) in real-world scenarios. While current research primarily emphasizes leveraging tools to augment LLMs, it frequently neglects emerging safety considerations tied to their application. To fill... | Junjie Ye, Sixian Li, Guanyu Li, Caishuang Huang, Songyang Gao, Yilong Wu, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 239 |  |  [A synthetic data approach for domain generalization of NLI models](https://doi.org/10.18653/v1/2024.acl-long.120) |  | 0 | Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfulness of model-generated text. There are several large scale NLI datasets today,... | Mohammad Javad Hosseini, Andrey Petrov, Alex Fabrikant, Annie Louis |  |
| 240 |  |  [Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild](https://doi.org/10.18653/v1/2024.acl-long.121) |  | 0 | The principle of continual relation extraction (CRE) involves adapting to emerging novel relations while preserving old knowledge. Existing CRE approaches excel in preserving old knowledge but falter when confronted with contaminated data streams, likely due to an artificial assumption of no... | Ting Wu, Jingyi Liu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 241 |  |  [LRQuant: Learnable and Robust Post-Training Quantization for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.122) |  | 0 | Post-training quantization (PTQ) for large language models (LLMs) significantly accelerates model inference and relieves memory constraints, without incurring model training. A “smoothing paradigm” is commonly used in LLM quantization, which transfers the quantization difficulty of activation to... | Jiaqi Zhao, Miao Zhang, Chao Zeng, Ming Wang, Xuebo Liu, Liqiang Nie |  |
| 242 |  |  [VariErr NLI: Separating Annotation Error from Human Label Variation](https://doi.org/10.18653/v1/2024.acl-long.123) |  | 0 | Human label variation arises when annotators assign different labels to the same item for valid reasons, while annotation errors occur when labels are assigned for invalid reasons. These two issues are prevalent in NLP benchmarks, yet existing research has studied them in isolation. To the best of... | Leon WeberGenzel, Siyao Peng, MarieCatherine de Marneffe, Barbara Plank |  |
| 243 |  |  [Benchmarking Knowledge Boundary for Large Language Models: A Different Perspective on Model Evaluation](https://doi.org/10.18653/v1/2024.acl-long.124) |  | 0 | In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks.To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs.We... | Xunjian Yin, Xu Zhang, Jie Ruan, Xiaojun Wan |  |
| 244 |  |  [ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval](https://doi.org/10.18653/v1/2024.acl-long.125) |  | 0 | We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and... | Soyoung Yoon, Eunbi Choi, Jiyeon Kim, Hyeongu Yun, Yireun Kim, Seungwon Hwang |  |
| 245 |  |  [Exploring the Potential of Large Language Models in Computational Argumentation](https://doi.org/10.18653/v1/2024.acl-long.126) |  | 0 | Computational argumentation has become an essential tool in various domains, including law, public policy, and artificial intelligence. It is an emerging research field in natural language processing that attracts increasing attention. Research on computational argumentation mainly involves two... | Guizhen Chen, Liying Cheng, Anh Tuan Luu, Lidong Bing |  |
| 246 |  |  [TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks](https://doi.org/10.18653/v1/2024.acl-long.127) |  | 0 | In this paper, we explore the capabilities of LLMs in capturing lexical-semantic knowledge from WordNet on the example of the LLaMA-2-7b model and test it on multiple lexical semantic tasks. As the outcome of our experiments, we present TaxoLLaMA, the “all-in-one” model for taxonomy-related tasks,... | Viktor Moskvoretskii, Ekaterina Neminova, Alina Lobanova, Alexander Panchenko, Irina Nikishina |  |
| 247 |  |  [CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.128) |  | 0 | The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows the application of existing knowledge to unfamiliar scenarios. However, existing works tend to undervalue the step of instantiation and heavilyrely on pre-built concept... | Weiqi Wang, Tianqing Fang, Chunyang Li, Haochen Shi, Wenxuan Ding, Baixuan Xu, Zhaowei Wang, Jiaxin Bai, Xin Liu, Cheng Jiayang, Chunkit Chan, Yangqiu Song |  |
| 248 |  |  [MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter](https://doi.org/10.18653/v1/2024.acl-long.129) |  | 0 | Parameter-Efficient Fine-tuning (PEFT) facilitates the fine-tuning of Large Language Models (LLMs) under limited resources. However, the fine-tuning performance with PEFT on complex, knowledge-intensive tasks is limited due to the constrained model capacity, which originates from the limited number... | Jitai Hao, Weiwei Sun, Xin Xin, Qi Meng, Zhumin Chen, Pengjie Ren, Zhaochun Ren |  |
| 249 |  |  [Surgical Feature-Space Decomposition of LLMs: Why, When and How?](https://doi.org/10.18653/v1/2024.acl-long.130) |  | 0 | Low-rank approximations, of the weight and feature space can enhance the performance of deep learning models, whether in terms of improving generalization or reducing the latency of inference. However, there is no clear consensus yet on how, when and why these approximations are helpful for large... | Arnav Chavan, Nahush Lele, Deepak K. Gupta |  |
| 250 |  |  [Reasoning in Flux: Enhancing Large Language Models Reasoning through Uncertainty-aware Adaptive Guidance](https://doi.org/10.18653/v1/2024.acl-long.131) |  | 0 | Machine reasoning, which involves solving complex problems through step-by-step deduction and analysis, is a crucial indicator of the capabilities of Large Language Models (LLMs). However, as the complexity of tasks escalates, LLMs often encounter increasing errors in their multi-step reasoning... | Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Xiaonan Li, Junqi Dai, Qinyuan Cheng, Xuanjing Huang, Xipeng Qiu |  |
| 251 |  |  [Modality-Aware Integration with Large Language Models for Knowledge-Based Visual Question Answering](https://doi.org/10.18653/v1/2024.acl-long.132) |  | 0 | Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging... | Junnan Dong, Qinggang Zhang, Huachi Zhou, Daochen Zha, Pai Zheng, Xiao Huang |  |
| 252 |  |  [Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression](https://doi.org/10.18653/v1/2024.acl-long.133) |  | 0 | Key-value (KV) caching is an important technique to accelerate the inference of large language models (LLMs), but incurs significant memory overhead. To compress the size of KV cache, existing methods often compromise precision or require extra data for calibration, limiting their practicality in... | Peiyu Liu, ZeFeng Gao, Xin Zhao, Yipeng Ma, Tao Wang, JiRong Wen |  |
| 253 |  |  [VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.134) |  | 0 | Recent approaches in domain-specific named entity recognition (NER), such as biomedical NER, have shown remarkable advances. However, they still lack of faithfulness, producing erroneous predictions. We assume that knowledge of entities can be useful in verifying the correctness of the predictions.... | Seoyeon Kim, Kwangwook Seo, Hyungjoo Chae, Jinyoung Yeo, Dongha Lee |  |
| 254 |  |  [Making Long-Context Language Models Better Multi-Hop Reasoners](https://doi.org/10.18653/v1/2024.acl-long.135) |  | 0 | Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased performance in the presence of noisy contexts. In this paper,... | Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang |  |
| 255 |  |  [TransliCo: A Contrastive Learning Framework to Address the Script Barrier in Multilingual Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.136) |  | 0 | The world’s more than 7000 languages are written in at least 293 scripts. Due to various reasons, many closely related languages use different scripts, which poses a difficulty for multilingual pretrained language models (mPLMs) in learning crosslingual knowledge through lexical overlap. As a... | Yihong Liu, Chunlan Ma, Haotian Ye, Hinrich Schütze |  |
| 256 |  |  [Extreme Miscalibration and the Illusion of Adversarial Robustness](https://doi.org/10.18653/v1/2024.acl-long.137) |  | 0 | Deep learning-based Natural Language Processing (NLP) models are vulnerable to adversarial attacks, where small perturbations can cause a model to misclassify. Adversarial Training (AT) is often used to increase model robustness. However, we have discovered an intriguing phenomenon: deliberately or... | Vyas Raina, Samson Tan, Volkan Cevher, Aditya Rawal, Sheng Zha, George Karypis |  |
| 257 |  |  [HyCoRec: Hypergraph-Enhanced Multi-Preference Learning for Alleviating Matthew Effect in Conversational Recommendation](https://doi.org/10.18653/v1/2024.acl-long.138) |  | 0 | The Matthew effect is a notorious issue in Recommender Systems (RSs), i.e., the rich get richer and the poor get poorer, wherein popular items are overexposed while less popular ones are regularly ignored. Most methods examine Matthew effect in static or nearly-static recommendation scenarios.... | Yongsen Zheng, Ruilin Xu, Ziliang Chen, Guohua Wang, Mingjie Qian, Jinghui Qin, Liang Lin |  |
| 258 |  |  [Co-training for Low Resource Scientific Natural Language Inference](https://doi.org/10.18653/v1/2024.acl-long.139) |  | 0 | Scientific Natural Language Inference (NLI) is the task of predicting the semantic relation between a pair of sentences extracted from research articles. The automatic annotation method based on distant supervision for the training set of SciNLI, the first and most popular dataset for this task,... | Mobashir Sadat, Cornelia Caragea |  |
| 259 |  |  [RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.140) |  | 0 | Reinforcement Learning with Human Feedback (RLHF) is a methodology designed to align Large Language Models (LLMs) with human preferences, playing an important role in LLMs alignment. Despite its advantages, RLHF relies on human annotators to rank the text, which can introduce potential security... | Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao |  |
| 260 |  |  [Time is Encoded in the Weights of Finetuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.141) |  | 0 | We present time vectors, a simple tool to customize language models to new time periods. Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model. This vector specifies a direction... | Kai Nylund, Suchin Gururangan, Noah A. Smith |  |
| 261 |  |  [Long-Context Language Modeling with Parallel Context Encoding](https://doi.org/10.18653/v1/2024.acl-long.142) |  | 0 | Extending large language models (LLMs) to process longer inputs is crucial for a wide range of applications. However, the substantial computational cost of transformers and limited generalization of positional encoding restrict the size of their context window. We introduce Context Expansion with... | Howard Yen, Tianyu Gao, Danqi Chen |  |
| 262 |  |  [SirLLM: Streaming Infinite Retentive LLM](https://doi.org/10.18653/v1/2024.acl-long.143) |  | 0 | As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process inputs of any length and maintain a degree of memory becomes essential. However, the one-off input of overly long texts is limited, as studies have shown that when input lengths exceed the... | Yao Yao, Zuchao Li, Hai Zhao |  |
| 263 |  |  [IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models](https://doi.org/10.18653/v1/2024.acl-long.144) |  | 0 | Machine learning models have made incredible progress, but they still struggle when applied to examples from unseen domains. This study focuses on a specific problem of domain generalization, where a model is trained on one source domain and tested on multiple target domains that are unseen during... | Tao Feng, Lizhen Qu, Zhuang Li, Haolan Zhan, Yuncheng Hua, Gholamreza Haffari |  |
| 264 |  |  [Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale](https://doi.org/10.18653/v1/2024.acl-long.145) |  | 0 | A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner.We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained from scratch on raw texts with high parallelism. GPST... | Xiang Hu, Pengyu Ji, Qingyang Zhu, Wei Wu, Kewei Tu |  |
| 265 |  |  [MELA: Multilingual Evaluation of Linguistic Acceptability](https://doi.org/10.18653/v1/2024.acl-long.146) |  | 0 | In this work, we present the largest benchmark to date on linguistic acceptability: Multilingual Evaluation of Linguistic Acceptability—MELA, with 46K samples covering 10 languages from a diverse set of language families. We establish LLM baselines on this benchmark, and investigate cross-lingual... | Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, Hai Hu |  |
| 266 |  |  [CopyNE: Better Contextual ASR by Copying Named Entities](https://doi.org/10.18653/v1/2024.acl-long.147) |  | 0 | End-to-end automatic speech recognition (ASR) systems have made significant progress in general scenarios. However, it remains challenging to transcribe contextual named entities (NEs) in the contextual ASR scenario. Previous approaches have attempted to address this by utilizing the NE dictionary.... | Shilin Zhou, Zhenghua Li, Yu Hong, Min Zhang, Zhefeng Wang, Baoxing Huai |  |
| 267 |  |  [Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval](https://doi.org/10.18653/v1/2024.acl-long.148) |  | 0 | Retrieving relevant tables containing the necessary information to accurately answer a given question over tables is critical to open-domain question-answering (QA) systems. Previous methods assume the answer to such a question can be found either in a single table or multiple tables identified... | Peter Baile Chen, Yi Zhang, Dan Roth |  |
| 268 |  |  [Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation](https://doi.org/10.18653/v1/2024.acl-long.149) |  | 0 | Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem – that is, users can perform a... | Haonan Chen, Zhicheng Dou, Kelong Mao, Jiongnan Liu, Ziliang Zhao |  |
| 269 |  |  [ItD: Large Language Models Can Teach Themselves Induction through Deduction](https://doi.org/10.18653/v1/2024.acl-long.150) |  | 0 | Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, researchers have found that they still have limited ability to conduct induction. Recent works mainly adopt “post processes” paradigms to improve the performance of LLMs on... | Wangtao Sun, Haotian Xu, Xuanqing Yu, Pei Chen, Shizhu He, Jun Zhao, Kang Liu |  |
| 270 |  |  [MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.151) |  | 0 | Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and... | Zimu Lu, Aojun Zhou, Houxing Ren, Ke Wang, Weikang Shi, Junting Pan, Mingjie Zhan, Hongsheng Li |  |
| 271 |  |  [Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent](https://doi.org/10.18653/v1/2024.acl-long.152) |  | 0 | Task-oriented dialogue (TOD) systems are predominantly designed to be composed of several functional modules (e.g. dialogue state tracker, dialogue policy, natural language generation) whether they are pipeline or end-to-end architectures. However, this modular design not only heavily relies on... | HengDa Xu, XianLing Mao, Puhai Yang, Fanshu Sun, Heyan Huang |  |
| 272 |  |  [On Context Utilization in Summarization with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.153) |  | 0 | Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of... | Mathieu Ravaut, Aixin Sun, Nancy F. Chen, Shafiq Joty |  |
| 273 |  |  [INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.154) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While... | Yutao Zhu, Peitian Zhang, Chenghao Zhang, Yifei Chen, Binyu Xie, Zheng Liu, JiRong Wen, Zhicheng Dou |  |
| 274 |  |  [Enhancing In-Context Learning via Implicit Demonstration Augmentation](https://doi.org/10.18653/v1/2024.acl-long.155) |  | 0 | The emergence of in-context learning (ICL) enables large pre-trained language models (PLMs) to make predictions for unseen inputs without updating parameters. Despite its potential, ICL’s effectiveness heavily relies on the quality, quantity, and permutation of demonstrations, commonly leading to... | Xiaoling Zhou, Wei Ye, Yidong Wang, Chaoya Jiang, Zhemg Lee, Rui Xie, Shikun Zhang |  |
| 275 |  |  [PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA](https://doi.org/10.18653/v1/2024.acl-long.156) |  | 0 | With the rapid scaling of large language models (LLMs), serving numerouslow-rank adaptations (LoRAs) concurrently has become increasingly impractical,leading to unaffordable costs and necessitating more parameter-efficientfinetuning methods. In this work, we introduce Partially Rotation-enhanced... | Sheng Wang, Boyang Xue, Jiacheng Ye, Jiyue Jiang, Liheng Chen, Lingpeng Kong, Chuan Wu |  |
| 276 |  |  [Improving Event Definition Following For Zero-Shot Event Detection](https://doi.org/10.18653/v1/2024.acl-long.157) |  | 0 | Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations.In this work, we aim to improve zero-shot event... | Zefan Cai, PoNien Kung, Ashima Suvarna, Mingyu Derek Ma, Hritik Bansal, Baobao Chang, P. Jeffrey Brantingham, Wei Wang, Nanyun Peng |  |
| 277 |  |  [Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements](https://doi.org/10.18653/v1/2024.acl-long.158) |  | 0 | The current charge prediction datasets mostly focus on single-defendant criminal cases.However, real-world criminal cases usually involve multiple defendants whose criminal facts are intertwined. In an early attempt to fill this gap, we introduce a new benchmark that encompasses legal cases... | Xiao Wei, Qi Xu, Hang Yu, Qian Liu, Erik Cambria |  |
| 278 |  |  [Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding](https://doi.org/10.18653/v1/2024.acl-long.159) |  | 0 | Conversational dense retrieval has shown to be effective in conversational search. However, a major limitation of conversational dense retrieval is their lack of interpretability, hindering intuitive understanding of model behaviors for targeted improvements. This paper presents CONVINV, a simple... | Yiruo Cheng, Kelong Mao, Zhicheng Dou |  |
| 279 |  |  [Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks](https://doi.org/10.18653/v1/2024.acl-long.160) |  | 0 | The widespread use of large language models (LLMs) is increasing the demand for methods that detect machine-generated text to prevent misuse. The goal of our study is to stress test the detectors’ robustness to malicious attacks under realistic scenarios. We comprehensively study the robustness of... | Yichen Wang, Shangbin Feng, Abe Bohan Hou, Xiao Pu, Chao Shen, Xiaoming Liu, Yulia Tsvetkov, Tianxing He |  |
| 280 |  |  [Training Language Models to Generate Text with Citations via Fine-grained Rewards](https://doi.org/10.18653/v1/2024.acl-long.161) |  | 0 | While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to... | Chengyu Huang, Zeqiu Wu, Yushi Hu, Wenya Wang |  |
| 281 |  |  [Hypergraph based Understanding for Document Semantic Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.162) |  | 0 | Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus... | Qiwei Li, Zuchao Li, Ping Wang, Haojun Ai, Hai Zhao |  |
| 282 |  |  [GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers](https://doi.org/10.18653/v1/2024.acl-long.163) |  | 0 | Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One... | Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi |  |
| 283 |  |  [Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.164) |  | 0 | Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events. Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event... | Qingkai Min, Qipeng Guo, Xiangkun Hu, Songfang Huang, Zheng Zhang, Yue Zhang |  |
| 284 |  |  [AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning](https://doi.org/10.18653/v1/2024.acl-long.165) |  | 0 | Language agents have achieved considerable performance on various complex question-answering tasks by planning with external tools. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of... | Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen |  |
| 285 |  |  [ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.166) |  | 0 | This study investigates the challenges posed by the dynamic nature of legal multi-label text classification tasks, where legal concepts evolve over time. Existing models often overlook the temporal dimension in their training process, leading to suboptimal performance of those models over time, as... | T. Y. S. S. Santosh, TuanQuang Vuong, Matthias Grabmair |  |
| 286 |  |  [Virtual Compiler Is All You Need For Assembly Code Search](https://doi.org/10.18653/v1/2024.acl-long.167) |  | 0 | Assembly code search is vital for reducing the burden on reverse engineers, allowing them to quickly identify specific functions using natural language within vast binary programs.Despite its significance, this critical task is impeded by the complexities involved in building high-quality datasets.... | Zeyu Gao, Hao Wang, Yuanda Wang, Chao Zhang |  |
| 287 |  |  [MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.168) |  | 0 | Parameter-efficient fine-tuning (PEFT) is a popular method for tailoring pre-trained large language models (LLMs), especially as the models’ scale and the diversity of tasks increase. Low-rank adaptation (LoRA) is based on the idea that the adaptation process is intrinsically low-dimensional, i.e.,... | Pengjie Ren, Chengshun Shi, Shiguang Wu, Mengqi Zhang, Zhaochun Ren, Maarten de Rijke, Zhumin Chen, Jiahuan Pei |  |
| 288 |  |  [Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning](https://doi.org/10.18653/v1/2024.acl-long.169) |  | 0 | Large language models (LLMs) have demonstrated striking reasoning capability. Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples,... | Yongqi Tong, Dawei Li, Sizhe Wang, Yujia Wang, Fei Teng, Jingbo Shang |  |
| 289 |  |  [An Iterative Associative Memory Model for Empathetic Response Generation](https://doi.org/10.18653/v1/2024.acl-long.170) |  | 0 | Empathetic response generation aims to comprehend the cognitive and emotional states in dialogue utterances and generate proper responses. Psychological theories posit that comprehending emotional and cognitive states necessitates iteratively capturing and understanding associated words across... | Zhou Yang, Zhaochun Ren, Yufeng Wang, Haizhou Sun, Chao Chen, Xiaofei Zhu, Xiangwen Liao |  |
| 290 |  |  [Detoxifying Large Language Models via Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.171) |  | 0 | This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments with... | Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, Linyi Yang, Jindong Wang, Huajun Chen |  |
| 291 |  |  [LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.172) |  | 0 | Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs, such as books, reports, and codebases. Recent works have proposed methods to... | Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li |  |
| 292 |  |  [Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.173) |  | 0 | Teachers are important to imparting knowledge and guiding learners, and the role of large language models (LLMs) as potential educators is emerging as an important area of study. Recognizing LLMs’ capability to generate educational content can lead to advances in automated and personalized... | Yuyan Chen, Songzhou Yan, Panjun Liu, Yanghua Xiao |  |
| 293 |  |  [UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-long.174) |  | 0 | In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a comprehensive approach developed to improve the effectiveness of Cross-Lingual Transfer Learning, particularly in languages with limited resources. Our approach tackles two essential... | Trinh Pham, Khoi Le, Anh Tuan Luu |  |
| 294 |  |  [VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval](https://doi.org/10.18653/v1/2024.acl-long.175) |  | 0 | Multi-modal retrieval becomes increasingly popular in practice. However, the existing retrievers are mostly text-oriented, which lack the capability to process visual information. Despite the presence of vision-language models like CLIP, the current methods are severely limited in representing the... | Junjie Zhou, Zheng Liu, Shitao Xiao, Bo Zhao, Yongping Xiong |  |
| 295 |  |  [Black-Box Prompt Optimization: Aligning Large Language Models without Model Training](https://doi.org/10.18653/v1/2024.acl-long.176) |  | 0 | Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them; that is, the alignment problem. To make LLMs better follow user instructions, existing alignment... | Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang |  |
| 296 |  |  [Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark](https://doi.org/10.18653/v1/2024.acl-long.177) |  | 0 | This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as vital tools for evaluating Large Language Models (LLMs) in Korean. Incorporating private test sets while mirroring the English Open LLM Leaderboard, we establish a robust evaluation framework that has been well integrated... | Chanjun Park, Hyeonwoo Kim, Dahyun Kim, Seonghwan Cho, Sanghoon Kim, Sukyung Lee, Yungi Kim, Hwalsuk Lee |  |
| 297 |  |  [Unified Hallucination Detection for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.178) |  | 0 | Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical... | Xiang Chen, Chenxi Wang, Yida Xue, Ningyu Zhang, Xiaoyan Yang, Qiang Li, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen |  |
| 298 |  |  [Empowering Character-level Text Infilling by Eliminating Sub-Tokens](https://doi.org/10.18653/v1/2024.acl-long.179) |  | 0 | In infilling tasks, sub-tokens, representing instances where a complete token is segmented into two parts, often emerge at the boundaries of prefixes, middles, and suffixes. Traditional methods focused on training models at the token level, leading to sub-optimal performance in character-level... | Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Hongsheng Li |  |
| 299 |  |  [Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.180) |  | 0 | Retrieval augmentation is a promising approach to handle long-context language modeling. However, the existing retrieval methods usually work with the chunked context, which is prone to inferior quality of semantic representation and incomplete retrieval of useful information. In this work, we... | Kun Luo, Zheng Liu, Shitao Xiao, Tong Zhou, Yubo Chen, Jun Zhao, Kang Liu |  |
| 300 |  |  [GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?](https://doi.org/10.18653/v1/2024.acl-long.181) |  | 0 | In the real world, knowledge is constantly evolving, which can render existing knowledge-based datasets outdated. This unreliability highlights the critical need for continuous updates to ensure both accuracy and relevance in knowledge-intensive tasks. To address this, we propose GrowOVER-QA and... | Dayoon Ko, Jinyoung Kim, Hahyeon Choi, Gunhee Kim |  |
| 301 |  |  [Attribute First, then Generate: Locally-attributable Grounded Text Generation](https://doi.org/10.18653/v1/2024.acl-long.182) |  | 0 | Recent efforts to address hallucinations in Large Language Models (LLMs) have focused on attributed text generation, which supplements generated texts with citations of supporting sources for post-generation fact-checking and corrections. Yet, these citations often point to entire documents or... | Aviv Slobodkin, Eran Hirsch, Arie Cattan, Tal Schuster, Ido Dagan |  |
| 302 |  |  [T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text](https://doi.org/10.18653/v1/2024.acl-long.183) |  | 0 | In this work, we propose a two-stage sign language production (SLP) paradigm that first encodes sign language sequences into discrete codes and then autoregressively generates sign language from text based on the learned codebook. However, existing vector quantization (VQ) methods are fixed-length... | Aoxiong Yin, Haoyuan Li, Kai Shen, Siliang Tang, Yueting Zhuang |  |
| 303 |  |  [OceanGPT: A Large Language Model for Ocean Science Tasks](https://doi.org/10.18653/v1/2024.acl-long.184) |  | 0 | Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet’s surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other... | Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, Huajun Chen |  |
| 304 |  |  [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://doi.org/10.18653/v1/2024.acl-long.185) |  | 0 | Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks.However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM... | Tongyao Zhu, Qian Liu, Liang Pang, Zhengbao Jiang, MinYen Kan, Min Lin |  |
| 305 |  |  [BIPED: Pedagogically Informed Tutoring System for ESL Education](https://doi.org/10.18653/v1/2024.acl-long.186) |  | 0 | Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English. Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to... | Soonwoo Kwon, Sojung Kim, Minju Park, Seunghyun Lee, Kyuseok Kim |  |
| 306 |  |  [Timeline-based Sentence Decomposition with In Context Learning for Temporal Fact Extraction](https://doi.org/10.18653/v1/2024.acl-long.187) |  | 0 | Facts extraction is pivotal for constructing knowledge graphs. Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction. In this paper, we specifically address the extraction of temporal facts from natural language text.... | Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu |  |
| 307 |  |  [Collaboration or Corporate Capture? Quantifying NLP's Reliance on Industry Artifacts and Contributions](https://doi.org/10.18653/v1/2024.acl-long.188) |  | 0 | Impressive performance of pre-trained models has garnered public attention and made news headlines in recent years. Almost always, these models are produced by or in collaboration with industry. Using them is critical for competing on natural language processing (NLP) benchmarks and correspondingly... | Will Aitken, Mohamed Abdalla, Karen Rudie, Catherine Stinson |  |
| 308 |  |  [Prompt Expansion for Adaptive Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.189) |  | 0 | Text-to-image generation models are powerful but difficult to use. Users craft specific prompts to get better images, though the images can be repetitive. This paper proposes the Prompt Expansion framework that helps users generate high-quality, diverse images with less effort. The Prompt Expansion... | Siddhartha Datta, Alexander Ku, Deepak Ramachandran, Peter Anderson |  |
| 309 |  |  [Progressively Modality Freezing for Multi-Modal Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.190) |  | 0 | Multi-Modal Entity Alignment aims to discover identical entities across heterogeneous knowledge graphs. While recent studies have delved into fusion paradigms to represent entities holistically, the elimination of features irrelevant to alignment and modal inconsistencies is overlooked, which are... | Yani Huang, Xuefeng Zhang, Richong Zhang, Junfan Chen, Jaein Kim |  |
| 310 |  |  [Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-long.191) |  | 0 | Dense retrieval calls for discriminative embeddings to represent the semantic relationship between query and document. It may benefit from the using of large language models (LLMs), given LLMs’ strong capability on semantic understanding. However, the LLMs are learned by auto-regression, whose... | Chaofan Li, Zheng Liu, Shitao Xiao, Yingxia Shao, Defu Lian |  |
| 311 |  |  [Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts](https://doi.org/10.18653/v1/2024.acl-long.192) |  | 0 | Large language models (LLMs) are known to effectively perform tasks by simply observing few exemplars. However, in low-resource languages, obtaining such hand-picked exemplars can still be challenging, where unsupervised techniques may be necessary. Moreover, competent generative capabilities of... | XuanPhi Nguyen, Mahani Aljunied, Shafiq Joty, Lidong Bing |  |
| 312 |  |  [Metaphor Understanding Challenge Dataset for LLMs](https://doi.org/10.18653/v1/2024.acl-long.193) |  | 0 | Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning and categorisation, and are deeply rooted in everyday communication. Metaphor understanding is therefore an essential task for large language models (LLMs). We release the Metaphor... | Xiaoyu Tong, Rochelle Choenni, Martha Lewis, Ekaterina Shutova |  |
| 313 |  |  [A Multi-Task Embedder For Retrieval Augmented LLMs](https://doi.org/10.18653/v1/2024.acl-long.194) |  | 0 | LLMs confront inherent limitations in terms of its knowledge, memory, and action. The retrieval augmentation stands as a vital mechanism to address these limitations, which brings in useful information from external sources to augment the LLM. However, existing retrieval methods encounter two... | Peitian Zhang, Zheng Liu, Shitao Xiao, Zhicheng Dou, JianYun Nie |  |
| 314 |  |  [Language Models Don't Learn the Physical Manifestation of Language](https://doi.org/10.18653/v1/2024.acl-long.195) |  | 0 | We argue that language-only models don’t learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test.These tasks highlight a fundamental gap between human linguistic understanding and the... | Bruce W. Lee, Jaehyuk Lim |  |
| 315 |  |  [What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection](https://doi.org/10.18653/v1/2024.acl-long.196) |  | 0 | Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language... | Shangbin Feng, Herun Wan, Ningnan Wang, Zhaoxuan Tan, Minnan Luo, Yulia Tsvetkov |  |
| 316 |  |  [Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives](https://doi.org/10.18653/v1/2024.acl-long.197) |  | 0 | The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM’s response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM’s intrinsic... | Wenqi Zhang, Yongliang Shen, Linjuan Wu, Qiuying Peng, Jun Wang, Yueting Zhuang, Weiming Lu |  |
| 317 |  |  [Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty](https://doi.org/10.18653/v1/2024.acl-long.198) |  | 0 | As natural language becomes the default interface for human-AI interaction, there is a need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence in responses via natural language and how downstream users behave in... | Kaitlyn Zhou, Jena D. Hwang, Xiang Ren, Maarten Sap |  |
| 318 |  |  [Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources](https://doi.org/10.18653/v1/2024.acl-long.199) |  | 0 | Although pre-training has become a prevalent approach for addressing various biomedical tasks, the current efficacy of pre-trained models is hindered by their reliance on a limited scope of medical sources. This limitation results in data scarcity during pre-training and restricts the range of... | Xiaochen Wang, Junyu Luo, Jiaqi Wang, Yuan Zhong, Xiaokun Zhang, Yaqing Wang, Parminder Bhatia, Cao Xiao, Fenglong Ma |  |
| 319 |  |  [When Good and Reproducible Results are a Giant with Feet of Clay: The Importance of Software Quality in NLP](https://doi.org/10.18653/v1/2024.acl-long.200) |  | 0 | Despite its crucial role in research experiments, code correctness is often presumed solely based on the perceived quality of results. This assumption, however, comes with the risk of erroneous outcomes and, in turn, potentially misleading findings. To mitigate this risk, we posit that the current... | Sara Papi, Marco Gaido, Andrea Pilzer, Matteo Negri |  |
| 320 |  |  [SBAAM! Eliminating Transcript Dependency in Automatic Subtitling](https://doi.org/10.18653/v1/2024.acl-long.201) |  | 0 | Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three primary subtasks: translating spoken dialogue, segmenting translations into concise textual units, and estimating timestamps that govern their on-screen duration. Past attempts to automate... | Marco Gaido, Sara Papi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli |  |
| 321 |  |  [StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection](https://doi.org/10.18653/v1/2024.acl-long.202) |  | 0 | Streaming speech-to-text translation (StreamST) is the task of automatically translating speech while incrementally receiving an audio stream. Unlike simultaneous ST (SimulST), which deals with pre-segmented speech, StreamST faces the challenges of handling continuous and unbounded audio streams.... | Sara Papi, Marco Gaido, Matteo Negri, Luisa Bentivogli |  |
| 322 |  |  [ARL2: Aligning Retrievers with Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](https://doi.org/10.18653/v1/2024.acl-long.203) |  | 0 | Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with... | Lingxi Zhang, Yue Yu, Kuan Wang, Chao Zhang |  |
| 323 |  |  [Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference](https://doi.org/10.18653/v1/2024.acl-long.204) |  | 0 | The customization of large language models (LLMs) for user-specified tasks gets important. However, maintaining all the customized LLMs on cloud servers incurs substantial memory and computational overheads, and uploading user data can also lead to privacy concerns. On-device LLMs can offer a... | Jihwan Bang, Juntae Lee, Kyuhong Shim, Seunghan Yang, Simyung Chang |  |
| 324 |  |  [FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model](https://doi.org/10.18653/v1/2024.acl-long.205) |  | 0 | Most existing image captioning evaluation metrics focus on assigning a single numerical score to a caption by comparing it with reference captions. However, these methods do not provide an explanation for the assigned score. Moreover, reference captions are expensive to acquire. In this paper, we... | Yebin Lee, Imseong Park, Myungjoo Kang |  |
| 325 |  |  [MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations](https://doi.org/10.18653/v1/2024.acl-long.206) |  | 0 | Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its context-dependent and often subtle nature. The detection of manipulative language is essential for protecting potential victims, yet the field of Natural Language Processing... | Yuxin Wang, Ivory Yang, Saeed Hassanpour, Soroush Vosoughi |  |
| 326 |  |  [MPCoder: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning](https://doi.org/10.18653/v1/2024.acl-long.207) |  | 0 | Large Language Models (LLMs) have demonstrated great potential for assisting developers in their daily development. However, most research focuses on generating correct code, how to use LLMs to generate personalized code has seldom been investigated. To bridge this gap, we proposed MPCoder... | Zhenlong Dai, Chang Yao, WenKang Han, Yuanying Yuanying, Zhipeng Gao, Jingyuan Chen |  |
| 327 |  |  [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://doi.org/10.18653/v1/2024.acl-long.208) |  | 0 | Large language models (LLMs) have become a dominant and important tool for NLP researchers in a wide range of tasks. Today, many researchers use LLMs in synthetic data generation, task evaluation, fine-tuning, distillation, and other model-in-the-loop research workflows. However, challenges arise... | Ajay Patel, Colin Raffel, Chris CallisonBurch |  |
| 328 |  |  [Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective](https://doi.org/10.18653/v1/2024.acl-long.209) |  | 0 | Neural Machine Translation (NMT) has made remarkable progress over the past years. However, under-translation and over-translation remain two challenging problems in state-of-the-art NMT systems. In this work, we conduct an in-depth analysis on the underlying cause of under-translation in NMT,... | Chenze Shao, Fandong Meng, Jiali Zeng, Jie Zhou |  |
| 329 |  |  [Identifying while Learning for Document Event Causality Identification](https://doi.org/10.18653/v1/2024.acl-long.210) |  | 0 | Event Causality Identification (ECI) aims to detect whether there exists a causal relation between two events in a document. Existing studies adopt a kind of \*identifying after learning\* paradigm, where events’ representations are first learned and then used for the identification. Furthermore,... | Cheng Liu, Wei Xiang, Bang Wang |  |
| 330 |  |  [OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems](https://doi.org/10.18653/v1/2024.acl-long.211) |  | 0 | Recent advancements have seen Large Language Models (LLMs) and Large Multimodal Models (LMMs) surpassing general human capabilities in various tasks, approaching the proficiency level of human experts across multiple domains. With traditional benchmarks becoming less challenging for these models,... | Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Leng Thai, Junhao Shen, Jinyi Hu, Xu Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, Maosong Sun |  |
| 331 |  |  [Insert or Attach: Taxonomy Completion via Box Embedding](https://doi.org/10.18653/v1/2024.acl-long.212) |  | 0 | Taxonomy completion, enriching existing taxonomies by inserting new concepts as parents or attaching them as children, has gained significant interest. Previous approaches embed concepts as vectors in Euclidean space, which makes it difficult to model asymmetric relations in taxonomy. In addition,... | Wei Xue, Yongliang Shen, Wenqi Ren, Jietian Guo, Shiliang Pu, Weiming Lu |  |
| 332 |  |  [Semiparametric Token-Sequence Co-Supervision](https://doi.org/10.18653/v1/2024.acl-long.213) |  | 0 | In this work, we introduce a semiparametric token-sequence co-supervision training method. It trains a language model by simultaneously leveraging supervision from the traditional next token prediction loss which is calculated over the parametric token embedding space and the next sequence... | Hyunji Lee, Doyoung Kim, Jihoon Jun, Se June Joo, Joel Jang, KyoungWoon On, Minjoon Seo |  |
| 333 |  |  [Instruction Fusion: Advancing Prompt Evolution through Hybridization](https://doi.org/10.18653/v1/2024.acl-long.214) |  | 0 | The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code... | Weidong Guo, Jiuding Yang, Kaitong Yang, Xiangyang Li, Zhuwei Rao, Yu Xu, Di Niu |  |
| 334 |  |  [TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation](https://doi.org/10.18653/v1/2024.acl-long.215) |  | 0 | Despite remarkable advancements in emulating human-like behavior through Large Language Models (LLMs), current textual simulations do not adequately address the notion of time. To this end, we introduce TimeArena, a novel textual simulated environment that incorporates complex temporal dynamics and... | Yikai Zhang, Siyu Yuan, Caiyu Hu, Kyle Richardson, Yanghua Xiao, Jiangjie Chen |  |
| 335 |  |  [Exploring Memorization in Fine-tuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.216) |  | 0 | Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is... | Shenglai Zeng, Yaxin Li, Jie Ren, Yiding Liu, Han Xu, Pengfei He, Yue Xing, Shuaiqiang Wang, Jiliang Tang, Dawei Yin |  |
| 336 |  |  [Towards Real-world Scenario: Imbalanced New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.217) |  | 0 | New Intent Discovery (NID) aims at detecting known and previously undefined categories of user intent by utilizing limited labeled and massive unlabeled data. Most prior works often operate under the unrealistic assumption that the distribution of both familiar and new intent classes is uniform,... | Shun Zhang, Chaoran Yan, Jian Yang, Jiaheng Liu, Ying Mo, Jiaqi Bai, Tongliang Li, Zhoujun Li |  |
| 337 |  |  [M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection](https://doi.org/10.18653/v1/2024.acl-long.218) |  | 0 | The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine... | Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, Thomas Arnold, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov |  |
| 338 |  |  [Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue](https://doi.org/10.18653/v1/2024.acl-long.219) |  | 0 | Tuning language models for dialogue generation has been a prevalent paradigm for building capable dialogue agents. Yet, traditional tuning narrowly views dialogue generation as resembling other language generation tasks, ignoring the role disparities between two speakers and the multi-round... | Jian Wang, Chak Tou Leong, Jiashuo Wang, Dongding Lin, Wenjie Li, Xiaoyong Wei |  |
| 339 |  |  [SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training](https://doi.org/10.18653/v1/2024.acl-long.220) |  | 0 | The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and neglects the varying degrees of duplication. To... | Nan He, Weichen Xiong, Hanwen Liu, Yi Liao, Lei Ding, Kai Zhang, Guohua Tang, Xiao Han, Yang Wei |  |
| 340 |  |  [Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?](https://doi.org/10.18653/v1/2024.acl-long.221) |  | 0 | Building machines with commonsense has been a longstanding challenge in NLP due to the reporting bias of commonsense rules and the exposure bias of rule-based commonsense reasoning. In contrast, humans convey and pass down commonsense implicitly through stories. This paper investigates the inherent... | Ning Bian, Xianpei Han, Hongyu Lin, Yaojie Lu, Ben He, Le Sun |  |
| 341 |  |  [Learning Global Controller in Latent Space for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.222) |  | 0 | While large language models (LLMs) have showcased remarkable prowess in various natural language processing tasks, their training costs are exorbitant. Consequently, a plethora of parameter-efficient fine-tuning methods have emerged to tailor large models for downstream tasks, including low-rank... | Zeqi Tan, Yongliang Shen, Xiaoxia Cheng, Chang Zong, Wenqi Zhang, Jian Shao, Weiming Lu, Yueting Zhuang |  |
| 342 |  |  [CaMML: Context-Aware Multimodal Learner for Large Models](https://doi.org/10.18653/v1/2024.acl-long.223) |  | 0 | In this work, we introduce Context-Aware MultiModal Learner (CaMML), for tuning large multimodal models (LMMs). CaMML, a lightweight module, is crafted to seamlessly integrate multimodal contextual samples into large models, thereby empowering the model to derive knowledge from analogous,... | Yixin Chen, Shuai Zhang, Boran Han, Tong He, Bo Li |  |
| 343 |  |  [MAVEN-ARG: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation](https://doi.org/10.18653/v1/2024.acl-long.224) |  | 0 | Understanding events in texts is a core objective of natural language understanding, which requires detecting event occurrences, extracting event arguments, and analyzing inter-event relationships. However, due to the annotation challenges brought by task complexity, a large-scale dataset covering... | Xiaozhi Wang, Hao Peng, Yong Guan, Kaisheng Zeng, Jianhui Chen, Lei Hou, Xu Han, Yankai Lin, Zhiyuan Liu, Ruobing Xie, Jie Zhou, Juanzi Li |  |
| 344 |  |  [NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes](https://doi.org/10.18653/v1/2024.acl-long.225) |  | 0 | Complex reasoning ability is one of the most important features of Large Language Models (LLMs). Numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, they are inadequate in offering a rigorous evaluation and prone to the risk of overfitting, as these... | Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng Zhang |  |
| 345 |  |  [Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.226) |  | 0 | Text watermarking technology aims to tag and identify content produced by large language models (LLMs) to prevent misuse. In this study, we introduce the concept of cross-lingual consistency in text watermarking, which assesses the ability of text watermarks to maintain their effectiveness after... | Zhiwei He, Binglin Zhou, Hongkun Hao, Aiwei Liu, Xing Wang, Zhaopeng Tu, Zhuosheng Zhang, Rui Wang |  |
| 346 |  |  [Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors](https://doi.org/10.18653/v1/2024.acl-long.227) |  | 0 | Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it... | Alicja Chaszczewicz, Raj Sanjay Shah, Ryan Louie, Bruce A Arnow, Robert E. Kraut, Diyi Yang |  |
| 347 |  |  [In-context Mixing (ICM): Code-mixed Prompts for Multilingual LLMs](https://doi.org/10.18653/v1/2024.acl-long.228) |  | 0 | We introduce a simple and effective prompting technique called in-context mixing (ICM) for effective in-context learning (ICL) with multilingual large language models (MLLMs). With ICM, we modify the few-shot examples within ICL prompts to be intra-sententially code-mixed by randomly swapping... | Bhavani Shankar, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 348 |  |  [Respond in my Language: Mitigating Language Inconsistency in Response Generation based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.229) |  | 0 | Large Language Models (LLMs) show strong instruction understanding ability across multiple languages. However, they are easily biased towards English in instruction tuning, and generate English responses even given non-English instructions. In this paper, we investigate the language inconsistent... | Liang Zhang, Qin Jin, Haoyang Huang, Dongdong Zhang, Furu Wei |  |
| 349 |  |  [Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries](https://doi.org/10.18653/v1/2024.acl-long.230) |  | 0 | This study investigates the privacy risks associated with text embeddings, focusing on the scenario where attackers cannot access the original embedding model. Contrary to previous research requiring direct model access, we explore a more realistic threat model by developing a transfer attack... | YuHsiang Huang, YuChe Tsai, Hsiang Hsiao, HongYi Lin, ShouDe Lin |  |
| 350 |  |  [Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding](https://doi.org/10.18653/v1/2024.acl-long.231) |  | 0 | Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF encounters numerous challenges, including the objective mismatch issue,... | Kuo Liao, Shuang Li, Meng Zhao, Liqun Liu, Mengge Xue, Zhenyu Hu, Honglin Han, Chengguo Yin |  |
| 351 |  |  [Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts](https://doi.org/10.18653/v1/2024.acl-long.232) |  | 0 | This study investigates the behaviors of Large Language Models (LLMs) when faced with conflicting prompts versus their internal memory. This will not only help to understand LLMs’ decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG).Drawing on... | Jiahao Ying, Yixin Cao, Kai Xiong, Long Cui, Yidong He, Yongbin Liu |  |
| 352 |  |  [CoCA: Fusing Position Embedding with Collinear Constrained Attention in Transformers for Long Context Window Extending](https://doi.org/10.18653/v1/2024.acl-long.233) |  | 0 | Self-attention and position embedding are two crucial modules in transformer-based Large Language Models (LLMs). However, the potential relationship between them is far from well studied, especially for long context window extending. In fact, anomalous behaviors that hinder long context... | Shiyi Zhu, Jing Ye, Wei Jiang, Siqiao Xue, Qi Zhang, Yifan Wu, Jianguo Li |  |
| 353 |  |  [InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification](https://doi.org/10.18653/v1/2024.acl-long.234) |  | 0 | Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs.... | Jan Trienes, Sebastian Joseph, Jörg Schlötterer, Christin Seifert, Kyle Lo, Wei Xu, Byron C. Wallace, Junyi Jessy Li |  |
| 354 |  |  [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.235) |  | 0 | With the advancement of language models (LMs), their exposure to private data is increasingly inevitable, and their deployment (especially for smaller ones) on personal devices, such as PCs and smartphones, has become a prevailing trend. In contexts laden with user information, enabling models to... | Kaiyan Zhang, Jianyu Wang, Ermo Hua, Biqing Qi, Ning Ding, Bowen Zhou |  |
| 355 |  |  [DAPR: A Benchmark on Document-Aware Passage Retrieval](https://doi.org/10.18653/v1/2024.acl-long.236) |  | 0 | The work of neural retrieval so far focuses on ranking short texts and is challenged with long documents. There are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. Wikipedia articles, research papers, etc. We propose and name this task... | Kexin Wang, Nils Reimers, Iryna Gurevych |  |
| 356 |  |  [Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors](https://doi.org/10.18653/v1/2024.acl-long.237) |  | 0 | Multiple-Choice Questions (MCQs) constitute a critical area of research in the study of Large Language Models (LLMs). Previous works have investigated the selection bias problem in MCQs within few-shot scenarios, in which the LLM’s performance may be influenced by the presentation of answer... | Mengge Xue, Zhenyu Hu, Liqun Liu, Kuo Liao, Shuang Li, Honglin Han, Meng Zhao, Chengguo Yin |  |
| 357 |  |  [SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.238) |  | 0 | Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks across specialized domains, where the acquisition of precise and dependable knowledge is crucial. However, existing KG construction methods heavily rely on human intervention to attain qualified KGs, which severely hinders the... | Hanzhu Chen, Xu Shen, Qitan Lv, Jie Wang, Xiaoqi Ni, Jieping Ye |  |
| 358 |  |  [Uncertainty-Guided Modal Rebalance for Hateful Memes Detection](https://doi.org/10.18653/v1/2024.acl-long.239) |  | 0 | Hateful memes detection is a challenging multimodal understanding task that requires comprehensive learning of vision, language, and cross-modal interactions. Previous research has focused on developing effective fusion strategies for integrating hate information from different modalities. However,... | Chuanpeng Yang, Yaxin Liu, Fuqing Zhu, Jizhong Han, Songlin Hu |  |
| 359 |  |  [Missci: Reconstructing Fallacies in Misrepresented Science](https://doi.org/10.18653/v1/2024.acl-long.240) |  | 0 | Health-related misinformation on social networks can lead to poor decision-making and real-world dangers. Such misinformation often misrepresents scientific publications and cites them as “proof” to gain perceived credibility. To effectively counter such claims automatically, a system must explain... | Max Glockner, Yufang Hou, Preslav Nakov, Iryna Gurevych |  |
| 360 |  |  [Uncovering the Full Potential of Visual Grounding Methods in VQA](https://doi.org/10.18653/v1/2024.acl-long.241) |  | 0 | Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model’s reliance on question-relevant visual information. The presence of such relevant information in the visual input is typically assumed in training and testing. This... | Daniel Reich, Tanja Schultz |  |
| 361 |  |  [Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs](https://doi.org/10.18653/v1/2024.acl-long.242) |  | 0 | The integration of large language models (LLMs) and search engines represents a significant evolution in knowledge acquisition methodologies. However, determining the knowledge that an LLM already possesses and the knowledge that requires the help of a search engine remains an unresolved issue.... | Jiejun Tan, Zhicheng Dou, Yutao Zhu, Peidong Guo, Kun Fang, JiRong Wen |  |
| 362 |  |  [Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation](https://doi.org/10.18653/v1/2024.acl-long.243) |  | 0 | Generative AI systems have become ubiquitous for all kinds of modalities, which makes the issue of the evaluation of such models more pressing. One popular approach is preference ratings, where the generated outputs of different systems are shown to evaluators who choose their preferences. In... | Pius von Däniken, Jan Deriu, Don Tuggener, Mark Cieliebak |  |
| 363 |  |  [LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback](https://doi.org/10.18653/v1/2024.acl-long.244) |  | 0 | Ensuring that online discussions are civil and productive is a major challenge for social media platforms. Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review. However, this kind of post-hoc... | Timon Ziegenbein, Gabriella Skitalinskaya, Alireza Bayat Makou, Henning Wachsmuth |  |
| 364 |  |  [Graph Language Models](https://doi.org/10.18653/v1/2024.acl-long.245) |  | 0 | While Language Models (LMs) are the workhorses of NLP, their interplay with structured knowledge graphs (KGs) is still actively researched. Current methods for encoding such graphs typically either (i) linearize them for embedding with LMs – which underutilize structural information, or (ii) use... | Moritz Plenz, Anette Frank |  |
| 365 |  |  [Analyzing Semantic Change through Lexical Replacements](https://doi.org/10.18653/v1/2024.acl-long.246) |  | 0 | Modern language models are capable of contextualizing words based on their surrounding context. However, this capability is often compromised due to semantic change that leads to words being used in new, unexpected contexts not encountered during pre-training. In this paper, we model semantic... | Francesco Periti, Pierluigi Cassotti, Haim Dubossarsky, Nina Tahmasebi |  |
| 366 |  |  [Exploiting Intrinsic Multilateral Logical Rules for Weakly Supervised Natural Language Video Localization](https://doi.org/10.18653/v1/2024.acl-long.247) |  | 0 | Weakly supervised natural language video localization (WS-NLVL) aims to retrieve the moment corresponding to a language query in a video with only video-language pairs utilized during training. Despite great success, existing WS-NLVL methods seldomly consider the complex temporal relations... | Zhe Xu, Kun Wei, Xu Yang, Cheng Deng |  |
| 367 |  |  [Interpretability of Language Models via Task Spaces](https://doi.org/10.18653/v1/2024.acl-long.248) |  | 0 | The usual way to interpret language models (LMs) is to test their performance on different benchmarks and subsequently infer their internal processes.In this paper, we present an alternative approach, concentrating on the _quality_ of LM processing, with a focus on their language abilities.To this... | Lucas Weber, Jaap Jumelet, Elia Bruni, Dieuwke Hupkes |  |
| 368 |  |  [Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types](https://doi.org/10.18653/v1/2024.acl-long.249) |  | 0 | There is abundant evidence of the fact that the way words change their meaning can be classified in different types of change, highlighting the relationship between the old and new meanings (among which generalisation, specialisation and co-hyponymy transfer).In this paper, we present a way of... | Pierluigi Cassotti, Stefano De Pascale, Nina Tahmasebi |  |
| 369 |  |  [Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators](https://doi.org/10.18653/v1/2024.acl-long.250) |  | 0 | Large Language Models (LLMs) tend to be unreliable on fact-based answers.To address this problem, NLP researchers have proposed a range of techniques to estimate LLM’s confidence over facts. However, due to the lack of a systematic comparison, it is not clear how the different methods compare to... | Matéo Mahaut, Laura Aina, Paula Czarnowska, Momchil Hardalov, Thomas Müller, Lluís Màrquez |  |
| 370 |  |  [StepCoder: Improving Code Generation with Reinforcement Learning from Compiler Feedback](https://doi.org/10.18653/v1/2024.acl-long.251) |  | 0 | The advancement of large language models (LLMs) has significantly propelled the field of code generation. Previous work integrated reinforcement learning (RL) with compiler feedback for exploring the output space of LLMs to enhance code generation quality. However, the lengthy code generated by... | Shihan Dou, Yan Liu, Haoxiang Jia, Enyu Zhou, Limao Xiong, Junjie Shan, Caishuang Huang, Xiao Wang, Xiaoran Fan, Zhiheng Xi, Yuhao Zhou, Tao Ji, Rui Zheng, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 371 |  |  [One-Shot Learning as Instruction Data Prospector for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.252) |  | 0 | Contemporary practices in instruction tuning often hinge on enlarging data scaling without a clear strategy for ensuring data quality, inadvertently introducing noise that may compromise model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that... | Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, LingHao Chen, Junhao Liu, Tongliang Liu, Fei Huang, Yongbin Li |  |
| 372 |  |  [Navigating the OverKill in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.253) |  | 0 | Large language models are meticulously aligned to be both helpful and harmless. However, recent research points to a potential overkill which means models may refuse to answer benign queries. In this paper, we investigate the factors for overkill by exploring how models handle and determine the... | Chenyu Shi, Xiao Wang, Qiming Ge, Songyang Gao, Xianjun Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Xun Zhao, Dahua Lin |  |
| 373 |  |  [A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains](https://doi.org/10.18653/v1/2024.acl-long.254) |  | 0 | Prompting language models to provide step-by-step answers (e.g., “Chain-of-Thought”) is the prominent approach for complex reasoning tasks, where more accurate reasoning chains typically improve downstream task performance. Recent literature discusses automatic methods to verify reasoning to... | Alon Jacovi, Yonatan Bitton, Bernd Bohnet, Jonathan Herzig, Or Honovich, Michael Tseng, Michael Collins, Roee Aharoni, Mor Geva |  |
| 374 |  |  [Re3: A Holistic Framework and Dataset for Modeling Collaborative Document Revision](https://doi.org/10.18653/v1/2024.acl-long.255) |  | 0 | Collaborative review and revision of textual documents is the core of knowledge work and a promising target for empirical analysis and NLP assistance. Yet, a holistic framework that would allow modeling complex relationships between document revisions, reviews and author responses is lacking. To... | Qian Ruan, Ilia Kuznetsov, Iryna Gurevych |  |
| 375 |  |  [NextLevelBERT: Masked Language Modeling with Higher-Level Representations for Long Documents](https://doi.org/10.18653/v1/2024.acl-long.256) |  | 0 | While (large) language models have significantly improved over the last years, they still struggle to sensibly process long sequences found, e.g., in books, due to the quadratic scaling of the underlying attention mechanism. To address this, we propose NextLevelBERT, a Masked Language Model... | Tamara Czinczoll, Christoph Hönes, Maximilian Schall, Gerard de Melo |  |
| 376 |  |  [FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.257) |  | 0 | The ability to follow instructions is crucial for Large Language Models (LLMs) to handle various real-world applications. Existing benchmarks primarily focus on evaluating pure response quality, rather than assessing whether the response follows constraints stated in the instruction. To fill this... | Yuxin Jiang, Yufei Wang, Xingshan Zeng, Wanjun Zhong, Liangyou Li, Fei Mi, Lifeng Shang, Xin Jiang, Qun Liu, Wei Wang |  |
| 377 |  |  [Learning to Edit: Aligning LLMs with Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.258) |  | 0 | Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated... | Yuxin Jiang, Yufei Wang, Chuhan Wu, Wanjun Zhong, Xingshan Zeng, Jiahui Gao, Liangyou Li, Xin Jiang, Lifeng Shang, Ruiming Tang, Qun Liu, Wei Wang |  |
| 378 |  |  [DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.259) |  | 0 | Code Large Language Models (Code LLMs) have demonstrated outstanding performance in code-related tasks. Various instruction finetuning approaches have been proposed to boost the code generation performance of pre-trained Code LLMs. In this paper, we introduce a diverse instruction model DolphCoder... | Yejie Wang, Keqing He, Guanting Dong, Pei Wang, Weihao Zeng, Muxi Diao, Weiran Xu, Jingang Wang, Mengdi Zhang, Xunliang Cai |  |
| 379 |  |  [When Only Time Will Tell: Interpreting How Transformers Process Local Ambiguities Through the Lens of Restart-Incrementality](https://doi.org/10.18653/v1/2024.acl-long.260) |  | 0 | Incremental models that process sentences one token at a time will sometimes encounter points where more than one interpretation is possible. Causal models are forced to output one interpretation and continue, whereas models that can revise may edit their previous output as the ambiguity is... | Brielen Madureira, Patrick Kahardipraja, David Schlangen |  |
| 380 |  |  [SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.261) |  | 0 | Spatial reasoning is a crucial component of both biological and artificial intelligence. In this work, we present a comprehensive study of the capability of current state-of-the-art large language models (LLMs) on spatial reasoning. To support our study, we created and contribute a novel Spatial... | Md Imbesat Hassan Rizvi, Xiaodan Zhu, Iryna Gurevych |  |
| 381 |  |  [Planning Like Human: A Dual-process Framework for Dialogue Planning](https://doi.org/10.18653/v1/2024.acl-long.262) |  | 0 | In proactive dialogue, the challenge lies not just in generating responses but in steering conversations toward predetermined goals, a task where Large Language Models (LLMs) typically struggle due to their reactive nature. Traditional approaches to enhance dialogue planning in LLMs, ranging from... | Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Ming Liu, Zerui Chen, Bing Qin |  |
| 382 |  |  [Spectral Filters, Dark Signals, and Attention Sinks](https://doi.org/10.18653/v1/2024.acl-long.263) |  | 0 | Projecting intermediate representations onto the vocabulary is an increasingly popular interpretation tool for transformer-based LLMs, also known as the logit lens (Nostalgebraist). We propose a quantitative extension to this approach and define spectral filters on intermediate representations... | Nicola Cancedda |  |
| 383 |  |  [DiffuCOMET: Contextual Commonsense Knowledge Diffusion](https://doi.org/10.18653/v1/2024.acl-long.264) |  | 0 | Inferring contextually-relevant and diverse commonsense to understand narratives remains challenging for knowledge models. In this work, we develop a series of knowledge models, DiffuCOMET, that leverage diffusion to learn to reconstruct the implicit semantic connections between narrative contexts... | Silin Gao, Mete Ismayilzada, Mengjie Zhao, Hiromi Wakaki, Yuki Mitsufuji, Antoine Bosselut |  |
| 384 |  |  [Systematic Task Exploration with LLMs: A Study in Citation Text Generation](https://doi.org/10.18653/v1/2024.acl-long.265) |  | 0 | Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language generation (NLG) tasks. Yet, this flexibility brings new challenges, as it introduces new degrees of freedom in formulating the task inputs and instructions and in evaluating... | Furkan Sahinuç, Ilia Kuznetsov, Yufang Hou, Iryna Gurevych |  |
| 385 |  |  [Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition](https://doi.org/10.18653/v1/2024.acl-long.266) |  | 0 | Recent work on dialogue-based collaborative plan acquisition (CPA) has suggested that Theory of Mind (ToM) modelling can improve missing knowledge prediction in settings with asymmetric skill-sets and knowledge. Although ToM was claimed to be important for effective collaboration, its real impact... | Matteo Bortoletto, Constantin Ruhdorfer, Adnen Abdessaied, Lei Shi, Andreas Bulling |  |
| 386 |  |  [Temporal Knowledge Question Answering via Abstract Reasoning Induction](https://doi.org/10.18653/v1/2024.acl-long.267) |  | 0 | In this study, we address the challenge of enhancing temporal knowledge reasoning in Large Language Models (LLMs). LLMs often struggle with this task, leading to the generation of inaccurate or misleading responses. This issue mainly arises from their limited ability to handle evolving factual... | Ziyang Chen, Dongfang Li, Xiang Zhao, Baotian Hu, Min Zhang |  |
| 387 |  |  [Who Wrote this Code? Watermarking for Code Generation](https://doi.org/10.18653/v1/2024.acl-long.268) |  | 0 | Since the remarkable generation performance of large language models raised ethical and legal concerns, approaches to detect machine-generated text by embedding watermarks are being developed.However, we discover that the existing works fail to function appropriately in code generation tasks due to... | Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, Gunhee Kim |  |
| 388 |  |  [MapCoder: Multi-Agent Code Generation for Competitive Problem Solving](https://doi.org/10.18653/v1/2024.acl-long.269) |  | 0 | Code synthesis, which requires a deep understanding of complex natural language (NL) problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. Thus, while large... | Md. Ashraful Islam, Mohammed Eunus Ali, Md. Rizwan Parvez |  |
| 389 |  |  [RelayAttention for Efficient Large Language Model Serving with Long System Prompts](https://doi.org/10.18653/v1/2024.acl-long.270) |  | 0 | A practical large language model (LLM) service may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across requests. However, the long system prompt causes throughput/latency bottlenecks as the cost of generating the next... | Lei Zhu, Xinjiang Wang, Wayne Zhang, Rynson W. H. Lau |  |
| 390 |  |  [Boosting Language Models Reasoning with Chain-of-Knowledge Prompting](https://doi.org/10.18653/v1/2024.acl-long.271) |  | 0 | Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like “Let’s think step by step” or multiple in-context exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate... | Jianing Wang, Qiushi Sun, Xiang Li, Ming Gao |  |
| 391 |  |  [Open Grounded Planning: Challenges and Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.272) |  | 0 | The emergence of large language models (LLMs) has increasingly drawn attention to the use of LLMs for human-like planning. Existing work on LLM-based planning either focuses on leveraging the inherent language generation capabilities of LLMs to produce free-style plans, or employs reinforcement... | Shiguang Guo, Ziliang Deng, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun |  |
| 392 |  |  [LLM Knows Body Language, Too: Translating Speech Voices into Human Gestures](https://doi.org/10.18653/v1/2024.acl-long.273) |  | 0 | In response to the escalating demand for digital human representations, progress has been made in the generation of realistic human gestures from given speeches. Despite the remarkable achievements of recent research, the generation process frequently includes unintended, meaningless, or... | Chenghao Xu, Guangtao Lyu, Jiexi Yan, Muli Yang, Cheng Deng |  |
| 393 |  |  [QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction](https://doi.org/10.18653/v1/2024.acl-long.274) |  | 0 | Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which... | Xiang Huang, Sitao Cheng, Shanshan Huang, Jiayu Shen, Yong Xu, Chaoyun Zhang, Yuzhong Qu |  |
| 394 |  |  [PITA: Prompting Task Interaction for Argumentation Mining](https://doi.org/10.18653/v1/2024.acl-long.275) |  | 0 | Argumentation mining (AM) aims to detect the arguments and their inherent relations from argumentative textual compositions. Generally, AM comprises three key challenging subtasks, including argument component type classification (ACTC), argumentative relation identification (ARI), and... | Yang Sun, Muyi Wang, Jianzhu Bao, Bin Liang, Xiaoyan Zhao, Caihua Yang, Min Yang, Ruifeng Xu |  |
| 395 |  |  [Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.276) |  | 0 | Large Language Models (LLMs) show promising results in language generation and instruction following but frequently “hallucinate”, making their outputs less reliable. Despite Uncertainty Quantification’s (UQ) potential solutions, implementing it accurately within LLMs is challenging. Our research... | Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, Kaidi Xu |  |
| 396 |  |  [Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations](https://doi.org/10.18653/v1/2024.acl-long.277) |  | 0 | Vision-and-language (VL) models with separate encoders for each modality (e.g., CLIP) have become the go-to models for zero-shot image classification and image-text retrieval. They are, however, mostly evaluated in English as multilingual benchmarks are limited in availability. We introduce... | Gregor Geigle, Radu Timofte, Goran Glavas |  |
| 397 |  |  [Estimating Agreement by Chance for Sequence Annotation](https://doi.org/10.18653/v1/2024.acl-long.278) |  | 0 | In the field of natural language processing, correction of performance assessment for chance agreement plays a crucial role in evaluating the reliability of annotations. However, there is a notable dearth of research focusing on chance correction for assessing the reliability of sequence annotation... | Diya Li, Carolyn P. Rosé, Ao Yuan, Chunxiao Zhou |  |
| 398 |  |  [Are Emergent Abilities in Large Language Models just In-Context Learning?](https://doi.org/10.18653/v1/2024.acl-long.279) |  | 0 | Large language models, comprising billions of parameters and pre-trained on extensive web-scale corpora, have been claimed to acquire certain capabilities without having been specifically trained on them. These capabilities, referred to as “emergent abilities,” have been a driving force in... | Sheng Lu, Irina Bigoulaeva, Rachneet Sachdeva, Harish Tayyar Madabushi, Iryna Gurevych |  |
| 399 |  |  [WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.280) |  | 0 | Recent work demonstrates that, after instruction tuning, Code Large Language Models (Code LLMs) can obtain impressive capabilities to address a wide range of code-related tasks. However, current instruction tuning methods for Code LLMs mainly focus on the traditional code generation task, resulting... | Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, Yishujie Zhao, Wenxiang Hu, Qiufeng Yin |  |
| 400 |  |  [Eliciting Better Multilingual Structured Reasoning from LLMs through Code](https://doi.org/10.18653/v1/2024.acl-long.281) |  | 0 | The development of large language models (LLM) has shown progress on reasoning, though studies have largely considered either English or simple reasoning tasks. To address this, we introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across... | Bryan Li, Tamer Alkhouli, Daniele Bonadiman, Nikolaos Pappas, Saab Mansour |  |
| 401 |  |  [OLIVE: Object Level In-Context Visual Embeddings](https://doi.org/10.18653/v1/2024.acl-long.282) |  | 0 | Recent generalist vision-language models (VLMs) have demonstrated impressive reasoning capabilities across diverse multimodal tasks. However, these models still struggle with fine-grained object-level understanding and grounding. In terms of modeling, existing VLMs implicitly align text tokens with... | Timothy Ossowski, Junjie Hu |  |
| 402 |  |  [Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness](https://doi.org/10.18653/v1/2024.acl-long.283) |  | 0 | We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training... | Jiuhai Chen, Jonas Mueller |  |
| 403 |  |  [Marathon: A Race Through the Realm of Long Context with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.284) |  | 0 | With the advancement of large language models (LLMs) and the expansion of their context windows, existing long-context benchmarks fall short in effectively evaluating the models’ comprehension and reasoning abilities in extended texts. Moreover, conventional benchmarks relying on F1 metrics often... | Lei Zhang, Yunshui Li, Ziqiang Liu, Jiaxi Yang, Junhao Liu, Longze Chen, Run Luo, Min Yang |  |
| 404 |  |  [Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph](https://doi.org/10.18653/v1/2024.acl-long.285) |  | 0 | Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs). However, it can fall short in specific scenarios where simple customized methods excel. In this paper, we delve into the patent approval prediction task and unveil that simple... | Xiaochen Gao, Feng Yao, Kewen Zhao, Beilei He, Animesh Kumar, Vish Krishnan, Jingbo Shang |  |
| 405 |  |  [PCAD: Towards ASR-Robust Spoken Language Understanding via Prototype Calibration and Asymmetric Decoupling](https://doi.org/10.18653/v1/2024.acl-long.286) |  | 0 | Spoken language understanding (SLU) inevitably suffers from error propagation from automatic speech recognition (ASR) in actual scenarios. Some recent works attempt to alleviate this issue through contrastive learning. However, they (1) sample negative pairs incorrectly in pre-training; (2) only... | Xianwei Zhuang, Xuxin Cheng, Liming Liang, Yuxin Xie, Zhichang Wang, Zhiqi Huang, Yuexian Zou |  |
| 406 |  |  [Rethinking the Multimodal Correlation of Multimodal Sequential Learning via Generalizable Attentional Results Alignment](https://doi.org/10.18653/v1/2024.acl-long.287) |  | 0 | Transformer-based methods have gone mainstream in multimodal sequential learning. The intra and inter modality interactions are captured by the query-key associations of multi-head attention. In this way, the calculated multimodal contexts (attentional results) are expected to be relevant to the... | Tao Jin, Wang Lin, Ye Wang, Linjun Li, Xize Cheng, Zhou Zhao |  |
| 407 |  |  [UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation](https://doi.org/10.18653/v1/2024.acl-long.288) |  | 0 | Large language models (LLMs) produce hallucinated text, compromising their practical utility in professional contexts. To assess the reliability of LLMs, numerous initiatives have developed benchmark evaluations for hallucination phenomena. However, they often employ constrained generation... | Xun Liang, Shichao Song, Simin Niu, Zhiyu Li, Feiyu Xiong, Bo Tang, Yezhaohui Wang, Dawei He, Cheng Peng, Zhonghao Wang, Haiying Deng |  |
| 408 |  |  [PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers](https://doi.org/10.18653/v1/2024.acl-long.289) |  | 0 | Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We... | Weizhe Lin, Jingbiao Mei, Jinghong Chen, Bill Byrne |  |
| 409 |  |  [Triple-Encoders: Representations That Fire Together, Wire Together](https://doi.org/10.18653/v1/2024.acl-long.290) |  | 0 | Search-based dialog models typically re-encode the dialog history at every turn, incurring high cost.Curved Contrastive Learning, a representation learning method that encodes relative distances between utterances into the embedding space via a bi-encoder, has recently shown promising results for... | JustusJonas Erker, Florian Mai, Nils Reimers, Gerasimos Spanakis, Iryna Gurevych |  |
| 410 |  |  [Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.291) |  | 0 | Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in... | Jingbiao Mei, Jinghong Chen, Weizhe Lin, Bill Byrne, Marcus Tomalin |  |
| 411 |  |  [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://doi.org/10.18653/v1/2024.acl-long.292) |  | 0 | Large Language Models (LLMs) exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers... | Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, Weiming Lu |  |
| 412 |  |  [Your Transformer is Secretly Linear](https://doi.org/10.18653/v1/2024.acl-long.293) |  | 0 | This paper reveals a novel linear characteristic exclusive to transformer decoders, including models like GPT, LLaMA, OPT, BLOOM and others. We analyze embedding transformations between sequential layers, uncovering an almost perfect linear relationship (Procrustes similarity score of 0.99).... | Anton Razzhigaev, Matvey Mikhalchuk, Elizaveta Goncharova, Nikolai Gerasimenko, Ivan V. Oseledets, Denis Dimitrov, Andrey Kuznetsov |  |
| 413 |  |  [Noise Correction on Subjective Datasets](https://doi.org/10.18653/v1/2024.acl-long.294) |  | 0 | Incorporating every annotator’s perspective is crucial for unbiased data modeling. Annotator fatigue and changing opinions over time can distort dataset annotations. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction... | Uthman Jinadu, Yi Ding |  |
| 414 |  |  [Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers](https://doi.org/10.18653/v1/2024.acl-long.295) |  | 0 | Recommender systems are widely used to suggest engaging content, and Large Language Models (LLMs) have given rise to generative recommenders. Such systems can directly generate items, including for open-set tasks like question suggestion. While the world knowledge of LLMs enables good... | Lütfi Kerem Senel, Besnik Fetahu, Davis Yoshida, Zhiyu Chen, Giuseppe Castellucci, Nikhita Vedula, Jason Ingyu Choi, Shervin Malmasi |  |
| 415 |  |  [Instruction-tuned Language Models are Better Knowledge Learners](https://doi.org/10.18653/v1/2024.acl-long.296) |  | 0 | In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by... | Zhengbao Jiang, Zhiqing Sun, Weijia Shi, Pedro Rodríguez, Chunting Zhou, Graham Neubig, Xi Victoria Lin, Wentau Yih, Srini Iyer |  |
| 416 |  |  [What Do Language Models Hear? Probing for Auditory Representations in Language Models](https://doi.org/10.18653/v1/2024.acl-long.297) |  | 0 | This work explores whether language models encode meaningfully grounded representations of sounds of objects. We learn a linear probe that retrieves the correct text representation of an object given a snippet of audio related to that object, where the sound representation is given by a pretrained... | Jerry Ngo, Yoon Kim |  |
| 417 |  |  [Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs](https://doi.org/10.18653/v1/2024.acl-long.298) |  | 0 | With the advent of large language models (LLM), the line between human-crafted and machine-generated texts has become increasingly blurred. This paper delves into the inquiry of identifying discernible and unique linguistic properties in texts that were written by humans, particularly uncovering... | Zae Myung Kim, Kwang Hee Lee, Preston Zhu, Vipul Raheja, Dongyeop Kang |  |
| 418 |  |  [Jailbreak Open-Sourced Large Language Models via Enforced Decoding](https://doi.org/10.18653/v1/2024.acl-long.299) |  | 0 | Large Language Models (LLMs) have achieved unprecedented performance in Natural Language Generation (NLG) tasks. However, many existing studies have shown that they could be misused to generate undesired content. In response, before releasing LLMs for public access, model developers usually align... | Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, Bochuan Cao, Lu Lin, Jinyuan Jia, Jinghui Chen, Dinghao Wu |  |
| 419 |  |  [NICE: To Optimize In-Context Examples or Not?](https://doi.org/10.18653/v1/2024.acl-long.300) |  | 0 | Recent work shows that in-context learning and optimization of in-context examples (ICE) can significantly improve the accuracy of large language models (LLMs) on a wide range of tasks, leading to an apparent consensus that ICE optimization is crucial for better performance. However, most of these... | Pragya Srivastava, Satvik Golechha, Amit Deshpande, Amit Sharma |  |
| 420 |  |  [CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation](https://doi.org/10.18653/v1/2024.acl-long.301) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most... | Weixiang Yan, Haitian Liu, Yunkun Wang, Yunzhe Li, Qian Chen, Wen Wang, Tingyu Lin, Weishan Zhao, Li Zhu, Hari Sundaram, Shuiguang Deng |  |
| 421 |  |  [Digital Socrates: Evaluating LLMs through Explanation Critiques](https://doi.org/10.18653/v1/2024.acl-long.302) |  | 0 | While LLMs can provide reasoned explanations along with their answers, the nature and quality of those explanations are still poorly understood. In response, our goal is to define a detailed way of characterizing the explanation capabilities of modern models and to create a nuanced, interpretable... | Yuling Gu, Oyvind Tafjord, Peter Clark |  |
| 422 |  |  [SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://doi.org/10.18653/v1/2024.acl-long.303) |  | 0 | As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, which aim to provoke unintended and unsafe... | Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill Yuchen Lin, Radha Poovendran |  |
| 423 |  |  [Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?](https://doi.org/10.18653/v1/2024.acl-long.304) |  | 0 | Large language models (LLMs) are typically prompted to follow a single instruction per inference call. In this work, we analyze whether LLMs also hold the capability to handle multiple instructions simultaneously, denoted as Multi-Task Inference. For this purpose, we introduce the MTI Bench... | Guijin Son, Sangwon Baek, Sangdae Nam, Ilgyun Jeong, Seungone Kim |  |
| 424 |  |  [Experiential Co-Learning of Software-Developing Agents](https://doi.org/10.18653/v1/2024.acl-long.305) |  | 0 | Recent advancements in large language models (LLMs) have brought significant changes to various domains, especially through LLM-driven autonomous agents. A representative scenario is in software development, where LLM agents demonstrate efficient collaboration, task division, and assurance of... | Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Zihao Xie, Yifei Wang, Weize Chen, Cheng Yang, Xin Cong, Xiaoyin Che, Zhiyuan Liu, Maosong Sun |  |
| 425 |  |  [Learning Geometry-Aware Representations for New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.306) |  | 0 | New intent discovery (NID) is an important problem for deploying practical dialogue systems, which trains intent classifiers on a semi-supervised corpus where unlabeled user utterances contain both known and novel intents. Most existing NID algorithms place hope on the sample similarity to cluster... | Kai Tang, Junbo Zhao, Xiao Ding, Runze Wu, Lei Feng, Gang Chen, Haobo Wang |  |
| 426 |  |  [Speaker Verification in Agent-generated Conversations](https://doi.org/10.18653/v1/2024.acl-long.307) |  | 0 | The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks. However, the... | Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, EePeng Lim |  |
| 427 |  |  [Benchmarking Data Science Agents](https://doi.org/10.18653/v1/2024.acl-long.308) |  | 0 | In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools of data science, presenting significant challenges even for specialists. Large Language Models (LLMs) have emerged as promising aids as data science agents, assisting humans in data... | Yuge Zhang, Qiyang Jiang, Xingyu Han, Nan Chen, Yuqing Yang, Kan Ren |  |
| 428 |  |  [Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.309) |  | 0 | Large language models (LLMs) demonstrate remarkable multilingual capabilities without being pre-trained on specially curated multilingual parallel corpora.It remains a challenging problem to explain the underlying mechanisms by which LLMs process multilingual texts.In this paper, we delve into the... | Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, JiRong Wen |  |
| 429 |  |  [Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.310) |  | 0 | Recent advancements in Large Language Models (LLMs) have showcased their remarkable capabilities in text understanding and generation. However, even stronger LLMs are susceptible to acquiring erroneous or obsolete information from the training corpus. Direct secondary fine-tuning with data... | Shiwen Ni, Dingwei Chen, Chengming Li, Xiping Hu, Ruifeng Xu, Min Yang |  |
| 430 |  |  [A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques](https://doi.org/10.18653/v1/2024.acl-long.311) |  | 0 | Large language models are first pre-trained on trillions of tokens and then instruction-tuned or aligned to specific preferences. While pre-training remains out of reach for most researchers due to the compute required, fine-tuning has become affordable thanks to parameter-efficient methods such as... | Megh Thakkar, Quentin Fournier, Matthew Riemer, PinYu Chen, Amal Zouaq, Payel Das, Sarath Chandar |  |
| 431 |  |  [Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation](https://doi.org/10.18653/v1/2024.acl-long.312) |  | 0 | Zero-shot dialogue state tracking (DST) seeks to enable dialogue systems to transition to unfamiliar domains without manual annotation or extensive retraining. Prior research has approached this objective by embedding prompts into language models (LMs). Common methodologies include integrating... | Xiang Luo, Zhiwen Tang, Jin Wang, Xuejie Zhang |  |
| 432 |  |  [PRP-Graph: Pairwise Ranking Prompting to LLMs with Graph Aggregation for Effective Text Re-ranking](https://doi.org/10.18653/v1/2024.acl-long.313) |  | 0 | Pairwise Ranking Prompting (PRP) demonstrates impressive effectiveness in zero-shot document re-ranking tasks with large language models (LLMs). However, in the existing methods, PRP only outputs the same label for the comparison results of different confidence intervals without considering the... | Jian Luo, Xuanang Chen, Ben He, Le Sun |  |
| 433 |  |  [RepCodec: A Speech Representation Codec for Speech Tokenization](https://doi.org/10.18653/v1/2024.acl-long.314) |  | 0 | With recent rapid growth of large language models (LLMs), discrete speech tokenization has played an important role for injecting speech into LLMs. However, this discretization gives rise to a loss of information, consequently impairing overall performance. To improve the performance of these... | Zhichao Huang, Chutong Meng, Tom Ko |  |
| 434 |  |  [GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick](https://doi.org/10.18653/v1/2024.acl-long.315) |  | 0 | Large language models (LLMs) excellently generate human-like text, but also raise concerns about misuse in fake news and academic dishonesty. Decoding-based watermark, particularly the watermark based on the GumbelMax trick (GM watermark), is a standout solution for safeguarding machine-generated... | Jiayi Fu, Xuandong Zhao, Ruihan Yang, Yuansen Zhang, Jiangjie Chen, Yanghua Xiao |  |
| 435 |  |  [Event-Radar: Event-driven Multi-View Learning for Multimodal Fake News Detection](https://doi.org/10.18653/v1/2024.acl-long.316) |  | 0 | The swift detection of multimedia fake news has emerged as a crucial task in combating malicious propaganda and safeguarding the security of the online environment. While existing methods have achieved commendable results in modeling entity-level inconsistency, addressing event-level inconsistency... | Zihan Ma, Minnan Luo, Hao Guo, Zhi Zeng, Yiran Hao, Xiang Zhao |  |
| 436 |  |  [Fine-Grained Modeling of Narrative Context: A Coherence Perspective via Retrospective Questions](https://doi.org/10.18653/v1/2024.acl-long.317) |  | 0 | This work introduces an original and practical paradigm for narrative comprehension, stemming from the characteristics that individual passages within narratives tend to be more cohesively related than isolated.Complementary to the common end-to-end paradigm, we propose a fine-grained modeling of... | Liyan Xu, Jiangnan Li, Mo Yu, Jie Zhou |  |
| 437 |  |  [Stealthy Attack on Large Language Model based Recommendation](https://doi.org/10.18653/v1/2024.acl-long.318) |  | 0 | Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of... | Jinghao Zhang, Yuting Liu, Qiang Liu, Shu Wu, Guibing Guo, Liang Wang |  |
| 438 |  |  [Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.319) |  | 0 | The evaluation of summary quality encompasses diverse dimensions such as consistency, coherence, relevance, and fluency. However, existing summarization methods often target a specific dimension, facing challenges in generating well-balanced summaries across multiple dimensions. In this paper, we... | Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Lee, Jungseul Ok |  |
| 439 |  |  [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://doi.org/10.18653/v1/2024.acl-long.320) |  | 0 | In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models insuch domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or... | Changyu Chen, Xiting Wang, TingEn Lin, Ang Lv, Yuchuan Wu, Xin Gao, JiRong Wen, Rui Yan, Yongbin Li |  |
| 440 |  |  [SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.321) |  | 0 | Elucidating the reasoning process with structured explanations from question to answer is crucial, as it significantly enhances the interpretability, traceability, and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricately... | Guoxin Chen, Kexin Tang, Chao Yang, Fuying Ye, Yu Qiao, Yiming Qian |  |
| 441 |  |  [Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning](https://doi.org/10.18653/v1/2024.acl-long.322) |  | 0 | Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, as datasets in such environments often contain noisy labels that adversely affect performance, PEFT methods are inevitably exposed to noisy labels. Despite... | Yeachan Kim, Junho Kim, SangKeun Lee |  |
| 442 |  |  [SparseFlow: Accelerating Transformers by Sparsifying Information Flows](https://doi.org/10.18653/v1/2024.acl-long.323) |  | 0 | Transformers have become the de-facto standard for natural language processing. However, dense information flows within transformers pose significant challenges for real-time and resource-constrained devices, as computational complexity grows quadratically with sequence length. To counteract such... | Yeachan Kim, SangKeun Lee |  |
| 443 |  |  [ProtT3: Protein-to-Text Generation for Text-based Protein Understanding](https://doi.org/10.18653/v1/2024.acl-long.324) |  | 0 | Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models... | Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, TatSeng Chua |  |
| 444 |  |  [KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.325) |  | 0 | Automatic evaluation methods for large language models (LLMs) are hindered by data contamination, leading to inflated assessments of their effectiveness. Existing strategies, which aim to detect contaminated texts, focus on quantifying contamination status instead of accurately gauging model... | Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Wei Ye, Jindong Wang, Xing Xie, Yue Zhang, Shikun Zhang |  |
| 445 |  |  [EmoBench: Evaluating the Emotional Intelligence of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.326) |  | 0 | Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on... | Sahand Sabour, Siyang Liu, Zheyuan Zhang, June M. Liu, Jinfeng Zhou, Alvionna S. Sunaryo, Tatia M. C. Lee, Rada Mihalcea, Minlie Huang |  |
| 446 |  |  [Are AI-Generated Text Detectors Robust to Adversarial Perturbations?](https://doi.org/10.18653/v1/2024.acl-long.327) |  | 0 | The widespread use of large language models (LLMs) has sparked concerns about the potential misuse of AI-generated text, as these models can produce content that closely resembles human-generated text. Current detectors for AI-generated text (AIGT) lack robustness against adversarial perturbations,... | Guanhua Huang, Yuchen Zhang, Zhe Li, Yongjian You, Mingze Wang, Zhouwang Yang |  |
| 447 |  |  [FinTextQA: A Dataset for Long-form Financial Question Answering](https://doi.org/10.18653/v1/2024.acl-long.328) |  | 0 | Accurate evaluation of financial question answering (QA) systems necessitates a comprehensive dataset encompassing diverse question types and contexts. However, current financial QA datasets lack scope diversity and question complexity. This work introduces FinTextQA, a novel dataset for long-form... | Jian Chen, Peilin Zhou, Yining Hua, Loh Xin, Kehui Chen, Ziyuan Li, Bing Zhu, Junwei Liang |  |
| 448 |  |  [On Measuring Faithfulness or Self-consistency of Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.329) |  | 0 | Large language models (LLMs) can explain their predictions through post-hoc or Chain-of-Thought (CoT) explanations. But an LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of... | Letitia Parcalabescu, Anette Frank |  |
| 449 |  |  [Learning or Self-aligning? Rethinking Instruction Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.330) |  | 0 | Instruction Fine-tuning (IFT) is a crucial phase in building large language models (LLMs). Previous works mainly focus on the IFT’s role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains... | Mengjie Ren, Boxi Cao, Hongyu Lin, Cao Liu, Xianpei Han, Ke Zeng, Guanglu Wan, Xunliang Cai, Le Sun |  |
| 450 |  |  [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?](https://doi.org/10.18653/v1/2024.acl-long.331) |  | 0 | Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our... | Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song |  |
| 451 |  |  [Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct LLM in Knowledge-based VQA](https://doi.org/10.18653/v1/2024.acl-long.332) |  | 0 | LLM has achieved impressive performance on multi-modal tasks, which have received ever-increasing research attention. Recent research focuses on improving prediction performance and reliability (e.g., addressing the hallucination problem). They often prepend relevant external knowledge to the input... | Qunbo Wang, Ruyi Ji, Tianhao Peng, Wenjun Wu, Zechao Li, Jing Liu |  |
| 452 |  |  [TasTe: Teaching Large Language Models to Translate through Self-Reflection](https://doi.org/10.18653/v1/2024.acl-long.333) |  | 0 | Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation. However, the existing approaches fail to yield... | Yutong Wang, Jiali Zeng, Xuebo Liu, Fandong Meng, Jie Zhou, Min Zhang |  |
| 453 |  |  [Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.334) |  | 0 | A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with fewer active parameters, but it is still hard to deploy them due to their immense parameter sizes.... | Xudong Lu, Qi Liu, Yuhui Xu, Aojun Zhou, Siyuan Huang, Bo Zhang, Junchi Yan, Hongsheng Li |  |
| 454 |  |  [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://doi.org/10.18653/v1/2024.acl-long.335) |  | 0 | Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents UNIMO-G, a simple... | Wei Li, Xue Xu, Jiachen Liu, Xinyan Xiao |  |
| 455 |  |  [The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities](https://doi.org/10.18653/v1/2024.acl-long.336) |  | 0 | Fine-tuning large language models (LLMs) for machine translation has shown improvements in overall translation quality. However, it is unclear what is the impact of fine-tuning on desirable LLM behaviors that are not present in neural machine translation models, such as steerability, inherent... | David Stap, Eva Hasler, Bill Byrne, Christof Monz, Ke Tran |  |
| 456 |  |  [Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?](https://doi.org/10.18653/v1/2024.acl-long.337) |  | 0 | While auxiliary information has become a key to enhancing Large Language Models (LLMs), relatively little is known about how LLMs merge these contexts, specifically contexts generated by LLMs and those retrieved from external sources.To investigate this, we formulate a systematic framework to... | Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng |  |
| 457 |  |  [Unveiling Linguistic Regions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.338) |  | 0 | Large Language Models (LLMs) have demonstrated considerable cross-lingual alignment and generalization ability. Current research primarily focuses on improving LLMs’ cross-lingual generalization capabilities. However, there is still a lack of research on the intrinsic mechanisms of how LLMs achieve... | Zhihao Zhang, Jun Zhao, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 458 |  |  [Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment](https://doi.org/10.18653/v1/2024.acl-long.339) |  | 0 | A song is a combination of singing voice and accompaniment. However, existing works focus on singing voice synthesis and music generation independently. Little attention was paid to exploring song synthesis. In this work, we propose a novel task called Text-to-Song synthesis which incorporates both... | Zhiqing Hong, Rongjie Huang, Xize Cheng, Yongqi Wang, Ruiqi Li, Fuming You, Zhou Zhao, Zhimeng Zhang |  |
| 459 |  |  [FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection](https://doi.org/10.18653/v1/2024.acl-long.340) |  | 0 | Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models. State-of-the-art models typically incorporate the FiD framework, which is composed by a neural retriever alongside an... | Yufei Huang, Xu Han, Maosong Sun |  |
| 460 |  |  [Discursive Socratic Questioning: Evaluating the Faithfulness of Language Models' Understanding of Discourse Relations](https://doi.org/10.18653/v1/2024.acl-long.341) |  | 0 | While large language models have significantly enhanced the effectiveness of discourse relation classifications, it remains unclear whether their comprehension is faithful and reliable. We provide DiSQ, a new method for evaluating the faithfulness of understanding discourse based on question... | Yisong Miao, Hongfu Liu, Wenqiang Lei, Nancy F. Chen, MinYen Kan |  |
| 461 |  |  [An Open Multilingual System for Scoring Readability of Wikipedia](https://doi.org/10.18653/v1/2024.acl-long.342) |  | 0 | With over 60M articles, Wikipedia has become the largest platform for open and freely accessible knowledge. While it has more than 15B monthly visits, its content is believed to be inaccessible to many readers due to the lack of readability of its text. However, previous investigations of the... | Mykola Trokhymovych, Indira Sen, Martin Gerlach |  |
| 462 |  |  [Unlearning Traces the Influential Training Data of Language Models](https://doi.org/10.18653/v1/2024.acl-long.343) |  | 0 | Identifying the training datasets that influence a language model’s outputs is essential for minimizing the generation of harmful content and enhancing its performance. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to... | Masaru Isonuma, Ivan Titov |  |
| 463 |  |  [Exploring Alignment in Shared Cross-lingual Spaces](https://doi.org/10.18653/v1/2024.acl-long.344) |  | 0 | Despite their remarkable ability to capture linguistic nuances across diverse languages, questions persist regarding the degree of alignment between languages in multilingual embeddings. Drawing inspiration from research on high-dimensional representations in neural language models, we employ... | Basel Mousi, Nadir Durrani, Fahim Dalvi, Majd Hawasly, Ahmed Abdelali |  |
| 464 |  |  [Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.345) |  | 0 | This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in... | Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jentse Huang, Zhaopeng Tu, Michael R. Lyu |  |
| 465 |  |  [Self-Evolving GPT: A Lifelong Autonomous Experiential Learner](https://doi.org/10.18653/v1/2024.acl-long.346) |  | 0 | To improve the performance of large language models (LLMs), researchers have explored providing LLMs with textual task-solving experience via prompts. However, they rely on manual efforts to acquire and apply such experience for each task, which is not feasible for the growing demand for LLMs and... | Jinglong Gao, Xiao Ding, Yiming Cui, Jianbai Zhao, Hepeng Wang, Ting Liu, Bing Qin |  |
| 466 |  |  [WRP: Weight Recover Prune for Structured Sparsity](https://doi.org/10.18653/v1/2024.acl-long.347) |  | 0 | As the scale of Large Language Models (LLMs) increases, it is necessary to compress the models to reduce the substantial demand on computational resources. Network pruning significantly reduces the model size by converting the weight matrix from dense to sparse data format. Current methodologies... | Zhendong Tan, Xingjun Zhang, Zheng Wei |  |
| 467 |  |  [Error-preserving Automatic Speech Recognition of Young English Learners' Language](https://doi.org/10.18653/v1/2024.acl-long.348) |  | 0 | One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. The recent advances in speech technology and natural language processing allow the creation of novel... | Janick Michot, Manuela Hürlimann, Jan Deriu, Luzia Sauer, Katsiaryna Mlynchyk, Mark Cieliebak |  |
| 468 |  |  [DiFiNet: Boundary-Aware Semantic Differentiation and Filtration Network for Nested Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.349) |  | 0 | Nested Named Entity Recognition (Nested NER) entails identifying and classifying entity spans within the text, including the detection of named entities that are embedded within external entities. Prior approaches primarily employ span-based techniques, utilizing the power of exhaustive searches to... | Yuxiang Cai, Qiao Liu, Yanglei Gan, Run Lin, Changlin Li, Xueyi Liu, Da Luo, JiayeYang JiayeYang |  |
| 469 |  |  [Legal Case Retrieval: A Survey of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.350) |  | 0 | Recent years have seen increasing attention on Legal Case Retrieval (LCR), a key task in the area of Legal AI that concerns the retrieval of cases from a large legal database of historical cases that are similar to a given query. This paper presents a survey of the major milestones made in LCR... | Yi Feng, Chuanyi Li, Vincent Ng |  |
| 470 |  |  [Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.351) |  | 0 | Compositional generalization, representing the model’s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive... | Tianqi Zhong, Zhaoyi Li, Quan Wang, Linqi Song, Ying Wei, Defu Lian, Zhendong Mao |  |
| 471 |  |  [LLaMA Pro: Progressive LLaMA with Block Expansion](https://doi.org/10.18653/v1/2024.acl-long.352) |  | 0 | Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLMs), e.g., from LLaMA to CodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with an expansion of Transformer blocks. We tune the expanded blocks using... | Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, Ye Feng, Ying Shan, Ping Luo |  |
| 472 |  |  [Generating Contrastive Narratives Using the Brownian Bridge Process for Narrative Coherence Learning](https://doi.org/10.18653/v1/2024.acl-long.353) |  | 0 | A major challenge for narrative reasoning is to learn narrative coherence. Existing works mainly follow the contrastive learning paradigm. However, the negative samples in their methods can be easily distinguished, which makes their methods unsatisfactory. In this work, we devise two strategies for... | Feiteng Mu, Wenjie Li |  |
| 473 |  |  [A Causal Approach for Counterfactual Reasoning in Narratives](https://doi.org/10.18653/v1/2024.acl-long.354) |  | 0 | Counterfactual reasoning in narratives requires predicting how alternative conditions, contrary to what actually happened, might have resulted in different outcomes.One major challenge is to maintain the causality between the counterfactual condition and the generated counterfactual outcome. In... | Feiteng Mu, Wenjie Li |  |
| 474 |  |  [SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation](https://doi.org/10.18653/v1/2024.acl-long.355) |  | 0 | Strong inductive biases enable learning from little data and help generalization outside the training distribution. Popular neural architectures such as Transformers lack strong structural inductive biases for seq2seq NLP tasks on their own. Consequently, they struggle with systematic... | Matthias Lindemann, Alexander Koller, Ivan Titov |  |
| 475 |  |  [The Hidden Space of Transformer Language Adapters](https://doi.org/10.18653/v1/2024.acl-long.356) |  | 0 | We analyze the operation of transformer language adapters, which are small modules trained on top of a frozen language model to adapt its predictions to new target languages. We show that adapted predictions mostly evolve in the source language the model was trained on, while the target language... | Jesujoba Alabi, Marius Mosbach, Matan Eyal, Dietrich Klakow, Mor Geva |  |
| 476 |  |  [A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts](https://doi.org/10.18653/v1/2024.acl-long.357) |  | 0 | In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research... | Nafis Irtiza Tripto, Saranya Venkatraman, Dominik Macko, Róbert Móro, Ivan Srba, Adaku Uchendu, Thai Le, Dongwon Lee |  |
| 477 |  |  [Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations](https://doi.org/10.18653/v1/2024.acl-long.358) |  | 0 | In spoken dialogue, even if two current turns are the same sentence, their responses might still differ when they are spoken in different styles. The spoken styles, containing paralinguistic and prosodic information, mark the most significant difference between text and speech modality. When using... | GuanTing Lin, ChengHan Chiang, Hungyi Lee |  |
| 478 |  |  [RetinaQA: A Robust Knowledge Base Question Answering Model for both Answerable and Unanswerable Questions](https://doi.org/10.18653/v1/2024.acl-long.359) |  | 0 | An essential requirement for a real-world Knowledge Base Question Answering (KBQA) system is the ability to detect the answerability of questions when generating logical forms. However, state-of-the-art KBQA models assume all questions to be answerable. Recent research has found that such models,... | Prayushi Faldu, Indrajit Bhattacharya, Mausam |  |
| 479 |  |  [GroundingGPT: Language Enhanced Multi-modal Grounding Model](https://doi.org/10.18653/v1/2024.acl-long.360) |  | 0 | Multi-modal large language models (MLLMs) have demonstrated remarkable performance across various tasks. However, these models often prioritize capturing global information and overlook the importance of perceiving local information. This limitation hinders their ability to effectively understand... | Zhaowei Li, Qi Xu, Dong Zhang, Hang Song, Yiqing Cai, Qi Qi, Ran Zhou, Junting Pan, Zefeng Li, Vu Tu, Zhida Huang, Tao Wang |  |
| 480 |  |  [Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches](https://doi.org/10.18653/v1/2024.acl-long.361) |  | 0 | Automated Fact-Checking (AFC) is the automated verification of claim accuracy. AFC is crucial in discerning truth from misinformation, especially given the huge amounts of content are generated online daily. Current research focuses on predicting claim veracity through metadata analysis and... | Islam Eldifrawi, Shengrui Wang, Amine Trabelsi |  |
| 481 |  |  [Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages](https://doi.org/10.18653/v1/2024.acl-long.362) |  | 0 | Multilingual neural machine translation systems learn to map sentences of different languages into a common representation space. Intuitively, with a growing number of seen languages the encoder sentence representation grows more flexible and easily adaptable to new languages. In this work, we test... | Carlos Mullov, NgocQuan Pham, Alexander Waibel |  |
| 482 |  |  [SwapMoE: Serving Off-the-shelf MoE-based Large Language Models with Tunable Memory Budget](https://doi.org/10.18653/v1/2024.acl-long.363) |  | 0 | Mixture of experts (MoE) is a popular technique to improve capacity of Large Language Models (LLMs) with conditionally-activated parallel experts. However, serving MoE models on memory-constrained devices is challenging due to the large parameter size. Typical solutions such as memory swapping or... | Rui Kong, Yuanchun Li, Qingtian Feng, Weijun Wang, Xiaozhou Ye, Ye Ouyang, Linghe Kong, Yunxin Liu |  |
| 483 |  |  [PixT3: Pixel-based Table-To-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.364) |  | 0 | Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. A common feature across existing methods... | Iñigo Alonso, Eneko Agirre, Mirella Lapata |  |
| 484 |  |  [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://doi.org/10.18653/v1/2024.acl-long.365) |  | 0 | Factual questions typically can be answered correctly at different levels of granularity. For example, both “August 4, 1961” and “1961” are correct answers to the question “When was Barack Obama born?”. Standard question answering (QA) evaluation protocols, however, do not explicitly take this into... | Gal Yona, Roee Aharoni, Mor Geva |  |
| 485 |  |  [TAMS: Translation-Assisted Morphological Segmentation](https://doi.org/10.18653/v1/2024.acl-long.366) |  | 0 | Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes.This is a core task in endangered language documentation, and NLP systems have the potential to dramatically speed up this process. In typical language... | Enora Rice, Ali Marashian, Luke Gessler, Alexis Palmer, Katharina von der Wense |  |
| 486 |  |  [XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval](https://doi.org/10.18653/v1/2024.acl-long.367) |  | 0 | Recently, pre-trained large language models (LLMs) have shown impressive abilities in generating codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been... | Mohammad Abdullah Matin Khan, M. Saiful Bari, Xuan Do Long, Weishi Wang, Md. Rizwan Parvez, Shafiq Joty |  |
| 487 |  |  [ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.368) |  | 0 | Large Language Models (LLMs) have succeeded remarkably in understanding long-form contents. However, exploring their capability for generating long-form contents, such as reports and articles, has been relatively unexplored and inadequately assessed by existing benchmarks. The prevalent evaluation... | Haochen Tan, Zhijiang Guo, Zhan Shi, Lu Xu, Zhili Liu, Yunlong Feng, Xiaoguang Li, Yasheng Wang, Lifeng Shang, Qun Liu, Linqi Song |  |
| 488 |  |  [A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia](https://doi.org/10.18653/v1/2024.acl-long.369) |  | 0 | Large language models (LLMs) have an impressive ability to draw on novel information supplied in their context. Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters, which... | Giovanni Monea, Maxime Peyrard, Martin Josifoski, Vishrav Chaudhary, Jason Eisner, Emre Kiciman, Hamid Palangi, Barun Patra, Robert West |  |
| 489 |  |  [Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA](https://doi.org/10.18653/v1/2024.acl-long.370) |  | 0 | Multipanel images, commonly seen as web screenshots, posters, etc., pervade our daily lives. These images, characterized by their composition of multiple subfigures in distinct layouts, effectively convey information to people. Toward building advanced multimodal AI applications, such as agents... | Yue Fan, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, ChingChen Kuo, Yang Zhao, Xinze Guan, Xin Wang |  |
| 490 |  |  [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.371) |  | 0 | The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in... | Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Yong Dai, Hongming Zhang, Zhenzhong Lan, Dong Yu |  |
| 491 |  |  [Translation-based Lexicalization Generation and Lexical Gap Detection: Application to Kinship Terms](https://doi.org/10.18653/v1/2024.acl-long.372) |  | 0 | Constructing lexicons with explicitly identified lexical gaps is a vital part of building multilingual lexical resources. Prior work has leveraged bilingual dictionaries and linguistic typologies for semi-automatic identification of lexical gaps. Instead, we propose a generally-applicable... | Senyu Li, Bradley Hauer, Ning Shi, Grzegorz Kondrak |  |
| 492 |  |  [Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations](https://doi.org/10.18653/v1/2024.acl-long.373) |  | 0 | We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to... | Ritam Dutt, Zhen Wu, Jiaxin Shi, Divyanshu Sheth, Prakhar Gupta, Carolyn P. Rosé |  |
| 493 |  |  [Robust Frame-Semantic Models with Lexical Unit Trees and Negative Samples](https://doi.org/10.18653/v1/2024.acl-long.374) |  | 0 | We present novel advancements in frame-semantic parsing, specifically focusing on target identification and frame identification. Our target identification model employs a novel prefix tree modification to enable robust support for multi-word lexical units, resulting in a coverage of 99.4% of the... | Jacob Daniel Devasier, Yogesh Gurjar, Chengkai Li |  |
| 494 |  |  [Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://doi.org/10.18653/v1/2024.acl-long.375) |  | 0 | Advancements in logical reasoning, utilizing LLMs to convert natural language into logical symbolism, combined with the use of external theorem provers, have repositioned the symbolic approach as a central point of interest. The main challenge within this paradigm lies in the LLMs’ capability to... | Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, Faramarz Fekri |  |
| 495 |  |  [Lightweight reranking for language model generations](https://doi.org/10.18653/v1/2024.acl-long.376) |  | 0 | Large Language Models (LLMs) can exhibit considerable variation in the quality of their sampled outputs. Reranking and selecting the best generation from the sampled set is a popular way of obtaining strong gains in generation quality. In this paper, we present a novel approach for reranking LLM... | Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang |  |
| 496 |  |  [ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews](https://doi.org/10.18653/v1/2024.acl-long.377) |  | 0 | We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a dataset of review comments and their corresponding paper edits. The data is drawn from real reviewer-author interactions from computer science, and we provide labels linking each reviewer... | Mike D'Arcy, Alexis Ross, Erin Bransom, Bailey Kuehl, Jonathan Bragg, Tom Hope, Doug Downey |  |
| 497 |  |  [The Unreasonable Effectiveness of Easy Training Data for Hard Tasks](https://doi.org/10.18653/v1/2024.acl-long.378) |  | 0 | How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present... | Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe |  |
| 498 |  |  [PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.379) |  | 0 | Instruction tuning has remarkably advanced large language models (LLMs) in understanding and responding to diverse human instructions. Despite the success in high-resource languages, its application in lower-resource ones faces challenges due to the imbalanced foundational abilities of LLMs across... | Zhihan Zhang, DongHo Lee, Yuwei Fang, Wenhao Yu, Mengzhao Jia, Meng Jiang, Francesco Barbieri |  |
| 499 |  |  [MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.380) |  | 0 | We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error propagation due to the autoregressive nature and... | Inderjeet Nair, Lu Wang |  |
| 500 |  |  [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs](https://doi.org/10.18653/v1/2024.acl-long.381) |  | 0 | Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning... | Justin ChihYao Chen, Swarnadeep Saha, Mohit Bansal |  |
| 501 |  |  [Mirror: Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning](https://doi.org/10.18653/v1/2024.acl-long.382) |  | 0 | While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs... | Hanqi Yan, Qinglin Zhu, Xinyu Wang, Lin Gui, Yulan He |  |
| 502 |  |  [Where Do People Tell Stories Online? Story Detection Across Online Communities](https://doi.org/10.18653/v1/2024.acl-long.383) |  | 0 | Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit... | Maria Antoniak, Joel Mire, Maarten Sap, Elliott Ash, Andrew Piper |  |
| 503 |  |  [Large Language Models Are No Longer Shallow Parsers](https://doi.org/10.18653/v1/2024.acl-long.384) |  | 0 | The development of large language models (LLMs) brings significant changes to the field of natural language processing (NLP), enabling remarkable performance in various high-level tasks, such as machine translation, question-answering, dialogue generation, etc., under end-to-end settings without... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 504 |  |  [Dialogue Summarization with Mixture of Experts based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.385) |  | 0 | Dialogue summarization is an important task that requires to generate highlights for a conversation from different aspects (e.g., content of various speakers). While several studies successfully employ large language models (LLMs) and achieve satisfying results, they are limited by using one model... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 505 |  |  [ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences](https://doi.org/10.18653/v1/2024.acl-long.386) |  | 0 | Recently, the increasing demand for superior medical services has highlighted the discrepancies in the medical infrastructure. With big data, especially texts, forming the foundation of medical services, there is an exigent need for effective natural language processing (NLP) solutions tailored to... | Yuanhe Tian, Ruyi Gan, Yan Song, Jiaxing Zhang, Yongdong Zhang |  |
| 506 |  |  [An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.387) |  | 0 | Large language models (LLMs) have shown strong arithmetic reasoning capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we have only a limited understanding of how they are processed by LLMs. To demystify it, prior work has primarily focused on ablating different components in... | Daking Rai, Ziyu Yao |  |
| 507 |  |  [Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling](https://doi.org/10.18653/v1/2024.acl-long.388) |  | 0 | Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of... | Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel T. Kessler, Eric Ma, Tal August, Irene Li, Alex Pentland, Yoon Kim, Deb K. Roy, Jad Kabbara |  |
| 508 |  |  [Intrinsic Task-based Evaluation for Referring Expression Generation](https://doi.org/10.18653/v1/2024.acl-long.389) |  | 0 | Recently, a human evaluation study of Referring Expression Generation (REG) models had an unexpected conclusion: on WEBNLG, Referring Expressions (REs) generated by the state-of-the-art neural models were not only indistinguishable from the REs in WEBNLG but also from the REs generated by a simple... | Guanyi Chen, Fahime Same, Kees van Deemter |  |
| 509 |  |  [From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.390) |  | 0 | Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts, tracing the progression of events and topics over time. Prior research typically focuses on either event or topic timeline summarization, neglecting the potential synergy of these two... | Qisheng Hu, Geonsik Moon, Hwee Tou Ng |  |
| 510 |  |  [End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.391) |  | 0 | Document-level relation extraction (DocRE) aims to extract relations between entities in a whole document. One of the pivotal challenges of DocRE is to capture the intricate interdependencies between relations of entity pairs. Previous methods have shown that logical rules can explicitly help... | Kunxun Qi, Jianfeng Du, Hai Wan |  |
| 511 |  |  [Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?](https://doi.org/10.18653/v1/2024.acl-long.392) |  | 0 | Recently proposed two-pass direct speech-to-speech translation (S2ST) models decompose the task into speech-to-text translation (S2TT) and text-to-speech (TTS) within an end-to-end model, yielding promising results. However, the training of these models still relies on parallel speech data, which... | Qingkai Fang, Shaolei Zhang, Zhengrui Ma, Min Zhang, Yang Feng |  |
| 512 |  |  [Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder](https://doi.org/10.18653/v1/2024.acl-long.393) |  | 0 | Reconstructing natural language from non-invasive electroencephalography (EEG) holds great promise as a language decoding technology for brain-computer interfaces (BCIs). However, EEG-based language decoding is still in its nascent stages, facing several technical issues such as: 1) Absence of a... | Jiaqi Wang, Zhenxi Song, Zhengyu Ma, Xipeng Qiu, Min Zhang, Zhiguo Zhang |  |
| 513 |  |  [CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers](https://doi.org/10.18653/v1/2024.acl-long.394) |  | 0 | The fast-growing large scale language models are delivering unprecedented performance on almost all natural language processing tasks. However, the effectiveness of large language models are reliant on an exponentially increasing number of parameters. The overwhelming computation complexity incurs... | Longwei Zou, Qingyang Wang, Han Zhao, Jiangangkong Jiangangkong, Yi Yang, Yangdong Deng |  |
| 514 |  |  [Prompt Optimization via Adversarial In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.395) |  | 0 | We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompts for in-context learning (ICL). Inspired by adversarial learning, adv-ICL is implemented as a two-player game between a generator and discriminator, with LLMs acting as both. In each round, given an input... | Do Xuan Long, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Shieh, Junxian He |  |
| 515 |  |  [StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion](https://doi.org/10.18653/v1/2024.acl-long.396) |  | 0 | Recent language model (LM) advancements have showcased impressive zero-shot voice conversion (VC) performance. However, existing LM-based VC models usually apply offline conversion from source semantics to acoustic features, demanding the complete source speech and limiting their deployment to... | Zhichao Wang, Yuanzhe Chen, Xinsheng Wang, Lei Xie, Yuping Wang |  |
| 516 |  |  [Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.397) |  | 0 | Multi-Hop Question Answering (MHQA) task presents a significant challenge for large language models (LLMs) due to the intensive knowledge required. Current solutions, like Retrieval-Augmented Generation, typically retrieve potential documents from an external corpus to read an answer. However, the... | Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, Zhaochun Ren |  |
| 517 |  |  [Multimodal Contextualized Semantic Parsing from Speech](https://doi.org/10.18653/v1/2024.acl-long.398) |  | 0 | We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents’ contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically... | Jordan Voas, David Harwath, Raymond Mooney |  |
| 518 |  |  [LaMP: When Large Language Models Meet Personalization](https://doi.org/10.18653/v1/2024.acl-long.399) |  | 0 | This paper highlights the importance of personalization in large language models and introduces the LaMP benchmark — a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and... | Alireza Salemi, Sheshera Mysore, Michael Bendersky, Hamed Zamani |  |
| 519 |  |  [AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters](https://doi.org/10.18653/v1/2024.acl-long.400) |  | 0 | Large language models’ (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage are under-scrutinized. In our work, we ground web text, which is a popular pretraining... | Li Lucy, Suchin Gururangan, Luca Soldaini, Emma Strubell, David Bamman, Lauren F. Klein, Jesse Dodge |  |
| 520 |  |  [MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.acl-long.401) |  | 0 | The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems. However, comprehensively evaluating the dialogue abilities of LLMs remains a challenge. Previous benchmarks have primarily focused on single-turn dialogues or provided coarse-grained and incomplete assessments of... | Ge Bai, Jie Liu, Xingyuan Bu, Yancheng He, Jiaheng Liu, Zhanhui Zhou, Zhuoran Lin, Wenbo Su, Tiezheng Ge, Bo Zheng, Wanli Ouyang |  |
| 521 |  |  [EFSA: Towards Event-Level Financial Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.402) |  | 0 | In this paper, we extend financial sentiment analysis (FSA) to event-level since events usually serve as the subject of the sentiment in financial text. Though extracting events from the financial text may be conducive to accurate sentiment predictions, it has specialized challenges due to the... | Tianyu Chen, Yiming Zhang, Guoxin Yu, Dapeng Zhang, Li Zeng, Qing He, Xiang Ao |  |
| 522 |  |  [What Evidence Do Language Models Find Convincing?](https://doi.org/10.18653/v1/2024.acl-long.403) |  | 0 | Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as “is aspartame linked to cancer”. To resolve these ambiguous queries, one must search through a large range of websites and consider “which, if any, of this evidence do I... | Alexander Wan, Eric Wallace, Dan Klein |  |
| 523 |  |  [Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.404) |  | 0 | Graph data organizes complex relationships and interactions between objects, facilitating advanced analysis and decision-making across different fields. In this paper, we propose a new paradigm for interactive and instructional graph data understanding and reasoning.Instead of adopting complex... | Qihang Ai, Jiafan Li, Jincheng Dai, Jianwu Zhou, Lemao Liu, Haiyun Jiang, Shuming Shi |  |
| 524 |  |  [LangBridge: Multilingual Reasoning Without Multilingual Supervision](https://doi.org/10.18653/v1/2024.acl-long.405) |  | 0 | We introduce LangBridge, a zero-shot approach to adapt language models for multilingual reasoning tasks without multilingual supervision. LangBridge operates by bridging two models, each specialized in different aspects: (1) one specialized in understanding multiple languages (e.g., mT5 encoder)... | Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, Minjoon Seo |  |
| 525 |  |  [Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs](https://doi.org/10.18653/v1/2024.acl-long.406) |  | 0 | Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to... | Siyuan Wang, Zhongyu Wei, Yejin Choi, Xiang Ren |  |
| 526 |  |  [SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving](https://doi.org/10.18653/v1/2024.acl-long.407) |  | 0 | Large Language Models (LLMs) have driven substantial progress in artificial intelligence in recent years, exhibiting impressive capabilities across a wide range of tasks, including mathematical problem-solving. Inspired by the success of subgoal-based methods, we propose a novel framework called... | Xueliang Zhao, Xinting Huang, Wei Bi, Lingpeng Kong |  |
| 527 |  |  [Unlocking the Power of Large Language Models for Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.408) |  | 0 | Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in data-driven AI applications. Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of... | Xuhui Jiang, Yinghan Shen, Zhichao Shi, Chengjin Xu, Wei Li, Zixuan Li, Jian Guo, Huawei Shen, Yuanzhuo Wang |  |
| 528 |  |  [Trial and Error: Exploration-Based Trajectory Optimization of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.409) |  | 0 | Large Language Models (LLMs) have become integral components in various autonomous agent systems.In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous... | Yifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian Li, Bill Yuchen Lin |  |
| 529 |  |  [ReFT: Reasoning with Reinforced Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.410) |  | 0 | One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data.... | Luong Quoc Trung, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, Hang Li |  |
| 530 |  |  [Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment](https://doi.org/10.18653/v1/2024.acl-long.411) |  | 0 | Evaluating and Rethinking the current landscape of Large Multimodal Models (LMMs), we observe that widely-used visual-language projection approaches (e.g., Q-former or MLP) focus on the alignment of image-text descriptions yet ignore the visual knowledge-dimension alignment, i.e., connecting... | Yunxin Li, Xinyu Chen, Baotian Hu, Haoyuan Shi, Min Zhang |  |
| 531 |  |  [FreeCtrl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.412) |  | 0 | Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data... | Zijian Feng, Hanzhang Zhou, Kezhi Mao, Zixiao Zhu |  |
| 532 |  |  [HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition](https://doi.org/10.18653/v1/2024.acl-long.413) |  | 0 | Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval,... | Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 533 |  |  [Conundrums in Cross-Prompt Automated Essay Scoring: Making Sense of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.414) |  | 0 | Cross-prompt automated essay scoring (AES), an under-investigated but challenging task that has gained increasing popularity in the AES community, aims to train an AES system that can generalize well to prompts that are unseen during model training. While recently-developed cross-prompt AES models... | Shengjie Li, Vincent Ng |  |
| 534 |  |  [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](https://doi.org/10.18653/v1/2024.acl-long.415) |  | 0 | Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes have been extensively researched in various NLP applications, there is a surprising gap for emotion analysis. However, emotion and gender are closely linked in societal... | Flor Miriam Plaza del Arco, Amanda Cercas Curry, Alba Cercas Curry, Gavin Abercrombie, Dirk Hovy |  |
| 535 |  |  [Label Augmentation for Zero-Shot Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.acl-long.416) |  | 0 | Hierarchical Text Classification poses the difficult challenge of classifying documents into multiple labels organized in a hierarchy. The vast majority of works aimed to address this problem relies on supervised methods which are difficult to implement due to the scarcity of labeled data in many... | Lorenzo Paletto, Valerio Basile, Roberto Esposito |  |
| 536 |  |  [STICKERCONV: Generating Multimodal Empathetic Responses from Scratch](https://doi.org/10.18653/v1/2024.acl-long.417) |  | 0 | Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which... | Yiqun Zhang, Fanheng Kong, Peidong Wang, Shuang Sun, Lingshuai Wang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song |  |
| 537 |  |  [EIT: Enhanced Interactive Transformer](https://doi.org/10.18653/v1/2024.acl-long.418) |  | 0 | Two principles: the complementary principle and the consensus principle are widely acknowledged in the literature of multi-view learning. However, the current design of multi-head self-attention, an instance of multi-view learning, prioritizes the complementarity while ignoring the consensus. To... | Tong Zheng, Bei Li, Huiwen Bao, Tong Xiao, JingBo Zhu |  |
| 538 |  |  [MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs](https://doi.org/10.18653/v1/2024.acl-long.419) |  | 0 | Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is... | Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Chenyang Tao, Dimitrios Dimitriadis, Salman Avestimehr |  |
| 539 |  |  [EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models](https://doi.org/10.18653/v1/2024.acl-long.420) |  | 0 | We introduce EXAMS-V, a new challenging multi-discipline multimodal multilingual exam benchmark for evaluating vision language models. It consists of 20,932 multiple-choice questions across 20 school disciplines covering natural science, social science, and other miscellaneous studies, e.g.,... | Rocktim Jyoti Das, Simeon Emilov Hristov, Haonan Li, Dimitar Dimitrov, Ivan Koychev, Preslav Nakov |  |
| 540 |  |  [Order-Agnostic Data Augmentation for Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.421) |  | 0 | Data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, existing NER DA techniques either perform rule-based manipulations on words that break the semantic coherence... | Huiming Wang, Liying Cheng, Wenxuan Zhang, De Wen Soh, Lidong Bing |  |
| 541 |  |  [Text Embedding Inversion Security for Multilingual Language Models](https://doi.org/10.18653/v1/2024.acl-long.422) |  | 0 | Textual data is often represented as real-numbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be susceptible to security breaches, as research shows that text can be... | Yiyi Chen, Heather C. Lent, Johannes Bjerva |  |
| 542 |  |  [Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment](https://doi.org/10.18653/v1/2024.acl-long.423) |  | 0 | Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and... | Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou |  |
| 543 |  |  [PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator](https://doi.org/10.18653/v1/2024.acl-long.424) |  | 0 | The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides made by leveraging real user and ChatGPT dialogues, as evidenced by Vicuna. However, due to challenges in gathering dialogues involving human participation, current endeavors... | Chuyi Kong, Yaxin Fan, Xiang Wan, Feng Jiang, Benyou Wang |  |
| 544 |  |  [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](https://doi.org/10.18653/v1/2024.acl-long.425) |  | 0 | The capability gap between open-source and closed-source large language models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we introduce a synthetic data approach that combines data produced by larger, more powerful models (strong models) with error information data generated by... | Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou |  |
| 545 |  |  [STRUCTSUM Generation for Faster Text Comprehension](https://doi.org/10.18653/v1/2024.acl-long.426) |  | 0 | We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly... | Parag Jain, Andreea Marzoca, Francesco Piccinno |  |
| 546 |  |  [Analysing The Impact of Sequence Composition on Language Model Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.427) |  | 0 | Most language model pre-training frameworks concatenate multiple documents into fixed-length sequences and use causal masking to compute the likelihood of each token given its context; this strategy is widely adopted due to its simplicity and efficiency. However, to this day, the influence of the... | Yu Zhao, Yuanbin Qu, Konrad Staniszewski, Szymon Tworkowski, Wei Liu, Piotr Milos, Yuxiang Wu, Pasquale Minervini |  |
| 547 |  |  [NACL: A General and Effective KV Cache Eviction Framework for LLM at Inference Time](https://doi.org/10.18653/v1/2024.acl-long.428) |  | 0 | Large Language Models (LLMs) have ignited an innovative surge of AI applications, marking a new era of exciting possibilities equipped with extended context windows. However, hosting these models is cost-prohibitive mainly due to the extensive memory consumption of KV Cache involving long-context... | Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu |  |
| 548 |  |  [SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network](https://doi.org/10.18653/v1/2024.acl-long.429) |  | 0 | Brain-inspired Spiking Neural Network (SNN) has demonstrated its effectiveness and efficiency in vision, natural language, and speech understanding tasks, indicating their capacity to “see”, “listen”, and “read”. In this paper, we design SpikeVoice, which performs high-quality Text-To-Speech (TTS)... | Kexin Wang, Jiahong Zhang, Yong Ren, Man Yao, Di Shang, Bo Xu, Guoqi Li |  |
| 549 |  |  [Context-aware Difference Distilling for Multi-change Captioning](https://doi.org/10.18653/v1/2024.acl-long.430) |  | 0 | Multi-change captioning aims to describe complex and coupled changes within an image pair in natural language. Compared with single-change captioning, this task requires the model to have higher-level cognition ability to reason an arbitrary number of changes. In this paper, we propose a novel... | Yunbin Tu, Liang Li, Li Su, ZhengJun Zha, Chenggang Yan, Qingming Huang |  |
| 550 |  |  [Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion](https://doi.org/10.18653/v1/2024.acl-long.431) |  | 0 | Recent years have witnessed the deployment of code language models (LMs) in various code intelligence tasks such as code completion. Yet, it is challenging for pre-trained LMs to generate correct completions in private repositories. Previous studies retrieve cross-file context based on import... | Wei Cheng, Yuhan Wu, Wei Hu |  |
| 551 |  |  [Chain-of-Exemplar: Enhancing Distractor Generation for Multimodal Educational Question Generation](https://doi.org/10.18653/v1/2024.acl-long.432) |  | 0 | Multiple-choice questions (MCQs) are important in enhancing concept learning and student engagement for educational purposes. Despite the multimodal nature of educational content, current methods focus mainly on text-based inputs and often neglect the integration of visual information. In this... | Haohao Luo, Yang Deng, Ying Shen, SeeKiong Ng, TatSeng Chua |  |
| 552 |  |  [LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification](https://doi.org/10.18653/v1/2024.acl-long.433) |  | 0 | With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly researched in various research areas. Recently, many attempts based on prompt-learning have been made to improve the performance of text classification. However, most of these methods are based on... | ChunLiu ChunLiu, Hongguang Zhang, Kainan Zhao, Xinghai Ju, Lin Yang |  |
| 553 |  |  [LEMON: Reviving Stronger and Smaller LMs from Larger LMs with Linear Parameter Fusion](https://doi.org/10.18653/v1/2024.acl-long.434) |  | 0 | In the new era of language models, small models (with billions of parameter sizes) are receiving increasing attention due to their flexibility and cost-effectiveness in deployment. However, limited by the model size, the performance of small models trained from scratch may often be unsatisfactory.... | Yilong Chen, Junyuan Shang, Zhenyu Zhang, Shiyao Cui, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu |  |
| 554 |  |  [Speech Sense Disambiguation: Tackling Homophone Ambiguity in End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.435) |  | 0 | End-to-end speech translation (ST) presents notable disambiguation challenges as it necessitates simultaneous cross-modal and cross-lingual transformations. While word sense disambiguation is an extensively investigated topic in textual machine translation, the exploration of disambiguation... | Tengfei Yu, Xuebo Liu, Liang Ding, Kehai Chen, Dacheng Tao, Min Zhang |  |
| 555 |  |  [To be Continuous, or to be Discrete, Those are Bits of Questions](https://doi.org/10.18653/v1/2024.acl-long.436) |  | 0 | Recently, binary representation has been proposed as a novel representation that lies between continuous and discrete representations. It exhibits considerable information-preserving capability when being used to replace continuous input vectors. In this paper, we investigate the feasibility of... | Yiran Wang, Masao Utiyama |  |
| 556 |  |  [Moûsai: Efficient Text-to-Music Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.437) |  | 0 | Recent years have seen the rapid development of large generative models for text; however, much less research has explored the connection between text and another “language” of communication – music. Music, much like text, can convey emotions, stories, and ideas, and has its own unique structure... | Flavio Schneider, Ojasv Kamal, Zhijing Jin, Bernhard Schölkopf |  |
| 557 |  |  [PokeMQA: Programmable knowledge editing for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.438) |  | 0 | Multi-hop question answering (MQA) is one of the challenging tasks to evaluate machine’s comprehension and reasoning abilities, where large language models (LLMs) have widely achieved the human-comparable performance. Due to the dynamics of knowledge facts in real world, knowledge editing has been... | Hengrui Gu, Kaixiong Zhou, Xiaotian Han, Ninghao Liu, Ruobing Wang, Xin Wang |  |
| 558 |  |  [MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention](https://doi.org/10.18653/v1/2024.acl-long.439) |  | 0 | In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content,... | Prince Jha, Raghav Jain, Konika Mandal, Aman Chadha, Sriparna Saha, Pushpak Bhattacharyya |  |
| 559 |  |  [Efficient OCR for Building a Diverse Digital History](https://doi.org/10.18653/v1/2024.acl-long.440) |  | 0 | Many users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) – which jointly learns a vision and language model – is poorly... | Jacob Carlson, Tom Bryan, Melissa Dell |  |
| 560 |  |  [Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space](https://doi.org/10.18653/v1/2024.acl-long.441) |  | 0 | Despite the notable success of language models (LMs) in various natural language processing (NLP) tasks, the reliability of LMs is susceptible to backdoor attacks. Prior research attempts to mitigate backdoor learning while training the LMs on the poisoned dataset, yet struggles against complex... | Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu |  |
| 561 |  |  [ANAH: Analytical Annotation of Hallucinations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.442) |  | 0 | Reducing the ‘hallucination' problem of Large Language Models (LLMs) is crucial for their wide applications. A comprehensive and fine-grained measurement of the hallucination is the first key step for the governance of this issue but is under-explored in the community.Thus, we present ANAH, a... | Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen |  |
| 562 |  |  [Aligning Large Language Models for Controllable Recommendations](https://doi.org/10.18653/v1/2024.acl-long.443) |  | 0 | Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems — systems that are conversational, explainable, and controllable. However, existing literature primarily... | Wensheng Lu, Jianxun Lian, Wei Zhang, Guanghua Li, Mingyang Zhou, Hao Liao, Xing Xie |  |
| 563 |  |  [Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods](https://doi.org/10.18653/v1/2024.acl-long.444) |  | 0 | Language Models (LMs) acquire parametric knowledge from their training process, embedding it within their weights. The increasing scalability of LMs, however, poses significant challenges for understanding a model’s inner workings and further for updating or correcting this embedded knowledge... | Haeun Yu, Pepa Atanasova, Isabelle Augenstein |  |
| 564 |  |  [Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://doi.org/10.18653/v1/2024.acl-long.445) |  | 0 | Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have... | Kai Lv, Yuqing Yang, Tengxiao Liu, Qipeng Guo, Xipeng Qiu |  |
| 565 |  |  [M³CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.446) |  | 0 | Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge from both textual and visual modalities for step-by-step reasoning, which gains increasing attention. Nevertheless, the current MCoT benchmark still faces some challenges: (1) absence of visual modal reasoning, (2)... | Qiguang Chen, Libo Qin, Jin Zhang, Zhi Chen, Xiao Xu, Wanxiang Che |  |
| 566 |  |  [Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.447) |  | 0 | Long-context modeling capabilities are important for large language models (LLMs) in various applications. However, directly training LLMs with long context windows is insufficient to enhance this capability since some training samples do not exhibit strong semantic dependencies across long... | Longze Chen, Ziqiang Liu, Wanwei He, Yinhe Zheng, Hao Sun, Yunshui Li, Run Luo, Min Yang |  |
| 567 |  |  [Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.448) |  | 0 | While the neural transducer is popular for online speech recognition, simultaneous speech translation (SST) requires both streaming and re-ordering capabilities. This paper presents the LS-Transducer-SST, a label-synchronous neural transducer for SST, which naturally possesses these two properties.... | Keqi Deng, Philip C. Woodland |  |
| 568 |  |  [Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL](https://doi.org/10.18653/v1/2024.acl-long.449) |  | 0 | With the advent of foundation models, prompt tuning has positioned itself as an important technique for directing model behaviors and eliciting desired responses. Prompt tuning regards selecting appropriate keywords included into the input, thereby adapting to the downstream task without adjusting... | Yunseon Choi, Sangmin Bae, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang Bian, KeeEung Kim |  |
| 569 |  |  [A Modular Approach for Multimodal Summarization of TV Shows](https://doi.org/10.18653/v1/2024.acl-long.450) |  | 0 | In this paper we address the task of summarizing television shows, which touches key areas in AI research: complex reasoning, multiple modalities, and long narratives. We present a modular approach where separate components perform specialized sub-tasks which we argue affords greater flexibility... | Louis Mahon, Mirella Lapata |  |
| 570 |  |  [Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities](https://doi.org/10.18653/v1/2024.acl-long.451) |  | 0 | Human interactions are deeply rooted in the interplay of thoughts, beliefs, and desires made possible by Theory of Mind (ToM): our cognitive ability to understand the mental states of ourselves and others. Although ToM may come naturally to us, emulating it presents a challenge to even the most... | Alex Wilf, Sihyun Shawn Lee, Paul Pu Liang, LouisPhilippe Morency |  |
| 571 |  |  [BizBench: A Quantitative Reasoning Benchmark for Business and Finance](https://doi.org/10.18653/v1/2024.acl-long.452) |  | 0 | Answering questions within business and finance requires reasoning, precision, and a wide-breadth of technical knowledge. Together, these requirements make this domain difficult for large language models (LLMs). We introduce BizBench, a benchmark for evaluating models’ ability to reason about... | Michael Krumdick, Rik KoncelKedziorski, Viet Dac Lai, Varshini Reddy, Charles Lovering, Chris Tanner |  |
| 572 |  |  [Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization](https://doi.org/10.18653/v1/2024.acl-long.453) |  | 0 | While image captioning is an essential field of vision language models (VLM), a lack of continuity between the learning objective and final performance metrics of VLMs complicates their training and optimization. Reinforcement learning (RL) can directly optimize such metrics, but it is accompanied... | Takumi Takada, Yuma Suzuki, Hiroki Takushima, Hayato Tanoue, Haruki Sato, Aiswariya Manoj Kumar, Hiroki Nishihara, Takayuki Hori, Kazuya Ueki |  |
| 573 |  |  [Deciphering Hate: Identifying Hateful Memes and Their Targets](https://doi.org/10.18653/v1/2024.acl-long.454) |  | 0 | Internet memes have become a powerful means for individuals to express emotions, thoughts, and perspectives on social media. While often considered as a source of humor and entertainment, memes can also disseminate hateful content targeting individuals or communities. Most existing research focuses... | Eftekhar Hossain, Omar Sharif, Mohammed Moshiul Hoque, Sarah Masud Preum |  |
| 574 |  |  [Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings](https://doi.org/10.18653/v1/2024.acl-long.455) |  | 0 | Transformers generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes structurally equivalent sentences using a... | Yichen Jiang, Xiang Zhou, Mohit Bansal |  |
| 575 |  |  [Label-Efficient Model Selection for Text Generation](https://doi.org/10.18653/v1/2024.acl-long.456) |  | 0 | Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models based on preference annotations. DiffUse... | Shir AshuryTahan, Ariel Gera, Benjamin Sznajder, Leshem Choshen, Liat EinDor, Eyal Shnarch |  |
| 576 |  |  [Machine Unlearning of Pre-trained Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.457) |  | 0 | This study investigates the concept of the ‘right to be forgotten’ within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models–a notably under-researched area. Our research delineates a comprehensive framework for... | Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue |  |
| 577 |  |  [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://doi.org/10.18653/v1/2024.acl-long.458) |  | 0 | Interpretability research aims to bridge the gap between the empirical success and our scientific understanding of the inner workings of large language models (LLMs). However, most existing research in this area focused on analyzing a single mechanism, such as how models copy or recall factual... | Francesco Ortu, Zhijing Jin, Diego Doimo, Mrinmaya Sachan, Alberto Cazzaniga, Bernhard Schölkopf |  |
| 578 |  |  [FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence](https://doi.org/10.18653/v1/2024.acl-long.459) |  | 0 | Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing... | Sebastian Joseph, Lily Chen, Jan Trienes, Hannah Louisa Göke, Monika Coers, Wei Xu, Byron C. Wallace, Junyi Jessy Li |  |
| 579 |  |  [BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.460) |  | 0 | Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based elements, including aspect term, opinion term, aspect category, and sentiment polarity. In practice, unseen aspects, due to distinct data distribution, impose many challenges for a trained neural model. Motivated by this,... | Yinhao Bai, Yalan Xie, Xiaoyi Liu, Yuhua Zhao, Zhixin Han, Mengting Hu, Hang Gao, Renhong Cheng |  |
| 580 |  |  [Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack](https://doi.org/10.18653/v1/2024.acl-long.461) |  | 0 | Recent developments in balancing the usefulness and safety of Large Language Models (LLMs) have raised a critical question: Are mainstream NLP tasks adequately aligned with safety consideration? Our study, focusing on safety-sensitive documents obtained through adversarial attacks, reveals... | Yu Fu, Yufei Li, Wen Xiao, Cong Liu, Yue Dong |  |
| 581 |  |  [Speech language models lack important brain-relevant semantics](https://doi.org/10.18653/v1/2024.acl-long.462) |  | 0 | Despite known differences between reading and listening in the brain, recent work has shown that text-based language models predict both text-evoked and speech-evoked brain activity to an impressive degree. This poses the question of what types of information language models truly predict in the... | Subba Reddy Oota, Emin Çelik, Fatma Deniz, Mariya Toneva |  |
| 582 |  |  [DocLLM: A Layout-Aware Generative Language Model for Multimodal Document Understanding](https://doi.org/10.18653/v1/2024.acl-long.463) |  | 0 | Enterprise documents such as forms, receipts, reports, and other such records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we... | Dongsheng Wang, Natraj Raman, Mathieu Sibue, Zhiqiang Ma, Petr Babkin, Simerjot Kaur, Yulong Pei, Armineh Nourbakhsh, Xiaomo Liu |  |
| 583 |  |  [Bypassing LLM Watermarks with Color-Aware Substitutions](https://doi.org/10.18653/v1/2024.acl-long.464) |  | 0 | Watermarking approaches are proposed to identify if text being circulated is human- or large language model- (LLM) generated. The state-of-the-art watermarking strategy of Kirchenbauer et al. (2023a) biases the LLM to generate specific (“green”) tokens. However, determining the robustness of this... | Qilong Wu, Varun Chandrasekaran |  |
| 584 |  |  [Parallel Structures in Pre-training Data Yield In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.465) |  | 0 | Pre-trained language models (LMs) are capable of in-context learning (ICL): they can adapt to a task with only a few examples given in the prompt without any parameter update. However, it is unclear where this capability comes from as there is a stark distribution shift between pre-training text... | Yanda Chen, Chen Zhao, Zhou Yu, Kathleen R. McKeown, He He |  |
| 585 |  |  [OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.466) |  | 0 | Neural Theory-of-Mind (N-ToM), machine’s ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence... | Hainiu Xu, Runcong Zhao, Lixing Zhu, Jinhua Du, Yulan He |  |
| 586 |  |  [Towards Privacy-Aware Sign Language Translation at Scale](https://doi.org/10.18653/v1/2024.acl-long.467) |  | 0 | A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much of the sign language data currently available on the web cannot be used for training supervised models due to the lack of aligned captions. Furthermore, scaling SLT using large-scale web-scraped datasets... | Phillip Rust, Bowen Shi, Skyler Wang, Necati Cihan Camgöz, Jean Maillard |  |
| 587 |  |  [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://doi.org/10.18653/v1/2024.acl-long.468) |  | 0 | Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture... | Haoxiang Wang, Yong Lin, Wei Xiong, Rui Yang, Shizhe Diao, Shuang Qiu, Han Zhao, Tong Zhang |  |
| 588 |  |  [Towards Real-World Writing Assistance: A Chinese Character Checking Benchmark with Faked and Misspelled Characters](https://doi.org/10.18653/v1/2024.acl-long.469) |  | 0 | Writing assistance aims to improve the correctness and quality of input texts, with character checking being crucial in detecting and correcting wrong characters. In the real world where handwriting occupies the vast majority, characters that humans get wrong include faked characters (i.e., untrue... | Yinghui Li, Zishan Xu, Shaoshen Chen, Haojing Huang, Yangning Li, Shirong Ma, Yong Jiang, Zhongli Li, Qingyu Zhou, HaiTao Zheng, Ying Shen |  |
| 589 |  |  [RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations](https://doi.org/10.18653/v1/2024.acl-long.470) |  | 0 | Individual neurons participate in the representation of multiple high-level concepts. To what extent can different interpretability methods successfully disentangle these roles? To help address this question, we introduce RAVEL (Resolving Attribute-Value Entanglements in Language Models), a dataset... | Jing Huang, Zhengxuan Wu, Christopher Potts, Mor Geva, Atticus Geiger |  |
| 590 |  |  [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://doi.org/10.18653/v1/2024.acl-long.471) |  | 0 | Large language models (LLMs) are increasingly prevalent in conversational systems due to their advanced understanding and generative capabilities in general contexts. However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective... | Zekun Li, Zhiyu Chen, Mike Ross, Patrick Huber, Seungwhan Moon, Zhaojiang Lin, Xin Dong, Adithya Sagar, Xifeng Yan, Paul A. Crook |  |
| 591 |  |  [Faithful Chart Summarization with ChaTS-Pi](https://doi.org/10.18653/v1/2024.acl-long.472) |  | 0 | Chart-to-summary generation can help explore data, communicate insights, and help the visually impaired people. Multi-modal generative models have been used to produce fluent summaries, but they can suffer from factual and perceptual errors. In this work we present CHATS-CRITIC, a reference-free... | Syrine Krichene, Francesco Piccinno, Fangyu Liu, Julian Eisenschlos |  |
| 592 |  |  [Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation](https://doi.org/10.18653/v1/2024.acl-long.473) |  | 0 | Dialogue State Tracking (DST) is designed to monitor the evolving dialogue state in the conversations and plays a pivotal role in developing task-oriented dialogue systems. However, obtaining the annotated data for the DST task is usually a costly endeavor. In this paper, we focus on employing LLMs... | Cheng Niu, Xingguang Wang, Xuxin Cheng, Juntong Song, Tong Zhang |  |
| 593 |  |  [MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.474) |  | 0 | Fact-checking real-world claims often requires reviewing multiple multimodal documents in order to assess the claim’s truthfulness, a highly laborious and time-consuming task. In this paper, we present a summarization model crafted to generate claim-specific summaries useful for fact-checking from... | TingChih Chen, ChiaWei Tang, Chris Thomas |  |
| 594 |  |  [KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction](https://doi.org/10.18653/v1/2024.acl-long.475) |  | 0 |  | Zixuan Li, Yutao Zeng, Yuxin Zuo, Weicheng Ren, Wenxuan Liu, Miao Su, Yucan Guo, Yantao Liu, Xiang Li, Zhilei Hu, Long Bai, Wei Li, Yidan Liu, Pan Yang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng |  |
| 595 |  |  [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](https://doi.org/10.18653/v1/2024.acl-long.476) |  | 0 | Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. These challenges arise from the presence of implicit... | Yanming Liu, Xinyue Peng, Tianyu Du, Jianwei Yin, Weihao Liu, Xuhong Zhang |  |
| 596 |  |  [On the Multi-turn Instruction Following for Conversational Web Agents](https://doi.org/10.18653/v1/2024.acl-long.477) |  | 0 | Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to... | Yang Deng, Xuan Zhang, Wenxuan Zhang, Yifei Yuan, SeeKiong Ng, TatSeng Chua |  |
| 597 |  |  [Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](https://doi.org/10.18653/v1/2024.acl-long.478) |  | 0 | With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research hotspot in human-computer interaction.However, there is a scarcity of benchmarks available for LLM-based mobile agents.Benchmarking these agents generally faces three main challenges:(1) The... | Shihan Deng, Weikai Xu, Hongda Sun, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Rui Yan, Shuo Shang |  |
| 598 |  |  [MC²: Towards Transparent and Culturally-Aware NLP for Minority Languages in China](https://doi.org/10.18653/v1/2024.acl-long.479) |  | 0 | Current large language models demonstrate deficiencies in understanding low-resource languages, particularly the minority languages in China. This limitation stems from the scarcity of available pre-training data. To address this accessibility challenge, we present MC2, a Multilingual Corpus of... | Chen Zhang, Mingxu Tao, Quzhe Huang, Jiuheng Lin, Zhibin Chen, Yansong Feng |  |
| 599 |  |  [Decoder-only Streaming Transformer for Simultaneous Translation](https://doi.org/10.18653/v1/2024.acl-long.480) |  | 0 | Simultaneous Machine Translation (SiMT) generates translation while reading source tokens, essentially producing the target prefix based on the source prefix. To achieve good performance, it leverages the relationship between source and target prefixes to exact a policy to guide the generation of... | Shoutao Guo, Shaolei Zhang, Yang Feng |  |
| 600 |  |  [Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization](https://doi.org/10.18653/v1/2024.acl-long.481) |  | 0 | While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of effort in defending against these attacks. We point out a pivotal factor contributing to the success of jailbreaks: the intrinsic conflict between the goals of... | Zhexin Zhang, Junxiao Yang, Pei Ke, Fei Mi, Hongning Wang, Minlie Huang |  |
| 601 |  |  [I am a Strange Dataset: Metalinguistic Tests for Language Models](https://doi.org/10.18653/v1/2024.acl-long.482) |  | 0 | Statements involving metalinguistic self-reference (“This paper has six sections.”) are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present “I am a Strange Dataset”, a new dataset for addressing this question. There are two subtasks:... | Tristan Thrush, Jared Moore, Miguel Monares, Christopher Potts, Douwe Kiela |  |
| 602 |  |  [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](https://doi.org/10.18653/v1/2024.acl-long.483) |  | 0 | Large Language Models (LLMs) sometimes suffer from producing hallucinations, especially LLMs may generate untruthful responses despite knowing the correct knowledge. Activating the truthfulness within LLM is the key to fully unlocking LLM’s knowledge potential. In this paper, we propose TruthX, an... | Shaolei Zhang, Tian Yu, Yang Feng |  |
| 603 |  |  [ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.484) |  | 0 | We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of... | Le Zhuo, Zewen Chi, Minghao Xu, Heyan Huang, Jianan Zhao, Heqi Zheng, Conghui He, XianLing Mao, Wentao Zhang |  |
| 604 |  |  [StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning](https://doi.org/10.18653/v1/2024.acl-long.485) |  | 0 | Simultaneous speech-to-speech translation (Simul-S2ST, a.k.a streaming speech translation) outputs target speech while receiving streaming speech inputs, which is critical for real-time communication. Beyond accomplishing translation between speech, Simul-S2ST requires a policy to control the model... | Shaolei Zhang, Qingkai Fang, Shoutao Guo, Zhengrui Ma, Min Zhang, Yang Feng |  |
| 605 |  |  [Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.486) |  | 0 | Recent work has showcased the powerful capability of large language models (LLMs) in recalling knowledge and reasoning. However, the reliability of LLMs in combining these two capabilities into reasoning through multi-hop facts has not been widely explored. This paper systematically investigates... | Tianjie Ju, Yijin Chen, Xinwei Yuan, Zhuosheng Zhang, Wei Du, Yubin Zheng, Gongshen Liu |  |
| 606 |  |  [Why Don't Prompt-Based Fairness Metrics Correlate?](https://doi.org/10.18653/v1/2024.acl-long.487) |  | 0 | The widespread use of large language models has brought up essential questions about the potential biases these models might learn. This led to the development of several metrics aimed at evaluating and mitigating these biases. In this paper, we first demonstrate that prompt-based fairness metrics... | Abdelrahman Zayed, Gonçalo Mordido, Ioana Baldini, Sarath Chandar |  |
| 607 |  |  [NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data](https://doi.org/10.18653/v1/2024.acl-long.488) |  | 0 | To address the global issue of online hate, hate speech detection (HSD) systems are typically developed on datasets from the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on non-representative samples, raising... | Manuel Tonneau, Pedro Vitor Quinta de Castro, Karim Lasri, Ibrahim Farouq, Lakshmi Subramanian, Víctor OrozcoOlvera, Samuel Fraiberger |  |
| 608 |  |  [M³AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset](https://doi.org/10.18653/v1/2024.acl-long.489) |  | 0 | Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the... | Zhe Chen, Heyang Liu, Wenyi Yu, Guangzhi Sun, Hongcheng Liu, Ji Wu, Chao Zhang, Yu Wang, Yanfeng Wang |  |
| 609 |  |  [Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination](https://doi.org/10.18653/v1/2024.acl-long.490) |  | 0 | Instruction-following language models often show undesirable biases. These undesirable biases may be accelerated in the real-world usage of language models, where a wide range of instructions is used through zero-shot example prompting. To solve this problem, we first define the bias neuron, which... | Nakyeong Yang, Taegwan Kang, Stanley Jungkyu Choi, Honglak Lee, Kyomin Jung |  |
| 610 |  |  [Domain Adaptation for Subjective Induction Questions Answering on Products by Adversarial Disentangled Learning](https://doi.org/10.18653/v1/2024.acl-long.491) |  | 0 | This paper focuses on answering subjective questions about products. Different from the factoid question with a single answer span, this subjective one involves multiple viewpoints. For example, the question of ‘how the phone’s battery is?’ not only involves facts of battery capacity but also... | Yufeng Zhang, Jianxing Yu, Yanghui Rao, Libin Zheng, Qinliang Su, Huaijie Zhu, Jian Yin |  |
| 611 |  |  [Revisiting Demonstration Selection Strategies in In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.492) |  | 0 | Large language models (LLMs) have shown an impressive ability to perform a wide range of tasks using in-context learning (ICL), where a few examples are used to describe a task to the model. However, the performance of ICL varies significantly with the choice of demonstrations, and previous... | Keqin Peng, Liang Ding, Yancheng Yuan, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao |  |
| 612 |  |  [Multimodal Table Understanding](https://doi.org/10.18653/v1/2024.acl-long.493) |  | 0 | Although great progress has been made by previous table understanding methods including recent approaches based on large language models (LLMs), they rely heavily on the premise that given tables must be converted into a certain text sequence (such as Markdown or HTML) to serve as model input.... | Mingyu Zheng, Xinwei Feng, Qingyi Si, Qiaoqiao She, Zheng Lin, Wenbin Jiang, Weiping Wang |  |
| 613 |  |  [Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding](https://doi.org/10.18653/v1/2024.acl-long.494) |  | 0 | Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length,... | Huang Lei, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen |  |
| 614 |  |  [Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.495) |  | 0 | Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled... | Mayur Patidar, Riya Sawhney, Avinash Kumar Singh, Biswajit Chatterjee, Mausam, Indrajit Bhattacharya |  |
| 615 |  |  [WatME: Towards Lossless Watermarking Through Lexical Redundancy](https://doi.org/10.18653/v1/2024.acl-long.496) |  | 0 | Text watermarking has emerged as a pivotal technique for identifying machine-generated text. However, existing methods often rely on arbitrary vocabulary partitioning during decoding to embed watermarks, which compromises the availability of suitable tokens and significantly degrades the quality of... | Liang Chen, Yatao Bian, Yang Deng, Deng Cai, Shuaiyi Li, Peilin Zhao, KamFai Wong |  |
| 616 |  |  [Text-like Encoding of Collaborative Information in Large Language Models for Recommendation](https://doi.org/10.18653/v1/2024.acl-long.497) |  | 0 | When adapting Large Language Models for Recommendation (LLMRec), it is crucial to integrate collaborative information. Existing methods achieve this by learning collaborative embeddings in LLMs’ latent space from scratch or by mapping from external models. However, they fail to represent the... | Yang Zhang, Keqin Bao, Ming Yan, Wenjie Wang, Fuli Feng, Xiangnan He |  |
| 617 |  |  [MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception](https://doi.org/10.18653/v1/2024.acl-long.498) |  | 0 | Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially... | Yuhao Wang, Yusheng Liao, Heyang Liu, Hongcheng Liu, Yanfeng Wang, Yu Wang |  |
| 618 |  |  [Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.499) |  | 0 | Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT). However, we find these CoT-like methods lead to a considerable number of originally correct answers turning wrong, which we define as the Toxic CoT problem. To... | Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao |  |
| 619 |  |  [Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation](https://doi.org/10.18653/v1/2024.acl-long.500) |  | 0 | Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects (e.g., “positive” from sentiment and “sport” from topic). Existing works neglect attribute correlations formed by the intertwining of different attributes. Particularly, the stereotype... | Yi Liu, Xiangyu Liu, Xiangrong Zhu, Wei Hu |  |
| 620 |  |  [Reward-based Input Construction for Cross-document Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.501) |  | 0 | Relation extraction (RE) is a fundamental task in natural language processing, aiming to identify relations between target entities in text. While many RE methods are designed for a single sentence or document, cross-document RE has emerged to address relations across multiple long documents. Given... | Byeonghu Na, Suhyeon Jo, Yeongmin Kim, IlChul Moon |  |
| 621 |  |  [Hyperspherical Multi-Prototype with Optimal Transport for Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.502) |  | 0 | Event Argument Extraction (EAE) aims to extract arguments for specified events from a text. Previous research has mainly focused on addressing long-distance dependencies of arguments, modeling co-occurrence relationships between roles and events, but overlooking potential inductive biases: (i)... | Guangjun Zhang, Hu Zhang, Yujie Wang, Ru Li, Hongye Tan, Jiye Liang |  |
| 622 |  |  [Understanding Retrieval Robustness for Retrieval-augmented Image Captioning](https://doi.org/10.18653/v1/2024.acl-long.503) |  | 0 | Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far... | Wenyan Li, Jiaang Li, Rita Ramos, Raphael Tang, Desmond Elliott |  |
| 623 |  |  [Semi-Supervised Spoken Language Glossification](https://doi.org/10.18653/v1/2024.acl-long.504) |  | 0 | Spoken language glossification (SLG) aims to translate the spoken language text into the sign language gloss, i.e., a written record of sign language. In this work, we present a framework named Semi-Supervised Spoken Language Glossification (S3LG) for SLG. To tackle the bottleneck of limited... | Huijie Yao, Wengang Zhou, Hao Zhou, Houqiang Li |  |
| 624 |  |  [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents](https://doi.org/10.18653/v1/2024.acl-long.505) |  | 0 | Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g.,... | Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang, Zhiyong Wu |  |
| 625 |  |  [InterrogateLLM: Zero-Resource Hallucination Detection in LLM-Generated Answers](https://doi.org/10.18653/v1/2024.acl-long.506) |  | 0 | Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where... | Yakir Yehuda, Itzik Malkiel, Oren Barkan, Jonathan Weill, Royi Ronen, Noam Koenigstein |  |
| 626 |  |  [F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods](https://doi.org/10.18653/v1/2024.acl-long.507) |  | 0 | Large language models (LLMs) garner significant attention for their unprecedented performance, leading to an increasing number of researches evaluating LLMs. However, these evaluation benchmarks are limited to assessing the instruction-following capabilities, overlooking the fundamental abilities... | Yu Sun, Keyuchen Keyuchen, Shujie Wang, Peiji Li, Qipeng Guo, Hang Yan, Xipeng Qiu, Xuanjing Huang, Dahua Lin |  |
| 627 |  |  [Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning](https://doi.org/10.18653/v1/2024.acl-long.508) |  | 0 | Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their... | Philipp Mondorf, Barbara Plank |  |
| 628 |  |  [Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback](https://doi.org/10.18653/v1/2024.acl-long.509) |  | 0 | There is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences. We consider the setting of fairness in content moderation, in which human feedback is used to determine how two comments — referencing different... | Maria Lerner, Florian E. Dorner, Elliott Ash, Naman Goel |  |
| 629 |  |  [Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://doi.org/10.18653/v1/2024.acl-long.510) |  | 0 | In this paper, we present an innovative process-oriented math process reward model called Math-shepherd, which assigns a reward score to each step of math problem solutions. The training of Math-shepherd is achieved using automatically constructed process-wise supervision data, breaking the... | Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, Zhifang Sui |  |
| 630 |  |  [Large Language Models are not Fair Evaluators](https://doi.org/10.18653/v1/2024.acl-long.511) |  | 0 | In this paper, we uncover a positional bias in the evaluation paradigm of adopting large language models (LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by... | Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng Kong, Qi Liu, Tianyu Liu, Zhifang Sui |  |
| 631 |  |  [Improving Large Language Models in Event Relation Logical Prediction](https://doi.org/10.18653/v1/2024.acl-long.512) |  | 0 | Event relations are crucial for narrative understanding and reasoning. Governed by nuanced logic, event relation extraction (ERE) is a challenging task that demands thorough semantic understanding and rigorous logical reasoning. In this paper, we conduct an in-depth investigation to systematically... | Meiqi Chen, Yubo Ma, Kaitao Song, Yixin Cao, Yan Zhang, Dongsheng Li |  |
| 632 |  |  [Synchronized Video Storytelling: Generating Video Narrations with Structured Storyline](https://doi.org/10.18653/v1/2024.acl-long.513) |  | 0 | Video storytelling is engaging multimedia content that utilizes video and its accompanying narration to share a story and attract the audience, where a key challenge is creating narrations for recorded visual scenes. Previous studies on dense video captioning and video story generation have made... | Dingyi Yang, Chunru Zhan, Ziheng Wang, Biao Wang, Tiezheng Ge, Bo Zheng, Qin Jin |  |
| 633 |  |  [Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation](https://doi.org/10.18653/v1/2024.acl-long.514) |  | 0 | Fine-grained vision-language models (VLM) have been widely used for inter-modality local alignment between the predefined fixed patches and textual words. However, in medical analysis, lesions exhibit varying sizes and positions, and using fixed patches may cause incomplete representations of... | Wenting Chen, Linlin Shen, Jingyang Lin, Jiebo Luo, Xiang Li, Yixuan Yuan |  |
| 634 |  |  [T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step](https://doi.org/10.18653/v1/2024.acl-long.515) |  | 0 | Large language models (LLMs) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models... | Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, Feng Zhao |  |
| 635 |  |  [Are LLM-based Evaluators Confusing NLG Quality Criteria?](https://doi.org/10.18653/v1/2024.acl-long.516) |  | 0 | Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and... | Xinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, Xiaojun Wan |  |
| 636 |  |  [Synergistic Interplay between Search and Large Language Models for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.517) |  | 0 | Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern retrieval models (RMs). The emergence of large language models (LLMs) has further revolutionized the IR field by... | Jiazhan Feng, Chongyang Tao, Xiubo Geng, Tao Shen, Can Xu, Guodong Long, Dongyan Zhao, Daxin Jiang |  |
| 637 |  |  [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://doi.org/10.18653/v1/2024.acl-long.518) |  | 0 | Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing. Current innovations, including State Space Models, were initially celebrated for surpassing Transformer performance on language modeling tasks.... | Yaroslav Aksenov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina, Boris Shaposhnikov, Alexey Gorbatovski, Daniil Gavrilov |  |
| 638 |  |  [Temperature-scaling surprisal estimates improve fit to human reading times - but does it do so for the "right reasons"?](https://doi.org/10.18653/v1/2024.acl-long.519) |  | 0 | A wide body of evidence shows that human language processing difficulty is predicted by the information-theoretic measure surprisal, a word’s negative log probability in context. However, it is still unclear how to best estimate these probabilities needed for predicting human processing difficulty... | Tong Liu, Iza Skrjanec, Vera Demberg |  |
| 639 |  |  [Beyond Recognising Entailment: Formalising Natural Language Inference from an Argumentative Perspective](https://doi.org/10.18653/v1/2024.acl-long.520) |  | 0 | In argumentation theory, argument schemes are a characterisation of stereotypical patterns of inference. There has been little work done to develop computational approaches to identify these schemes in natural language. Moreover, advancements in recognizing textual entailment lack a standardized... | Ameer SaadatYazdi, Nadin Kökciyan |  |
| 640 |  |  [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://doi.org/10.18653/v1/2024.acl-long.521) |  | 0 | We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM)... | Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, YuGang Jiang, Xipeng Qiu |  |
| 641 |  |  [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.522) |  | 0 | Social media abounds with multimodal sarcasm, and identifying sarcasm targets is particularly challenging due to the implicit incongruity not directly evident in the text and image modalities. Current methods for Multimodal Sarcasm Target Identification (MSTI) predominantly focus on superficial... | Zixin Chen, Hongzhan Lin, Ziyang Luo, Mingfei Cheng, Jing Ma, Guang Chen |  |
| 642 |  |  [Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation](https://doi.org/10.18653/v1/2024.acl-long.523) |  | 0 | Aligning large language models (LLMs) with human expectations without human-annotated preference data is an important problem. In this paper, we propose a method to evaluate the response preference by using the output probabilities of response pairs under contrastive prompt pairs, which could... | Aiwei Liu, Haoping Bai, Zhiyun Lu, Xiang Kong, Simon Wang, Jiulong Shan, Meng Cao, Lijie Wen |  |
| 643 |  |  [Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines](https://doi.org/10.18653/v1/2024.acl-long.524) |  | 0 | Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by... | Michael Toker, Hadas Orgad, Mor Ventura, Dana Arad, Yonatan Belinkov |  |
| 644 |  |  [Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.525) |  | 0 | Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training method, and evaluation benchmark. In... | Yuchong Sun, Che Liu, Kun Zhou, Jinwen Huang, Ruihua Song, Xin Zhao, Fuzheng Zhang, Di Zhang, Kun Gai |  |
| 645 |  |  [Robust Singing Voice Transcription Serves Synthesis](https://doi.org/10.18653/v1/2024.acl-long.526) |  | 0 | Note-level Automatic Singing Voice Transcription (AST) converts singing recordings into note sequences, facilitating the automatic annotation of singing datasets for Singing Voice Synthesis (SVS) applications. Current AST methods, however, struggle with accuracy and robustness when used for... | Ruiqi Li, Yu Zhang, Yongqi Wang, Zhiqing Hong, Rongjie Huang, Zhou Zhao |  |
| 646 |  |  [VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.527) |  | 0 | Security practitioners maintain vulnerability reports (e.g., GitHub Advisory) to help developers mitigate security risks. An important task for these databases is automatically extracting structured information mentioned in the report, e.g., the affected software packages, to accelerate the defense... | Tianyu Chen, Lin Li, ZhuLiuchuan ZhuLiuchuan, Zongyang Li, Xueqing Liu, Guangtai Liang, Qianxiang Wang, Tao Xie |  |
| 647 |  |  [Self-Modifying State Modeling for Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.528) |  | 0 | Simultaneous Machine Translation (SiMT) generates target outputs while receiving stream source inputs and requires a read/write policy to decide whether to wait for the next source token or generate a new target token, whose decisions form a decision path. Existing SiMT methods, which learn the... | Donglei Yu, Xiaomian Kang, Yuchen Liu, Yu Zhou, Chengqing Zong |  |
| 648 |  |  [MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-long.529) |  | 0 | Embodied agents equipped with GPT as their brain have exhibited extraordinary decision-making and generalization abilities across various tasks. However, existing zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT-4 to select potential locations within localized... | Jiaqi Chen, Bingqian Lin, Ran Xu, Zhenhua Chai, Xiaodan Liang, KwanYee Kenneth Wong |  |
| 649 |  |  [BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.530) |  | 0 | With the prosperity of large language models (LLMs), powerful LLM-based intelligent agents have been developed to provide customized services with a set of user-defined tools. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent... | Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian |  |
| 650 |  |  [DetermLR: Augmenting LLM-based Logical Reasoning from Indeterminacy to Determinacy](https://doi.org/10.18653/v1/2024.acl-long.531) |  | 0 | Recent advances in large language models (LLMs) have revolutionized the landscape of reasoning tasks. To enhance the capabilities of LLMs to emulate human reasoning, prior studies have focused on modeling reasoning steps using various thought structures like chains, trees, or graphs. However,... | Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, JiRong Wen, Rui Yan |  |
| 651 |  |  [LePaRD: A Large-Scale Dataset of Judicial Citations to Precedent](https://doi.org/10.18653/v1/2024.acl-long.532) |  | 0 | We present the Legal Passage Retrieval Dataset, LePaRD. LePaRD contains millions of examples of U.S. federal judges citing precedent in context. The dataset aims to facilitate work on legal passage retrieval, a challenging practice-oriented legal retrieval and reasoning task. Legal passage... | Robert Mahari, Dominik Stammbach, Elliott Ash, Alex Pentland |  |
| 652 |  |  [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.533) |  | 0 | Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has... | Giacomo Frisoni, Alessio Cocchieri, Alex Presepi, Gianluca Moro, Zaiqiao Meng |  |
| 653 |  |  [MERA: A Comprehensive LLM Evaluation in Russian](https://doi.org/10.18653/v1/2024.acl-long.534) |  | 0 | Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). However, despite researchers’ attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still... | Alena Fenogenova, Artem Chervyakov, Nikita Martynov, Anastasia Kozlova, Maria Tikhonova, Albina Akhmetgareeva, Anton A. Emelyanov, Denis Shevelev, Pavel Lebedev, Leonid Sinev, Ulyana Isaeva, Katerina Kolomeytseva, Daniil Moskovskiy, Elizaveta Goncharova, Nikita Savushkin, Polina Mikhailova, Anastasia Minaeva, Denis Dimitrov, Alexander Panchenko, Sergey Markov |  |
| 654 |  |  [SC2: Towards Enhancing Content Preservation and Style Consistency in Long Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.535) |  | 0 | Text style transfer (TST) aims to vary the style polarity of text while preserving the semantic content. Although recent advancements have demonstrated remarkable progress in short TST, it remains a relatively straightforward task with limited practical applications. The more comprehensive long TST... | Jie Zhao, Ziyu Guan, Cai Xu, Wei Zhao, Yue Jiang |  |
| 655 |  |  [Dodo: Dynamic Contextual Compression for Decoder-only LMs](https://doi.org/10.18653/v1/2024.acl-long.536) |  | 0 | Transformer-based language models (LMs) are inefficient in long contexts. We propose Dodo, a solution for context compression. Instead of one vector per token in a standard transformer model, Dodo represents text with a dynamic number of hidden states at each layer, reducing the cost of... | Guanghui Qin, Corby Rosset, Ethan C. Chau, Nikhil Rao, Benjamin Van Durme |  |
| 656 |  |  [POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.537) |  | 0 | Low-resource languages (LRLs) face challenges in supervised neural machine translation (NMT) due to limited parallel data, prompting research in unsupervised NMT.Unsupervised NMT (UNMT), without requiring ground truth, provides solutions for LRL translations using synthetic pseudo-parallel data and... | Shilong Pan, Zhiliang Tian, Liang Ding, Haoqi Zheng, Zhen Huang, Zhihua Wen, Dongsheng Li |  |
| 657 |  |  [NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism](https://doi.org/10.18653/v1/2024.acl-long.538) |  | 0 | We present NewsBench, a novel evaluation framework to systematically assess the capabilities of Large Language Models (LLMs) for editorial capabilities in Chinese journalism. Our constructed benchmark dataset is focused on four facets of writing proficiency and six facets of safety adherence, and... | Miao Li, MingBin Chen, Bo Tang, ShengbinHou ShengbinHou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Cheng Peng, Yi Luo |  |
| 658 |  |  [MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization](https://doi.org/10.18653/v1/2024.acl-long.539) |  | 0 | Intuitively, reasoning abilities are considered language-agnostic. However, existing LLMs exhibit inconsistent reasoning abilities across different languages, e.g., reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To... | Shuaijie She, Wei Zou, Shujian Huang, Wenhao Zhu, Xiang Liu, Xiang Geng, Jiajun Chen |  |
| 659 |  |  [Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training](https://doi.org/10.18653/v1/2024.acl-long.540) |  | 0 | Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to... | Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, Ruifeng Xu |  |
| 660 |  |  [Predicting Text Preference Via Structured Comparative Reasoning](https://doi.org/10.18653/v1/2024.acl-long.541) |  | 0 | Comparative reasoning plays a crucial role in predicting text preferences; however, large language models (LLMs) often demonstrate inconsistencies in their reasoning, leading to incorrect preference predictions. While approaches like Chain-of-Thought improve accuracy in many settings, they struggle... | Jing Nathan Yan, Tianqi Liu, Justin T. Chiu, Jiaming Shen, Zhen Qin, Yue Yu, Charumathi Lakshmanan, Yair Kurzion, Alexander M. Rush, Jialu Liu, Michael Bendersky |  |
| 661 |  |  [CoELM: Construction-Enhanced Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.542) |  | 0 | Recent studies have shown that integrating constructional information can improve the performance of pre-trained language models (PLMs) in natural language understanding. However, exploration into leveraging constructional information to enhance generative language models for natural language... | Lvxiaowei Xu, Zhilin Gong, Jianhua Dai, Tianxiang Wang, Ming Cai, Jiawei Peng |  |
| 662 |  |  [Uni-Dubbing: Zero-Shot Speech Synthesis from Visual Articulation](https://doi.org/10.18653/v1/2024.acl-long.543) |  | 0 | In the field of speech synthesis, there is a growing emphasis on employing multimodal speech to enhance robustness. A key challenge in this area is the scarcity of datasets that pair audio with corresponding video. We employ a methodology that incorporates modality alignment during the pre-training... | Songju Lei, Xize Cheng, Mengjiao Lyu, Jianqiao Hu, Jintao Tan, Runlin Liu, Lingyu Xiong, Tao Jin, Xiandong Li, Zhou Zhao |  |
| 663 |  |  [On the Impact of Calibration Data in Post-training Quantization and Pruning](https://doi.org/10.18653/v1/2024.acl-long.544) |  | 0 | Quantization and pruning form the foundation of compression for neural networks, enabling efficient inference for large language models (LLMs). Recently, various quantization and pruning techniques have demonstrated remarkable performance in a post-training setting. They rely upon calibration data,... | Miles Williams, Nikolaos Aletras |  |
| 664 |  |  [SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution](https://doi.org/10.18653/v1/2024.acl-long.545) |  | 0 | Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent... | Prerna Agarwal, Nishant Kumar, Srikanta Bedathur |  |
| 665 |  |  [Meta-Task Prompting Elicits Embeddings from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.546) |  | 0 | We introduce a new unsupervised text embedding method, Meta-Task Prompting with Explicit One-Word Limitation (MetaEOL), for generating high-quality sentence embeddings from Large Language Models (LLMs) without the need for model fine-tuning. Leveraging meta-task prompting, MetaEOL guides LLMs to... | Yibin Lei, Di Wu, Tianyi Zhou, Tao Shen, Yu Cao, Chongyang Tao, Andrew Yates |  |
| 666 |  |  [A Sentiment Consolidation Framework for Meta-Review Generation](https://doi.org/10.18653/v1/2024.acl-long.547) |  | 0 | Modern natural language generation systems with Large Language Models (LLMs) exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if they truly possess the capability of information consolidation to generate summaries, especially on documents with... | Miao Li, Jey Han Lau, Eduard H. Hovy |  |
| 667 |  |  [Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing](https://doi.org/10.18653/v1/2024.acl-long.548) |  | 0 | Structured Sentiment Analysis (SSA) was cast as a problem of bi-lexical dependency graph parsing by prior studies.Multiple formulations have been proposed to construct the graph, which share several intrinsic drawbacks:(1) The internal structures of spans are neglected, thus only the boundary... | Chengjie Zhou, Bobo Li, Hao Fei, Fei Li, Chong Teng, Donghong Ji |  |
| 668 |  |  [OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification](https://doi.org/10.18653/v1/2024.acl-long.549) |  | 0 | There has been an increasing interest in large speech models that can perform multiple tasks in a single model. Such models usually adopt an encoder-decoder or decoder-only architecture due to their popularity and good performance in many domains. However, autoregressive models can be slower during... | Yifan Peng, Yui Sudo, Muhammad Shakeel, Shinji Watanabe |  |
| 669 |  |  [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.550) |  | 0 | We study whether Large Language Models (LLMs) latently perform multi-hop reasoning with complex prompts such as “The mother of the singer of ‘Superstition’ is”. We look for evidence of a latent reasoning pathway where an LLM (1) latently identifies “the singer of ‘Superstition’” as Stevie Wonder,... | Sohee Yang, Elena Gribovskaya, Nora Kassner, Mor Geva, Sebastian Riedel |  |
| 670 |  |  [MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning](https://doi.org/10.18653/v1/2024.acl-long.551) |  | 0 | In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation... | Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou |  |
| 671 |  |  [Harnessing Toulmin's theory for zero-shot argument explication](https://doi.org/10.18653/v1/2024.acl-long.552) |  | 0 | To better analyze informal arguments on public forums, we propose the task of argument explication, which makes explicit a text’s argumentative structure and implicit reasoning by outputting triples of propositions ⟨claim, reason warrant⟩. The three slots, or argument components, are derived from... | Ankita Gupta, Ethan Zuckerman, Brendan T. O'Connor |  |
| 672 |  |  [BinaryAlign: Word Alignment as Binary Sequence Labeling](https://doi.org/10.18653/v1/2024.acl-long.553) |  | 0 | Real world deployments of word alignment are almost certain to cover both high and low resource languages. However, the state-of-the-art for this task recommends a different model class depending on the availability of gold alignment training data for a particular language pair. We propose... | Gaetan Latouche, MarcAndré Carbonneau, Benjamin Swanson |  |
| 673 |  |  [Quantifying the Persona Effect in LLM Simulations](https://doi.org/10.18653/v1/2024.acl-long.554) |  | 0 | Large language models (LLMs) have shown remarkable promise in simulating human language and behavior. This study investigates how integrating persona variables—demographic, social, and behavioral factors—impacts LLMs’ ability to simulate diverse perspectives. We find that persona variables account... | Tiancheng Hu, Nigel Collier |  |
| 674 |  |  [Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?](https://doi.org/10.18653/v1/2024.acl-long.555) |  | 0 | Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four... | Nishant Balepur, Abhilasha Ravichander, Rachel Rudinger |  |
| 675 |  |  [Retrieval Augmented Fact Verification by Synthesizing Contrastive Arguments](https://doi.org/10.18653/v1/2024.acl-long.556) |  | 0 | The rapid propagation of misinformation poses substantial risks to public interest. To combat misinformation, large language models (LLMs) are adapted to automatically verify claim credibility. Nevertheless, existing methods heavily rely on the embedded knowledge within LLMs and / or black-box APIs... | Zhenrui Yue, Huimin Zeng, Lanyu Shang, Yifan Liu, Yang Zhang, Dong Wang |  |
| 676 |  |  [SyllabusQA: A Course Logistics Question Answering Dataset](https://doi.org/10.18653/v1/2024.acl-long.557) |  | 0 | Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly... | Nigel Fernandez, Alexander Scarlatos, Andrew S. Lan |  |
| 677 |  |  [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.558) |  | 0 | Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address... | Yilin Wen, Zifeng Wang, Jimeng Sun |  |
| 678 |  |  [AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German Consumer Contracts](https://doi.org/10.18653/v1/2024.acl-long.559) |  | 0 | Legal tasks and datasets are often used as benchmarks for the capabilities of language models. However, openly available annotated datasets are rare. In this paper, we introduce AGB-DE, a corpus of 3,764 clauses from German consumer contracts that have been annotated and legally assessed by legal... | Daniel Braun, Florian Matthes |  |
| 679 |  |  [Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks](https://doi.org/10.18653/v1/2024.acl-long.560) |  | 0 | Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model’s average performance across the test prompts of a benchmark to evaluate the model’s performance. This is consistent with the assumption that the test prompts... | Charlotte Siska, Katerina Marazopoulou, Melissa Ailem, James Bono |  |
| 680 |  |  [Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning](https://doi.org/10.18653/v1/2024.acl-long.561) |  | 0 | We present a new method for large language models to solve compositional tasks. Although they have shown strong performance on traditional language understanding tasks, large language models struggle to solve compositional tasks, where the solution depends on solving smaller instances of the same... | Eric Pasewark, Kyle Montgomery, Kefei Duan, Dawn Song, Chenguang Wang |  |
| 681 |  |  [Bridging the Preference Gap between Retrievers and LLMs](https://doi.org/10.18653/v1/2024.acl-long.562) |  | 0 | Large Language Models (LLMs) have demonstrated superior results across a wide range of tasks, and Retrieval-augmented Generation (RAG) is an effective way to enhance the performance by locating relevant information and placing it into the context window of the LLM. However, the relationship between... | Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky |  |
| 682 |  |  [Large Language Models Can Learn Temporal Reasoning](https://doi.org/10.18653/v1/2024.acl-long.563) |  | 0 | While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs... | Siheng Xiong, Ali Payani, Ramana Kompella, Faramarz Fekri |  |
| 683 |  |  [Learning Relational Decomposition of Queries for Question Answering from Tables](https://doi.org/10.18653/v1/2024.acl-long.564) |  | 0 | Table Question-Answering involves both understanding the natural language query and grounding it in the context of the input table to extract relevant information. In this context, many methods have highlighted the benefits of intermediate pre-training using SQL queries. However, while most... | Raphaël Mouravieff, Benjamin Piwowarski, Sylvain Lamprier |  |
| 684 |  |  [Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People](https://doi.org/10.18653/v1/2024.acl-long.565) |  | 0 | Conversational tones — the manners and attitudes in which speakers communicate — are essential to effective communication. As Large Language Models (LLMs) become increasingly popular, it is necessary to characterize the divergences in their conversational tones relative to humans. Prior research... | DunMing Huang, Pol van Rijn, Ilia Sucholutsky, Raja Marjieh, Nori Jacoby |  |
| 685 |  |  [Pareto Optimal Learning for Estimating Large Language Model Errors](https://doi.org/10.18653/v1/2024.acl-long.566) |  | 0 | Large Language Models (LLMs) have shown impressive abilities in many applications. When a concrete and precise answer is desired, it is important to have a quantitative estimation of the potential error rate. However, this can be challenging due to the text-in-text-out nature of the generative... | Theodore Zhao, Mu Wei, Joseph Preston, Hoifung Poon |  |
| 686 |  |  [Simul-LLM: A Framework for Exploring High-Quality Simultaneous Translation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.567) |  | 0 | Large language models (LLMs) with billions of parameters and pretrained on massive amounts of data are now capable of near or better than state-of-the-art performance in a variety of downstream natural language processing tasks. Neural machine translation (NMT) is one such task that LLMs have been... | Victor Agostinelli, Max Wild, Matthew Raffel, Kazi Ahmed Asif Fuad, Lizhong Chen |  |
| 687 |  |  [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM](https://doi.org/10.18653/v1/2024.acl-long.568) |  | 0 | Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with... | Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen |  |
| 688 |  |  [Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.569) |  | 0 | This study explores the realm of knowledge base question answering (KBQA). KBQA is considered a challenging task, particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)-based methods require extensive data annotations, which result in... | Guanming Xiong, Junwei Bao, Wen Zhao |  |
| 689 |  |  [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](https://doi.org/10.18653/v1/2024.acl-long.570) |  | 0 | Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect... | Boshi Wang, Hao Fang, Jason Eisner, Benjamin Van Durme, Yu Su |  |
| 690 |  |  [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://doi.org/10.18653/v1/2024.acl-long.571) |  | 0 | The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the... | Hao Zhao, Zihan Qiu, Huijia Wu, Zili Wang, Zhaofeng He, Jie Fu |  |
| 691 |  |  [Aligning Large Language Models with Human Preferences through Representation Engineering](https://doi.org/10.18653/v1/2024.acl-long.572) |  | 0 | Aligning large language models (LLMs) with human preferences is crucial for enhancing their utility in terms of helpfulness, truthfulness, safety, harmlessness, and interestingness. Existing methods for achieving this alignment often involve employing reinforcement learning from human feedback... | Wenhao Liu, Xiaohua Wang, Muling Wu, Tianlong Li, Changze Lv, Zixuan Ling, Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang |  |
| 692 |  |  [CODIS: Benchmarking Context-dependent Visual Comprehension for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.573) |  | 0 | Multimodal large language models (MLLMs) have demonstrated promising results in a variety of tasks that combine vision and language. As these models become more integral to research and applications, conducting comprehensive evaluations of their capabilities has grown increasingly important.... | Fuwen Luo, Chi Chen, Zihao Wan, Zhaolu Kang, Qidong Yan, Yingjie Li, Xiaolong Wang, Siyu Wang, Ziyue Wang, Xiaoyue Mi, Peng Li, Ning Ma, Maosong Sun, Yang Liu |  |
| 693 |  |  [ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.574) |  | 0 | Human annotation is a time-consuming task that requires a significant amount of effort. To address this issue, interactive data annotation utilizes an annotation model to provide suggestions for humans to approve or correct. However, annotation models trained with limited labeled data are prone to... | Chen Huang, Yiping Jin, Ilija Ilievski, Wenqiang Lei, Jiancheng Lv |  |
| 694 |  |  [PolCLIP: A Unified Image-Text Word Sense Disambiguation Model via Generating Multimodal Complementary Representations](https://doi.org/10.18653/v1/2024.acl-long.575) |  | 0 | Word sense disambiguation (WSD) can be viewed as two subtasks: textual word sense disambiguation (Textual-WSD) and visual word sense disambiguation (Visual-WSD). They aim to identify the most semantically relevant senses or images to a given context containing ambiguous target words. However,... | Qihao Yang, Yong Li, Xuelin Wang, Fu Lee Wang, Tianyong Hao |  |
| 695 |  |  [Prompted Aspect Key Point Analysis for Quantitative Review Summarization](https://doi.org/10.18653/v1/2024.acl-long.576) |  | 0 | Key Point Analysis (KPA) aims for quantitative summarization that provides key points (KPs) as succinct textual summaries and quantities measuring their prevalence. KPA studies for arguments and reviews have been reported in the literature. A majority of KPA studies for reviews adopt supervised... | An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria |  |
| 696 |  |  [Ask Again, Then Fail: Large Language Models' Vacillations in Judgment](https://doi.org/10.18653/v1/2024.acl-long.577) |  | 0 | We observe that current large language models often waver in their judgments when faced with follow-up questions, even if the original judgment was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this... | Qiming Xie, Zengzhi Wang, Yi Feng, Rui Xia |  |
| 697 |  |  [CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.578) |  | 0 | Large language models (LLMs) are increasingly used to meet user information needs, but their effectiveness in dealing with user queries that contain various types of ambiguity remains unknown, ultimately risking user trust and satisfaction. To this end, we introduce CLAMBER, a benchmark for... | Tong Zhang, Peixin Qin, Yang Deng, Chen Huang, Wenqiang Lei, Junhong Liu, Dingnan Jin, Hongru Liang, TatSeng Chua |  |
| 698 |  |  [Multimodal Reasoning with Multimodal Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.579) |  | 0 | Multimodal reasoning with large language models (LLMs) often suffers from hallucinations and the presence of deficient or outdated knowledge within LLMs. Some approaches have sought to mitigate these issues by employing textual knowledge graphs, but their singular modality of knowledge limits... | Junlin Lee, Yequan Wang, Jing Li, Min Zhang |  |
| 699 |  |  [Confidence is not Timeless: Modeling Temporal Validity for Rule-based Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.acl-long.580) |  | 0 | Recently, Temporal Knowledge Graph Forecasting (TKGF) has emerged as a pivotal domain for forecasting future events. Unlike black-box neural network methods, rule-based approaches are lauded for their efficiency and interpretability. For this line of work, it is crucial to correctly estimate the... | Rikui Huang, Wei Wei, Xiaoye Qu, Shengzhe Zhang, Dangyang Chen, Yu Cheng |  |
| 700 |  |  [CARE: A Clue-guided Assistant for CSRs to Read User Manuals](https://doi.org/10.18653/v1/2024.acl-long.581) |  | 0 | It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don’t fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence,... | Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei |  |
| 701 |  |  [Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning Processes](https://doi.org/10.18653/v1/2024.acl-long.582) |  | 0 | Numerical reasoning is an essential ability for NLP systems to handle numeric information. Recent research indicates that fine-tuning a small-scale model to learn generating reasoning processes alongside answers can significantly enhance performance. However, current methods have the limitation... | Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che |  |
| 702 |  |  [PAGED: A Benchmark for Procedural Graphs Extraction from Documents](https://doi.org/10.18653/v1/2024.acl-long.583) |  | 0 | Automatic extraction of procedural graphs from documents creates a low-cost way for users to easily understand a complex procedure by skimming visual graphs. Despite the progress in recent studies, it remains unanswered: whether the existing studies have well solved this task (Q1) and whether the... | Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei |  |
| 703 |  |  [Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors](https://doi.org/10.18653/v1/2024.acl-long.584) |  | 0 | With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text... | Ying Zhou, Ben He, Le Sun |  |
| 704 |  |  [RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models](https://doi.org/10.18653/v1/2024.acl-long.585) |  | 0 | Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs). Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents. In order to develop effective hallucination... | Cheng Niu, Yuanhao Wu, Juno Zhu, Siliang Xu, Kashun Shum, Randy Zhong, Juntong Song, Tong Zhang |  |
| 705 |  |  [The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.586) |  | 0 | In the era of large language models (LLMs), hallucination (the tendency to generate factually incorrect content) poses great challenges to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the hallucination, three key questions should be well studied: how to detect... | Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Xin Zhao, JianYun Nie, JiRong Wen |  |
| 706 |  |  [Revisiting Knowledge Distillation for Autoregressive Language Models](https://doi.org/10.18653/v1/2024.acl-long.587) |  | 0 | Knowledge distillation (KD) is a common approach to compress a teacher model to reduce its inference cost and memory footprint, by training a smaller student model. However, in the context of autoregressive language models (LMs), we empirically find that larger teacher LMs might dramatically result... | Qihuang Zhong, Liang Ding, Li Shen, Juhua Liu, Bo Du, Dacheng Tao |  |
| 707 |  |  [Continual Learning with Semi-supervised Contrastive Distillation for Incremental Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.588) |  | 0 | Incrementally expanding the capability of an existing translation model to solve new domain tasks over time is a fundamental and practical problem, which usually suffers from catastrophic forgetting. Generally, multi-domain learning can be seen as a good solution. However, there are two drawbacks:... | Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 708 |  |  [Make-A-Voice: Revisiting Voice Large Language Models as Scalable Multilingual and Multitask Learners](https://doi.org/10.18653/v1/2024.acl-long.589) |  | 0 | Large language models (LLMs) have successfully served as a general-purpose interface across multiple tasks and languages, while the adaptation of voice LLMs is mostly designed for specific purposes (either single-task or monolingual), where the advantages of LLMs especially for low-resource... | Rongjie Huang, Chunlei Zhang, Yongqi Wang, Dongchao Yang, Jinchuan Tian, Zhenhui Ye, Luping Liu, Zehan Wang, Ziyue Jiang, Xuankai Chang, Jiatong Shi, Chao Weng, Zhou Zhao, Dong Yu |  |
| 709 |  |  [Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages](https://doi.org/10.18653/v1/2024.acl-long.590) |  | 0 | Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of chat vector to equip pre-trained language... | ShihCheng Huang, PinZu Li, YuChi Hsu, KuangMing Chen, YuTung Lin, ShihKai Hsiao, Richard TzongHan Tsai, Hungyi Lee |  |
| 710 |  |  [PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails](https://doi.org/10.18653/v1/2024.acl-long.591) |  | 0 | Large language models (LLMs) are typically aligned to be harmless to humans. Unfortunately, recent work has shown that such models are susceptible to automated jailbreak attacks that induce them to generate harmful content. More recent LLMs often incorporate an additional layer of defense, a Guard... | Neal Mangaokar, Ashish Hooda, Jihye Choi, Shreyas Chandrashekaran, Kassem Fawaz, Somesh Jha, Atul Prakash |  |
| 711 |  |  [Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLMs-Powered Assistance](https://doi.org/10.18653/v1/2024.acl-long.592) |  | 0 | Learning from noisy labels (LNL) is a challenge that arises in many real-world scenarios where collected training data can contain incorrect or corrupted labels. Most existing solutions identify noisy labels and adopt active learning to query human experts on them for denoising. In the era of large... | Bo Yuan, Yulin Chen, Yin Zhang, Wei Jiang |  |
| 712 |  |  [CLOMO: Counterfactual Logical Modification with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.593) |  | 0 | In this study, we delve into the realm of counterfactual reasoning capabilities of large language models (LLMs). Our primary objective is to cultivate the counterfactual thought processes within LLMs and rigorously assess these processes for their validity. Specifically, we introduce a novel task,... | Yinya Huang, Ruixin Hong, Hongming Zhang, Wei Shao, Zhicheng Yang, Dong Yu, Changshui Zhang, Xiaodan Liang, Linqi Song |  |
| 713 |  |  [Exploring Hybrid Question Answering via Program-based Prompting](https://doi.org/10.18653/v1/2024.acl-long.594) |  | 0 | Question answering over heterogeneous data requires reasoning over diverse sources of data, which is challenging due to the large scale of information and organic coupling of heterogeneous data. Various approaches have been proposed to address these challenges. One approach involves training... | Qi Shi, Han Cui, Haofeng Wang, Qingfu Zhu, Wanxiang Che, Ting Liu |  |
| 714 |  |  [IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages](https://doi.org/10.18653/v1/2024.acl-long.595) |  | 0 | As large language models (LLMs) see increasing adoption across the globe, it is imperative for LLMs to be representative of the linguistic diversity of the world. India is a linguistically diverse country of 1.4 Billion people. To facilitate research on multilingual LLM evaluation, we release... | Harman Singh, Nitish Gupta, Shikhar Bharadwaj, Dinesh Tewari, Partha Talukdar |  |
| 715 |  |  [Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.596) |  | 0 | Temporal knowledge graph completion aims to infer the missing facts in temporal knowledge graphs. Current approaches usually embed factual knowledge into continuous vector space and apply geometric operations to learn potential patterns in temporal knowledge graphs. However, these methods only... | Rui Ying, Mengting Hu, Jianfeng Wu, Yalan Xie, Xiaoyi Liu, Zhunheng Wang, Ming Jiang, Hang Gao, Linlin Zhang, Renhong Cheng |  |
| 716 |  |  [Uncertainty Aware Learning for Language Model Alignment](https://doi.org/10.18653/v1/2024.acl-long.597) |  | 0 | As instruction-tuned large language models (LLMs) evolve, aligning pretrained foundation models presents increasing challenges. Existing alignment strategies, which typically leverage diverse and high-quality data sources, often overlook the intrinsic uncertainty of tasks, learning all data samples... | Yikun Wang, Rui Zheng, Liang Ding, Qi Zhang, Dahua Lin, Dacheng Tao |  |
| 717 |  |  [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.598) |  | 0 | Accurate and interpretable user satisfaction estimation (USE) is critical for understanding, evaluating, and continuously improving conversational systems. Users express their satisfaction or dissatisfaction with diverse conversational patterns in both general-purpose (ChatGPT and Bing Copilot) and... | YingChun Lin, Jennifer Neville, Jack W. Stokes, Longqi Yang, Tara Safavi, Mengting Wan, Scott Counts, Siddharth Suri, Reid Andersen, Xiaofeng Xu, Deepak Gupta, Sujay Kumar Jauhar, Xia Song, Georg Buscher, Saurabh Tiwary, Brent J. Hecht, Jaime Teevan |  |
| 718 |  |  [Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey](https://doi.org/10.18653/v1/2024.acl-long.599) |  | 0 | Large Language Models (LLMs) demonstrate significant value in domain-specific applications, benefiting from their fundamental capabilities. Nevertheless, it is still unclear which fundamental capabilities contribute to success in specific domains. Moreover, the existing benchmark-based evaluation... | Jiawei Li, Yizhe Yang, Yu Bai, Xiaofeng Zhou, Yinghao Li, Huashan Sun, Yuhang Liu, Xingpeng Si, Yuhao Ye, Yixiao Wu, Yiguan Lin, Bin Xu, Ren Bowen, Chong Feng, Yang Gao, Heyan Huang |  |
| 719 |  |  [Measuring Political Bias in Large Language Models: What Is Said and How It Is Said](https://doi.org/10.18653/v1/2024.acl-long.600) |  | 0 | We propose to measure political bias in LLMs by analyzing both the content and style of their generated content regarding political issues. Existing benchmarks and measures focus on gender and racial biases. However, political bias exists in LLMs and can lead to polarization and other harms in... | Yejin Bang, Delong Chen, Nayeon Lee, Pascale Fung |  |
| 720 |  |  [Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use](https://doi.org/10.18653/v1/2024.acl-long.601) |  | 0 | In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in... | Yuhan Chen, Ang Lv, TingEn Lin, Changyu Chen, Yuchuan Wu, Fei Huang, Yongbin Li, Rui Yan |  |
| 721 |  |  [Layer-Condensed KV Cache for Efficient Inference of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.602) |  | 0 | Huge memory consumption has been a major bottleneck for deploying high-throughput large language models in real-world applications. In addition to the large number of parameters, the key-value (KV) cache for the attention mechanism in the transformer architecture consumes a significant amount of... | Haoyi Wu, Kewei Tu |  |
| 722 |  |  [Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages](https://doi.org/10.18653/v1/2024.acl-long.603) |  | 0 | While large language models (LLMs) have been pre-trained on multilingual corpora, their performance still lags behind in most languages compared to a few resource-rich languages. One common approach to mitigate this issue is to translate training data from resource-rich languages into other... | Yuanchi Zhang, Yile Wang, Zijun Liu, Shuo Wang, Xiaolong Wang, Peng Li, Maosong Sun, Yang Liu |  |
| 723 |  |  [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](https://doi.org/10.18653/v1/2024.acl-long.604) |  | 0 | We introduce CHARM, the first benchmark for comprehensively and in-depth evaluating the commonsense reasoning ability of large language models (LLMs) in Chinese, which covers both globally known and Chinese-specific commonsense. We evaluated 7 English and 12 Chinese-oriented LLMs on CHARM,... | Jiaxing Sun, Weiquan Huang, Jiang Wu, Chenya Gu, Wei Li, Songyang Zhang, Hang Yan, Conghui He |  |
| 724 |  |  [Browse and Concentrate: Comprehending Multimodal Content via Prior-LLM Context Fusion](https://doi.org/10.18653/v1/2024.acl-long.605) |  | 0 | With the bloom of Large Language Models (LLMs), Multimodal Large Language Models (MLLMs) that incorporate LLMs with pre-trained vision models have recently demonstrated impressive performance across diverse vision-language tasks. However, they fall short to comprehend context involving multiple... | Ziyue Wang, Chi Chen, Yiqi Zhu, Fuwen Luo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu |  |
| 725 |  |  [Model Composition for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.606) |  | 0 | Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is... | Chi Chen, Yiyang Du, Zheng Fang, Ziyue Wang, Fuwen Luo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu |  |
| 726 |  |  [Draft& Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.607) |  | 0 | We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower... | Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Sharad Mehrotra |  |
| 727 |  |  [Soul-Mix: Enhancing Multimodal Machine Translation with Manifold Mixup](https://doi.org/10.18653/v1/2024.acl-long.608) |  | 0 | Multimodal machine translation (MMT) aims to improve the performance of machine translation with the help of visual information, which has received widespread attention recently. It has been verified that visual information brings greater performance gains when the textual information is limited.... | Xuxin Cheng, Ziyu Yao, Yifei Xin, Hao An, Hongxiang Li, Yaowei Li, Yuexian Zou |  |
| 728 |  |  [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.609) |  | 0 | The process of meaning composition, wherein smaller units like morphemes or words combine to form the meaning of phrases and sentences, is essential for human sentence comprehension. Despite extensive neurolinguistic research into the brain regions involved in meaning composition, a computational... | Changjiang Gao, Jixing Li, Jiajun Chen, Shujian Huang |  |
| 729 |  |  [MIST: Mutual Information Maximization for Short Text Clustering](https://doi.org/10.18653/v1/2024.acl-long.610) |  | 0 | Short text clustering poses substantial challenges due to the limited amount of information provided by each text sample. Previous efforts based on dense representations are still inadequate as texts are not sufficiently segregated in the embedding space before clustering. Even though the... | Krissanee Kamthawee, Can Udomcharoenchaikit, Sarana Nutanong |  |
| 730 |  |  [Self-chats from Large Language Models Make Small Emotional Support Chatbot Better](https://doi.org/10.18653/v1/2024.acl-long.611) |  | 0 | Large Language Models (LLMs) have shown strong generalization abilities to excel in various tasks, including emotion support conversations. However, deploying such LLMs like GPT-3 (175B parameters) is resource-intensive and challenging at scale. In this study, we utilize LLMs as “Counseling... | Zhonghua Zheng, Lizi Liao, Yang Deng, Libo Qin, Liqiang Nie |  |
| 731 |  |  [Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment](https://doi.org/10.18653/v1/2024.acl-long.612) |  | 0 | The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced techniques such as instruction tuning and reinforcement... | Janghwan Lee, Seongmin Park, Sukjin Hong, Minsoo Kim, DuSeong Chang, Jungwook Choi |  |
| 732 |  |  [Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.613) |  | 0 | Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit contextunderlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense infer-ences for contexts and questions... | Tianqing Fang, Zeming Chen, Yangqiu Song, Antoine Bosselut |  |
| 733 |  |  [An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing](https://doi.org/10.18653/v1/2024.acl-long.614) |  | 0 | We present Expert-Token-Routing, a unified generalist framework that facilitates seamless integration of multiple expert LLMs. Our framework represents expert LLMs as special expert tokens within the vocabulary of a meta LLM. The meta LLM can route to an expert LLM like generating new tokens.... | Ziwei Chai, Guoyin Wang, Jing Su, Tianjie Zhang, Xuanwen Huang, Xuwu Wang, Jingjing Xu, Jianbo Yuan, Hongxia Yang, Fei Wu, Yang Yang |  |
| 734 |  |  [Learning to Plan and Generate Text with Citations](https://doi.org/10.18653/v1/2024.acl-long.615) |  | 0 | The increasing demand for the deployment of LLMs in information-seeking scenarios has spurred efforts in creating verifiable systems, which generate responses to queries along with supporting evidence. In this paper, we explore the attribution capabilities of plan-based models which have been... | Constanza Fierro, Reinald Kim Amplayo, Fantine Huot, Nicola De Cao, Joshua Maynez, Shashi Narayan, Mirella Lapata |  |
| 735 |  |  [Exploring Precision and Recall to assess the quality and diversity of LLMs](https://doi.org/10.18653/v1/2024.acl-long.616) |  | 0 | We introduce a novel evaluation framework for Large Language Models (LLMs) such as Llama-2 and Mistral, focusing on importing Precision and Recall metrics from image generation to text generation. This approach allows for a nuanced assessment of the quality and diversity of generated text without... | Florian Le Bronnec, Alexandre Verine, Benjamin Négrevergne, Yann Chevaleyre, Alexandre Allauzen |  |
| 736 |  |  [Aligning Large Language Models by On-Policy Self-Judgment](https://doi.org/10.18653/v1/2024.acl-long.617) |  | 0 | Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, SELF-JUDGE that (1) does on-policy learning and 2) is parameter efficient, as it... | Sangkyu Lee, Sungdong Kim, Ashkan Yousefpour, Minjoon Seo, Kang Min Yoo, Youngjae Yu |  |
| 737 |  |  [IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning](https://doi.org/10.18653/v1/2024.acl-long.618) |  | 0 | Legal systems worldwide are inundated with exponential growth in cases and documents. There is an imminent need to develop NLP and ML techniques for automatically processing and understanding legal documents to streamline the legal system. However, evaluating and comparing various NLP models... | Abhinav Joshi, Shounak Paul, Akshat Sharma, Pawan Goyal, Saptarshi Ghosh, Ashutosh Modi |  |
| 738 |  |  [JumpCoder: Go Beyond Autoregressive Coder via Online Modification](https://doi.org/10.18653/v1/2024.acl-long.619) |  | 0 | While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often... | Mouxiang Chen, Hao Tian, Zhongxin Liu, Xiaoxue Ren, Jianling Sun |  |
| 739 |  |  [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.620) |  | 0 | Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the fine-tuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to... | Shivalika Singh, Freddie Vargus, Daniel D'souza, Börje Karlsson, Abinaya Mahendiran, WeiYin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura O'Mahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzeminski, Hakimeh Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Minh Vu Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet Üstün, Marzieh Fadaee, Sara Hooker |  |
| 740 |  |  [Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks](https://doi.org/10.18653/v1/2024.acl-long.621) |  | 0 | Large Language Models (LLMs) have transformed NLP with their remarkable In-context Learning (ICL) capabilities. Automated assistants based on LLMs are gaining popularity; however, adapting them to novel tasks is still challenging. While colossal models excel in zero-shot performance, their... | Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty |  |
| 741 |  |  [Split and Rephrase with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.622) |  | 0 | The Split and Rephrase (SPRP) task, which consists in splitting complex sentences into a sequence of shorter grammatical sentences, while preserving the original meaning, can facilitate the processing of complex texts for humans and machines alike. It is also a valuable testbed to evaluate natural... | David Ponce, Thierry Etchegoyhen, Jesus Calleja, Harritxu Gete |  |
| 742 |  |  [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://doi.org/10.18653/v1/2024.acl-long.623) |  | 0 | Self-attention is an essential component of large language models (LLM) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM... | Lu Ye, Ze Tao, Yong Huang, Yang Li |  |
| 743 |  |  [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.624) |  | 0 | Alignment has become a critical step for instruction-tuned Large Language Models (LLMs) to become helpful assistants. However, effective evaluation of alignment for emerging Chinese LLMs is still significantly lacking, calling for real-scenario grounded, open-ended, challenging and automatic... | Xiao Liu, Xuanyu Lei, Shengyuan Wang, Yue Huang, Andrew Feng, Bosi Wen, Jiale Cheng, Pei Ke, Yifan Xu, Weng Lam Tam, Xiaohan Zhang, Lichao Sun, Xiaotao Gu, Hongning Wang, Jing Zhang, Minlie Huang, Yuxiao Dong, Jie Tang |  |
| 744 |  |  [SAPT: A Shared Attention Framework for Parameter-Efficient Continual Learning of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.625) |  | 0 | The continual learning (CL) ability is vital for deploying large language models (LLMs) in the dynamic world. Existing methods devise the learning module to acquire task-specific knowledge with parameter-efficient tuning (PET) block and the selection module to pick out the corresponding one for the... | Weixiang Zhao, Shilong Wang, Yulin Hu, Yanyan Zhao, Bing Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che |  |
| 745 |  |  [DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution](https://doi.org/10.18653/v1/2024.acl-long.626) |  | 0 | Fine-tuning large-scale pre-trained models is inherently a resource-intensive task. While it can enhance the capabilities of the model, it also incurs substantial computational costs, posing challenges to the practical application of downstream tasks. Existing parameter-efficient fine-tuning (PEFT)... | Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu |  |
| 746 |  |  [Cross-Lingual Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.627) |  | 0 | Knowledge editing aims to change language models’ performance on several special cases (i.e., editing scope) by infusing the corresponding expected knowledge into them. With the recent advancements in large language models (LLMs), knowledge editing has been shown as a promising technique to adapt... | Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, Jiarong Xu, Fandong Meng |  |
| 747 |  |  [Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques](https://doi.org/10.18653/v1/2024.acl-long.628) |  | 0 | Recent research on sequence labelling has been exploring different strategies to mitigate the lack of manually annotated data for the large majority of the world languages. Among others, the most successful approaches have been based on (i) the crosslingual transfer capabilities of multilingual... | Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri |  |
| 748 |  |  [Learning Task Decomposition to Assist Humans in Competitive Programming](https://doi.org/10.18653/v1/2024.acl-long.629) |  | 0 | When using language models (LMs) to solve complex problems, humans might struggle to understand the LM-generated solutions and repair the flawed ones. To assist humans in repairing them, we propose to automatically decompose complex solutions into multiple simpler pieces that correspond to specific... | Jiaxin Wen, Ruiqi Zhong, Pei Ke, Zhihong Shao, Hongning Wang, Minlie Huang |  |
| 749 |  |  [An Entropy-based Text Watermarking Detection Method](https://doi.org/10.18653/v1/2024.acl-long.630) |  | 0 | Text watermarking algorithms for large language models (LLMs) can effectively identify machine-generated texts by embedding and detecting hidden features in the text. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy... | Yijian Lu, Aiwei Liu, Dianzhi Yu, Jingjing Li, Irwin King |  |
| 750 |  |  [Enhancing Explainable Rating Prediction through Annotated Macro Concepts](https://doi.org/10.18653/v1/2024.acl-long.631) |  | 0 | Generating recommendation reasons for recommendation results is a long-standing problem because it is challenging to explain the underlying reasons for recommending an item based on user and item IDs. Existing models usually learn semantic embeddings for each user and item, and generate the reasons... | Huachi Zhou, Shuang Zhou, Hao Chen, Ninghao Liu, Fan Yang, Xiao Huang |  |
| 751 |  |  [How to Engage your Readers? Generating Guiding Questions to Promote Active Reading](https://doi.org/10.18653/v1/2024.acl-long.632) |  | 0 | Using questions in written text is an effective strategy to enhance readability. However, what makes an active reading question good, what the linguistic role of these questions is, and what is their impact on human reading remains understudied. We introduce GuidingQ, a dataset of 10K in-text... | Peng Cui, Vilém Zouhar, Xiaoyu Zhang, Mrinmaya Sachan |  |
| 752 |  |  [Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective](https://doi.org/10.18653/v1/2024.acl-long.633) |  | 0 | Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model’s ability to timely terminate generation,... | Zihao Yue, Liang Zhang, Qin Jin |  |
| 753 |  |  [Integrate the Essence and Eliminate the Dross: Fine-Grained Self-Consistency for Free-Form Language Generation](https://doi.org/10.18653/v1/2024.acl-long.634) |  | 0 | Self-consistency (SC), leveraging multiple samples from LLMs, shows significant gains on various reasoning tasks but struggles with free-form generation due to the difficulty of aggregating answers. Its variants, UCS and USC, rely on sample selection or voting mechanisms to improve output quality.... | Xinglin Wang, Yiwei Li, Shaoxiong Feng, Peiwen Yuan, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 754 |  |  [More frequent verbs are associated with more diverse valency frames: Efficient principles at the lexicon-grammar interface](https://doi.org/10.18653/v1/2024.acl-long.635) |  | 0 | A substantial body of work has provided evidence that the lexicons of natural languages are organized to support efficient communication. However, existing work has largely focused on word-internal properties, such as Zipf’s observation that more frequent words are optimized in form to minimize... | Siyu Tao, Lucia Donatelli, Michael Hahn |  |
| 755 |  |  [Quantifying Generalizations: Exploring the Divide Between Human and LLMs' Sensitivity to Quantification](https://doi.org/10.18653/v1/2024.acl-long.636) |  | 0 | Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., “Birds fly”), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the... | Claudia Collacciani, Giulia Rambelli, Marianna Bolognesi |  |
| 756 |  |  [Can Large Language Models Interpret Noun-Noun Compounds? A Linguistically-Motivated Study on Lexicalized and Novel Compounds](https://doi.org/10.18653/v1/2024.acl-long.637) |  | 0 | Noun-noun compounds interpretation is the task where a model is given one of such constructions, and it is asked to provide a paraphrase, making the semantic relation between the nouns explicit, as in carrot cake is “a cake made of carrots.” Such a task requires the ability to understand the... | Giulia Rambelli, Emmanuele Chersoni, Claudia Collacciani, Marianna Bolognesi |  |
| 757 |  |  [CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation](https://doi.org/10.18653/v1/2024.acl-long.638) |  | 0 | Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in... | Quan Tu, Shilong Fan, Zihang Tian, Tianhao Shen, Shuo Shang, Xin Gao, Rui Yan |  |
| 758 |  |  [Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond](https://doi.org/10.18653/v1/2024.acl-long.639) |  | 0 | The recent advancements in generative language models have demonstrated their ability to memorize knowledge from documents and recall knowledge to respond to user queries effectively. Building upon this capability, we propose to enable multimodal large language models (MLLMs) to memorize and recall... | Yongqi Li, Wenjie Wang, Leigang Qu, Liqiang Nie, Wenjie Li, TatSeng Chua |  |
| 759 |  |  [Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.640) |  | 0 | Aspect Sentiment Quad Prediction (ASQP) aims to predict all quads (aspect term, aspect category, opinion term, sentiment polarity) for a given review, which is the most representative and challenging task in aspect-based sentiment analysis. A key challenge in the ASQP task is the scarcity of... | Yice Zhang, Jie Zeng, Weiming Hu, Ziyi Wang, Shiwei Chen, Ruifeng Xu |  |
| 760 |  |  [Learning to Generate Answers with Citations via Factual Consistency Models](https://doi.org/10.18653/v1/2024.acl-long.641) |  | 0 | Large Language Models (LLMs) frequently hallucinate, impeding their reliability in mission-critical situations. One approach to address this issue is to provide citations to relevant sources alongside generated content, enhancing the verifiability of generations. However, citing passages accurately... | Rami Aly, Zhiqiang Tang, Samson Tan, George Karypis |  |
| 761 |  |  [Improving Text Embeddings with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.642) |  | 0 | In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by... | Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, Furu Wei |  |
| 762 |  |  [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.643) |  | 0 | Teaching small-scale language models to perform math reasoning is a valuable yet challenging task. Besides obtaining labeled data from human experts, one of the most common ways to collect high-quality data is by sampling from a larger and more powerful language model. Although previous works have... | Tianduo Wang, Shichen Li, Wei Lu |  |
| 763 |  |  [UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset](https://doi.org/10.18653/v1/2024.acl-long.644) |  | 0 | Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual abilities.In this work, we therefore construct an open-source... | Haoyu Wang, Shuo Wang, Yukun Yan, Xujia Wang, Zhiyu Yang, Yuzhuang Xu, Zhenghao Liu, Liner Yang, Ning Ding, Xu Han, Zhiyuan Liu, Maosong Sun |  |
| 764 |  |  [Document-level Claim Extraction and Decontextualisation for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.645) |  | 0 | Selecting which claims to check is a time-consuming task for human fact-checkers, especially from documents consisting of multiple sentences and containing multiple claims. However, existing claim extraction approaches focus more on identifying and extracting claims from individual sentences, e.g.,... | Zhenyun Deng, Michael Sejr Schlichtkrull, Andreas Vlachos |  |
| 765 |  |  [PairCFR: Enhancing Model Training on Paired Counterfactually Augmented Data through Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.646) |  | 0 | Counterfactually Augmented Data (CAD) involves creating new data samples by applying minimal yet sufficient modifications to flip the label of existing data samples to other classes. Training with CAD enhances model robustness against spurious features that happen to correlate with labels by... | Xiaoqi Qiu, Yongjie Wang, Xu Guo, Zhiwei Zeng, Yu Yue, Yuhong Feng, Chunyan Miao |  |
| 766 |  |  [LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.647) |  | 0 | In this study, we explore in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting tailored for the EAE task. Specifically, we hypothesize... | Hanzhang Zhou, Junlang Qian, Zijian Feng, Hui Lu, Zixiao Zhu, Kezhi Mao |  |
| 767 |  |  [Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.648) |  | 0 | Though advanced in understanding visual information with human languages, Large Vision-Language Models (LVLMs) still suffer from multimodal hallucinations. A natural concern is that during multimodal interaction, the generated hallucinations could influence the LVLMs’ subsequent generation. Thus,... | Weihong Zhong, Xiaocheng Feng, Liang Zhao, Qiming Li, Lei Huang, Yuxuan Gu, Weitao Ma, Yuan Xu, Bing Qin |  |
| 768 |  |  [mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models](https://doi.org/10.18653/v1/2024.acl-long.649) |  | 0 | Large language models (LLMs) with Chain-of-thought (CoT) have recently emerged as a powerful technique for eliciting reasoning to improve various downstream tasks. As most research mainly focuses on English, with few explorations in a multilingual context, the question of how reliable this... | Huiyuan Lai, Malvina Nissim |  |
| 769 |  |  [GunStance: Stance Detection for Gun Control and Gun Regulation](https://doi.org/10.18653/v1/2024.acl-long.650) |  | 0 | The debate surrounding gun control and gun regulation in the United States has intensified in the wake of numerous mass shooting events. As perspectives on this matter vary, it becomes increasingly important to comprehend individuals’ positions. Stance detection, the task of determining an author’s... | Nikesh Gyawali, Iustin Sirbu, Tiberiu Sosea, Sarthak Khanal, Doina Caragea, Traian Rebedea, Cornelia Caragea |  |
| 770 |  |  [Beyond Traditional Benchmarks: Analyzing Behaviors of Open LLMs on Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.651) |  | 0 | We analyze the behaviors of open large language models (LLMs) on the task of data-to-text (D2T) generation, i.e., generating coherent and relevant text from structured data. To avoid the issue of LLM training data contamination with standard benchmarks, we design Quintd - a tool for collecting... | Zdenek Kasner, Ondrej Dusek |  |
| 771 |  |  [Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.acl-long.652) |  | 0 | The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue... | Min Zhang, Jianfeng He, Taoran Ji, ChangTien Lu |  |
| 772 |  |  [Don't Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation](https://doi.org/10.18653/v1/2024.acl-long.653) |  | 0 | Neural machine translation systems estimate probabilities of target sentences given source sentences, yet these estimates may not align with human preferences. This work introduces QE-fusion, a method that synthesizes translations using a quality estimation metric (QE), which correlates better with... | Giorgos Vernikos, Andrei PopescuBelis |  |
| 773 |  |  [Generating and Evaluating Plausible Explanations for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.654) |  | 0 | Explanations for AI should aid human users, yet this ultimate goal remains under-explored. This paper aims to bridge this gap by investigating the specific explanatory needs of human users in the context of Knowledge Graph Completion (KGC) systems. In contrast to the prevailing approaches that... | Antonio Di Mauro, Zhao Xu, Wiem Ben Rim, Timo Sztyler, Carolin Lawrence |  |
| 774 |  |  [One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation](https://doi.org/10.18653/v1/2024.acl-long.655) |  | 0 | Evaluation of opinion summaries using conventional reference-based metrics often fails to provide a comprehensive assessment and exhibits limited correlation with human judgments. While Large Language Models (LLMs) have shown promise as reference-free metrics for NLG evaluation, their potential... | Tejpalsingh Siledar, Swaroop Nath, Sankara Sri Raghava Ravindra Muddu, Rupasai Rangaraju, Swaprava Nath, Pushpak Bhattacharyya, Suman Banerjee, Amey Patil, Sudhanshu Singh, Muthusamy Chelliah, Nikesh Garera |  |
| 775 |  |  [LANDeRMT: Dectecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.656) |  | 0 | Recent advancements in large language models (LLMs) have shown promising results in multilingual translation even with limited bilingual supervision. The major challenges are catastrophic forgetting and parameter interference for finetuning LLMs when provided parallel training data. To address... | Shaolin Zhu, Leiyu Pan, Bo Li, Deyi Xiong |  |
| 776 |  |  [A Joint Coreference-Aware Approach to Document-Level Target Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.657) |  | 0 | Most existing work on aspect-based sentiment analysis (ABSA) focuses on the sentence level, while research at the document level has not received enough attention. Compared to sentence-level ABSA, the document-level ABSA is not only more practical but also requires holistic document-level... | Hongjie Cai, Heqing Ma, Jianfei Yu, Rui Xia |  |
| 777 |  |  [VisDiaHalBench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.658) |  | 0 | Despite the significant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hallucination problem, where the LVLMs’ response contains descriptions of non-existent objects. Although various benchmarks have been proposed to investigate this problem,... | Qingxing Cao, Junhao Cheng, Xiaodan Liang, Liang Lin |  |
| 778 |  |  [AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints](https://doi.org/10.18653/v1/2024.acl-long.659) |  | 0 | Accurate representation of procedures in restricted scenarios, such as non-standardized scientific experiments, requires precise depiction of constraints. Unfortunately, Domain-specific Language (DSL), as an effective tool to express constraints structurally, often requires case-by-case... | YuZhe Shi, Haofei Hou, Zhangqian Bi, Fanxu Meng, Xiang Wei, Lecheng Ruan, Qining Wang |  |
| 779 |  |  [Multipath parsing in the brain](https://doi.org/10.18653/v1/2024.acl-long.660) |  | 0 | Humans understand sentences word-by-word, in the order that they hear them. This incrementality entails resolving temporary ambiguities about syntactic relationships. We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency... | Berta Franzluebbers, Donald Dunagan, Milos Stanojevic, Jan Buys, John T. Hale |  |
| 780 |  |  [Search-Adaptor: Embedding Customization for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.661) |  | 0 | Embeddings extracted by pre-trained Large Language Models (LLMs) have significant potential to improve information retrieval and search. Beyond the zero-shot setup in which they are being conventionally used, being able to take advantage of the information from the relevant query-corpus paired data... | Jinsung Yoon, Yanfei Chen, Sercan Ö. Arik, Tomas Pfister |  |
| 781 |  |  [Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs](https://doi.org/10.18653/v1/2024.acl-long.662) |  | 0 | AI alignment in the shape of Reinforcement Learning from Human Feedback (RLHF) is increasingly treated as a crucial ingredient for high performance large language models. Proximal Policy Optimization (PPO) has been installed by the seminal literature as the standard method for the RL part of RLHF.... | Arash Ahmadian, Chris Cremer, Matthias Gallé, Marzieh Fadaee, Julia Kreutzer, Olivier Pietquin, Ahmet Üstün, Sara Hooker |  |
| 782 |  |  [VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation](https://doi.org/10.18653/v1/2024.acl-long.663) |  | 0 | In the rapidly advancing field of conditional image generation research, challenges such as limited explainability lie in effectively evaluating the performance and capabilities of various models. This paper introduces VIEScore, a Visual Instruction-guided Explainable metric for evaluating any... | Max Ku, Dongfu Jiang, Cong Wei, Xiang Yue, Wenhu Chen |  |
| 783 |  |  [Tree Transformer's Disambiguation Ability of Prepositional Phrase Attachment and Garden Path Effects](https://doi.org/10.18653/v1/2024.acl-long.664) |  | 0 | This work studies two types of ambiguity in natural language: prepositional phrase (PP) attachment ambiguity, and garden path constructions. Due to the different nature of these ambiguities – one being structural, the other incremental in nature – we pretrain and evaluate the Tree Transformer of... | Lingling Zhou, Suzan Verberne, Gijs Wijnholds |  |
| 784 |  |  [Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.665) |  | 0 | Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot... | Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, KaiWei Chang, Aram Galstyan |  |
| 785 |  |  [Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.666) |  | 0 | We present the structured average intersection-over-union ratio (STRUCT-IOU), an evaluation metric that compares a constituency parse tree over automatically recognized spoken word boundaries with the ground-truth parse tree over written words. To compute the metric, we (1) project the ground-truth... | Freda Shi, Kevin Gimpel, Karen Livescu |  |
| 786 |  |  [ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.667) |  | 0 | Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap,... | Akshita Jha, Vinodkumar Prabhakaran, Remi Denton, Sarah Laszlo, Shachi Dave, Rida Qadri, Chandan K. Reddy, Sunipa Dev |  |
| 787 |  |  [Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking](https://doi.org/10.18653/v1/2024.acl-long.668) |  | 0 | This paper proposes PiNose, which trains a probing model on offline self-consistency checking results, thereby circumventing the need for human-annotated data and achieving transferability across diverse data distributions. As the consistency check process is offline, PiNose reduces the... | Xiaokang Zhang, Zijun Yao, Jing Zhang, Kaifeng Yun, Jifan Yu, Juanzi Li, Jie Tang |  |
| 788 |  |  [What Do Language Models Learn in Context? The Structured Task Hypothesis](https://doi.org/10.18653/v1/2024.acl-long.669) |  | 0 | Large language models (LLMs) exhibit an intriguing ability to learn a novel task from in-context examples presented in a demonstration, termed in-context learning (ICL). Understandably, a swath of research has been dedicated to uncovering the theories underpinning ICL. One popular hypothesis... | Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell |  |
| 789 |  |  [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://doi.org/10.18653/v1/2024.acl-long.670) |  | 0 | Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce Lumos, one of the first frameworks for training open-source... | Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Raghavi Chandu, KaiWei Chang, Yejin Choi, Bill Yuchen Lin |  |
| 790 |  |  [Investigating Cultural Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.671) |  | 0 | The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the... | Badr AlKhamissi, Muhammad N. ElNokrashy, Mai Alkhamissi, Mona T. Diab |  |
| 791 |  |  [More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play](https://doi.org/10.18653/v1/2024.acl-long.672) |  | 0 | The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy AI, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics,... | Wichayaporn Wongkamjan, Feng Gu, Yanze Wang, Ulf Hermjakob, Jonathan May, Brandon M. Stewart, Jonathan K. Kummerfeld, Denis Peskoff, Jordan L. BoydGraber |  |
| 792 |  |  [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://doi.org/10.18653/v1/2024.acl-long.673) |  | 0 | We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token... | Puyuan Peng, PoYao Huang, ShangWen Li, Abdelrahman Mohamed, David Harwath |  |
| 793 |  |  [RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors](https://doi.org/10.18653/v1/2024.acl-long.674) |  | 0 | Many commercial and open-source models claim to detect machine-generated text with extremely high accuracy (99% or more). However, very few of these detectors are evaluated on shared benchmark datasets and even when they are, the datasets used for evaluation are insufficiently challenging—lacking... | Liam Dugan, Alyssa Hwang, Filip Trhlík, Andrew Zhu, Josh Magnus Ludan, Hainiu Xu, Daphne Ippolito, Chris CallisonBurch |  |
| 794 |  |  [Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles](https://doi.org/10.18653/v1/2024.acl-long.675) |  | 0 | A dog whistle is a form of coded communication that carries a secondary meaning to specific audiences and is often weaponized for racial and socioeconomic discrimination. Dog whistling historically originated from United States politics, but in recent years has taken root in social media as a means... | Julia Kruk, Michela Marchini, Rijul Magu, Caleb Ziems, David Muchlinski, Diyi Yang |  |
| 795 |  |  [On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.676) |  | 0 | The performance of modern language models (LMs) has been improved by chain-of-thought (CoT) reasoning, i.e., the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that CoT reasoning extends an LM’s computational... | Franz Nowak, Anej Svete, Alexandra Butoi, Ryan Cotterell |  |
| 796 |  |  [Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends](https://doi.org/10.18653/v1/2024.acl-long.677) |  | 0 | Recent advancements in large language models (LLMs) have significantly advanced the capabilities of summarization systems.However, they continue to face a persistent challenge: hallucination. While prior work has extensively examined LLMs in news domains, evaluation of dialogue summarization has... | Sanjana Ramprasad, Elisa Ferracane, Zachary C. Lipton |  |
| 797 |  |  [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://doi.org/10.18653/v1/2024.acl-long.678) |  | 0 | Large language models (LLMs) are central to modern natural language processing, delivering exceptional performance in various tasks. However, their substantial computational and memory requirements present challenges, especially for devices with limited DRAM capacity. This paper tackles the... | Keivan Alizadeh, Iman Mirzadeh, Dmitry Belenko, S. Khatamifard, Minsik Cho, Mohammad Rastegari, Mehrdad Farajtabar |  |
| 798 |  |  [Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models](https://doi.org/10.18653/v1/2024.acl-long.679) |  | 0 | Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the under-explored field of video-based conversation by introducing Video-ChatGPT. It is a... | Muhammad Maaz, Hanoona Abdul Rasheed, Salman Khan, Fahad Khan |  |
| 799 |  |  [To Distill or Not to Distill? On the Robustness of Robust Knowledge Distillation](https://doi.org/10.18653/v1/2024.acl-long.680) |  | 0 | Arabic is known to present unique challengesfor Automatic Speech Recognition (ASR). Onone hand, its rich linguistic diversity andwide range of dialects complicate the de-velopment of robust, inclusive models. Onthe other, current multilingual ASR modelsare compute-intensive and lack proper... | Abdul Waheed, Karima Kadaoui, Muhammad AbdulMageed |  |
| 800 |  |  [LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.681) |  | 0 | We present LayerSkip, an end-to-end solution to speed-up inference of large language models (LLMs). First, during training we apply layer dropout, with low dropout rates for earlier layers and higher dropout rates for later layers, and an early exit loss where all transformer layers share the same... | Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, Ahmed A Aly, Beidi Chen, CaroleJean Wu |  |
| 801 |  |  [Classist Tools: Social Class Correlates with Performance in NLP](https://doi.org/10.18653/v1/2024.acl-long.682) |  | 0 | The field of sociolinguistics has studied factors affecting language use for the last century. Labov (1964) and Bernstein (1960) showed that socioeconomic class strongly influences our accents, syntax and lexicon. However, despite growing concerns surrounding fairness and bias in Natural Language... | Amanda Cercas Curry, Giuseppe Attanasio, Zeerak Talat, Dirk Hovy |  |
| 802 |  |  [ActionIE: Action Extraction from Scientific Literature with Programming Languages](https://doi.org/10.18653/v1/2024.acl-long.683) |  | 0 | Extraction of experimental procedures from human language in scientific literature and patents into actionable sequences in robotics language holds immense significance in scientific domains. Such an action extraction task is particularly challenging given the intricate details and... | Xianrui Zhong, Yufeng Du, Siru Ouyang, Ming Zhong, Tingfeng Luo, Qirong Ho, Hao Peng, Heng Ji, Jiawei Han |  |
| 803 |  |  [A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech](https://doi.org/10.18653/v1/2024.acl-long.684) |  | 0 | Violence-provoking speech – speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of... | Gaurav Verma, Rynaa Grover, Jiawei Zhou, Binny Mathew, Jordan Kraemer, Munmun De Choudhury, Srijan Kumar |  |
| 804 |  |  [Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs](https://doi.org/10.18653/v1/2024.acl-long.685) |  | 0 | The growing popularity of Large Language Models has sparked interest in context compression for Large Language Models (LLMs). However, the performance of previous methods degrades dramatically as compression ratios increase, sometimes even falling to the closed-book level. This decline can be... | Zhiwei Cao, Qian Cao, Yu Lu, Ningxin Peng, Luyang Huang, Shanbo Cheng, Jinsong Su |  |
| 805 |  |  [COSMIC: Mutual Information for Task-Agnostic Summarization Evaluation](https://doi.org/10.18653/v1/2024.acl-long.686) |  | 0 | Assessing the quality of summarizers poses significant challenges—gold summaries are hard to obtain and their suitability depends on the use context of the summarization system. Who is the user of the system, and what do they intend to do with the summary? In response, we propose a novel... | Maxime Darrin, Philippe Formont, Jackie Chi Kit Cheung, Pablo Piantanida |  |
| 806 |  |  [EUROPA: A Legal Multilingual Keyphrase Generation Dataset](https://doi.org/10.18653/v1/2024.acl-long.687) |  | 0 | Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a novel dataset for multilingual keyphrase generation in the legal domain. It is derived from... | Olivier Salaün, Frédéric Piedboeuf, Guillaume Le Berre, David AlfonsoHermelo, Philippe Langlais |  |
| 807 |  |  [GLIMPSE: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews](https://doi.org/10.18653/v1/2024.acl-long.688) |  | 0 | Scientific peer review is essential for the quality of academic publications. However, the increasing number of paper submissions to conferences has strained the reviewing process. This surge poses a burden on area chairs who have to carefully read an ever-growing volume of reviews and discern each... | Maxime Darrin, Ines Arous, Pablo Piantanida, Jackie Chi Kit Cheung |  |
| 808 |  |  [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](https://doi.org/10.18653/v1/2024.acl-long.689) |  | 0 | Multimodal large language models (MLLMs) have proven effective in a wide range of tasks that require complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, the success of MLLMs remains relatively limited to... | Fakhraddin Alwajih, El Moatez Billah Nagoudi, Gagan Bhatia, Abdelrahman Mohamed, Muhammad AbdulMageed |  |
| 809 |  |  [Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks](https://doi.org/10.18653/v1/2024.acl-long.690) |  | 0 | Multistep instructions, such as recipes and how-to guides, greatly benefit from visual aids, such as a series of images that accompany the instruction steps. While Large Language Models (LLMs) have become adept at generating coherent textual steps, Large Vision/Language Models (LVLMs) are less... | João Bordalo, Vasco Ramos, Rodrigo Valerio, Diogo GlóriaSilva, Yonatan Bitton, Michal Yarom, Idan Szpektor, João Magalhães |  |
| 810 |  |  [Cheetah: Natural Language Generation for 517 African Languages](https://doi.org/10.18653/v1/2024.acl-long.691) |  | 0 | Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language... | Ife Adebara, AbdelRahim A. Elmadany, Muhammad AbdulMageed |  |
| 811 |  |  [TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table QA by Content Planning and Execution-based Reasoning](https://doi.org/10.18653/v1/2024.acl-long.692) |  | 0 | Long-form Table Question Answering (LFTQA) requires systems to generate paragraph long and complex answers to questions over tabular data. While Large language models based systems have made significant progress, it often hallucinates, especially when the task involves complex reasoning over... | Yilun Zhao, Lyuhao Chen, Arman Cohan, Chen Zhao |  |
| 812 |  |  [KnowledgeFMath: A Knowledge-Intensive Math Reasoning Dataset in Finance Domains](https://doi.org/10.18653/v1/2024.acl-long.693) |  | 0 | We introduce FinanceMath, a novel benchmark designed to evaluate LLMs' capabilities in solving knowledge-intensive math reasoning problems. Compared to prior works, this study features three core advancements. First, FinanceMath includes 1,200 problems with a hybrid of textual and tabular content.... | Yilun Zhao, Hongjun Liu, Yitao Long, Rui Zhang, Chen Zhao, Arman Cohan |  |
| 813 |  |  [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://doi.org/10.18653/v1/2024.acl-long.694) |  | 0 | There is a growing need for Large Language Models (LLMs) to effectively use tools and external Application Programming Interfaces (APIs) to plan and complete tasks. As such, there is tremendous interest in methods that can acquire sufficient quantities of train and test data that involve calls to... | Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, Maxwell Crouse, Asim Munawar, Vernon Austel, Sadhana Kumaravel, Vinod Muthusamy, Pavan Kapanipathi, Luis A. Lastras |  |
| 814 |  |  [LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks](https://doi.org/10.18653/v1/2024.acl-long.695) |  | 0 | LoRA employs lightweight modules to customize large language models (LLMs) for each downstream task or domain, where different learned additional modules represent diverse skills. Combining existing LoRAs to address new tasks can enhance the reusability of learned LoRAs, particularly beneficial for... | Hanqing Wang, Bowen Ping, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu, Maosong Sun |  |
| 815 |  |  [Harder Task Needs More Experts: Dynamic Routing in MoE Models](https://doi.org/10.18653/v1/2024.acl-long.696) |  | 0 | In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike existing MoE approaches that rely on fixed TopK... | Quzhe Huang, Zhenwei An, Nan Zhuang, Mingxu Tao, Chen Zhang, Yang Jin, Kun Xu, Liwei Chen, Songfang Huang, Yansong Feng |  |
| 816 |  |  [XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception](https://doi.org/10.18653/v1/2024.acl-long.697) |  | 0 | Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer... | HyoJung Han, Mohamed Anwar, Juan Pino, WeiNing Hsu, Marine Carpuat, Bowen Shi, Changhan Wang |  |
| 817 |  |  [SOTOPIA-π: Interactive Learning of Socially Intelligent Language Agents](https://doi.org/10.18653/v1/2024.acl-long.698) |  | 0 | Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-π, that improves the social intelligence of... | Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Yonatan Bisk, Graham Neubig, Hao Zhu |  |
| 818 |  |  [\mathcal XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts](https://doi.org/10.18653/v1/2024.acl-long.699) |  | 0 | We introduce XFT, a simple yet powerful training scheme, by simply merging upcycled Mixture-of-Experts (MoE) to unleash the performance limit of instruction-tuned code Large Language Models (LLMs). While vanilla sparse upcycling fails to improve instruction tuning, XFT introduces a shared expert... | Yifeng Ding, Jiawei Liu, Yuxiang Wei, Lingming Zhang |  |
| 819 |  |  [Generalizability of Mixture of Domain-Specific Adapters from the Lens of Signed Weight Directions and its Application to Effective Model Pruning](https://doi.org/10.18653/v1/2024.acl-long.700) |  | 0 | Several parameter-efficient fine-tuning methods based on adapters have been proposed as a streamlined approach to incorporate not only a single specialized knowledge into existing Pre-Trained Language Models (PLMs) but also multiple of them at once. Recent works such as AdapterSoup propose to mix... | Tuc Nguyen, Thai Le |  |
| 820 |  |  [Learning to Decode Collaboratively with Multiple Language Models](https://doi.org/10.18653/v1/2024.acl-long.701) |  | 0 | We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level. We model the decision of which LLM generates the next token as a latent variable. By optimizing the marginal likelihood of a training set under our latent variable... | Zejiang Shen, Hunter Lang, Bailin Wang, Yoon Kim, David A. Sontag |  |
| 821 |  |  [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.702) |  | 0 | Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs).There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to... | Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu |  |
| 822 |  |  [Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.703) |  | 0 | Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world. Current temporal reasoning datasets are limited to questions about single or isolated events, falling short in mirroring the realistic temporal characteristics involving concurrent nature and intricate... | Zhaochen Su, Juntao Li, Jun Zhang, Tong Zhu, Xiaoye Qu, Pan Zhou, Yan Bowen, Yu Cheng, Min Zhang |  |
| 823 |  |  [CritiqueLLM: Towards an Informative Critique Generation Model for Evaluation of Large Language Model Generation](https://doi.org/10.18653/v1/2024.acl-long.704) |  | 0 | Since the natural language processing (NLP) community started to make large language models (LLMs) act as a critic to evaluate the quality of generated texts, most of the existing works train a critique generation model on the evaluation data labeled by GPT-4’s direct prompting. We observe that... | Pei Ke, Bosi Wen, Andrew Feng, Xiao Liu, Xuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang |  |
| 824 |  |  [LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments](https://doi.org/10.18653/v1/2024.acl-long.705) |  | 0 | Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence. However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent... | Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, WeiWei Tu, Zhaofeng He, Lijie Wen |  |
| 825 |  |  [Small But Funny: A Feedback-Driven Approach to Humor Distillation](https://doi.org/10.18653/v1/2024.acl-long.706) |  | 0 | The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing. Consequently, distillation through imitation of teacher responses has emerged as a popular technique to... | Sahithya Ravi, Patrick Huber, Akshat Shrivastava, Vered Shwartz, Arash Einolghozati |  |
| 826 |  |  [Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.707) |  | 0 | Although Large Language Models (LLMs) demonstrate remarkable ability in processing and generating human-like text, they do have limitations when it comes to comprehending and expressing world knowledge that extends beyond the boundaries of natural language(e.g., chemical molecular formula).... | Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu |  |
| 827 |  |  [From Sights to Insights: Towards Summarization of Multimodal Clinical Documents](https://doi.org/10.18653/v1/2024.acl-long.708) |  | 0 | The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective... | Akash Ghosh, Mohit Tomar, Abhisek Tiwari, Sriparna Saha, Jatin Salve, Setu Sinha |  |
| 828 |  |  [When Phrases Meet Probabilities: Enabling Open Relation Extraction with Cooperating Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.709) |  | 0 | Current clustering-based open relation extraction (OpenRE) methods usually apply clustering algorithms on top of pre-trained language models. However, this practice has three drawbacks. First, embeddings from language models are high-dimensional and anisotropic, so using simple metrics to calculate... | Jiaxin Wang, Lingling Zhang, Wee Sun Lee, Yujie Zhong, Liwei Kang, Jun Liu |  |
| 829 |  |  [Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation](https://doi.org/10.18653/v1/2024.acl-long.710) |  | 0 | The latest generative large language models (LLMs) have found their application in data augmentation tasks, where small numbers of text samples are LLM-paraphrased and then used to fine-tune downstream models. However, more research is needed to assess how different prompts, seed data selection... | Ján Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Mária Bieliková, Peter Brusilovsky |  |
| 830 |  |  [Beyond Orthography: Automatic Recovery of Short Vowels and Dialectal Sounds in Arabic](https://doi.org/10.18653/v1/2024.acl-long.711) |  | 0 | This paper presents a novel Dialectal Sound and Vowelization Recovery framework, designed to recognize borrowed and dialectal sounds within phonologically diverse and dialect-rich languages, that extends beyond its standard orthographic sound sets. The proposed framework utilized quantized sequence... | Yassine El Kheir, Hamdy Mubarak, Ahmed Ali, Shammur Absar Chowdhury |  |
| 831 |  |  [Document-Level Machine Translation with Large-Scale Public Parallel Corpora](https://doi.org/10.18653/v1/2024.acl-long.712) |  | 0 | Despite the fact that document-level machine translation has inherent advantages over sentence-level machine translation due to additional information available to a model from document context, most translation systems continue to operate at a sentence level. This is primarily due to the severe... | Proyag Pal, Alexandra Birch, Kenneth Heafield |  |
| 832 |  |  [Bridging the Empirical-Theoretical Gap in Neural Network Formal Language Learning Using Minimum Description Length](https://doi.org/10.18653/v1/2024.acl-long.713) |  | 0 | Neural networks offer good approximation to many tasks but consistently fail to reach perfect generalization, even when theoretical work shows that such perfect solutions can be expressed by certain architectures. Using the task of formal language learning, we focus on one simple formal language... | Nur Geffen Lan, Emmanuel Chemla, Roni Katzir |  |
| 833 |  |  [Context versus Prior Knowledge in Language Models](https://doi.org/10.18653/v1/2024.acl-long.714) |  | 0 | To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different questions and contexts: models will rely more on prior... | Kevin Du, Vésteinn Snæbjarnarson, Niklas Stoehr, Jennifer C. White, Aaron Schein, Ryan Cotterell |  |
| 834 |  |  [Word Matters: What Influences Domain Adaptation in Summarization?](https://doi.org/10.18653/v1/2024.acl-long.715) |  | 0 | Domain adaptation aims to enable Large Language Models (LLMs) to generalize domain datasets unseen effectively during the training phase. However, factors such as the size of the model parameters and the scale of training data are general influencers and do not reflect the nuances of domain... | Yinghao Li, Siyu Miao, Heyan Huang, Yang Gao |  |
| 835 |  |  [Visualization Recommendation with Prompt-based Reprogramming of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.716) |  | 0 | Visualization recommendations, which aim to automatically match proper visual charts for specific data tables, can significantly simplify the data analysis process. Traditional approaches in this domain have primarily relied on rule-based or machine learning-based methodologies. These methods often... | Xinhang Li, Jingbo Zhou, Wei Chen, Derong Xu, Tong Xu, Enhong Chen |  |
| 836 |  |  [HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs](https://doi.org/10.18653/v1/2024.acl-long.717) |  | 0 | Given unstructured text, Large Language Models (LLMs) are adept at answering simple (single-hop) questions. However, as the complexity of the questions increase, the performance of LLMs degrade. We believe this is due to the overhead associated with understanding the complex question followed by... | Pranoy Panda, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, A. P. Prathosh |  |
| 837 |  |  [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](https://doi.org/10.18653/v1/2024.acl-long.718) |  | 0 | When a teacher provides examples for a student to study, these examples must be informative, enabling a student to progress from their current state toward a target concept or skill. Good teachers must therefore simultaneously infer what students already know and adapt their teaching to students’... | Alexis Ross, Jacob Andreas |  |
| 838 |  |  [Bridging Word-Pair and Token-Level Metaphor Detection with Explainable Domain Mining](https://doi.org/10.18653/v1/2024.acl-long.719) |  | 0 | Metaphor detection aims to identify whether a linguistic expression in text is metaphorical or literal. Most existing research tackles this problem either using word-pair or token-level information as input, and thus treats word-pair and token-level metaphor detection as distinct subtasks.... | Yuan Tian, Ruike Zhang, Nan Xu, Wenji Mao |  |
| 839 |  |  [Faithful Logical Reasoning via Symbolic Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.720) |  | 0 | While the recent Chain-of-Thought (CoT) technique enhances the reasoning ability of large language models (LLMs) with the theory of mind, it might still struggle in handling logical reasoning that relies much on symbolic expressions and rigid deducing rules. To strengthen the logical reasoning... | Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, MongLi Lee, Wynne Hsu |  |
| 840 |  |  [S²GSL: Incorporating Segment to Syntactic Enhanced Graph Structure Learning for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.721) |  | 0 | Previous graph-based approaches in Aspect-based Sentiment Analysis(ABSA) have demonstrated impressive performance by utilizing graph neural networks and attention mechanisms to learn structures of static dependency trees and dynamic latent trees. However, incorporating both semantic and syntactic... | Bingfeng Chen, Qihan Ouyang, Yongqi Luo, Boyan Xu, Ruichu Cai, Zhifeng Hao |  |
| 841 |  |  [Maverick: Efficient and Accurate Coreference Resolution Defying Recent Trends](https://doi.org/10.18653/v1/2024.acl-long.722) |  | 0 | Large autoregressive generative models have emerged as the cornerstone for achieving the highest performance across several Natural Language Processing tasks. However, the urge to attain superior results has, at times, led to the premature replacement of carefully designed task-specific approaches... | Giuliano Martinelli, Edoardo Barba, Roberto Navigli |  |
| 842 |  |  [ESCoT: Towards Interpretable Emotional Support Dialogue Systems](https://doi.org/10.18653/v1/2024.acl-long.723) |  | 0 | Understanding the reason for emotional support response is crucial for establishing connections between users and emotional support dialogue systems. Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable... | Tenggan Zhang, Xinjie Zhang, Jinming Zhao, Li Zhou, Qin Jin |  |
| 843 |  |  [PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering](https://doi.org/10.18653/v1/2024.acl-long.724) |  | 0 | Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure... | Fangzhi Xu, Qika Lin, Tianzhe Zhao, Jiawei Han, Jun Liu |  |
| 844 |  |  [WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection](https://doi.org/10.18653/v1/2024.acl-long.725) |  | 0 | Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern... | Anudeex Shetty, Yue Teng, Ke He, Qiongkai Xu |  |
| 845 |  |  [Advancing Parameter Efficiency in Fine-tuning via Representation Editing](https://doi.org/10.18653/v1/2024.acl-long.726) |  | 0 | Parameter Efficient Fine-Tuning (PEFT) has gained significant attention for its ability to achieve competitive results while updating only a small subset of trainable parameters. Despite the promising performance of current PEFT methods, they present challenges in hyperparameter selection, such as... | Muling Wu, Wenhao Liu, Xiaohua Wang, Tianlong Li, Changze Lv, Zixuan Ling, Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang |  |
| 846 |  |  [Context Consistency between Training and Inference in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.727) |  | 0 | Simultaneous Machine Translation (SiMT) aims to yield a real-time partial translation with a monotonically growing source-side context.However, there is a counterintuitive phenomenon about the context usage between training and inference: \*e.g.\*, in wait-k inference, model consistently trained... | Meizhi Zhong, Lemao Liu, Kehai Chen, Mingming Yang, Min Zhang |  |
| 847 |  |  [Using Natural Language Explanations to Improve Robustness of In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.728) |  | 0 | Recent studies demonstrated that large language models (LLMs) can excel in many tasks via in-context learning (ICL). However, recentworks show that ICL-prompted models tend to produce inaccurate results when presented with adversarial inputs. In this work, we investigate whether augmenting ICL with... | Xuanli He, Yuxiang Wu, OanaMaria Camburu, Pasquale Minervini, Pontus Stenetorp |  |
| 848 |  |  [Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers](https://doi.org/10.18653/v1/2024.acl-long.729) |  | 0 | Although dominant in natural language processing, transformer-based models still struggle with long-sequence processing, due to the computational costs of their self-attention operations, which increase exponentially as the length of the input sequence grows. To address this challenge, we propose a... | Jiawen Xie, Pengyu Cheng, Xiao Liang, Yong Dai, Nan Du |  |
| 849 |  |  [ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.730) |  | 0 | This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g.,... | Hojae Han, Jaejin Kim, Jaeseok Yoo, Youngwon Lee, Seungwon Hwang |  |
| 850 |  |  [Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels](https://doi.org/10.18653/v1/2024.acl-long.731) |  | 0 | Traditional supervised learning heavily relies on human-annotated datasets, especially in data-hungry neural approaches. However, various tasks, especially multi-label tasks like document-level relation extraction, pose challenges in fully manual annotation due to the specific domain knowledge and... | Zixia Jia, Junpeng Li, Shichuan Zhang, Anji Liu, Zilong Zheng |  |
| 851 |  |  [MULFE: A Multi-Level Benchmark for Free Text Model Editing](https://doi.org/10.18653/v1/2024.acl-long.732) |  | 0 | Adjusting the outdated behaviors of large langugae models (LLMs) after deployment remains a significant challenge. It motivates the model editing research, which is however mainly explored in a restricted task form with triple-based edit requests. Recent works have initiated a transition to a more... | Chenhao Wang, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao |  |
| 852 |  |  [MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech](https://doi.org/10.18653/v1/2024.acl-long.733) |  | 0 | Zero-shot text-to-speech (TTS) has gained significant attention due to its powerful voice cloning capabilities, requiring only a few seconds of unseen speaker voice prompts. However, all previous work has been developed for cloud-based systems. Taking autoregressive models as an example, although... | Shengpeng Ji, Ziyue Jiang, Hanting Wang, Jialong Zuo, Zhou Zhao |  |
| 853 |  |  [Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation](https://doi.org/10.18653/v1/2024.acl-long.734) |  | 0 | Embodied AI aims to develop robots that can understand and execute human language instructions, as well as communicate in natural languages. On this front, we study the task of generating highly detailed navigational instructions for the embodied robots to follow. Although recent studies have... | Muraleekrishna Gopinathan, Martin Masek, Jumana AbuKhalaf, David Suter |  |
| 854 |  |  [HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position](https://doi.org/10.18653/v1/2024.acl-long.735) |  | 0 | Addressing the limitation of context length in large language models for code-related tasks is the primary focus of this paper. Existing LLMs are constrained by their pre-trained context lengths, leading to performance issues in handling long complex code sequences. Inspired by how human... | Kechi Zhang, Ge Li, Huangzhao Zhang, Zhi Jin |  |
| 855 |  |  [Never Lost in the Middle: Mastering Long-Context Question Answering with Position-Agnostic Decompositional Training](https://doi.org/10.18653/v1/2024.acl-long.736) |  | 0 | While large language models (LLMs) are equipped with longer text input capabilities than before, they are struggling to seek correct information in long contexts. The “lost in the middle” problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located... | Junqing He, Kunhao Pan, Xiaoqun Dong, Zhuoyang Song, LiuYiBo LiuYiBo, Qianguosun Qianguosun, Yuxin Liang, Hao Wang, Enming Zhang, Jiaxing Zhang |  |
| 856 |  |  [CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges](https://doi.org/10.18653/v1/2024.acl-long.737) |  | 0 | Large Language Models (LLMs) have shown promise in automated code generation but typically excel only in simpler tasks such as generating standalone code units. However, real-world software development often involves complex code repositories with complex dependencies and extensive documentation.... | Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, Zhi Jin |  |
| 857 |  |  [When is Tree Search Useful for LLM Planning? It Depends on the Discriminator](https://doi.org/10.18653/v1/2024.acl-long.738) |  | 0 | In this paper, we examine how large language models (LLMs) solve multi-step problems under a language agent framework with three components: a generator, a discriminator, and a planning method. We investigate the practical utility of two advanced planning methods, iterative correction and tree... | Ziru Chen, Michael White, Raymond J. Mooney, Ali Payani, Yu Su, Huan Sun |  |
| 858 |  |  [LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.739) |  | 0 | Recently developed large language models (LLMs) have been shown to perform remarkably well on a wide range of language understanding tasks. But, can they really “reason” over the natural language? This question has been receiving significant research attention and many reasoning skills such as... | Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam Mitra, Chitta Baral |  |
| 859 |  |  [Meta-Tuning LLMs to Leverage Lexical Knowledge for Generalizable Language Style Understanding](https://doi.org/10.18653/v1/2024.acl-long.740) |  | 0 | Language style is often used by writers to convey their intentions, identities, and mastery of language. In this paper, we show that current large language models struggle to capture some language styles without fine-tuning. To address this challenge, we investigate whether LLMs can be meta-trained... | Ruohao Guo, Wei Xu, Alan Ritter |  |
| 860 |  |  [Reducing Privacy Risks in Online Self-Disclosures with Language Models](https://doi.org/10.18653/v1/2024.acl-long.741) |  | 0 | Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure... | Yao Dou, Isadora Krsek, Tarek Naous, Anubha Kabra, Sauvik Das, Alan Ritter, Wei Xu |  |
| 861 |  |  [Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.742) |  | 0 | Memory Editing (ME) has emerged as an efficient method to modify erroneous facts or inject new facts into Large Language Models (LLMs). Two mainstream ME methods exist: parameter-modifying ME and parameter-preserving ME (integrating extra modules while preserving original parameters). Regrettably,... | Zihao Lin, Mohammad Beigi, Hongxuan Li, Yufan Zhou, Yuxiang Zhang, Qifan Wang, Wenpeng Yin, Lifu Huang |  |
| 862 |  |  [REFINESUMM: Self-Refining MLLM for Generating a Multimodal Summarization Dataset](https://doi.org/10.18653/v1/2024.acl-long.743) |  | 0 | Multimodal Large Language Models (MLLMs) excel at synthesizing key information from diverse sources. However, generating accurate and faithful multimodal summaries is challenging, primarily due to the lack of appropriate multimodal datasets for fine-tuning that meaningfully integrate textual and... | Vaidehi Patil, Leonardo F. R. Ribeiro, Mengwen Liu, Mohit Bansal, Markus Dreyer |  |
| 863 |  |  [When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards](https://doi.org/10.18653/v1/2024.acl-long.744) |  | 0 | Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value — we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance... | Norah Alzahrani, Hisham Abdullah Alyahya, Yazeed Alnumay, Sultan Alrashed, Shaykhah Alsubaie, Yousef Almushayqih, Faisal Mirza, Nouf Alotaibi, Nora AlTwairesh, Areeb Alowisheq, M. Saiful Bari, Haidar Khan |  |
| 864 |  |  [LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts](https://doi.org/10.18653/v1/2024.acl-long.745) |  | 0 | This paper introduces a framework for the automated evaluation of natural language texts. A manually constructed rubric describes how to assess multiple dimensions of interest. To evaluate a text, a large language model (LLM) is prompted with each rubric question and produces a distribution over... | Helia Hashemi, Jason Eisner, Corby Rosset, Benjamin Van Durme, Chris Kedzie |  |
| 865 |  |  [LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.746) |  | 0 | Discourse Entity (DE) recognition is the task of identifying novel and known entities introduced within a text. While previous work has found that large language models have basic, if imperfect, DE recognition abilities (Schuster and Linzen, 2022), it remains largely unassessed which of the... | Xiaomeng Zhu, Robert Frank |  |
| 866 |  |  [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.747) |  | 0 | Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term... | Adyasha Maharana, DongHo Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, Yuwei Fang |  |
| 867 |  |  [Prototypical Reward Network for Data-Efficient RLHF](https://doi.org/10.18653/v1/2024.acl-long.748) |  | 0 | The reward model for Reinforcement Learning from Human Feedback (RLHF) has proven effective in fine-tuning Large Language Models (LLMs). Notably, collecting human feedback for RLHF can be resource-intensive and lead to scalability issues for LLMs and complex tasks. Our proposed framework Proto-RM... | Jinghan Zhang, Xiting Wang, Yiqiao Jin, Changyu Chen, Xinhao Zhang, Kunpeng Liu |  |
| 868 |  |  [NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms](https://doi.org/10.18653/v1/2024.acl-long.749) |  | 0 | The performance of Large Language Models (LLMs) degrades from the temporal drift between data used for model training and newer text seen during inference. One understudied avenue of language change causing data drift is the emergence of neologisms – new word forms – over time. We create a diverse... | Jonathan Zheng, Alan Ritter, Wei Xu |  |
| 869 |  |  [Impacts of Misspelled Queries on Translation and Product Search](https://doi.org/10.18653/v1/2024.acl-long.750) |  | 0 | Machine translation is used in e-commerce to translate second-language queries into the primary language of the store, to be matched by the search system against the product catalog. However, many queries contain spelling mistakes. We first present an analysis of the spelling-robustness of a... | Greg Hanneman, Natawut Monaikul, Taichi Nakatani |  |
| 870 |  |  [Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs](https://doi.org/10.18653/v1/2024.acl-long.751) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in tasks such as summarization, arithmetic reasoning, and question answering. However, they encounter significant challenges in the domain of moral reasoning and ethical decision-making, especially in complex scenarios with multiple... | Bilgehan Sel, Priya Shanmugasundaram, Mohammad Kachuee, Kun Zhou, Ruoxi Jia, Ming Jin |  |
| 871 |  |  [The MERSA Dataset and a Transformer-Based Approach for Speech Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.752) |  | 0 | Research in the field of speech emotion recognition (SER) relies on the availability of comprehensive datasets to make it possible to design accurate emotion detection models. This study introduces the Multimodal Emotion Recognition and Sentiment Analysis (MERSA) dataset, which includes both... | Enshi Zhang, Rafael Trujillo, Christian Poellabauer |  |
| 872 |  |  [Transparent and Scrutable Recommendations Using Natural Language User Profiles](https://doi.org/10.18653/v1/2024.acl-long.753) |  | 0 | Recent state-of-the-art recommender systems predominantly rely on either implicit or explicit feedback from users to suggest new items. While effective in recommending novel options, many recommender systems often use uninterpretable embeddings to represent user preferences. This lack of... | Jerome Ramos, Hossein A. Rahmani, Xi Wang, Xiao Fu, Aldo Lipani |  |
| 873 |  |  [Fora: A corpus and framework for the study of facilitated dialogue](https://doi.org/10.18653/v1/2024.acl-long.754) |  | 0 | Facilitated dialogue is increasingly popular as a method of civic engagement and as a method for gathering social insight, but resources for its study are scant. We present Fora, a unique collection of annotated facilitated dialogues. We compile 262 facilitated conversations that were hosted with... | Hope Schroeder, Deb Roy, Jad Kabbara |  |
| 874 |  |  [Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.755) |  | 0 | Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks with a few demonstration examples via in-context learning. Common strategies to boost such “in-context” learning ability are to ensemble multiple model decoded results and require the... | Yue Yu, Jiaming Shen, Tianqi Liu, Zhen Qin, Jing Nathan Yan, Jialu Liu, Chao Zhang, Michael Bendersky |  |
| 875 |  |  [What is the Best Way for ChatGPT to Translate Poetry?](https://doi.org/10.18653/v1/2024.acl-long.756) |  | 0 | Machine translation (MT) has historically faced significant challenges when applied to literary works, particularly in the domain of poetry translation. The advent of Large Language Models such as ChatGPT holds potential for innovation in this field. This study examines ChatGPT’s capabilities in... | Shanshan Wang, Derek F. Wong, Jingming Yao, Lidia S. Chao |  |
| 876 |  |  [Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.757) |  | 0 | Large language models are trained on massive scrapes of the web, which are often unstructured, noisy, and poorly phrased. Current scaling laws show that learning from such data requires an abundance of both compute and data, which grows with the size of the model being trained. This is infeasible... | Pratyush Maini, Skyler Seto, Richard He Bai, David Grangier, Yizhe Zhang, Navdeep Jaitly |  |
| 877 |  |  [DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention](https://doi.org/10.18653/v1/2024.acl-long.758) |  | 0 | Large language models (LLMs) often require task-relevant knowledge to augment their internal knowledge through prompts. However, simply injecting external knowledge into prompts does not guarantee that LLMs can identify and use relevant information in the prompts to conduct chain-of-thought... | Junda Wu, Tong Yu, Xiang Chen, Haoliang Wang, Ryan A. Rossi, Sungchul Kim, Anup B. Rao, Julian J. McAuley |  |
| 878 |  |  [Representation Learning with Conditional Information Flow Maximization](https://doi.org/10.18653/v1/2024.acl-long.759) |  | 0 | This paper proposes an information-theoretic representation learning framework, named conditional information flow maximization, to extract noise-invariant sufficient representations for the input data and target task. It promotes the learned representations have good feature uniformity and... | Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu |  |
| 879 |  |  [GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.760) |  | 0 | Social biases in LLMs are usually measured via bias benchmark datasets. Current benchmarks have limitations in scope, grounding, quality, and human effort required. Previous work has shown success with a community-sourced, rather than crowd-sourced, approach to benchmark development. However, this... | Virginia K. Felkner, Jennifer A. Thompson, Jonathan May |  |
| 880 |  |  [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](https://doi.org/10.18653/v1/2024.acl-long.761) |  | 0 | While large language models have achieved remarkable performance on various code generation benchmarks, there have been growing concerns regarding potential contamination of these benchmarks as they may be leaked into pretraining and finetuning data. While recent work has investigated contamination... | Martin Riddell, Ansong Ni, Arman Cohan |  |
| 881 |  |  [Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic](https://doi.org/10.18653/v1/2024.acl-long.762) |  | 0 | We propose RESTA to perform LLM realignment towards safety, which gets compromised due to downstream task fine-tuning. RESTA stands for REstoring Safety through Task Arithmetic. At its core, it involves a simple arithmetic addition of a safety vector to the weights of the compromised model. We... | Rishabh Bhardwaj, Do Duc Anh, Soujanya Poria |  |
| 882 |  |  [Tracking the Newsworthiness of Public Documents](https://doi.org/10.18653/v1/2024.acl-long.763) |  | 0 | Journalists regularly make decisions on whether or not to report stories, based on “news values”. In this work, we wish to explicitly model these decisions to explore _when_ and _why_ certain stories get press attention. This is challenging because very few labelled links between source documents... | Alexander Spangher, Serdar Tumgoren, Ben Welsh, Nanyun Peng, Emilio Ferrara, Jonathan May |  |
| 883 |  |  [EWEK-QA : Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems](https://doi.org/10.18653/v1/2024.acl-long.764) |  | 0 | The emerging citation-based QA systems are gaining more attention especially in generative AI search applications. The importance of extracted knowledge provided to these systems is vital from both accuracy (completeness of information) and efficiency (extracting the information in a timely... | Mohammad Dehghan, Mohammad Ali Alomrani, Sunyam Bagga, David AlfonsoHermelo, Khalil Bibi, Abbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu, Jimmy Lin, Boxing Chen, Prasanna Parthasarathi, Mahdi Biparva, Mehdi Rezagholizadeh |  |
| 884 |  |  [Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models](https://doi.org/10.18653/v1/2024.acl-long.765) |  | 0 | Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer from degradation, as VQA datasets lack the diversity and... | Shengzhi Li, Rongyu Lin, Shichao Pei |  |
| 885 |  |  [Multistage Collaborative Knowledge Distillation from a Large Language Model for Semi-Supervised Sequence Generation](https://doi.org/10.18653/v1/2024.acl-long.766) |  | 0 | We study semi-supervised sequence generation tasks, where the few labeled examples are too scarce to finetune a model, and meanwhile, few-shot prompted large language models (LLMs) exhibit room for improvement. In this paper, we present the discovery that a student model distilled from a few-shot... | Jiachen Zhao, Wenlong Zhao, Andrew Drozdov, Benjamin Rozonoyer, Md. Arafat Sultan, JayYoon Lee, Mohit Iyyer, Andrew McCallum |  |
| 886 |  |  [Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor](https://doi.org/10.18653/v1/2024.acl-long.767) |  | 0 | Controlled text generation, aiming to ensure that language models produce text containing only the desired domain or corpus attributes, is immensely crucial in the practical application of language models. Existing methods, however, are inapplicable to black-box models or suffer a significant... | Sangwon Yu, Changmin Lee, Hojin Lee, Sungroh Yoon |  |
| 887 |  |  [LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP](https://doi.org/10.18653/v1/2024.acl-long.768) |  | 0 | Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor-intensive process that requires... | Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor BergKirkpatrick |  |
| 888 |  |  [Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning](https://doi.org/10.18653/v1/2024.acl-long.769) |  | 0 | Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the... | Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning Cheng, Tianyi Zhou |  |
| 889 |  |  [Confabulation: The Surprising Value of Large Language Model Hallucinations](https://doi.org/10.18653/v1/2024.acl-long.770) |  | 0 | This paper presents a systematic defense of large language model (LLM) hallucinations or ‘confabulations’ as a potential resource instead of a categorically negative pitfall. The standard view is that confabulations are inherently problematic and AI research should eliminate this flaw. In this... | Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So |  |
| 890 |  |  [IAPT: Instance-Aware Prompt Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.771) |  | 0 | Soft prompt tuning is a widely studied parameter-efficient fine-tuning method. However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance. As a result, soft prompt tuning is less considered than Low-rank adaptation (LoRA) in the... | Wei Zhu, Aaron Xuxiang Tian, Congrui Yin, Yuan Ni, Xiaoling Wang, Guotong Xie |  |
| 891 |  |  [DeVAn: Dense Video Annotation for Video-Language Models](https://doi.org/10.18653/v1/2024.acl-long.772) |  | 0 | We present a novel human annotated dataset for evaluating the ability for visual-language models to generate both short and long descriptions for real-world video clips, termed DeVAn (Dense Video Annotation). The dataset contains 8.5K YouTube video clips of 20-60 seconds in duration and covers a... | Tingkai Liu, Yunzhe Tao, Haogeng Liu, Qihang Fan, Ding Zhou, Huaibo Huang, Ran He, Hongxia Yang |  |
| 892 |  |  [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://doi.org/10.18653/v1/2024.acl-long.773) |  | 0 | Most traditional AI safety research views models as machines and centers on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. Observing this, we shift... | Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, Weiyan Shi |  |
| 893 |  |  [The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.774) |  | 0 | Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that... | Adithya Bhaskar, Dan Friedman, Danqi Chen |  |
| 894 |  |  [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.775) |  | 0 | Large vision-language models (LVLMs) excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains.To fill... | Lei Li, Yuqi Wang, Runxin Xu, Peiyi Wang, Xiachong Feng, Lingpeng Kong, Qi Liu |  |
| 895 |  |  [L-Eval: Instituting Standardized Evaluation for Long Context Language Models](https://doi.org/10.18653/v1/2024.acl-long.776) |  | 0 | Recently, there has been growing interest in long-context scaling of large language models (LLMs). To facilitate research in this field, we propose L-Eval to institute a more standardized evaluation for Long-Context Language Models (LCLMs) addressing two key aspects: dataset construction and... | Chenxin An, Shansan Gong, Ming Zhong, Xingjian Zhao, Mukai Li, Jun Zhang, Lingpeng Kong, Xipeng Qiu |  |
| 896 |  |  [DIALECTBENCH: An NLP Benchmark for Dialects, Varieties, and Closely-Related Languages](https://doi.org/10.18653/v1/2024.acl-long.777) |  | 0 | Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks... | Fahim Faisal, Orevaoghene Ahia, Aarohi Srivastava, Kabir Ahuja, David Chiang, Yulia Tsvetkov, Antonios Anastasopoulos |  |
| 897 |  |  [Causal-Guided Active Learning for Debiasing Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.778) |  | 0 | Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs. However, due to the diversity of dataset biases and the... | Zhouhao Sun, Li Du, Xiao Ding, Yixuan Ma, Yang Zhao, Kaitao Qiu, Ting Liu, Bing Qin |  |
| 898 |  |  [PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.779) |  | 0 | Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to... | Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang |  |
| 899 |  |  [Towards Better Understanding of Contrastive Sentence Representation Learning: A Unified Paradigm for Gradient](https://doi.org/10.18653/v1/2024.acl-long.780) |  | 0 | Sentence Representation Learning (SRL) is a crucial task in Natural Language Processing (NLP), where contrastive Self-Supervised Learning (SSL) is currently a mainstream approach. However, the reasons behind its remarkable effectiveness remain unclear. Specifically, many studies have investigated... | Mingxin Li, Richong Zhang, Zhijie Nie |  |
| 900 |  |  [Emergent Word Order Universals from Cognitively-Motivated Language Models](https://doi.org/10.18653/v1/2024.acl-long.781) |  | 0 | The world’s languages exhibit certain so-called typological or implicational universals; for example, Subject-Object-Verb (SOV) languages typically use postpositions. Explaining the source of such biases is a key goal of linguistics.We study word-order universals through a computational simulation... | Tatsuki Kuribayashi, Ryo Ueda, Ryo Yoshida, Yohei Oseki, Ted Briscoe, Timothy Baldwin |  |
| 901 |  |  [Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View](https://doi.org/10.18653/v1/2024.acl-long.782) |  | 0 | As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: \*Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?\* This paper probes... | Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, Shumin Deng |  |
| 902 |  |  [MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin](https://doi.org/10.18653/v1/2024.acl-long.783) |  | 0 | This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL), which learns an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap... | Tianshuo Zhou, Sen Mei, Xinze Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu, Yu Gu, Ge Yu |  |
| 903 |  |  [Distributional Inclusion Hypothesis and Quantifications: Probing for Hypernymy in Functional Distributional Semantics](https://doi.org/10.18653/v1/2024.acl-long.784) |  | 0 | Functional Distributional Semantics (FDS) models the meaning of words by truth-conditional functions. This provides a natural representation for hypernymy but no guarantee that it can be learnt when FDS models are trained on a corpus. In this paper, we probe into FDS models and study the... | Chun Hei Lo, Wai Lam, Hong Cheng, Guy Emerson |  |
| 904 |  |  [CausalGym: Benchmarking causal interpretability methods on linguistic tasks](https://doi.org/10.18653/v1/2024.acl-long.785) |  | 0 | Language models (LMs) have proven to be powerful tools for psycholinguistic research, but most prior work has focused on purely behavioural measures (e.g., surprisal comparisons). At the same time, research in model interpretability has begun to illuminate the abstract causal mechanisms shaping LM... | Aryaman Arora, Dan Jurafsky, Christopher Potts |  |
| 905 |  |  [Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration](https://doi.org/10.18653/v1/2024.acl-long.786) |  | 0 | Despite efforts to expand the knowledge of large language models (LLMs), knowledge gaps—missing or outdated information in LLMs—might always persist given the evolving nature of knowledge. In this work, we study approaches to identify LLM knowledge gaps and abstain from answering questions when... | Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Vidhisha Balachandran, Yulia Tsvetkov |  |
| 906 |  |  [Mission: Impossible Language Models](https://doi.org/10.18653/v1/2024.acl-long.787) |  | 0 | Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic... | Julie Kallini, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, Christopher Potts |  |
| 907 |  |  [Semisupervised Neural Proto-Language Reconstruction](https://doi.org/10.18653/v1/2024.acl-long.788) |  | 0 | Existing work implementing comparative reconstruction of ancestral languages (proto-languages) has usually required full supervision. However, historical reconstruction models are only of practical value if they can be trained with a limited amount of labeled data. We propose a semisupervised... | Liang Lu, Peirong Xie, David R. Mortensen |  |
| 908 |  |  [Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?](https://doi.org/10.18653/v1/2024.acl-long.789) |  | 0 | The field of natural language processing (NLP) has recently witnessed a transformative shift with the emergence of foundation models, particularly Large Language Models (LLMs) that have revolutionized text-based NLP. This paradigm has extended to other modalities, including speech, where... | Marco Gaido, Sara Papi, Matteo Negri, Luisa Bentivogli |  |
| 909 |  |  [Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?](https://doi.org/10.18653/v1/2024.acl-long.790) |  | 0 | Reference summaries for abstractive speech summarization require human annotation, which can be performed by listening to an audio recording or by reading textual transcripts of the recording. In this paper, we examine whether summaries based on annotators listening to the recordings differ from... | Roshan Sharma, Suwon Shon, Mark Lindsey, Hira Dhamyal, Bhiksha Raj |  |
| 910 |  |  [D2LLM: Decomposed and Distilled Large Language Models for Semantic Search](https://doi.org/10.18653/v1/2024.acl-long.791) |  | 0 | The key challenge in semantic search is to create models that are both accurate and efficient in pinpointing relevant sentences for queries. While BERT-style bi-encoders excel in efficiency with pre-computed embeddings, they often miss subtle nuances in search tasks. Conversely, GPT-style LLMs with... | Zihan Liao, Hang Yu, Jianguo Li, Jun Wang, Wei Zhang |  |
| 911 |  |  [Arabic Diacritics in the Wild: Exploiting Opportunities for Improved Diacritization](https://doi.org/10.18653/v1/2024.acl-long.792) |  | 0 | The widespread absence of diacritical marks in Arabic text poses a significant challenge for Arabic natural language processing (NLP). This paper explores instances of naturally occurring diacritics, referred to as “diacritics in the wild,” to unveil patterns and latent information across six... | Salman Elgamal, Ossama Obeid, Mhd Tameem Kabbani, Go Inoue, Nizar Habash |  |
| 912 |  |  [Disinformation Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.793) |  | 0 | Automated disinformation generation is often listed as one of the risks of large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for democratic societies around the world. This paper presents a comprehensive... | Ivan Vykopal, Matús Pikuliak, Ivan Srba, Róbert Móro, Dominik Macko, Mária Bieliková |  |
| 913 |  |  [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://doi.org/10.18653/v1/2024.acl-long.794) |  | 0 | Incremental Learning (IL) has been a long-standing problem in both vision and Natural Language Processing (NLP) communities.In recent years, as Pre-trained Language Models (PLMs) have achieved remarkable progress in various NLP downstream tasks, utilizing PLMs as backbones has become a common... | Junhao Zheng, Shengjie Qiu, Qianli Ma |  |
| 914 |  |  [How to Handle Different Types of Out-of-Distribution Scenarios in Computational Argumentation? A Comprehensive and Fine-Grained Field Study](https://doi.org/10.18653/v1/2024.acl-long.795) |  | 0 | The advent of pre-trained Language Models (LMs) has markedly advanced natural language processing, but their efficacy in out-of-distribution (OOD) scenarios remains a significant challenge. Computational argumentation (CA), modeling human argumentation processes, is a field notably impacted by... | Andreas Waldis, Yufang Hou, Iryna Gurevych |  |
| 915 |  |  [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](https://doi.org/10.18653/v1/2024.acl-long.796) |  | 0 | Large language models (LLMs) show remarkable human-like capability in various domains and languages. To bridge this quality gap, we introduce Cendol, a collection of Indonesian LLMs encompassing both decoder-only and encoder-decoder architectures across a range of model sizes. We highlight Cendol’s... | Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Rifki Afina Putri, Tjeng Wawan Cenggoro, Jhonson Lee, Salsabil Maulana Akbar, Emmanuel Dave, Nuur Shadieq, Muhammad Ihza Mahendra, Dea Annisayanti Putri, Bryan Wilie, Genta Indra Winata, Alham Fikri Aji, Ayu Purwarianti, Pascale Fung |  |
| 916 |  |  [Must NLP be Extractive?](https://doi.org/10.18653/v1/2024.acl-long.797) |  | 0 | How do we roll out language technologies across a world with 7,000 languages? In one story, we scale the successes of NLP further into ‘low-resource’ languages, doing ever more with less. However, this approach does not recognise the fact that, beyond the 500 institutional languages, the remaining... | Steven Bird |  |
| 917 |  |  [Spiral of Silence: How is Large Language Model Killing Information Retrieval? - A Case Study on Open Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.798) |  | 0 | The practice of Retrieval-Augmented Generation (RAG), which integrates Large Language Models (LLMs) with retrieval systems, has become increasingly prevalent. However, the repercussions of LLM-derived content infiltrating the web and influencing the retrieval-generation feedback loop are largely... | Xiaoyang Chen, Ben He, Hongyu Lin, Xianpei Han, Tianshu Wang, Boxi Cao, Le Sun, Yingfei Sun |  |
| 918 |  |  [Latxa: An Open Language Model and Evaluation Suite for Basque](https://doi.org/10.18653/v1/2024.acl-long.799) |  | 0 | We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we... | Julen Etxaniz, Oscar Sainz, Naiara Miguel, Itziar Aldabe, German Rigau, Eneko Agirre, Aitor Ormazabal, Mikel Artetxe, Aitor Soroa |  |
| 919 |  |  [Why are Sensitive Functions Hard for Transformers?](https://doi.org/10.18653/v1/2024.acl-long.800) |  | 0 | Empirical studies have identified a range of learnability biases and limitations of transformers, such as a persistent difficulty in learning to compute simple formal languages such as PARITY, and a bias towards low-degree functions. However, theoretical understanding remains limited, with existing... | Michael Hahn, Mark Rofin |  |
| 920 |  |  [Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction](https://doi.org/10.18653/v1/2024.acl-long.801) |  | 0 | Large Language Model (LLM)-enhanced agents become increasingly prevalent in Human-AI communication, offering vast potential from entertainment to professional domains. However, current multi-modal dialogue systems overlook the acoustic information present in speech, which is crucial for... | Haoqiu Yan, Yongxin Zhu, Kai Zheng, Bing Liu, Haoyu Cao, Deqiang Jiang, Linli Xu |  |
| 921 |  |  [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://doi.org/10.18653/v1/2024.acl-long.802) |  | 0 | Code generation has fast become one of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs, such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation,... | Indraneil Paul, Goran Glavas, Iryna Gurevych |  |
| 922 |  |  [The Echoes of Multilinguality: Tracing Cultural Value Shifts during Language Model Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.803) |  | 0 | Texts written in different languages reflect different culturally-dependent beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are jointly trained on a concatenation of text in multiple languages, to encode different cultural values for each language. Yet, as the... | Rochelle Choenni, Anne Lauscher, Ekaterina Shutova |  |
| 923 |  |  [MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.804) |  | 0 | A major consideration in multilingual language modeling is how to best represent languages with diverse vocabularies and scripts.Although contemporary text encoding methods cover most of the world’s writing systems, they exhibit bias towards the high-resource languages of the Global West. As a... | Tomasz Limisiewicz, Terra Blevins, Hila Gonen, Orevaoghene Ahia, Luke Zettlemoyer |  |
| 924 |  |  [MultiLegalPile: A 689GB Multilingual Legal Corpus](https://doi.org/10.18653/v1/2024.acl-long.805) |  | 0 | Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, few datasets are available for specialized critical domains such as law and the available ones are often small and only in English. To fill this gap, we curate and release MultiLegalPile, a 689GB... | Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, Daniel E. Ho |  |
| 925 |  |  [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](https://doi.org/10.18653/v1/2024.acl-long.806) |  | 0 | Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we... | Haolin Deng, Chang Wang, Xin Li, Dezhang Yuan, Junlang Zhan, Tianhua Zhou, Jin Ma, Jun Gao, Ruifeng Xu |  |
| 926 |  |  [What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages](https://doi.org/10.18653/v1/2024.acl-long.807) |  | 0 | What can large language models learn? By definition, language models (LM) are distributionsover strings. Therefore, an intuitive way of addressing the above question is to formalize it as a matter of learnability of classes of distributions over strings. While prior work in this direction focused... | Nadav Borenstein, Anej Svete, Robin Chan, Josef Valvoda, Franz Nowak, Isabelle Augenstein, Eleanor Chodroff, Ryan Cotterell |  |
| 927 |  |  [Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.808) |  | 0 | We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model in the literature. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and... | Behzad Shayegh, Yuqiao Wen, Lili Mou |  |
| 928 |  |  [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs](https://doi.org/10.18653/v1/2024.acl-long.809) |  | 0 | Safety is critical to the usage of large language models (LLMs). Multiple techniques such as data filtering and supervised fine-tuning have been developed to strengthen LLM safety. However, currently known techniques presume that corpora used for safety alignment of LLMs are solely interpreted by... | Fengqing Jiang, Zhangchen Xu, Luyao Niu, Zhen Xiang, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran |  |
| 929 |  |  [ChatDev: Communicative Agents for Software Development](https://doi.org/10.18653/v1/2024.acl-long.810) |  | 0 | Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique... | Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, Maosong Sun |  |
| 930 |  |  [Disentangled Learning with Synthetic Parallel Data for Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.811) |  | 0 | Text style transfer (TST) is an important task in natural language generation, which aims to transfer the text style (e.g., sentiment) while keeping its semantic information. Due to the absence of parallel datasets for supervision, most existing studies have been conducted in an unsupervised... | Jingxuan Han, Quan Wang, Zikang Guo, Benfeng Xu, Licheng Zhang, Zhendong Mao |  |
| 931 |  |  [PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](https://doi.org/10.18653/v1/2024.acl-long.812) |  | 0 | Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with... | Zaibin Zhang, Yongting Zhang, Lijun Li, Jing Shao, Hongzhi Gao, Yu Qiao, Lijun Wang, Huchuan Lu, Feng Zhao |  |
| 932 |  |  [Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation](https://doi.org/10.18653/v1/2024.acl-long.813) |  | 0 | Emotional Support Conversation (ESC) is a task aimed at alleviating individuals’ emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently,... | Dongjin Kang, Sunghwan Kim, Taeyoon Kwon, Seungjun Moon, Hyunsouk Cho, Youngjae Yu, Dongha Lee, Jinyoung Yeo |  |
| 933 |  |  [ınftyBench: Extending Long Context Evaluation Beyond 100K Tokens](https://doi.org/10.18653/v1/2024.acl-long.814) |  | 0 | Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a... | Xinrong Zhang, Yingfa Chen, Shengding Hu, Zihang Xu, Junhao Chen, Moo Khai Hao, Xu Han, Zhen Leng Thai, Shuo Wang, Zhiyuan Liu, Maosong Sun |  |
| 934 |  |  [Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models](https://doi.org/10.18653/v1/2024.acl-long.815) |  | 0 | Efforts to apply transformer-based language models (TLMs) to the problem of reasoning in natural language have enjoyed ever-increasing success in recent years. The most fundamental task in this area to which nearly all others can be reduced is that of determining satisfiability. However, from a... | Tharindu Madusanka, Ian PrattHartmann, Riza BatistaNavarro |  |
| 935 |  |  [Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.816) |  | 0 | Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are... | Paul Röttger, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Kirk, Hinrich Schütze, Dirk Hovy |  |
| 936 |  |  [AI 'News' Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian](https://doi.org/10.18653/v1/2024.acl-long.817) |  | 0 | Large Language Models (LLMs) are increasingly used as ‘content farm’ models (CFMs), to generate synthetic text that could pass for real news articles. This is already happening even for languages that do not have high-quality monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on... | Giovanni Puccetti, Anna Rogers, Chiara Alzetta, Felice Dell'Orletta, Andrea Esuli |  |
| 937 |  |  [Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.818) |  | 0 | This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA... | Mosh Levy, Alon Jacoby, Yoav Goldberg |  |
| 938 |  |  [Disambiguate Words like Composing Them: A Morphology-Informed Approach to Enhance Chinese Word Sense Disambiguation](https://doi.org/10.18653/v1/2024.acl-long.819) |  | 0 | In parataxis languages like Chinese, word meanings are highly correlated with morphological knowledge, which can help to disambiguate word senses. However, in-depth exploration of morphological knowledge in previous word sense disambiguation (WSD) methods is still lacking due to the absence of... | Yue Wang, Qiliang Liang, Yaqi Yin, Hansi Wang, Yang Liu |  |
| 939 |  |  [Do Llamas Work in English? On the Latent Language of Multilingual Transformers](https://doi.org/10.18653/v1/2024.acl-long.820) |  | 0 | We ask whether multilingual language models trained on unbalanced, English-dominated corpora use English as an internal pivot language—-a question of key importance for understanding how language models function and the origins of linguistic bias. Focusing on the Llama-2 family of transformer... | Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West |  |
| 940 |  |  [G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.821) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable abilities in general scenarios. Instruction finetuning empowers them to align with humans in various tasks. Nevertheless, the Diversity and Quality of the instruction data remain two main challenges for instruction finetuning. With regard to... | Xingyuan Pan, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Shanbo Cheng |  |
| 941 |  |  [Media Framing: A typology and Survey of Computational Approaches Across Disciplines](https://doi.org/10.18653/v1/2024.acl-long.822) |  | 0 | Framing studies how individuals and societies make sense of the world, by communicating or representing complex issues through schema of interpretation. The framing of information in the mass media influences our interpretation of facts and corresponding decisions, so detecting and analysing it is... | Yulia Otmakhova, Shima Khanehzar, Lea Frermann |  |
| 942 |  |  [SPZ: A Semantic Perturbation-based Data Augmentation Method with Zonal-Mixing for Alzheimer's Disease Detection](https://doi.org/10.18653/v1/2024.acl-long.823) |  | 0 | Alzheimer’s Disease (AD), characterized by significant cognitive and functional impairment, necessitates the development of early detection techniques. Traditional diagnostic practices, such as cognitive assessments and biomarker analysis, are often invasive and costly. Deep learning-based... | Fangfang Li, Cheng Huang, Puzhen Su, Jie Yin |  |
| 943 |  |  [Calibrating Large Language Models Using Their Generations Only](https://doi.org/10.18653/v1/2024.acl-long.824) |  | 0 | As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model’s confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs—especially when the only... | Dennis Ulmer, Martin Gubri, Hwaran Lee, Sangdoo Yun, Seong Joon Oh |  |
| 944 |  |  [Iterative Forward Tuning Boosts In-Context Learning in Language Models](https://doi.org/10.18653/v1/2024.acl-long.825) |  | 0 | Despite the advancements in in-context learning (ICL) for large language models (LLMs), current research centers on specific prompt engineering, such as demonstration selection, with the expectation that a single iteration of demonstrations processing can generalize effectively to a given test... | Jiaxi Yang, Binyuan Hui, Min Yang, Bailin Wang, Bowen Li, Binhua Li, Fei Huang, Yongbin Li |  |
| 945 |  |  [Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement](https://doi.org/10.18653/v1/2024.acl-long.826) |  | 0 | Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM’s bias in evaluating their own output. In this paper, we formally define LLM’s self-bias – the tendency to... | Wenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, William Wang |  |
| 946 |  |  [Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't](https://doi.org/10.18653/v1/2024.acl-long.827) |  | 0 | We investigate what linguistic factors affect the performance of Automatic Speech Recognition (ASR) models. We hypothesize that orthographic and phonological complexities both degrade accuracy. To examine this, we fine-tune the multilingual self-supervised pretrained model Wav2Vec2-XLSR-53 on 25... | Chihiro Taguchi, David Chiang |  |
| 947 |  |  [Steering Llama 2 via Contrastive Activation Addition](https://doi.org/10.18653/v1/2024.acl-long.828) |  | 0 | We introduce Contrastive Activation Addition (CAA), a method for steering language models by modifying their activations during forward passes. CAA computes “steering vectors” by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular... | Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, Alexander Matt Turner |  |
| 948 |  |  [EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities](https://doi.org/10.18653/v1/2024.acl-long.829) |  | 0 | The advent of artificial intelligence has led to a growing emphasis on data-driven modeling in macroeconomics, with agent-based modeling (ABM) emerging as a prominent bottom-up simulation paradigm. In ABM, agents (\*e.g.\*, households, firms) interact within a macroeconomic environment,... | Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao |  |
| 949 |  |  [SafetyBench: Evaluating the Safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.830) |  | 0 | With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety... | Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, Minlie Huang |  |
| 950 |  |  [Deciphering Oracle Bone Language with Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.831) |  | 0 | Originating from China’s Shang Dynasty approximately 3,000 years ago, the Oracle Bone Script (OBS) is a cornerstone in the annals of linguistic history, predating many established writing systems. Despite the discovery of thousands of inscriptions, a vast expanse of OBS remains undeciphered,... | Haisu Guan, Huanxin Yang, Xinyu Wang, Shengwei Han, Yongge Liu, Lianwen Jin, Xiang Bai, Yuliang Liu |  |
| 951 |  |  [M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.832) |  | 0 | Managing long sequences has become an important and necessary feature for large language models (LLMs). However, assessing their ability to handle long contexts remains a challenge. This paper introduces M4LE, a Multi-ability, Multi-range, Multi-task, Multi-domain benchmark for Long-context... | WaiChung Kwan, Xingshan Zeng, Yufei Wang, Yusen Sun, Liangyou Li, Yuxin Jiang, Lifeng Shang, Qun Liu, KamFai Wong |  |
| 952 |  |  [RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models via Romanization](https://doi.org/10.18653/v1/2024.acl-long.833) |  | 0 | This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Roman scripts. We propose an approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens... | Jaavid Aktar Husain, Raj Dabre, Aswanth M., Jay Gala, Thanmay Jayakumar, Ratish Puduppully, Anoop Kunchukuttan |  |
| 953 |  |  [Causal Estimation of Memorisation Profiles](https://doi.org/10.18653/v1/2024.acl-long.834) |  | 0 | Understanding memorisation in language models has practical and societal implications, e.g., studying models’ training dynamics or preventing copyright infringements.Prior work defines memorisation as the causal effect of training with an instance on the model’s ability to predict that instance.... | Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel |  |
| 954 |  |  [CHECKWHY: Causal Fact Verification via Argument Structure](https://doi.org/10.18653/v1/2024.acl-long.835) |  | 0 | With the growing complexity of fact verification tasks, the concern with “thoughtful” reasoning capabilities is increasing. However, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. In this... | Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu Zhou |  |
| 955 |  |  [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://doi.org/10.18653/v1/2024.acl-long.836) |  | 0 | Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However,... | Christian Tomani, David Vilar, Markus Freitag, Colin Cherry, Subhajit Naskar, Mara Finkelstein, Xavier Garcia, Daniel Cremers |  |
| 956 |  |  [On Efficient and Statistical Quality Estimation for Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.837) |  | 0 | Annotated datasets are an essential ingredient to train, evaluate, compare and productionalize supervised machine learning models. It is therefore imperative that annotations are of high quality. For their creation, good quality management and thereby reliable quality estimates are needed. Then, if... | JanChristoph Klie, Juan Haladjian, Marc Kirchner, Rahul Nair |  |
| 957 |  |  [EZ-STANCE: A Large Dataset for English Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.838) |  | 0 | Zero-shot stance detection (ZSSD) aims to determine whether the author of a text is in favor, against, or neutral toward a target that is unseen during training. In this paper, we present EZ-STANCE, a large English ZSSD dataset with 47,316 annotated text-target pairs. In contrast to VAST, which is... | Chenye Zhao, Cornelia Caragea |  |
| 958 |  |  [American Sign Language Handshapes Reflect Pressures for Communicative Efficiency](https://doi.org/10.18653/v1/2024.acl-long.839) |  | 0 | Communicative efficiency is a key topic in linguistics and cognitive psychology, with many studies demonstrating how the pressure to communicate with minimal effort guides the form of natural language. However, this phenomenon is rarely explored in signed languages. This paper shows how handshapes... | Kayo Yin, Terry Regier, Dan Klein |  |
| 959 |  |  [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://doi.org/10.18653/v1/2024.acl-long.840) |  | 0 | Information about pretraining corpora used to train the current best-performing language models is seldom discussed: commercial models rarely detail their data, and even open models are often released without accompanying training data or recipes to reproduce them. As a result, it is challenging to... | Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Raghavi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha, Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Abhilasha Ravichander, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi, Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo |  |
| 960 |  |  [OLMo: Accelerating the Science of Language Models](https://doi.org/10.18653/v1/2024.acl-long.841) |  | 0 | Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and... | Dirk Groeneveld, Iz Beltagy, Evan Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi |  |
| 961 |  |  [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://doi.org/10.18653/v1/2024.acl-long.842) |  | 0 | Large language models (LLMs) undergo safety alignment to ensure safe conversations with humans. However, this paper introduces a training-free attack method capable of reversing safety alignment, converting the outcomes of stronger alignment into greater potential for harm by accessing only LLM... | Zhanhui Zhou, Jie Liu, Zhichen Dong, Jiaheng Liu, Chao Yang, Wanli Ouyang, Yu Qiao |  |
| 962 |  |  [IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for Indian Languages](https://doi.org/10.18653/v1/2024.acl-long.843) |  | 0 | Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the... | Mohammed Safi Ur Rahman Khan, Priyam Mehta, Ananth Sankar, Umashankar Kumaravelan, Sumanth Doddapaneni, Suriyaprasaad B, Varun Balan G, Sparsh Jain, Anoop Kunchukuttan, Pratyush Kumar, Raj Dabre, Mitesh M. Khapra |  |
| 963 |  |  [Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.844) |  | 0 | Large Language Models (LLMs) have achieved remarkable performance in objective tasks such as open-domain question answering and mathematical reasoning, which can often be solved through recalling learned factual knowledge or chain-of-thought style reasoning. However, we find that the performance of... | Xiaolong Wang, Yile Wang, Yuanchi Zhang, Fuwen Luo, Peng Li, Maosong Sun, Yang Liu |  |
| 964 |  |  [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://doi.org/10.18653/v1/2024.acl-long.845) |  | 0 | Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows... | Ahmet Üstün, Viraat Aryabumi, Zheng Xin Yong, WeiYin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, HuiLee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker |  |
| 965 |  |  [BatchEval: Towards Human-like Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.846) |  | 0 | Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior... | Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 966 |  |  [ToMBench: Benchmarking Theory of Mind in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.847) |  | 0 | Theory of Mind (ToM) is the cognitive capability to perceive and ascribe mental states to oneself and others. Recent research has sparked a debate over whether large language models (LLMs) exhibit a form of ToM. However, existing ToM evaluations are hindered by challenges such as constrained scope,... | Zhuang Chen, Jincenzi Wu, Jinfeng Zhou, Bosi Wen, Guanqun Bi, Gongyao Jiang, Yaru Cao, Mengting Hu, Yunghwei Lai, Zexuan Xiong, Minlie Huang |  |
| 967 |  |  [COKE: A Cognitive Knowledge Graph for Machine Theory of Mind](https://doi.org/10.18653/v1/2024.acl-long.848) |  | 0 | Theory of mind (ToM) refers to humans’ ability to understand and infer the desires, beliefs, and intentions of others. The acquisition of ToM plays a key role in humans’ social cognition and interpersonal relations. Though indispensable for social intelligence, ToM is still lacking for modern AI... | Jincenzi Wu, Zhuang Chen, Jiawen Deng, Sahand Sabour, Helen Meng, Minlie Huang |  |
| 968 |  |  [MultiPICo: Multilingual Perspectivist Irony Corpus](https://doi.org/10.18653/v1/2024.acl-long.849) |  | 0 | Recently, several scholars have contributed to the growth of a new theoretical framework in NLP called perspectivism. This approach aimsto leverage data annotated by different individuals to model diverse perspectives that affect their opinions on subjective phenomena such as irony. In this... | Silvia Casola, Simona Frenda, Soda Marem Lo, Erhan Sezerer, Antonio Uva, Valerio Basile, Cristina Bosco, Alessandro Pedrani, Chiara Rubagotti, Viviana Patti, Davide Bernardi |  |
| 969 |  |  [AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents](https://doi.org/10.18653/v1/2024.acl-long.850) |  | 0 | Autonomous agents that address day-to-day digital tasks (e.g., ordering groceries for a household), must not only operate multiple apps (e.g., notes, messaging, shopping app) via APIs, but also generate rich code with complex control flow in an iterative manner based on their interaction with the... | Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian |  |
| 970 |  |  [MMToM-QA: Multimodal Theory of Mind Question Answering](https://doi.org/10.18653/v1/2024.acl-long.851) |  | 0 | Theory of Mind (ToM), the ability to understand people’s mental states, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM... | Chuanyang Jin, Yutong Wu, Jing Cao, Jiannan Xiang, YenLing Kuo, Zhiting Hu, Tomer D. Ullman, Antonio Torralba, Joshua B. Tenenbaum, Tianmin Shu |  |
| 971 |  |  [DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents](https://doi.org/10.18653/v1/2024.acl-long.852) |  | 0 | Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems. However, the degree to which these numerical reasoning skills are effective in real-world scenarios, particularly in expert domains, is still largely unexplored. This paper introduces DocMath-Eval, a... | Yilun Zhao, Yitao Long, Hongjun Liu, Ryo Kamoi, Linyong Nan, Lyuhao Chen, Yixin Liu, Xiangru Tang, Rui Zhang, Arman Cohan |  |
| 972 |  |  [Unintended Impacts of LLM Alignment on Global Representation](https://doi.org/10.18653/v1/2024.acl-long.853) |  | 0 | Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on... | Michael J. Ryan, William Held, Diyi Yang |  |
| 973 |  |  [ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.854) |  | 0 | While state-of-the-art large language models (LLMs) can excel at adapting text from one style to another, current work does not address the explainability of style transfer models. Recent work has explored generating textual explanations from larger teacher models and distilling them into smaller... | Arkadiy Saakyan, Smaranda Muresan |  |
| 974 |  |  [MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy](https://doi.org/10.18653/v1/2024.acl-long.855) |  | 0 | It has been widely observed that exact or approximate MAP (mode-seeking) decoding from natural language generation (NLG) models consistently leads to degenerate outputs (Holtzman et al., 2019; Stahlberg and Byrne, 2019). Prior work has attributed this behavior to either a fundamental and... | Davis Yoshida, Kartik Goyal, Kevin Gimpel |  |
| 975 |  |  [Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!](https://doi.org/10.18653/v1/2024.acl-long.856) |  | 0 | Annually, at the Conference of Machine Translation (WMT), the Metrics Shared Task organizers conduct the meta-evaluation of Machine Translation (MT) metrics, ranking them according to their correlation with human judgments. Their results guide researchers toward enhancing the next generation of... | Stefano Perrella, Lorenzo Proietti, Alessandro Scirè, Edoardo Barba, Roberto Navigli |  |
| 976 |  |  [NounAtlas: Filling the Gap in Nominal Semantic Role Labeling](https://doi.org/10.18653/v1/2024.acl-long.857) |  | 0 | Despite significant advances in Semantic Role Labeling (SRL), much work in this field has been carried out with a focus on verbal predicates, with the research on nominal SRL lagging behind. In many contexts, however, nominal predicates are often as informative as verbal ones, thus needing proper... | Roberto Navigli, Marco Pinto, Pasquale Silvestri, Dennis Rotondi, Simone Ciciliano, Alessandro Scirè |  |
| 977 |  |  [The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation](https://doi.org/10.18653/v1/2024.acl-long.858) |  | 0 | Large language models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive... | Rongwu Xu, Brian S. Lin, Shujian Yang, Tianqi Zhang, Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei Xu, Han Qiu |  |
| 978 |  |  [LooGLE: Can Long-Context Language Models Understand Long Contexts?](https://doi.org/10.18653/v1/2024.acl-long.859) |  | 0 | Large language models (LLMs) are typically limited to processing texts within context window size, which has spurred significant research efforts into enhancing LLMs’ long-context understanding as well as developing high-quality benchmarks to evaluate the ability. However, prior datasets suffer... | Jiaqi Li, Mengmeng Wang, Zilong Zheng, Muhan Zhang |  |
| 979 |  |  [Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation](https://doi.org/10.18653/v1/2024.acl-long.860) |  | 0 | In this paper, we introduce a novel Face-to-Face spoken dialogue model. It processes audio-visual speech from user input and generates audio-visual speech as the response, marking the initial step towards creating an avatar chatbot system without relying on intermediate text. To this end, we newly... | Se Jin Park, Chae Won Kim, Hyeongseop Rha, Minsu Kim, Joanna Hong, Jeong Hun Yeo, Yong Man Ro |  |
| 980 |  |  [ECBD: Evidence-Centered Benchmark Design for NLP](https://doi.org/10.18653/v1/2024.acl-long.861) |  | 0 | Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually... | Yu Lu Liu, Su Lin Blodgett, Jackie C. K. Cheung, Vera Liao, Alexandra Olteanu, Ziang Xiao |  |
| 981 |  |  [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.862) |  | 0 | As the reach of large language models (LMs) expands globally, their ability to cater to diverse cultural contexts becomes crucial. Despite advancements in multilingual capabilities, models are not designed with appropriate cultural nuances. In this paper, we show that multilingual and Arabic... | Tarek Naous, Michael J. Ryan, Alan Ritter, Wei Xu |  |
| 982 |  |  [Explicating the Implicit: Argument Detection Beyond Sentence Boundaries](https://doi.org/10.18653/v1/2024.acl-long.863) |  | 0 | Detecting semantic arguments of a predicate word has been conventionally modeled as a sentence-level task. The typical reader, however, perfectly interprets predicate-argument relations in a much wider context than just the sentence where the predicate was evoked. In this work, we reformulate the... | Paul Roit, Aviv Slobodkin, Eran Hirsch, Arie Cattan, Ayal Klein, Valentina Pyatkin, Ido Dagan |  |
| 983 |  |  [Word Embeddings Are Steers for Language Models](https://doi.org/10.18653/v1/2024.acl-long.864) |  | 0 | Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically... | Chi Han, Jialiang Xu, Manling Li, Yi Fung, Chenkai Sun, Nan Jiang, Tarek F. Abdelzaher, Heng Ji |  |
| 984 |  |  [Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024](https://aclanthology.org/volumes/2024.findings-acl/) |  | 0 |  | LunWei Ku, Andre Martins, Vivek Srikumar |  |
| 985 |  |  [Frontmatter](https://aclanthology.org/2024.findings-acl.0) |  | 0 |  |  |  |
| 986 |  |  [Controllable Data Augmentation for Few-Shot Text Mining with Chain-of-Thought Attribute Manipulation](https://doi.org/10.18653/v1/2024.findings-acl.1) |  | 0 | Prompting large language models (LLMs) for data augmentation has recently become a common practice in few-shot NLP tasks. In this paper, we propose Chain-of-Thought Attribute Manipulation (CoTAM), a novel approach that generates new data from existing examples by only tweaking in the user-provided,... | Letian Peng, Yuwei Zhang, Jingbo Shang |  |
| 987 |  |  [Match More, Extract Better! Hybrid Matching Model for Open Domain Web Keyphrase Extraction](https://doi.org/10.18653/v1/2024.findings-acl.2) |  | 0 | Keyphrase extraction aims to automatically extract salient phrases representing the critical information in the source document. Identifying salient phrases is challenging because there is a lot of noisy information in the document, leading to wrong extraction. To address this issue, in this paper,... | Mingyang Song, Liping Jing, Yi Feng |  |
| 988 |  |  [AFPQ: Asymmetric Floating Point Quantization for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.3) |  | 0 | Large language models (LLMs) show great performance in various tasks, but face deployment challenges from limited memory capacity and bandwidth.Low-bit weight quantization can save memory and accelerate inference.Although floating-point (FP) formats show good performance in LLM quantization, they... | Yijia Zhang, Sicheng Zhang, Shijie Cao, Dayou Du, Jianyu Wei, Ting Cao, Ningyi Xu |  |
| 989 |  |  [End-to-End Emotion Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.4) |  | 0 | Emotion detection is the task of automatically associating one or more emotions with a text. The emotions are experienced, targeted, and caused by different semantic constituents. Therefore, it is necessary to incorporate these semantic constituents into the process of emotion detection. In this... | Xiaotong Jiang, Zhongqing Wang, Guodong Zhou |  |
| 990 |  |  [Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System](https://doi.org/10.18653/v1/2024.findings-acl.5) |  | 0 | Intelligent task-oriented dialogue systems (ToDs) are expected to continuously acquire new knowledge, also known as Continual Learning (CL), which is crucial to fit ever-changing user needs. However, catastrophic forgetting dramatically degrades the model performance in face of a long streamed... | Chen Chen, Ruizhe Li, Yuchen Hu, Yuanyuan Chen, Chengwei Qin, Qiang Zhang |  |
| 991 |  |  [Unveiling Imitation Learning: Exploring the impact of Data Falsity to Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.6) |  | 0 | Many recent studies endeavor to improve open-sourced language models through imitation learning, re-training on the synthetic instruction data from state-of-the-art proprietary models like ChatGPT and GPT-4.However, the innate nature of synthetic data inherently contains noisy data, giving rise to... | Hyunsoo Cho |  |
| 992 |  |  [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://doi.org/10.18653/v1/2024.findings-acl.7) |  | 0 | While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these... | Alex Gu, WenDing Li, Naman Jain, Theo Olausson, Celine Lee, Koushik Sen, Armando SolarLezama |  |
| 993 |  |  [CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support](https://doi.org/10.18653/v1/2024.findings-acl.8) |  | 0 | Literature review requires researchers to synthesize a large amount of information and is increasingly challenging as the scientific literature expands. In this work, we investigate the potential of LLMs for producing hierarchical organizations of scientific studies to assist researchers with... | ChaoChun Hsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, Chenhao Tan, David Wadden, Lucy Lu Wang, Aakanksha Naik |  |
| 994 |  |  [Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.9) |  | 0 | With the recent advances of large language models (LLMs), it is no longer infeasible to build an automated debate system that helps people to synthesise persuasive arguments. Previous work attempted this task by integrating multiple components. In our work, we introduce an argument mining dataset... | Hao Li, Yuping Wu, Viktor Schlegel, Riza BatistaNavarro, Tharindu Madusanka, Iqra Zahid, Jiayan Zeng, Xiaochi Wang, Xinran He, Yizhi Li, Goran Nenadic |  |
| 995 |  |  [A Grounded Preference Model for LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.10) |  | 0 | Despite LLMs’ recent advancements, they still suffer from factual inconsistency and hallucination. An often-opted remedy is retrieval-augmented generation – however, there is no guarantee that the model will strictly adhere to retrieved grounding. Fundamentally, LLMs need to be aligned to be more... | Tahira Naseem, Guangxuan Xu, Sarathkrishna Swaminathan, Asaf Yehudai, Subhajit Chaudhury, Radu Florian, Ramón Fernandez Astudillo, Asim Munawar |  |
| 996 |  |  [Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](https://doi.org/10.18653/v1/2024.findings-acl.11) |  | 0 | Large language models (LLMs), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment LLMs with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains,... | Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han |  |
| 997 |  |  [Text2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.12) |  | 0 | The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE, Text2DB, that emphasizes the... | Yizhu Jiao, Sha Li, Sizhe Zhou, Heng Ji, Jiawei Han |  |
| 998 |  |  [How Important is a Language Model for Low-resource ASR?](https://doi.org/10.18653/v1/2024.findings-acl.13) |  | 0 | N-gram language models (LMs) are the innovation that first made large-vocabulary continuous automatic speech recognition (ASR) viable. With neural end-to-end ASR architectures, however, LMs have become an afterthought. While the effect on accuracy may be negligible for English and Mandarin,... | Zoey Liu, Nitin Venkateswaran, Éric Le Ferrand, Emily Prud'hommeaux |  |
| 999 |  |  [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](https://doi.org/10.18653/v1/2024.findings-acl.14) |  | 0 | Large language models (LLMs) are typically trained on general source data forvarious domains, but a recent surge in domain-specific LLMs has shown theirpotential to outperform general-purpose models in domain-specific tasks (e.g.,biomedicine). Although domain-specific pre-training enhances... | Vithursan Thangarasa, Mahmoud Salem, Shreyas Saxena, ChenYu Leong, Joel Hestness, Sean Lie |  |
| 1000 |  |  [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.15) |  | 0 | Today’s most accurate language models are trained on orders of magnitude more language data than human language learners receive— but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs’ representations and predictions more accurate (and... | Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas |  |
| 1001 |  |  [P-TA: Using Proximal Policy Optimization to Enhance Tabular Data Augmentation via Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.16) |  | 0 | A multitude of industries depend on accurate and reasonable tabular data augmentation for their business processes. Contemporary methodologies in generating tabular data revolve around utilizing Generative Adversarial Networks (GAN) or fine-tuning Large Language Models (LLM). However, GAN-based... | Shuo Yang, Chenchen Yuan, Yao Rong, Felix Steinbauer, Gjergji Kasneci |  |
| 1002 |  |  [Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.17) |  | 0 | There is increasing interest in distilling task-specific knowledge from large language models (LLM) to smaller student models.Nonetheless, LLM distillation presents a dual challenge: 1) there is a high cost associated with querying the teacher LLM, such as GPT-4, for gathering an ample number of... | Yuhang Zhou, Wei Ai |  |
| 1003 |  |  [Small Models are Valuable Plug-ins for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.18) |  | 0 | Large language models (LLMs) such as GPT-3 and GPT-4 are powerful but their weights are often publicly unavailable and their immense sizes make the models difficult to be tuned with common hardware. As a result, effectively tuning these models with large-scale supervised data can be challenging. As... | Canwen Xu, Yichong Xu, Shuohang Wang, Yang Liu, Chenguang Zhu, Julian J. McAuley |  |
| 1004 |  |  [Are self-explanations from Large Language Models faithful?](https://doi.org/10.18653/v1/2024.findings-acl.19) |  | 0 | Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it’s important to measure if... | Andreas Madsen, Sarath Chandar, Siva Reddy |  |
| 1005 |  |  [ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction](https://doi.org/10.18653/v1/2024.findings-acl.20) |  | 0 | Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains. To address these limitations, we present... | Henry Peng Zou, Vinay Samuel, Yue Zhou, Weizhi Zhang, Liancheng Fang, Zihe Song, Philip S. Yu, Cornelia Caragea |  |
| 1006 |  |  [Prompt Engineering a Prompt Engineer](https://doi.org/10.18653/v1/2024.findings-acl.21) |  | 0 | Prompt engineering is a challenging yet crucial task for optimizing the performance of large language models on customized tasks. It requires complex reasoning to examine the model’s errors, hypothesize what is missing or misleading in the current prompt, and communicate the task with clarity.... | Qinyuan Ye, Mohamed Ahmed, Reid Pryzant, Fereshte Khani |  |
| 1007 |  |  [ASPIRE: Language-Guided Data Augmentation for Improving Robustness Against Spurious Correlations](https://doi.org/10.18653/v1/2024.findings-acl.22) |  | 0 | Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. This paper presents... | Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, S. Sakshi, Sanjoy Chowdhury, Dinesh Manocha |  |
| 1008 |  |  [Tables as Texts or Images: Evaluating the Table Reasoning Ability of LLMs and MLLMs](https://doi.org/10.18653/v1/2024.findings-acl.23) |  | 0 | Tables contrast with unstructured text data by its structure to organize the information.In this paper, we investigate the efficiency of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related... | Naihao Deng, Zhenjie Sun, Ruiqi He, Aman Sikka, Yulong Chen, Lin Ma, Yue Zhang, Rada Mihalcea |  |
| 1009 |  |  [Biasly: An Expert-Annotated Dataset for Subtle Misogyny Detection and Mitigation](https://doi.org/10.18653/v1/2024.findings-acl.24) |  | 0 | Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles,... | Brooklyn Sheppard, Anna Richter, Allison Cohen, Elizabeth Allyn Smith, Tamara Kneese, Carolyne Pelletier, Ioana Baldini, Yue Dong |  |
| 1010 |  |  [BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra](https://doi.org/10.18653/v1/2024.findings-acl.25) |  | 0 | Many existing end-to-end systems for hybrid question answering tasks can often be boiled down to a “prompt-and-pray” paradigm, where the user has limited control and insight into the intermediate reasoning steps used to achieve the final result. Additionally, due to the context size limitation of... | Parker Glenn, Parag Dakle, Liang Wang, Preethi Raghavan |  |
| 1011 |  |  [LLM-QAT: Data-Free Quantization Aware Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.26) |  | 0 | Several post-training quantization methods have been applied to large language models (LLMs), and have been shown to perform well down to 8-bits. We find that these methods break down at lower bit precision, and investigate quantization-aware training for LLMs (LLM-QAT) to push quantization levels... | Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, Vikas Chandra |  |
| 1012 |  |  [InfiMM: Advancing Multimodal Understanding with an Open-Sourced Visual Language Model](https://doi.org/10.18653/v1/2024.findings-acl.27) |  | 0 | In this work, we present InfiMM, an advanced Multimodal Large Language Model that adapts to intricate vision-language tasks. InfiMM, inspired by the Flamingo architecture, distinguishes itself through the utilization of large-scale training data, comprehensive training strategies, and diverse large... | Haogeng Liu, Quanzeng You, Yiqi Wang, Xiaotian Han, Bohan Zhai, Yongfei Liu, Wentao Chen, Yiren Jian, Yunzhe Tao, Jianbo Yuan, Ran He, Hongxia Yang |  |
| 1013 |  |  [Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution](https://doi.org/10.18653/v1/2024.findings-acl.28) |  | 0 | Although achieving great success, Large Language Models (LLMs) usually suffer from unreliable hallucinations. Although language attribution can be a potential solution, there are no suitable benchmarks and evaluation metrics to attribute LLMs to structured knowledge. In this paper, we define a new... | Xinze Li, Yixin Cao, Liangming Pan, Yubo Ma, Aixin Sun |  |
| 1014 |  |  [Benchmarking Cognitive Biases in Large Language Models as Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.29) |  | 0 | Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 16 LLMs encompassing four different size ranges and evaluate their output responses by preference ranking from the other LLMs as... | Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang |  |
| 1015 |  |  [X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions](https://doi.org/10.18653/v1/2024.findings-acl.30) |  | 0 | Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples into these languages can be a solution but unreliable,... | Chong Li, Wen Yang, Jiajun Zhang, Jinliang Lu, Shaonan Wang, Chengqing Zong |  |
| 1016 |  |  [Muffin: Mitigating Unhelpfulness in Emotional Support Conversations with Multifaceted AI Feedback](https://doi.org/10.18653/v1/2024.findings-acl.31) |  | 0 |  | Jiashuo Wang, Chunpu Xu, Chak Tou Leong, Wenjie Li, Jing Li |  |
| 1017 |  |  [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.32) |  | 0 | This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce... | Suyuchen Wang, Ivan Kobyzev, Peng Lu, Mehdi Rezagholizadeh, Bang Liu |  |
| 1018 |  |  [MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.33) |  | 0 | Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we... | Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, Mark Gerstein |  |
| 1019 |  |  [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.34) |  | 0 | Neural-symbolic methods have demonstrated efficiency in enhancing the reasoning abilities of large language models (LLMs). However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be... | Yiming Wang, Zhuosheng Zhang, Pei Zhang, Baosong Yang, Rui Wang |  |
| 1020 |  |  [DPDLLM: A Black-box Framework for Detecting Pre-training Data from Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.35) |  | 0 | The success of large language models (LLM) benefits from large-scale model parameters and large amounts of pre-training data. However, the textual data for training LLM can not be confirmed to be legal because they are crawled from different web sites. For example, there are copyrighted articles,... | Baohang Zhou, Zezhong Wang, Lingzhi Wang, Hongru Wang, Ying Zhang, Kehui Song, Xuhui Sui, KamFai Wong |  |
| 1021 |  |  [PACIT: Unlocking the Power of Examples for Better In-Context Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.36) |  | 0 | Instruction tuning enhances the instruction following ability of large language models by finetuning with supervised instruction data. Previous work proposes in-context instruction tuning (ICIT) where specific positive or negative examples are incorporated into the prompt for better performance. In... | Tianci Xue, Ziqi Wang, Yixia Li, Yun Chen, Guanhua Chen |  |
| 1022 |  |  [Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.37) |  | 0 | Recent advances in large language models (LLMs) have promoted generative error correction (GER) for automatic speech recognition (ASR), which aims to predict the ground-truth transcription from the decoded N-best hypotheses. Thanks to the strong language generation ability of LLMs and rich... | Yuchen Hu, Chen Chen, Chengwei Qin, Qiushi Zhu, Engsiong Chng, Ruizhe Li |  |
| 1023 |  |  [Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing](https://doi.org/10.18653/v1/2024.findings-acl.38) |  | 0 | Cross-document Relation Extraction aims to predict the relation between target entities located in different documents. In this regard, the dominant models commonly retain useful information for relation prediction via bridge entities, which allows the model to elaborately capture the intrinsic... | Hao Yue, Shaopeng Lai, Chengyi Yang, Liang Zhang, Junfeng Yao, Jinsong Su |  |
| 1024 |  |  [Large Language Models can Share Images, Too!](https://doi.org/10.18653/v1/2024.findings-acl.39) |  | 0 | This paper explores the image-sharing capability of Large Language Models (LLMs), such as GPT-4 and LLaMA 2, in a zero-shot setting. To facilitate a comprehensive evaluation of LLMs, we introduce the photochatplus dataset, which includes enriched annotations (ie intent, triggering sentence, image... | YoungJun Lee, Dokyong Lee, JooWon Sung, Jonghwan Hyeon, HoJin Choi |  |
| 1025 |  |  [CodeM: Less Data Yields More Versatility via Ability Matrix](https://doi.org/10.18653/v1/2024.findings-acl.40) |  | 0 | In the era of code large language models (code LLMs), data engineering plays a pivotal role during the instruction fine-tuning phase. To train a versatile model, previous efforts devote tremendous efforts into crafting instruction data covering all the downstream scenarios. Nonetheless, this will... | Daoguang Zan, Ailun Yu, Wei Liu, Bo Shen, Shaoxin Lin, Yongshun Gong, Yafen Yao, Yan Liu, Bei Guan, Weihua Luo, Yongji Wang, Qianxiang Wang, Lizhen Cui |  |
| 1026 |  |  [Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning](https://doi.org/10.18653/v1/2024.findings-acl.41) |  | 0 | Advances in large vision-language models (LVLMs) have led to significant progress in generating natural language descriptions for visual contents. These powerful models are known for producing texts that are factually inconsistent with the visual input. While some efforts mitigate such... | KungHsiang Huang, Mingyang Zhou, Hou Pong Chan, Yi Fung, Zhenhailong Wang, Lingyu Zhang, ShihFu Chang, Heng Ji |  |
| 1027 |  |  [BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence](https://doi.org/10.18653/v1/2024.findings-acl.42) |  | 0 | Retrieval-augmented large language models (LLMs) have demonstrated efficacy in knowledge-intensive tasks such as open-domain QA, addressing inherent challenges in knowledge update and factual inadequacy.However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs,... | Jiajie Jin, Yutao Zhu, Yujia Zhou, Zhicheng Dou |  |
| 1028 |  |  [Beyond Literal Descriptions: Understanding and Locating Open-World Objects Aligned with Human Intentions](https://doi.org/10.18653/v1/2024.findings-acl.43) |  | 0 | Visual grounding (VG) aims at locating the foreground entities that match the given natural language expression. Previous datasets and methods for classic VG task mainly rely on the prior assumption that the given expression must literally refer to the target object, which greatly impedes the... | Wenxuan Wang, Yisi Zhang, Xingjian He, Yichen Yan, Zijia Zhao, Xinlong Wang, Jing Liu |  |
| 1029 |  |  [Incremental Sequence Labeling: A Tale of Two Shifts](https://doi.org/10.18653/v1/2024.findings-acl.44) |  | 0 | The incremental sequence labeling task involves continuously learning new classes over time while retaining knowledge of the previous ones. Our investigation identifies two significant semantic shifts: E2O (where the model mislabels an old entity as a non-entity) and O2E (where the model labels a... | Shengjie Qiu, Junhao Zheng, Zhen Liu, Yicheng Luo, Qianli Ma |  |
| 1030 |  |  [How Proficient Are Large Language Models in Formal Languages? An In-Depth Insight for Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.45) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions based on facts in knowledge bases. A typical approach to KBQA is semantic parsing, which translates a question into an executable logical form in a formal language. Recent works leverage the capabilities of large... | Jinxin Liu, Shulin Cao, Jiaxin Shi, Tingjian Zhang, Lunyiu Nie, Linmei Hu, Lei Hou, Juanzi Li |  |
| 1031 |  |  [MELOV: Multimodal Entity Linking with Optimized Visual Features in Latent Space](https://doi.org/10.18653/v1/2024.findings-acl.46) |  | 0 | Multimodal entity linking (MEL), which aligns ambiguous mentions within multimodal contexts to referent entities from multimodal knowledge bases, is essential for many natural language processing applications. Previous MEL methods mainly focus on exploring complex multimodal interaction mechanisms... | Xuhui Sui, Ying Zhang, Yu Zhao, Kehui Song, Baohang Zhou, Xiaojie Yuan |  |
| 1032 |  |  [Unsupervised Distractor Generation via Large Language Model Distilling and Counterfactual Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.47) |  | 0 | Within the context of reading comprehension, the task of Distractor Generation (DG) aims to generate several incorrect options to confuse readers. In recent years, the emergence of Large Language Models (LLMs) provides a potential for unsupervised DG without expensive human-annotated distractor... | Fanyi Qu, Hao Sun, Yunfang Wu |  |
| 1033 |  |  [Conversational Question Answering with Language Models Generated Reformulations over Knowledge Graph](https://doi.org/10.18653/v1/2024.findings-acl.48) |  | 0 | Conversational question answering (ConvQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to... | Lihui Liu, Blaine Hill, Boxin Du, Fei Wang, Hanghang Tong |  |
| 1034 |  |  [Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step by Step](https://doi.org/10.18653/v1/2024.findings-acl.49) |  | 0 | Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an... | Li Zhong, Zilong Wang, Jingbo Shang |  |
| 1035 |  |  [Effective In-Context Example Selection through Data Compression](https://doi.org/10.18653/v1/2024.findings-acl.50) |  | 0 | In-context learning has been extensively validated in large language models. However, the mechanism and selection strategy for in-context example selection, which is a crucial ingredient in this approach, lacks systematic and in-depth research. In this paper, we propose a data compression approach... | Zhongxiang Sun, Kepu Zhang, Haoyu Wang, Xiao Zhang, Jun Xu |  |
| 1036 |  |  [Are U a Joke Master? Pun Generation via Multi-Stage Curriculum Learning towards a Humor LLM](https://doi.org/10.18653/v1/2024.findings-acl.51) |  | 0 | Although large language models (LLMs) acquire extensive world knowledge and some reasoning abilities, their proficiency in generating humorous sentences remains a challenge. Previous research has demonstrated that the humor generation capabilities of ChatGPT are confined to producing merely 25... | Yang Chen, Chong Yang, Tu Hu, Xinhao Chen, Man Lan, Li Cai, Xinlin Zhuang, Xuan Lin, Xin Lu, Aimin Zhou |  |
| 1037 |  |  [Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.52) |  | 0 | Deploying large language models (LLMs) to real scenarios for domain-specific question answering (QA) is a key thrust for LLM applications, which poses numerous challenges, especially in ensuring that responses are both accommodating to user requirements and appropriately leveraging domain-specific... | Yichi Zhang, Zhuo Chen, Yin Fang, Yanxi Lu, Fangming Li, Wen Zhang, Huajun Chen |  |
| 1038 |  |  [MARIO: MAth Reasoning with code Interpreter Output - A Reproducible Pipeline](https://doi.org/10.18653/v1/2024.findings-acl.53) |  | 0 | Large language models (LLMs) have significantly improved in understanding natural language but still lack in mathematical reasoning, a hurdle on the path to true artificial general intelligence. The training of large language models, based on next-token prediction, struggles to capture the precise... | Minpeng Liao, Chengxi Li, Wei Luo, Jing Wu, Kai Fan |  |
| 1039 |  |  [DiffusPoll: Conditional Text Diffusion Model for Poll Generation](https://doi.org/10.18653/v1/2024.findings-acl.54) |  | 0 | Online social media platforms often gather user feedback through polls to enhance user engagement. Automatically generating polls from social media and its context can decrease the labor expenses of media workers and enhance workplace productivity. However, on social media platforms, there are... | Le Cheng, Shuangyin Li |  |
| 1040 |  |  [Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.55) |  | 0 | While large language models (LLMs) have shown excellent capabilities in language understanding, text generation and many other tasks, they still struggle in complex multi-step reasoning problems such as mathematical reasoning. In this paper, through a newly proposed arithmetical puzzle problem, we... | Haolong Li, Yu Ma, Yinqi Zhang, Chen Ye, Jie Chen |  |
| 1041 |  |  [Implanting LLM's Knowledge via Reading Comprehension Tree for Toxicity Detection](https://doi.org/10.18653/v1/2024.findings-acl.56) |  | 0 | Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs... | Hankun Kang, Tieyun Qian |  |
| 1042 |  |  [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://doi.org/10.18653/v1/2024.findings-acl.57) |  | 0 | This paper focuses on task-agnostic prompt compression for better generalizability and efficiency. Considering the redundancy in natural language, existing approaches compress prompts by removing tokens or lexical units according to their information entropy obtained from a causal language model... | Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rühle, Yuqing Yang, ChinYew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang |  |
| 1043 |  |  [EconNLI: Evaluating Large Language Models on Economics Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.58) |  | 0 | Large Language Models (LLMs) are widely used for writing economic analysis reports or providing financial advice, but their ability to understand economic knowledge and reason about potential results of specific economic events lacks systematic evaluation. To address this gap, we propose a new... | Yue Guo, Yi Yang |  |
| 1044 |  |  [Better Late Than Never: Model-Agnostic Hallucination Post-Processing Framework Towards Clinical Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.59) |  | 0 | Clinical text summarization has proven successful in generating concise and coherent summaries. However, these summaries may include unintended text with hallucinations, which can mislead clinicians and patients. Existing methods for mitigating hallucinations can be categorized into task-specific... | Songda Li, Yunqi Zhang, Chunyuan Deng, Yake Niu, Hui Zhao |  |
| 1045 |  |  [Finding and Editing Multi-Modal Neurons in Pre-Trained Transformers](https://doi.org/10.18653/v1/2024.findings-acl.60) |  | 0 | Understanding the internal mechanisms by which multi-modal large language models (LLMs) interpret different modalities and integrate cross-modal representations is becoming increasingly critical for continuous improvements in both academia and industry. In this paper, we propose a novel method to... | Haowen Pan, Yixin Cao, Xiaozhi Wang, Xun Yang, Meng Wang |  |
| 1046 |  |  [Realistic Evaluation of Toxicity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.61) |  | 0 | Large language models (LLMs) have become integral to our professional workflows and daily lives. Nevertheless, these machine companions of ours have a critical flaw: the huge amount of data which endows them with vast and diverse knowledge, also exposes them to the inevitable toxicity and bias.... | Tinh Son Luong, ThanhThien Le, Linh Ngo Van, Thien Huu Nguyen |  |
| 1047 |  |  [Controllable Text Generation with Residual Memory Transformer](https://doi.org/10.18653/v1/2024.findings-acl.62) |  | 0 | Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have brought great success in text generation. However, it is still an open challenge to effectively control the generation process of a CLM while balancing the flexibility, control granularity, and generation efficiency. In this... | Hanqing Zhang, Si Sun, Haiming Wu, Dawei Song |  |
| 1048 |  |  [Prompt-Based Length Controlled Generation with Multiple Control Types](https://doi.org/10.18653/v1/2024.findings-acl.63) |  | 0 | Large language models (LLMs) have attracted great attention given their strong performance on a wide range of NLP tasks. In practice, users often expect generated texts to fall within a specific length range, making length controlled generation an important topic, especially for GPT-style models.... | Renlong Jie, Xiaojun Meng, Lifeng Shang, Xin Jiang, Qun Liu |  |
| 1049 |  |  [PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain](https://doi.org/10.18653/v1/2024.findings-acl.64) |  | 0 | We present PCA-Bench, a multimodal decision-making benchmark for evaluating the integrated capabilities of Multimodal Large Language Models (MLLMs). Departing from previous benchmarks focusing on simplistic tasks and individual model capability, PCA-Bench introduces three complex scenarios:... | Liang Chen, Yichi Zhang, Shuhuai Ren, Haozhe Zhao, Zefan Cai, Yuchi Wang, Peiyi Wang, Xiangdi Meng, Tianyu Liu, Baobao Chang |  |
| 1050 |  |  [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.65) |  | 0 | Conversational recommender systems are an emerging area that has garnered increasing interest in the community, especially with the advancements in large language models (LLMs) that enable sophisticated handling of conversational input. Despite the progress, the field still has many aspects left to... | Minjin Kim, Minju Kim, Hana Kim, Beongwoo Kwak, SeongKu Kang, Youngjae Yu, Jinyoung Yeo, Dongha Lee |  |
| 1051 |  |  [CoLLaVO: Crayon Large Language and Vision mOdel](https://doi.org/10.18653/v1/2024.findings-acl.66) |  | 0 | The remarkable success of Large Language Models (LLMs) and instruction tuning drives the evolution of Vision Language Models (VLMs) towards a versatile general-purpose model. Yet, it remains unexplored whether current VLMs genuinely possess quality object-level image understanding capabilities... | ByungKwan Lee, Beomchan Park, Chae Won Kim, Yong Man Ro |  |
| 1052 |  |  [Modelling Variability in Human Annotator Simulation](https://doi.org/10.18653/v1/2024.findings-acl.67) |  | 0 | Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation tasks such as data annotation and system assessment. It is important to incorporate the variability present in human evaluation into HAS, since it helps capture diverse subjective interpretations and... | Wen Wu, Wenlin Chen, Chao Zhang, Philip C. Woodland |  |
| 1053 |  |  [BEnQA: A Question Answering Benchmark for Bengali and English](https://doi.org/10.18653/v1/2024.findings-acl.68) |  | 0 | In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with different types of questions, including factual,... | Sheikh Shafayat, H. M. Quamran Hasan, Minhajur Rahman Chowdhury Mahim, Rifki Afina Putri, James Thorne, Alice Oh |  |
| 1054 |  |  [MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.69) |  | 0 |  | Wanqing Cui, Keping Bi, Jiafeng Guo, Xueqi Cheng |  |
| 1055 |  |  [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.70) |  | 0 | Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within... | Zhuoran Jin, Pengfei Cao, Hongbang Yuan, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao |  |
| 1056 |  |  [BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning](https://doi.org/10.18653/v1/2024.findings-acl.71) |  | 0 | Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding... | Qizhi Pei, Lijun Wu, Kaiyuan Gao, Xiaozhuan Liang, Yin Fang, Jinhua Zhu, Shufang Xie, Tao Qin, Rui Yan |  |
| 1057 |  |  [SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.72) |  | 0 | Fine-tuning all parameters of large language models (LLMs) necessitates substantial computational power and extended time. Latest advancements in parameter-efficient fine-tuning (PEFT) techniques, such as Adapter tuning and LoRA, allow for adjustments to only a minor fraction of the parameters of... | Zhihao Wen, Jie Zhang, Yuan Fang |  |
| 1058 |  |  [GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving](https://doi.org/10.18653/v1/2024.findings-acl.73) |  | 0 | Recent advancements in large language models (LLMs) and multi-modal models (MMs) have demonstrated their remarkable capabilities in problem-solving. Yet, their proficiency in tackling geometry math problems, which necessitates an integrated understanding of both textual and visual information, has... | Jiaxin Zhang, Zhongzhi Li, MingLiang Zhang, Fei Yin, ChengLin Liu, Yashar Moshfeghi |  |
| 1059 |  |  [Boosting Textural NER with Synthetic Image and Instructive Alignment](https://doi.org/10.18653/v1/2024.findings-acl.74) |  | 0 | Named entity recognition (NER) is a pivotal task reliant on textual data, often impeding the disambiguation of entities due to the absence of context. To tackle this challenge, conventional methods often incorporate images crawled from the internet as auxiliary information. However, the images... | Jiahao Wang, Wenjun Ke, Peng Wang, Hang Zhang, Dong Nie, Jiajun Liu, Guozheng Li, Ziyu Shang |  |
| 1060 |  |  [Neurons in Large Language Models: Dead, N-gram, Positional](https://doi.org/10.18653/v1/2024.findings-acl.75) |  | 0 | We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the... | Elena Voita, Javier Ferrando, Christoforos Nalmpantis |  |
| 1061 |  |  [LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.76) |  | 0 | Grounded Multimodal Named Entity Recognition (GMNER) is a nascent multimodal task that aims to identify named entities, entity types and their corresponding visual regions. GMNER task exhibits two challenging properties: 1) The weak correlation between image-text pairs in social media results in a... | Jinyuan Li, Han Li, Di Sun, Jiahao Wang, Wenkun Zhang, Zan Wang, Gang Pan |  |
| 1062 |  |  [Learning Job Title Representation from Job Description Aggregation Network](https://doi.org/10.18653/v1/2024.findings-acl.77) |  | 0 | Learning job title representation is a vital process for developing automatic human resource tools. To do so, existing methods primarily rely on learning the title representation through skills extracted from the job description, neglecting the rich and diverse content within. Thus, we propose an... | Napat Laosaengpha, Thanit Tativannarat, Chawan Piansaddhayanon, Attapol Rutherford, Ekapol Chuangsuwanich |  |
| 1063 |  |  [FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts](https://doi.org/10.18653/v1/2024.findings-acl.78) |  | 0 | Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of visual question-answering multimodal language models in reasoning with... | Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth |  |
| 1064 |  |  [Flexible Weight Tuning and Weight Fusion Strategies for Continual Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.79) |  | 0 | Continual Named Entity Recognition (CNER) is dedicated to sequentially learning new entity types while mitigating catastrophic forgetting of old entity types. Traditional CNER approaches commonly employ knowledge distillation to retain old knowledge within the current model. However, because only... | Yahan Yu, Duzhen Zhang, Xiuyi Chen, Chenhui Chu |  |
| 1065 |  |  [Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.80) |  | 0 | The automatic evaluation of natural language generation (NLG) systems presents a long-lasting challenge. Recent studies have highlighted various neural metrics that align well with human evaluations. Yet, the robustness of these evaluators against adversarial perturbations remains largely... | Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li |  |
| 1066 |  |  [Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.81) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities and versatility in NLP tasks, however they sometimes fail to maintain crucial invariances for specific tasks. One example is permutation sensitivity, where LLMs’ outputs may significantly vary depending on the order of... | Adian Liusie, Yassir Fathullah, Mark J. F. Gales |  |
| 1067 |  |  [Uncovering Limitations of Large Language Models in Information Seeking from Tables](https://doi.org/10.18653/v1/2024.findings-acl.82) |  | 0 | Tables are recognized for their high information density and widespread usage, serving as essential sources of information. Seeking information from tables (TIS) is a crucial capability for Large Language Models (LLMs), serving as the foundation of knowledge-based Q&A systems. However, this field... | Chaoxu Pang, Yixuan Cao, Chunhao Yang, Ping Luo |  |
| 1068 |  |  [An Ensemble-of-Experts Framework for Rehearsal-free Continual Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.83) |  | 0 | Continual relation extraction (CRE) aims to continuously learn relations in new tasks without forgetting old relations in previous tasks.Current CRE methods are all rehearsal-based which need to store samples and thus may encounter privacy and security issues.This paper targets rehearsal-free... | Shen Zhou, Yongqi Li, Xin Miao, Tieyun Qian |  |
| 1069 |  |  [Temporal Validity Change Prediction](https://doi.org/10.18653/v1/2024.findings-acl.84) |  | 0 | Temporal validity is an important property of text that has many downstream applications, such as recommender systems, conversational AI, and user status tracking. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, many data... | Georg Wenzel, Adam Jatowt |  |
| 1070 |  |  [RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.85) |  | 0 | Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter-efficient fine-tuning methods that optimize input prompts or adjust a small number of model parameters (e.g LoRA). In this study, we explore... | Saeed Najafi, Alona Fyshe |  |
| 1071 |  |  [Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.86) |  | 0 | Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e. sets of concepts which share some property... | Hanane Kteich, Na Li, Usashi Chatterjee, Zied Bouraoui, Steven Schockaert |  |
| 1072 |  |  [Revisiting Multimodal Transformers for Tabular Data with Text Fields](https://doi.org/10.18653/v1/2024.findings-acl.87) |  | 0 | Tabular data with text fields can be leveraged in applications such as financial risk assessment or medical diagnosis prediction. When employing multimodal approaches to make predictions based on these modalities, it is crucial to make the most appropriate modeling choices in terms of numerical... | Thomas Bonnier |  |
| 1073 |  |  [An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla](https://doi.org/10.18653/v1/2024.findings-acl.88) |  | 0 | Pretrained language models inherently exhibit various social biases, prompting a crucial examination of their social impact across various linguistic contexts due to their widespread usage. Previous studies have provided numerous methods for intrinsic bias measurements, predominantly focused on... | Jayanta Sadhu, Ayan Antik Khan, Abhik Bhattacharjee, Rifat Shahriyar |  |
| 1074 |  |  [ConTempo: A Unified Temporally Contrastive Framework for Temporal Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.89) |  | 0 | The task of temporal relation extraction (TRE) involves identifying and extracting temporal relations between events from narratives. We identify two primary issues with TRE systems. First, by formulating TRE as a simple text classification task where every temporal relation is independent, it is... | Jingcheng Niu, Saifei Liao, Victoria Ng, Simon de Montigny, Gerald Penn |  |
| 1075 |  |  [CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.90) |  | 0 | In this work, we dive deep into one of the popular knowledge-grounded dialogue benchmarks that focus on faithfulness, FaithDial. We show that a significant portion of the FaithDial data contains annotation artifacts, which may bias models towards completely ignoring the conversation history. We... | Abbas Ghaddar, David AlfonsoHermelo, Philippe Langlais, Mehdi Rezagholizadeh, Boxing Chen, Prasanna Parthasarathi |  |
| 1076 |  |  [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.91) |  | 0 | The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs’ abilities to critique and rectify their... | Zicheng Lin, Zhibin Gou, Tian Liang, Ruilin Luo, Haowei Liu, Yujiu Yang |  |
| 1077 |  |  [DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.92) |  | 0 | Recently, while large language models (LLMs) have demonstrated impressive results, they still suffer from hallucination, i.e., the generation of false information. Model editing is the task of fixing factual mistakes in LLMs; yet, most previous works treat it as a one-time task, paying little... | Taolin Zhang, Qizhou Chen, Dongyang Li, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue', Jun Huang |  |
| 1078 |  |  [Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.93) |  | 0 | Generic text summarization approaches often fail to address the specific intent and needs of individual users. Recently, scholarly attention has turned to the development of summarization methods that are more closely tailored and controlled to align with specific objectives and user needs. Despite... | Ashok Urlana, Pruthwik Mishra, Tathagato Roy, Rahul Mishra |  |
| 1079 |  |  [Benchmarking Large Language Models on Communicative Medical Coaching: A Dataset and a Novel System](https://doi.org/10.18653/v1/2024.findings-acl.94) |  | 0 | Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors,... | Hengguan Huang, Songtao Wang, Hongfu Liu, Hao Wang, Ye Wang |  |
| 1080 |  |  [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://doi.org/10.18653/v1/2024.findings-acl.95) |  | 0 | This paper introduce a novel thought prompting approach called ”Everything of Thoughts” (XoT) for Large Language Models (LLMs) to defy the law of ”Penrose triangle” of existing thought paradigms, to achieve three key perspectives in thought generation simultaneously: performance, efficiency, and... | Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang |  |
| 1081 |  |  [SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources with Retrieval and Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.96) |  | 0 | We introduce SPAGHETTI: Semantic Parsing Augmented Generation for Hybrid English information from Text Tables and Infoboxes, a hybrid question-answering (QA) pipeline that utilizes information from heterogeneous knowledge sources, including knowledge base, text, tables, and infoboxes. Our... | Heidi C. Zhang, Sina J. Semnani, Farhad Ghassemi, Jialiang Xu, Shicheng Liu, Monica S. Lam |  |
| 1082 |  |  [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.97) |  | 0 | In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of LLMs on DA,... | Bosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze Luo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie Hu, Anh Tuan Luu, Shafiq Joty |  |
| 1083 |  |  [k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text](https://doi.org/10.18653/v1/2024.findings-acl.98) |  | 0 | Recent watermarked generation algorithms inject detectable signatures during language generation to facilitate post-hoc detection. While token-level watermarks are vulnerable to paraphrase attacks, SemStamp (Hou et al., 2023) applies watermark on the semantic representation of sentences and... | Abe Bohan Hou, Jingyu Zhang, Yichen Wang, Daniel Khashabi, Tianxing He |  |
| 1084 |  |  [ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.99) |  | 0 | This paper introduces the ColorSwap dataset, designed to assess and improve the proficiency of multimodal models in matching objects with their colors. The dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000 examples. Each example includes a caption-image pair, along with a... | Jirayu Burapacheep, Ishan Gaur, Agam Bhatia, Tristan Thrush |  |
| 1085 |  |  [Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers](https://doi.org/10.18653/v1/2024.findings-acl.100) |  | 0 | Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that... | Tuo Zhang, Jinyue Yuan, Salman Avestimehr |  |
| 1086 |  |  [CeeBERT: Cross-Domain Inference in Early Exit BERT](https://doi.org/10.18653/v1/2024.findings-acl.101) |  | 0 | Pre-trained Language Models (PLMs), like BERT, with self-supervision objectives exhibit remarkable performance and generalization across various tasks. However, they suffer in inference latency due to their large size. To address this issue, side branches are attached at intermediate layers,... | Divya Jyoti Bajpai, Manjesh K. Hanawal |  |
| 1087 |  |  [UNIWIZ: A Unified Large Language Model Orchestrated Wizard for Safe Knowledge Grounded Conversations](https://doi.org/10.18653/v1/2024.findings-acl.102) |  | 0 | Large Language Models (LLMs) have made significant progress in integrating safety and knowledge alignment. However, adversarial actors can manipulate these models into generating unsafe responses, and excessive safety alignment can lead to unintended hallucinations. To address these challenges, we... | Souvik Das, Rohini K. Srihari |  |
| 1088 |  |  [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://doi.org/10.18653/v1/2024.findings-acl.103) |  | 0 | We show that content on the web is often translated into many languages, and the low quality of these multi-way translations indicates they were likely created using Machine Translation (MT). Multi-way parallel, machine generated content not only dominates the translations in lower resource... | Brian Thompson, Mehak Preet Dhaliwal, Peter Frisch, Tobias Domhan, Marcello Federico |  |
| 1089 |  |  [RankMean: Module-Level Importance Score for Merging Fine-tuned LLM Models](https://doi.org/10.18653/v1/2024.findings-acl.104) |  | 0 | Traditionally, developing new language models (LMs) capable of addressing multiple tasks involves fine-tuning pre-trained LMs using a wide collection of datasets, a process that often incurs significant computational expenses. Model merging emerges as a cost-effective alternative, allowing the... | Gabriel J. Perin, Xuxi Chen, Shusen Liu, Bhavya Kailkhura, Zhangyang Wang, Brian Gallagher |  |
| 1090 |  |  [VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.105) |  | 0 | Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability. A comprehensive quantitative evaluation is necessary to identify and understand the extent of hallucinations in these... | Haoyi Qiu, Wenbo Hu, ZiYi Dou, Nanyun Peng |  |
| 1091 |  |  [Cyclical Contrastive Learning Based on Geodesic for Zero-shot Cross-lingual Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.106) |  | 0 | Owing to the scarcity of labeled training data, Spoken Language Understanding (SLU) is still a challenging task in low-resource languages. Therefore, zero-shot cross-lingual SLU attracts more and more attention. Contrastive learning is widely applied to explicitly align representations of similar... | Xuxin Cheng, Zhihong Zhu, Bang Yang, Xianwei Zhuang, Hongxiang Li, Yuexian Zou |  |
| 1092 |  |  [Towards Safer Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.107) |  | 0 | The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with... | Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang |  |
| 1093 |  |  [The Impact of Reasoning Step Length on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.108) |  | 0 | Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical... | Mingyu Jin, Qinkai Yu, Dong Shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du |  |
| 1094 |  |  [Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness](https://doi.org/10.18653/v1/2024.findings-acl.109) |  | 0 | While task-agnostic debiasing provides notable generalizability and reduced reliance on downstream data, its impact on language modeling ability and the risk of relearning social biases from downstream task-specific data remain as the two most significant challenges when debiasing Pretrained... | Guangliang Liu, Milad Afshari, Xitong Zhang, Zhiyu Xue, Avrajit Ghosh, Bidhan Bashyal, Rongrong Wang, Kristen Marie Johnson |  |
| 1095 |  |  [SKGSum: Structured Knowledge-Guided Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.110) |  | 0 | A summary structure is inherent to certain types of texts according to the Genre Theory of Linguistics. Such structures aid readers in efficiently locating information within summaries. However, most existing automatic summarization methods overlook the importance of summary structure, resulting in... | Qiqi Wang, Ruofan Wang, Kaiqi Zhao, Robert Amor, Benjamin Liu, Jiamou Liu, Xianda Zheng, Zijian Huang |  |
| 1096 |  |  [Chinese Spoken Named Entity Recognition in Real-world Scenarios: Dataset and Approaches](https://doi.org/10.18653/v1/2024.findings-acl.111) |  | 0 | Spoken Named Entity Recognition (NER) aims to extract entities from speech. The extracted entities can help voice assistants better understand user’s questions and instructions. However, current Chinese Spoken NER datasets are laboratory-controlled data that are collected by reading existing texts... | Shilin Zhou, Zhenghua Li, Chen Gong, Lei Zhang, Yu Hong, Min Zhang |  |
| 1097 |  |  [DEBATE: Devil's Advocate-Based Assessment and Text Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.112) |  | 0 | As natural language generation (NLG) models have become prevalent, systematically assessing the quality of machine-generated texts has become increasingly important. Recent studies introduce LLM-based evaluators that operate as reference-free metrics, demonstrating their capability to adeptly... | Alex Kim, Keonwoo Kim, Sangwon Yoon |  |
| 1098 |  |  [Can Large Multimodal Models Uncover Deep Semantics Behind Images?](https://doi.org/10.18653/v1/2024.findings-acl.113) |  | 0 | Understanding the deep semantics of images is essential in the era dominated by social media. However, current research works primarily on the superficial description of images, revealing a notable deficiency in the systematic investigation of the inherent deep semantics. In this work, we introduce... | Yixin Yang, Zheng Li, Qingxiu Dong, Heming Xia, Zhifang Sui |  |
| 1099 |  |  [Harvesting Events from Multiple Sources: Towards a Cross-Document Event Extraction Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.114) |  | 0 | Document-level event extraction aims to extract structured event information from unstructured text. However, a single document often contains limited event information and the roles of different event arguments may be biased due to the influence of the information source.This paper addresses the... | Qiang Gao, Zixiang Meng, Bobo Li, Jun Zhou, Fei Li, Chong Teng, Donghong Ji |  |
| 1100 |  |  [A Graph per Persona: Reasoning about Subjective Natural Language Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.115) |  | 0 | Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the... | Eunjeong Hwang, Vered Shwartz, Dan Gutfreund, Veronika Thost |  |
| 1101 |  |  [MolTC: Towards Molecular Relational Modeling In Language Models](https://doi.org/10.18653/v1/2024.findings-acl.116) |  | 0 | Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities,... | Junfeng Fang, Shuai Zhang, Chang Wu, Zhengyi Yang, Zhiyuan Liu, Sihang Li, Kun Wang, Wenjie Du, Xiang Wang |  |
| 1102 |  |  [KPEval: Towards Fine-Grained Semantic-Based Keyphrase Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.117) |  | 0 | Despite the significant advancements in keyphrase extraction and keyphrase generation methods, the predominant approach for evaluation mainly relies on exact matching with human references. This scheme fails to recognize systems that generate keyphrases semantically equivalent to the references or... | Di Wu, Da Yin, KaiWei Chang |  |
| 1103 |  |  [Learning Low-dimensional Multi-domain Knowledge Graph Embedding via Dual Archimedean Spirals](https://doi.org/10.18653/v1/2024.findings-acl.118) |  | 0 | Knowledge graph embedding (KGE) is extensively employed for link prediction by representing entities and relations as low-dimensional vectors. In real-world scenarios, knowledge graphs (KGs) usually encompass diverse domains, which poses challenges to KG representations. However, existing KGE... | Jiang Li, Xiangdong Su, Fujun Zhang, Guanglai Gao |  |
| 1104 |  |  [LoRA Meets Dropout under a Unified Framework](https://doi.org/10.18653/v1/2024.findings-acl.119) |  | 0 | With the remarkable capabilities, large language models (LLMs) have emergedas essential elements in numerous NLP applications, while parameter-efficientfinetuning, especially LoRA, has gained popularity as a lightweight approachfor model customization. Meanwhile, various dropout methods, initially... | Sheng Wang, Liheng Chen, Jiyue Jiang, Boyang Xue, Lingpeng Kong, Chuan Wu |  |
| 1105 |  |  [Enhancing Text-to-SQL Parsing through Question Rewriting and Execution-Guided Refinement](https://doi.org/10.18653/v1/2024.findings-acl.120) |  | 0 | Large Language Model (LLM)-based approach has become the mainstream for Text-to-SQL task and achieves remarkable performance. In this paper, we augment the existing prompt engineering methods by exploiting the database content and execution feedback. Specifically, we introduce DART-SQL, which... | Wenxin Mao, Ruiqi Wang, Jiyu Guo, Jichuan Zeng, Cuiyun Gao, Peiyi Han, Chuanyi Liu |  |
| 1106 |  |  [The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.121) |  | 0 | Large language models often necessitate grounding on external knowledge to generate faithful and reliable answers. Yet even with the correct groundings in the reference, they can ignore them and rely on wrong groundings or their inherent biases to hallucinate when users, being largely unaware of... | Shuo Zhang, Liangming Pan, Junzhou Zhao, William Yang Wang |  |
| 1107 |  |  [ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.122) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of... | Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, Anh Tuan Luu |  |
| 1108 |  |  [Achilles-Bench: A Challenging Benchmark for Low-Resource Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.123) |  | 0 | With promising yet saturated results in high-resource settings, low-resource datasets have gradually become crucial benchmarks (e.g., BigBench Hard, superGLUE) for evaluating the learning ability of advanced neural networks. In this work, we find that there exists a set of “hard examples” in... | Yudong Wang, Chang Ma, Qingxiu Dong, Zhifang Sui, Lingpeng Kong, Jingjing Xu |  |
| 1109 |  |  [INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair](https://doi.org/10.18653/v1/2024.findings-acl.124) |  | 0 | This paper introduces INTERVENOR (INTERactiVE chaiN Of Repair), a system designed to emulate the interactive code repair processes observed in humans, encompassing both code diagnosis and code repair. INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair... | Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, Ge Yu |  |
| 1110 |  |  [SocialBench: Sociality Evaluation of Role-Playing Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.125) |  | 0 | Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge and... | Hongzhan Chen, Hehong Chen, Ming Yan, Wenshen Xu, Gao Xing, Weizhou Shen, Xiaojun Quan, Chenliang Li, Ji Zhang, Fei Huang |  |
| 1111 |  |  [From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications](https://doi.org/10.18653/v1/2024.findings-acl.126) |  | 0 | Evaluating large language models (LLMs) is fundamental, particularly in the context of practical applications. Conventional evaluation methods, typically designed primarily for LLM development, yield numerical scores that ignore the user experience. Therefore, our study shifts the focus from... | Yongqiang Ma, Lizhi Qing, Jiawei Liu, Yangyang Kang, Yue Zhang, Wei Lu, Xiaozhong Liu, Qikai Cheng |  |
| 1112 |  |  [Context-Aware Tracking and Dynamic Introduction for Incomplete Utterance Rewriting in Extended Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.findings-acl.127) |  | 0 | Incomplete utterance rewriting (IUR) aims to reconstruct the utterance with omitted information and pronouns to be standalone and complete based on the context. The existing works predominantly focus on simple ellipsis and coreference problems in brief multi-turn dialogues. But in actual scenarios:... | Xinnan Guo, Qian Zhu, Qiuhui Shi, Xuan Lin, Liubin Wang, DaqianLi DaqianLi, Yongrui Chen |  |
| 1113 |  |  [EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.128) |  | 0 | Emotional intelligence in large language models (LLMs) is of great importance in Natural Language Processing. However, the previous research mainly focus on basic sentiment analysis tasks, such as emotion recognition, which is not enough to evaluate LLMs’ overall emotional intelligence. Therefore,... | Yuyan Chen, Songzhou Yan, Sijia Liu, Yueze Li, Yanghua Xiao |  |
| 1114 |  |  [Plum: Prompt Learning using Metaheuristics](https://doi.org/10.18653/v1/2024.findings-acl.129) |  | 0 | Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering... | Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang Liu, Kashun Shum, Jipeng Zhang, Renjie Pi, Tong Zhang |  |
| 1115 |  |  [HOTVCOM: Generating Buzzworthy Comments for Videos](https://doi.org/10.18653/v1/2024.findings-acl.130) |  | 0 | In the era of social media video platforms, popular “hot-comments” play a crucial role in attracting user impressions of short-form videos, making them vital for marketing and branding purpose. However, existing research predominantly focuses on generating descriptive comments or “danmaku” in... | Yuyan Chen, Songzhou Yan, Qingpei Guo, Jiyuan Jia, Zhixu Li, Yanghua Xiao |  |
| 1116 |  |  [Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?](https://doi.org/10.18653/v1/2024.findings-acl.131) |  | 0 | The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs’... | Yuyan Chen, Yueze Li, Songzhou Yan, Sijia Liu, Jiaqing Liang, Yanghua Xiao |  |
| 1117 |  |  [Distilling Robustness into Natural Language Inference Models with Domain-Targeted Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.132) |  | 0 | Knowledge distillation optimises a smaller student model to behave similarly to a larger teacher model, retaining some of the performance benefits. While this method can improve results on in-distribution examples, it does not necessarily generalise to out-of-distribution (OOD) settings. We... | Joe Stacey, Marek Rei |  |
| 1118 |  |  [Into the Unknown: Generating Geospatial Descriptions for New Environments](https://doi.org/10.18653/v1/2024.findings-acl.133) |  | 0 | Similar to vision-and-language navigation (VLN) tasks that focus on bridging the gap between vision and language for embodied navigation, the new Rendezvous (RVS) task requires reasoning over allocentric spatial relationships using non-sequential navigation instructions and maps. However,... | Tzuf PazArgaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge |  |
| 1119 |  |  [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.134) |  | 0 | Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability... | Omer Goldman, Avi Caciularu, Matan Eyal, Kris Cao, Idan Szpektor, Reut Tsarfaty |  |
| 1120 |  |  [Length-aware Byte Pair Encoding for Mitigating Over-segmentation in Korean Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.135) |  | 0 | Byte Pair Encoding is an effective approach in machine translation across several languages. However, our analysis indicates that BPE is prone to over-segmentation in the morphologically rich language, Korean, which can erode word semantics and lead to semantic confusion during training. This... | Jungseob Lee, Hyeonseok Moon, Seungjun Lee, Chanjun Park, Sugyeong Eo, Hyunwoong Ko, Jaehyung Seo, Seungyoon Lee, Heuiseok Lim |  |
| 1121 |  |  [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://doi.org/10.18653/v1/2024.findings-acl.136) |  | 0 | As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across... | Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal |  |
| 1122 |  |  [M3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-acl.137) |  | 0 | In this paper, we introduce a new embedding model called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It provides a uniform support for the semantic retrieval of more than 100 working languages. It can simultaneously... | Jianlyu Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu |  |
| 1123 |  |  [Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback](https://doi.org/10.18653/v1/2024.findings-acl.138) |  | 0 | Large Language Models (LLMs) have shown remarkable progress in automated code generation. Yet, LLM-generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must... | Zhangqian Bi, Yao Wan, Zheng Wang, Hongyu Zhang, Batu Guan, Fangxin Lu, Zili Zhang, Yulei Sui, Hai Jin, Xuanhua Shi |  |
| 1124 |  |  [An Element is Worth a Thousand Words: Enhancing Legal Case Retrieval by Incorporating Legal Elements](https://doi.org/10.18653/v1/2024.findings-acl.139) |  | 0 | Legal case retrieval plays an important role in promoting judicial justice and fairness. One of its greatest challenges is that the definition of relevance goes far beyond the common semantic relevance as in ad-hoc retrieval. In this paper, we reveal that the legal elements, which typically... | Chenlong Deng, Zhicheng Dou, Yujia Zhou, Peitian Zhang, Kelong Mao |  |
| 1125 |  |  [SoMeLVLM: A Large Vision Language Model for Social Media Processing](https://doi.org/10.18653/v1/2024.findings-acl.140) |  | 0 | The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks... | Xinnong Zhang, Haoyu Kuang, Xinyi Mou, Hanjia Lyu, Kun Wu, Siming Chen, Jiebo Luo, Xuanjing Huang, Zhongyu Wei |  |
| 1126 |  |  [KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.141) |  | 0 | The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs against socially acceptable commonsense standards in... | Jaehyung Seo, Jaewook Lee, Chanjun Park, Seongtae Hong, Seungjun Lee, Heuiseok Lim |  |
| 1127 |  |  [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.142) |  | 0 | Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at... | Amit Dhurandhar, Tejaswini Pedapati, Ronny Luss, Soham Dan, Aurélie C. Lozano, Payel Das, Georgios Kollias |  |
| 1128 |  |  [Ranking Large Language Models without Ground Truth](https://doi.org/10.18653/v1/2024.findings-acl.143) |  | 0 | Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In... | Amit Dhurandhar, Rahul Nair, Moninder Singh, Elizabeth Daly, Karthikeyan Natesan Ramamurthy |  |
| 1129 |  |  [Integrating Physician Diagnostic Logic into Large Language Models: Preference Learning from Process Feedback](https://doi.org/10.18653/v1/2024.findings-acl.144) |  | 0 | The utilization of large language models for medical dialogue generation has attracted considerable attention due to its potential to enhance response richness and coherence. While previous studies have made strides in optimizing model performance, there is a pressing need to bolster the model’s... | Chengfeng Dou, Ying Zhang, Zhi Jin, Wenpin Jiao, Haiyan Zhao, Yongqiang Zhao, Zhengwei Tao |  |
| 1130 |  |  [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://doi.org/10.18653/v1/2024.findings-acl.145) |  | 0 | The pre-trained language models are continually fine-tuned to better support downstream applications. However, this operation may result in significant performance degeneration on general tasks beyond the targeted domain. To overcome this problem, we propose LM-Cocktail which enables the fine-tuned... | Shitao Xiao, Zheng Liu, Peitian Zhang, Xingrun Xing |  |
| 1131 |  |  [Episodic Memory Retrieval from LLMs: A Neuromorphic Mechanism to Generate Commonsense Counterfactuals for Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.146) |  | 0 | Large language models (LLMs) have achieved satisfactory performance in counterfactual generation. However, confined by the stochastic generation process of LLMs, there often are misalignments between LLMs and humans which hinder LLMs from handling complex tasks like relation extraction. As a... | Xin Miao, Yongqi Li, Shen Zhou, Tieyun Qian |  |
| 1132 |  |  [SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages](https://doi.org/10.18653/v1/2024.findings-acl.147) |  | 0 | Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader... | Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine de Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Indra Winata, Seid Muhie Yimam, Saif M. Mohammad |  |
| 1133 |  |  [Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector](https://doi.org/10.18653/v1/2024.findings-acl.148) |  | 0 | Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models,... | Haihui Yang, Xiaojun Quan |  |
| 1134 |  |  [VISPool: Enhancing Transformer Encoders with Vector Visibility Graph Neural Networks](https://doi.org/10.18653/v1/2024.findings-acl.149) |  | 0 | The emergence of transformers has revolutionized natural language processing (NLP), as evidenced in various NLP tasks. While graph neural networks (GNNs) show recent promise in NLP, they are not standalone replacements for transformers. Rather, recent research explores combining transformers and... | Tuna Alikasifoglu, Arda C. Aras, Aykut Koç |  |
| 1135 |  |  [The Emotion Dynamics of Literary Novels](https://doi.org/10.18653/v1/2024.findings-acl.150) |  | 0 | Stories are rich in the emotions they exhibit in their narratives and evoke in the readers. The emotional journeys of the various characters within a story are central to their appeal. Computational analysis of the emotions of novels, however, has rarely examined the variation in the emotional... | Krishnapriya Vishnubhotla, Adam Hammond, Graeme Hirst, Saif M. Mohammad |  |
| 1136 |  |  [Accurate and Nuanced Open-QA Evaluation Through Textual Entailment](https://doi.org/10.18653/v1/2024.findings-acl.151) |  | 0 | Open-domain question answering (Open-QA) is a common task for evaluating large language models (LLMs). However, current Open-QA evaluations are criticized for the ambiguity in questions and the lack of semantic understanding in evaluators. Complex evaluators, powered by foundation models or LLMs... | Peiran Yao, Denilson Barbosa |  |
| 1137 |  |  [Dictionary-Aided Translation for Handling Multi-Word Expressions in Low-Resource Languages](https://doi.org/10.18653/v1/2024.findings-acl.152) |  | 0 | Multi-word expressions (MWEs) present unique challenges in natural language processing (NLP), particularly within the context of translation systems, due to their inherent scarcity, non-compositional nature, and other distinct lexical and morphosyntactic characteristics, issues that are exacerbated... | Antonios Dimakis, Stella Markantonatou, Antonios Anastasopoulos |  |
| 1138 |  |  [LANS: A Layout-Aware Neural Solver for Plane Geometry Problem](https://doi.org/10.18653/v1/2024.findings-acl.153) |  | 0 | Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion, and reasoning. Existing neural solvers take GPS as a vision-language task but are short in the representation of geometry diagrams that carry rich and complex layout information.... | Zhongzhi Li, MingLiang Zhang, Fei Yin, ChengLin Liu |  |
| 1139 |  |  [Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.154) |  | 0 | We propose Knowledge Crosswords, a geometric knowledge reasoning benchmark consisting of incomplete knowledge networks bounded by structured factual constraints, where LLMs are tasked with inferring the missing facts to meet all constraints. The novel setting of geometric knowledge reasoning... | Wenxuan Ding, Shangbin Feng, Yuhan Liu, Zhaoxuan Tan, Vidhisha Balachandran, Tianxing He, Yulia Tsvetkov |  |
| 1140 |  |  [DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection](https://doi.org/10.18653/v1/2024.findings-acl.155) |  | 0 | Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where... | Herun Wan, Shangbin Feng, Zhaoxuan Tan, Heng Wang, Yulia Tsvetkov, Minnan Luo |  |
| 1141 |  |  [The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts](https://doi.org/10.18653/v1/2024.findings-acl.156) |  | 0 | As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to... | Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, Daniel Khashabi |  |
| 1142 |  |  [Self-Specialization: Uncovering Latent Expertise within Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.157) |  | 0 | Recent works have demonstrated the effectiveness of self-alignment in which a large language model is aligned to follow general instructions using instructional data generated from the model itself starting from a handful of human-written seeds. Instead of general alignment, in this work, we focus... | Junmo Kang, Hongyin Luo, Yada Zhu, Jacob A. Hansen, James R. Glass, David D. Cox, Alan Ritter, Rogério Feris, Leonid Karlinsky |  |
| 1143 |  |  [FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion](https://doi.org/10.18653/v1/2024.findings-acl.158) |  | 0 | Taxonomy Expansion, which relies on modeling concepts and concept relations, can be formulated as a set representation learning task. The generalization of set, fuzzy set, incorporates uncertainty and measures the information within a semantic concept, making it suitable for concept modeling.... | Fred Xu, Song Jiang, Zijie Huang, Xiao Luo, Shichang Zhang, Yuanzhou Chen, Yizhou Sun |  |
| 1144 |  |  [Chain of Logic: Rule-Based Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.159) |  | 0 | Rule-based reasoning, a fundamental type of legal reasoning, enables us to draw conclusions by accurately applying a rule to a set of facts. We explore causal language models as rule-based reasoners, specifically with respect to compositional rules - rules consisting of multiple elements which form... | Sergio Servantez, Joe Barrow, Kristian J. Hammond, Rajiv Jain |  |
| 1145 |  |  [Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations](https://doi.org/10.18653/v1/2024.findings-acl.160) |  | 0 | Long-form generations from large language models (LLMs) contain a mix of factual and non-factual claims, making evaluating factuality difficult.Prior works evaluate the factuality of a long paragraph by decomposing it into multiple facts, verifying those facts independently, and aggregating the... | ChengHan Chiang, Hungyi Lee |  |
| 1146 |  |  [Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment](https://doi.org/10.18653/v1/2024.findings-acl.161) |  | 0 | Do LMs infer the semantics of text from co-occurrence patterns in their training data? Merrill et al. (2022) argue that, in theory, sentence co-occurrence probabilities predicted by an optimal LM should reflect the entailment relationship of the constituent sentences, but it is unclear whether... | William Merrill, Zhaofeng Wu, Norihito Naka, Yoon Kim, Tal Linzen |  |
| 1147 |  |  [Simulated Misinformation Susceptibility (SMISTS): Enhancing Misinformation Research with Large Language Model Simulations](https://doi.org/10.18653/v1/2024.findings-acl.162) |  | 0 | Psychological inoculation, a strategy designed to build resistance against persuasive misinformation, has shown efficacy in curbing its spread and mitigating its adverse effects at early stages. Despite its effectiveness, the design and optimization of these inoculations typically demand... | Weicheng Ma, Chunyuan Deng, Aram Moossavi, Lili Wang, Soroush Vosoughi, Diyi Yang |  |
| 1148 |  |  [Social Intelligence Data Infrastructure: Structuring the Present and Navigating the Future](https://doi.org/10.18653/v1/2024.findings-acl.163) |  | 0 | As Natural Language Processing (NLP) systems become increasingly integrated into human social life, these technologies will need to increasingly rely on social intelligence. Although there are many valuable datasets that benchmark isolated dimensions of social intelligence, there does not yet exist... | Minzhi Li, Weiyan Shi, Caleb Ziems, Diyi Yang |  |
| 1149 |  |  [Selective Prefix Tuning for Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.164) |  | 0 | The prevalent approach for optimizing pre-trained language models in downstream tasks is fine-tuning. However, it is both time-consuming and memory-inefficient. In response, a more efficient method called Prefix Tuning, which insert learnable vectors into each Transformer layers, has been proposed... | Hongyi Zhang, Zuchao Li, Ping Wang, Hai Zhao |  |
| 1150 |  |  [MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization](https://doi.org/10.18653/v1/2024.findings-acl.165) |  | 0 | The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We... | Xiaobo Guo, Soroush Vosoughi |  |
| 1151 |  |  [Non-compositional Expression Generation and its Continual Learning](https://doi.org/10.18653/v1/2024.findings-acl.166) |  | 0 | Non-compositional expressions are an integral part of natural language and their meanings cannot be directly derived from the meanings of their component words. Recent work has shown how their processing remains a challenge for pre-trained language models. Here we consider the fact that prior... | Jianing Zhou, Suma Bhat |  |
| 1152 |  |  [Medical Dialogue System: A Survey of Categories, Methods, Evaluation and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.167) |  | 0 | This paper surveys and organizes research works of medical dialog systems, which is an important yet challenging task. Although these systems have been surveyed in the medical community from an application perspective, a systematic review from a rigorous technical perspective has to date remained... | Xiaoming Shi, Zeming Liu, Li Du, Yuxuan Wang, Hongru Wang, Yuhang Guo, Tong Ruan, Jie Xu, Xiaofan Zhang, Shaoting Zhang |  |
| 1153 |  |  [Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.168) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this... | Thi Nguyen, Linhao Luo, Fatemeh Shiri, Dinh Phung, YuanFang Li, ThuyTrang Vu, Gholamreza Haffari |  |
| 1154 |  |  [Comprehensive Abstractive Comment Summarization with Dynamic Clustering and Chain of Thought](https://doi.org/10.18653/v1/2024.findings-acl.169) |  | 0 | Real-world news comments pose a significant challenge due to their noisy and ambiguous nature, which complicates their modeling for clustering and summarization tasks. Most previous research has predominantly focused on extractive summarization methods within specific constraints. This paper... | Longyin Zhang, Bowei Zou, Jacintha Yi, AiTi Aw |  |
| 1155 |  |  [Self-Supervised Position Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.170) |  | 0 | Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Previous works have proven that LLMs are prone to exhibit... | Zhongkun Liu, Zheng Chen, Mengqi Zhang, Zhaochun Ren, Pengjie Ren, Zhumin Chen |  |
| 1156 |  |  [HyperCL: A Contrastive Learning Framework for Hyper-Relational Knowledge Graph Embedding with Hierarchical Ontology](https://doi.org/10.18653/v1/2024.findings-acl.171) |  | 0 |  | Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang |  |
| 1157 |  |  [Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection](https://doi.org/10.18653/v1/2024.findings-acl.172) |  | 0 | Multifaceted ideology detection (MID) aims to detect the ideological leanings of texts towards multiple facets. Previous studies on ideology detection mainly focus on one generic facet and ignore label semantics and explanatory descriptions of ideologies, which are a kind of instructive information... | Songtao Liu, Bang Wang, Wei Xiang, Han Xu, Minghua Xu |  |
| 1158 |  |  [Character-Level Chinese Dependency Parsing via Modeling Latent Intra-Word Structure](https://doi.org/10.18653/v1/2024.findings-acl.173) |  | 0 | Revealing the syntactic structure of sentences in Chinese poses significant challenges for word-level parsers due to the absence of clear word boundaries. To facilitate a transition from word-level to character-level Chinese dependency parsing, this paper proposes modeling latent internal... | Yang Hou, Zhenghua Li |  |
| 1159 |  |  [AlignRE: An Encoding and Semantic Alignment Approach for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.174) |  | 0 | Zero-shot Relation Extraction (ZSRE) aims to predict unseen relations between entity pairs from input sentences. Existing prototype-based ZSRE methods encode relation descriptions into prototype embeddings and predict by measuring the similarity between sentence embeddings and prototype embeddings.... | Zehan Li, Fu Zhang, Jingwei Cheng |  |
| 1160 |  |  [Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction](https://doi.org/10.18653/v1/2024.findings-acl.175) |  | 0 | Supervised fine-tuning (SFT) on instruction-following corpus is a crucial approach toward the alignment of large language models (LLMs). However, the performance of LLMs on standard knowledge and reasoning benchmarks tends to suffer from deterioration at the latter stage of the SFT process, echoing... | Tingchen Fu, Deng Cai, Lemao Liu, Shuming Shi, Rui Yan |  |
| 1161 |  |  [Efficient Knowledge Infusion via KG-LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.176) |  | 0 | To tackle the problem of domain-specific knowledge scarcity within large language models (LLMs), knowledge graph-retrievalaugmented method has been proven to be an effective and efficient technique for knowledge infusion. However, existing approaches face two primary challenges: knowledge mismatch... | Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang |  |
| 1162 |  |  [Towards Precise Localization of Critical Errors in Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.177) |  | 0 | The advent of large language models has experienced a remarkable improvement in the field of machine translation. However, machine translation is still vulnerable to critical meaning deviations, which may incur catastrophic issues in social or ethical contexts. In particular, existing critical... | Dahyun Jung, Sugyeong Eo, Heuiseok Lim |  |
| 1163 |  |  [LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.178) |  | 0 | Large Language Models (LLMs), such as LLaMA and T5, have shown exceptional performance across various tasks through fine-tuning. Although low-rank adaption (LoRA) has emerged to cheaply fine-tune these LLMs on downstream tasks, their deployment is still hindered by the vast model scale and... | Mingyang Zhang, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang |  |
| 1164 |  |  [Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.179) |  | 0 | The recent advancements in large language models (LLMs) have been extraordinary, yet the escalating inference costs associated with them present challenges in real-world applications. To address these challenges, we propose a novel approach called Early-exiting Speculative Decoding (EESD) with... | Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai |  |
| 1165 |  |  [Towards Better Utilization of Multi-Reference Training Data for Chinese Grammatical Error Correction](https://doi.org/10.18653/v1/2024.findings-acl.180) |  | 0 | For the grammatical error correction (GEC) task, there usually exist multiple correction ways for an erroneous input sentence, leading to multiple references. Observing the high proportion of multi-reference instances in Chinese GEC training data, we target a systematic study on how to better... | Yumeng Liu, Zhenghua Li, Haochen Jiang, Bo Zhang, Chen Li, Ji Zhang |  |
| 1166 |  |  [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.181) |  | 0 | Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs... | Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, Jie Tang |  |
| 1167 |  |  [Transition-based Opinion Generation for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.182) |  | 0 | Recently, the use of pre-trained generation models for extracting sentiment elements has resulted in significant advancements in aspect-based sentiment analysis benchmarks. However, these approaches often overlook the importance of explicitly modeling structure among sentiment elements. To address... | Tianlai Ma, Zhongqing Wang, Guodong Zhou |  |
| 1168 |  |  [Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion](https://doi.org/10.18653/v1/2024.findings-acl.183) |  | 0 | Dynamic topic models track the evolution of topics in sequential documents, which have derived various applications like trend analysis. However, existing models suffer from repetitive topic and unassociated topic issues, failing to reveal the evolution and hindering further applications. To... | Xiaobao Wu, Xinshuai Dong, Liangming Pan, Thong Nguyen, Anh Tuan Luu |  |
| 1169 |  |  [A Chinese Dataset for Evaluating the Safeguards in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.184) |  | 0 | Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks. Previous studies have proposed comprehensive taxonomies of LLM risks, as well as corresponding prompts that can be used to examine LLM safety. However, the focus has... | Yuxia Wang, Zenan Zhai, Haonan Li, Xudong Han, Shom Lin, Zhenxuan Zhang, Angela Zhao, Preslav Nakov, Timothy Baldwin |  |
| 1170 |  |  [LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction](https://doi.org/10.18653/v1/2024.findings-acl.185) |  | 0 | Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting... | Meiyun Wang, Kiyoshi Izumi, Hiroki Sakaji |  |
| 1171 |  |  [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://doi.org/10.18653/v1/2024.findings-acl.186) |  | 0 | Autonomous graphical user interface (GUI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To... | Zhuosheng Zhang, Aston Zhang |  |
| 1172 |  |  [SP³: Enhancing Structured Pruning via PCA Projection](https://doi.org/10.18653/v1/2024.findings-acl.187) |  | 0 |  | Yuxuan Hu, Jing Zhang, Zhe Zhao, Chen Zhao, Xiaodong Chen, Cuiping Li, Hong Chen |  |
| 1173 |  |  [GENDEX: Generative Data Augmentation Strategy Leveraging External Data for Abstractive Dialogue Summarization](https://doi.org/10.18653/v1/2024.findings-acl.188) |  | 0 | With the proliferation of digital communication, dialogue summarization has become increasingly important. However, it still faces a shortage of data. To address this issue, we developed \*\*Gen\*\*erative \*\*D\*\*ata Augmentation Strategy Leveraging \*\*Ex\*\*ternal Data for Abstractive Dialogue... | Sangwon Park, Hongseok Choi, Dongha Choi, Hyunju Lee |  |
| 1174 |  |  [Concept-Best-Matching: Evaluating Compositionality In Emergent Communication](https://doi.org/10.18653/v1/2024.findings-acl.189) |  | 0 | Artificial agents that learn to communicate in order to accomplish a given task acquire communication protocols that are typically opaque to a human. A large body of work has attempted to evaluate the emergent communication via various evaluation measures, with \*\*compositionality\*\* featuring as... | Boaz Carmeli, Yonatan Belinkov, Ron Meir |  |
| 1175 |  |  [A Tale of Two Revisions: Summarizing Changes Across Document Versions](https://doi.org/10.18653/v1/2024.findings-acl.190) |  | 0 | Document revision is a crucial aspect of the writing process, particularly in collaborative environments where multiple authors contribute simultaneously. However, current tools lack an efficient way to provide a comprehensive overview of changes between versions, leading to difficulties in... | T. Y. S. S. Santosh, Natwar Modani, Apoorv Saxena |  |
| 1176 |  |  [Refine, Align, and Aggregate: Multi-view Linguistic Features Enhancement for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.191) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplets of aspect terms, their associated sentiment and opinion terms. Previous works based on different modeling paradigms have achieved promising results. However, these methods struggle to comprehensively explore the various... | Guixin Su, Mingmin Wu, Zhongqiang Huang, Yongcheng Zhang, Tongguan Wang, Yuxue Hu, Ying Sha |  |
| 1177 |  |  [Pro-Woman, Anti-Man? Identifying Gender Bias in Stance Detection](https://doi.org/10.18653/v1/2024.findings-acl.192) |  | 0 | Gender bias has been widely observed in NLP models, which has the potential to perpetuate harmful stereotypes and discrimination. In this paper, we construct a dataset GenderStance of 36k samples to measure gender bias in stance detection, determining whether models consistently predict the same... | Yingjie Li, Yue Zhang |  |
| 1178 |  |  [Likelihood-based Mitigation of Evaluation Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.193) |  | 0 | Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics.However, the likelihood, a measure of LLM’s plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure.It is therefore... | Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki Okazaki |  |
| 1179 |  |  [The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.194) |  | 0 | Benchmark plays a pivotal role in assessing the advancements of large language models (LLMs). While numerous benchmarks have been proposed to evaluate LLMs’ capabilities, there is a notable absence of a dedicated benchmark for assessing their musical abilities. To address this gap, we present... | Jiajia Li, Lu Yang, Mingni Tang, Chenchong Chenchong, Zuchao Li, Ping Wang, Hai Zhao |  |
| 1180 |  |  [PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference](https://doi.org/10.18653/v1/2024.findings-acl.195) |  | 0 | Large Language Models (LLMs) have shown remarkable comprehension abilities but face challenges in GPU memory usage during inference, hindering their scalability for real-time applications like chatbots. To accelerate inference, we store computed keys and values (KV cache) in the GPU memory.... | Dongjie Yang, Xiaodong Han, Yan Gao, Yao Hu, Shilin Zhang, Hai Zhao |  |
| 1181 |  |  [From Role-Play to Drama-Interaction: An LLM Solution](https://doi.org/10.18653/v1/2024.findings-acl.196) |  | 0 | Drama is a form of storytelling inspired by human creativity, proceeding with a predefined storyline, carrying emotions and thoughts.This paper introduces LLM-based interactive drama, which endows traditional drama with an unprecedented immersion, where a person is allowed to walk into it and... | Weiqi Wu, Hongqiu Wu, Lai Jiang, Xingyuan Liu, Hai Zhao, Min Zhang |  |
| 1182 |  |  [TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.197) |  | 0 | While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users’ narrative... | Jaewoo Ahn, Taehyun Lee, Junyoung Lim, JinHwa Kim, Sangdoo Yun, Hwaran Lee, Gunhee Kim |  |
| 1183 |  |  [Red Teaming Visual Language Models](https://doi.org/10.18653/v1/2024.findings-acl.198) |  | 0 | VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar... | Mukai Li, Lei Li, Yuwei Yin, Masood Ahmed, Zhenguang Liu, Qi Liu |  |
| 1184 |  |  [Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach](https://doi.org/10.18653/v1/2024.findings-acl.199) |  | 0 | A Large Language Model (LLM) tends to generate inconsistent and sometimes contradictory outputs when presented with a prompt that has equivalent semantics but is expressed differently from the original prompt. To achieve semantic consistency of an LLM, one of the key approaches is to finetune the... | Jingyuan Yang, Dapeng Chen, Yajing Sun, Rongjun Li, Zhiyong Feng, Wei Peng |  |
| 1185 |  |  [Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments](https://doi.org/10.18653/v1/2024.findings-acl.200) |  | 0 | In embodied instruction-following (EIF), the integration of pretrained language models (LMs) as task planners emerges as a significant branch, where tasks are planned at the skill level by prompting LMs with pretrained skills and user instructions. However, grounding these pretrained skills in... | Sangwoo Shin, Seunghyun Kim, Youngsoo Jang, Moontae Lee, Honguk Woo |  |
| 1186 |  |  [LIRE: listwise reward enhancement for preference alignment](https://doi.org/10.18653/v1/2024.findings-acl.201) |  | 0 | Recently, tremendous strides have been made to align the generation of Large Language Models (LLMs) with human values to mitigate toxic or unhelpful content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves effective and is widely adopted by researchers. However, implementing... | Mingye Zhu, Yi Liu, Lei Zhang, Junbo Guo, Zhendong Mao |  |
| 1187 |  |  [See It All: Contextualized Late Aggregation for 3D Dense Captioning](https://doi.org/10.18653/v1/2024.findings-acl.202) |  | 0 | 3D dense captioning is a task to localize objects in a 3D scene and generate descriptive sentences for each object. Recent approaches in 3D dense captioning have adopted transformer encoder-decoder frameworks from object detection to build an end-to-end pipeline without hand-crafted components.... | Minjung Kim, Hyung Lim, Seung Hwan Kim, Soonyoung Lee, Bumsoo Kim, Gunhee Kim |  |
| 1188 |  |  [DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.203) |  | 0 | Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning autonomous language agents in various real-life applications. To improve the neural-symbolic reasoning capabilities of language agents powered by Large Language Models (LLMs) in KGQA, we propose the... | Haishuo Fang, Xiaodan Zhu, Iryna Gurevych |  |
| 1189 |  |  [GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment](https://doi.org/10.18653/v1/2024.findings-acl.204) |  | 0 | The burgeoning size of Large Language Models (LLMs) has led to enhanced capabilities in generating responses, albeit at the expense of increased inference times and elevated resource demands. Existing methods of acceleration, predominantly hinged on knowledge distillation, generally necessitate... | Yao Yao, Zuchao Li, Hai Zhao |  |
| 1190 |  |  [Compositional Generalization with Grounded Language Models](https://doi.org/10.18653/v1/2024.findings-acl.205) |  | 0 | Grounded language models use external sources of information, such as knowledge graphs, to meet some of the general challenges associated with pre-training. By extending previous work on compositional generalization in semantic parsing, we allow for a controlled evaluation of the degree to which... | Sondre Wold, Étienne Simon, Lucas Georges Gabriel Charpentier, Egor V. Kostylev, Erik Velldal, Lilja Øvrelid |  |
| 1191 |  |  [Rethinking Negative Instances for Generative Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.206) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric... | Yuyang Ding, Juntao Li, Pinzheng Wang, Zecheng Tang, Yan Bowen, Min Zhang |  |
| 1192 |  |  [WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.207) |  | 0 | Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. This study reveals a... | Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 1193 |  |  [DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference](https://doi.org/10.18653/v1/2024.findings-acl.208) |  | 0 | Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have... | Jialong Wu, Linhai Zhang, Deyu Zhou, Guoqiang Xu |  |
| 1194 |  |  [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.209) |  | 0 | Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning... | Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu |  |
| 1195 |  |  [How Much Does Nonverbal Communication Conform to Entropy Rate Constancy?: A Case Study on Listener Gaze in Interaction](https://doi.org/10.18653/v1/2024.findings-acl.210) |  | 0 | According to the Entropy Rate Constancy (ERC) principle, the information density of a text is approximately constant over its length. Whether this principle also applies to nonverbal communication signals is still under investigation. We perform empirical analyses of video-recorded dialogue data... | Yu Wang, Yang Xu, Gabriel Skantze, Hendrik Buschmeier |  |
| 1196 |  |  [Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.211) |  | 0 | This study investigates how Large Language Models (LLMs) leverage source and reference data in machine translation evaluation task, aiming to better understand the mechanisms behind their remarkable performance in this task.We design the controlled experiments across various input modes and model... | Xu Huang, Zhirui Zhang, Xiang Geng, Yichao Du, Jiajun Chen, Shujian Huang |  |
| 1197 |  |  [Chain-of-Verification Reduces Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.212) |  | 0 | Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method... | Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, Jason Weston |  |
| 1198 |  |  [Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method](https://doi.org/10.18653/v1/2024.findings-acl.213) |  | 0 | Bargaining is an important and unique part of negotiation between humans. As LLM-driven agents learn to negotiate and act like real humans, how to evaluate agents’ bargaining abilities remains an open problem.For the first time, we formally described the Bargaining task as an asymmetric incomplete... | Tian Xia, Zhiwei He, Tong Ren, Yibo Miao, Zhuosheng Zhang, Yang Yang, Rui Wang |  |
| 1199 |  |  [DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories](https://doi.org/10.18653/v1/2024.findings-acl.214) |  | 0 | How to evaluate the coding abilities of Large Language Models (LLMs) remains an open question. We find that existing benchmarks are poorly aligned with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs.To address the knowledge gap, we propose a new benchmark... | Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Huanyu Liu, Hao Zhu, Lecheng Wang, Kaibo Liu, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yuqi Zhu, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li, Bin Gu, Mengfei Yang |  |
| 1200 |  |  [LPNL: Scalable Link Prediction with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.215) |  | 0 | Exploring the application of large language models (LLMs) to graph learning is an emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to graph learning with LLMs. This work focuses on the link prediction task and introduces \*\*LPNL\*\*... | Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng |  |
| 1201 |  |  [Aligning Speech Segments Beyond Pure Semantics](https://doi.org/10.18653/v1/2024.findings-acl.216) |  | 0 | Multilingual parallel data for speech-to-speech translation is scarce and expensive to create from scratch. This is all the more true for expressive speech translation, which aims at preserving not only the semantics, but also the overall prosody (e.g. style, emotion, rate-of-speech). Existing... | Kevin Heffernan, Artyom Kozhevnikov, Loïc Barrault, Alexandre Mourachko, Holger Schwenk |  |
| 1202 |  |  [Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives](https://doi.org/10.18653/v1/2024.findings-acl.217) |  | 0 | Humans use multiple senses to comprehend the environment. Vision and language are two of the most vital senses since they allow us to easily communicate our thoughts and perceive the world around us. There has been a lot of interest in creating video-language understanding systems with human-like... | Thong Nguyen, Yi Bin, Junbin Xiao, Leigang Qu, Yicong Li, Jay Zhangjie Wu, CongDuy Nguyen, SeeKiong Ng, Anh Tuan Luu |  |
| 1203 |  |  [Generative Input: Towards Next-Generation Input Methods Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.218) |  | 0 | Since the release of ChatGPT, generative models have achieved tremendous success and become the de facto approach for various NLP tasks. However, its application in the field of input methods remains under-explored. Many neural network approaches have been applied to the construction of Chinese... | Keyu Ding, Yongcan Wang, Zihang Xu, Zhenzhen Jia, Enhong Chen |  |
| 1204 |  |  [A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential](https://doi.org/10.18653/v1/2024.findings-acl.219) |  | 0 | Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, “generate-then-read” pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although... | Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Peng Zhou |  |
| 1205 |  |  [Functional Overlap Reranking for Neural Code Generation](https://doi.org/10.18653/v1/2024.findings-acl.220) |  | 0 | Code Large Language Models (CodeLLMs) have ushered in a new era in code generation advancements. However, selecting the best code solutions from all possible CodeLLM outputs remains a challenge. Previous methods often overlooked the intricate functional similarities and interactions between... | Hung To, Minh Nguyen, Nghi Bui |  |
| 1206 |  |  [Adversarial Preference Optimization: Enhancing Your Alignment via RM-LLM Game](https://doi.org/10.18653/v1/2024.findings-acl.221) |  | 0 | Human preference alignment is essential to improve the interaction quality of large language models (LLMs). Existing alignment methods depend on manually annotated preference data to guide the LLM optimization directions. However, continuously updating LLMs for alignment raises a distribution gap... | Pengyu Cheng, Yifan Yang, Jian Li, Yong Dai, Tianhao Hu, Peixin Cao, Nan Du, Xiaolong Li |  |
| 1207 |  |  [Pinpointing Diffusion Grid Noise to Enhance Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.findings-acl.222) |  | 0 | Aspect sentiment quad prediction (ASQP) has garnered significant attention in aspect-based sentiment analysis (ABSA). Current ASQP research primarily relies on pre-trained generative language models to produce templated sequences, often complemented by grid-based auxiliary methods. Despite these... | Linan Zhu, Xiangfan Chen, Xiaolei Guo, Chenwei Zhang, Zhechao Zhu, Zehai Zhou, Xiangjie Kong |  |
| 1208 |  |  [Continual Contrastive Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.223) |  | 0 | Recently, neural networks have shown impressive progress across diverse fields, with speech processing being no exception. However, recent breakthroughs in this area require extensive offline training using large datasets and tremendous computing resources. Unfortunately, these models struggle to... | Umberto Cappellazzo, Enrico Fini, Muqiao Yang, Daniele Falavigna, Alessio Brutti, Bhiksha Raj |  |
| 1209 |  |  [LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.224) |  | 0 | Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and... | Kai Wang, Yuwei Xu, Zhiyong Wu, Siqiang Luo |  |
| 1210 |  |  [Unsupervised Parsing by Searching for Frequent Word Sequences among Sentences with Equivalent Predicate-Argument Structures](https://doi.org/10.18653/v1/2024.findings-acl.225) |  | 0 | Unsupervised constituency parsing focuses on identifying word sequences that form a syntactic unit (i.e., constituents) in target sentences. Linguists identify the constituent by evaluating a set of Predicate-Argument Structure (PAS) equivalent sentences where we find the constituent appears more... | Junjie Chen, Xiangheng He, Danushka Bollegala, Yusuke Miyao |  |
| 1211 |  |  [Data-Centric Explainable Debiasing for Improving Fairness in Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.226) |  | 0 | Human-like social bias of pre-trained language models (PLMs) on downstream tasks have attracted increasing attention. The potential flaws in the training data are the main factor that causes unfairness in PLMs. Existing data-centric debiasing strategies mainly leverage explicit bias words (defined... | Yingji Li, Mengnan Du, Rui Song, Xin Wang, Ying Wang |  |
| 1212 |  |  [Knowledge-Driven Cross-Document Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.227) |  | 0 | Relation extraction (RE) is a well-known NLP application often treated as a sentence or document-level task. However, a handful of recent efforts explore it across documents or in the cross-document setting (CrossDocRE). This is distinct from the single document case because different documents... | Monika Jain, Raghava Mutharaju, Kuldeep Singh, Ramakanth Kavuluru |  |
| 1213 |  |  [Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.228) |  | 0 | Recent research in dialogue systems focuses on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users complete specific tasks, while open-domain systems aim to create engaging conversations. However, user intents often emerge during interactions. A... | Wen Chang, YunNung Chen |  |
| 1214 |  |  [KG-Adapter: Enabling Knowledge Graph Integration in Large Language Models through Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.229) |  | 0 | Although large language models (LLMs) show remarkable capabilities and generalizability across various tasks, they are criticized for lack of expertise. One promising solution is to combine knowledge graphs (KGs) with LLMs, and recent studies focus on integrating KGs into LLMs through prompt-based... | Shiyu Tian, Yangyang Luo, Tianze Xu, Caixia Yuan, Huixing Jiang, Chen Wei, Xiaojie Wang |  |
| 1215 |  |  [Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.230) |  | 0 | Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local optimality. To address this shortcoming, ensemble-optimization tries to... | Lei Lin, JiaYi Fu, Pengli Liu, Qingyang Li, Yan Gong, Junchen Wan, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, Kun Gai |  |
| 1216 |  |  [Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.231) |  | 0 | Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with a hybrid of structured tables and unstructured text remain uncertain. This study explores LLMs’ mathematical reasoning on four financial tabular question-answering... | Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, Dan Roth |  |
| 1217 |  |  [Improving In-Context Learning with Prediction Feedback for Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.232) |  | 0 | Large language models (LLMs) have achieved promising results in sentiment analysis through the in-context learning (ICL) paradigm. However, their ability to distinguish subtle sentiments still remains a challenge. Inspired by the human ability to adjust understanding via feedback, this paper... | Hongling Xu, Qianlong Wang, Yice Zhang, Min Yang, Xi Zeng, Bing Qin, Ruifeng Xu |  |
| 1218 |  |  [Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model](https://doi.org/10.18653/v1/2024.findings-acl.233) |  | 0 | Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into symbol-based and neural-based models. Symbol-based models are interpretable but inefficient, while... | Zhiwei Li, Ran Song, Caihong Sun, Wei Xu, Zhengtao Yu, JiRong Wen |  |
| 1219 |  |  [Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint](https://doi.org/10.18653/v1/2024.findings-acl.234) |  | 0 | Large language models (LLMs) internalize enormous parametric knowledge during pre-training. Concurrently, realistic applications necessitate external contextual knowledge to aid models on the underlying tasks. This raises a crucial dilemma known as knowledge conflicts, where the contextual... | Xiaowei Yuan, Zhao Yang, Yequan Wang, Shengping Liu, Jun Zhao, Kang Liu |  |
| 1220 |  |  [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.235) |  | 0 | In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose SALAD-Bench, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench... | Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, Jing Shao |  |
| 1221 |  |  [Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation](https://doi.org/10.18653/v1/2024.findings-acl.236) |  | 0 | Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality factual statements from free-text radiology reports... | Pablo Messina, René Vidal, Denis Parra, Alvaro Soto, Vladimir Araujo |  |
| 1222 |  |  [GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network](https://doi.org/10.18653/v1/2024.findings-acl.237) |  | 0 | Large Language Models (LLMs) exhibit strong In-Context Learning (ICL) capabilities when prompts with demonstrations are used. However, fine-tuning still remains crucial to further enhance their adaptability. Prompt-based fine-tuning proves to be an effective fine-tuning method in low-data... | Shuzhou Yuan, Ercong Nie, Michael Färber, Helmut Schmid, Hinrich Schütze |  |
| 1223 |  |  [M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.238) |  | 0 | There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it... | Anand Subramanian, Viktor Schlegel, Abhinav Ramesh Kashyap, ThanhTung Nguyen, Vijay Prakash Dwivedi, Stefan Winkler |  |
| 1224 |  |  [MovieSum: An Abstractive Summarization Dataset for Movie Screenplays](https://doi.org/10.18653/v1/2024.findings-acl.239) |  | 0 | Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore,... | Rohit Saxena, Frank Keller |  |
| 1225 |  |  [Autonomous Workflow for Multimodal Fine-Grained Training Assistants Towards Mixed Reality](https://doi.org/10.18653/v1/2024.findings-acl.240) |  | 0 | Autonomous artificial intelligence (AI) agents have emerged as promising protocols for automatically understanding the language-based environment, particularly with the exponential development of large language models (LLMs). However, a fine-grained, comprehensive understanding of multimodal... | Jiahuan Pei, Irene Viola, Haochen Huang, Junxiao Wang, Moonisa Ahsan, Fanghua Ye, Yiming Jiang, Yao Sai, Di Wang, Zhumin Chen, Pengjie Ren, Pablo César |  |
| 1226 |  |  [Perceptions of Language Technology Failures from South Asian English Speakers](https://doi.org/10.18653/v1/2024.findings-acl.241) |  | 0 | English NLP systems have empirically worse performance for dialects other than Standard American English (SAmE). However, how these discrepancies impact use of language technology by speakers of non-SAmE global Englishes is not well understood. We focus on reducing this gap for South Asian... | Faye Holt, William Held, Diyi Yang |  |
| 1227 |  |  [A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task](https://doi.org/10.18653/v1/2024.findings-acl.242) |  | 0 | Transformers demonstrate impressive performance on a range of reasoning benchmarks. To evaluate the degree to which these abilities are a result of actual reasoning, existing work has focused on developing sophisticated benchmarks for behavioral studies. However, these studies do not provide... | Jannik Brinkmann, Abhay Sheshadri, Victor Levoso, Paul Swoboda, Christian Bartelt |  |
| 1228 |  |  [Optimal Transport Guided Correlation Assignment for Multimodal Entity Linking](https://doi.org/10.18653/v1/2024.findings-acl.243) |  | 0 | Multimodal entity linking (MEL) aims to link ambiguous mentions in multimodal contexts to entities in a multimodal knowledge graph. A pivotal challenge is to fully leverage multi-element correlations between mentions and entities to bridge modality gap and enable fine-grained semantic matching.... | Zefeng Zhang, Jiawei Sheng, Chuang Zhang, Liangyunzhi Liangyunzhi, Wenyuan Zhang, Siqi Wang, Tingwen Liu |  |
| 1229 |  |  [On Efficiently Representing Regular Languages as RNNs](https://doi.org/10.18653/v1/2024.findings-acl.244) |  | 0 | Recent work by Hewitt et al. (2020) provides an interpretation of the empirical success of recurrent neural networks (RNNs) as language models (LMs). It shows that RNNs can efficiently represent bounded hierarchical structures that are prevalent in human language.This suggests that RNNs’ success... | Anej Svete, Robin Chan, Ryan Cotterell |  |
| 1230 |  |  [A Survey on Modelling Morality for Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.245) |  | 0 | In this survey, we provide a systematic review of recent work on modelling morality in text, an area of research that has garnered increasing attention in recent years. Our survey is motivated by the importance of modelling decisions on the created resources, the models trained on these resources... | Ines Reinig, Maria Becker, Ines Rehbein, Simone Paolo Ponzetto |  |
| 1231 |  |  [Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.246) |  | 0 | Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs). Existing data selection approaches on LLMs either... | Ruibo Chen, Yihan Wu, Lichang Chen, Guodong Liu, Qi He, Tianyi Xiong, Chenxi Liu, Junfeng Guo, Heng Huang |  |
| 1232 |  |  [DebugBench: Evaluating Debugging Capability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.247) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs’ debugging ability are significantly limited by the risk of... | Runchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai Lin, Yinxu Pan, Yesai Wu, Haotian Hui, Weichuan Liu, Zhiyuan Liu, Maosong Sun |  |
| 1233 |  |  [POP-CEE: Position-oriented Prompt-tuning Model for Causal Emotion Entailment](https://doi.org/10.18653/v1/2024.findings-acl.248) |  | 0 | The objective of the Causal Emotion Entailment (CEE) task is to identify the causes of the target emotional utterances in a given conversation. Most existing studies have focused on a fine-tuning paradigm based on a pretrained model, e.g., the BERT model. However, there are gaps between the... | Zhihan Zhou, Xue Gu, Yujie Zhao, Hao Xu |  |
| 1234 |  |  [Context Length Extension via Generalized Extrapolation Scale](https://doi.org/10.18653/v1/2024.findings-acl.249) |  | 0 |  | Linhan Li, Huaping Zhang |  |
| 1235 |  |  [Selectively Answering Visual Questions](https://doi.org/10.18653/v1/2024.findings-acl.250) |  | 0 | Recently, large multi-modal models (LMMs) have emerged with the capacity to perform vision tasks such as captioning and visual question answering (VQA) with unprecedented accuracy. Applications such as helping the blind or visually impaired have a critical need for precise answers. It is specially... | Julian Eisenschlos, Hernán Maina, Guido Ivetta, Luciana Benotti |  |
| 1236 |  |  [Wav2SQL: Direct Generalizable Speech-To-SQL Parsing](https://doi.org/10.18653/v1/2024.findings-acl.251) |  | 0 | We release a multi-accent dataset and propose speech-programming and gradient reversal classifier to improve the generalization.Abstract: Speech-to-SQL (S2SQL) aims to convert spoken questions into SQL queries given relational databases, which has been traditionally implemented in a cascaded manner... | Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize Cheng, Zhou Zhao |  |
| 1237 |  |  [E2-LLM: Efficient and Extreme Length Extension of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.252) |  | 0 | Training Large Language Models (LLMs) to process extensive context lengths incurs prohibitive computational costs. Prevailing techniques for extending context capabilities in LLMs typically require not only additional training procedures but also access to datasets with long context (e.g.,... | Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, Yu Zhang, Ge Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, Tiezheng Ge, Jie Fu, Wenhu Chen, Bo Zheng |  |
| 1238 |  |  [Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality](https://doi.org/10.18653/v1/2024.findings-acl.253) |  | 0 | People tend to use language to mention surprising properties of events: for example, when a banana is blue, we are more likely to mention color than when it is yellow. This fact is taken to suggest that yellowness is somehow a typical feature of bananas, and blueness is exceptional. Similar to how... | Da Ju, Karen Ullrich, Adina Williams |  |
| 1239 |  |  [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](https://doi.org/10.18653/v1/2024.findings-acl.254) |  | 0 | Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally... | Sitao Cheng, Ziyuan Zhuang, Yong Xu, Fangkai Yang, Chaoyun Zhang, Xiaoting Qin, Xiang Huang, Ling Chen, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang |  |
| 1240 |  |  [Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts](https://doi.org/10.18653/v1/2024.findings-acl.255) |  | 0 | In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of legal proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce Prediction with Explanation (PredEx), the largest expert-annotated dataset... | Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya |  |
| 1241 |  |  [RulE: Knowledge Graph Reasoning with Rule Embedding](https://doi.org/10.18653/v1/2024.findings-acl.256) |  | 0 | Knowledge graph reasoning is an important problem for knowledge graphs. In this paper, we propose a novel and principled framework called RulE (stands for Rule Embedding) to effectively leverage logical rules to enhance KG reasoning. Unlike knowledge graph embedding methods, RulE learns rule... | Xiaojuan Tang, SongChun Zhu, Yitao Liang, Muhan Zhang |  |
| 1242 |  |  [Multi-Objective Linguistic Control of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.257) |  | 0 | Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, prefer to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple... | Dang Nguyen, Jiuhai Chen, Tianyi Zhou |  |
| 1243 |  |  [Evaluating the Smooth Control of Attribute Intensity in Text Generation with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.258) |  | 0 | Controlling the attribute intensity of text generation is crucial across scenarios (e.g., writing conciseness, chatting emotion, and explanation clarity). The remarkable capabilities of large language models (LLMs) have revolutionized text generation, prompting us to explore such smooth control of... | Shang Zhou, Feng Yao, Chengyu Dong, Zihan Wang, Jingbo Shang |  |
| 1244 |  |  [Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.259) |  | 0 | The recent trend of using Large Language Models (LLMs) as tool agents in real-world applications underscores the necessity for comprehensive evaluations of their capabilities, particularly in complex scenarios involving planning, creating, and using tools. However, existing benchmarks typically... | Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang, Ruifeng Xu, Qun Liu |  |
| 1245 |  |  [Do Androids Know They're Only Dreaming of Electric Sheep?](https://doi.org/10.18653/v1/2024.findings-acl.260) |  | 0 | We design probes trained on the internal representations of a transformer language model to predict its hallucinatory behavior on three grounded generation tasks. To train the probes, we annotate for span-level hallucination on both sampled (organic) and manually edited (synthetic) reference... | Sky CHWang, Benjamin Van Durme, Jason Eisner, Chris Kedzie |  |
| 1246 |  |  [URG: A Unified Ranking and Generation Method for Ensembling Language Models](https://doi.org/10.18653/v1/2024.findings-acl.261) |  | 0 | Prior research endeavors of the ensemble Large Language Models (LLMs) achieved great success by employing an individual language model (LM) rank before the text generation. However, the use of an individual LM ranker faces two primary challenges: (1) The time-intensive nature of the ranking... | Bo Lv, Chen Tang, Yanan Zhang, Xin Liu, Ping Luo, Yue Yu |  |
| 1247 |  |  [Multi-Modal Retrieval For Large Language Model Based Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.262) |  | 0 | Retrieval is a widely adopted approach for improving language models leveraging external information. As the field moves towards multi-modal large language models, it is important to extend the pure text based methods to incorporate other modalities in retrieval as well for applications across the... | Aditya Gourav, Jari Kolehmainen, Prashanth Gurunath Shivakumar, Yile Gu, Grant P. Strimel, Ankur Gandhe, Ariya Rastrow, Ivan Bulyko |  |
| 1248 |  |  [LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.263) |  | 0 | Low-Rank Adaptation (LoRA) provides an effective yet efficient solution for fine-tuning large language models (LLMs). The modular and plug-and-play nature of LoRA enables the integration of diverse domain-specific LoRAs to enhance the capabilities of LLMs. Previous research on exploiting multiple... | Ziyu Zhao, Leilei Gan, Guoyin Wang, Wangchunshu Zhou, Hongxia Yang, Kun Kuang, Fei Wu |  |
| 1249 |  |  [ELAD: Explanation-Guided Large Language Models Active Distillation](https://doi.org/10.18653/v1/2024.findings-acl.264) |  | 0 | The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences. Traditional distillation methods, which transfer the capabilities of LLMs to smaller models, often fail to determine whether the... | Yifei Zhang, Bo Pan, Chen Ling, Yuntong Hu, Liang Zhao |  |
| 1250 |  |  [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](https://doi.org/10.18653/v1/2024.findings-acl.265) |  | 0 | Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen).... | Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher |  |
| 1251 |  |  [Semantics or spelling? Probing contextual word embeddings with orthographic noise](https://doi.org/10.18653/v1/2024.findings-acl.266) |  | 0 | Pretrained language model (PLM) hidden states are frequently employed as contextual word embeddings (CWE): high-dimensional representations that encode semantic information given linguistic context. Across many areas of computational linguistics research, similarity between CWEs is interpreted as... | Jacob Matthews, John Starr, Marten van Schijndel |  |
| 1252 |  |  [The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)](https://doi.org/10.18653/v1/2024.findings-acl.267) |  | 0 | Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model generation with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could... | Shenglai Zeng, Jiankun Zhang, Pengfei He, Yiding Liu, Yue Xing, Han Xu, Jie Ren, Yi Chang, Shuaiqiang Wang, Dawei Yin, Jiliang Tang |  |
| 1253 |  |  [EmpathicStories++: A Multimodal Dataset for Empathy Towards Personal Experiences](https://doi.org/10.18653/v1/2024.findings-acl.268) |  | 0 | Modeling empathy is a complex endeavor that is rooted in interpersonal and experiential dimensions of human interaction, and remains an open problem within AI. Existing empathy datasets fall short in capturing the richness of empathy responses, often being confined to in-lab or acted scenarios,... | Jocelyn Shen, Yubin Kim, Mohit Hulse, Wazeer Zulfikar, Sharifa Alghowinem, Cynthia Breazeal, Hae Won Park |  |
| 1254 |  |  [MRL Parsing Without Tears: The Case of Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.269) |  | 0 | Syntactic parsing remains a critical tool for relation extraction and information extraction, especially in resource-scarce languages where LLMs are lacking. Yet in morphologically rich languages (MRLs), where parsers need to identify multiple lexical units in each token, existing systems suffer in... | Shaltiel Shmidman, Avi Shmidman, Moshe Koppel, Reut Tsarfaty |  |
| 1255 |  |  [SyntaxShap: Syntax-aware Explainability Method for Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.270) |  | 0 | To harness the power of large language models in safety-critical domains, we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods... | Kenza Amara, Rita Sevastjanova, Mennatallah ElAssady |  |
| 1256 |  |  [Automated Detection and Analysis of Data Practices Using A Real-World Corpus](https://doi.org/10.18653/v1/2024.findings-acl.271) |  | 0 | Privacy policies are crucial for informing users about data practices, yet their length and complexity often deter users from reading them. In this paper, we propose an automated approach to identify and visualize data practices within privacy policies at different levels of detail. Leveraging... | Mukund Srinath, Pranav Narayanan Venkit, Maria Badillo, Florian Schaub, C. Lee Giles, Shomir Wilson |  |
| 1257 |  |  [Enhancing Hyperbolic Knowledge Graph Embeddings via Lorentz Transformations](https://doi.org/10.18653/v1/2024.findings-acl.272) |  | 0 | Knowledge Graph Embedding (KGE) is a powerful technique for predicting missing links in Knowledge Graphs (KGs) by learning the entities and relations. Hyperbolic space has emerged as a promising embedding space for KGs due to its ability to represent hierarchical data. Nevertheless, most existing... | Xiran Fan, Minghua Xu, Huiyuan Chen, Yuzhong Chen, Mahashweta Das, Hao Yang |  |
| 1258 |  |  [Tell Me What's Next: Textual Foresight for Generic UI Representations](https://doi.org/10.18653/v1/2024.findings-acl.273) |  | 0 | Mobile app user interfaces (UIs) are rich with action, text, structure, and image content that can be utilized to learn generic UI representations for tasks like automating user commands, summarizing content, and evaluating the accessibility of user interfaces. Prior work has learned strong visual... | Andrea Burns, Kate Saenko, Bryan A. Plummer |  |
| 1259 |  |  [Probing the Uniquely Identifiable Linguistic Patterns of Conversational AI Agents](https://doi.org/10.18653/v1/2024.findings-acl.274) |  | 0 | The proliferation of Conversational AI agents (CAAs) has emphasised the need to distinguish between human and machine-generated texts, with implications spanning digital forensics and cybersecurity. While prior research primarily focussed on distinguishing human from machine-generated text, our... | Iqra Zahid, Tharindu Madusanka, Riza BatistaNavarro, Youcheng Sun |  |
| 1260 |  |  [The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.275) |  | 0 | Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or “prompting,” practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of... | Abel Salinas, Fred Morstatter |  |
| 1261 |  |  [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](https://doi.org/10.18653/v1/2024.findings-acl.276) |  | 0 | In recent years, few-shot and zero-shot learning, which learn to predict labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat frequent-shot (freq-shot; labels with abundant instances), few-shot, and zero-shot learning as distinct... | Hanzi Xu, Muhao Chen, Lifu Huang, Slobodan Vucetic, Wenpeng Yin |  |
| 1262 |  |  [SPIN: Sparsifying and Integrating Internal Neurons in Large Language Models for Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.277) |  | 0 | Among the many tasks that Large Language Models (LLMs) have revolutionized is text classification. Current text classification paradigms, however, rely solely on the output of the final layer in the LLM, with the rich information contained in internal neurons largely untapped. In this study, we... | Difan Jiao, Yilun Liu, Zhenwei Tang, Daniel Matter, Jürgen Pfeffer, Ashton Anderson |  |
| 1263 |  |  [Decomposing Co-occurrence Matrices into Interpretable Components as Formal Concepts](https://doi.org/10.18653/v1/2024.findings-acl.278) |  | 0 | This study addresses the interpretability of word representations through an investigation of a count-based co-occurrence matrix. Employing the mathematical methodology of Formal Concept Analysis, we reveal an underlying structure that is amenable to human interpretation. Furthermore, we unveil the... | Akihiro Maeda, Takuma Torii, Shohei Hidaka |  |
| 1264 |  |  [Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification](https://doi.org/10.18653/v1/2024.findings-acl.279) |  | 0 | Radiology reports are highly technical documents aimed primarily at doctor-doctor communication. There has been an increasing interest in sharing those reports with patients, necessitating providing them patient-friendly simplifications of the original reports. This study explores the suitability... | Ziyu Yang, Santhosh Cherian, Slobodan Vucetic |  |
| 1265 |  |  [Planning First, Question Second: An LLM-Guided Method for Controllable Question Generation](https://doi.org/10.18653/v1/2024.findings-acl.280) |  | 0 | In the field of education, for better assessment of students’ abilities, generated questions often need to meet experts’ requirements, indicating the need for controllable question generation (CQG). However, current CQG methods mainly focus on difficulty control, neglecting the control of question... | Kunze Li, Yu Zhang |  |
| 1266 |  |  [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://doi.org/10.18653/v1/2024.findings-acl.281) |  | 0 | Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external... | Yanming Liu, Xinyue Peng, Xuhong Zhang, Weihao Liu, Jianwei Yin, Jiannan Cao, Tianyu Du |  |
| 1267 |  |  [MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model](https://doi.org/10.18653/v1/2024.findings-acl.282) |  | 0 | Large Language Models (LLMs) often struggle with hallucinations and outdated information. To address this, Information Retrieval (IR) systems can be employed to augment LLMs with up-to-date knowledge. However, existing IR techniques contain deficiencies, posing a performance bottleneck. Given the... | Danupat Khamnuansin, Tawunrat Chalothorn, Ekapol Chuangsuwanich |  |
| 1268 |  |  [Chain-of-Question: A Progressive Question Decomposition Approach for Complex Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.283) |  | 0 | Complex KBQA leverages the knowledge base (KB) to answer complex natural questions involving complicated semantics like multi-hop reasoning. Existing methods involve a question decomposition process, i.e., breaking a complex question into several simpler sub-questions, to assist obtaining logical... | Yixing Peng, Quan Wang, Licheng Zhang, Yi Liu, Zhendong Mao |  |
| 1269 |  |  [Instruction Tuning with Retrieval-based Examples Ranking for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.284) |  | 0 | Aspect-based sentiment analysis (ABSA) identifies sentiment information related to specific aspects and provides deeper market insights to businesses and organizations. With the emergence of large language models (LMs), recent studies have proposed using fixed examples for instruction tuning to... | Guangmin Zheng, Jin Wang, LiangChih Yu, Xuejie Zhang |  |
| 1270 |  |  [Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation](https://doi.org/10.18653/v1/2024.findings-acl.285) |  | 0 | Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change. Simulating the response of the public and forecasting the potential impact has become increasingly important. However, existing methods for simulating such phenomena encounter... | Xinyi Mou, Zhongyu Wei, Xuanjing Huang |  |
| 1271 |  |  [Incorporating Syntax and Lexical Knowledge to Multilingual Sentiment Classification on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.286) |  | 0 | This paper exploits a sentiment extractor supported by syntactic and lexical resources to enhance multilingual sentiment classification solved through the generative approach, without retraining LLMs. By adding external information of words and phrases that have positive/negative polarities, the... | Hiroshi Kanayama, Yang Zhao, Ran Iwamoto, Takuya Ohko |  |
| 1272 |  |  [Locating and Extracting Relational Concepts in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.287) |  | 0 | Relational concepts are indeed foundational to the structure of knowledge representation, as they facilitate the association between various entity concepts, allowing us to express and comprehend complex world knowledge.By expressing relational concepts in natural language prompts, people can... | Zijian Wang, Britney White, Chang Xu |  |
| 1273 |  |  [Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.288) |  | 0 | Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their superiority in terms of factuality, they do not consistently outperform the original retrieval-free Language Models (LMs). Our experiments reveal that this example-level performance inconsistency exists not only between... | Mingda Li, Xinyu Li, Yifan Chen, Wenfeng Xuan, Weinan Zhang |  |
| 1274 |  |  [SenticVec: Toward Robust and Human-Centric Neurosymbolic Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.289) |  | 0 | The success of state-of-the-art Natural Language Processing (NLP) systems heavily depends on deep neural networks, which excel in various tasks through strong data fitting and latent feature modeling abilities. However, certain challenges linked to deep neural networks and supervised deep learning... | Xulang Zhang, Rui Mao, Erik Cambria |  |
| 1275 |  |  [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.290) |  | 0 | Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs’ trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs’ trustworthiness... | Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao |  |
| 1276 |  |  [Language Models can Evaluate Themselves via Probability Discrepancy](https://doi.org/10.18653/v1/2024.findings-acl.291) |  | 0 | In this paper, we begin by illustrating that, when presented with a query, Large Language Models (LLMs) capable of providing accurate responses tend to exhibit a more uniform probability distribution compared to their less proficient counterparts. Building upon this observation, we introduce a... | Tingyu Xia, Bowen Yu, Yuan Wu, Yi Chang, Chang Zhou |  |
| 1277 |  |  [Evaluating the Validity of Word-level Adversarial Attacks with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.292) |  | 0 | Deep neural networks exhibit vulnerability to word-level adversarial attacks in natural language processing. Most of these attack methods adopt synonymous substitutions to perturb original samples for crafting adversarial examples while attempting to maintain semantic consistency with the... | Huichi Zhou, Zhaoyang Wang, Hongtao Wang, Dongping Chen, Wenhan Mu, Fangyuan Zhang |  |
| 1278 |  |  [On the Language Encoder of Contrastive Cross-modal Models](https://doi.org/10.18653/v1/2024.findings-acl.293) |  | 0 | Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder – the central component of encoding natural language descriptions of image/audio into... | Mengjie Zhao, Junya Ono, Zhi Zhong, ChiehHsin Lai, Yuhta Takida, Naoki Murata, WeiHsiang Liao, Takashi Shibuya, Hiromi Wakaki, Yuki Mitsufuji |  |
| 1279 |  |  [Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World](https://doi.org/10.18653/v1/2024.findings-acl.294) |  | 0 | Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration... | Guande Wu, Chen Zhao, Cláudio T. Silva, He He |  |
| 1280 |  |  [Anchor-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.295) |  | 0 | Large language models (LLMs) predominantly employ decoder-only transformer architectures, necessitating the retention of keys/values information for historical tokens to provide contextual information and avoid redundant computation. However, the substantial size and parameter volume of these LLMs... | Jianhui Pang, Fanghua Ye, Derek F. Wong, Xin He, Wanshun Chen, Longyue Wang |  |
| 1281 |  |  [MLeVLM: Improve Multi-level Progressive Capabilities based on Multimodal Large Language Model for Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.296) |  | 0 | Medical visual question answering (MVQA) requires in-depth understanding of medical images and questions to provide reliable answers. We summarize multi-level progressive capabilities that models need to focus on in MVQA: recognition, details, diagnosis, knowledge, and reasoning. Existing MVQA... | Dexuan Xu, Yanyuan Chen, Jieyi Wang, Yue Huang, Hanpin Wang, Zhi Jin, Hongxing Wang, Weihua Yue, Jing He, Hang Li, Yu Huang |  |
| 1282 |  |  [Disentangling Length from Quality in Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.297) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has been a crucial component in the recent success of Large Language Models. However, RLHF is know to exploit biases in human preferences, such as verbosity. A well-formatted and eloquent answer is often more highly rated by users, even when it is... | Ryan Park, Rafael Rafailov, Stefano Ermon, Chelsea Finn |  |
| 1283 |  |  [MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.298) |  | 0 | Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity... | Jiaqi Li, Miaozeng Du, Chuanyi Zhang, Yongrui Chen, Nan Hu, Guilin Qi, Haiyun Jiang, Siyuan Cheng, Bozhong Tian |  |
| 1284 |  |  [Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise: A Case Study on Chinese Legal Domain](https://doi.org/10.18653/v1/2024.findings-acl.299) |  | 0 | While large language models (LLMs) like GPT-4 have recently demonstrated astonishing zero-shot capabilities in general domain tasks, they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the... | Zhen Wan, Yating Zhang, Yexiang Wang, Fei Cheng, Sadao Kurohashi |  |
| 1285 |  |  [MemeMQA: Multimodal Question Answering for Memes via Rationale-Based Inferencing](https://doi.org/10.18653/v1/2024.findings-acl.300) |  | 0 | Memes have evolved as a prevalent medium for diverse communication, ranging from humour to propaganda. With the rising popularity of image-focused content, there is a growing need to explore its potential harm from different aspects. Previous studies have analyzed memes in closed settings -... | Siddhant Agarwal, Shivam Sharma, Preslav Nakov, Tanmoy Chakraborty |  |
| 1286 |  |  [Improving Attributed Text Generation of Large Language Models via Preference Learning](https://doi.org/10.18653/v1/2024.findings-acl.301) |  | 0 | Large language models have been widely adopted in natural language processing, yet they face the challenge of generating unreliable content. Recent works aim to reduce misinformation and hallucinations by resorting to attribution as a means to provide evidence (i.e., citations). However, current... | Dongfang Li, Zetian Sun, Baotian Hu, Zhenyu Liu, Xinshuo Hu, Xuebo Liu, Min Zhang |  |
| 1287 |  |  [KOMBO: Korean Character Representations Based on the Combination Rules of Subcharacters](https://doi.org/10.18653/v1/2024.findings-acl.302) |  | 0 | The Korean writing system, Hangeul, has a unique character representation rigidly following the invention principles recorded in Hunminjeongeum. However, existing pre-trained language models (PLMs) for Korean have overlooked these principles. In this paper, we introduce a novel framework for Korean... | SungHo Kim, Juhyeong Park, Yeachan Kim, SangKeun Lee |  |
| 1288 |  |  [Tree-Planted Transformers: Unidirectional Transformer Language Models with Implicit Syntactic Supervision](https://doi.org/10.18653/v1/2024.findings-acl.303) |  | 0 | Syntactic Language Models (SLMs) can be trained efficiently to reach relatively high performance; however, they have trouble with inference efficiency due to the explicit generation of syntactic structures. In this paper, we propose a new method dubbed tree-planting: instead of explicitly... | Ryo Yoshida, Taiga Someya, Yohei Oseki |  |
| 1289 |  |  [Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues](https://doi.org/10.18653/v1/2024.findings-acl.304) |  | 0 | With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of... | Zhiyuan Chang, Mingyang Li, Yi Liu, Junjie Wang, Qing Wang, Yang Liu |  |
| 1290 |  |  [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.305) |  | 0 | The development of large language models tailored for handling patients’ clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations.To address these challenges, we first create synthetic large-scale clinical notes using publicly... | Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im, Eunbyeol Cho, Seongsu Bae, Jungwoo Oh, Gyubok Lee, Jong Hak Moon, Seng Chan You, Seungjin Baek, Chang Hoon Han, Yoon Bin Jung, Yohan Jo, Edward Choi |  |
| 1291 |  |  [Extending Context Window of Large Language Models via Semantic Compression](https://doi.org/10.18653/v1/2024.findings-acl.306) |  | 0 | Transformer based Large Language Models (LLMs) often impose limitations on the length of the text input to ensure the generation of fluent and relevant responses due to the quadratic complexity. These constraints restrict their applicability in long text scenarios. In this paper, we propose a novel... | Weizhi Fei, Xueyan Niu, Pingyi Zhou, Lu Hou, Bo Bai, Lei Deng, Wei Han |  |
| 1292 |  |  [Plausible Extractive Rationalization through Semi-Supervised Entailment Signal](https://doi.org/10.18653/v1/2024.findings-acl.307) |  | 0 | The increasing use of complex and opaque black box models requires the adoption of interpretable measures, one such option is extractive rationalizing models, which serve as a more interpretable alternative. These models, also known as Explain-Then-Predict models, employ an explainer model to... | Wei Jie Yeo, Ranjan Satapathy, Erik Cambria |  |
| 1293 |  |  [Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.308) |  | 0 | Building a reliable visual question answering (VQA) system across different languages is a challenging problem, primarily due to the lack of abundant samples for training. To address this challenge, recent studies have employed machine translation systems for the cross-lingual VQA task. This... | ChaeHun Park, Koanho Lee, Hyesu Lim, Jaeseok Kim, Junmo Park, YuJung Heo, DuSeong Chang, Jaegul Choo |  |
| 1294 |  |  [Scented-EAE: Stage-Customized Entity Type Embedding for Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.309) |  | 0 | Existing methods for incorporating entities into EAE rely on prompts or NER. They typically fail to explicitly explore the role of entity types, which results in shallow argument comprehension and often encounter three issues: (1) weak semantic associations due to missing role-entity correspondence... | Yu Yang, Jinyu Guo, Kai Shuang, Chenrui Mao |  |
| 1295 |  |  [Fast Randomized Low-Rank Adaptation of Pre-trained Language Models with PAC Regularization](https://doi.org/10.18653/v1/2024.findings-acl.310) |  | 0 | Low-rank adaptation (LoRA) achieves parameter efficient fine-tuning for large language models (LLMs) by decomposing the model weight update into a pair of low-rank projection matrices. Yet, the memory overhead restricts it to scale up when the model size increases. We propose Randomized LoRA... | Zijian Lei, Dong Qian, William K. Cheung |  |
| 1296 |  |  [SDA: Semantic Discrepancy Alignment for Text-conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.311) |  | 0 | In the realm of text-conditioned image retrieval, models utilize a query composed of a reference image and modification text to retrieve corresponding images. Despite its significance, this task is fraught with challenges, including small-scale datasets due to labeling costs and the complexity of... | Yuchen Yang, Yu Wang, Yanfeng Wang |  |
| 1297 |  |  [Se²: Sequential Example Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.312) |  | 0 | The remarkable capability of large language models(LLMs) for in-context learning(ICL) needs to be activated by demonstration examples. Prior work has extensively explored the selection of examples for ICL, predominantly following the “select then organize” paradigm, such approaches often neglect... | Haoyu Liu, Jianfeng Liu, Shaohan Huang, Yuefeng Zhan, Hao Sun, Weiwei Deng, Furu Wei, Qi Zhang |  |
| 1298 |  |  [Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding](https://doi.org/10.18653/v1/2024.findings-acl.313) |  | 0 | This research aims to accelerate the inference speed of large language models (LLMs) with billions of parameters. We propose Smart Parallel Auto-Correct dEcoding (SPACE), an approach designed for achieving lossless acceleration of LLMs. By integrating semi-autoregressive inference and speculative... | Hanling Yi, Feng Lin, Hongbin Li, Peiyang Ning, Xiaotian Yu, Rong Xiao |  |
| 1299 |  |  [StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.314) |  | 0 | Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggle to discern whether a model genuinely possesses the required capabilities or merely memorizes/guesses the... | Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun |  |
| 1300 |  |  [Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching](https://doi.org/10.18653/v1/2024.findings-acl.315) |  | 0 | Protecting privacy leakage in large language models remains a paramount challenge. In this paper, we reveal Privacy Seesaw in LLM privacy safeguarding, a phenomenon where measures to secure specific private information inadvertently heighten exposure risks for other privacy. Through comprehensive... | Xinwei Wu, Weilong Dong, Shaoyang Xu, Deyi Xiong |  |
| 1301 |  |  [Which Information Matters? Dissecting Human-written Multi-document Summaries with Partial Information Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.316) |  | 0 | Understanding the nature of high-quality summaries is crucial to further improve the performance of multi-document summarization. We propose an approach to characterize human-written summaries using partial information decomposition, which decomposes the mutual information provided by all source... | Laura Mascarell, Yan L'Homme, Majed El Helou |  |
| 1302 |  |  [BadActs: A Universal Backdoor Defense in the Activation Space](https://doi.org/10.18653/v1/2024.findings-acl.317) |  | 0 | Backdoor attacks pose an increasingly severe security threat to Deep Neural Networks (DNNs) during their development stage. In response, backdoor sample purification has emerged as a promising defense mechanism, aiming to eliminate backdoor triggers while preserving the integrity of the clean... | Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu |  |
| 1303 |  |  [ReactXT: Understanding Molecular "Reaction-ship" via Reaction-Contextualized Molecule-Text Pretraining](https://doi.org/10.18653/v1/2024.findings-acl.318) |  | 0 | Molecule-text modeling, which aims to facilitate molecule-relevant tasks with a textual interface and textual knowledge, is an emerging research direction. Beyond single molecules, studying reaction-text modeling holds promise for helping the synthesis of new materials and drugs. However, previous... | Zhiyuan Liu, Yaorui Shi, An Zhang, Sihang Li, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, TatSeng Chua |  |
| 1304 |  |  [Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.319) |  | 0 | Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training (MMCAP) approach for generative Med-VQA, leveraging a knowledge... | Quan Yan, Junwen Duan, Jianxin Wang |  |
| 1305 |  |  [Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques](https://doi.org/10.18653/v1/2024.findings-acl.320) |  | 0 | Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss... | Siva Rajesh Kasa, Aniket Goel, Karan Gupta, Sumegh Roychowdhury, Pattisapu Priyatam, Anish Bhanushali, Prasanna Srinivasa Murthy |  |
| 1306 |  |  [Evaluating Large Language Models on Wikipedia-Style Survey Generation](https://doi.org/10.18653/v1/2024.findings-acl.321) |  | 0 | Educational materials such as survey articles in specialized fields like computer science traditionally require tremendous expert inputs and are therefore expensive to create and update. Recently, Large Language Models (LLMs) have achieved significant success across various general tasks. However,... | Fan Gao, Hang Jiang, Rui Yang, Qingcheng Zeng, Jinghui Lu, Moritz Blum, Tianwei She, Yuang Jiang, Irene Li |  |
| 1307 |  |  [The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse](https://doi.org/10.18653/v1/2024.findings-acl.322) |  | 0 | Although model editing has shown promise in revising knowledge in Large Language Models (LLMs), its impact on the inherent capabilities of LLMs is often overlooked. In this work, we reveal a critical phenomenon: even a single edit can trigger model collapse, manifesting as significant performance... | Wanli Yang, Fei Sun, Xinyu Ma, Xun Liu, Dawei Yin, Xueqi Cheng |  |
| 1308 |  |  [Can We Continually Edit Language Models? On the Knowledge Attenuation in Sequential Model Editing](https://doi.org/10.18653/v1/2024.findings-acl.323) |  | 0 | Model editing has become a promising method for precisely and effectively updating knowledge in language models. In this paper, we investigate knowledge attenuation, in which the retention of updated knowledge within the language model decreases as the number of edits increases after sequential... | Qi Li, Xiaowen Chu |  |
| 1309 |  |  [Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation](https://doi.org/10.18653/v1/2024.findings-acl.324) |  | 0 | Large Language Models (LLMs) driven by In-Context Learning (ICL) have significantly improved the performance of text-to-SQL. Previous methods generally employ a two-stage reasoning framework, namely 1) schema linking and 2) logical synthesis, making the framework not only effective but also... | Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo, Chenhao Ma, Reynold Cheng |  |
| 1310 |  |  [Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.325) |  | 0 |  | Zhibin Lan, Liqiang Niu, Fandong Meng, Jie Zhou, Min Zhang, Jinsong Su |  |
| 1311 |  |  [StatBot.Swiss: Bilingual Open Data Exploration in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.326) |  | 0 | The potential for improvements brought by Large Language Models (LLMs) in Text-to-SQL systems is mostly assessed on monolingual English datasets. However, LLMs’ performance for other languages remains vastly unexplored. In this work, we release the StatBot.Swiss dataset, the first bilingual... | Farhad Nooralahzadeh, Yi Zhang, Ellery Smith, Sabine Maennel, Cyril MattheyDoret, Raphaël de Fondeville, Kurt Stockinger |  |
| 1312 |  |  [Subtle Signatures, Strong Shields: Advancing Robust and Imperceptible Watermarking in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.327) |  | 0 | The widespread adoption of Large Language Models (LLMs) has led to an increase in AI-generated text on the Internet, presenting a crucial challenge to differentiate AI-created content from human-written text. This challenge is critical to prevent issues of authenticity, trust, and potential... | Yubing Ren, Ping Guo, Yanan Cao, Wei Ma |  |
| 1313 |  |  [Thinking about how to extract: Energizing LLMs' emergence capabilities for document-level event argument extraction](https://doi.org/10.18653/v1/2024.findings-acl.328) |  | 0 | There are two key challenges remaining for the document-level event argument extraction (D-EAE) tasks: key feature forgetting and cross-event argument confusion. The emergence capability of large language models (LLMs) holds promise for solving the above two challenges. In this paper, we propose a... | Kai Shuang, Zhouji Zhouji, Qiwei Wang, Jinyu Guo |  |
| 1314 |  |  [Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning](https://doi.org/10.18653/v1/2024.findings-acl.329) |  | 0 | Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the burden of annotation, but meanwhile suffers from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, we... | Shuzheng Si, Helan Hu, Haozhe Zhao, Shuang Zeng, Kaikai An, Zefan Cai, Baobao Chang |  |
| 1315 |  |  [Predicting Narratives of Climate Obstruction in Social Media Advertising](https://doi.org/10.18653/v1/2024.findings-acl.330) |  | 0 | Social media advertising offers a platform for fossil fuel value chain companies and their agents to reinforce their narratives, often emphasizing economic, labor market, and energy security benefits to promote oil and gas policy and products. Whether such narratives can be detected automatically... | Harri Rowlands, Gaku Morio, Dylan Tanner, Christopher D. Manning |  |
| 1316 |  |  [SSS: Editing Factual Knowledge in Language Models towards Semantic Sparse Space](https://doi.org/10.18653/v1/2024.findings-acl.331) |  | 0 | Language Models (LMs) acquire factual knowledge during pre-training and store it in the parameters, which can be valuable for downstream tasks. As world evolves, some facts may be incorrectly induced or become obsolete over time. Various model editing methods have been proposed to modify specific... | Huazheng Wang, Haifeng Sun, Jingyu Wang, Qi Qi, Zixuan Xia, Menghao Zhang, Jianxin Liao |  |
| 1317 |  |  [GeoHard: Towards Measuring Class-wise Hardness through Modelling Class Semantics](https://doi.org/10.18653/v1/2024.findings-acl.332) |  | 0 |  | Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl |  |
| 1318 |  |  [Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.333) |  | 0 | In this paper, we investigate the phenomena of “selection biases” in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option order and token usage, which significantly impact LLMs’... | ShengLun Wei, ChengKuang Wu, HenHsen Huang, HsinHsi Chen |  |
| 1319 |  |  [ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic](https://doi.org/10.18653/v1/2024.findings-acl.334) |  | 0 | The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to... | Fajri Koto, Haonan Li, Sara Shatnawi, Jad Doughman, Abdelrahman Boda Sadallah, Aisha Alraeesi, Khalid Almubarak, Zaid Alyafeai, Neha Sengupta, Shady Shehata, Nizar Habash, Preslav Nakov, Timothy Baldwin |  |
| 1320 |  |  [On the Relationship Between RNN Hidden-State Vectors and Semantic Structures](https://doi.org/10.18653/v1/2024.findings-acl.335) |  | 0 | We examine the assumption that hidden-state vectors of recurrent neural networks (RNNs) tend to form clusters of semantically similar vectors, which we dub the clustering hypothesis. While this hypothesis has been assumed in RNN analyses in recent years, its validity has not been studied thoroughly... | Edi Muskardin, Martin Tappler, Ingo Pill, Bernhard K. Aichernig, Thomas Pock |  |
| 1321 |  |  [XMC-Agent : Dynamic Navigation over Scalable Hierarchical Index for Incremental Extreme Multi-label Classification](https://doi.org/10.18653/v1/2024.findings-acl.336) |  | 0 | The eXtreme Multi-label Classification (XMC) aims at accurately assigning large-scale labels to instances, and is challenging for learning, managing, and predicting over the large-scale and rapidly growing set of labels. Traditional XMC methods, like one-vs-all and tree-based methods struggle with... | Yanjiang Liu, Tianyun Zhong, Yaojie Lu, Hongyu Lin, Ben He, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Zhongyi Liu, Xianpei Han, Le Sun |  |
| 1322 |  |  [Benchmarking Large Language Models on CFLUE - A Chinese Financial Language Understanding Evaluation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.337) |  | 0 | In light of recent breakthroughs in large language models (LLMs) that have revolutionized natural language processing (NLP), there is an urgent need for new benchmarks to keep pace with the fast development of LLMs. In this paper, we propose CFLUE, the Chinese Financial Language Understanding... | Jie Zhu, Junhui Li, Yalong Wen, Lifan Guo |  |
| 1323 |  |  [Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint](https://doi.org/10.18653/v1/2024.findings-acl.338) |  | 0 | Reinforcement learning (RL) has been widely used in training large language models (LLMs) for preventing unexpected outputs, e.g., reducing harmfulness and errors. However, existing RL methods mainly adopt instance-level reward, which cannot provide fine-grained supervision for complex reasoning... | Zhipeng Chen, Kun Zhou, Xin Zhao, Junchen Wan, Fuzheng Zhang, Di Zhang, JiRong Wen |  |
| 1324 |  |  [Definition generation for lexical semantic change detection](https://doi.org/10.18653/v1/2024.findings-acl.339) |  | 0 | We use contextualized word definitions generated by large language models as semantic representations in the task of diachronic lexical semantic change detection (LSCD). In short, generated definitions are used as ‘senses’, and the change score of a target word is retrieved by comparing their... | Mariia Fedorova, Andrey Kutuzov, Yves Scherrer |  |
| 1325 |  |  [MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector](https://doi.org/10.18653/v1/2024.findings-acl.340) |  | 0 | Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the... | Marta R. Costajussà, Mariano Coria Meglioli, Pierre Andrews, David Dale, Prangthip Hansanti, Elahe Kalbassi, Alexandre Mourachko, Christophe Ropers, Carleigh Wood |  |
| 1326 |  |  [Phased Instruction Fine-Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.341) |  | 0 | Instruction Fine-Tuning, a method enhancing pre-trained language models’ capabilities from mere next-word prediction to complex instruction following, often employs a one-off training approach on diverse instruction dataset. However, this method may not effectively enhance models’ adherence to... | Wei Pang, Chuan Zhou, XiaoHua Zhou, Xiaojie Wang |  |
| 1327 |  |  [TOREE: Evaluating Topic Relevance of Student Essays for Chinese Primary and Middle School Education](https://doi.org/10.18653/v1/2024.findings-acl.342) |  | 0 | Topic relevance of an essay demands that the composition adheres to a clear theme and aligns well with the essay prompt requirements, a critical aspect of essay quality evaluation. However, existing research of Automatic Essay Scoring (AES) for Chinese essays has overlooked topic relevance and... | Xinlin Zhuang, Hongyi Wu, Xinshu Shen, Peimin Yu, Gaowei Yi, Xinhao Chen, Tu Hu, Yang Chen, Yupei Ren, Yadong Zhang, Youqi Song, Binxuan Liu, Man Lan |  |
| 1328 |  |  [Predicting the Unpredictable: Uncertainty-Aware Reasoning over Temporal Knowledge Graphs via Diffusion Process](https://doi.org/10.18653/v1/2024.findings-acl.343) |  | 0 | Temporal Knowledge Graph (TKG) reasoning seeks to predict future incomplete facts leveraging historical data. While existing approaches have shown effectiveness in addressing the task through various perspectives, such as graph learning and logic rules, they are limited in capturing the... | Yuxiang Cai, Qiao Liu, Yanglei Gan, Changlin Li, Xueyi Liu, Run Lin, Da Luo, JiayeYang JiayeYang |  |
| 1329 |  |  [Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-acl.344) |  | 0 | The widespread use of Text-to-Image (T2I) models in content generation requires careful examination of their safety, including their robustness to adversarial attacks. Despite extensive research on adversarial attacks, the reasons for their effectiveness remain underexplored. This paper presents an... | Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, Yue Dong |  |
| 1330 |  |  [Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs](https://doi.org/10.18653/v1/2024.findings-acl.345) |  | 0 | Controlled Text Generation (CTG) aims to produce texts that exhibit specific desired attributes. In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG). This framework utilizes an attribute scorer... | Xun Liang, Hanyu Wang, Shichao Song, Mengting Hu, Xunzhi Wang, Zhiyu Li, Feiyu Xiong, Bo Tang |  |
| 1331 |  |  [Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.346) |  | 0 | In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples... | JunHyung Park, Mingyu Lee, Junho Kim, SangKeun Lee |  |
| 1332 |  |  [Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge](https://doi.org/10.18653/v1/2024.findings-acl.347) |  | 0 | Recent research has explored methods for updating and modifying factual knowledge in large language models, often focusing on specific multi-layer perceptron blocks. This study expands on this work by examining the effectiveness of existing knowledge editing methods across languages and delving... | Daniel Mela, Aitor GonzalezAgirre, Javier Hernando, Marta Villegas |  |
| 1333 |  |  [BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains](https://doi.org/10.18653/v1/2024.findings-acl.348) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the... | Yanis Labrak, Adrien Bazoge, Emmanuel Morin, PierreAntoine Gourraud, Mickael Rouvier, Richard Dufour |  |
| 1334 |  |  [All Languages Matter: On the Multilingual Safety of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.349) |  | 0 | Safety lies at the core of developing and deploying large language models (LLMs). However, previous safety benchmarks only concern the safety in one language, e.g. the majority language in the pretraining data such as English. In this work, we build the first multilingual safety benchmark for LLMs,... | Wenxuan Wang, Zhaopeng Tu, Chang Chen, Youliang Yuan, Jentse Huang, Wenxiang Jiao, Michael R. Lyu |  |
| 1335 |  |  [LJPCheck: Functional Tests for Legal Judgment Prediction](https://doi.org/10.18653/v1/2024.findings-acl.350) |  | 0 | Legal Judgment Prediction (LJP) refers to the task of automatically predicting judgment results (e.g., charges, law articles and term of penalty) given the fact description of cases. While SOTA models have achieved high accuracy and F1 scores on public datasets, existing datasets fail to evaluate... | Yuan Zhang, Wanhong Huang, Yi Feng, Chuanyi Li, Zhiwei Fei, Jidong Ge, Bin Luo, Vincent Ng |  |
| 1336 |  |  [CMDL: A Large-Scale Chinese Multi-Defendant Legal Judgment Prediction Dataset](https://doi.org/10.18653/v1/2024.findings-acl.351) |  | 0 | Legal Judgment Prediction (LJP) has attracted significant attention in recent years. However, previous studies have primarily focused on cases involving only a single defendant, skipping multi-defendant cases due to complexity and difficulty. To advance research, we introduce CMDL, a large-scale... | Wanhong Huang, Yi Feng, Chuanyi Li, Honghan Wu, Jidong Ge, Vincent Ng |  |
| 1337 |  |  [Model Editing by Standard Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.352) |  | 0 | Standard fine-tuning is considered not as effective as specialized methods for model editing due to its comparatively poor performance. However, it is simple, agnostic to the architectural details of the model being edited, and able to leverage advances in standard training techniques with no... | Govind Krishnan Gangadhar, Karl Stratos |  |
| 1338 |  |  [Abstract Meaning Representation-Based Logic-Driven Data Augmentation for Logical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.353) |  | 0 | Combining large language models with logical reasoning enhances their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges when gathering reliable data from the web to build comprehensive training datasets,... | Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Gaël Gendron, Timothy Pistotti, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Paul Denny, Michael Witbrock, Jiamou Liu |  |
| 1339 |  |  [CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow](https://doi.org/10.18653/v1/2024.findings-acl.354) |  | 0 | We introduce a novel dataset tailored for code generation, aimed at aiding developers in common tasks. Our dataset provides examples that include a clarified intent, code snippets associated, and an average of three related unit tests. It encompasses a range of libraries such as Pandas, Numpy, and... | Nathanaël Beau, Benoît Crabbé |  |
| 1340 |  |  [ViHateT5: Enhancing Hate Speech Detection in Vietnamese With a Unified Text-to-Text Transformer Model](https://doi.org/10.18653/v1/2024.findings-acl.355) |  | 0 | Recent advancements in hate speech detection (HSD) in Vietnamese have made significant progress, primarily attributed to the emergence of transformer-based pre-trained language models, particularly those built on the BERT architecture. However, the necessity for specialized fine-tuned models has... | Luan Thanh Nguyen |  |
| 1341 |  |  [Bias in News Summarization: Measures, Pitfalls and Corpora](https://doi.org/10.18653/v1/2024.findings-acl.356) |  | 0 | Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their content selection, faithfulness, grammaticality and coherence. However, it is well known that LLMs can reproduce and reinforce harmful social biases. This... | Julius Steen, Katja Markert |  |
| 1342 |  |  [When to Trust LLMs: Aligning Confidence with Response Quality](https://doi.org/10.18653/v1/2024.findings-acl.357) |  | 0 | Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods often... | Shuchang Tao, Liuyi Yao, Hanxing Ding, Yuexiang Xie, Qi Cao, Fei Sun, Jinyang Gao, Huawei Shen, Bolin Ding |  |
| 1343 |  |  [Zero-shot Cross-lingual Alignment for Embedding Initialization](https://doi.org/10.18653/v1/2024.findings-acl.358) |  | 0 | For multilingual training, we present CrossInit, an initialization method that initializes embeddings into similar geometrical structures across languages in an unsupervised manner. CrossInit leverages a common cognitive linguistic mechanism, Zipf’s law, which indicates that similar concepts across... | Xi Ai, Zhiyong Huang |  |
| 1344 |  |  [Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)](https://doi.org/10.18653/v1/2024.findings-acl.359) |  | 0 | Large Vision-Language Models (LVLMs) are an extension of Large Language Models (LLMs) that facilitate processing both image and text inputs, expanding AI capabilities. However, LVLMs struggle with object hallucinations due to their reliance on text cues and learned object co-occurrence biases.... | Avshalom Manevich, Reut Tsarfaty |  |
| 1345 |  |  [It takes two to borrow: a donor and a recipient. Who's who?](https://doi.org/10.18653/v1/2024.findings-acl.360) |  | 0 | We address the open problem of automatically identifying the direction of lexical borrowing, given word pairs in the donor and recipient languages. We propose strong benchmarks for this task, by applying a set of machine learning models. We extract and publicly release a comprehensive borrowings... | Liviu P. Dinu, Ana Sabina Uban, Anca Dinu, IoanBogdan Iordache, Simona Georgescu, Laurentiu Zoicas |  |
| 1346 |  |  [Advancing Post-OCR Correction: A Comparative Study of Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.361) |  | 0 | This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages... | Shuhao Guan, Derek Greene |  |
| 1347 |  |  [GeoAgent: To Empower LLMs using Geospatial Tools for Address Standardization](https://doi.org/10.18653/v1/2024.findings-acl.362) |  | 0 | This paper presents a novel solution to tackle the challenges that posed by the abundance of non-standard addresses, which input by users in modern applications such as navigation maps, ride-hailing apps, food delivery platforms, and logistics services. These manually entered addresses often... | Chenghua Huang, Shisong Chen, Zhixu Li, Jianfeng Qu, Yanghua Xiao, Jiaxin Liu, Zhigang Chen |  |
| 1348 |  |  [HQP: A Human-Annotated Dataset for Detecting Online Propaganda](https://doi.org/10.18653/v1/2024.findings-acl.363) |  | 0 | Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following... | Abdurahman Maarouf, Dominik Bär, Dominique Geissler, Stefan Feuerriegel |  |
| 1349 |  |  [Teaching Language Models to Self-Improve by Learning from Language Feedback](https://doi.org/10.18653/v1/2024.findings-acl.364) |  | 0 | Aligning Large Language Models (LLMs) with human intentions and values is crucial yet challenging. Current methods primarily rely on human preferences, which are costly and insufficient in capturing nuanced feedback expressed in natural language. In this paper, we present Self-Refinement Tuning... | Chi Hu, Yimin Hu, Hang Cao, Tong Xiao, JingBo Zhu |  |
| 1350 |  |  [Exploring Spatial Schema Intuitions in Large Language and Vision Models](https://doi.org/10.18653/v1/2024.findings-acl.365) |  | 0 | Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action.Our investigation navigates the intriguing terrain of... | Philipp Wicke, Lennart Wachowiak |  |
| 1351 |  |  [Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model](https://doi.org/10.18653/v1/2024.findings-acl.366) |  | 0 | The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot... | Yibo Miao, Hongcheng Gao, Hao Zhang, Zhijie Deng |  |
| 1352 |  |  [Decoding the Narratives: Analyzing Personal Drug Experiences Shared on Reddit](https://doi.org/10.18653/v1/2024.findings-acl.367) |  | 0 | Online communities such as drug-related subreddits serve as safe spaces for people who use drugs (PWUD), fostering discussions on substance use experiences, harm reduction, and addiction recovery. Users’ shared narratives on these forums provide insights into the likelihood of developing a... | Layla Bouzoubaa, Elham Aghakhani, Max Song, Quang Trinh, Rezvaneh (Shadi) Rezapour |  |
| 1353 |  |  [Unveiling the Art of Heading Design: A Harmonious Blend of Summarization, Neology, and Algorithm](https://doi.org/10.18653/v1/2024.findings-acl.368) |  | 0 | Crafting an appealing heading is crucial for attracting readers and marketing work or products. A popular way is to summarize the main idea with a refined description and a memorable acronym. However, there lacks a systematic study and a formal benchmark including datasets and metrics. Motivated by... | Shaobo Cui, Yiyang Feng, Yisong Mao, Yifan Hou, Boi Faltings |  |
| 1354 |  |  [Understanding Fine-grained Distortions in Reports of Scientific Findings](https://doi.org/10.18653/v1/2024.findings-acl.369) |  | 0 | Distorted science communication harms individuals and society as it can lead to unhealthy behavior change and decrease trust in scientific institutions. Given the rapidly increasing volume of science communication in recent years, a fine-grained understanding of how findings from scientific... | Amelie Wührl, Dustin Wright, Roman Klinger, Isabelle Augenstein |  |
| 1355 |  |  [MM-SOC: Benchmarking Multimodal Large Language Models in Social Media Platforms](https://doi.org/10.18653/v1/2024.findings-acl.370) |  | 0 | Social media platforms are hubs for multimodal information exchange, encompassing text, images, and videos, making it challenging for machines to comprehend the information or emotions associated with interactions in online spaces. Multimodal Large Language Models (MLLMs) have emerged as a... | Yiqiao Jin, Minje Choi, Gaurav Verma, Jindong Wang, Srijan Kumar |  |
| 1356 |  |  [Instances Need More Care: Rewriting Prompts for Instances with LLMs in the Loop Yields Better Zero-Shot Performance](https://doi.org/10.18653/v1/2024.findings-acl.371) |  | 0 | Large language models (LLMs) have revolutionized zero-shot task performance, mitigating the need for task-specific annotations while enhancing task generalizability. Despite its advancements, current methods using trigger phrases such as “Let’s think step by step” remain limited. This study... | Saurabh Srivastava, Chengyue Huang, Weiguo Fan, Ziyu Yao |  |
| 1357 |  |  [Benchmarking Retrieval-Augmented Generation for Medicine](https://doi.org/10.18653/v1/2024.findings-acl.372) |  | 0 | While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted.... | Guangzhi Xiong, Qiao Jin, Zhiyong Lu, Aidong Zhang |  |
| 1358 |  |  [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://doi.org/10.18653/v1/2024.findings-acl.373) |  | 0 | While LLMs demonstrate impressive capabilities in musical knowledge, we find that music reasoning is still an unsolved task.We introduce ChatMusician, an open-source large language model (LLM) that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2... | Ruibin Yuan, Hanfeng Lin, Yi Wang, Zeyue Tian, Shangda Wu, Tianhao Shen, Ge Zhang, Yuhang Wu, Cong Liu, Ziya Zhou, Liumeng Xue, Ziyang Ma, Qin Liu, Tianyu Zheng, Yizhi Li, Yinghao Ma, Yiming Liang, Xiaowei Chi, Ruibo Liu, Zili Wang, Chenghua Lin, Qifeng Liu, Tao Jiang, Wenhao Huang, Wenhu Chen, Jie Fu, Emmanouil Benetos, Gus Xia, Roger B. Dannenberg, Wei Xue, Shiyin Kang, Yike Guo |  |
| 1359 |  |  [Towards Robust Temporal Reasoning of Large Language Models via a Multi-Hop QA Dataset and Pseudo-Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.374) |  | 0 | Knowledge in the real world is being updated constantly. However, it is costly to frequently update large language models (LLMs). Therefore, it is crucial for LLMs to understand the concept of temporal knowledge. However, prior works on temporal question answering (TQA) did not emphasize... | Qingyu Tan, Hwee Tou Ng, Lidong Bing |  |
| 1360 |  |  [Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements](https://doi.org/10.18653/v1/2024.findings-acl.375) |  | 0 |  | Anton Voronov, Lena Wolf, Max Ryabinin |  |
| 1361 |  |  [Knowledge Graph-Enhanced Large Language Models via Path Selection](https://doi.org/10.18653/v1/2024.findings-acl.376) |  | 0 | Large Language Models (LLMs) have shown unprecedented performance in various real-world applications. However, they are known to generate factually inaccurate outputs, a.k.a. the hallucination problem. In recent years, incorporating external knowledge extracted from Knowledge Graphs (KGs) has... | Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li |  |
| 1362 |  |  [OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission Translation Errors Detection](https://doi.org/10.18653/v1/2024.findings-acl.377) |  | 0 | Recently, there has been considerable attention on detecting hallucinations and omissions in Machine Translation (MT) systems. The two dominant approaches to tackle this task involve analyzing the MT system’s internal states or relying on the output of external tools, such as sentence similarity or... | Chenyang Huang, Abbas Ghaddar, Ivan Kobyzev, Mehdi Rezagholizadeh, Osmar Zaïane, Boxing Chen |  |
| 1363 |  |  [ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.378) |  | 0 | In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we... | Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan |  |
| 1364 |  |  [Speech-based Slot Filling using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.379) |  | 0 | Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated... | Guangzhi Sun, Shutong Feng, Dongcheng Jiang, Chao Zhang, Milica Gasic, Philip C. Woodland |  |
| 1365 |  |  [Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies](https://doi.org/10.18653/v1/2024.findings-acl.380) |  | 0 | As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how... | Changye Li, Zhecheng Sheng, Trevor Cohen, Serguei Pakhomov |  |
| 1366 |  |  [HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.381) |  | 0 | While large language models (LLMs) excel in various natural language tasks in English, their performance in low-resource languages like Hebrew, especially for generative tasks such as abstractive summarization, remains unclear. The high morphological richness in Hebrew adds further challenges due... | Tzuf PazArgaman, Itai Mondshine, Asaf Achi Mordechai, Reut Tsarfaty |  |
| 1367 |  |  [TRAM: Benchmarking Temporal Reasoning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.382) |  | 0 | Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper,... | Yuqing Wang, Yun Zhao |  |
| 1368 |  |  [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.383) |  | 0 | This paper investigates the capabilities of Large Language Models (LLMs) in understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our... | Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, William Yang Wang |  |
| 1369 |  |  [Exploring Defeasibility in Causal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.384) |  | 0 | Defeasibility in causal reasoning implies that the causal relationship between cause and effect can be strengthened or weakened. Namely, the causal strength between cause and effect should increase or decrease with the incorporation of strengthening arguments (supporters) or weakening arguments... | Shaobo Cui, Lazar Milikic, Yiyang Feng, Mete Ismayilzada, Debjit Paul, Antoine Bosselut, Boi Faltings |  |
| 1370 |  |  [Better Synthetic Data by Retrieving and Transforming Existing Datasets](https://doi.org/10.18653/v1/2024.findings-acl.385) |  | 0 | Despite recent advances in large language models, building dependable and deployable NLP models typically requires abundant, high-quality training data. However, task-specific data is not available for many use cases, and manually curating task-specific data is labor-intensive. Recent work has... | Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, Graham Neubig |  |
| 1371 |  |  [Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models](https://doi.org/10.18653/v1/2024.findings-acl.386) |  | 0 | In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to... | Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He |  |
| 1372 |  |  [Perspective Taking through Generating Responses to Conflict Situations](https://doi.org/10.18653/v1/2024.findings-acl.387) |  | 0 | Although language model performance across diverse tasks continues to improve, these models still struggle to understand and explain the beliefs of other people. This skill requires perspective-taking, the process of conceptualizing the point of view of another person. Perspective taking becomes... | Joan Plepi, Charles Welch, Lucie Flek |  |
| 1373 |  |  [LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement](https://doi.org/10.18653/v1/2024.findings-acl.388) |  | 0 | Pretrained large language models (LLMs) are currently state-of-the-art for solving the vast majority of natural language processing tasks. While many real-world applications still require fine-tuning to reach satisfactory levels of performance, many of them are in the low-data regime, making... | Nicholas Lee, Thanakul Wattanawong, Sehoon Kim, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipalli, Michael W. Mahoney, Kurt Keutzer, Amir Gholami |  |
| 1374 |  |  [The Power of Summary-Source Alignments](https://doi.org/10.18653/v1/2024.findings-acl.389) |  | 0 | Multi-document summarization (MDS) is a challenging task, often decomposed to subtasks of salience and redundancy detection, followed by text generation.In this context, alignment of corresponding sentences between a reference summary and its source documents has been leveraged to generate training... | Ori Ernst, Ori Shapira, Aviv Slobodkin, Sharon Adar, Mohit Bansal, Jacob Goldberger, Ran Levy, Ido Dagan |  |
| 1375 |  |  [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.390) |  | 0 | Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming... | Gantavya Bhatt, Yifang Chen, Arnav Mohanty Das, Jifan Zhang, Sang T. Truong, Stephen Mussmann, Yinglun Zhu, Jeff A. Bilmes, Simon S. Du, Kevin G. Jamieson, Jordan T. Ash, Robert D. Nowak |  |
| 1376 |  |  [Learning Multimodal Contrast with Cross-modal Memory and Reinforced Contrast Recognition](https://doi.org/10.18653/v1/2024.findings-acl.391) |  | 0 | In many practical scenarios, contents from different modalities are not semantically aligned; for instance, visual and textual information may conflict with each other, resulting in non-compositional expression effects such as irony or humor. Effective modeling and smooth integration of multimodal... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 1377 |  |  [Text Simplification via Adaptive Teaching](https://doi.org/10.18653/v1/2024.findings-acl.392) |  | 0 | Text simplification is the process of rewriting a piece of text using simpler vocabulary and grammatical structure in order to make the text more accessible and understandable for a larger audience. In this paper, we introduce a new text simplification model based on the notion of adaptive teaching... | Seyed Ali Bahrainian, Jonathan Dou, Carsten Eickhoff |  |
| 1378 |  |  [A multi-level multi-label text classification dataset of 19th century Ottoman and Russian literary and critical texts](https://doi.org/10.18653/v1/2024.findings-acl.393) |  | 0 | This paper introduces a multi-level, multi-label text classification dataset comprising over 3000 documents. The dataset features literary and critical texts from 19th-century Ottoman Turkish and Russian. It is the first study to apply large language models (LLMs) to this dataset, sourced from... | Gokcen Gokceoglu, Devrim Cavusoglu, Emre Akbas, Özen Nergis Dolcerocca |  |
| 1379 |  |  [It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment Analysis Performance](https://doi.org/10.18653/v1/2024.findings-acl.394) |  | 0 | Aspect-Based Sentiment Analysis (ABSA) involves extracting opinions from textual data about specific entities and their corresponding aspects through various complementary subtasks. Several prior research has focused on developing ad hoc designs of varying complexities for these subtasks. In this... | Laura Cabello, Uchenna Akujuobi |  |
| 1380 |  |  [Whose Emotions and Moral Sentiments do Language Models Reflect?](https://doi.org/10.18653/v1/2024.findings-acl.395) |  | 0 | Language models (LMs) are known to represent the perspectives of some social groups better than others, which may impact their performance, especially on subjective tasks such as content moderation and hate speech detection. To explore how LMs represent different perspectives, existing research... | Zihao He, Siyi Guo, Ashwin Rao, Kristina Lerman |  |
| 1381 |  |  [LLM can Achieve Self-Regulation via Hyperparameter Aware Generation](https://doi.org/10.18653/v1/2024.findings-acl.396) |  | 0 | In the realm of Large Language Models (LLMs), users commonly employ diverse decoding strategies and adjust hyperparameters to control the generated text. However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves? The... | Siyin Wang, Shimin Li, Tianxiang Sun, Jinlan Fu, Qinyuan Cheng, Jiasheng Ye, Junjie Ye, Xipeng Qiu, Xuanjing Huang |  |
| 1382 |  |  [Forward-Backward Reasoning in Large Language Models for Mathematical Verification](https://doi.org/10.18653/v1/2024.findings-acl.397) |  | 0 | Self-Consistency samples diverse reasoning chains with answers and chooses the final answer by majority voting. It is based on forward reasoning and cannot further improve performance by sampling more reasoning chains when saturated. To further boost performance, we introduce backward reasoning to... | Weisen Jiang, Han Shi, Longhui Yu, Zhengying Liu, Yu Zhang, Zhenguo Li, James T. Kwok |  |
| 1383 |  |  [Towards Uncertainty-Aware Language Agent](https://doi.org/10.18653/v1/2024.findings-acl.398) |  | 0 | While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware... | Jiuzhou Han, Wray L. Buntine, Ehsan Shareghi |  |
| 1384 |  |  [Detection and Positive Reconstruction of Cognitive Distortion Sentences: Mandarin Dataset and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.399) |  | 0 | This research introduces a Positive Reconstruction Framework based on positive psychology theory. Overcoming negative thoughts can be challenging, our objective is to address and reframe them through a positive reinterpretation. To tackle this challenge, a two-fold approach is necessary:... | Shuya Lin, Yuxiong Wang, Jonathan Dong, Shiguang Ni |  |
| 1385 |  |  [PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.400) |  | 0 | Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pre-training data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework,... | Jiuzhou Han, Nigel Collier, Wray L. Buntine, Ehsan Shareghi |  |
| 1386 |  |  [Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.401) |  | 0 | Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over... | Yifu Gao, Linbo Qiao, Zhigang Kan, Zhihua Wen, Yongquan He, Dongsheng Li |  |
| 1387 |  |  [VISREAS: Complex Visual Reasoning with Unanswerable Questions](https://doi.org/10.18653/v1/2024.findings-acl.402) |  | 0 | Verifying a question’s validity before answering is crucial in real-world applications, where users may provide imperfect instructions. In this scenario, an ideal model should address the discrepancies in the query and convey them to the users rather than generating the best possible answer.... | Syeda Nahida Akter, Sangwu Lee, Yingshan Chang, Yonatan Bisk, Eric Nyberg |  |
| 1388 |  |  [A Unified Generative Framework for Bilingual Euphemism Detection and Identification](https://doi.org/10.18653/v1/2024.findings-acl.403) |  | 0 | Various euphemisms are emerging in social networks, attracting widespread attention from the natural language processing community. However, existing euphemism datasets are only domain-specific or language-specific. In addition, existing approaches to the study of euphemisms are one-sided. Either... | Yuxue Hu, Junsong Li, Tongguan Wang, Dongyu Su, Guixin Su, Ying Sha |  |
| 1389 |  |  [StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing](https://doi.org/10.18653/v1/2024.findings-acl.404) |  | 0 | Given a script, the challenge in Movie Dubbing (Visual Voice Cloning, V2C) is to generate speech that aligns well with the video in both time and emotion, based on the tone of a reference audio track. Existing state-of-the-art V2C models break the phonemes in the script according to the divisions... | Gaoxiang Cong, Yuankai Qi, Liang Li, Amin Beheshti, Zhedong Zhang, Anton van den Hengel, MingHsuan Yang, Chenggang Yan, Qingming Huang |  |
| 1390 |  |  [ETAS: Zero-Shot Transformer Architecture Search via Network Trainability and Expressivity](https://doi.org/10.18653/v1/2024.findings-acl.405) |  | 0 | Transformer Architecture Search (TAS) methods aim to automate searching for the optimal Transformer architecture configurations for a given task. However, they are impeded by the prohibitive cost of evaluating Transformer architectures. Recently, several Zero-Shot TAS methods have been proposed to... | Jiechao Yang, Yong Liu |  |
| 1391 |  |  [Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment](https://doi.org/10.18653/v1/2024.findings-acl.406) |  | 0 | Medical dialogue systems have attracted significant attention for their potential to act as medical assistants. Enabling these medical systems to emulate clinicians’ diagnostic reasoning process has been the long-standing research focus. Previous studies rudimentarily realized the simulation of... | Kaishuai Xu, Yi Cheng, Wenjun Hou, Qiaoyu Tan, Wenjie Li |  |
| 1392 |  |  [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.407) |  | 0 | This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath... | Yanan Wu, Jie Liu, Xingyuan Bu, Jiaheng Liu, Zhanhui Zhou, Yuanxing Zhang, Chenchen Zhang, Zhiqi Bai, Haibin Chen, Tiezheng Ge, Wanli Ouyang, Wenbo Su, Bo Zheng |  |
| 1393 |  |  [REInstruct: Building Instruction Data from Unlabeled Corpus](https://doi.org/10.18653/v1/2024.findings-acl.408) |  | 0 | Manually annotating instruction data for large language models is difficult, costly, and hard to scale. Meanwhile, current automatic annotation methods typically rely on distilling synthetic data from proprietary LLMs, which not only limits the upper bound of the quality of the instruction data but... | Shu Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun |  |
| 1394 |  |  [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://doi.org/10.18653/v1/2024.findings-acl.409) |  | 0 | Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller... | Xin Chen, Hanxian Huang, Yanjun Gao, Yi Wang, Jishen Zhao, Ke Ding |  |
| 1395 |  |  [PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning](https://doi.org/10.18653/v1/2024.findings-acl.410) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as an effective method for adapting pre-trained language models to various tasks efficiently. Recently, there has been a growing interest in transferring knowledge from one or multiple tasks to the downstream target task to achieve performance... | Zhisheng Lin, Han Fu, Chenghao Liu, Zhuo Li, Jianling Sun |  |
| 1396 |  |  [MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.411) |  | 0 | Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics. However, traditional math benchmarks like GSM8k offer a unidimensional perspective, which fall short in providing a holistic assessment of the LLMs’ math capabilities. To address this gap, we... | Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 1397 |  |  [Identifying Semantic Induction Heads to Understand In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.412) |  | 0 | Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to... | Jie Ren, Qipeng Guo, Hang Yan, Dongrui Liu, Quanshi Zhang, Xipeng Qiu, Dahua Lin |  |
| 1398 |  |  [Chinese Spelling Corrector Is Just a Language Learner](https://doi.org/10.18653/v1/2024.findings-acl.413) |  | 0 | This paper emphasizes Chinese spelling correction by means of self-supervised learning, which means there are no annotated errors within the training data. Our intuition is that humans are naturally good correctors with exposure to error-free sentences, which contrasts with current unsupervised... | Lai Jiang, Hongqiu Wu, Hai Zhao, Min Zhang |  |
| 1399 |  |  [Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.414) |  | 0 |  | Junfei Wu, Qiang Liu, Ding Wang, Jinghao Zhang, Shu Wu, Liang Wang, Tieniu Tan |  |
| 1400 |  |  [RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.415) |  | 0 | Adaptive retrieval-augmented generation (ARAG) aims to dynamically determine the necessity of retrieval for queries instead of retrieving indiscriminately to enhance the efficiency and relevance of the sourced information. However, previous works largely overlook the evaluation of ARAG approaches,... | Zihan Zhang, Meng Fang, Ling Chen |  |
| 1401 |  |  [LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.416) |  | 0 | We introduces \*\*\*LLaST\*\*\*, a framework for building high-performance Large Language model based Speech-to-text Translation systems. We address the limitations of end-to-end speech translation (E2E ST) models by exploring model architecture design and optimization techniques tailored for LLMs.... | Xi Chen, Songyang Zhang, Qibing Bai, Kai Chen, Satoshi Nakamura |  |
| 1402 |  |  [Plan, Generate and Complicate: Improving Low-resource Dialogue State Tracking via Easy-to-Difficult Zero-shot Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.417) |  | 0 | Data augmentation methods have been a promising direction to improve the performance of small models for low-resource dialogue state tracking. However, traditional methods rely on pre-defined user goals and neglect the importance of data complexity in this task. In this paper, we propose EDZ-DA, an... | Ming Gu, Yan Yang |  |
| 1403 |  |  [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](https://doi.org/10.18653/v1/2024.findings-acl.418) |  | 0 | The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning. There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance... | Shanghaoran Quan |  |
| 1404 |  |  [LEIA: Facilitating Cross-lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.419) |  | 0 | Adapting English-based large language models (LLMs) to other languages has become increasingly popular due to the efficiency and potential of cross-lingual transfer. However, existing language adaptation methods often overlook the benefits of cross-lingual supervision. In this study, we introduce... | Ikuya Yamada, Ryokan Ri |  |
| 1405 |  |  [Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective](https://doi.org/10.18653/v1/2024.findings-acl.420) |  | 0 | Code generation aims to understand the problem description and generate corresponding code snippets, where existing works generally decompose such complex tasks into intermediate steps by prompting strategies, such as Chain-of-Thought and its variants. While these studies have achieved some... | Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou |  |
| 1406 |  |  [Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration](https://doi.org/10.18653/v1/2024.findings-acl.421) |  | 0 | The proliferation of Large Language Models (LLMs) has led to an influx of AI-generated content (AIGC) on the internet, transforming the corpus of Information Retrieval (IR) systems from solely human-written to a coexistence with LLM-generated content. The impact of this surge in AIGC on IR systems... | Sunhao Dai, Weihao Liu, Yuqi Zhou, Liang Pang, Rongju Ruan, Gang Wang, Zhenhua Dong, Jun Xu, JiRong Wen |  |
| 1407 |  |  [Continual Dialogue State Tracking via Reason-of-Select Distillation](https://doi.org/10.18653/v1/2024.findings-acl.422) |  | 0 | An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services, confronting catastrophic forgetting and a critical capability loss termed the... | Yujie Feng, Bo Liu, Xiaoyu Dong, Zexin Lu, LiMing Zhan, XiaoMing Wu, Albert Y. S. Lam |  |
| 1408 |  |  [Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text](https://doi.org/10.18653/v1/2024.findings-acl.423) |  | 0 | AI-generated text detection has attracted increasing attention as powerful language models approach human-level generation. Limited work is devoted to detecting (partially) AI-paraphrased texts. However, AI paraphrasing is commonly employed in various application scenarios for text refinement and... | Yafu Li, Zhilin Wang, Leyang Cui, Wei Bi, Shuming Shi, Yue Zhang |  |
| 1409 |  |  [SoFA: Shielded On-the-fly Alignment via Priority Rule Following](https://doi.org/10.18653/v1/2024.findings-acl.424) |  | 0 | The alignment problem in Large Language Models (LLMs) involves adapting them to the broad spectrum of human values. This requirement challenges existing alignment methods due to diversity of preferences and regulatory standards. This paper introduces a novel alignment paradigm, priority rule... | Xinyu Lu, Bowen Yu, Yaojie Lu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, Yongbin Li |  |
| 1410 |  |  [Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition](https://doi.org/10.18653/v1/2024.findings-acl.425) |  | 0 | Recent advances in LLMs have sparked a debate on whether they understand text. In this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. To substantiate this claim, we propose a... | Ariel Goldstein, Gabriel Stanovsky |  |
| 1411 |  |  [Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning](https://doi.org/10.18653/v1/2024.findings-acl.426) |  | 0 | Telling stories is an integral part of human communication which can evoke emotions and influence the affective states of the audience. Automatically modeling emotional trajectories in stories has thus attracted considerable scholarly interest. However, as most existing works have been limited to... | Lukas Christ, Shahin Amiriparian, Manuel Milling, Ilhan Aslan, Björn W. Schuller |  |
| 1412 |  |  [RAP: Efficient Text-Video Retrieval with Sparse-and-Correlated Adapter](https://doi.org/10.18653/v1/2024.findings-acl.427) |  | 0 | Text-Video Retrieval (TVR) aims to align relevant video content with natural language queries. To date, most of the state-of-the-art TVR methods learn image-to-video transfer learning based on the large-scale pre-trained vision-language models (e.g., CLIP). However, fully fine-tuning these... | Meng Cao, Haoran Tang, Jinfa Huang, Peng Jin, Can Zhang, Ruyang Liu, Long Chen, Xiaodan Liang, Li Yuan, Ge Li |  |
| 1413 |  |  [Benchmarking and Improving Long-Text Translation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.428) |  | 0 | Recent studies have illuminated the promising capabilities of large language models (LLMs) in handling long texts. However, their performance in machine translation (MT) of long documents remains underexplored. This paper aims to shed light on how LLMs navigate this complex task, offering a... | Longyue Wang, Zefeng Du, Wenxiang Jiao, Chenyang Lyu, Jianhui Pang, Leyang Cui, Kaiqiang Song, Derek F. Wong, Shuming Shi, Zhaopeng Tu |  |
| 1414 |  |  [Personalized Topic Selection Model for Topic-Grounded Dialogue](https://doi.org/10.18653/v1/2024.findings-acl.429) |  | 0 | Recently, the topic-grounded dialogue (TGD) system has become increasingly popular as its powerful capability to actively guide users to accomplish specific tasks through topic-guided conversations. Most existing works utilize side information (e.g. topics or personas) in isolation to enhance the... | Shixuan Fan, Wei Wei, Xiaofei Wen, XianLing Mao, Jixiong Chen, Dangyang Chen |  |
| 1415 |  |  [Debiasing In-Context Learning by Instructing LLMs How to Follow Demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.430) |  | 0 | In-context learning(ICL) has gained considerable attention due to its data efficiency and task adaptability. Unfortunately, ICL suffers from the demonstration bias, i.e., its performance and robustness are severely affected by the selection and ordering of demonstrations. In this paper, we identify... | Lvxue Li, Jiaqi Chen, Xinyu Lu, Yaojie Lu, Hongyu Lin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Zhongyi Liu, Xianpei Han, Le Sun |  |
| 1416 |  |  [Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog Systems](https://doi.org/10.18653/v1/2024.findings-acl.431) |  | 0 | Creating effective and reliable task-oriented dialog systems (ToDSs) is challenging, not only because of the complex structure of these systems, but also due to the scarcity of training data, especially when several modules need to be trained separately, each one with its own input/output training... | Christos Vlachos, Themos Stafylakis, Ion Androutsopoulos |  |
| 1417 |  |  [MS2SL: Multimodal Spoken Data-Driven Continuous Sign Language Production](https://doi.org/10.18653/v1/2024.findings-acl.432) |  | 0 | Sign language understanding has made significant strides; however, there is still no viable solution for generating sign sequences directlyfrom entire spoken content, e.g., text or speech. In this paper, we propose a unified framework for continuous sign language production, easing communication... | Jian Ma, Wenguan Wang, Yi Yang, Feng Zheng |  |
| 1418 |  |  [BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.433) |  | 0 | Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional... | Xueliang Zhao, Xinting Huang, Tingchen Fu, Qintong Li, Shansan Gong, Lemao Liu, Wei Bi, Lingpeng Kong |  |
| 1419 |  |  [PartialFormer: Modeling Part Instead of Whole for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.434) |  | 0 | The design choices in Transformer feed-forward neural networks have resulted in significant computational and parameter overhead. In this work, we emphasize the importance of hidden dimensions in designing lightweight FFNs, a factor often overlooked in previous architectures. Guided by this... | Tong Zheng, Bei Li, Huiwen Bao, Jiale Wang, Weiqiao Shan, Tong Xiao, JingBo Zhu |  |
| 1420 |  |  [Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with Extract-Then-Assign Strategy](https://doi.org/10.18653/v1/2024.findings-acl.435) |  | 0 | In the task of aspect sentiment quad prediction (ASQP), generative methods for predicting sentiment quads have shown promisingresults. However, they still suffer from imprecise predictions and limited interpretability, caused by data scarcity and inadequate modeling of the quadruplet composition... | Jieyong Kim, Ryang Heo, Yongsik Seo, SeongKu Kang, Jinyoung Yeo, Dongha Lee |  |
| 1421 |  |  [PACE: Improving Prompt with Actor-Critic Editing for Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.436) |  | 0 | Large language models (LLMs) have showcased remarkable potential across various tasks by conditioning on prompts. However, the quality of different human-written prompts leads to substantial discrepancies in LLMs’ performance, and improving prompts usually necessitates considerable human effort and... | Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, Ge Li |  |
| 1422 |  |  [Penetrative AI: Making LLMs Comprehend the Physical World](https://doi.org/10.18653/v1/2024.findings-acl.437) |  | 0 | Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real... | Huatao Xu, Liying Han, Qirui Yang, Mo Li, Mani Srivastava |  |
| 1423 |  |  [The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis](https://doi.org/10.18653/v1/2024.findings-acl.438) |  | 0 | In-context learning is a popular inference strategy where large language models solve a task using only a few labeled demonstrations without needing any parameter updates. Although there have been extensive studies on English in-context learning, multilingual in-context learning remains... | Miaoran Zhang, Vagrant Gautam, Mingyang Wang, Jesujoba Alabi, Xiaoyu Shen, Dietrich Klakow, Marius Mosbach |  |
| 1424 |  |  [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](https://doi.org/10.18653/v1/2024.findings-acl.439) |  | 0 |  | Ming Dong, Yujing Chen, Miao Zhang, Hao Sun, Tingting He |  |
| 1425 |  |  [An Empirical Study of In-context Learning in LLMs for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.440) |  | 0 | Recent interest has surged in employing Large Language Models (LLMs) for machine translation (MT) via in-context learning (ICL) (Vilar et al., 2023). Most prior studies primarily focus on optimizing translation quality, with limited attention to understanding the specific aspects of ICL that... | Pranjal A. Chitale, Jay P. Gala, Raj Dabre |  |
| 1426 |  |  ["My Answer is C": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models](https://doi.org/10.18653/v1/2024.findings-acl.441) |  | 0 | The open-ended nature of language generation makes the evaluation of autoregressive large language models (LLMs) challenging. One common evaluation approach uses multiple-choice questions to limit the response space. The model is then evaluated by ranking the candidate answers by the log... | Xinpeng Wang, Bolei Ma, Chengzhi Hu, Leon WeberGenzel, Paul Röttger, Frauke Kreuter, Dirk Hovy, Barbara Plank |  |
| 1427 |  |  [ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.442) |  | 0 | The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has achieved remarkable success in various natural language processing tasks. However, existing methodologies that integrate LLMs and KGs often navigate the task-solving process solely based on the LLM’s analysis of the... | Lei Sun, Zhengwei Tao, Youdi Li, Hiroshi Arakawa |  |
| 1428 |  |  [A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.443) |  | 0 | Large Language Models (LLMs) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques... | Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, Stjepan Picek |  |
| 1429 |  |  [A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning](https://doi.org/10.18653/v1/2024.findings-acl.444) |  | 0 |  | Panagiotis Kaliosis, John Pavlopoulos, Foivos Charalampakos, Georgios Moschovis, Ion Androutsopoulos |  |
| 1430 |  |  [Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.445) |  | 0 | Aligned Large Language Models (LLMs) showcase remarkable versatility, capable of handling diverse real-world tasks. Meanwhile, aligned LLMs are also expected to exhibit speciality, excelling in specific applications. However, fine-tuning with extra data, a common practice to gain speciality, often... | Hengyuan Zhang, Yanru Wu, Dawei Li, Sak Yang, Rui Zhao, Yong Jiang, Fei Tan |  |
| 1431 |  |  [A Two-Agent Game for Zero-shot Relation Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.446) |  | 0 | Relation triplet extraction is a fundamental task in natural language processing that aims to identify semantic relationships between entities in text. It is particularly challenging in the zero-shot setting, i.e., zero-shot relation triplet extraction (ZeroRTE), where the relation sets between... | Ting Xu, Haiqin Yang, Fei Zhao, Zhen Wu, Xinyu Dai |  |
| 1432 |  |  [Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning](https://doi.org/10.18653/v1/2024.findings-acl.447) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as the predominant technique for fine-tuning in the era of large language models. However, existing PEFT methods still have inadequate training efficiency. Firstly, the utilization of large-scale foundation models during the training process is... | Naibin Gu, Peng Fu, Xiyu Liu, Bowen Shen, Zheng Lin, Weiping Wang |  |
| 1433 |  |  [Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German](https://doi.org/10.18653/v1/2024.findings-acl.448) |  | 0 | The translation of gender-neutral person-referring terms (e.g.,the students) is often non-trivial.Translating from English into German poses an interesting case—in German, person-referring nouns are usually gender-specific, and if the gender of the referent(s) is unknown or diverse, the generic... | Manuel Lardelli, Giuseppe Attanasio, Anne Lauscher |  |
| 1434 |  |  [Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.449) |  | 0 |  | Shichao Sun, Ruifeng Yuan, Ziqiang Cao, Wenjie Li, Pengfei Liu |  |
| 1435 |  |  [Trust in Internal or External Knowledge? Generative Multi-Modal Entity Linking with Knowledge Retriever](https://doi.org/10.18653/v1/2024.findings-acl.450) |  | 0 | Multi-modal entity linking (MEL) is a challenging task that requires accurate prediction of entities within extensive search spaces, utilizing multi-modal contexts. Existing generative approaches struggle with the knowledge gap between visual entity information and the intrinsic parametric... | Xinwei Long, Jiali Zeng, Fandong Meng, Jie Zhou, Bowen Zhou |  |
| 1436 |  |  [A Semantic Distance Metric Learning approach for Lexical Semantic Change Detection](https://doi.org/10.18653/v1/2024.findings-acl.451) |  | 0 | Detecting temporal semantic changes of words is an important task for various NLP applications that must make time-sensitive predictions.Lexical Semantic Change Detection (SCD) task involves predicting whether a given target word, w, changes its meaning between two different text corpora, C1 and... | Taichi Aida, Danushka Bollegala |  |
| 1437 |  |  [What Have We Achieved on Non-autoregressive Translation?](https://doi.org/10.18653/v1/2024.findings-acl.452) |  | 0 | Recent advances have made non-autoregressive (NAT) translation comparable to autoregressive methods (AT). However, their evaluation using BLEU has been shown to weakly correlate with human annotations. Limited research compares non-autoregressive translation and autoregressive translation... | Yafu Li, Huajian Zhang, Jianhao Yan, Yongjing Yin, Yue Zhang |  |
| 1438 |  |  [From Zero to Hero: Cold-Start Anomaly Detection](https://doi.org/10.18653/v1/2024.findings-acl.453) |  | 0 |  | Tal Reiss, George Kour, Naama Zwerdling, Ateret AnabyTavor, Yedid Hoshen |  |
| 1439 |  |  [Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives](https://doi.org/10.18653/v1/2024.findings-acl.454) |  | 0 | Existing datasets for narrative understanding often fail to represent the complexity and uncertainty of relationships in real-life social scenarios. To address this gap, we introduce a new benchmark, Conan, designed for extracting and analysing intricate character relation graphs from detective... | Runcong Zhao, Qinglin Zhu, Hainiu Xu, Jiazheng Li, Yuxiang Zhou, Yulan He, Lin Gui |  |
| 1440 |  |  [DistillMIKE: Editing Distillation of Massive In-Context Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.455) |  | 0 | Among the recently emerged knowledge editing methods, in-context knowledge editing (IKE) has shown respectable abilities on knowledge editing in terms of generalization and specificity. Noting the promising advantages but unexplored issues of IKE, we propose \*\*DistillMIKE\*\* as a novel extension... | Shanbao Qiao, Xuebing Liu, SeungHoon Na |  |
| 1441 |  |  [Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.456) |  | 0 | To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first drafts several future tokens efficiently and then verifies them in... | Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu, Wenjie Li, Zhifang Sui |  |
| 1442 |  |  [Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.457) |  | 0 | Hierarchical text classification (HTC) is a challenging problem with two key issues: utilizing structural information and mitigating label imbalance. Recently, the unit-based approach generating unit-based feature representations has outperformed the global approach focusing on a global feature... | Gibaeg Kim, Sanghun Im, HeungSeon Oh |  |
| 1443 |  |  [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](https://doi.org/10.18653/v1/2024.findings-acl.458) |  | 0 | In the era of large language models, applying techniques such as Retrieval Augmented Generation can better address Open-Domain Question-Answering problems. Due to constraints including model sizes and computing resources, the length of context is often limited, and it becomes challenging to empower... | Zhuo Chen, Xinyu Wang, Yong Jiang, Pengjun Xie, Fei Huang, Kewei Tu |  |
| 1444 |  |  [CICLe: Conformal In-Context Learning for Largescale Multi-Class Food Risk Classification](https://doi.org/10.18653/v1/2024.findings-acl.459) |  | 0 | Contaminated or adulterated food poses a substantial risk to human health. Given sets of labeled web texts for training, Machine Learning and Natural Language Processing can be applied to automatically detect such risks. We publish a dataset of 7,546 short texts describing public food recall... | Korbinian Randl, John Pavlopoulos, Aron Henriksson, Tony Lindgren |  |
| 1445 |  |  [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](https://doi.org/10.18653/v1/2024.findings-acl.460) |  | 0 | Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outliers in LLMs. Such outliers are found to... | Ruikang Liu, Haoli Bai, Haokun Lin, Yuening Li, Han Gao, Zhengzhuo Xu, Lu Hou, Jun Yao, Chun Yuan |  |
| 1446 |  |  [Learning Adverbs with Spectral Mixture Kernels](https://doi.org/10.18653/v1/2024.findings-acl.461) |  | 0 | For humans and robots to collaborate more in the real world, robots need to understand human intentions from the different manner of their behaviors. In our study, we focus on the meaning of adverbs which describe human motions. We propose a topic model, Hierarchical Dirichlet Process-Spectral... | Tomoe Taniguchi, Daichi Mochihashi, Ichiro Kobayashi |  |
| 1447 |  |  [E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.462) |  | 0 | The rapid development of Large Language Models (LLMs) has led to their increasing utilization in Chinese K-12 education. Despite the growing integration of LLMs and education, the absence of a dedicated benchmark for evaluating LLMs within this domain presents a pressing concern. Consequently,... | Jinchang Hou, Chang Ao, Haihong Wu, Xiangtao Kong, Zhigang Zheng, Daijia Tang, Chengming Li, Xiping Hu, Ruifeng Xu, Shiwen Ni, Min Yang |  |
| 1448 |  |  [ChartAssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.463) |  | 0 | Charts play a vital role in data visualization, understanding data patterns, and informed decision-making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While... | Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, Ping Luo |  |
| 1449 |  |  [Teaching Small Language Models to Reason for Knowledge-Intensive Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.464) |  | 0 | Large Language Models (LLMs) can teach small language models (SLMs) to solve complex reasoning tasks (e.g., mathematical question answering) by Chain-of-thought Distillation (CoTD). Specifically, CoTD fine-tunes SLMs by utilizing rationales generated from LLMs such as ChatGPT. However, CoTD has... | Xiang Li, Shizhu He, Fangyu Lei, JunYang JunYang, Tianhuang Su, Kang Liu, Jun Zhao |  |
| 1450 |  |  [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://doi.org/10.18653/v1/2024.findings-acl.465) |  | 0 | We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences. The framework addresses the limitations of current alignment approaches,... | Yuhang Lai, Siyuan Wang, Shujun Liu, Xuanjing Huang, Zhongyu Wei |  |
| 1451 |  |  [LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting](https://doi.org/10.18653/v1/2024.findings-acl.466) |  | 0 | Time-series forecasting (TSF) finds broad applications in real-world scenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates strong zero-shot TSF capabilities while preserving computational efficiency. However, existing prompting methods oversimplify TSF as language next-token... | Haoxin Liu, Zhiyuan Zhao, Jindong Wang, Harshavardhan Kamarthi, B. Aditya Prakash |  |
| 1452 |  |  [Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.467) |  | 0 | Text classification is a crucial task encountered frequently in practical scenarios, yet it is still under-explored in the era of large language models (LLMs). This study shows that LLMs are vulnerable to changes in the number and arrangement of options in text classification. Our extensive... | Zhenyi Lu, Jie Tian, Wei Wei, Xiaoye Qu, Yu Cheng, Wenfeng Xie, Dangyang Chen |  |
| 1453 |  |  [UOR: Universal Backdoor Attacks on Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.468) |  | 0 | Task-agnostic and transferable backdoors implanted in pre-trained language models (PLMs) pose a severe security threat as they can be inherited to any downstream task. However, existing methods rely on manual selection of triggers and backdoor representations, hindering their effectiveness and... | Wei Du, Peixuan Li, Haodong Zhao, Tianjie Ju, Ge Ren, Gongshen Liu |  |
| 1454 |  |  [Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences](https://doi.org/10.18653/v1/2024.findings-acl.469) |  | 0 | To date, most investigations on surprisal and entropy effects in reading have been conducted on the group level, disregarding individual differences. In this work, we revisit the predictive power (PP) of different LMs’ surprisal and entropy measures on data of human reading times as a measure of... | Patrick Haller, Lena S. Bolliger, Lena Ann Jäger |  |
| 1455 |  |  [The State of Relation Extraction Data Quality: Is Bigger Always Better?](https://doi.org/10.18653/v1/2024.findings-acl.470) |  | 0 | Relation extraction (RE) extracts structured tuples of relationships (e.g. friend, enemy) between entities (e.g. Sherlock Holmes, John Watson) from text, with exciting potential applications. Hundreds of RE papers have been published in recent years; do their evaluation practices inform these... | Erica Cai, Brendan T. O'Connor |  |
| 1456 |  |  [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Queries](https://doi.org/10.18653/v1/2024.findings-acl.471) |  | 0 | Large language models (LLMs) have manifested strong ability to generate codes for productive activities. However, current benchmarks for code synthesis, such as HumanEval, MBPP, and DS-1000, are predominantly oriented towards introductory tasks on algorithm and data science, insufficiently... | Shudan Zhang, Hanlin Zhao, Xiao Liu, Qinkai Zheng, Zehan Qi, Xiaotao Gu, Yuxiao Dong, Jie Tang |  |
| 1457 |  |  [LLMCrit: Teaching Large Language Models to Use Criteria](https://doi.org/10.18653/v1/2024.findings-acl.472) |  | 0 | Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, current research in this area tends to... | Weizhe Yuan, Pengfei Liu, Matthias Gallé |  |
| 1458 |  |  [Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.473) |  | 0 | The language ability of Large Language Models (LLMs) is often unbalanced towards English because of the imbalance in the distribution of the pre-training data. This disparity is demanded in further fine-tuning and affecting the cross-lingual abilities of LLMs. In this paper, we propose to empower... | Leonardo Ranaldi, Giulia Pucci, André Freitas |  |
| 1459 |  |  [Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies](https://doi.org/10.18653/v1/2024.findings-acl.474) |  | 0 | Conceptual spaces represent entities in terms of their primitive semantic features. Such representations are highly valuable but they are notoriously difficult to learn, especially when it comes to modelling perceptual and subjective features. Distilling conceptual spaces from Large Language Models... | Nitesh Kumar, Usashi Chatterjee, Steven Schockaert |  |
| 1460 |  |  [Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.475) |  | 0 | To achieve non-parametric NMT domain adaptation, k-Nearest-Neighbor Machine Translation (kNN-MT) constructs an external datastore to store domain-specific translation knowledge, which derives a kNN distribution to interpolate the prediction distribution of the NMT model via a linear interpolation... | Yan Gao, Zhiwei Cao, Zhongjian Miao, Baosong Yang, Shiyu Liu, Min Zhang, Jinsong Su |  |
| 1461 |  |  [Symmetric Dot-Product Attention for Efficient Training of BERT Language Models](https://doi.org/10.18653/v1/2024.findings-acl.476) |  | 0 | Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing. Nowadays, to tackle increasingly more complex... | Martin Courtois, Malte Ostendorff, Leonhard Hennig, Georg Rehm |  |
| 1462 |  |  [Synthesizing Conversations from Unlabeled Documents using Automatic Response Segmentation](https://doi.org/10.18653/v1/2024.findings-acl.477) |  | 0 | In this study, we tackle the challenge of inadequate and costly training data that has hindered the development of conversational question answering (ConvQA) systems. Enterprises have a large corpus of diverse internal documents. Instead of relying on a searching engine, a more compelling approach... | Fanyou Wu, Weijie Xu, Chandan K. Reddy, Srinivasan Sengamedu |  |
| 1463 |  |  [Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains](https://doi.org/10.18653/v1/2024.findings-acl.478) |  | 0 | Although large language models (LLMs) exhibit remarkable capacity to leverage in-context demonstrations, it is still unclear to what extent they can learn new facts or concept definitions via prompts. To address this question, we examine the capacity of instruction-tuned LLMs to follow in-context... | Marcio Fonseca, Shay B. Cohen |  |
| 1464 |  |  [Alignment-Based Decoding Policy for Low-Latency and Anticipation-Free Neural Japanese Input Method Editors](https://doi.org/10.18653/v1/2024.findings-acl.479) |  | 0 | Japanese input method editors (IMEs) are essential tools for inputting Japanese text using a limited set of characters such as the kana syllabary. However, despite their importance, the potential of newer attention-based encoder-decoder neural networks, such as Transformer, has not yet been fully... | Armin Sarhangzadeh, Taro Watanabe |  |
| 1465 |  |  [ECoK: Emotional Commonsense Knowledge Graph for Mining Emotional Gold](https://doi.org/10.18653/v1/2024.findings-acl.480) |  | 0 | The demand for understanding and expressing emotions in the field of natural language processing is growing rapidly. Knowledge graphs, as an important form of knowledge representation, have been widely utilized in various emotion-related tasks. However, existing knowledge graphs mainly focus on the... | Zhunheng Wang, Xiaoyi Liu, Mengting Hu, Rui Ying, Ming Jiang, Jianfeng Wu, Yalan Xie, Hang Gao, Renhong Cheng |  |
| 1466 |  |  [Deterministic Reversible Data Augmentation for Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.481) |  | 0 | Data augmentation is an effective way to diversify corpora in machine translation, but previous methods may introduce semantic inconsistency between original and augmented data because of irreversible operations and random subword sampling procedures. To generate both symbolically diverse and... | Jiashu Yao, Heyan Huang, Zeming Liu, Yuhang Guo |  |
| 1467 |  |  [Latent Learningscape Guided In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.482) |  | 0 | The growing interest in leveraging large language models is driven by their exceptional imitation and reasoning capabilities. In-context learning (ICL), a streamlined method, has shown potential in boosting these models’ performance without modifying their underlying parameters, especially when... | Anlai Zhou, Sunshine Jiang, Yifei Liu, Yiquan Wu, Kun Kuang, Jun Xiao |  |
| 1468 |  |  [SMR: State Memory Replay for Long Sequence Modeling](https://doi.org/10.18653/v1/2024.findings-acl.483) |  | 0 | Despite the promising performance of state space models (SSMs) in long sequence modeling, limitations still exist. Advanced SSMs like S5 and S6 (Mamba) in addressing non-uniform sampling, their recursive structures impede efficient SSM computation via convolution. To overcome compatibility... | Biqing Qi, Junqi Gao, Kaiyan Zhang, Dong Li, Jianxing Liu, Ligang Wu, Bowen Zhou |  |
| 1469 |  |  [Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks](https://doi.org/10.18653/v1/2024.findings-acl.484) |  | 0 | Large language models (LLMs) are proficient at generating fluent text with minimal task-specific supervision. However, their ability to generate rationales for knowledge-intensive tasks (KITs) remains under-explored. Generating rationales for KIT solutions, such as commonsense multiple-choice QA,... | Aditi Mishra, Sajjadur Rahman, Kushan Mitra, Hannah Kim, Estevam Hruschka |  |
| 1470 |  |  [Challenging Large Language Models with New Tasks: A Study on their Adaptability and Robustness](https://doi.org/10.18653/v1/2024.findings-acl.485) |  | 0 | Recent progress in large language models (LLMs) has marked a notable milestone in the field of artificial intelligence. The conventional evaluation of LLMs primarily relies on existing tasks and benchmarks, raising concerns about test set contamination and the genuine comprehension abilities of... | Chenxi Li, Yuanhe Tian, Zhaxi Zerong, Yan Song, Fei Xia |  |
| 1471 |  |  [Linear Cross-Lingual Mapping of Sentence Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.486) |  | 0 | Semantics of a sentence is defined with much less ambiguity than semantics of a single word, and we assume that it should be better preserved by translation to another language. If multilingual sentence embeddings intend to represent sentence semantics, then the similarity between embeddings of any... | Oleg Vasilyev, Fumika Isono, John Bohannon |  |
| 1472 |  |  [ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Self-Refinement](https://doi.org/10.18653/v1/2024.findings-acl.487) |  | 0 | Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a... | Xinliang Frederick Zhang, Carter Wood Blum, Temma Choji, Shalin Shah, Alakananda Vempala |  |
| 1473 |  |  [LLMs Beyond English: Scaling the Multilingual Capability of LLMs with Cross-Lingual Feedback](https://doi.org/10.18653/v1/2024.findings-acl.488) |  | 0 | To democratize large language models (LLMs) to most natural languages, it is imperative to make these models capable of understanding and generating texts in many languages, in particular low-resource ones. While recent multilingual LLMs demonstrate remarkable performance in such capabilities,... | Wen Lai, Mohsen Mesgar, Alexander Fraser |  |
| 1474 |  |  [BASS: Batched Attention-optimized Speculative Sampling](https://doi.org/10.18653/v1/2024.findings-acl.489) |  | 0 | Speculative decoding has emerged as a powerful method to improve latency and throughput in hosting large language models. However, most existing implementations focus on generating a single sequence. Real-world generative AI applications often require multiple responses and how to perform... | Haifeng Qian, Sujan Kumar Gonugondla, Sungsoo Ha, Mingyue Shang, Sanjay Krishna Gouda, Ramesh Nallapati, Sudipta Sengupta, Xiaofei Ma, Anoop Deoras |  |
| 1475 |  |  [Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games](https://doi.org/10.18653/v1/2024.findings-acl.490) |  | 0 | In this study, we explore the application of Large Language Models (LLMs) in Jubensha, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to... | Dekun Wu, Haochen Shi, Zhiyuan Sun, Bang Liu |  |
| 1476 |  |  [It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.491) |  | 0 | Natural language processing has seen rapid progress over the past decade. Due to the speed of developments, some practices get established without proper evaluation. Considering one such case and focusing on reading comprehension, we ask our first research question: 1) How does the order of inputs... | Sagi Shaier, Lawrence Hunter, Katharina von der Wense |  |
| 1477 |  |  [Large Language Models Relearn Removed Concepts](https://doi.org/10.18653/v1/2024.findings-acl.492) |  | 0 | Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by... | Michelle Lo, Fazl Barez, Shay B. Cohen |  |
| 1478 |  |  [Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond](https://doi.org/10.18653/v1/2024.findings-acl.493) |  | 0 | Task embedding, a meta-learning technique that captures task-specific information, has gained popularity, especially in areas such as multi-task learning, model editing, and interpretability. However, it faces challenges with the emergence of prompt-guided Large Language Models (LLMs) operating in... | Xinyu Wang, Hainiu Xu, Lin Gui, Yulan He |  |
| 1479 |  |  [TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles](https://doi.org/10.18653/v1/2024.findings-acl.494) |  | 0 | In light of recent advances in large language models (LLMs), the expectations for the next generation of virtual assistants include enhanced naturalness and adaptability across diverse usage scenarios. However, the creation of high-quality annotated data for Task-Oriented Dialog (TOD) is recognized... | Yinhong Liu, Yimai Fang, David Vandyke, Nigel Collier |  |
| 1480 |  |  [Machine-Generated Text Localization](https://doi.org/10.18653/v1/2024.findings-acl.495) |  | 0 | Machine-Generated Text (MGT) detection aims to identify a piece of text as machine or human written. Prior work has primarily formulated MGT detection as a binary classification task over an entire document, with limited work exploring cases where only part of a document is machine generated. This... | Zhongping Zhang, Wenda Qin, Bryan A. Plummer |  |
| 1481 |  |  [BenchIE⌃FL: A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.496) |  | 0 | Open Information Extraction (OIE) is a field of natural language processing that aims to present textual information in a format that allows it to be organized, analyzed and reflected upon. Numerous OIE systems are developed, claiming ever-increasing performance, marking the need for objective... | Fabrice Lamarche, Philippe Langlais |  |
| 1482 |  |  [CausalCite: A Causal Formulation of Paper Citations](https://doi.org/10.18653/v1/2024.findings-acl.497) |  | 0 | Citation count of a paper is a commonly used proxy for evaluating the significance of a paper in the scientific community. Yet citation measures are widely criticized for failing to accurately reflect the true impact of a paper. Thus, we propose CausalCite, a new way to measure the significance of... | Ishan Kumar, Zhijing Jin, Ehsan Mokhtarian, Siyuan Guo, Yuen Chen, Negar Kiyavash, Mrinmaya Sachan, Bernhard Schölkopf |  |
| 1483 |  |  [Question Translation Training for Better Multilingual Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.498) |  | 0 | Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into... | Wenhao Zhu, Shujian Huang, Fei Yuan, Shuaijie She, Jiajun Chen, Alexandra Birch |  |
| 1484 |  |  [Improving LLM Generations via Fine-Grained Self-Endorsement](https://doi.org/10.18653/v1/2024.findings-acl.499) |  | 0 | This work studies mitigating fact-conflicting hallucinations for large language model (LLM) at inference time.Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses.Compared with prior ensemble methods (e.g.,... | Ante Wang, Linfeng Song, Baolin Peng, Lifeng Jin, Ye Tian, Haitao Mi, Jinsong Su, Dong Yu |  |
| 1485 |  |  [Multi-Label Classification for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2024.findings-acl.500) |  | 0 | Discourse relations play a pivotal role in establishing coherence within textual content, uniting sentences and clauses into a cohesive narrative. The Penn Discourse Treebank (PDTB) stands as one of the most extensively utilized datasets in this domain. In PDTB-3, the annotators can assign multiple... | Wanqiu Long, Siddharth Narayanaswamy, Bonnie Webber |  |
| 1486 |  |  [StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code](https://doi.org/10.18653/v1/2024.findings-acl.501) |  | 0 | Code LLMs have the potential to make it easier for non-experts to understand and write code. However, current CodeLLM benchmarks rely on a single expert-written prompt per problem, making it hard to generalize their success to non-expert users. In this paper, we present a new... | Hannah McLean Babe, Sydney Nguyen, Yangtian Zi, Arjun Guha, Molly Q. Feldman, Carolyn Jane Anderson |  |
| 1487 |  |  [ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution](https://doi.org/10.18653/v1/2024.findings-acl.502) |  | 0 | Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing.... | Xuanming Zhang, Zixun Chen, Zhou Yu |  |
| 1488 |  |  [Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.503) |  | 0 | One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse.Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing... | Yuu Jinnai, Ukyo Honda, Tetsuro Morimura, Peinan Zhang |  |
| 1489 |  |  [GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages](https://doi.org/10.18653/v1/2024.findings-acl.504) |  | 0 | Neural Machine Translation (NMT) continues to improve in quality and adoption, yet the in advertent perpetuation of gender bias remains a significant concern. Despite numerous studies on gender bias in translations into English from weakly gendered-languages, there are no benchmarks for evaluating... | Spencer Rarrick, Ranjita Naik, Sundar Poudel, Vishal Chowdhary |  |
| 1490 |  |  [Hyperparameter-Free Approach for Faster Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.505) |  | 0 | Minimum Bayes-Risk (MBR) decoding is shown to be a powerful alternative to beam search decoding for a wide range of text generation tasks. However, MBR requires a huge amount of time for inference to compute the MBR objective, which makes the method infeasible in many situations where response time... | Yuu Jinnai, Kaito Ariu |  |
| 1491 |  |  [Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.506) |  | 0 | In recent years, neural machine translation (NMT) has become widely used in everyday life. However, the current NMT lacks a mechanism to adjust the difficulty level of translations to match the user’s language level. Additionally, due to the bias in the training data for NMT, translations of simple... | Masashi Oshika, Makoto Morishita, Tsutomu Hirao, Ryohei Sasano, Koichi Takeda |  |
| 1492 |  |  [Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining](https://doi.org/10.18653/v1/2024.findings-acl.507) |  | 0 | Large Language Models (LLMs) have shown human-like reasoning abilities but still face challenges in solving complex logical problems. Existing unidirectional chaining methods, such as forward chaining and backward chaining, suffer from issues like low prediction accuracy and efficiency. To address... | Shuqi Liu, Bowei He, Linqi Song |  |
| 1493 |  |  [Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?](https://doi.org/10.18653/v1/2024.findings-acl.508) |  | 0 | In this work, we investigate the controllability of large language models (LLMs) on scientific summarization tasks. We identify key stylistic and content coverage factors that characterize different types of summaries such as paper reviews, abstracts, and lay summaries. By controlling stylistic... | Marcio Fonseca, Shay B. Cohen |  |
| 1494 |  |  [Knowledge Context Modeling with Pre-trained Language Models for Contrastive Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.509) |  | 0 | Text-based knowledge graph completion (KGC) methods utilize pre-trained language models for triple encoding and further fine-tune the model to achieve completion. Despite their excellent performance, they neglect the knowledge context in inferring process. Intuitively, knowledge contexts, which... | Guangqian Yang, Yi Liu, Lei Zhang, Licheng Zhang, Hongtao Xie, Zhendong Mao |  |
| 1495 |  |  [Stronger, Lighter, Better: Towards Life-Long Attribute Value Extraction for E-Commerce Products](https://doi.org/10.18653/v1/2024.findings-acl.510) |  | 0 | Attribute value extraction involves identifying the value spans of predetermined attributes in product texts. This area of research has traditionally operated under a closed-world assumption, focusing on products from a static set of categories and their associated attributes. However, products in... | Tao Zhang, Chenwei Zhang, Xian Li, Jingbo Shang, Hoang Nguyen, Philip S. Yu |  |
| 1496 |  |  [Exploring Domain Robust Lightweight Reward Models based on Router Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.511) |  | 0 | Recent advancements in large language models have heavily relied on the large reward model from reinforcement learning from human feedback for fine-tuning. However, the use of a single reward model across various domains may not always be optimal, often requiring retraining from scratch when new... | Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, YoonHyung Roh |  |
| 1497 |  |  [Generalized Category Discovery with Large Language Models in the Loop](https://doi.org/10.18653/v1/2024.findings-acl.512) |  | 0 | Generalized Category Discovery (GCD) is a crucial task that aims to recognize both known and novel categories from a set of unlabeled data by utilizing a few labeled data with only known categories. Due to the lack of supervision and category information, current methods usually perform poorly on... | Wenbin An, Wenkai Shi, Feng Tian, Haonan Lin, Qianying Wang, Yaqiang Wu, Mingxiang Cai, Luyan Wang, Yan Chen, Haiping Zhu, Ping Chen |  |
| 1498 |  |  [VAEGPT-Sim: Improving Sentence Representation with Limited Corpus Using Gradually-Denoising VAE](https://doi.org/10.18653/v1/2024.findings-acl.513) |  | 0 | Text embedding requires a highly efficient method for training domain-specific models on limited data, as general models trained on large corpora lack universal applicability in highly specific fields. Therefore, we have introduced VAEGPT-Sim, an innovative model for generating synonyms that... | Zhenyi Wang, Haiyan Ning, Qing Ling, Dan Wang |  |
| 1499 |  |  [PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion](https://doi.org/10.18653/v1/2024.findings-acl.514) |  | 0 | Recent evaluations of Large Language Models (LLMs) have centered around testing their zero-shot/few-shot capabilities for basic natural language tasks and their ability to translate instructions into tool APIs. However, the evaluation of LLMs utilizing complex tools to finish multi-turn,... | Yiduo Guo, Zekai Zhang, Yaobo Liang, Dongyan Zhao, Nan Duan |  |
| 1500 |  |  [Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.515) |  | 0 | For a LLM to be trustworthy, its confidence level should be well-calibrated with its actual performance. While it is now common sense that LLM performances are greatly impacted by prompts, the confidence calibration in prompting LLMs has yet to be thoroughly explored.In this paper, we explore how... | Xinran Zhao, Hongming Zhang, Xiaoman Pan, Wenlin Yao, Dong Yu, Tongshuang Wu, Jianshu Chen |  |
| 1501 |  |  [DB-LLM: Accurate Dual-Binarization for Efficient LLMs](https://doi.org/10.18653/v1/2024.findings-acl.516) |  | 0 | Large language models (LLMs) have significantly advanced the field of natural language processing, while the expensive memory and computation consumption impede their practical deployment. Quantization emerges as one of the most effective methods for improving the computational efficiency of LLMs.... | Hong Chen, Chengtao Lv, Liang Ding, Haotong Qin, Xiabin Zhou, Yifu Ding, Xuebo Liu, Min Zhang, Jinyang Guo, Xianglong Liu, Dacheng Tao |  |
| 1502 |  |  [TempCompass: Do Video LLMs Really Understand Videos?](https://doi.org/10.18653/v1/2024.findings-acl.517) |  | 0 | Recently, there is a surge in interest surrounding video large language models (Video LLMs). However, existing benchmarks fail to provide a comprehensive feedback on the temporal perception ability of Video LLMs. On the one hand, most of them are unable to distinguish between different temporal... | Yuanxin Liu, Shicheng Li, Yi Liu, Yuxiang Wang, Shuhuai Ren, Lei Li, Sishuo Chen, Xu Sun, Lu Hou |  |
| 1503 |  |  ["Get Their Hands Dirty, Not Mine": On Researcher-Annotator Collaboration and the Agency of Annotators](https://doi.org/10.18653/v1/2024.findings-acl.518) |  | 0 | Annotation quality is often framed as post-hoc cleanup of annotator-caused issues. This position paper discusses whether, how, and why this narrative limits the scope of improving annotation. We call to consider annotation as a procedural collaboration, outlining three points in this direction:(1)... | Shengqi Zhu, Jeffrey M. Rzeszotarski |  |
| 1504 |  |  [Teaching Large Language Models an Unseen Language on the Fly](https://doi.org/10.18653/v1/2024.findings-acl.519) |  | 0 | Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones, for which there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through... | Chen Zhang, Xiao Liu, Jiuheng Lin, Yansong Feng |  |
| 1505 |  |  [Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.520) |  | 0 | Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks, such as machine translation, text summarization. Recent research (Kocmi and Federmann, 2023) has shown that utilizing LLMs for assessing the quality of machine translation (MT)... | Qingyu Lu, Baopu Qiu, Liang Ding, Kanjian Zhang, Tom Kocmi, Dacheng Tao |  |
| 1506 |  |  [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.521) |  | 0 | The Large Vision-Language Models (LVLMs) have demonstrated great abilities in image perception and language understanding. However, existing datasets either focus solely on primary perception abilities and commonsense knowledge, or have a low level of text comprehension difficulty, which are... | Yi Zong, Xipeng Qiu |  |
| 1507 |  |  [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](https://doi.org/10.18653/v1/2024.findings-acl.522) |  | 0 | We present DiffChat, a novel method to align Large Language Models (LLMs) to “chat” with prompt-as-input Text-to-Image Synthesis (TIS)models (e.g., Stable Diffusion) for interactive image creation. Given a raw prompt/image and a user-specified instruction, DiffChat can effectively make appropriate... | Jiapeng Wang, Chengyu Wang, Tingfeng Cao, Jun Huang, Lianwen Jin |  |
| 1508 |  |  [Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration](https://doi.org/10.18653/v1/2024.findings-acl.523) |  | 0 | We identify two crucial limitations in the evaluation of recent parallel-integrated method Parallel Context Windows (PCW), which extends the maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing window-wise attention and positional embedding techniques. We first show that... | Kejuan Yang, Xiao Liu, Kaiwen Men, Aohan Zeng, Yuxiao Dong, Jie Tang |  |
| 1509 |  |  [Rationales for Answers to Simple Math Word Problems Confuse Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.524) |  | 0 | Recently, large language models (LLMs) have demonstrated breakthrough mathematical problem-solving capabilities in grade school math word problems (MWP). For example, on the MWP benchmark GSM8K, the accuracy of GPT-3.5-Turbo and MetaMath-70B reaches 80.80% and 82.30%, respectively. One question... | Yidan Zhang, Mingfeng Xue, Dayiheng Liu, Zhenan He |  |
| 1510 |  |  [ResLoRA: Identity Residual Mapping in Low-Rank Adaption](https://doi.org/10.18653/v1/2024.findings-acl.525) |  | 0 | As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs). However, updating the weights of LoRA blocks effectively and expeditiously is challenging due to the long calculation path in the... | Shuhua Shi, Shaohan Huang, Minghui Song, Zhoujun Li, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 1511 |  |  [Towards Objectively Benchmarking Social Intelligence of Language Agents at the Action Level](https://doi.org/10.18653/v1/2024.findings-acl.526) |  | 0 | Prominent large language models have exhibited human-level performance in many domains, even enabling the derived agents to simulate human and social interactions. While practical works have substantiated the practicability of grounding language agents in sandbox simulation or embodied simulators,... | Chenxu Wang, Bin Dai, Huaping Liu, Baoyuan Wang |  |
| 1512 |  |  [Semantic Role Labeling from Chinese Speech via End-to-End Learning](https://doi.org/10.18653/v1/2024.findings-acl.527) |  | 0 | Semantic Role Labeling (SRL), crucial for understanding semantic relationships in sentences, has traditionally focused on text-based input. However, the increasing use of voice assistants and the need for hands-free interaction have highlighted the importance of SRL from speech.SRL from speech can... | Huiyao Chen, Xinxin Li, Meishan Zhang, Min Zhang |  |
| 1513 |  |  [MEEL: Multi-Modal Event Evolution Learning](https://doi.org/10.18653/v1/2024.findings-acl.528) |  | 0 | Multi-modal Event Reasoning (MMER) endeavors to endow machines with the ability to comprehend intricate event relations across diverse data modalities. MMER is fundamental and underlies a wide broad of applications. Despite extensive instruction fine-tuning, current multi-modal large language... | Zhengwei Tao, Zhi Jin, Junqiang Huang, Xiancai Chen, Xiaoying Bai, Yifan Zhang, Chongyang Tao |  |
| 1514 |  |  [LLM-REDIAL: A Large-Scale Dataset for Conversational Recommender Systems Created from User Behaviors with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.529) |  | 0 | The large-scale conversational recommendation dataset is pivotal for the development of conversational recommender systems (CRS). Most existing CRS datasets suffers from the problems of data inextensibility and semantic inconsistency. To tackle these limitations and establish a benchmark in the... | Tingting Liang, Chenxin Jin, Lingzhi Wang, Wenqi Fan, Congying Xia, Kai Chen, Yuyu Yin |  |
| 1515 |  |  [Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models](https://doi.org/10.18653/v1/2024.findings-acl.530) |  | 0 | LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks introducing LLM biases into consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been... | Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim |  |
| 1516 |  |  [EVIT: Event-Oriented Instruction Tuning for Event Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.531) |  | 0 | Events refer to specific occurrences, incidents, or happenings that take place under a particular background. Event reasoning aims to infer events according to certain relations and predict future events. The cutting-edge techniques for event reasoning play a crucial role in various natural... | Zhengwei Tao, Xiancai Chen, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Yiwei Lou |  |
| 1517 |  |  [InstructCMP: Length Control in Sentence Compression through Instruction-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.532) |  | 0 | Extractive summarization can produce faithful summaries but often requires additional constraints such as a desired summary length. Traditional sentence compression models do not typically consider the constraints because of their restricted model abilities, which require model modifications for... | JuseonDo, Hidetaka Kamigaito, Manabu Okumura, Jingun Kwon |  |
| 1518 |  |  [SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation](https://doi.org/10.18653/v1/2024.findings-acl.533) |  | 0 | Citing pertinent literature is pivotal to writing and reviewing a scientific document. Existing techniques mainly focus on the local context or the global context for recommending citations but fail to consider the actual human citation behaviour. We propose SymTax, a three-stage recommendation... | Karan Goyal, Mayank Goel, Vikram Goyal, Mukesh K. Mohania |  |
| 1519 |  |  [Assessing News Thumbnail Representativeness: Counterfactual text can enhance the cross-modal matching ability](https://doi.org/10.18653/v1/2024.findings-acl.534) |  | 0 | This paper addresses the critical challenge of assessing the representativeness of news thumbnail images, which often serve as the first visual engagement for readers when an article is disseminated on social media. We focus on whether a news image represents the actors discussed in the news text.... | Yejun Yoon, Seunghyun Yoon, Kunwoo Park |  |
| 1520 |  |  [Towards Better Question Generation in QA-based Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.535) |  | 0 | Event Extraction (EE) is an essential information extraction task that aims to extract event-related information from unstructured texts.The paradigm of this task has shifted from conventional classification-based methods to more contemporary question-answering-based (QA-based) approaches. However,... | Zijin Hong, Jian Liu |  |
| 1521 |  |  [Budget-Constrained Tool Learning with Planning](https://doi.org/10.18653/v1/2024.findings-acl.536) |  | 0 | Despite intensive efforts devoted to tool learning, the problem of budget-constrained tool learning, which focuses on resolving user queries within a specific budget constraint, has been widely overlooked. This paper proposes a novel method for budget-constrained tool learning. Our approach... | Yuanhang Zheng, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu |  |
| 1522 |  |  [TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.537) |  | 0 | Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality... | Huayang Li, Siheng Li, Deng Cai, Longyue Wang, Lemao Liu, Taro Watanabe, Yujiu Yang, Shuming Shi |  |
| 1523 |  |  [The Critique of Critique](https://doi.org/10.18653/v1/2024.findings-acl.538) |  | 0 |  | Shichao Sun, Junlong Li, Weizhe Yuan, Ruifeng Yuan, Wenjie Li, Pengfei Liu |  |
| 1524 |  |  [CoCo-Agent: A Comprehensive Cognitive MLLM Agent for Smartphone GUI Automation](https://doi.org/10.18653/v1/2024.findings-acl.539) |  | 0 | Multimodal large language models (MLLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation.However, those GUI agents require comprehensive cognition including exhaustive... | Xinbei Ma, Zhuosheng Zhang, Hai Zhao |  |
| 1525 |  |  [FRVA: Fact-Retrieval and Verification Augmented Entailment Tree Generation for Explainable Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.540) |  | 0 | Structured entailment tree can exhibit the reasoning chains from knowledge facts to predicted answers, which is important for constructing an explainable question answering system. Existing works mainly include directly generating the entire tree and stepwise generating the proof steps. The... | Yue Fan, Hu Zhang, Ru Li, Yujie Wang, Hongye Tan, Jiye Liang |  |
| 1526 |  |  [P4: Plug-and-Play Discrete Prompting for Large Language Models Personalization](https://doi.org/10.18653/v1/2024.findings-acl.541) |  | 0 | Empowering Large Language Models (LLMs) with distinct human-like personality traits has become an innovative task for developing advanced dialog systems.Although LLMs demonstrate impressive capabilities in following instructions, directly prompting them to exhibit certain personalities through... | Yuansen Zhang, Xiao Wang, Tianze Chen, Jiayi Fu, Tao Gui, Qi Zhang |  |
| 1527 |  |  [Large Language Models Can Learn Representation in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.542) |  | 0 | One major challenge for Large Language Models (LLMs) is completing complex tasks involving multiple entities, such as tool APIs. To tackle this, one approach is to retrieve relevant entities to enhance LLMs in task completion. A crucial issue here is obtaining accurate natural language... | Yiduo Guo, Yaobo Liang, Dongyan Zhao, Nan Duan |  |
| 1528 |  |  [CTC-based Non-autoregressive Textless Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.543) |  | 0 | Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences. Recently, some research has turned to non-autoregressive (NAR) models to expedite decoding, yet the... | Qingkai Fang, Zhengrui Ma, Yan Zhou, Min Zhang, Yang Feng |  |
| 1529 |  |  [RRNorm: A Novel Framework for Chinese Disease Diagnoses Normalization via LLM-Driven Terminology Component Recognition and Reconstruction](https://doi.org/10.18653/v1/2024.findings-acl.544) |  | 0 | The Clinical Terminology Normalization aims at finding standard terms from a given termbase for mentions extracted from clinical texts. However, we found that extracted mentions suffer from the multi-implication problem, especially disease diagnoses. The reason for this is that physicians often use... | Yongqi Fan, Yansha Zhu, Kui Xue, Jingping Liu, Tong Ruan |  |
| 1530 |  |  [Unexpected Phenomenon: LLMs' Spurious Associations in Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.545) |  | 0 | Information extraction plays a critical role in natural language processing. When applying large language models (LLMs) to this domain, we discover an unexpected phenomenon: LLMs’ spurious associations. In tasks such as relation extraction, LLMs can accurately identify entity pairs, even if the... | Weiyan Zhang, Wanpeng Lu, Jiacheng Wang, Yating Wang, Lihan Chen, Haiyun Jiang, Jingping Liu, Tong Ruan |  |
| 1531 |  |  [AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought](https://doi.org/10.18653/v1/2024.findings-acl.546) |  | 0 | Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention.Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning knowledge from different languages. Despite achieving... | Yongheng Zhang, Qiguang Chen, Min Li, Wanxiang Che, Libo Qin |  |
| 1532 |  |  [LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.547) |  | 0 | Multilingual neural machine translation models generally distinguish translation directions by the language tag (LT) in front of the source or target sentences. However, current LT strategies cannot indicate the desired target language as expected on zero-shot translation, i.e., the off-target... | Zengkui Sun, Yijin Liu, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 1533 |  |  [Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data](https://doi.org/10.18653/v1/2024.findings-acl.548) |  | 0 | Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models’ capability in statistical and causal reasoning with... | Xiao Liu, Zirui Wu, Xueqing Wu, Pan Lu, KaiWei Chang, Yansong Feng |  |
| 1534 |  |  [On the Vulnerability of Safety Alignment in Open-Access LLMs](https://doi.org/10.18653/v1/2024.findings-acl.549) |  | 0 | Large language models (LLMs) possess immense capabilities but are susceptible to malicious exploitation. To mitigate the risk, safety alignment is employed to align LLMs with ethical standards. However, safety-aligned LLMs may remain vulnerable to carefully crafted jailbreak attacks, but these... | Jingwei Yi, Rui Ye, Qisi Chen, Bin Zhu, Siheng Chen, Defu Lian, Guangzhong Sun, Xing Xie, Fangzhao Wu |  |
| 1535 |  |  [PEK: A Parameter-Efficient Framework for Knowledge-Grounded Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.550) |  | 0 | Pre-trained language models (PLMs) have shown great dialogue generation capability in different scenarios. However, the huge VRAM consumption when fine-tuning them is one of their drawbacks. PEFT approaches can significantly reduce the number of trainable parameters, which enables us to fine-tune... | Pan Yang, Dandan Song, Zhijing Wu, Yanru Zhou |  |
| 1536 |  |  [Evidence Retrieval is almost All You Need for Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.551) |  | 0 | Current fact verification methods generally follow the two-stage training paradigm: evidence retrieval and claim verification. While existing works focus on developing sophisticated claim verification modules, the fundamental importance of evidence retrieval is largely ignored. Existing approaches... | Liwen Zheng, Chaozhuo Li, Xi Zhang, Yuming Shang, Feiran Huang, Haoran Jia |  |
| 1537 |  |  [Outdated Issue Aware Decoding for Factual Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.552) |  | 0 | Recently, Knowledge Editing has received increasing attention, since it could update the specific knowledge from outdated ones in pretrained models without re-training. However, as pointed out by recent studies, existing related methods tend to merely memorize the superficial word composition of... | Zengkui Sun, Yijin Liu, Jiaan Wang, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 1538 |  |  [Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness](https://doi.org/10.18653/v1/2024.findings-acl.553) |  | 0 | Dialects introduce syntactic and lexical variations in language that occur in regional or social groups. Most NLP methods are not sensitive to such variations. This may lead to unfair behavior of the methods, conveying negative bias towards dialect speakers. While previous work has studied... | Maximilian Spliethöver, Sai Nikhil Menon, Henning Wachsmuth |  |
| 1539 |  |  [DP-MLM: Differentially Private Text Rewriting Using Masked Language Models](https://doi.org/10.18653/v1/2024.findings-acl.554) |  | 0 |  | Stephen Meisenbacher, Maulik Chevli, Juraj Vladika, Florian Matthes |  |
| 1540 |  |  [Question-Instructed Visual Descriptions for Zero-Shot Video Answering](https://doi.org/10.18653/v1/2024.findings-acl.555) |  | 0 | We present Q-ViD, a simple approach for video question answering (video QA), that unlike prior methods, which are based on complex architectures, computationally expensive pipelines or use closed models like GPTs, Q-ViD relies on a single instruction-aware open vision-language model (InstructBLIP)... | David Mogrovejo, Thamar Solorio |  |
| 1541 |  |  [EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.556) |  | 0 | Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in accuracy improvement, let alone explainability, a critical capability of fact verification systems.Constructing an explainable fact verification system in... | Huanhuan Ma, Weizhi Xu, Yifan Wei, Liuji Chen, Liang Wang, Qiang Liu, Shu Wu |  |
| 1542 |  |  [Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.557) |  | 0 | Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial and urgent problem.This paper first delivers three key... | Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Jiangning Liu, Dahua Lin, Kai Chen, Feng Zhao |  |
| 1543 |  |  [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](https://doi.org/10.18653/v1/2024.findings-acl.558) |  | 0 | Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factually correct, making it... | Ekaterina Fadeeva, Aleksandr Rubashevskii, Artem Shelmanov, Sergey Petrakov, Haonan Li, Hamdy Mubarak, Evgenii Tsymbalov, Gleb Kuzmin, Alexander Panchenko, Timothy Baldwin, Preslav Nakov, Maxim Panov |  |
| 1544 |  |  [Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.559) |  | 0 | Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the... | Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Zhouhao Sun, Shi Jun, Ting Liu, Bing Qin |  |
| 1545 |  |  [Critical Learning Periods: Leveraging Early Training Dynamics for Efficient Data Pruning](https://doi.org/10.18653/v1/2024.findings-acl.560) |  | 0 | Neural Machine Translation models are extremely data and compute-hungry. However, not all datapoints contribute equally to model training and generalization. Data pruning to remove the low-value data points has the benefit of drastically reducing the compute budget without significantdrop in model... | Everlyn Chimoto, Jay Gala, Orevaoghene Ahia, Julia Kreutzer, Bruce A. Bassett, Sara Hooker |  |
| 1546 |  |  [What Are You Token About? Differentiable Perturbed Top-k Token Selection for Scientific Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.561) |  | 0 | Scientific document summarization aims to condense complex and long articles in both technical and plain-language terms to facilitate the accessibility and dissemination of scientific findings. Existing datasets suffer from a deficiency in source heterogeneity, as their data predominantly stem from... | Luca Ragazzi, Paolo Italiani, Gianluca Moro, Mattia Panni |  |
| 1547 |  |  [Description Boosting for Zero-Shot Entity and Relation Classification](https://doi.org/10.18653/v1/2024.findings-acl.562) |  | 0 | Zero-shot entity and relation classification models leverage available external information of unseen classes – e.g., textual descriptions – to annotate input text data. Thanks to the minimum data requirement, Zero-Shot Learning (ZSL) methods have high value in practice, especially in applications... | Gabriele Picco, Leopold Fuchs, Marcos Martínez Galindo, Alberto Purpura, Vanessa López, Hoang Thanh Lam |  |
| 1548 |  |  [Domain-Aware k-Nearest-Neighbor Knowledge Distillation for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.563) |  | 0 | kNN-MT has utilized neighborhood knowledge for auxiliary decoding, significantly improving translation performance. Subsequently, kNN-KD transitions the use of neighborhood knowledge from the decoding phase to the training phase, to address the temporal and spatial inefficiencies inherent in... | Zhexuan Wang, Shudong Liu, Xuebo Liu, Miao Zhang, Derek F. Wong, Min Zhang |  |
| 1549 |  |  [Beyond Single-Event Extraction: Towards Efficient Document-Level Multi-Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.564) |  | 0 | Recent mainstream event argument extraction methods process each event in isolation, resulting in inefficient inference and ignoring the correlations among multiple events. To address these limitations, here we propose a multiple-event argument extraction model DEEIA (Dependency-guided Encoding and... | Wanlong Liu, Li Zhou, Dingyi Zeng, Yichen Xiao, Shaohuan Cheng, Chen Zhang, Grandee Lee, Malu Zhang, Wenyu Chen |  |
| 1550 |  |  [Revisiting Interpolation Augmentation for Speech-to-Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.565) |  | 0 | Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization... | Chen Xu, Jie Wang, Xiaoqian Liu, Qian Dong, Chunliang Zhang, Tong Xiao, JingBo Zhu, Dapeng Man, Wu Yang |  |
| 1551 |  |  [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://doi.org/10.18653/v1/2024.findings-acl.566) |  | 0 | Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do... | Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Lijia Sun, Xibin Gao, Yi Zhang |  |
| 1552 |  |  [Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning](https://doi.org/10.18653/v1/2024.findings-acl.567) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of Large Language Models (LLMs) to various downstream applications. However, the effectiveness of the PEFT diminishes notably when downstream tasks require accurate learning of specific knowledge. In this paper, we adopt a... | Renzhi Wang, Piji Li |  |
| 1553 |  |  [Leveraging Collection-Wide Similarities for Unsupervised Document Structure Extraction](https://doi.org/10.18653/v1/2024.findings-acl.568) |  | 0 | Document collections of various domains, e.g., legal, medical, or financial, often share some underlying collection-wide structure, which captures information that can aid both human users and structure-aware models.We propose to identify the typical structure of document within a collection, which... | Gili Lior, Yoav Goldberg, Gabriel Stanovsky |  |
| 1554 |  |  [Enhancing Cross Text-Molecule Learning by Self-Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.569) |  | 0 | The development of Large Language Models (LLMs) has greatly advanced the field of drug discovery, with the belief that natural language can enhance human control over molecule design. However, the scarcity of high-quality labeled data remains a challenge for cross text-molecule learning. Existing... | Yinuo Jiang, Xiang Zhuang, Keyan Ding, Qiang Zhang, Huajun Chen |  |
| 1555 |  |  [RePALM: Popular Quote Tweet Generation via Auto-Response Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.570) |  | 0 | A quote tweet enables users to share others’ content while adding their own commentary. In order to enhance public engagement through quote tweets, we investigate the task of generating popular quote tweets. This task aims to produce quote tweets that garner higher popularity, as indicated by... | Erxin Yu, Jing Li, Chunpu Xu |  |
| 1556 |  |  [On the Effect of (Near) Duplicate Subwords in Language Modelling](https://doi.org/10.18653/v1/2024.findings-acl.571) |  | 0 | Tokenisation is a core part of language models (LMs). It involves splitting a character sequence into subwords which are assigned random indices before being served to the LM. However, this process—while typically lossless—may lead to less efficient LM training, because it removes character-level... | Anton Schäfer, Thomas Hofmann, Imanol Schlag, Tiago Pimentel |  |
| 1557 |  |  [Do Pre-Trained Language Models Detect and Understand Semantic Underspecification? Ask the DUST!](https://doi.org/10.18653/v1/2024.findings-acl.572) |  | 0 | In everyday language use, speakers frequently utter and interpret sentences that are semantically underspecified, namely, whose content is insufficient to fully convey their message or interpret them univocally. For example, to interpret the underspecified sentence “Don’t spend too much”, which... | Frank Wildenburg, Michael Hanna, Sandro Pezzelle |  |
| 1558 |  |  [Visual Hallucinations of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.573) |  | 0 | Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines incorrect details about an image in visual question answering. Existing studies find VH instances only in existing image datasets, which results in biased understanding of MLLMs’ performance under VH due to limited diversity of... | Wen Huang, Hongbin Liu, Minxin Guo, Neil Gong |  |
| 1559 |  |  [SumSurvey: An Abstractive Dataset of Scientific Survey Papers for Long Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.574) |  | 0 | With the popularity of large language models (LLMs) and their ability to handle longer input documents, there is a growing need for high-quality long document summarization datasets. Although many models already support 16k input, current lengths of summarization datasets are inadequate, and... | Ran Liu, Ming Liu, Min Yu, He Zhang, Jianguo Jiang, Gang Li, Weiqing Huang |  |
| 1560 |  |  [Pushing the Limits of Low-Resource NER Using LLM Artificial Data Generation](https://doi.org/10.18653/v1/2024.findings-acl.575) |  | 0 | Named Entity Recognition (NER) is an important task, but to achieve great performance, it is usually necessary to collect a large amount of labeled data, incurring high costs. In this paper, we propose using open-source Large Language Models (LLM) to generate NER data with only a few labeled... | Joan Santoso, Patrick Sutanto, Billy Cahyadi, Esther Irawati Setiawan |  |
| 1561 |  |  [Understanding and Patching Compositional Reasoning in LLMs](https://doi.org/10.18653/v1/2024.findings-acl.576) |  | 0 | LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. Our research embarks on a quest to uncover the root causes of compositional reasoning failures of LLMs, uncovering that most of them stem from the improperly generated or leveraged implicit... | Zhaoyi Li, Gangwei Jiang, Hong Xie, Linqi Song, Defu Lian, Ying Wei |  |
| 1562 |  |  [Bilingual Rhetorical Structure Parsing with Large Parallel Annotations](https://doi.org/10.18653/v1/2024.findings-acl.577) |  | 0 | Discourse parsing is a crucial task in natural language processing that aims to reveal the higher-level relations in a text. Despite growing interest in cross-lingual discourse parsing, challenges persist due to limited parallel data and inconsistencies in the Rhetorical Structure Theory (RST)... | Elena Chistova |  |
| 1563 |  |  [Book2Dial: Generating Teacher Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](https://doi.org/10.18653/v1/2024.findings-acl.578) |  | 0 | Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student... | Junling Wang, Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Mrinmaya Sachan |  |
| 1564 |  |  [SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.579) |  | 0 |  | Wenxin Liang, Tingyu Zhang, Han Liu, Feng Zhang |  |
| 1565 |  |  [Automated Focused Feedback Generation for Scientific Writing Assistance](https://doi.org/10.18653/v1/2024.findings-acl.580) |  | 0 | Scientific writing is a challenging task, particularly for novice researchers who often rely on feedback from experienced peers. Recent work has primarily focused on improving surface form and style rather than manuscript content. In this paper, we propose a novel task: automated focused feedback... | Eric Chamoun, Michael Sejr Schlichtkrull, Andreas Vlachos |  |
| 1566 |  |  [FastGAS: Fast Graph-based Annotation Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.581) |  | 0 | In-context learning (ICL) empowers large language models (LLMs) to tackle new tasks by using a series of training instances as prompts. Since generating the prompts needs to sample from a vast pool of instances and annotate them (e.g., add labels in classification task), existing methods have... | Zihan Chen, Song Wang, Cong Shen, Jundong Li |  |
| 1567 |  |  [Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations](https://doi.org/10.18653/v1/2024.findings-acl.582) |  | 0 | Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly compatible with further tuning and compression. However, as the... | Bowen Shen, Zheng Lin, Daren Zha, Wei Liu, Jian Luan, Bin Wang, Weiping Wang |  |
| 1568 |  |  [Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.583) |  | 0 | Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual... | Langlin Huang, Yang Feng |  |
| 1569 |  |  [Deductive Closure Training of Language Models for Coherence, Accuracy, and Updatability](https://doi.org/10.18653/v1/2024.findings-acl.584) |  | 0 | While language models (LMs) can sometimes generate factually correct text and estimate truth values of individual claims, these generally do not reflect a globally coherent, manipulable model of the world. As a consequence, current LMs also generate incorrect or nonsensical content, and are... | Afra Feyza Akyürek, Ekin Akyürek, Leshem Choshen, Derry Wijaya, Jacob Andreas |  |
| 1570 |  |  [Self-Supervised Singing Voice Pre-Training towards Speech-to-Singing Conversion](https://doi.org/10.18653/v1/2024.findings-acl.585) |  | 0 | Speech-to-singing voice conversion (STS) task always suffers from data scarcity, because it requires paired speech and singing data. Compounding this issue are the challenges of content-pitch alignment and the suboptimal quality of generated outputs, presenting significant hurdles in STS research.... | Ruiqi Li, Rongjie Huang, Yongqi Wang, Zhiqing Hong, Zhou Zhao |  |
| 1571 |  |  [Evaluating Large Language Model Biases in Persona-Steered Generation](https://doi.org/10.18653/v1/2024.findings-acl.586) |  | 0 | The task of persona-steered text generation requires large language models (LLMs) to generate text that reflects the distribution of views that an individual fitting a persona could have. People have multifaceted personas, but prior work on bias in LLM-generated opinions has only explored... | Andy Liu, Mona T. Diab, Daniel Fried |  |
| 1572 |  |  [Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization](https://doi.org/10.18653/v1/2024.findings-acl.587) |  | 0 | The rapid increase in multimedia data has spurred advancements in Multimodal Summarization with Multimodal Output (MSMO), which aims to produce a multimodal summary that integrates both text and relevant images. The inherent heterogeneity of content within multimodal inputs and outputs presents a... | Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen |  |
| 1573 |  |  [CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.588) |  | 0 | It is imperative to ensure the stability of every prediction made by a language model; that is, a language’s prediction should remain consistent despite minor input variations, like word substitutions. In this paper, we investigate the problem of certifying a language model’s robustness against... | Qian Lou, Xin Liang, Jiaqi Xue, Yancheng Zhang, Rui Xie, Mengxin Zheng |  |
| 1574 |  |  [Recovering document annotations for sentence-level bitext](https://doi.org/10.18653/v1/2024.findings-acl.589) |  | 0 | In machine translation, historical models were incapable of handling longer contexts, so the lack of document-level datasets was less noticeable. Now, despite the emergence of long-sequence methods, we remain within a sentence-level paradigm and without data to adequately approach context-aware... | Rachel Wicks, Matt Post, Philipp Koehn |  |
| 1575 |  |  [MetaPro 2.0: Computational Metaphor Processing on the Effectiveness of Anomalous Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.590) |  | 0 | Metaphor interpretation is a difficult task in natural language understanding. The development of relevant techniques in this domain is slow, mostly because of the lack of large annotated datasets and effective pre-trained language models (PLMs) for metaphor learning. Thus, we propose a large... | Rui Mao, Kai He, Claudia Ong, Qian Liu, Erik Cambria |  |
| 1576 |  |  [Boosting LLM Agents with Recursive Contemplation for Effective Deception Handling](https://doi.org/10.18653/v1/2024.findings-acl.591) |  | 0 | Recent advances in large language models (LLMs) have led to significant success in using LLMs as agents. Nevertheless, a common assumption that LLMs always process honest information neglects the widespread deceptive or misleading content in human and AI-generated material. This oversight might... | Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, Gao Huang |  |
| 1577 |  |  [Direct Preference Optimization with an Offset](https://doi.org/10.18653/v1/2024.findings-acl.592) |  | 0 | Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language... | Afra Amini, Tim Vieira, Ryan Cotterell |  |
| 1578 |  |  [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation](https://doi.org/10.18653/v1/2024.findings-acl.593) |  | 0 | Direct speech-to-speech translation achieves high-quality results through the introduction of discrete units obtained from self-supervised learning. However, talking head translation, converting audio-visual speech (i.e., talking head video) from one language into another, still confronts several... | Xize Cheng, Rongjie Huang, Linjun Li, Zehan Wang, Tao Jin, Aoxiong Yin, Feiyang Chen, Xinyu Duan, Baoxing Huai, Zhou Zhao |  |
| 1579 |  |  [More than Minorities and Majorities: Understanding Multilateral Bias in Language Generation](https://doi.org/10.18653/v1/2024.findings-acl.594) |  | 0 | Pretrained models learned from real corpora can often capture undesirable features, leading to bias issues against different demographic groups. Most existing studies on bias dataset construction or bias mitigation methods only focus on one demographic group pair to study a certain bias, e.g. black... | Jiaxu Zhao, Zijing Shi, Yitong Li, Yulong Pei, Ling Chen, Meng Fang, Mykola Pechenizkiy |  |
| 1580 |  |  [Fair Federated Learning with Biased Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.595) |  | 0 | Existing literature that integrates CLIP into federated learning (FL) largely ignores the inherent group unfairness within CLIP and its ethical implications on FL applications. Furthermore, such CLIP bias may be amplified in FL, due to the unique issue of data heterogeneity across clients. However,... | Huimin Zeng, Zhenrui Yue, Yang Zhang, Lanyu Shang, Dong Wang |  |
| 1581 |  |  [SpeechGuard: Exploring the Adversarial Robustness of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.596) |  | 0 | Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this work, we investigate the potential vulnerabilities of such... | Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel GarciaRomero, Sundararajan Srinivasan, Kyu J. Han, Katrin Kirchhoff |  |
| 1582 |  |  [ACUEval: Fine-grained Hallucination Evaluation and Correction for Abstractive Summarization](https://doi.org/10.18653/v1/2024.findings-acl.597) |  | 0 | The impressive generation capabilities of large language models (LLMs) have made it harder to detect the subtle hallucinations they make in abstractive summarization, where generated summaries consist of a blend of correct and incorrect information w.r.t. a given document. Recently-proposed... | David Wan, Koustuv Sinha, Srini Iyer, Asli Celikyilmaz, Mohit Bansal, Ramakanth Pasunuru |  |
| 1583 |  |  [An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.598) |  | 0 | Multimodal Large Language Models (MLLMs) fine-tuned with multimodal instruction-following data have demonstrated formidable capabilities in multimodal tasks. However, fine-tuning all parameters of MLLMs has become challenging due to the rapid growth of the overall model’s parameters. To address... | Xiongtao Zhou, Jie He, Yuhua Ke, Guangyao Zhu, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 1584 |  |  [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](https://doi.org/10.18653/v1/2024.findings-acl.599) |  | 0 | Recently, there has been growing interest within the community regarding whether large language models are capable of planning or executing plans. However, most prior studies use LLMs to generate high-level plans for simplified scenarios lacking linguistic complexity and domain diversity, limiting... | Arda Uzunoglu, Gözde Gül Sahin, Abdulfattah Safa |  |
| 1585 |  |  [TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation](https://doi.org/10.18653/v1/2024.findings-acl.600) |  | 0 | The recent advances in natural language processing have predominantly favored well-resourced English-centric models, resulting in a significant gap with low-resource languages. In this work, we introduce TURNA, a language model developed for the low-resource language Turkish and is capable of both... | Gökçe Uludogan, Zeynep Yirmibesoglu Balal, Salih Furkan Akkurt, Meliksah Türker, Onur Güngör, Susan Üsküdarli |  |
| 1586 |  |  [MELD-ST: An Emotion-aware Speech Translation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.601) |  | 0 | Emotion plays a crucial role in human conversation. This paper underscores the significance of considering emotion in speech translation. We present the MELD-ST dataset for the emotion-aware speech translation task, comprising English-to-Japanese and English-to-German language pairs. Each language... | Sirou Chen, Sakiko Yahata, Shuichiro Shimizu, Zhengdong Yang, Yihang Li, Chenhui Chu, Sadao Kurohashi |  |
| 1587 |  |  [Designing Informative Metrics for Few-Shot Example Selection](https://doi.org/10.18653/v1/2024.findings-acl.602) |  | 0 | Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the “best” examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach... | Rishabh Adiga, Lakshmi Subramanian, Varun Chandrasekaran |  |
| 1588 |  |  [Chain-of-Quizzes: Pedagogy-inspired Example Selection in In-Context-Learning](https://doi.org/10.18653/v1/2024.findings-acl.603) |  | 0 | In-context learning (ICL) has emerged as a powerful tool for enhancing large language models (LLMs) in addressing downstream tasks. In this paper, we explore the vital task of example selection in ICL by mimicking the human learning process. We propose a Chain-of-Quizzes (CoQ) framework inspired by... | Yiquan Wu, Anlai Zhou, Yuhang Liu, Yifei Liu, Adam Jatowt, Weiming Lu, Jun Xiao, Kun Kuang |  |
| 1589 |  |  [It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.604) |  | 0 | Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This process of elimination (PoE), when used with COT, can enhance self-consistency, interpretability, and tasks such as... | Nishant Balepur, Shramay Palta, Rachel Rudinger |  |
| 1590 |  |  [From Discrimination to Generation: Low-Resource Intent Detection with Language Model Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.605) |  | 0 | Intent detection aims to identify user goals from utterances, and is a ubiquitous step towards the satisfaction of user desired needs in many interaction systems. As dynamic and varied intents arise, models that are capable of identifying new intents promptly are required. However, existing studies... | Feng Zhang, Wei Chen, Fei Ding, Meng Gao, Tengjiao Wang, Jiahui Yao, Jiabin Zheng |  |
| 1591 |  |  [Efficient Continual Pre-training for Building Domain Specific Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.606) |  | 0 | Large language models (LLMs) have demonstrated remarkable open-domain capabilities. LLMs tailored for a domain are typically trained entirely on domain corpus to excel at handling domain-specific tasks. In this work, we explore an alternative strategy of continual pre-training as a means to develop... | Yong Xie, Karan Aggarwal, Aitzaz Ahmad |  |
| 1592 |  |  [Distantly-Supervised Joint Extraction with Noise-Robust Learning](https://doi.org/10.18653/v1/2024.findings-acl.607) |  | 0 | Joint entity and relation extraction is a process that identifies entity pairs and their relations using a single model. We focus on the problem of joint extraction in distantly-labeled data, whose labels are generated by aligning entity mentions with the corresponding entity and relation tags... | Yufei Li, Xiao Yu, Yanghong Guo, Yanchi Liu, Haifeng Chen, Cong Liu |  |
| 1593 |  |  [LLM Factoscope: Uncovering LLMs' Factual Discernment through Measuring Inner States](https://doi.org/10.18653/v1/2024.findings-acl.608) |  | 0 | Large Language Models (LLMs) have revolutionized various domains with extensive knowledge and creative capabilities. However, a critical issue with LLMs is their tendency to produce outputs that diverge from factual reality. This phenomenon is particularly concerning in sensitive applications such... | Jinwen He, Yujia Gong, Zijin Lin, Cheng'an Wei, Yue Zhao, Kai Chen |  |
| 1594 |  |  [DictLLM: Harnessing Key-Value Data Structures with Large Language Models for Enhanced Medical Diagnostics](https://doi.org/10.18653/v1/2024.findings-acl.609) |  | 0 | Structured data offers an efficient means of organizing information. Exsisting text-serialization based methods for processing structured data using large language models (LLMs) are not designed to explicitly capture the heterogeneity of structured data. Such methods are suboptimal for LLMs to... | YiQiu Guo, Yuchen Yang, Ya Zhang, Yu Wang, Yanfeng Wang |  |
| 1595 |  |  [imapScore: Medical Fact Evaluation Made Easy](https://doi.org/10.18653/v1/2024.findings-acl.610) |  | 0 | Automatic evaluation of natural language generation (NLG) tasks has gained extensive research interests, since it can rapidly assess the performance of large language models (LLMs). However, automatic NLG evaluation struggles with medical QA because it fails to focus on the crucial correctness of... | Huimin Wang, Yutian Zhao, Xian Wu, Yefeng Zheng |  |
| 1596 |  |  [Making Harmful Behaviors Unlearnable for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.611) |  | 0 | Large language models (LLMs) have shown great potential to empower various domains and are often customized by fine-tuning for the requirements of different applications. However, the powerful learning ability of LLMs not only enables them to learn new tasks but also makes them vulnerable to... | Xin Zhou, Yi Lu, Ruotian Ma, Yujian Wei, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1597 |  |  [Debiasing Large Language Models with Structured Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.612) |  | 0 | Due to biases inherently present in data for pre-training, current pre-trained Large Language Models (LLMs) also ubiquitously manifest the same phenomena. Since the bias influences the output from the LLMs across various tasks, the widespread deployment of the LLMs is hampered. We propose a simple... | Congda Ma, Tianyu Zhao, Manabu Okumura |  |
| 1598 |  |  [Contrastive Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.613) |  | 0 | Instruction tuning has been used as a promising approach to improve the performance of large language models (LLMs) on unseen tasks. However, current LLMs exhibit limited robustness to unseen instructions, generating inconsistent outputs when the same instruction is phrased with slightly varied... | Tianyi Yan, Fei Wang, James Y. Huang, Wenxuan Zhou, Fan Yin, Aram Galstyan, Wenpeng Yin, Muhao Chen |  |
| 1599 |  |  [Bootstrapped Pre-training with Dynamic Identifier Prediction for Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.614) |  | 0 | Generative retrieval uses differentiable search indexes to directly generate relevant document identifiers in response to a query. Recent studies have highlighted the potential of a strong generative retrieval model, trained with carefully crafted pre-training tasks, to enhance downstream retrieval... | Yubao Tang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng |  |
| 1600 |  |  [Refining and Synthesis: A Simple yet Effective Data Augmentation Framework for Cross-Domain Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.615) |  | 0 | Aspect-based Sentiment Analysis (ABSA) is extensively researched in the NLP community, yet related models face challenges due to data sparsity when shifting to a new domain. Hence, data augmentation for cross-domain ABSA has attracted increasing attention in recent years. However, two key points... | Haining Wang, Kang He, Bobo Li, Lei Chen, Fei Li, Xu Han, Chong Teng, Donghong Ji |  |
| 1601 |  |  [Codec-SUPERB: An In-Depth Analysis of Sound Codec Models](https://doi.org/10.18653/v1/2024.findings-acl.616) |  | 0 | The sound codec’s dual roles in minimizing data transmission latency and serving as tokenizers underscore its critical importance.Recent years have witnessed significant developments in codec models.The ideal sound codec should preserve content, paralinguistics, speakers, and audio... | Haibin Wu, HoLam Chung, YiCheng Lin, YuanKuei Wu, Xuanjun Chen, YuChi Pai, HsiuHsuan Wang, KaiWei Chang, Alexander H. Liu, Hungyi Lee |  |
| 1602 |  |  [CACL: Community-Aware Heterogeneous Graph Contrastive Learning for Social Media Bot Detection](https://doi.org/10.18653/v1/2024.findings-acl.617) |  | 0 | Social media bot detection is increasingly crucial with the rise of social media platforms. Existing methods predominantly construct social networks as graph and utilize graph neural networks (GNNs) for bot detection. However, most of these methods focus on how to improve the performance of GNNs... | Sirry Chen, Shuo Feng, Songsong Liang, ChenChen Zong, Jing Li, Piji Li |  |
| 1603 |  |  [Are Machines Better at Complex Reasoning? Unveiling Human-Machine Inference Gaps in Entailment Verification](https://doi.org/10.18653/v1/2024.findings-acl.618) |  | 0 | Making inferences in text comprehension to understand the meaning is essential in language processing. This work studies the entailment verification (EV) problem of complex, multi-sentence premises requiring a system to make multiple inferences implicitly. Modern applications of EV in detecting... | Soumya Sanyal, Tianyi Xiao, Jiacheng Liu, Wenya Wang, Xiang Ren |  |
| 1604 |  |  [ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.619) |  | 0 | Charts provide visual representations of data and are widely used for analyzing information, addressing queries, and conveying insights to others. Various chart-related downstream tasks have emerged recently, such as question-answering and summarization. A common strategy to solve these tasks is to... | Ahmed Masry, Mehrad Shahmohammadi, Md. Rizwan Parvez, Enamul Hoque, Shafiq Joty |  |
| 1605 |  |  [Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.620) |  | 0 | The many-to-many multilingual neural machine translation can be regarded as the process of integrating semantic features from the source sentences and linguistic features from the target sentences. To enhance zero-shot translation, models need to share knowledge across languages, which can be... | Mengyu Bu, Shuhao Gu, Yang Feng |  |
| 1606 |  |  [Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with Architecture-Routed Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.621) |  | 0 | Weight-sharing supernets are crucial for performance estimation in cutting-edge neural architecture search (NAS) frameworks. Despite their ability to generate diverse subnetworks without retraining, the quality of these subnetworks is not guaranteed due to weight sharing. In NLP tasks like machine... | Ganesh Jawahar, Haichuan Yang, Yunyang Xiong, Zechun Liu, Dilin Wang, Fei Sun, Meng Li, Aasish Pappu, Barlas Oguz, Muhammad AbdulMageed, Laks V. S. Lakshmanan, Raghuraman Krishnamoorthi, Vikas Chandra |  |
| 1607 |  |  [SharedCon: Implicit Hate Speech Detection using Shared Semantics](https://doi.org/10.18653/v1/2024.findings-acl.622) |  | 0 | The ever-growing presence of hate speech on social network services and other online platforms not only fuels online harassment but also presents a growing challenge for hate speech detection. As this task is akin to binary classification, one of the promising approaches for hate speech detection... | Hyeseon Ahn, Youngwook Kim, Jungin Kim, YoSub Han |  |
| 1608 |  |  [Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models](https://doi.org/10.18653/v1/2024.findings-acl.623) |  | 0 | Instruction-tuning language models has become a crucial step in aligning them for general use. Typically, this process involves extensive training on large datasets, incurring high training costs. In this paper, we introduce a novel training data selection based on the learning percentage of the... | Dheeraj Mekala, Alex Nguyen, Jingbo Shang |  |
| 1609 |  |  [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.624) |  | 0 | Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the... | Qiusi Zhan, Zhixiang Liang, Zifan Ying, Daniel Kang |  |
| 1610 |  |  [Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.625) |  | 0 | Code Pre-trained Models (CodePTMs) based vulnerability detection have achieved promising results over recent years. However, these models struggle to generalize as they typically learn superficial mapping from source code to labels instead of understanding the root causes of code vulnerabilities,... | Xiaohu Du, Ming Wen, Jiahao Zhu, Zifan Xie, Bin Ji, Huijun Liu, Xuanhua Shi, Hai Jin |  |
| 1611 |  |  [PPTSER: A Plug-and-Play Tag-guided Method for Few-shot Semantic Entity Recognition on Visually-rich Documents](https://doi.org/10.18653/v1/2024.findings-acl.626) |  | 0 | Visually-rich document information extraction (VIE) is a vital aspect of document understanding, wherein Semantic Entity Recognition (SER) plays a significant role. However, few-shot SER on visually-rich documents remains relatively unexplored despite its considerable potential for practical... | Wenhui Liao, Jiapeng Wang, Zening Lin, Longfei Xiong, Lianwen Jin |  |
| 1612 |  |  [LLM Performance Predictors are good initializers for Architecture Search](https://doi.org/10.18653/v1/2024.findings-acl.627) |  | 0 | In this work, we utilize Large Language Models (LLMs) for a novel use case: constructing Performance Predictors (PP) that estimate the performance of specific deep neural network architectures on downstream tasks. We create PP prompts for LLMs, comprising (i) role descriptions, (ii) instructions... | Ganesh Jawahar, Muhammad AbdulMageed, Laks V. S. Lakshmanan, Dujian Ding |  |
| 1613 |  |  [MODDP: A Multi-modal Open-domain Chinese Dataset for Dialogue Discourse Parsing](https://doi.org/10.18653/v1/2024.findings-acl.628) |  | 0 | Dialogue discourse parsing (DDP) aims to capture the relations between utterances in the dialogue. In everyday real-world scenarios, dialogues are typically multi-modal and cover open-domain topics. However, most existing widely used benchmark datasets for DDP contain only textual modality and are... | Chen Gong, Dexin Kong, Suxian Zhao, Xingyu Li, Guohong Fu |  |
| 1614 |  |  [Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.629) |  | 0 | In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis... | Wei Zhai, Hongzhi Qi, Qing Zhao, Jianqiang Li, Ziqi Wang, Han Wang, Bing Yang, Guanghui Fu |  |
| 1615 |  |  [Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.630) |  | 0 | A single language model, even when aligned with labelers through reinforcement learning from human feedback (RLHF), may not suit all human preferences. Recent approaches therefore prefer customization, gathering multi-dimensional feedback, and creating distinct reward models for each... | Zhanhui Zhou, Jie Liu, Jing Shao, Xiangyu Yue, Chao Yang, Wanli Ouyang, Yu Qiao |  |
| 1616 |  |  [DORY: Deliberative Prompt Recovery for LLM](https://doi.org/10.18653/v1/2024.findings-acl.631) |  | 0 | Prompt recovery in large language models (LLMs) is crucial for understanding how LLMs work and addressing concerns regarding privacy, copyright, etc. The trend towards inference-only APIs complicates this task by restricting access to essential outputs for recovery. To tackle this challenge, we... | Lirong Gao, Ru Peng, Yiming Zhang, Junbo Zhao |  |
| 1617 |  |  [STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.632) |  | 0 | Equipping a conversational search engine with strategies regarding when to ask clarification questions is becoming increasingly important across various domains. Attributing to the context understanding capability of LLMs and their access to domain-specific sources of knowledge, LLM-based... | Yue Chen, Chen Huang, Yang Deng, Wenqiang Lei, Dingnan Jin, Jia Liu, TatSeng Chua |  |
| 1618 |  |  [Evaluating Robustness of Generative Search Engine on Adversarial Factoid Questions](https://doi.org/10.18653/v1/2024.findings-acl.633) |  | 0 | Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns,... | Xuming Hu, Xiaochuan Li, Junzhe Chen, Yinghui Li, Yangning Li, Xiaoguang Li, Yasheng Wang, Qun Liu, Lijie Wen, Philip S. Yu, Zhijiang Guo |  |
| 1619 |  |  [Automatic Engineering of Long Prompts](https://doi.org/10.18653/v1/2024.findings-acl.634) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities in solving complex open-domain tasks, guided by comprehensive instructions and demonstrations provided in the form of prompts. However, these prompts can be lengthy, often comprising hundreds of lines and thousands of tokens,... | ChoJui Hsieh, Si Si, Felix X. Yu, Inderjit S. Dhillon |  |
| 1620 |  |  [AS-ES Learning: Towards efficient CoT learning in small models](https://doi.org/10.18653/v1/2024.findings-acl.635) |  | 0 | Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs, especially when it comes to logical reasoning. Attempts have been made to induce such ability in small models as well by distilling from the data with CoT generated by Large Language Models (LLMs). However, existing methods often... | Nuwa Xi, Yuhan Chen, Sendong Zhao, Haochun Wang, GongZhang GongZhang, Bing Qin, Ting Liu |  |
| 1621 |  |  [II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.636) |  | 0 | Visual Question Answering (VQA) often involves diverse reasoning scenarios across Vision and Language (V&L). Most prior VQA studies, however, have merely focused on assessing the model’s overall accuracy without evaluating it on different reasoning cases. Furthermore, some recent works observe that... | Jihyung Kil, Farideh Tavazoee, Dongyeop Kang, JooKyung Kim |  |
| 1622 |  |  [TAME-RD: Text Assisted Replication of Image Multi-Adjustments for Reverse Designing](https://doi.org/10.18653/v1/2024.findings-acl.637) |  | 0 | Given a source and its edited version performed based on human instructions in natural language, how do we extract the underlying edit operations, to automatically replicate similar edits on other images? This is the problem of reverse designing, and we present TAME-RD, a model to solve this... | Pooja Guhan, Uttaran Bhattacharya, Somdeb Sarkhel, Vahid Azizi, Xiang Chen, Saayan Mitra, Aniket Bera, Dinesh Manocha |  |
| 1623 |  |  [Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.638) |  | 0 | In this paper, by treating in-context learning (ICL) as a meta-optimization process, we explain why LLMs are sensitive to the order of ICL examples. This understanding leads us to the development of Batch-ICL, an effective, efficient, and order-agnostic inference algorithm for ICL. Differing from... | Kaiyi Zhang, Ang Lv, Yuhan Chen, Hansen Ha, Tao Xu, Rui Yan |  |
| 1624 |  |  [IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.639) |  | 0 | We present INDICVOICES, a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a... | Tahir Javed, Janki Nawale, Eldho Ittan George, Sakshi Joshi, Kaushal Santosh Bhogale, Deovrat Mehendale, Ishvinder Virender Sethi, Aparna Ananthanarayanan, Hafsah Faquih, Pratiti Palit, Sneha Ravishankar, Saranya Sukumaran, Tripura Panchagnula, Sunjay Murali, Kunal Sharad Gandhi, Ambujavalli R, Manickam K. M, C. Venkata Vaijayanthi, Krishnan Srinivasa Raghavan Karunganni, Pratyush Kumar, Mitesh M. Khapra |  |
| 1625 |  |  [ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.640) |  | 0 | In our work, we explore the synergistic capabilities of pre-trained vision-and-language models (VLMs) and large language models (LLMs) on visual commonsense reasoning (VCR) problems. We find that VLMs and LLMs-based decision pipelines are good at different kinds of VCR problems. Pre-trained VLMs... | Kaiwen Zhou, Kwonjoon Lee, Teruhisa Misu, Xin Wang |  |
| 1626 |  |  [Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.641) |  | 0 | In-context learning of large-language models (LLMs) has achieved remarkable success in the field of natural language processing, while extensive case studies reveal that the single-step chain-of-thought prompting approach faces challenges such as attention diffusion and inadequate performance in... | Yuanzhen Xie, Xinzhou Jin, Tao Xie, Mingxiong Lin, Liang Chen, Chenyun Yu, Cheng Lei, Chengxiang Zhuo, Bo Hu, Zang Li |  |
| 1627 |  |  [Unveiling Opinion Evolution via Prompting and Diffusion for Short Video Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.642) |  | 0 | Short video fake news detection is crucial for combating the spread of misinformation. Current detection methods tend to aggregate features from individual modalities into multimodal features, overlooking the implicit opinions and the evolving nature of opinions across modalities. In this paper, we... | Linlin Zong, Jiahui Zhou, Wenmin Lin, Xinyue Liu, Xianchao Zhang, Bo Xu |  |
| 1628 |  |  [iSign: A Benchmark for Indian Sign Language Processing](https://doi.org/10.18653/v1/2024.findings-acl.643) |  | 0 | Indian Sign Language has limited resources for developing machine learning and data-driven approaches for automated language processing. Though text/audio-based language processing techniques have shown colossal research interest and tremendous improvements in the last few years, Sign Languages... | Abhinav Joshi, Romit Mohanty, Mounika Kanakanti, Andesha Mangla, Sudeep Choudhary, Monali Barbate, Ashutosh Modi |  |
| 1629 |  |  [Data Contamination Calibration for Black-box LLMs](https://doi.org/10.18653/v1/2024.findings-acl.644) |  | 0 | The rapid advancements of Large Language Models (LLMs) tightly associate with the expansion of the training data size. However, the unchecked ultra-large-scale training sets introduce a series of potential risks like data contamination, i.e. the benchmark data is used for training. In this work, we... | Wentao Ye, Jiaqi Hu, Liyao Li, Haobo Wang, Gang Chen, Junbo Zhao |  |
| 1630 |  |  [Truth-Aware Context Selection: Mitigating Hallucinations of Large Language Models Being Misled by Untruthful Contexts](https://doi.org/10.18653/v1/2024.findings-acl.645) |  | 0 | Although Large Language Models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by untruthful contexts provided by users or knowledge augmentation tools, leading to hallucinations. To alleviate LLMs from being misled by untruthful context and take advantage... | Tian Yu, Shaolei Zhang, Yang Feng |  |
| 1631 |  |  [Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.646) |  | 0 | Large language models (LLMs) exhibit outstanding performance in machine translation via in-context learning. In contrast to sentence-level translation, document-level translation (DOCMT) by LLMs based on in-context learning faces two major challenges: firstly, document translations generated by... | Menglong Cui, Jiangcun Du, Shaolin Zhu, Deyi Xiong |  |
| 1632 |  |  [Improving Grammatical Error Correction via Contextual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.647) |  | 0 | Nowadays, data augmentation through synthetic data has been widely used in the field of Grammatical Error Correction (GEC) to alleviate the problem of data scarcity. However, these synthetic data are mainly used in the pre-training phase rather than the data-limited fine tuning phase due to... | Yixuan Wang, Baoxin Wang, Yijun Liu, Qingfu Zhu, Dayong Wu, Wanxiang Che |  |
| 1633 |  |  [RECOST: External Knowledge Guided Data-efficient Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.648) |  | 0 | In the current landscape of large language models (LLMs), the process of instruction tuning serves as an essential step. Considering the high computing power overhead, data-efficient instruction tuning was proposed to reduce the training data size in this process, aiming at selecting high-quality... | Qi Zhang, Yiming Zhang, Haobo Wang, Junbo Zhao |  |
| 1634 |  |  [Understanding Cross-Lingual Alignment - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.649) |  | 0 | Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising... | Katharina Hämmerl, Jindrich Libovický, Alexander Fraser |  |
| 1635 |  |  [Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-acl.650) |  | 0 | Lifelong prompt tuning has significantly advanced parameter-efficient lifelong learning with its efficiency and minimal storage demands on various tasks.Our empirical studies, however, highlights certain transferability constraints in the current methodologies: a universal algorithm that guarantees... | Chenyuan Wu, Gangwei Jiang, Defu Lian |  |
| 1636 |  |  [PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.651) |  | 0 | While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves... | An Liu, Zonghan Yang, Zhenhe Zhang, Qingyuan Hu, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu |  |
| 1637 |  |  [Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction](https://doi.org/10.18653/v1/2024.findings-acl.652) |  | 0 | Advancements in AI and natural language processing have revolutionized machine-human language interactions, with question answering (QA) systems playing a pivotal role. The knowledge base question answering (KBQA) task, utilizing structured knowledge graphs (KG), allows for handling extensive... | Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domogala, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz |  |
| 1638 |  |  [Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM](https://doi.org/10.18653/v1/2024.findings-acl.653) |  | 0 | Generating accurate SQL queries for user questions (text-to-SQL) has been a long-standing challenge since it requires a deep understanding of both the user’s question and the corresponding database schema in order to retrieve the desired content accurately. Existing methods rely on the... | Zijin Hong, Zheng Yuan, Hao Chen, Qinggang Zhang, Feiran Huang, Xiao Huang |  |
| 1639 |  |  [Centroid-Based Efficient Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.654) |  | 0 | Minimum Bayes risk (MBR) decoding achieved state-of-the-art translation performance by using COMET, a neural metric that has a high correlation with human evaluation.However, MBR decoding requires quadratic time since it computes the expected score between a translation hypothesis and all reference... | Hiroyuki Deguchi, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe, Hideki Tanaka, Masao Utiyama |  |
| 1640 |  |  [Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration](https://doi.org/10.18653/v1/2024.findings-acl.655) |  | 0 | In this paper, we tackle the task of distractor generation (DG) for multiple-choice questions. Our study introduces two key designs. First, we propose the concept of retrieval augmented pretraining, which involves refining the language model pretraining to align it more closely with the downstream... | HanCheng Yu, YuAn Shih, KinMan Law, KaiYu Hsieh, YuChen Cheng, HsinChih Ho, ZihAn Lin, WenChuan Hsu, YaoChung Fan |  |
| 1641 |  |  [Exploiting Positional Bias for Query-Agnostic Generative Content in Search](https://doi.org/10.18653/v1/2024.findings-acl.656) |  | 0 | In recent years, research shows that neural ranking models (NRMs) substantially outperform their lexical counterparts in text retrieval. In traditional search pipelines, a combination of features leads to well-defined behaviour. However, as neural approaches become increasingly prevalent as the... | Andrew Parry, Sean MacAvaney, Debasis Ganguly |  |
| 1642 |  |  [ICC : Quantifying Image Caption Concreteness for Multimodal Dataset Curation](https://doi.org/10.18653/v1/2024.findings-acl.657) |  | 0 | Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly... | Moran Yanuka, Morris Alper, Hadar AverbuchElor, Raja Giryes |  |
| 1643 |  |  [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.658) |  | 0 | Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However,... | Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, Haobo Wang |  |
| 1644 |  |  [When is a Language Process a Language Model?](https://doi.org/10.18653/v1/2024.findings-acl.659) |  | 0 | A language model may be viewed as a 𝛴-valued stochastic process for some alphabet 𝛴.However, in some pathological situations, such a stochastic process may “leak” probability mass onto the set of infinite strings and hence is not equivalent to the conventional view of a language model as a... | Li Du, Holden Lee, Jason Eisner, Ryan Cotterell |  |
| 1645 |  |  [Accelerating Multilingual Language Model for Excessively Tokenized Languages](https://doi.org/10.18653/v1/2024.findings-acl.660) |  | 0 | Recent advancements in large language models (LLMs) have remarkably enhanced performances on a variety of tasks in multiple languages. However, tokenizers in LLMs trained primarily on English-centric corpora often overly fragment a text into character or Unicode-level tokens in non-Roman alphabetic... | Jimin Hong, Gibbeum Lee, Jaewoong Cho |  |
| 1646 |  |  [Definition Generation for Automatically Induced Semantic Frame](https://doi.org/10.18653/v1/2024.findings-acl.661) |  | 0 | In a semantic frame resource such as FrameNet, the definition sentence of a frame is essential for humans to understand the meaning of the frame intuitively. Recently, several attempts have been made to induce semantic frames from large corpora, but the cost of creating the definition sentences for... | Yi Han, Ryohei Sasano, Koichi Takeda |  |
| 1647 |  |  [Distillation Enhanced Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.662) |  | 0 | Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generative language models, distinct from traditional sparse or dense retrieval methods. In this work, we identify a... | Yongqi Li, Zhen Zhang, Wenjie Wang, Liqiang Nie, Wenjie Li, TatSeng Chua |  |
| 1648 |  |  [ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos](https://doi.org/10.18653/v1/2024.findings-acl.663) |  | 0 | In an era of rapidly evolving internet technology, the surge in multimodal content, including videos, has expanded the horizons of online communication. However, the detection of toxic content in this diverse landscape, particularly in low-resource code-mixed languages, remains a critical... | Krishanu Maity, Poornash Sangeetha, Sriparna Saha, Pushpak Bhattacharyya |  |
| 1649 |  |  [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.664) |  | 0 | Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable... | Zhicheng Guo, Sijie Cheng, Hao Wang, Shihao Liang, Yujia Qin, Peng Li, Zhiyuan Liu, Maosong Sun, Yang Liu |  |
| 1650 |  |  [Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence](https://doi.org/10.18653/v1/2024.findings-acl.665) |  | 0 | Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants. Previous works mainly focus on raising... | Weixiang Zhao, Zhuojun Li, Shilong Wang, Yang Wang, Yulin Hu, Yanyan Zhao, Chen Wei, Bing Qin |  |
| 1651 |  |  [KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.666) |  | 0 | To reliably deploy Large Language Models (LLMs) in a specific country, they must possess an understanding of the nation’s culture and basic knowledge. To this end, we introduce National Alignment, which measures the alignment between an LLM and a targeted country from two aspects: social value... | Jiyoung Lee, Minwoo Kim, Seungho Kim, Junghwan Kim, Seunghyun Won, Hwaran Lee, Edward Choi |  |
| 1652 |  |  [Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development](https://doi.org/10.18653/v1/2024.findings-acl.667) |  | 0 | The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance, enhancing patient safety by identifying potential risks associated with medications, facilitating early detection of adverse events, and guiding regulatory decision-making. Traditional ADE detection methods are reliable but... | Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal |  |
| 1653 |  |  [Space Decomposition for Sentence Embedding](https://doi.org/10.18653/v1/2024.findings-acl.668) |  | 0 | Determining sentence pair similarity is crucial for various NLP tasks. A common technique to address this is typically evaluated on a continuous semantic textual similarity scale from 0 to 5. However, based on a linguistic observation in STS annotation guidelines, we found that the score in the... | Wuttikorn Ponwitayarat, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 1654 |  |  [Don't Augment, Rewrite? Assessing Abusive Language Detection with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.669) |  | 0 | Research on abusive language detection and content moderation is crucial to combat online harm. However, current limitations set by regulatory bodies and social media platforms can make it difficult to share collected data. We address this challenge by exploring the possibility to replace existing... | Camilla Casula, Elisa Leonardelli, Sara Tonelli |  |
| 1655 |  |  [Improving Low-Resource Machine Translation for Formosan Languages Using Bilingual Lexical Resources](https://doi.org/10.18653/v1/2024.findings-acl.670) |  | 0 | This paper investigates how machine translation for low-resource languages can be improved by incorporating information from bilingual lexicons during the training process for mainly translation between Mandarin and Formosan languages, which are all moribund or critically endangered, and we also... | Francis Zheng, Edison MarreseTaylor, Yutaka Matsuo |  |
| 1656 |  |  [CMMLU: Measuring massive multitask language understanding in Chinese](https://doi.org/10.18653/v1/2024.findings-acl.671) |  | 0 | As the capabilities of large language models (LLMs) continue to advance, evaluating their performance is becoming more important and more challenging. This paper aims to address this issue for Mandarin Chinese in the form of CMMLU, a comprehensive Chinese benchmark that covers various subjects,... | Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, Timothy Baldwin |  |
| 1657 |  |  [Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.672) |  | 0 | Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging. It not only requires checking whether the VLM follows the given instruction but also verifying whether the text output is properly grounded on the given image. Inspired by the recent approach of evaluating LMs... | Seongyun Lee, Seungone Kim, Sue Hyun Park, Geewook Kim, Minjoon Seo |  |
| 1658 |  |  [Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction](https://doi.org/10.18653/v1/2024.findings-acl.673) |  | 0 | The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual... | Xiaoyuan Li, Wenjie Wang, Moxin Li, Junrong Guo, Yang Zhang, Fuli Feng |  |
| 1659 |  |  [Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.674) |  | 0 |  | Michele Mastromattei, Fabio Massimo Zanzotto |  |
| 1660 |  |  [When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.675) |  | 0 | Large Language Models (LLMs) have been found to have difficulty knowing they do not possess certain knowledge and tend to provide specious answers in such cases. Retrieval Augmentation (RA) has been extensively studied to mitigate LLMs’ hallucinations. However, due to the extra overhead and... | Shiyu Ni, Keping Bi, Jiafeng Guo, Xueqi Cheng |  |
| 1661 |  |  [Hybrid Alignment Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.676) |  | 0 | Alignment training is crucial for enabling large language models (LLMs) to cater to human intentions and preferences. It is typically performed based on two stages with different objectives: instruction-following alignment and human-preference alignment. However, aligning LLMs with these objectives... | Chenglong Wang, Hang Zhou, Kaiyan Chang, Bei Li, Yongyu Mu, Tong Xiao, Tongran Liu, JingBo Zhu |  |
| 1662 |  |  [Graph-Structured Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.677) |  | 0 | Speculative decoding has emerged as a promising technique to accelerate the inference of Large Language Models (LLMs) by employing a small language model to draft a hypothesis sequence, which is then validated by the LLM. The effectiveness of this approach heavily relies on the balance between... | Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan |  |
| 1663 |  |  [Duwak: Dual Watermarks in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.678) |  | 0 | As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable... | Chaoyi Zhu, Jeroen Galjaard, PinYu Chen, Lydia Y. Chen |  |
| 1664 |  |  [CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion](https://doi.org/10.18653/v1/2024.findings-acl.679) |  | 0 | The rapid advancement of Large Language Models (LLMs) has brought about remarkable generative capabilities but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods... | Qibing Ren, Chang Gao, Jing Shao, Junchi Yan, Xin Tan, Wai Lam, Lizhuang Ma |  |
| 1665 |  |  [Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training](https://doi.org/10.18653/v1/2024.findings-acl.680) |  | 0 | While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the “reversal curse”. It is a typical example that the model knows “A’s father is B”, but is unable to reason “B’s child is A”. This limitation poses a... | Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, Jiang Bian, Yujiu Yang |  |
| 1666 |  |  [wav2vec-S: Adapting Pre-trained Speech Models for Streaming](https://doi.org/10.18653/v1/2024.findings-acl.681) |  | 0 | Pre-trained speech models, such as wav2vec 2.0, have significantly advanced speech-related tasks, including speech recognition and translation. However, their applicability in streaming scenarios is limited because these models are trained on complete utterances, leading to a mismatch with... | Biao Fu, Kai Fan, Minpeng Liao, Yidong Chen, Xiaodong Shi, Zhongqiang Huang |  |
| 1667 |  |  [Peering into the Mind of Language Models: An Approach for Attribution in Contextual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.682) |  | 0 | With the enhancement in the field of generative artificial intelligence (AI), contextual question answering has become extremely relevant. Attributing model generations to the input source document is essential to ensure trustworthiness and reliability. We observe that when large language models... | Anirudh Phukan, Shwetha Somasundaram, Apoorv Saxena, Koustava Goswami, Balaji Vasan Srinivasan |  |
| 1668 |  |  [TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification](https://doi.org/10.18653/v1/2024.findings-acl.683) |  | 0 | Large Language Model (LLM) services and models often come with legal rules on \*who\* can use them and \*how\* they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe... | Martin Gubri, Dennis Ulmer, Hwaran Lee, Sangdoo Yun, Seong Joon Oh |  |
| 1669 |  |  [CLASP: Cross-modal Alignment Using Pre-trained Unimodal Models](https://doi.org/10.18653/v1/2024.findings-acl.684) |  | 0 | Recent advancements in joint speech-text pre-training have significantly advanced the processing of natural language. However, a key limitation is their reliance on parallel speech-text data, posing challenges due to data accessibility. Addressing this, our paper introduces an innovative framework... | Jianing Zhou, Ziheng Zeng, Hongyu Gong, Suma Bhat |  |
| 1670 |  |  [TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind](https://doi.org/10.18653/v1/2024.findings-acl.685) |  | 0 | Theory of Mind (ToM)—the cognitive ability to reason about mental states of ourselves and others, is the foundation of social interaction. Although ToM comes naturally to humans, it poses a significant challenge to even the most advanced Large Language Models (LLMs). Due to the complex logical... | Guiyang Hou, Wenqi Zhang, Yongliang Shen, Linjuan Wu, Weiming Lu |  |
| 1671 |  |  [Identifying and Mitigating Annotation Bias in Natural Language Understanding using Causal Mediation Analysis](https://doi.org/10.18653/v1/2024.findings-acl.686) |  | 0 | NLU models have achieved promising results on standard benchmarks. Despite state-of-the-art accuracy, analysis reveals that many models make predictions using annotation bias rather than the properties we intend the model to learn. Consequently, these models perform poorly on out-of-distribution... | Sitiporn Sae Lim, Can Udomcharoenchaikit, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 1672 |  |  [Perturbed examples reveal invariances shared by language models](https://doi.org/10.18653/v1/2024.findings-acl.687) |  | 0 | The rapid growth in natural language processing (NLP) research has led to numerous new models, outpacing our understanding of how they compare to established ones. One major reason for this difficulty is saturating benchmarks, which may not well reflect differences in model performance in the wild.... | Ruchit Rawal, Mariya Toneva |  |
| 1673 |  |  [Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.688) |  | 0 | Stochastic sampling strategies such as top-k and top-p have been widely used in dialogue generation task. However, as an open-domain chatting system, there will be two different conversation scenarios, i.e. chit-chat and knowledge-based question answering. In the former situation, responses... | Yiwei Li, Fei Mi, Yitong Li, Yasheng Wang, Bin Sun, Shaoxiong Feng, Kan Li |  |
| 1674 |  |  [Discourse Structure-Aware Prefix for Generation-Based End-to-End Argumentation Mining](https://doi.org/10.18653/v1/2024.findings-acl.689) |  | 0 | End-to-end argumentation mining (AM) aims to extract the argumentation structure including argumentation components and their argumentation relations from text. Recent developments in end-to-end AM models have demonstrated significant progress by redefining the AM task as a sequence generation... | Yang Sun, Guanrong Chen, Caihua Yang, Jianzhu Bao, Bin Liang, Xi Zeng, Min Yang, Ruifeng Xu |  |
| 1675 |  |  [Poor-Supervised Evaluation for SuperLLM via Mutual Consistency](https://doi.org/10.18653/v1/2024.findings-acl.690) |  | 0 | The guidance from capability evaluations has greatly propelled the progress of human society and the development of Artificial Intelligence. However, as LLMs evolve, it becomes challenging to construct evaluation benchmark with accurate labels for SuperLLMs whose capabilities approach or even... | Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 1676 |  |  [Addressing Entity Translation Problem via Translation Difficulty and Context Diversity](https://doi.org/10.18653/v1/2024.findings-acl.691) |  | 0 | Neural machine translation (NMT) systems often produce inadequate translations for named entities. In this study, we conducted preliminary experiments to examine the factors affecting the translation accuracy of named entities, specifically focusing on their translation difficulty and context... | Tian Liang, Xing Wang, Mingming Yang, Yujiu Yang, Shuming Shi, Zhaopeng Tu |  |
| 1677 |  |  [ADAM: Dense Retrieval Distillation with Adaptive Dark Examples](https://doi.org/10.18653/v1/2024.findings-acl.692) |  | 0 | To improve the performance of the dual-encoder retriever, one effective approach is knowledge distillation from the cross-encoder ranker. Existing works prepare training instances by pairing each query with one positive and a batch of negatives. However, most hard negatives mined by advanced dense... | Chongyang Tao, Chang Liu, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, Daxin Jiang |  |
| 1678 |  |  [Instruction Position Matters in Sequence Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.693) |  | 0 | Large language models (LLMs) are capable of performing conditional sequence generation tasks, such as translation or summarization, through instruction fine-tuning. The fine-tuning data is generally sequentially concatenated from a specific task instruction, an input sentence, and the corresponding... | Yijin Liu, Xianfeng Zeng, Chenze Shao, Fandong Meng, Jie Zhou |  |
| 1679 |  |  [XMoE: Sparse Models with Fine-grained and Adaptive Expert Selection](https://doi.org/10.18653/v1/2024.findings-acl.694) |  | 0 | Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations by multiplying values... | Yuanhang Yang, Shiyi Qi, Wenchao Gu, Chaozheng Wang, Cuiyun Gao, Zenglin Xu |  |
| 1680 |  |  [BranchNorm: Robustly Scaling Extremely Deep Transformers](https://doi.org/10.18653/v1/2024.findings-acl.695) |  | 0 | Recently, DeepNorm scales Transformers into extremely deep (i.e., 1000 layers) and reveals the promising potential of deep scaling. To stabilize the training of deep models, DeepNorm attempts to constrain the model update to a constant value. Although applying such a constraint can benefit the... | Yijin Liu, Xianfeng Zeng, Fandong Meng, Jie Zhou |  |
| 1681 |  |  [MusTQ: A Temporal Knowledge Graph Question Answering Dataset for Multi-Step Temporal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.696) |  | 0 | Question answering over temporal knowledge graphs (TKGQA) is an emerging topic, which has attracted increasing interest since it considers the dynamic knowledge in the world. Several datasets along with model developments are proposed in the TKGQA research field. However, existing studies generally... | Tingyi Zhang, Jiaan Wang, Zhixu Li, Jianfeng Qu, An Liu, Zhigang Chen, Hongping Zhi |  |
| 1682 |  |  [Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.697) |  | 0 | Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an... | Anthony Sicilia, Hyunwoo Kim, Khyathi Raghavi Chandu, Malihe Alikhani, Jack Hessel |  |
| 1683 |  |  [Knowledge Fusion By Evolving Weights of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.698) |  | 0 | Fine-tuning pre-trained language models, particularly large language models, demands extensive computing resources and can result in varying performance outcomes across different domains and datasets. This paper examines the approach of integrating multiple models from diverse training scenarios... | Guodong Du, Jing Li, Hanting Liu, Runhua Jiang, Shuyang Yu, Yifei Guo, Sim Kuan Goh, HoKin Tang |  |
| 1684 |  |  [ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale](https://doi.org/10.18653/v1/2024.findings-acl.699) |  | 0 | Multi-task learning (MTL) has shown considerable practical benefits, particularly when using language models (LMs). While this is commonly achieved by learning tasks under a joint optimization procedure, some methods, such as AdapterFusion, divide the problem into two stages: (i) task learning,... | Markus Frohmann, Carolin Holtermann, Shahed Masoudian, Anne Lauscher, Navid Rekabsaz |  |
| 1685 |  |  [Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.700) |  | 0 | For dialogue systems, the utilization of multimodal dialogue responses, as opposed to relying solely on text-only responses, offers the capability to describe different concepts through various modalities. This enhances the effectiveness of communication and elevates the overall conversational... | ChangSheng Kao, YunNung Chen |  |
| 1686 |  |  [MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization](https://doi.org/10.18653/v1/2024.findings-acl.701) |  | 0 | Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather... | Zhiyu Yang, Zihan Zhou, Shuo Wang, Xin Cong, Xu Han, Yukun Yan, Zhenghao Liu, Zhixing Tan, Pengyuan Liu, Dong Yu, Zhiyuan Liu, Xiaodong Shi, Maosong Sun |  |
| 1687 |  |  [Continual Few-shot Relation Extraction via Adaptive Gradient Correction and Knowledge Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.702) |  | 0 | Continual few-shot relation extraction (CFRE) aims to continually learn new relations with limited samples. However, current methods neglect the instability of embeddings in the process of different task training, which leads to serious catastrophic forgetting. In this paper, we propose the concept... | Jianpeng Hu, Chengxiang Tan, Jiacheng Xu, Xiangyun Kong |  |
| 1688 |  |  [CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.703) |  | 0 | What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the... | Linhao Yu, Yongqi Leng, Yufei Huang, Shang Wu, Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang Song, Tingting Cui, Xiaoqing Cheng, Liutao Liutao, Deyi Xiong |  |
| 1689 |  |  [Cache & Distil: Optimising API Calls to Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.704) |  | 0 | Large-scale deployment of generative AI tools often depends on costly API calls to a Large Language Model (LLM) to fulfil user queries, a process that also exposes the request stream to external providers. To curtail the frequency of these calls, one can employ a local smaller language model -a... | Guillem Ramírez, Matthias Lindemann, Alexandra Birch, Ivan Titov |  |
| 1690 |  |  [Investigating the Impact of Model Instability on Explanations and Uncertainty](https://doi.org/10.18653/v1/2024.findings-acl.705) |  | 0 | Explainable AI methods facilitate the understanding of model behaviour, yet, small, imperceptible perturbations to inputs can vastly distort explanations. As these explanations are typically evaluated holistically, before model deployment, it is difficult to assess when a particular explanation is... | Sara Marjanovic, Isabelle Augenstein, Christina Lioma |  |
| 1691 |  |  [A Two-Stage Adaptation of Large Language Models for Text Ranking](https://doi.org/10.18653/v1/2024.findings-acl.706) |  | 0 | Text ranking is a critical task in information retrieval. Recent advances in pre-trained language models (PLMs), especially large language models (LLMs), present new opportunities for applying them to text ranking. While supervised fine-tuning (SFT) with ranking data has been widely explored to... | Longhui Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang |  |
| 1692 |  |  [Fine-tuning with HED-IT: The impact of human post-editing for dialogical language models](https://doi.org/10.18653/v1/2024.findings-acl.707) |  | 0 | Automatic methods for generating and gathering linguistic data have proven effective for fine-tuning Language Models (LMs) in languages less resourced than English. Still, while there has been emphasis on data quantity, less attention has been given to its quality. In this work, we investigate the... | Daniela Occhipinti, Michele Marchi, Irene Mondella, Huiyuan Lai, Felice Dell'Orletta, Malvina Nissim, Marco Guerini |  |
| 1693 |  |  [Analyze, Generate and Refine: Query Expansion with LLMs for Zero-Shot Open-Domain QA](https://doi.org/10.18653/v1/2024.findings-acl.708) |  | 0 | Query expansion (QE) is a critical component in the open-domain question answering (OpenQA) pipeline, enhancing the retrieval performance by broadening the scope of queries with additional relevant texts. However, existing methods like GAR and EAR rely heavily on supervised training and often... | Xinran Chen, Xuanang Chen, Ben He, Tengfei Wen, Le Sun |  |
| 1694 |  |  [On the Evaluation of Speech Foundation Models for Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.709) |  | 0 | The Spoken Language Understanding Evaluation (SLUE) suite of benchmark tasks was recently introduced to address the need for openresources and benchmarking of complex spoken language understanding (SLU) tasks, including both classification and sequence generation tasks, on natural speech. The... | Siddhant Arora, Ankita Pasad, ChungMing Chien, Jionghao Han, Roshan S. Sharma, Jeeweon Jung, Hira Dhamyal, William Chen, Suwon Shon, Hungyi Lee, Karen Livescu, Shinji Watanabe |  |
| 1695 |  |  [Towards Multiple References Era - Addressing Data Leakage and Limited Reference Diversity in Machine Translation Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.710) |  | 0 | Recent research has shown a weak correlation between n-gram-based metrics and human evaluations in machine translation task, particularly when evaluating large language models (LLMs). Additionally, the data leakage risk in LLMs may cause an overestimation problem when evaluating LLMs on downstream... | Xianfeng Zeng, Yijin Liu, Fandong Meng, Jie Zhou |  |
| 1696 |  |  [Prompting open-source and commercial language models for grammatical error correction of English learner text](https://doi.org/10.18653/v1/2024.findings-acl.711) |  | 0 | Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input... | Christopher Davis, Andrew Caines, Øistein E. Andersen, Shiva Taslimipoor, Helen Yannakoudakis, Zheng Yuan, Christopher Bryant, Marek Rei, Paula Buttery |  |
| 1697 |  |  [BATS: BenchmArking Text Simplicity 🦇](https://doi.org/10.18653/v1/2024.findings-acl.712) |  | 0 | Evaluation of text simplification currently focuses on the difference of a source text to its simplified variant. Datasets for this evaluation base on a specific topic and group of readers for which is simplified. The broad applicability of text simplification and specifics that come with intended... | Christin Kreutz, Fabian Haak, Björn Engelmann, Philipp Schaer |  |
| 1698 |  |  [AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection](https://doi.org/10.18653/v1/2024.findings-acl.713) |  | 0 | Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently, such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian... | Pia Pachinger, Janis Goldzycher, Anna Maria Planitzer, Wojciech Kusa, Allan Hanbury, Julia Neidhardt |  |
| 1699 |  |  [Discovering influential text using convolutional neural networks](https://doi.org/10.18653/v1/2024.findings-acl.714) |  | 0 | Experimental methods for estimating the impacts of text on human evaluation have been widely used in the social sciences. However, researchers in experimental settings are usually limited to testing a small number of pre-specified text treatments. While efforts to mine unstructured texts for... | Megan Ayers, Luke Sanford, Margaret E. Roberts, Eddie Yang |  |
| 1700 |  |  [LC4EE: LLMs as Good Corrector for Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.715) |  | 0 | Event extraction (EE) is a critical task in natural language processing, yet deploying a practical EE system remains challenging. On one hand, powerful large language models (LLMs) currently show poor performance because EE task is more complex than other tasks. On the other hand, state-of-the-art... | Mengna Zhu, Kaisheng Zeng, Jibing Wu, Lihua Liu, Hongbin Huang, Lei Hou, Juanzi Li |  |
| 1701 |  |  [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.716) |  | 0 | Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs’ training data, it could explicitly or implicitly include test data, leading to LLMs being... | Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, Bin Gu, Mengfei Yang, Ge Li |  |
| 1702 |  |  [Efficient Training of Language Models with Compact and Consistent Next Token Distributions](https://doi.org/10.18653/v1/2024.findings-acl.717) |  | 0 | Maximizing the likelihood of the next token is an established, statistically sound objective for pre-training language models. In this paper we show that we can train better models faster by pre-aggregating the corpus with a collapsed n-gram distribution. Previous studies have proposed corpus-level... | Ashutosh Sathe, Sunita Sarawagi |  |
| 1703 |  |  [Ancient Chinese Glyph Identification Powered by Radical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.718) |  | 0 | The ancestor of Chinese character – the ancient characters from about 1300 BC to 200 BC are not fixed in their writing glyphs. At the same or different points in time, one character can possess multiple glyphs that are different in shapes or radicals. Nearly half of ancient glyphs have not been... | Yang Chi, Fausto Giunchiglia, Chuntao Li, Hao Xu |  |
| 1704 |  |  [PUB: A Pragmatics Understanding Benchmark for Assessing LLMs' Pragmatics Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.719) |  | 0 | LLMs have demonstrated remarkable capability for understanding semantics, but their understanding of pragmatics is not well studied. To this end, we release a Pragmatics Understanding Benchmark (PUB) dataset consisting of fourteen tasks in four pragmatics phenomena, namely; Implicature,... | Settaluri Lakshmi Sravanthi, Meet Doshi, Pavan Tankala, V. Rudra Murthy, Raj Dabre, Pushpak Bhattacharyya |  |
| 1705 |  |  [EmoTransKG: An Innovative Emotion Knowledge Graph to Reveal Emotion Transformation](https://doi.org/10.18653/v1/2024.findings-acl.720) |  | 0 | This paper introduces EmoTransKG, an innovative Emotion Knowledge Graph (EKG) that establishes connections and transformations between emotions across diverse open-textual events. Compared to existing EKGs, which primarily focus on linking emotion keywords to related terms or on assigning sentiment... | Huan Zhao, Xupeng Zha, Zixing Zhang |  |
| 1706 |  |  [How Vocabulary Sharing Facilitates Multilingualism in LLaMA?](https://doi.org/10.18653/v1/2024.findings-acl.721) |  | 0 | Large Language Models (LLMs), often show strong performance on English tasks, while exhibiting limitations on other languages. What is an LLM’s multilingual capability when it is trained only on certain languages? The underlying mechanism remains unclear. This study endeavors to examine the... | Fei Yuan, Shuai Yuan, Zhiyong Wu, Lei Li |  |
| 1707 |  |  [Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model](https://doi.org/10.18653/v1/2024.findings-acl.722) |  | 0 | While supervised fine-tuning (SFT) has been a straightforward approach for tailoring the output of foundation large language model (LLM) to specific preferences, concerns have been raised about the depth of this alignment, with some critiques suggesting it is merely “superficial”. We critically... | Runzhe Zhan, Xinyi Yang, Derek F. Wong, Lidia S. Chao, Yue Zhang |  |
| 1708 |  |  [Dual Prompt Tuning based Contrastive Learning for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.723) |  | 0 | Hierarchical text classification aims at categorizing texts into a multi-tiered tree-structured hierarchy of labels. Existing methods pay more attention to capture hierarchy-aware text feature by exploiting explicit parent-child relationships, while interactions between peer labels are rarely taken... | Sishi Xiong, Yu Zhao, Jie Zhang, Mengxiang Li, Zhongjiang He, Xuelong Li, Shuangyong Song |  |
| 1709 |  |  [Probing the Emergence of Cross-lingual Alignment during LLM Training](https://doi.org/10.18653/v1/2024.findings-acl.724) |  | 0 | Multilingual Large Language Models (LLMs) achieve remarkable levels of zero-shot cross-lingual transfer performance. We speculate that this is predicated on their ability to align languages without explicit supervision from parallel sentences. While representations of translationally equivalent... | Hetong Wang, Pasquale Minervini, Edoardo M. Ponti |  |
| 1710 |  |  [STSPL-SSC: Semi-Supervised Few-Shot Short Text Clustering with Semantic text similarity Optimized Pseudo-Labels](https://doi.org/10.18653/v1/2024.findings-acl.725) |  | 0 | This study introduces the Semantic Textual Similarity Pseudo-Label Semi-Supervised Clustering (STSPL-SSC) framework. The STSPL-SSC framework is designed to tackle the prevalent issue of scarce labeled data by combining a Semantic Textual Similarity Pseudo-Label Generation process with a Robust... | Wenhua Nie, Lin Deng, ChangBo Liu, Jialing Wei, Ruitong Han, Haoran Zheng |  |
| 1711 |  |  [A Comprehensive Evaluation of Quantization Strategies for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.726) |  | 0 | Increasing the number of parameters in large language models (LLMs) usually improves performance in downstream tasks but raises compute and memory costs, making deployment difficult in resource-limited settings. Quantization techniques, which reduce the bits needed for model weights or activations... | Renren Jin, Jiangcun Du, Wuwei Huang, Wei Liu, Jian Luan, Bin Wang, Deyi Xiong |  |
| 1712 |  |  [Exploiting Target Language Data for Neural Machine Translation Beyond Back Translation](https://doi.org/10.18653/v1/2024.findings-acl.727) |  | 0 | Neural Machine Translation (NMT) encounters challenges when translating in new domains and low-resource languages. To address these issues, researchers have proposed methods to integrate additional knowledge into NMT, such as translation memories (TMs). However, finding TMs that closely match the... | Abudurexiti Reheman, Yingfeng Luo, Junhao Ruan, Chunliang Zhang, Anxiang Ma, Tong Xiao, JingBo Zhu |  |
| 1713 |  |  [Bayesian Prompt Ensembles: Model Uncertainty Estimation for Black-Box Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.728) |  | 0 | An important requirement for the reliable deployment of pre-trained large language models (LLMs) is the well-calibrated quantification of the uncertainty in their outputs. While the likelihood of predicting the next token is a practical surrogate of the data uncertainty learned during training,... | Francesco Tonolini, Nikolaos Aletras, Jordan Massiah, Gabriella Kazai |  |
| 1714 |  |  [X-ACE: Explainable and Multi-factor Audio Captioning Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.729) |  | 0 | Automated audio captioning (AAC) aims to generate descriptions based on audio input, attracting exploration of emerging audio language models (ALMs). However, current evaluation metrics only provide a single score to assess the overall quality of captions without characterizing the nuanced... | Qian Wang, JiaChen Gu, ZhenHua Ling |  |
| 1715 |  |  [Reasons to Reject? Aligning Language Models with Judgments](https://doi.org/10.18653/v1/2024.findings-acl.730) |  | 0 | As humans, we consistently interact with our peers and receive feedback in the form of natural language. This language feedback allows us to maintain appropriate behavior, and rectify potential errors. The question arises naturally: can we use language feedback to align large language models... | Weiwen Xu, Deng Cai, Zhisong Zhang, Wai Lam, Shuming Shi |  |
| 1716 |  |  [Decomposing Argumentative Essay Generation via Dialectical Planning of Complex Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.731) |  | 0 | Argumentative Essay Generation (AEG) is a challenging task in computational argumentation, where detailed logical reasoning and effective rhetorical skills are essential.Previous methods on argument generation typically involve planning prior to generation.However, the planning strategies in these... | Yuhang He, Jianzhu Bao, Yang Sun, Bin Liang, Min Yang, Bing Qin, Ruifeng Xu |  |
| 1717 |  |  [Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition](https://doi.org/10.18653/v1/2024.findings-acl.732) |  | 0 | Recognizing fallacies is crucial for ensuring the quality and validity of arguments across various domains. However, computational fallacy recognition faces challenges due to the diverse genres, domains, and types of fallacies found in datasets. This leads to a highly multi-class, and even... | Tariq Alhindi, Smaranda Muresan, Preslav Nakov |  |
| 1718 |  |  [Concept-aware Data Construction Improves In-context Learning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.733) |  | 0 | Many recent language models (LMs) are capable of in-context learning (ICL), manifested in the LMs’ ability to perform a new task solely from natural-language instruction. Previous work curating in-context learners assumes that ICL emerges from a vast over-parametrization or the scale of multi-task... | Michal Stefánik, Marek Kadlcík, Petr Sojka |  |
| 1719 |  |  [Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis](https://doi.org/10.18653/v1/2024.findings-acl.734) |  | 0 | Supervised machine-learning models for predicting user behavior offer a challenging classification problem with lower average prediction performance scores than other text classification tasks. This study evaluates multi-task learning frameworks grounded in Cognitive Appraisal Theory to predict... | Gerard Yeo, Shaz Furniturewala, Kokil Jaidka |  |
| 1720 |  |  [Non-Autoregressive Machine Translation as Constrained HMM](https://doi.org/10.18653/v1/2024.findings-acl.735) |  | 0 | In non-autoregressive translation (NAT), directed acyclic Transformers (DAT) have demonstrated their ability to achieve comparable performance to the autoregressive Transformers.In this paper, we first show that DAT is essentially a fully connected left-to-right Hidden Markov Model (HMM), with the... | Haoran Li, Zhanming Jie, Wei Lu |  |
| 1721 |  |  [Multi-modal Stance Detection: New Datasets and Model](https://doi.org/10.18653/v1/2024.findings-acl.736) |  | 0 | Stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. Previous work on stance detection largely focused on pure texts. In this paper, we study multi-modal stance detection for tweets consisting of texts and images,... | Bin Liang, Ang Li, Jingqian Zhao, Lin Gui, Min Yang, Yue Yu, KamFai Wong, Ruifeng Xu |  |
| 1722 |  |  [Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression](https://doi.org/10.18653/v1/2024.findings-acl.737) |  | 0 | Large language models (LLMs) can generate long-form and coherent text, yet they often hallucinate facts, which undermines their reliability. To mitigate this issue, inference-time methods steer LLM representations toward the “truthful directions” previously learned for truth elicitation. However,... | Farima Fatahi Bayat, Xin Liu, H. V. Jagadish, Lu Wang |  |
| 1723 |  |  [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.738) |  | 0 | In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities... | Duzhen Zhang, Yahan Yu, Jiahua Dong, Chenxing Li, Dan Su, Chenhui Chu, Dong Yu |  |
| 1724 |  |  [CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.739) |  | 0 | The advancement of large language models (LLMs) has enhanced the ability to generalize across a wide range of unseen natural language processing (NLP) tasks through instruction-following.Yet, their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased... | Yizhi Li, Ge Zhang, Xingwei Qu, Jiali Li, Zhaoqun Li, Noah Wang, Hao Li, Ruibin Yuan, Yinghao Ma, Kai Zhang, Wangchunshu Zhou, Yiming Liang, Lei Zhang, Lei Ma, Jiajun Zhang, Zuowen Li, Wenhao Huang, Chenghua Lin, Jie Fu |  |
| 1725 |  |  [Countering Reward Over-Optimization in LLM with Demonstration-Guided Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.740) |  | 0 | While reinforcement learning (RL) has been proven essential for tuning large language models (LLMs), it can lead to reward over-optimization (ROO). Existing approaches address ROO by adding KL regularization, requiring computationally expensive hyperparameter tuning. Additionally, KL regularization... | Mathieu Rita, Florian Strub, Rahma Chaabouni, Paul Michel, Emmanuel Dupoux, Olivier Pietquin |  |
| 1726 |  |  [Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss](https://doi.org/10.18653/v1/2024.findings-acl.741) |  | 0 | Accurately modeling idiomatic or non-compositional language has been a longstanding challenge in Natural Language Processing (NLP). This is partly because these expressions do not derive their meanings solely from their constituent words, but also due to the scarcity of relevant data resources, and... | Wei He, Marco Idiart, Carolina Scarton, Aline Villavicencio |  |
| 1727 |  |  [AdaLomo: Low-memory Optimization with Adaptive Learning Rate](https://doi.org/10.18653/v1/2024.findings-acl.742) |  | 0 | Large language models have achieved remarkable success, but their extensive parameter size necessitates substantial memory for training, thereby setting a high threshold. While the recently proposed low-memory optimization (LOMO) reduces memory footprint, its optimization technique, akin to... | Kai Lv, Hang Yan, Qipeng Guo, Haijun Lv, Xipeng Qiu |  |
| 1728 |  |  [Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks](https://doi.org/10.18653/v1/2024.findings-acl.743) |  | 0 | Current knowledge editing approaches struggle to effectively propagate updates to interconnected facts.In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel... | Wenyue Hua, Jiang Guo, Mingwen Dong, Henghui Zhu, Patrick Ng, Zhiguo Wang |  |
| 1729 |  |  [Exciting Mood Changes: A Time-aware Hierarchical Transformer for Change Detection Modelling](https://doi.org/10.18653/v1/2024.findings-acl.744) |  | 0 | Through the rise of social media platforms, longitudinal language modelling has received much attention over the latest years, especially in downstream tasks such as mental health monitoring of individuals where modelling linguistic content in a temporal fashion is crucial. A key limitation in... | Anthony Hills, Talia Tseriotou, Xenia Miscouridou, Adam Tsakalidis, Maria Liakata |  |
| 1730 |  |  [CorNav: Autonomous Agent with Self-Corrected Planning for Zero-Shot Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.findings-acl.745) |  | 0 | Understanding and following natural language instructions while navigating through complex, real-world environments poses a significant challenge for general-purpose robots. These environments often include obstacles and pedestrians, making it essential for autonomous agents to possess the... | Xiwen Liang, Liang Ma, Shanshan Guo, Jianhua Han, Hang Xu, Shikui Ma, Xiaodan Liang |  |
| 1731 |  |  [SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.746) |  | 0 | Multi-modal information retrieval (MMIR) is a rapidly evolving field where significant progress has been made through advanced representation learning and cross-modality alignment research, particularly in image-text pairing.However, current benchmarks for evaluating MMIR performance on image-text... | Siwei Wu, Yizhi Li, Kang Zhu, Ge Zhang, Yiming Liang, Kaijing Ma, Chenghao Xiao, Haoran Zhang, Bohao Yang, Wenhu Chen, Wenhao Huang, Noura Al Moubayed, Jie Fu, Chenghua Lin |  |
| 1732 |  |  [Diving Deep into the Motion Representation of Video-Text Models](https://doi.org/10.18653/v1/2024.findings-acl.747) |  | 0 | Videos are more informative than images becausethey capture the dynamics of the scene.By representing motion in videos, we can capturedynamic activities. In this work, we introduceGPT-4 generated motion descriptions thatcapture fine-grained motion descriptions of activitiesand apply them to three... | Chinmaya Devaraj, Cornelia Fermüller, Yiannis Aloimonos |  |
| 1733 |  |  [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation](https://doi.org/10.18653/v1/2024.findings-acl.748) |  | 0 | We introduce Bonito, an open-source model for conditional task generation that converts unannotated text into task-specific training datasets for instruction tuning. We aim to enable zero-shot task adaptation of large language models on users’ specialized, private data. We train Bonito by... | Nihal V. Nayak, Yiyang Nan, Avi Trost, Stephen H. Bach |  |
| 1734 |  |  [Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.749) |  | 0 | Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also often retain a large portion of... | Anirudh Som, Karan Sikka, Helen Gent, Ajay Divakaran, Andreas Kathol, Dimitra Vergyri |  |
| 1735 |  |  [Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse](https://doi.org/10.18653/v1/2024.findings-acl.750) |  | 0 | Whataboutism, a potent tool for disrupting narratives and sowing distrust, remains under-explored in quantitative NLP research. Moreover, past work has not distinguished its use as a strategy for misinformation and propaganda from its use as a tool for pragmatic and semantic framing. We introduce... | Khiem Phi, Noushin Salek Faramarzi, Chenlu Wang, Ritwik Banerjee |  |
| 1736 |  |  [Epistemology of Language Models: Do Language Models Have Holistic Knowledge?](https://doi.org/10.18653/v1/2024.findings-acl.751) |  | 0 | This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as... | Minsu Kim, James Thorne |  |
| 1737 |  |  [Strong hallucinations from negation and how to fix them](https://doi.org/10.18653/v1/2024.findings-acl.752) |  | 0 | Despite great performance on many tasks, language models (LMs) still struggle with reasoning, sometimes providing responses that cannot possibly be true because they stem from logical incoherence. We call such responses strong hallucinations and prove that they follow from an LM’s computation of... | Swarnadeep Bhar, Nicholas Asher |  |
| 1738 |  |  [LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores](https://doi.org/10.18653/v1/2024.findings-acl.753) |  | 0 | Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for... | Yiqi Liu, Nafise Sadat Moosavi, Chenghua Lin |  |
| 1739 |  |  [HelloFresh: LLM Evalutions on Streams of Real-World Human Editorial Actions across X Community Notes and Wikipedia edits](https://doi.org/10.18653/v1/2024.findings-acl.754) |  | 0 | Benchmarks have been essential for driving progress in machine learning. A better understanding of LLM capabilities on real world tasks is vital for safe development.Designing adequate LLM benchmarks is challenging: Data from real-world tasks is hard to collect, public availability of static... | Tim Franzmeyer, Aleksandar Shtedritski, Samuel Albanie, Philip Torr, João F. Henriques, Jakob N. Foerster |  |
| 1740 |  |  [Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies](https://doi.org/10.18653/v1/2024.findings-acl.755) |  | 0 | This study explores the sycophantic tendencies of Large Language Models (LLMs), where these models tend to provide answers that match what users want to hear, even if they are not entirely correct. The motivation behind this exploration stems from the common behavior observed in individuals... | Aswin RRV, Nemika Tyagi, Md Nayem Uddin, Neeraj Varshney, Chitta Baral |  |
| 1741 |  |  [Empowering Large Language Models for Textual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.756) |  | 0 | With the capabilities of understanding and executing natural language instructions, Large language models (LLMs) can potentially act as a powerful tool for textual data augmentation. However, the quality of augmented data depends heavily on the augmentation instructions provided, and the... | Yichuan Li, Kaize Ding, Jianling Wang, Kyumin Lee |  |
| 1742 |  |  [Choose Your Transformer: Improved Transferability Estimation of Transformer Models on Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.757) |  | 0 | There currently exists a multitude of pre-trained transformer language models (LMs) that are readily available. From a practical perspective, this raises the question of which pre-trained LM will perform best if fine-tuned for a specific downstream NLP task. However, exhaustively fine-tuning all... | Lukas Garbaciauskas, Max Ploner, Alan Akbik |  |
| 1743 |  |  [Argument-Aware Approach To Event Linking](https://doi.org/10.18653/v1/2024.findings-acl.758) |  | 0 | Event linking connects event mentions in text with relevant nodes in a knowledge base (KB). Prior research in event linking has mainly borrowed methods from entity linking, overlooking the distinct features of events. Compared to the extensively explored entity linking task, events have more... | IHung Hsu, Zihan Xue, Nilay Pochhi, Sahil Bansal, Prem Natarajan, Jayanth Srinivasa, Nanyun Peng |  |
| 1744 |  |  [CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation](https://doi.org/10.18653/v1/2024.findings-acl.759) |  | 0 | Grounded generation aims to equip language models (LMs) with the ability to produce more credible and accountable responses by accurately citing verifiable sources. However, existing methods, by either feeding LMs with raw or preprocessed materials, remain prone to errors. To address this, we... | IHung Hsu, Zifeng Wang, Long T. Le, Lesly Miculicich, Nanyun Peng, ChenYu Lee, Tomas Pfister |  |
| 1745 |  |  [TextEE: Benchmark, Reevaluation, Reflections, and Future Challenges in Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.760) |  | 0 | Event extraction has gained considerable interest due to its wide-ranging applications. However, recent studies draw attention to evaluation issues, suggesting that reported scores may not accurately reflect the true performance. In this work, we identify and address evaluation challenges,... | KuanHao Huang, IHung Hsu, Tanmay Parekh, Zhiyu Xie, Zixuan Zhang, Prem Natarajan, KaiWei Chang, Nanyun Peng, Heng Ji |  |
| 1746 |  |  [Understanding the Impacts of Language Technologies' Performance Disparities on African American Language Speakers](https://doi.org/10.18653/v1/2024.findings-acl.761) |  | 0 | This paper examines the experiences of African American Language (AAL) speakers when using language technologies. Previous work has used quantitative methods to uncover performance disparities between AAL speakers and White Mainstream English speakers when using language technologies, but has not... | Jay Cunningham, Su Lin Blodgett, Michael Madaio, Hal Daumé III, Christina Harrington, Hanna M. Wallach |  |
| 1747 |  |  [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://doi.org/10.18653/v1/2024.findings-acl.762) |  | 0 | The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of... | Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen Lin, Jie Fu, Wenhu Chen, Xiang Yue |  |
| 1748 |  |  [Measuring and Addressing Indexical Bias in Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.763) |  | 0 | Information Retrieval (IR) systems are designed to deliver relevant content, but traditional systems may not optimize rankings for fairness, neutrality, or the balance of ideas. Consequently, IR can often introduce indexical biases, or biases in the positional order of documents. Although indexical... | Caleb Ziems, William Held, Jane DwivediYu, Diyi Yang |  |
| 1749 |  |  [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://doi.org/10.18653/v1/2024.findings-acl.764) |  | 0 | Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, leading to inherent biases toward Western culture. This bias... | Zaid Alyafeai, Khalid Almubarak, Ahmed Ashraf, Deema Alnuhait, Saied Alshahrani, Gubran A. Q. Abdulrahman, Gamil Ahmed, Qais Gawah, Zead Saleh, Mustafa Ghaleb, Yousef Ali, Maged Saeed AlShaibani |  |
| 1750 |  |  [RadGraph-XL: A Large-Scale Expert-Annotated Dataset for Entity and Relation Extraction from Radiology Reports](https://doi.org/10.18653/v1/2024.findings-acl.765) |  | 0 | In order to enable extraction of structured clinical data from unstructured radiology reports, we introduce RadGraph-XL, a large-scale, expert-annotated dataset for clinical entity and relation extraction. RadGraph-XL consists of 2,300 radiology reports, which are annotated with over 410,000... | JeanBenoit Delbrouck, Pierre J. Chambon, Zhihong Chen, Maya Varma, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Tan Bui, Steven Quoc Hung Truong, Curtis P. Langlotz |  |
| 1751 |  |  [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.766) |  | 0 | Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance... | H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia, Ganesh Ramakrishnan |  |
| 1752 |  |  [Selective "Selective Prediction": Reducing Unnecessary Abstention in Vision-Language Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.767) |  | 0 | Selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain... | Tejas Srinivasan, Jack Hessel, Tanmay Gupta, Bill Yuchen Lin, Yejin Choi, Jesse Thomason, Khyathi Raghavi Chandu |  |
| 1753 |  |  [Language Model Priors and Data Augmentation Strategies for Low-resource Machine Translation: A Case Study Using Finnish to Northern Sámi](https://doi.org/10.18653/v1/2024.findings-acl.768) |  | 0 | We investigate ways of using monolingual data in both the source and target languages for improving low-resource machine translation. As a case study, we experiment with translation from Finnish to Northern Sámi.Our experiments show that while conventional backtranslation remains a strong... | Jonne Sälevä, Constantine Lignos |  |
| 1754 |  |  [Differentially Private Knowledge Distillation via Synthetic Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.769) |  | 0 | Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy puts pressure on practitioners to train LLMs with Differential Privacy (DP) on private data. Concurrently, the exponential growth in parameter... | James Flemings, Murali Annavaram |  |
| 1755 |  |  [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](https://doi.org/10.18653/v1/2024.findings-acl.770) |  | 0 | Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on... | Fangyuan Xu, Kyle Lo, Luca Soldaini, Bailey Kuehl, Eunsol Choi, David Wadden |  |
| 1756 |  |  [XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the Multilingual Generation of News Headlines and Tags](https://doi.org/10.18653/v1/2024.findings-acl.771) |  | 0 | Millions of news articles published online daily can overwhelm readers. Headlines and entity (topic) tags are essential for guiding readers to decide if the content is worth their time. While headline generation has been extensively studied, tag generation remains largely unexplored, yet it offers... | Faisal Tareque Shohan, Mir Tafseer Nayeem, Samsul Islam, Abu Ubaida Akash, Shafiq Joty |  |
| 1757 |  |  [InFoBench: Evaluating Instruction Following Ability in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.772) |  | 0 | This paper introduces the Decomposed Requirements Following Ratio (DRFR), a new metric for evaluating Large Language Models’ (LLMs) ability to follow instructions. Addressing a gap in current methodologies, DRFR breaks down complex instructions into simpler criteria, facilitating a detailed... | Yiwei Qin, Kaiqiang Song, Yebowen Hu, Wenlin Yao, Sangwoo Cho, Xiaoyang Wang, Xuansheng Wu, Fei Liu, Pengfei Liu, Dong Yu |  |
| 1758 |  |  [EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.773) |  | 0 | Large Language Models (LLMs) have achieved state-of-the-art performance in text re-ranking. This process includes queries and candidate passages in the prompts, utilizing pointwise, listwise, and pairwise prompting strategies. A limitation of these ranking strategies with LLMs is their cost: the... | Muhammad Shihab Rashid, Jannat Ara Meem, Yue Dong, Vagelis Hristidis |  |
| 1759 |  |  [FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.774) |  | 0 | We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction... | Gagan Bhatia, El Moatez Billah Nagoudi, Hasan Cavusoglu, Muhammad AbdulMageed |  |
| 1760 |  |  [Aligning Large Multimodal Models with Factually Augmented RLHF](https://doi.org/10.18653/v1/2024.findings-acl.775) |  | 0 | Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in “hallucination”, generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement... | Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liangyan Gui, YuXiong Wang, Yiming Yang, Kurt Keutzer, Trevor Darrell |  |
| 1761 |  |  [The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness](https://doi.org/10.18653/v1/2024.findings-acl.776) |  | 0 | As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research. This has resulted in the development of various LLM defense strategies. Unfortunately, despite the shared goal of improving the... | Neeraj Varshney, Pavel Dolin, Agastya Seth, Chitta Baral |  |
| 1762 |  |  [PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering](https://doi.org/10.18653/v1/2024.findings-acl.777) |  | 0 | Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. ‘Who was the US president in 1970?’). Little work has studied questions whose temporal context is relative to the present time (e.g. ‘Who was the previous US... | Jannat Ara Meem, Muhammad Shihab Rashid, Yue Dong, Vagelis Hristidis |  |
| 1763 |  |  [360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](https://doi.org/10.18653/v1/2024.findings-acl.778) |  | 0 |  | Shen Gao, Hao Li, Zhengliang Shi, Chengrui Huang, Quan Tu, Shuo Shang, Zhiliang Tian, Minlie Huang |  |
| 1764 |  |  [Extracting Polymer Nanocomposite Samples from Full-Length Documents](https://doi.org/10.18653/v1/2024.findings-acl.779) |  | 0 | This paper investigates the use of large language models (LLMs) for extracting sample lists of polymer nanocomposites (PNCs) from full-length materials science research papers. The challenge lies in the complex nature of PNC samples, which have numerous attributes scattered throughout the text. The... | Ghazal Khalighinejad, Defne Circi, L. Catherine Brinson, Bhuwan Dhingra |  |
| 1765 |  |  [Leveraging LLM Reasoning Enhances Personalized Recommender Systems](https://doi.org/10.18653/v1/2024.findings-acl.780) |  | 0 |  | Alicia Tsai, Adam Kraft, Long Jin, Chenwei Cai, Anahita Hosseini, Taibai Xu, Zemin Zhang, Lichan Hong, Ed Huaihsin Chi, Xinyang Yi |  |
| 1766 |  |  [Toucan: Many-to-Many Translation for 150 African Language Pairs](https://doi.org/10.18653/v1/2024.findings-acl.781) |  | 0 | We address a notable gap in Natural Language Processing (NLP) by introducing a collection of resources designed to improve Machine Translation (MT) for low-resource languages, with a specific focus on African languages. First, We introduce two language models (LMs), Cheetah-1.2B and Cheetah-3.7B,... | AbdelRahim A. Elmadany, Ife Adebara, Muhammad AbdulMageed |  |
| 1767 |  |  [Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.782) |  | 0 | We consider the task of building a dialogue system that can motivate users to adopt positive lifestyle changes, Motivational Interviewing (MI). Addressing such a task requires a system that could infer how to motivate the user effectively. We propose DIIR, a framework that is capable of learning... | Zhouhang Xie, Bodhisattwa Prasad Majumder, Mengjie Zhao, Yoshinori Maeda, Keiichi Yamada, Hiromi Wakaki, Julian J. McAuley |  |
| 1768 |  |  [Evaluating Structural Generalization in Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.783) |  | 0 | Compositional generalization refers to the ability to generalize to novel combinations of previously observed words and syntactic structures.Since it is regarded as a desired property of neural models, recent work has assessed compositional generalization in machine translation as well as semantic... | Ryoma Kumon, Daiki Matsuoka, Hitomi Yanaka |  |
| 1769 |  |  [Figuratively Speaking: Authorship Attribution via Multi-Task Figurative Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.784) |  | 0 | The identification of Figurative Language (FL) features in text is crucial for various Natural Language Processing (NLP) tasks, where understanding of the author’s intended meaning and its nuances is key for successful communication. At the same time, the use of a specific blend of various FL forms... | Gregorios A. Katsios, Ning Sa, Tomek Strzalkowski |  |
| 1770 |  |  [CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.785) |  | 0 | Recent large language models (LLMs) have shown indications of mathematical reasoning ability on challenging competition-level problems, especially with self-generated verbalizations of intermediate reasoning steps (i.e., chain-of-thought prompting). However, current evaluations mainly focus on the... | Yujun Mao, Yoon Kim, Yilun Zhou |  |
| 1771 |  |  [Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.786) |  | 0 | Contemporary translation engines based on the encoder-decoder framework have made significant strides in development.However, the emergence of Large Language Models (LLMs) has disrupted their position by presenting the potential for achieving superior translation quality.To uncover the... | Jiali Zeng, Fandong Meng, Yongjing Yin, Jie Zhou |  |
| 1772 |  |  [Integrating Pre-Trained Speech and Language Models for End-to-End Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.787) |  | 0 | Advances in machine learning have made it possible to perform various text and speech processing tasks, such as automatic speech recognition (ASR), in an end-to-end (E2E) manner. E2E approaches utilizing pre-trained models are gaining attention for conserving training data and resources. However,... | Yukiya Hono, Koh Mitsuda, Tianyu Zhao, Kentaro Mitsui, Toshiaki Wakatsuki, Kei Sawada |  |
| 1773 |  |  [Proving membership in LLM pretraining data via data watermarks](https://doi.org/10.18653/v1/2024.findings-acl.788) |  | 0 | Detecting whether copyright holders’ works were used in LLM pretraining is poised to be an important problem. This work proposes using data watermarks to enable principled detection with only black-box model access, provided that the rightholder contributed multiple training documents and... | Johnny TianZheng Wei, Ryan Yixiang Wang, Robin Jia |  |
| 1774 |  |  [Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses](https://doi.org/10.18653/v1/2024.findings-acl.789) |  | 0 | Detecting hallucinations in large language model (LLM) outputs is pivotal, yet traditional fine-tuning for this classification task is impeded by the expensive and quickly outdated annotation process, especially across numerous vertical domains and in the face of rapid LLM advancements. In this... | Dongxu Zhang, Varun Gangal, Barrett Martin Lattimer, Yi Yang |  |
| 1775 |  |  [SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC](https://doi.org/10.18653/v1/2024.findings-acl.790) |  | 0 |  | Jinglong Luo, Yehong Zhang, Zhuo Zhang, Jiaqi Zhang, Xin Mu, Hui Wang, Yue Yu, Zenglin Xu |  |
| 1776 |  |  [Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications](https://doi.org/10.18653/v1/2024.findings-acl.791) |  | 0 | With the proliferation of LLM-integrated applications such as GPT-s, millions are deployed, offering valuable services through proprietary instruction prompts. These systems, however, are prone to prompt extraction attacks through meticulously designed queries. To help mitigate this problem, we... | Junlin Wang, Tianyi Yang, Roy Xie, Bhuwan Dhingra |  |
| 1777 |  |  [History-Aware Conversational Dense Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.792) |  | 0 | Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In... | Fengran Mo, Chen Qu, Kelong Mao, Tianyu Zhu, Zhan Su, Kaiyu Huang, JianYun Nie |  |
| 1778 |  |  [Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.793) |  | 0 | Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various downstream tasks. However, scaling them up is challenging because building large-scale MMKGs often introduces mismatched images (i.e., noise). Most entities in KGs belong to the long tail, meaning there are few images of them... | Yikai Zhang, Qianyu He, Xintao Wang, Siyu Yuan, Jiaqing Liang, Yanghua Xiao |  |
| 1779 |  |  [ZeroStance: Leveraging ChatGPT for Open-Domain Stance Detection via Dataset Generation](https://doi.org/10.18653/v1/2024.findings-acl.794) |  | 0 | Zero-shot stance detection that aims to detect the stance (typically against, favor, or neutral) towards unseen targets has attracted considerable attention. However, most previous studies only focus on targets from a single or limited text domains (e.g., financial domain), and thus zero-shot... | Chenye Zhao, Yingjie Li, Cornelia Caragea, Yue Zhang |  |
| 1780 |  |  [Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.795) |  | 0 | Large language models (LLMs) are very proficient text generators. We leverage this capability of LLMs to generate task-specific data via zero-shot prompting and promote cross-lingual transfer for low-resource target languages. Given task-specific data in a source language and a teacher model... | Barah Fazili, Ashish Agrawal, Preethi Jyothi |  |
| 1781 |  |  [Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.796) |  | 0 | Learning multi-task models for jointly detecting stance and verifying rumors poses challenges due to the need for training data of stance at post level and rumor veracity at claim level, which are difficult to obtain. To address this issue, we leverage large language models (LLMs) as the foundation... | Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, Bo Wang |  |
| 1782 |  |  [Exploring the Potential of Dense Information in Multimodal Alignment](https://doi.org/10.18653/v1/2024.findings-acl.797) |  | 0 | Despite the success of data augmentation in improving CLIP model, existing methods that utilize LLM or SAM to enrich the information in captions still suffer from several limitations, including insufficient detail and excessive hallucinations, ultimately resulting in compromised alignment and... | Zhiyuan Fan, Zhihong Chen, Benyou Wang |  |
| 1783 |  |  [Referral Augmentation for Zero-Shot Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.798) |  | 0 | We propose Referral-Augmented Retrieval (RAR), a simple technique that concatenates document indices with referrals: text from other documents that cite or link to the given document. We find that RAR provides significant performance gains for tasks across paper retrieval, entity retrieval, and... | Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan |  |
| 1784 |  |  [InstructEval: Instruction-Tuned Text Evaluator from Human Preference](https://doi.org/10.18653/v1/2024.findings-acl.799) |  | 0 | This paper explores to construct a general text evaluator based on open-source Large Language Models (LLMs), a domain predominantly occupied by commercial counterparts such as GPT-4. Recognizing the limitations of open-source models like Llama in evaluative tasks, we introduce InstructEval, a... | Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li |  |
| 1785 |  |  [A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models](https://doi.org/10.18653/v1/2024.findings-acl.800) |  | 0 | Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done only after fine-tuning the models and ignoring the training data. In this... | Cuong Dang, Dung D. Le, Thai Le |  |
| 1786 |  |  [InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment](https://doi.org/10.18653/v1/2024.findings-acl.801) |  | 0 | Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment.... | Jianing Wang, Junda Wu, Yupeng Hou, Yao Liu, Ming Gao, Julian J. McAuley |  |
| 1787 |  |  [RaDA: Retrieval-augmented Web Agent Planning with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.802) |  | 0 | Agents powered by large language models (LLMs) inherit important limitations, such as the restricted context length, dependency on human-engineered exemplars (e.g., for task decomposition), and insufficient generalization. To address these challenges, we propose RaDA, a novel planning method for... | Minsoo Kim, Victor S. Bursztyn, Eunyee Koh, Shunan Guo, Seungwon Hwang |  |
| 1788 |  |  [Competition-Level Problems are Effective LLM Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.803) |  | 0 | Large language models (LLMs) have demonstrated impressive reasoning capabilities, yet there is ongoing debate about these abilities and the potential data contamination problem recently. This paper aims to evaluate the reasoning capacities of LLMs, specifically in solving recent competition-level... | Yiming Huang, Zhenghao Lin, Xiao Liu, Yeyun Gong, Shuai Lu, Fangyu Lei, Yaobo Liang, Yelong Shen, Chen Lin, Nan Duan, Weizhu Chen |  |
| 1789 |  |  [Large Language Models for Automated Open-domain Scientific Hypotheses Discovery](https://doi.org/10.18653/v1/2024.findings-acl.804) |  | 0 | Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are... | Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, Erik Cambria |  |
| 1790 |  |  [GRADUAL: Granularity-aware Dual Prototype Learning for Better Few-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.805) |  | 0 | Recent studies have shown that fusing text labels and context sentences is an effective method for learning prototype representations in few-shot relation extraction. However, the \*\*inconsistency of prototype representations\*\* across different few-shot tasks persists due to different context... | Zhiming Li, Yuchen Lyu |  |
| 1791 |  |  [Training a Better Chinese Spelling Correction Model via Prior-knowledge Guided Teacher](https://doi.org/10.18653/v1/2024.findings-acl.806) |  | 0 | Recent advancements in Chinese Spelling Correction (CSC) predominantly leverage pre-trained language models (PLMs). However, a notable challenge with fine-tuned PLM-based CSC models is their tendency to over-correct, leading to poor generalization for error patterns outside the standard... | Chi Wei, Shaobin Huang, Rongsheng Li, Naiyu Yan, Rui Wang |  |
| 1792 |  |  [The Revolution of Multimodal Large Language Models: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.807) |  | 0 | Connecting text and visual modalities plays an essential role in generative intelligence. For this reason, inspired by the success of large language models, significant research efforts are being devoted to the development of Multimodal Large Language Models (MLLMs). These models can seamlessly... | Davide Caffagni, Federico Cocchi, Luca Barsellotti, Nicholas Moratelli, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara |  |
| 1793 |  |  [OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.808) |  | 0 | Advancing automated programming necessitates robust and comprehensive code generation benchmarks, yet current evaluation frameworks largely neglect object-oriented programming (OOP) in favour of functional programming (FP), e.g., HumanEval and MBPP. To address this, our study introduces a... | Shuai Wang, Liang Ding, Li Shen, Yong Luo, Bo Du, Dacheng Tao |  |
| 1794 |  |  [Code Needs Comments: Enhancing Code LLMs with Comment Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.809) |  | 0 | The programming skill is one crucial ability for Large Language Models (LLMs), necessitating a deep understanding of programming languages (PLs) and their correlation with natural languages (NLs). We examine the impact of pre-training data on code-focused LLMs’ performance by assessing the comment... | Demin Song, Honglin Guo, Yunhua Zhou, Shuhao Xing, Yudong Wang, Zifan Song, Wenwei Zhang, Qipeng Guo, Hang Yan, Xipeng Qiu, Dahua Lin |  |
| 1795 |  |  [Efficient Domain Adaptation for Non-Autoregressive Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.810) |  | 0 | Domain adaptation remains a challenge in the realm of Neural Machine Translation (NMT), even in the era of large language models (LLMs). Existing non-parametric approaches like nearest neighbor machine translation have made small Autoregressive Translation (AT) models achieve efficient domain... | Wangjie You, Pei Guo, Juntao Li, Kehai Chen, Min Zhang |  |
| 1796 |  |  [Exploring Reversal Mathematical Reasoning Ability for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.811) |  | 0 | Large language models (LLMs) have presented remarkable capabilities in the wide range of natural language understanding and reasoning tasks. Despite their success, a few works indicate that LLMs suffer from the “reversal curse”, in which LLMs can’t employ the inverted structure “B is A” when they... | Pei Guo, Wangjie You, Juntao Li, Bowen Yan, Min Zhang |  |
| 1797 |  |  [A Unified Joint Approach with Topological Context Learning and Rule Augmentation for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.812) |  | 0 | Knowledge graph completion (KGC) task is to infer the missing knowledge in the knowledge graph based on known factual triples. However, present KGC approaches still face the following two challenges. Those methods perform simple linear update on relation representation, and only local neighborhood... | Jingtao Guo, Chunxia Zhang, Lingxi Li, Xiaojun Xue, Zhendong Niu |  |
| 1798 |  |  [FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.813) |  | 0 | Since most large language models (LLMs) are trained once and never updated, they struggle to dynamically adapt to our ever-changing world. In this work, we present FreshQA, a dynamic QA benchmark that tests a model’s ability to answer questions that may require reasoning over up-to-date world... | Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry W. Wei, Jason Wei, Chris Tar, YunHsuan Sung, Denny Zhou, Quoc V. Le, Thang Luong |  |
| 1799 |  |  [ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.814) |  | 0 | With the development of instruction-tuned large language models (LLMs), improving the safety of LLMs has become more critical. However, the current approaches for aligning the LLMs output with expected safety usually require substantial training efforts, e.g., high-quality safety data and expensive... | Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao |  |
| 1800 |  |  [CR-LLM: A Dataset and Optimization for Concept Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.815) |  | 0 | Concept reasoning is an important capability for models to understand the world. However, the existing datasets, such as concept extraction and concept generation, suffer from modeledge leakage and context leakage. To address these limitations, we construct a dataset of concept reasoning for large... | Nianqi Li, Jingping Liu, Sihang Jiang, Haiyun Jiang, Yanghua Xiao, Jiaqing Liang, Zujie Liang, Feng Wei, Jinglei Chen, Zhenghong Hao, Bing Han |  |
| 1801 |  |  [DATA-CUBE: Data Curriculum for Instruction-based Sentence Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.816) |  | 0 | Recently, multi-task instruction tuning has been utilized to improve sentence representation learning (SRL). It enables SRL models to generate task-specific representations with the guidance of task instruction, thus exhibiting strong generalization ability on unseen tasks. However, these methods... | Yingqian Min, Kun Zhou, Dawei Gao, Xin Zhao, He Hu, Yaliang Li |  |
| 1802 |  |  [Combating Label Sparsity in Short Text Topic Modeling via Nearest Neighbor Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.817) |  | 0 | Extracting semantic topics from short texts presents a significant challenge in the field of data mining. While efforts have been made to mitigate data sparsity issue, the limited length of short documents also results in the absence of semantically relevant words, causing biased evidence lower... | Yang Lin, Xinyu Ma, Xin Gao, Ruiqing Li, Yasha Wang, Xu Chu |  |
| 1803 |  |  [RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.818) |  | 0 | The application scope of large language models (LLMs) is increasingly expanding. In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback. Whether the model can appropriately respond to users’... | Jianhao Yan, Yun Luo, Yue Zhang |  |
| 1804 |  |  [Complex Logical Query Answering by Calibrating Knowledge Graph Completion Models](https://doi.org/10.18653/v1/2024.findings-acl.819) |  | 0 | Complex logical query answering (CLQA) is a challenging task that involves finding answer entities for complex logical queries over incomplete knowledge graphs (KGs). Previous research has explored the use of pre-trained knowledge graph completion (KGC) models, which can predict the missing facts... | Changyi Xiao, Yixin Cao |  |
| 1805 |  |  [Argument-Based Sentiment Analysis on Forward-Looking Statements](https://doi.org/10.18653/v1/2024.findings-acl.820) |  | 0 | This paper introduces a novel approach to analyzing the forward-looking statements in equity research reports by integrating argument mining with sentiment analysis. Recognizing the limitations of traditional models in capturing the nuances of future-oriented analysis, we propose a refined... | ChinYi Lin, ChungChi Chen, HenHsen Huang, HsinHsi Chen |  |
| 1806 |  |  [Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.821) |  | 0 | Large language models (LLMs) have showcased their remarkable capabilities to handle various downstream tasks, including multilingual machine translation ability. Despite their impressive performance, decoder-only LLMs lack an explicit alignment between source and target contexts, leading to... | Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang |  |
| 1807 |  |  [Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion](https://doi.org/10.18653/v1/2024.findings-acl.822) |  | 0 | Block Diagrams play an essential role in visualizing the relationships between components or systems. Generating summaries of block diagrams is important for document understanding or question answering (QA) tasks by providing concise overviews of complex systems. However, it’s a challenging task... | Shreyanshu Bhushan, EunSoo Jung, Minho Lee |  |
| 1808 |  |  [MultiSQL: A Schema-Integrated Context-Dependent Text2SQL Dataset with Diverse SQL Operations](https://doi.org/10.18653/v1/2024.findings-acl.823) |  | 0 | Text2SQL is a task that translates natural language into SQL statements. Context-dependent Text2SQL offers a more natural database interaction by simulating dialogues between users and databases, with CoSQL and SparC as representative datasets. Yet, these datasets struggle to accurately replicate... | Chunhui Li, Yifan Wang, Zhen Wu, Zhen Yu, Fei Zhao, Shujian Huang, Xinyu Dai |  |
| 1809 |  |  [Towards Demonstration-Aware Large Language Models for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.824) |  | 0 | Tuning-based large language models for machine translation (aka large translation model, LTM) have demonstrated significant performance in the field of machine translation. Despite their success, these models often face difficulties in leveraging demonstrations to further improve their performance.... | Chen Li, Meishan Zhang, Xuebo Liu, Zhaocong Li, Derek F. Wong, Min Zhang |  |
| 1810 |  |  [DADA: Distribution-Aware Domain Adaptation of PLMs for Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.825) |  | 0 | Pre-trained language models (PLMs) exhibit promise in retrieval tasks but struggle with out-of-domain data due to distribution shifts.Addressing this, generative domain adaptation (DA), known as GPL, tackles distribution shifts by generating pseudo queries and labels to train models for predicting... | Dohyeon Lee, Jongyoon Kim, Seungwon Hwang, Joonsuk Park |  |
| 1811 |  |  [LLMs cannot find reasoning errors, but can correct them given the error location](https://doi.org/10.18653/v1/2024.findings-acl.826) |  | 0 | While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023b; Madaan et al.,2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang... | Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter Chen, Tony Mak |  |
| 1812 |  |  [Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL translation](https://doi.org/10.18653/v1/2024.findings-acl.827) |  | 0 | Understanding textual description to generate code seems to be an achieved capability of instruction-following Large Language Models (LLMs) in zero-shot scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and... | Federico Ranaldi, Elena Sofia Ruzzetti, Dario Onorati, Leonardo Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli, Fabio Massimo Zanzotto |  |
| 1813 |  |  [ChartCheck: Explainable Fact-Checking over Real-World Chart Images](https://doi.org/10.18653/v1/2024.findings-acl.828) |  | 0 | Whilst fact verification has attracted substantial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key... | Mubashara Akhtar, Nikesh Subedi, Vivek Gupta, Sahar Tahmasebi, Oana Cocarascu, Elena Simperl |  |
| 1814 |  |  [Real World Conversational Entity Linking Requires More Than Zero-Shots](https://doi.org/10.18653/v1/2024.findings-acl.829) |  | 0 | Entity linking (EL) in conversations faces notable challenges in practical applications, primarily due to scarcity of entity-annotated conversational datasets and sparse knowledge bases (KB) containing domain-specific, long-tail entities. We designed targeted evaluation scenarios to measure the... | Mohanna Hoveyda, Arjen P. de Vries, Faegheh Hasibi, Maarten de Rijke |  |
| 1815 |  |  [CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling](https://doi.org/10.18653/v1/2024.findings-acl.830) |  | 0 | Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting... | Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei Zhu, Di Yang, Jiahao Zhao, Guancheng Ye, Chengming Li, Xiping Hu |  |
| 1816 |  |  [Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech](https://doi.org/10.18653/v1/2024.findings-acl.831) |  | 0 | Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide... | Neemesh Yadav, Sarah Masud, Vikram Goyal, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 1817 |  |  [TextGenSHAP: Scalable Post-Hoc Explanations in Text Generation with Long Documents](https://doi.org/10.18653/v1/2024.findings-acl.832) |  | 0 | Large language models (LLMs) have attracted great interest in many real-world applications; however, their “black-box” nature necessitates scalable and faithful explanations. Shapley values have matured as an explainability method for deep learning, but extending them to LLMs is difficult due to... | James Enouen, Hootan Nakhost, Sayna Ebrahimi, Sercan Ö. Arik, Yan Liu, Tomas Pfister |  |
| 1818 |  |  [Balanced Data Sampling for Language Model Training with Clustering](https://doi.org/10.18653/v1/2024.findings-acl.833) |  | 0 | Data plays a fundamental role in the training of Large Language Models (LLMs). While attention has been paid to the collection and composition of datasets, determining the data sampling strategy in training remains an open question. Most LLMs are trained with a simple strategy, random sampling.... | Yunfan Shao, Linyang Li, Zhaoye Fei, Hang Yan, Dahua Lin, Xipeng Qiu |  |
| 1819 |  |  [Length Generalization of Causal Transformers without Position Encoding](https://doi.org/10.18653/v1/2024.findings-acl.834) |  | 0 | Generalizing to longer sentences is important for recent Transformer-based language models. Besides algorithms manipulating explicit position features, the success of Transformers without position encodings (NoPE) provides a new way to overcome the challenge. In this paper, we study the length... | Jie Wang, Tao Ji, Yuanbin Wu, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang, Xiaoling Wang |  |
| 1820 |  |  [Unsupervised Sign Language Translation and Generation](https://doi.org/10.18653/v1/2024.findings-acl.835) |  | 0 | Motivated by the success of unsupervised neural machine translation (UNMT), we introduce an unsupervised sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data. USLNet comprises two main... | Zhengsheng Guo, Zhiwei He, Wenxiang Jiao, Xing Wang, Rui Wang, Kehai Chen, Zhaopeng Tu, Yong Xu, Min Zhang |  |
| 1821 |  |  [Mitigating Data Scarcity in Semantic Parsing across Languages with the Multilingual Semantic Layer and its Dataset](https://doi.org/10.18653/v1/2024.findings-acl.836) |  | 0 | Data scarcity is a prevalent challenge in the era of Large Language Models (LLMs). The insatiable hunger of LLMs for large corpora becomes even more pronounced when dealing with non-English and low-resource languages. The issue is particularly exacerbated in Semantic Parsing (SP), i.e. the task of... | Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Karim Ghonim, Lu Xu, HeeSoo Choi, Alberte FernándezCastro, Roberto Navigli |  |
| 1822 |  |  [Efficient Sparse Attention needs Adaptive Token Release](https://doi.org/10.18653/v1/2024.findings-acl.837) |  | 0 |  | Chaoran Zhang, Lixin Zou, Dan Luo, Xiangyang Luo, Zihao Li, Min Tang, Chenliang Li |  |
| 1823 |  |  [Learning Fine-Grained Grounded Citations for Attributed Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.838) |  | 0 | Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations. Attributed LLMs, which augment generated text with in-line citations, demonstrate potential in mitigating hallucinations and improving verifiability. However, current... | Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin |  |
| 1824 |  |  [ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget](https://doi.org/10.18653/v1/2024.findings-acl.839) |  | 0 | Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in a wide range of applications. In this paper, we propose ReLiK, a Retriever-Reader architecture for both EL and RE, where, given an input text, the Retriever... | Riccardo Orlando, PereLluís Huguet Cabot, Edoardo Barba, Roberto Navigli |  |
| 1825 |  |  [Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery](https://doi.org/10.18653/v1/2024.findings-acl.840) |  | 0 | In Conversational Intent Discovery (CID), Small Language Models (SLMs) struggle with overfitting to familiar intents and fail to label newly discovered ones. This issue stems from their limited grasp of semantic nuances and their intrinsically discriminative framework. Therefore, we propose... | Jinggui Liang, Lizi Liao, Hao Fei, Jing Jiang |  |
| 1826 |  |  [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](https://doi.org/10.18653/v1/2024.findings-acl.841) |  | 0 | Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In... | Alessandro Scirè, Karim Ghonim, Roberto Navigli |  |
| 1827 |  |  [Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.842) |  | 0 | Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy generates some low-probability text, resulting in low-quality... | Wenqing Chen, Weicheng Wang, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu |  |
| 1828 |  |  [Looking Right is Sometimes Right: Investigating the Capabilities of Decoder-only LLMs for Sequence Labeling](https://doi.org/10.18653/v1/2024.findings-acl.843) |  | 0 | Pre-trained language models based on masked language modeling (MLM) excel in natural language understanding (NLU) tasks. While fine-tuned MLM-based encoders consistently outperform causal language modeling decoders of comparable size, recent decoder-only large language models (LLMs) perform on par... | David Dukic, Jan Snajder |  |
| 1829 |  |  [mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans](https://doi.org/10.18653/v1/2024.findings-acl.844) |  | 0 | It is very challenging to curate a dataset for language-specific knowledge and common sense in order to evaluate natural language understanding capabilities of language models. Due to the limitation in the availability of annotators, most current multilingual datasets are created through... | Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |  |
| 1830 |  |  [Dual-Stage Multi-Task Syntax-Oriented Pre-Training for Syntactically Controlled Paraphrase Generation](https://doi.org/10.18653/v1/2024.findings-acl.845) |  | 0 | Syntactically Controlled Paraphrase Generation (SCPG), which aims at generating sentences having syntactic structures resembling given exemplars, is attracting more research efforts in recent years. We took an empirical survey on previous SCPG datasets and methods and found three tacitly approved... | Hongxu Liu, Xiaojie Wang, Jiashen Sun, Ke Zeng, Guanglu Wan |  |
| 1831 |  |  [Demonstration Augmentation for Zero-shot In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.846) |  | 0 | Large Language Models (LLMs) have demonstrated an impressive capability known as In-context Learning (ICL), which enables them to acquire knowledge from textual demonstrations without the need for parameter updates.However, many studies have highlighted that the model’s performance is sensitive to... | Yi Su, Yunpeng Tai, Yixin Ji, Juntao Li, Yan Bowen, Min Zhang |  |
| 1832 |  |  [Pushing the Limits of Zero-shot End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.847) |  | 0 | Data scarcity and the modality gap between the speech and text modalities are two major obstacles of end-to-end Speech Translation (ST) systems, thus hindering their performance. Prior work has attempted to mitigate these challenges by leveraging external MT data and optimizing distance metrics... | Ioannis Tsiamas, Gerard I. Gállego, José A. R. Fonollosa, Marta R. Costajussà |  |
| 1833 |  |  [NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.848) |  | 0 | Numeral systems and units of measurement are two conjoined topics in activities of human beings and have mutual effects with the languages expressing them. Currently, the evaluation of Large Language Models (LLMs) often involves mathematical reasoning, yet little attention is given to how minor... | Ancheng Xu, Minghuan Tan, Lei Wang, Min Yang, Ruifeng Xu |  |
| 1834 |  |  [On The Persona-based Summarization of Domain-Specific Documents](https://doi.org/10.18653/v1/2024.findings-acl.849) |  | 0 | In an ever-expanding world of domain-specific knowledge, the increasing complexity of consuming, and storing information necessitates the generation of summaries from large information repositories. However, every persona of a domain has different requirements of information and hence their... | Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku |  |
| 1835 |  |  [Evaluating Large Language Models for Health-related Queries with Presuppositions](https://doi.org/10.18653/v1/2024.findings-acl.850) |  | 0 | As corporations rush to integrate large language models (LLMs) it is critical that they provide factually accurate information, that is robust to any presuppositions that a user may express. In this work, we introduce UPHILL, a dataset consisting of health-related queries with varying degrees of... | Navreet Kaur, Monojit Choudhury, Danish Pruthi |  |
| 1836 |  |  [Word Sense Linking: Disambiguating Outside the Sandbox](https://doi.org/10.18653/v1/2024.findings-acl.851) |  | 0 | Word Sense Disambiguation (WSD) is the task of associating a word in a given context with its most suitable meaning among a set of possible candidates. While the task has recently witnessed renewed interest, with systems achieving performances above the estimated inter-annotator agreement, at the... | Andrei Stefan Bejgu, Edoardo Barba, Luigi Procopio, Alberte FernándezCastro, Roberto Navigli |  |
| 1837 |  |  [Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.852) |  | 0 | Memorisation is a natural part of learning from real-world data: neural models pick up on atypical input-output combinations and store those training examples in their parameter space. That this happens is well-known, but how and where are questions that remain largely unanswered. Given a... | Verna Dankers, Ivan Titov |  |
| 1838 |  |  [Towards Multi-Relational Multi-Hop Reasoning over Dense Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.853) |  | 0 | Temporal knowledge graph reasoning has emerged as a crucial task for answering time-dependent questions within a knowledge graph (KG).Despite tremendous progress, the present research is impeded by the sparsity of a temporal KG and an over-reliance on simple single-relational reasoning patterns. To... | Jian Liu, Zihe Liu, Xueqiang Lyu, Peng Jin, Jinan Xu |  |
| 1839 |  |  [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.854) |  | 0 | Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs.... | Weihang Su, Changyue Wang, Qingyao Ai, Yiran Hu, Zhijing Wu, Yujia Zhou, Yiqun Liu |  |
| 1840 |  |  [Progressive Tuning: Towards Generic Sentiment Abilities for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.855) |  | 0 | Understanding sentiment is arguably an advanced and important capability of AI agents in the physical world. In previous works, many efforts have been devoted to individual sentiment subtasks, without considering interrelated sentiment knowledge among these subtasks. Although some recent works... | Guiyang Hou, Yongliang Shen, Weiming Lu |  |
| 1841 |  |  [Fooling the Textual Fooler via Randomizing Latent Representations](https://doi.org/10.18653/v1/2024.findings-acl.856) |  | 0 | Despite outstanding performance in a variety of Natural Language Processing (NLP) tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Several attacks can even compromise the model without... | Duy C. Hoang, Nguyen HungQuang, Saurav Manchanda, Minlong Peng, KokSeng Wong, Khoa D. Doan |  |
| 1842 |  |  [Part-of-speech Tagging for Extremely Low-resource Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.857) |  | 0 | Modern natural language processing (NLP) systems thrive when given access to large datasets. However, a large fraction of the world’s languages are not privy to such benefits due to sparse documentation and inadequate digital representation. This is especially true for Indian regional languages. As... | Sanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 1843 |  |  [FOCUS: Forging Originality through Contrastive Use in Self-Plagiarism for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.858) |  | 0 | Pre-trained Language Models (PLMs) have shown impressive results in various Natural Language Generation (NLG) tasks, such as powering chatbots and generating stories. However, an ethical concern arises due to their potential to produce verbatim copies of paragraphs from their training data. This is... | Kaixin Lan, Tao Fang, Derek F. Wong, Yabo Xu, Lidia S. Chao, Cecilia G. Zhao |  |
| 1844 |  |  [Amanda: Adaptively Modality-Balanced Domain Adaptation for Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2024.findings-acl.859) |  | 0 | This paper investigates unsupervised multimodal domain adaptation for multimodal emotion recognition, which is a solution for data scarcity yet remains under studied. Due to the varying distribution discrepancies of different modalities between source and target domains, the primary challenge lies... | Xinxin Zhang, Jun Sun, Simin Hong, Taihao Li |  |
| 1845 |  |  [MedREQAL: Examining Medical Knowledge Recall of Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.860) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated an impressive ability to encode knowledge during pre-training on large text corpora. They can leverage this knowledge for downstream tasks like question answering (QA), even in complex areas involving health topics. Considering their... | Juraj Vladika, Phillip Schneider, Florian Matthes |  |
| 1846 |  |  [Deepfake Defense: Constructing and Evaluating a Specialized Urdu Deepfake Audio Dataset](https://doi.org/10.18653/v1/2024.findings-acl.861) |  | 0 | Deepfakes, particularly in the auditory domain, have become a significant threat, necessitating the development of robust countermeasures. This paper addresses the escalating challenges posed by deepfake attacks on Automatic Speaker Verification (ASV) systems. We present a novel Urdu deepfake audio... | Sheza Munir, Wassay Sajjad, Mukeet Raza, Emaan Abbas, Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza |  |
| 1847 |  |  [Leveraging Entailment Judgements in Cross-Lingual Summarisation](https://doi.org/10.18653/v1/2024.findings-acl.862) |  | 0 | Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to include document-summary pairs where the reference summary is unfaithful to the corresponding document as it contains content not supported by the document (i.e., hallucinated content). This low data quality misleads... | Huajian Zhang, Laura PerezBeltrachini |  |
| 1848 |  |  [Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.863) |  | 0 | In the field of information extraction (IE), tasks across a wide range of modalities and their combinations have been traditionally studied in isolation, leaving a gap in deeply recognizing and analyzing cross-modal information. To address this, this work for the first time introduces the concept... | Meishan Zhang, Hao Fei, Bin Wang, Shengqiong Wu, Yixin Cao, Fei Li, Min Zhang |  |
| 1849 |  |  [Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data](https://doi.org/10.18653/v1/2024.findings-acl.864) |  | 0 | The remarkable multimodal capabilities demonstrated by OpenAI’s GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human... | Yanda Li, Chi Zhang, Gang Yu, Wanqi Yang, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei |  |
| 1850 |  |  [Modeling Overregularization in Children with Small Language Models](https://doi.org/10.18653/v1/2024.findings-acl.865) |  | 0 | The imitation of the children’s language acquisition process has been explored to make language models (LMs) more efficient.In particular, errors caused by children’s regularization (so-called overregularization, e.g., using wroted for the past tense of write) have been widely studied to reveal the... | Akari Haga, Saku Sugawara, Akiyo Fukatsu, Miyu Oba, Hiroki Ouchi, Taro Watanabe, Yohei Oseki |  |
| 1851 |  |  [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.866) |  | 0 | Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as... | Zhu Liu, Cunliang Kong, Ying Liu, Maosong Sun |  |
| 1852 |  |  [Harnessing Large Language Models as Post-hoc Correctors](https://doi.org/10.18653/v1/2024.findings-acl.867) |  | 0 | As Machine Learning (ML) models grow in size and demand higher-quality training data, the expenses associated with re-training and fine-tuning these models are escalating rapidly. Inspired by recent impressive achievements of Large Language Models (LLMs) in different fields, this paper delves into... | Zhiqiang Zhong, Kuangyu Zhou, Davide Mottin |  |
| 1853 |  |  [Debatrix: Multi-dimensional Debate Judge with Iterative Chronological Analysis Based on LLM](https://doi.org/10.18653/v1/2024.findings-acl.868) |  | 0 | How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments.At the same time, current research mainly... | Jingcong Liang, Rong Ye, Meng Han, Ruofei Lai, Xinyu Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 1854 |  |  [CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment](https://doi.org/10.18653/v1/2024.findings-acl.869) |  | 0 | Language models trained on large-scale corpus often generate harmful responses that are harmful and contrary to human values. A prevalent approach for human alignment is reinforcement learning from human feedback (RLHF), utilizing algorithms such as proximal policy optimization (PPO). However,... | Jixiang Hong, Quan Tu, Changyu Chen, Gao Xing, Ji Zhang, Rui Yan |  |
| 1855 |  |  [Towards a new research agenda for multimodal enterprise document understanding: What are we missing?](https://doi.org/10.18653/v1/2024.findings-acl.870) |  | 0 | The field of multimodal document understanding has produced a suite of models that have achieved stellar performance across several tasks, even coming close to human performance on certain benchmarks. Nevertheless, the application of these models to real-world enterprise datasets remains... | Armineh Nourbakhsh, Sameena Shah, Carolyn P. Rosé |  |
| 1856 |  |  [CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.871) |  | 0 | An important unexplored aspect in previous work on user satisfaction estimation for Task-Oriented Dialogue (TOD) systems is their evaluation in terms of robustness for the identification of user dissatisfaction: current benchmarks for user satisfaction estimation in TOD systems are highly skewed... | Amin Abolghasemi, Zhaochun Ren, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke, Suzan Verberne |  |
| 1857 |  |  [Measuring Retrieval Complexity in Question Answering Systems](https://doi.org/10.18653/v1/2024.findings-acl.872) |  | 0 | In this paper, we investigate which questions are challenging for retrieval-based Question Answering (QA). We (i) propose retrieval complexity (RC), a novel metric conditioned on the completeness of retrieved documents, which measures the difficulty of answering questions, and (ii) propose an... | Matteo Gabburo, Nicolaas Paul Jedema, Siddhant Garg, Leonardo F. R. Ribeiro, Alessandro Moschitti |  |
| 1858 |  |  [Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media](https://doi.org/10.18653/v1/2024.findings-acl.873) |  | 0 | We introduce a hybrid abstractive summarisation approach combining hierarchical VAEs with LLMs to produce clinically meaningful summaries from social media user timelines, appropriate for mental health monitoring. The summaries combine two different narrative points of view: (a) clinical insights... | Jiayu Song, Jenny Chim, Adam Tsakalidis, Julia Ive, Dana AtzilSlonim, Maria Liakata |  |
| 1859 |  |  [PIXAR: Auto-Regressive Language Modeling in Pixel Space](https://doi.org/10.18653/v1/2024.findings-acl.874) |  | 0 | Recent work showed the possibility of building open-vocabulary large language models (LLMs) that directly operate on pixel representations. These models are implemented as autoencoders that reconstruct masked patches of rendered text.However, these pixel-based LLMs are limited to discriminative... | Yintao Tai, Xiyang Liao, Alessandro Suglia, Antonio Vergari |  |
| 1860 |  |  [Sparsity-Accelerated Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.875) |  | 0 | Large language models (LLMs) have demonstrated proficiency across various natural language processing (NLP) tasks but often require additional training, such as continual pre-training and supervised fine-tuning. However, the costs associated with this, primarily due to their large parameter count,... | Da Ma, Lu Chen, Pengyu Wang, Hongshen Xu, Hanqi Li, Liangtai Sun, Su Zhu, Shuai Fan, Kai Yu |  |
| 1861 |  |  [Preemptive Answer "Attacks" on Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.876) |  | 0 | Large language models (LLMs) showcase impressive reasoning capabilities when coupled with Chain-of-Thought (CoT) prompting. However, the robustness of this approach warrants further investigation. In this paper, we introduce a novel scenario termed preemptive answers, where the LLM obtains an... | Rongwu Xu, Zehan Qi, Wei Xu |  |
| 1862 |  |  [Do Language Models Exhibit Human-like Structural Priming Effects?](https://doi.org/10.18653/v1/2024.findings-acl.877) |  | 0 | We explore which linguistic factors—at the sentence and token level—play an important role in influencing language model predictions, and investigate whether these are reflective of results found in humans and human corpora (Gries and Kootstra, 2017). We make use of the structural priming... | Jaap Jumelet, Willem H. Zuidema, Arabella Sinclair |  |
| 1863 |  |  [RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.878) |  | 0 | The advent of Large Language Models (LLMs) has paved the way for complex tasks such as role-playing, which enhances user interactions by enabling models to imitate various characters. However, the closed-source nature of state-of-the-art LLMs and their general-purpose training limit role-playing... | Noah Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhao Huang, Jie Fu, Junran Peng |  |
| 1864 |  |  [LangSuit·E: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments](https://doi.org/10.18653/v1/2024.findings-acl.879) |  | 0 | Recent advances in Large Language Models (LLMs) have shown inspiring achievements in constructing autonomous agents that rely onlanguage descriptions as inputs. However, it remains unclear how well LLMs can function as few-shot or zero-shot embodied agents in dynamic interactive environments. To... | Zixia Jia, Mengmeng Wang, Baichen Tong, SongChun Zhu, Zilong Zheng |  |
| 1865 |  |  [Views Are My Own, but Also Yours: Benchmarking Theory of Mind Using Common Ground](https://doi.org/10.18653/v1/2024.findings-acl.880) |  | 0 | Evaluating the theory of mind (ToM) capabilities of language models (LMs) has recently received a great deal of attention. However, many existing benchmarks rely on synthetic data, which risks misaligning the resulting experiments with human behavior. We introduce the first ToM dataset based on... | Adil Soubki, John Murzaku, Arash Yousefi Jordehi, Peter Zeng, Magdalena Markowska, Seyed Abolghasem Mirroshandel, Owen Rambow |  |
| 1866 |  |  [MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.881) |  | 0 | Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other... | Divyanshu Aggarwal, Ashutosh Sathe, Ishaan Watts, Sunayana Sitaram |  |
| 1867 |  |  [MoE-SLU: Towards ASR-Robust Spoken Language Understanding via Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.882) |  | 0 | As a crucial task in the task-oriented dialogue systems, spoken language understanding (SLU) has garnered increasing attention. However, errors from automatic speech recognition (ASR) often hinder the performance of understanding. To tackle this problem, we propose MoE-SLU, an ASR-Robust SLU... | Xuxin Cheng, Zhihong Zhu, Xianwei Zhuang, Zhanpeng Chen, Zhiqi Huang, Yuexian Zou |  |
| 1868 |  |  [Multi-Task Transfer Matters During Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.883) |  | 0 | Instruction-tuning trains a language model on hundreds of tasks jointly to improve a model’s ability to learn in-context;however, the mechanisms that drive in-context learning are poorly understood and, as a result, the role of instruction-tuning on in-context generalization is poorly understood as... | David Mueller, Mark Dredze, Nicholas Andrews |  |
| 1869 |  |  [What Makes a Good Order of Examples in In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.884) |  | 0 | Although large language models (LLMs) have demonstrated impressive few-shot learning capabilities via in-context learning (ICL), ICL performance is known to be highly sensitive to the order of examples provided. To identify appropriate orders, recent studies propose heuristic methods to evaluate... | Qi Guo, Leiyu Wang, Yidong Wang, Wei Ye, Shikun Zhang |  |
| 1870 |  |  [BloomVQA: Assessing Hierarchical Multi-modal Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.885) |  | 0 | We propose a novel VQA dataset, BloomVQA, to facilitate comprehensive evaluation of large vision-language models on comprehension tasks. Unlike current benchmarks that often focus on fact-based memorization and simple reasoning tasks without theoretical grounding, we collect multiple-choice samples... | Yunye Gong, Robik Shrestha, Jared Claypoole, Michael Cogswell, Arijit Ray, Christopher Kanan, Ajay Divakaran |  |
| 1871 |  |  [AttributionBench: How Hard is Automatic Attribution Evaluation?](https://doi.org/10.18653/v1/2024.findings-acl.886) |  | 0 | Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence. However, evaluating the answer’s attribution, i.e., whether every claim within the generated responses is fully supported by its cited evidence, remains an open problem.... | Yifei Li, Xiang Yue, Zeyi Liao, Huan Sun |  |
| 1872 |  |  [Diffusion Guided Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.887) |  | 0 | Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language—ideally tailored towards each specific use case and target audience. For auto-regressive... | Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger |  |
| 1873 |  |  [InstructEd: Soft-Instruction Tuning for Model Editing with Hops](https://doi.org/10.18653/v1/2024.findings-acl.888) |  | 0 | The task of model editing becomes popular for correcting inaccurate or outdated parametric knowledge in Large Language Models (LLMs). However, there are major limitations of state of the art (SOTA) model editing methods, including the excessive memorization issue caused by the direct editing... | Xiaoqi Han, Ru Li, Xiaoli Li, Jiye Liang, Zifang Zhang, Jeff Z. Pan |  |
| 1874 |  |  [TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2024.findings-acl.889) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) leverages human preference data to train language models to align more closely with human essence. These human preference data, however, are labeled at the sequence level, creating a mismatch between sequence-level preference labels and tokens,... | Eunseop Yoon, Hee Suk Yoon, SooHwan Eom, Gunsoo Han, Daniel Wontae Nam, Daejin Jo, KyoungWoon On, Mark HasegawaJohnson, Sungwoong Kim, Chang Dong Yoo |  |
| 1875 |  |  [Found in the middle: Calibrating Positional Attention Bias Improves Long Context Utilization](https://doi.org/10.18653/v1/2024.findings-acl.890) |  | 0 | Large language models (LLMs), even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon has been known as the lost-in-the-middle problem. In this work, we make three contributions. First, we set out... | ChengYu Hsieh, YungSung Chuang, ChunLiang Li, Zifeng Wang, Long T. Le, Abhishek Kumar, James R. Glass, Alexander Ratner, ChenYu Lee, Ranjay Krishna, Tomas Pfister |  |
| 1876 |  |  [S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.891) |  | 0 | Traditional Dialogue State Tracking (DST) has focused on tracking preferences and intents in conversations centered around specific tasks (e.g. booking services). These conventional systems assume a relatively restricted conversation flow in which each turn gradually offers new information.... | Sarkar Snigdha Sarathi Das, Chirag Shah, Mengting Wan, Jennifer Neville, Longqi Yang, Reid Andersen, Georg Buscher, Tara Safavi |  |
| 1877 |  |  [Set the Clock: Temporal Alignment of Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.892) |  | 0 | Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call... | Bowen Zhao, Zander Brumbaugh, Yizhong Wang, Hannaneh Hajishirzi, Noah A. Smith |  |
| 1878 |  |  [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.893) |  | 0 | To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it’s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity... | Beyza Ermis, Luiza Pozzobon, Sara Hooker, Patrick Lewis |  |
| 1879 |  |  [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](https://doi.org/10.18653/v1/2024.findings-acl.894) |  | 0 | The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are... | Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu |  |
| 1880 |  |  [Enhancing Sentence Simplification in Portuguese: Leveraging Paraphrases, Context, and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.895) |  | 0 | Automatic text simplification focuses on transforming texts into a more comprehensible version without sacrificing their precision. However, automatic methods usually require (paired) datasets that can be rather scarce in languages other than English. This paper presents a new approach to automatic... | Arthur Scalercio, Maria José Finatto, Aline Paes |  |
| 1881 |  |  [How Far can 100 Samples Go? Unlocking Zero-Shot Translation with Tiny Multi-Parallel Data](https://doi.org/10.18653/v1/2024.findings-acl.896) |  | 0 | Zero-shot translation aims to translate between language pairs not seen during training in Multilingual Machine Translation (MMT) and is widely considered an open problem. A common, albeit resource-consuming, solution is to add as many related translation directions as possible to the training... | Di Wu, Shaomu Tan, Yan Meng, David Stap, Christof Monz |  |
| 1882 |  |  [Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study on Two Materials Dataset](https://doi.org/10.18653/v1/2024.findings-acl.897) |  | 0 | We explore the ability of GPT-4 to perform ad-hoc schema-based information extraction from scientific literature. We assess specifically whether it can, with a basic one-shot prompting approach over the full text of the included manusciprts, replicate two existing material science datasets, one... | Satanu Ghosh, Neal R. Brodnik, Carolina Frey, Collin Holgate, Tresa M. Pollock, Samantha H. Daly, Samuel Carton |  |
| 1883 |  |  [Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction](https://doi.org/10.18653/v1/2024.findings-acl.898) |  | 0 | Neural parameterization has significantly advanced unsupervised grammar induction. However, training these models with a traditional likelihood loss for all possible parses exacerbates two issues: 1) \*structural optimization ambiguity\* that arbitrarily selects one among structurally ambiguous... | Jinwook Park, Kangil Kim |  |
| 1884 |  |  [LMDX: Language Model-based Document Information Extraction and Localization](https://doi.org/10.18653/v1/2024.findings-acl.899) |  | 0 | Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art and exhibiting emergent capabilities across various tasks. However, their application in extracting information from visually rich documents, which is at the core of many document... | Vincent Perot, Kai Kang, Florian Luisier, Guolong Su, Xiaoyu Sun, Ramya Sree Boppana, Zilong Wang, Zifeng Wang, Jiaqi Mu, Hao Zhang, ChenYu Lee, Nan Hua |  |
| 1885 |  |  [DBQR-QA: A Question Answering Dataset on a Hybrid of Database Querying and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.900) |  | 0 | This paper introduces the Database Querying and Reasoning Dataset for Question Answering (DBQR-QA), aimed at addressing the gap in current question-answering (QA) research by emphasizing the essential processes of database querying and reasoning to answer questions. Specifically designed to... | Rungsiman Nararatwong, ChungChi Chen, Natthawut Kertkeidkachorn, Hiroya Takamura, Ryutaro Ichise |  |
| 1886 |  |  [NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.901) |  | 0 | We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat embodies the principle that an ensemble of role-specific LLMs, through structured role-play and strategic prompting, can perform their assigned... | Junda Wang, Zonghai Yao, Zhichao Yang, Huixue Zhou, Rumeng Li, Xun Wang, Yucheng Xu, Hong Yu |  |
| 1887 |  |  [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://doi.org/10.18653/v1/2024.findings-acl.902) |  | 0 | Editing knowledge in large language models is an attractive capability that allows us to correct incorrectly learned facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated... | Akshat Gupta, Anurag Rao, Gopala Anumanchipalli |  |
| 1888 |  |  [3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding](https://doi.org/10.18653/v1/2024.findings-acl.903) |  | 0 | This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation... | Yihao Ding, Lorenzo Vaiani, Soyeon Caren Han, Jean Lee, Paolo Garza, Josiah Poon, Luca Cagliero |  |
| 1889 |  |  [Faithful Persona-based Conversational Dataset Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.904) |  | 0 | High-quality conversational datasets are essential for developing AI models that can communicate with users.One way to foster deeper interactions between a chatbot and its user is through \*personas\*, aspects of the user’s character that provide insights into their personality, motivations, and... | Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, Hakim Sidahmed |  |
| 1890 |  |  [Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.905) |  | 0 | Despite vision-language models’ (VLMs) remarkable capabilities as versatile visual assistants, two substantial challenges persist within the existing VLM frameworks: (1) lacking task diversity in pretraining and visual instruction tuning, and (2) annotation error and bias in GPT-4 synthesized... | Zhiyang Xu, Chao Feng, Rulin Shao, Trevor Ashby, Ying Shen, Di Jin, Yu Cheng, Qifan Wang, Lifu Huang |  |
| 1891 |  |  [TAXI: Evaluating Categorical Knowledge Editing for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.906) |  | 0 | Humans rarely learn one fact in isolation. Instead, learning a new fact induces knowledge of other facts about the world. For example, in learning a korat is a type of cat, you also infer it is a mammal and has claws, ensuring your model of the world is consistent. Knowledge editing aims to inject... | Derek Powell, Walter Gerych, Thomas Hartvigsen |  |
| 1892 |  |  [Automatic Bug Detection in LLM-Powered Text-Based Games Using LLMs](https://doi.org/10.18653/v1/2024.findings-acl.907) |  | 0 | Advancements in large language models (LLMs) are revolutionizing interactive game design, enabling dynamic plotlines and interactions between players and non-player characters (NPCs). However, LLMs may exhibit flaws such as hallucinations, forgetfulness, or misinterpretations of prompts, causing... | Claire Jin, Sudha Rao, Xiangyu Peng, Portia Botchway, Jessica Quaye, Chris Brockett, Bill Dolan |  |
| 1893 |  |  [Embodied Language Learning: Opportunities, Challenges, and Future Directions](https://doi.org/10.18653/v1/2024.findings-acl.908) |  | 0 | While large language and vision-language models showcase impressive capabilities, they face a notable limitation: the inability to connect language with the physical world. To bridge this gap, research has focused on embodied language learning, where the language learner is situated in the world,... | Nadine Amin, Julia Rayz |  |
| 1894 |  |  [Challenges to Evaluating the Generalization of Coreference Resolution Models: A Measurement Modeling Perspective](https://doi.org/10.18653/v1/2024.findings-acl.909) |  | 0 | It is increasingly common to evaluate the same coreference resolution (CR) model on multiple datasets. Do these multi-dataset evaluations allow us to draw meaningful conclusions about model generalization? Or, do they rather reflect the idiosyncrasies of a particular experimental setup (e.g., the... | Ian Porada, Alexandra Olteanu, Kaheer Suleman, Adam Trischler, Jackie Chi Kit Cheung |  |
| 1895 |  |  [SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events](https://doi.org/10.18653/v1/2024.findings-acl.910) |  | 0 | Interpreting and assessing goal driven actions is vital to understanding and reasoning over complex events. It is important to be able to acquire the knowledge needed for this understanding, though doing so is challenging. We argue that such knowledge can be elicited through a participant... | Sai Vallurupalli, Katrin Erk, Francis Ferraro |  |
| 1896 |  |  [SLIDE: A Framework Integrating Small and Large Language Models for Open-Domain Dialogues Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.911) |  | 0 | The long-standing one-to-many problem of gold standard responses in open-domain dialogue systems presents challenges for automatic evaluation metrics. Though prior works have demonstrated some success by applying powerful Large Language Models (LLMs), existing approaches still struggle with the... | Kun Zhao, Bohao Yang, Chen Tang, Chenghua Lin, Liang Zhan |  |
| 1897 |  |  [Deep Exploration of Cross-Lingual Zero-Shot Generalization in Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.912) |  | 0 | Instruction tuning has emerged as a powerful technique, significantly boosting zero-shot performance on unseen tasks. While recent work has explored cross-lingual generalization by applying instruction tuning to multilingual models, previous studies have primarily focused on English, with a limited... | Janghoon Han, Changho Lee, Joongbo Shin, Stanley Jungkyu Choi, Honglak Lee, Kyunghoon Bae |  |
| 1898 |  |  [What Makes Language Models Good-enough?](https://doi.org/10.18653/v1/2024.findings-acl.913) |  | 0 | Psycholinguistic research suggests that humans may build a representation of linguistic input that is ‘good-enough’ for the task at hand. This study examines what architectural features make language models learn human-like good-enough language processing. We focus on the number of layers and... | Daiki Asami, Saku Sugawara |  |
| 1899 |  |  [Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction](https://doi.org/10.18653/v1/2024.findings-acl.914) |  | 0 | Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality corpora, due to the labor-intensive labeling of spelling errors in real-life human writing or typing scenarios. Two data augmentation methods are widely adopted: (1) \*Random Replacement\* with the guidance of confusion sets... | Dingyao Yu, Yang An, Wei Ye, Xiongfeng Xiao, Shaoguang Mao, Tao Ge, Shikun Zhang |  |
| 1900 |  |  [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples](https://doi.org/10.18653/v1/2024.findings-acl.915) |  | 0 | We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two critical under- explored problems: the neglect of physically grounded reasoning (counting... | Jianrui Zhang, Mu Cai, Tengyang Xie, Yong Jae Lee |  |
| 1901 |  |  [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.916) |  | 0 | Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this... | Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, May Dongmei Wang, Wei Jin, Joyce C. Ho, Carl Yang |  |
| 1902 |  |  [Textless Acoustic Model with Self-Supervised Distillation for Noise-Robust Expressive Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.917) |  | 0 | In this paper, we propose a textless acoustic model with a self-supervised distillation strategy for noise-robust expressive speech-to-speech translation (S2ST).Recently proposed expressive S2ST systems have achieved impressive expressivity preservation performances by cascading unit-to-speech... | MinJae Hwang, Ilia Kulikov, Benjamin N. Peloquin, Hongyu Gong, PengJen Chen, Ann Lee |  |
| 1903 |  |  [Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.918) |  | 0 | The integration of generative Large Language Models (LLMs) into various applications, including the legal domain, has been accelerated by their expansive and versatile nature. However, when facing a legal case, users without a legal background often struggle to formulate professional queries and... | Yang Wu, Chenghao Wang, Ece Gumusel, Xiaozhong Liu |  |
| 1904 |  |  [TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.919) |  | 0 | The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent... | Hui Liu, Wenya Wang, Haoru Li, Haoliang Li |  |
| 1905 |  |  [Verifiable Generation with Subsentence-Level Fine-Grained Citations](https://doi.org/10.18653/v1/2024.findings-acl.920) |  | 0 | Verifiable generation requires large language models (LLMs) to cite source documents supporting their outputs, thereby improve output transparency and trustworthiness. Yet, previous work mainly targets the generation of sentence-level citations, lacking specificity about which parts of a sentence... | Shuyang Cao, Lu Wang |  |
| 1906 |  |  [Tailoring with Targeted Precision: Edit-Based Agents for Open-Domain Procedure Customization](https://doi.org/10.18653/v1/2024.findings-acl.921) |  | 0 | How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user’s specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM’s ability to perform such customization. Our approach is to test... | Yash Kumar Lal, Li Zhang, Faeze Brahman, Bodhisattwa Prasad Majumder, Peter Clark, Niket Tandon |  |
| 1907 |  |  [A Meta-Learning Perspective on Transformers for Causal Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.922) |  | 0 | The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal... | Xinbo Wu, Lav R. Varshney |  |
| 1908 |  |  [PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs](https://doi.org/10.18653/v1/2024.findings-acl.923) |  | 0 | Large Language Models (LLMs) have exhibited impressive capabilities in various tasks, yet their vast parameter sizes restrict their applicability in resource-constrained settings. Knowledge distillation (KD) offers a viable solution by transferring expertise from large teacher models to compact... | Rongzhi Zhang, Jiaming Shen, Tianqi Liu, Haorui Wang, Zhen Qin, Feng Han, Jialu Liu, Simon Baumgartner, Michael Bendersky, Chao Zhang |  |
| 1909 |  |  [Small Language Models Need Strong Verifiers to Self-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.924) |  | 0 | Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether small (≤ 13B) language models (LMs) have the ability of... | Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang |  |
| 1910 |  |  [Hire a Linguist!: Learning Endangered Languages in LLMs with In-Context Linguistic Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.925) |  | 0 | How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large... | Kexun Zhang, Yee Man Choi, Zhenqiao Song, Taiqi He, William Yang Wang, Lei Li |  |
| 1911 |  |  [From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation](https://doi.org/10.18653/v1/2024.findings-acl.926) |  | 0 | We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end-users are not fully proficient, such as language learners. Using a novel framework, we evaluate the effectiveness of several key approaches for this task, including... | Ali Malik, Stephen Mayhew, Christopher Piech, Klinton Bicknell |  |
| 1912 |  |  [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://doi.org/10.18653/v1/2024.findings-acl.927) |  | 0 | Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations.Despite growing mitigation... | Khaoula Chehbouni, Megha Roshan, Emmanuel Ma, Futian Andrew Wei, Afaf Taïk, Jackie Chi Kit Cheung, Golnoosh Farnadi |  |
| 1913 |  |  [CToolEval: A Chinese Benchmark for LLM-Powered Agent Evaluation in Real-World API Interactions](https://doi.org/10.18653/v1/2024.findings-acl.928) |  | 0 | Assessing the capabilities of large language models (LLMs) as agents in decision making and operational tasks is crucial for the development of LLM-as-agent service. We propose CToolEval, a benchmark designed to evaluate LLMs in the context of Chinese societal applications, featuring 398 APIs... | Zishan Guo, Yufei Huang, Deyi Xiong |  |
| 1914 |  |  [Token Alignment via Character Matching for Subword Completion](https://doi.org/10.18653/v1/2024.findings-acl.929) |  | 0 | Generative models, widely utilized in various applications, can often struggle with prompts corresponding to partial tokens. This struggle stems from tokenization, where partial tokens fall out of distribution during inference, leading to incorrect or nonsensical outputs. This paper examines a... | Ben Athiwaratkun, Shiqi Wang, Mingyue Shang, Yuchen Tian, Zijian Wang, Sujan Kumar Gonugondla, Sanjay Krishna Gouda, Robert Kwiatkowski, Ramesh Nallapati, Parminder Bhatia, Bing Xiang |  |
| 1915 |  |  [Rethinking Efficient Multilingual Text Summarization Meta-Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.930) |  | 0 | Evaluating multilingual summarization evaluation metrics, i.e., meta-evaluation, is challenging because of the difficulty of human annotation collection. Therefore, we investigate an efficient multilingual meta-evaluation framework that uses machine translation systems to transform a monolingual... | Rilyn Han, Jiawen Chen, Yixin Liu, Arman Cohan |  |
| 1916 |  |  [emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation](https://doi.org/10.18653/v1/2024.findings-acl.931) |  | 0 | We propose emotion2vec, a universal speech emotion representation model. emotion2vec is pre-trained on open-source unlabeled emotion data through self-supervised online distillation, combining utterance-level loss and frame-level loss during pre-training. emotion2vec outperforms state-of-the-art... | Ziyang Ma, Zhisheng Zheng, Jiaxin Ye, Jinchao Li, Zhifu Gao, Shiliang Zhang, Xie Chen |  |
| 1917 |  |  [Language-Informed Beam Search Decoding for Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.932) |  | 0 | Beam search decoding is the de-facto method for decoding auto-regressive Neural Machine Translation (NMT) models, including multilingual NMT where the target language is specified as an input. However, decoding multilingual NMT models commonly produces off-target translations – yielding translation... | Yilin Yang, Stefan Lee, Prasad Tadepalli |  |
| 1918 |  |  [RA-LoRA: Rank-Adaptive Parameter-Efficient Fine-Tuning for Accurate 2-bit Quantized Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.933) |  | 0 | Deploying large language models (LLMs) with their extensive parameters and high memory demands challenges computational efficiency, particularly in fine-tuning for specific applications with limited resources. Techniques like Low-Rank Adaptation (LoRA) help by training a smaller, modifiable... | Minsoo Kim, Sihwa Lee, Wonyong Sung, Jungwook Choi |  |
| 1919 |  |  [The PGNSC Benchmark: How Do We Predict Where Information Spreads?](https://doi.org/10.18653/v1/2024.findings-acl.934) |  | 0 | Social networks have become ideal vehicles for news dissemination because posted content is easily able to reach users beyond a news outlet’s direct audience. Understanding how information is transmitted among communities of users is a critical step towards understanding the impact social networks... | Alexander Taylor, Wei Wang |  |
| 1920 |  |  [STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.935) |  | 0 | Interactive fiction games have emerged as an important application to improve the generalization capabilities of language-based reinforcement learning (RL) agents. Existing environments for interactive fiction games are domain-specific or time-consuming to generate and do not train the RL agents to... | Shreyas Basavatia, Keerthiram Murugesan, Shivam Ratnakar |  |
| 1921 |  |  [Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.936) |  | 0 |  | Dohyun Lee, Daniel Rim, Minseok Choi, Jaegul Choo |  |
| 1922 |  |  [Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.937) |  | 0 | Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs. However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text... | Xintong Wang, Jingheng Pan, Liang Ding, Chris Biemann |  |
| 1923 |  |  [Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs](https://doi.org/10.18653/v1/2024.findings-acl.938) |  | 0 | Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs. In this study, we view partial code as implementation hints and... | Dingmin Wang, Jinman Zhao, Hengzhi Pei, Samson Tan, Sheng Zha |  |
| 1924 |  |  [A Critical Study of What Code-LLMs (Do Not) Learn](https://doi.org/10.18653/v1/2024.findings-acl.939) |  | 0 | Large Language Models trained on code corpora (code-LLMs) have demonstrated impressive performance in various coding assistance tasks. However, despite their increased size and training dataset, code-LLMs still have limitations such as suggesting codes with syntactic errors, variable misuse etc.... | Abhinav Anand, Shweta Verma, Krishna Narasimhan, Mira Mezini |  |
| 1925 |  |  [Visual In-Context Learning for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.940) |  | 0 | In Large Visual Language Models (LVLMs), the efficacy of In-Context Learning (ICL) remains limited by challenges in cross-modal interactions and representation disparities. To overcome these challenges, we introduce a novel Visual In-Context Learning (VICL) method comprising Visual Demonstration... | Yucheng Zhou, Xiang Li, Qianning Wang, Jianbing Shen |  |
| 1926 |  |  [SCALE: Synergized Collaboration of Asymmetric Language Translation Engines](https://doi.org/10.18653/v1/2024.findings-acl.941) |  | 0 | In this paper, we introduce SCALE, a collaborative framework that connects a compact Specialized Translation Model (STM) and a general-purpose Large Language Model (LLM) as one unified translation engine. By introducing translation from STM into the triplet in-context demonstrations, SCALE unlocks... | Xin Cheng, Xun Wang, Tao Ge, SiQing Chen, Furu Wei, Dongyan Zhao, Rui Yan |  |
| 1927 |  |  [No perspective, no perception!! Perspective-aware Healthcare Answer Summarization](https://doi.org/10.18653/v1/2024.findings-acl.942) |  | 0 | Healthcare Community Question Answering (CQA) forums offer an accessible platform for individuals seeking information on various healthcare-related topics. People find such platforms suitable for self-disclosure, seeking medical opinions, finding simplified explanations for their medical... | Gauri Naik, Sharad Chandakacherla, Shweta Yadav, Md. Shad Akhtar |  |
| 1928 |  |  [Retrieval-Augmented Retrieval: Large Language Models are Strong Zero-Shot Retriever](https://doi.org/10.18653/v1/2024.findings-acl.943) |  | 0 | We propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Large language model as Retriever (LameR), is built upon no other neural models but an LLM in a retrieval-augmented retrieval fashion, while breaking brute-force... | Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Yibin Lei, Tianyi Zhou, Michael Blumenstein, Daxin Jiang |  |
| 1929 |  |  [A Survey on Predicting the Factuality and the Bias of News Media](https://doi.org/10.18653/v1/2024.findings-acl.944) |  | 0 | The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim or article, either manually or automatically. An increasing number of scholars are focusing on a coarser granularity, aiming to profile entire... | Preslav Nakov, Jisun An, Haewoon Kwak, Muhammad Arslan Manzoor, Zain Muhammad Mujahid, Husrev T. Sencar |  |
| 1930 |  |  [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://doi.org/10.18653/v1/2024.findings-acl.945) |  | 0 | Wavelet transforms, a powerful mathematical tool, have been widely used in different domains, including Signal and Image processing, to unravel intricate patterns, enhance data representation, and extract meaningful features from data. Tangible results from their application suggest that Wavelet... | Rana Aref Salama, Abdou Youssef, Mona T. Diab |  |
| 1931 |  |  [Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.946) |  | 0 | Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural language processing, with numerous approaches aiming to answer First-Order Logic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g., beta distribution)-based methodologies have effectively addressed... | Jeonghoon Kim, Heesoo Jung, Hyeju Jang, Hogun Park |  |
| 1932 |  |  [ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.947) |  | 0 | Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient strategy to harness LLMs with modest NER... | Yuzhao Heng, Chunyuan Deng, Yitong Li, Yue Yu, Yinghao Li, Rongzhi Zhang, Chao Zhang |  |
| 1933 |  |  [Defending LLMs against Jailbreaking Attacks via Backtranslation](https://doi.org/10.18653/v1/2024.findings-acl.948) |  | 0 | Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by... | Yihan Wang, Zhouxing Shi, Andrew Bai, ChoJui Hsieh |  |
| 1934 |  |  [A Large Collection of Model-generated Contradictory Responses for Consistency-aware Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.949) |  | 0 | Mitigating the generation of contradictory responses poses a substantial challenge in dialogue response generation. The quality and quantity of available contradictory response data play a vital role in suppressing these contradictions, offering two significant benefits. First, having access to... | Shiki Sato, Reina Akama, Jun Suzuki, Kentaro Inui |  |
| 1935 |  |  [Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset](https://doi.org/10.18653/v1/2024.findings-acl.950) |  | 0 | This paper explores the question of how accurately current large language models can perform logical reasoning in natural language, with an emphasis on whether these models exhibit reasoning biases similar to humans. Specifically, our study focuses on syllogistic reasoning, a form of deductive... | Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada |  |
| 1936 |  |  [Unveiling the Spectrum of Data Contamination in Language Model: A Survey from Detection to Remediation](https://doi.org/10.18653/v1/2024.findings-acl.951) |  | 0 | Data contamination has garnered increased attention in the era of Large language models (LLMs) due to the reliance on extensive internet-derived training corpora. The issue of training corpus overlap with evaluation benchmarks—referred to as contamination—has been the focus of significant recent... | Chunyuan Deng, Yilun Zhao, Yuzhao Heng, Yitong Li, Jiannan Cao, Xiangru Tang, Arman Cohan |  |
| 1937 |  |  [DIMSIM: Distilled Multilingual Critics for Indic Text Simplification](https://doi.org/10.18653/v1/2024.findings-acl.952) |  | 0 | Self-correction techniques have recently emerged as a promising framework to improve the quality of responses generated by large language models (LLMs). Few-shot prompted LLMs act as critics to produce feedback for an input, which is further fed to a refiner (also an LLM) to produce an output.... | Sneha Mondal, Ritika, Ashish Agrawal, Preethi Jyothi, Aravindan Raghuveer |  |
| 1938 |  |  [MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources](https://doi.org/10.18653/v1/2024.findings-acl.953) |  | 0 | Leveraging external knowledge is crucial for achieving high performance in knowledge-intensive tasks, such as question answering. The retrieve-and-read approach is widely adopted for integrating external knowledge into a language model. However, this approach suffers from increased computational... | Dongkyu Lee, Chandana Satya Prakash, Jack FitzGerald, Jens Lehmann |  |
| 1939 |  |  [Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.954) |  | 0 | Social bias is shaped by the accumulation of social perceptions towards targets across various demographic identities. To fully understand such social bias in large language models (LLMs), it is essential to consider the composite of social perceptions from diverse perspectives among identities.... | Jisu Shin, Hoyun Song, Huije Lee, Soyeong Jeong, Jong Park |  |
| 1940 |  |  [Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.findings-acl.955) |  | 0 | Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has... | Yuwei Xia, Ding Wang, Qiang Liu, Liang Wang, Shu Wu, Xiaoyu Zhang |  |
| 1941 |  |  [Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements](https://doi.org/10.18653/v1/2024.findings-acl.956) |  | 0 | Making LLMs speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. However, existing LLMs lack sufficient controllability to the stance of their generated... | Ming Li, Jiuhai Chen, Lichang Chen, Tianyi Zhou |  |
| 1942 |  |  [Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.findings-acl.957) |  | 0 | Detecting implicit hate speech that is not directly hateful remains a challenge. Recent research has attempted to detect implicit hate speech by applying contrastive learning to pre-trained language models such as BERT and RoBERTa, but the proposed models still do not have a significant advantage... | Jaehoon Kim, Seungwan Jin, Sohyun Park, Someen Park, Kyungsik Han |  |
| 1943 |  |  [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.958) |  | 0 | Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the... | Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, Tianyi Zhou |  |
| 1944 |  |  [Selective Prompting Tuning for Personalized Conversations with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.959) |  | 0 | In conversational AI, personalizing dialogues with persona profiles and contextual understanding is essential. Despite large language models’ (LLMs) improved response coherence, effective persona integration remains a challenge. In this work, we first study two common approaches for personalizing... | Qiushi Huang, Xubo Liu, Tom Ko, Bo Wu, Wenwu Wang, Yu Zhang, Lilian Tang |  |
| 1945 |  |  [Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models](https://doi.org/10.18653/v1/2024.findings-acl.960) |  | 0 | In the rapidly advancing field of artificial intelligence, the concept of ‘Red-Teaming’ or ‘Jailbreaking’ large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This... | Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria |  |
| 1946 |  |  [ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.961) |  | 0 | Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text. Despite the success of VLMs, they still significantly lag behind human performance in IRCD. The main challenges lie in aligning key... | Honglin Lin, Siyu Li, Guoshun Nan, Chaoyue Tang, Xueting Wang, Jingxin Xu, Yankai Rong, Zhouzhili Zhouzhili, Yutong Gao, Qimei Cui, Xiaofeng Tao |  |
| 1947 |  |  [PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns](https://doi.org/10.18653/v1/2024.findings-acl.962) |  | 0 | Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities. However, it is not clear how they can emulate the general intelligence and reasoning ability of humans. As recognizing patterns and abstracting concepts are key to... | Yew Ken Chia, Vernon Toh, Deepanway Ghosal, Lidong Bing, Soujanya Poria |  |
| 1948 |  |  [How Do Moral Emotions Shape Political Participation? A Cross-Cultural Analysis of Online Petitions Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.963) |  | 0 | Understanding the interplay between emotions in language and user behaviors is critical. We study how moral emotions shape the political participation of users based on cross-cultural online petition data. To quantify moral emotions, we employ a context-aware NLP model that is designed to capture... | Jaehong Kim, Chaeyoon Jeong, Seongchan Park, Meeyoung Cha, Wonjae Lee |  |
| 1949 |  |  [VillagerAgent: A Graph-Based Multi-Agent Framework for Coordinating Complex Task Dependencies in Minecraft](https://doi.org/10.18653/v1/2024.findings-acl.964) |  | 0 | In this paper, we aim to evaluate multi-agent systems against complex dependencies, including spatial, causal, and temporal constraints. First, we construct a new benchmark, named VillagerBench, within the Minecraft environment. VillagerBench comprises diverse tasks crafted to test various aspects... | Yubo Dong, Xukun Zhu, Zhengzhe Pan, Linchao Zhu, Yi Yang |  |
| 1950 |  |  [CF-TCIR: A Compositor-Free Framework for Hierarchical Text-Conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.965) |  | 0 | In text-conditioned image retrieval (TCIR), the combination of a reference image and modification text forms a query tuple, aiming to locate the most congruent target image within a dataset. The advantages of rich image semantic information and text flexibility are combined in this manner for more... | Yuchen Yang, Yu Wang, Yanfeng Wang |  |
| 1951 |  |  [DMIN: A Discourse-specific Multi-granularity Integration Network for Conversational Aspect-based Sentiment Quadruple Analysis](https://doi.org/10.18653/v1/2024.findings-acl.966) |  | 0 | Conversational Aspect-based Sentiment Quadruple Analysis (DiaASQ) aims to extract fine-grained sentiment quadruples from dialogues. Previous research has primarily concentrated on enhancing token-level interactions, still lacking in sufficient modeling of the discourse structure information in... | Peijie Huang, Xisheng Xiao, Yuhong Xu, Jiawei Chen |  |
| 1952 |  |  [Are Decoder-Only Language Models Better than Encoder-Only Language Models in Understanding Word Meaning?](https://doi.org/10.18653/v1/2024.findings-acl.967) |  | 0 | The natural language processing field has been evolving around language models for the past few years, from the usage of n-gram language models for re-ranking, to transfer learning with encoder-only (BERT-like) language models, and finally to large language models (LLMs) as general solvers. LLMs... | Muhammad Reza Qorib, Geonsik Moon, Hwee Tou Ng |  |
| 1953 |  |  [FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.968) |  | 0 | To process contexts with unlimited length using Large Language Models (LLMs), recent studies explore hierarchically managing the long text. Only several text fragments are taken from the external memory and passed into the temporary working memory, i.e., LLM’s context window. However, existing... | Xihang Yue, Linchao Zhu, Yi Yang |  |
| 1954 |  |  [On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations](https://doi.org/10.18653/v1/2024.findings-acl.969) |  | 0 | Driven by the demand for cross-sentence and large-scale relation extraction, document-level relation extraction (DocRE) has attracted increasing research interest. Despite the continuous improvement in performance, we find that existing DocRE models which initially perform well may make more... | Shiao Meng, Xuming Hu, Aiwei Liu, Fukun Ma, Yawen Yang, Shuang Li, Lijie Wen |  |
| 1955 |  |  [RESEMO: A Benchmark Chinese Dataset for Studying Responsive Emotion from Social Media Content](https://doi.org/10.18653/v1/2024.findings-acl.970) |  | 0 | On social media platforms, users’ emotions are triggered when they encounter particular content from other users,where such emotions are different from those that spontaneously emerged, owing to the “responsive” nature. Analyzing the aforementioned responsive emotions from user interactions is a... | Bo Hu, Meng Zhang, Chenfei Xie, Yuanhe Tian, Yan Song, Zhendong Mao |  |
| 1956 |  |  [EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records](https://doi.org/10.18653/v1/2024.findings-acl.971) |  | 0 | In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to address critical yet underexplored aspects in text-to-SQL parsing: interactivity, compositionality, and efficiency. To the best of our knowledge,... | Jaehee Ryu, Seonhee Cho, Gyubok Lee, Edward Choi |  |
| 1957 |  |  [KEEP CHATTING! An Attractive Dataset for Continuous Conversation Agents](https://doi.org/10.18653/v1/2024.findings-acl.972) |  | 0 | Ongoing chatting is an important step for conversational agents to build long-term connections with people. However, people tend to quickly lose interest in chatting if the conversational agent’s words are not engaging enough. In this paper, we present a novel task of increasing users’ willingness... | Yihe Wang, Jin Liu, Yao Wan, Yitong Li, Zifeng Liu, Weipeng Chen |  |
| 1958 |  |  [RePair: Automated Program Repair with Process-based Feedback](https://doi.org/10.18653/v1/2024.findings-acl.973) |  | 0 | The gap between the trepidation of program reliability and the expense of repairs underscore the indispensability for Automated Program Repair (APR). APR is instrumental in transforming vulnerable programs into more robust ones, bolstering program reliability while simultaneously diminishing the... | Yuze Zhao, Zhenya Huang, Yixiao Ma, Rui Li, Kai Zhang, Hao Jiang, Qi Liu, Linbo Zhu, Yu Su |  |
| 1959 |  |  [Concise and Precise Context Compression for Tool-Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.974) |  | 0 | Through reading the documentation in the context, tool-using language models can dynamically extend their capability using external tools. The cost is that we have to input lengthy documentation every time the model needs to use the tool, occupying the input window as well as slowing down the... | Yang Xu, Yunlong Feng, Honglin Mu, Yutai Hou, Yitong Li, Xinghao Wang, Wanjun Zhong, Zhongyang Li, Dandan Tu, Qingfu Zhu, Min Zhang, Wanxiang Che |  |
| 1960 |  |  [MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries](https://doi.org/10.18653/v1/2024.findings-acl.975) |  | 0 | Medical decisions directly impact individuals’ health and well-being. Extracting decision spans from clinical notes plays a crucial role in understanding medical decision-making processes. In this paper, we develop a new dataset called “MedDec,” which contains clinical notes of eleven different... | Mohamed Elgaar, Jiali Cheng, Nidhi Vakil, Hadi Amiri, Leo Anthony Celi |  |

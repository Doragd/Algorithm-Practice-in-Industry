# ACL2024

## 会议论文列表

本会议共有 1960 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Feriji: A French-Zarma Parallel Corpus, Glossary & Translator](https://doi.org/10.18653/v1/2024.acl-srw.1) |  | 0 | Machine translation (MT) is a rapidly expanding field that has experienced significant advancements in recent years with the development of models capable of translating multiple languages with remarkable accuracy. However, the representation of African languages in this field still needs improvement due to linguistic complexities and limited resources. This applies to the Zarma language, a dialect of Songhay (of the Nilo-Saharan language family) spoken by over 5 million people across Niger and... | Mamadou Keita, Elysabhete Amadou Ibrahim, Habibatou Abdoulaye Alfari, Christopher Homan |  |
| 2 |  |  [Pragmatic inference of scalar implicature by LLMs](https://doi.org/10.18653/v1/2024.acl-srw.2) |  | 0 | This study investigates how Large Language Models (LLMs), particularly BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic inference of scalar implicature, such as some. Two sets of experiments were conducted using cosine similarity and next sentence/token prediction as experimental methods. The results in experiment 1 showed that, both models interpret some as pragmatic implicature not all in the absence of context, aligning with human language processing. In... | Yeeun Cho, Seong mook Kim |  |
| 3 |  |  [Topic Modeling for Short Texts with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.3) |  | 0 | As conventional topic models rely on word co-occurrence to infer latent topics, topic modeling for short texts has been a long-standing challenge. Large Language Models (LLMs) can potentially overcome this challenge by contextually learning the meanings of words via pretraining. In this paper, we study two approaches to using LLMs for topic modeling: parallel prompting and sequential prompting. Input length limitations prevent LLMs from processing many texts at once. However, an arbitrary... | Tomoki Doi, Masaru Isonuma, Hitomi Yanaka |  |
| 4 |  |  [Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases](https://doi.org/10.18653/v1/2024.acl-srw.4) |  | 0 |  | Xiang Zhang, Khatoon Khedri, Reza Rawassizadeh |  |
| 5 |  |  [Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer](https://doi.org/10.18653/v1/2024.acl-srw.5) |  | 0 | Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer during translation. We design an S2ST pipeline with style-transfer capability on the basis of discrete self-supervised speech representations and codec units. The acoustic language model we introduce... | Yongqi Wang, Jionghao Bai, Rongjie Huang, Ruiqi Li, Zhiqing Hong, Zhou Zhao |  |
| 6 |  |  [InstructCoder: Instruction Tuning Large Language Models for Code Editing](https://doi.org/10.18653/v1/2024.acl-srw.6) |  | 0 |  | Kaixin Li, Qisheng Hu, James Xu Zhao, Hui Chen, Yuxi Xie, Tiedong Liu, Michael Shieh, Junxian He |  |
| 7 |  |  [BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization](https://doi.org/10.18653/v1/2024.acl-srw.7) |  | 0 | Large Language Models (LLMs) have become pivotal in advancing natural language processing, yet their potential to perpetuate biases poses significant concerns. This paper introduces a new framework employing Direct Preference Optimization (DPO) to mitigate gender, racial, and religious biases in LLM-generated English text. By developing a loss function that favors less biased over biased completions, our approach cultivates a preference for respectful and non-discriminatory language in LLMs. We... | Ahmed Allam |  |
| 8 |  |  [MoExtend: Tuning New Experts for Modality and Task Extension](https://doi.org/10.18653/v1/2024.acl-srw.8) |  | 0 |  | Shanshan Zhong, Shanghua Gao, Zhongzhan Huang, Wushao Wen, Marinka Zitnik, Pan Zhou |  |
| 9 |  |  [On the Interpretability of Deep Learning Models for Collaborative Argumentation Analysis in Classrooms](https://doi.org/10.18653/v1/2024.acl-srw.9) |  | 0 |  | Deliang Wang, Gaowei Chen |  |
| 10 |  |  [Document Alignment based on Overlapping Fixed-Length Segments](https://doi.org/10.18653/v1/2024.acl-srw.10) |  | 0 | Acquiring large-scale parallel corpora is crucial for NLP tasks such as Neural Machine Translation, and web crawling has become a popular methodology for this purpose. Previous studies have been conducted based on sentence-based segmentation (SBS) when aligning documents in various languages which are obtained through web crawling. Among them, the TK-PERT method (Thompson and Koehn, 2020) achieved state-of-the-art results and addressed the boilerplate text in web crawling data well through a... | Xiaotian Wang, Takehito Utsuro, Masaaki Nagata |  |
| 11 |  |  [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.acl-srw.11) |  | 0 |  | Enrico Benedetti, Akiko Aizawa, Florian Boudin |  |
| 12 |  |  [Z-coref: Thai Coreference and Zero Pronoun Resolution](https://doi.org/10.18653/v1/2024.acl-srw.12) |  | 0 |  | Poomphob Suwannapichat, Sansiri Tarnpradab, Santitham Promon |  |
| 13 |  |  [ReMAG-KR: Retrieval and Medically Assisted Generation with Knowledge Reduction for Medical Question Answering](https://doi.org/10.18653/v1/2024.acl-srw.13) |  | 0 | Large Language Models (LLMs) have significant potential for facilitating intelligent end-user applications in healthcare. However, hallucinations remain an inherent problem with LLMs, making it crucial to address this issue with extensive medical knowledge and data. In this work, we propose a Retrieve-and-Medically-Augmented-Generation with Knowledge Reduction (ReMAG-KR) pipeline, employing a carefully curated knowledge base using cross-encoder re-ranking strategies. The pipeline is tested on... | Sidhaarth Murali, Sowmya S., Supreetha R. |  |
| 14 |  |  [Plot Retrieval as an Assessment of Abstract Semantic Association](https://doi.org/10.18653/v1/2024.acl-srw.14) |  | 0 |  | Shicheng Xu, Liang Pang, Jiangnan Li, Mo Yu, Fandong Meng, Huawei Shen, Xueqi Cheng, Jie Zhou |  |
| 15 |  |  [Demystifying Instruction Mixing for Fine-tuning Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.15) |  | 0 | Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more... | Renxi Wang, Haonan Li, Minghao Wu, Yuxia Wang, Xudong Han, Chiyu Zhang, Timothy Baldwin |  |
| 16 |  |  [Fine-Tuning ASR models for Very Low-Resource Languages: A Study on Mvskoke](https://doi.org/10.18653/v1/2024.acl-srw.16) |  | 0 | Recent advancements in multilingual models for automatic speech recognition (ASR) have been able to achieve a high accuracy for languages with extremely limited resources. This study examines ASR modeling for the Mvskoke language, an indigenous language of America. The parameter efficiency of adapter training is contrasted with training entire models, and it is demonstrated how performance varies with different amounts of data. Additionally, the models are evaluated with trigram language model... | Julia Mainzinger, GinaAnne Levow |  |
| 17 |  |  [Automating Qualitative Data Analysis with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.17) |  | 0 | This PhD proposal aims to investigate ways of automating qualitative data analysis, specifically the thematic coding of texts. Despite existing methods vastly covered in literature, they mainly use Topic Modeling and other quantitative approaches which are far from resembling a human’s analysis outcome. This proposal examines the limitations of current research in the field. It proposes a novel methodology based on Large Language Models to tackle automated coding and make it as close as... | Angelina Parfenova, Alexander Denzler, Jörgen Pfeffer |  |
| 18 |  |  [ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection](https://doi.org/10.18653/v1/2024.acl-srw.18) |  | 0 | Research on token-level reference-free hallucination detection has predominantly focused on English, primarily due to the scarcity of robust datasets in other languages. This has hindered systematic investigations into the effectiveness of cross-lingual transfer for this important NLP application. To address this gap, we introduce ANHALTEN, a new evaluation dataset that extends the English hallucination detection dataset to German. To the best of our knowledge, this is the first work that... | Janek Herrlein, ChiaChien Hung, Goran Glavas |  |
| 19 |  |  [Label-Aware Automatic Verbalizer for Few-Shot Text Classification in Mid-To-Low Resource Languages](https://doi.org/10.18653/v1/2024.acl-srw.19) |  | 0 | Prompt-based learning has shown its effectiveness in few-shot text classification. A key factor in its success is a verbalizer, which translates output from a language model into a predicted class. Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the classes. However, manual selection may not yield the optimal words for a given language model, potentially leading to subpar classification performance, especially in mid-to-low resource languages with... | Thanakorn Thaminkaew, Piyawat Lertvittayakumjorn, Peerapon Vateekul |  |
| 20 |  |  [Vector Spaces for Quantifying Disparity of Multiword Expressions in Annotated Text](https://doi.org/10.18653/v1/2024.acl-srw.20) |  | 0 | Multiword Expressions (MWEs) make a goodcase study for linguistic diversity due to theiridiosyncratic nature. Defining MWE canonicalforms as types, diversity may be measurednotably through disparity, based on pairwisedistances between types. To this aim, wetrain static MWE-aware word embeddings forverbal MWEs in 14 languages, and we showinteresting properties of these vector spaces.We use these vector spaces to implement theso-called functional diversity measure. Weapply this measure to the... | Louis Estève, Agata Savary, Thomas Lavergne |  |
| 21 |  |  [Narratives at Conflict: Computational Analysis of News Framing in Multilingual Disinformation Campaigns](https://doi.org/10.18653/v1/2024.acl-srw.21) |  | 0 | Any report frames issues to favor a particular interpretation by highlighting or excluding certain aspects of a story. Despite the widespread use of framing in disinformation, framing properties and detection methods remain underexplored outside the English-speaking world. We explore how multilingual framing of the same issue differs systematically. We use eight years of Russia-backed disinformation campaigns, spanning 8k news articles in 4 languages targeting 15 countries. We find that... | Antonina Sinelnik, Dirk Hovy |  |
| 22 |  |  [Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data](https://doi.org/10.18653/v1/2024.acl-srw.22) |  | 0 | Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages. Automated scalable methods are necessary due to the impracticality of manual labeling. In this paper, we model the detection of topic-related content as a binary classification task and compare the accuracy of fine-tuned pre-trained encoder models against in-context learning strategies. Using only a few hundred... | Julian Schelb, Andreas Spitz, Roberto Ulloa |  |
| 23 |  |  [Knowledge Editing of Large Language Models Unconstrained by Word Order](https://doi.org/10.18653/v1/2024.acl-srw.23) |  | 0 | Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves. To address this issue, a method called local modification-based knowledge editing has been developed. This method identifies the knowledge neurons that encode the target knowledge and adjusts the parameters associated with these neurons to update the knowledge. Knowledge... | Ryoma Ishigaki, Jundai Suzuki, Masaki Shuzo, Eisaku Maeda |  |
| 24 |  |  [Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning](https://doi.org/10.18653/v1/2024.acl-srw.24) |  | 0 | Identifying beneficial tasks to transfer from is a critical step toward successful intermediate-task transfer learning. In this work, we experiment with 130 source-target task combinations and demonstrate that the transfer performance exhibits severe variance across different source tasks and training seeds, highlighting the crucial role of intermediate-task selection in a broader context. We compare four representative task selection methods in a unified setup, focusing on their effectiveness... | PinJie Lin, Miaoran Zhang, Marius Mosbach, Dietrich Klakow |  |
| 25 |  |  [Does the structure of textual content have an impact on language models for automatic summarization?](https://doi.org/10.18653/v1/2024.acl-srw.25) |  | 0 | The processing of long sequences with models remains a subject in its own right, including automatic summary, despite recent improvements. In this work, we present experiments on the automatic summarization of scientific articles using BART models, taking into account textual information coming from distinct passages from the long texts to be summarized. We demonstrate that taking into account document structure improves the performance of state-of-the-art models and approaches the performance... | Eve Sauvage, Sabrina Campano, Lydia Ould Ouali, Cyril Grouin |  |
| 26 |  |  [Action Inference for Destination Prediction in Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-srw.26) |  | 0 | Vision-and-Language Navigation (VLN) encompasses interacting with autonomous vehicles using language and visual input from the perspective of mobility.Most of the previous work in this field focuses on spatial reasoning and the semantic grounding of visual information.However, reasoning based on the actions of pedestrians in the scene is not much considered.In this study, we provide a VLN dataset for destination prediction with action inference to investigate the extent to which current VLN... | Anirudh Reddy Kondapally, Kentaro Yamada, Hitomi Yanaka |  |
| 27 |  |  [A Computational Analysis and Exploration of Linguistic Borrowings in French Rap Lyrics](https://doi.org/10.18653/v1/2024.acl-srw.27) |  | 0 | In France, linguistic borrowings in the relatively conservative French language are an important site of cultural debate, and rap in particular is a hotspot for borrowings. In this work, we use computational methods to understand the factors that affect the prominence and prevalence of a borrowing. To do so, we manually annotate a lexicon of over 700 borrowings occurring in this context (including key aspects for each borrowing such as origin and semantic class). We analyze the prevalence of... | Lucas Zurbuchen, Rob Voigt |  |
| 28 |  |  [On Improving Repository-Level Code QA for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.28) |  | 0 | Large Language Models (LLMs) such as ChatGPT, GitHub Copilot, Llama, or Mistral assist programmers as copilots and knowledge sources to make the coding process faster and more efficient. This paper aims to improve the copilot performance by implementing different self-alignment processes and retrieval-augmented generation (RAG) pipelines, as well as their combination. To test the effectiveness of all approaches, we create a dataset and apply a model-based evaluation, using LLM as a judge. It is... | Jan Strich, Florian Schneider, Irina Nikishina, Chris Biemann |  |
| 29 |  |  [Compromesso! Italian Many-Shot Jailbreaks undermine the safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.29) |  | 0 | As diverse linguistic communities and users adopt Large Language Models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to align these models with safe and ethical guidelines, they can still be induced into unsafe behavior with jailbreaking, a technique in which models are prompted to act outside their operational guidelines. What research has been conducted on these vulnerabilities was predominantly on English, limiting the understanding of LLM... | Fabio Pernisi, Dirk Hovy, Paul Röttger |  |
| 30 |  |  [Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.30) |  | 0 |  | Yunsoo Kim |  |
| 31 |  |  [ViMedAQA: A Vietnamese Medical Abstractive Question-Answering Dataset and Findings of Large Language Model](https://doi.org/10.18653/v1/2024.acl-srw.31) |  | 0 | Question answering involves creating answers to questions. With the growth of large language models, the ability of question-answering systems has dramatically improved. However, there is a lack of Vietnamese abstractive question-answering datasets, especially in the medical domain. Therefore, this research aims to mitigate this gap by introducing ViMedAQA. This \*\*Vi\*\*etnamese \*\*Med\*\*ical \*\*A\*\*bstractive \*\*Q\*\*uestion-\*\*A\*\*nswering dataset covers four topics in the Vietnamese... | MinhNam Tran, PhuVinh Nguyen, Long Nguyen, Dien Dinh |  |
| 32 |  |  [Rescue: Ranking LLM Responses with Partial Ordering to Improve Response Generation](https://doi.org/10.18653/v1/2024.acl-srw.32) |  | 0 | Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert-annotated data is costly for most tasks. In this paper, we explore a novel method to optimize LLMs using ranking metrics. This method trains the model to prioritize the best responses from a pool of candidates created for a particular task. Rather than a... | Yikun Wang, Rui Zheng, Haoming Li, Qi Zhang, Tao Gui, Fei Liu |  |
| 33 |  |  [Basreh or Basra? Geoparsing Historical Locations in the Svoboda Diaries](https://doi.org/10.18653/v1/2024.acl-srw.33) |  | 0 | Geoparsing, the task of assigning coordinates to locations extracted from free text, is invaluable in enabling us to place locations in time and space. In the historical domain, many geoparsing corpora are from large news collections. We examine the Svoboda Diaries, a small historical corpus written primarily in English, with many location names in transliterated Arabic. We develop a pipeline employing named entity recognition for geotagging, and a map-based generate-and-rank approach... | Jolie Zhou, Camille Cole, Annie Chen |  |
| 34 |  |  [Homophone2Vec: Embedding Space Analysis for Empirical Evaluation of Phonological and Semantic Similarity](https://doi.org/10.18653/v1/2024.acl-srw.34) |  | 0 | This paper introduces a novel method for empirically evaluating the relationship between the phonological and semantic similarity of linguistic units using embedding spaces. Chinese character homophones are used as a proof-of-concept. We employ cosine similarity as a proxy for semantic similarity between characters, and compare relationships between phonologically-related characters and baseline characters (chosen as similar-frequency characters). We show there is a strongly statistically... | Sophie Wu, Anita Zheng, Joey Chuang |  |
| 35 |  |  [Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition](https://doi.org/10.18653/v1/2024.acl-srw.35) |  | 0 | Knowledge distillation allows smaller neural networks to emulate the performance of larger, teacher models with reduced computational demands. Traditional methods for Large Language Models (LLMs) often necessitate extensive fine-tuning, which limits their accessibility. To address this, we introduce Trace-of-Thought Prompting, a novel framework designed to distill critical reasoning capabilities from large-scale teacher models (over 8 billion parameters) to small-scale student models (up to 8... | Tyler McDonald, Ali Emami |  |
| 36 |  |  [Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges](https://doi.org/10.18653/v1/2024.acl-srw.36) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply common sense. A relevant application is to use them for creating high-quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money, and effort that... | Vinay Samuel, Houda Aynaou, Arijit Ghosh Chowdhury, Karthik Venkat Ramanan, Aman Chadha |  |
| 37 |  |  [Automatic Derivation of Semantic Representations for Thai Serial Verb Constructions: A Grammar-Based Approach](https://doi.org/10.18653/v1/2024.acl-srw.37) |  | 0 | Deep semantic representations are useful for many NLU tasks (Droganova and Zeman 2019; Schuster and Manning-2016). Manual annotation to build these representations is time-consuming, and so automatic approaches are preferred (Droganova and Zeman 2019; Bender et al. 2015). This paper demonstrates how rich semantic representations can be automatically derived for Thai Serial Verb Constructions (SVCs), where the semantic relationship between component verbs is not immediately clear from the... | Vipasha Bansal |  |
| 38 |  |  [Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai](https://doi.org/10.18653/v1/2024.acl-srw.38) |  | 0 |  | Parinthapat Pengpun, Can Udomcharoenchaikit, Weerayut Buaphet, Peerat Limkonchotiwat |  |
| 39 |  |  [Bridging Distribution Gap via Semantic Rewriting with LLMs to Enhance OOD Robustness](https://doi.org/10.18653/v1/2024.acl-srw.39) |  | 0 | This paper investigates the robustness of Large Language Models (LLMs) against Out-Of-Distribution (OOD) data within the context of sentiment analysis. Traditional fine-tuning approaches often fail to generalize effectively across different data distributions, limiting the practical deployment of LLMs in dynamic real-world scenarios. To address this challenge, we introduce a novel method called “Semantic Rewriting,” which leverages the inherent flexibility of LLMs to align both in-distribution... | Manas Madine |  |
| 40 |  |  [CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units](https://doi.org/10.18653/v1/2024.acl-srw.40) |  | 0 | Multilingual code-switching research is often hindered by the lack and linguistically biased status of available datasets. To expand language representation, we synthesize code-switching data by replacing intonation units detected through PSST, a speech segmentation model fine-tuned from OpenAI’s Whisper, using a speech-to-text translation dataset, CoVoST 2. With our dataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching translation performance of two multilingual... | Yeeun Kang |  |
| 41 |  |  [An Analysis under a Unified Formulation of Learning Algorithms with Output Constraints](https://doi.org/10.18653/v1/2024.acl-srw.41) |  | 0 |  | Mooho Song, JayYoon Lee |  |
| 42 |  |  [Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation](https://doi.org/10.18653/v1/2024.acl-srw.42) |  | 0 | The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but progress is slow. This paper identifies some factors that may have been holding research back, and proposes a new, enhanced dataset and prompting-based method for automatic synthesis generation, the most... | James O'Doherty, Cian Nolan, Yufang Hou, Anya Belz |  |
| 43 |  |  [Improving Sentence Embeddings with Automatic Generation of Training Data Using Few-shot Examples](https://doi.org/10.18653/v1/2024.acl-srw.43) |  | 0 | Decoder-based large language models (LLMs) have shown high performance on many tasks in natural language processing. This is also true for sentence embedding learning, where a decoder-based model, PromptEOL, has achieved the best performance on semantic textual similarity (STS) tasks. However, PromptEOL requires a manually annotated natural language inference (NLI) dataset for fine-tuning.We aim to improve sentence embeddings without using large manually annotated datasets by automatically... | Soma Sato, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda |  |
| 44 |  |  [Curriculum Learning for Small Code Language Models](https://doi.org/10.18653/v1/2024.acl-srw.44) |  | 0 | Code language models have emerged as useful tools for various programming tasks, yet they often struggle when it comes to complex ones. In this paper, we explore the potential of curriculum learning in enhancing the performance of these models. While prior research has suggested that curriculum learning does not necessarily help in improving the performance of language models, our results surprisingly show that this may not be the case for code language models. We demonstrate that a... | Marwa Naïr, Kamel Mohammed Yamani, Lynda Said L'Hadj, Riyadh Baghdadi |  |
| 45 |  |  [Question-Analysis Prompting Improves LLM Performance in Reasoning Tasks](https://doi.org/10.18653/v1/2024.acl-srw.45) |  | 0 | Although LLMs have the potential to transform many fields, they still underperform humans in reasoning tasks. Existing methods induce the model to produce step-by-step calculations, but this research explores the question: Does making the LLM analyze the question improve its performance? We propose a novel prompting strategy called Question Analysis Prompting (QAP), in which the model is prompted to explain the question in ’n’ words before solving. The value of ’n’ influences the length of... | Dharunish Yugeswardeenoo, Kevin Zhu, Sean O'Brien |  |
| 46 |  |  [An Individualized News Affective Response Dataset](https://doi.org/10.18653/v1/2024.acl-srw.46) |  | 0 |  | Tiancheng Hu, Nigel Collier |  |
| 47 |  |  [How Well Do Vision Models Encode Diagram Attributes?](https://doi.org/10.18653/v1/2024.acl-srw.47) |  | 0 |  | Haruto Yoshida, Keito Kudo, Yoichi Aoki, Ryota Tanaka, Itsumi Saito, Keisuke Sakaguchi, Kentaro Inui |  |
| 48 |  |  [CheckersGPT: Learning World Models through Language Modeling](https://doi.org/10.18653/v1/2024.acl-srw.48) |  | 0 | Although Large Language Models (LLMs) have been trained using just the next token prediction objective, these have shown impressive performance on various tasks. Consequently, it has attracted research interests in this regard. While one line of work in the past has suggested that LLMs learn surface-level statistics from the dataset, another line of work emphasizes that the learned representations are effective for simulating the underlying world model, considering the causal relationship for... | Abhinav Joshi, Vaibhav Sharma, Ashutosh Modi |  |
| 49 |  |  [In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery](https://doi.org/10.18653/v1/2024.acl-srw.49) |  | 0 | State of the art Symbolic Regression (SR) methods currently build specialized models, while the application of Large Language Models (LLMs) remains largely unexplored. In this work, we introduce the first comprehensive framework that utilizes LLMs for the task of SR.We propose In-Context Symbolic Regression (ICSR), an SR method which iteratively refines a functional form with an LLM and determines its coefficients with an external optimizer. ICSR leverages LLMs’ strong mathematical prior both... | Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen |  |
| 50 |  |  [STEP: Staged Parameter-Efficient Pre-training for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.50) |  | 0 | We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity, and cultural context. We propose a seed-data-free framework for generating synthetic instruction-tuning data that incorporates these essential properties. Our framework employs an LLM to generate... | Kazuki Yano, Takumi Ito, Jun Suzuki |  |
| 51 |  |  [Can Language Models Serve as Text-Based World Simulators?](https://doi.org/10.18653/v1/2024.acl-short.1) |  | 0 | Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called... | Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, MarcAlexandre Côté, Peter Clark, Peter A. Jansen |  |
| 52 |  |  [FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.2) |  | 0 | One type of question that is commonly found in day-to-day scenarios is “fan-out” questions, complex multi-hop, multi-document reasoning questions that require finding information about a large number of entities. However, there exist few resources to evaluate this type of question-answering capability among large language models. To evaluate complex reasoning in LLMs more fully, we present FanOutQA, a high-quality dataset of fan-out question-answer pairs and human-annotated decompositions with... | Andrew Zhu, Alyssa Hwang, Liam Dugan, Chris CallisonBurch |  |
| 53 |  |  [Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance](https://doi.org/10.18653/v1/2024.acl-short.3) |  | 0 | This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity metrics. Our experiments showcase the effectiveness of AST editing distance in capturing intricate code structures, revealing a high correlation with established metrics. Furthermore, we explore the... | Yewei Song, Cedric Lothritz, Xunzhu Tang, Tegawendé F. Bissyandé, Jacques Klein |  |
| 54 |  |  [Resisting the Lure of the Skyline: Grounding Practices in Active Learning for Morphological Inflection](https://doi.org/10.18653/v1/2024.acl-short.4) |  | 0 | Active learning (AL) aims to lower the demand of annotation by selecting informative unannotated samples for the model building. In this paper, we explore the importance of conscious experimental design in the language documentation and description setting, particularly the distribution of the unannotated sample pool. We focus on the task of morphological inflection using a Transformer model. We propose context motivated benchmarks: a baseline and skyline. The baseline describes the frequency... | Saliha Muradoglu, Michael Ginn, Miikka Silfverberg, Mans Hulden |  |
| 55 |  |  [Speculative Contrastive Decoding](https://doi.org/10.18653/v1/2024.acl-short.5) |  | 0 | Large language models (LLMs) exhibit exceptional performance in language tasks, yet their auto-regressive inference is limited due to high computational requirements and is sub-optimal due to the exposure bias. Inspired by speculative decoding and contrastive decoding, we introduce Speculative Contrastive Decoding (SCD), a straightforward yet powerful decoding approach that leverages predictions from smaller language models (LMs) to achieve both decoding acceleration and quality improvement.... | Hongyi Yuan, Keming Lu, Fei Huang, Zheng Yuan, Chang Zhou |  |
| 56 |  |  [RDRec: Rationale Distillation for LLM-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.6) |  | 0 | Large language model (LLM)-based recommender models that bridge users and items through textual prompts for effective semantic reasoning have gained considerable attention. However, few methods consider the underlying rationales behind interactions, such as user preferences and item attributes, limiting the reasoning ability of LLMs for recommendations. This paper proposes a rationale distillation recommender (RDRec), a compact model designed to learn rationales generated by a larger language... | Xinfeng Wang, Jin Cui, Yoshimi Suzuki, Fumiyo Fukumoto |  |
| 57 |  |  [Isotropy, Clusters, and Classifiers](https://doi.org/10.18653/v1/2024.acl-short.7) |  | 0 | Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters—which also negatively impacts linear classification objectives. We demonstrate this fact both empirically and mathematically and use... | Timothee Mickus, StigArne Grönroos, Joseph Attieh |  |
| 58 |  |  [Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks](https://doi.org/10.18653/v1/2024.acl-short.8) |  | 0 | The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate. We show that LLMs are frequently able to correctly and confidently predict the first digit of n-digit by m-digit multiplication tasks without using chain of thought reasoning, despite these tasks require compounding operations to solve. Simultaneously, LLMs in practice often fail to correctly or confidently predict the last digit of an n-digit by... | Andrew Gambardella, Yusuke Iwasawa, Yutaka Matsuo |  |
| 59 |  |  [Simpson's Paradox and the Accuracy-Fluency Tradeoff in Translation](https://doi.org/10.18653/v1/2024.acl-short.9) |  | 0 | A good translation should be faithful to the source and should respect the norms of the target language. We address a theoretical puzzle about the relationship between these objectives. On one hand, intuition and some prior work suggest that accuracy and fluency should trade off against each other, and that capturing every detail of the source can only be achieved at the cost of fluency. On the other hand, quality assessment researchers often suggest that accuracy and fluency are highly... | Zheng Wei Lim, Ekaterina Vylomova, Trevor Cohn, Charles Kemp |  |
| 60 |  |  [UltraSparseBERT: 99% Conditionally Sparse Language Modelling](https://doi.org/10.18653/v1/2024.acl-short.10) |  | 0 | We present UltraSparseBERT, a BERT variant that uses 0.3% of its neurons during inference while performing on par with similar BERT models. UltraSparseBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by reorganizing feedforward networks into fast feedforward networks (FFFs).To showcase but one benefit of high sparsity, we provide an Intel MKL implementation achieving 78x speedup over the optimized feedforward baseline on CPUs, and an OpenAI Triton... | Peter Belcak, Roger Wattenhofer |  |
| 61 |  |  [SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark](https://doi.org/10.18653/v1/2024.acl-short.11) |  | 0 | The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models’ abilities. Additionally, our... | Zhenwen Liang, Kehan Guo, Gang Liu, Taicheng Guo, Yujun Zhou, Tianyu Yang, Jiajun Jiao, Renjie Pi, Jipeng Zhang, Xiangliang Zhang |  |
| 62 |  |  [On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.12) |  | 0 | Retrieval augmented generation (RAG) exhibits outstanding performance in promoting the knowledge capabilities of large language models (LLMs) with retrieved documents related to user queries. However, RAG only focuses on improving the response quality of LLMs via enhancing queries indiscriminately with retrieved information, paying little attention to what type of knowledge LLMs really need to answer original queries more accurately. In this paper, we suggest that long-tail knowledge is crucial... | Dongyang Li, Junbing Yan, Taolin Zhang, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue, Jun Huang |  |
| 63 |  |  [IEPile: Unearthing Large Scale Schema-Conditioned Information Extraction Corpus](https://doi.org/10.18653/v1/2024.acl-short.13) |  | 0 | Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE datasets tend to be small in scale, fragmented, and lack standardized schema. To this end, we introduce IEPile, a comprehensive bilingual (English and Chinese) IE instruction corpus, which contains... | Honghao Gui, Lin Yuan, Hongbin Ye, Ningyu Zhang, Mengshu Sun, Lei Liang, Huajun Chen |  |
| 64 |  |  [Bi-Directional Multi-Granularity Generation Framework for Knowledge Graph-to-Text with Large Language Model](https://doi.org/10.18653/v1/2024.acl-short.14) |  | 0 | The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. Existing methods generate the whole target text based on all KG triples at once and may incorporate incorrect KG triples for each sentence. To this end, we propose the bi-directional multi-granularity generation framework. Instead of generating the whole text at a time, we construct the sentence level... | Haowei Du, Chen Li, Dinghao Zhang, Dongyan Zhao |  |
| 65 |  |  [Code-Switching Can be Better Aligners: Advancing Cross-Lingual SLU through Representation-Level and Prediction-Level Alignment](https://doi.org/10.18653/v1/2024.acl-short.15) |  | 0 | Zero-shot cross-lingual spoken language understanding (SLU) can promote the globalization application of dialog systems, which has attracted increasing attention. While current code-switching based cross-lingual SLU frameworks have shown promising results, they (i) predominantly utilize contrastive objectives to model hard alignment, which may disrupt the inherent structure within sentences of each language; and (ii) focus optimization objectives solely on the original sentences, neglecting the... | Zhihong Zhu, Xuxin Cheng, Zhanpeng Chen, Xianwei Zhuang, Zhiqi Huang, Yuexian Zou |  |
| 66 |  |  [AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://doi.org/10.18653/v1/2024.acl-short.16) |  | 0 | We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low-Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each of which is followed by a feature transformation vector. Based on a novel freezing score, we incrementally freeze these projection matrices during fine-tuning to reduce the computation and alleviate... | Zeyu Liu, Souvik Kundu, Anni Li, Junrui Wan, Lianghao Jiang, Peter A. Beerel |  |
| 67 |  |  [DDPrompt: Differential Diversity Prompting in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.17) |  | 0 | Large Language Models (LLMs) have shown that their reasoning ability could be enhanced through approaches like Chain-of-Thought (CoT) prompting. However, these methods use single prompts for different types of questions and do not design appropriate prompts for questions with different characteristics. In this paper, we aim to explore a methodology that generates differentially diverse reasoning paths for different types of questions. To achieve this, we propose a novel prompting strategy... | Lin Mu, Wenhao Zhang, Yiwen Zhang, Peiquan Jin |  |
| 68 |  |  [Monotonic Representation of Numeric Attributes in Language Models](https://doi.org/10.18653/v1/2024.acl-short.18) |  | 0 | Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model’s internal representations is not understood well. Here, we introduce a method for finding and editing representations of numeric properties such as an entity’s birth year. We find directions that encode numeric properties monotonically, in an interpretable fashion. When editing representations along these directions, LM... | Benjamin Heinzerling, Kentaro Inui |  |
| 69 |  |  [Two Issues with Chinese Spelling Correction and A Refinement Solution](https://doi.org/10.18653/v1/2024.acl-short.19) |  | 0 | The Chinese Spelling Correction (CSC) task aims to detect and correct misspelled characters in Chinese text, and has received lots of attention in the past few years. Most recent studies adopt a Transformer-based model and leverage different features of characters such as pronunciation, glyph and contextual information to enhance the model’s ability to complete the task. Despite their state-of-the-art performance, we observe two issues that should be addressed to further advance the CSC task.... | Changxuan Sun, Linlin She, Xuesong Lu |  |
| 70 |  |  [DynaSemble: Dynamic Ensembling of Textual and Structure-Based Models for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-short.20) |  | 0 | We consider two popular approaches to KnowledgeGraph Completion (KGC): textual modelsthat rely on textual entity descriptions, andstructure-based models that exploit the connectivitystructure of the Knowledge Graph(KG). Preliminary experiments show that theseapproaches have complementary strengths:structure-based models perform exceptionallywell when the gold answer is easily reachablefrom the query head in the KG, while textualmodels exploit descriptions to give goodperformance even when the... | Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam |  |
| 71 |  |  [Fine-Tuning Pre-Trained Language Models with Gaze Supervision](https://doi.org/10.18653/v1/2024.acl-short.21) |  | 0 | Human gaze data provide cognitive information that reflect human language comprehension and has been effectively integrated into a variety of natural language processing (NLP) tasks, demonstrating improved performance over corresponding plain text-based models. In this work, we propose to integrate a gaze module into pre-trained language models (LMs) at the fine-tuning stage to improve their capabilities to learn representations that are grounded in human language processing. This is done by... | Shuwen Deng, Paul Prasse, David R. Reich, Tobias Scheffer, Lena A. Jäger |  |
| 72 |  |  [Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech](https://doi.org/10.18653/v1/2024.acl-short.22) |  | 0 | Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task (Pupier et al. 2022), as a way of incorporating prosodic information in the parsing system and bypassing the limitations of a pipeline approach that would consist of using first an Automatic Speech Recognition (ASR) system and then a syntactic parser. In this article, we report on a set of experiments aiming at assessing the performance of two parsing paradigms... | Adrien Pupier, Maximin Coavoux, Jérôme Goulian, Benjamin Lecouteux |  |
| 73 |  |  [Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access](https://doi.org/10.18653/v1/2024.acl-short.23) |  | 0 | Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding... | Saibo Geng, Berkay Döner, Chris Wendler, Martin Josifoski, Robert West |  |
| 74 |  |  [On the Semantic Latent Space of Diffusion-Based Text-To-Speech Models](https://doi.org/10.18653/v1/2024.acl-short.24) |  | 0 | The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized speech’s vocal properties remains a challenge. Inspired by recent advances in image synthesis, we explore the latent space of frozen TTS models, which is composed of the latent bottleneck activations of... | Miri VarshavskyHassid, Roy Hirsch, Regev Cohen, Tomer Golany, Daniel Freedman, Ehud Rivlin |  |
| 75 |  |  [Learnable Privacy Neurons Localization in Language Models](https://doi.org/10.18653/v1/2024.acl-short.25) |  | 0 | Concerns regarding Large Language Models (LLMs) to memorize and disclose private information, particularly Personally Identifiable Information (PII), become prominent within the community. Many efforts have been made to mitigate the privacy risks.However, the mechanism through which LLMs memorize PII remains poorly understood. To bridge this gap, we introduce a pioneering method for pinpointing PII-sensitive neurons (privacy neurons) within LLMs. Our method employs learnable binary weight masks... | Ruizhe Chen, Tianxiang Hu, Yang Feng, Zuozhu Liu |  |
| 76 |  |  [Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs](https://doi.org/10.18653/v1/2024.acl-short.26) |  | 0 | Humans often express their communicative intents indirectly or non-literally, which requires their interlocutors—human or AI—to understand beyond the literal meaning of words. While most existing work has focused on discriminative evaluations, we present a new approach to generatively evaluate large language models’ (LLMs’) intention understanding by examining their responses to non-literal utterances. Ideally, an LLM should respond in line with the true intention of a non-literal utterance,... | Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap |  |
| 77 |  |  [Generating Harder Cross-document Event Coreference Resolution Datasets using Metaphoric Paraphrasing](https://doi.org/10.18653/v1/2024.acl-short.27) |  | 0 | The most popular Cross-Document Event Coreference Resolution (CDEC) datasets fail to convey the true difficulty of the task, due to the lack of lexical diversity between coreferring event triggers (words or phrases that refer to an event). Furthermore, there is a dearth of event datasets for figurative language, limiting a crucial avenue of research in event comprehension. We address these two issues by introducing ECB+META, a lexically rich variant of Event Coref Bank Plus (ECB+) for CDEC on... | Shafiuddin Rehan Ahmed, Zhiyong Eric Wang, George Baker, Kevin Stowe, James H. Martin |  |
| 78 |  |  [Soft Self-Consistency Improves Language Models Agents](https://doi.org/10.18653/v1/2024.acl-short.28) |  | 0 | Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current “sample and select” methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for interactive tasks that involve generating multiple actions (answers) sequentially. After establishing... | Han Wang, Archiki Prasad, Elias StengelEskin, Mohit Bansal |  |
| 79 |  |  [RecGPT: Generative Pre-training for Text-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.29) |  | 0 | We present the first domain-adapted and fully-trained large language model, RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for text-based recommendation. Experimental results on rating prediction and sequential recommendation tasks show that our model, RecGPT-7B-Instruct, outperforms previous strong baselines. We are releasing our RecGPT models as well as their pre-training and fine-tuning datasets to facilitate future research and downstream applications in text-based... | Hoang Ngo, Dat Quoc Nguyen |  |
| 80 |  |  [MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations](https://doi.org/10.18653/v1/2024.acl-short.30) |  | 0 | Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence high-lighting changes in emotions, behaviors, perspectives,... | GiaBao Dinh Ho, Chang Wei Tan, Zahra Zamanzadeh Darban, Mahsa Salehi, Reza Haffari, Wray L. Buntine |  |
| 81 |  |  [What Does Parameter-free Probing Really Uncover?](https://doi.org/10.18653/v1/2024.acl-short.31) |  | 0 | Supervised approaches to probing large language models (LLMs) have been criticized of using pre-defined theory-laden target labels. As an alternative, parameter-free probing constructs structural representations bottom-up via information derived from the LLM alone. This has been suggested to capture a genuine “LLM-internal grammar”. However, its relation to familiar linguistic formalisms remains unclear. I extend prior work on a parameter-free probing technique called perturbed masking applied... | Tommi BuderGröndahl |  |
| 82 |  |  [ATLAS: Improving Lay Summarisation with Attribute-based Control](https://doi.org/10.18653/v1/2024.acl-short.32) |  | 0 | Lay summarisation aims to produce summaries of scientific articles that are comprehensible to non-expert audiences. However, previous work assumes a one-size-fits-all approach, where the content and style of the produced summary are entirely dependent on the data used to train the model. In practice, audiences with different levels of expertise will have specific needs, impacting what content should appear in a lay summary and how it should be presented. Aiming to address this, we propose... | Zhihao Zhang, Tomas Goldsack, Carolina Scarton, Chenghua Lin |  |
| 83 |  |  [EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-short.33) |  | 0 | The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated, leaving the gap between current LVLMs and qualified embodied intelligence unknown. Therefore, we construct EmbSpatial-Bench, a benchmark for evaluating embodied spatial understanding of LVLMs. The benchmark is automatically derived from embodied scenes and covers 6... | Mengfei Du, Binhao Wu, Zejun Li, Xuanjing Huang, Zhongyu Wei |  |
| 84 |  |  [Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark](https://doi.org/10.18653/v1/2024.acl-short.34) |  | 0 | Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of noise, such as ambiguous questions and syntactical errors. This study provides an in-depth analysis of the distribution and types of noise in the widely used BIRD-Bench benchmark and the impact of noise on... | Niklas Wretblad, Fredrik Gordh Riseby, Rahul Biswas, Amin Ahmadi, Oskar Holmström |  |
| 85 |  |  [Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-short.35) |  | 0 | This study investigates the existence of positional biases in Transformer-based language models for text representation learning, particularly in the context of web document retrieval. We build on previous research that demonstrated loss of information in the middle of input sequences for causal language models, extending it to the domain of embedding learning. We examine positional biases at multiple stages of the training pipeline for an encoder-decoder neural retrieval model, namely language... | João Coelho, Bruno Martins, João Magalhães, Jamie Callan, Chenyan Xiong |  |
| 86 |  |  [That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses](https://doi.org/10.18653/v1/2024.acl-short.36) |  | 0 | The Uniform Information Density (UID) hypothesis posits that speakers optimize the communicative properties of their utterances by avoiding spikes in information, thereby maintaining a relatively uniform information profile over time. This paper investigates the impact of UID principles on syntactic reduction, specifically focusing on the optional omission of the connector “that” in English subordinate clauses. Building upon previous research, we extend our investigation to a larger corpus of... | Ella Rabinovich |  |
| 87 |  |  [Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?](https://doi.org/10.18653/v1/2024.acl-short.37) |  | 0 | We examine whether large language models (LLMs) exhibit race- and gender-based name discrimination in hiring decisions, similar to classic findings in the social sciences (Bertrand and Mullainathan, 2004). We design a series of templatic prompts to LLMs to write an email to a named job applicant informing them of a hiring decision. By manipulating the applicant’s first name, we measure the effect of perceived race, ethnicity, and gender on the probability that the LLM generates an acceptance or... | Haozhe An, Christabel Acquaye, Colin Wang, Zongxia Li, Rachel Rudinger |  |
| 88 |  |  [Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster](https://doi.org/10.18653/v1/2024.acl-short.38) |  | 0 | Content moderators play a key role in keeping the conversation on social media healthy. While the high volume of content they need to judge represents a bottleneck to the moderation pipeline, no studies have explored how models could support them to make faster decisions. There is, by now, a vast body of research into detecting hate speech, sometimes explicitly motivated by a desire to help improve content moderation, but published research using real content moderators is scarce. In this work... | Agostina Calabrese, Leonardo Neves, Neil Shah, Maarten W. Bos, Björn Ross, Mirella Lapata, Francesco Barbieri |  |
| 89 |  |  [Born Differently Makes a Difference: Counterfactual Study of Bias in Biography Generation from a Data-to-Text Perspective](https://doi.org/10.18653/v1/2024.acl-short.39) |  | 0 | How do personal attributes affect biography generation? Addressing this question requires an identical pair of biographies where only the personal attributes of interest are different. However, it is rare in the real world. To address this, we propose a counterfactual methodology from a data-to-text perspective, manipulating the personal attributes of interest while keeping the co-occurring attributes unchanged. We first validate that the fine-tuned Flan-T5 model generates the biographies based... | Biaoyan Fang, Ritvik Dinesh, Xiang Dai, Sarvnaz Karimi |  |
| 90 |  |  [Sign Language Translation with Sentence Embedding Supervision](https://doi.org/10.18653/v1/2024.acl-short.40) |  | 0 | State-of-the-art sign language translation (SLT) systems facilitate the learning process through gloss annotations, either in an end2end manner or by involving an intermediate step. Unfortunately, gloss labelled sign language data is usually not available at scale and, when available, gloss annotations widely differ from dataset to dataset. We present a novel approach using sentence embeddings of the target sentences at training time that take the role of glosses. The new kind of supervision... | Yasser Hamidullah, Josef van Genabith, Cristina EspañaBonet |  |
| 91 |  |  [STREAM: Simplified Topic Retrieval, Exploration, and Analysis Module](https://doi.org/10.18653/v1/2024.acl-short.41) |  | 0 | Topic modeling is a widely used technique to analyze large document corpora. With the ever-growing emergence of scientific contributions in the field, non-technical users may often use the simplest available software module, independent of whether there are potentially better models available. We present a Simplified Topic Retrieval, Exploration, and Analysis Module (STREAM) for user-friendly topic modelling and especially subsequent interactive topic visualization and analysis. For better... | Anton Thielmann, Arik Reuter, Christoph Weisser, Gillian Kant, Manish Kumar, Benjamin Säfken |  |
| 92 |  |  [DocFinQA: A Long-Context Financial Reasoning Dataset](https://doi.org/10.18653/v1/2024.acl-short.42) |  | 0 | For large language models (LLMs) to be effective in the financial domain – where each decision can have a significant impact – it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents spanning hundreds of pages, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with full-document... | Varshini Reddy, Rik KoncelKedziorski, Viet Dac Lai, Michael Krumdick, Charles Lovering, Chris Tanner |  |
| 93 |  |  [MaskLID: Code-Switching Language Identification through Iterative Masking](https://doi.org/10.18653/v1/2024.acl-short.43) |  | 0 | We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the... | Amir Hossein Kargaran, François Yvon, Hinrich Schütze |  |
| 94 |  |  [An Empirical Analysis on Large Language Models in Debate Evaluation](https://doi.org/10.18653/v1/2024.acl-short.44) |  | 0 | In this study, we investigate the capabilities and inherent biases of advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context of debate evaluation. We discover that LLM’s performance exceeds humans and surpasses the performance of state-of-the-art methods fine-tuned on extensive datasets. We additionally explore and analyze biases present in LLMs, including positional bias, lexical bias, order bias, which may affect their evaluative judgments. Our findings reveal a... | Xinyi Liu, Pinxin Liu, Hangfeng He |  |
| 95 |  |  [Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains](https://doi.org/10.18653/v1/2024.acl-short.45) |  | 0 | We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to both metrics that rely on the surface form and... | Vilém Zouhar, Shuoyang Ding, Anna Currey, Tatyana Badeka, Jenyuan Wang, Brian Thompson |  |
| 96 |  |  [IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages](https://doi.org/10.18653/v1/2024.acl-short.46) |  | 0 | In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include (a) INDIC-MARCO, a multilingual version of the MS MARCO dataset in 11 Indian Languages created using Machine Translation, and (b) Indic-ColBERT, a collection of 11 distinct Monolingual Neural... | Saiful Haq, Ashutosh Sharma, Omar Khattab, Niyati Chhaya, Pushpak Bhattacharyya |  |
| 97 |  |  [AGR: Reinforced Causal Agent-Guided Self-explaining Rationalization](https://doi.org/10.18653/v1/2024.acl-short.47) |  | 0 | Most existing rationalization approaches are susceptible to degeneration accumulation due to a lack of effective control over the learning direction of the model during training. To address this issue, we propose a novel approach AGR (Agent-Guided Rationalization), guiding the next action of the model based on its current training state. Specifically, we introduce causal intervention calculus to quantify the causal effects inherent during rationale training, and utilize reinforcement learning... | Yunxiao Zhao, Zhiqiang Wang, Xiaoli Li, Jiye Liang, Ru Li |  |
| 98 |  |  [Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research](https://doi.org/10.18653/v1/2024.acl-short.48) |  | 0 | We analysed a sample of NLP research papers archived in ACL Anthology as an attempt to quantify the degree of openness and the benefit of such an open culture in the NLP community. We observe that papers published in different NLP venues show different patterns related to artefact reuse. We also note that more than 30% of the papers we analysed do not release their artefacts publicly. Further, we observe a wide language-wise disparity in publicly available NLP-related artefacts. | Surangika Ranathunga, Nisansa de Silva, Dilith Jayakody, Aloka Fernando |  |
| 99 |  |  [The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.49) |  | 0 | In order to oversee advanced AI systems, it is important to understand their reasons for generating a given output. When prompted, large language models (LLMs) can provide natural language explanations or reasoning traces that sound plausible and receive high ratings from human annotators. However, it is unclear to what extent these explanations are truly capturing the factors responsible for the model’s predictions: the most “human-like” explanation may be different from the one that is most... | Noah Y. Siegel, OanaMaria Camburu, Nicolas Heess, María PérezOrtiz |  |
| 100 |  |  [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](https://doi.org/10.18653/v1/2024.acl-short.50) |  | 0 | While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision & Language Large Language Models (VLLMs) can mimic this crucial feature of language use is an open question. This applies to common, everyday objects, but it is particularly interesting for uncommon or novel objects for which a category label may be lacking or fuzzy.... | Alberto Testoni, Juell Sprott, Sandro Pezzelle |  |
| 101 |  |  [Are LLMs classical or nonmonotonic reasoners? Lessons from generics](https://doi.org/10.18653/v1/2024.acl-short.51) |  | 0 | Recent scholarship on reasoning in LLMs has supplied evidence of impressive performance and flexible adaptation to machine generated or human critique. Nonmonotonic reasoning, crucial to human cognition for navigating the real world, remains a challenging, yet understudied task. In this work, we study nonmonotonic reasoning capabilities of seven state-of-the-art LLMs in one abstract and one commonsense reasoning task featuring generics, such as ‘Birds fly’, and exceptions, ‘Penguins don’t fly’... | Alina Leidinger, Robert van Rooij, Ekaterina Shutova |  |
| 102 |  |  [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](https://doi.org/10.18653/v1/2024.acl-short.52) |  | 0 | Large language models (LLMs) are highly capable at a variety of tasks given the right prompt, but writing one is still a difficult and tedious process. In this work, we introduce ConstitutionalExperts, a method for learning a prompt consisting of constitutional principles (i.e. rules), given a training dataset. Unlike prior methods that optimize the prompt as a single entity, our method incrementally improves the prompt by surgically editing individual principles. We also show that we can... | Savvas Petridis, Ben Wedin, Ann Yuan, James Wexler, Nithum Thain |  |
| 103 |  |  [Time Sensitive Knowledge Editing through Efficient Finetuning](https://doi.org/10.18653/v1/2024.acl-short.53) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capability in different tasks and are bringing transformative changes to many domains. However, keeping the knowledge in LLMs up-to-date remains a challenge once pretraining is complete. It is thus essential to design effective methods to both update obsolete knowledge and induce new knowledge into LLMs. Existing locate-and-edit knowledge editing (KE) method suffers from two limitations. First, the post-edit LLMs by such methods... | Xiou Ge, Ali Mousavi, Edouard Grave, Armand Joulin, Kun Qian, Benjamin Han, Mostafa Arefiyan, Yunyao Li |  |
| 104 |  |  [PRewrite: Prompt Rewriting with Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-short.54) |  | 0 | Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a “trial and error” fashion that can be time consuming, ineffective, and sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the prompts be made better with further modifications?To address these problems, we investigate automated prompt engineering in this paper. Specifically, we propose PRewrite, an automated method to rewrite... | Weize Kong, Spurthi Amba Hombaiah, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky |  |
| 105 |  |  [Paraphrasing in Affirmative Terms Improves Negation Understanding](https://doi.org/10.18653/v1/2024.acl-short.55) |  | 0 | Negation is a common linguistic phenomenon. Yet language models face challenges with negation in many natural language understanding tasks such as question answering and natural language inference. In this paper, we experiment with seamless strategies that incorporate affirmative interpretations (i.e., paraphrases without negation) to make models more robust against negation. Crucially, our affirmative interpretations are obtained automatically. We show improvements with CondaQA, a large corpus... | MohammadHossein Rezaei, Eduardo Blanco |  |
| 106 |  |  [Exploring Conditional Variational Mechanism to Pinyin Input Method for Addressing One-to-Many Mappings in Low-Resource Scenarios](https://doi.org/10.18653/v1/2024.acl-short.56) |  | 0 | Pinyin input method engine (IME) refers to the transformation tool from pinyin sequence to Chinese characters, which is widely used on mobile phone applications. Due to the homophones, Pinyin IME suffers from the one-to-many mapping problem in the process of pinyin sequences to Chinese characters. To solve the above issue, this paper makes the first exploration to leverage an effective conditional variational mechanism (CVM) for pinyin IME. However, to ensure the stable and smooth operation of... | Bin Sun, Jianfeng Li, Hao Zhou, Fandong Meng, Kan Li, Jie Zhou |  |
| 107 |  |  [Consistency Training by Synthetic Question Generation for Conversational Question Answering](https://doi.org/10.18653/v1/2024.acl-short.57) |  | 0 | Efficiently modeling historical information is a critical component in addressing user queries within a conversational question-answering (QA) context, as historical context plays a vital role in clarifying the user’s questions. However, irrelevant history induces noise in the reasoning process, especially for those questions with a considerable historical context. In our novel model-agnostic approach, referred to as \*\*CoTaH\*\* (\*\*Co\*\*nsistency-\*\*T\*\*rained \*\*a\*\*ugmented... | Hamed Hematian Hemati, Hamid Beigy |  |
| 108 |  |  [How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?](https://doi.org/10.18653/v1/2024.acl-short.58) |  | 0 | While machine translation evaluation has been studied primarily for high-resource languages, there has been a recent interest in evaluation for low-resource languages due to the increasing availability of data and models. In this paper, we focus on a zero-shot evaluation setting focusing on low-resource Indian languages, namely Assamese, Kannada, Maithili, and Punjabi. We collect sufficient Multi-Dimensional Quality Metrics (MQM) and Direct Assessment (DA) annotations to create test sets and... | Anushka Singh, Ananya Sai, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Mitesh M. Khapra |  |
| 109 |  |  [Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-short.59) |  | 0 | Large language models (LLMs) as listwise rerankers have shown impressive zero-shot capabilities in various passage ranking tasks. Despite their success, there is still a gap in existing literature on their effectiveness in reranking low-resource languages. To address this, we investigate how LLMs function as listwise rerankers in cross-lingual information retrieval (CLIR) systems with queries in English and passages in four African languages: Hausa, Somali, Swahili, and Yoruba. We analyze and... | Mofetoluwa Adeyemi, Akintunde Oladipo, Ronak Pradeep, Jimmy Lin |  |
| 110 |  |  [Cross-Modal Projection in Multimodal LLMs Doesn't Really Project Visual Attributes to Textual Space](https://doi.org/10.18653/v1/2024.acl-short.60) |  | 0 | Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to... | Gaurav Verma, Minje Choi, Kartik Sharma, Jamelle WatsonDaniels, Sejoon Oh, Srijan Kumar |  |
| 111 |  |  [Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-short.61) |  | 0 | While the abundance of rich and vast datasets across numerous fields has facilitated the advancement of natural language processing, sectors in need of specialized data types continue to struggle with the challenge of finding quality data. Our study introduces a novel guidance data augmentation technique utilizing abstracted context and sentence structures to produce varied sentences while maintaining context-entity relationships, addressing data scarcity challenges. By fostering a closer... | Hyeonseok Kang, Hyein Seo, Jeesu Jung, Sangkeun Jung, DuSeong Chang, Riwoo Chung |  |
| 112 |  |  [Aligning Large Language Models via Fine-grained Supervision](https://doi.org/10.18653/v1/2024.acl-short.62) |  | 0 | Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by transforming coarse human preferences of LLM outputs into a feedback signal that guides the model learning process. However, because this approach operates on sequence-level feedback, it lacks the... | Dehong Xu, Liang Qiu, Minseok Kim, Faisal Ladhak, Jaeyoung Do |  |
| 113 |  |  [Annotating FrameNet via Structure-Conditioned Language Generation](https://doi.org/10.18653/v1/2024.acl-short.63) |  | 0 | Despite the remarkable generative capabilities of language models in producing naturalistic language, their effectiveness on explicit manipulation and generation of linguistic structures remain understudied. In this paper, we investigate the task of generating new sentences preserving a given semantic structure, following the FrameNet formalism. We propose a framework to produce novel frame-semantically annotated sentences following an overgenerate-and-filter approach. Our results show that... | Xinyue Cui, Swabha Swayamdipta |  |
| 114 |  |  [DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms](https://doi.org/10.18653/v1/2024.acl-short.64) |  | 0 | Recently, large language models (LLMs) enhanced by self-reflection have achieved promising performance on machine transla004 tion. The key idea is guiding LLMs to generate translation with human-like feedback. However, existing self-reflection methods lack effective feedback information, limiting the translation performance. To address this, we introduce a DUAL-REFLECT framework, leveraging the dual learning of translation tasks to provide effective feedback, thereby enhancing the models’... | Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang |  |
| 115 |  |  [Towards Artwork Explanation in Large-scale Vision Language Models](https://doi.org/10.18653/v1/2024.acl-short.65) |  | 0 | Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships between various pieces of knowledge, and how they integrate these understandings into their explanations. To address this issue, we propose a new task: the artwork explanation generation task, along... | Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe |  |
| 116 |  |  [On the Hallucination in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-short.66) |  | 0 | It is widely known that hallucination is a critical issue in Simultaneous Machine Translation (SiMT) due to the absence of source-side information. While many efforts have been made to enhance performance for SiMT, few of them attempt to understand and analyze hallucination in SiMT.Therefore, we conduct a comprehensive analysis of hallucination in SiMT from two perspectives: understanding the distribution of hallucination words and the target-side context usage of them.Intensive experiments... | Meizhi Zhong, Kehai Chen, Zhengshan Xue, Lemao Liu, Mingming Yang, Min Zhang |  |
| 117 |  |  [Self-Augmented In-Context Learning for Unsupervised Word Translation](https://doi.org/10.18653/v1/2024.acl-short.67) |  | 0 | Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of ‘traditional’ mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages. To address this challenge with LLMs, we propose self-augmented in-context learning (SAIL) for unsupervised BLI: starting from a... | Yaoyiran Li, Anna Korhonen, Ivan Vulic |  |
| 118 |  |  [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://doi.org/10.18653/v1/2024.acl-short.68) |  | 0 | We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary... | Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Bowen Jin, May Dongmei Wang, Joyce C. Ho, Carl Yang |  |
| 119 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.acl-long.0) |  | 0 |  |  |  |
| 120 |  |  [Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.1) |  | 0 | Finetuning large language models (LLMs) has been empirically effective on a variety of downstream tasks. Existing approaches to finetuning an LLM either focus on parameter-efficient finetuning, which only updates a small number of trainable parameters, or attempt to reduce the memory footprint during the training phase of the finetuning. Typically, the memory footprint during finetuning stems from three contributors: model weights, optimizer states, and intermediate activations. However,... | Zhengxin Zhang, Dan Zhao, Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Qing Li, Yong Jiang, Zhihao Jia |  |
| 121 |  |  [Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances](https://doi.org/10.18653/v1/2024.acl-long.2) |  | 0 | Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions. Existing methods manifest limitations in leveraging nonverbal information for discerning complex semantics in unsupervised scenarios. This paper introduces a novel unsupervised multimodal clustering method (UMC), making a pioneering contribution to this field. UMC introduces a unique approach to constructing augmentation views for multimodal data, which are... | Hanlei Zhang, Hua Xu, Fei Long, Xin Wang, Kai Gao |  |
| 122 |  |  [MAGE: Machine-generated Text Detection in the Wild](https://doi.org/10.18653/v1/2024.acl-long.3) |  | 0 | Large language models (LLMs) have achieved human-level text generation, emphasizing the need for effective deepfake text detection to mitigate risks like the spread of fake news and plagiarism. Existing research has been constrained by evaluating detection methods o specific domains or particular language models. In practical scenarios, however, the detector faces texts from various domains or LLMs without knowing their sources. To this end, we build a comprehensive testbed by gathering texts... | Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Zhilin Wang, Longyue Wang, Linyi Yang, Shuming Shi, Yue Zhang |  |
| 123 |  |  [PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models](https://doi.org/10.18653/v1/2024.acl-long.4) |  | 0 | The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP).... | Haoran Li, Dadi Guo, Donghao Li, Wei Fan, Qi Hu, Xin Liu, Chunkit Chan, Duanyi Yao, Yuan Yao, Yangqiu Song |  |
| 124 |  |  [GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators](https://doi.org/10.18653/v1/2024.acl-long.5) |  | 0 | Recent advances in large language models (LLMs) have stepped forward the development of multilingual speech and machine translation by its reduced representation errors and incorporated external knowledge. However, both translation tasks typically utilize beam search decoding and top-1 hypothesis selection for inference. These techniques struggle to fully exploit the rich information in the diverse N-best hypotheses, making them less optimal for translation tasks that require a single,... | Yuchen Hu, Chen Chen, ChaoHan Huck Yang, Ruizhe Li, Dong Zhang, Zhehuai Chen, Engsiong Chng |  |
| 125 |  |  [Exploring Chain-of-Thought for Multi-modal Metaphor Detection](https://doi.org/10.18653/v1/2024.acl-long.6) |  | 0 | Metaphors are commonly found in advertising and internet memes. However, the free form of internet memes often leads to a lack of high-quality textual data. Metaphor detection demands a deep interpretation of both textual and visual elements, requiring extensive common-sense knowledge, which poses a challenge to language models. To address these challenges, we propose a compact framework called C4MMD, which utilizes a Chain-of-Thought(CoT) method for Multi-modal Metaphor Detection.... | Yanzhi Xu, Yueying Hua, Shichen Li, Zhongqing Wang |  |
| 126 |  |  [BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation](https://doi.org/10.18653/v1/2024.acl-long.7) |  | 0 | The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges. Weight quantization has emerged as a widely embraced solution to reduce memory and computational demands. This paper introduces BitDistiller, a framework that synergizes Quantization-Aware Training (QAT) with Knowledge Distillation (KD) to boost the performance of LLMs at ultra-low precisions (sub-4-bit). Specifically, BitDistiller... | Dayou Du, Yijia Zhang, Shijie Cao, Jiaqi Guo, Ting Cao, Xiaowen Chu, Ningyi Xu |  |
| 127 |  |  [A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation](https://doi.org/10.18653/v1/2024.acl-long.8) |  | 0 | Temporal knowledge graph (TKG) reasoning has two settings: interpolation reasoning and extrapolation reasoning. Both of them draw plenty of research interest and have great significance. Methods of the former de-emphasize the temporal correlations among facts sequences, while methods of the latter require strict chronological order of knowledge and ignore inferring clues provided by missing facts of the past. These limit the practicability of TKG applications as almost all of the existing TKG... | Kai Chen, Ye Wang, Yitong Li, Aiping Li, Han Yu, Xin Song |  |
| 128 |  |  [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.9) |  | 0 | Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignore it or be misled by it. The key reason is that the training of LLMs does not clearly make LLMs learn how to utilize input retrieved texts with varied quality. In this paper, we propose a novel perspective that considers the role of LLMs in RAG as... | Shicheng Xu, Liang Pang, Mo Yu, Fandong Meng, Huawei Shen, Xueqi Cheng, Jie Zhou |  |
| 129 |  |  [CSCD-NS: a Chinese Spelling Check Dataset for Native Speakers](https://doi.org/10.18653/v1/2024.acl-long.10) |  | 0 | In this paper, we present CSCD-NS, the first Chinese spelling check (CSC) dataset designed for native speakers, containing 40,000 samples from a Chinese social platform. Compared with existing CSC datasets aimed at Chinese learners, CSCD-NS is ten times larger in scale and exhibits a distinct error distribution, with a significantly higher proportion of word-level errors. To further enhance the data resource, we propose a novel method that simulates the input process through an input method,... | Yong Hu, Fandong Meng, Jie Zhou |  |
| 130 |  |  [Evaluating Dynamic Topic Models](https://doi.org/10.18653/v1/2024.acl-long.11) |  | 0 | There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension combining topic quality with the model’s temporal consistency. We demonstrate the utility of the proposed measure by applying it to synthetic data and data from existing DTMs, including DTMs from large... | Charu James, Mayank Nagda, Nooshin Haji Ghassemi, Marius Kloft, Sophie Fellenz |  |
| 131 |  |  [How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition](https://doi.org/10.18653/v1/2024.acl-long.12) |  | 0 | Large language models (LLMs) with enormous pre-training tokens and parameters emerge diverse abilities, including math reasoning, codegeneration, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). While the open-source community has explored ad-hoc SFT for enhancing individual capabilities, proprietary LLMs exhibit versatility across various skills. Therefore, understanding the facilitation of multiple abilities via SFT is paramount. In this study,... | Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou |  |
| 132 |  |  [Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification](https://doi.org/10.18653/v1/2024.acl-long.13) |  | 0 | In legal decisions, split votes (SV) occur when judges cannot reach a unanimous decision, posing a difficulty for lawyers who must navigate diverse legal arguments and opinions. In high-stakes domains, %as human-AI interaction systems become increasingly important, understanding the alignment of perceived difficulty between humans and AI systems is crucial to build trust. However, existing NLP calibration methods focus on a classifier’s awareness of predictive performance, measured against the... | Shanshan Xu, T. Y. S. S. Santosh, Oana Ichim, Barbara Plank, Matthias Grabmair |  |
| 133 |  |  [Inference to the Best Explanation in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.14) |  | 0 | While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process is still poorly understood. This paper proposes IBE-Eval, a framework inspired by philosophical accounts on Inference to the Best Explanation (IBE) to advance the interpretation and evaluation of LLMs’ explanations. IBE-Eval estimates the plausibility of natural language explanations through a combination of explicit logical and linguistic features including: consistency,... | Dhairya Dalal, Marco Valentino, André Freitas, Paul Buitelaar |  |
| 134 |  |  [A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus](https://doi.org/10.18653/v1/2024.acl-long.15) |  | 0 | Natural language inference (NLI), the task of recognizing the entailment relationship in sentence pairs, is an actively studied topic serving as a proxy for natural language understanding. Despite the relevance of the task in building conversational agents and improving text classification, machine translation and other NLP tasks, to the best of our knowledge, there is no publicly available NLI corpus for the Romanian language. To this end, we introduce the first Romanian NLI corpus (RoNLI)... | Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu |  |
| 135 |  |  [MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering](https://doi.org/10.18653/v1/2024.acl-long.16) |  | 0 | Recent advances in few-shot question answering (QA) mostly rely on the power of pre-trained large language models (LLMs) and fine-tuning in specific settings. Although the pre-training stage has already equipped LLMs with powerful reasoning capabilities, LLMs still need to be fine-tuned to adapt to specific domains to achieve the best results. In this paper, we propose to select the most informative data for fine-tuning, thereby improving the efficiency of the fine-tuning process with... | Xiusi Chen, JyunYu Jiang, WeiCheng Chang, ChoJui Hsieh, HsiangFu Yu, Wei Wang |  |
| 136 |  |  [SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs](https://doi.org/10.18653/v1/2024.acl-long.17) |  | 0 | Large language models hold significant potential for integrating various data types, such as text documents and database records, for advanced analytics. However, blending text and numerical data presents substantial challenges. LLMs need to process and cross-reference entities and numbers, handle data inconsistencies and redundancies, and develop planning capabilities such as building a working memory for managing complex data queries. In this paper, we introduce four novel tasks centered... | Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, Dong Yu, Fei Liu |  |
| 137 |  |  [SciMON: Scientific Inspiration Machines Optimized for Novelty](https://doi.org/10.18653/v1/2024.acl-long.18) |  | 0 | We explore and enhance the ability of neural language models to generate novel scientific directions grounded in literature. Work on literature-based hypothesis generation has traditionally focused on binary link prediction—severely limiting the expressivity of hypotheses. This line of work also does not focus on optimizing novelty. We take a dramatic departure with a novel setting in which models use as input background contexts (e.g., problems, experimental settings, goals), and output... | Qingyun Wang, Doug Downey, Heng Ji, Tom Hope |  |
| 138 |  |  [Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction](https://doi.org/10.18653/v1/2024.acl-long.19) |  | 0 | We introduce EVLGen, a streamlined framework designed for the pre-training of visually conditioned language generation models with high computational demands, utilizing frozen pre-trained large language models (LLMs). The conventional approach in vision-language pre-training (VLP) typically involves a two-stage optimization process: an initial resource-intensive phase dedicated to general-purpose vision-language representation learning, focused on extracting and consolidating relevant visual... | Yiren Jian, Tingkai Liu, Yunzhe Tao, Chunhui Zhang, Soroush Vosoughi, Hongxia Yang |  |
| 139 |  |  [Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.20) |  | 0 | As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models. We introduce the concept of Confidence-Probability Alignment, that connects an LLM’s internal confidence, quantified by token probabilities, to the confidence conveyed in the model’s response when explicitly asked about its certainty. Using various datasets... | Abhishek Kumar, Robert Morabito, Sanzhar Umbet, Jad Kabbara, Ali Emami |  |
| 140 |  |  [Retrieval-Augmented Multilingual Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.21) |  | 0 | Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time. Updating knowledge via fine-tuning is computationally resource-hungry and not reliable, and so knowledge editing (KE) has developed as an effective and economical alternative to inject new knowledge or to fix factual errors in LLMs. Although there has been considerable interest in this area, current KE research exclusively focuses on monolingual settings, typically in English.... | Weixuan Wang, Barry Haddow, Alexandra Birch |  |
| 141 |  |  [Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge](https://doi.org/10.18653/v1/2024.acl-long.22) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable success in tasks like the Winograd Schema Challenge (WSC), showcasing advanced textual common-sense reasoning. However, applying this reasoning to multimodal domains, where understanding text and images together is essential, remains a substantial challenge. To address this, we introduce WinoVis, a novel dataset specifically designed to probe text-to-image models on pronoun disambiguation within multimodal contexts. Utilizing GPT-4 for... | Brendan Park, Madeline Janecek, Naser EzzatiJivan, Yifeng Li, Ali Emami |  |
| 142 |  |  [Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.23) |  | 0 | Research on Large Language Models (LLMs) has often neglected subtle biases that, although less apparent, can significantly influence the models’ outputs toward particular social narratives. This study addresses two such biases within LLMs: representative bias, which denotes a tendency of LLMs to generate outputs that mirror the experiences of certain identity groups, and affinity bias, reflecting the models’ evaluative preferences for specific narratives or viewpoints. We introduce two novel... | Abhishek Kumar, Sarfaroz Yunusov, Ali Emami |  |
| 143 |  |  [Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News](https://doi.org/10.18653/v1/2024.acl-long.24) |  | 0 | The mainstream media has much leeway in what it chooses to cover and how it covers it. These choices have real-world consequences on what people know and their subsequent behaviors. However, the lack of objective measures to evaluate editorial choices makes research in this area particularly difficult. In this paper, we argue that there are newsworthy topics where objective measures exist in the form of supporting data and propose a computational framework to analyze editorial choices in this... | Alexandria Leto, Elliot Pickens, Coen D. Needell, David Rothschild, Maria Leonor Pacheco |  |
| 144 |  |  [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences](https://doi.org/10.18653/v1/2024.acl-long.25) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate from image sequences, which is essential for understanding our ever-changing world, has been less investigated. To address this challenge, this paper introduces Mementos, a new benchmark designed to... | Xiyao Wang, Yuhang Zhou, Xiaoyu Liu, Hongjin Lu, Yuancheng Xu, Feihong He, Jaehong Yoon, Taixi Lu, Fuxiao Liu, Gedas Bertasius, Mohit Bansal, Huaxiu Yao, Furong Huang |  |
| 145 |  |  [TTM-RE: Memory-Augmented Document-Level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.26) |  | 0 | Document-level relation extraction aims to categorize the association between any two entities within a document.We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels. For example, in the ReDocRED benchmark dataset, state-of-the-art methods trained on the large-scale, lower-quality, distantly supervised training data generally do not perform better than those trained solely... | Chufan Gao, Xuan Wang, Jimeng Sun |  |
| 146 |  |  [Answer is All You Need: Instruction-following Text Embedding via Answering the Question](https://doi.org/10.18653/v1/2024.acl-long.27) |  | 0 | This work aims to build a text embedder that can capture characteristics of texts specified by user instructions clarifying the similarity criterion. While previous methods improve general task awareness by injecting the instruction information into encoding, they fail to be sensitive to clearer criteria like “evaluate similarity based on emotion”. We instead propose a different viewpoint, which treats the instruction as a “question” about the input text and encodes the expected answers to... | Letian Peng, Yuwei Zhang, Zilong Wang, Jayanth Srinivasa, Gaowen Liu, Zihan Wang, Jingbo Shang |  |
| 147 |  |  [Explore Spurious Correlations at the Concept Level in Language Models for Text Classification](https://doi.org/10.18653/v1/2024.acl-long.28) |  | 0 | Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label distributions in training data or ICL exemplars. Previous research has primarily concentrated on word, phrase, and syntax features, neglecting the concept level, often due to the absence of concept labels and... | Yuhang Zhou, Paiheng Xu, Xiaoyu Liu, Bang An, Wei Ai, Furong Huang |  |
| 148 |  |  [Every Answer Matters: Evaluating Commonsense with Probabilistic Measures](https://doi.org/10.18653/v1/2024.acl-long.29) |  | 0 | Large language models have demonstrated impressive performance on commonsense tasks; however, these tasks are often posed as multiple-choice questions, allowing models to exploit systematic biases. Commonsense is also inherently probabilistic with multiple correct answers. The purpose of “boiling water” could be making tea, cooking but also could be killing germs. Existing tasks do not capture the probabilistic nature of common sense. To this end, we present commonsense frame completion (CFC),... | Qi Cheng, Michael Boratko, Pranay Kumar Yelugam, Tim O'Gorman, Nalini Singh, Andrew McCallum, Xiang Li |  |
| 149 |  |  [GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis](https://doi.org/10.18653/v1/2024.acl-long.30) |  | 0 | Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study, we propose GradSafe, which effectively detects jailbreak prompts by scrutinizing the gradients of safety-critical parameters in LLMs. Our method is grounded in a pivotal observation: the gradients of... | Yueqi Xie, Minghong Fang, Renjie Pi, Neil Gong |  |
| 150 |  |  [Pouring Your Heart Out: Investigating the Role of Figurative Language in Online Expressions of Empathy](https://doi.org/10.18653/v1/2024.acl-long.31) |  | 0 | Empathy is a social mechanism used to support and strengthen emotional connection with others, including in online communities. However, little is currently known about the nature of these online expressions, nor the particular factors that may lead to their improved detection. In this work, we study the role of a specific and complex subcategory of linguistic phenomena, figurative language, in online expressions of empathy. Our extensive experiments reveal that incorporating features regarding... | Gyeongeun Lee, Christina Wong, Meghan Guo, Natalie Parde |  |
| 151 |  |  [An Information-Theoretic Approach to Analyze NLP Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.32) |  | 0 | Understanding the contribution of the inputs on the output is useful across many tasks. This work provides an information-theoretic framework to analyse the influence of inputs for text classification tasks. Natural language processing (NLP) tasks take either a single or multiple text elements to predict an output variable. Each text element has two components: the semantic meaning and a linguistic realization. Multiple-choice reading comprehension (MCRC) and sentiment classification (SC) are... | Luran Wang, Mark J. F. Gales, Vatsal Raina |  |
| 152 |  |  [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](https://doi.org/10.18653/v1/2024.acl-long.33) |  | 0 | Conversational systems often rely on embedding models for intent classification and intent clustering tasks. The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for these downstream conversational tasks. However, traditional evaluation benchmarks rely solely on task metrics that don’t particularly measure gaps related to semantic understanding. Thus, we propose an... | Yuwei Zhang, Siffi Singh, Sailik Sengupta, Igor Shalyminov, Hang Su, Hwanjun Song, Saab Mansour |  |
| 153 |  |  [Wav2Gloss: Generating Interlinear Glossed Text from Speech](https://doi.org/10.18653/v1/2024.acl-long.34) |  | 0 | Thousands of the world’s languages are in danger of extinction—a tremendous threat to cultural identities and human language diversity. Interlinear Glossed Text (IGT) is a form of linguistic annotation that can support documentation and resource creation for these languages’ communities. IGT typically consists of (1) transcriptions, (2) morphological segmentation, (3) glosses, and (4) free translations to a majority language. We propose Wav2Gloss: a task in which these four annotation... | Taiqi He, Kwanghee Choi, Lindia Tjuatja, Nathaniel R. Robinson, Jiatong Shi, Shinji Watanabe, Graham Neubig, David R. Mortensen, Lori S. Levin |  |
| 154 |  |  [Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification](https://doi.org/10.18653/v1/2024.acl-long.35) |  | 0 | Is it possible accurately classify political relations within evolving event ontologies without extensive annotations? This study investigates zero-shot learning methods that use expert knowledge from existing annotation codebook, and evaluates the performance of advanced ChatGPT (GPT-3.5/4) and a natural language inference (NLI)-based model called ZSP. ChatGPT uses codebook’s labeled summaries as prompts, whereas ZSP breaks down the classification task into context, event mode, and class... | Yibo Hu, Erick Skorupa Parolin, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito D'Orazio |  |
| 155 |  |  [SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.36) |  | 0 | Compositional generalization is an important ability of language models and has many different manifestations. For data-to-text generation, previous research on this ability is limited to a single manifestation called Systematicity and lacks consideration of large language models (LLMs), which cannot fully cover practical application scenarios. In this work, we propose SPOR, a comprehensive and practical evaluation method for compositional generalization in data-to-text generation. SPOR... | Ziyao Xu, Houfeng Wang |  |
| 156 |  |  [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.37) |  | 0 | Embodied Instruction Following (EIF) is a crucial task in embodied learning, requiring agents to interact with their environment through egocentric observations to fulfill natural language instructions. Recent advancements have seen a surge in employing large language models (LLMs) within a framework-centric approach to enhance performance in embodied learning tasks, including EIF. Despite these efforts, there exists a lack of a unified understanding regarding the impact of various... | Haochen Shi, Zhiyuan Sun, Xingdi Yuan, MarcAlexandre Côté, Bang Liu |  |
| 157 |  |  [Multimodal Instruction Tuning with Conditional Mixture of LoRA](https://doi.org/10.18653/v1/2024.acl-long.38) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in diverse tasks across different domains, with an increasing focus on improving their zero-shot generalization capabilities for unseen multimodal tasks. Multimodal instruction tuning has emerged as a successful strategy for achieving zero-shot generalization by fine-tuning pre-trained models on diverse multimodal tasks through instructions. As MLLMs grow in complexity and size, the need for parameter-efficient... | Ying Shen, Zhiyang Xu, Qifan Wang, Yu Cheng, Wenpeng Yin, Lifu Huang |  |
| 158 |  |  [DocLens: Multi-aspect Fine-grained Medical Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.39) |  | 0 | Medical text generation aims to assist with administrative work and highlight salient information to support decision-making.To reflect the specific requirements of medical text, in this paper, we propose a set of metrics to evaluate the completeness, conciseness, and attribution of the generated text at a fine-grained level. The metrics can be computed by various types of evaluators including instruction-following (both proprietary and open-source) and supervised entailment models. We... | Yiqing Xie, Sheng Zhang, Hao Cheng, Pengfei Liu, Zelalem Gero, Cliff Wong, Tristan Naumann, Hoifung Poon, Carolyn P. Rosé |  |
| 159 |  |  [FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability](https://doi.org/10.18653/v1/2024.acl-long.40) |  | 0 | This paper presents FoFo, a pioneering benchmark for evaluating large language models’ (LLMs) ability to follow complex, domain-specific formats, a crucial yet under-examined capability for their application as AI agents. Despite LLMs’ advancements, existing benchmarks fail to assess their format-following proficiency adequately. FoFo fills this gap with a diverse range of real-world formats and instructions, developed through an AI-Human collaborative method. Our evaluation across both... | Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang, Yihao Feng, Ran Xu, Wenpeng Yin, Caiming Xiong |  |
| 160 |  |  [Hyper-CL: Conditioning Sentence Representations with Hypernetworks](https://doi.org/10.18653/v1/2024.acl-long.41) |  | 0 | While the introduction of contrastive learning frameworks in sentence representation learning has significantly contributed to advancements in the field, it still remains unclear whether state-of-the-art sentence embeddings can capture the fine-grained semantics of sentences, particularly when conditioned on specific perspectives.In this paper, we introduce Hyper-CL, an efficient methodology that integrates hypernetworks with contrastive learning to compute conditioned sentence... | Young Hyun Yoo, Jii Cha, Changhyeon Kim, Taeuk Kim |  |
| 161 |  |  [Analysis of Multi-Source Language Training in Cross-Lingual Transfer](https://doi.org/10.18653/v1/2024.acl-long.42) |  | 0 | The successful adaptation of multilingual language models (LMs) to a specific language-task pair critically depends on the availability of data tailored for that condition. While cross-lingual transfer (XLT) methods have contributed to addressing this data scarcity problem, there still exists ongoing debate about the mechanisms behind their effectiveness.In this work, we focus on one of promising assumptions about inner workings of XLT, that it encourages multilingual LMs to place greater... | Seong Hoon Lim, Taejun Yun, Jinhyeon Kim, Jihun Choi, Taeuk Kim |  |
| 162 |  |  [ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions](https://doi.org/10.18653/v1/2024.acl-long.43) |  | 0 | We present ABEX, a novel and effective generative data augmentation methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms of an input document – we first convert a document into its concise, abstract description and then generate new documents based on expanding the resultant abstraction. To learn the task of expanding abstract descriptions, we first train BART on a large-scale synthetic... | Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, Chandra Kiran Reddy Evuru, Ramaneswaran S., S. Sakshi, Dinesh Manocha |  |
| 163 |  |  [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants](https://doi.org/10.18653/v1/2024.acl-long.44) |  | 0 | We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource languages. Each question is based on a short passage from the FLORES-200 dataset and has four multiple-choice answers. The questions were carefully curated to discriminate between models with... | Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel Artetxe, Satya Narayan Shukla, Donald Husa, Naman Goyal, Abhinandan Krishnan, Luke Zettlemoyer, Madian Khabsa |  |
| 164 |  |  [Learn from Failure: Fine-tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving](https://doi.org/10.18653/v1/2024.acl-long.45) |  | 0 | Recent advances in Automated Theorem Proving have shown the effectiveness of leveraging a (large) language model that generates tactics (i.e. proof steps) to search through proof states. The current model, while trained solely on successful proof paths, faces a discrepancy at the inference stage, as it must sample and try various tactics at each proof state until finding success, unlike its training which does not incorporate learning from failed attempts. Intuitively, a tactic that leads to a... | Chenyang An, Zhibo Chen, Qihao Ye, Emily First, Letian Peng, Jiayun Zhang, Zihan Wang, Sorin Lerner, Jingbo Shang |  |
| 165 |  |  [Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach](https://doi.org/10.18653/v1/2024.acl-long.46) |  | 0 | In this paper, we primarily address the issue of dialogue-form context query within the interactive text-to-image retrieval task. Our methodology, PlugIR, actively utilizes the general instruction-following capability of LLMs in two ways. First, by reformulating the dialogue-form context, we eliminate the necessity of fine-tuning a retrieval model on existing visual dialogue data, thereby enabling the use of any arbitrary black-box model. Second, we construct the LLM questioner to generate... | Saehyung Lee, Sangwon Yu, Junsung Park, Jihun Yi, Sungroh Yoon |  |
| 166 |  |  [IMBUE: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction](https://doi.org/10.18653/v1/2024.acl-long.47) |  | 0 | Navigating certain communication situations can be challenging due to individuals’ lack of skills and the interference of strong emotions. However, effective learning opportunities are rarely accessible. In this work, we conduct a human-centered study that uses language models to simulate bespoke communication training and provide just-in-time feedback to support the practice and learning of interpersonal effectiveness skills. We apply the interpersonal effectiveness framework from Dialectical... | Inna W. Lin, Ashish Sharma, Christopher Michael Rytting, Adam S. Miner, Jina Suh, Tim Althoff |  |
| 167 |  |  [Token-wise Influential Training Data Retrieval for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.48) |  | 0 | Given a Large Language Model (LLM) generation, how can we identify which training data led to this generation? In this paper, we proposed RapidIn, a scalable framework adapting to LLMs for estimating the influence of each training data. The proposed framework consists of two stages: caching and retrieval. First, we compress the gradient vectors by over 200,000x, allowing them to be cached on disk or in GPU/CPU memory. Then, given a generation, RapidIn efficiently traverses the cached gradients... | Huawei Lin, Jikai Long, Zhaozhuo Xu, Weijie Zhao |  |
| 168 |  |  [Tree-of-Counterfactual Prompting for Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.49) |  | 0 | Stance detection enables the inference of attitudes from human communications. Automatic stance identification was mostly cast as a classification problem. However, stance decisions involve complex judgments, which can be nowadays generated by prompting Large Language Models (LLMs). In this paper we present a new method for stance identification which (1) relies on a new prompting framework, called Tree-of-Counterfactual prompting; (2) operates not only on textual communications, but also on... | Maxwell A. Weinzierl, Sanda M. Harabagiu |  |
| 169 |  |  [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://doi.org/10.18653/v1/2024.acl-long.50) |  | 0 | Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap,... | Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, PoYu Huang, Graham Neubig, Shuyan Zhou, Russ Salakhutdinov, Daniel Fried |  |
| 170 |  |  [FineSurE: Fine-grained Summarization Evaluation using LLMs](https://doi.org/10.18653/v1/2024.acl-long.51) |  | 0 | Automated evaluation is crucial for streamlining text summarization benchmarking and model development, given the costly and time-consuming nature of human evaluation. Traditional methods like ROUGE do not correlate well with human judgment, while recently proposed LLM-based metrics provide only summary-level assessment using Likert-scale scores. This limits deeper model analysis, e.g., we can only assign one hallucination score at the summary level, while at the sentence level, we can count... | Hwanjun Song, Hang Su, Igor Shalyminov, Jason Cai, Saab Mansour |  |
| 171 |  |  [Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback](https://doi.org/10.18653/v1/2024.acl-long.52) |  | 0 | Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). Previous approaches for VLMMs involve Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and additional learnable parameters. Here, aligning video with text, and vice versa, remains a challenge, primarily due to the insufficient quality and quantity of multimodal instruction-tune data compared to that of text-only. This... | Daechul Ahn, Yura Choi, Youngjae Yu, Dongyeop Kang, Jonghyun Choi |  |
| 172 |  |  [Prompt Refinement with Image Pivot for Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.53) |  | 0 | For text-to-image generation, automatically refining user-provided natural language prompts into the keyword-enriched prompts favored by systems is essential for the user experience. Such a prompt refinement process is analogous to translating the prompt from “user languages” into “system languages”. However, the scarcity of such parallel corpora makes it difficult to train a prompt refinement model. Inspired by zero-shot machine translation techniques, we introduce Prompt Refinement with Image... | Jingtao Zhan, Qingyao Ai, Yiqun Liu, Yingwei Pan, Ting Yao, Jiaxin Mao, Shaoping Ma, Tao Mei |  |
| 173 |  |  [Striking Gold in Advertising: Standardization and Exploration of Ad Text Generation](https://doi.org/10.18653/v1/2024.acl-long.54) |  | 0 | In response to the limitations of manual ad creation, significant research has been conducted in the field of automatic ad text generation (ATG). However, the lack of comprehensive benchmarks and well-defined problem sets has made comparing different methods challenging. To tackle these challenges, we standardize the task of ATG and propose a first benchmark dataset, CAMERA, carefully designed and enabling the utilization of multi-modal information and facilitating industry-wise evaluations.... | Masato Mita, Soichiro Murakami, Akihiko Kato, Peinan Zhang |  |
| 174 |  |  [AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation](https://doi.org/10.18653/v1/2024.acl-long.55) |  | 0 | Abstraction ability is crucial in human intelligence, which can also benefit various tasks in NLP study. Existing work shows that LLMs are deficient in abstract ability, and how to improve it remains unexplored. In this work, we design the framework AbsInstruct to enhance LLMs’ abstraction ability through instruction tuning. The framework builds instructions with in-depth explanations to assist LLMs in capturing the underlying rationale of abstraction. Meanwhile, we introduce a plausibility... | Zhaowei Wang, Wei Fan, Qing Zong, Hongming Zhang, Sehyun Choi, Tianqing Fang, Xin Liu, Yangqiu Song, Ginny Y. Wong, Simon See |  |
| 175 |  |  [Reflect-RL: Two-Player Online RL Fine-Tuning for LMs](https://doi.org/10.18653/v1/2024.acl-long.56) |  | 0 | As language models (LMs) demonstrate their capabilities in various fields, their application to tasks requiring multi-round interactions has become increasingly popular. These tasks usually have complex dynamics, so supervised fine-tuning (SFT) on a limited offline dataset does not yield good performance. However, only a few works attempted to directly train the LMs within interactive decision-making environments. We aim to create an effective approach to fine-tune LMs with online reinforcement... | Runlong Zhou, Simon S. Du, Beibin Li |  |
| 176 |  |  [Can ChatGPT's Performance be Improved on Verb Metaphor Detection Tasks? Bootstrapping and Combining Tacit Knowledge](https://doi.org/10.18653/v1/2024.acl-long.57) |  | 0 | Metaphors detection, as an important task in the field of NLP, has been receiving sustained academic attention in recent years. Current researches focus supervised metaphors detection systems, which usually require large-scale, high-quality labeled data support. The emerge of large language models (e.g., ChatGPT) has made many NLP tasks (e.g., automatic summarization and dialogue systems) a qualitative leap. However, it is worth noting that the use of ChatGPT for unsupervised metaphors... | Cheng Yang, Puli Chen, Qingbao Huang |  |
| 177 |  |  [Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.58) |  | 0 | The surge in Large Language Models (LLMs) has revolutionized natural language processing, but fine-tuning them for specific tasks often encounters challenges in balancing performance and preserving general instruction-following abilities. In this paper, we posit that the distribution gap between task datasets and the LLMs serves as the primary underlying cause. To address the problem, we introduce Self-Distillation Fine-Tuning (SDFT), a novel approach that bridges the distribution gap by... | Zhaorui Yang, Tianyu Pang, Haozhe Feng, Han Wang, Wei Chen, Minfeng Zhu, Qian Liu |  |
| 178 |  |  [An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.59) |  | 0 | Retrieval-augmented generation integrates the capabilities of large language models with relevant information retrieved from an extensive corpus, yet encounters challenges when confronted with real-world noisy data. One recent solution is to train a filter module to find relevant content but only achieve suboptimal noise compression. In this paper, we propose to introduce the information bottleneck theory into retrieval-augmented generation. Our approach involves the filtration of noise by... | Kun Zhu, Xiaocheng Feng, Xiyuan Du, Yuxuan Gu, Weijiang Yu, Haotian Wang, Qianglong Chen, Zheng Chu, Jingchang Chen, Bing Qin |  |
| 179 |  |  [RORA: Robust Free-Text Rationale Evaluation](https://doi.org/10.18653/v1/2024.acl-long.60) |  | 0 | Free-text rationales play a pivotal role in explainable NLP, bridging the knowledge and reasoning gaps behind a model’s decision-making. However, due to the diversity of potential reasoning paths and a corresponding lack of definitive ground truth, their evaluation remains a challenge. Existing metrics rely on the degree to which a rationale supports a target label, but we find these fall short in evaluating rationales that inadvertently leak the label. To address this problem, we propose RORA,... | Zhengping Jiang, Yining Lu, Hanjie Chen, Daniel Khashabi, Benjamin Van Durme, Anqi Liu |  |
| 180 |  |  [Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents](https://doi.org/10.18653/v1/2024.acl-long.61) |  | 0 | Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users’ implicit intentions through explicit queries. Next, we propose the... | Cheng Qian, Bingxiang He, Zhong Zhuang, Jia Deng, Yujia Qin, Xin Cong, Zhong Zhang, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun |  |
| 181 |  |  [InstructProtein: Aligning Human and Protein Language via Knowledge Instruction](https://doi.org/10.18653/v1/2024.acl-long.62) |  | 0 | Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in both human and protein languages: (i) taking a protein sequence as input to predict its textual function description and (ii) using natural language to prompt protein sequence generation. To achieve... | Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen |  |
| 182 |  |  [ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.63) |  | 0 | In this position paper, we argue that human evaluation of generative large language models (LLMs) should be a multidisciplinary undertaking that draws upon the insights from disciplines such as user experience research and human behavioral psychology to ensure that the experimental design and results are reliable. The conclusions from these evaluations, therefore, must consider factors such as usability, aesthetics and cognitive biases. We highlight how cognitive biases can conflate fluent... | Aparna Elangovan, Ling Liu, Lei Xu, Sravan Babu Bodapati, Dan Roth |  |
| 183 |  |  [Linguistically Conditioned Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.64) |  | 0 | Semantic textual similarity (STS) is a fundamental NLP task that measures the semantic similarity between a pair of sentences. In order to reduce the inherent ambiguity posed from the sentences, a recent work called Conditional STS (C-STS) has been proposed to measure the sentences’ similarity conditioned on a certain aspect. Despite the popularity of C-STS, we find that the current C-STS dataset suffers from various issues that could impede proper evaluation on this task. In this paper, we... | Jingxuan Tu, Keer Xu, Liulu Yue, Bingyang Ye, Kyeongmin Rim, James Pustejovsky |  |
| 184 |  |  [Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future](https://doi.org/10.18653/v1/2024.acl-long.65) |  | 0 | Reasoning, a fundamental cognitive process integral to human intelligence, has garnered substantial interest within artificial intelligence.Notably, recent studies have revealed that chain-of-thought prompting significantly enhances LLM’s reasoning capabilities, which attracts widespread attention from both academics and industry.In this paper, we systematically investigate relevant research, summarizing advanced methods through a meticulous taxonomy that offers novel perspectives.Moreover, we... | Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, Ting Liu |  |
| 185 |  |  [TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.66) |  | 0 | Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world.Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark.To address this, we propose TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena.TimeBench provides a thorough evaluation for investigating the temporal reasoning... | Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, Bing Qin |  |
| 186 |  |  [BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.67) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning capabilities.Nevertheless, they still suffer from factual errors when tackling knowledge-intensive tasks.Retrieval-augmented reasoning represents a promising approach.However, significant challenges still persist, including inaccurate and insufficient retrieval for complex questions, as well as difficulty in integrating multi-source knowledge.To address this, we propose Beam Aggregation Reasoning (BeamAggR), a reasoning framework... | Zheng Chu, Jingchang Chen, Qianglong Chen, Haotian Wang, Kun Zhu, Xiyuan Du, Weijiang Yu, Ming Liu, Bing Qin |  |
| 187 |  |  [ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base](https://doi.org/10.18653/v1/2024.acl-long.68) |  | 0 | Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a million-scale analogy knowledge base (KB) derived from existing knowledge graphs (KGs). ANALOGYKB identifies two types of analogies from the KGs: 1) analogies of the same relations, which can be directly... | Siyu Yuan, Jiangjie Chen, Changzhi Sun, Jiaqing Liang, Yanghua Xiao, Deqing Yang |  |
| 188 |  |  [TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation](https://doi.org/10.18653/v1/2024.acl-long.69) |  | 0 | A practical dialogue system requires the capacity for ongoing skill acquisition and adaptability to new tasks while preserving prior knowledge. However, current methods for Continual Dialogue State Tracking (DST), a crucial function of dialogue systems, struggle with the catastrophic forgetting issue and knowledge transfer between tasks. We present TaSL, a novel framework for task skill localization and consolidation that enables effective knowledge transfer without relying on memory replay.... | Yujie Feng, Xu Chu, Yongxin Xu, Guangyuan Shi, Bo Liu, XiaoMing Wu |  |
| 189 |  |  [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://doi.org/10.18653/v1/2024.acl-long.70) |  | 0 | In the era of large language models, Mixture-of-Experts (MoE) is a promising architecture for managing computational costs when scaling up model parameters. However, conventional MoE architectures like GShard, which activate the top-K out of N experts, face challenges in ensuring expert specialization, i.e. each expert acquires non-overlapping and focused knowledge. In response, we propose the DeepSeekMoE architecture towards ultimate expert specialization. It involves two principal strategies:... | Damai Dai, Chengqi Deng, Chenggang Zhao, R. X. Xu, Huazuo Gao, Deli Chen, Jiashi Li, Wangding Zeng, Xingkai Yu, Y. Wu, Zhenda Xie, Y. K. Li, Panpan Huang, Fuli Luo, Chong Ruan, Zhifang Sui, Wenfeng Liang |  |
| 190 |  |  [Grounding Language Model with Chunking-Free In-Context Retrieval](https://doi.org/10.18653/v1/2024.acl-long.71) |  | 0 | This paper presents a novel Chunking-Free In-Context (CFIC) retrieval approach, specifically tailored for Retrieval-Augmented Generation (RAG) systems. Traditional RAG systems often struggle with grounding responses using precise evidence text due to the challenges of processing lengthy documents and filtering out irrelevant content. Commonly employed solutions, such as document chunking and adapting language models to handle longer contexts, have their limitations. These methods either disrupt... | Hongjin Qian, Zheng Liu, Kelong Mao, Yujia Zhou, Zhicheng Dou |  |
| 191 |  |  [Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation](https://doi.org/10.18653/v1/2024.acl-long.72) |  | 0 | Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains largely unexplored. To fill this gap, this paper introduces the task of complex logical hypothesis generation, as an initial step towards abductive logical reasoning with KG. In this task, we aim to... | Jiaxin Bai, Yicheng Wang, Tianshi Zheng, Yue Guo, Xin Liu, Yangqiu Song |  |
| 192 |  |  [Active Prompting with Chain-of-Thought for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.73) |  | 0 | The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs’ ability to produce high-quality answers. In particular, an effective approach for complex question-and-answering tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs.... | Shizhe Diao, Pengcheng Wang, Yong Lin, Rui Pan, Xiang Liu, Tong Zhang |  |
| 193 |  |  [EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs](https://doi.org/10.18653/v1/2024.acl-long.74) |  | 0 | We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge modalities, EasyGen leverages BiDiffuser, a bidirectional conditional diffusion model, to foster more efficient modality interactions. EasyGen achieves text generation by... | Xiangyu Zhao, Bo Liu, Qijiong Liu, Guangyuan Shi, XiaoMing Wu |  |
| 194 |  |  [Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search](https://doi.org/10.18653/v1/2024.acl-long.75) |  | 0 | In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the demonstrated code generation capabilities of Large Language Models (LLMs). Nevertheless, our preliminary investigations indicate that the improvements conferred by such an LLM-augmented framework are... | Haochen Li, Xin Zhou, Zhiqi Shen |  |
| 195 |  |  [A Multidimensional Framework for Evaluating Lexical Semantic Change with Social Science Applications](https://doi.org/10.18653/v1/2024.acl-long.76) |  | 0 | Historical linguists have identified multiple forms of lexical semantic change. We present a three-dimensional framework for integrating these forms and a unified computational methodology for evaluating them concurrently. The dimensions represent increases or decreases in semantic 1) sentiment (valence of a target word’s collocates), 2) intensity (emotional arousal of collocates or the frequency of intensifiers), and 3) breadth (diversity of contexts in which the target word appears). These... | Naomi Baes, Nick Haslam, Ekaterina Vylomova |  |
| 196 |  |  [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](https://doi.org/10.18653/v1/2024.acl-long.77) |  | 0 | Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model’s ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the... | Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, Jinsong Su |  |
| 197 |  |  [Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency](https://doi.org/10.18653/v1/2024.acl-long.78) |  | 0 | Large language models (LLMs) have exhibited remarkable ability in code generation. However, generating the correct solution in a single attempt still remains a challenge. Prior works utilize verification properties in software engineering to verify and re-rank solutions in a majority voting manner. But the assumption behind them that generated verification properties have better qualities than solutions may not always hold. In this paper, we treat them equally as different perspectives of LLMs’... | Baizhou Huang, Shuai Lu, Xiaojun Wan, Nan Duan |  |
| 198 |  |  [Citation-Enhanced Generation for LLM-based Chatbots](https://doi.org/10.18653/v1/2024.acl-long.79) |  | 0 | Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data... | Weitao Li, Junkai Li, Weizhi Ma, Yang Liu |  |
| 199 |  |  [Transitive Consistency Constrained Learning for Entity-to-Entity Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.80) |  | 0 | Entity-to-entity stance detection identifies the stance between a pair of entities with a directed link that indicates the source, target and polarity. It is a streamlined task without the complex dependency structure for structural sentiment analysis, while it is more informative compared to most previous work assuming that the source is the author. Previous work performs entity-to-entity stance detection training on individual entity pairs. However, stances between inter-connected entity... | Haoyang Wen, Eduard H. Hovy, Alexander Hauptmann |  |
| 200 |  |  [Feature-Adaptive and Data-Scalable In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.81) |  | 0 | In-context learning (ICL), which promotes inference with several demonstrations, has become a widespread paradigm to stimulate LLM capabilities for downstream tasks. Due to context length constraints, it cannot be further improved in spite of more training data, and general features directly from LLMs in ICL are not adaptive to the specific downstream task. In this paper, we propose a feature-adaptive and data-scalable in-context learning framework (FADS-ICL), which can leverage task-adaptive... | Jiahao Li, Quan Wang, Licheng Zhang, Guoqing Jin, Zhendong Mao |  |
| 201 |  |  [Probing the Multi-turn Planning Capabilities of LLMs via 20 Question Games](https://doi.org/10.18653/v1/2024.acl-long.82) |  | 0 | Large language models (LLMs) are effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification questions to resolve ambiguities effectively. This capability requires complex understanding, state tracking, reasoning and planning over multiple conversational turns. However, directly measuring this can be... | Yizhe Zhang, Jiarui Lu, Navdeep Jaitly |  |
| 202 |  |  [WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.83) |  | 0 | To mitigate the potential misuse of large language models (LLMs), recent research has developed watermarking algorithms, which restrict the generation process to leave an invisible trace for watermark detection. Due to the two-stage nature of the task, most studies evaluate the generation and detection separately, thereby presenting a challenge in unbiased, thorough, and applicable evaluations. In this paper, we introduce WaterBench, the first comprehensive benchmark for LLM watermarks, in... | Shangqing Tu, Yuliang Sun, Yushi Bai, Jifan Yu, Lei Hou, Juanzi Li |  |
| 203 |  |  [Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models](https://doi.org/10.18653/v1/2024.acl-long.84) |  | 0 | Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences. While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of Transformer language model with explicit dependency-based inductive bias. DTGs simulate dependency transition systems with constrained attention patterns by modifying attention masks, incorporate the... | Yida Zhao, Chao Lou, Kewei Tu |  |
| 204 |  |  [A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation](https://doi.org/10.18653/v1/2024.acl-long.85) |  | 0 | Simultaneous translation models play a crucial role in facilitating communication. However, existing research primarily focuses on text-to-text or speech-to-text models, necessitating additional cascade components to achieve speech-to-speech translation. These pipeline methods suffer from error propagation and accumulate delays in each cascade component, resulting in reduced synchronization between the speaker and listener. To overcome these challenges, we propose a novel non-autoregressive... | Zhengrui Ma, Qingkai Fang, Shaolei Zhang, Shoutao Guo, Yang Feng, Min Zhang |  |
| 205 |  |  [Probing Language Models for Pre-training Data Detection](https://doi.org/10.18653/v1/2024.acl-long.86) |  | 0 | Large Language Models (LLMs) have shown their impressive capabilities, while also raising concerns about the data contamination problems due to privacy issues and leakage of benchmark datasets in the pre-training phase. Therefore, it is vital to detect the contamination by checking whether an LLM has been pre-trained on the target texts. Recent studies focus on the generated texts and compute perplexities, which are superficial features and not reliable. In this study, we propose to utilize the... | Zhenhua Liu, Tong Zhu, Chuanyuan Tan, Bing Liu, Haonan Lu, Wenliang Chen |  |
| 206 |  |  [Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.87) |  | 0 | The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for swift and precise analysis of complex events.We refer to the complex events composed of many news articles over an extended period as Temporal Complex Event (TCE). This paper proposes a novel approach using Large Language Models (LLMs) to systematically extract and analyze the event chain within TCE, characterized by their key points and timestamps. We establish a benchmark, named... | Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, TatSeng Chua |  |
| 207 |  |  [IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation](https://doi.org/10.18653/v1/2024.acl-long.88) |  | 0 | Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. Current language model agents mainly focus on reasonable behaviors from the level of individuals, and their behaviors might be hard to constraint on the level of the whole storyline. In this paper we introduce IBSEN, a director-actor coordinate agent framework that generates drama scripts and makes the plot played by agents more controllable. The director agent writes plot... | Senyu Han, Lu Chen, LiMin Lin, Zhengshan Xu, Kai Yu |  |
| 208 |  |  [Language Model Adaption for Reinforcement Learning with Natural Language Action Space](https://doi.org/10.18653/v1/2024.acl-long.89) |  | 0 | Reinforcement learning with natural language action space often suffers from the curse of dimensionality due to the combinatorial nature of the natural language. Previous research leverages pretrained language models to capture action semantics and reduce the size of the action space. However, since pretrained models are typically trained on general corpora, there can be an unpredictable mismatch between the priors encoded in pretrained models and the characteristics of the specific RL... | Jiangxing Wang, Jiachen Li, Xiao Han, Deheng Ye, Zongqing Lu |  |
| 209 |  |  [Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues](https://doi.org/10.18653/v1/2024.acl-long.90) |  | 0 | We investigate intention detection in persuasive multi-turn dialogs employing the largest available Large Language Models (LLMs).Much of the prior research measures the intention detection capability of machine learning models without considering the conversational history.To evaluate LLMs’ intention detection capability in conversation, we modified the existing datasets of persuasive conversation and created datasets using a multiple-choice paradigm.It is crucial to consider others’... | Hiromasa Sakurai, Yusuke Miyao |  |
| 210 |  |  [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://doi.org/10.18653/v1/2024.acl-long.91) |  | 0 | In long context scenarios, large language models (LLMs) face three main challenges: higher computational cost, performance reduction, and position bias. Research indicates that LLM performance hinges on the density and position of key information in the input prompt. Inspired by these findings, we propose LongLLMLingua for prompt compression towards improving LLMs’ perception of the key information to simultaneously address the three challenges. Our extensive evaluation across various long... | Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, ChinYew Lin, Yuqing Yang, Lili Qiu |  |
| 211 |  |  [Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.92) |  | 0 | Persuasive dialogue requires multi-turn following and planning abilities to achieve the goal of persuading users, which is still challenging even for state-of-the-art large language models (LLMs). Previous works focus on retrieval-based models or generative models in a specific domain due to a lack of data across multiple domains. In this paper, we leverage GPT-4 to create the first multi-domain persuasive dialogue dataset DailyPersuasion. Then we propose a general method named PersuGPT to... | Chuhao Jin, Kening Ren, Lingzhen Kong, Xiting Wang, Ruihua Song, Huan Chen |  |
| 212 |  |  [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://doi.org/10.18653/v1/2024.acl-long.93) |  | 0 | Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients’ self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through... | Mengxi Xiao, Qianqian Xie, Ziyan Kuang, Zhicheng Liu, Kailai Yang, Min Peng, Weiguang Han, Jimin Huang |  |
| 213 |  |  [Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.94) |  | 0 | The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, in real-world applications, the presence of various missing modality cases often leads to a degradation in the model’s performance. In this work, we propose a novel multimodal Transformer framework using prompt learning to address the issue of missing modalities. Our method introduces three types of prompts: generative prompts, missing-signal prompts, and missing-type... | Zirun Guo, Tao Jin, Zhou Zhao |  |
| 214 |  |  [An Effective Pronunciation Assessment Approach Leveraging Hierarchical Transformers and Pre-training Strategies](https://doi.org/10.18653/v1/2024.acl-long.95) |  | 0 | Automatic pronunciation assessment (APA) manages to quantify a second language (L2) learner’s pronunciation proficiency in a target language by providing fine-grained feedback with multiple pronunciation aspect scores at various linguistic levels. Most existing efforts on APA typically parallelize the modeling process, namely predicting multiple aspect scores across various linguistic levels simultaneously. This inevitably makes both the hierarchy of linguistic units and the relatedness among... | BiCheng Yan, JiunTing Li, YiCheng Wang, HsinWei Wang, TienHong Lo, YungChang Hsu, WeiCheng Chao, Berlin Chen |  |
| 215 |  |  [Detection-Correction Structure via General Language Model for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.acl-long.96) |  | 0 | Grammatical error correction (GEC) is a task dedicated to rectifying texts with minimal edits, which can be decoupled into two components: detection and correction. However, previous works have predominantly focused on direct correction, with no prior efforts to integrate both into a single model. Moreover, the exploration of the detection-correction paradigm by large language models (LLMs) remains underdeveloped. This paper introduces an integrated detection-correction structure, named... | Wei Li, Houfeng Wang |  |
| 216 |  |  [Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer](https://doi.org/10.18653/v1/2024.acl-long.97) |  | 0 | While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper, we introduce Generative Pre-trained Speech Transformer (GPST), a hierarchical transformer designed for efficient speech language modeling. GPST quantizes audio waveforms into two distinct types of discrete speech representations and integrates them within a hierarchical transformer architecture,... | Yongxin Zhu, Dan Su, Liqiang He, Linli Xu, Dong Yu |  |
| 217 |  |  [Selene: Pioneering Automated Proof in Software Verification](https://doi.org/10.18653/v1/2024.acl-long.98) |  | 0 | Ensuring correctness is a pivotal aspect of software engineering. Among the various strategies available, software verification offers a definitive assurance of correctness. Nevertheless, writing verification proofs is resource-intensive and manpower-consuming, and there is a great need to automate this process. We introduce Selene in this paper, which is the first project-level automated proof benchmark constructed based on the real-world industrial-level operating system microkernel, seL4.... | Lichen Zhang, Shuai Lu, Nan Duan |  |
| 218 |  |  [Dissecting Human and LLM Preferences](https://doi.org/10.18653/v1/2024.acl-long.99) |  | 0 | As a relative quality comparison of model responses, human and Large Language Model (LLM) preferences serve as common alignment goals in model fine-tuning and criteria in evaluation. Yet, these preferences merely reflect broad tendencies, resulting in less explainable and controllable models with potential safety risks. In this work, we dissect the preferences of human and 32 different LLMs to understand their quantitative composition, using annotations from real-world user-model conversations... | Junlong Li, Fan Zhou, Shichao Sun, Yikai Zhang, Hai Zhao, Pengfei Liu |  |
| 219 |  |  [UniCoder: Scaling Code Large Language Model via Universal Code](https://doi.org/10.18653/v1/2024.acl-long.100) |  | 0 | Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks.When applying LLMs for code generation, recent works mainly focus on directing the models to articulate intermediate natural-language reasoning steps, as in chain-of-thought (CoT) prompting, and then output code with the natural language or other structured intermediate steps. However, such output is not suitable for code... | Tao Sun, Linzheng Chai, Jian Yang, Yuwei Yin, Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun Yang, Zhoujun Li |  |
| 220 |  |  [AoE: Angle-optimized Embeddings for Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.101) |  | 0 | Text embedding is pivotal in semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. STS learning largely relies on the cosine function as the optimization objective to reflect semantic similarity. However, the cosine has saturation zones rendering vanishing gradients and hindering learning subtle semantic differences in text embeddings. To address this issue, we propose a novel Angle-optimized Embedding model, AoE. It optimizes angle... | Xianming Li, Jing Li |  |
| 221 |  |  [InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews](https://doi.org/10.18653/v1/2024.acl-long.102) |  | 0 | Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether RPAs accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the knowledge and linguistic patterns of characters. This paper, instead, introduces a novel perspective to evaluate the personality fidelity of RPAs with psychological scales. Overcoming drawbacks of... | Xintao Wang, Yunze Xiao, Jentse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, Yanghua Xiao |  |
| 222 |  |  [Does DetectGPT Fully Utilize Perturbation? Bridging Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better](https://doi.org/10.18653/v1/2024.acl-long.103) |  | 0 | The burgeoning generative capabilities of large language models (LLMs) have raised growing concerns about abuse, demanding automatic machine-generated text detectors. DetectGPT, a zero-shot metric-based detector, first introduces perturbation and shows great performance improvement. However, in DetectGPT, the random perturbation strategy could introduce noise, and logit regression depends on the threshold, harming the generalizability and applicability of individual or small-batch inputs.... | Shengchao Liu, Xiaoming Liu, Yichen Wang, Zehua Cheng, Chengzhengxu Li, Zhaohan Zhang, Yu Lan, Chao Shen |  |
| 223 |  |  [AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators](https://doi.org/10.18653/v1/2024.acl-long.104) |  | 0 | With the rise of generative AI, automated fact-checking methods to combat misinformation are becoming more and more important. However, factual claim detection, the first step in a fact-checking pipeline, suffers from two key issues that limit its scalability and generalizability: (1) inconsistency in definitions of the task and what a claim is, and (2) the high cost of manual annotation. To address (1), we review the definitions in related work and propose a unifying definition of factual... | Jingwei Ni, Minjing Shi, Dominik Stammbach, Mrinmaya Sachan, Elliott Ash, Markus Leippold |  |
| 224 |  |  [Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering](https://doi.org/10.18653/v1/2024.acl-long.105) |  | 0 | Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for various research and practical endeavors. One avenue in reaching this goal is basing the answers on reliable sources. However, this Evidence-Based QA has proven to work insufficiently with LLMs in terms of citing the correct sources (source quality) and truthfully representing the information within sources (answer attributability). In this work, we systematically investigate how to robustly... | Tobias Schimanski, Jingwei Ni, Mathias Kraus, Elliott Ash, Markus Leippold |  |
| 225 |  |  [LoRAMoE: Alleviating World Knowledge Forgetting in Large Language Models via MoE-Style Plugin](https://doi.org/10.18653/v1/2024.acl-long.106) |  | 0 | Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to align with human instructions and enhance their capabilities in downstream tasks. Substantially increasing instruction data is a direct solution to align the model with a broader range of downstream tasks or notably improve its performance on a specific task. However, we find that large-scale increases in instruction data can damage the world knowledge previously stored in LLMs. To address this... | Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Wei Shen, Limao Xiong, Yuhao Zhou, Xiao Wang, Zhiheng Xi, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 226 |  |  [Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation](https://doi.org/10.18653/v1/2024.acl-long.107) |  | 0 | Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., ”hallucinations”, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this work, we explore Self-Alignment for Factuality, where we leverage the self-evaluation capability of an LLM to provide training signals that steer the model towards factuality. Specifically, we... | Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Lifeng Jin, Linfeng Song, Haitao Mi, Helen Meng |  |
| 227 |  |  [M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions](https://doi.org/10.18653/v1/2024.acl-long.108) |  | 0 | Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant memories from an external database. However, existing RAG methods typically organize all memories in a whole database, potentially limiting focus on crucial memories and introducing noise. In this paper, we introduce a multiple partition paradigm for RAG (called M-RAG), where each database partition serves as a basic unit for RAG execution. Based on this paradigm, we propose a novel framework that... | Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi |  |
| 228 |  |  [AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension](https://doi.org/10.18653/v1/2024.acl-long.109) |  | 0 | Recently, instruction-following audio-language models have received broad attention for human-audio interaction. However, the absence of benchmarks capable of evaluating audio-centric interaction capabilities has impeded advancements in this field. Previous models primarily focus on assessing different fundamental tasks, such as automatic speech recognition, and lack an assessment of the open-ended generative capabilities centered around audio. Thus, it is challenging to track the progression... | Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, Jingren Zhou |  |
| 229 |  |  [Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies](https://doi.org/10.18653/v1/2024.acl-long.110) |  | 0 | Ten years ago a single metric, BLEU, governed progress in machine translation research. For better or worse, there is no such consensus today, and consequently it is difficult for researchers to develop and retain intuitions about metric deltas that drove earlier research and deployment decisions. This paper investigates the “dynamic range” of a number of modern metrics in an effort to provide a collective understanding of the meaning of differences in scores both within and among metrics; in... | Tom Kocmi, Vilém Zouhar, Christian Federmann, Matt Post |  |
| 230 |  |  [ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.111) |  | 0 | Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. This development underscores the urgent need for evaluating value orientations and understanding of LLMs to ensure their responsible integration into public-facing applications. This work introduces ValueBench, the first comprehensive psychometric benchmark for evaluating value orientations and understanding in LLMs. ValueBench collects data from 44 established psychometric... | Yuanyi Ren, Haoran Ye, Hanjun Fang, Xin Zhang, Guojie Song |  |
| 231 |  |  [DM-BLI: Dynamic Multiple Subspaces Alignment for Unsupervised Bilingual Lexicon Induction](https://doi.org/10.18653/v1/2024.acl-long.112) |  | 0 | Unsupervised bilingual lexicon induction (BLI) task aims to find word translations between languages and has achieved great success in similar language pairs. However, related works mostly rely on a single linear mapping for language alignment and fail on distant or low-resource language pairs, achieving less than half the performance observed in rich-resource language pairs. In this paper, we introduce DM-BLI, a Dynamic Multiple subspaces alignment framework for unsupervised BLI. DM-BLI... | Ling Hu, Yuemei Xu |  |
| 232 |  |  [SparseFit: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.113) |  | 0 | Models that generate natural language explanations (NLEs) for their predictions have recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers at training time, which can be expensive and potentially infeasible for some applications. When only a few NLEs are available (a few-shot setup), fine-tuning pre-trained language models (PLMs) in conjunction with prompt-based learning has recently shown promising results.... | Jesus Solano, Mardhiyah Sanni, OanaMaria Camburu, Pasquale Minervini |  |
| 233 |  |  [Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation](https://doi.org/10.18653/v1/2024.acl-long.114) |  | 0 | The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper investigates three methods to handle ambiguous emotion. First, we show that incorporating utterances without majority-agreed labels as an additional class in the classifier reduces the classification... | Wen Wu, Bo Li, Chao Zhang, ChungCheng Chiu, Qiujia Li, Junwen Bai, Tara N. Sainath, Philip C. Woodland |  |
| 234 |  |  [REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation](https://doi.org/10.18653/v1/2024.acl-long.115) |  | 0 | Open domain question answering (ODQA) aims to answer questions with knowledge from an external corpus. Fusion-in-Decoder (FiD) is an effective retrieval-augmented reader model to address this task. Given that FiD independently encodes passages, which overlooks the semantic relationships between passages, some studies use knowledge graphs (KGs) to establish dependencies among passages. However, they only leverage knowledge triples from existing KGs, which suffer from incompleteness and may lack... | Jinyuan Fang, Zaiqiao Meng, Craig MacDonald |  |
| 235 |  |  [Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks](https://doi.org/10.18653/v1/2024.acl-long.116) |  | 0 | Disentangled latent spaces usually have better semantic separability and geometrical properties, which leads to better interpretability and more controllable data generation. While this has been well investigated in Computer Vision, in tasks such as image disentanglement, in the NLP domain, sentence disentanglement is still comparatively under-investigated. Most previous work have concentrated on disentangling task-specific generative factors, such as sentiment, within the context of style... | Yingji Zhang, Danilo S. Carvalho, André Freitas |  |
| 236 |  |  [MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation](https://doi.org/10.18653/v1/2024.acl-long.117) |  | 0 | A story premise succinctly defines a story’s main idea, foundation, and trajectory. It serves as the initial trigger in automatic story generation. Existing sources of story premises are limited by a lack of diversity, uneven quality, and high costs that make them difficult to scale. In response, we introduce Modular Story Premise Synthesis (MoPS) which breaks down story premises into modules like background and persona for automated design and generation. MoPS consists of three phases: (1)... | Yan Ma, Yu Qiao, Pengfei Liu |  |
| 237 |  |  [Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization](https://doi.org/10.18653/v1/2024.acl-long.118) |  | 0 | Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited set of labeled texts, alongside plenty of unlabeled texts that include both in-distribution and out-of-distribution examples. In this paper, we revisit the main challenge in OSTC, i.e., outlier detection, from a measurement disagreement perspective and innovatively propose to improve OSTC performance by directly maximizing the measurement disagreements. Based on the properties of in-measurement... | Junfan Chen, Richong Zhang, Junchi Chen, Chunming Hu |  |
| 238 |  |  [ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages](https://doi.org/10.18653/v1/2024.acl-long.119) |  | 0 | Tool learning is widely acknowledged as a foundational approach or deploying large language models (LLMs) in real-world scenarios. While current research primarily emphasizes leveraging tools to augment LLMs, it frequently neglects emerging safety considerations tied to their application. To fill this gap, we present ToolSword, a comprehensive framework dedicated to meticulously investigating safety issues linked to LLMs in tool learning. Specifically, ToolSword delineates six safety scenarios... | Junjie Ye, Sixian Li, Guanyu Li, Caishuang Huang, Songyang Gao, Yilong Wu, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 239 |  |  [A synthetic data approach for domain generalization of NLI models](https://doi.org/10.18653/v1/2024.acl-long.120) |  | 0 | Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfulness of model-generated text. There are several large scale NLI datasets today, and models have improved greatly by hill-climbing on these collections. Yet their realistic performance on out-of-distribution/domain data is less well-understood. We explore the opportunity for... | Mohammad Javad Hosseini, Andrey Petrov, Alex Fabrikant, Annie Louis |  |
| 240 |  |  [Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild](https://doi.org/10.18653/v1/2024.acl-long.121) |  | 0 | The principle of continual relation extraction (CRE) involves adapting to emerging novel relations while preserving old knowledge. Existing CRE approaches excel in preserving old knowledge but falter when confronted with contaminated data streams, likely due to an artificial assumption of no annotation errors. Recognizing the prevalence of noisy labels in real-world datasets, we introduce a more practical learning scenario, termed as noisy-CRE. In response to this challenge, we propose a... | Ting Wu, Jingyi Liu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 241 |  |  [LRQuant: Learnable and Robust Post-Training Quantization for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.122) |  | 0 | Post-training quantization (PTQ) for large language models (LLMs) significantly accelerates model inference and relieves memory constraints, without incurring model training. A “smoothing paradigm” is commonly used in LLM quantization, which transfers the quantization difficulty of activation to weight quantization using mathematically equivalent transformations. However, existing methods face two issues: 1) Most smoothing parameters are hand-crafted defined which leads to suboptimal results;... | Jiaqi Zhao, Miao Zhang, Chao Zeng, Ming Wang, Xuebo Liu, Liqiang Nie |  |
| 242 |  |  [VariErr NLI: Separating Annotation Error from Human Label Variation](https://doi.org/10.18653/v1/2024.acl-long.123) |  | 0 | Human label variation arises when annotators assign different labels to the same item for valid reasons, while annotation errors occur when labels are assigned for invalid reasons. These two issues are prevalent in NLP benchmarks, yet existing research has studied them in isolation. To the best of our knowledge, there exists no prior work that focuses on teasing apart error from signal, especially in cases where signal is beyond black-and-white.To fill this gap, we introduce a systematic... | Leon WeberGenzel, Siyao Peng, MarieCatherine de Marneffe, Barbara Plank |  |
| 243 |  |  [Benchmarking Knowledge Boundary for Large Language Models: A Different Perspective on Model Evaluation](https://doi.org/10.18653/v1/2024.acl-long.124) |  | 0 | In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks.To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs.We argue that it is not reliable and comprehensive to evaluate language models with a fixed question or limited paraphrases as the query, since language models are sensitive to prompt.Therefore, we... | Xunjian Yin, Xu Zhang, Jie Ruan, Xiaojun Wan |  |
| 244 |  |  [ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval](https://doi.org/10.18653/v1/2024.acl-long.125) |  | 0 | We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and compare our model on the BEIR benchmark for zero-shot retrieval task, demonstrating that ListT5 (1) outperforms the state-of-the-art RankT5 baseline with a notable +1.3 gain in the average NDCG@10 score,... | Soyoung Yoon, Eunbi Choi, Jiyeon Kim, Hyeongu Yun, Yireun Kim, Seungwon Hwang |  |
| 245 |  |  [Exploring the Potential of Large Language Models in Computational Argumentation](https://doi.org/10.18653/v1/2024.acl-long.126) |  | 0 | Computational argumentation has become an essential tool in various domains, including law, public policy, and artificial intelligence. It is an emerging research field in natural language processing that attracts increasing attention. Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation. As large language models (LLMs) have demonstrated impressive capabilities in understanding context and generating natural language, it is... | Guizhen Chen, Liying Cheng, Anh Tuan Luu, Lidong Bing |  |
| 246 |  |  [TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks](https://doi.org/10.18653/v1/2024.acl-long.127) |  | 0 | In this paper, we explore the capabilities of LLMs in capturing lexical-semantic knowledge from WordNet on the example of the LLaMA-2-7b model and test it on multiple lexical semantic tasks. As the outcome of our experiments, we present TaxoLLaMA, the “all-in-one” model for taxonomy-related tasks, lightweight due to 4-bit quantization and LoRA. TaxoLLaMA achieves 11 SOTA results, and 4 top-2 results out of 16 tasks on the Taxonomy Enrichment, Hypernym Discovery, Taxonomy Construction, and... | Viktor Moskvoretskii, Ekaterina Neminova, Alina Lobanova, Alexander Panchenko, Irina Nikishina |  |
| 247 |  |  [CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.128) |  | 0 | The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows the application of existing knowledge to unfamiliar scenarios. However, existing works tend to undervalue the step of instantiation and heavilyrely on pre-built concept taxonomies and human annotations to collect both types of knowledge, resulting in a lack of instantiated knowledge to complete reasoning, high cost, and limited scalability. To tackle these challenges,... | Weiqi Wang, Tianqing Fang, Chunyang Li, Haochen Shi, Wenxuan Ding, Baixuan Xu, Zhaowei Wang, Jiaxin Bai, Xin Liu, Cheng Jiayang, Chunkit Chan, Yangqiu Song |  |
| 248 |  |  [MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter](https://doi.org/10.18653/v1/2024.acl-long.129) |  | 0 | Parameter-Efficient Fine-tuning (PEFT) facilitates the fine-tuning of Large Language Models (LLMs) under limited resources. However, the fine-tuning performance with PEFT on complex, knowledge-intensive tasks is limited due to the constrained model capacity, which originates from the limited number of additional trainable parameters. To overcome this limitation, we introduce a novel mechanism that fine-tunes LLMs with adapters of larger size yet memory-efficient. This is achieved by leveraging... | Jitai Hao, Weiwei Sun, Xin Xin, Qi Meng, Zhumin Chen, Pengjie Ren, Zhaochun Ren |  |
| 249 |  |  [Surgical Feature-Space Decomposition of LLMs: Why, When and How?](https://doi.org/10.18653/v1/2024.acl-long.130) |  | 0 | Low-rank approximations, of the weight and feature space can enhance the performance of deep learning models, whether in terms of improving generalization or reducing the latency of inference. However, there is no clear consensus yet on how, when and why these approximations are helpful for large language models (LLMs). In this work, we empirically study the efficacy of weight and feature space decomposition in transformer-based LLMs. We demonstrate that surgical decomposition not only provides... | Arnav Chavan, Nahush Lele, Deepak K. Gupta |  |
| 250 |  |  [Reasoning in Flux: Enhancing Large Language Models Reasoning through Uncertainty-aware Adaptive Guidance](https://doi.org/10.18653/v1/2024.acl-long.131) |  | 0 | Machine reasoning, which involves solving complex problems through step-by-step deduction and analysis, is a crucial indicator of the capabilities of Large Language Models (LLMs). However, as the complexity of tasks escalates, LLMs often encounter increasing errors in their multi-step reasoning process. This study delves into the underlying factors contributing to these reasoning errors and seeks to leverage uncertainty to refine them. Specifically, we introduce Uncertainty-aware Adaptive... | Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Xiaonan Li, Junqi Dai, Qinyuan Cheng, Xuanjing Huang, Xipeng Qiu |  |
| 251 |  |  [Modality-Aware Integration with Large Language Models for Knowledge-Based Visual Question Answering](https://doi.org/10.18653/v1/2024.acl-long.132) |  | 0 | Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel... | Junnan Dong, Qinggang Zhang, Huachi Zhou, Daochen Zha, Pai Zheng, Xiao Huang |  |
| 252 |  |  [Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression](https://doi.org/10.18653/v1/2024.acl-long.133) |  | 0 | Key-value (KV) caching is an important technique to accelerate the inference of large language models (LLMs), but incurs significant memory overhead. To compress the size of KV cache, existing methods often compromise precision or require extra data for calibration, limiting their practicality in LLM deployment. In this paper, we introduce DecoQuant, a novel data-free low-bit quantization technique based on tensor decomposition methods, to effectively compress KV cache. Our core idea is to... | Peiyu Liu, ZeFeng Gao, Xin Zhao, Yipeng Ma, Tao Wang, JiRong Wen |  |
| 253 |  |  [VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.134) |  | 0 | Recent approaches in domain-specific named entity recognition (NER), such as biomedical NER, have shown remarkable advances. However, they still lack of faithfulness, producing erroneous predictions. We assume that knowledge of entities can be useful in verifying the correctness of the predictions. Despite the usefulness of knowledge, resolving such errors with knowledge is nontrivial, since the knowledge itself does not directly indicate the ground-truth label. To this end, we propose... | Seoyeon Kim, Kwangwook Seo, Hyungjoo Chae, Jinyoung Yeo, Dongha Lee |  |
| 254 |  |  [Making Long-Context Language Models Better Multi-Hop Reasoners](https://doi.org/10.18653/v1/2024.acl-long.135) |  | 0 | Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased performance in the presence of noisy contexts. In this paper, we introduce Reasoning with Attributions, a novel approach that prompts LMs to supply attributions for each assertion during their reasoning. We validate our approach through experiments on three... | Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang |  |
| 255 |  |  [TransliCo: A Contrastive Learning Framework to Address the Script Barrier in Multilingual Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.136) |  | 0 | The world’s more than 7000 languages are written in at least 293 scripts. Due to various reasons, many closely related languages use different scripts, which poses a difficulty for multilingual pretrained language models (mPLMs) in learning crosslingual knowledge through lexical overlap. As a consequence, mPLMs are faced with a script barrier: representations from different scripts are located in different subspaces, which can result in crosslingual transfer involving languages of different... | Yihong Liu, Chunlan Ma, Haotian Ye, Hinrich Schütze |  |
| 256 |  |  [Extreme Miscalibration and the Illusion of Adversarial Robustness](https://doi.org/10.18653/v1/2024.acl-long.137) |  | 0 | Deep learning-based Natural Language Processing (NLP) models are vulnerable to adversarial attacks, where small perturbations can cause a model to misclassify. Adversarial Training (AT) is often used to increase model robustness. However, we have discovered an intriguing phenomenon: deliberately or accidentally miscalibrating models masks gradients in a way that interferes with adversarial attack search methods, giving rise to an apparent increase in robustness. We show that this observed gain... | Vyas Raina, Samson Tan, Volkan Cevher, Aditya Rawal, Sheng Zha, George Karypis |  |
| 257 |  |  [HyCoRec: Hypergraph-Enhanced Multi-Preference Learning for Alleviating Matthew Effect in Conversational Recommendation](https://doi.org/10.18653/v1/2024.acl-long.138) |  | 0 | The Matthew effect is a notorious issue in Recommender Systems (RSs), i.e., the rich get richer and the poor get poorer, wherein popular items are overexposed while less popular ones are regularly ignored. Most methods examine Matthew effect in static or nearly-static recommendation scenarios. However, the Matthew effect will be increasingly amplified when the user interacts with the system over time. To address these issues, we propose a novel paradigm, Hypergraph-Enhanced Multi-Preference... | Yongsen Zheng, Ruilin Xu, Ziliang Chen, Guohua Wang, Mingjie Qian, Jinghui Qin, Liang Lin |  |
| 258 |  |  [Co-training for Low Resource Scientific Natural Language Inference](https://doi.org/10.18653/v1/2024.acl-long.139) |  | 0 | Scientific Natural Language Inference (NLI) is the task of predicting the semantic relation between a pair of sentences extracted from research articles. The automatic annotation method based on distant supervision for the training set of SciNLI, the first and most popular dataset for this task, results in label noise which inevitably degenerates the performance of classifiers. In this paper, we propose a novel co-training method that assigns weights based on the training dynamics of the... | Mobashir Sadat, Cornelia Caragea |  |
| 259 |  |  [RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.140) |  | 0 | Reinforcement Learning with Human Feedback (RLHF) is a methodology designed to align Large Language Models (LLMs) with human preferences, playing an important role in LLMs alignment. Despite its advantages, RLHF relies on human annotators to rank the text, which can introduce potential security vulnerabilities if any adversarial annotator (i.e., attackers) manipulates the ranking score by up-ranking any malicious text to steer the LLM adversarially. To assess the red-teaming of RLHF against... | Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao |  |
| 260 |  |  [Time is Encoded in the Weights of Finetuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.141) |  | 0 | We present time vectors, a simple tool to customize language models to new time periods. Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model. This vector specifies a direction in weight space that, as our experiments show, improves performance on text from that time period. Time vectors specialized to adjacent time periods appear to be positioned closer together in a... | Kai Nylund, Suchin Gururangan, Noah A. Smith |  |
| 261 |  |  [Long-Context Language Modeling with Parallel Context Encoding](https://doi.org/10.18653/v1/2024.acl-long.142) |  | 0 | Extending large language models (LLMs) to process longer inputs is crucial for a wide range of applications. However, the substantial computational cost of transformers and limited generalization of positional encoding restrict the size of their context window. We introduce Context Expansion with Parallel Encoding (CEPE), a framework that can be applied to any existing decoder-only LLMs to extend their context window. CEPE employs a small encoder to process long inputs chunk by chunk, enabling... | Howard Yen, Tianyu Gao, Danqi Chen |  |
| 262 |  |  [SirLLM: Streaming Infinite Retentive LLM](https://doi.org/10.18653/v1/2024.acl-long.143) |  | 0 | As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process inputs of any length and maintain a degree of memory becomes essential. However, the one-off input of overly long texts is limited, as studies have shown that when input lengths exceed the LLMs’ pre-trained text length, there is a dramatic decline in text generation capabilities. Moreover, simply extending the length of pre-training texts is impractical due to the difficulty in obtaining... | Yao Yao, Zuchao Li, Hai Zhao |  |
| 263 |  |  [IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models](https://doi.org/10.18653/v1/2024.acl-long.144) |  | 0 | Machine learning models have made incredible progress, but they still struggle when applied to examples from unseen domains. This study focuses on a specific problem of domain generalization, where a model is trained on one source domain and tested on multiple target domains that are unseen during training. We propose IMO: Invariant features Masks for Out-of-Distribution text classification, to achieve OOD generalization by learning invariant features. During training, IMO would learn sparse... | Tao Feng, Lizhen Qu, Zhuang Li, Haolan Zhan, Yuncheng Hua, Gholamreza Haffari |  |
| 264 |  |  [Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale](https://doi.org/10.18653/v1/2024.acl-long.145) |  | 0 | A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner.We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained from scratch on raw texts with high parallelism. GPST circumvents the limitations of previous SLMs such as relying on gold trees and sequential training. It consists of two components, a usual SLM supervised by a uni-directional language modeling loss, and... | Xiang Hu, Pengyu Ji, Qingyang Zhu, Wei Wu, Kewei Tu |  |
| 265 |  |  [MELA: Multilingual Evaluation of Linguistic Acceptability](https://doi.org/10.18653/v1/2024.acl-long.146) |  | 0 | In this work, we present the largest benchmark to date on linguistic acceptability: Multilingual Evaluation of Linguistic Acceptability—MELA, with 46K samples covering 10 languages from a diverse set of language families. We establish LLM baselines on this benchmark, and investigate cross-lingual transfer in acceptability judgements with XLM-R. In pursuit of multilingual interpretability, we conduct probing experiments with fine-tuned XLM-R to explore the process of syntax capability... | Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, Hai Hu |  |
| 266 |  |  [CopyNE: Better Contextual ASR by Copying Named Entities](https://doi.org/10.18653/v1/2024.acl-long.147) |  | 0 | End-to-end automatic speech recognition (ASR) systems have made significant progress in general scenarios. However, it remains challenging to transcribe contextual named entities (NEs) in the contextual ASR scenario. Previous approaches have attempted to address this by utilizing the NE dictionary. These approaches treat entities as individual tokens and generate them token-by-token, which may result in incomplete transcriptions of entities. In this paper, we treat entities as indivisible... | Shilin Zhou, Zhenghua Li, Yu Hong, Min Zhang, Zhefeng Wang, Baoxing Huai |  |
| 267 |  |  [Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval](https://doi.org/10.18653/v1/2024.acl-long.148) |  | 0 | Retrieving relevant tables containing the necessary information to accurately answer a given question over tables is critical to open-domain question-answering (QA) systems. Previous methods assume the answer to such a question can be found either in a single table or multiple tables identified through question decomposition or rewriting. However, neither of these approaches is sufficient, as many questions require retrieving multiple tables and joining them through a join plan that cannot be... | Peter Baile Chen, Yi Zhang, Dan Roth |  |
| 268 |  |  [Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation](https://doi.org/10.18653/v1/2024.acl-long.149) |  | 0 | Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem – that is, users can perform a conversation in various ways, and these alternate conversations are unrecorded. Consequently, they often struggle to generalize to diverse conversations in real-world scenarios. In this work, we propose... | Haonan Chen, Zhicheng Dou, Kelong Mao, Jiongnan Liu, Ziliang Zhao |  |
| 269 |  |  [ItD: Large Language Models Can Teach Themselves Induction through Deduction](https://doi.org/10.18653/v1/2024.acl-long.150) |  | 0 | Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, researchers have found that they still have limited ability to conduct induction. Recent works mainly adopt “post processes” paradigms to improve the performance of LLMs on induction (e.g., the hypothesis search & refinement methods), but their performance is still constrained by the inherent inductive capability of the LLMs. In this paper, we propose a novel framework,... | Wangtao Sun, Haotian Xu, Xuanqing Yu, Pei Chen, Shizhu He, Jun Zhao, Kang Liu |  |
| 270 |  |  [MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.151) |  | 0 | Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems by leveraging the ground-truth solutions of the seed data. We augment these ground-truth solutions and use a specially finetuned model to translate these augmented solutions back... | Zimu Lu, Aojun Zhou, Houxing Ren, Ke Wang, Weikang Shi, Junting Pan, Mingjie Zhan, Hongsheng Li |  |
| 271 |  |  [Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent](https://doi.org/10.18653/v1/2024.acl-long.152) |  | 0 | Task-oriented dialogue (TOD) systems are predominantly designed to be composed of several functional modules (e.g. dialogue state tracker, dialogue policy, natural language generation) whether they are pipeline or end-to-end architectures. However, this modular design not only heavily relies on massive fully-annotated data, but also suffers from many intrinsic drawbacks, such as serious error accumulation, poor generalization ability, high customization cost, and low fault tolerance rate. In... | HengDa Xu, XianLing Mao, Puhai Yang, Fanshu Sun, Heyan Huang |  |
| 272 |  |  [On Context Utilization in Summarization with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.153) |  | 0 | Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of their input context. They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input. This bias raises concerns,... | Mathieu Ravaut, Aixin Sun, Nancy F. Chen, Shafiq Joty |  |
| 273 |  |  [INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.154) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While prompt-based methods can provide task descriptions to LLMs, they often fall short in facilitating a comprehensive understanding and execution of IR tasks, thereby limiting LLMs’ applicability. To address... | Yutao Zhu, Peitian Zhang, Chenghao Zhang, Yifei Chen, Binyu Xie, Zheng Liu, JiRong Wen, Zhicheng Dou |  |
| 274 |  |  [Enhancing In-Context Learning via Implicit Demonstration Augmentation](https://doi.org/10.18653/v1/2024.acl-long.155) |  | 0 | The emergence of in-context learning (ICL) enables large pre-trained language models (PLMs) to make predictions for unseen inputs without updating parameters. Despite its potential, ICL’s effectiveness heavily relies on the quality, quantity, and permutation of demonstrations, commonly leading to suboptimal and unstable performance. In this paper, we tackle this challenge for the first time from the perspective of demonstration augmentation. Specifically, we start with enriching representations... | Xiaoling Zhou, Wei Ye, Yidong Wang, Chaoya Jiang, Zhemg Lee, Rui Xie, Shikun Zhang |  |
| 275 |  |  [PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA](https://doi.org/10.18653/v1/2024.acl-long.156) |  | 0 | With the rapid scaling of large language models (LLMs), serving numerouslow-rank adaptations (LoRAs) concurrently has become increasingly impractical,leading to unaffordable costs and necessitating more parameter-efficientfinetuning methods. In this work, we introduce Partially Rotation-enhanced Low-Rank Adaptation (PRoLoRA), an intra-layer sharing mechanism comprising fouressential components: broadcast reduction, rotation enhancement,partially-sharing refinement, and rectified initialization... | Sheng Wang, Boyang Xue, Jiacheng Ye, Jiyue Jiang, Liheng Chen, Lingpeng Kong, Chuan Wu |  |
| 276 |  |  [Improving Event Definition Following For Zero-Shot Event Detection](https://doi.org/10.18653/v1/2024.acl-long.157) |  | 0 | Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations.In this work, we aim to improve zero-shot event detection by training models to better follow event definitions. We hypothesize that a diverse set of event types and definitions are the key for models to learn to follow event definitions while existing... | Zefan Cai, PoNien Kung, Ashima Suvarna, Mingyu Derek Ma, Hritik Bansal, Baobao Chang, P. Jeffrey Brantingham, Wei Wang, Nanyun Peng |  |
| 277 |  |  [Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements](https://doi.org/10.18653/v1/2024.acl-long.158) |  | 0 | The current charge prediction datasets mostly focus on single-defendant criminal cases.However, real-world criminal cases usually involve multiple defendants whose criminal facts are intertwined. In an early attempt to fill this gap, we introduce a new benchmark that encompasses legal cases involving multiple defendants, where each defendant is labeled with a charge and four types of crime elements, i.e., Object Element, Objective Element, Subject Element, and Subjective Element. Based on the... | Xiao Wei, Qi Xu, Hang Yu, Qian Liu, Erik Cambria |  |
| 278 |  |  [Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding](https://doi.org/10.18653/v1/2024.acl-long.159) |  | 0 | Conversational dense retrieval has shown to be effective in conversational search. However, a major limitation of conversational dense retrieval is their lack of interpretability, hindering intuitive understanding of model behaviors for targeted improvements. This paper presents CONVINV, a simple yet effective approach to shed light on interpretable conversational dense retrieval models. CONVINV transforms opaque conversational session embeddings into explicitly interpretable text while... | Yiruo Cheng, Kelong Mao, Zhicheng Dou |  |
| 279 |  |  [Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks](https://doi.org/10.18653/v1/2024.acl-long.160) |  | 0 | The widespread use of large language models (LLMs) is increasing the demand for methods that detect machine-generated text to prevent misuse. The goal of our study is to stress test the detectors’ robustness to malicious attacks under realistic scenarios. We comprehensively study the robustness of popular machine-generated text detectors under attacks from diverse categories: editing, paraphrasing, co-generating, and prompting. Our attacks assume limited access to the generator LLMs, and we... | Yichen Wang, Shangbin Feng, Abe Bohan Hou, Xiao Pu, Chao Shen, Xiaoming Liu, Yulia Tsvetkov, Tianxing He |  |
| 280 |  |  [Training Language Models to Generate Text with Citations via Fine-grained Rewards](https://doi.org/10.18653/v1/2024.acl-long.161) |  | 0 | While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to external documents as evidence. While previous works have directly prompted LLMs to generate in-text citations, their performances are far from satisfactory, especially when it comes to smaller LLMs.... | Chengyu Huang, Zeqiu Wu, Yushi Hu, Wenya Wang |  |
| 281 |  |  [Hypergraph based Understanding for Document Semantic Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.162) |  | 0 | Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries. We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to... | Qiwei Li, Zuchao Li, Ping Wang, Haojun Ai, Hai Zhao |  |
| 282 |  |  [GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers](https://doi.org/10.18653/v1/2024.acl-long.163) |  | 0 | Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly. This motivates us to evaluate the robustness of LLMs’ math reasoning... | Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi |  |
| 283 |  |  [Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.164) |  | 0 | Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events. Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event mentions. However, due to the complexity and diversity of contexts, these models are prone to learning simple co-occurrences. Recently, large language models (LLMs) like ChatGPT have demonstrated... | Qingkai Min, Qipeng Guo, Xiangkun Hu, Songfang Huang, Zheng Zhang, Yue Zhang |  |
| 284 |  |  [AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning](https://doi.org/10.18653/v1/2024.acl-long.165) |  | 0 | Language agents have achieved considerable performance on various complex question-answering tasks by planning with external tools. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework for QA that does not rely on large-scale annotated data and synthetic planning... | Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen |  |
| 285 |  |  [ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.166) |  | 0 | This study investigates the challenges posed by the dynamic nature of legal multi-label text classification tasks, where legal concepts evolve over time. Existing models often overlook the temporal dimension in their training process, leading to suboptimal performance of those models over time, as they treat training data as a single homogeneous block. To address this, we introduce ChronosLex, an incremental training paradigm that trains models on chronological splits, preserving the temporal... | T. Y. S. S. Santosh, TuanQuang Vuong, Matthias Grabmair |  |
| 286 |  |  [Virtual Compiler Is All You Need For Assembly Code Search](https://doi.org/10.18653/v1/2024.acl-long.167) |  | 0 | Assembly code search is vital for reducing the burden on reverse engineers, allowing them to quickly identify specific functions using natural language within vast binary programs.Despite its significance, this critical task is impeded by the complexities involved in building high-quality datasets. This paper explores training a Large Language Model (LLM) to emulate a general compiler. By leveraging Ubuntu packages to compile a dataset of 20 billion tokens, we further continue pre-train... | Zeyu Gao, Hao Wang, Yuanda Wang, Chao Zhang |  |
| 287 |  |  [MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.168) |  | 0 | Parameter-efficient fine-tuning (PEFT) is a popular method for tailoring pre-trained large language models (LLMs), especially as the models’ scale and the diversity of tasks increase. Low-rank adaptation (LoRA) is based on the idea that the adaptation process is intrinsically low-dimensional, i.e., significant model changes can be represented with relatively few parameters. However, decreasing the rank encounters challenges with generalization errors for specific tasks when compared to... | Pengjie Ren, Chengshun Shi, Shiguang Wu, Mengqi Zhang, Zhaochun Ren, Maarten de Rijke, Zhumin Chen, Jiahuan Pei |  |
| 288 |  |  [Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning](https://doi.org/10.18653/v1/2024.acl-long.169) |  | 0 | Large language models (LLMs) have demonstrated striking reasoning capability. Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples, learning from our mistakes is another vital aspect of human cognition. Hence, a question naturally arises: can LLMs learn and benefit from their mistakes, especially for their reasoning?This study... | Yongqi Tong, Dawei Li, Sizhe Wang, Yujia Wang, Fei Teng, Jingbo Shang |  |
| 289 |  |  [An Iterative Associative Memory Model for Empathetic Response Generation](https://doi.org/10.18653/v1/2024.acl-long.170) |  | 0 | Empathetic response generation aims to comprehend the cognitive and emotional states in dialogue utterances and generate proper responses. Psychological theories posit that comprehending emotional and cognitive states necessitates iteratively capturing and understanding associated words across dialogue utterances. However, existing approaches regard dialogue utterances as either a long sequence or independent utterances for comprehension, which are prone to overlook the associated words between... | Zhou Yang, Zhaochun Ren, Yufeng Wang, Haizhou Sun, Chao Chen, Xiaofei Zhu, Xiangwen Liao |  |
| 290 |  |  [Detoxifying Large Language Models via Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.171) |  | 0 | This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments with several knowledge editing approaches, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet... | Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, Linyi Yang, Jindong Wang, Huajun Chen |  |
| 291 |  |  [LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.172) |  | 0 | Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs, such as books, reports, and codebases. Recent works have proposed methods to improve LLMs’ long context capabilities by extending context windows and more sophisticated memory mechanisms. However, comprehensive benchmarks tailored for evaluating long context understanding are... | Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li |  |
| 292 |  |  [Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.173) |  | 0 | Teachers are important to imparting knowledge and guiding learners, and the role of large language models (LLMs) as potential educators is emerging as an important area of study. Recognizing LLMs’ capability to generate educational content can lead to advances in automated and personalized learning. While LLMs have been tested for their comprehension and problem-solving skills, their capability in teaching remains largely unexplored.In teaching, questioning is a key skill that guides students... | Yuyan Chen, Songzhou Yan, Panjun Liu, Yanghua Xiao |  |
| 293 |  |  [UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-long.174) |  | 0 | In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a comprehensive approach developed to improve the effectiveness of Cross-Lingual Transfer Learning, particularly in languages with limited resources. Our approach tackles two essential elements of a language model: the initialization of embeddings and the optimal vocabulary size. Specifically, we propose a novel embedding initialization method that leverages both lexical and... | Trinh Pham, Khoi Le, Anh Tuan Luu |  |
| 294 |  |  [VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval](https://doi.org/10.18653/v1/2024.acl-long.175) |  | 0 | Multi-modal retrieval becomes increasingly popular in practice. However, the existing retrievers are mostly text-oriented, which lack the capability to process visual information. Despite the presence of vision-language models like CLIP, the current methods are severely limited in representing the text-only and image-only data. In this work, we present a new embedding model VISTA for universal multi-modal retrieval. Our work brings forth threefold technical contributions. Firstly, we introduce... | Junjie Zhou, Zheng Liu, Shitao Xiao, Bo Zhao, Yongping Xiong |  |
| 295 |  |  [Black-Box Prompt Optimization: Aligning Large Language Models without Model Training](https://doi.org/10.18653/v1/2024.acl-long.176) |  | 0 | Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them; that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods primarily focus on further training them. However, the extra training of LLMs is usually expensive in terms of GPU computing; even worse, some LLMs are not accessible for user-demanded training,... | Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang |  |
| 296 |  |  [Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark](https://doi.org/10.18653/v1/2024.acl-long.177) |  | 0 | This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as vital tools for evaluating Large Language Models (LLMs) in Korean. Incorporating private test sets while mirroring the English Open LLM Leaderboard, we establish a robust evaluation framework that has been well integrated in the Korean LLM community. We perform data leakage analysis that shows the benefit of private test sets along with a correlation study within the Ko-H5 benchmark and temporal analyses of the Ko-H5... | Chanjun Park, Hyeonwoo Kim, Dahyun Kim, Seonghwan Cho, Sanghoon Kim, Sukyung Lee, Yungi Kim, Hwalsuk Lee |  |
| 297 |  |  [Unified Hallucination Detection for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.178) |  | 0 | Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In... | Xiang Chen, Chenxi Wang, Yida Xue, Ningyu Zhang, Xiaoyan Yang, Qiang Li, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen |  |
| 298 |  |  [Empowering Character-level Text Infilling by Eliminating Sub-Tokens](https://doi.org/10.18653/v1/2024.acl-long.179) |  | 0 | In infilling tasks, sub-tokens, representing instances where a complete token is segmented into two parts, often emerge at the boundaries of prefixes, middles, and suffixes. Traditional methods focused on training models at the token level, leading to sub-optimal performance in character-level infilling tasks during the inference stage. Alternately, some approaches considered character-level infilling, but they relied on predicting sub-tokens in inference, yet this strategy diminished ability... | Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Hongsheng Li |  |
| 299 |  |  [Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.180) |  | 0 | Retrieval augmentation is a promising approach to handle long-context language modeling. However, the existing retrieval methods usually work with the chunked context, which is prone to inferior quality of semantic representation and incomplete retrieval of useful information. In this work, we propose a new method for the retrieval augmentation of long-context language modeling, called Landmark Embedding. Our method is characterized by threefold technical contributions. Firstly, we introduce a... | Kun Luo, Zheng Liu, Shitao Xiao, Tong Zhou, Yubo Chen, Jun Zhao, Kang Liu |  |
| 300 |  |  [GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?](https://doi.org/10.18653/v1/2024.acl-long.181) |  | 0 | In the real world, knowledge is constantly evolving, which can render existing knowledge-based datasets outdated. This unreliability highlights the critical need for continuous updates to ensure both accuracy and relevance in knowledge-intensive tasks. To address this, we propose GrowOVER-QA and GrowOVER-Dialogue, dynamic open-domain QA and dialogue benchmarks that undergo a continuous cycle of updates, keeping pace with the rapid evolution of knowledge. Our research indicates that... | Dayoon Ko, Jinyoung Kim, Hahyeon Choi, Gunhee Kim |  |
| 301 |  |  [Attribute First, then Generate: Locally-attributable Grounded Text Generation](https://doi.org/10.18653/v1/2024.acl-long.182) |  | 0 | Recent efforts to address hallucinations in Large Language Models (LLMs) have focused on attributed text generation, which supplements generated texts with citations of supporting sources for post-generation fact-checking and corrections. Yet, these citations often point to entire documents or paragraphs, burdening users with extensive verification work. In this paper, we introduce a locally-attributable text generation approach, prioritizing concise attributions. Our method, named “Attribute... | Aviv Slobodkin, Eran Hirsch, Arie Cattan, Tal Schuster, Ido Dagan |  |
| 302 |  |  [T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text](https://doi.org/10.18653/v1/2024.acl-long.183) |  | 0 | In this work, we propose a two-stage sign language production (SLP) paradigm that first encodes sign language sequences into discrete codes and then autoregressively generates sign language from text based on the learned codebook. However, existing vector quantization (VQ) methods are fixed-length encodings, overlooking the uneven information density in sign language, which leads to under-encoding of important regions and over-encoding of unimportant regions. To address this issue, we propose a... | Aoxiong Yin, Haoyuan Li, Kai Shen, Siliang Tang, Yueting Zhuang |  |
| 303 |  |  [OceanGPT: A Large Language Model for Ocean Science Tasks](https://doi.org/10.18653/v1/2024.acl-long.184) |  | 0 | Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet’s surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the... | Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, Huajun Chen |  |
| 304 |  |  [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://doi.org/10.18653/v1/2024.acl-long.185) |  | 0 | Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks.However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question... | Tongyao Zhu, Qian Liu, Liang Pang, Zhengbao Jiang, MinYen Kan, Min Lin |  |
| 305 |  |  [BIPED: Pedagogically Informed Tutoring System for ESL Education](https://doi.org/10.18653/v1/2024.acl-long.186) |  | 0 | Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English. Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to address diverse learning strategies. To develop a more pedagogically informed CITS capable of teaching complex concepts, we construct a BIlingual PEDagogically-informed Tutoring Dataset (BIPED) of... | Soonwoo Kwon, Sojung Kim, Minju Park, Seunghyun Lee, Kyuseok Kim |  |
| 306 |  |  [Timeline-based Sentence Decomposition with In Context Learning for Temporal Fact Extraction](https://doi.org/10.18653/v1/2024.acl-long.187) |  | 0 | Facts extraction is pivotal for constructing knowledge graphs. Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction. In this paper, we specifically address the extraction of temporal facts from natural language text. Previous studies fail to handle the challenge of establishing time-to-fact correspondences in complex sentences. To overcome this hurdle, we propose a timeline-based sentence decomposition strategy... | Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu |  |
| 307 |  |  [Collaboration or Corporate Capture? Quantifying NLP's Reliance on Industry Artifacts and Contributions](https://doi.org/10.18653/v1/2024.acl-long.188) |  | 0 | Impressive performance of pre-trained models has garnered public attention and made news headlines in recent years. Almost always, these models are produced by or in collaboration with industry. Using them is critical for competing on natural language processing (NLP) benchmarks and correspondingly to stay relevant in NLP research. We surveyed 100 papers published at EMNLP 2022 to determine the degree to which researchers rely on industry models, other artifacts, and contributions to publish in... | Will Aitken, Mohamed Abdalla, Karen Rudie, Catherine Stinson |  |
| 308 |  |  [Prompt Expansion for Adaptive Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.189) |  | 0 | Text-to-image generation models are powerful but difficult to use. Users craft specific prompts to get better images, though the images can be repetitive. This paper proposes the Prompt Expansion framework that helps users generate high-quality, diverse images with less effort. The Prompt Expansion model takes a text query as input and outputs a set of expanded text prompts that are optimized such that when passed to a text-to-image model, they generate a wider variety of appealing images. We... | Siddhartha Datta, Alexander Ku, Deepak Ramachandran, Peter Anderson |  |
| 309 |  |  [Progressively Modality Freezing for Multi-Modal Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.190) |  | 0 | Multi-Modal Entity Alignment aims to discover identical entities across heterogeneous knowledge graphs. While recent studies have delved into fusion paradigms to represent entities holistically, the elimination of features irrelevant to alignment and modal inconsistencies is overlooked, which are caused by inherent differences in multi-modal features. To address these challenges, we propose a novel strategy of progressive modality freezing, called PMF, that focuses on alignment-relevant... | Yani Huang, Xuefeng Zhang, Richong Zhang, Junfan Chen, Jaein Kim |  |
| 310 |  |  [Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-long.191) |  | 0 | Dense retrieval calls for discriminative embeddings to represent the semantic relationship between query and document. It may benefit from the using of large language models (LLMs), given LLMs’ strong capability on semantic understanding. However, the LLMs are learned by auto-regression, whose working mechanism is completely different from representing whole text as one discriminative embedding. Thus, it is imperative to study how to adapt LLMs properly so that they can be effectively... | Chaofan Li, Zheng Liu, Shitao Xiao, Yingxia Shao, Defu Lian |  |
| 311 |  |  [Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts](https://doi.org/10.18653/v1/2024.acl-long.192) |  | 0 | Large language models (LLMs) are known to effectively perform tasks by simply observing few exemplars. However, in low-resource languages, obtaining such hand-picked exemplars can still be challenging, where unsupervised techniques may be necessary. Moreover, competent generative capabilities of LLMs are observed only in high-resource languages, while their performances among under-represented languages fall behind due to pre-training data imbalance. To elicit LLMs’ ability onto low-resource... | XuanPhi Nguyen, Mahani Aljunied, Shafiq Joty, Lidong Bing |  |
| 312 |  |  [Metaphor Understanding Challenge Dataset for LLMs](https://doi.org/10.18653/v1/2024.acl-long.193) |  | 0 | Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning and categorisation, and are deeply rooted in everyday communication. Metaphor understanding is therefore an essential task for large language models (LLMs). We release the Metaphor Understanding Challenge Dataset (MUNCH), designed to evaluate the metaphor understanding capabilities of LLMs. The dataset provides over 10k paraphrases for sentences containing metaphor use, as well as 1.5k... | Xiaoyu Tong, Rochelle Choenni, Martha Lewis, Ekaterina Shutova |  |
| 313 |  |  [A Multi-Task Embedder For Retrieval Augmented LLMs](https://doi.org/10.18653/v1/2024.acl-long.194) |  | 0 | LLMs confront inherent limitations in terms of its knowledge, memory, and action. The retrieval augmentation stands as a vital mechanism to address these limitations, which brings in useful information from external sources to augment the LLM. However, existing retrieval methods encounter two pressing issues. On one hand, the general retrievers are not properly optimized for retrieval augmentation hence exhibit limited effectiveness; on the other hand, the task-specific retrievers excel in the... | Peitian Zhang, Zheng Liu, Shitao Xiao, Zhicheng Dou, JianYun Nie |  |
| 314 |  |  [Language Models Don't Learn the Physical Manifestation of Language](https://doi.org/10.18653/v1/2024.acl-long.195) |  | 0 | We argue that language-only models don’t learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test.These tasks highlight a fundamental gap between human linguistic understanding and the sensory-deprived linguistic understanding of LLMs. In support of our hypothesis, 1. deliberate reasoning (Chain-of-Thought), 2. few-shot examples, or 3. stronger LLM from the same model family (LLaMA 2... | Bruce W. Lee, Jaehyuk Lim |  |
| 315 |  |  [What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection](https://doi.org/10.18653/v1/2024.acl-long.196) |  | 0 | Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse... | Shangbin Feng, Herun Wan, Ningnan Wang, Zhaoxuan Tan, Minnan Luo, Yulia Tsvetkov |  |
| 316 |  |  [Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives](https://doi.org/10.18653/v1/2024.acl-long.197) |  | 0 | The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM’s response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM’s intrinsic reflection is unstable. Our investigation unveils that the key bottleneck is the quality of the self-evaluated feedback. We find LLMs often exhibit overconfidence or high randomness when... | Wenqi Zhang, Yongliang Shen, Linjuan Wu, Qiuying Peng, Jun Wang, Yueting Zhuang, Weiming Lu |  |
| 317 |  |  [Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty](https://doi.org/10.18653/v1/2024.acl-long.198) |  | 0 | As natural language becomes the default interface for human-AI interaction, there is a need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence in responses via natural language and how downstream users behave in response to LM-articulated uncertainties. We examine publicly deployed models and find that LMs are reluctant to express uncertainties when answering questions even when they produce incorrect... | Kaitlyn Zhou, Jena D. Hwang, Xiang Ren, Maarten Sap |  |
| 318 |  |  [Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources](https://doi.org/10.18653/v1/2024.acl-long.199) |  | 0 | Although pre-training has become a prevalent approach for addressing various biomedical tasks, the current efficacy of pre-trained models is hindered by their reliance on a limited scope of medical sources. This limitation results in data scarcity during pre-training and restricts the range of applicable downstream tasks. In response to these challenges, we develop MedCSP, a new pre-training strategy designed to bridge the gap between multimodal medical sources. MedCSP employs modality-level... | Xiaochen Wang, Junyu Luo, Jiaqi Wang, Yuan Zhong, Xiaokun Zhang, Yaqing Wang, Parminder Bhatia, Cao Xiao, Fenglong Ma |  |
| 319 |  |  [When Good and Reproducible Results are a Giant with Feet of Clay: The Importance of Software Quality in NLP](https://doi.org/10.18653/v1/2024.acl-long.200) |  | 0 | Despite its crucial role in research experiments, code correctness is often presumed solely based on the perceived quality of results. This assumption, however, comes with the risk of erroneous outcomes and, in turn, potentially misleading findings. To mitigate this risk, we posit that the current focus on reproducibility should go hand in hand with the emphasis on software quality. We support our arguments with a case study in which we identify and fix three bugs in widely used implementations... | Sara Papi, Marco Gaido, Andrea Pilzer, Matteo Negri |  |
| 320 |  |  [SBAAM! Eliminating Transcript Dependency in Automatic Subtitling](https://doi.org/10.18653/v1/2024.acl-long.201) |  | 0 | Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three primary subtasks: translating spoken dialogue, segmenting translations into concise textual units, and estimating timestamps that govern their on-screen duration. Past attempts to automate this process rely, to varying degrees, on automatic transcripts, employed diversely for the three subtasks. In response to the acknowledged limitations associated with this reliance on transcripts,... | Marco Gaido, Sara Papi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli |  |
| 321 |  |  [StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection](https://doi.org/10.18653/v1/2024.acl-long.202) |  | 0 | Streaming speech-to-text translation (StreamST) is the task of automatically translating speech while incrementally receiving an audio stream. Unlike simultaneous ST (SimulST), which deals with pre-segmented speech, StreamST faces the challenges of handling continuous and unbounded audio streams. This requires additional decisions about what to retain of the previous history, which is impractical to keep entirely due to latency and computational constraints. Despite the real-world demand for... | Sara Papi, Marco Gaido, Matteo Negri, Luisa Bentivogli |  |
| 322 |  |  [ARL2: Aligning Retrievers with Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](https://doi.org/10.18653/v1/2024.acl-long.203) |  | 0 | Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to separate training processes and the inherent black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2... | Lingxi Zhang, Yue Yu, Kuan Wang, Chao Zhang |  |
| 323 |  |  [Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference](https://doi.org/10.18653/v1/2024.acl-long.204) |  | 0 | The customization of large language models (LLMs) for user-specified tasks gets important. However, maintaining all the customized LLMs on cloud servers incurs substantial memory and computational overheads, and uploading user data can also lead to privacy concerns. On-device LLMs can offer a promising solution by mitigating these issues. Yet, the performance of on-device LLMs is inherently constrained by the limitations of small-scaled models. To overcome these restrictions, we first propose... | Jihwan Bang, Juntae Lee, Kyuhong Shim, Seunghan Yang, Simyung Chang |  |
| 324 |  |  [FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model](https://doi.org/10.18653/v1/2024.acl-long.205) |  | 0 | Most existing image captioning evaluation metrics focus on assigning a single numerical score to a caption by comparing it with reference captions. However, these methods do not provide an explanation for the assigned score. Moreover, reference captions are expensive to acquire. In this paper, we propose FLEUR, an explainable reference-free metric to introduce explainability into image captioning evaluation metrics. By leveraging a large multimodal model, FLEUR can evaluate the caption against... | Yebin Lee, Imseong Park, Myungjoo Kang |  |
| 325 |  |  [MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations](https://doi.org/10.18653/v1/2024.acl-long.206) |  | 0 | Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its context-dependent and often subtle nature. The detection of manipulative language is essential for protecting potential victims, yet the field of Natural Language Processing (NLP) currently faces a scarcity of resources and research on this topic. Our study addresses this gap by introducing a new dataset, named MentalManip, which consists of 4,000 annotated fictional... | Yuxin Wang, Ivory Yang, Saeed Hassanpour, Soroush Vosoughi |  |
| 326 |  |  [MPCoder: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning](https://doi.org/10.18653/v1/2024.acl-long.207) |  | 0 | Large Language Models (LLMs) have demonstrated great potential for assisting developers in their daily development. However, most research focuses on generating correct code, how to use LLMs to generate personalized code has seldom been investigated. To bridge this gap, we proposed MPCoder (Multi-user Personalized Code Generator) to generate personalized code for multiple users. To better learn coding style features, we utilize explicit coding style residual learning to capture the syntax code... | Zhenlong Dai, Chang Yao, WenKang Han, Yuanying Yuanying, Zhipeng Gao, Jingyuan Chen |  |
| 327 |  |  [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://doi.org/10.18653/v1/2024.acl-long.208) |  | 0 | Large language models (LLMs) have become a dominant and important tool for NLP researchers in a wide range of tasks. Today, many researchers use LLMs in synthetic data generation, task evaluation, fine-tuning, distillation, and other model-in-the-loop research workflows. However, challenges arise when using these models that stem from their scale, their closed source nature, and the lack of standardized tooling for these new and emerging workflows. The rapid rise to prominence of these models... | Ajay Patel, Colin Raffel, Chris CallisonBurch |  |
| 328 |  |  [Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective](https://doi.org/10.18653/v1/2024.acl-long.209) |  | 0 | Neural Machine Translation (NMT) has made remarkable progress over the past years. However, under-translation and over-translation remain two challenging problems in state-of-the-art NMT systems. In this work, we conduct an in-depth analysis on the underlying cause of under-translation in NMT, providing an explanation from the perspective of decoding objective. To optimize the beam search objective, the model tends to overlook words it is less confident about, leading to the under-translation... | Chenze Shao, Fandong Meng, Jiali Zeng, Jie Zhou |  |
| 329 |  |  [Identifying while Learning for Document Event Causality Identification](https://doi.org/10.18653/v1/2024.acl-long.210) |  | 0 | Event Causality Identification (ECI) aims to detect whether there exists a causal relation between two events in a document. Existing studies adopt a kind of \*identifying after learning\* paradigm, where events’ representations are first learned and then used for the identification. Furthermore, they mainly focus on the causality existence, but ignoring causal direction. In this paper, we take care of the causal direction and propose a new \*identifying while learning\* mode for the ECI task.... | Cheng Liu, Wei Xiang, Bang Wang |  |
| 330 |  |  [OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems](https://doi.org/10.18653/v1/2024.acl-long.211) |  | 0 | Recent advancements have seen Large Language Models (LLMs) and Large Multimodal Models (LMMs) surpassing general human capabilities in various tasks, approaching the proficiency level of human experts across multiple domains. With traditional benchmarks becoming less challenging for these models, new rigorous challenges are essential to gauge their advanced abilities. In this work, we present OlympiadBench, an Olympiad-level bilingual multimodal scientific benchmark, featuring 8,476 problems... | Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Leng Thai, Junhao Shen, Jinyi Hu, Xu Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, Maosong Sun |  |
| 331 |  |  [Insert or Attach: Taxonomy Completion via Box Embedding](https://doi.org/10.18653/v1/2024.acl-long.212) |  | 0 | Taxonomy completion, enriching existing taxonomies by inserting new concepts as parents or attaching them as children, has gained significant interest. Previous approaches embed concepts as vectors in Euclidean space, which makes it difficult to model asymmetric relations in taxonomy. In addition, they introduce pseudo-leaves to convert attachment cases into insertion cases, leading to an incorrect bias in network learning dominated by numerous pseudo-leaves. Addressing these, our framework,... | Wei Xue, Yongliang Shen, Wenqi Ren, Jietian Guo, Shiliang Pu, Weiming Lu |  |
| 332 |  |  [Semiparametric Token-Sequence Co-Supervision](https://doi.org/10.18653/v1/2024.acl-long.213) |  | 0 | In this work, we introduce a semiparametric token-sequence co-supervision training method. It trains a language model by simultaneously leveraging supervision from the traditional next token prediction loss which is calculated over the parametric token embedding space and the next sequence prediction loss which is calculated over the nonparametric sequence embedding space. The nonparametric sequence embedding space is constructed by a separate language model tasked to condense an input text... | Hyunji Lee, Doyoung Kim, Jihoon Jun, Se June Joo, Joel Jang, KyoungWoon On, Minjoon Seo |  |
| 333 |  |  [Instruction Fusion: Advancing Prompt Evolution through Hybridization](https://doi.org/10.18653/v1/2024.acl-long.214) |  | 0 | The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks. This paper examines the constraints of existing prompt evolution techniques and introduces a novel approach, Instruction Fusion (IF). IF innovatively combines two distinct prompts through... | Weidong Guo, Jiuding Yang, Kaitong Yang, Xiangyang Li, Zhuwei Rao, Yu Xu, Di Niu |  |
| 334 |  |  [TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation](https://doi.org/10.18653/v1/2024.acl-long.215) |  | 0 | Despite remarkable advancements in emulating human-like behavior through Large Language Models (LLMs), current textual simulations do not adequately address the notion of time. To this end, we introduce TimeArena, a novel textual simulated environment that incorporates complex temporal dynamics and constraints that better reflect real-life planning scenarios. In TimeArena, agents are asked to complete multiple tasks as soon as possible, allowing for parallel processing to save time. We... | Yikai Zhang, Siyu Yuan, Caiyu Hu, Kyle Richardson, Yanghua Xiao, Jiangjie Chen |  |
| 335 |  |  [Exploring Memorization in Fine-tuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.216) |  | 0 | Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is rather limited. Compared to pre-training, fine-tuning typically involves more sensitive data and diverse objectives, thus may bring distinct privacy risks and unique memorization behaviors. In this work,... | Shenglai Zeng, Yaxin Li, Jie Ren, Yiding Liu, Han Xu, Pengfei He, Yue Xing, Shuaiqiang Wang, Jiliang Tang, Dawei Yin |  |
| 336 |  |  [Towards Real-world Scenario: Imbalanced New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.217) |  | 0 | New Intent Discovery (NID) aims at detecting known and previously undefined categories of user intent by utilizing limited labeled and massive unlabeled data. Most prior works often operate under the unrealistic assumption that the distribution of both familiar and new intent classes is uniform, overlooking the skewed and long-tailed distributions frequently encountered in real-world scenarios. To bridge the gap, our work introduces the imbalanced new intent discovery i-NID task, which seeks to... | Shun Zhang, Chaoran Yan, Jian Yang, Jiaheng Liu, Ying Mo, Jiaqi Bai, Tongliang Li, Zhoujun Li |  |
| 337 |  |  [M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection](https://doi.org/10.18653/v1/2024.acl-long.218) |  | 0 | The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by... | Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, Thomas Arnold, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov |  |
| 338 |  |  [Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue](https://doi.org/10.18653/v1/2024.acl-long.219) |  | 0 | Tuning language models for dialogue generation has been a prevalent paradigm for building capable dialogue agents. Yet, traditional tuning narrowly views dialogue generation as resembling other language generation tasks, ignoring the role disparities between two speakers and the multi-round interactive process that dialogues ought to be. Such a manner often leads to unsatisfactory chat consistency for the built agent. In this work, we emphasize the interactive, communicative nature of dialogue... | Jian Wang, Chak Tou Leong, Jiashuo Wang, Dongding Lin, Wenjie Li, Xiaoyong Wei |  |
| 339 |  |  [SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training](https://doi.org/10.18653/v1/2024.acl-long.220) |  | 0 | The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and neglects the varying degrees of duplication. To address this, we propose a soft deduplication method that maintains dataset integrity while selectively reducing the sampling weight of data with high commonness. Central to our approach is the... | Nan He, Weichen Xiong, Hanwen Liu, Yi Liao, Lei Ding, Kai Zhang, Guohua Tang, Xiao Han, Yang Wei |  |
| 340 |  |  [Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?](https://doi.org/10.18653/v1/2024.acl-long.221) |  | 0 | Building machines with commonsense has been a longstanding challenge in NLP due to the reporting bias of commonsense rules and the exposure bias of rule-based commonsense reasoning. In contrast, humans convey and pass down commonsense implicitly through stories. This paper investigates the inherent commonsense ability of large language models (LLMs) expressed through storytelling. We systematically investigate and compare stories and rules for retrieving and leveraging commonsense in LLMs.... | Ning Bian, Xianpei Han, Hongyu Lin, Yaojie Lu, Ben He, Le Sun |  |
| 341 |  |  [Learning Global Controller in Latent Space for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.222) |  | 0 | While large language models (LLMs) have showcased remarkable prowess in various natural language processing tasks, their training costs are exorbitant. Consequently, a plethora of parameter-efficient fine-tuning methods have emerged to tailor large models for downstream tasks, including low-rank training. Recent approaches either amalgamate existing fine-tuning methods or dynamically adjust rank allocation. Nonetheless, these methods continue to grapple with issues like local optimization,... | Zeqi Tan, Yongliang Shen, Xiaoxia Cheng, Chang Zong, Wenqi Zhang, Jian Shao, Weiming Lu, Yueting Zhuang |  |
| 342 |  |  [CaMML: Context-Aware Multimodal Learner for Large Models](https://doi.org/10.18653/v1/2024.acl-long.223) |  | 0 | In this work, we introduce Context-Aware MultiModal Learner (CaMML), for tuning large multimodal models (LMMs). CaMML, a lightweight module, is crafted to seamlessly integrate multimodal contextual samples into large models, thereby empowering the model to derive knowledge from analogous, domain-specific, up-to-date information and make grounded inferences. Importantly, CaMML is highly scalable and can efficiently handle lengthy multimodal context examples owing to its hierarchical design.... | Yixin Chen, Shuai Zhang, Boran Han, Tong He, Bo Li |  |
| 343 |  |  [MAVEN-ARG: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation](https://doi.org/10.18653/v1/2024.acl-long.224) |  | 0 | Understanding events in texts is a core objective of natural language understanding, which requires detecting event occurrences, extracting event arguments, and analyzing inter-event relationships. However, due to the annotation challenges brought by task complexity, a large-scale dataset covering the full process of event understanding has long been absent. In this paper, we introduce MAVEN-Arg, which augments MAVEN datasets with event argument annotations, making the first all-in-one dataset... | Xiaozhi Wang, Hao Peng, Yong Guan, Kaisheng Zeng, Jianhui Chen, Lei Hou, Xu Han, Yankai Lin, Zhiyuan Liu, Ruobing Xie, Jie Zhou, Juanzi Li |  |
| 344 |  |  [NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes](https://doi.org/10.18653/v1/2024.acl-long.225) |  | 0 | Complex reasoning ability is one of the most important features of Large Language Models (LLMs). Numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, they are inadequate in offering a rigorous evaluation and prone to the risk of overfitting, as these publicly accessible and static benchmarks allow models to potentially tailor their responses to specific benchmark metrics, thereby inflating their performance. Addressing these limitations, we introduce a... | Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng Zhang |  |
| 345 |  |  [Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.226) |  | 0 | Text watermarking technology aims to tag and identify content produced by large language models (LLMs) to prevent misuse. In this study, we introduce the concept of cross-lingual consistency in text watermarking, which assesses the ability of text watermarks to maintain their effectiveness after being translated into other languages. Preliminary empirical results from two LLMs and three watermarking methods reveal that current text watermarking technologies lack consistency when texts are... | Zhiwei He, Binglin Zhou, Hongkun Hao, Aiwei Liu, Xing Wang, Zhaopeng Tu, Zhuosheng Zhang, Rui Wang |  |
| 346 |  |  [Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors](https://doi.org/10.18653/v1/2024.acl-long.227) |  | 0 | Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it difficult for them to support the large number of people with mental health issues who use peer counseling. Our work aims to leverage large language models to provide contextualized and multi-level... | Alicja Chaszczewicz, Raj Sanjay Shah, Ryan Louie, Bruce A Arnow, Robert E. Kraut, Diyi Yang |  |
| 347 |  |  [In-context Mixing (ICM): Code-mixed Prompts for Multilingual LLMs](https://doi.org/10.18653/v1/2024.acl-long.228) |  | 0 | We introduce a simple and effective prompting technique called in-context mixing (ICM) for effective in-context learning (ICL) with multilingual large language models (MLLMs). With ICM, we modify the few-shot examples within ICL prompts to be intra-sententially code-mixed by randomly swapping content words in the target languages with their English translations. We observe that ICM prompts yield superior performance in NLP tasks such as disfluency correction, grammar error correction and text... | Bhavani Shankar, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 348 |  |  [Respond in my Language: Mitigating Language Inconsistency in Response Generation based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.229) |  | 0 | Large Language Models (LLMs) show strong instruction understanding ability across multiple languages. However, they are easily biased towards English in instruction tuning, and generate English responses even given non-English instructions. In this paper, we investigate the language inconsistent generation problem in monolingual instruction tuning. We find that instruction tuning in English increases the models’ preference for English responses. It attaches higher probabilities to English... | Liang Zhang, Qin Jin, Haoyang Huang, Dongdong Zhang, Furu Wei |  |
| 349 |  |  [Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries](https://doi.org/10.18653/v1/2024.acl-long.230) |  | 0 | This study investigates the privacy risks associated with text embeddings, focusing on the scenario where attackers cannot access the original embedding model. Contrary to previous research requiring direct model access, we explore a more realistic threat model by developing a transfer attack method. This approach uses a surrogate model to mimic the victim model’s behavior, allowing the attacker to infer sensitive information from text embeddings without direct access. Our experiments across... | YuHsiang Huang, YuChe Tsai, Hsiang Hsiao, HongYi Lin, ShouDe Lin |  |
| 350 |  |  [Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding](https://doi.org/10.18653/v1/2024.acl-long.231) |  | 0 | Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF encounters numerous challenges, including the objective mismatch issue, leading to suboptimal performance in Natural Language Understanding (NLU) tasks.To address this limitation, we propose a novel Reinforcement Learning framework enhanced with Label-sensitive Reward (RLLR)... | Kuo Liao, Shuang Li, Meng Zhao, Liqun Liu, Mengge Xue, Zhenyu Hu, Honglin Han, Chengguo Yin |  |
| 351 |  |  [Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts](https://doi.org/10.18653/v1/2024.acl-long.232) |  | 0 | This study investigates the behaviors of Large Language Models (LLMs) when faced with conflicting prompts versus their internal memory. This will not only help to understand LLMs’ decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG).Drawing on cognitive theory, we target the first scenario of decision-making styles where there is no superiority in the conflict and categorize LLMs’ preference into dependent, intuitive, and rational/irrational... | Jiahao Ying, Yixin Cao, Kai Xiong, Long Cui, Yidong He, Yongbin Liu |  |
| 352 |  |  [CoCA: Fusing Position Embedding with Collinear Constrained Attention in Transformers for Long Context Window Extending](https://doi.org/10.18653/v1/2024.acl-long.233) |  | 0 | Self-attention and position embedding are two crucial modules in transformer-based Large Language Models (LLMs). However, the potential relationship between them is far from well studied, especially for long context window extending. In fact, anomalous behaviors that hinder long context extrapolation exist between Rotary Position Embedding (RoPE) and vanilla self-attention.Incorrect initial angles between Q and K can cause misestimation in modeling rotary position embedding of the closest... | Shiyi Zhu, Jing Ye, Wei Jiang, Siqiao Xue, Qi Zhang, Yifan Wu, Jianguo Li |  |
| 353 |  |  [InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification](https://doi.org/10.18653/v1/2024.acl-long.234) |  | 0 | Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from... | Jan Trienes, Sebastian Joseph, Jörg Schlötterer, Christin Seifert, Kyle Lo, Wei Xu, Byron C. Wallace, Junyi Jessy Li |  |
| 354 |  |  [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.235) |  | 0 | With the advancement of language models (LMs), their exposure to private data is increasingly inevitable, and their deployment (especially for smaller ones) on personal devices, such as PCs and smartphones, has become a prevailing trend. In contexts laden with user information, enabling models to both safeguard user privacy and execute commands efficiently emerges as an essential research imperative. In this paper, we propose CoGenesis, a collaborative generation framework integrating large... | Kaiyan Zhang, Jianyu Wang, Ermo Hua, Biqing Qi, Ning Ding, Bowen Zhou |  |
| 355 |  |  [DAPR: A Benchmark on Document-Aware Passage Retrieval](https://doi.org/10.18653/v1/2024.acl-long.236) |  | 0 | The work of neural retrieval so far focuses on ranking short texts and is challenged with long documents. There are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. Wikipedia articles, research papers, etc. We propose and name this task Document-Aware Passage Retrieval (DAPR). While analyzing the errors of the State-of-The-Art (SoTA) passage retrievers, we find the major errors (53.5%) are due to missing document context. This drives us... | Kexin Wang, Nils Reimers, Iryna Gurevych |  |
| 356 |  |  [Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors](https://doi.org/10.18653/v1/2024.acl-long.237) |  | 0 | Multiple-Choice Questions (MCQs) constitute a critical area of research in the study of Large Language Models (LLMs). Previous works have investigated the selection bias problem in MCQs within few-shot scenarios, in which the LLM’s performance may be influenced by the presentation of answer choices, leaving the selection bias during Supervised Fine-Tuning (SFT) unexplored. In this paper, we reveal that selection bias persists in the SFT phase , primarily due to the LLM’s inadequate Multiple... | Mengge Xue, Zhenyu Hu, Liqun Liu, Kuo Liao, Shuang Li, Honglin Han, Meng Zhao, Chengguo Yin |  |
| 357 |  |  [SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.238) |  | 0 | Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks across specialized domains, where the acquisition of precise and dependable knowledge is crucial. However, existing KG construction methods heavily rely on human intervention to attain qualified KGs, which severely hinders the practical applicability in real-world scenarios. To address this challenge, we propose a general KG construction framework, named \*\*SAC-KG\*\*, to exploit large language models (LLMs) as... | Hanzhu Chen, Xu Shen, Qitan Lv, Jie Wang, Xiaoqi Ni, Jieping Ye |  |
| 358 |  |  [Uncertainty-Guided Modal Rebalance for Hateful Memes Detection](https://doi.org/10.18653/v1/2024.acl-long.239) |  | 0 | Hateful memes detection is a challenging multimodal understanding task that requires comprehensive learning of vision, language, and cross-modal interactions. Previous research has focused on developing effective fusion strategies for integrating hate information from different modalities. However, these methods excessively rely on cross-modal fusion features, ignoring the modality uncertainty caused by the contribution degree of each modality to hate sentiment and the modality imbalance caused... | Chuanpeng Yang, Yaxin Liu, Fuqing Zhu, Jizhong Han, Songlin Hu |  |
| 359 |  |  [Missci: Reconstructing Fallacies in Misrepresented Science](https://doi.org/10.18653/v1/2024.acl-long.240) |  | 0 | Health-related misinformation on social networks can lead to poor decision-making and real-world dangers. Such misinformation often misrepresents scientific publications and cites them as “proof” to gain perceived credibility. To effectively counter such claims automatically, a system must explain how the claim was falsely derived from the cited publication. Current methods for automated fact-checking or fallacy detection neglect to assess the (mis)used evidence in relation to misinformation... | Max Glockner, Yufang Hou, Preslav Nakov, Iryna Gurevych |  |
| 360 |  |  [Uncovering the Full Potential of Visual Grounding Methods in VQA](https://doi.org/10.18653/v1/2024.acl-long.241) |  | 0 | Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model’s reliance on question-relevant visual information. The presence of such relevant information in the visual input is typically assumed in training and testing. This assumption, however, is inherently flawed when dealing with imperfect image representations common in large-scale VQA, where the information carried by visual features frequently deviates from expected... | Daniel Reich, Tanja Schultz |  |
| 361 |  |  [Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs](https://doi.org/10.18653/v1/2024.acl-long.242) |  | 0 | The integration of large language models (LLMs) and search engines represents a significant evolution in knowledge acquisition methodologies. However, determining the knowledge that an LLM already possesses and the knowledge that requires the help of a search engine remains an unresolved issue. Most existing methods solve this problem through the results of preliminary answers or reasoning done by the LLM itself, but this incurs excessively high computational costs. This paper introduces a... | Jiejun Tan, Zhicheng Dou, Yutao Zhu, Peidong Guo, Kun Fang, JiRong Wen |  |
| 362 |  |  [Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation](https://doi.org/10.18653/v1/2024.acl-long.243) |  | 0 | Generative AI systems have become ubiquitous for all kinds of modalities, which makes the issue of the evaluation of such models more pressing. One popular approach is preference ratings, where the generated outputs of different systems are shown to evaluators who choose their preferences. In recent years the field shifted towards the development of automated (trained) metrics to assess generated outputs, which can be used to create preference ratings automatically. In this work, we investigate... | Pius von Däniken, Jan Deriu, Don Tuggener, Mark Cieliebak |  |
| 363 |  |  [LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback](https://doi.org/10.18653/v1/2024.acl-long.244) |  | 0 | Ensuring that online discussions are civil and productive is a major challenge for social media platforms. Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review. However, this kind of post-hoc moderation is expensive and time-consuming, and moderators are often overwhelmed by the amount and severity of flagged content. Instead, a promising alternative is to prevent negative behavior during content... | Timon Ziegenbein, Gabriella Skitalinskaya, Alireza Bayat Makou, Henning Wachsmuth |  |
| 364 |  |  [Graph Language Models](https://doi.org/10.18653/v1/2024.acl-long.245) |  | 0 | While Language Models (LMs) are the workhorses of NLP, their interplay with structured knowledge graphs (KGs) is still actively researched. Current methods for encoding such graphs typically either (i) linearize them for embedding with LMs – which underutilize structural information, or (ii) use Graph Neural Networks (GNNs) to preserve the graph structure – but GNNs cannot represent text features as well as pretrained LMs. In our work we introduce a novel LM type, the Graph Language Model... | Moritz Plenz, Anette Frank |  |
| 365 |  |  [Analyzing Semantic Change through Lexical Replacements](https://doi.org/10.18653/v1/2024.acl-long.246) |  | 0 | Modern language models are capable of contextualizing words based on their surrounding context. However, this capability is often compromised due to semantic change that leads to words being used in new, unexpected contexts not encountered during pre-training. In this paper, we model semantic change by studying the effect of unexpected contexts introduced by lexical replacements. We propose a replacement schema where a target word is substituted with lexical replacements of varying relatedness,... | Francesco Periti, Pierluigi Cassotti, Haim Dubossarsky, Nina Tahmasebi |  |
| 366 |  |  [Exploiting Intrinsic Multilateral Logical Rules for Weakly Supervised Natural Language Video Localization](https://doi.org/10.18653/v1/2024.acl-long.247) |  | 0 | Weakly supervised natural language video localization (WS-NLVL) aims to retrieve the moment corresponding to a language query in a video with only video-language pairs utilized during training. Despite great success, existing WS-NLVL methods seldomly consider the complex temporal relations enclosing the language query (e.g., between the language query and sub-queries decomposed from it or its synonymous query), yielding illogical predictions. In this paper, we propose a novel plug-and-play... | Zhe Xu, Kun Wei, Xu Yang, Cheng Deng |  |
| 367 |  |  [Interpretability of Language Models via Task Spaces](https://doi.org/10.18653/v1/2024.acl-long.248) |  | 0 | The usual way to interpret language models (LMs) is to test their performance on different benchmarks and subsequently infer their internal processes.In this paper, we present an alternative approach, concentrating on the _quality_ of LM processing, with a focus on their language abilities.To this end, we construct ‘linguistic task spaces’ – representations of an LM’s language conceptualisation – that shed light on the connections LMs draw between language phenomena.Task spaces are based on the... | Lucas Weber, Jaap Jumelet, Elia Bruni, Dieuwke Hupkes |  |
| 368 |  |  [Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types](https://doi.org/10.18653/v1/2024.acl-long.249) |  | 0 | There is abundant evidence of the fact that the way words change their meaning can be classified in different types of change, highlighting the relationship between the old and new meanings (among which generalisation, specialisation and co-hyponymy transfer).In this paper, we present a way of detecting these types of change by constructing a model that leverages information both from synchronic lexical relations and definitions of word meanings. Specifically, we use synset definitions and... | Pierluigi Cassotti, Stefano De Pascale, Nina Tahmasebi |  |
| 369 |  |  [Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators](https://doi.org/10.18653/v1/2024.acl-long.250) |  | 0 | Large Language Models (LLMs) tend to be unreliable on fact-based answers.To address this problem, NLP researchers have proposed a range of techniques to estimate LLM’s confidence over facts. However, due to the lack of a systematic comparison, it is not clear how the different methods compare to one other.To fill this gap, we present a rigorous survey and empirical comparison of estimators of factual confidence.We define an experimental framework allowing for fair comparison, covering both... | Matéo Mahaut, Laura Aina, Paula Czarnowska, Momchil Hardalov, Thomas Müller, Lluís Màrquez |  |
| 370 |  |  [StepCoder: Improving Code Generation with Reinforcement Learning from Compiler Feedback](https://doi.org/10.18653/v1/2024.acl-long.251) |  | 0 | The advancement of large language models (LLMs) has significantly propelled the field of code generation. Previous work integrated reinforcement learning (RL) with compiler feedback for exploring the output space of LLMs to enhance code generation quality. However, the lengthy code generated by LLMs in response to complex human requirements makes RL exploration a challenge. Also, since the unit tests may not cover the complicated code, optimizing LLMs by using these unexecuted code snippets is... | Shihan Dou, Yan Liu, Haoxiang Jia, Enyu Zhou, Limao Xiong, Junjie Shan, Caishuang Huang, Xiao Wang, Xiaoran Fan, Zhiheng Xi, Yuhao Zhou, Tao Ji, Rui Zheng, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 371 |  |  [One-Shot Learning as Instruction Data Prospector for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.252) |  | 0 | Contemporary practices in instruction tuning often hinge on enlarging data scaling without a clear strategy for ensuring data quality, inadvertently introducing noise that may compromise model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that leverages one-shot learning to discern and select high-quality instruction data from extensive datasets. Nuggets assesses the potential of individual instruction examples to act as effective one-shot... | Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, LingHao Chen, Junhao Liu, Tongliang Liu, Fei Huang, Yongbin Li |  |
| 372 |  |  [Navigating the OverKill in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.253) |  | 0 | Large language models are meticulously aligned to be both helpful and harmless. However, recent research points to a potential overkill which means models may refuse to answer benign queries. In this paper, we investigate the factors for overkill by exploring how models handle and determine the safety of queries. Our findings reveal the presence of shortcuts within models, leading to excessive attention to harmful words like ‘kill’ and prompts emphasizing safety will exacerbate overkill. Based... | Chenyu Shi, Xiao Wang, Qiming Ge, Songyang Gao, Xianjun Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Xun Zhao, Dahua Lin |  |
| 373 |  |  [A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains](https://doi.org/10.18653/v1/2024.acl-long.254) |  | 0 | Prompting language models to provide step-by-step answers (e.g., “Chain-of-Thought”) is the prominent approach for complex reasoning tasks, where more accurate reasoning chains typically improve downstream task performance. Recent literature discusses automatic methods to verify reasoning to evaluate and improve their correctness. However, no fine-grained step-level datasets are available to enable thorough evaluation of such verification methods, hindering progress in this direction. We... | Alon Jacovi, Yonatan Bitton, Bernd Bohnet, Jonathan Herzig, Or Honovich, Michael Tseng, Michael Collins, Roee Aharoni, Mor Geva |  |
| 374 |  |  [Re3: A Holistic Framework and Dataset for Modeling Collaborative Document Revision](https://doi.org/10.18653/v1/2024.acl-long.255) |  | 0 | Collaborative review and revision of textual documents is the core of knowledge work and a promising target for empirical analysis and NLP assistance. Yet, a holistic framework that would allow modeling complex relationships between document revisions, reviews and author responses is lacking. To address this gap, we introduce Re3, a framework for joint analysis of collaborative document revision. We instantiate this framework in the scholarly domain, and present Re3-Sci, a large corpus of... | Qian Ruan, Ilia Kuznetsov, Iryna Gurevych |  |
| 375 |  |  [NextLevelBERT: Masked Language Modeling with Higher-Level Representations for Long Documents](https://doi.org/10.18653/v1/2024.acl-long.256) |  | 0 | While (large) language models have significantly improved over the last years, they still struggle to sensibly process long sequences found, e.g., in books, due to the quadratic scaling of the underlying attention mechanism. To address this, we propose NextLevelBERT, a Masked Language Model operating not on tokens, but on higher-level semantic representations in the form of text embeddings. We pretrain NextLevelBERT to predict the vector representation of entire masked text chunks and evaluate... | Tamara Czinczoll, Christoph Hönes, Maximilian Schall, Gerard de Melo |  |
| 376 |  |  [FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.257) |  | 0 | The ability to follow instructions is crucial for Large Language Models (LLMs) to handle various real-world applications. Existing benchmarks primarily focus on evaluating pure response quality, rather than assessing whether the response follows constraints stated in the instruction. To fill this research gap, in this paper, we propose FollowBench, a Multi-level Fine-grained Constraints Following Benchmark for LLMs. FollowBench comprehensively includes five different types (i.e., Content,... | Yuxin Jiang, Yufei Wang, Xingshan Zeng, Wanjun Zhong, Liangyou Li, Fei Mi, Lifeng Shang, Xin Jiang, Qun Liu, Wei Wang |  |
| 377 |  |  [Learning to Edit: Aligning LLMs with Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.258) |  | 0 | Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated knowledge, impeding LLMs from effectively combining the new knowledge with their inherent knowledge when answering questions. To this end, we propose a Learning to Edit (LTE) framework, focusing on teaching... | Yuxin Jiang, Yufei Wang, Chuhan Wu, Wanjun Zhong, Xingshan Zeng, Jiahui Gao, Liangyou Li, Xin Jiang, Lifeng Shang, Ruiming Tang, Qun Liu, Wei Wang |  |
| 378 |  |  [DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.259) |  | 0 | Code Large Language Models (Code LLMs) have demonstrated outstanding performance in code-related tasks. Various instruction finetuning approaches have been proposed to boost the code generation performance of pre-trained Code LLMs. In this paper, we introduce a diverse instruction model DolphCoder with self-evaluating for code generation. It learns diverse instruction targets and combines a code evaluation objective to enhance its code generation ability. Our model achieves superior performance... | Yejie Wang, Keqing He, Guanting Dong, Pei Wang, Weihao Zeng, Muxi Diao, Weiran Xu, Jingang Wang, Mengdi Zhang, Xunliang Cai |  |
| 379 |  |  [When Only Time Will Tell: Interpreting How Transformers Process Local Ambiguities Through the Lens of Restart-Incrementality](https://doi.org/10.18653/v1/2024.acl-long.260) |  | 0 | Incremental models that process sentences one token at a time will sometimes encounter points where more than one interpretation is possible. Causal models are forced to output one interpretation and continue, whereas models that can revise may edit their previous output as the ambiguity is resolved. In this work, we look at how restart-incremental Transformers build and update internal states, in an effort to shed light on what processes cause revisions not viable in autoregressive models. We... | Brielen Madureira, Patrick Kahardipraja, David Schlangen |  |
| 380 |  |  [SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.261) |  | 0 | Spatial reasoning is a crucial component of both biological and artificial intelligence. In this work, we present a comprehensive study of the capability of current state-of-the-art large language models (LLMs) on spatial reasoning. To support our study, we created and contribute a novel Spatial Reasoning Characterization (SpaRC) framework and Spatial Reasoning Paths (SpaRP) datasets, to enable an in-depth understanding of the spatial relations and compositions as well as the usefulness of... | Md Imbesat Hassan Rizvi, Xiaodan Zhu, Iryna Gurevych |  |
| 381 |  |  [Planning Like Human: A Dual-process Framework for Dialogue Planning](https://doi.org/10.18653/v1/2024.acl-long.262) |  | 0 | In proactive dialogue, the challenge lies not just in generating responses but in steering conversations toward predetermined goals, a task where Large Language Models (LLMs) typically struggle due to their reactive nature. Traditional approaches to enhance dialogue planning in LLMs, ranging from elaborate prompt engineering to the integration of policy networks, either face efficiency issues or deliver suboptimal performance. Inspired by the dual-process theory in psychology, which identifies... | Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Ming Liu, Zerui Chen, Bing Qin |  |
| 382 |  |  [Spectral Filters, Dark Signals, and Attention Sinks](https://doi.org/10.18653/v1/2024.acl-long.263) |  | 0 | Projecting intermediate representations onto the vocabulary is an increasingly popular interpretation tool for transformer-based LLMs, also known as the logit lens (Nostalgebraist). We propose a quantitative extension to this approach and define spectral filters on intermediate representations based on partitioning the singular vectors of the vocabulary embedding and unembedding matrices into bands. We find that the signals exchanged in the tail end of the spectrum, i.e. corresponding to the... | Nicola Cancedda |  |
| 383 |  |  [DiffuCOMET: Contextual Commonsense Knowledge Diffusion](https://doi.org/10.18653/v1/2024.acl-long.264) |  | 0 | Inferring contextually-relevant and diverse commonsense to understand narratives remains challenging for knowledge models. In this work, we develop a series of knowledge models, DiffuCOMET, that leverage diffusion to learn to reconstruct the implicit semantic connections between narrative contexts and relevant commonsense knowledge. Across multiple diffusion steps, our method progressively refines a representation of commonsense facts that is anchored to a narrative, producing... | Silin Gao, Mete Ismayilzada, Mengjie Zhao, Hiromi Wakaki, Yuki Mitsufuji, Antoine Bosselut |  |
| 384 |  |  [Systematic Task Exploration with LLMs: A Study in Citation Text Generation](https://doi.org/10.18653/v1/2024.acl-long.265) |  | 0 | Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language generation (NLG) tasks. Yet, this flexibility brings new challenges, as it introduces new degrees of freedom in formulating the task inputs and instructions and in evaluating model performance. To facilitate the exploration of creative NLG tasks, we propose a three-component research framework that consists of systematic input manipulation, reference data, and output... | Furkan Sahinuç, Ilia Kuznetsov, Yufang Hou, Iryna Gurevych |  |
| 385 |  |  [Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition](https://doi.org/10.18653/v1/2024.acl-long.266) |  | 0 | Recent work on dialogue-based collaborative plan acquisition (CPA) has suggested that Theory of Mind (ToM) modelling can improve missing knowledge prediction in settings with asymmetric skill-sets and knowledge. Although ToM was claimed to be important for effective collaboration, its real impact on this novel task remains under-explored. By representing plans as graphs and by exploiting task-specific constraints we show that, as performance on CPA nearly doubles when predicting one’s own... | Matteo Bortoletto, Constantin Ruhdorfer, Adnen Abdessaied, Lei Shi, Andreas Bulling |  |
| 386 |  |  [Temporal Knowledge Question Answering via Abstract Reasoning Induction](https://doi.org/10.18653/v1/2024.acl-long.267) |  | 0 | In this study, we address the challenge of enhancing temporal knowledge reasoning in Large Language Models (LLMs). LLMs often struggle with this task, leading to the generation of inaccurate or misleading responses. This issue mainly arises from their limited ability to handle evolving factual knowledge and complex temporal logic. To overcome these limitations, we propose Abstract Reasoning Induction (ARI) framework, which divides temporal reasoning into two distinct phases: Knowledge agnostic... | Ziyang Chen, Dongfang Li, Xiang Zhao, Baotian Hu, Min Zhang |  |
| 387 |  |  [Who Wrote this Code? Watermarking for Code Generation](https://doi.org/10.18653/v1/2024.acl-long.268) |  | 0 | Since the remarkable generation performance of large language models raised ethical and legal concerns, approaches to detect machine-generated text by embedding watermarks are being developed.However, we discover that the existing works fail to function appropriately in code generation tasks due to the task’s nature of having low entropy.Extending a logit-modifying watermark method, we propose Selective WatErmarking via Entropy Thresholding (SWEET), which enhances detection ability and... | Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, Gunhee Kim |  |
| 388 |  |  [MapCoder: Multi-Agent Code Generation for Competitive Problem Solving](https://doi.org/10.18653/v1/2024.acl-long.269) |  | 0 | Code synthesis, which requires a deep understanding of complex natural language (NL) problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. Thus, while large language models (LLMs) demonstrate impressive proficiency in natural language processing (NLP), their performance in code generation tasks remains limited. In this paper, we introduce a new approach to code... | Md. Ashraful Islam, Mohammed Eunus Ali, Md. Rizwan Parvez |  |
| 389 |  |  [RelayAttention for Efficient Large Language Model Serving with Long System Prompts](https://doi.org/10.18653/v1/2024.acl-long.270) |  | 0 | A practical large language model (LLM) service may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across requests. However, the long system prompt causes throughput/latency bottlenecks as the cost of generating the next token grows w.r.t the sequence length. This paper aims to improve the efficiency of LLM services that involve long system prompts. Our key observation is that handling these system prompts requires... | Lei Zhu, Xinjiang Wang, Wayne Zhang, Rynson W. H. Lau |  |
| 390 |  |  [Boosting Language Models Reasoning with Chain-of-Knowledge Prompting](https://doi.org/10.18653/v1/2024.acl-long.271) |  | 0 | Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like “Let’s think step by step” or multiple in-context exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However, the generated rationales often come with hallucinations, making unfactual and unfaithful reasoning chains. To mitigate this brittleness, we propose a novel Chain-of-Knowledge (CoK)... | Jianing Wang, Qiushi Sun, Xiang Li, Ming Gao |  |
| 391 |  |  [Open Grounded Planning: Challenges and Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.272) |  | 0 | The emergence of large language models (LLMs) has increasingly drawn attention to the use of LLMs for human-like planning. Existing work on LLM-based planning either focuses on leveraging the inherent language generation capabilities of LLMs to produce free-style plans, or employs reinforcement learning approaches to learn decision-making for a limited set of actions within restricted environments. However, both approaches exhibit significant discrepancies from the open and executable... | Shiguang Guo, Ziliang Deng, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun |  |
| 392 |  |  [LLM Knows Body Language, Too: Translating Speech Voices into Human Gestures](https://doi.org/10.18653/v1/2024.acl-long.273) |  | 0 | In response to the escalating demand for digital human representations, progress has been made in the generation of realistic human gestures from given speeches. Despite the remarkable achievements of recent research, the generation process frequently includes unintended, meaningless, or non-realistic gestures. To address this challenge, we propose a gesture translation paradigm, GesTran, which leverages large language models (LLMs) to deepen the understanding of the connection between speech... | Chenghao Xu, Guangtao Lyu, Jiexi Yan, Muli Yang, Cheng Deng |  |
| 393 |  |  [QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction](https://doi.org/10.18653/v1/2024.acl-long.274) |  | 0 | Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which solves a question step-by-step and performs stepwise self-correction. We introduce an environmental feedback-based self-correction method called ERASER. Unlike traditional approaches, ERASER leverages... | Xiang Huang, Sitao Cheng, Shanshan Huang, Jiayu Shen, Yong Xu, Chaoyun Zhang, Yuzhong Qu |  |
| 394 |  |  [PITA: Prompting Task Interaction for Argumentation Mining](https://doi.org/10.18653/v1/2024.acl-long.275) |  | 0 | Argumentation mining (AM) aims to detect the arguments and their inherent relations from argumentative textual compositions. Generally, AM comprises three key challenging subtasks, including argument component type classification (ACTC), argumentative relation identification (ARI), and argumentative relation type classification (ARTC). Prior methods are afflicted by a sequential feature decoding paradigm, wherein they initially address the features of argumentation components (ACs) for the task... | Yang Sun, Muyi Wang, Jianzhu Bao, Bin Liang, Xiaoyan Zhao, Caihua Yang, Min Yang, Ruifeng Xu |  |
| 395 |  |  [Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.276) |  | 0 | Large Language Models (LLMs) show promising results in language generation and instruction following but frequently “hallucinate”, making their outputs less reliable. Despite Uncertainty Quantification’s (UQ) potential solutions, implementing it accurately within LLMs is challenging. Our research introduces a simple heuristic: not all tokens in auto-regressive LLM text equally represent the underlying meaning, as “linguistic redundancy” often allows a few keywords to convey the essence of long... | Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, Kaidi Xu |  |
| 396 |  |  [Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations](https://doi.org/10.18653/v1/2024.acl-long.277) |  | 0 | Vision-and-language (VL) models with separate encoders for each modality (e.g., CLIP) have become the go-to models for zero-shot image classification and image-text retrieval. They are, however, mostly evaluated in English as multilingual benchmarks are limited in availability. We introduce Babel-ImageNet, a massively multilingual benchmark that offers (partial) translations of ImageNet labels to 100 languages, built without machine translation or manual annotation. We instead automatically... | Gregor Geigle, Radu Timofte, Goran Glavas |  |
| 397 |  |  [Estimating Agreement by Chance for Sequence Annotation](https://doi.org/10.18653/v1/2024.acl-long.278) |  | 0 | In the field of natural language processing, correction of performance assessment for chance agreement plays a crucial role in evaluating the reliability of annotations. However, there is a notable dearth of research focusing on chance correction for assessing the reliability of sequence annotation tasks, despite their widespread prevalence in the field. To address this gap, this paper introduces a novel model for generating random annotations, which serves as the foundation for estimating... | Diya Li, Carolyn P. Rosé, Ao Yuan, Chunxiao Zhou |  |
| 398 |  |  [Are Emergent Abilities in Large Language Models just In-Context Learning?](https://doi.org/10.18653/v1/2024.acl-long.279) |  | 0 | Large language models, comprising billions of parameters and pre-trained on extensive web-scale corpora, have been claimed to acquire certain capabilities without having been specifically trained on them. These capabilities, referred to as “emergent abilities,” have been a driving force in discussions regarding the potentials and risks of language models. A key challenge in evaluating emergent abilities is that they are confounded by model competencies that arise through alternative prompting... | Sheng Lu, Irina Bigoulaeva, Rachneet Sachdeva, Harish Tayyar Madabushi, Iryna Gurevych |  |
| 399 |  |  [WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.280) |  | 0 | Recent work demonstrates that, after instruction tuning, Code Large Language Models (Code LLMs) can obtain impressive capabilities to address a wide range of code-related tasks. However, current instruction tuning methods for Code LLMs mainly focus on the traditional code generation task, resulting in poor performance in complex multi-task scenarios. In this paper, we concentrate on multiple code-related tasks and present WaveCoder, a series of Code LLMs trained with Widespread And Versatile... | Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, Yishujie Zhao, Wenxiang Hu, Qiufeng Yin |  |
| 400 |  |  [Eliciting Better Multilingual Structured Reasoning from LLMs through Code](https://doi.org/10.18653/v1/2024.acl-long.281) |  | 0 | The development of large language models (LLM) has shown progress on reasoning, though studies have largely considered either English or simple reasoning tasks. To address this, we introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across six languages. xSTREET exposes a gap in base LLM performance between English and non-English reasoning tasks.We then propose two methods to remedy this gap, building on the insight that LLMs trained on... | Bryan Li, Tamer Alkhouli, Daniele Bonadiman, Nikolaos Pappas, Saab Mansour |  |
| 401 |  |  [OLIVE: Object Level In-Context Visual Embeddings](https://doi.org/10.18653/v1/2024.acl-long.282) |  | 0 | Recent generalist vision-language models (VLMs) have demonstrated impressive reasoning capabilities across diverse multimodal tasks. However, these models still struggle with fine-grained object-level understanding and grounding. In terms of modeling, existing VLMs implicitly align text tokens with image patch tokens, which is ineffective for embedding alignment at the same granularity and inevitably introduces noisy spurious background features. Additionally, these models struggle when... | Timothy Ossowski, Junjie Hu |  |
| 402 |  |  [Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness](https://doi.org/10.18653/v1/2024.acl-long.283) |  | 0 | We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training data remains unknown. By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that cautions when not to... | Jiuhai Chen, Jonas Mueller |  |
| 403 |  |  [Marathon: A Race Through the Realm of Long Context with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.284) |  | 0 | With the advancement of large language models (LLMs) and the expansion of their context windows, existing long-context benchmarks fall short in effectively evaluating the models’ comprehension and reasoning abilities in extended texts. Moreover, conventional benchmarks relying on F1 metrics often inaccurately score responses: they may undervalue correct answers that differ from the reference responses and overvalue incorrect ones that resemble the reference texts. In response to these... | Lei Zhang, Yunshui Li, Ziqiang Liu, Jiaxi Yang, Junhao Liu, Longze Chen, Run Luo, Min Yang |  |
| 404 |  |  [Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph](https://doi.org/10.18653/v1/2024.acl-long.285) |  | 0 | Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs). However, it can fall short in specific scenarios where simple customized methods excel. In this paper, we delve into the patent approval prediction task and unveil that simple domain-specific graph methods outperform enlarging the model, using the intrinsic dependencies within the patent data. Specifically, we first extend the embedding-based state-of-the-art (SOTA) by... | Xiaochen Gao, Feng Yao, Kewen Zhao, Beilei He, Animesh Kumar, Vish Krishnan, Jingbo Shang |  |
| 405 |  |  [PCAD: Towards ASR-Robust Spoken Language Understanding via Prototype Calibration and Asymmetric Decoupling](https://doi.org/10.18653/v1/2024.acl-long.286) |  | 0 | Spoken language understanding (SLU) inevitably suffers from error propagation from automatic speech recognition (ASR) in actual scenarios. Some recent works attempt to alleviate this issue through contrastive learning. However, they (1) sample negative pairs incorrectly in pre-training; (2) only focus on implicit metric learning while neglecting explicit erroneous predictions; (3) treat manual and ASR transcripts indiscriminately. In this paper, we propose a novel framework termed PCAD, which... | Xianwei Zhuang, Xuxin Cheng, Liming Liang, Yuxin Xie, Zhichang Wang, Zhiqi Huang, Yuexian Zou |  |
| 406 |  |  [Rethinking the Multimodal Correlation of Multimodal Sequential Learning via Generalizable Attentional Results Alignment](https://doi.org/10.18653/v1/2024.acl-long.287) |  | 0 | Transformer-based methods have gone mainstream in multimodal sequential learning. The intra and inter modality interactions are captured by the query-key associations of multi-head attention. In this way, the calculated multimodal contexts (attentional results) are expected to be relevant to the query modality. However, in existing literature, the alignment degree between different calculated attentional results of the same query are under-explored. Based on this concern, we propose a new... | Tao Jin, Wang Lin, Ye Wang, Linjun Li, Xize Cheng, Zhou Zhao |  |
| 407 |  |  [UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation](https://doi.org/10.18653/v1/2024.acl-long.288) |  | 0 | Large language models (LLMs) produce hallucinated text, compromising their practical utility in professional contexts. To assess the reliability of LLMs, numerous initiatives have developed benchmark evaluations for hallucination phenomena. However, they often employ constrained generation techniques to produce the evaluation dataset due to cost and time limitations. For instance, this may involve employing directed hallucination induction or deliberately modifying authentic text to generate... | Xun Liang, Shichao Song, Simin Niu, Zhiyu Li, Feiyu Xiong, Bo Tang, Yezhaohui Wang, Dawei He, Cheng Peng, Zhonghao Wang, Haiying Deng |  |
| 408 |  |  [PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers](https://doi.org/10.18653/v1/2024.acl-long.289) |  | 0 | Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We present an extensive training and evaluation framework, M2KR, for KB-VQA. M2KR contains a collection of vision and language tasks which we have incorporated into a single suite of benchmark tasks for... | Weizhe Lin, Jingbiao Mei, Jinghong Chen, Bill Byrne |  |
| 409 |  |  [Triple-Encoders: Representations That Fire Together, Wire Together](https://doi.org/10.18653/v1/2024.acl-long.290) |  | 0 | Search-based dialog models typically re-encode the dialog history at every turn, incurring high cost.Curved Contrastive Learning, a representation learning method that encodes relative distances between utterances into the embedding space via a bi-encoder, has recently shown promising results for dialog modeling at far superior efficiency.While high efficiency is achieved through independently encoding utterances, this ignores the importance of contextualization. To overcome this issue, this... | JustusJonas Erker, Florian Mai, Nils Reimers, Gerasimos Spanakis, Iryna Gurevych |  |
| 410 |  |  [Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.291) |  | 0 | Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. We propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Our approach achieves... | Jingbiao Mei, Jinghong Chen, Weizhe Lin, Bill Byrne, Marcus Tomalin |  |
| 411 |  |  [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://doi.org/10.18653/v1/2024.acl-long.292) |  | 0 | Large Language Models (LLMs) exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers necessitate manually crafted prompts to inform task rules and regulate LLM behaviors, inherently incapacitating to address complex dynamic scenarios e.g., large interactive games. In light of this, we... | Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, Weiming Lu |  |
| 412 |  |  [Your Transformer is Secretly Linear](https://doi.org/10.18653/v1/2024.acl-long.293) |  | 0 | This paper reveals a novel linear characteristic exclusive to transformer decoders, including models like GPT, LLaMA, OPT, BLOOM and others. We analyze embedding transformations between sequential layers, uncovering an almost perfect linear relationship (Procrustes similarity score of 0.99). However, linearity decreases when the residual component is removed, due to a consistently low transformer layer output norm. Our experiments show that pruning or linearly approximating some of the layers... | Anton Razzhigaev, Matvey Mikhalchuk, Elizaveta Goncharova, Nikolai Gerasimenko, Ivan V. Oseledets, Denis Dimitrov, Andrey Kuznetsov |  |
| 413 |  |  [Noise Correction on Subjective Datasets](https://doi.org/10.18653/v1/2024.acl-long.294) |  | 0 | Incorporating every annotator’s perspective is crucial for unbiased data modeling. Annotator fatigue and changing opinions over time can distort dataset annotations. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, this method provides a controllable way to... | Uthman Jinadu, Yi Ding |  |
| 414 |  |  [Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers](https://doi.org/10.18653/v1/2024.acl-long.295) |  | 0 | Recommender systems are widely used to suggest engaging content, and Large Language Models (LLMs) have given rise to generative recommenders. Such systems can directly generate items, including for open-set tasks like question suggestion. While the world knowledge of LLMs enables good recommendations, improving the generated content through user feedback is challenging as continuously fine-tuning LLMs is prohibitively expensive. We present a training-free approach for optimizing generative... | Lütfi Kerem Senel, Besnik Fetahu, Davis Yoshida, Zhiyu Chen, Giuseppe Castellucci, Nikhita Vedula, Jason Ingyu Choi, Shervin Malmasi |  |
| 415 |  |  [Instruction-tuned Language Models are Better Knowledge Learners](https://doi.org/10.18653/v1/2024.acl-long.296) |  | 0 | In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs. However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized. We found that QA... | Zhengbao Jiang, Zhiqing Sun, Weijia Shi, Pedro Rodríguez, Chunting Zhou, Graham Neubig, Xi Victoria Lin, Wentau Yih, Srini Iyer |  |
| 416 |  |  [What Do Language Models Hear? Probing for Auditory Representations in Language Models](https://doi.org/10.18653/v1/2024.acl-long.297) |  | 0 | This work explores whether language models encode meaningfully grounded representations of sounds of objects. We learn a linear probe that retrieves the correct text representation of an object given a snippet of audio related to that object, where the sound representation is given by a pretrained audio model. This probe is trained via a contrastive loss that pushes the language representations and sound representations of an object to be close to one another. After training, the probe is... | Jerry Ngo, Yoon Kim |  |
| 417 |  |  [Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs](https://doi.org/10.18653/v1/2024.acl-long.298) |  | 0 | With the advent of large language models (LLM), the line between human-crafted and machine-generated texts has become increasingly blurred. This paper delves into the inquiry of identifying discernible and unique linguistic properties in texts that were written by humans, particularly uncovering the underlying discourse structures of texts beyond their surface structures. Introducing a novel methodology, we leverage hierarchical parse trees and recursive hypergraphs to unveil distinctive... | Zae Myung Kim, Kwang Hee Lee, Preston Zhu, Vipul Raheja, Dongyeop Kang |  |
| 418 |  |  [Jailbreak Open-Sourced Large Language Models via Enforced Decoding](https://doi.org/10.18653/v1/2024.acl-long.299) |  | 0 | Large Language Models (LLMs) have achieved unprecedented performance in Natural Language Generation (NLG) tasks. However, many existing studies have shown that they could be misused to generate undesired content. In response, before releasing LLMs for public access, model developers usually align those language models through Supervised Fine-Tuning (SFT) or Reinforcement Learning with Human Feedback (RLHF). Consequently, those aligned large language models refuse to generate undesired content... | Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, Bochuan Cao, Lu Lin, Jinyuan Jia, Jinghui Chen, Dinghao Wu |  |
| 419 |  |  [NICE: To Optimize In-Context Examples or Not?](https://doi.org/10.18653/v1/2024.acl-long.300) |  | 0 | Recent work shows that in-context learning and optimization of in-context examples (ICE) can significantly improve the accuracy of large language models (LLMs) on a wide range of tasks, leading to an apparent consensus that ICE optimization is crucial for better performance. However, most of these studies assume a fixed or no instruction provided in the prompt. We challenge this consensus by investigating the necessity of optimizing ICE when task-specific instructions are provided and find that... | Pragya Srivastava, Satvik Golechha, Amit Deshpande, Amit Sharma |  |
| 420 |  |  [CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation](https://doi.org/10.18653/v1/2024.acl-long.301) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most benchmarks are insufficient as they focus on a narrow range of popular programming languages and specific tasks, whereas real-world software development scenarios show a critical need to implement systems... | Weixiang Yan, Haitian Liu, Yunkun Wang, Yunzhe Li, Qian Chen, Wen Wang, Tingyu Lin, Weishan Zhao, Li Zhu, Hari Sundaram, Shuiguang Deng |  |
| 421 |  |  [Digital Socrates: Evaluating LLMs through Explanation Critiques](https://doi.org/10.18653/v1/2024.acl-long.302) |  | 0 | While LLMs can provide reasoned explanations along with their answers, the nature and quality of those explanations are still poorly understood. In response, our goal is to define a detailed way of characterizing the explanation capabilities of modern models and to create a nuanced, interpretable explanation evaluation tool that can generate such characterizations automatically, without relying on expensive API calls or human annotations. Our approach is to (a) define the new task of... | Yuling Gu, Oyvind Tafjord, Peter Clark |  |
| 422 |  |  [SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://doi.org/10.18653/v1/2024.acl-long.303) |  | 0 | As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, which aim to provoke unintended and unsafe behaviors from LLMs, remain a significant LLM safety threat. We analyze tokens, which are the smallest unit of text that can be processed by LLMs and make the following observations: (1) probabilities of... | Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill Yuchen Lin, Radha Poovendran |  |
| 423 |  |  [Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?](https://doi.org/10.18653/v1/2024.acl-long.304) |  | 0 | Large language models (LLMs) are typically prompted to follow a single instruction per inference call. In this work, we analyze whether LLMs also hold the capability to handle multiple instructions simultaneously, denoted as Multi-Task Inference. For this purpose, we introduce the MTI Bench (Multi-Task Inference Benchmark), a comprehensive evaluation benchmark encompassing 5,000 instances across 25 tasks. Each task in the MTI Bench involves 2 to 3 sub-tasks. As expected, we first demonstrate... | Guijin Son, Sangwon Baek, Sangdae Nam, Ilgyun Jeong, Seungone Kim |  |
| 424 |  |  [Experiential Co-Learning of Software-Developing Agents](https://doi.org/10.18653/v1/2024.acl-long.305) |  | 0 | Recent advancements in large language models (LLMs) have brought significant changes to various domains, especially through LLM-driven autonomous agents. A representative scenario is in software development, where LLM agents demonstrate efficient collaboration, task division, and assurance of software quality, markedly reducing the need for manual involvement. However, these agents frequently perform a variety of tasks independently, without benefiting from past experiences, which leads to... | Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Zihao Xie, Yifei Wang, Weize Chen, Cheng Yang, Xin Cong, Xiaoyin Che, Zhiyuan Liu, Maosong Sun |  |
| 425 |  |  [Learning Geometry-Aware Representations for New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.306) |  | 0 | New intent discovery (NID) is an important problem for deploying practical dialogue systems, which trains intent classifiers on a semi-supervised corpus where unlabeled user utterances contain both known and novel intents. Most existing NID algorithms place hope on the sample similarity to cluster unlabeled corpus to known or new samples. Lacking supervision on new intents, we experimentally find the intent classifier fails to fully distinguish new intents since they tend to assemble into... | Kai Tang, Junbo Zhao, Xiao Ding, Runze Wu, Lei Feng, Gang Chen, Haobo Wang |  |
| 426 |  |  [Speaker Verification in Agent-generated Conversations](https://doi.org/10.18653/v1/2024.acl-long.307) |  | 0 | The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks. However, the ability to personalize the generated utterances to speakers, whether conducted by human or LLM, has not been well studied. To bridge this gap, our study introduces a novel evaluation challenge:... | Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, EePeng Lim |  |
| 427 |  |  [Benchmarking Data Science Agents](https://doi.org/10.18653/v1/2024.acl-long.308) |  | 0 | In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools of data science, presenting significant challenges even for specialists. Large Language Models (LLMs) have emerged as promising aids as data science agents, assisting humans in data analysis and processing. Yet their practical efficacy remains constrained by the varied demands of real-world applications and complicated analytical process. In this paper, we introduce DSEval – a... | Yuge Zhang, Qiyang Jiang, Xingyu Han, Nan Chen, Yuqing Yang, Kan Ren |  |
| 428 |  |  [Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.309) |  | 0 | Large language models (LLMs) demonstrate remarkable multilingual capabilities without being pre-trained on specially curated multilingual parallel corpora.It remains a challenging problem to explain the underlying mechanisms by which LLMs process multilingual texts.In this paper, we delve into the composition of Transformer architectures in LLMs to pinpoint language-specific regions.Specially, we propose a novel detection method, language activation probability entropy (LAPE), to identify... | Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, JiRong Wen |  |
| 429 |  |  [Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.310) |  | 0 | Recent advancements in Large Language Models (LLMs) have showcased their remarkable capabilities in text understanding and generation. However, even stronger LLMs are susceptible to acquiring erroneous or obsolete information from the training corpus. Direct secondary fine-tuning with data containing new knowledge may be ineffective in updating knowledge due to the conflict between old and new knowledge. In this paper, we propose a new paradigm for fine-tuning called F-Learning (Forgetting... | Shiwen Ni, Dingwei Chen, Chengming Li, Xiping Hu, Ruifeng Xu, Min Yang |  |
| 430 |  |  [A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques](https://doi.org/10.18653/v1/2024.acl-long.311) |  | 0 | Large language models are first pre-trained on trillions of tokens and then instruction-tuned or aligned to specific preferences. While pre-training remains out of reach for most researchers due to the compute required, fine-tuning has become affordable thanks to parameter-efficient methods such as LoRA and QLoRA. Alignment is known to be sensitive to the many factors involved, including the quantity and quality of data, the alignment method, and the adapter rank. However, there has not yet... | Megh Thakkar, Quentin Fournier, Matthew Riemer, PinYu Chen, Amal Zouaq, Payel Das, Sarath Chandar |  |
| 431 |  |  [Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation](https://doi.org/10.18653/v1/2024.acl-long.312) |  | 0 | Zero-shot dialogue state tracking (DST) seeks to enable dialogue systems to transition to unfamiliar domains without manual annotation or extensive retraining. Prior research has approached this objective by embedding prompts into language models (LMs). Common methodologies include integrating prompts at the input layer or introducing learnable variables at each transformer layer. Nonetheless, each strategy exhibits inherent limitations. Prompts integrated at the input layer risk... | Xiang Luo, Zhiwen Tang, Jin Wang, Xuejie Zhang |  |
| 432 |  |  [PRP-Graph: Pairwise Ranking Prompting to LLMs with Graph Aggregation for Effective Text Re-ranking](https://doi.org/10.18653/v1/2024.acl-long.313) |  | 0 | Pairwise Ranking Prompting (PRP) demonstrates impressive effectiveness in zero-shot document re-ranking tasks with large language models (LLMs). However, in the existing methods, PRP only outputs the same label for the comparison results of different confidence intervals without considering the uncertainty of pairwise comparison, which implies an underutilization of the generation probability information of LLMs. To bridge this gap, we propose PRP-Graph, a novel pairwise re-ranking approach,... | Jian Luo, Xuanang Chen, Ben He, Le Sun |  |
| 433 |  |  [RepCodec: A Speech Representation Codec for Speech Tokenization](https://doi.org/10.18653/v1/2024.acl-long.314) |  | 0 | With recent rapid growth of large language models (LLMs), discrete speech tokenization has played an important role for injecting speech into LLMs. However, this discretization gives rise to a loss of information, consequently impairing overall performance. To improve the performance of these discrete speech tokens, we present RepCodec, a novel speech representation codec for semantic speech tokenization. In contrast to audio codecs which reconstruct the raw audio, RepCodec learns a vector... | Zhichao Huang, Chutong Meng, Tom Ko |  |
| 434 |  |  [GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick](https://doi.org/10.18653/v1/2024.acl-long.315) |  | 0 | Large language models (LLMs) excellently generate human-like text, but also raise concerns about misuse in fake news and academic dishonesty. Decoding-based watermark, particularly the watermark based on the GumbelMax trick (GM watermark), is a standout solution for safeguarding machine-generated texts due to its notable detectability. However, GM watermark encounters a major challenge with generation diversity, always yielding identical outputs for the same prompt, negatively impacting... | Jiayi Fu, Xuandong Zhao, Ruihan Yang, Yuansen Zhang, Jiangjie Chen, Yanghua Xiao |  |
| 435 |  |  [Event-Radar: Event-driven Multi-View Learning for Multimodal Fake News Detection](https://doi.org/10.18653/v1/2024.acl-long.316) |  | 0 | The swift detection of multimedia fake news has emerged as a crucial task in combating malicious propaganda and safeguarding the security of the online environment. While existing methods have achieved commendable results in modeling entity-level inconsistency, addressing event-level inconsistency following the inherent subject-predicate logic of news and robustly learning news representations from poor-quality news samples remain two challenges. In this paper, we propose an Event-diven fake... | Zihan Ma, Minnan Luo, Hao Guo, Zhi Zeng, Yiran Hao, Xiang Zhao |  |
| 436 |  |  [Fine-Grained Modeling of Narrative Context: A Coherence Perspective via Retrospective Questions](https://doi.org/10.18653/v1/2024.acl-long.317) |  | 0 | This work introduces an original and practical paradigm for narrative comprehension, stemming from the characteristics that individual passages within narratives tend to be more cohesively related than isolated.Complementary to the common end-to-end paradigm, we propose a fine-grained modeling of narrative context, by formulating a graph dubbed NarCo, which explicitly depicts task-agnostic coherence dependencies that are ready to be consumed by various downstream tasks. In particular, edges in... | Liyan Xu, Jiangnan Li, Mo Yu, Jie Zhou |  |
| 437 |  |  [Stealthy Attack on Large Language Model based Recommendation](https://doi.org/10.18653/v1/2024.acl-long.318) |  | 0 | Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item’s exposure by... | Jinghao Zhang, Yuting Liu, Qiang Liu, Shu Wu, Guibing Guo, Liang Wang |  |
| 438 |  |  [Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.319) |  | 0 | The evaluation of summary quality encompasses diverse dimensions such as consistency, coherence, relevance, and fluency. However, existing summarization methods often target a specific dimension, facing challenges in generating well-balanced summaries across multiple dimensions. In this paper, we propose multi-objective reinforcement learning tailored to generate balanced summaries across all four dimensions. We introduce two multi-dimensional optimization (MDO) strategies for adaptive... | Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Lee, Jungseul Ok |  |
| 439 |  |  [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://doi.org/10.18653/v1/2024.acl-long.320) |  | 0 | In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models insuch domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain... | Changyu Chen, Xiting Wang, TingEn Lin, Ang Lv, Yuchuan Wu, Xin Gao, JiRong Wen, Rui Yan, Yongbin Li |  |
| 440 |  |  [SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.321) |  | 0 | Elucidating the reasoning process with structured explanations from question to answer is crucial, as it significantly enhances the interpretability, traceability, and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricately structured reasoning, which poses great challenges. Most existing methods focus on single-step reasoning through supervised learning, ignoring logical dependencies between steps. Moreover, existing... | Guoxin Chen, Kexin Tang, Chao Yang, Fuying Ye, Yu Qiao, Yiming Qian |  |
| 441 |  |  [Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning](https://doi.org/10.18653/v1/2024.acl-long.322) |  | 0 | Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, as datasets in such environments often contain noisy labels that adversely affect performance, PEFT methods are inevitably exposed to noisy labels. Despite this challenge, the adaptability of PEFT to noisy environments remains underexplored. To bridge this gap, we investigate various PEFT methods under noisy labels. Interestingly, our findings reveal that... | Yeachan Kim, Junho Kim, SangKeun Lee |  |
| 442 |  |  [SparseFlow: Accelerating Transformers by Sparsifying Information Flows](https://doi.org/10.18653/v1/2024.acl-long.323) |  | 0 | Transformers have become the de-facto standard for natural language processing. However, dense information flows within transformers pose significant challenges for real-time and resource-constrained devices, as computational complexity grows quadratically with sequence length. To counteract such dense information flows, we propose SparseFlow, a novel efficient method designed to sparsify the dense pathways of token representations across all transformer blocks. To this end, SparseFlow... | Yeachan Kim, SangKeun Lee |  |
| 443 |  |  [ProtT3: Protein-to-Text Generation for Text-based Protein Understanding](https://doi.org/10.18653/v1/2024.acl-long.324) |  | 0 | Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models (PLMs) can understand and convert protein data into high-quality representations, but struggle to process texts. To address their limitations, we introduce ProtT3, a framework for Protein-to-Text... | Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, TatSeng Chua |  |
| 444 |  |  [KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.325) |  | 0 | Automatic evaluation methods for large language models (LLMs) are hindered by data contamination, leading to inflated assessments of their effectiveness. Existing strategies, which aim to detect contaminated texts, focus on quantifying contamination status instead of accurately gauging model performance. In this paper, we introduce KIEval, a Knowledge-grounded Interactive Evaluation framework, which incorporates an LLM-powered “interactor” role for the first time to accomplish a dynamic... | Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Wei Ye, Jindong Wang, Xing Xie, Yue Zhang, Shikun Zhang |  |
| 445 |  |  [EmoBench: Evaluating the Emotional Intelligence of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.326) |  | 0 | Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on emotion recognition, neglecting essential EI capabilities such as emotion management and thought facilitation through emotion understanding; second, they are primarily constructed from existing datasets,... | Sahand Sabour, Siyang Liu, Zheyuan Zhang, June M. Liu, Jinfeng Zhou, Alvionna S. Sunaryo, Tatia M. C. Lee, Rada Mihalcea, Minlie Huang |  |
| 446 |  |  [Are AI-Generated Text Detectors Robust to Adversarial Perturbations?](https://doi.org/10.18653/v1/2024.acl-long.327) |  | 0 | The widespread use of large language models (LLMs) has sparked concerns about the potential misuse of AI-generated text, as these models can produce content that closely resembles human-generated text. Current detectors for AI-generated text (AIGT) lack robustness against adversarial perturbations, with even minor changes in characters or words causing a reversal in distinguishing between human-created and AI-generated text. This paper investigates the robustness of existing AIGT detection... | Guanhua Huang, Yuchen Zhang, Zhe Li, Yongjian You, Mingze Wang, Zhouwang Yang |  |
| 447 |  |  [FinTextQA: A Dataset for Long-form Financial Question Answering](https://doi.org/10.18653/v1/2024.acl-long.328) |  | 0 | Accurate evaluation of financial question answering (QA) systems necessitates a comprehensive dataset encompassing diverse question types and contexts. However, current financial QA datasets lack scope diversity and question complexity. This work introduces FinTextQA, a novel dataset for long-form question answering (LFQA) in finance. FinTextQA comprises 1,262 high-quality, source-attributed QA pairs extracted and selected from finance textbooks and government agency websites.Moreover, we... | Jian Chen, Peilin Zhou, Yining Hua, Loh Xin, Kehui Chen, Ziyuan Li, Bing Zhu, Junwei Liang |  |
| 448 |  |  [On Measuring Faithfulness or Self-consistency of Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.329) |  | 0 | Large language models (LLMs) can explain their predictions through post-hoc or Chain-of-Thought (CoT) explanations. But an LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of post-hoc or CoT explanations. In this work we argue that these faithfulness tests do not measure faithfulness to the models’ inner workings – but rather their self-consistency at output level.Our... | Letitia Parcalabescu, Anette Frank |  |
| 449 |  |  [Learning or Self-aligning? Rethinking Instruction Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.330) |  | 0 | Instruction Fine-tuning (IFT) is a crucial phase in building large language models (LLMs). Previous works mainly focus on the IFT’s role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors.... | Mengjie Ren, Boxi Cao, Hongyu Lin, Cao Liu, Xianpei Han, Ke Zeng, Guanglu Wan, Xunliang Cai, Le Sun |  |
| 450 |  |  [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?](https://doi.org/10.18653/v1/2024.acl-long.331) |  | 0 | Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same best performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We... | Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song |  |
| 451 |  |  [Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct LLM in Knowledge-based VQA](https://doi.org/10.18653/v1/2024.acl-long.332) |  | 0 | LLM has achieved impressive performance on multi-modal tasks, which have received ever-increasing research attention. Recent research focuses on improving prediction performance and reliability (e.g., addressing the hallucination problem). They often prepend relevant external knowledge to the input text as an extra prompt. However, these methods would be affected by the noise in the knowledge and the context length limitation of LLM. In our work, we focus on making better use of external... | Qunbo Wang, Ruyi Ji, Tianhao Peng, Wenjun Wu, Zechao Li, Jing Liu |  |
| 452 |  |  [TasTe: Teaching Large Language Models to Translate through Self-Reflection](https://doi.org/10.18653/v1/2024.acl-long.333) |  | 0 | Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation. However, the existing approaches fail to yield satisfactory translation outputs that match the quality of supervised neural machine translation (NMT) systems. One plausible explanation for this discrepancy is that the straightforward prompts employed in... | Yutong Wang, Jiali Zeng, Xuebo Liu, Fandong Meng, Jie Zhou, Min Zhang |  |
| 453 |  |  [Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.334) |  | 0 | A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with fewer active parameters, but it is still hard to deploy them due to their immense parameter sizes. Different from previous weight pruning methods that rely on specifically designed hardware, this paper mainly aims to enhance the deployment efficiency of MoE LLMs by introducing plug-and-play... | Xudong Lu, Qi Liu, Yuhui Xu, Aojun Zhou, Siyuan Huang, Bo Zhang, Junchi Yan, Hongsheng Li |  |
| 454 |  |  [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://doi.org/10.18653/v1/2024.acl-long.335) |  | 0 | Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents UNIMO-G, a simple multimodal conditional diffusion framework that operates on multimodal prompts with interleaved textual and visual inputs, which demonstrates a unified ability for both text-driven and subject-driven image... | Wei Li, Xue Xu, Jiachen Liu, Xinyan Xiao |  |
| 455 |  |  [The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities](https://doi.org/10.18653/v1/2024.acl-long.336) |  | 0 | Fine-tuning large language models (LLMs) for machine translation has shown improvements in overall translation quality. However, it is unclear what is the impact of fine-tuning on desirable LLM behaviors that are not present in neural machine translation models, such as steerability, inherent document-level translation abilities, and the ability to produce less literal translations. We perform an extensive translation evaluation on the LLaMA and Falcon family of models with model size ranging... | David Stap, Eva Hasler, Bill Byrne, Christof Monz, Ke Tran |  |
| 456 |  |  [Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?](https://doi.org/10.18653/v1/2024.acl-long.337) |  | 0 | While auxiliary information has become a key to enhancing Large Language Models (LLMs), relatively little is known about how LLMs merge these contexts, specifically contexts generated by LLMs and those retrieved from external sources.To investigate this, we formulate a systematic framework to identify whether LLMs’ responses are attributed to either generated or retrieved contexts.To easily trace the origin of the response, we construct datasets with conflicting contexts, i.e., each question is... | Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng |  |
| 457 |  |  [Unveiling Linguistic Regions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.338) |  | 0 | Large Language Models (LLMs) have demonstrated considerable cross-lingual alignment and generalization ability. Current research primarily focuses on improving LLMs’ cross-lingual generalization capabilities. However, there is still a lack of research on the intrinsic mechanisms of how LLMs achieve cross-lingual alignment. From the perspective of region partitioning, this paper conducts several investigations on the linguistic competence of LLMs. We discover a core region in LLMs that... | Zhihao Zhang, Jun Zhao, Qi Zhang, Tao Gui, Xuanjing Huang |  |
| 458 |  |  [Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment](https://doi.org/10.18653/v1/2024.acl-long.339) |  | 0 | A song is a combination of singing voice and accompaniment. However, existing works focus on singing voice synthesis and music generation independently. Little attention was paid to exploring song synthesis. In this work, we propose a novel task called Text-to-Song synthesis which incorporates both vocal and accompaniment generation. We develop Melodist, a two-stage text-to-song method that consists of singing voice synthesis (SVS) and vocal-to-accompaniment (V2A) synthesis. Melodist leverages... | Zhiqing Hong, Rongjie Huang, Xize Cheng, Yongqi Wang, Ruiqi Li, Fuming You, Zhou Zhao, Zhimeng Zhang |  |
| 459 |  |  [FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection](https://doi.org/10.18653/v1/2024.acl-long.340) |  | 0 | Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models. State-of-the-art models typically incorporate the FiD framework, which is composed by a neural retriever alongside an encoder-decoder neural reader. In the answer generation process, the retriever will retrieve numerous passages (around 100 for instance), each of which is then individually encoded by the encoder.... | Yufei Huang, Xu Han, Maosong Sun |  |
| 460 |  |  [Discursive Socratic Questioning: Evaluating the Faithfulness of Language Models' Understanding of Discourse Relations](https://doi.org/10.18653/v1/2024.acl-long.341) |  | 0 | While large language models have significantly enhanced the effectiveness of discourse relation classifications, it remains unclear whether their comprehension is faithful and reliable. We provide DiSQ, a new method for evaluating the faithfulness of understanding discourse based on question answering. We first employ in-context learning to annotate the reasoning for discourse comprehension, based on the connections among key events within the discourse. Following this, DiSQ interrogates the... | Yisong Miao, Hongfu Liu, Wenqiang Lei, Nancy F. Chen, MinYen Kan |  |
| 461 |  |  [An Open Multilingual System for Scoring Readability of Wikipedia](https://doi.org/10.18653/v1/2024.acl-long.342) |  | 0 | With over 60M articles, Wikipedia has become the largest platform for open and freely accessible knowledge. While it has more than 15B monthly visits, its content is believed to be inaccessible to many readers due to the lack of readability of its text. However, previous investigations of the readability of Wikipedia have been restricted to English only, and there are currently no systems supporting the automatic readability assessment of the 300+ languages in Wikipedia. To bridge this gap, we... | Mykola Trokhymovych, Indira Sen, Martin Gerlach |  |
| 462 |  |  [Unlearning Traces the Influential Training Data of Language Models](https://doi.org/10.18653/v1/2024.acl-long.343) |  | 0 | Identifying the training datasets that influence a language model’s outputs is essential for minimizing the generation of harmful content and enhancing its performance. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to retrain a model multiple times. This paper presents UnTrac: unlearning traces the influence of a training dataset on the model’s performance. UnTrac is extremely simple; each training dataset is unlearned... | Masaru Isonuma, Ivan Titov |  |
| 463 |  |  [Exploring Alignment in Shared Cross-lingual Spaces](https://doi.org/10.18653/v1/2024.acl-long.344) |  | 0 | Despite their remarkable ability to capture linguistic nuances across diverse languages, questions persist regarding the degree of alignment between languages in multilingual embeddings. Drawing inspiration from research on high-dimensional representations in neural language models, we employ clustering to uncover latent concepts within multilingual models. Our analysis focuses on quantifying the alignment and overlap of these concepts across various languages within the latent space. To this... | Basel Mousi, Nadir Durrani, Fahim Dalvi, Majd Hawasly, Ahmed Abdelali |  |
| 464 |  |  [Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.345) |  | 0 | This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and opinions) cultural objects.... | Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jentse Huang, Zhaopeng Tu, Michael R. Lyu |  |
| 465 |  |  [Self-Evolving GPT: A Lifelong Autonomous Experiential Learner](https://doi.org/10.18653/v1/2024.acl-long.346) |  | 0 | To improve the performance of large language models (LLMs), researchers have explored providing LLMs with textual task-solving experience via prompts. However, they rely on manual efforts to acquire and apply such experience for each task, which is not feasible for the growing demand for LLMs and the variety of user questions.To address this issue, we design a lifelong autonomous experiential learning framework based on LLMs to explore whether LLMs can imitate human ability for learning and... | Jinglong Gao, Xiao Ding, Yiming Cui, Jianbai Zhao, Hepeng Wang, Ting Liu, Bing Qin |  |
| 466 |  |  [WRP: Weight Recover Prune for Structured Sparsity](https://doi.org/10.18653/v1/2024.acl-long.347) |  | 0 | As the scale of Large Language Models (LLMs) increases, it is necessary to compress the models to reduce the substantial demand on computational resources. Network pruning significantly reduces the model size by converting the weight matrix from dense to sparse data format. Current methodologies advocate for one-shot pruning to avoid the expense of retraining, ensuring the maintenance of model performance under conditions of 50%-60% unstructured pruning. Nevertheless, matrices characterized by... | Zhendong Tan, Xingjun Zhang, Zheng Wei |  |
| 467 |  |  [Error-preserving Automatic Speech Recognition of Young English Learners' Language](https://doi.org/10.18653/v1/2024.acl-long.348) |  | 0 | One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. The recent advances in speech technology and natural language processing allow the creation of novel tools to practice their speaking skills. In this work, we tackle the first component of such a pipeline, namely, the automated speech recognition module (ASR). State-of-the-art models are often trained... | Janick Michot, Manuela Hürlimann, Jan Deriu, Luzia Sauer, Katsiaryna Mlynchyk, Mark Cieliebak |  |
| 468 |  |  [DiFiNet: Boundary-Aware Semantic Differentiation and Filtration Network for Nested Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.349) |  | 0 | Nested Named Entity Recognition (Nested NER) entails identifying and classifying entity spans within the text, including the detection of named entities that are embedded within external entities. Prior approaches primarily employ span-based techniques, utilizing the power of exhaustive searches to address the challenge of overlapping entities. Nonetheless, these methods often grapple with the absence of explicit guidance for boundary detection, resulting insensitivity in discerning minor... | Yuxiang Cai, Qiao Liu, Yanglei Gan, Run Lin, Changlin Li, Xueyi Liu, Da Luo, JiayeYang JiayeYang |  |
| 469 |  |  [Legal Case Retrieval: A Survey of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.350) |  | 0 | Recent years have seen increasing attention on Legal Case Retrieval (LCR), a key task in the area of Legal AI that concerns the retrieval of cases from a large legal database of historical cases that are similar to a given query. This paper presents a survey of the major milestones made in LCR research, targeting researchers who are finding their way into the field and seek a brief account of the relevant datasets and the recent neural models and their performances. | Yi Feng, Chuanyi Li, Vincent Ng |  |
| 470 |  |  [Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.351) |  | 0 | Compositional generalization, representing the model’s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation... | Tianqi Zhong, Zhaoyi Li, Quan Wang, Linqi Song, Ying Wei, Defu Lian, Zhendong Mao |  |
| 471 |  |  [LLaMA Pro: Progressive LLaMA with Block Expansion](https://doi.org/10.18653/v1/2024.acl-long.352) |  | 0 | Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLMs), e.g., from LLaMA to CodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with an expansion of Transformer blocks. We tune the expanded blocks using only new corpus, efficiently and effectively improving the model’s knowledge while mitigating forgetting. In this paper, we experiment on the corpus of code and math, yielding LLaMA Pro-8.3B, a... | Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, Ye Feng, Ying Shan, Ping Luo |  |
| 472 |  |  [Generating Contrastive Narratives Using the Brownian Bridge Process for Narrative Coherence Learning](https://doi.org/10.18653/v1/2024.acl-long.353) |  | 0 | A major challenge for narrative reasoning is to learn narrative coherence. Existing works mainly follow the contrastive learning paradigm. However, the negative samples in their methods can be easily distinguished, which makes their methods unsatisfactory. In this work, we devise two strategies for mining hard negatives, including (1) crisscrossing a narrative and its contrastive variants; and (2) event-level replacement. To obtain contrastive variants, we utilize the Brownian Bridge process to... | Feiteng Mu, Wenjie Li |  |
| 473 |  |  [A Causal Approach for Counterfactual Reasoning in Narratives](https://doi.org/10.18653/v1/2024.acl-long.354) |  | 0 | Counterfactual reasoning in narratives requires predicting how alternative conditions, contrary to what actually happened, might have resulted in different outcomes.One major challenge is to maintain the causality between the counterfactual condition and the generated counterfactual outcome. In this paper, we propose a basic VAE module for counterfactual reasoning in narratives. We further introduce a pre-trained classifier and external event commonsense to mitigate the posterior collapse... | Feiteng Mu, Wenjie Li |  |
| 474 |  |  [SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation](https://doi.org/10.18653/v1/2024.acl-long.355) |  | 0 | Strong inductive biases enable learning from little data and help generalization outside the training distribution. Popular neural architectures such as Transformers lack strong structural inductive biases for seq2seq NLP tasks on their own. Consequently, they struggle with systematic generalization beyond the training distribution, e.g. with extrapolating to longer inputs, even when pre-trained on large amounts of text.We show how a structural inductive bias can be efficiently injected into a... | Matthias Lindemann, Alexander Koller, Ivan Titov |  |
| 475 |  |  [The Hidden Space of Transformer Language Adapters](https://doi.org/10.18653/v1/2024.acl-long.356) |  | 0 | We analyze the operation of transformer language adapters, which are small modules trained on top of a frozen language model to adapt its predictions to new target languages. We show that adapted predictions mostly evolve in the source language the model was trained on, while the target language becomes pronounced only in the very last layers of the model. Moreover, the adaptation process is gradual and distributed across layers, where it is possible to skip small groups of adapters without... | Jesujoba Alabi, Marius Mosbach, Matan Eyal, Dietrich Klakow, Mor Geva |  |
| 476 |  |  [A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts](https://doi.org/10.18653/v1/2024.acl-long.357) |  | 0 | In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research delves into an intriguing question: Does a text retain its original authorship when it undergoes numerous paraphrasing iterations? Specifically, since Large Language Models (LLMs) have demonstrated... | Nafis Irtiza Tripto, Saranya Venkatraman, Dominik Macko, Róbert Móro, Ivan Srba, Adaku Uchendu, Thai Le, Dongwon Lee |  |
| 477 |  |  [Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations](https://doi.org/10.18653/v1/2024.acl-long.358) |  | 0 | In spoken dialogue, even if two current turns are the same sentence, their responses might still differ when they are spoken in different styles. The spoken styles, containing paralinguistic and prosodic information, mark the most significant difference between text and speech modality. When using text-only LLMs to model spoken dialogue, text-only LLMs cannot give different responses based on the speaking style of the current turn. In this paper, we focus on enabling LLMs to listen to the... | GuanTing Lin, ChengHan Chiang, Hungyi Lee |  |
| 478 |  |  [RetinaQA: A Robust Knowledge Base Question Answering Model for both Answerable and Unanswerable Questions](https://doi.org/10.18653/v1/2024.acl-long.359) |  | 0 | An essential requirement for a real-world Knowledge Base Question Answering (KBQA) system is the ability to detect the answerability of questions when generating logical forms. However, state-of-the-art KBQA models assume all questions to be answerable. Recent research has found that such models, when superficially adapted to detect answerability, struggle to satisfactorily identify the different categories of unanswerable questions, and simultaneously preserve good performance for answerable... | Prayushi Faldu, Indrajit Bhattacharya, Mausam |  |
| 479 |  |  [GroundingGPT: Language Enhanced Multi-modal Grounding Model](https://doi.org/10.18653/v1/2024.acl-long.360) |  | 0 | Multi-modal large language models (MLLMs) have demonstrated remarkable performance across various tasks. However, these models often prioritize capturing global information and overlook the importance of perceiving local information. This limitation hinders their ability to effectively understand fine-grained details and handle grounding tasks that necessitate nuanced comprehension. Although some recent works have made strides in this, they have primarily focused on single-modality inputs.... | Zhaowei Li, Qi Xu, Dong Zhang, Hang Song, Yiqing Cai, Qi Qi, Ran Zhou, Junting Pan, Zefeng Li, Vu Tu, Zhida Huang, Tao Wang |  |
| 480 |  |  [Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches](https://doi.org/10.18653/v1/2024.acl-long.361) |  | 0 | Automated Fact-Checking (AFC) is the automated verification of claim accuracy. AFC is crucial in discerning truth from misinformation, especially given the huge amounts of content are generated online daily. Current research focuses on predicting claim veracity through metadata analysis and language scrutiny, with an emphasis on justifying verdicts. This paper surveys recent methodologies, proposinga comprehensive taxonomy and presenting the evolution of research in that landscape. A... | Islam Eldifrawi, Shengrui Wang, Amine Trabelsi |  |
| 481 |  |  [Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages](https://doi.org/10.18653/v1/2024.acl-long.362) |  | 0 | Multilingual neural machine translation systems learn to map sentences of different languages into a common representation space. Intuitively, with a growing number of seen languages the encoder sentence representation grows more flexible and easily adaptable to new languages. In this work, we test this hypothesis by zero-shot translating from unseen languages. To deal with unknown vocabularies from unknown languages we propose a setup where we decouple learning of vocabulary and syntax, i.e.... | Carlos Mullov, NgocQuan Pham, Alexander Waibel |  |
| 482 |  |  [SwapMoE: Serving Off-the-shelf MoE-based Large Language Models with Tunable Memory Budget](https://doi.org/10.18653/v1/2024.acl-long.363) |  | 0 | Mixture of experts (MoE) is a popular technique to improve capacity of Large Language Models (LLMs) with conditionally-activated parallel experts. However, serving MoE models on memory-constrained devices is challenging due to the large parameter size. Typical solutions such as memory swapping or expert pruning may lead to significantly higher latency or severe accuracy loss.In this paper, we introduce SwapMoE, a framework for efficient serving of MoE-based large language models with tunable... | Rui Kong, Yuanchun Li, Qingtian Feng, Weijun Wang, Xiaozhou Ye, Ye Ouyang, Linghe Kong, Yunxin Liu |  |
| 483 |  |  [PixT3: Pixel-based Table-To-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.364) |  | 0 | Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. A common feature across existing methods is their treatment of the input as a string, i.e., by employing linearization techniques that do not always preserve information in the table, are verbose, and lack space efficiency. We propose to... | Iñigo Alonso, Eneko Agirre, Mirella Lapata |  |
| 484 |  |  [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://doi.org/10.18653/v1/2024.acl-long.365) |  | 0 | Factual questions typically can be answered correctly at different levels of granularity. For example, both “August 4, 1961” and “1961” are correct answers to the question “When was Barack Obama born?”. Standard question answering (QA) evaluation protocols, however, do not explicitly take this into account and compare a predicted answer against answers of a single granularity level. In this work, we propose GRANOLA QA, a novel evaluation setting where a predicted answer is evaluated in terms of... | Gal Yona, Roee Aharoni, Mor Geva |  |
| 485 |  |  [TAMS: Translation-Assisted Morphological Segmentation](https://doi.org/10.18653/v1/2024.acl-long.366) |  | 0 | Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes.This is a core task in endangered language documentation, and NLP systems have the potential to dramatically speed up this process. In typical language documentation settings, training data for canonical morpheme segmentation is scarce, making it difficult to train high quality models. However, translation data is often much more abundant, and, in this... | Enora Rice, Ali Marashian, Luke Gessler, Alexis Palmer, Katharina von der Wense |  |
| 486 |  |  [XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval](https://doi.org/10.18653/v1/2024.acl-long.367) |  | 0 | Recently, pre-trained large language models (LLMs) have shown impressive abilities in generating codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level, and in many cases without proper training data. Even more concerning is... | Mohammad Abdullah Matin Khan, M. Saiful Bari, Xuan Do Long, Weishi Wang, Md. Rizwan Parvez, Shafiq Joty |  |
| 487 |  |  [ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.368) |  | 0 | Large Language Models (LLMs) have succeeded remarkably in understanding long-form contents. However, exploring their capability for generating long-form contents, such as reports and articles, has been relatively unexplored and inadequately assessed by existing benchmarks. The prevalent evaluation methods, which predominantly rely on crowdsourcing, are recognized for their labor-intensive nature and lack of efficiency, whereas automated metrics, such as the ROUGE score, demonstrate discordance... | Haochen Tan, Zhijiang Guo, Zhan Shi, Lu Xu, Zhili Liu, Yunlong Feng, Xiaoguang Li, Yasheng Wang, Lifeng Shang, Qun Liu, Linqi Song |  |
| 488 |  |  [A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia](https://doi.org/10.18653/v1/2024.acl-long.369) |  | 0 | Large language models (LLMs) have an impressive ability to draw on novel information supplied in their context. Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters, which LLMs also excel at recalling. Favoring the contextual information is critical for retrieval-augmented generation methods, which enrich the context with up-to-date information, hoping that grounding... | Giovanni Monea, Maxime Peyrard, Martin Josifoski, Vishrav Chaudhary, Jason Eisner, Emre Kiciman, Hamid Palangi, Barun Patra, Robert West |  |
| 489 |  |  [Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA](https://doi.org/10.18653/v1/2024.acl-long.370) |  | 0 | Multipanel images, commonly seen as web screenshots, posters, etc., pervade our daily lives. These images, characterized by their composition of multiple subfigures in distinct layouts, effectively convey information to people. Toward building advanced multimodal AI applications, such as agents that understand complex scenes and navigate through webpages, the skill of multipanel visual reasoning is essential, and a comprehensive evaluation of models in this regard is important. Therefore, we... | Yue Fan, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, ChingChen Kuo, Yang Zhao, Xinze Guan, Xin Wang |  |
| 490 |  |  [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.371) |  | 0 | The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM)... | Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Yong Dai, Hongming Zhang, Zhenzhong Lan, Dong Yu |  |
| 491 |  |  [Translation-based Lexicalization Generation and Lexical Gap Detection: Application to Kinship Terms](https://doi.org/10.18653/v1/2024.acl-long.372) |  | 0 | Constructing lexicons with explicitly identified lexical gaps is a vital part of building multilingual lexical resources. Prior work has leveraged bilingual dictionaries and linguistic typologies for semi-automatic identification of lexical gaps. Instead, we propose a generally-applicable algorithmic method to automatically generate concept lexicalizations, which is based on machine translation and hypernymy relations between concepts. The absence of a lexicalization implies a lexical gap. We... | Senyu Li, Bradley Hauer, Ning Shi, Grzegorz Kondrak |  |
| 492 |  |  [Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations](https://doi.org/10.18653/v1/2024.acl-long.373) |  | 0 | We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to underlying social meanings. These extracted explanations or rationales serve as augmentations to the conversational text to facilitate dialogue understanding and transfer. Our empirical results over 2,340... | Ritam Dutt, Zhen Wu, Jiaxin Shi, Divyanshu Sheth, Prakhar Gupta, Carolyn P. Rosé |  |
| 493 |  |  [Robust Frame-Semantic Models with Lexical Unit Trees and Negative Samples](https://doi.org/10.18653/v1/2024.acl-long.374) |  | 0 | We present novel advancements in frame-semantic parsing, specifically focusing on target identification and frame identification. Our target identification model employs a novel prefix tree modification to enable robust support for multi-word lexical units, resulting in a coverage of 99.4% of the targets in the FrameNet 1.7 fulltext annotations. It utilizes a RoBERTa-based filter to achieve an F1 score of 0.775, surpassing the previous state-of-the-art solution by +0.012. For frame... | Jacob Daniel Devasier, Yogesh Gurjar, Chengkai Li |  |
| 494 |  |  [Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://doi.org/10.18653/v1/2024.acl-long.375) |  | 0 | Advancements in logical reasoning, utilizing LLMs to convert natural language into logical symbolism, combined with the use of external theorem provers, have repositioned the symbolic approach as a central point of interest. The main challenge within this paradigm lies in the LLMs’ capability to accurately translate natural language (NL) statements into first-order-logic (FOL) expressions. Although LLMs have shown notable success, there remains a gap in understanding the limitations and... | Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, Faramarz Fekri |  |
| 495 |  |  [Lightweight reranking for language model generations](https://doi.org/10.18653/v1/2024.acl-long.376) |  | 0 | Large Language Models (LLMs) can exhibit considerable variation in the quality of their sampled outputs. Reranking and selecting the best generation from the sampled set is a popular way of obtaining strong gains in generation quality. In this paper, we present a novel approach for reranking LLM generations. Unlike other techniques that might involve additional inferences or training a specialized reranker, our approach relies on easy to compute pairwise statistics between the generations that... | Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang |  |
| 496 |  |  [ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews](https://doi.org/10.18653/v1/2024.acl-long.377) |  | 0 | We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a dataset of review comments and their corresponding paper edits. The data is drawn from real reviewer-author interactions from computer science, and we provide labels linking each reviewer comment to the specific paper edits made by the author in response. We automatically create a high-precision silver training set, as well as an expert-labeled test set that shows high inter-annotator... | Mike D'Arcy, Alexis Ross, Erin Bransom, Bailey Kuehl, Jonathan Bragg, Tom Hope, Doug Downey |  |
| 497 |  |  [The Unreasonable Effectiveness of Easy Training Data for Hard Tasks](https://doi.org/10.18653/v1/2024.acl-long.378) |  | 0 | How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate... | Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe |  |
| 498 |  |  [PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.379) |  | 0 | Instruction tuning has remarkably advanced large language models (LLMs) in understanding and responding to diverse human instructions. Despite the success in high-resource languages, its application in lower-resource ones faces challenges due to the imbalanced foundational abilities of LLMs across different languages, stemming from the uneven language distribution in their pre-training data. To tackle this issue, we propose pivot language guided generation (PLUG), an approach that utilizes a... | Zhihan Zhang, DongHo Lee, Yuwei Fang, Wenhao Yu, Mengzhao Jia, Meng Jiang, Francesco Barbieri |  |
| 499 |  |  [MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.380) |  | 0 | We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error propagation due to the autoregressive nature and single-pass-based decoding, which lack error correction capability. Additionally, relying solely on a single sample may result in the omission of true nodes and edges. To counter this, we draw inspiration from... | Inderjeet Nair, Lu Wang |  |
| 500 |  |  [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs](https://doi.org/10.18653/v1/2024.acl-long.381) |  | 0 | Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning between LLM agents via multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism that leads to a better consensus.... | Justin ChihYao Chen, Swarnadeep Saha, Mohit Bansal |  |
| 501 |  |  [Mirror: Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning](https://doi.org/10.18653/v1/2024.acl-long.382) |  | 0 | While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore, We propose Mirror, a Multiple-perspective self-reflection method for knowledge-rich reasoning, to avoid... | Hanqi Yan, Qinglin Zhu, Xinyu Wang, Lin Gui, Yulan He |  |
| 502 |  |  [Where Do People Tell Stories Online? Story Detection Across Online Communities](https://doi.org/10.18653/v1/2024.acl-long.383) |  | 0 | Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit posts and comments, a detailed codebook adapted to the social media context, and models to predict storytelling at the document and span levels. Our dataset is sampled from hundreds of popular... | Maria Antoniak, Joel Mire, Maarten Sap, Elliott Ash, Andrew Piper |  |
| 503 |  |  [Large Language Models Are No Longer Shallow Parsers](https://doi.org/10.18653/v1/2024.acl-long.384) |  | 0 | The development of large language models (LLMs) brings significant changes to the field of natural language processing (NLP), enabling remarkable performance in various high-level tasks, such as machine translation, question-answering, dialogue generation, etc., under end-to-end settings without requiring much training data. Meanwhile, fundamental NLP tasks, particularly syntactic parsing, are also essential for language study as well as evaluating the capability of LLMs for instruction... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 504 |  |  [Dialogue Summarization with Mixture of Experts based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.385) |  | 0 | Dialogue summarization is an important task that requires to generate highlights for a conversation from different aspects (e.g., content of various speakers). While several studies successfully employ large language models (LLMs) and achieve satisfying results, they are limited by using one model at a time or treat it as a black box, which makes it hard to discriminatively learn essential content in a dialogue from different aspects, therefore may lead to anticipation bias and potential loss... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 505 |  |  [ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences](https://doi.org/10.18653/v1/2024.acl-long.386) |  | 0 | Recently, the increasing demand for superior medical services has highlighted the discrepancies in the medical infrastructure. With big data, especially texts, forming the foundation of medical services, there is an exigent need for effective natural language processing (NLP) solutions tailored to the healthcare domain. Conventional approaches leveraging pre-trained models present promising results in this domain and current large language models (LLMs) offer advanced foundation for medical... | Yuanhe Tian, Ruyi Gan, Yan Song, Jiaxing Zhang, Yongdong Zhang |  |
| 506 |  |  [An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.387) |  | 0 | Large language models (LLMs) have shown strong arithmetic reasoning capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we have only a limited understanding of how they are processed by LLMs. To demystify it, prior work has primarily focused on ablating different components in the CoT prompt and empirically observing their resulting LLM performance change. Yet, the reason why these components are important to LLM reasoning is not explored. To fill this gap, in this work, we... | Daking Rai, Ziyu Yao |  |
| 507 |  |  [Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling](https://doi.org/10.18653/v1/2024.acl-long.388) |  | 0 | Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of large language models (LLMs) in legal education to help non-experts learn intricate legal concepts through storytelling, an effective pedagogical tool in conveying complex and abstract concepts. We also... | Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel T. Kessler, Eric Ma, Tal August, Irene Li, Alex Pentland, Yoon Kim, Deb K. Roy, Jad Kabbara |  |
| 508 |  |  [Intrinsic Task-based Evaluation for Referring Expression Generation](https://doi.org/10.18653/v1/2024.acl-long.389) |  | 0 | Recently, a human evaluation study of Referring Expression Generation (REG) models had an unexpected conclusion: on WEBNLG, Referring Expressions (REs) generated by the state-of-the-art neural models were not only indistinguishable from the REs in WEBNLG but also from the REs generated by a simple rule-based system. Here, we argue that this limitation could stem from the use of a purely ratings-based human evaluation (which is a common practice in Natural Language Generation). To investigate... | Guanyi Chen, Fahime Same, Kees van Deemter |  |
| 509 |  |  [From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.390) |  | 0 | Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts, tracing the progression of events and topics over time. Prior research typically focuses on either event or topic timeline summarization, neglecting the potential synergy of these two forms. In this study, we bridge this gap by introducing a novel approach that leverages large language models (LLMs) for generating both event and topic timelines. Our approach diverges from conventional... | Qisheng Hu, Geonsik Moon, Hwee Tou Ng |  |
| 510 |  |  [End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.391) |  | 0 | Document-level relation extraction (DocRE) aims to extract relations between entities in a whole document. One of the pivotal challenges of DocRE is to capture the intricate interdependencies between relations of entity pairs. Previous methods have shown that logical rules can explicitly help capture such interdependencies. These methods either learn logical rules to refine the output of a trained DocRE model, or first learn logical rules from annotated data and then inject the learnt rules... | Kunxun Qi, Jianfeng Du, Hai Wan |  |
| 511 |  |  [Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?](https://doi.org/10.18653/v1/2024.acl-long.392) |  | 0 | Recently proposed two-pass direct speech-to-speech translation (S2ST) models decompose the task into speech-to-text translation (S2TT) and text-to-speech (TTS) within an end-to-end model, yielding promising results. However, the training of these models still relies on parallel speech data, which is extremely challenging to collect. In contrast, S2TT and TTS have accumulated a large amount of data and pretrained models, which have not been fully utilized in the development of S2ST models.... | Qingkai Fang, Shaolei Zhang, Zhengrui Ma, Min Zhang, Yang Feng |  |
| 512 |  |  [Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder](https://doi.org/10.18653/v1/2024.acl-long.393) |  | 0 | Reconstructing natural language from non-invasive electroencephalography (EEG) holds great promise as a language decoding technology for brain-computer interfaces (BCIs). However, EEG-based language decoding is still in its nascent stages, facing several technical issues such as: 1) Absence of a hybrid strategy that can effectively integrate cross-modality (between EEG and text) self-learning with intra-modality self-reconstruction of EEG features or textual sequences; 2) Under-utilization of... | Jiaqi Wang, Zhenxi Song, Zhengyu Ma, Xipeng Qiu, Min Zhang, Zhiguo Zhang |  |
| 513 |  |  [CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers](https://doi.org/10.18653/v1/2024.acl-long.394) |  | 0 | The fast-growing large scale language models are delivering unprecedented performance on almost all natural language processing tasks. However, the effectiveness of large language models are reliant on an exponentially increasing number of parameters. The overwhelming computation complexity incurs a high inference latency that negatively affects user experience. Existing methods to improve inference efficiency, such as tensor parallelism and quantization, target to reduce per-layer computing... | Longwei Zou, Qingyang Wang, Han Zhao, Jiangangkong Jiangangkong, Yi Yang, Yangdong Deng |  |
| 514 |  |  [Prompt Optimization via Adversarial In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.395) |  | 0 | We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompts for in-context learning (ICL). Inspired by adversarial learning, adv-ICL is implemented as a two-player game between a generator and discriminator, with LLMs acting as both. In each round, given an input prefixed by task instructions and several exemplars, the generator produces an output. The discriminator then classifies the generator’s input-output pair as model-generated or real data. Based on the... | Do Xuan Long, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Shieh, Junxian He |  |
| 515 |  |  [StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion](https://doi.org/10.18653/v1/2024.acl-long.396) |  | 0 | Recent language model (LM) advancements have showcased impressive zero-shot voice conversion (VC) performance. However, existing LM-based VC models usually apply offline conversion from source semantics to acoustic features, demanding the complete source speech and limiting their deployment to real-time applications. In this paper, we introduce StreamVoice, a novel streaming LM-based model for zero-shot VC, facilitating real-time conversion given arbitrary speaker prompts and source speech.... | Zhichao Wang, Yuanzhe Chen, Xinsheng Wang, Lei Xie, Yuping Wang |  |
| 516 |  |  [Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.397) |  | 0 | Multi-Hop Question Answering (MHQA) task presents a significant challenge for large language models (LLMs) due to the intensive knowledge required. Current solutions, like Retrieval-Augmented Generation, typically retrieve potential documents from an external corpus to read an answer. However, the performance of this retrieve-then-read paradigm is constrained by the retriever and the inevitable noise in the retrieved documents. To mitigate these challenges, we introduce a novel... | Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, Zhaochun Ren |  |
| 517 |  |  [Multimodal Contextualized Semantic Parsing from Speech](https://doi.org/10.18653/v1/2024.acl-long.398) |  | 0 | We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents’ contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically updating an agent’s knowledge with new information, mirroring the complexity of human communication. We develop the VG-SPICE dataset, crafted to challenge agents with visual scene graph construction... | Jordan Voas, David Harwath, Raymond Mooney |  |
| 518 |  |  [LaMP: When Large Language Models Meet Personalization](https://doi.org/10.18653/v1/2024.acl-long.399) |  | 0 | This paper highlights the importance of personalization in large language models and introduces the LaMP benchmark — a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and multiple entries for each user profile. It consists of seven personalized tasks, spanning three text classification and four text generation tasks. We additionally propose two retrieval augmentation... | Alireza Salemi, Sheshera Mysore, Michael Bendersky, Hamed Zamani |  |
| 519 |  |  [AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters](https://doi.org/10.18653/v1/2024.acl-long.400) |  | 0 | Large language models’ (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage are under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from:... | Li Lucy, Suchin Gururangan, Luca Soldaini, Emma Strubell, David Bamman, Lauren F. Klein, Jesse Dodge |  |
| 520 |  |  [MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.acl-long.401) |  | 0 | The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems. However, comprehensively evaluating the dialogue abilities of LLMs remains a challenge. Previous benchmarks have primarily focused on single-turn dialogues or provided coarse-grained and incomplete assessments of multi-turn dialogues, overlooking the complexity and fine-grained nuances of real-life dialogues. To address this issue, we introduce MT-Bench-101, specifically designed to evaluate the fine-grained... | Ge Bai, Jie Liu, Xingyuan Bu, Yancheng He, Jiaheng Liu, Zhanhui Zhou, Zhuoran Lin, Wenbo Su, Tiezheng Ge, Bo Zheng, Wanli Ouyang |  |
| 521 |  |  [EFSA: Towards Event-Level Financial Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.402) |  | 0 | In this paper, we extend financial sentiment analysis (FSA) to event-level since events usually serve as the subject of the sentiment in financial text. Though extracting events from the financial text may be conducive to accurate sentiment predictions, it has specialized challenges due to the lengthy and discontinuity of events in a financial text. To this end, we reconceptualize the event extraction as a classification task by designing a categorization comprising coarse-grained and... | Tianyu Chen, Yiming Zhang, Guoxin Yu, Dapeng Zhang, Li Zeng, Qing He, Xiang Ao |  |
| 522 |  |  [What Evidence Do Language Models Find Convincing?](https://doi.org/10.18653/v1/2024.acl-long.403) |  | 0 | Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as “is aspartame linked to cancer”. To resolve these ambiguous queries, one must search through a large range of websites and consider “which, if any, of this evidence do I find convincing?”. In this work, we study how LLMs answer this question. In particular, we construct ConflictingQA, a dataset that pairs controversial queries with a series of real-world evidence... | Alexander Wan, Eric Wallace, Dan Klein |  |
| 523 |  |  [Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.404) |  | 0 | Graph data organizes complex relationships and interactions between objects, facilitating advanced analysis and decision-making across different fields. In this paper, we propose a new paradigm for interactive and instructional graph data understanding and reasoning.Instead of adopting complex graph neural models or heuristic graph-to-text instruction design, we leverage Vision-Language Models (VLMs) to encode the graph images with varying structures across different domains. This paper first... | Qihang Ai, Jiafan Li, Jincheng Dai, Jianwu Zhou, Lemao Liu, Haiyun Jiang, Shuming Shi |  |
| 524 |  |  [LangBridge: Multilingual Reasoning Without Multilingual Supervision](https://doi.org/10.18653/v1/2024.acl-long.405) |  | 0 | We introduce LangBridge, a zero-shot approach to adapt language models for multilingual reasoning tasks without multilingual supervision. LangBridge operates by bridging two models, each specialized in different aspects: (1) one specialized in understanding multiple languages (e.g., mT5 encoder) and (2) one specialized in reasoning (e.g., MetaMath). LangBridge connects the two models by introducing minimal trainable parameters between them. Despite utilizing only English data for training,... | Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, Minjoon Seo |  |
| 525 |  |  [Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs](https://doi.org/10.18653/v1/2024.acl-long.406) |  | 0 | Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in... | Siyuan Wang, Zhongyu Wei, Yejin Choi, Xiang Ren |  |
| 526 |  |  [SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving](https://doi.org/10.18653/v1/2024.acl-long.407) |  | 0 | Large Language Models (LLMs) have driven substantial progress in artificial intelligence in recent years, exhibiting impressive capabilities across a wide range of tasks, including mathematical problem-solving. Inspired by the success of subgoal-based methods, we propose a novel framework called SEquential subGoal Optimization (SEGO) to enhance LLMs’ ability to solve mathematical problems. By establishing a connection between the subgoal breakdown process and the probability of solving... | Xueliang Zhao, Xinting Huang, Wei Bi, Lingpeng Kong |  |
| 527 |  |  [Unlocking the Power of Large Language Models for Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.408) |  | 0 | Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in data-driven AI applications. Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of the representation learning techniques. Against this backdrop, we introduce ChatEA, an innovative framework that incorporates large language models (LLMs) to improve EA. To address the constraints of... | Xuhui Jiang, Yinghan Shen, Zhichao Shi, Chengjin Xu, Wei Li, Zixuan Li, Jian Guo, Huawei Shen, Yuanzhuo Wang |  |
| 528 |  |  [Trial and Error: Exploration-Based Trajectory Optimization of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.409) |  | 0 | Large Language Models (LLMs) have become integral components in various autonomous agent systems.In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous studies that exclusively train on successful expert trajectories, our method allows agents to learn from their exploration failures. This leads to improved performance through an iterative... | Yifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian Li, Bill Yuchen Lin |  |
| 529 |  |  [ReFT: Reasoning with Reinforced Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.410) |  | 0 | One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data. In math problem-solving, for example, there is usually only one annotated reasoning path for each question in the training data. Intuitively, it would be better for the algorithm to learn from multiple... | Luong Quoc Trung, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, Hang Li |  |
| 530 |  |  [Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment](https://doi.org/10.18653/v1/2024.acl-long.411) |  | 0 | Evaluating and Rethinking the current landscape of Large Multimodal Models (LMMs), we observe that widely-used visual-language projection approaches (e.g., Q-former or MLP) focus on the alignment of image-text descriptions yet ignore the visual knowledge-dimension alignment, i.e., connecting visuals to their relevant knowledge. Visual knowledge plays a significant role in analyzing, inferring, and interpreting information from visuals, helping improve the accuracy of answers to knowledge-based... | Yunxin Li, Xinyu Chen, Baotian Hu, Haoyuan Shi, Min Zhang |  |
| 531 |  |  [FreeCtrl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.412) |  | 0 | Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data resources. In contrast, some proposed learning-free alternatives circumvent learning but often yield inferior results, exemplifying the fundamental machine learning trade-off between computational... | Zijian Feng, Hanzhang Zhou, Kezhi Mao, Zixiao Zhu |  |
| 532 |  |  [HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition](https://doi.org/10.18653/v1/2024.acl-long.413) |  | 0 | Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval, a novel framework that iteratively aligns LLM-based evaluators with human preference via Hierarchical Criteria Decomposition. HD-Eval inherits the essence from the evaluation mindset of human experts... | Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 533 |  |  [Conundrums in Cross-Prompt Automated Essay Scoring: Making Sense of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.414) |  | 0 | Cross-prompt automated essay scoring (AES), an under-investigated but challenging task that has gained increasing popularity in the AES community, aims to train an AES system that can generalize well to prompts that are unseen during model training. While recently-developed cross-prompt AES models have combined essay representations that are learned via sophisticated neural architectures with so-called prompt-independent features, an intriguing question is: are complex neural models needed to... | Shengjie Li, Vincent Ng |  |
| 534 |  |  [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](https://doi.org/10.18653/v1/2024.acl-long.415) |  | 0 | Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes have been extensively researched in various NLP applications, there is a surprising gap for emotion analysis. However, emotion and gender are closely linked in societal discourse. E.g., women are often thought of as more empathetic, while men’s anger is more socially accepted. To fill this gap, we present the first comprehensive study of gendered emotion attribution in... | Flor Miriam Plaza del Arco, Amanda Cercas Curry, Alba Cercas Curry, Gavin Abercrombie, Dirk Hovy |  |
| 535 |  |  [Label Augmentation for Zero-Shot Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.acl-long.416) |  | 0 | Hierarchical Text Classification poses the difficult challenge of classifying documents into multiple labels organized in a hierarchy. The vast majority of works aimed to address this problem relies on supervised methods which are difficult to implement due to the scarcity of labeled data in many real world applications. This paper focuses on strict Zero-Shot Classification, the setting in which the system lacks both labeled instances and training data.We propose a novel approach that uses a... | Lorenzo Paletto, Valerio Basile, Roberto Esposito |  |
| 536 |  |  [STICKERCONV: Generating Multimodal Empathetic Responses from Scratch](https://doi.org/10.18653/v1/2024.acl-long.417) |  | 0 | Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses collaborative agent interactions to realistically simulate human behavior with sticker usage, thereby enhancing multimodal empathetic communication. Building on this foundation, we develop a... | Yiqun Zhang, Fanheng Kong, Peidong Wang, Shuang Sun, Lingshuai Wang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song |  |
| 537 |  |  [EIT: Enhanced Interactive Transformer](https://doi.org/10.18653/v1/2024.acl-long.418) |  | 0 | Two principles: the complementary principle and the consensus principle are widely acknowledged in the literature of multi-view learning. However, the current design of multi-head self-attention, an instance of multi-view learning, prioritizes the complementarity while ignoring the consensus. To address this problem, we propose an enhanced multi-head self-attention (EMHA). First, to satisfy the complementary principle, EMHA removes the one-to-one mapping constraint among queries and keys in... | Tong Zheng, Bei Li, Huiwen Bao, Tong Xiao, JingBo Zhu |  |
| 538 |  |  [MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs](https://doi.org/10.18653/v1/2024.acl-long.419) |  | 0 | Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is an important task for enhanced reliability. Uncertainty Estimation (UE) in generative LLMs is an evolving domain, where SOTA probability-based methods commonly employ length-normalized scoring. In... | Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Chenyang Tao, Dimitrios Dimitriadis, Salman Avestimehr |  |
| 539 |  |  [EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models](https://doi.org/10.18653/v1/2024.acl-long.420) |  | 0 | We introduce EXAMS-V, a new challenging multi-discipline multimodal multilingual exam benchmark for evaluating vision language models. It consists of 20,932 multiple-choice questions across 20 school disciplines covering natural science, social science, and other miscellaneous studies, e.g., religion, fine arts, business, etc. EXAMS-V includes a variety of multimodal features such as text, images, tables, figures, diagrams, maps, scientific symbols, and equations. The questions come in 11... | Rocktim Jyoti Das, Simeon Emilov Hristov, Haonan Li, Dimitar Dimitrov, Ivan Koychev, Preslav Nakov |  |
| 540 |  |  [Order-Agnostic Data Augmentation for Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.421) |  | 0 | Data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, existing NER DA techniques either perform rule-based manipulations on words that break the semantic coherence of the sentence, or exploit generative models for entity or context substitution, which requires a substantial amount of labeled data and contradicts the objective of operating in low-resource... | Huiming Wang, Liying Cheng, Wenxuan Zhang, De Wen Soh, Lidong Bing |  |
| 541 |  |  [Text Embedding Inversion Security for Multilingual Language Models](https://doi.org/10.18653/v1/2024.acl-long.422) |  | 0 | Textual data is often represented as real-numbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be susceptible to security breaches, as research shows that text can be reconstructed from embeddings, even without knowledge of the underlying model. While defence mechanisms have been explored, these are exclusively focused on English, leaving other languages... | Yiyi Chen, Heather C. Lent, Johannes Bjerva |  |
| 542 |  |  [Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment](https://doi.org/10.18653/v1/2024.acl-long.423) |  | 0 | Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and potential dialogues ingrained in their vast training corpora. Thus, we introduce Ditto, the first self-alignment method for role-play, which encourages an instruction-following LLM to simulate role-play... | Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou |  |
| 543 |  |  [PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator](https://doi.org/10.18653/v1/2024.acl-long.424) |  | 0 | The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides made by leveraging real user and ChatGPT dialogues, as evidenced by Vicuna. However, due to challenges in gathering dialogues involving human participation, current endeavors like Baize and UltraChat rely on ChatGPT conducting roleplay to simulate humans based on instructions, resulting in overdependence on seeds, diminished human-likeness, limited topic diversity, and an... | Chuyi Kong, Yaxin Fan, Xiang Wan, Feng Jiang, Benyou Wang |  |
| 544 |  |  [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](https://doi.org/10.18653/v1/2024.acl-long.425) |  | 0 | The capability gap between open-source and closed-source large language models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we introduce a synthetic data approach that combines data produced by larger, more powerful models (strong models) with error information data generated by smaller, not well-aligned models (weak models). The method not only enhances the domain generalization of text-to-SQL models but also explores the potential of error data supervision through... | Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou |  |
| 545 |  |  [STRUCTSUM Generation for Faster Text Comprehension](https://doi.org/10.18653/v1/2024.acl-long.426) |  | 0 | We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly suitable for sparse content. Despite the effectiveness of LLMs on different tasks, we show that current models struggle with generating structured outputs. In response, we present effective prompting... | Parag Jain, Andreea Marzoca, Francesco Piccinno |  |
| 546 |  |  [Analysing The Impact of Sequence Composition on Language Model Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.427) |  | 0 | Most language model pre-training frameworks concatenate multiple documents into fixed-length sequences and use causal masking to compute the likelihood of each token given its context; this strategy is widely adopted due to its simplicity and efficiency. However, to this day, the influence of the pre-training sequence composition strategy on the generalisation properties of the model remains under-explored.In this work, we find that applying causal masking can lead to the inclusion of... | Yu Zhao, Yuanbin Qu, Konrad Staniszewski, Szymon Tworkowski, Wei Liu, Piotr Milos, Yuxiang Wu, Pasquale Minervini |  |
| 547 |  |  [NACL: A General and Effective KV Cache Eviction Framework for LLM at Inference Time](https://doi.org/10.18653/v1/2024.acl-long.428) |  | 0 | Large Language Models (LLMs) have ignited an innovative surge of AI applications, marking a new era of exciting possibilities equipped with extended context windows. However, hosting these models is cost-prohibitive mainly due to the extensive memory consumption of KV Cache involving long-context modeling. Despite several works proposing to evict unnecessary tokens from the KV Cache, most of them rely on the biased local statistics of accumulated attention scores and report performance using... | Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu |  |
| 548 |  |  [SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network](https://doi.org/10.18653/v1/2024.acl-long.429) |  | 0 | Brain-inspired Spiking Neural Network (SNN) has demonstrated its effectiveness and efficiency in vision, natural language, and speech understanding tasks, indicating their capacity to “see”, “listen”, and “read”. In this paper, we design SpikeVoice, which performs high-quality Text-To-Speech (TTS) via SNN, to explore the potential of SNN to “speak”. A major obstacle to using SNN for such generative tasks lies in the demand for models to grasp long-term dependencies. The serial nature of spiking... | Kexin Wang, Jiahong Zhang, Yong Ren, Man Yao, Di Shang, Bo Xu, Guoqi Li |  |
| 549 |  |  [Context-aware Difference Distilling for Multi-change Captioning](https://doi.org/10.18653/v1/2024.acl-long.430) |  | 0 | Multi-change captioning aims to describe complex and coupled changes within an image pair in natural language. Compared with single-change captioning, this task requires the model to have higher-level cognition ability to reason an arbitrary number of changes. In this paper, we propose a novel context-aware difference distilling (CARD) network to capture all genuine changes for yielding sentences. Given an image pair, CARD first decouples context features that aggregate all similar/dissimilar... | Yunbin Tu, Liang Li, Li Su, ZhengJun Zha, Chenggang Yan, Qingming Huang |  |
| 550 |  |  [Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion](https://doi.org/10.18653/v1/2024.acl-long.431) |  | 0 | Recent years have witnessed the deployment of code language models (LMs) in various code intelligence tasks such as code completion. Yet, it is challenging for pre-trained LMs to generate correct completions in private repositories. Previous studies retrieve cross-file context based on import relations or text similarity, which is insufficiently relevant to completion targets. In this paper, we propose a dataflow-guided retrieval augmentation approach, called DraCo, for repository-level code... | Wei Cheng, Yuhan Wu, Wei Hu |  |
| 551 |  |  [Chain-of-Exemplar: Enhancing Distractor Generation for Multimodal Educational Question Generation](https://doi.org/10.18653/v1/2024.acl-long.432) |  | 0 | Multiple-choice questions (MCQs) are important in enhancing concept learning and student engagement for educational purposes. Despite the multimodal nature of educational content, current methods focus mainly on text-based inputs and often neglect the integration of visual information. In this work, we study the problem of multimodal educational question generation, which aims at generating subject-specific educational questions with plausible yet incorrect distractors based on multimodal... | Haohao Luo, Yang Deng, Ying Shen, SeeKiong Ng, TatSeng Chua |  |
| 552 |  |  [LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification](https://doi.org/10.18653/v1/2024.acl-long.433) |  | 0 | With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly researched in various research areas. Recently, many attempts based on prompt-learning have been made to improve the performance of text classification. However, most of these methods are based on heuristic Chain-of-Thought (CoT), and tend to be more complex but less efficient. In this paper, we rethink the LLM-based text classification methodology, propose a simple and effective transfer... | ChunLiu ChunLiu, Hongguang Zhang, Kainan Zhao, Xinghai Ju, Lin Yang |  |
| 553 |  |  [LEMON: Reviving Stronger and Smaller LMs from Larger LMs with Linear Parameter Fusion](https://doi.org/10.18653/v1/2024.acl-long.434) |  | 0 | In the new era of language models, small models (with billions of parameter sizes) are receiving increasing attention due to their flexibility and cost-effectiveness in deployment. However, limited by the model size, the performance of small models trained from scratch may often be unsatisfactory. Learning a stronger and smaller model with the help of larger models is an intuitive idea. Inspired by the observing modular structures in preliminary analysis, we propose LEMON to learn competent... | Yilong Chen, Junyuan Shang, Zhenyu Zhang, Shiyao Cui, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu |  |
| 554 |  |  [Speech Sense Disambiguation: Tackling Homophone Ambiguity in End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.435) |  | 0 | End-to-end speech translation (ST) presents notable disambiguation challenges as it necessitates simultaneous cross-modal and cross-lingual transformations. While word sense disambiguation is an extensively investigated topic in textual machine translation, the exploration of disambiguation strategies for ST models remains limited. Addressing this gap, this paper introduces the concept of speech sense disambiguation (SSD), specifically emphasizing homophones - words pronounced identically but... | Tengfei Yu, Xuebo Liu, Liang Ding, Kehai Chen, Dacheng Tao, Min Zhang |  |
| 555 |  |  [To be Continuous, or to be Discrete, Those are Bits of Questions](https://doi.org/10.18653/v1/2024.acl-long.436) |  | 0 | Recently, binary representation has been proposed as a novel representation that lies between continuous and discrete representations. It exhibits considerable information-preserving capability when being used to replace continuous input vectors. In this paper, we investigate the feasibility of further introducing it to the output side, aiming to allow models to output binary labels instead. To preserve the structural information on the output side along with label information, we extend the... | Yiran Wang, Masao Utiyama |  |
| 556 |  |  [Moûsai: Efficient Text-to-Music Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.437) |  | 0 | Recent years have seen the rapid development of large generative models for text; however, much less research has explored the connection between text and another “language” of communication – music. Music, much like text, can convey emotions, stories, and ideas, and has its own unique structure and syntax. In our work, we bridge text and music via a text-to-music generation model that is highly efficient, expressive, and can handle long-term structure. Specifically, we develop Moûsai, a... | Flavio Schneider, Ojasv Kamal, Zhijing Jin, Bernhard Schölkopf |  |
| 557 |  |  [PokeMQA: Programmable knowledge editing for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.438) |  | 0 | Multi-hop question answering (MQA) is one of the challenging tasks to evaluate machine’s comprehension and reasoning abilities, where large language models (LLMs) have widely achieved the human-comparable performance. Due to the dynamics of knowledge facts in real world, knowledge editing has been explored to update model with the up-to-date facts while avoiding expensive re-training or fine-tuning. Starting from the edited fact, the updated model needs to provide cascading changes in the chain... | Hengrui Gu, Kaixiong Zhou, Xiaotian Han, Ninghao Liu, Ruobing Wang, Xin Wang |  |
| 558 |  |  [MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention](https://doi.org/10.18653/v1/2024.acl-long.439) |  | 0 | In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content, neglecting the widespread influence of multimodal content like memes. Addressing this gap, we present MemeGuard, a comprehensive framework leveraging Large Language Models (LLMs) and Visual Language Models... | Prince Jha, Raghav Jain, Konika Mandal, Aman Chadha, Sriparna Saha, Pushpak Bhattacharyya |  |
| 559 |  |  [Efficient OCR for Building a Diverse Digital History](https://doi.org/10.18653/v1/2024.acl-long.440) |  | 0 | Many users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) – which jointly learns a vision and language model – is poorly extensible to low-resource document collections, as learning a language-vision model requires extensive labeled sequences and compute. This study models OCR as a character level image retrieval problem,... | Jacob Carlson, Tom Bryan, Melissa Dell |  |
| 560 |  |  [Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space](https://doi.org/10.18653/v1/2024.acl-long.441) |  | 0 | Despite the notable success of language models (LMs) in various natural language processing (NLP) tasks, the reliability of LMs is susceptible to backdoor attacks. Prior research attempts to mitigate backdoor learning while training the LMs on the poisoned dataset, yet struggles against complex backdoor attacks in real-world scenarios. In this paper, we investigate the learning mechanisms of backdoor LMs in the frequency space by Fourier analysis. Our findings indicate that the backdoor mapping... | Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu |  |
| 561 |  |  [ANAH: Analytical Annotation of Hallucinations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.442) |  | 0 | Reducing the ‘hallucination' problem of Large Language Models (LLMs) is crucial for their wide applications. A comprehensive and fine-grained measurement of the hallucination is the first key step for the governance of this issue but is under-explored in the community.Thus, we present ANAH, a bilingual dataset that offers ANalytical Annotation of Hallucinations in LLMs within Generative Question Answering.Each answer sentence in our dataset undergoes rigorous annotation, involving the retrieval... | Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen |  |
| 562 |  |  [Aligning Large Language Models for Controllable Recommendations](https://doi.org/10.18653/v1/2024.acl-long.443) |  | 0 | Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems — systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy using a fixed task template, often overlooking the diversity of recommendation tasks and the ability of LLMs to follow... | Wensheng Lu, Jianxun Lian, Wei Zhang, Guanghua Li, Mingyang Zhou, Hao Liao, Xing Xie |  |
| 563 |  |  [Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods](https://doi.org/10.18653/v1/2024.acl-long.444) |  | 0 | Language Models (LMs) acquire parametric knowledge from their training process, embedding it within their weights. The increasing scalability of LMs, however, poses significant challenges for understanding a model’s inner workings and further for updating or correcting this embedded knowledge without the significant cost of retraining. This underscores the importance of unveiling exactly what knowledge is stored and its association with specific model components. Instance Attribution (IA) and... | Haeun Yu, Pepa Atanasova, Isabelle Augenstein |  |
| 564 |  |  [Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://doi.org/10.18653/v1/2024.acl-long.445) |  | 0 | Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have focused on parameter-efficient fine-tuning, which tunes or adds a small number of parameters, few have addressed the challenge of tuning the full parameters of LLMs with limited resources. In this work,... | Kai Lv, Yuqing Yang, Tengxiao Liu, Qipeng Guo, Xipeng Qiu |  |
| 565 |  |  [M³CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.446) |  | 0 | Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge from both textual and visual modalities for step-by-step reasoning, which gains increasing attention. Nevertheless, the current MCoT benchmark still faces some challenges: (1) absence of visual modal reasoning, (2) single-step visual modal reasoning, and (3) domain missing, thereby hindering the development of MCoT. Motivated by this, we introduce a novel benchmark (M3CoT) to address the above challenges, advancing the... | Qiguang Chen, Libo Qin, Jin Zhang, Zhi Chen, Xiao Xu, Wanxiang Che |  |
| 566 |  |  [Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.447) |  | 0 | Long-context modeling capabilities are important for large language models (LLMs) in various applications. However, directly training LLMs with long context windows is insufficient to enhance this capability since some training samples do not exhibit strong semantic dependencies across long contexts.In this study, we propose a data mining framework ProLong that can assign each training sample with a long dependency score, which can be used to rank and filter samples that are more advantageous... | Longze Chen, Ziqiang Liu, Wanwei He, Yinhe Zheng, Hao Sun, Yunshui Li, Run Luo, Min Yang |  |
| 567 |  |  [Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.448) |  | 0 | While the neural transducer is popular for online speech recognition, simultaneous speech translation (SST) requires both streaming and re-ordering capabilities. This paper presents the LS-Transducer-SST, a label-synchronous neural transducer for SST, which naturally possesses these two properties. The LS-Transducer-SST dynamically decides when to emit translation tokens based on an Auto-regressive Integrate-and-Fire (AIF) mechanism. A latency-controllable AIF is also proposed, which can... | Keqi Deng, Philip C. Woodland |  |
| 568 |  |  [Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL](https://doi.org/10.18653/v1/2024.acl-long.449) |  | 0 | With the advent of foundation models, prompt tuning has positioned itself as an important technique for directing model behaviors and eliciting desired responses. Prompt tuning regards selecting appropriate keywords included into the input, thereby adapting to the downstream task without adjusting or fine-tuning the model parameters. There is a wide range of work in prompt tuning, from approaches that directly harness the backpropagated gradient signals from the model, to those employing... | Yunseon Choi, Sangmin Bae, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang Bian, KeeEung Kim |  |
| 569 |  |  [A Modular Approach for Multimodal Summarization of TV Shows](https://doi.org/10.18653/v1/2024.acl-long.450) |  | 0 | In this paper we address the task of summarizing television shows, which touches key areas in AI research: complex reasoning, multiple modalities, and long narratives. We present a modular approach where separate components perform specialized sub-tasks which we argue affords greater flexibility compared to end-to-end methods. Our modules involve detecting scene boundaries, reordering scenes so as to minimize the number of cuts between different events, converting visual information to text,... | Louis Mahon, Mirella Lapata |  |
| 570 |  |  [Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities](https://doi.org/10.18653/v1/2024.acl-long.451) |  | 0 | Human interactions are deeply rooted in the interplay of thoughts, beliefs, and desires made possible by Theory of Mind (ToM): our cognitive ability to understand the mental states of ourselves and others. Although ToM may come naturally to us, emulating it presents a challenge to even the most advanced Large Language Models (LLMs). Recent improvements to LLMs’ reasoning capabilities from simple yet effective prompting techniques such as Chain-of-Thought (CoT) have seen limited applicability to... | Alex Wilf, Sihyun Shawn Lee, Paul Pu Liang, LouisPhilippe Morency |  |
| 571 |  |  [BizBench: A Quantitative Reasoning Benchmark for Business and Finance](https://doi.org/10.18653/v1/2024.acl-long.452) |  | 0 | Answering questions within business and finance requires reasoning, precision, and a wide-breadth of technical knowledge. Together, these requirements make this domain difficult for large language models (LLMs). We introduce BizBench, a benchmark for evaluating models’ ability to reason about realistic financial problems. BizBench comprises eight quantitative reasoning tasks, focusing on question-answering (QA) over financial data via program synthesis. We include three financially-themed... | Michael Krumdick, Rik KoncelKedziorski, Viet Dac Lai, Varshini Reddy, Charles Lovering, Chris Tanner |  |
| 572 |  |  [Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization](https://doi.org/10.18653/v1/2024.acl-long.453) |  | 0 | While image captioning is an essential field of vision language models (VLM), a lack of continuity between the learning objective and final performance metrics of VLMs complicates their training and optimization. Reinforcement learning (RL) can directly optimize such metrics, but it is accompanied by a significant computational cost, making it difficult to apply to recent large-scale VLMs. In this paper, we propose Direct Metric Optimization (DMO), which is a lightweight final-metric-optimizing... | Takumi Takada, Yuma Suzuki, Hiroki Takushima, Hayato Tanoue, Haruki Sato, Aiswariya Manoj Kumar, Hiroki Nishihara, Takayuki Hori, Kazuya Ueki |  |
| 573 |  |  [Deciphering Hate: Identifying Hateful Memes and Their Targets](https://doi.org/10.18653/v1/2024.acl-long.454) |  | 0 | Internet memes have become a powerful means for individuals to express emotions, thoughts, and perspectives on social media. While often considered as a source of humor and entertainment, memes can also disseminate hateful content targeting individuals or communities. Most existing research focuses on the negative aspects of memes in high-resource languages, overlooking the distinctive challenges associated with low-resource languages like Bengali (also known as Bangla). Furthermore, while... | Eftekhar Hossain, Omar Sharif, Mohammed Moshiul Hoque, Sarah Masud Preum |  |
| 574 |  |  [Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings](https://doi.org/10.18653/v1/2024.acl-long.455) |  | 0 | Transformers generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes structurally equivalent sentences using a systematic attention pattern. Inspired by this observation, we propose SQ-Transformer (Structurally Quantized) that explicitly encourages systematicity in the embeddings and attention layers even with... | Yichen Jiang, Xiang Zhou, Mohit Bansal |  |
| 575 |  |  [Label-Efficient Model Selection for Text Generation](https://doi.org/10.18653/v1/2024.acl-long.456) |  | 0 | Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models based on preference annotations. DiffUse reduces the required amount of annotations, thus saving valuable time and resources in performing evaluation.DiffUse intelligently selects instances by clustering embeddings that represent the semantic... | Shir AshuryTahan, Ariel Gera, Benjamin Sznajder, Leshem Choshen, Liat EinDor, Eyal Shnarch |  |
| 576 |  |  [Machine Unlearning of Pre-trained Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.457) |  | 0 | This study investigates the concept of the ‘right to be forgotten’ within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models–a notably under-researched area. Our research delineates a comprehensive framework for machine unlearning in pre-trained LLMs, encompassing a critical analysis of seven diverse unlearning methods. Through rigorous evaluation using curated datasets from arXiv, books, and GitHub, we establish... | Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue |  |
| 577 |  |  [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://doi.org/10.18653/v1/2024.acl-long.458) |  | 0 | Interpretability research aims to bridge the gap between the empirical success and our scientific understanding of the inner workings of large language models (LLMs). However, most existing research in this area focused on analyzing a single mechanism, such as how models copy or recall factual knowledge. In this work, we propose the formulation of competition of mechanisms, which instead of individual mechanisms focuses on the interplay of multiple mechanisms, and traces how one of them becomes... | Francesco Ortu, Zhijing Jin, Diego Doimo, Mrinmaya Sachan, Alberto Cazzaniga, Bernhard Schölkopf |  |
| 578 |  |  [FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence](https://doi.org/10.18653/v1/2024.acl-long.459) |  | 0 | Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment. FactPICO consists of 345 plain language summaries of RCT abstracts... | Sebastian Joseph, Lily Chen, Jan Trienes, Hannah Louisa Göke, Monika Coers, Wei Xu, Byron C. Wallace, Junyi Jessy Li |  |
| 579 |  |  [BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.460) |  | 0 | Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based elements, including aspect term, opinion term, aspect category, and sentiment polarity. In practice, unseen aspects, due to distinct data distribution, impose many challenges for a trained neural model. Motivated by this, this work formulates ASQP into the few-shot scenario, which aims for fast adaptation in real applications. Therefore, we first construct a few-shot ASQP dataset (FSQP) that contains richer categories and... | Yinhao Bai, Yalan Xie, Xiaoyi Liu, Yuhua Zhao, Zhixin Han, Mengting Hu, Hang Gao, Renhong Cheng |  |
| 580 |  |  [Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack](https://doi.org/10.18653/v1/2024.acl-long.461) |  | 0 | Recent developments in balancing the usefulness and safety of Large Language Models (LLMs) have raised a critical question: Are mainstream NLP tasks adequately aligned with safety consideration? Our study, focusing on safety-sensitive documents obtained through adversarial attacks, reveals significant disparities in the safety alignment of various NLP tasks. For instance, LLMs can effectively summarize malicious long documents but often refuse to translate them. This discrepancy highlights a... | Yu Fu, Yufei Li, Wen Xiao, Cong Liu, Yue Dong |  |
| 581 |  |  [Speech language models lack important brain-relevant semantics](https://doi.org/10.18653/v1/2024.acl-long.462) |  | 0 | Despite known differences between reading and listening in the brain, recent work has shown that text-based language models predict both text-evoked and speech-evoked brain activity to an impressive degree. This poses the question of what types of information language models truly predict in the brain. We investigate this question via a direct approach, in which we systematically remove specific low-level stimulus features (textual, speech, and visual) from language model representations to... | Subba Reddy Oota, Emin Çelik, Fatma Deniz, Mariya Toneva |  |
| 582 |  |  [DocLLM: A Layout-Aware Generative Language Model for Multimodal Document Understanding](https://doi.org/10.18653/v1/2024.acl-long.463) |  | 0 | Enterprise documents such as forms, receipts, reports, and other such records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs... | Dongsheng Wang, Natraj Raman, Mathieu Sibue, Zhiqiang Ma, Petr Babkin, Simerjot Kaur, Yulong Pei, Armineh Nourbakhsh, Xiaomo Liu |  |
| 583 |  |  [Bypassing LLM Watermarks with Color-Aware Substitutions](https://doi.org/10.18653/v1/2024.acl-long.464) |  | 0 | Watermarking approaches are proposed to identify if text being circulated is human- or large language model- (LLM) generated. The state-of-the-art watermarking strategy of Kirchenbauer et al. (2023a) biases the LLM to generate specific (“green”) tokens. However, determining the robustness of this watermarking method under finite (low) edit budgets is an open problem. Additionally, existing attack methods failto evade detection for longer text segments. We overcome these limitations, and propose... | Qilong Wu, Varun Chandrasekaran |  |
| 584 |  |  [Parallel Structures in Pre-training Data Yield In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.465) |  | 0 | Pre-trained language models (LMs) are capable of in-context learning (ICL): they can adapt to a task with only a few examples given in the prompt without any parameter update. However, it is unclear where this capability comes from as there is a stark distribution shift between pre-training text and ICL prompts. In this work, we study what patterns of the pre-training data contribute to ICL. We find that LMs’ ICL ability depends on parallel structures in the pre-training data—pairs of phrases... | Yanda Chen, Chen Zhao, Zhou Yu, Kathleen R. McKeown, He He |  |
| 585 |  |  [OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.466) |  | 0 | Neural Theory-of-Mind (N-ToM), machine’s ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence of personality traits and preferences, a lack of questions addressing characters’ psychological mental states, and limited diversity in the questions posed. In response to these issues, we construct... | Hainiu Xu, Runcong Zhao, Lixing Zhu, Jinhua Du, Yulan He |  |
| 586 |  |  [Towards Privacy-Aware Sign Language Translation at Scale](https://doi.org/10.18653/v1/2024.acl-long.467) |  | 0 | A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much of the sign language data currently available on the web cannot be used for training supervised models due to the lack of aligned captions. Furthermore, scaling SLT using large-scale web-scraped datasets bears privacy risks due to the presence of biometric information, which the responsible development of SLT technologies should account for. In this work, we propose a two-stage framework for... | Phillip Rust, Bowen Shi, Skyler Wang, Necati Cihan Camgöz, Jean Maillard |  |
| 587 |  |  [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://doi.org/10.18653/v1/2024.acl-long.468) |  | 0 | Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates... | Haoxiang Wang, Yong Lin, Wei Xiong, Rui Yang, Shizhe Diao, Shuang Qiu, Han Zhao, Tong Zhang |  |
| 588 |  |  [Towards Real-World Writing Assistance: A Chinese Character Checking Benchmark with Faked and Misspelled Characters](https://doi.org/10.18653/v1/2024.acl-long.469) |  | 0 | Writing assistance aims to improve the correctness and quality of input texts, with character checking being crucial in detecting and correcting wrong characters. In the real world where handwriting occupies the vast majority, characters that humans get wrong include faked characters (i.e., untrue characters created due to writing errors) and misspelled characters (i.e., true characters used incorrectly due to spelling errors). However, existing datasets and related studies only focus on... | Yinghui Li, Zishan Xu, Shaoshen Chen, Haojing Huang, Yangning Li, Shirong Ma, Yong Jiang, Zhongli Li, Qingyu Zhou, HaiTao Zheng, Ying Shen |  |
| 589 |  |  [RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations](https://doi.org/10.18653/v1/2024.acl-long.470) |  | 0 | Individual neurons participate in the representation of multiple high-level concepts. To what extent can different interpretability methods successfully disentangle these roles? To help address this question, we introduce RAVEL (Resolving Attribute-Value Entanglements in Language Models), a dataset that enables tightly controlled, quantitative comparisons between a variety of existing interpretability methods. We use the resulting conceptual framework to define the new method of Multi-task... | Jing Huang, Zhengxuan Wu, Christopher Potts, Mor Geva, Atticus Geiger |  |
| 590 |  |  [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://doi.org/10.18653/v1/2024.acl-long.471) |  | 0 | Large language models (LLMs) are increasingly prevalent in conversational systems due to their advanced understanding and generative capabilities in general contexts. However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective dialogue state tracking (DST) within specific tasks and domains, remains less satisfying. In this work, we propose a novel approach FnCTOD for solving DST with LLMs through function calling. This method... | Zekun Li, Zhiyu Chen, Mike Ross, Patrick Huber, Seungwhan Moon, Zhaojiang Lin, Xin Dong, Adithya Sagar, Xifeng Yan, Paul A. Crook |  |
| 591 |  |  [Faithful Chart Summarization with ChaTS-Pi](https://doi.org/10.18653/v1/2024.acl-long.472) |  | 0 | Chart-to-summary generation can help explore data, communicate insights, and help the visually impaired people. Multi-modal generative models have been used to produce fluent summaries, but they can suffer from factual and perceptual errors. In this work we present CHATS-CRITIC, a reference-free chart summarization metric for scoring faithfulness. CHATS-CRITIC is composed of an image-to-text model to recover the table from a chart, and a tabular entailment model applied to score the summary... | Syrine Krichene, Francesco Piccinno, Fangyu Liu, Julian Eisenschlos |  |
| 592 |  |  [Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation](https://doi.org/10.18653/v1/2024.acl-long.473) |  | 0 | Dialogue State Tracking (DST) is designed to monitor the evolving dialogue state in the conversations and plays a pivotal role in developing task-oriented dialogue systems. However, obtaining the annotated data for the DST task is usually a costly endeavor. In this paper, we focus on employing LLMs to generate dialogue data to reduce dialogue collection and annotation costs. Specifically, GPT-4 is used to simulate the user and agent interaction, generating thousands of dialogues annotated with... | Cheng Niu, Xingguang Wang, Xuxin Cheng, Juntong Song, Tong Zhang |  |
| 593 |  |  [MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.474) |  | 0 | Fact-checking real-world claims often requires reviewing multiple multimodal documents in order to assess the claim’s truthfulness, a highly laborious and time-consuming task. In this paper, we present a summarization model crafted to generate claim-specific summaries useful for fact-checking from multimodal multi-document datasets. The model takes inputs in the form of documents, images, and a claim, with the objective of assisting in fact-checking tasks. We introduce a dynamic perceiver-based... | TingChih Chen, ChiaWei Tang, Chris Thomas |  |
| 594 |  |  [KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction](https://doi.org/10.18653/v1/2024.acl-long.475) |  | 0 |  | Zixuan Li, Yutao Zeng, Yuxin Zuo, Weicheng Ren, Wenxuan Liu, Miao Su, Yucan Guo, Yantao Liu, Xiang Li, Zhilei Hu, Long Bai, Wei Li, Yidan Liu, Pan Yang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng |  |
| 595 |  |  [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](https://doi.org/10.18653/v1/2024.acl-long.476) |  | 0 | Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. These challenges arise from the presence of implicit relationships that demand multi-step reasoning. In this paper, we propose a novel approach ERA-CoT, which aids LLMs in understanding context by capturing relationships between entities and supports the reasoning... | Yanming Liu, Xinyue Peng, Tianyu Du, Jianwei Yin, Weihao Liu, Xuhong Zhang |  |
| 596 |  |  [On the Multi-turn Instruction Following for Conversational Web Agents](https://doi.org/10.18653/v1/2024.acl-long.477) |  | 0 | Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates... | Yang Deng, Xuan Zhang, Wenxuan Zhang, Yifei Yuan, SeeKiong Ng, TatSeng Chua |  |
| 597 |  |  [Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](https://doi.org/10.18653/v1/2024.acl-long.478) |  | 0 | With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research hotspot in human-computer interaction.However, there is a scarcity of benchmarks available for LLM-based mobile agents.Benchmarking these agents generally faces three main challenges:(1) The inefficiency of UI-only operations imposes limitations to task evaluation.(2) Specific instructions within a singular application lack adequacy for assessing the multi-dimensional reasoning and... | Shihan Deng, Weikai Xu, Hongda Sun, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Rui Yan, Shuo Shang |  |
| 598 |  |  [MC²: Towards Transparent and Culturally-Aware NLP for Minority Languages in China](https://doi.org/10.18653/v1/2024.acl-long.479) |  | 0 | Current large language models demonstrate deficiencies in understanding low-resource languages, particularly the minority languages in China. This limitation stems from the scarcity of available pre-training data. To address this accessibility challenge, we present MC2, a Multilingual Corpus of Minority Languages in China, which is the largest open-source corpus of its kind so far. MC2 includes four underrepresented languages: Tibetan, Uyghur, Kazakh, and Mongolian. Notably, we focus on the... | Chen Zhang, Mingxu Tao, Quzhe Huang, Jiuheng Lin, Zhibin Chen, Yansong Feng |  |
| 599 |  |  [Decoder-only Streaming Transformer for Simultaneous Translation](https://doi.org/10.18653/v1/2024.acl-long.480) |  | 0 | Simultaneous Machine Translation (SiMT) generates translation while reading source tokens, essentially producing the target prefix based on the source prefix. To achieve good performance, it leverages the relationship between source and target prefixes to exact a policy to guide the generation of translations. Although existing SiMT methods primarily focus on the Encoder-Decoder architecture, we explore the potential of Decoder-only architecture, owing to its superior performance in various... | Shoutao Guo, Shaolei Zhang, Yang Feng |  |
| 600 |  |  [Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization](https://doi.org/10.18653/v1/2024.acl-long.481) |  | 0 | While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of effort in defending against these attacks. We point out a pivotal factor contributing to the success of jailbreaks: the intrinsic conflict between the goals of being helpful and ensuring safety. Accordingly, we propose to integrate goal prioritization at both training and inference stages to counteract. Implementing goal prioritization during inference... | Zhexin Zhang, Junxiao Yang, Pei Ke, Fei Mi, Hongning Wang, Minlie Huang |  |
| 601 |  |  [I am a Strange Dataset: Metalinguistic Tests for Language Models](https://doi.org/10.18653/v1/2024.acl-long.482) |  | 0 | Statements involving metalinguistic self-reference (“This paper has six sections.”) are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present “I am a Strange Dataset”, a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like “The penultimate word in this sentence is” (where a correct continuation is “is”). In verification, models judge the truth of... | Tristan Thrush, Jared Moore, Miguel Monares, Christopher Potts, Douwe Kiela |  |
| 602 |  |  [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](https://doi.org/10.18653/v1/2024.acl-long.483) |  | 0 | Large Language Models (LLMs) sometimes suffer from producing hallucinations, especially LLMs may generate untruthful responses despite knowing the correct knowledge. Activating the truthfulness within LLM is the key to fully unlocking LLM’s knowledge potential. In this paper, we propose TruthX, an inference-time intervention method to activate the truthfulness of LLM by identifying and editing the features within LLM’s internal representations that govern the truthfulness. TruthX employs an... | Shaolei Zhang, Tian Yu, Yang Feng |  |
| 603 |  |  [ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.484) |  | 0 | We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of proteins. Besides, we propose the protein-as-word language modeling approach to train ProtLLM. By developing a specialized protein vocabulary, we equip the model with the capability to predict not... | Le Zhuo, Zewen Chi, Minghao Xu, Heyan Huang, Jianan Zhao, Heqi Zheng, Conghui He, XianLing Mao, Wentao Zhang |  |
| 604 |  |  [StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning](https://doi.org/10.18653/v1/2024.acl-long.485) |  | 0 | Simultaneous speech-to-speech translation (Simul-S2ST, a.k.a streaming speech translation) outputs target speech while receiving streaming speech inputs, which is critical for real-time communication. Beyond accomplishing translation between speech, Simul-S2ST requires a policy to control the model to generate corresponding target speech at the opportune moment within speech inputs, thereby posing a double challenge of translation and policy. In this paper, we propose StreamSpeech, a direct... | Shaolei Zhang, Qingkai Fang, Shoutao Guo, Zhengrui Ma, Min Zhang, Yang Feng |  |
| 605 |  |  [Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.486) |  | 0 | Recent work has showcased the powerful capability of large language models (LLMs) in recalling knowledge and reasoning. However, the reliability of LLMs in combining these two capabilities into reasoning through multi-hop facts has not been widely explored. This paper systematically investigates the possibilities for LLMs to utilize shortcuts based on direct connections between the initial and terminal entities of multi-hop knowledge. We first explore the existence of factual shortcuts through... | Tianjie Ju, Yijin Chen, Xinwei Yuan, Zhuosheng Zhang, Wei Du, Yubin Zheng, Gongshen Liu |  |
| 606 |  |  [Why Don't Prompt-Based Fairness Metrics Correlate?](https://doi.org/10.18653/v1/2024.acl-long.487) |  | 0 | The widespread use of large language models has brought up essential questions about the potential biases these models might learn. This led to the development of several metrics aimed at evaluating and mitigating these biases. In this paper, we first demonstrate that prompt-based fairness metrics exhibit poor agreement, as measured by correlation, raising important questions about the reliability of fairness assessment using prompts. Then, we outline six relevant reasons why such a low... | Abdelrahman Zayed, Gonçalo Mordido, Ioana Baldini, Sarath Chandar |  |
| 607 |  |  [NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data](https://doi.org/10.18653/v1/2024.acl-long.488) |  | 0 | To address the global issue of online hate, hate speech detection (HSD) systems are typically developed on datasets from the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on non-representative samples, raising concerns about overestimating model performance in real-world settings. In this work, we introduce NaijaHate, the first dataset annotated for HSD which contains a representative sample of Nigerian... | Manuel Tonneau, Pedro Vitor Quinta de Castro, Karim Lasri, Ibrahim Farouq, Lakshmi Subramanian, Víctor OrozcoOlvera, Samuel Fraiberger |  |
| 608 |  |  [M³AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset](https://doi.org/10.18653/v1/2024.acl-long.489) |  | 0 | Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the papers. Although multiple academic video datasets have been constructed and released, few of them support both multimodal content recognition and understanding tasks, which is partially due to the lack... | Zhe Chen, Heyang Liu, Wenyi Yu, Guangzhi Sun, Hongcheng Liu, Ji Wu, Chao Zhang, Yu Wang, Yanfeng Wang |  |
| 609 |  |  [Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination](https://doi.org/10.18653/v1/2024.acl-long.490) |  | 0 | Instruction-following language models often show undesirable biases. These undesirable biases may be accelerated in the real-world usage of language models, where a wide range of instructions is used through zero-shot example prompting. To solve this problem, we first define the bias neuron, which significantly affects biased outputs, and prove its existence empirically. Furthermore, we propose a novel and practical bias mitigation method, CRISPR, to eliminate bias neurons of language models in... | Nakyeong Yang, Taegwan Kang, Stanley Jungkyu Choi, Honglak Lee, Kyomin Jung |  |
| 610 |  |  [Domain Adaptation for Subjective Induction Questions Answering on Products by Adversarial Disentangled Learning](https://doi.org/10.18653/v1/2024.acl-long.491) |  | 0 | This paper focuses on answering subjective questions about products. Different from the factoid question with a single answer span, this subjective one involves multiple viewpoints. For example, the question of ‘how the phone’s battery is?’ not only involves facts of battery capacity but also contains users’ opinions on the battery’s pros and cons. A good answer should be able to integrate these heterogeneous and even inconsistent viewpoints, which is formalized as a subjective induction QA... | Yufeng Zhang, Jianxing Yu, Yanghui Rao, Libin Zheng, Qinliang Su, Huaijie Zhu, Jian Yin |  |
| 611 |  |  [Revisiting Demonstration Selection Strategies in In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.492) |  | 0 | Large language models (LLMs) have shown an impressive ability to perform a wide range of tasks using in-context learning (ICL), where a few examples are used to describe a task to the model. However, the performance of ICL varies significantly with the choice of demonstrations, and previous research usually focuses on the data aspect ignoring the model’s effect. In this work, we first revisit the factors contributing to this variance from the model aspect, and find that the demonstration choice... | Keqin Peng, Liang Ding, Yancheng Yuan, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao |  |
| 612 |  |  [Multimodal Table Understanding](https://doi.org/10.18653/v1/2024.acl-long.493) |  | 0 | Although great progress has been made by previous table understanding methods including recent approaches based on large language models (LLMs), they rely heavily on the premise that given tables must be converted into a certain text sequence (such as Markdown or HTML) to serve as model input. However, it is difficult to access such high-quality textual table representations in some real-world scenarios, and table images are much more accessible. Therefore, how to directly understand tables... | Mingyu Zheng, Xinwei Feng, Qingyi Si, Qiaoqiao She, Zheng Lin, Wenbin Jiang, Weiping Wang |  |
| 613 |  |  [Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding](https://doi.org/10.18653/v1/2024.acl-long.494) |  | 0 | Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length, they exhibit poor logical coherence and appeal in their plots and deficiencies in character and event depiction, ultimately compromising the overall narrative quality. In this paper, we propose a... | Huang Lei, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen |  |
| 614 |  |  [Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.495) |  | 0 | Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled training dataset is available in a source domain. We propose a novel KBQA architecture called FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers, re-ranks using an LLM and uses... | Mayur Patidar, Riya Sawhney, Avinash Kumar Singh, Biswajit Chatterjee, Mausam, Indrajit Bhattacharya |  |
| 615 |  |  [WatME: Towards Lossless Watermarking Through Lexical Redundancy](https://doi.org/10.18653/v1/2024.acl-long.496) |  | 0 | Text watermarking has emerged as a pivotal technique for identifying machine-generated text. However, existing methods often rely on arbitrary vocabulary partitioning during decoding to embed watermarks, which compromises the availability of suitable tokens and significantly degrades the quality of responses. This study assesses the impact of watermarking on different capabilities of large language models (LLMs) from a cognitive science lens. Our finding highlights a significant disparity;... | Liang Chen, Yatao Bian, Yang Deng, Deng Cai, Shuaiyi Li, Peilin Zhao, KamFai Wong |  |
| 616 |  |  [Text-like Encoding of Collaborative Information in Large Language Models for Recommendation](https://doi.org/10.18653/v1/2024.acl-long.497) |  | 0 | When adapting Large Language Models for Recommendation (LLMRec), it is crucial to integrate collaborative information. Existing methods achieve this by learning collaborative embeddings in LLMs’ latent space from scratch or by mapping from external models. However, they fail to represent the information in a text-like format, which may not align optimally with LLMs. To bridge this gap, we introduce BinLLM, a novel LLMRec method that seamlessly integrates collaborative information through... | Yang Zhang, Keqin Bao, Ming Yan, Wenjie Wang, Fuli Feng, Xiangnan He |  |
| 617 |  |  [MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception](https://doi.org/10.18653/v1/2024.acl-long.498) |  | 0 | Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially due to the models’ struggle with understanding what they can and cannot perceive from images, a capability we refer to as self-awareness in perception. Despite its importance, this aspect of MLLMs has... | Yuhao Wang, Yusheng Liao, Heyang Liu, Hongcheng Liu, Yanfeng Wang, Yu Wang |  |
| 618 |  |  [Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.499) |  | 0 | Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT). However, we find these CoT-like methods lead to a considerable number of originally correct answers turning wrong, which we define as the Toxic CoT problem. To interpret and mitigate this problem, we first utilize attribution tracing and causal tracing methods to probe the internal working mechanism of the LLM during CoT reasoning. Through comparisons, we... | Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao |  |
| 619 |  |  [Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation](https://doi.org/10.18653/v1/2024.acl-long.500) |  | 0 | Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects (e.g., “positive” from sentiment and “sport” from topic). Existing works neglect attribute correlations formed by the intertwining of different attributes. Particularly, the stereotype formed by imbalanced attribute correlations significantly affects multi-aspect control. In this paper, we propose MAGIC, a new multi-aspect controllable text generation method with disentangled... | Yi Liu, Xiangyu Liu, Xiangrong Zhu, Wei Hu |  |
| 620 |  |  [Reward-based Input Construction for Cross-document Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.501) |  | 0 | Relation extraction (RE) is a fundamental task in natural language processing, aiming to identify relations between target entities in text. While many RE methods are designed for a single sentence or document, cross-document RE has emerged to address relations across multiple long documents. Given the nature of long documents in cross-document RE, extracting document embeddings is challenging due to the length constraints of pre-trained language models. Therefore, we propose REward-based Input... | Byeonghu Na, Suhyeon Jo, Yeongmin Kim, IlChul Moon |  |
| 621 |  |  [Hyperspherical Multi-Prototype with Optimal Transport for Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.502) |  | 0 | Event Argument Extraction (EAE) aims to extract arguments for specified events from a text. Previous research has mainly focused on addressing long-distance dependencies of arguments, modeling co-occurrence relationships between roles and events, but overlooking potential inductive biases: (i) semantic differences among arguments of the same type and (ii) large margin separation between arguments of the different types. Inspired by prototype networks, we introduce a new model named HMPEAE,... | Guangjun Zhang, Hu Zhang, Yujie Wang, Ru Li, Hongye Tan, Jiye Liang |  |
| 622 |  |  [Understanding Retrieval Robustness for Retrieval-augmented Image Captioning](https://doi.org/10.18653/v1/2024.acl-long.503) |  | 0 | Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far from perfect in practice: the retrieved information can sometimes mislead the model, resulting in incorrect generation and worse performance. In this paper, we analyze the robustness of a... | Wenyan Li, Jiaang Li, Rita Ramos, Raphael Tang, Desmond Elliott |  |
| 623 |  |  [Semi-Supervised Spoken Language Glossification](https://doi.org/10.18653/v1/2024.acl-long.504) |  | 0 | Spoken language glossification (SLG) aims to translate the spoken language text into the sign language gloss, i.e., a written record of sign language. In this work, we present a framework named Semi-Supervised Spoken Language Glossification (S3LG) for SLG. To tackle the bottleneck of limited parallel data in SLG, our S3LG incorporates large-scale monolingual spoken language text into SLG training. The proposed framework follows the self-training structure that iteratively annotates and learns... | Huijie Yao, Wengang Zhou, Hao Zhou, Houqiang Li |  |
| 624 |  |  [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents](https://doi.org/10.18653/v1/2024.acl-long.505) |  | 0 | Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a novel visual GUI agent – SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key... | Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang, Zhiyong Wu |  |
| 625 |  |  [InterrogateLLM: Zero-Resource Hallucination Detection in LLM-Generated Answers](https://doi.org/10.18653/v1/2024.acl-long.506) |  | 0 | Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where LLMs invent answers that sound realistic, yet drift away from factual truth. In this paper, we present a novel method for detecting hallucinations in large language models, which tackles a critical... | Yakir Yehuda, Itzik Malkiel, Oren Barkan, Jonathan Weill, Royi Ronen, Noam Koenigstein |  |
| 626 |  |  [F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods](https://doi.org/10.18653/v1/2024.acl-long.507) |  | 0 | Large language models (LLMs) garner significant attention for their unprecedented performance, leading to an increasing number of researches evaluating LLMs. However, these evaluation benchmarks are limited to assessing the instruction-following capabilities, overlooking the fundamental abilities that emerge during the pre-training stage. Previous subjective evaluation methods mainly reply on scoring by API models. However, in the absence of references, large models have shown limited ability... | Yu Sun, Keyuchen Keyuchen, Shujie Wang, Peiji Li, Qipeng Guo, Hang Yan, Xipeng Qiu, Xuanjing Huang, Dahua Lin |  |
| 627 |  |  [Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning](https://doi.org/10.18653/v1/2024.acl-long.508) |  | 0 | Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their capability in executing deductive reasoning tasks. Nonetheless, a significant portion of research primarily assesses the accuracy of LLMs in solving such tasks, often overlooking a deeper analysis of their... | Philipp Mondorf, Barbara Plank |  |
| 628 |  |  [Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback](https://doi.org/10.18653/v1/2024.acl-long.509) |  | 0 | There is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences. We consider the setting of fairness in content moderation, in which human feedback is used to determine how two comments — referencing different sensitive attribute groups — should be treated in comparison to one another. With a novel dataset collected from Prolific and MTurk, we find significant gaps in fairness preferences depending on the... | Maria Lerner, Florian E. Dorner, Elliott Ash, Naman Goel |  |
| 629 |  |  [Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://doi.org/10.18653/v1/2024.acl-long.510) |  | 0 | In this paper, we present an innovative process-oriented math process reward model called Math-shepherd, which assigns a reward score to each step of math problem solutions. The training of Math-shepherd is achieved using automatically constructed process-wise supervision data, breaking the bottleneck of heavy reliance on manual annotation in existing work. We explore the effectiveness of Math-shepherd in two scenarios: 1) Verification: Math-shepherd is utilized for reranking multiple outputs... | Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, Zhifang Sui |  |
| 630 |  |  [Large Language Models are not Fair Evaluators](https://doi.org/10.18653/v1/2024.acl-long.511) |  | 0 | In this paper, we uncover a positional bias in the evaluation paradigm of adopting large language models (LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by simply altering their order of appearance in the context. This manipulation allows us to skew the evaluation result, making one model appear considerably superior to the other, e.g., Vicuna-13B could... | Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng Kong, Qi Liu, Tianyu Liu, Zhifang Sui |  |
| 631 |  |  [Improving Large Language Models in Event Relation Logical Prediction](https://doi.org/10.18653/v1/2024.acl-long.512) |  | 0 | Event relations are crucial for narrative understanding and reasoning. Governed by nuanced logic, event relation extraction (ERE) is a challenging task that demands thorough semantic understanding and rigorous logical reasoning. In this paper, we conduct an in-depth investigation to systematically explore the capability of LLMs in understanding and applying event relation logic. More in detail, we first investigate the deficiencies of LLMs in logical reasoning across different tasks. Our study... | Meiqi Chen, Yubo Ma, Kaitao Song, Yixin Cao, Yan Zhang, Dongsheng Li |  |
| 632 |  |  [Synchronized Video Storytelling: Generating Video Narrations with Structured Storyline](https://doi.org/10.18653/v1/2024.acl-long.513) |  | 0 | Video storytelling is engaging multimedia content that utilizes video and its accompanying narration to share a story and attract the audience, where a key challenge is creating narrations for recorded visual scenes. Previous studies on dense video captioning and video story generation have made some progress. However, in practical applications, we typically require synchronized narrations for ongoing visual scenes. In this work, we introduce a new task of Synchronized Video Storytelling, which... | Dingyi Yang, Chunru Zhan, Ziheng Wang, Biao Wang, Tiezheng Ge, Bo Zheng, Qin Jin |  |
| 633 |  |  [Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation](https://doi.org/10.18653/v1/2024.acl-long.514) |  | 0 | Fine-grained vision-language models (VLM) have been widely used for inter-modality local alignment between the predefined fixed patches and textual words. However, in medical analysis, lesions exhibit varying sizes and positions, and using fixed patches may cause incomplete representations of lesions. Moreover, these methods provide explainability by using heatmaps to show the general image areas potentially associated with texts rather than specific regions, making their explanations not... | Wenting Chen, Linlin Shen, Jingyang Lin, Jiebo Luo, Xiang Li, Yixuan Yuan |  |
| 634 |  |  [T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step](https://doi.org/10.18653/v1/2024.acl-long.515) |  | 0 | Large language models (LLMs) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models holistically, we comprehensively decompose the tool utilization into multiple sub-processes, including instruction following, planning, reasoning, retrieval, understanding, and review. Based on that, we further... | Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, Feng Zhao |  |
| 635 |  |  [Are LLM-based Evaluators Confusing NLG Quality Criteria?](https://doi.org/10.18653/v1/2024.acl-long.516) |  | 0 | Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies... | Xinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, Xiaojun Wan |  |
| 636 |  |  [Synergistic Interplay between Search and Large Language Models for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.517) |  | 0 | Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern retrieval models (RMs). The emergence of large language models (LLMs) has further revolutionized the IR field by enabling users to interact with search systems in natural languages. In this paper, we explore the advantages and disadvantages of LLMs and RMs, highlighting their respective strengths in understanding... | Jiazhan Feng, Chongyang Tao, Xiubo Geng, Tao Shen, Can Xu, Guodong Long, Dongyan Zhao, Daxin Jiang |  |
| 637 |  |  [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://doi.org/10.18653/v1/2024.acl-long.518) |  | 0 | Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing. Current innovations, including State Space Models, were initially celebrated for surpassing Transformer performance on language modeling tasks. However, these models have revealed deficiencies in essential In-Context Learning capabilities – a domain where the Transformer traditionally shines. The Based model emerged as a hybrid solution,... | Yaroslav Aksenov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina, Boris Shaposhnikov, Alexey Gorbatovski, Daniil Gavrilov |  |
| 638 |  |  [Temperature-scaling surprisal estimates improve fit to human reading times - but does it do so for the "right reasons"?](https://doi.org/10.18653/v1/2024.acl-long.519) |  | 0 | A wide body of evidence shows that human language processing difficulty is predicted by the information-theoretic measure surprisal, a word’s negative log probability in context. However, it is still unclear how to best estimate these probabilities needed for predicting human processing difficulty – while a long-standing belief held that models with lower perplexity would provide more accurate estimates of word predictability, and therefore lead to better reading time predictions, recent work... | Tong Liu, Iza Skrjanec, Vera Demberg |  |
| 639 |  |  [Beyond Recognising Entailment: Formalising Natural Language Inference from an Argumentative Perspective](https://doi.org/10.18653/v1/2024.acl-long.520) |  | 0 | In argumentation theory, argument schemes are a characterisation of stereotypical patterns of inference. There has been little work done to develop computational approaches to identify these schemes in natural language. Moreover, advancements in recognizing textual entailment lack a standardized definition of inference, which makes it challenging to compare methods trained on different datasets and rely on the generalisability of their results. In this work, we propose a rigorous approach to... | Ameer SaadatYazdi, Nadin Kökciyan |  |
| 640 |  |  [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://doi.org/10.18653/v1/2024.acl-long.521) |  | 0 | We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages.We... | Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, YuGang Jiang, Xipeng Qiu |  |
| 641 |  |  [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.522) |  | 0 | Social media abounds with multimodal sarcasm, and identifying sarcasm targets is particularly challenging due to the implicit incongruity not directly evident in the text and image modalities. Current methods for Multimodal Sarcasm Target Identification (MSTI) predominantly focus on superficial indicators in an end-to-end manner, overlooking the nuanced understanding of multimodal sarcasm conveyed through both the text and image. This paper proposes a versatile MSTI framework with a... | Zixin Chen, Hongzhan Lin, Ziyang Luo, Mingfei Cheng, Jing Ma, Guang Chen |  |
| 642 |  |  [Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation](https://doi.org/10.18653/v1/2024.acl-long.523) |  | 0 | Aligning large language models (LLMs) with human expectations without human-annotated preference data is an important problem. In this paper, we propose a method to evaluate the response preference by using the output probabilities of response pairs under contrastive prompt pairs, which could achieve better performance on LLaMA2-7B and LLaMA2-13B compared to RLAIF. Based on this, we propose an automatic alignment method, Direct Large Model Alignment (DLMA). First, we use contrastive prompt... | Aiwei Liu, Haoping Bai, Zhiyun Lu, Xiang Kong, Simon Wang, Jiulong Shan, Meng Cao, Lijie Wen |  |
| 643 |  |  [Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines](https://doi.org/10.18653/v1/2024.acl-long.524) |  | 0 | Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by generating images from its intermediate representations. Using the Diffusion Lens, we perform an extensive analysis of two recent T2I models. Exploring compound prompts, we find that complex scenes... | Michael Toker, Hadas Orgad, Mor Ventura, Dana Arad, Yonatan Belinkov |  |
| 644 |  |  [Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.525) |  | 0 | Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training method, and evaluation benchmark. In this paper, we introduce Parrot, a solution aiming to enhance multi-turn instruction following for LLMs. First, we introduce an efficient but effective method for collecting multi-turn instructions... | Yuchong Sun, Che Liu, Kun Zhou, Jinwen Huang, Ruihua Song, Xin Zhao, Fuzheng Zhang, Di Zhang, Kun Gai |  |
| 645 |  |  [Robust Singing Voice Transcription Serves Synthesis](https://doi.org/10.18653/v1/2024.acl-long.526) |  | 0 | Note-level Automatic Singing Voice Transcription (AST) converts singing recordings into note sequences, facilitating the automatic annotation of singing datasets for Singing Voice Synthesis (SVS) applications. Current AST methods, however, struggle with accuracy and robustness when used for practical annotation. This paper presents ROSVOT, the first robust AST model that serves SVS, incorporating a multi-scale framework that effectively captures coarse-grained note information and ensures... | Ruiqi Li, Yu Zhang, Yongqi Wang, Zhiqing Hong, Rongjie Huang, Zhou Zhao |  |
| 646 |  |  [VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.527) |  | 0 | Security practitioners maintain vulnerability reports (e.g., GitHub Advisory) to help developers mitigate security risks. An important task for these databases is automatically extracting structured information mentioned in the report, e.g., the affected software packages, to accelerate the defense of the vulnerability ecosystem.However, it is challenging for existing work on affected package identification to achieve high precision. One reason is that all existing work focuses on relatively... | Tianyu Chen, Lin Li, ZhuLiuchuan ZhuLiuchuan, Zongyang Li, Xueqing Liu, Guangtai Liang, Qianxiang Wang, Tao Xie |  |
| 647 |  |  [Self-Modifying State Modeling for Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.528) |  | 0 | Simultaneous Machine Translation (SiMT) generates target outputs while receiving stream source inputs and requires a read/write policy to decide whether to wait for the next source token or generate a new target token, whose decisions form a decision path. Existing SiMT methods, which learn the policy by exploring various decision paths in training, face inherent limitations. These methods not only fail to precisely optimize the policy due to the inability to accurately assess the individual... | Donglei Yu, Xiaomian Kang, Yuchen Liu, Yu Zhou, Chengqing Zong |  |
| 648 |  |  [MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-long.529) |  | 0 | Embodied agents equipped with GPT as their brain have exhibited extraordinary decision-making and generalization abilities across various tasks. However, existing zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT-4 to select potential locations within localized environments, without constructing an effective “global-view” for the agent to understand the overall environment. In this work, we present a novel \*\*map\*\*-guided \*\*GPT\*\*-based agent, dubbed... | Jiaqi Chen, Bingqian Lin, Ran Xu, Zhenhua Chai, Xiaodan Liang, KwanYee Kenneth Wong |  |
| 649 |  |  [BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.530) |  | 0 | With the prosperity of large language models (LLMs), powerful LLM-based intelligent agents have been developed to provide customized services with a set of user-defined tools. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent task. However, we show that such methods are vulnerable to our proposed backdoor attacks named BadAgent on various agent tasks, where a backdoor can be embedded by fine-tuning on the backdoor data. At... | Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian |  |
| 650 |  |  [DetermLR: Augmenting LLM-based Logical Reasoning from Indeterminacy to Determinacy](https://doi.org/10.18653/v1/2024.acl-long.531) |  | 0 | Recent advances in large language models (LLMs) have revolutionized the landscape of reasoning tasks. To enhance the capabilities of LLMs to emulate human reasoning, prior studies have focused on modeling reasoning steps using various thought structures like chains, trees, or graphs. However, LLM-based reasoning still encounters the following challenges: (1) Limited adaptability of preset structures to diverse tasks; (2) Insufficient precision in exploiting known conditions to derive new ones;... | Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, JiRong Wen, Rui Yan |  |
| 651 |  |  [LePaRD: A Large-Scale Dataset of Judicial Citations to Precedent](https://doi.org/10.18653/v1/2024.acl-long.532) |  | 0 | We present the Legal Passage Retrieval Dataset, LePaRD. LePaRD contains millions of examples of U.S. federal judges citing precedent in context. The dataset aims to facilitate work on legal passage retrieval, a challenging practice-oriented legal retrieval and reasoning task. Legal passage retrieval seeks to predict relevant passages from precedential court decisions given the context of a legal argument. We extensively evaluate various approaches on LePaRD, and find that classification-based... | Robert Mahari, Dominik Stammbach, Elliott Ash, Alex Pentland |  |
| 652 |  |  [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.533) |  | 0 | Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible... | Giacomo Frisoni, Alessio Cocchieri, Alex Presepi, Gianluca Moro, Zaiqiao Meng |  |
| 653 |  |  [MERA: A Comprehensive LLM Evaluation in Russian](https://doi.org/10.18653/v1/2024.acl-long.534) |  | 0 | Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). However, despite researchers’ attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce a new instruction benchmark, MERA, oriented towards the FMs’ performance on the Russian language. The benchmark encompasses 21... | Alena Fenogenova, Artem Chervyakov, Nikita Martynov, Anastasia Kozlova, Maria Tikhonova, Albina Akhmetgareeva, Anton A. Emelyanov, Denis Shevelev, Pavel Lebedev, Leonid Sinev, Ulyana Isaeva, Katerina Kolomeytseva, Daniil Moskovskiy, Elizaveta Goncharova, Nikita Savushkin, Polina Mikhailova, Anastasia Minaeva, Denis Dimitrov, Alexander Panchenko, Sergey Markov |  |
| 654 |  |  [SC2: Towards Enhancing Content Preservation and Style Consistency in Long Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.535) |  | 0 | Text style transfer (TST) aims to vary the style polarity of text while preserving the semantic content. Although recent advancements have demonstrated remarkable progress in short TST, it remains a relatively straightforward task with limited practical applications. The more comprehensive long TST task presents two challenges: (1) existing methods encounter difficulties in accurately evaluating content attributes in multiple words, leading to content degradation; (2) the conventional vanilla... | Jie Zhao, Ziyu Guan, Cai Xu, Wei Zhao, Yue Jiang |  |
| 655 |  |  [Dodo: Dynamic Contextual Compression for Decoder-only LMs](https://doi.org/10.18653/v1/2024.acl-long.536) |  | 0 | Transformer-based language models (LMs) are inefficient in long contexts. We propose Dodo, a solution for context compression. Instead of one vector per token in a standard transformer model, Dodo represents text with a dynamic number of hidden states at each layer, reducing the cost of self-attention to a fraction of typical time and space. Moreover, off-the-shelf models such as LLaMA can be adapted to Dodo by efficient parameter tuning methods such as LoRA. In use, Dodo can act as either an... | Guanghui Qin, Corby Rosset, Ethan C. Chau, Nikhil Rao, Benjamin Van Durme |  |
| 656 |  |  [POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.537) |  | 0 | Low-resource languages (LRLs) face challenges in supervised neural machine translation (NMT) due to limited parallel data, prompting research in unsupervised NMT.Unsupervised NMT (UNMT), without requiring ground truth, provides solutions for LRL translations using synthetic pseudo-parallel data and parallel data from auxiliary language pairs. However, they usually encounter translation errors, including errors from synthetic data and from auxiliary language pairs with linguistic biases.We argue... | Shilong Pan, Zhiliang Tian, Liang Ding, Haoqi Zheng, Zhen Huang, Zhihua Wen, Dongsheng Li |  |
| 657 |  |  [NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism](https://doi.org/10.18653/v1/2024.acl-long.538) |  | 0 | We present NewsBench, a novel evaluation framework to systematically assess the capabilities of Large Language Models (LLMs) for editorial capabilities in Chinese journalism. Our constructed benchmark dataset is focused on four facets of writing proficiency and six facets of safety adherence, and it comprises manually and carefully designed 1,267 test samples in the types of multiple choice questions and short answer questions for five editorial tasks in 24 news domains. To measure... | Miao Li, MingBin Chen, Bo Tang, ShengbinHou ShengbinHou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Cheng Peng, Yi Luo |  |
| 658 |  |  [MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization](https://doi.org/10.18653/v1/2024.acl-long.539) |  | 0 | Intuitively, reasoning abilities are considered language-agnostic. However, existing LLMs exhibit inconsistent reasoning abilities across different languages, e.g., reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To enhance reasoning abilities in non-dominant languages, we propose a Multilingual-Alignment-as-Preference Optimization framework (MAPO) to align the reasoning processes in other languages with the... | Shuaijie She, Wei Zou, Shujian Huang, Wenhao Zhu, Xiang Liu, Xiang Geng, Jiajun Chen |  |
| 659 |  |  [Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training](https://doi.org/10.18653/v1/2024.acl-long.540) |  | 0 | Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to mitigate these challenges. However, inappropriate retrieved passages can potentially hinder the LLMs’ capacity to generate comprehensive and high-quality responses. Prior RAG studies on the robustness of... | Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, Ruifeng Xu |  |
| 660 |  |  [Predicting Text Preference Via Structured Comparative Reasoning](https://doi.org/10.18653/v1/2024.acl-long.541) |  | 0 | Comparative reasoning plays a crucial role in predicting text preferences; however, large language models (LLMs) often demonstrate inconsistencies in their reasoning, leading to incorrect preference predictions. While approaches like Chain-of-Thought improve accuracy in many settings, they struggle to consistently distinguish the similarities and differences of complex texts. We introduce SC2, a model that prompts LLMs to predict text preferences by generating structured intermediate... | Jing Nathan Yan, Tianqi Liu, Justin T. Chiu, Jiaming Shen, Zhen Qin, Yue Yu, Charumathi Lakshmanan, Yair Kurzion, Alexander M. Rush, Jialu Liu, Michael Bendersky |  |
| 661 |  |  [CoELM: Construction-Enhanced Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.542) |  | 0 | Recent studies have shown that integrating constructional information can improve the performance of pre-trained language models (PLMs) in natural language understanding. However, exploration into leveraging constructional information to enhance generative language models for natural language generation has been limited. Additionally, probing studies indicate that PLMs primarily grasp the syntactic structure of constructions but struggle to capture their semantics. In this work, we encode... | Lvxiaowei Xu, Zhilin Gong, Jianhua Dai, Tianxiang Wang, Ming Cai, Jiawei Peng |  |
| 662 |  |  [Uni-Dubbing: Zero-Shot Speech Synthesis from Visual Articulation](https://doi.org/10.18653/v1/2024.acl-long.543) |  | 0 | In the field of speech synthesis, there is a growing emphasis on employing multimodal speech to enhance robustness. A key challenge in this area is the scarcity of datasets that pair audio with corresponding video. We employ a methodology that incorporates modality alignment during the pre-training phase on multimodal datasets, uniquely facilitating zero-shot generalization through the process of freezing the video modality feature extraction component and the encoder module within the... | Songju Lei, Xize Cheng, Mengjiao Lyu, Jianqiao Hu, Jintao Tan, Runlin Liu, Lingyu Xiong, Tao Jin, Xiandong Li, Zhou Zhao |  |
| 663 |  |  [On the Impact of Calibration Data in Post-training Quantization and Pruning](https://doi.org/10.18653/v1/2024.acl-long.544) |  | 0 | Quantization and pruning form the foundation of compression for neural networks, enabling efficient inference for large language models (LLMs). Recently, various quantization and pruning techniques have demonstrated remarkable performance in a post-training setting. They rely upon calibration data, a small set of unlabeled examples that are used to generate layer activations. However, no prior work has systematically investigated how the calibration data impacts the effectiveness of model... | Miles Williams, Nikolaos Aletras |  |
| 664 |  |  [SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution](https://doi.org/10.18653/v1/2024.acl-long.545) |  | 0 | Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent advances in the capabilities of Large Language Models (LLMs) has led towards generating low-level LFs such as SPARQL and S-Expression in a few-shot setting. Unfortunately, these methods: (1) are... | Prerna Agarwal, Nishant Kumar, Srikanta Bedathur |  |
| 665 |  |  [Meta-Task Prompting Elicits Embeddings from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.546) |  | 0 | We introduce a new unsupervised text embedding method, Meta-Task Prompting with Explicit One-Word Limitation (MetaEOL), for generating high-quality sentence embeddings from Large Language Models (LLMs) without the need for model fine-tuning. Leveraging meta-task prompting, MetaEOL guides LLMs to produce embeddings through a series of carefully designed prompts that address multiple representational aspects. Our comprehensive experiments demonstrate that embeddings averaged from various... | Yibin Lei, Di Wu, Tianyi Zhou, Tao Shen, Yu Cao, Chongyang Tao, Andrew Yates |  |
| 666 |  |  [A Sentiment Consolidation Framework for Meta-Review Generation](https://doi.org/10.18653/v1/2024.acl-long.547) |  | 0 | Modern natural language generation systems with Large Language Models (LLMs) exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if they truly possess the capability of information consolidation to generate summaries, especially on documents with opinionated information. We focus on meta-review generation, a form of sentiment summarisation for the scientific domain. To make scientific sentiment summarization more grounded, we hypothesize that... | Miao Li, Jey Han Lau, Eduard H. Hovy |  |
| 667 |  |  [Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing](https://doi.org/10.18653/v1/2024.acl-long.548) |  | 0 | Structured Sentiment Analysis (SSA) was cast as a problem of bi-lexical dependency graph parsing by prior studies.Multiple formulations have been proposed to construct the graph, which share several intrinsic drawbacks:(1) The internal structures of spans are neglected, thus only the boundary tokens of spans are used for relation prediction and span recognition, thus hindering the model’s expressiveness;(2) Long spans occupy a significant proportion in the SSA datasets, which further... | Chengjie Zhou, Bobo Li, Hao Fei, Fei Li, Chong Teng, Donghong Ji |  |
| 668 |  |  [OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification](https://doi.org/10.18653/v1/2024.acl-long.549) |  | 0 | There has been an increasing interest in large speech models that can perform multiple tasks in a single model. Such models usually adopt an encoder-decoder or decoder-only architecture due to their popularity and good performance in many domains. However, autoregressive models can be slower during inference compared to non-autoregressive models and also have potential risks of hallucination. Though prior studies observed promising results of non-autoregressive models for certain tasks at small... | Yifan Peng, Yui Sudo, Muhammad Shakeel, Shinji Watanabe |  |
| 669 |  |  [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.550) |  | 0 | We study whether Large Language Models (LLMs) latently perform multi-hop reasoning with complex prompts such as “The mother of the singer of ‘Superstition’ is”. We look for evidence of a latent reasoning pathway where an LLM (1) latently identifies “the singer of ‘Superstition’” as Stevie Wonder, the bridge entity, and (2) uses its knowledge of Stevie Wonder’s mother to complete the prompt. We analyze these two hops individually and consider their co-occurrence as indicative of latent multi-hop... | Sohee Yang, Elena Gribovskaya, Nora Kassner, Mor Geva, Sebastian Riedel |  |
| 670 |  |  [MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning](https://doi.org/10.18653/v1/2024.acl-long.551) |  | 0 | In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation for such data augmentation in math reasoning and are intended to answer: (1) What strategies of data augmentation are more effective; (2) What is the scaling relationship between the amount of... | Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou |  |
| 671 |  |  [Harnessing Toulmin's theory for zero-shot argument explication](https://doi.org/10.18653/v1/2024.acl-long.552) |  | 0 | To better analyze informal arguments on public forums, we propose the task of argument explication, which makes explicit a text’s argumentative structure and implicit reasoning by outputting triples of propositions ⟨claim, reason warrant⟩. The three slots, or argument components, are derived from the widely known Toulmin (1958) model of argumentation. While prior research applies Toulmin or related theories to annotate datasets and train supervised models, we develop an effective method to... | Ankita Gupta, Ethan Zuckerman, Brendan T. O'Connor |  |
| 672 |  |  [BinaryAlign: Word Alignment as Binary Sequence Labeling](https://doi.org/10.18653/v1/2024.acl-long.553) |  | 0 | Real world deployments of word alignment are almost certain to cover both high and low resource languages. However, the state-of-the-art for this task recommends a different model class depending on the availability of gold alignment training data for a particular language pair. We propose BinaryAlign, a novel word alignment technique based on binary sequence labeling that outperforms existing approaches in both scenarios, offering a unifying approach to the task. Additionally, we vary the... | Gaetan Latouche, MarcAndré Carbonneau, Benjamin Swanson |  |
| 673 |  |  [Quantifying the Persona Effect in LLM Simulations](https://doi.org/10.18653/v1/2024.acl-long.554) |  | 0 | Large language models (LLMs) have shown remarkable promise in simulating human language and behavior. This study investigates how integrating persona variables—demographic, social, and behavioral factors—impacts LLMs’ ability to simulate diverse perspectives. We find that persona variables account for <10% variance in annotations in existing subjective NLP datasets. Nonetheless, incorporating persona variables via prompting in LLMs provides modest but statistically significant improvements.... | Tiancheng Hu, Nigel Collier |  |
| 674 |  |  [Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?](https://doi.org/10.18653/v1/2024.acl-long.555) |  | 0 | Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four LLMs, this prompt bests a majority baseline in 11/12 cases, with up to 0.33 accuracy gain. To help explain this behavior, we conduct an in-depth, black-box analysis on memorization, choice dynamics,... | Nishant Balepur, Abhilasha Ravichander, Rachel Rudinger |  |
| 675 |  |  [Retrieval Augmented Fact Verification by Synthesizing Contrastive Arguments](https://doi.org/10.18653/v1/2024.acl-long.556) |  | 0 | The rapid propagation of misinformation poses substantial risks to public interest. To combat misinformation, large language models (LLMs) are adapted to automatically verify claim credibility. Nevertheless, existing methods heavily rely on the embedded knowledge within LLMs and / or black-box APIs for evidence collection, leading to subpar performance with smaller LLMs or upon unreliable context. In this paper, we propose retrieval augmented fact verification through the synthesis of... | Zhenrui Yue, Huimin Zeng, Lanyu Shang, Yifan Liu, Yang Zhang, Dong Wang |  |
| 676 |  |  [SyllabusQA: A Course Logistics Question Answering Dataset](https://doi.org/10.18653/v1/2024.acl-long.557) |  | 0 | Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly available datasets. We introduce SyllabusQA, an open-source dataset with 63 real course syllabi covering 36 majors, containing 5,078 open-ended course logistics-related question-answer pairs that are... | Nigel Fernandez, Alexander Scarlatos, Andrew S. Lan |  |
| 677 |  |  [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.558) |  | 0 | Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMs’ inference and transparency. Our method enables LLMs to comprehend KG inputs... | Yilin Wen, Zifeng Wang, Jimeng Sun |  |
| 678 |  |  [AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German Consumer Contracts](https://doi.org/10.18653/v1/2024.acl-long.559) |  | 0 | Legal tasks and datasets are often used as benchmarks for the capabilities of language models. However, openly available annotated datasets are rare. In this paper, we introduce AGB-DE, a corpus of 3,764 clauses from German consumer contracts that have been annotated and legally assessed by legal experts. Together with the data, we present a first baseline for the task of detecting potentially void clauses, comparing the performance of an SVM baseline with three fine-tuned open language models... | Daniel Braun, Florian Matthes |  |
| 679 |  |  [Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks](https://doi.org/10.18653/v1/2024.acl-long.560) |  | 0 | Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model’s average performance across the test prompts of a benchmark to evaluate the model’s performance. This is consistent with the assumption that the test prompts within a benchmark represent a random sample from some real-world distribution of interest. We note that this is generally not the case; instead, we hold that the distribution of interest varies... | Charlotte Siska, Katerina Marazopoulou, Melissa Ailem, James Bono |  |
| 680 |  |  [Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning](https://doi.org/10.18653/v1/2024.acl-long.561) |  | 0 | We present a new method for large language models to solve compositional tasks. Although they have shown strong performance on traditional language understanding tasks, large language models struggle to solve compositional tasks, where the solution depends on solving smaller instances of the same problem. We propose a natural approach to solve compositional tasks recursively. Our method, Re-Tuning, tunes models to break down a problem into subproblems, solve those subproblems, and combine the... | Eric Pasewark, Kyle Montgomery, Kefei Duan, Dawn Song, Chenguang Wang |  |
| 681 |  |  [Bridging the Preference Gap between Retrievers and LLMs](https://doi.org/10.18653/v1/2024.acl-long.562) |  | 0 | Large Language Models (LLMs) have demonstrated superior results across a wide range of tasks, and Retrieval-augmented Generation (RAG) is an effective way to enhance the performance by locating relevant information and placing it into the context window of the LLM. However, the relationship between retrievers and LLMs in a RAG is still under-investigated. Most existing work treats the retriever and the LLM as independent components and leaves a gap between retrieving human-”friendly”... | Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky |  |
| 682 |  |  [Large Language Models Can Learn Temporal Reasoning](https://doi.org/10.18653/v1/2024.acl-long.563) |  | 0 | While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs due to its reliance on diverse temporal concepts and intricate temporal logic. In this paper, we propose TG-LLM, a novel framework towards language-based TR. Instead of reasoning over the original... | Siheng Xiong, Ali Payani, Ramana Kompella, Faramarz Fekri |  |
| 683 |  |  [Learning Relational Decomposition of Queries for Question Answering from Tables](https://doi.org/10.18653/v1/2024.acl-long.564) |  | 0 | Table Question-Answering involves both understanding the natural language query and grounding it in the context of the input table to extract relevant information. In this context, many methods have highlighted the benefits of intermediate pre-training using SQL queries. However, while most approaches aim at generating final answers directly from inputs, we claim that there is better to do with SQL queries during training.By learning to imitate a restricted subset of SQL-like algebraic... | Raphaël Mouravieff, Benjamin Piwowarski, Sylvain Lamprier |  |
| 684 |  |  [Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People](https://doi.org/10.18653/v1/2024.acl-long.565) |  | 0 | Conversational tones — the manners and attitudes in which speakers communicate — are essential to effective communication. As Large Language Models (LLMs) become increasingly popular, it is necessary to characterize the divergences in their conversational tones relative to humans. Prior research relied on pre-existing taxonomies or text corpora, which suffer from experimenter bias and may not be representative of real-world distributions. Inspired by methods from cognitive science, we propose... | DunMing Huang, Pol van Rijn, Ilia Sucholutsky, Raja Marjieh, Nori Jacoby |  |
| 685 |  |  [Pareto Optimal Learning for Estimating Large Language Model Errors](https://doi.org/10.18653/v1/2024.acl-long.566) |  | 0 | Large Language Models (LLMs) have shown impressive abilities in many applications. When a concrete and precise answer is desired, it is important to have a quantitative estimation of the potential error rate. However, this can be challenging due to the text-in-text-out nature of the generative models. We present a method based on Pareto optimization that generates a risk score to estimate the probability of error in an LLM response by integrating multiple sources of information. We prove... | Theodore Zhao, Mu Wei, Joseph Preston, Hoifung Poon |  |
| 686 |  |  [Simul-LLM: A Framework for Exploring High-Quality Simultaneous Translation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.567) |  | 0 | Large language models (LLMs) with billions of parameters and pretrained on massive amounts of data are now capable of near or better than state-of-the-art performance in a variety of downstream natural language processing tasks. Neural machine translation (NMT) is one such task that LLMs have been applied to with great success. However, little research has focused on applying LLMs to the more difficult subset of NMT called simultaneous translation (SimulMT), where translation begins before the... | Victor Agostinelli, Max Wild, Matthew Raffel, Kazi Ahmed Asif Fuad, Lizhong Chen |  |
| 687 |  |  [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM](https://doi.org/10.18653/v1/2024.acl-long.568) |  | 0 | Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted... | Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen |  |
| 688 |  |  [Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.569) |  | 0 | This study explores the realm of knowledge base question answering (KBQA). KBQA is considered a challenging task, particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)-based methods require extensive data annotations, which result in significant costs. Recently, the advent of few-shot in-context learning, powered by large language models (LLMs), has showcased promising capabilities. Yet, fully leveraging LLMs to parse questions into logical... | Guanming Xiong, Junwei Bao, Wen Zhao |  |
| 689 |  |  [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](https://doi.org/10.18653/v1/2024.acl-long.570) |  | 0 | Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained. We find that existing LLMs, including GPT-4 and open-source LLMs specifically... | Boshi Wang, Hao Fang, Jason Eisner, Benjamin Van Durme, Yu Su |  |
| 690 |  |  [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://doi.org/10.18653/v1/2024.acl-long.571) |  | 0 | The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the availability of expert knowledge: enhancing performance through increased use of expert knowledge often results in diminishing sparsity during expert selection. To mitigate this contradiction, we... | Hao Zhao, Zihan Qiu, Huijia Wu, Zili Wang, Zhaofeng He, Jie Fu |  |
| 691 |  |  [Aligning Large Language Models with Human Preferences through Representation Engineering](https://doi.org/10.18653/v1/2024.acl-long.572) |  | 0 | Aligning large language models (LLMs) with human preferences is crucial for enhancing their utility in terms of helpfulness, truthfulness, safety, harmlessness, and interestingness. Existing methods for achieving this alignment often involve employing reinforcement learning from human feedback (RLHF) to fine-tune LLMs based on human labels assessing the relative quality of model responses. Nevertheless, RLHF is susceptible to instability during fine-tuning and presents challenges in... | Wenhao Liu, Xiaohua Wang, Muling Wu, Tianlong Li, Changze Lv, Zixuan Ling, Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang |  |
| 692 |  |  [CODIS: Benchmarking Context-dependent Visual Comprehension for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.573) |  | 0 | Multimodal large language models (MLLMs) have demonstrated promising results in a variety of tasks that combine vision and language. As these models become more integral to research and applications, conducting comprehensive evaluations of their capabilities has grown increasingly important. However, most existing benchmarks fail to consider that, in certain situations, images need to be interpreted within a broader context. In this work, we introduce a new benchmark, named as CODIS, designed... | Fuwen Luo, Chi Chen, Zihao Wan, Zhaolu Kang, Qidong Yan, Yingjie Li, Xiaolong Wang, Siyu Wang, Ziyue Wang, Xiaoyue Mi, Peng Li, Ning Ma, Maosong Sun, Yang Liu |  |
| 693 |  |  [ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.574) |  | 0 | Human annotation is a time-consuming task that requires a significant amount of effort. To address this issue, interactive data annotation utilizes an annotation model to provide suggestions for humans to approve or correct. However, annotation models trained with limited labeled data are prone to generating incorrect suggestions, leading to extra human correction effort. To tackle this challenge, we propose Araida, an analogical reasoning-based approach that enhances automatic annotation... | Chen Huang, Yiping Jin, Ilija Ilievski, Wenqiang Lei, Jiancheng Lv |  |
| 694 |  |  [PolCLIP: A Unified Image-Text Word Sense Disambiguation Model via Generating Multimodal Complementary Representations](https://doi.org/10.18653/v1/2024.acl-long.575) |  | 0 | Word sense disambiguation (WSD) can be viewed as two subtasks: textual word sense disambiguation (Textual-WSD) and visual word sense disambiguation (Visual-WSD). They aim to identify the most semantically relevant senses or images to a given context containing ambiguous target words. However, existing WSD models seldom address these two subtasks jointly due to lack of images in Textual-WSD datasets or lack of senses in Visual-WSD datasets. To bridge this gap, we propose PolCLIP, a unified... | Qihao Yang, Yong Li, Xuelin Wang, Fu Lee Wang, Tianyong Hao |  |
| 695 |  |  [Prompted Aspect Key Point Analysis for Quantitative Review Summarization](https://doi.org/10.18653/v1/2024.acl-long.576) |  | 0 | Key Point Analysis (KPA) aims for quantitative summarization that provides key points (KPs) as succinct textual summaries and quantities measuring their prevalence. KPA studies for arguments and reviews have been reported in the literature. A majority of KPA studies for reviews adopt supervised learning to extract short sentences as KPs before matching KPs to review comments for quantification of KP prevalence. Recent abstractive approaches still generate KPs based on sentences, often leading... | An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria |  |
| 696 |  |  [Ask Again, Then Fail: Large Language Models' Vacillations in Judgment](https://doi.org/10.18653/v1/2024.acl-long.577) |  | 0 | We observe that current large language models often waver in their judgments when faced with follow-up questions, even if the original judgment was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a Follow-up Questioning Mechanism along with two metrics to quantify this inconsistency, confirming its widespread presence in current large language models. Furthermore, to mitigate... | Qiming Xie, Zengzhi Wang, Yi Feng, Rui Xia |  |
| 697 |  |  [CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.578) |  | 0 | Large language models (LLMs) are increasingly used to meet user information needs, but their effectiveness in dealing with user queries that contain various types of ambiguity remains unknown, ultimately risking user trust and satisfaction. To this end, we introduce CLAMBER, a benchmark for evaluating LLMs using a well-organized taxonomy. Building upon the taxonomy, we construct 12K high-quality data to assess the strengths, weaknesses, and potential risks of various off-the-shelf LLMs.Our... | Tong Zhang, Peixin Qin, Yang Deng, Chen Huang, Wenqiang Lei, Junhong Liu, Dingnan Jin, Hongru Liang, TatSeng Chua |  |
| 698 |  |  [Multimodal Reasoning with Multimodal Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.579) |  | 0 | Multimodal reasoning with large language models (LLMs) often suffers from hallucinations and the presence of deficient or outdated knowledge within LLMs. Some approaches have sought to mitigate these issues by employing textual knowledge graphs, but their singular modality of knowledge limits comprehensive cross-modal understanding. In this paper, we propose the Multimodal Reasoning with Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal knowledge graphs (MMKGs) to learn... | Junlin Lee, Yequan Wang, Jing Li, Min Zhang |  |
| 699 |  |  [Confidence is not Timeless: Modeling Temporal Validity for Rule-based Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.acl-long.580) |  | 0 | Recently, Temporal Knowledge Graph Forecasting (TKGF) has emerged as a pivotal domain for forecasting future events. Unlike black-box neural network methods, rule-based approaches are lauded for their efficiency and interpretability. For this line of work, it is crucial to correctly estimate the predictive effectiveness of the rules, i.e., the confidence. However, the existing literature lacks in-depth investigation into how confidence evolves with time. Moreover, inaccurate and heuristic... | Rikui Huang, Wei Wei, Xiaoye Qu, Shengzhe Zhang, Dangyang Chen, Yu Cheng |  |
| 700 |  |  [CARE: A Clue-guided Assistant for CSRs to Read User Manuals](https://doi.org/10.18653/v1/2024.acl-long.581) |  | 0 | It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don’t fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE. It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains. Specifically,... | Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei |  |
| 701 |  |  [Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning Processes](https://doi.org/10.18653/v1/2024.acl-long.582) |  | 0 | Numerical reasoning is an essential ability for NLP systems to handle numeric information. Recent research indicates that fine-tuning a small-scale model to learn generating reasoning processes alongside answers can significantly enhance performance. However, current methods have the limitation that most methods generate reasoning processes with large language models (LLMs), which are “unreliable” since such processes could contain information unrelated to the answer. To address this... | Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che |  |
| 702 |  |  [PAGED: A Benchmark for Procedural Graphs Extraction from Documents](https://doi.org/10.18653/v1/2024.acl-long.583) |  | 0 | Automatic extraction of procedural graphs from documents creates a low-cost way for users to easily understand a complex procedure by skimming visual graphs. Despite the progress in recent studies, it remains unanswered: whether the existing studies have well solved this task (Q1) and whether the emerging large language models (LLMs) can bring new opportunities to this task (Q2). To this end, we propose a new benchmark PAGED, equipped with a large high-quality dataset and standard evaluations.... | Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei |  |
| 703 |  |  [Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors](https://doi.org/10.18653/v1/2024.acl-long.584) |  | 0 | With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text detection has emerged to distinguish between human and machine-generated content. However, recent research indicates that these detection systems often lack robustness and struggle to effectively... | Ying Zhou, Ben He, Le Sun |  |
| 704 |  |  [RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models](https://doi.org/10.18653/v1/2024.acl-long.585) |  | 0 | Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs). Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents. In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination. This paper presents RAGTruth, a corpus tailored for analyzing word-level... | Cheng Niu, Yuanhao Wu, Juno Zhu, Siliang Xu, Kashun Shum, Randy Zhong, Juntong Song, Tong Zhang |  |
| 705 |  |  [The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.586) |  | 0 | In the era of large language models (LLMs), hallucination (the tendency to generate factually incorrect content) poses great challenges to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the hallucination, three key questions should be well studied: how to detect hallucinations (detection), why do LLMs hallucinate (source), and what can be done to mitigate them (mitigation). To address these challenges, this work presents a systematic empirical study on LLM... | Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Xin Zhao, JianYun Nie, JiRong Wen |  |
| 706 |  |  [Revisiting Knowledge Distillation for Autoregressive Language Models](https://doi.org/10.18653/v1/2024.acl-long.587) |  | 0 | Knowledge distillation (KD) is a common approach to compress a teacher model to reduce its inference cost and memory footprint, by training a smaller student model. However, in the context of autoregressive language models (LMs), we empirically find that larger teacher LMs might dramatically result in a poorer student. In response to this problem, we conduct a series of analyses and reveal that different tokens have different teaching modes, neglecting which will lead to performance... | Qihuang Zhong, Liang Ding, Li Shen, Juhua Liu, Bo Du, Dacheng Tao |  |
| 707 |  |  [Continual Learning with Semi-supervised Contrastive Distillation for Incremental Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.588) |  | 0 | Incrementally expanding the capability of an existing translation model to solve new domain tasks over time is a fundamental and practical problem, which usually suffers from catastrophic forgetting. Generally, multi-domain learning can be seen as a good solution. However, there are two drawbacks: 1) it requires having the training data for all domains available at the same time, which may be unrealistic due to storage or privacy concerns; 2) it requires re-training the model on the data of all... | Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 708 |  |  [Make-A-Voice: Revisiting Voice Large Language Models as Scalable Multilingual and Multitask Learners](https://doi.org/10.18653/v1/2024.acl-long.589) |  | 0 | Large language models (LLMs) have successfully served as a general-purpose interface across multiple tasks and languages, while the adaptation of voice LLMs is mostly designed for specific purposes (either single-task or monolingual), where the advantages of LLMs especially for low-resource language processing and zero-shot task generalization are less exploited in the audio community. To bridge the gap, we introduce Make-A-Voice as a multi-modal voice LLM and conduct a comprehensive study on... | Rongjie Huang, Chunlei Zhang, Yongqi Wang, Dongchao Yang, Jinchuan Tian, Zhenhui Ye, Luping Liu, Zehan Wang, Ziyue Jiang, Xuankai Chang, Jiatong Shi, Chao Weng, Zhou Zhao, Dong Yu |  |
| 709 |  |  [Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages](https://doi.org/10.18653/v1/2024.acl-long.590) |  | 0 | Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of chat vector to equip pre-trained language models with instruction following and human value alignment via simple model arithmetic. The chat vector is derived by subtracting the weights of a pre-trained base model (e.g. LLaMA2) from those of... | ShihCheng Huang, PinZu Li, YuChi Hsu, KuangMing Chen, YuTung Lin, ShihKai Hsiao, Richard TzongHan Tsai, Hungyi Lee |  |
| 710 |  |  [PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails](https://doi.org/10.18653/v1/2024.acl-long.591) |  | 0 | Large language models (LLMs) are typically aligned to be harmless to humans. Unfortunately, recent work has shown that such models are susceptible to automated jailbreak attacks that induce them to generate harmful content. More recent LLMs often incorporate an additional layer of defense, a Guard Model, which is a second LLM that is designed to check and moderate the output response of the primary LLM. Our key contribution is to show a novel attack strategy, PRP, that is successful against... | Neal Mangaokar, Ashish Hooda, Jihye Choi, Shreyas Chandrashekaran, Kassem Fawaz, Somesh Jha, Atul Prakash |  |
| 711 |  |  [Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLMs-Powered Assistance](https://doi.org/10.18653/v1/2024.acl-long.592) |  | 0 | Learning from noisy labels (LNL) is a challenge that arises in many real-world scenarios where collected training data can contain incorrect or corrupted labels. Most existing solutions identify noisy labels and adopt active learning to query human experts on them for denoising. In the era of large language models (LLMs), although we can reduce the human effort to improve these methods, their performances are still subject to accurately separating the clean and noisy samples from noisy data. In... | Bo Yuan, Yulin Chen, Yin Zhang, Wei Jiang |  |
| 712 |  |  [CLOMO: Counterfactual Logical Modification with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.593) |  | 0 | In this study, we delve into the realm of counterfactual reasoning capabilities of large language models (LLMs). Our primary objective is to cultivate the counterfactual thought processes within LLMs and rigorously assess these processes for their validity. Specifically, we introduce a novel task, Counterfactual Logical Modification (CLOMO), and a high-quality human-annotated benchmark. In this task, LLMs must adeptly alter a given argumentative text to uphold a predetermined logical... | Yinya Huang, Ruixin Hong, Hongming Zhang, Wei Shao, Zhicheng Yang, Dong Yu, Changshui Zhang, Xiaodan Liang, Linqi Song |  |
| 713 |  |  [Exploring Hybrid Question Answering via Program-based Prompting](https://doi.org/10.18653/v1/2024.acl-long.594) |  | 0 | Question answering over heterogeneous data requires reasoning over diverse sources of data, which is challenging due to the large scale of information and organic coupling of heterogeneous data. Various approaches have been proposed to address these challenges. One approach involves training specialized retrievers to select relevant information, thereby reducing the input length. Another approach is to transform diverse modalities of data into a single modality, simplifying the task difficulty... | Qi Shi, Han Cui, Haofeng Wang, Qingfu Zhu, Wanxiang Che, Ting Liu |  |
| 714 |  |  [IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages](https://doi.org/10.18653/v1/2024.acl-long.595) |  | 0 | As large language models (LLMs) see increasing adoption across the globe, it is imperative for LLMs to be representative of the linguistic diversity of the world. India is a linguistically diverse country of 1.4 Billion people. To facilitate research on multilingual LLM evaluation, we release IndicGenBench — the largest benchmark for evaluating LLMs on user-facing generation tasks across a diverse set 29 of Indic languages covering 13 scripts and 4 language families. IndicGenBench is composed... | Harman Singh, Nitish Gupta, Shikhar Bharadwaj, Dinesh Tewari, Partha Talukdar |  |
| 715 |  |  [Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.596) |  | 0 | Temporal knowledge graph completion aims to infer the missing facts in temporal knowledge graphs. Current approaches usually embed factual knowledge into continuous vector space and apply geometric operations to learn potential patterns in temporal knowledge graphs. However, these methods only adopt a single operation, which may have limitations in capturing the complex temporal dynamics present in temporal knowledge graphs. Therefore, we propose a simple but effective method, i.e. TCompoundE,... | Rui Ying, Mengting Hu, Jianfeng Wu, Yalan Xie, Xiaoyi Liu, Zhunheng Wang, Ming Jiang, Hang Gao, Linlin Zhang, Renhong Cheng |  |
| 716 |  |  [Uncertainty Aware Learning for Language Model Alignment](https://doi.org/10.18653/v1/2024.acl-long.597) |  | 0 | As instruction-tuned large language models (LLMs) evolve, aligning pretrained foundation models presents increasing challenges. Existing alignment strategies, which typically leverage diverse and high-quality data sources, often overlook the intrinsic uncertainty of tasks, learning all data samples equally. This may lead to suboptimal data efficiency and model performance. In response, we propose uncertainty-aware learning (UAL) to improve the model alignment of different task scenarios, by... | Yikun Wang, Rui Zheng, Liang Ding, Qi Zhang, Dahua Lin, Dacheng Tao |  |
| 717 |  |  [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.598) |  | 0 | Accurate and interpretable user satisfaction estimation (USE) is critical for understanding, evaluating, and continuously improving conversational systems. Users express their satisfaction or dissatisfaction with diverse conversational patterns in both general-purpose (ChatGPT and Bing Copilot) and task-oriented (customer service chatbot) conversational systems. Existing approaches based on featurized ML models or text embeddings fall short in extracting generalizable patterns and are hard to... | YingChun Lin, Jennifer Neville, Jack W. Stokes, Longqi Yang, Tara Safavi, Mengting Wan, Scott Counts, Siddharth Suri, Reid Andersen, Xiaofeng Xu, Deepak Gupta, Sujay Kumar Jauhar, Xia Song, Georg Buscher, Saurabh Tiwary, Brent J. Hecht, Jaime Teevan |  |
| 718 |  |  [Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey](https://doi.org/10.18653/v1/2024.acl-long.599) |  | 0 | Large Language Models (LLMs) demonstrate significant value in domain-specific applications, benefiting from their fundamental capabilities. Nevertheless, it is still unclear which fundamental capabilities contribute to success in specific domains. Moreover, the existing benchmark-based evaluation cannot effectively reflect the performance of real-world applications. In this survey, we review recent advances of LLMs in domain applications, aiming to summarize the fundamental capabilities and... | Jiawei Li, Yizhe Yang, Yu Bai, Xiaofeng Zhou, Yinghao Li, Huashan Sun, Yuhang Liu, Xingpeng Si, Yuhao Ye, Yixiao Wu, Yiguan Lin, Bin Xu, Ren Bowen, Chong Feng, Yang Gao, Heyan Huang |  |
| 719 |  |  [Measuring Political Bias in Large Language Models: What Is Said and How It Is Said](https://doi.org/10.18653/v1/2024.acl-long.600) |  | 0 | We propose to measure political bias in LLMs by analyzing both the content and style of their generated content regarding political issues. Existing benchmarks and measures focus on gender and racial biases. However, political bias exists in LLMs and can lead to polarization and other harms in downstream applications. In order to provide transparency to users, we advocate that there should be fine-grained and explainable measures of political biases generated by LLMs. Our proposed measure looks... | Yejin Bang, Delong Chen, Nayeon Lee, Pascale Fung |  |
| 720 |  |  [Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use](https://doi.org/10.18653/v1/2024.acl-long.601) |  | 0 | In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in the context will be potentially overlooked by model when it is positioned in the trough zone of the attention waveform, leading to decreased performance. To address this issue, we propose a novel... | Yuhan Chen, Ang Lv, TingEn Lin, Changyu Chen, Yuchuan Wu, Fei Huang, Yongbin Li, Rui Yan |  |
| 721 |  |  [Layer-Condensed KV Cache for Efficient Inference of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.602) |  | 0 | Huge memory consumption has been a major bottleneck for deploying high-throughput large language models in real-world applications. In addition to the large number of parameters, the key-value (KV) cache for the attention mechanism in the transformer architecture consumes a significant amount of memory, especially when the number of layers is large for deep language models. In this paper, we propose a novel method that only computes and caches the KVs of a small number of layers, thus... | Haoyi Wu, Kewei Tu |  |
| 722 |  |  [Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages](https://doi.org/10.18653/v1/2024.acl-long.603) |  | 0 | While large language models (LLMs) have been pre-trained on multilingual corpora, their performance still lags behind in most languages compared to a few resource-rich languages. One common approach to mitigate this issue is to translate training data from resource-rich languages into other languages and then continue training. However, using the data obtained solely relying on translation while ignoring the original capabilities of LLMs across languages is not always effective, which we show... | Yuanchi Zhang, Yile Wang, Zijun Liu, Shuo Wang, Xiaolong Wang, Peng Li, Maosong Sun, Yang Liu |  |
| 723 |  |  [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](https://doi.org/10.18653/v1/2024.acl-long.604) |  | 0 | We introduce CHARM, the first benchmark for comprehensively and in-depth evaluating the commonsense reasoning ability of large language models (LLMs) in Chinese, which covers both globally known and Chinese-specific commonsense. We evaluated 7 English and 12 Chinese-oriented LLMs on CHARM, employing 5 representative prompt strategies for improving LLMs’ reasoning ability, such as Chain-of-Thought. Our findings indicated that the LLM’s language orientation and the task’s domain influence the... | Jiaxing Sun, Weiquan Huang, Jiang Wu, Chenya Gu, Wei Li, Songyang Zhang, Hang Yan, Conghui He |  |
| 724 |  |  [Browse and Concentrate: Comprehending Multimodal Content via Prior-LLM Context Fusion](https://doi.org/10.18653/v1/2024.acl-long.605) |  | 0 | With the bloom of Large Language Models (LLMs), Multimodal Large Language Models (MLLMs) that incorporate LLMs with pre-trained vision models have recently demonstrated impressive performance across diverse vision-language tasks. However, they fall short to comprehend context involving multiple images. A primary reason for this shortcoming is that the visual features for each images are encoded individually by frozen encoders before feeding into the LLM backbone, lacking awareness of other... | Ziyue Wang, Chi Chen, Yiqi Zhu, Fuwen Luo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu |  |
| 725 |  |  [Model Composition for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.606) |  | 0 | Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is resource-intensive and challenging to extend to new modalities. In this paper, we propose a new paradigm through the model composition of existing MLLMs to create a new model that retains the modal... | Chi Chen, Yiyang Du, Zheng Fang, Ziyue Wang, Fuwen Luo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu |  |
| 726 |  |  [Draft& Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.607) |  | 0 | We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower quality but more quickly, which is achieved by selectively skipping certain intermediate layers during drafting. Subsequently, the verification stage employs the original LLM to validate those draft... | Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Sharad Mehrotra |  |
| 727 |  |  [Soul-Mix: Enhancing Multimodal Machine Translation with Manifold Mixup](https://doi.org/10.18653/v1/2024.acl-long.608) |  | 0 | Multimodal machine translation (MMT) aims to improve the performance of machine translation with the help of visual information, which has received widespread attention recently. It has been verified that visual information brings greater performance gains when the textual information is limited. However, most previous works ignore to take advantage of the complete textual inputs and the limited textual inputs at the same time, which limits the overall performance. To solve this issue, we... | Xuxin Cheng, Ziyu Yao, Yifei Xin, Hao An, Hongxiang Li, Yaowei Li, Yuexian Zou |  |
| 728 |  |  [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.609) |  | 0 | The process of meaning composition, wherein smaller units like morphemes or words combine to form the meaning of phrases and sentences, is essential for human sentence comprehension. Despite extensive neurolinguistic research into the brain regions involved in meaning composition, a computational metric to quantify the extent of composition is still lacking. Drawing on the key-value memory interpretation of transformer feed-forward network blocks, we introduce the Composition Score, a novel... | Changjiang Gao, Jixing Li, Jiajun Chen, Shujian Huang |  |
| 729 |  |  [MIST: Mutual Information Maximization for Short Text Clustering](https://doi.org/10.18653/v1/2024.acl-long.610) |  | 0 | Short text clustering poses substantial challenges due to the limited amount of information provided by each text sample. Previous efforts based on dense representations are still inadequate as texts are not sufficiently segregated in the embedding space before clustering. Even though the state-of-the-art method utilizes contrastive learning to boost performance, the process of summarizing all local tokens to form a sequence representation for the whole text includes noise that may obscure... | Krissanee Kamthawee, Can Udomcharoenchaikit, Sarana Nutanong |  |
| 730 |  |  [Self-chats from Large Language Models Make Small Emotional Support Chatbot Better](https://doi.org/10.18653/v1/2024.acl-long.611) |  | 0 | Large Language Models (LLMs) have shown strong generalization abilities to excel in various tasks, including emotion support conversations. However, deploying such LLMs like GPT-3 (175B parameters) is resource-intensive and challenging at scale. In this study, we utilize LLMs as “Counseling Teacher” to enhance smaller models’ emotion support response abilities, significantly reducing the necessity of scaling up model size. To this end, we first introduce an iterative expansion framework, aiming... | Zhonghua Zheng, Lizi Liao, Yang Deng, Libo Qin, Liqiang Nie |  |
| 731 |  |  [Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment](https://doi.org/10.18653/v1/2024.acl-long.612) |  | 0 | The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced techniques such as instruction tuning and reinforcement learning from human feedback (RLHF). However, the computational efficiency required for LLMs, achieved through techniques like post-training quantization (PTQ), presents challenges such as token-flipping... | Janghwan Lee, Seongmin Park, Sukjin Hong, Minsoo Kim, DuSeong Chang, Jungwook Choi |  |
| 732 |  |  [Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.613) |  | 0 | Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit contextunderlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense infer-ences for contexts and questions involving interactions between complex events. To address this demand, we present COM2 (COMplexCOMmonsense), a new dataset created by sampling multi-hop logical queries (e.g., the joint effect or cause... | Tianqing Fang, Zeming Chen, Yangqiu Song, Antoine Bosselut |  |
| 733 |  |  [An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing](https://doi.org/10.18653/v1/2024.acl-long.614) |  | 0 | We present Expert-Token-Routing, a unified generalist framework that facilitates seamless integration of multiple expert LLMs. Our framework represents expert LLMs as special expert tokens within the vocabulary of a meta LLM. The meta LLM can route to an expert LLM like generating new tokens. Expert-Token-Routing not only supports learning the implicit expertise of expert LLMs from existing instruction dataset but also allows for dynamic extension of new expert LLMs in a plug-and-play manner.... | Ziwei Chai, Guoyin Wang, Jing Su, Tianjie Zhang, Xuanwen Huang, Xuwu Wang, Jingjing Xu, Jianbo Yuan, Hongxia Yang, Fei Wu, Yang Yang |  |
| 734 |  |  [Learning to Plan and Generate Text with Citations](https://doi.org/10.18653/v1/2024.acl-long.615) |  | 0 | The increasing demand for the deployment of LLMs in information-seeking scenarios has spurred efforts in creating verifiable systems, which generate responses to queries along with supporting evidence. In this paper, we explore the attribution capabilities of plan-based models which have been recently shown to improve the faithfulness, grounding, and controllability of generated text. We conceptualize plans as a sequence of questions which serve as blueprints of the generated content and its... | Constanza Fierro, Reinald Kim Amplayo, Fantine Huot, Nicola De Cao, Joshua Maynez, Shashi Narayan, Mirella Lapata |  |
| 735 |  |  [Exploring Precision and Recall to assess the quality and diversity of LLMs](https://doi.org/10.18653/v1/2024.acl-long.616) |  | 0 | We introduce a novel evaluation framework for Large Language Models (LLMs) such as Llama-2 and Mistral, focusing on importing Precision and Recall metrics from image generation to text generation. This approach allows for a nuanced assessment of the quality and diversity of generated text without the need for aligned corpora. By conducting a comprehensive evaluation of state-of-the-art language models, the study reveals new insights into their performance on open-ended generation tasks, which... | Florian Le Bronnec, Alexandre Verine, Benjamin Négrevergne, Yann Chevaleyre, Alexandre Allauzen |  |
| 736 |  |  [Aligning Large Language Models by On-Policy Self-Judgment](https://doi.org/10.18653/v1/2024.acl-long.617) |  | 0 | Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, SELF-JUDGE that (1) does on-policy learning and 2) is parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model to act as both a... | Sangkyu Lee, Sungdong Kim, Ashkan Yousefpour, Minjoon Seo, Kang Min Yoo, Youngjae Yu |  |
| 737 |  |  [IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning](https://doi.org/10.18653/v1/2024.acl-long.618) |  | 0 | Legal systems worldwide are inundated with exponential growth in cases and documents. There is an imminent need to develop NLP and ML techniques for automatically processing and understanding legal documents to streamline the legal system. However, evaluating and comparing various NLP models designed specifically for the legal domain is challenging. This paper addresses this challenge by proposing : Benchmark for Indian Legal Text Understanding and Reasoning. contains monolingual (English,... | Abhinav Joshi, Shounak Paul, Akshat Sharma, Pawan Goyal, Saptarshi Ghosh, Ashutosh Modi |  |
| 738 |  |  [JumpCoder: Go Beyond Autoregressive Coder via Online Modification](https://doi.org/10.18653/v1/2024.acl-long.619) |  | 0 | While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often leading to error propagation and suboptimal performance. We introduce JumpCoder, a novel model-agnostic framework that enables human-like online modification and non-sequential generation to augment code... | Mouxiang Chen, Hao Tian, Zhongxin Liu, Xiaoxue Ren, Jianling Sun |  |
| 739 |  |  [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.620) |  | 0 | Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the fine-tuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to instructions. Instruction fine-tuning (IFT) requires specifically constructed and annotated datasets. However, existing datasets are almost all in the English language. In this work, our primary goal... | Shivalika Singh, Freddie Vargus, Daniel D'souza, Börje Karlsson, Abinaya Mahendiran, WeiYin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura O'Mahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzeminski, Hakimeh Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Minh Vu Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet Üstün, Marzieh Fadaee, Sara Hooker |  |
| 740 |  |  [Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks](https://doi.org/10.18653/v1/2024.acl-long.621) |  | 0 | Large Language Models (LLMs) have transformed NLP with their remarkable In-context Learning (ICL) capabilities. Automated assistants based on LLMs are gaining popularity; however, adapting them to novel tasks is still challenging. While colossal models excel in zero-shot performance, their computational demands limit widespread use, and smaller language models struggle without context. This paper investigates whether LLMs can generalize from labeled examples of predefined tasks to novel tasks.... | Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty |  |
| 741 |  |  [Split and Rephrase with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.622) |  | 0 | The Split and Rephrase (SPRP) task, which consists in splitting complex sentences into a sequence of shorter grammatical sentences, while preserving the original meaning, can facilitate the processing of complex texts for humans and machines alike. It is also a valuable testbed to evaluate natural language processing models, as it requires modelling complex grammatical aspects. In this work, we evaluate large language models on the task, showing that they can provide large improvements over the... | David Ponce, Thierry Etchegoyhen, Jesus Calleja, Harritxu Gete |  |
| 742 |  |  [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://doi.org/10.18653/v1/2024.acl-long.623) |  | 0 | Self-attention is an essential component of large language models (LLM) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM requests have shared system prompts in prefixes. In this paper, we introduce ChunkAttention, a prefix-aware self-attention module that can detect matching prompt prefixes across multiple requests and share... | Lu Ye, Ze Tao, Yong Huang, Yang Li |  |
| 743 |  |  [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.624) |  | 0 | Alignment has become a critical step for instruction-tuned Large Language Models (LLMs) to become helpful assistants. However, effective evaluation of alignment for emerging Chinese LLMs is still significantly lacking, calling for real-scenario grounded, open-ended, challenging and automatic evaluations tailored for alignment. To fill in this gap, we introduce AlignBench, a comprehensive multi-dimensional benchmark for evaluating LLMs’ alignment in Chinese. We tailor a human-in-the-loop data... | Xiao Liu, Xuanyu Lei, Shengyuan Wang, Yue Huang, Andrew Feng, Bosi Wen, Jiale Cheng, Pei Ke, Yifan Xu, Weng Lam Tam, Xiaohan Zhang, Lichao Sun, Xiaotao Gu, Hongning Wang, Jing Zhang, Minlie Huang, Yuxiao Dong, Jie Tang |  |
| 744 |  |  [SAPT: A Shared Attention Framework for Parameter-Efficient Continual Learning of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.625) |  | 0 | The continual learning (CL) ability is vital for deploying large language models (LLMs) in the dynamic world. Existing methods devise the learning module to acquire task-specific knowledge with parameter-efficient tuning (PET) block and the selection module to pick out the corresponding one for the testing input, aiming at handling the challenges of catastrophic forgetting and knowledge transfer in CL. However, these methods tend to address only one of the challenges, ignoring the potential of... | Weixiang Zhao, Shilong Wang, Yulin Hu, Yanyan Zhao, Bing Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che |  |
| 745 |  |  [DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution](https://doi.org/10.18653/v1/2024.acl-long.626) |  | 0 | Fine-tuning large-scale pre-trained models is inherently a resource-intensive task. While it can enhance the capabilities of the model, it also incurs substantial computational costs, posing challenges to the practical application of downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods such as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the differential parameter budget requirements across weight matrices, which may lead to suboptimal fine-tuning... | Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu |  |
| 746 |  |  [Cross-Lingual Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.627) |  | 0 | Knowledge editing aims to change language models’ performance on several special cases (i.e., editing scope) by infusing the corresponding expected knowledge into them. With the recent advancements in large language models (LLMs), knowledge editing has been shown as a promising technique to adapt LLMs to new knowledge without retraining from scratch. However, most of the previous studies neglect the multi-lingual nature of some main-stream LLMs (e.g., LLaMA, ChatGPT and GPT-4), and typically... | Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, Jiarong Xu, Fandong Meng |  |
| 747 |  |  [Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques](https://doi.org/10.18653/v1/2024.acl-long.628) |  | 0 | Recent research on sequence labelling has been exploring different strategies to mitigate the lack of manually annotated data for the large majority of the world languages. Among others, the most successful approaches have been based on (i) the crosslingual transfer capabilities of multilingual pre-trained language models (model-transfer), (ii) data translation and label projection (data-transfer) and (iii), prompt-based learning by reusing the mask objective to exploit the few-shot... | Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri |  |
| 748 |  |  [Learning Task Decomposition to Assist Humans in Competitive Programming](https://doi.org/10.18653/v1/2024.acl-long.629) |  | 0 | When using language models (LMs) to solve complex problems, humans might struggle to understand the LM-generated solutions and repair the flawed ones. To assist humans in repairing them, we propose to automatically decompose complex solutions into multiple simpler pieces that correspond to specific subtasks. We introduce a novel objective for learning task decomposition, termed assistive value (AssistV), which measures the feasibility and speed for humans to repair the decomposed solution. We... | Jiaxin Wen, Ruiqi Zhong, Pei Ke, Zhihong Shao, Hongning Wang, Minlie Huang |  |
| 749 |  |  [An Entropy-based Text Watermarking Detection Method](https://doi.org/10.18653/v1/2024.acl-long.630) |  | 0 | Text watermarking algorithms for large language models (LLMs) can effectively identify machine-generated texts by embedding and detecting hidden features in the text. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy scenarios still needs to be improved. In this work, we opine that the influence of token entropy should be fully considered in the watermark detection process, i.e., the weight of each token during... | Yijian Lu, Aiwei Liu, Dianzhi Yu, Jingjing Li, Irwin King |  |
| 750 |  |  [Enhancing Explainable Rating Prediction through Annotated Macro Concepts](https://doi.org/10.18653/v1/2024.acl-long.631) |  | 0 | Generating recommendation reasons for recommendation results is a long-standing problem because it is challenging to explain the underlying reasons for recommending an item based on user and item IDs. Existing models usually learn semantic embeddings for each user and item, and generate the reasons according to the embeddings of the user-item pair. However, user and item IDs do not carry inherent semantic meaning, thus the limited number of reviews cannot model users’ preferences and item... | Huachi Zhou, Shuang Zhou, Hao Chen, Ninghao Liu, Fan Yang, Xiao Huang |  |
| 751 |  |  [How to Engage your Readers? Generating Guiding Questions to Promote Active Reading](https://doi.org/10.18653/v1/2024.acl-long.632) |  | 0 | Using questions in written text is an effective strategy to enhance readability. However, what makes an active reading question good, what the linguistic role of these questions is, and what is their impact on human reading remains understudied. We introduce GuidingQ, a dataset of 10K in-text questions from textbooks and scientific articles. By analyzing the dataset, we present a comprehensive understanding of the use, distribution, and linguistic characteristics of these questions. Then, we... | Peng Cui, Vilém Zouhar, Xiaoyu Zhang, Mrinmaya Sachan |  |
| 752 |  |  [Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective](https://doi.org/10.18653/v1/2024.acl-long.633) |  | 0 | Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model’s ability to timely terminate generation, leading to continued outputs beyond visual perception limits. By investigating how the model decides to terminate generation with EOS, the special end-of-sentence token, we find that the model assesses the... | Zihao Yue, Liang Zhang, Qin Jin |  |
| 753 |  |  [Integrate the Essence and Eliminate the Dross: Fine-Grained Self-Consistency for Free-Form Language Generation](https://doi.org/10.18653/v1/2024.acl-long.634) |  | 0 | Self-consistency (SC), leveraging multiple samples from LLMs, shows significant gains on various reasoning tasks but struggles with free-form generation due to the difficulty of aggregating answers. Its variants, UCS and USC, rely on sample selection or voting mechanisms to improve output quality. These methods, however, face limitations due to their inability to fully utilize the nuanced consensus knowledge present within multiple candidate samples, often resulting in suboptimal outputs. We... | Xinglin Wang, Yiwei Li, Shaoxiong Feng, Peiwen Yuan, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 754 |  |  [More frequent verbs are associated with more diverse valency frames: Efficient principles at the lexicon-grammar interface](https://doi.org/10.18653/v1/2024.acl-long.635) |  | 0 | A substantial body of work has provided evidence that the lexicons of natural languages are organized to support efficient communication. However, existing work has largely focused on word-internal properties, such as Zipf’s observation that more frequent words are optimized in form to minimize communicative cost. Here, we investigate the hypothesis that efficient lexicon organization is also reflected in valency, or the combinations and orders of additional words and phrases a verb selects for... | Siyu Tao, Lucia Donatelli, Michael Hahn |  |
| 755 |  |  [Quantifying Generalizations: Exploring the Divide Between Human and LLMs' Sensitivity to Quantification](https://doi.org/10.18653/v1/2024.acl-long.636) |  | 0 | Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., “Birds fly”), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the basis of how we express it (Hampton, 2012; Leslie, 2014).This study investigates how Large Language Models (LLMs) interpret generics, drawing upon psycholinguistic experimental methodologies.... | Claudia Collacciani, Giulia Rambelli, Marianna Bolognesi |  |
| 756 |  |  [Can Large Language Models Interpret Noun-Noun Compounds? A Linguistically-Motivated Study on Lexicalized and Novel Compounds](https://doi.org/10.18653/v1/2024.acl-long.637) |  | 0 | Noun-noun compounds interpretation is the task where a model is given one of such constructions, and it is asked to provide a paraphrase, making the semantic relation between the nouns explicit, as in carrot cake is “a cake made of carrots.” Such a task requires the ability to understand the implicit structured representation of the compound meaning. In this paper, we test to what extent the recent Large Language Models can interpret the semantic relation between the constituents of lexicalized... | Giulia Rambelli, Emmanuele Chersoni, Claudia Collacciani, Marianna Bolognesi |  |
| 757 |  |  [CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation](https://doi.org/10.18653/v1/2024.acl-long.638) |  | 0 | Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset. The dataset comprises 1,785 multi-turn... | Quan Tu, Shilong Fan, Zihang Tian, Tianhao Shen, Shuo Shang, Xin Gao, Rui Yan |  |
| 758 |  |  [Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond](https://doi.org/10.18653/v1/2024.acl-long.639) |  | 0 | The recent advancements in generative language models have demonstrated their ability to memorize knowledge from documents and recall knowledge to respond to user queries effectively. Building upon this capability, we propose to enable multimodal large language models (MLLMs) to memorize and recall images within their parameters. Given a user query for visual content, the MLLM is anticipated to “recall” the relevant image from its parameters as the response. Achieving this target presents... | Yongqi Li, Wenjie Wang, Leigang Qu, Liqiang Nie, Wenjie Li, TatSeng Chua |  |
| 759 |  |  [Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.640) |  | 0 | Aspect Sentiment Quad Prediction (ASQP) aims to predict all quads (aspect term, aspect category, opinion term, sentiment polarity) for a given review, which is the most representative and challenging task in aspect-based sentiment analysis. A key challenge in the ASQP task is the scarcity of labeled data, which limits the performance of existing methods. To tackle this issue, we propose a self-training framework with a pseudo-label scorer, wherein a scorer assesses the match between reviews and... | Yice Zhang, Jie Zeng, Weiming Hu, Ziyi Wang, Shiwei Chen, Ruifeng Xu |  |
| 760 |  |  [Learning to Generate Answers with Citations via Factual Consistency Models](https://doi.org/10.18653/v1/2024.acl-long.641) |  | 0 | Large Language Models (LLMs) frequently hallucinate, impeding their reliability in mission-critical situations. One approach to address this issue is to provide citations to relevant sources alongside generated content, enhancing the verifiability of generations. However, citing passages accurately in answers remains a substantial challenge. This paper proposes a weakly-supervised fine-tuning method leveraging factual consistency models (FCMs). Our approach alternates between generating texts... | Rami Aly, Zhiqiang Tang, Samson Tan, George Karypis |  |
| 761 |  |  [Improving Text Embeddings with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.642) |  | 0 | In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by fine-tuning with a few labeled datasets, our method does not require building complex training pipelines or relying on manually collected datasets that are often constrained by task diversity and... | Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, Furu Wei |  |
| 762 |  |  [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.643) |  | 0 | Teaching small-scale language models to perform math reasoning is a valuable yet challenging task. Besides obtaining labeled data from human experts, one of the most common ways to collect high-quality data is by sampling from a larger and more powerful language model. Although previous works have demonstrated the effectiveness of this method, such a knowledge distillation paradigm can be costly and unstable, especially considering that many large language models, such as GPT-4, are... | Tianduo Wang, Shichen Li, Wei Lu |  |
| 763 |  |  [UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset](https://doi.org/10.18653/v1/2024.acl-long.644) |  | 0 | Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual abilities.In this work, we therefore construct an open-source multilingual supervised fine-tuning dataset.Different from previous works that simply translate English instructions, we consider both the language-specific and language-agnostic abilities of LLMs. Firstly,... | Haoyu Wang, Shuo Wang, Yukun Yan, Xujia Wang, Zhiyu Yang, Yuzhuang Xu, Zhenghao Liu, Liner Yang, Ning Ding, Xu Han, Zhiyuan Liu, Maosong Sun |  |
| 764 |  |  [Document-level Claim Extraction and Decontextualisation for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.645) |  | 0 | Selecting which claims to check is a time-consuming task for human fact-checkers, especially from documents consisting of multiple sentences and containing multiple claims. However, existing claim extraction approaches focus more on identifying and extracting claims from individual sentences, e.g., identifying whether a sentence contains a claim or the exact boundaries of the claim within a sentence. In this paper, we propose a method for document-level claim extraction for fact-checking, which... | Zhenyun Deng, Michael Sejr Schlichtkrull, Andreas Vlachos |  |
| 765 |  |  [PairCFR: Enhancing Model Training on Paired Counterfactually Augmented Data through Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.646) |  | 0 | Counterfactually Augmented Data (CAD) involves creating new data samples by applying minimal yet sufficient modifications to flip the label of existing data samples to other classes. Training with CAD enhances model robustness against spurious features that happen to correlate with labels by spreading the casual relationships across different classes. Yet, recent research reveals that training with CAD may lead models to overly focus on modified features while ignoring other important... | Xiaoqi Qiu, Yongjie Wang, Xu Guo, Zhiwei Zeng, Yu Yue, Yuhong Feng, Chunyan Miao |  |
| 766 |  |  [LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.647) |  | 0 | In this study, we explore in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting tailored for the EAE task. Specifically, we hypothesize and validate that LLMs learn task-specific heuristics from demonstrations in ICL. Building upon this hypothesis, we introduce an explicit heuristic-driven demonstration construction approach, which... | Hanzhang Zhou, Junlang Qian, Zijian Feng, Hui Lu, Zixiao Zhu, Kezhi Mao |  |
| 767 |  |  [Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.648) |  | 0 | Though advanced in understanding visual information with human languages, Large Vision-Language Models (LVLMs) still suffer from multimodal hallucinations. A natural concern is that during multimodal interaction, the generated hallucinations could influence the LVLMs’ subsequent generation. Thus, we raise a question: When presented with a query relevant to the previously generated hallucination, will LVLMs be misled and respond incorrectly, even though the ground visual information exists? To... | Weihong Zhong, Xiaocheng Feng, Liang Zhao, Qiming Li, Lei Huang, Yuxuan Gu, Weitao Ma, Yuan Xu, Bing Qin |  |
| 768 |  |  [mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models](https://doi.org/10.18653/v1/2024.acl-long.649) |  | 0 | Large language models (LLMs) with Chain-of-thought (CoT) have recently emerged as a powerful technique for eliciting reasoning to improve various downstream tasks. As most research mainly focuses on English, with few explorations in a multilingual context, the question of how reliable this reasoning capability is in different languages is still open. To address it directly, we study multilingual reasoning consistency across multiple languages, using popular open-source LLMs. First, we compile... | Huiyuan Lai, Malvina Nissim |  |
| 769 |  |  [GunStance: Stance Detection for Gun Control and Gun Regulation](https://doi.org/10.18653/v1/2024.acl-long.650) |  | 0 | The debate surrounding gun control and gun regulation in the United States has intensified in the wake of numerous mass shooting events. As perspectives on this matter vary, it becomes increasingly important to comprehend individuals’ positions. Stance detection, the task of determining an author’s position towards a proposition or target, has gained attention for its potential use in understanding public perceptions towards controversial topics and identifying the best strategies to address... | Nikesh Gyawali, Iustin Sirbu, Tiberiu Sosea, Sarthak Khanal, Doina Caragea, Traian Rebedea, Cornelia Caragea |  |
| 770 |  |  [Beyond Traditional Benchmarks: Analyzing Behaviors of Open LLMs on Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.651) |  | 0 | We analyze the behaviors of open large language models (LLMs) on the task of data-to-text (D2T) generation, i.e., generating coherent and relevant text from structured data. To avoid the issue of LLM training data contamination with standard benchmarks, we design Quintd - a tool for collecting novel structured data records from public APIs. We find that open LLMs (Llama 2, Mistral, and Zephyr) can generate fluent and coherent texts in zero-shot settings from data in common formats collected... | Zdenek Kasner, Ondrej Dusek |  |
| 771 |  |  [Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.acl-long.652) |  | 0 | The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue remains insufficiently examined. This paper delves into the capability of LLMs to detect implicit hate speech and express confidence in their responses. Our evaluation meticulously considers various prompt... | Min Zhang, Jianfeng He, Taoran Ji, ChangTien Lu |  |
| 772 |  |  [Don't Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation](https://doi.org/10.18653/v1/2024.acl-long.653) |  | 0 | Neural machine translation systems estimate probabilities of target sentences given source sentences, yet these estimates may not align with human preferences. This work introduces QE-fusion, a method that synthesizes translations using a quality estimation metric (QE), which correlates better with human judgments. QE-fusion leverages a pool of candidates sampled from a model, combining spans from different candidates using a QE metric such as CometKiwi. We compare QE-fusion against beam search... | Giorgos Vernikos, Andrei PopescuBelis |  |
| 773 |  |  [Generating and Evaluating Plausible Explanations for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.654) |  | 0 | Explanations for AI should aid human users, yet this ultimate goal remains under-explored. This paper aims to bridge this gap by investigating the specific explanatory needs of human users in the context of Knowledge Graph Completion (KGC) systems. In contrast to the prevailing approaches that primarily focus on mathematical theories, we recognize the potential limitations of explanations that may end up being overly complex or nonsensical for users. Through in-depth user interviews, we gain... | Antonio Di Mauro, Zhao Xu, Wiem Ben Rim, Timo Sztyler, Carolin Lawrence |  |
| 774 |  |  [One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation](https://doi.org/10.18653/v1/2024.acl-long.655) |  | 0 | Evaluation of opinion summaries using conventional reference-based metrics often fails to provide a comprehensive assessment and exhibits limited correlation with human judgments. While Large Language Models (LLMs) have shown promise as reference-free metrics for NLG evaluation, their potential remains unexplored for opinion summary evaluation. Furthermore, the absence of sufficient opinion summary evaluation datasets hinders progress in this area. In response, we introduce the SUMMEVAL-OP... | Tejpalsingh Siledar, Swaroop Nath, Sankara Sri Raghava Ravindra Muddu, Rupasai Rangaraju, Swaprava Nath, Pushpak Bhattacharyya, Suman Banerjee, Amey Patil, Sudhanshu Singh, Muthusamy Chelliah, Nikesh Garera |  |
| 775 |  |  [LANDeRMT: Dectecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.656) |  | 0 | Recent advancements in large language models (LLMs) have shown promising results in multilingual translation even with limited bilingual supervision. The major challenges are catastrophic forgetting and parameter interference for finetuning LLMs when provided parallel training data. To address these challenges, we propose LANDeRMT, a Language-Aware Neuron Detecting and Routing framework that selectively finetunes LLMs to Machine Translation with diverse translation training data. In LANDeRMT,... | Shaolin Zhu, Leiyu Pan, Bo Li, Deyi Xiong |  |
| 776 |  |  [A Joint Coreference-Aware Approach to Document-Level Target Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.657) |  | 0 | Most existing work on aspect-based sentiment analysis (ABSA) focuses on the sentence level, while research at the document level has not received enough attention. Compared to sentence-level ABSA, the document-level ABSA is not only more practical but also requires holistic document-level understanding capabilities such as coreference resolution. To investigate the impact of coreference information on document-level ABSA, we conduct a three-stage research for the document-level target sentiment... | Hongjie Cai, Heqing Ma, Jianfei Yu, Rui Xia |  |
| 777 |  |  [VisDiaHalBench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.658) |  | 0 | Despite the significant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hallucination problem, where the LVLMs’ response contains descriptions of non-existent objects. Although various benchmarks have been proposed to investigate this problem, they mostly focus on single-turn evaluation and overlook the hallucination raised by textual inputs. To investigate the hallucination problem of LVLMs when given long-term misleading textual history,... | Qingxing Cao, Junhao Cheng, Xiaodan Liang, Liang Lin |  |
| 778 |  |  [AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints](https://doi.org/10.18653/v1/2024.acl-long.659) |  | 0 | Accurate representation of procedures in restricted scenarios, such as non-standardized scientific experiments, requires precise depiction of constraints. Unfortunately, Domain-specific Language (DSL), as an effective tool to express constraints structurally, often requires case-by-case hand-crafting, necessitating customized, labor-intensive efforts. To overcome this challenge, we introduce the AutoDSL framework to automate DSL-based constraint design across various domains. Utilizing domain... | YuZhe Shi, Haofei Hou, Zhangqian Bi, Fanxu Meng, Xiang Wei, Lecheng Ruan, Qining Wang |  |
| 779 |  |  [Multipath parsing in the brain](https://doi.org/10.18653/v1/2024.acl-long.660) |  | 0 | Humans understand sentences word-by-word, in the order that they hear them. This incrementality entails resolving temporary ambiguities about syntactic relationships. We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency parsers with timecourse data from people undergoing functional neuroimaging while listening to an audiobook. In particular, we compare competing hypotheses regarding the number of developing syntactic... | Berta Franzluebbers, Donald Dunagan, Milos Stanojevic, Jan Buys, John T. Hale |  |
| 780 |  |  [Search-Adaptor: Embedding Customization for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.661) |  | 0 | Embeddings extracted by pre-trained Large Language Models (LLMs) have significant potential to improve information retrieval and search. Beyond the zero-shot setup in which they are being conventionally used, being able to take advantage of the information from the relevant query-corpus paired data can further boost the LLM capabilities. In this paper, we propose a novel method, Search-Adaptor, for customizing LLMs for information retrieval in an efficient and robust way. Search-Adaptor... | Jinsung Yoon, Yanfei Chen, Sercan Ö. Arik, Tomas Pfister |  |
| 781 |  |  [Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs](https://doi.org/10.18653/v1/2024.acl-long.662) |  | 0 | AI alignment in the shape of Reinforcement Learning from Human Feedback (RLHF) is increasingly treated as a crucial ingredient for high performance large language models. Proximal Policy Optimization (PPO) has been installed by the seminal literature as the standard method for the RL part of RLHF. However, it involves both high computational cost and sensitive hyperparameter tuning. We posit that most of the motivational principles that led to the development of PPO are less of a practical... | Arash Ahmadian, Chris Cremer, Matthias Gallé, Marzieh Fadaee, Julia Kreutzer, Olivier Pietquin, Ahmet Üstün, Sara Hooker |  |
| 782 |  |  [VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation](https://doi.org/10.18653/v1/2024.acl-long.663) |  | 0 | In the rapidly advancing field of conditional image generation research, challenges such as limited explainability lie in effectively evaluating the performance and capabilities of various models. This paper introduces VIEScore, a Visual Instruction-guided Explainable metric for evaluating any conditional image generation tasks. VIEScore leverages general knowledge from Multimodal Large Language Models (MLLMs) as the backbone and does not require training or fine-tuning. We evaluate VIEScore on... | Max Ku, Dongfu Jiang, Cong Wei, Xiang Yue, Wenhu Chen |  |
| 783 |  |  [Tree Transformer's Disambiguation Ability of Prepositional Phrase Attachment and Garden Path Effects](https://doi.org/10.18653/v1/2024.acl-long.664) |  | 0 | This work studies two types of ambiguity in natural language: prepositional phrase (PP) attachment ambiguity, and garden path constructions. Due to the different nature of these ambiguities – one being structural, the other incremental in nature – we pretrain and evaluate the Tree Transformer of Wang et al. (2019), an unsupervised Transformer model that induces tree representations internally. To assess PP attachment ambiguity we inspect the model’s induced parse trees against a newly prepared... | Lingling Zhou, Suzan Verberne, Gijs Wijnholds |  |
| 784 |  |  [Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.665) |  | 0 | Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning algorithm that enables augmentation of black-box LLMs with one or more KGs. The algorithm equips a LLM with actions for interfacing a KG and enables the LLM to perform tree search over possible... | Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, KaiWei Chang, Aram Galstyan |  |
| 785 |  |  [Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.666) |  | 0 | We present the structured average intersection-over-union ratio (STRUCT-IOU), an evaluation metric that compares a constituency parse tree over automatically recognized spoken word boundaries with the ground-truth parse tree over written words. To compute the metric, we (1) project the ground-truth parse tree to the speech domain by forced alignment, (2) align the projected ground-truth constituents with the predicted ones under certain structured constraints, and (3) calculate the average IOU... | Freda Shi, Kevin Gimpel, Karen Livescu |  |
| 786 |  |  [ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.667) |  | 0 | Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap, we introduce the ViSAGe (Visual Stereotypes Around the Globe) dataset to enable the evaluation of known nationality-based stereotypes in T2I models, across 135 nationalities. We enrich an existing... | Akshita Jha, Vinodkumar Prabhakaran, Remi Denton, Sarah Laszlo, Shachi Dave, Rida Qadri, Chandan K. Reddy, Sunipa Dev |  |
| 787 |  |  [Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking](https://doi.org/10.18653/v1/2024.acl-long.668) |  | 0 | This paper proposes PiNose, which trains a probing model on offline self-consistency checking results, thereby circumventing the need for human-annotated data and achieving transferability across diverse data distributions. As the consistency check process is offline, PiNose reduces the computational burden of generating multiple responses by online consistency verification. Additionally, it examines various aspects of internal states prior to response decoding, contributing to more effective... | Xiaokang Zhang, Zijun Yao, Jing Zhang, Kaifeng Yun, Jifan Yu, Juanzi Li, Jie Tang |  |
| 788 |  |  [What Do Language Models Learn in Context? The Structured Task Hypothesis](https://doi.org/10.18653/v1/2024.acl-long.669) |  | 0 | Large language models (LLMs) exhibit an intriguing ability to learn a novel task from in-context examples presented in a demonstration, termed in-context learning (ICL). Understandably, a swath of research has been dedicated to uncovering the theories underpinning ICL. One popular hypothesis explains ICL by task selection. LLMs identify the task based on the demonstration and generalize it to the prompt. Another popular hypothesis is that ICL is a form of meta-learning, i.e., the models learn a... | Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell |  |
| 789 |  |  [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://doi.org/10.18653/v1/2024.acl-long.670) |  | 0 | Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce Lumos, one of the first frameworks for training open-source LLM-based agents. Lumos features a learnable, unified and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into the... | Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Raghavi Chandu, KaiWei Chang, Yejin Choi, Bill Yuchen Lin |  |
| 790 |  |  [Investigating Cultural Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.671) |  | 0 | The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the diverse knowledge adopted by different cultures? Our study reveals that these models demonstrate greater cultural alignment along two dimensions—firstly, when prompted with the dominant language of a... | Badr AlKhamissi, Muhammad N. ElNokrashy, Mai Alkhamissi, Mona T. Diab |  |
| 791 |  |  [More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play](https://doi.org/10.18653/v1/2024.acl-long.672) |  | 0 | The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy AI, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics, which is why the game has received attention as an AI challenge. This work seeks to understand the degree to which Cicero succeeds at communication. First, we annotate in-game communication with... | Wichayaporn Wongkamjan, Feng Gu, Yanze Wang, Ulf Hermjakob, Jonathan May, Brandon M. Stewart, Jonathan K. Kummerfeld, Denis Peskoff, Jordan L. BoydGraber |  |
| 792 |  |  [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://doi.org/10.18653/v1/2024.acl-long.673) |  | 0 | We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VoiceCraft produces edited speech that is nearly... | Puyuan Peng, PoYao Huang, ShangWen Li, Abdelrahman Mohamed, David Harwath |  |
| 793 |  |  [RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors](https://doi.org/10.18653/v1/2024.acl-long.674) |  | 0 | Many commercial and open-source models claim to detect machine-generated text with extremely high accuracy (99% or more). However, very few of these detectors are evaluated on shared benchmark datasets and even when they are, the datasets used for evaluation are insufficiently challenging—lacking variations in sampling strategy, adversarial attacks, and open-source generative models. In this work we present RAID: the largest and most challenging benchmark dataset for machine-generated text... | Liam Dugan, Alyssa Hwang, Filip Trhlík, Andrew Zhu, Josh Magnus Ludan, Hainiu Xu, Daphne Ippolito, Chris CallisonBurch |  |
| 794 |  |  [Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles](https://doi.org/10.18653/v1/2024.acl-long.675) |  | 0 | A dog whistle is a form of coded communication that carries a secondary meaning to specific audiences and is often weaponized for racial and socioeconomic discrimination. Dog whistling historically originated from United States politics, but in recent years has taken root in social media as a means of evading hate speech detection systems and maintaining plausible deniability. In this paper, we present an approach for word-sense disambiguation of dog whistles from standard speech using Large... | Julia Kruk, Michela Marchini, Rijul Magu, Caleb Ziems, David Muchlinski, Diyi Yang |  |
| 795 |  |  [On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.676) |  | 0 | The performance of modern language models (LMs) has been improved by chain-of-thought (CoT) reasoning, i.e., the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that CoT reasoning extends an LM’s computational power, as RNNs and transformers with additional scratch space are known to be Turing complete. Comparing LMs to Turing machines, however, introduces a category error—Turing machines decide language... | Franz Nowak, Anej Svete, Alexandra Butoi, Ryan Cotterell |  |
| 796 |  |  [Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends](https://doi.org/10.18653/v1/2024.acl-long.677) |  | 0 | Recent advancements in large language models (LLMs) have significantly advanced the capabilities of summarization systems.However, they continue to face a persistent challenge: hallucination. While prior work has extensively examined LLMs in news domains, evaluation of dialogue summarization has primarily focused on BART-based models, resulting in a notable gap in understanding LLM effectiveness.Our work seeks to address this gap by benchmarking LLMs for dialogue summarization faithfulness... | Sanjana Ramprasad, Elisa Ferracane, Zachary C. Lipton |  |
| 797 |  |  [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://doi.org/10.18653/v1/2024.acl-long.678) |  | 0 | Large language models (LLMs) are central to modern natural language processing, delivering exceptional performance in various tasks. However, their substantial computational and memory requirements present challenges, especially for devices with limited DRAM capacity. This paper tackles the challenge of efficiently running LLMs that exceed the available DRAM capacity by storing the model parameters in flash memory, but bringing them on demand to DRAM. Our method involves constructing an... | Keivan Alizadeh, Iman Mirzadeh, Dmitry Belenko, S. Khatamifard, Minsik Cho, Mohammad Rastegari, Mehrdad Farajtabar |  |
| 798 |  |  [Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models](https://doi.org/10.18653/v1/2024.acl-long.679) |  | 0 | Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the under-explored field of video-based conversation by introducing Video-ChatGPT. It is a multimodal model that merges a video-adapted visual encoder with an LLM. The resulting model is capable of understanding and generating detailed conversations about videos. We introduce a new dataset... | Muhammad Maaz, Hanoona Abdul Rasheed, Salman Khan, Fahad Khan |  |
| 799 |  |  [To Distill or Not to Distill? On the Robustness of Robust Knowledge Distillation](https://doi.org/10.18653/v1/2024.acl-long.680) |  | 0 | Arabic is known to present unique challengesfor Automatic Speech Recognition (ASR). Onone hand, its rich linguistic diversity andwide range of dialects complicate the de-velopment of robust, inclusive models. Onthe other, current multilingual ASR modelsare compute-intensive and lack proper com-prehensive evaluations. In light of thesechallenges, we distill knowledge from largeteacher models into smaller student variantsthat more efficient. We also introduce a novelhuman-annotated dataset... | Abdul Waheed, Karima Kadaoui, Muhammad AbdulMageed |  |
| 800 |  |  [LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.681) |  | 0 | We present LayerSkip, an end-to-end solution to speed-up inference of large language models (LLMs). First, during training we apply layer dropout, with low dropout rates for earlier layers and higher dropout rates for later layers, and an early exit loss where all transformer layers share the same exit. Second, during inference, we show that this training recipe increases the accuracy of early exit at earlier layers, without adding any auxiliary layers or modules to the model. Third, we present... | Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, Ahmed A Aly, Beidi Chen, CaroleJean Wu |  |
| 801 |  |  [Classist Tools: Social Class Correlates with Performance in NLP](https://doi.org/10.18653/v1/2024.acl-long.682) |  | 0 | The field of sociolinguistics has studied factors affecting language use for the last century. Labov (1964) and Bernstein (1960) showed that socioeconomic class strongly influences our accents, syntax and lexicon. However, despite growing concerns surrounding fairness and bias in Natural Language Processing (NLP), there is a dearth of studies delving into the effects it may have on NLP systems. We show empirically that NLP systems’ performance is affected by speakers’ SES, potentially... | Amanda Cercas Curry, Giuseppe Attanasio, Zeerak Talat, Dirk Hovy |  |
| 802 |  |  [ActionIE: Action Extraction from Scientific Literature with Programming Languages](https://doi.org/10.18653/v1/2024.acl-long.683) |  | 0 | Extraction of experimental procedures from human language in scientific literature and patents into actionable sequences in robotics language holds immense significance in scientific domains. Such an action extraction task is particularly challenging given the intricate details and context-dependent nature of the instructions, especially in fields like chemistry where reproducibility is paramount. In this paper, we introduce ActionIE, a method that leverages Large Language Models (LLMs) to... | Xianrui Zhong, Yufeng Du, Siru Ouyang, Ming Zhong, Tingfeng Luo, Qirong Ho, Hao Peng, Heng Ji, Jiawei Han |  |
| 803 |  |  [A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech](https://doi.org/10.18653/v1/2024.acl-long.684) |  | 0 | Violence-provoking speech – speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of harmful speech, like fear speech and hate speech, our work takes a community-centric approach to studying anti-Asian violence-provoking speech. Using data from ~420k Twitter posts spanning a 3-year... | Gaurav Verma, Rynaa Grover, Jiawei Zhou, Binny Mathew, Jordan Kraemer, Munmun De Choudhury, Srijan Kumar |  |
| 804 |  |  [Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs](https://doi.org/10.18653/v1/2024.acl-long.685) |  | 0 | The growing popularity of Large Language Models has sparked interest in context compression for Large Language Models (LLMs). However, the performance of previous methods degrades dramatically as compression ratios increase, sometimes even falling to the closed-book level. This decline can be attributed to the loss of key information during the compression process. Our preliminary study supports this hypothesis, emphasizing the significance of retaining key information to maintain model... | Zhiwei Cao, Qian Cao, Yu Lu, Ningxin Peng, Luyang Huang, Shanbo Cheng, Jinsong Su |  |
| 805 |  |  [COSMIC: Mutual Information for Task-Agnostic Summarization Evaluation](https://doi.org/10.18653/v1/2024.acl-long.686) |  | 0 | Assessing the quality of summarizers poses significant challenges—gold summaries are hard to obtain and their suitability depends on the use context of the summarization system. Who is the user of the system, and what do they intend to do with the summary? In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries while preserving task outcomes. We theoretically establish both a lower and upper bound on the expected... | Maxime Darrin, Philippe Formont, Jackie Chi Kit Cheung, Pablo Piantanida |  |
| 806 |  |  [EUROPA: A Legal Multilingual Keyphrase Generation Dataset](https://doi.org/10.18653/v1/2024.acl-long.687) |  | 0 | Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a novel dataset for multilingual keyphrase generation in the legal domain. It is derived from legal judgments from the Court of Justice of the European Union (EU), and contains instances in all 24 EU official languages. We run multilingual models on our corpus and analyze the results, showing... | Olivier Salaün, Frédéric Piedboeuf, Guillaume Le Berre, David AlfonsoHermelo, Philippe Langlais |  |
| 807 |  |  [GLIMPSE: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews](https://doi.org/10.18653/v1/2024.acl-long.688) |  | 0 | Scientific peer review is essential for the quality of academic publications. However, the increasing number of paper submissions to conferences has strained the reviewing process. This surge poses a burden on area chairs who have to carefully read an ever-growing volume of reviews and discern each reviewer’s main arguments as part of their decision process. In this paper, we introduce , a summarization method designed to offer a concise yet comprehensive overview of scholarly reviews. Unlike... | Maxime Darrin, Ines Arous, Pablo Piantanida, Jackie Chi Kit Cheung |  |
| 808 |  |  [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](https://doi.org/10.18653/v1/2024.acl-long.689) |  | 0 | Multimodal large language models (MLLMs) have proven effective in a wide range of tasks that require complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, the success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, even those with large speaker populations, such as Arabic. To alleviate this challenge, we... | Fakhraddin Alwajih, El Moatez Billah Nagoudi, Gagan Bhatia, Abdelrahman Mohamed, Muhammad AbdulMageed |  |
| 809 |  |  [Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks](https://doi.org/10.18653/v1/2024.acl-long.690) |  | 0 | Multistep instructions, such as recipes and how-to guides, greatly benefit from visual aids, such as a series of images that accompany the instruction steps. While Large Language Models (LLMs) have become adept at generating coherent textual steps, Large Vision/Language Models (LVLMs) are less capable of generating accompanying image sequences. The most challenging aspect is that each generated image needs to adhere to the relevant textual step instruction, as well as be visually consistent... | João Bordalo, Vasco Ramos, Rodrigo Valerio, Diogo GlóriaSilva, Yonatan Bitton, Michal Yarom, Idan Szpektor, João Magalhães |  |
| 810 |  |  [Cheetah: Natural Language Generation for 517 African Languages](https://doi.org/10.18653/v1/2024.acl-long.691) |  | 0 | Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations... | Ife Adebara, AbdelRahim A. Elmadany, Muhammad AbdulMageed |  |
| 811 |  |  [TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table QA by Content Planning and Execution-based Reasoning](https://doi.org/10.18653/v1/2024.acl-long.692) |  | 0 | Long-form Table Question Answering (LFTQA) requires systems to generate paragraph long and complex answers to questions over tabular data. While Large language models based systems have made significant progress, it often hallucinates, especially when the task involves complex reasoning over tables. To tackle this issue, we propose a new LLM-based framework, TaPERA, for LFTQA tasks. Our framework uses a modular approach that decomposes the whole process into three sub-modules: 1) QA-based... | Yilun Zhao, Lyuhao Chen, Arman Cohan, Chen Zhao |  |
| 812 |  |  [KnowledgeFMath: A Knowledge-Intensive Math Reasoning Dataset in Finance Domains](https://doi.org/10.18653/v1/2024.acl-long.693) |  | 0 | We introduce FinanceMath, a novel benchmark designed to evaluate LLMs' capabilities in solving knowledge-intensive math reasoning problems. Compared to prior works, this study features three core advancements. First, FinanceMath includes 1,200 problems with a hybrid of textual and tabular content. These problems require college-level knowledge in the finance domain for effective resolution. Second, we provide expert-annotated, detailed solution references in Python program format, ensuring a... | Yilun Zhao, Hongjun Liu, Yitao Long, Rui Zhang, Chen Zhao, Arman Cohan |  |
| 813 |  |  [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://doi.org/10.18653/v1/2024.acl-long.694) |  | 0 | There is a growing need for Large Language Models (LLMs) to effectively use tools and external Application Programming Interfaces (APIs) to plan and complete tasks. As such, there is tremendous interest in methods that can acquire sufficient quantities of train and test data that involve calls to tools / APIs. Two lines of research have emerged as the predominant strategies for addressing this challenge. The first has focused on synthetic data generation techniques, while the second has... | Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, Maxwell Crouse, Asim Munawar, Vernon Austel, Sadhana Kumaravel, Vinod Muthusamy, Pavan Kapanipathi, Luis A. Lastras |  |
| 814 |  |  [LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks](https://doi.org/10.18653/v1/2024.acl-long.695) |  | 0 | LoRA employs lightweight modules to customize large language models (LLMs) for each downstream task or domain, where different learned additional modules represent diverse skills. Combining existing LoRAs to address new tasks can enhance the reusability of learned LoRAs, particularly beneficial for tasks with limited annotated data. Most prior works on LoRA combination primarily rely on task-level weights for each involved LoRA, making different examples and tokens share the same LoRA weights.... | Hanqing Wang, Bowen Ping, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu, Maosong Sun |  |
| 815 |  |  [Harder Task Needs More Experts: Dynamic Routing in MoE Models](https://doi.org/10.18653/v1/2024.acl-long.696) |  | 0 | In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike existing MoE approaches that rely on fixed TopK Routing, which activates a predetermined number of experts regardless of the input’s complexity, our method dynamically allocates experts based on the confidence level in expert selection for each... | Quzhe Huang, Zhenwei An, Nan Zhuang, Mingxu Tao, Chen Zhang, Yang Jin, Kun Xu, Liwei Chen, Songfang Huang, Yansong Feng |  |
| 816 |  |  [XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception](https://doi.org/10.18653/v1/2024.acl-long.697) |  | 0 | Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer languages than audio-only resources.To address this gap, we present XLAVS-R, a cross-lingual audio-visual speech representation model for noise-robust speech recognition and translation in over 100... | HyoJung Han, Mohamed Anwar, Juan Pino, WeiNing Hsu, Marine Carpuat, Bowen Shi, Changhan Wang |  |
| 817 |  |  [SOTOPIA-π: Interactive Learning of Socially Intelligent Language Agents](https://doi.org/10.18653/v1/2024.acl-long.698) |  | 0 | Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-π, that improves the social intelligence of language agents. This method leverages behavior cloning and self-reinforcement based training on filtered social interaction data according to large language model (LLM) rating. We show that our training... | Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Yonatan Bisk, Graham Neubig, Hao Zhu |  |
| 818 |  |  [\mathcal XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts](https://doi.org/10.18653/v1/2024.acl-long.699) |  | 0 | We introduce XFT, a simple yet powerful training scheme, by simply merging upcycled Mixture-of-Experts (MoE) to unleash the performance limit of instruction-tuned code Large Language Models (LLMs). While vanilla sparse upcycling fails to improve instruction tuning, XFT introduces a shared expert mechanism with a novel routing weight normalization strategy into sparse upcycling, which significantly boosts instruction tuning. After fine-tuning the upcycled MoE model, XFT introduces a learnable... | Yifeng Ding, Jiawei Liu, Yuxiang Wei, Lingming Zhang |  |
| 819 |  |  [Generalizability of Mixture of Domain-Specific Adapters from the Lens of Signed Weight Directions and its Application to Effective Model Pruning](https://doi.org/10.18653/v1/2024.acl-long.700) |  | 0 | Several parameter-efficient fine-tuning methods based on adapters have been proposed as a streamlined approach to incorporate not only a single specialized knowledge into existing Pre-Trained Language Models (PLMs) but also multiple of them at once. Recent works such as AdapterSoup propose to mix not all but only a selective sub-set of domain-specific adapters during inference via model weight averaging to optimize performance on novel, unseen domains with excellent computational efficiency.... | Tuc Nguyen, Thai Le |  |
| 820 |  |  [Learning to Decode Collaboratively with Multiple Language Models](https://doi.org/10.18653/v1/2024.acl-long.701) |  | 0 | We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level. We model the decision of which LLM generates the next token as a latent variable. By optimizing the marginal likelihood of a training set under our latent variable model, the base LLM automatically learns when to generate itself and when to call on one of the “assistant” language models to generate, all without direct supervision. Token-level collaboration... | Zejiang Shen, Hunter Lang, Bailin Wang, Yoon Kim, David A. Sontag |  |
| 821 |  |  [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.702) |  | 0 | Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs).There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to retrieve) and crafting the appropriate query once retrieval is triggered (determining what to retrieve).However, current dynamic RAG methods fall short in both aspects. Firstly, the strategies for deciding... | Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu |  |
| 822 |  |  [Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.703) |  | 0 | Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world. Current temporal reasoning datasets are limited to questions about single or isolated events, falling short in mirroring the realistic temporal characteristics involving concurrent nature and intricate temporal interconnections. In this paper, we introduce CoTempQA, a comprehensive co-temporal Question Answering (QA) benchmark containing four co-temporal scenarios (Equal, Overlap, During, Mix) with 4,748... | Zhaochen Su, Juntao Li, Jun Zhang, Tong Zhu, Xiaoye Qu, Pan Zhou, Yan Bowen, Yu Cheng, Min Zhang |  |
| 823 |  |  [CritiqueLLM: Towards an Informative Critique Generation Model for Evaluation of Large Language Model Generation](https://doi.org/10.18653/v1/2024.acl-long.704) |  | 0 | Since the natural language processing (NLP) community started to make large language models (LLMs) act as a critic to evaluate the quality of generated texts, most of the existing works train a critique generation model on the evaluation data labeled by GPT-4’s direct prompting. We observe that these models lack the ability to generate informative critiques in both pointwise grading and pairwise comparison especially without references. As a result, their generated critiques cannot provide... | Pei Ke, Bosi Wen, Andrew Feng, Xiao Liu, Xuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang |  |
| 824 |  |  [LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments](https://doi.org/10.18653/v1/2024.acl-long.705) |  | 0 | Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence. However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent scenarios, overlooking the complexities of multi-agent interactions. There is a lack of a benchmark that evaluates the diverse capabilities of LLM agents in multi-agent, dynamic environments. To this... | Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, WeiWei Tu, Zhaofeng He, Lijie Wen |  |
| 825 |  |  [Small But Funny: A Feedback-Driven Approach to Humor Distillation](https://doi.org/10.18653/v1/2024.acl-long.706) |  | 0 | The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing. Consequently, distillation through imitation of teacher responses has emerged as a popular technique to transfer knowledge from LLMs to more accessible, Small Language Models (SLMs). While this works well for simpler tasks, there is a substantial performance gap on tasks requiring intricate language... | Sahithya Ravi, Patrick Huber, Akshat Shrivastava, Vered Shwartz, Arash Einolghozati |  |
| 826 |  |  [Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.707) |  | 0 | Although Large Language Models (LLMs) demonstrate remarkable ability in processing and generating human-like text, they do have limitations when it comes to comprehending and expressing world knowledge that extends beyond the boundaries of natural language(e.g., chemical molecular formula). Injecting a collection of symbolic data directly into the training of LLMs can be problematic, as it disregards the synergies among different symbolic families and overlooks the need for a balanced mixture... | Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu |  |
| 827 |  |  [From Sights to Insights: Towards Summarization of Multimodal Clinical Documents](https://doi.org/10.18653/v1/2024.acl-long.708) |  | 0 | The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective solutions. Doctors often struggle to draw quick conclusions from these extensive documents. To address this issue and save time for healthcare professionals, an effective summarization model is... | Akash Ghosh, Mohit Tomar, Abhisek Tiwari, Sriparna Saha, Jatin Salve, Setu Sinha |  |
| 828 |  |  [When Phrases Meet Probabilities: Enabling Open Relation Extraction with Cooperating Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.709) |  | 0 | Current clustering-based open relation extraction (OpenRE) methods usually apply clustering algorithms on top of pre-trained language models. However, this practice has three drawbacks. First, embeddings from language models are high-dimensional and anisotropic, so using simple metrics to calculate distances between these embeddings may not accurately reflect the relational similarity. Second, there exists a gap between the pre-trained language models and downstream clustering for their... | Jiaxin Wang, Lingling Zhang, Wee Sun Lee, Yujie Zhong, Liwei Kang, Jun Liu |  |
| 829 |  |  [Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation](https://doi.org/10.18653/v1/2024.acl-long.710) |  | 0 | The latest generative large language models (LLMs) have found their application in data augmentation tasks, where small numbers of text samples are LLM-paraphrased and then used to fine-tune downstream models. However, more research is needed to assess how different prompts, seed data selection strategies, filtering methods, or model settings affect the quality of paraphrased data (and downstream models). In this study, we investigate three text diversity incentive methods well established in... | Ján Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Mária Bieliková, Peter Brusilovsky |  |
| 830 |  |  [Beyond Orthography: Automatic Recovery of Short Vowels and Dialectal Sounds in Arabic](https://doi.org/10.18653/v1/2024.acl-long.711) |  | 0 | This paper presents a novel Dialectal Sound and Vowelization Recovery framework, designed to recognize borrowed and dialectal sounds within phonologically diverse and dialect-rich languages, that extends beyond its standard orthographic sound sets. The proposed framework utilized quantized sequence of input with(out) continuous pretrained self-supervised representation. We show the efficacy of the pipeline using limited data for Arabic, a dialect-rich language containing more than 22 major... | Yassine El Kheir, Hamdy Mubarak, Ahmed Ali, Shammur Absar Chowdhury |  |
| 831 |  |  [Document-Level Machine Translation with Large-Scale Public Parallel Corpora](https://doi.org/10.18653/v1/2024.acl-long.712) |  | 0 | Despite the fact that document-level machine translation has inherent advantages over sentence-level machine translation due to additional information available to a model from document context, most translation systems continue to operate at a sentence level. This is primarily due to the severe lack of publicly available large-scale parallel corpora at the document level. We release a large-scale open parallel corpus with document context extracted from ParaCrawl in five language pairs, along... | Proyag Pal, Alexandra Birch, Kenneth Heafield |  |
| 832 |  |  [Bridging the Empirical-Theoretical Gap in Neural Network Formal Language Learning Using Minimum Description Length](https://doi.org/10.18653/v1/2024.acl-long.713) |  | 0 | Neural networks offer good approximation to many tasks but consistently fail to reach perfect generalization, even when theoretical work shows that such perfect solutions can be expressed by certain architectures. Using the task of formal language learning, we focus on one simple formal language and show that the theoretically correct solution is in fact not an optimum of commonly used objectives — even with regularization techniques that according to common wisdom should lead to simple weights... | Nur Geffen Lan, Emmanuel Chemla, Roni Katzir |  |
| 833 |  |  [Context versus Prior Knowledge in Language Models](https://doi.org/10.18653/v1/2024.acl-long.714) |  | 0 | To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different questions and contexts: models will rely more on prior knowledge for questions about entities (e.g., persons, places, etc.) that they are more familiar with due to higher exposure in the training corpus, and be more easily persuaded by some contexts than others.... | Kevin Du, Vésteinn Snæbjarnarson, Niklas Stoehr, Jennifer C. White, Aaron Schein, Ryan Cotterell |  |
| 834 |  |  [Word Matters: What Influences Domain Adaptation in Summarization?](https://doi.org/10.18653/v1/2024.acl-long.715) |  | 0 | Domain adaptation aims to enable Large Language Models (LLMs) to generalize domain datasets unseen effectively during the training phase. However, factors such as the size of the model parameters and the scale of training data are general influencers and do not reflect the nuances of domain adaptation performance. This paper investigates the fine-grained factors affecting domain adaptation performance, analyzing the specific impact of ‘words’ in training data on summarization tasks. We propose... | Yinghao Li, Siyu Miao, Heyan Huang, Yang Gao |  |
| 835 |  |  [Visualization Recommendation with Prompt-based Reprogramming of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.716) |  | 0 | Visualization recommendations, which aim to automatically match proper visual charts for specific data tables, can significantly simplify the data analysis process. Traditional approaches in this domain have primarily relied on rule-based or machine learning-based methodologies. These methods often demand extensive manual maintenance and yet fail to fully comprehend the tabular data, leading to unsatisfactory performance. Recently, Large Language Models (LLMs) have emerged as powerful tools,... | Xinhang Li, Jingbo Zhou, Wei Chen, Derong Xu, Tong Xu, Enhong Chen |  |
| 836 |  |  [HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs](https://doi.org/10.18653/v1/2024.acl-long.717) |  | 0 | Given unstructured text, Large Language Models (LLMs) are adept at answering simple (single-hop) questions. However, as the complexity of the questions increase, the performance of LLMs degrade. We believe this is due to the overhead associated with understanding the complex question followed by filtering and aggregating unstructured information in the raw text. Recent methods try to reduce this burden by integrating structured knowledge triples into the raw text, aiming to provide a structured... | Pranoy Panda, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, A. P. Prathosh |  |
| 837 |  |  [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](https://doi.org/10.18653/v1/2024.acl-long.718) |  | 0 | When a teacher provides examples for a student to study, these examples must be informative, enabling a student to progress from their current state toward a target concept or skill. Good teachers must therefore simultaneously infer what students already know and adapt their teaching to students’ changing state of knowledge. There is increasing interest in using computational models, particularly large language models, as pedagogical tools. As students, language models in particular have shown... | Alexis Ross, Jacob Andreas |  |
| 838 |  |  [Bridging Word-Pair and Token-Level Metaphor Detection with Explainable Domain Mining](https://doi.org/10.18653/v1/2024.acl-long.719) |  | 0 | Metaphor detection aims to identify whether a linguistic expression in text is metaphorical or literal. Most existing research tackles this problem either using word-pair or token-level information as input, and thus treats word-pair and token-level metaphor detection as distinct subtasks. Benefited from the simplified structure of word pairs, recent methods for word-pair metaphor detection can provide intermediate explainable clues for the detection results, which remains a challenging issue... | Yuan Tian, Ruike Zhang, Nan Xu, Wenji Mao |  |
| 839 |  |  [Faithful Logical Reasoning via Symbolic Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.720) |  | 0 | While the recent Chain-of-Thought (CoT) technique enhances the reasoning ability of large language models (LLMs) with the theory of mind, it might still struggle in handling logical reasoning that relies much on symbolic expressions and rigid deducing rules. To strengthen the logical reasoning capability of LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully LLM-based framework that integrates symbolic expressions and logic rules with CoT prompting. Technically, building... | Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, MongLi Lee, Wynne Hsu |  |
| 840 |  |  [S²GSL: Incorporating Segment to Syntactic Enhanced Graph Structure Learning for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.721) |  | 0 | Previous graph-based approaches in Aspect-based Sentiment Analysis(ABSA) have demonstrated impressive performance by utilizing graph neural networks and attention mechanisms to learn structures of static dependency trees and dynamic latent trees. However, incorporating both semantic and syntactic information simultaneously within complex global structures can introduce irrelevant contexts and syntactic dependencies during the process of graph structure learning, potentially resulting in... | Bingfeng Chen, Qihan Ouyang, Yongqi Luo, Boyan Xu, Ruichu Cai, Zhifeng Hao |  |
| 841 |  |  [Maverick: Efficient and Accurate Coreference Resolution Defying Recent Trends](https://doi.org/10.18653/v1/2024.acl-long.722) |  | 0 | Large autoregressive generative models have emerged as the cornerstone for achieving the highest performance across several Natural Language Processing tasks. However, the urge to attain superior results has, at times, led to the premature replacement of carefully designed task-specific approaches without exhaustive experimentation. The Coreference Resolution task is no exception; all recent state-of-the-art solutions adopt large generative autoregressive models that outperform encoder-based... | Giuliano Martinelli, Edoardo Barba, Roberto Navigli |  |
| 842 |  |  [ESCoT: Towards Interpretable Emotional Support Dialogue Systems](https://doi.org/10.18653/v1/2024.acl-long.723) |  | 0 | Understanding the reason for emotional support response is crucial for establishing connections between users and emotional support dialogue systems. Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. To empower the system with better interpretability, we propose an emotional support response generation scheme, named Emotion-Focused and Strategy-Driven Chain-of-Thought (ESCoT),... | Tenggan Zhang, Xinjie Zhang, Jinming Zhao, Li Zhou, Qin Jin |  |
| 843 |  |  [PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering](https://doi.org/10.18653/v1/2024.acl-long.724) |  | 0 | Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure perception. To this end, we model the logical reasoning task by transforming each logical sample into reasoning paths and propose an architecture PathReasoner. It addresses the task from the views of both data... | Fangzhi Xu, Qika Lin, Tianzhe Zhao, Jiawei Han, Jun Liu |  |
| 844 |  |  [WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection](https://doi.org/10.18653/v1/2024.acl-long.725) |  | 0 | Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern could be mitigated by adding backdoor watermarks to the text embeddings and subsequently verifying the attack models post-publication. Through the analysis of the recent watermarking strategy for EaaS,... | Anudeex Shetty, Yue Teng, Ke He, Qiongkai Xu |  |
| 845 |  |  [Advancing Parameter Efficiency in Fine-tuning via Representation Editing](https://doi.org/10.18653/v1/2024.acl-long.726) |  | 0 | Parameter Efficient Fine-Tuning (PEFT) has gained significant attention for its ability to achieve competitive results while updating only a small subset of trainable parameters. Despite the promising performance of current PEFT methods, they present challenges in hyperparameter selection, such as determining the rank of LoRA or Adapter, or specifying the length of soft prompts. In addressing these challenges, we propose a novel approach to fine-tuning neural models, termed Representation... | Muling Wu, Wenhao Liu, Xiaohua Wang, Tianlong Li, Changze Lv, Zixuan Ling, Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang |  |
| 846 |  |  [Context Consistency between Training and Inference in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.727) |  | 0 | Simultaneous Machine Translation (SiMT) aims to yield a real-time partial translation with a monotonically growing source-side context.However, there is a counterintuitive phenomenon about the context usage between training and inference: \*e.g.\*, in wait-k inference, model consistently trained with wait-k is much worse than that model inconsistently trained with wait-k' (k'≠ k) in terms of translation quality. To this end, we first investigate the underlying reasons behind this phenomenon and... | Meizhi Zhong, Lemao Liu, Kehai Chen, Mingming Yang, Min Zhang |  |
| 847 |  |  [Using Natural Language Explanations to Improve Robustness of In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.728) |  | 0 | Recent studies demonstrated that large language models (LLMs) can excel in many tasks via in-context learning (ICL). However, recentworks show that ICL-prompted models tend to produce inaccurate results when presented with adversarial inputs. In this work, we investigate whether augmenting ICL with natural language explanations (NLEs) improves the robustness of LLMs on adversarial datasets covering natural language inference and paraphrasing identification. We prompt LLMs with a small set of... | Xuanli He, Yuxiang Wu, OanaMaria Camburu, Pasquale Minervini, Pontus Stenetorp |  |
| 848 |  |  [Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers](https://doi.org/10.18653/v1/2024.acl-long.729) |  | 0 | Although dominant in natural language processing, transformer-based models still struggle with long-sequence processing, due to the computational costs of their self-attention operations, which increase exponentially as the length of the input sequence grows. To address this challenge, we propose a \*\*Sim\*\*ple framework to enhance the long-content processing of off-the-shelf pre-trained transformers via three steps: \*\*C\*\*hunk, \*\*A\*\*lign, and \*\*S\*\*elect (SimCAS). More... | Jiawen Xie, Pengyu Cheng, Xiao Liang, Yong Dai, Nan Du |  |
| 849 |  |  [ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.730) |  | 0 | This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g., time/space performance, robustness, maintainability) requirements. However, textual descriptions can either express requirements verbosely or may even omit some of them. We introduce ARCHCODE, a novel... | Hojae Han, Jaejin Kim, Jaeseok Yoo, Youngwon Lee, Seungwon Hwang |  |
| 850 |  |  [Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels](https://doi.org/10.18653/v1/2024.acl-long.731) |  | 0 | Traditional supervised learning heavily relies on human-annotated datasets, especially in data-hungry neural approaches. However, various tasks, especially multi-label tasks like document-level relation extraction, pose challenges in fully manual annotation due to the specific domain knowledge and large class sets. Therefore, we address the multi-label positive-unlabelled learning (MLPUL) problem, where only a subset of positive classes is annotated. We propose Mixture Learner for Partially... | Zixia Jia, Junpeng Li, Shichuan Zhang, Anji Liu, Zilong Zheng |  |
| 851 |  |  [MULFE: A Multi-Level Benchmark for Free Text Model Editing](https://doi.org/10.18653/v1/2024.acl-long.732) |  | 0 | Adjusting the outdated behaviors of large langugae models (LLMs) after deployment remains a significant challenge. It motivates the model editing research, which is however mainly explored in a restricted task form with triple-based edit requests. Recent works have initiated a transition to a more practical and unified editing task that takes free-form text as edit requests. However, there are gaps in nuanced benchmark designs and re-evaluation of existing methods. To bridge the gaps, we... | Chenhao Wang, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao |  |
| 852 |  |  [MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech](https://doi.org/10.18653/v1/2024.acl-long.733) |  | 0 | Zero-shot text-to-speech (TTS) has gained significant attention due to its powerful voice cloning capabilities, requiring only a few seconds of unseen speaker voice prompts. However, all previous work has been developed for cloud-based systems. Taking autoregressive models as an example, although these approaches achieve high-fidelity voice cloning, they fall short in terms of inference speed, model size, and robustness. Therefore, we propose MobileSpeech, which is a fast, lightweight, and... | Shengpeng Ji, Ziyue Jiang, Hanting Wang, Jialong Zuo, Zhou Zhao |  |
| 853 |  |  [Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation](https://doi.org/10.18653/v1/2024.acl-long.734) |  | 0 | Embodied AI aims to develop robots that can understand and execute human language instructions, as well as communicate in natural languages. On this front, we study the task of generating highly detailed navigational instructions for the embodied robots to follow. Although recent studies have demonstrated significant leaps in the generation of step-by-step instructions from sequences of images, the generated instructions lack variety in terms of their referral to objects and landmarks. Existing... | Muraleekrishna Gopinathan, Martin Masek, Jumana AbuKhalaf, David Suter |  |
| 854 |  |  [HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position](https://doi.org/10.18653/v1/2024.acl-long.735) |  | 0 | Addressing the limitation of context length in large language models for code-related tasks is the primary focus of this paper. Existing LLMs are constrained by their pre-trained context lengths, leading to performance issues in handling long complex code sequences. Inspired by how human programmers navigate code, we introduce Hierarchical Rotary Position Embedding (HiRoPE), a novel approach that enhances the traditional rotary position embedding into a hierarchical format based on the... | Kechi Zhang, Ge Li, Huangzhao Zhang, Zhi Jin |  |
| 855 |  |  [Never Lost in the Middle: Mastering Long-Context Question Answering with Position-Agnostic Decompositional Training](https://doi.org/10.18653/v1/2024.acl-long.736) |  | 0 | While large language models (LLMs) are equipped with longer text input capabilities than before, they are struggling to seek correct information in long contexts. The “lost in the middle” problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located in the middle. To overcome this crucial issue, this paper proposes to enhance the information searching and reflection ability of LLMs in long contexts via specially designed tasks called... | Junqing He, Kunhao Pan, Xiaoqun Dong, Zhuoyang Song, LiuYiBo LiuYiBo, Qianguosun Qianguosun, Yuxin Liang, Hao Wang, Enming Zhang, Jiaxing Zhang |  |
| 856 |  |  [CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges](https://doi.org/10.18653/v1/2024.acl-long.737) |  | 0 | Large Language Models (LLMs) have shown promise in automated code generation but typically excel only in simpler tasks such as generating standalone code units. However, real-world software development often involves complex code repositories with complex dependencies and extensive documentation. To enable LLMs to handle these realworld repo-level code generation, we present CodeAgent, a novel LLM-based agent framework that employs external tools for effective repo-level code generation.... | Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, Zhi Jin |  |
| 857 |  |  [When is Tree Search Useful for LLM Planning? It Depends on the Discriminator](https://doi.org/10.18653/v1/2024.acl-long.738) |  | 0 | In this paper, we examine how large language models (LLMs) solve multi-step problems under a language agent framework with three components: a generator, a discriminator, and a planning method. We investigate the practical utility of two advanced planning methods, iterative correction and tree search. We present a comprehensive analysis of how discrimination accuracy affects the overall performance of agents when using these two methods or a simpler method, re-ranking. Experiments on two tasks,... | Ziru Chen, Michael White, Raymond J. Mooney, Ali Payani, Yu Su, Huan Sun |  |
| 858 |  |  [LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.739) |  | 0 | Recently developed large language models (LLMs) have been shown to perform remarkably well on a wide range of language understanding tasks. But, can they really “reason” over the natural language? This question has been receiving significant research attention and many reasoning skills such as commonsense, numerical, and qualitative have been studied. However, the crucial skill pertaining to ‘logical reasoning’ has remained underexplored. Existing work investigating this reasoning ability of... | Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam Mitra, Chitta Baral |  |
| 859 |  |  [Meta-Tuning LLMs to Leverage Lexical Knowledge for Generalizable Language Style Understanding](https://doi.org/10.18653/v1/2024.acl-long.740) |  | 0 | Language style is often used by writers to convey their intentions, identities, and mastery of language. In this paper, we show that current large language models struggle to capture some language styles without fine-tuning. To address this challenge, we investigate whether LLMs can be meta-trained based on representative lexicons to recognize new styles they have not been fine-tuned on. Experiments on 13 established style classification tasks, as well as 63 novel tasks generated using LLMs,... | Ruohao Guo, Wei Xu, Alan Ritter |  |
| 860 |  |  [Reducing Privacy Risks in Online Self-Disclosures with Language Models](https://doi.org/10.18653/v1/2024.acl-long.741) |  | 0 | Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F1. We further conduct an HCI user... | Yao Dou, Isadora Krsek, Tarek Naous, Anubha Kabra, Sauvik Das, Alan Ritter, Wei Xu |  |
| 861 |  |  [Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.742) |  | 0 | Memory Editing (ME) has emerged as an efficient method to modify erroneous facts or inject new facts into Large Language Models (LLMs). Two mainstream ME methods exist: parameter-modifying ME and parameter-preserving ME (integrating extra modules while preserving original parameters). Regrettably, previous studies on ME evaluation have two critical limitations: (i) evaluating LLMs with single edit only, neglecting the need for continuous editing, and (ii) evaluations focusing solely on basic... | Zihao Lin, Mohammad Beigi, Hongxuan Li, Yufan Zhou, Yuxiang Zhang, Qifan Wang, Wenpeng Yin, Lifu Huang |  |
| 862 |  |  [REFINESUMM: Self-Refining MLLM for Generating a Multimodal Summarization Dataset](https://doi.org/10.18653/v1/2024.acl-long.743) |  | 0 | Multimodal Large Language Models (MLLMs) excel at synthesizing key information from diverse sources. However, generating accurate and faithful multimodal summaries is challenging, primarily due to the lack of appropriate multimodal datasets for fine-tuning that meaningfully integrate textual and visual modalities. To address this gap, we present a new dataset designed specifically for image-text multimodal summarization, harnessing the capabilities of state-of-the-art MLLMs. We generate... | Vaidehi Patil, Leonardo F. R. Ribeiro, Mengwen Liu, Mohit Bansal, Markus Dreyer |  |
| 863 |  |  [When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards](https://doi.org/10.18653/v1/2024.acl-long.744) |  | 0 | Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value — we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple-choice question benchmarks (e.g., MMLU), minor perturbations to the benchmark, such as changing the order of... | Norah Alzahrani, Hisham Abdullah Alyahya, Yazeed Alnumay, Sultan Alrashed, Shaykhah Alsubaie, Yousef Almushayqih, Faisal Mirza, Nouf Alotaibi, Nora AlTwairesh, Areeb Alowisheq, M. Saiful Bari, Haidar Khan |  |
| 864 |  |  [LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts](https://doi.org/10.18653/v1/2024.acl-long.745) |  | 0 | This paper introduces a framework for the automated evaluation of natural language texts. A manually constructed rubric describes how to assess multiple dimensions of interest. To evaluate a text, a large language model (LLM) is prompted with each rubric question and produces a distribution over potential responses. The LLM predictions often fail to agree well with human judges—indeed, the humans do not fully agree with one another. However, the multiple LLM distributions can be _combined_ to... | Helia Hashemi, Jason Eisner, Corby Rosset, Benjamin Van Durme, Chris Kedzie |  |
| 865 |  |  [LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.746) |  | 0 | Discourse Entity (DE) recognition is the task of identifying novel and known entities introduced within a text. While previous work has found that large language models have basic, if imperfect, DE recognition abilities (Schuster and Linzen, 2022), it remains largely unassessed which of the fundamental semantic properties that govern the introduction and subsequent reference to DEs they have knowledge of. We propose the Linguistically-Informed Evaluation for Discourse Entity Recognition... | Xiaomeng Zhu, Robert Frank |  |
| 866 |  |  [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.747) |  | 0 | Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and... | Adyasha Maharana, DongHo Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, Yuwei Fang |  |
| 867 |  |  [Prototypical Reward Network for Data-Efficient RLHF](https://doi.org/10.18653/v1/2024.acl-long.748) |  | 0 | The reward model for Reinforcement Learning from Human Feedback (RLHF) has proven effective in fine-tuning Large Language Models (LLMs). Notably, collecting human feedback for RLHF can be resource-intensive and lead to scalability issues for LLMs and complex tasks. Our proposed framework Proto-RM leverages prototypical networks to enhance reward models under limited human feedback. By enabling stable and reliable structural learning from fewer samples, Proto-RM significantly enhances LLMs'... | Jinghan Zhang, Xiting Wang, Yiqiao Jin, Changyu Chen, Xinhao Zhang, Kunpeng Liu |  |
| 868 |  |  [NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms](https://doi.org/10.18653/v1/2024.acl-long.749) |  | 0 | The performance of Large Language Models (LLMs) degrades from the temporal drift between data used for model training and newer text seen during inference. One understudied avenue of language change causing data drift is the emergence of neologisms – new word forms – over time. We create a diverse resource of recent English neologisms by using several popular collection methods. We analyze temporal drift using neologisms by comparing sentences containing new words with near-identical sentences... | Jonathan Zheng, Alan Ritter, Wei Xu |  |
| 869 |  |  [Impacts of Misspelled Queries on Translation and Product Search](https://doi.org/10.18653/v1/2024.acl-long.750) |  | 0 | Machine translation is used in e-commerce to translate second-language queries into the primary language of the store, to be matched by the search system against the product catalog. However, many queries contain spelling mistakes. We first present an analysis of the spelling-robustness of a population of MT systems, quantifying how spelling variations affect MT output, the list of returned products, and ultimately user behavior. We then present two sets of practical experiments illustrating... | Greg Hanneman, Natawut Monaikul, Taichi Nakatani |  |
| 870 |  |  [Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs](https://doi.org/10.18653/v1/2024.acl-long.751) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in tasks such as summarization, arithmetic reasoning, and question answering. However, they encounter significant challenges in the domain of moral reasoning and ethical decision-making, especially in complex scenarios with multiple stakeholders. This paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing moral reasoning in LLMs by exploring decisions’ consequences from multiple stakeholder perspectives. The... | Bilgehan Sel, Priya Shanmugasundaram, Mohammad Kachuee, Kun Zhou, Ruoxi Jia, Ming Jin |  |
| 871 |  |  [The MERSA Dataset and a Transformer-Based Approach for Speech Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.752) |  | 0 | Research in the field of speech emotion recognition (SER) relies on the availability of comprehensive datasets to make it possible to design accurate emotion detection models. This study introduces the Multimodal Emotion Recognition and Sentiment Analysis (MERSA) dataset, which includes both natural and scripted speech recordings, transcribed text, physiological data, and self-reported emotional surveys from 150 participants collected over a two-week period. This work also presents a novel... | Enshi Zhang, Rafael Trujillo, Christian Poellabauer |  |
| 872 |  |  [Transparent and Scrutable Recommendations Using Natural Language User Profiles](https://doi.org/10.18653/v1/2024.acl-long.753) |  | 0 | Recent state-of-the-art recommender systems predominantly rely on either implicit or explicit feedback from users to suggest new items. While effective in recommending novel options, many recommender systems often use uninterpretable embeddings to represent user preferences. This lack of transparency not only limits user understanding of why certain items are suggested but also reduces the user’s ability to scrutinize and modify their preferences, thereby affecting their ability to receive a... | Jerome Ramos, Hossein A. Rahmani, Xi Wang, Xiao Fu, Aldo Lipani |  |
| 873 |  |  [Fora: A corpus and framework for the study of facilitated dialogue](https://doi.org/10.18653/v1/2024.acl-long.754) |  | 0 | Facilitated dialogue is increasingly popular as a method of civic engagement and as a method for gathering social insight, but resources for its study are scant. We present Fora, a unique collection of annotated facilitated dialogues. We compile 262 facilitated conversations that were hosted with partner organizations seeking to engage their members and surface insights regarding issues like education, elections, and public health, primarily through the sharing of personal experience. Alongside... | Hope Schroeder, Deb Roy, Jad Kabbara |  |
| 874 |  |  [Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.755) |  | 0 | Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks with a few demonstration examples via in-context learning. Common strategies to boost such “in-context” learning ability are to ensemble multiple model decoded results and require the model to generate an explanation along with the prediction. However, these models often treat different class predictions equally and neglect the potential discrepancy between the explanations and... | Yue Yu, Jiaming Shen, Tianqi Liu, Zhen Qin, Jing Nathan Yan, Jialu Liu, Chao Zhang, Michael Bendersky |  |
| 875 |  |  [What is the Best Way for ChatGPT to Translate Poetry?](https://doi.org/10.18653/v1/2024.acl-long.756) |  | 0 | Machine translation (MT) has historically faced significant challenges when applied to literary works, particularly in the domain of poetry translation. The advent of Large Language Models such as ChatGPT holds potential for innovation in this field. This study examines ChatGPT’s capabilities in English-Chinese poetry translation tasks, utilizing targeted prompts and small sample scenarios to ascertain optimal performance. Despite promising outcomes, our analysis reveals persistent issues in... | Shanshan Wang, Derek F. Wong, Jingming Yao, Lidia S. Chao |  |
| 876 |  |  [Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.757) |  | 0 | Large language models are trained on massive scrapes of the web, which are often unstructured, noisy, and poorly phrased. Current scaling laws show that learning from such data requires an abundance of both compute and data, which grows with the size of the model being trained. This is infeasible both because of the large compute costs and duration associated with pre-training, and the impending scarcity of high-quality data on the web. In this work, we propose Web Rephrase Augmented... | Pratyush Maini, Skyler Seto, Richard He Bai, David Grangier, Yizhe Zhang, Navdeep Jaitly |  |
| 877 |  |  [DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention](https://doi.org/10.18653/v1/2024.acl-long.758) |  | 0 | Large language models (LLMs) often require task-relevant knowledge to augment their internal knowledge through prompts. However, simply injecting external knowledge into prompts does not guarantee that LLMs can identify and use relevant information in the prompts to conduct chain-of-thought reasoning, especially when the LLM’s internal knowledge is derived from biased information on the pretraining data. In this paper, we propose a novel causal view to formally explain the internal knowledge... | Junda Wu, Tong Yu, Xiang Chen, Haoliang Wang, Ryan A. Rossi, Sungchul Kim, Anup B. Rao, Julian J. McAuley |  |
| 878 |  |  [Representation Learning with Conditional Information Flow Maximization](https://doi.org/10.18653/v1/2024.acl-long.759) |  | 0 | This paper proposes an information-theoretic representation learning framework, named conditional information flow maximization, to extract noise-invariant sufficient representations for the input data and target task. It promotes the learned representations have good feature uniformity and sufficient predictive ability, which can enhance the generalization of pre-trained language models (PLMs) for the target task. Firstly, an information flow maximization principle is proposed to learn more... | Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu |  |
| 879 |  |  [GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.760) |  | 0 | Social biases in LLMs are usually measured via bias benchmark datasets. Current benchmarks have limitations in scope, grounding, quality, and human effort required. Previous work has shown success with a community-sourced, rather than crowd-sourced, approach to benchmark development. However, this work still required considerable effort from annotators with relevant lived experience. This paper explores whether an LLM (specifically, GPT-3.5-Turbo) can assist with the task of developing a bias... | Virginia K. Felkner, Jennifer A. Thompson, Jonathan May |  |
| 880 |  |  [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](https://doi.org/10.18653/v1/2024.acl-long.761) |  | 0 | While large language models have achieved remarkable performance on various code generation benchmarks, there have been growing concerns regarding potential contamination of these benchmarks as they may be leaked into pretraining and finetuning data. While recent work has investigated contamination in natural language generation and understanding tasks, there has been less extensive research into how data contamination impacts the evaluation of code generation, which is critical for... | Martin Riddell, Ansong Ni, Arman Cohan |  |
| 881 |  |  [Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic](https://doi.org/10.18653/v1/2024.acl-long.762) |  | 0 | We propose RESTA to perform LLM realignment towards safety, which gets compromised due to downstream task fine-tuning. RESTA stands for REstoring Safety through Task Arithmetic. At its core, it involves a simple arithmetic addition of a safety vector to the weights of the compromised model. We demonstrate the effectiveness of RESTA in both parameter-efficient and full fine-tuning, covering a wide range of downstream tasks, including instruction following in Chinese, English, and Hindi, as well... | Rishabh Bhardwaj, Do Duc Anh, Soujanya Poria |  |
| 882 |  |  [Tracking the Newsworthiness of Public Documents](https://doi.org/10.18653/v1/2024.acl-long.763) |  | 0 | Journalists regularly make decisions on whether or not to report stories, based on “news values”. In this work, we wish to explicitly model these decisions to explore _when_ and _why_ certain stories get press attention. This is challenging because very few labelled links between source documents and news articles exist and language use between corpora is very different. We address this problem by implementing a novel _probabilistic relational modeling_ framework, which we show is a... | Alexander Spangher, Serdar Tumgoren, Ben Welsh, Nanyun Peng, Emilio Ferrara, Jonathan May |  |
| 883 |  |  [EWEK-QA : Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems](https://doi.org/10.18653/v1/2024.acl-long.764) |  | 0 | The emerging citation-based QA systems are gaining more attention especially in generative AI search applications. The importance of extracted knowledge provided to these systems is vital from both accuracy (completeness of information) and efficiency (extracting the information in a timely manner). In this regard, citation-based QA systems are suffering from two shortcomings. First, they usually rely only on web as a source of extracted knowledge and adding other external knowledge sources can... | Mohammad Dehghan, Mohammad Ali Alomrani, Sunyam Bagga, David AlfonsoHermelo, Khalil Bibi, Abbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu, Jimmy Lin, Boxing Chen, Prasanna Parthasarathi, Mahdi Biparva, Mehdi Rezagholizadeh |  |
| 884 |  |  [Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models](https://doi.org/10.18653/v1/2024.acl-long.765) |  | 0 | Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer from degradation, as VQA datasets lack the diversity and complexity of the original text instruction datasets with which the underlying language model was trained. To address this degradation, we first collect a lightweight, 5k-sample VQA preference dataset... | Shengzhi Li, Rongyu Lin, Shichao Pei |  |
| 885 |  |  [Multistage Collaborative Knowledge Distillation from a Large Language Model for Semi-Supervised Sequence Generation](https://doi.org/10.18653/v1/2024.acl-long.766) |  | 0 | We study semi-supervised sequence generation tasks, where the few labeled examples are too scarce to finetune a model, and meanwhile, few-shot prompted large language models (LLMs) exhibit room for improvement. In this paper, we present the discovery that a student model distilled from a few-shot prompted LLM can commonly generalize better than its teacher to unseen examples on such tasks. We find that the student is able to learn a general pattern from the high-quality pseudolabels produced by... | Jiachen Zhao, Wenlong Zhao, Andrew Drozdov, Benjamin Rozonoyer, Md. Arafat Sultan, JayYoon Lee, Mohit Iyyer, Andrew McCallum |  |
| 886 |  |  [Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor](https://doi.org/10.18653/v1/2024.acl-long.767) |  | 0 | Controlled text generation, aiming to ensure that language models produce text containing only the desired domain or corpus attributes, is immensely crucial in the practical application of language models. Existing methods, however, are inapplicable to black-box models or suffer a significant trade-off between control and fluency in text generation. This paper introduces the Score-based Progressive Editor (ScoPE), a novel approach designed to overcome these issues. ScoPE modifies the context at... | Sangwon Yu, Changmin Lee, Hojin Lee, Sungroh Yoon |  |
| 887 |  |  [LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP](https://doi.org/10.18653/v1/2024.acl-long.768) |  | 0 | Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor-intensive process that requires expert knowledge. At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription—this issue poses a bottleneck for researchers seeking to apply... | Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor BergKirkpatrick |  |
| 888 |  |  [Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning](https://doi.org/10.18653/v1/2024.acl-long.769) |  | 0 | Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the involvement of LLMs in this process. To reduce the filtering cost, we study Superfiltering: Can we use a smaller and weaker model to select data for finetuning a larger and stronger model? Despite the... | Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning Cheng, Tianyi Zhou |  |
| 889 |  |  [Confabulation: The Surprising Value of Large Language Model Hallucinations](https://doi.org/10.18653/v1/2024.acl-long.770) |  | 0 | This paper presents a systematic defense of large language model (LLM) hallucinations or ‘confabulations’ as a potential resource instead of a categorically negative pitfall. The standard view is that confabulations are inherently problematic and AI research should eliminate this flaw. In this paper, we argue and empirically demonstrate that measurable semantic characteristics of LLM confabulations mirror a human propensity to utilize increased narrativity as a cognitive resource for... | Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So |  |
| 890 |  |  [IAPT: Instance-Aware Prompt Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.771) |  | 0 | Soft prompt tuning is a widely studied parameter-efficient fine-tuning method. However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance. As a result, soft prompt tuning is less considered than Low-rank adaptation (LoRA) in the large language modeling (LLM) era. In this work, we propose a novel prompt tuning method, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft tokens. First, we install a... | Wei Zhu, Aaron Xuxiang Tian, Congrui Yin, Yuan Ni, Xiaoling Wang, Guotong Xie |  |
| 891 |  |  [DeVAn: Dense Video Annotation for Video-Language Models](https://doi.org/10.18653/v1/2024.acl-long.772) |  | 0 | We present a novel human annotated dataset for evaluating the ability for visual-language models to generate both short and long descriptions for real-world video clips, termed DeVAn (Dense Video Annotation). The dataset contains 8.5K YouTube video clips of 20-60 seconds in duration and covers a wide range of topics and interests. Each video clip is independently annotated by 5 human annotators, producing both captions (1 sentence) and summaries (3-10 sentences). Given any video selected from... | Tingkai Liu, Yunzhe Tao, Haogeng Liu, Qihang Fan, Ding Zhou, Huaibo Huang, Ran He, Hongxia Yang |  |
| 892 |  |  [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://doi.org/10.18653/v1/2024.acl-long.773) |  | 0 | Most traditional AI safety research views models as machines and centers on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. Observing this, we shift the perspective, by treating LLMs as human-like communicators to examine the interplay between everyday language interaction and AI safety. Specifically, we study how to persuade LLMs to jailbreak... | Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, Weiyan Shi |  |
| 893 |  |  [The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.774) |  | 0 | Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that perform similarly in-domain, but generalize vastly differently. To better understand these phenomena, we investigate if they can be understood in terms of “competing subnetworks”: the model initially... | Adithya Bhaskar, Dan Friedman, Danqi Chen |  |
| 894 |  |  [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.775) |  | 0 | Large vision-language models (LVLMs) excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains.To fill this gap, we introduce Multimodal ArXiv, consisting of ArXivCap and ArXivQA, for enhancing LVLMs scientific comprehension.ArXivCap is a figure-caption dataset comprising 6.4M images and 3.9M captions,... | Lei Li, Yuqi Wang, Runxin Xu, Peiyi Wang, Xiachong Feng, Lingpeng Kong, Qi Liu |  |
| 895 |  |  [L-Eval: Instituting Standardized Evaluation for Long Context Language Models](https://doi.org/10.18653/v1/2024.acl-long.776) |  | 0 | Recently, there has been growing interest in long-context scaling of large language models (LLMs). To facilitate research in this field, we propose L-Eval to institute a more standardized evaluation for Long-Context Language Models (LCLMs) addressing two key aspects: dataset construction and evaluation metrics. On the one hand, we build a new evaluation suite containing 20 sub-tasks, 508 long documents, and more than 2,000 human-labeled query-response pairs including diverse task types,... | Chenxin An, Shansan Gong, Ming Zhong, Xingjian Zhao, Mukai Li, Jun Zhang, Lingpeng Kong, Xipeng Qiu |  |
| 896 |  |  [DIALECTBENCH: An NLP Benchmark for Dialects, Varieties, and Closely-Related Languages](https://doi.org/10.18653/v1/2024.acl-long.777) |  | 0 | Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks are limited to standard language varieties. To fill this gap, we propose DIALECTBENCH, the first-ever large-scale benchmark for NLP on varieties, which aggregates an extensive set of task-varied... | Fahim Faisal, Orevaoghene Ahia, Aarohi Srivastava, Kabir Ahuja, David Chiang, Yulia Tsvetkov, Antonios Anastasopoulos |  |
| 897 |  |  [Causal-Guided Active Learning for Debiasing Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.778) |  | 0 | Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs. However, due to the diversity of dataset biases and the over-optimization problem, previous prior-knowledge-based debiasing methods and fine-tuning-based debiasing methods may not be suitable for current LLMs.To address this issue, we explore combining active... | Zhouhao Sun, Li Du, Xiao Ding, Yixuan Ma, Yang Zhao, Kaitao Qiu, Ting Liu, Bing Qin |  |
| 898 |  |  [PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.779) |  | 0 | Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification... | Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang |  |
| 899 |  |  [Towards Better Understanding of Contrastive Sentence Representation Learning: A Unified Paradigm for Gradient](https://doi.org/10.18653/v1/2024.acl-long.780) |  | 0 | Sentence Representation Learning (SRL) is a crucial task in Natural Language Processing (NLP), where contrastive Self-Supervised Learning (SSL) is currently a mainstream approach. However, the reasons behind its remarkable effectiveness remain unclear. Specifically, many studies have investigated the similarities between contrastive and non-contrastive SSL from a theoretical perspective. Such similarities can be verified in classification tasks, where the two approaches achieve comparable... | Mingxin Li, Richong Zhang, Zhijie Nie |  |
| 900 |  |  [Emergent Word Order Universals from Cognitively-Motivated Language Models](https://doi.org/10.18653/v1/2024.acl-long.781) |  | 0 | The world’s languages exhibit certain so-called typological or implicational universals; for example, Subject-Object-Verb (SOV) languages typically use postpositions. Explaining the source of such biases is a key goal of linguistics.We study word-order universals through a computational simulation with language models (LMs).Our experiments show that typologically-typical word orders tend to have lower perplexity estimated by LMs with cognitively plausible biases: syntactic biases, specific... | Tatsuki Kuribayashi, Ryo Ueda, Ryo Yoshida, Yohei Oseki, Ted Briscoe, Timothy Baldwin |  |
| 901 |  |  [Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View](https://doi.org/10.18653/v1/2024.acl-long.782) |  | 0 | As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: \*Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?\* This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique ‘societies’ comprised of LLM agents, where each agent... | Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, Shumin Deng |  |
| 902 |  |  [MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin](https://doi.org/10.18653/v1/2024.acl-long.783) |  | 0 | This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL), which learns an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of the well-trained dense retriever, T5-ANCE, by incorporating the visual module’s encoded image features as its inputs.... | Tianshuo Zhou, Sen Mei, Xinze Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu, Yu Gu, Ge Yu |  |
| 903 |  |  [Distributional Inclusion Hypothesis and Quantifications: Probing for Hypernymy in Functional Distributional Semantics](https://doi.org/10.18653/v1/2024.acl-long.784) |  | 0 | Functional Distributional Semantics (FDS) models the meaning of words by truth-conditional functions. This provides a natural representation for hypernymy but no guarantee that it can be learnt when FDS models are trained on a corpus. In this paper, we probe into FDS models and study the representations learnt, drawing connections between quantifications, the Distributional Inclusion Hypothesis (DIH), and the variational-autoencoding objective of FDS model training. Using synthetic data sets,... | Chun Hei Lo, Wai Lam, Hong Cheng, Guy Emerson |  |
| 904 |  |  [CausalGym: Benchmarking causal interpretability methods on linguistic tasks](https://doi.org/10.18653/v1/2024.acl-long.785) |  | 0 | Language models (LMs) have proven to be powerful tools for psycholinguistic research, but most prior work has focused on purely behavioural measures (e.g., surprisal comparisons). At the same time, research in model interpretability has begun to illuminate the abstract causal mechanisms shaping LM behavior. To help bring these strands of research closer together, we introduce CausalGym. We adapt and expand the SyntaxGym suite of tasks to benchmark the ability of interpretability methods to... | Aryaman Arora, Dan Jurafsky, Christopher Potts |  |
| 905 |  |  [Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration](https://doi.org/10.18653/v1/2024.acl-long.786) |  | 0 | Despite efforts to expand the knowledge of large language models (LLMs), knowledge gaps—missing or outdated information in LLMs—might always persist given the evolving nature of knowledge. In this work, we study approaches to identify LLM knowledge gaps and abstain from answering questions when knowledge gaps are present. We first adapt existing approaches to model calibration or adaptation through fine-tuning/prompting and analyze their ability to abstain from generating low-confidence... | Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Vidhisha Balachandran, Yulia Tsvetkov |  |
| 906 |  |  [Mission: Impossible Language Models](https://doi.org/10.18653/v1/2024.acl-long.787) |  | 0 | Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic impossible languages of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at... | Julie Kallini, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, Christopher Potts |  |
| 907 |  |  [Semisupervised Neural Proto-Language Reconstruction](https://doi.org/10.18653/v1/2024.acl-long.788) |  | 0 | Existing work implementing comparative reconstruction of ancestral languages (proto-languages) has usually required full supervision. However, historical reconstruction models are only of practical value if they can be trained with a limited amount of labeled data. We propose a semisupervised historical reconstruction task in which the model is trained on only a small amount of labeled data (cognate sets with proto-forms) and a large amount of unlabeled data (cognate sets without proto-forms).... | Liang Lu, Peirong Xie, David R. Mortensen |  |
| 908 |  |  [Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?](https://doi.org/10.18653/v1/2024.acl-long.789) |  | 0 | The field of natural language processing (NLP) has recently witnessed a transformative shift with the emergence of foundation models, particularly Large Language Models (LLMs) that have revolutionized text-based NLP. This paradigm has extended to other modalities, including speech, where researchers are actively exploring the combination of Speech Foundation Models (SFMs) and LLMs into single, unified models capable of addressing multimodal tasks. Among such tasks, this paper focuses on... | Marco Gaido, Sara Papi, Matteo Negri, Luisa Bentivogli |  |
| 909 |  |  [Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?](https://doi.org/10.18653/v1/2024.acl-long.790) |  | 0 | Reference summaries for abstractive speech summarization require human annotation, which can be performed by listening to an audio recording or by reading textual transcripts of the recording. In this paper, we examine whether summaries based on annotators listening to the recordings differ from those based on annotators reading transcripts. Using existing intrinsic evaluation based on human evaluation, automatic metrics, LLM-based evaluation, and a retrieval-based reference-free method, we... | Roshan Sharma, Suwon Shon, Mark Lindsey, Hira Dhamyal, Bhiksha Raj |  |
| 910 |  |  [D2LLM: Decomposed and Distilled Large Language Models for Semantic Search](https://doi.org/10.18653/v1/2024.acl-long.791) |  | 0 | The key challenge in semantic search is to create models that are both accurate and efficient in pinpointing relevant sentences for queries. While BERT-style bi-encoders excel in efficiency with pre-computed embeddings, they often miss subtle nuances in search tasks. Conversely, GPT-style LLMs with cross-encoder designs capture these nuances but are computationally intensive, hindering real-time applications. In this paper, we present D2LLMs—Decomposed and Distilled LLMs for semantic... | Zihan Liao, Hang Yu, Jianguo Li, Jun Wang, Wei Zhang |  |
| 911 |  |  [Arabic Diacritics in the Wild: Exploiting Opportunities for Improved Diacritization](https://doi.org/10.18653/v1/2024.acl-long.792) |  | 0 | The widespread absence of diacritical marks in Arabic text poses a significant challenge for Arabic natural language processing (NLP). This paper explores instances of naturally occurring diacritics, referred to as “diacritics in the wild,” to unveil patterns and latent information across six diverse genres: news articles, novels, children’s books, poetry, political documents, and ChatGPT outputs. We present a new annotated dataset that maps real-world partially diacritized words to their... | Salman Elgamal, Ossama Obeid, Mhd Tameem Kabbani, Go Inoue, Nizar Habash |  |
| 912 |  |  [Disinformation Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.793) |  | 0 | Automated disinformation generation is often listed as one of the risks of large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for democratic societies around the world. This paper presents a comprehensive study of the disinformation capabilities of the current generation of LLMs to generate false news articles in English language. In our study, we evaluated the capabilities of 10 LLMs using 20... | Ivan Vykopal, Matús Pikuliak, Ivan Srba, Róbert Móro, Dominik Macko, Mária Bieliková |  |
| 913 |  |  [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://doi.org/10.18653/v1/2024.acl-long.794) |  | 0 | Incremental Learning (IL) has been a long-standing problem in both vision and Natural Language Processing (NLP) communities.In recent years, as Pre-trained Language Models (PLMs) have achieved remarkable progress in various NLP downstream tasks, utilizing PLMs as backbones has become a common practice in recent research of IL in NLP.Most assume that catastrophic forgetting is the biggest obstacle to achieving superior IL performance and propose various techniques to overcome this issue.However,... | Junhao Zheng, Shengjie Qiu, Qianli Ma |  |
| 914 |  |  [How to Handle Different Types of Out-of-Distribution Scenarios in Computational Argumentation? A Comprehensive and Fine-Grained Field Study](https://doi.org/10.18653/v1/2024.acl-long.795) |  | 0 | The advent of pre-trained Language Models (LMs) has markedly advanced natural language processing, but their efficacy in out-of-distribution (OOD) scenarios remains a significant challenge. Computational argumentation (CA), modeling human argumentation processes, is a field notably impacted by these challenges because complex annotation schemes and high annotation costs naturally lead to resources barely covering the multiplicity of available text sources and topics. Due to this data scarcity,... | Andreas Waldis, Yufang Hou, Iryna Gurevych |  |
| 915 |  |  [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](https://doi.org/10.18653/v1/2024.acl-long.796) |  | 0 | Large language models (LLMs) show remarkable human-like capability in various domains and languages. To bridge this quality gap, we introduce Cendol, a collection of Indonesian LLMs encompassing both decoder-only and encoder-decoder architectures across a range of model sizes. We highlight Cendol’s effectiveness across a diverse array of tasks, attaining ~20% improvement, and demonstrate its capability to generalize to unseen tasks and indigenous languages of Indonesia. Furthermore, Cendol... | Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Rifki Afina Putri, Tjeng Wawan Cenggoro, Jhonson Lee, Salsabil Maulana Akbar, Emmanuel Dave, Nuur Shadieq, Muhammad Ihza Mahendra, Dea Annisayanti Putri, Bryan Wilie, Genta Indra Winata, Alham Fikri Aji, Ayu Purwarianti, Pascale Fung |  |
| 916 |  |  [Must NLP be Extractive?](https://doi.org/10.18653/v1/2024.acl-long.797) |  | 0 | How do we roll out language technologies across a world with 7,000 languages? In one story, we scale the successes of NLP further into ‘low-resource’ languages, doing ever more with less. However, this approach does not recognise the fact that, beyond the 500 institutional languages, the remaining languages are oral vernaculars spoken by communities who use a language of wider communication to interact with the outside world. I argue that such ‘contact languages’ are the appropriate target for... | Steven Bird |  |
| 917 |  |  [Spiral of Silence: How is Large Language Model Killing Information Retrieval? - A Case Study on Open Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.798) |  | 0 | The practice of Retrieval-Augmented Generation (RAG), which integrates Large Language Models (LLMs) with retrieval systems, has become increasingly prevalent. However, the repercussions of LLM-derived content infiltrating the web and influencing the retrieval-generation feedback loop are largely uncharted territories. In this study, we construct and iteratively run a simulation pipeline to deeply investigate the short-term and long-term effects of LLM text on RAG systems. Taking the trending... | Xiaoyang Chen, Ben He, Hongyu Lin, Xianpei Han, Tianshu Wang, Boxi Cao, Le Sun, Yingfei Sun |  |
| 918 |  |  [Latxa: An Open Language Model and Evaluation Suite for Basque](https://doi.org/10.18653/v1/2024.acl-long.799) |  | 0 | We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we further introduce 4 multiple choice evaluation datasets: EusProficiency, comprising 5,169 questions from official language proficiency exams; EusReading, comprising 352 reading comprehension questions;... | Julen Etxaniz, Oscar Sainz, Naiara Miguel, Itziar Aldabe, German Rigau, Eneko Agirre, Aitor Ormazabal, Mikel Artetxe, Aitor Soroa |  |
| 919 |  |  [Why are Sensitive Functions Hard for Transformers?](https://doi.org/10.18653/v1/2024.acl-long.800) |  | 0 | Empirical studies have identified a range of learnability biases and limitations of transformers, such as a persistent difficulty in learning to compute simple formal languages such as PARITY, and a bias towards low-degree functions. However, theoretical understanding remains limited, with existing expressiveness theory either overpredicting or underpredicting realistic learning abilities. We prove that, under the transformer architecture, the loss landscape is constrained by the input-space... | Michael Hahn, Mark Rofin |  |
| 920 |  |  [Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction](https://doi.org/10.18653/v1/2024.acl-long.801) |  | 0 | Large Language Model (LLM)-enhanced agents become increasingly prevalent in Human-AI communication, offering vast potential from entertainment to professional domains. However, current multi-modal dialogue systems overlook the acoustic information present in speech, which is crucial for understanding human communication nuances. This oversight can lead to misinterpretations of speakers’ intentions, resulting in inconsistent or even contradictory responses within dialogues. To bridge this gap,... | Haoqiu Yan, Yongxin Zhu, Kai Zheng, Bing Liu, Haoyu Cao, Deqiang Jiang, Linli Xu |  |
| 921 |  |  [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://doi.org/10.18653/v1/2024.acl-long.802) |  | 0 | Code generation has fast become one of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs, such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation, alongside the exploitation of data sources other than the original textual content, has been much sparser than for their natural language counterparts. In particular, most mainstream Code-LMs have been... | Indraneil Paul, Goran Glavas, Iryna Gurevych |  |
| 922 |  |  [The Echoes of Multilinguality: Tracing Cultural Value Shifts during Language Model Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.803) |  | 0 | Texts written in different languages reflect different culturally-dependent beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are jointly trained on a concatenation of text in multiple languages, to encode different cultural values for each language. Yet, as the ‘multilinguality’ of these LMs is driven by cross-lingual sharing, we also have reason to belief that cultural values bleed over from one language into another. This limits the use of MLMs in practice, as apart... | Rochelle Choenni, Anne Lauscher, Ekaterina Shutova |  |
| 923 |  |  [MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.804) |  | 0 | A major consideration in multilingual language modeling is how to best represent languages with diverse vocabularies and scripts.Although contemporary text encoding methods cover most of the world’s writing systems, they exhibit bias towards the high-resource languages of the Global West. As a result, texts of underrepresented languages tend to be segmented into long sequences of linguistically meaningless units. To address the disparities, we introduce a new paradigm that encodes the same... | Tomasz Limisiewicz, Terra Blevins, Hila Gonen, Orevaoghene Ahia, Luke Zettlemoyer |  |
| 924 |  |  [MultiLegalPile: A 689GB Multilingual Legal Corpus](https://doi.org/10.18653/v1/2024.acl-long.805) |  | 0 | Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, few datasets are available for specialized critical domains such as law and the available ones are often small and only in English. To fill this gap, we curate and release MultiLegalPile, a 689GB corpus in 24 languages from 17 jurisdictions. MultiLegalPile includes diverse legal data sources and allows for pretraining NLP models under fair use, with most of the dataset licensed very... | Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, Daniel E. Ho |  |
| 925 |  |  [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](https://doi.org/10.18653/v1/2024.acl-long.806) |  | 0 | Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries... | Haolin Deng, Chang Wang, Xin Li, Dezhang Yuan, Junlang Zhan, Tianhua Zhou, Jin Ma, Jun Gao, Ruifeng Xu |  |
| 926 |  |  [What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages](https://doi.org/10.18653/v1/2024.acl-long.807) |  | 0 | What can large language models learn? By definition, language models (LM) are distributionsover strings. Therefore, an intuitive way of addressing the above question is to formalize it as a matter of learnability of classes of distributions over strings. While prior work in this direction focused on assessing the theoretical limits, in contrast, we seek to understand the empirical learnability. Unlike prior empirical work, we evaluate neural LMs on their home turf—learning probabilistic... | Nadav Borenstein, Anej Svete, Robin Chan, Josef Valvoda, Franz Nowak, Isabelle Augenstein, Eleanor Chodroff, Ryan Cotterell |  |
| 927 |  |  [Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.808) |  | 0 | We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model in the literature. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then... | Behzad Shayegh, Yuqiao Wen, Lili Mou |  |
| 928 |  |  [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs](https://doi.org/10.18653/v1/2024.acl-long.809) |  | 0 | Safety is critical to the usage of large language models (LLMs). Multiple techniques such as data filtering and supervised fine-tuning have been developed to strengthen LLM safety. However, currently known techniques presume that corpora used for safety alignment of LLMs are solely interpreted by semantics. This assumption, however, does not hold in real-world applications, which leads to severe vulnerabilities in LLMs. For example, users of forums often use ASCII art, a form of text-based art,... | Fengqing Jiang, Zhangchen Xu, Luyao Niu, Zhen Xiang, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran |  |
| 929 |  |  [ChatDev: Communicative Agents for Software Development](https://doi.org/10.18653/v1/2024.acl-long.810) |  | 0 | Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique designs, leading to technical inconsistencies across various phases, which results in a fragmented and ineffective development process. In this paper, we introduce ChatDev, a chat-powered software... | Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, Maosong Sun |  |
| 930 |  |  [Disentangled Learning with Synthetic Parallel Data for Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.811) |  | 0 | Text style transfer (TST) is an important task in natural language generation, which aims to transfer the text style (e.g., sentiment) while keeping its semantic information. Due to the absence of parallel datasets for supervision, most existing studies have been conducted in an unsupervised manner, where the generated sentences often suffer from high semantic divergence and thus low semantic preservation. In this paper, we propose a novel disentanglement-based framework for TST named... | Jingxuan Han, Quan Wang, Zikang Guo, Benfeng Xu, Licheng Zhang, Zhendong Mao |  |
| 931 |  |  [PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](https://doi.org/10.18653/v1/2024.acl-long.812) |  | 0 | Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. In this paper, we explore these concerns through the innovative lens of agent psychology, revealing that the dark psychological states of agents constitute a... | Zaibin Zhang, Yongting Zhang, Lijun Li, Jing Shao, Hongzhi Gao, Yu Qiao, Lijun Wang, Huchuan Lu, Feng Zhao |  |
| 932 |  |  [Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation](https://doi.org/10.18653/v1/2024.acl-long.813) |  | 0 | Emotional Support Conversation (ESC) is a task aimed at alleviating individuals’ emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially... | Dongjin Kang, Sunghwan Kim, Taeyoon Kwon, Seungjun Moon, Hyunsouk Cho, Youngjae Yu, Dongha Lee, Jinyoung Yeo |  |
| 933 |  |  [ınftyBench: Extending Long Context Evaluation Beyond 100K Tokens](https://doi.org/10.18653/v1/2024.acl-long.814) |  | 0 | Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a standardized benchmark to evaluate this long-context capability. Existing public benchmarks typically focus on contexts around 10K tokens, limiting the assessment and comparison of LLMs in processing longer... | Xinrong Zhang, Yingfa Chen, Shengding Hu, Zihang Xu, Junhao Chen, Moo Khai Hao, Xu Han, Zhen Leng Thai, Shuo Wang, Zhiyuan Liu, Maosong Sun |  |
| 934 |  |  [Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models](https://doi.org/10.18653/v1/2024.acl-long.815) |  | 0 | Efforts to apply transformer-based language models (TLMs) to the problem of reasoning in natural language have enjoyed ever-increasing success in recent years. The most fundamental task in this area to which nearly all others can be reduced is that of determining satisfiability. However, from a logical point of view, satisfiability problems vary along various dimensions, which may affect TLMs’ ability to learn how to solve them. The problem instances of satisfiability in natural language can... | Tharindu Madusanka, Ian PrattHartmann, Riza BatistaNavarro |  |
| 935 |  |  [Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.816) |  | 0 | Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by... | Paul Röttger, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Kirk, Hinrich Schütze, Dirk Hovy |  |
| 936 |  |  [AI 'News' Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian](https://doi.org/10.18653/v1/2024.acl-long.817) |  | 0 | Large Language Models (LLMs) are increasingly used as ‘content farm’ models (CFMs), to generate synthetic text that could pass for real news articles. This is already happening even for languages that do not have high-quality monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on English, on as little as 40K Italian news articles, is sufficient for producing news-like texts that native speakers of Italian struggle to identify as synthetic.We investigate three LLMs and three... | Giovanni Puccetti, Anna Rogers, Chiara Alzetta, Felice Dell'Orletta, Andrea Esuli |  |
| 937 |  |  [Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.818) |  | 0 | This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA reasoning framework, specifically designed to assess the impact of input length. We isolate the effect of input length using multiple versions of the same sample, each being extended with padding of... | Mosh Levy, Alon Jacoby, Yoav Goldberg |  |
| 938 |  |  [Disambiguate Words like Composing Them: A Morphology-Informed Approach to Enhance Chinese Word Sense Disambiguation](https://doi.org/10.18653/v1/2024.acl-long.819) |  | 0 | In parataxis languages like Chinese, word meanings are highly correlated with morphological knowledge, which can help to disambiguate word senses. However, in-depth exploration of morphological knowledge in previous word sense disambiguation (WSD) methods is still lacking due to the absence of publicly available resources. In this paper, we are motivated to enhance Chinese WSD with full morphological knowledge, including both word-formations and morphemes. We first construct the largest and... | Yue Wang, Qiliang Liang, Yaqi Yin, Hansi Wang, Yang Liu |  |
| 939 |  |  [Do Llamas Work in English? On the Latent Language of Multilingual Transformers](https://doi.org/10.18653/v1/2024.acl-long.820) |  | 0 | We ask whether multilingual language models trained on unbalanced, English-dominated corpora use English as an internal pivot language—-a question of key importance for understanding how language models function and the origins of linguistic bias. Focusing on the Llama-2 family of transformer models, our study is based on carefully constructed non-English prompts with a unique correct single-token continuation. From layer to layer, transformers gradually map an input embedding of the final... | Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West |  |
| 940 |  |  [G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.821) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable abilities in general scenarios. Instruction finetuning empowers them to align with humans in various tasks. Nevertheless, the Diversity and Quality of the instruction data remain two main challenges for instruction finetuning. With regard to this, in this paper, we propose a novel gradient-based method to automatically select high-quality and diverse instruction finetuning data for machine translation. Our key innovation centers around... | Xingyuan Pan, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Shanbo Cheng |  |
| 941 |  |  [Media Framing: A typology and Survey of Computational Approaches Across Disciplines](https://doi.org/10.18653/v1/2024.acl-long.822) |  | 0 | Framing studies how individuals and societies make sense of the world, by communicating or representing complex issues through schema of interpretation. The framing of information in the mass media influences our interpretation of facts and corresponding decisions, so detecting and analysing it is essential to understand biases in the information we consume. Despite that, framing is still mostly examined manually, on a case-by-case basis, while existing large-scale automatic analyses using NLP... | Yulia Otmakhova, Shima Khanehzar, Lea Frermann |  |
| 942 |  |  [SPZ: A Semantic Perturbation-based Data Augmentation Method with Zonal-Mixing for Alzheimer's Disease Detection](https://doi.org/10.18653/v1/2024.acl-long.823) |  | 0 | Alzheimer’s Disease (AD), characterized by significant cognitive and functional impairment, necessitates the development of early detection techniques. Traditional diagnostic practices, such as cognitive assessments and biomarker analysis, are often invasive and costly. Deep learning-based approaches for non-invasive AD detection have been explored in recent studies, but the lack of accessible data hinders further improvements in detection performance. To address these challenges, we propose a... | Fangfang Li, Cheng Huang, Puzhen Su, Jie Yin |  |
| 943 |  |  [Calibrating Large Language Models Using Their Generations Only](https://doi.org/10.18653/v1/2024.acl-long.824) |  | 0 | As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model’s confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs—especially when the only interface to the models is their generated text—remains a challenge. We propose APRICOT (Auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that... | Dennis Ulmer, Martin Gubri, Hwaran Lee, Sangdoo Yun, Seong Joon Oh |  |
| 944 |  |  [Iterative Forward Tuning Boosts In-Context Learning in Language Models](https://doi.org/10.18653/v1/2024.acl-long.825) |  | 0 | Despite the advancements in in-context learning (ICL) for large language models (LLMs), current research centers on specific prompt engineering, such as demonstration selection, with the expectation that a single iteration of demonstrations processing can generalize effectively to a given test sample. However, this perspective overlooks the potential benefits derived from multiple iterations involving demonstrations, a practice aligning more closely with the iterative decision-making process... | Jiaxi Yang, Binyuan Hui, Min Yang, Bailin Wang, Bowen Li, Binhua Li, Fei Huang, Yongbin Li |  |
| 945 |  |  [Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement](https://doi.org/10.18653/v1/2024.acl-long.826) |  | 0 | Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM’s bias in evaluating their own output. In this paper, we formally define LLM’s self-bias – the tendency to favor its own generation – using two statistics. We analyze six LLMs (GPT-4, GPT-3.5, Gemini, LLaMA2, Mixtral and DeepSeek) on translation, constrained text generation, and mathematical reasoning... | Wenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, William Wang |  |
| 946 |  |  [Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't](https://doi.org/10.18653/v1/2024.acl-long.827) |  | 0 | We investigate what linguistic factors affect the performance of Automatic Speech Recognition (ASR) models. We hypothesize that orthographic and phonological complexities both degrade accuracy. To examine this, we fine-tune the multilingual self-supervised pretrained model Wav2Vec2-XLSR-53 on 25 languages with 15 writing systems, and we compare their ASR accuracy, number of graphemes, unigram grapheme entropy, logographicity (how much word/morpheme-level information is encoded in the writing... | Chihiro Taguchi, David Chiang |  |
| 947 |  |  [Steering Llama 2 via Contrastive Activation Addition](https://doi.org/10.18653/v1/2024.acl-long.828) |  | 0 | We introduce Contrastive Activation Addition (CAA), a method for steering language models by modifying their activations during forward passes. CAA computes “steering vectors” by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular behavior, such as factual versus hallucinatory responses. During inference, these steering vectors are added at all token positions after the user’s prompt with either a positive or negative... | Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, Alexander Matt Turner |  |
| 948 |  |  [EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities](https://doi.org/10.18653/v1/2024.acl-long.829) |  | 0 | The advent of artificial intelligence has led to a growing emphasis on data-driven modeling in macroeconomics, with agent-based modeling (ABM) emerging as a prominent bottom-up simulation paradigm. In ABM, agents (\*e.g.\*, households, firms) interact within a macroeconomic environment, collectively generating market dynamics. Existing agent modeling typically employs predetermined rules or learning-based neural networks for decision-making. However, customizing each agent presents significant... | Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao |  |
| 949 |  |  [SafetyBench: Evaluating the Safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.830) |  | 0 | With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs,... | Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, Minlie Huang |  |
| 950 |  |  [Deciphering Oracle Bone Language with Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.831) |  | 0 | Originating from China’s Shang Dynasty approximately 3,000 years ago, the Oracle Bone Script (OBS) is a cornerstone in the annals of linguistic history, predating many established writing systems. Despite the discovery of thousands of inscriptions, a vast expanse of OBS remains undeciphered, casting a veil of mystery over this ancient language. The emergence of modern AI technologies presents a novel frontier for OBS decipherment, challenging traditional NLP methods that rely heavily on large... | Haisu Guan, Huanxin Yang, Xinyu Wang, Shengwei Han, Yongge Liu, Lianwen Jin, Xiang Bai, Yuliang Liu |  |
| 951 |  |  [M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.832) |  | 0 | Managing long sequences has become an important and necessary feature for large language models (LLMs). However, assessing their ability to handle long contexts remains a challenge. This paper introduces M4LE, a Multi-ability, Multi-range, Multi-task, Multi-domain benchmark for Long-context Evaluation. It encompasses 36 NLP datasets, covering 11 types of tasks and 12 domains, providing a comprehensive test bed. To address the lack of tasks featuring naturally long sequences, we propose an... | WaiChung Kwan, Xingshan Zeng, Yufei Wang, Yusen Sun, Liangyou Li, Yuxin Jiang, Lifeng Shang, Qun Liu, KamFai Wong |  |
| 952 |  |  [RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models via Romanization](https://doi.org/10.18653/v1/2024.acl-long.833) |  | 0 | This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Roman scripts. We propose an approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens with English enhance cross-lingual alignment. Our approach involve the continual pretraining of a English LLM like Llama 2 on romanized text of non-English, non-Roman script languages, followed by... | Jaavid Aktar Husain, Raj Dabre, Aswanth M., Jay Gala, Thanmay Jayakumar, Ratish Puduppully, Anoop Kunchukuttan |  |
| 953 |  |  [Causal Estimation of Memorisation Profiles](https://doi.org/10.18653/v1/2024.acl-long.834) |  | 0 | Understanding memorisation in language models has practical and societal implications, e.g., studying models’ training dynamics or preventing copyright infringements.Prior work defines memorisation as the causal effect of training with an instance on the model’s ability to predict that instance. This definition relies on a counterfactual: the ability to observe what would have happened had the model not seen that instance.Existing methods struggle to provide computationally efficient and... | Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel |  |
| 954 |  |  [CHECKWHY: Causal Fact Verification via Argument Structure](https://doi.org/10.18653/v1/2024.acl-long.835) |  | 0 | With the growing complexity of fact verification tasks, the concern with “thoughtful” reasoning capabilities is increasing. However, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. In this paper, we introduce CHECKWHY, a challenging dataset tailored to a novel causal fact verification task: checking the truthfulness of the causal relation within claims through rigorous reasoning steps.... | Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu Zhou |  |
| 955 |  |  [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://doi.org/10.18653/v1/2024.acl-long.836) |  | 0 | Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However, research has shown that this assumption does not always hold, and generation quality can be improved by decoding to optimize a utility function backed by a metric or quality-estimation signal, as is done by... | Christian Tomani, David Vilar, Markus Freitag, Colin Cherry, Subhajit Naskar, Mara Finkelstein, Xavier Garcia, Daniel Cremers |  |
| 956 |  |  [On Efficient and Statistical Quality Estimation for Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.837) |  | 0 | Annotated datasets are an essential ingredient to train, evaluate, compare and productionalize supervised machine learning models. It is therefore imperative that annotations are of high quality. For their creation, good quality management and thereby reliable quality estimates are needed. Then, if quality is insufficient during the annotation process, rectifying measures can be taken to improve it. Quality estimation is often performed by having experts manually label instances as correct or... | JanChristoph Klie, Juan Haladjian, Marc Kirchner, Rahul Nair |  |
| 957 |  |  [EZ-STANCE: A Large Dataset for English Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.838) |  | 0 | Zero-shot stance detection (ZSSD) aims to determine whether the author of a text is in favor, against, or neutral toward a target that is unseen during training. In this paper, we present EZ-STANCE, a large English ZSSD dataset with 47,316 annotated text-target pairs. In contrast to VAST, which is the only other large existing ZSSD dataset for English, EZ-STANCE is 2.5 times larger, includes both noun-phrase targets and claim targets that cover a wide range of domains, provides two challenging... | Chenye Zhao, Cornelia Caragea |  |
| 958 |  |  [American Sign Language Handshapes Reflect Pressures for Communicative Efficiency](https://doi.org/10.18653/v1/2024.acl-long.839) |  | 0 | Communicative efficiency is a key topic in linguistics and cognitive psychology, with many studies demonstrating how the pressure to communicate with minimal effort guides the form of natural language. However, this phenomenon is rarely explored in signed languages. This paper shows how handshapes in American Sign Language (ASL) reflect these efficiency pressures and provides new evidence of communicative efficiency in the visual-gestural modality.We focus on hand configurations in native ASL... | Kayo Yin, Terry Regier, Dan Klein |  |
| 959 |  |  [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://doi.org/10.18653/v1/2024.acl-long.840) |  | 0 | Information about pretraining corpora used to train the current best-performing language models is seldom discussed: commercial models rarely detail their data, and even open models are often released without accompanying training data or recipes to reproduce them. As a result, it is challenging to conduct and advance scientific research on language modeling, such as understanding how training data impacts model capabilities and limitations. To facilitate scientific research on language model... | Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Raghavi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha, Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Abhilasha Ravichander, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi, Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo |  |
| 960 |  |  [OLMo: Accelerating the Science of Language Models](https://doi.org/10.18653/v1/2024.acl-long.841) |  | 0 | Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community... | Dirk Groeneveld, Iz Beltagy, Evan Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi |  |
| 961 |  |  [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://doi.org/10.18653/v1/2024.acl-long.842) |  | 0 | Large language models (LLMs) undergo safety alignment to ensure safe conversations with humans. However, this paper introduces a training-free attack method capable of reversing safety alignment, converting the outcomes of stronger alignment into greater potential for harm by accessing only LLM output token distributions. Specifically, our method achieves this reversal by contrasting the output token distribution of a safety-aligned language model (e.g., Llama-2-chat) against its pre-trained... | Zhanhui Zhou, Jie Liu, Zhichen Dong, Jiaheng Liu, Chao Yang, Wanli Ouyang, Yu Qiao |  |
| 962 |  |  [IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for Indian Languages](https://doi.org/10.18653/v1/2024.acl-long.843) |  | 0 | Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the development of Indic LLMs, covering 22 languages, containing a total of 251B tokens and 74.8M instruction-response pairs. Recognizing the importance of both data quality and quantity, our approach combines... | Mohammed Safi Ur Rahman Khan, Priyam Mehta, Ananth Sankar, Umashankar Kumaravelan, Sumanth Doddapaneni, Suriyaprasaad B, Varun Balan G, Sparsh Jain, Anoop Kunchukuttan, Pratyush Kumar, Raj Dabre, Mitesh M. Khapra |  |
| 963 |  |  [Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.844) |  | 0 | Large Language Models (LLMs) have achieved remarkable performance in objective tasks such as open-domain question answering and mathematical reasoning, which can often be solved through recalling learned factual knowledge or chain-of-thought style reasoning. However, we find that the performance of LLMs in subjective tasks is still unsatisfactory, such as metaphor recognition, dark humor detection, etc. Compared to objective tasks, subjective tasks focus more on interpretation or emotional... | Xiaolong Wang, Yile Wang, Yuanchi Zhang, Fuwen Luo, Peng Li, Maosong Sun, Yang Liu |  |
| 964 |  |  [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://doi.org/10.18653/v1/2024.acl-long.845) |  | 0 | Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive... | Ahmet Üstün, Viraat Aryabumi, Zheng Xin Yong, WeiYin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, HuiLee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker |  |
| 965 |  |  [BatchEval: Towards Human-like Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.846) |  | 0 | Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior ensemble performance with static reference. Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BatchEval, a paradigm that... | Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 966 |  |  [ToMBench: Benchmarking Theory of Mind in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.847) |  | 0 | Theory of Mind (ToM) is the cognitive capability to perceive and ascribe mental states to oneself and others. Recent research has sparked a debate over whether large language models (LLMs) exhibit a form of ToM. However, existing ToM evaluations are hindered by challenges such as constrained scope, subjective judgment, and unintended contamination, yielding inadequate assessments. To address this gap, we introduce ToMBench with three key characteristics: a systematic evaluation framework... | Zhuang Chen, Jincenzi Wu, Jinfeng Zhou, Bosi Wen, Guanqun Bi, Gongyao Jiang, Yaru Cao, Mengting Hu, Yunghwei Lai, Zexuan Xiong, Minlie Huang |  |
| 967 |  |  [COKE: A Cognitive Knowledge Graph for Machine Theory of Mind](https://doi.org/10.18653/v1/2024.acl-long.848) |  | 0 | Theory of mind (ToM) refers to humans’ ability to understand and infer the desires, beliefs, and intentions of others. The acquisition of ToM plays a key role in humans’ social cognition and interpersonal relations. Though indispensable for social intelligence, ToM is still lacking for modern AI and NLP systems since they cannot access the human mental state and cognitive process beneath the training corpus. To empower AI systems with the ToM ability and narrow the gap between them and humans,... | Jincenzi Wu, Zhuang Chen, Jiawen Deng, Sahand Sabour, Helen Meng, Minlie Huang |  |
| 968 |  |  [MultiPICo: Multilingual Perspectivist Irony Corpus](https://doi.org/10.18653/v1/2024.acl-long.849) |  | 0 | Recently, several scholars have contributed to the growth of a new theoretical framework in NLP called perspectivism. This approach aimsto leverage data annotated by different individuals to model diverse perspectives that affect their opinions on subjective phenomena such as irony. In this context, we propose MultiPICo, a multilingual perspectivist corpus of ironic short conversations in different languages andlinguistic varieties extracted from Twitter and Reddit. The corpus includes... | Silvia Casola, Simona Frenda, Soda Marem Lo, Erhan Sezerer, Antonio Uva, Valerio Basile, Cristina Bosco, Alessandro Pedrani, Chiara Rubagotti, Viviana Patti, Davide Bernardi |  |
| 969 |  |  [AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents](https://doi.org/10.18653/v1/2024.acl-long.850) |  | 0 | Autonomous agents that address day-to-day digital tasks (e.g., ordering groceries for a household), must not only operate multiple apps (e.g., notes, messaging, shopping app) via APIs, but also generate rich code with complex control flow in an iterative manner based on their interaction with the environment. However, existing benchmarks for tool use are inadequate, as they only cover tasks that require a simple sequence of API calls. To remedy this gap, we built AppWorld Engine, a high-quality... | Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian |  |
| 970 |  |  [MMToM-QA: Multimodal Theory of Mind Question Answering](https://doi.org/10.18653/v1/2024.acl-long.851) |  | 0 | Theory of Mind (ToM), the ability to understand people’s mental states, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM benchmarks use unimodal datasets – either video or text. Human ToM, on the other hand, is more than video or text understanding. People can flexibly reason about another person’s mind based on... | Chuanyang Jin, Yutong Wu, Jing Cao, Jiannan Xiang, YenLing Kuo, Zhiting Hu, Tomer D. Ullman, Antonio Torralba, Joshua B. Tenenbaum, Tianmin Shu |  |
| 971 |  |  [DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents](https://doi.org/10.18653/v1/2024.acl-long.852) |  | 0 | Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems. However, the degree to which these numerical reasoning skills are effective in real-world scenarios, particularly in expert domains, is still largely unexplored. This paper introduces DocMath-Eval, a comprehensive benchmark specifically designed to evaluate the numerical reasoning capabilities of LLMs in the context of understanding and analyzing specialized documents containing both text and tables.... | Yilun Zhao, Yitao Long, Hongjun Liu, Ryo Kamoi, Linyong Nan, Lyuhao Chen, Yixin Liu, Xiangru Tang, Rui Zhang, Arman Cohan |  |
| 972 |  |  [Unintended Impacts of LLM Alignment on Global Representation](https://doi.org/10.18653/v1/2024.acl-long.853) |  | 0 | Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on benchmarks of instruction following, reasoning, and truthfulness. However, human preferences are not universal, and aligning to specific preference sets may have unintended effects. We explore how... | Michael J. Ryan, William Held, Diyi Yang |  |
| 973 |  |  [ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.854) |  | 0 | While state-of-the-art large language models (LLMs) can excel at adapting text from one style to another, current work does not address the explainability of style transfer models. Recent work has explored generating textual explanations from larger teacher models and distilling them into smaller student models. One challenge with such approach is that LLM outputs may contain errors that require expertise to correct, but gathering and incorporating expert feedback is difficult due to cost and... | Arkadiy Saakyan, Smaranda Muresan |  |
| 974 |  |  [MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy](https://doi.org/10.18653/v1/2024.acl-long.855) |  | 0 | It has been widely observed that exact or approximate MAP (mode-seeking) decoding from natural language generation (NLG) models consistently leads to degenerate outputs (Holtzman et al., 2019; Stahlberg and Byrne, 2019). Prior work has attributed this behavior to either a fundamental and unavoidable inadequacy of modes in probabilistic models or weaknesses in language modeling. Contrastingly, we argue that degenerate modes can even occur in the absence of any modeling error, due to... | Davis Yoshida, Kartik Goyal, Kevin Gimpel |  |
| 975 |  |  [Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!](https://doi.org/10.18653/v1/2024.acl-long.856) |  | 0 | Annually, at the Conference of Machine Translation (WMT), the Metrics Shared Task organizers conduct the meta-evaluation of Machine Translation (MT) metrics, ranking them according to their correlation with human judgments. Their results guide researchers toward enhancing the next generation of metrics and MT systems. With the recent introduction of neural metrics, the field has witnessed notable advancements. Nevertheless, the inherent opacity of these metrics has posed substantial challenges... | Stefano Perrella, Lorenzo Proietti, Alessandro Scirè, Edoardo Barba, Roberto Navigli |  |
| 976 |  |  [NounAtlas: Filling the Gap in Nominal Semantic Role Labeling](https://doi.org/10.18653/v1/2024.acl-long.857) |  | 0 | Despite significant advances in Semantic Role Labeling (SRL), much work in this field has been carried out with a focus on verbal predicates, with the research on nominal SRL lagging behind. In many contexts, however, nominal predicates are often as informative as verbal ones, thus needing proper treatment. In this paper we aim to fill this gap and make nominal SRL a first-class citizen. We introduce a novel approach to create the first large-scale, high-quality inventory of nominal predicates... | Roberto Navigli, Marco Pinto, Pasquale Silvestri, Dennis Rotondi, Simone Ciciliano, Alessandro Scirè |  |
| 977 |  |  [The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation](https://doi.org/10.18653/v1/2024.acl-long.858) |  | 0 | Large language models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive one. Therefore, in this study, we delve into LLMs’ susceptibility to persuasive conversations, particularly on factual questions that they can answer correctly. We first curate the Farm (i.e., Fact to... | Rongwu Xu, Brian S. Lin, Shujian Yang, Tianqi Zhang, Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei Xu, Han Qiu |  |
| 978 |  |  [LooGLE: Can Long-Context Language Models Understand Long Contexts?](https://doi.org/10.18653/v1/2024.acl-long.859) |  | 0 | Large language models (LLMs) are typically limited to processing texts within context window size, which has spurred significant research efforts into enhancing LLMs’ long-context understanding as well as developing high-quality benchmarks to evaluate the ability. However, prior datasets suffer from short comings like short length compared to the context window of modern LLMs; outdated documents that might have data leakage problems; and an emphasis on short dependency tasks only. In this... | Jiaqi Li, Mengmeng Wang, Zilong Zheng, Muhan Zhang |  |
| 979 |  |  [Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation](https://doi.org/10.18653/v1/2024.acl-long.860) |  | 0 | In this paper, we introduce a novel Face-to-Face spoken dialogue model. It processes audio-visual speech from user input and generates audio-visual speech as the response, marking the initial step towards creating an avatar chatbot system without relying on intermediate text. To this end, we newly introduce MultiDialog, the first large-scale multimodal (i.e, audio and visual) spoken dialogue corpus containing 340 hours of approximately 9,000 dialogues, recorded based on the open domain dialogue... | Se Jin Park, Chae Won Kim, Hyeongseop Rha, Minsu Kim, Joanna Hong, Jeong Hun Yeo, Yong Man Ro |  |
| 980 |  |  [ECBD: Evidence-Centered Benchmark Design for NLP](https://doi.org/10.18653/v1/2024.acl-long.861) |  | 0 | Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually measuring. There is currently no principled way of analyzing these decisions and how they impact the validity of the benchmark’s measurements. To address this gap, we draw on evidence-centered design in... | Yu Lu Liu, Su Lin Blodgett, Jackie C. K. Cheung, Vera Liao, Alexandra Olteanu, Ziang Xiao |  |
| 981 |  |  [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.862) |  | 0 | As the reach of large language models (LMs) expands globally, their ability to cater to diverse cultural contexts becomes crucial. Despite advancements in multilingual capabilities, models are not designed with appropriate cultural nuances. In this paper, we show that multilingual and Arabic monolingual LMs exhibit bias towards entities associated with Western culture. We introduce CAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities spanning eight types that contrast... | Tarek Naous, Michael J. Ryan, Alan Ritter, Wei Xu |  |
| 982 |  |  [Explicating the Implicit: Argument Detection Beyond Sentence Boundaries](https://doi.org/10.18653/v1/2024.acl-long.863) |  | 0 | Detecting semantic arguments of a predicate word has been conventionally modeled as a sentence-level task. The typical reader, however, perfectly interprets predicate-argument relations in a much wider context than just the sentence where the predicate was evoked. In this work, we reformulate the problem of argument detection through textual entailment to capture semantic relations across sentence boundaries. We propose a method that tests whether some semantic relation can be inferred from a... | Paul Roit, Aviv Slobodkin, Eran Hirsch, Arie Cattan, Ayal Klein, Valentina Pyatkin, Ido Dagan |  |
| 983 |  |  [Word Embeddings Are Steers for Language Models](https://doi.org/10.18653/v1/2024.acl-long.864) |  | 0 | Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically revisit output word embeddings and find that their linear transformations are equivalent to steering language model generation styles. We name such steers LM-Steers and find them existing in LMs of... | Chi Han, Jialiang Xu, Manling Li, Yi Fung, Chenkai Sun, Nan Jiang, Tarek F. Abdelzaher, Heng Ji |  |
| 984 |  |  [Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024](https://aclanthology.org/volumes/2024.findings-acl/) |  | 0 |  | LunWei Ku, Andre Martins, Vivek Srikumar |  |
| 985 |  |  [Frontmatter](https://aclanthology.org/2024.findings-acl.0) |  | 0 |  |  |  |
| 986 |  |  [Controllable Data Augmentation for Few-Shot Text Mining with Chain-of-Thought Attribute Manipulation](https://doi.org/10.18653/v1/2024.findings-acl.1) |  | 0 | Prompting large language models (LLMs) for data augmentation has recently become a common practice in few-shot NLP tasks. In this paper, we propose Chain-of-Thought Attribute Manipulation (CoTAM), a novel approach that generates new data from existing examples by only tweaking in the user-provided, task-specific attribute, e.g., sentiment polarity or topic in movie reviews. Instead of conventional latent representation controlling, we leverage the chain-of-thought prompting to directly edit the... | Letian Peng, Yuwei Zhang, Jingbo Shang |  |
| 987 |  |  [Match More, Extract Better! Hybrid Matching Model for Open Domain Web Keyphrase Extraction](https://doi.org/10.18653/v1/2024.findings-acl.2) |  | 0 | Keyphrase extraction aims to automatically extract salient phrases representing the critical information in the source document. Identifying salient phrases is challenging because there is a lot of noisy information in the document, leading to wrong extraction. To address this issue, in this paper, we propose a hybrid matching model for keyphrase extraction, which combines representation-focused and interaction-based matching modules into a unified framework for improving the performance of the... | Mingyang Song, Liping Jing, Yi Feng |  |
| 988 |  |  [AFPQ: Asymmetric Floating Point Quantization for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.3) |  | 0 | Large language models (LLMs) show great performance in various tasks, but face deployment challenges from limited memory capacity and bandwidth.Low-bit weight quantization can save memory and accelerate inference.Although floating-point (FP) formats show good performance in LLM quantization, they tend to perform poorly with small group sizes or sub-4 bits.We find the reason is that the absence of asymmetry in previous FP quantization makes it unsuitable for handling asymmetric value... | Yijia Zhang, Sicheng Zhang, Shijie Cao, Dayou Du, Jianyu Wei, Ting Cao, Ningyi Xu |  |
| 989 |  |  [End-to-End Emotion Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.4) |  | 0 | Emotion detection is the task of automatically associating one or more emotions with a text. The emotions are experienced, targeted, and caused by different semantic constituents. Therefore, it is necessary to incorporate these semantic constituents into the process of emotion detection. In this study, we propose a new task called emotion semantic parsing which aims to parse the emotion and semantic constituents into an abstract semantic tree structure. In particular, we design an end-to-end... | Xiaotong Jiang, Zhongqing Wang, Guodong Zhou |  |
| 990 |  |  [Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System](https://doi.org/10.18653/v1/2024.findings-acl.5) |  | 0 | Intelligent task-oriented dialogue systems (ToDs) are expected to continuously acquire new knowledge, also known as Continual Learning (CL), which is crucial to fit ever-changing user needs. However, catastrophic forgetting dramatically degrades the model performance in face of a long streamed curriculum. In this paper, we aim to overcome the forgetting problem in ToDs and propose a method (HESIT) with hyper-gradient-based exemplar strategy, which samples influential exemplars for periodic... | Chen Chen, Ruizhe Li, Yuchen Hu, Yuanyuan Chen, Chengwei Qin, Qiang Zhang |  |
| 991 |  |  [Unveiling Imitation Learning: Exploring the impact of Data Falsity to Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.6) |  | 0 | Many recent studies endeavor to improve open-sourced language models through imitation learning, re-training on the synthetic instruction data from state-of-the-art proprietary models like ChatGPT and GPT-4.However, the innate nature of synthetic data inherently contains noisy data, giving rise to a substantial presence of low-quality data replete with misleading queries, erroneous responses, and flawed reasoning.Although we intuitively grasp the potential harm of noisy data, we lack a... | Hyunsoo Cho |  |
| 992 |  |  [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://doi.org/10.18653/v1/2024.findings-acl.7) |  | 0 | While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover... | Alex Gu, WenDing Li, Naman Jain, Theo Olausson, Celine Lee, Koushik Sen, Armando SolarLezama |  |
| 993 |  |  [CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support](https://doi.org/10.18653/v1/2024.findings-acl.8) |  | 0 | Literature review requires researchers to synthesize a large amount of information and is increasingly challenging as the scientific literature expands. In this work, we investigate the potential of LLMs for producing hierarchical organizations of scientific studies to assist researchers with literature review. We define hierarchical organizations as tree structures where nodes refer to topical categories and every node is linked to the studies assigned to that category. Our naive LLM-based... | ChaoChun Hsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, Chenhao Tan, David Wadden, Lucy Lu Wang, Aakanksha Naik |  |
| 994 |  |  [Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.9) |  | 0 | With the recent advances of large language models (LLMs), it is no longer infeasible to build an automated debate system that helps people to synthesise persuasive arguments. Previous work attempted this task by integrating multiple components. In our work, we introduce an argument mining dataset that captures the end-to-end process of preparing an argumentative essay for a debate, which covers the tasks of claim and evidence identification (Task 1 ED), evidence convincingness ranking (Task 2... | Hao Li, Yuping Wu, Viktor Schlegel, Riza BatistaNavarro, Tharindu Madusanka, Iqra Zahid, Jiayan Zeng, Xiaochi Wang, Xinran He, Yizhi Li, Goran Nenadic |  |
| 995 |  |  [A Grounded Preference Model for LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.10) |  | 0 | Despite LLMs’ recent advancements, they still suffer from factual inconsistency and hallucination. An often-opted remedy is retrieval-augmented generation – however, there is no guarantee that the model will strictly adhere to retrieved grounding. Fundamentally, LLMs need to be aligned to be more faithful to grounding, which will require high-quality preference annotations. This paper investigates whether we can create high-quality grounded preference data for model alignment without using... | Tahira Naseem, Guangxuan Xu, Sarathkrishna Swaminathan, Asaf Yehudai, Subhajit Chaudhury, Radu Florian, Ramón Fernandez Astudillo, Asim Munawar |  |
| 996 |  |  [Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](https://doi.org/10.18653/v1/2024.findings-acl.11) |  | 0 | Large language models (LLMs), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment LLMs with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains, texts are interconnected (e.g., academic papers in a bibliographic graph are linked by citations and co-authorships) which form a (text-attributed) graph. The knowledge in such graphs is encoded not... | Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han |  |
| 997 |  |  [Text2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.12) |  | 0 | The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE, Text2DB, that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the... | Yizhu Jiao, Sha Li, Sizhe Zhou, Heng Ji, Jiawei Han |  |
| 998 |  |  [How Important is a Language Model for Low-resource ASR?](https://doi.org/10.18653/v1/2024.findings-acl.13) |  | 0 | N-gram language models (LMs) are the innovation that first made large-vocabulary continuous automatic speech recognition (ASR) viable. With neural end-to-end ASR architectures, however, LMs have become an afterthought. While the effect on accuracy may be negligible for English and Mandarin, jettisoning the LM might not make sense for the world’s remaining 6000+ languages. In this paper, we investigate the role of the LM in low-resource ASR. First we ask: does using an n-gram LM in decoding in... | Zoey Liu, Nitin Venkateswaran, Éric Le Ferrand, Emily Prud'hommeaux |  |
| 999 |  |  [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](https://doi.org/10.18653/v1/2024.findings-acl.14) |  | 0 | Large language models (LLMs) are typically trained on general source data forvarious domains, but a recent surge in domain-specific LLMs has shown theirpotential to outperform general-purpose models in domain-specific tasks (e.g.,biomedicine). Although domain-specific pre-training enhances efficiency andleads to smaller models, the computational costs of training these LLMs remainhigh, posing budgeting challenges. We introduce MediSwift, a suite of biomedicalLMs that leverage sparse... | Vithursan Thangarasa, Mahmoud Salem, Shreyas Saxena, ChenYu Leong, Joel Hestness, Sean Lie |  |
| 1000 |  |  [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.15) |  | 0 | Today’s most accurate language models are trained on orders of magnitude more language data than human language learners receive— but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs’ representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve... | Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas |  |
| 1001 |  |  [P-TA: Using Proximal Policy Optimization to Enhance Tabular Data Augmentation via Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.16) |  | 0 | A multitude of industries depend on accurate and reasonable tabular data augmentation for their business processes. Contemporary methodologies in generating tabular data revolve around utilizing Generative Adversarial Networks (GAN) or fine-tuning Large Language Models (LLM). However, GAN-based approaches are documented to produce samples with common-sense errors attributed to the absence of external knowledge. On the other hand, LLM-based methods exhibit a limited capacity to capture the... | Shuo Yang, Chenchen Yuan, Yao Rong, Felix Steinbauer, Gjergji Kasneci |  |
| 1002 |  |  [Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.17) |  | 0 | There is increasing interest in distilling task-specific knowledge from large language models (LLM) to smaller student models.Nonetheless, LLM distillation presents a dual challenge: 1) there is a high cost associated with querying the teacher LLM, such as GPT-4, for gathering an ample number of demonstrations; 2) the teacher LLM might provide imperfect outputs with a negative impact on the student’s learning process. To enhance sample efficiency within resource-constrained, imperfect teacher... | Yuhang Zhou, Wei Ai |  |
| 1003 |  |  [Small Models are Valuable Plug-ins for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.18) |  | 0 | Large language models (LLMs) such as GPT-3 and GPT-4 are powerful but their weights are often publicly unavailable and their immense sizes make the models difficult to be tuned with common hardware. As a result, effectively tuning these models with large-scale supervised data can be challenging. As an alternative, In-Context Learning (ICL) can only use a small number of supervised examples due to context length limits. In this paper, we propose Super In-Context Learning (SuperICL) which allows... | Canwen Xu, Yichong Xu, Shuohang Wang, Yang Liu, Chenguang Zhu, Julian J. McAuley |  |
| 1004 |  |  [Are self-explanations from Large Language Models faithful?](https://doi.org/10.18653/v1/2024.findings-acl.19) |  | 0 | Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it’s important to measure if self-explanations truly reflect the model’s behavior. Such a measure is called interpretability-faithfulness and is challenging to perform since the ground truth is inaccessible, and many LLMs only have an... | Andreas Madsen, Sarath Chandar, Siva Reddy |  |
| 1005 |  |  [ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction](https://doi.org/10.18653/v1/2024.findings-acl.20) |  | 0 | Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains. To address these limitations, we present ImplicitAVE, the first, publicly available multimodal dataset for implicit attribute value extraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated and expanded to include implicit... | Henry Peng Zou, Vinay Samuel, Yue Zhou, Weizhi Zhang, Liancheng Fang, Zihe Song, Philip S. Yu, Cornelia Caragea |  |
| 1006 |  |  [Prompt Engineering a Prompt Engineer](https://doi.org/10.18653/v1/2024.findings-acl.21) |  | 0 | Prompt engineering is a challenging yet crucial task for optimizing the performance of large language models on customized tasks. It requires complex reasoning to examine the model’s errors, hypothesize what is missing or misleading in the current prompt, and communicate the task with clarity. While recent works indicate that large language models can be meta-prompted to perform automatic prompt engineering, we argue that their potential is limited due to insufficient guidance for complex... | Qinyuan Ye, Mohamed Ahmed, Reid Pryzant, Fereshte Khani |  |
| 1007 |  |  [ASPIRE: Language-Guided Data Augmentation for Improving Robustness Against Spurious Correlations](https://doi.org/10.18653/v1/2024.findings-acl.22) |  | 0 | Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. This paper presents ASPIRE (Language-guided Data Augmentation for SPurIous correlation REmoval), a simple yet effective solution for supplementing the training dataset with images without spurious features, for robust... | Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, S. Sakshi, Sanjoy Chowdhury, Dinesh Manocha |  |
| 1008 |  |  [Tables as Texts or Images: Evaluating the Table Reasoning Ability of LLMs and MLLMs](https://doi.org/10.18653/v1/2024.findings-acl.23) |  | 0 | Tables contrast with unstructured text data by its structure to organize the information.In this paper, we investigate the efficiency of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related tasks such as question-answering and fact-checking. We pioneer in the assessment of LLMs’ performance on image-based table representation. Specifically, we compare five text-based and three image-based... | Naihao Deng, Zhenjie Sun, Ruiqi He, Aman Sikka, Yulong Chen, Lin Ma, Yue Zhang, Rada Mihalcea |  |
| 1009 |  |  [Biasly: An Expert-Annotated Dataset for Subtle Misogyny Detection and Mitigation](https://doi.org/10.18653/v1/2024.findings-acl.24) |  | 0 | Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles, capturing colloquial expressions of misogyny in North American film. The open-source dataset can be used for a range of NLP tasks, including binary and multi-label classification, severity score regression,... | Brooklyn Sheppard, Anna Richter, Allison Cohen, Elizabeth Allyn Smith, Tamara Kneese, Carolyne Pelletier, Ioana Baldini, Yue Dong |  |
| 1010 |  |  [BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra](https://doi.org/10.18653/v1/2024.findings-acl.25) |  | 0 | Many existing end-to-end systems for hybrid question answering tasks can often be boiled down to a “prompt-and-pray” paradigm, where the user has limited control and insight into the intermediate reasoning steps used to achieve the final result. Additionally, due to the context size limitation of many transformer-based LLMs, it is often not reasonable to expect that the full structured and unstructured context will fit into a given prompt in a zero-shot setting, let alone a few-shot setting. We... | Parker Glenn, Parag Dakle, Liang Wang, Preethi Raghavan |  |
| 1011 |  |  [LLM-QAT: Data-Free Quantization Aware Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.26) |  | 0 | Several post-training quantization methods have been applied to large language models (LLMs), and have been shown to perform well down to 8-bits. We find that these methods break down at lower bit precision, and investigate quantization-aware training for LLMs (LLM-QAT) to push quantization levels even further. We propose a data-free distillation method that leverages generations produced by the pre-trained model, which better preserves the original output distribution and allows quantizing any... | Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, Vikas Chandra |  |
| 1012 |  |  [InfiMM: Advancing Multimodal Understanding with an Open-Sourced Visual Language Model](https://doi.org/10.18653/v1/2024.findings-acl.27) |  | 0 | In this work, we present InfiMM, an advanced Multimodal Large Language Model that adapts to intricate vision-language tasks. InfiMM, inspired by the Flamingo architecture, distinguishes itself through the utilization of large-scale training data, comprehensive training strategies, and diverse large language models. This approach ensures the preservation of Flamingo’s foundational strengths while simultaneously introducing augmented capabilities. Empirical evaluations across a variety of... | Haogeng Liu, Quanzeng You, Yiqi Wang, Xiaotian Han, Bohan Zhai, Yongfei Liu, Wentao Chen, Yiren Jian, Yunzhe Tao, Jianbo Yuan, Ran He, Hongxia Yang |  |
| 1013 |  |  [Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution](https://doi.org/10.18653/v1/2024.findings-acl.28) |  | 0 | Although achieving great success, Large Language Models (LLMs) usually suffer from unreliable hallucinations. Although language attribution can be a potential solution, there are no suitable benchmarks and evaluation metrics to attribute LLMs to structured knowledge. In this paper, we define a new task of Knowledge-aware Language Model Attribution (KaLMA) that improves upon three core concerns with conventional attributed LMs. First, we extend attribution source from unstructured texts to... | Xinze Li, Yixin Cao, Liangming Pan, Yubo Ma, Aixin Sun |  |
| 1014 |  |  [Benchmarking Cognitive Biases in Large Language Models as Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.29) |  | 0 | Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 16 LLMs encompassing four different size ranges and evaluate their output responses by preference ranking from the other LLMs as evaluators, such as System Star is better than System Square. We then evaluate the quality of ranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLer), a benchmark to... | Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang |  |
| 1015 |  |  [X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions](https://doi.org/10.18653/v1/2024.findings-acl.30) |  | 0 | Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples into these languages can be a solution but unreliable, leading to responses with translation errors and lacking language-specific or cultural knowledge. To address this issue, we propose a novel method to construct cross-lingual instruction following... | Chong Li, Wen Yang, Jiajun Zhang, Jinliang Lu, Shaonan Wang, Chengqing Zong |  |
| 1016 |  |  [Muffin: Mitigating Unhelpfulness in Emotional Support Conversations with Multifaceted AI Feedback](https://doi.org/10.18653/v1/2024.findings-acl.31) |  | 0 |  | Jiashuo Wang, Chunpu Xu, Chak Tou Leong, Wenjie Li, Jing Li |  |
| 1017 |  |  [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.32) |  | 0 | This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce Resonance RoPE, a novel approach designed to narrow the generalization gap in TSTL scenarios by refining the interpolation of RoPE features for OOD positions, significantly improving the model... | Suyuchen Wang, Ivan Kobyzev, Peng Lu, Mehdi Rezagholizadeh, Bang Liu |  |
| 1018 |  |  [MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.33) |  | 0 | Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose MedAgents, a novel multi-disciplinary collaboration framework for the medical domain. MedAgents leverages LLM-based agents in a role-playing setting that participate in a collaborative... | Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, Mark Gerstein |  |
| 1019 |  |  [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.34) |  | 0 | Neural-symbolic methods have demonstrated efficiency in enhancing the reasoning abilities of large language models (LLMs). However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be convertible into programs, which cater to the computer execution mindset and deviate from human reasoning habits. To broaden symbolic methods’ applicability and adaptability in the real world, we... | Yiming Wang, Zhuosheng Zhang, Pei Zhang, Baosong Yang, Rui Wang |  |
| 1020 |  |  [DPDLLM: A Black-box Framework for Detecting Pre-training Data from Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.35) |  | 0 | The success of large language models (LLM) benefits from large-scale model parameters and large amounts of pre-training data. However, the textual data for training LLM can not be confirmed to be legal because they are crawled from different web sites. For example, there are copyrighted articles, personal reviews and information in the pre-training data for LLM which are illegal. To address the above issue and develop legal LLM, we propose to detect the pre-training data from LLM in a pure... | Baohang Zhou, Zezhong Wang, Lingzhi Wang, Hongru Wang, Ying Zhang, Kehui Song, Xuhui Sui, KamFai Wong |  |
| 1021 |  |  [PACIT: Unlocking the Power of Examples for Better In-Context Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.36) |  | 0 | Instruction tuning enhances the instruction following ability of large language models by finetuning with supervised instruction data. Previous work proposes in-context instruction tuning (ICIT) where specific positive or negative examples are incorporated into the prompt for better performance. In this work, we propose PACIT, a simple and effective in-context instruction tuning method, inspired by the pedagogical concept of desirable difficulty. The PACIT method unlocks the power of examples... | Tianci Xue, Ziqi Wang, Yixia Li, Yun Chen, Guanhua Chen |  |
| 1022 |  |  [Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.37) |  | 0 | Recent advances in large language models (LLMs) have promoted generative error correction (GER) for automatic speech recognition (ASR), which aims to predict the ground-truth transcription from the decoded N-best hypotheses. Thanks to the strong language generation ability of LLMs and rich information in the N-best list, GER shows great effectiveness in enhancing ASR results. However, it still suffers from two limitations: 1) LLMs are unaware of the source speech during GER, which may lead to... | Yuchen Hu, Chen Chen, Chengwei Qin, Qiushi Zhu, Engsiong Chng, Ruizhe Li |  |
| 1023 |  |  [Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing](https://doi.org/10.18653/v1/2024.findings-acl.38) |  | 0 | Cross-document Relation Extraction aims to predict the relation between target entities located in different documents. In this regard, the dominant models commonly retain useful information for relation prediction via bridge entities, which allows the model to elaborately capture the intrinsic interdependence between target entities. However, these studies ignore the non-bridge entities, each of which co-occurs with only one target entity and offers the semantic association between target... | Hao Yue, Shaopeng Lai, Chengyi Yang, Liang Zhang, Junfeng Yao, Jinsong Su |  |
| 1024 |  |  [Large Language Models can Share Images, Too!](https://doi.org/10.18653/v1/2024.findings-acl.39) |  | 0 | This paper explores the image-sharing capability of Large Language Models (LLMs), such as GPT-4 and LLaMA 2, in a zero-shot setting. To facilitate a comprehensive evaluation of LLMs, we introduce the photochatplus dataset, which includes enriched annotations (ie intent, triggering sentence, image description, and salient information). Furthermore, we present the gradient-free and extensible Decide, Describe, and Retrieve () framework. With extensive experiments, we unlock the image-sharing... | YoungJun Lee, Dokyong Lee, JooWon Sung, Jonghwan Hyeon, HoJin Choi |  |
| 1025 |  |  [CodeM: Less Data Yields More Versatility via Ability Matrix](https://doi.org/10.18653/v1/2024.findings-acl.40) |  | 0 | In the era of code large language models (code LLMs), data engineering plays a pivotal role during the instruction fine-tuning phase. To train a versatile model, previous efforts devote tremendous efforts into crafting instruction data covering all the downstream scenarios. Nonetheless, this will incur significant expenses in constructing data and training model. Therefore, this paper introduces CodeM, a novel data construction strategy, which can efficiently train a versatile model using less... | Daoguang Zan, Ailun Yu, Wei Liu, Bo Shen, Shaoxin Lin, Yongshun Gong, Yafen Yao, Yan Liu, Bei Guan, Weihua Luo, Yongji Wang, Qianxiang Wang, Lizhen Cui |  |
| 1026 |  |  [Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning](https://doi.org/10.18653/v1/2024.findings-acl.41) |  | 0 | Advances in large vision-language models (LVLMs) have led to significant progress in generating natural language descriptions for visual contents. These powerful models are known for producing texts that are factually inconsistent with the visual input. While some efforts mitigate such inconsistencies in natural image captioning, the factuality of generated captions for structured visuals, such as charts, has not received as much scrutiny. This work introduces a comprehensive typology of... | KungHsiang Huang, Mingyang Zhou, Hou Pong Chan, Yi Fung, Zhenhailong Wang, Lingyu Zhang, ShihFu Chang, Heng Ji |  |
| 1027 |  |  [BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence](https://doi.org/10.18653/v1/2024.findings-acl.42) |  | 0 | Retrieval-augmented large language models (LLMs) have demonstrated efficacy in knowledge-intensive tasks such as open-domain QA, addressing inherent challenges in knowledge update and factual inadequacy.However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs, leading to a decline in LLM’s answer quality. This paper introduces BIDER, an approach that refines retrieval documents into Key Supporting Evidence (KSE) through knowledge synthesis, supervised... | Jiajie Jin, Yutao Zhu, Yujia Zhou, Zhicheng Dou |  |
| 1028 |  |  [Beyond Literal Descriptions: Understanding and Locating Open-World Objects Aligned with Human Intentions](https://doi.org/10.18653/v1/2024.findings-acl.43) |  | 0 | Visual grounding (VG) aims at locating the foreground entities that match the given natural language expression. Previous datasets and methods for classic VG task mainly rely on the prior assumption that the given expression must literally refer to the target object, which greatly impedes the practical deployment of agents in real-world scenarios. Since users usually prefer to provide the intention-based expressions for the desired object instead of covering all the details, it is necessary for... | Wenxuan Wang, Yisi Zhang, Xingjian He, Yichen Yan, Zijia Zhao, Xinlong Wang, Jing Liu |  |
| 1029 |  |  [Incremental Sequence Labeling: A Tale of Two Shifts](https://doi.org/10.18653/v1/2024.findings-acl.44) |  | 0 | The incremental sequence labeling task involves continuously learning new classes over time while retaining knowledge of the previous ones. Our investigation identifies two significant semantic shifts: E2O (where the model mislabels an old entity as a non-entity) and O2E (where the model labels a non-entity or old entity as a new entity). Previous research has predominantly focused on addressing the E2O problem, neglecting the O2E issue. This negligence results in a model bias towards... | Shengjie Qiu, Junhao Zheng, Zhen Liu, Yicheng Luo, Qianli Ma |  |
| 1030 |  |  [How Proficient Are Large Language Models in Formal Languages? An In-Depth Insight for Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.45) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions based on facts in knowledge bases. A typical approach to KBQA is semantic parsing, which translates a question into an executable logical form in a formal language. Recent works leverage the capabilities of large language models (LLMs) for logical form generation to improve performance. However, although it is validated that LLMs are capable of solving some KBQA problems, there has been little discussion on the... | Jinxin Liu, Shulin Cao, Jiaxin Shi, Tingjian Zhang, Lunyiu Nie, Linmei Hu, Lei Hou, Juanzi Li |  |
| 1031 |  |  [MELOV: Multimodal Entity Linking with Optimized Visual Features in Latent Space](https://doi.org/10.18653/v1/2024.findings-acl.46) |  | 0 | Multimodal entity linking (MEL), which aligns ambiguous mentions within multimodal contexts to referent entities from multimodal knowledge bases, is essential for many natural language processing applications. Previous MEL methods mainly focus on exploring complex multimodal interaction mechanisms to better capture coherence evidence between mentions and entities by mining complementary information. However, in real-world social media scenarios, vision modality often exhibits low quality, low... | Xuhui Sui, Ying Zhang, Yu Zhao, Kehui Song, Baohang Zhou, Xiaojie Yuan |  |
| 1032 |  |  [Unsupervised Distractor Generation via Large Language Model Distilling and Counterfactual Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.47) |  | 0 | Within the context of reading comprehension, the task of Distractor Generation (DG) aims to generate several incorrect options to confuse readers. In recent years, the emergence of Large Language Models (LLMs) provides a potential for unsupervised DG without expensive human-annotated distractor labels. In this paper, we leverage LLMs as a cost-effective annotator to enhance the DG capability of smaller student models. To perform knowledge distilling, we propose a dual task training framework... | Fanyi Qu, Hao Sun, Yunfang Wu |  |
| 1033 |  |  [Conversational Question Answering with Language Models Generated Reformulations over Knowledge Graph](https://doi.org/10.18653/v1/2024.findings-acl.48) |  | 0 | Conversational question answering (ConvQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to understand given a conversation history, but hard for a machine to interpret, which can degrade ConvQA performance. To address this problem, we propose a reinforcement learning (RL) based model, CoRnNet,... | Lihui Liu, Blaine Hill, Boxin Du, Fei Wang, Hanghang Tong |  |
| 1034 |  |  [Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step by Step](https://doi.org/10.18653/v1/2024.findings-acl.49) |  | 0 | Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs,... | Li Zhong, Zilong Wang, Jingbo Shang |  |
| 1035 |  |  [Effective In-Context Example Selection through Data Compression](https://doi.org/10.18653/v1/2024.findings-acl.50) |  | 0 | In-context learning has been extensively validated in large language models. However, the mechanism and selection strategy for in-context example selection, which is a crucial ingredient in this approach, lacks systematic and in-depth research. In this paper, we propose a data compression approach to the selection of in-context examples. We introduce a two-stage method that can effectively choose relevant examples and retain sufficient information about the training dataset within the... | Zhongxiang Sun, Kepu Zhang, Haoyu Wang, Xiao Zhang, Jun Xu |  |
| 1036 |  |  [Are U a Joke Master? Pun Generation via Multi-Stage Curriculum Learning towards a Humor LLM](https://doi.org/10.18653/v1/2024.findings-acl.51) |  | 0 | Although large language models (LLMs) acquire extensive world knowledge and some reasoning abilities, their proficiency in generating humorous sentences remains a challenge. Previous research has demonstrated that the humor generation capabilities of ChatGPT are confined to producing merely 25 unique jokes. In this work, we concentrate on endowing LLMs with the ability of generating puns, a particular category of humor by preference learning method. We propose a multi-stage curriculum... | Yang Chen, Chong Yang, Tu Hu, Xinhao Chen, Man Lan, Li Cai, Xinlin Zhuang, Xuan Lin, Xin Lu, Aimin Zhou |  |
| 1037 |  |  [Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.52) |  | 0 | Deploying large language models (LLMs) to real scenarios for domain-specific question answering (QA) is a key thrust for LLM applications, which poses numerous challenges, especially in ensuring that responses are both accommodating to user requirements and appropriately leveraging domain-specific knowledge bases. They are the two major difficulties for LLM application as vanilla fine-tuning falls short of addressing. Combining these requirements, we conceive of them as the requirement for the... | Yichi Zhang, Zhuo Chen, Yin Fang, Yanxi Lu, Fangming Li, Wen Zhang, Huajun Chen |  |
| 1038 |  |  [MARIO: MAth Reasoning with code Interpreter Output - A Reproducible Pipeline](https://doi.org/10.18653/v1/2024.findings-acl.53) |  | 0 | Large language models (LLMs) have significantly improved in understanding natural language but still lack in mathematical reasoning, a hurdle on the path to true artificial general intelligence. The training of large language models, based on next-token prediction, struggles to capture the precise nature of mathematical reasoning, presenting both practical and theoretical challenges. In this paper, we address this challenge by enriching the data landscape and introducing a reasonable data... | Minpeng Liao, Chengxi Li, Wei Luo, Jing Wu, Kai Fan |  |
| 1039 |  |  [DiffusPoll: Conditional Text Diffusion Model for Poll Generation](https://doi.org/10.18653/v1/2024.findings-acl.54) |  | 0 | Online social media platforms often gather user feedback through polls to enhance user engagement. Automatically generating polls from social media and its context can decrease the labor expenses of media workers and enhance workplace productivity. However, on social media platforms, there are internet water armies that manipulate public opinion through sheer numbers and causing the comments to be biased, drowning out minority views. In such circumstances, polls created based on biased comments... | Le Cheng, Shuangyin Li |  |
| 1040 |  |  [Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.55) |  | 0 | While large language models (LLMs) have shown excellent capabilities in language understanding, text generation and many other tasks, they still struggle in complex multi-step reasoning problems such as mathematical reasoning. In this paper, through a newly proposed arithmetical puzzle problem, we show that the model can perform well on multi-step reasoning tasks via fine tuning on high-quality synthetic data. Experiments with the open-llama-3B model on three different test datasets show that... | Haolong Li, Yu Ma, Yinqi Zhang, Chen Ye, Jie Chen |  |
| 1041 |  |  [Implanting LLM's Knowledge via Reading Comprehension Tree for Toxicity Detection](https://doi.org/10.18653/v1/2024.findings-acl.56) |  | 0 | Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs despite their large amount of knowledge, it is not a good idea to detect toxicity only with either SLM or LLM based method.In this work, we propose to implant LLM’s knowledge into SLM based methods... | Hankun Kang, Tieyun Qian |  |
| 1042 |  |  [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://doi.org/10.18653/v1/2024.findings-acl.57) |  | 0 | This paper focuses on task-agnostic prompt compression for better generalizability and efficiency. Considering the redundancy in natural language, existing approaches compress prompts by removing tokens or lexical units according to their information entropy obtained from a causal language model such as LLaMa-7B. The challenge is that information entropy may be a suboptimal compression metric: (i) it only leverages unidirectional context and may fail to capture all essential information needed... | Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rühle, Yuqing Yang, ChinYew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang |  |
| 1043 |  |  [EconNLI: Evaluating Large Language Models on Economics Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.58) |  | 0 | Large Language Models (LLMs) are widely used for writing economic analysis reports or providing financial advice, but their ability to understand economic knowledge and reason about potential results of specific economic events lacks systematic evaluation. To address this gap, we propose a new dataset, natural language inference on economic events (EconNLI), to evaluate LLMs’ knowledge and reasoning abilities in the economic domain. We evaluate LLMs on (1) their ability to correctly classify... | Yue Guo, Yi Yang |  |
| 1044 |  |  [Better Late Than Never: Model-Agnostic Hallucination Post-Processing Framework Towards Clinical Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.59) |  | 0 | Clinical text summarization has proven successful in generating concise and coherent summaries. However, these summaries may include unintended text with hallucinations, which can mislead clinicians and patients. Existing methods for mitigating hallucinations can be categorized into task-specific and task-agnostic approaches. Task-specific methods lack versatility for real-world applicability. Meanwhile, task-agnostic methods are not model-agnostic, so they require retraining for different... | Songda Li, Yunqi Zhang, Chunyuan Deng, Yake Niu, Hui Zhao |  |
| 1045 |  |  [Finding and Editing Multi-Modal Neurons in Pre-Trained Transformers](https://doi.org/10.18653/v1/2024.findings-acl.60) |  | 0 | Understanding the internal mechanisms by which multi-modal large language models (LLMs) interpret different modalities and integrate cross-modal representations is becoming increasingly critical for continuous improvements in both academia and industry. In this paper, we propose a novel method to identify key neurons for interpretability — how multi-modal LLMs bridge visual and textual concepts for captioning. Our method improves conventional works upon efficiency and applied range by removing... | Haowen Pan, Yixin Cao, Xiaozhi Wang, Xun Yang, Meng Wang |  |
| 1046 |  |  [Realistic Evaluation of Toxicity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.61) |  | 0 | Large language models (LLMs) have become integral to our professional workflows and daily lives. Nevertheless, these machine companions of ours have a critical flaw: the huge amount of data which endows them with vast and diverse knowledge, also exposes them to the inevitable toxicity and bias. While most LLMs incorporate defense mechanisms to prevent the generation of harmful content, these safeguards can be easily bypassed with minimal prompt engineering. In this paper, we introduce the new... | Tinh Son Luong, ThanhThien Le, Linh Ngo Van, Thien Huu Nguyen |  |
| 1047 |  |  [Controllable Text Generation with Residual Memory Transformer](https://doi.org/10.18653/v1/2024.findings-acl.62) |  | 0 | Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have brought great success in text generation. However, it is still an open challenge to effectively control the generation process of a CLM while balancing the flexibility, control granularity, and generation efficiency. In this paper, we provide a new alternative for controllable text generation (CTG), by designing a non-intrusive, lightweight control plugin, namely Residual Memory Transformer (RMT), to accompany the... | Hanqing Zhang, Si Sun, Haiming Wu, Dawei Song |  |
| 1048 |  |  [Prompt-Based Length Controlled Generation with Multiple Control Types](https://doi.org/10.18653/v1/2024.findings-acl.63) |  | 0 | Large language models (LLMs) have attracted great attention given their strong performance on a wide range of NLP tasks. In practice, users often expect generated texts to fall within a specific length range, making length controlled generation an important topic, especially for GPT-style models. Existing length control methods mostly focus on a simple control type of “equal to” a target length. Different from them, we propose a prompt-based method to achieve length controlled generation under... | Renlong Jie, Xiaojun Meng, Lifeng Shang, Xin Jiang, Qun Liu |  |
| 1049 |  |  [PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain](https://doi.org/10.18653/v1/2024.findings-acl.64) |  | 0 | We present PCA-Bench, a multimodal decision-making benchmark for evaluating the integrated capabilities of Multimodal Large Language Models (MLLMs). Departing from previous benchmarks focusing on simplistic tasks and individual model capability, PCA-Bench introduces three complex scenarios: autonomous driving, domestic robotics, and open-world games. Given task instructions and diverse contexts, the model is required to seamlessly integrate multiple capabilities of Perception, Cognition, and... | Liang Chen, Yichi Zhang, Shuhuai Ren, Haozhe Zhao, Zefan Cai, Yuchi Wang, Peiyi Wang, Xiangdi Meng, Tianyu Liu, Baobao Chang |  |
| 1050 |  |  [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.65) |  | 0 | Conversational recommender systems are an emerging area that has garnered increasing interest in the community, especially with the advancements in large language models (LLMs) that enable sophisticated handling of conversational input. Despite the progress, the field still has many aspects left to explore. The currently available public datasets for conversational recommendation lack specific user preferences and explanations for recommendations, hindering high-quality recommendations. To... | Minjin Kim, Minju Kim, Hana Kim, Beongwoo Kwak, SeongKu Kang, Youngjae Yu, Jinyoung Yeo, Dongha Lee |  |
| 1051 |  |  [CoLLaVO: Crayon Large Language and Vision mOdel](https://doi.org/10.18653/v1/2024.findings-acl.66) |  | 0 | The remarkable success of Large Language Models (LLMs) and instruction tuning drives the evolution of Vision Language Models (VLMs) towards a versatile general-purpose model. Yet, it remains unexplored whether current VLMs genuinely possess quality object-level image understanding capabilities determined from ‘what objects are in the image?’ or ‘which object corresponds to a specified bounding box?’. Our findings reveal that the image understanding capabilities of current VLMs are strongly... | ByungKwan Lee, Beomchan Park, Chae Won Kim, Yong Man Ro |  |
| 1052 |  |  [Modelling Variability in Human Annotator Simulation](https://doi.org/10.18653/v1/2024.findings-acl.67) |  | 0 | Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation tasks such as data annotation and system assessment. It is important to incorporate the variability present in human evaluation into HAS, since it helps capture diverse subjective interpretations and mitigate potential biases and over-representation. This work introduces a novel framework for modelling variability in HAS. Conditional softmax flow (S-CNF) is proposed to model the distribution of... | Wen Wu, Wenlin Chen, Chao Zhang, Philip C. Woodland |  |
| 1053 |  |  [BEnQA: A Question Answering Benchmark for Bengali and English](https://doi.org/10.18653/v1/2024.findings-acl.68) |  | 0 | In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with different types of questions, including factual, application, and reasoning-based questions. We benchmark several Large Language Models (LLMs) with our parallel dataset and observe a notable performance disparity between the models in Bengali and English.... | Sheikh Shafayat, H. M. Quamran Hasan, Minhajur Rahman Chowdhury Mahim, Rifki Afina Putri, James Thorne, Alice Oh |  |
| 1054 |  |  [MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.69) |  | 0 |  | Wanqing Cui, Keping Bi, Jiafeng Guo, Xueqi Cheng |  |
| 1055 |  |  [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.70) |  | 0 | Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within LMs. In this paper, we aim to interpret the mechanism of knowledge conflicts through the lens of information flow, and then mitigate conflicts by precise interventions at the pivotal point. We find there... | Zhuoran Jin, Pengfei Cao, Hongbang Yuan, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao |  |
| 1056 |  |  [BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning](https://doi.org/10.18653/v1/2024.findings-acl.71) |  | 0 | Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding of molecular structures, particularly in their textual representations (e.g., IUPAC). This paper introduces BioT5+, an extension of the BioT5 framework, tailored to enhance biological research and drug... | Qizhi Pei, Lijun Wu, Kaiyuan Gao, Xiaozhuan Liang, Yin Fang, Jinhua Zhu, Shufang Xie, Tao Qin, Rui Yan |  |
| 1057 |  |  [SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.72) |  | 0 | Fine-tuning all parameters of large language models (LLMs) necessitates substantial computational power and extended time. Latest advancements in parameter-efficient fine-tuning (PEFT) techniques, such as Adapter tuning and LoRA, allow for adjustments to only a minor fraction of the parameters of these LLMs. Concurrently, it has been noted that the issue of over-smoothing diminishes the effectiveness of these Transformer-based LLMs, resulting in suboptimal performances in downstream tasks. In... | Zhihao Wen, Jie Zhang, Yuan Fang |  |
| 1058 |  |  [GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving](https://doi.org/10.18653/v1/2024.findings-acl.73) |  | 0 | Recent advancements in large language models (LLMs) and multi-modal models (MMs) have demonstrated their remarkable capabilities in problem-solving. Yet, their proficiency in tackling geometry math problems, which necessitates an integrated understanding of both textual and visual information, has not been thoroughly evaluated. To address this gap, we introduce the GeoEval benchmark, a comprehensive collection that includes a main subset of 2,000 problems, a 750 problems subset focusing on... | Jiaxin Zhang, Zhongzhi Li, MingLiang Zhang, Fei Yin, ChengLin Liu, Yashar Moshfeghi |  |
| 1059 |  |  [Boosting Textural NER with Synthetic Image and Instructive Alignment](https://doi.org/10.18653/v1/2024.findings-acl.74) |  | 0 | Named entity recognition (NER) is a pivotal task reliant on textual data, often impeding the disambiguation of entities due to the absence of context. To tackle this challenge, conventional methods often incorporate images crawled from the internet as auxiliary information. However, the images often lack sufficient entities or would introduce noise. Even with high-quality images, it is still challenging to efficiently use images as auxiliaries (i.e., fine-grained alignment with texts). We... | Jiahao Wang, Wenjun Ke, Peng Wang, Hang Zhang, Dong Nie, Jiajun Liu, Guozheng Li, Ziyu Shang |  |
| 1060 |  |  [Neurons in Large Language Models: Dead, N-gram, Positional](https://doi.org/10.18653/v1/2024.findings-acl.75) |  | 0 | We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than in some layers of the 66b model) are “dead”, i.e. they never activate on a large collection of diverse data. At the... | Elena Voita, Javier Ferrando, Christoforos Nalmpantis |  |
| 1061 |  |  [LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.76) |  | 0 | Grounded Multimodal Named Entity Recognition (GMNER) is a nascent multimodal task that aims to identify named entities, entity types and their corresponding visual regions. GMNER task exhibits two challenging properties: 1) The weak correlation between image-text pairs in social media results in a significant portion of named entities being ungroundable. 2) There exists a distinction between coarse-grained referring expressions commonly used in similar tasks (e.g., phrase localization,... | Jinyuan Li, Han Li, Di Sun, Jiahao Wang, Wenkun Zhang, Zan Wang, Gang Pan |  |
| 1062 |  |  [Learning Job Title Representation from Job Description Aggregation Network](https://doi.org/10.18653/v1/2024.findings-acl.77) |  | 0 | Learning job title representation is a vital process for developing automatic human resource tools. To do so, existing methods primarily rely on learning the title representation through skills extracted from the job description, neglecting the rich and diverse content within. Thus, we propose an alternative framework for learning job titles through their respective job description (JD) and utilize a Job Description Aggregator component to handle the lengthy description and bidirectional... | Napat Laosaengpha, Thanit Tativannarat, Chawan Piansaddhayanon, Attapol Rutherford, Ekapol Chuangsuwanich |  |
| 1063 |  |  [FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts](https://doi.org/10.18653/v1/2024.findings-acl.78) |  | 0 | Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of visual question-answering multimodal language models in reasoning with flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and human-verified flowchart images from three distinct content sources, along with 22,413 diverse question-answer pairs, to test... | Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth |  |
| 1064 |  |  [Flexible Weight Tuning and Weight Fusion Strategies for Continual Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.79) |  | 0 | Continual Named Entity Recognition (CNER) is dedicated to sequentially learning new entity types while mitigating catastrophic forgetting of old entity types. Traditional CNER approaches commonly employ knowledge distillation to retain old knowledge within the current model. However, because only the representations of old and new models are constrained to be consistent, the reliance solely on distillation in existing methods still suffers from catastrophic forgetting. To further alleviate the... | Yahan Yu, Duzhen Zhang, Xiuyi Chen, Chenhui Chu |  |
| 1065 |  |  [Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.80) |  | 0 | The automatic evaluation of natural language generation (NLG) systems presents a long-lasting challenge. Recent studies have highlighted various neural metrics that align well with human evaluations. Yet, the robustness of these evaluators against adversarial perturbations remains largely under-explored due to the unique challenges in obtaining adversarial data for different NLG evaluation tasks. To address the problem, we introduce AdvEval, a novel black-box adversarial framework against NLG... | Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li |  |
| 1066 |  |  [Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.81) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities and versatility in NLP tasks, however they sometimes fail to maintain crucial invariances for specific tasks. One example is permutation sensitivity, where LLMs’ outputs may significantly vary depending on the order of the input options. While debiasing techniques can mitigate these issues, and yield better performance and reliability, they often come with a high computational cost at inference. This paper... | Adian Liusie, Yassir Fathullah, Mark J. F. Gales |  |
| 1067 |  |  [Uncovering Limitations of Large Language Models in Information Seeking from Tables](https://doi.org/10.18653/v1/2024.findings-acl.82) |  | 0 | Tables are recognized for their high information density and widespread usage, serving as essential sources of information. Seeking information from tables (TIS) is a crucial capability for Large Language Models (LLMs), serving as the foundation of knowledge-based Q&A systems. However, this field presently suffers from an absence of thorough and reliable evaluation. This paper introduces a more reliable benchmark for Table Information Seeking (TabIS). To avoid the unreliable evaluation caused... | Chaoxu Pang, Yixuan Cao, Chunhao Yang, Ping Luo |  |
| 1068 |  |  [An Ensemble-of-Experts Framework for Rehearsal-free Continual Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.83) |  | 0 | Continual relation extraction (CRE) aims to continuously learn relations in new tasks without forgetting old relations in previous tasks.Current CRE methods are all rehearsal-based which need to store samples and thus may encounter privacy and security issues.This paper targets rehearsal-free continual relation extraction for the first time and decomposes it into task identification and within-task prediction sub-problems. Existing rehearsal-free methods focus on training a model (expert) for... | Shen Zhou, Yongqi Li, Xin Miao, Tieyun Qian |  |
| 1069 |  |  [Temporal Validity Change Prediction](https://doi.org/10.18653/v1/2024.findings-acl.84) |  | 0 | Temporal validity is an important property of text that has many downstream applications, such as recommender systems, conversational AI, and user status tracking. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, many data sources contain additional context, such as successive sentences in a story or posts on a social media profile. This context may alter the duration for which the originally collected statement is... | Georg Wenzel, Adam Jatowt |  |
| 1070 |  |  [RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.85) |  | 0 | Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter-efficient fine-tuning methods that optimize input prompts or adjust a small number of model parameters (e.g LoRA). In this study, we explore the impact of altering the input text of the original task in conjunction with parameter-efficient fine-tuning methods. To most effectively rewrite the input text, we train a few-shot paraphrase model... | Saeed Najafi, Alona Fyshe |  |
| 1071 |  |  [Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.86) |  | 0 | Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e. sets of concepts which share some property of interest. Such commonalities are the basis for inductive generalisation, hence high-quality concept embeddings can make learning easier and more robust. Unfortunately, standard embeddings... | Hanane Kteich, Na Li, Usashi Chatterjee, Zied Bouraoui, Steven Schockaert |  |
| 1072 |  |  [Revisiting Multimodal Transformers for Tabular Data with Text Fields](https://doi.org/10.18653/v1/2024.findings-acl.87) |  | 0 | Tabular data with text fields can be leveraged in applications such as financial risk assessment or medical diagnosis prediction. When employing multimodal approaches to make predictions based on these modalities, it is crucial to make the most appropriate modeling choices in terms of numerical feature encoding or fusion strategy. In this paper, we focus on multimodal classification tasks based on tabular datasets with text fields. We build on multimodal Transformers to propose the Tabular-Text... | Thomas Bonnier |  |
| 1073 |  |  [An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla](https://doi.org/10.18653/v1/2024.findings-acl.88) |  | 0 | Pretrained language models inherently exhibit various social biases, prompting a crucial examination of their social impact across various linguistic contexts due to their widespread usage. Previous studies have provided numerous methods for intrinsic bias measurements, predominantly focused on high-resource languages. In this work, we aim to extend these investigations to Bangla, a low-resource language. Specifically, in this study, we (1) create a dataset for intrinsic gender bias measurement... | Jayanta Sadhu, Ayan Antik Khan, Abhik Bhattacharjee, Rifat Shahriyar |  |
| 1074 |  |  [ConTempo: A Unified Temporally Contrastive Framework for Temporal Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.89) |  | 0 | The task of temporal relation extraction (TRE) involves identifying and extracting temporal relations between events from narratives. We identify two primary issues with TRE systems. First, by formulating TRE as a simple text classification task where every temporal relation is independent, it is hard to enhance the TRE model’s representation of meaning of temporal relations, and its facility with the underlying temporal calculus. We solve the issue by proposing a novel Temporally Contrastive... | Jingcheng Niu, Saifei Liao, Victoria Ng, Simon de Montigny, Gerald Penn |  |
| 1075 |  |  [CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.90) |  | 0 | In this work, we dive deep into one of the popular knowledge-grounded dialogue benchmarks that focus on faithfulness, FaithDial. We show that a significant portion of the FaithDial data contains annotation artifacts, which may bias models towards completely ignoring the conversation history. We therefore introduce CHARP, a testbed, designed for evaluating supposedly non-hallucinatory models trained on the FaithDial dataset. Our extensive analysis reveals that models primarily exhibit poor... | Abbas Ghaddar, David AlfonsoHermelo, Philippe Langlais, Mehdi Rezagholizadeh, Boxing Chen, Prasanna Parthasarathi |  |
| 1076 |  |  [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.91) |  | 0 | The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs’ abilities to critique and rectify their reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses... | Zicheng Lin, Zhibin Gou, Tian Liang, Ruilin Luo, Haowei Liu, Yujiu Yang |  |
| 1077 |  |  [DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.92) |  | 0 | Recently, while large language models (LLMs) have demonstrated impressive results, they still suffer from hallucination, i.e., the generation of false information. Model editing is the task of fixing factual mistakes in LLMs; yet, most previous works treat it as a one-time task, paying little attention to ever-emerging mistakes generated by LLMs. We address the task of sequential model editing (SME) that aims to rectify mistakes continuously. A Dynamic Auxiliary Fusion Network (DAFNet) is... | Taolin Zhang, Qizhou Chen, Dongyang Li, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue', Jun Huang |  |
| 1078 |  |  [Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.93) |  | 0 | Generic text summarization approaches often fail to address the specific intent and needs of individual users. Recently, scholarly attention has turned to the development of summarization methods that are more closely tailored and controlled to align with specific objectives and user needs. Despite a growing corpus of controllable summarization research, there is no comprehensive survey available that thoroughly explores the diverse controllable attributes employed in this context, delves into... | Ashok Urlana, Pruthwik Mishra, Tathagato Roy, Rahul Mishra |  |
| 1079 |  |  [Benchmarking Large Language Models on Communicative Medical Coaching: A Dataset and a Novel System](https://doi.org/10.18653/v1/2024.findings-acl.94) |  | 0 | Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce “ChatCoach”, a human-AI cooperative framework designed to assist medical learners in practicing their... | Hengguan Huang, Songtao Wang, Hongfu Liu, Hao Wang, Ye Wang |  |
| 1080 |  |  [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://doi.org/10.18653/v1/2024.findings-acl.95) |  | 0 | This paper introduce a novel thought prompting approach called ”Everything of Thoughts” (XoT) for Large Language Models (LLMs) to defy the law of ”Penrose triangle” of existing thought paradigms, to achieve three key perspectives in thought generation simultaneously: performance, efficiency, and flexibility. XoT leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge and planning capability into thoughts, thereby enhancing LLMs’... | Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang |  |
| 1081 |  |  [SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources with Retrieval and Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.96) |  | 0 | We introduce SPAGHETTI: Semantic Parsing Augmented Generation for Hybrid English information from Text Tables and Infoboxes, a hybrid question-answering (QA) pipeline that utilizes information from heterogeneous knowledge sources, including knowledge base, text, tables, and infoboxes. Our LLM-augmented approach achieves state-of-the-art performance on the Compmix dataset, the most comprehensive heterogeneous open-domain QA dataset, with 56.5% exact match (EM) rate. More importantly, manual... | Heidi C. Zhang, Sina J. Semnani, Farhad Ghassemi, Jialiang Xu, Shicheng Liu, Monica S. Lam |  |
| 1082 |  |  [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.97) |  | 0 | In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of LLMs on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From both data and learning perspectives, we examine various... | Bosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze Luo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie Hu, Anh Tuan Luu, Shafiq Joty |  |
| 1083 |  |  [k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text](https://doi.org/10.18653/v1/2024.findings-acl.98) |  | 0 | Recent watermarked generation algorithms inject detectable signatures during language generation to facilitate post-hoc detection. While token-level watermarks are vulnerable to paraphrase attacks, SemStamp (Hou et al., 2023) applies watermark on the semantic representation of sentences and demonstrates promising robustness. SemStamp employs locality-sensitive hashing (LSH) to partition the semantic space with arbitrary hyperplanes, which results in a suboptimal tradeoff between robustness and... | Abe Bohan Hou, Jingyu Zhang, Yichen Wang, Daniel Khashabi, Tianxing He |  |
| 1084 |  |  [ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.99) |  | 0 | This paper introduces the ColorSwap dataset, designed to assess and improve the proficiency of multimodal models in matching objects with their colors. The dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000 examples. Each example includes a caption-image pair, along with a “color-swapped” pair. We follow the Winoground schema: the two captions in an example have the same words, but the color words have been rearranged to modify different objects. The dataset was... | Jirayu Burapacheep, Ishan Gaur, Agam Bhatia, Tristan Thrush |  |
| 1085 |  |  [Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers](https://doi.org/10.18653/v1/2024.findings-acl.100) |  | 0 | Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows... | Tuo Zhang, Jinyue Yuan, Salman Avestimehr |  |
| 1086 |  |  [CeeBERT: Cross-Domain Inference in Early Exit BERT](https://doi.org/10.18653/v1/2024.findings-acl.101) |  | 0 | Pre-trained Language Models (PLMs), like BERT, with self-supervision objectives exhibit remarkable performance and generalization across various tasks. However, they suffer in inference latency due to their large size. To address this issue, side branches are attached at intermediate layers, enabling early inference of samples without requiring them to pass through all layers. However, the challenge is to decide which layer to infer and exit each sample so that the accuracy and latency are... | Divya Jyoti Bajpai, Manjesh K. Hanawal |  |
| 1087 |  |  [UNIWIZ: A Unified Large Language Model Orchestrated Wizard for Safe Knowledge Grounded Conversations](https://doi.org/10.18653/v1/2024.findings-acl.102) |  | 0 | Large Language Models (LLMs) have made significant progress in integrating safety and knowledge alignment. However, adversarial actors can manipulate these models into generating unsafe responses, and excessive safety alignment can lead to unintended hallucinations. To address these challenges, we introduce UniWiz, a novel 2-step data orchestration framework that unifies safety and knowledge data generation. We propose a “safety-priming” method to generate synthetic safety data and overcome... | Souvik Das, Rohini K. Srihari |  |
| 1088 |  |  [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://doi.org/10.18653/v1/2024.findings-acl.103) |  | 0 | We show that content on the web is often translated into many languages, and the low quality of these multi-way translations indicates they were likely created using Machine Translation (MT). Multi-way parallel, machine generated content not only dominates the translations in lower resource languages; it also constitutes a large fraction of the total web content in those languages. We also find evidence of a selection bias in the type of content which is translated into many languages,... | Brian Thompson, Mehak Preet Dhaliwal, Peter Frisch, Tobias Domhan, Marcello Federico |  |
| 1089 |  |  [RankMean: Module-Level Importance Score for Merging Fine-tuned LLM Models](https://doi.org/10.18653/v1/2024.findings-acl.104) |  | 0 | Traditionally, developing new language models (LMs) capable of addressing multiple tasks involves fine-tuning pre-trained LMs using a wide collection of datasets, a process that often incurs significant computational expenses. Model merging emerges as a cost-effective alternative, allowing the integration of existing models fine-tuned on different tasks into a single model that performs well across all tasks, eliminating the need for additional training. In this paper, we propose RankMean, an... | Gabriel J. Perin, Xuxi Chen, Shusen Liu, Bhavya Kailkhura, Zhangyang Wang, Brian Gallagher |  |
| 1090 |  |  [VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.105) |  | 0 | Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability. A comprehensive quantitative evaluation is necessary to identify and understand the extent of hallucinations in these models. However, existing benchmarks are often limited in scope, focusing mainly on object hallucinations. Furthermore, current evaluation methods struggle to effectively address the subtle semantic... | Haoyi Qiu, Wenbo Hu, ZiYi Dou, Nanyun Peng |  |
| 1091 |  |  [Cyclical Contrastive Learning Based on Geodesic for Zero-shot Cross-lingual Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.106) |  | 0 | Owing to the scarcity of labeled training data, Spoken Language Understanding (SLU) is still a challenging task in low-resource languages. Therefore, zero-shot cross-lingual SLU attracts more and more attention. Contrastive learning is widely applied to explicitly align representations of similar sentences across different languages. However, the vanilla contrastive learning method may face two problems in zero-shot cross-lingual SLU: (1) the consistency between different languages is... | Xuxin Cheng, Zhihong Zhu, Bang Yang, Xianwei Zhuang, Hongxiang Li, Yuexian Zou |  |
| 1092 |  |  [Towards Safer Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.107) |  | 0 | The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with problematic prompts. To address this problem, existing work attempted to implement a gradient ascent based approach to prevent LLMs from producing harmful output. While these methods can be effective, they... | Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang |  |
| 1093 |  |  [The Impact of Reasoning Step Length on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.108) |  | 0 | Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We... | Mingyu Jin, Qinkai Yu, Dong Shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du |  |
| 1094 |  |  [Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness](https://doi.org/10.18653/v1/2024.findings-acl.109) |  | 0 | While task-agnostic debiasing provides notable generalizability and reduced reliance on downstream data, its impact on language modeling ability and the risk of relearning social biases from downstream task-specific data remain as the two most significant challenges when debiasing Pretrained Language Models (PLMs). The impact on language modeling ability can be alleviated given a high-quality and long-contextualized debiasing corpus, but there remains a deficiency in understanding the specifics... | Guangliang Liu, Milad Afshari, Xitong Zhang, Zhiyu Xue, Avrajit Ghosh, Bidhan Bashyal, Rongrong Wang, Kristen Marie Johnson |  |
| 1095 |  |  [SKGSum: Structured Knowledge-Guided Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.110) |  | 0 | A summary structure is inherent to certain types of texts according to the Genre Theory of Linguistics. Such structures aid readers in efficiently locating information within summaries. However, most existing automatic summarization methods overlook the importance of summary structure, resulting in summaries that emphasize the most prominent information while omitting essential details from other sections. While a few summarizers recognize the importance of summary structure, they rely heavily... | Qiqi Wang, Ruofan Wang, Kaiqi Zhao, Robert Amor, Benjamin Liu, Jiamou Liu, Xianda Zheng, Zijian Huang |  |
| 1096 |  |  [Chinese Spoken Named Entity Recognition in Real-world Scenarios: Dataset and Approaches](https://doi.org/10.18653/v1/2024.findings-acl.111) |  | 0 | Spoken Named Entity Recognition (NER) aims to extract entities from speech. The extracted entities can help voice assistants better understand user’s questions and instructions. However, current Chinese Spoken NER datasets are laboratory-controlled data that are collected by reading existing texts in quiet environments, rather than natural spoken data, and the texts used for reading are also limited in topics. These limitations obstruct the development of Spoken NER in more natural and common... | Shilin Zhou, Zhenghua Li, Chen Gong, Lei Zhang, Yu Hong, Min Zhang |  |
| 1097 |  |  [DEBATE: Devil's Advocate-Based Assessment and Text Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.112) |  | 0 | As natural language generation (NLG) models have become prevalent, systematically assessing the quality of machine-generated texts has become increasingly important. Recent studies introduce LLM-based evaluators that operate as reference-free metrics, demonstrating their capability to adeptly handle novel tasks. However, these models generally rely on a single-agent approach, which, we argue, introduces an inherent limit to their performance. This is because there exist biases in LLM agent’s... | Alex Kim, Keonwoo Kim, Sangwon Yoon |  |
| 1098 |  |  [Can Large Multimodal Models Uncover Deep Semantics Behind Images?](https://doi.org/10.18653/v1/2024.findings-acl.113) |  | 0 | Understanding the deep semantics of images is essential in the era dominated by social media. However, current research works primarily on the superficial description of images, revealing a notable deficiency in the systematic investigation of the inherent deep semantics. In this work, we introduce DEEPEVAL, a comprehensive benchmark to assess Large Multimodal Models’ (LMMs) capacities of visual deep semantics. DEEPEVAL includes human-annotated dataset and three progressive subtasks:... | Yixin Yang, Zheng Li, Qingxiu Dong, Heming Xia, Zhifang Sui |  |
| 1099 |  |  [Harvesting Events from Multiple Sources: Towards a Cross-Document Event Extraction Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.114) |  | 0 | Document-level event extraction aims to extract structured event information from unstructured text. However, a single document often contains limited event information and the roles of different event arguments may be biased due to the influence of the information source.This paper addresses the limitations of traditional document-level event extraction by proposing the task of cross-document event extraction (CDEE) to integrate event information from multiple documents and provide a... | Qiang Gao, Zixiang Meng, Bobo Li, Jun Zhou, Fei Li, Chong Teng, Donghong Ji |  |
| 1100 |  |  [A Graph per Persona: Reasoning about Subjective Natural Language Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.115) |  | 0 | Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the interpretability requirements often needed in these kinds of applications. We propose a novel approach for reasoning about subjective knowledge that integrates potential and implicit meanings and explicitly... | Eunjeong Hwang, Vered Shwartz, Dan Gutfreund, Veronika Thost |  |
| 1101 |  |  [MolTC: Towards Molecular Relational Modeling In Language Models](https://doi.org/10.18653/v1/2024.findings-acl.116) |  | 0 | Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities, has emerged as a promising way for efficient and effective MRL. Despite their potential, these methods predominantly rely on textual data, thus not fully harnessing the wealth of structural information... | Junfeng Fang, Shuai Zhang, Chang Wu, Zhengyi Yang, Zhiyuan Liu, Sihang Li, Kun Wang, Wenjie Du, Xiang Wang |  |
| 1102 |  |  [KPEval: Towards Fine-Grained Semantic-Based Keyphrase Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.117) |  | 0 | Despite the significant advancements in keyphrase extraction and keyphrase generation methods, the predominant approach for evaluation mainly relies on exact matching with human references. This scheme fails to recognize systems that generate keyphrases semantically equivalent to the references or diverse keyphrases that carry practical utility. To better assess the capability of keyphrase systems, we propose KPEval, a comprehensive evaluation framework consisting of four critical aspects:... | Di Wu, Da Yin, KaiWei Chang |  |
| 1103 |  |  [Learning Low-dimensional Multi-domain Knowledge Graph Embedding via Dual Archimedean Spirals](https://doi.org/10.18653/v1/2024.findings-acl.118) |  | 0 | Knowledge graph embedding (KGE) is extensively employed for link prediction by representing entities and relations as low-dimensional vectors. In real-world scenarios, knowledge graphs (KGs) usually encompass diverse domains, which poses challenges to KG representations. However, existing KGE methods rarely make domain constraints on the embedding distribution of multi-domain KGs, leading to the embedding overlapping of different domains and performance degradation of link prediction. To... | Jiang Li, Xiangdong Su, Fujun Zhang, Guanglai Gao |  |
| 1104 |  |  [LoRA Meets Dropout under a Unified Framework](https://doi.org/10.18653/v1/2024.findings-acl.119) |  | 0 | With the remarkable capabilities, large language models (LLMs) have emergedas essential elements in numerous NLP applications, while parameter-efficientfinetuning, especially LoRA, has gained popularity as a lightweight approachfor model customization. Meanwhile, various dropout methods, initially designedfor full finetuning with all the parameters updated, alleviates overfittingassociated with excessive parameter redundancy. Hence, a possible contradictionarises from negligible trainable... | Sheng Wang, Liheng Chen, Jiyue Jiang, Boyang Xue, Lingpeng Kong, Chuan Wu |  |
| 1105 |  |  [Enhancing Text-to-SQL Parsing through Question Rewriting and Execution-Guided Refinement](https://doi.org/10.18653/v1/2024.findings-acl.120) |  | 0 | Large Language Model (LLM)-based approach has become the mainstream for Text-to-SQL task and achieves remarkable performance. In this paper, we augment the existing prompt engineering methods by exploiting the database content and execution feedback. Specifically, we introduce DART-SQL, which comprises two key components: (1) Question Rewriting: DART-SQL rewrites natural language questions by leveraging database content information to eliminate ambiguity. (2) Execution-Guided Refinement:... | Wenxin Mao, Ruiqi Wang, Jiyu Guo, Jichuan Zeng, Cuiyun Gao, Peiyi Han, Chuanyi Liu |  |
| 1106 |  |  [The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.121) |  | 0 | Large language models often necessitate grounding on external knowledge to generate faithful and reliable answers. Yet even with the correct groundings in the reference, they can ignore them and rely on wrong groundings or their inherent biases to hallucinate when users, being largely unaware of the specifics of the stored information, pose questions that might not directly correlate with the retrieved groundings. In this work, we formulate this knowledge alignment problem and introduce... | Shuo Zhang, Liangming Pan, Junzhou Zhao, William Yang Wang |  |
| 1107 |  |  [ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.122) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of retrieval adversely impacting semantic parsing, and the complexity of previous KBQA methods. To tackle these challenges, we introduce ChatKBQA, a novel and simple generate-then-retrieve KBQA framework,... | Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, Anh Tuan Luu |  |
| 1108 |  |  [Achilles-Bench: A Challenging Benchmark for Low-Resource Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.123) |  | 0 | With promising yet saturated results in high-resource settings, low-resource datasets have gradually become crucial benchmarks (e.g., BigBench Hard, superGLUE) for evaluating the learning ability of advanced neural networks. In this work, we find that there exists a set of “hard examples” in low-resource settings that challenge neural networks but are not well evaluated, which causes over-estimated performance. We first give a theoretical analysis on which factors bring the difficulty of... | Yudong Wang, Chang Ma, Qingxiu Dong, Zhifang Sui, Lingpeng Kong, Jingjing Xu |  |
| 1109 |  |  [INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair](https://doi.org/10.18653/v1/2024.findings-acl.124) |  | 0 | This paper introduces INTERVENOR (INTERactiVE chaiN Of Repair), a system designed to emulate the interactive code repair processes observed in humans, encompassing both code diagnosis and code repair. INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair process, functioning as both a Code Learner and a Code Teacher. Specifically, the Code Learner is tasked with adhering to instructions to generate or repair code, while the Code Teacher is responsible for... | Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, Ge Yu |  |
| 1110 |  |  [SocialBench: Sociality Evaluation of Role-Playing Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.125) |  | 0 | Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge and style of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce SocialBench, the first benchmark designed to systematically evaluate the... | Hongzhan Chen, Hehong Chen, Ming Yan, Wenshen Xu, Gao Xing, Weizhou Shen, Xiaojun Quan, Chenliang Li, Ji Zhang, Fei Huang |  |
| 1111 |  |  [From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications](https://doi.org/10.18653/v1/2024.findings-acl.126) |  | 0 | Evaluating large language models (LLMs) is fundamental, particularly in the context of practical applications. Conventional evaluation methods, typically designed primarily for LLM development, yield numerical scores that ignore the user experience. Therefore, our study shifts the focus from model-centered to human-centered evaluation in the context of AI-powered writing assistance applications. Our proposed metric, termed “Revision Distance,” utilizes LLMs to suggest revision edits that mimic... | Yongqiang Ma, Lizhi Qing, Jiawei Liu, Yangyang Kang, Yue Zhang, Wei Lu, Xiaozhong Liu, Qikai Cheng |  |
| 1112 |  |  [Context-Aware Tracking and Dynamic Introduction for Incomplete Utterance Rewriting in Extended Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.findings-acl.127) |  | 0 | Incomplete utterance rewriting (IUR) aims to reconstruct the utterance with omitted information and pronouns to be standalone and complete based on the context. The existing works predominantly focus on simple ellipsis and coreference problems in brief multi-turn dialogues. But in actual scenarios: 1) the context of the dialogues frequently comprises multiple similar candidates for ellipsis and coreference resolution, pouring to confuse. 2) the number of turns tends to be more extensive, while... | Xinnan Guo, Qian Zhu, Qiuhui Shi, Xuan Lin, Liubin Wang, DaqianLi DaqianLi, Yongrui Chen |  |
| 1113 |  |  [EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.128) |  | 0 | Emotional intelligence in large language models (LLMs) is of great importance in Natural Language Processing. However, the previous research mainly focus on basic sentiment analysis tasks, such as emotion recognition, which is not enough to evaluate LLMs’ overall emotional intelligence. Therefore, this paper presents a novel framework named EmotionQueen for evaluating the emotional intelligence of LLMs. The framework includes four distinctive tasks: Key Event Recognition, Mixed Event... | Yuyan Chen, Songzhou Yan, Sijia Liu, Yueze Li, Yanghua Xiao |  |
| 1114 |  |  [Plum: Prompt Learning using Metaheuristics](https://doi.org/10.18653/v1/2024.findings-acl.129) |  | 0 | Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly “general”, i.e.,... | Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang Liu, Kashun Shum, Jipeng Zhang, Renjie Pi, Tong Zhang |  |
| 1115 |  |  [HOTVCOM: Generating Buzzworthy Comments for Videos](https://doi.org/10.18653/v1/2024.findings-acl.130) |  | 0 | In the era of social media video platforms, popular “hot-comments” play a crucial role in attracting user impressions of short-form videos, making them vital for marketing and branding purpose. However, existing research predominantly focuses on generating descriptive comments or “danmaku” in English, offering immediate reactions to specific video moments. Addressing this gap, our study introduces HOTVCOM, the largest Chinese video hot-comment dataset, comprising 94k diverse videos and 137... | Yuyan Chen, Songzhou Yan, Qingpei Guo, Jiyuan Jia, Zhixu Li, Yanghua Xiao |  |
| 1116 |  |  [Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?](https://doi.org/10.18653/v1/2024.findings-acl.131) |  | 0 | The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs’ problem-solving capability such as “Twenty Questions”.However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario.Moreover, the existing... | Yuyan Chen, Yueze Li, Songzhou Yan, Sijia Liu, Jiaqing Liang, Yanghua Xiao |  |
| 1117 |  |  [Distilling Robustness into Natural Language Inference Models with Domain-Targeted Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.132) |  | 0 | Knowledge distillation optimises a smaller student model to behave similarly to a larger teacher model, retaining some of the performance benefits. While this method can improve results on in-distribution examples, it does not necessarily generalise to out-of-distribution (OOD) settings. We investigate two complementary methods for improving the robustness of the resulting student models on OOD domains. The first approach augments the distillation with generated unlabeled examples that match... | Joe Stacey, Marek Rei |  |
| 1118 |  |  [Into the Unknown: Generating Geospatial Descriptions for New Environments](https://doi.org/10.18653/v1/2024.findings-acl.133) |  | 0 | Similar to vision-and-language navigation (VLN) tasks that focus on bridging the gap between vision and language for embodied navigation, the new Rendezvous (RVS) task requires reasoning over allocentric spatial relationships using non-sequential navigation instructions and maps. However, performance substantially drops in new environments with no training data.Using opensource descriptions paired with coordinates (e.g., Wikipedia) provides training data but suffers from limited... | Tzuf PazArgaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge |  |
| 1119 |  |  [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.134) |  | 0 | Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability is assigned to all tokens. We also demonstrate the empirical importance of compression for downstream success of pre-trained language models. We control the compression ability of several BPE... | Omer Goldman, Avi Caciularu, Matan Eyal, Kris Cao, Idan Szpektor, Reut Tsarfaty |  |
| 1120 |  |  [Length-aware Byte Pair Encoding for Mitigating Over-segmentation in Korean Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.135) |  | 0 | Byte Pair Encoding is an effective approach in machine translation across several languages. However, our analysis indicates that BPE is prone to over-segmentation in the morphologically rich language, Korean, which can erode word semantics and lead to semantic confusion during training. This semantic confusion, stemming from over-segmentation, ultimately contributes to a degradation of overall translation quality. To address this issue, we introduce Length-aware Subword Vocabulary Construction... | Jungseob Lee, Hyeonseok Moon, Seungjun Lee, Chanjun Park, Sugyeong Eo, Hyunwoong Ko, Jaehyung Seo, Seungyoon Lee, Heuiseok Lim |  |
| 1121 |  |  [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://doi.org/10.18653/v1/2024.findings-acl.136) |  | 0 | As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages from the pre-training corpus. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only... | Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal |  |
| 1122 |  |  [M3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-acl.137) |  | 0 | In this paper, we introduce a new embedding model called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It provides a uniform support for the semantic retrieval of more than 100 working languages. It can simultaneously accomplish the three common retrieval functionalities: dense retrieval, multi-vector retrieval, and sparse retrieval. Besides, it is also capable of processing inputs of different granularities, spanning... | Jianlyu Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu |  |
| 1123 |  |  [Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback](https://doi.org/10.18653/v1/2024.findings-acl.138) |  | 0 | Large Language Models (LLMs) have shown remarkable progress in automated code generation. Yet, LLM-generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must find ways to allow the model to explore the project-level code context. We present CoCoGen, a new code generation approach that uses compiler feedback to improve the LLM-generated code. CoCoGen first... | Zhangqian Bi, Yao Wan, Zheng Wang, Hongyu Zhang, Batu Guan, Fangxin Lu, Zili Zhang, Yulei Sui, Hai Jin, Xuanhua Shi |  |
| 1124 |  |  [An Element is Worth a Thousand Words: Enhancing Legal Case Retrieval by Incorporating Legal Elements](https://doi.org/10.18653/v1/2024.findings-acl.139) |  | 0 | Legal case retrieval plays an important role in promoting judicial justice and fairness. One of its greatest challenges is that the definition of relevance goes far beyond the common semantic relevance as in ad-hoc retrieval. In this paper, we reveal that the legal elements, which typically comprise key facts in a specialized legal context, can largely improve the relevance matching of legal case retrieval. To facilitate the use of legal elements, we construct a Chinese legal element dataset... | Chenlong Deng, Zhicheng Dou, Yujia Zhou, Peitian Zhang, Kelong Mao |  |
| 1125 |  |  [SoMeLVLM: A Large Vision Language Model for Social Media Processing](https://doi.org/10.18653/v1/2024.findings-acl.140) |  | 0 | The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks simultaneously, but even with carefully designed prompting methods, the general domain models often fall short in aligning with the unique speaking style and context of social media tasks. In this paper, we... | Xinnong Zhang, Haoyu Kuang, Xinyi Mou, Hanjia Lyu, Kun Wu, Siming Chen, Jiebo Luo, Xuanjing Huang, Zhongyu Wei |  |
| 1126 |  |  [KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.141) |  | 0 | The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs against socially acceptable commonsense standards in various scenarios. To address this gap in commonsense reasoning, we present KoCommonGEN v2, a fine-grained benchmark dataset focused on Korean commonsense reasoning. This dataset, enriched with human... | Jaehyung Seo, Jaewook Lee, Chanjun Park, Seongtae Hong, Seungjun Lee, Heuiseok Lim |  |
| 1127 |  |  [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.142) |  | 0 | Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at various levels of the model architecture has found promise in addressing scaling and efficiency issues, there remains a disconnect between how sparsity affects network topology. Inspired by brain neuronal... | Amit Dhurandhar, Tejaswini Pedapati, Ronny Luss, Soham Dan, Aurélie C. Lozano, Payel Das, Georgios Kollias |  |
| 1128 |  |  [Ranking Large Language Models without Ground Truth](https://doi.org/10.18653/v1/2024.findings-acl.143) |  | 0 | Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In this paper, we provide a novel perspective where, given a dataset of prompts (viz. questions, instructions, etc.) and a set of LLMs, we rank them without access to any ground truth or reference... | Amit Dhurandhar, Rahul Nair, Moninder Singh, Elizabeth Daly, Karthikeyan Natesan Ramamurthy |  |
| 1129 |  |  [Integrating Physician Diagnostic Logic into Large Language Models: Preference Learning from Process Feedback](https://doi.org/10.18653/v1/2024.findings-acl.144) |  | 0 | The utilization of large language models for medical dialogue generation has attracted considerable attention due to its potential to enhance response richness and coherence. While previous studies have made strides in optimizing model performance, there is a pressing need to bolster the model’s capacity for diagnostic logic to ensure patient safety. In response to this need, we propose an approach termed preference learning from process feedback (PLPF), which involves integrating the doctor’s... | Chengfeng Dou, Ying Zhang, Zhi Jin, Wenpin Jiao, Haiyan Zhao, Yongqiang Zhao, Zhengwei Tao |  |
| 1130 |  |  [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://doi.org/10.18653/v1/2024.findings-acl.145) |  | 0 | The pre-trained language models are continually fine-tuned to better support downstream applications. However, this operation may result in significant performance degeneration on general tasks beyond the targeted domain. To overcome this problem, we propose LM-Cocktail which enables the fine-tuned model to stay resilient in general perspectives. Our method is conducted in the form of model merging, where the fine-tuned language model is merged with the pre-trained base model or the peer models... | Shitao Xiao, Zheng Liu, Peitian Zhang, Xingrun Xing |  |
| 1131 |  |  [Episodic Memory Retrieval from LLMs: A Neuromorphic Mechanism to Generate Commonsense Counterfactuals for Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.146) |  | 0 | Large language models (LLMs) have achieved satisfactory performance in counterfactual generation. However, confined by the stochastic generation process of LLMs, there often are misalignments between LLMs and humans which hinder LLMs from handling complex tasks like relation extraction. As a result, LLMs may generate commonsense-violated counterfactuals like ‘eggs were produced by a box’. To bridge this gap, we propose to mimick the episodic memory retrieval, the working mechanism of human... | Xin Miao, Yongqi Li, Shen Zhou, Tieyun Qian |  |
| 1132 |  |  [SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages](https://doi.org/10.18653/v1/2024.findings-acl.147) |  | 0 | Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader phenomenon of semantic relatedness. In this paper, we present SemRel, a new semantic relatedness dataset collection annotated by native speakers across 13 languages: Afrikaans, Algerian Arabic, Amharic,... | Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine de Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Indra Winata, Seid Muhie Yimam, Saif M. Mohammad |  |
| 1133 |  |  [Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector](https://doi.org/10.18653/v1/2024.findings-acl.148) |  | 0 | Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models, they are difficult to adapt to decoder-only LLMs. In this paper, we propose an alignment-enhanced corrector for the overcorrection problem that applies to both Seq2Seq models and decoder-only LLMs. Our... | Haihui Yang, Xiaojun Quan |  |
| 1134 |  |  [VISPool: Enhancing Transformer Encoders with Vector Visibility Graph Neural Networks](https://doi.org/10.18653/v1/2024.findings-acl.149) |  | 0 | The emergence of transformers has revolutionized natural language processing (NLP), as evidenced in various NLP tasks. While graph neural networks (GNNs) show recent promise in NLP, they are not standalone replacements for transformers. Rather, recent research explores combining transformers and GNNs. Existing GNN-based approaches rely on static graph construction methods requiring excessive text processing, and most of them are not scalable with the increasing document and word counts. We... | Tuna Alikasifoglu, Arda C. Aras, Aykut Koç |  |
| 1135 |  |  [The Emotion Dynamics of Literary Novels](https://doi.org/10.18653/v1/2024.findings-acl.150) |  | 0 | Stories are rich in the emotions they exhibit in their narratives and evoke in the readers. The emotional journeys of the various characters within a story are central to their appeal. Computational analysis of the emotions of novels, however, has rarely examined the variation in the emotional trajectories of the different characters within them, instead considering the entire novel to represent a single story arc. In this work, we use character dialogue to distinguish between the emotion arcs... | Krishnapriya Vishnubhotla, Adam Hammond, Graeme Hirst, Saif M. Mohammad |  |
| 1136 |  |  [Accurate and Nuanced Open-QA Evaluation Through Textual Entailment](https://doi.org/10.18653/v1/2024.findings-acl.151) |  | 0 | Open-domain question answering (Open-QA) is a common task for evaluating large language models (LLMs). However, current Open-QA evaluations are criticized for the ambiguity in questions and the lack of semantic understanding in evaluators. Complex evaluators, powered by foundation models or LLMs and pertaining to semantic equivalence, still deviate from human judgments by a large margin. We propose to study the entailment relations of answers to identify more informative and more general system... | Peiran Yao, Denilson Barbosa |  |
| 1137 |  |  [Dictionary-Aided Translation for Handling Multi-Word Expressions in Low-Resource Languages](https://doi.org/10.18653/v1/2024.findings-acl.152) |  | 0 | Multi-word expressions (MWEs) present unique challenges in natural language processing (NLP), particularly within the context of translation systems, due to their inherent scarcity, non-compositional nature, and other distinct lexical and morphosyntactic characteristics, issues that are exacerbated in low-resource settings.In this study, we elucidate and attempt to address these challenges by leveraging a substantial corpus of human-annotated Greek MWEs. To address the complexity of translating... | Antonios Dimakis, Stella Markantonatou, Antonios Anastasopoulos |  |
| 1138 |  |  [LANS: A Layout-Aware Neural Solver for Plane Geometry Problem](https://doi.org/10.18653/v1/2024.findings-acl.153) |  | 0 | Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion, and reasoning. Existing neural solvers take GPS as a vision-language task but are short in the representation of geometry diagrams that carry rich and complex layout information. In this paper, we propose a layout-aware neural solver named LANS, integrated with two new modules: multimodal layout-aware pre-trained language module (MLA-PLM) and layout-aware fusion attention... | Zhongzhi Li, MingLiang Zhang, Fei Yin, ChengLin Liu |  |
| 1139 |  |  [Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.154) |  | 0 | We propose Knowledge Crosswords, a geometric knowledge reasoning benchmark consisting of incomplete knowledge networks bounded by structured factual constraints, where LLMs are tasked with inferring the missing facts to meet all constraints. The novel setting of geometric knowledge reasoning necessitates new LM abilities beyond existing atomic/linear multi-hop QA, such as backtracking, verifying facts and constraints, reasoning with uncertainty, and more. Knowledge Crosswords contains 2,101... | Wenxuan Ding, Shangbin Feng, Yuhan Liu, Zhaoxuan Tan, Vidhisha Balachandran, Tianxing He, Yulia Tsvetkov |  |
| 1140 |  |  [DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection](https://doi.org/10.18653/v1/2024.findings-acl.155) |  | 0 | Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could generate news reactions to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could generate... | Herun Wan, Shangbin Feng, Zhaoxuan Tan, Heng Wang, Yulia Tsvetkov, Minnan Luo |  |
| 1141 |  |  [The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts](https://doi.org/10.18653/v1/2024.findings-acl.156) |  | 0 | As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages,we observe that (1) LLMs tend to generate... | Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, Daniel Khashabi |  |
| 1142 |  |  [Self-Specialization: Uncovering Latent Expertise within Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.157) |  | 0 | Recent works have demonstrated the effectiveness of self-alignment in which a large language model is aligned to follow general instructions using instructional data generated from the model itself starting from a handful of human-written seeds. Instead of general alignment, in this work, we focus on self-alignment for expert domain specialization (e.g., biomedicine, finance). As a preliminary, we quantitively show the marginal effect that generic instruction-following training has on... | Junmo Kang, Hongyin Luo, Yada Zhu, Jacob A. Hansen, James R. Glass, David D. Cox, Alan Ritter, Rogério Feris, Leonid Karlinsky |  |
| 1143 |  |  [FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion](https://doi.org/10.18653/v1/2024.findings-acl.158) |  | 0 | Taxonomy Expansion, which relies on modeling concepts and concept relations, can be formulated as a set representation learning task. The generalization of set, fuzzy set, incorporates uncertainty and measures the information within a semantic concept, making it suitable for concept modeling. Existing works usually model sets as vectors or geometric objects such as boxes, which are not closed under set operations. In this work, we propose a sound and efficient formulation of set representation... | Fred Xu, Song Jiang, Zijie Huang, Xiao Luo, Shichang Zhang, Yuanzhou Chen, Yizhou Sun |  |
| 1144 |  |  [Chain of Logic: Rule-Based Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.159) |  | 0 | Rule-based reasoning, a fundamental type of legal reasoning, enables us to draw conclusions by accurately applying a rule to a set of facts. We explore causal language models as rule-based reasoners, specifically with respect to compositional rules - rules consisting of multiple elements which form a complex logical expression. Reasoning about compositional rules is challenging because it requires multiple reasoning steps, and attending to the logical relationships between elements. We... | Sergio Servantez, Joe Barrow, Kristian J. Hammond, Rajiv Jain |  |
| 1145 |  |  [Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations](https://doi.org/10.18653/v1/2024.findings-acl.160) |  | 0 | Long-form generations from large language models (LLMs) contain a mix of factual and non-factual claims, making evaluating factuality difficult.Prior works evaluate the factuality of a long paragraph by decomposing it into multiple facts, verifying those facts independently, and aggregating the results.Such methods assume that combining factual claims forms a factual paragraph.The above assumption can be violated: we show that strong open-source models like Llama-chat can generate paragraphs... | ChengHan Chiang, Hungyi Lee |  |
| 1146 |  |  [Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment](https://doi.org/10.18653/v1/2024.findings-acl.161) |  | 0 | Do LMs infer the semantics of text from co-occurrence patterns in their training data? Merrill et al. (2022) argue that, in theory, sentence co-occurrence probabilities predicted by an optimal LM should reflect the entailment relationship of the constituent sentences, but it is unclear whether probabilities predicted by neural LMs encode entailment in this way because of strong assumptions made by Merrill et al. (namely, that humans always avoid redundancy). In this work, we investigate whether... | William Merrill, Zhaofeng Wu, Norihito Naka, Yoon Kim, Tal Linzen |  |
| 1147 |  |  [Simulated Misinformation Susceptibility (SMISTS): Enhancing Misinformation Research with Large Language Model Simulations](https://doi.org/10.18653/v1/2024.findings-acl.162) |  | 0 | Psychological inoculation, a strategy designed to build resistance against persuasive misinformation, has shown efficacy in curbing its spread and mitigating its adverse effects at early stages. Despite its effectiveness, the design and optimization of these inoculations typically demand substantial human and financial resources, primarily due to the need for repeated experimental trials. To address these challenges, this paper introduces Simulated Misinformation Susceptibility Tests (SMISTs),... | Weicheng Ma, Chunyuan Deng, Aram Moossavi, Lili Wang, Soroush Vosoughi, Diyi Yang |  |
| 1148 |  |  [Social Intelligence Data Infrastructure: Structuring the Present and Navigating the Future](https://doi.org/10.18653/v1/2024.findings-acl.163) |  | 0 | As Natural Language Processing (NLP) systems become increasingly integrated into human social life, these technologies will need to increasingly rely on social intelligence. Although there are many valuable datasets that benchmark isolated dimensions of social intelligence, there does not yet exist any body of work to join these threads into a cohesive subfield in which researchers can quickly identify research gaps and future directions. Towards this goal, we build a Social AI Data... | Minzhi Li, Weiyan Shi, Caleb Ziems, Diyi Yang |  |
| 1149 |  |  [Selective Prefix Tuning for Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.164) |  | 0 | The prevalent approach for optimizing pre-trained language models in downstream tasks is fine-tuning. However, it is both time-consuming and memory-inefficient. In response, a more efficient method called Prefix Tuning, which insert learnable vectors into each Transformer layers, has been proposed and proven effective. Recent investigations reveal that prefix tokens carry context-specific information, prompting the hypothesis that enhancing their specialization can improve model performance. To... | Hongyi Zhang, Zuchao Li, Ping Wang, Hai Zhao |  |
| 1150 |  |  [MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization](https://doi.org/10.18653/v1/2024.findings-acl.165) |  | 0 | The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We introduce a novel multi-objective learning framework employing a Longformer-Encoder-Decoder for this task. The framework optimizes aspect number prediction, minimizes disparity between generated and... | Xiaobo Guo, Soroush Vosoughi |  |
| 1151 |  |  [Non-compositional Expression Generation and its Continual Learning](https://doi.org/10.18653/v1/2024.findings-acl.166) |  | 0 | Non-compositional expressions are an integral part of natural language and their meanings cannot be directly derived from the meanings of their component words. Recent work has shown how their processing remains a challenge for pre-trained language models. Here we consider the fact that prior knowledge of their component words is inadequate to infer their meaning as a whole and that these expressions constitute a long-tailed process in language (based on their occurrence in corpora and their... | Jianing Zhou, Suma Bhat |  |
| 1152 |  |  [Medical Dialogue System: A Survey of Categories, Methods, Evaluation and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.167) |  | 0 | This paper surveys and organizes research works of medical dialog systems, which is an important yet challenging task. Although these systems have been surveyed in the medical community from an application perspective, a systematic review from a rigorous technical perspective has to date remained noticeably absent. As a result, an overview of the categories, methods, evaluation of medical dialogue systems remain limited and underspecified, hindering the further improvement of this area. To fill... | Xiaoming Shi, Zeming Liu, Li Du, Yuxuan Wang, Hongru Wang, Yuhang Guo, Tong Ruan, Jie Xu, Xiaofan Zhang, Shaoting Zhang |  |
| 1153 |  |  [Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.168) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation... | Thi Nguyen, Linhao Luo, Fatemeh Shiri, Dinh Phung, YuanFang Li, ThuyTrang Vu, Gholamreza Haffari |  |
| 1154 |  |  [Comprehensive Abstractive Comment Summarization with Dynamic Clustering and Chain of Thought](https://doi.org/10.18653/v1/2024.findings-acl.169) |  | 0 | Real-world news comments pose a significant challenge due to their noisy and ambiguous nature, which complicates their modeling for clustering and summarization tasks. Most previous research has predominantly focused on extractive summarization methods within specific constraints. This paper concentrates on Clustering and Abstractive Summarization of online news Comments (CASC). First, we introduce an enhanced fast clustering algorithm that maintains a dynamic similarity threshold to ensure the... | Longyin Zhang, Bowei Zou, Jacintha Yi, AiTi Aw |  |
| 1155 |  |  [Self-Supervised Position Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.170) |  | 0 | Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Previous works have proven that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing debiasing methods for LLMs require external bias knowledge or... | Zhongkun Liu, Zheng Chen, Mengqi Zhang, Zhaochun Ren, Pengjie Ren, Zhumin Chen |  |
| 1156 |  |  [HyperCL: A Contrastive Learning Framework for Hyper-Relational Knowledge Graph Embedding with Hierarchical Ontology](https://doi.org/10.18653/v1/2024.findings-acl.171) |  | 0 |  | Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang |  |
| 1157 |  |  [Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection](https://doi.org/10.18653/v1/2024.findings-acl.172) |  | 0 | Multifaceted ideology detection (MID) aims to detect the ideological leanings of texts towards multiple facets. Previous studies on ideology detection mainly focus on one generic facet and ignore label semantics and explanatory descriptions of ideologies, which are a kind of instructive information and reveal the specific concepts of ideologies. In this paper, we develop a novel concept semantics-enhanced framework for the MID task. Specifically, we propose a bidirectional iterative concept... | Songtao Liu, Bang Wang, Wei Xiang, Han Xu, Minghua Xu |  |
| 1158 |  |  [Character-Level Chinese Dependency Parsing via Modeling Latent Intra-Word Structure](https://doi.org/10.18653/v1/2024.findings-acl.173) |  | 0 | Revealing the syntactic structure of sentences in Chinese poses significant challenges for word-level parsers due to the absence of clear word boundaries. To facilitate a transition from word-level to character-level Chinese dependency parsing, this paper proposes modeling latent internal structures within words. In this way, each word-level dependency tree is interpreted as a forest of character-level trees. A constrained Eisner algorithm is implemented to ensure the compatibility of... | Yang Hou, Zhenghua Li |  |
| 1159 |  |  [AlignRE: An Encoding and Semantic Alignment Approach for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.174) |  | 0 | Zero-shot Relation Extraction (ZSRE) aims to predict unseen relations between entity pairs from input sentences. Existing prototype-based ZSRE methods encode relation descriptions into prototype embeddings and predict by measuring the similarity between sentence embeddings and prototype embeddings. However, these methods often overlook abundant side information of relations and suffer from a significant encoding gap between prototypes and sentences, limiting performance. To this end, we propose... | Zehan Li, Fu Zhang, Jingwei Cheng |  |
| 1160 |  |  [Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction](https://doi.org/10.18653/v1/2024.findings-acl.175) |  | 0 | Supervised fine-tuning (SFT) on instruction-following corpus is a crucial approach toward the alignment of large language models (LLMs). However, the performance of LLMs on standard knowledge and reasoning benchmarks tends to suffer from deterioration at the latter stage of the SFT process, echoing the phenomenon of alignment tax. Through our pilot study, we put a hypothesis that the data biases are probably one cause behind the phenomenon. To address the issue, we introduce a simple... | Tingchen Fu, Deng Cai, Lemao Liu, Shuming Shi, Rui Yan |  |
| 1161 |  |  [Efficient Knowledge Infusion via KG-LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.176) |  | 0 | To tackle the problem of domain-specific knowledge scarcity within large language models (LLMs), knowledge graph-retrievalaugmented method has been proven to be an effective and efficient technique for knowledge infusion. However, existing approaches face two primary challenges: knowledge mismatch between public available knowledge graphs and the specific domain of the task at hand, and poor information compliance of LLMs with knowledge graphs. In this paper, we leverage a small set of labeled... | Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang |  |
| 1162 |  |  [Towards Precise Localization of Critical Errors in Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.177) |  | 0 | The advent of large language models has experienced a remarkable improvement in the field of machine translation. However, machine translation is still vulnerable to critical meaning deviations, which may incur catastrophic issues in social or ethical contexts. In particular, existing critical error detection primarily focuses on identifying sentence-level errors, leaving the precise localization of such errors within the sentence unaddressed. In this paper, we introduce a new task, word-level... | Dahyun Jung, Sugyeong Eo, Heuiseok Lim |  |
| 1163 |  |  [LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.178) |  | 0 | Large Language Models (LLMs), such as LLaMA and T5, have shown exceptional performance across various tasks through fine-tuning. Although low-rank adaption (LoRA) has emerged to cheaply fine-tune these LLMs on downstream tasks, their deployment is still hindered by the vast model scale and computational costs. Post-training model pruning offers a way to compress LLMs. However, the current pruning methods designed for LLMs are not compatible with LoRA. This is due to their utilization of... | Mingyang Zhang, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang |  |
| 1164 |  |  [Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.179) |  | 0 | The recent advancements in large language models (LLMs) have been extraordinary, yet the escalating inference costs associated with them present challenges in real-world applications. To address these challenges, we propose a novel approach called Early-exiting Speculative Decoding (EESD) with lossless acceleration. Specifically, EESD utilizes a segment of the LLM to generate draft tokens, incorporating Early-exiting structures after the first N layers. To enhance the quality of draft tokens, a... | Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai |  |
| 1165 |  |  [Towards Better Utilization of Multi-Reference Training Data for Chinese Grammatical Error Correction](https://doi.org/10.18653/v1/2024.findings-acl.180) |  | 0 | For the grammatical error correction (GEC) task, there usually exist multiple correction ways for an erroneous input sentence, leading to multiple references. Observing the high proportion of multi-reference instances in Chinese GEC training data, we target a systematic study on how to better utilize multi-reference training data. We propose two new approaches and a simple two-stage training strategy. We compare them against previously proposed approaches, on two Chinese training datasets,... | Yumeng Liu, Zhenghua Li, Haochen Jiang, Bo Zhang, Chen Li, Ji Zhang |  |
| 1166 |  |  [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.181) |  | 0 | Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though... | Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, Jie Tang |  |
| 1167 |  |  [Transition-based Opinion Generation for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.182) |  | 0 | Recently, the use of pre-trained generation models for extracting sentiment elements has resulted in significant advancements in aspect-based sentiment analysis benchmarks. However, these approaches often overlook the importance of explicitly modeling structure among sentiment elements. To address this limitation, we present a study that aims to integrate general pre-trained sequence-to-sequence language models with a structure-aware transition-based approach. Therefore, we propose a transition... | Tianlai Ma, Zhongqing Wang, Guodong Zhou |  |
| 1168 |  |  [Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion](https://doi.org/10.18653/v1/2024.findings-acl.183) |  | 0 | Dynamic topic models track the evolution of topics in sequential documents, which have derived various applications like trend analysis. However, existing models suffer from repetitive topic and unassociated topic issues, failing to reveal the evolution and hindering further applications. To address these issues, we break the tradition of simply chaining topics in existing work and propose a novel neural Chain-Free Dynamic Topic Model. We introduce a new evolution-tracking contrastive learning... | Xiaobao Wu, Xinshuai Dong, Liangming Pan, Thong Nguyen, Anh Tuan Luu |  |
| 1169 |  |  [A Chinese Dataset for Evaluating the Safeguards in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.184) |  | 0 | Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks. Previous studies have proposed comprehensive taxonomies of LLM risks, as well as corresponding prompts that can be used to examine LLM safety. However, the focus has been almost exclusively on English. We aim to broaden LLM safety research by introducing a dataset for the safety evaluation of Chinese LLMs, and extending it to better identify false negative and... | Yuxia Wang, Zenan Zhai, Haonan Li, Xudong Han, Shom Lin, Zhenxuan Zhang, Angela Zhao, Preslav Nakov, Timothy Baldwin |  |
| 1170 |  |  [LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction](https://doi.org/10.18653/v1/2024.findings-acl.185) |  | 0 | Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting tasks. In this study, we introduce a novel framework called LLMFactor, which employs Sequential Knowledge-Guided Prompting (SKGP) to identify factors that influence stock movements using LLMs. Unlike... | Meiyun Wang, Kiyoshi Izumi, Hiroki Sakaji |  |
| 1171 |  |  [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://doi.org/10.18653/v1/2024.findings-acl.186) |  | 0 | Autonomous graphical user interface (GUI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, most existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment... | Zhuosheng Zhang, Aston Zhang |  |
| 1172 |  |  [SP³: Enhancing Structured Pruning via PCA Projection](https://doi.org/10.18653/v1/2024.findings-acl.187) |  | 0 |  | Yuxuan Hu, Jing Zhang, Zhe Zhao, Chen Zhao, Xiaodong Chen, Cuiping Li, Hong Chen |  |
| 1173 |  |  [GENDEX: Generative Data Augmentation Strategy Leveraging External Data for Abstractive Dialogue Summarization](https://doi.org/10.18653/v1/2024.findings-acl.188) |  | 0 | With the proliferation of digital communication, dialogue summarization has become increasingly important. However, it still faces a shortage of data. To address this issue, we developed \*\*Gen\*\*erative \*\*D\*\*ata Augmentation Strategy Leveraging \*\*Ex\*\*ternal Data for Abstractive Dialogue Summarization (\*\*GENDEX\*\*), which is based on the hypothetical foundation that texts containing people and their interpersonal interactions can potentially serve as summaries of corresponding... | Sangwon Park, Hongseok Choi, Dongha Choi, Hyunju Lee |  |
| 1174 |  |  [Concept-Best-Matching: Evaluating Compositionality In Emergent Communication](https://doi.org/10.18653/v1/2024.findings-acl.189) |  | 0 | Artificial agents that learn to communicate in order to accomplish a given task acquire communication protocols that are typically opaque to a human. A large body of work has attempted to evaluate the emergent communication via various evaluation measures, with \*\*compositionality\*\* featuring as a prominent desired trait. However, current evaluation procedures do not directly expose the compositionality of the emergent communication. We propose a procedure to assess the compositionality of... | Boaz Carmeli, Yonatan Belinkov, Ron Meir |  |
| 1175 |  |  [A Tale of Two Revisions: Summarizing Changes Across Document Versions](https://doi.org/10.18653/v1/2024.findings-acl.190) |  | 0 | Document revision is a crucial aspect of the writing process, particularly in collaborative environments where multiple authors contribute simultaneously. However, current tools lack an efficient way to provide a comprehensive overview of changes between versions, leading to difficulties in understanding revisions. To address this, we propose a novel task of providing thematic summary of changes between document versions, organizing individual edits based on shared themes. We assess... | T. Y. S. S. Santosh, Natwar Modani, Apoorv Saxena |  |
| 1176 |  |  [Refine, Align, and Aggregate: Multi-view Linguistic Features Enhancement for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.191) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplets of aspect terms, their associated sentiment and opinion terms. Previous works based on different modeling paradigms have achieved promising results. However, these methods struggle to comprehensively explore the various specific relations between sentiment elements in multi-view linguistic features, which is the prior indication effect for facilitating sentiment triplets extraction, requiring to align and aggregate them to... | Guixin Su, Mingmin Wu, Zhongqiang Huang, Yongcheng Zhang, Tongguan Wang, Yuxue Hu, Ying Sha |  |
| 1177 |  |  [Pro-Woman, Anti-Man? Identifying Gender Bias in Stance Detection](https://doi.org/10.18653/v1/2024.findings-acl.192) |  | 0 | Gender bias has been widely observed in NLP models, which has the potential to perpetuate harmful stereotypes and discrimination. In this paper, we construct a dataset GenderStance of 36k samples to measure gender bias in stance detection, determining whether models consistently predict the same stance for a particular gender group. We find that all models are gender-biased and prone to classify sentences that contain male nouns as Against and those with female nouns as Favor. Moreover,... | Yingjie Li, Yue Zhang |  |
| 1178 |  |  [Likelihood-based Mitigation of Evaluation Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.193) |  | 0 | Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics.However, the likelihood, a measure of LLM’s plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure.It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods.In this paper, we... | Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki Okazaki |  |
| 1179 |  |  [The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.194) |  | 0 | Benchmark plays a pivotal role in assessing the advancements of large language models (LLMs). While numerous benchmarks have been proposed to evaluate LLMs’ capabilities, there is a notable absence of a dedicated benchmark for assessing their musical abilities. To address this gap, we present ZIQI-Eval, a comprehensive and large-scale music benchmark specifically designed to evaluate the music-related capabilities of LLMs.ZIQI-Eval encompasses a wide range of questions, covering 10 major... | Jiajia Li, Lu Yang, Mingni Tang, Chenchong Chenchong, Zuchao Li, Ping Wang, Hai Zhao |  |
| 1180 |  |  [PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference](https://doi.org/10.18653/v1/2024.findings-acl.195) |  | 0 | Large Language Models (LLMs) have shown remarkable comprehension abilities but face challenges in GPU memory usage during inference, hindering their scalability for real-time applications like chatbots. To accelerate inference, we store computed keys and values (KV cache) in the GPU memory. Existing methods study the KV cache compression to reduce memory by pruning the pre-computed KV cache. However, they neglect the inter-layer dependency between layers and huge memory consumption in... | Dongjie Yang, Xiaodong Han, Yan Gao, Yao Hu, Shilin Zhang, Hai Zhao |  |
| 1181 |  |  [From Role-Play to Drama-Interaction: An LLM Solution](https://doi.org/10.18653/v1/2024.findings-acl.196) |  | 0 | Drama is a form of storytelling inspired by human creativity, proceeding with a predefined storyline, carrying emotions and thoughts.This paper introduces LLM-based interactive drama, which endows traditional drama with an unprecedented immersion, where a person is allowed to walk into it and interact with the characters and scenes.We define this new artistic genre by 6 essential elements—plot, character, thought, diction, spectacle and interaction—and study the entire pipeline to forge a... | Weiqi Wu, Hongqiu Wu, Lai Jiang, Xingyuan Liu, Hai Zhao, Min Zhang |  |
| 1182 |  |  [TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.197) |  | 0 | While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users’ narrative immersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom role-playing. To accurately represent characters at specific time points, agents must avoid character hallucination, where... | Jaewoo Ahn, Taehyun Lee, Junyoung Lim, JinHwa Kim, Sangdoo Yun, Hwaran Lee, Gunhee Kim |  |
| 1183 |  |  [Red Teaming Visual Language Models](https://doi.org/10.18653/v1/2024.findings-acl.198) |  | 0 | VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar scenarios, especially with their combination of textual and visual inputs, remains a question. To explore this problem, we present a novel red teaming dataset RTVLM, which encompasses 12 subtasks (e.g., image... | Mukai Li, Lei Li, Yuwei Yin, Masood Ahmed, Zhenguang Liu, Qi Liu |  |
| 1184 |  |  [Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach](https://doi.org/10.18653/v1/2024.findings-acl.199) |  | 0 | A Large Language Model (LLM) tends to generate inconsistent and sometimes contradictory outputs when presented with a prompt that has equivalent semantics but is expressed differently from the original prompt. To achieve semantic consistency of an LLM, one of the key approaches is to finetune the model with prompt-output pairs with semantically equivalent meanings. Despite its effectiveness, a data-driven finetuning method incurs substantial computation costs in data preparation and model... | Jingyuan Yang, Dapeng Chen, Yajing Sun, Rongjun Li, Zhiyong Feng, Wei Peng |  |
| 1185 |  |  [Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments](https://doi.org/10.18653/v1/2024.findings-acl.200) |  | 0 | In embodied instruction-following (EIF), the integration of pretrained language models (LMs) as task planners emerges as a significant branch, where tasks are planned at the skill level by prompting LMs with pretrained skills and user instructions. However, grounding these pretrained skills in different domains remains challenging due to their intricate entanglement with the domain-specific knowledge. To address this challenge, we present a semantic skill grounding (SemGro) framework that... | Sangwoo Shin, Seunghyun Kim, Youngsoo Jang, Moontae Lee, Honguk Woo |  |
| 1186 |  |  [LIRE: listwise reward enhancement for preference alignment](https://doi.org/10.18653/v1/2024.findings-acl.201) |  | 0 | Recently, tremendous strides have been made to align the generation of Large Language Models (LLMs) with human values to mitigate toxic or unhelpful content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves effective and is widely adopted by researchers. However, implementing RLHF is complex, and its sensitivity to hyperparameters renders achieving stable performance and scalability challenging. Furthermore, prevailing approaches to preference alignment primarily concentrate... | Mingye Zhu, Yi Liu, Lei Zhang, Junbo Guo, Zhendong Mao |  |
| 1187 |  |  [See It All: Contextualized Late Aggregation for 3D Dense Captioning](https://doi.org/10.18653/v1/2024.findings-acl.202) |  | 0 | 3D dense captioning is a task to localize objects in a 3D scene and generate descriptive sentences for each object. Recent approaches in 3D dense captioning have adopted transformer encoder-decoder frameworks from object detection to build an end-to-end pipeline without hand-crafted components. However, these approaches struggle with contradicting objectives where a single query attention has to simultaneously view both the tightly localized object regions and contextual environment. To... | Minjung Kim, Hyung Lim, Seung Hwan Kim, Soonyoung Lee, Bumsoo Kim, Gunhee Kim |  |
| 1188 |  |  [DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.203) |  | 0 | Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning autonomous language agents in various real-life applications. To improve the neural-symbolic reasoning capabilities of language agents powered by Large Language Models (LLMs) in KGQA, we propose the Decomposition-Alignment-Reasoning Agent (DARA) framework. DARA effectively parses questions into formal queries through a dual mechanism: high-level iterative task decomposition and low-level task grounding. Importantly,... | Haishuo Fang, Xiaodan Zhu, Iryna Gurevych |  |
| 1189 |  |  [GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment](https://doi.org/10.18653/v1/2024.findings-acl.204) |  | 0 | The burgeoning size of Large Language Models (LLMs) has led to enhanced capabilities in generating responses, albeit at the expense of increased inference times and elevated resource demands. Existing methods of acceleration, predominantly hinged on knowledge distillation, generally necessitate fine-tuning of considerably large models, such as Llama-7B, posing a challenge for average users. Furthermore, present techniques for expediting inference and reducing costs operate independently. To... | Yao Yao, Zuchao Li, Hai Zhao |  |
| 1190 |  |  [Compositional Generalization with Grounded Language Models](https://doi.org/10.18653/v1/2024.findings-acl.205) |  | 0 | Grounded language models use external sources of information, such as knowledge graphs, to meet some of the general challenges associated with pre-training. By extending previous work on compositional generalization in semantic parsing, we allow for a controlled evaluation of the degree to which these models learn and generalize from patterns in knowledge graphs. We develop a procedure for generating natural language questions paired with knowledge graphs that targets different aspects of... | Sondre Wold, Étienne Simon, Lucas Georges Gabriel Charpentier, Egor V. Kostylev, Erik Velldal, Lilja Øvrelid |  |
| 1191 |  |  [Rethinking Negative Instances for Generative Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.206) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric schema. In this work, we explore the potential enhancement of the existing methods by incorporating negative instances into training. Our experiments reveal that negative instances contribute to... | Yuyang Ding, Juntao Li, Pinzheng Wang, Zecheng Tang, Yan Bowen, Min Zhang |  |
| 1192 |  |  [WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.207) |  | 0 | Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a... | Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 1193 |  |  [DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference](https://doi.org/10.18653/v1/2024.findings-acl.208) |  | 0 | Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on... | Jialong Wu, Linhai Zhang, Deyu Zhou, Guoqiang Xu |  |
| 1194 |  |  [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.209) |  | 0 | Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored.... | Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu |  |
| 1195 |  |  [How Much Does Nonverbal Communication Conform to Entropy Rate Constancy?: A Case Study on Listener Gaze in Interaction](https://doi.org/10.18653/v1/2024.findings-acl.210) |  | 0 | According to the Entropy Rate Constancy (ERC) principle, the information density of a text is approximately constant over its length. Whether this principle also applies to nonverbal communication signals is still under investigation. We perform empirical analyses of video-recorded dialogue data and investigate whether listener gaze, as an important nonverbal communication signal, adheres to the ERC principle. Results show (1) that the ERC principle holds for listener gaze; and (2) that the two... | Yu Wang, Yang Xu, Gabriel Skantze, Hendrik Buschmeier |  |
| 1196 |  |  [Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.211) |  | 0 | This study investigates how Large Language Models (LLMs) leverage source and reference data in machine translation evaluation task, aiming to better understand the mechanisms behind their remarkable performance in this task.We design the controlled experiments across various input modes and model types, and employ both coarse-grained and fine-grained prompts to discern the utility of source versus reference information.We find that reference information significantly enhances the evaluation... | Xu Huang, Zhirui Zhang, Xiang Geng, Yichao Du, Jiajun Chen, Shujian Huang |  |
| 1197 |  |  [Chain-of-Verification Reduces Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.212) |  | 0 | Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other... | Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, Jason Weston |  |
| 1198 |  |  [Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method](https://doi.org/10.18653/v1/2024.findings-acl.213) |  | 0 | Bargaining is an important and unique part of negotiation between humans. As LLM-driven agents learn to negotiate and act like real humans, how to evaluate agents’ bargaining abilities remains an open problem.For the first time, we formally described the Bargaining task as an asymmetric incomplete information game, defining the gains of the Buyer and Seller in multiple bargaining processes. It allows us to quantitatively assess an agent’s performance in the Bargain task.We collected a real... | Tian Xia, Zhiwei He, Tong Ren, Yibo Miao, Zhuosheng Zhang, Yang Yang, Rui Wang |  |
| 1199 |  |  [DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories](https://doi.org/10.18653/v1/2024.findings-acl.214) |  | 0 | How to evaluate the coding abilities of Large Language Models (LLMs) remains an open question. We find that existing benchmarks are poorly aligned with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs.To address the knowledge gap, we propose a new benchmark named DevEval, which has three advances. (1) DevEval aligns with real-world repositories in multiple dimensions, e.g., code and dependency distributions. (2) DevEval is annotated by 13 developers and... | Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Huanyu Liu, Hao Zhu, Lecheng Wang, Kaibo Liu, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yuqi Zhu, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li, Bin Gu, Mengfei Yang |  |
| 1200 |  |  [LPNL: Scalable Link Prediction with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.215) |  | 0 | Exploring the application of large language models (LLMs) to graph learning is an emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to graph learning with LLMs. This work focuses on the link prediction task and introduces \*\*LPNL\*\* (Link Prediction via Natural Language), a framework based on large language models designed for scalable link prediction on large-scale heterogeneous graphs. We design novel prompts for link prediction... | Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng |  |
| 1201 |  |  [Aligning Speech Segments Beyond Pure Semantics](https://doi.org/10.18653/v1/2024.findings-acl.216) |  | 0 | Multilingual parallel data for speech-to-speech translation is scarce and expensive to create from scratch. This is all the more true for expressive speech translation, which aims at preserving not only the semantics, but also the overall prosody (e.g. style, emotion, rate-of-speech). Existing corpora contain speech utterances with the same meaning, yet the overall prosody is typically different, as human annotators are not tasked with reproducing these aspects, or crowed-sourced efforts do not... | Kevin Heffernan, Artyom Kozhevnikov, Loïc Barrault, Alexandre Mourachko, Holger Schwenk |  |
| 1202 |  |  [Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives](https://doi.org/10.18653/v1/2024.findings-acl.217) |  | 0 | Humans use multiple senses to comprehend the environment. Vision and language are two of the most vital senses since they allow us to easily communicate our thoughts and perceive the world around us. There has been a lot of interest in creating video-language understanding systems with human-like senses since a video-language pair can mimic both our linguistic medium and visual environment with temporal dynamics. In this survey, we review the key tasks of these systems and highlight the... | Thong Nguyen, Yi Bin, Junbin Xiao, Leigang Qu, Yicong Li, Jay Zhangjie Wu, CongDuy Nguyen, SeeKiong Ng, Anh Tuan Luu |  |
| 1203 |  |  [Generative Input: Towards Next-Generation Input Methods Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.218) |  | 0 | Since the release of ChatGPT, generative models have achieved tremendous success and become the de facto approach for various NLP tasks. However, its application in the field of input methods remains under-explored. Many neural network approaches have been applied to the construction of Chinese input method engines (IMEs). Previous research often assumed that the input pinyin was correct and focused on Pinyin-to-character (P2C) task, which significantly falls short of meeting users’ demands.... | Keyu Ding, Yongcan Wang, Zihang Xu, Zhenzhen Jia, Enhong Chen |  |
| 1204 |  |  [A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential](https://doi.org/10.18653/v1/2024.findings-acl.219) |  | 0 | Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, “generate-then-read” pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although promising, this research direction is underexplored and still cannot work in the scenario when source knowledge is given. In this paper, we formalize a general “A + B” framework with varying... | Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Peng Zhou |  |
| 1205 |  |  [Functional Overlap Reranking for Neural Code Generation](https://doi.org/10.18653/v1/2024.findings-acl.220) |  | 0 | Code Large Language Models (CodeLLMs) have ushered in a new era in code generation advancements. However, selecting the best code solutions from all possible CodeLLM outputs remains a challenge. Previous methods often overlooked the intricate functional similarities and interactions between solution clusters. We introduce SRank, a novel reranking strategy for selecting the best solutions from code generation, focusing on modeling the relationships between clusters of solutions. By quantifying... | Hung To, Minh Nguyen, Nghi Bui |  |
| 1206 |  |  [Adversarial Preference Optimization: Enhancing Your Alignment via RM-LLM Game](https://doi.org/10.18653/v1/2024.findings-acl.221) |  | 0 | Human preference alignment is essential to improve the interaction quality of large language models (LLMs). Existing alignment methods depend on manually annotated preference data to guide the LLM optimization directions. However, continuously updating LLMs for alignment raises a distribution gap between model-generated samples and human-annotated responses, hindering training effectiveness. To mitigate this issue, previous methods require additional preference annotation on newly generated... | Pengyu Cheng, Yifan Yang, Jian Li, Yong Dai, Tianhao Hu, Peixin Cao, Nan Du, Xiaolong Li |  |
| 1207 |  |  [Pinpointing Diffusion Grid Noise to Enhance Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.findings-acl.222) |  | 0 | Aspect sentiment quad prediction (ASQP) has garnered significant attention in aspect-based sentiment analysis (ABSA). Current ASQP research primarily relies on pre-trained generative language models to produce templated sequences, often complemented by grid-based auxiliary methods. Despite these efforts, the persistent challenge of generation instability remains unresolved and the effectiveness of grid methods remains underexplored in current studies. To this end, we introduce Grid Noise... | Linan Zhu, Xiangfan Chen, Xiaolei Guo, Chenwei Zhang, Zhechao Zhu, Zehai Zhou, Xiangjie Kong |  |
| 1208 |  |  [Continual Contrastive Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.223) |  | 0 | Recently, neural networks have shown impressive progress across diverse fields, with speech processing being no exception. However, recent breakthroughs in this area require extensive offline training using large datasets and tremendous computing resources. Unfortunately, these models struggle to retain their previously acquired knowledge when learning new tasks continually. In this paper, we investigate the problem of learning sequence-to-sequence models for spoken language understanding in a... | Umberto Cappellazzo, Enrico Fini, Muqiao Yang, Daniele Falavigna, Alessio Brutti, Bhiksha Raj |  |
| 1209 |  |  [LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.224) |  | 0 | Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs). Particularly, we utilize the state-of-the-art LLMs to generate a graph-structural prompt to enhance... | Kai Wang, Yuwei Xu, Zhiyong Wu, Siqiang Luo |  |
| 1210 |  |  [Unsupervised Parsing by Searching for Frequent Word Sequences among Sentences with Equivalent Predicate-Argument Structures](https://doi.org/10.18653/v1/2024.findings-acl.225) |  | 0 | Unsupervised constituency parsing focuses on identifying word sequences that form a syntactic unit (i.e., constituents) in target sentences. Linguists identify the constituent by evaluating a set of Predicate-Argument Structure (PAS) equivalent sentences where we find the constituent appears more frequently than non-constituents (i.e., the constituent corresponds to a frequent word sequence within the sentence set). However, such frequency information is unavailable in previous parsing methods... | Junjie Chen, Xiangheng He, Danushka Bollegala, Yusuke Miyao |  |
| 1211 |  |  [Data-Centric Explainable Debiasing for Improving Fairness in Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.226) |  | 0 | Human-like social bias of pre-trained language models (PLMs) on downstream tasks have attracted increasing attention. The potential flaws in the training data are the main factor that causes unfairness in PLMs. Existing data-centric debiasing strategies mainly leverage explicit bias words (defined as sensitive attribute words specific to demographic groups) for counterfactual data augmentation to balance the training data. However, they lack consideration of implicit bias words potentially... | Yingji Li, Mengnan Du, Rui Song, Xin Wang, Ying Wang |  |
| 1212 |  |  [Knowledge-Driven Cross-Document Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.227) |  | 0 | Relation extraction (RE) is a well-known NLP application often treated as a sentence or document-level task. However, a handful of recent efforts explore it across documents or in the cross-document setting (CrossDocRE). This is distinct from the single document case because different documents often focus on disparate themes, while text within a document tends to have a single goal.Current CrossDocRE efforts do not consider domain knowledge, which are often assumed to be known to the reader... | Monika Jain, Raghava Mutharaju, Kuldeep Singh, Ramakanth Kavuluru |  |
| 1213 |  |  [Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.228) |  | 0 | Recent research in dialogue systems focuses on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users complete specific tasks, while open-domain systems aim to create engaging conversations. However, user intents often emerge during interactions. A recent study introduced SalesBot, simulating dialogues that transition from chit-chat to task-oriented scenarios to train sales agents. Unfortunately, the initial data lacked smooth transitions and... | Wen Chang, YunNung Chen |  |
| 1214 |  |  [KG-Adapter: Enabling Knowledge Graph Integration in Large Language Models through Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.229) |  | 0 | Although large language models (LLMs) show remarkable capabilities and generalizability across various tasks, they are criticized for lack of expertise. One promising solution is to combine knowledge graphs (KGs) with LLMs, and recent studies focus on integrating KGs into LLMs through prompt-based methods. However, these approaches fail to use the structural information of the KGs, suffer from the problem of knowledge conflict, and over-reliance on super LLMs. To address these challenges, we... | Shiyu Tian, Yangyang Luo, Tianze Xu, Caixia Yuan, Huixing Jiang, Chen Wei, Xiaojie Wang |  |
| 1215 |  |  [Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.230) |  | 0 | Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local optimality. To address this shortcoming, ensemble-optimization tries to obtain multiple reasoning paths to get the final answer assembly. However, current ensemble-optimization methods either simply employ rule-based post-processing such as self-consistency, or train an... | Lei Lin, JiaYi Fu, Pengli Liu, Qingyang Li, Yan Gong, Junchen Wan, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, Kun Gai |  |
| 1216 |  |  [Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.231) |  | 0 | Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with a hybrid of structured tables and unstructured text remain uncertain. This study explores LLMs’ mathematical reasoning on four financial tabular question-answering datasets: TATQA, FinQA, ConvFinQA, and Multihiertt. Through extensive experiments with various models and prompting techniques, we assess how LLMs adapt to complex tables and mathematical tasks. We focus... | Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, Dan Roth |  |
| 1217 |  |  [Improving In-Context Learning with Prediction Feedback for Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.232) |  | 0 | Large language models (LLMs) have achieved promising results in sentiment analysis through the in-context learning (ICL) paradigm. However, their ability to distinguish subtle sentiments still remains a challenge. Inspired by the human ability to adjust understanding via feedback, this paper enhances ICL by incorporating prior predictions and feedback, aiming to rectify sentiment misinterpretation of LLMs. Specifically, the proposed framework consists of three steps: (1) acquiring prior... | Hongling Xu, Qianlong Wang, Yice Zhang, Min Yang, Xi Zeng, Bing Qin, Ruifeng Xu |  |
| 1218 |  |  [Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model](https://doi.org/10.18653/v1/2024.findings-acl.233) |  | 0 | Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into symbol-based and neural-based models. Symbol-based models are interpretable but inefficient, while neural-based approaches are efficient but lack interpretability. Hence, mining interpretable factors effectively presents a significant challenge. Inspired by the success of Large Language Models (LLMs) in... | Zhiwei Li, Ran Song, Caihong Sun, Wei Xu, Zhengtao Yu, JiRong Wen |  |
| 1219 |  |  [Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint](https://doi.org/10.18653/v1/2024.findings-acl.234) |  | 0 | Large language models (LLMs) internalize enormous parametric knowledge during pre-training. Concurrently, realistic applications necessitate external contextual knowledge to aid models on the underlying tasks. This raises a crucial dilemma known as knowledge conflicts, where the contextual knowledge clashes with the parametric knowledge. However, existing decoding works are specialized in resolving knowledge conflicts and could inadvertently deteriorate performance in absence of conflicts. In... | Xiaowei Yuan, Zhao Yang, Yequan Wang, Shengping Liu, Jun Zhao, Kang Liu |  |
| 1220 |  |  [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.235) |  | 0 | In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose SALAD-Bench, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of... | Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, Jing Shao |  |
| 1221 |  |  [Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation](https://doi.org/10.18653/v1/2024.findings-acl.236) |  | 0 | Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality factual statements from free-text radiology reports in order to improve the representations of text encoders and, consequently, their performance on various downstream tasks.In the first stage, we propose a Fact Extractor that leverages large language... | Pablo Messina, René Vidal, Denis Parra, Alvaro Soto, Vladimir Araujo |  |
| 1222 |  |  [GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network](https://doi.org/10.18653/v1/2024.findings-acl.237) |  | 0 | Large Language Models (LLMs) exhibit strong In-Context Learning (ICL) capabilities when prompts with demonstrations are used. However, fine-tuning still remains crucial to further enhance their adaptability. Prompt-based fine-tuning proves to be an effective fine-tuning method in low-data scenarios, but high demands on computing resources limit its practicality. We address this issue by introducing a prompt-based parameter-efficient fine-tuning (PEFT) approach. GNNavi leverages insights into... | Shuzhou Yuan, Ercong Nie, Michael Färber, Helmut Schmid, Hinrich Schütze |  |
| 1223 |  |  [M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.238) |  | 0 | There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain: a fundamental pre-requisite for success on down-stream tasks.Addressing this gap, we use Multiple Choice and Abstractive Question... | Anand Subramanian, Viktor Schlegel, Abhinav Ramesh Kashyap, ThanhTung Nguyen, Vijay Prakash Dwivedi, Stefan Winkler |  |
| 1224 |  |  [MovieSum: An Abstractive Summarization Dataset for Movie Screenplays](https://doi.org/10.18653/v1/2024.findings-acl.239) |  | 0 | Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore, while television transcripts have received attention in recent studies, movie screenplay summarization remains underexplored. To stimulate research in this area, we present a new dataset, MovieSum,... | Rohit Saxena, Frank Keller |  |
| 1225 |  |  [Autonomous Workflow for Multimodal Fine-Grained Training Assistants Towards Mixed Reality](https://doi.org/10.18653/v1/2024.findings-acl.240) |  | 0 | Autonomous artificial intelligence (AI) agents have emerged as promising protocols for automatically understanding the language-based environment, particularly with the exponential development of large language models (LLMs). However, a fine-grained, comprehensive understanding of multimodal environments remains under-explored. This work designs an autonomous workflow tailored for integrating AI agents seamlessly into extended reality (XR) applications for fine-grained training. We present a... | Jiahuan Pei, Irene Viola, Haochen Huang, Junxiao Wang, Moonisa Ahsan, Fanghua Ye, Yiming Jiang, Yao Sai, Di Wang, Zhumin Chen, Pengjie Ren, Pablo César |  |
| 1226 |  |  [Perceptions of Language Technology Failures from South Asian English Speakers](https://doi.org/10.18653/v1/2024.findings-acl.241) |  | 0 | English NLP systems have empirically worse performance for dialects other than Standard American English (SAmE). However, how these discrepancies impact use of language technology by speakers of non-SAmE global Englishes is not well understood. We focus on reducing this gap for South Asian Englishes (SAsE), a macro-group of regional varieties with cumulatively more speakers than SAmE, by surveying SAsE speakers about their interactions with language technology and compare their responses to a... | Faye Holt, William Held, Diyi Yang |  |
| 1227 |  |  [A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task](https://doi.org/10.18653/v1/2024.findings-acl.242) |  | 0 | Transformers demonstrate impressive performance on a range of reasoning benchmarks. To evaluate the degree to which these abilities are a result of actual reasoning, existing work has focused on developing sophisticated benchmarks for behavioral studies. However, these studies do not provide insights into the internal mechanisms driving the observed capabilities. To improve our understanding of the internal mechanisms of transformers, we present a comprehensive mechanistic analysis of a... | Jannik Brinkmann, Abhay Sheshadri, Victor Levoso, Paul Swoboda, Christian Bartelt |  |
| 1228 |  |  [Optimal Transport Guided Correlation Assignment for Multimodal Entity Linking](https://doi.org/10.18653/v1/2024.findings-acl.243) |  | 0 | Multimodal entity linking (MEL) aims to link ambiguous mentions in multimodal contexts to entities in a multimodal knowledge graph. A pivotal challenge is to fully leverage multi-element correlations between mentions and entities to bridge modality gap and enable fine-grained semantic matching. Existing methods attempt several local correlative mechanisms, relying heavily on the automatically learned attention weights, which may over-concentrate on partial correlations. To mitigate this issue,... | Zefeng Zhang, Jiawei Sheng, Chuang Zhang, Liangyunzhi Liangyunzhi, Wenyuan Zhang, Siqi Wang, Tingwen Liu |  |
| 1229 |  |  [On Efficiently Representing Regular Languages as RNNs](https://doi.org/10.18653/v1/2024.findings-acl.244) |  | 0 | Recent work by Hewitt et al. (2020) provides an interpretation of the empirical success of recurrent neural networks (RNNs) as language models (LMs). It shows that RNNs can efficiently represent bounded hierarchical structures that are prevalent in human language.This suggests that RNNs’ success might be linked to their ability to model hierarchy. However, a closer inspection of hewitt-etal-2020-rnns construction shows that it is not inherently limited to hierarchical structures. This poses a... | Anej Svete, Robin Chan, Ryan Cotterell |  |
| 1230 |  |  [A Survey on Modelling Morality for Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.245) |  | 0 | In this survey, we provide a systematic review of recent work on modelling morality in text, an area of research that has garnered increasing attention in recent years. Our survey is motivated by the importance of modelling decisions on the created resources, the models trained on these resources and the analyses that result from the models’ predictions. We review work at the interface of NLP, Computational Social Science and Psychology and give an overview of the different goals and research... | Ines Reinig, Maria Becker, Ines Rehbein, Simone Paolo Ponzetto |  |
| 1231 |  |  [Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.246) |  | 0 | Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs). Existing data selection approaches on LLMs either rely on single unreliable scores, or use downstream tasks for selection, which is time-consuming and can lead to potential over-fitting on the chosen evaluation datasets. To address this challenge, we... | Ruibo Chen, Yihan Wu, Lichang Chen, Guodong Liu, Qi He, Tianyi Xiong, Chenxi Liu, Junfeng Guo, Heng Huang |  |
| 1232 |  |  [DebugBench: Evaluating Debugging Capability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.247) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs’ debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce ‘DebugBench’, an LLM debugging benchmark consisting of 4,253 instances. It covers... | Runchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai Lin, Yinxu Pan, Yesai Wu, Haotian Hui, Weichuan Liu, Zhiyuan Liu, Maosong Sun |  |
| 1233 |  |  [POP-CEE: Position-oriented Prompt-tuning Model for Causal Emotion Entailment](https://doi.org/10.18653/v1/2024.findings-acl.248) |  | 0 | The objective of the Causal Emotion Entailment (CEE) task is to identify the causes of the target emotional utterances in a given conversation. Most existing studies have focused on a fine-tuning paradigm based on a pretrained model, e.g., the BERT model. However, there are gaps between the pretrained task and the CEE task. Although a pretrained model enhances contextual comprehension to some extent, it cannot acquire specific knowledge that is relevant to the CEE task. In addition, in a... | Zhihan Zhou, Xue Gu, Yujie Zhao, Hao Xu |  |
| 1234 |  |  [Context Length Extension via Generalized Extrapolation Scale](https://doi.org/10.18653/v1/2024.findings-acl.249) |  | 0 |  | Linhan Li, Huaping Zhang |  |
| 1235 |  |  [Selectively Answering Visual Questions](https://doi.org/10.18653/v1/2024.findings-acl.250) |  | 0 | Recently, large multi-modal models (LMMs) have emerged with the capacity to perform vision tasks such as captioning and visual question answering (VQA) with unprecedented accuracy. Applications such as helping the blind or visually impaired have a critical need for precise answers. It is specially important for models to be well calibrated and be able to quantify their uncertainty in order to selectively decide when to answer and when to abstain or ask for clarifications. We perform the first... | Julian Eisenschlos, Hernán Maina, Guido Ivetta, Luciana Benotti |  |
| 1236 |  |  [Wav2SQL: Direct Generalizable Speech-To-SQL Parsing](https://doi.org/10.18653/v1/2024.findings-acl.251) |  | 0 | We release a multi-accent dataset and propose speech-programming and gradient reversal classifier to improve the generalization.Abstract: Speech-to-SQL (S2SQL) aims to convert spoken questions into SQL queries given relational databases, which has been traditionally implemented in a cascaded manner while facing the following challenges: 1) model training is faced with the major issue of data scarcity, where limited parallel data is available; and 2) the systems should be robust enough to handle... | Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize Cheng, Zhou Zhao |  |
| 1237 |  |  [E2-LLM: Efficient and Extreme Length Extension of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.252) |  | 0 | Training Large Language Models (LLMs) to process extensive context lengths incurs prohibitive computational costs. Prevailing techniques for extending context capabilities in LLMs typically require not only additional training procedures but also access to datasets with long context (e.g., sequences of 32K tokens), presupposing substantial GPU expenditures. To address the aforementioned issues, we introduce a novel solution named Efficient and Extreme length extension for Large Language Models... | Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, Yu Zhang, Ge Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, Tiezheng Ge, Jie Fu, Wenhu Chen, Bo Zheng |  |
| 1238 |  |  [Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality](https://doi.org/10.18653/v1/2024.findings-acl.253) |  | 0 | People tend to use language to mention surprising properties of events: for example, when a banana is blue, we are more likely to mention color than when it is yellow. This fact is taken to suggest that yellowness is somehow a typical feature of bananas, and blueness is exceptional. Similar to how a yellow color is typical of bananas, there may also be genders that are typical of occupations. In this work, we explore this question using information theoretic techniques coupled with corpus... | Da Ju, Karen Ullrich, Adina Williams |  |
| 1239 |  |  [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](https://doi.org/10.18653/v1/2024.findings-acl.254) |  | 0 | Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally build a reasoning path, where LLMs either invoke tools or pick up items by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can... | Sitao Cheng, Ziyuan Zhuang, Yong Xu, Fangkai Yang, Chaoyun Zhang, Xiaoting Qin, Xiang Huang, Ling Chen, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang |  |
| 1240 |  |  [Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts](https://doi.org/10.18653/v1/2024.findings-acl.255) |  | 0 | In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of legal proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce Prediction with Explanation (PredEx), the largest expert-annotated dataset for legal judgment prediction and explanation in the Indian context, featuring over 15,000 annotations. This groundbreaking corpus significantly enhances the training and evaluation of AI models in... | Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya |  |
| 1241 |  |  [RulE: Knowledge Graph Reasoning with Rule Embedding](https://doi.org/10.18653/v1/2024.findings-acl.256) |  | 0 | Knowledge graph reasoning is an important problem for knowledge graphs. In this paper, we propose a novel and principled framework called RulE (stands for Rule Embedding) to effectively leverage logical rules to enhance KG reasoning. Unlike knowledge graph embedding methods, RulE learns rule embeddings from existing triplets and first-order rules by jointly representing entities, relations and logical rules in a unified embedding space. Based on the learned rule embeddings, a confidence score... | Xiaojuan Tang, SongChun Zhu, Yitao Liang, Muhan Zhang |  |
| 1242 |  |  [Multi-Objective Linguistic Control of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.257) |  | 0 | Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, prefer to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple linguistic complexities of LLM output by finetuning using off-the-shelf data. To this end, we propose multi-control tuning (MCTune), which includes multiple linguistic complexity values of ground-truth... | Dang Nguyen, Jiuhai Chen, Tianyi Zhou |  |
| 1243 |  |  [Evaluating the Smooth Control of Attribute Intensity in Text Generation with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.258) |  | 0 | Controlling the attribute intensity of text generation is crucial across scenarios (e.g., writing conciseness, chatting emotion, and explanation clarity). The remarkable capabilities of large language models (LLMs) have revolutionized text generation, prompting us to explore such smooth control of LLM generation. Specifically, we propose metrics to assess the range, calibration, and consistency of the generated text’s attribute intensity in response to varying control values, as well as its... | Shang Zhou, Feng Yao, Chengyu Dong, Zihan Wang, Jingbo Shang |  |
| 1244 |  |  [Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.259) |  | 0 | The recent trend of using Large Language Models (LLMs) as tool agents in real-world applications underscores the necessity for comprehensive evaluations of their capabilities, particularly in complex scenarios involving planning, creating, and using tools. However, existing benchmarks typically focus on simple synthesized queries that do not reflect real-world complexity, thereby offering limited perspectives in evaluating tool utilization. To address this issue, we present UltraTool, a novel... | Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang, Ruifeng Xu, Qun Liu |  |
| 1245 |  |  [Do Androids Know They're Only Dreaming of Electric Sheep?](https://doi.org/10.18653/v1/2024.findings-acl.260) |  | 0 | We design probes trained on the internal representations of a transformer language model to predict its hallucinatory behavior on three grounded generation tasks. To train the probes, we annotate for span-level hallucination on both sampled (organic) and manually edited (synthetic) reference outputs. Our probes are narrowly trained and we find that they are sensitive to their training domain: they generalize poorly from one task to another or from synthetic to organic hallucinations. However,... | Sky CHWang, Benjamin Van Durme, Jason Eisner, Chris Kedzie |  |
| 1246 |  |  [URG: A Unified Ranking and Generation Method for Ensembling Language Models](https://doi.org/10.18653/v1/2024.findings-acl.261) |  | 0 | Prior research endeavors of the ensemble Large Language Models (LLMs) achieved great success by employing an individual language model (LM) rank before the text generation. However, the use of an individual LM ranker faces two primary challenges: (1) The time-intensive nature of the ranking process, stemming from the comparisons between models; (2) The issue of error propagation arising from the separate ranking and generation models within the framework. In order to overcome these challenges,... | Bo Lv, Chen Tang, Yanan Zhang, Xin Liu, Ping Luo, Yue Yu |  |
| 1247 |  |  [Multi-Modal Retrieval For Large Language Model Based Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.262) |  | 0 | Retrieval is a widely adopted approach for improving language models leveraging external information. As the field moves towards multi-modal large language models, it is important to extend the pure text based methods to incorporate other modalities in retrieval as well for applications across the wide spectrum of machine learning tasks and data types. In this work, we propose multi-modal retrieval with two approaches: kNN-LM and cross-attention techniques. We demonstrate the effectiveness of... | Aditya Gourav, Jari Kolehmainen, Prashanth Gurunath Shivakumar, Yile Gu, Grant P. Strimel, Ankur Gandhe, Ariya Rastrow, Ivan Bulyko |  |
| 1248 |  |  [LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.263) |  | 0 | Low-Rank Adaptation (LoRA) provides an effective yet efficient solution for fine-tuning large language models (LLMs). The modular and plug-and-play nature of LoRA enables the integration of diverse domain-specific LoRAs to enhance the capabilities of LLMs. Previous research on exploiting multiple LoRAs either focuses on specific isolated downstream tasks or fixes the selection of LoRAs during training. However, in real-world scenarios, LLMs receive diverse prompts covering different tasks, and... | Ziyu Zhao, Leilei Gan, Guoyin Wang, Wangchunshu Zhou, Hongxia Yang, Kun Kuang, Fei Wu |  |
| 1249 |  |  [ELAD: Explanation-Guided Large Language Models Active Distillation](https://doi.org/10.18653/v1/2024.findings-acl.264) |  | 0 | The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences. Traditional distillation methods, which transfer the capabilities of LLMs to smaller models, often fail to determine whether the knowledge has been sufficiently transferred, potentially resulting in high costs or incomplete distillation. In this paper, we propose an Explanation-Guided LLMs Active Distillation (ELAD) framework that... | Yifei Zhang, Bo Pan, Chen Ling, Yuntong Hu, Liang Zhao |  |
| 1250 |  |  [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](https://doi.org/10.18653/v1/2024.findings-acl.265) |  | 0 | Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent research shows that, despite limits in their intended use, people prompt LLMs in many different languages.Therefore, in this paper, we investigate the basic multilingual capabilities of... | Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher |  |
| 1251 |  |  [Semantics or spelling? Probing contextual word embeddings with orthographic noise](https://doi.org/10.18653/v1/2024.findings-acl.266) |  | 0 | Pretrained language model (PLM) hidden states are frequently employed as contextual word embeddings (CWE): high-dimensional representations that encode semantic information given linguistic context. Across many areas of computational linguistics research, similarity between CWEs is interpreted as semantic similarity. However, it remains unclear exactly what information is encoded in PLM hidden states. We investigate this practice by probing PLM representations using minimal orthographic noise.... | Jacob Matthews, John Starr, Marten van Schijndel |  |
| 1252 |  |  [The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)](https://doi.org/10.18653/v1/2024.findings-acl.267) |  | 0 | Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model generation with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. To this end, we conduct extensive empirical studies with novel attack methods,... | Shenglai Zeng, Jiankun Zhang, Pengfei He, Yiding Liu, Yue Xing, Han Xu, Jie Ren, Yi Chang, Shuaiqiang Wang, Dawei Yin, Jiliang Tang |  |
| 1253 |  |  [EmpathicStories++: A Multimodal Dataset for Empathy Towards Personal Experiences](https://doi.org/10.18653/v1/2024.findings-acl.268) |  | 0 | Modeling empathy is a complex endeavor that is rooted in interpersonal and experiential dimensions of human interaction, and remains an open problem within AI. Existing empathy datasets fall short in capturing the richness of empathy responses, often being confined to in-lab or acted scenarios, lacking longitudinal data, and missing self-reported labels. We introduce a new multimodal dataset for empathy during personal experience sharing: the EmpathicStories++ dataset containing 53 hours of... | Jocelyn Shen, Yubin Kim, Mohit Hulse, Wazeer Zulfikar, Sharifa Alghowinem, Cynthia Breazeal, Hae Won Park |  |
| 1254 |  |  [MRL Parsing Without Tears: The Case of Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.269) |  | 0 | Syntactic parsing remains a critical tool for relation extraction and information extraction, especially in resource-scarce languages where LLMs are lacking. Yet in morphologically rich languages (MRLs), where parsers need to identify multiple lexical units in each token, existing systems suffer in latency and setup complexity. Some use a pipeline to peel away the layers: first segmentation, then morphology tagging, and then syntax parsing; however, errors in earlier layers are then propagated... | Shaltiel Shmidman, Avi Shmidman, Moshe Koppel, Reut Tsarfaty |  |
| 1255 |  |  [SyntaxShap: Syntax-aware Explainability Method for Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.270) |  | 0 | To harness the power of large language models in safety-critical domains, we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data. This paper introduces \*SyntaxShap\*, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented... | Kenza Amara, Rita Sevastjanova, Mennatallah ElAssady |  |
| 1256 |  |  [Automated Detection and Analysis of Data Practices Using A Real-World Corpus](https://doi.org/10.18653/v1/2024.findings-acl.271) |  | 0 | Privacy policies are crucial for informing users about data practices, yet their length and complexity often deter users from reading them. In this paper, we propose an automated approach to identify and visualize data practices within privacy policies at different levels of detail. Leveraging crowd-sourced annotations from the ToS;DR platform, we experiment with various methods to match policy excerpts with predefined data practice descriptions. We further conduct a case study to evaluate our... | Mukund Srinath, Pranav Narayanan Venkit, Maria Badillo, Florian Schaub, C. Lee Giles, Shomir Wilson |  |
| 1257 |  |  [Enhancing Hyperbolic Knowledge Graph Embeddings via Lorentz Transformations](https://doi.org/10.18653/v1/2024.findings-acl.272) |  | 0 | Knowledge Graph Embedding (KGE) is a powerful technique for predicting missing links in Knowledge Graphs (KGs) by learning the entities and relations. Hyperbolic space has emerged as a promising embedding space for KGs due to its ability to represent hierarchical data. Nevertheless, most existing hyperbolic KGE methods rely on tangent approximation and are not fully hyperbolic, resulting in distortions and inaccuracies. To overcome this limitation, we propose LorentzKG, a fully hyperbolic KGE... | Xiran Fan, Minghua Xu, Huiyuan Chen, Yuzhong Chen, Mahashweta Das, Hao Yang |  |
| 1258 |  |  [Tell Me What's Next: Textual Foresight for Generic UI Representations](https://doi.org/10.18653/v1/2024.findings-acl.273) |  | 0 | Mobile app user interfaces (UIs) are rich with action, text, structure, and image content that can be utilized to learn generic UI representations for tasks like automating user commands, summarizing content, and evaluating the accessibility of user interfaces. Prior work has learned strong visual representations with local or global captioning losses, but fails to retain both granularities.To combat this, we propose Textual Foresight, a novel pretraining objective for learning UI screen... | Andrea Burns, Kate Saenko, Bryan A. Plummer |  |
| 1259 |  |  [Probing the Uniquely Identifiable Linguistic Patterns of Conversational AI Agents](https://doi.org/10.18653/v1/2024.findings-acl.274) |  | 0 | The proliferation of Conversational AI agents (CAAs) has emphasised the need to distinguish between human and machine-generated texts, with implications spanning digital forensics and cybersecurity. While prior research primarily focussed on distinguishing human from machine-generated text, our study takes a more refined approach by analysing different CAAs. We construct linguistic profiles for five CAAs, aiming to identify Uniquely Identifiable Linguistic Patterns (UILPs) for each model using... | Iqra Zahid, Tharindu Madusanka, Riza BatistaNavarro, Youcheng Sun |  |
| 1260 |  |  [The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.275) |  | 0 | Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or “prompting,” practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work,... | Abel Salinas, Fred Morstatter |  |
| 1261 |  |  [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](https://doi.org/10.18653/v1/2024.findings-acl.276) |  | 0 | In recent years, few-shot and zero-shot learning, which learn to predict labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat frequent-shot (freq-shot; labels with abundant instances), few-shot, and zero-shot learning as distinct challenges, optimizing systems for just one of these scenarios. Yet, in real-world settings, label occurrences vary greatly. Some of them might appear thousands of times, while others might only appear... | Hanzi Xu, Muhao Chen, Lifu Huang, Slobodan Vucetic, Wenpeng Yin |  |
| 1262 |  |  [SPIN: Sparsifying and Integrating Internal Neurons in Large Language Models for Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.277) |  | 0 | Among the many tasks that Large Language Models (LLMs) have revolutionized is text classification. Current text classification paradigms, however, rely solely on the output of the final layer in the LLM, with the rich information contained in internal neurons largely untapped. In this study, we present SPIN: a model-agnostic framework that sparsifies and integrates internal neurons of intermediate layers of LLMs for text classification. Specifically, SPIN sparsifies internal neurons by linear... | Difan Jiao, Yilun Liu, Zhenwei Tang, Daniel Matter, Jürgen Pfeffer, Ashton Anderson |  |
| 1263 |  |  [Decomposing Co-occurrence Matrices into Interpretable Components as Formal Concepts](https://doi.org/10.18653/v1/2024.findings-acl.278) |  | 0 | This study addresses the interpretability of word representations through an investigation of a count-based co-occurrence matrix. Employing the mathematical methodology of Formal Concept Analysis, we reveal an underlying structure that is amenable to human interpretation. Furthermore, we unveil the emergence of hierarchical and geometrical structures within word vectors as consequences of word usage. Our experiments on the PPMI matrix demonstrate that the formal concepts that we identified... | Akihiro Maeda, Takuma Torii, Shohei Hidaka |  |
| 1264 |  |  [Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification](https://doi.org/10.18653/v1/2024.findings-acl.279) |  | 0 | Radiology reports are highly technical documents aimed primarily at doctor-doctor communication. There has been an increasing interest in sharing those reports with patients, necessitating providing them patient-friendly simplifications of the original reports. This study explores the suitability of large language models in automatically generating those simplifications. We examine the usefulness of chain-of-thought and self-correction prompting mechanisms in this domain. We also propose a new... | Ziyu Yang, Santhosh Cherian, Slobodan Vucetic |  |
| 1265 |  |  [Planning First, Question Second: An LLM-Guided Method for Controllable Question Generation](https://doi.org/10.18653/v1/2024.findings-acl.280) |  | 0 | In the field of education, for better assessment of students’ abilities, generated questions often need to meet experts’ requirements, indicating the need for controllable question generation (CQG). However, current CQG methods mainly focus on difficulty control, neglecting the control of question content and assessed abilities, which are also crucial in educational QG. In this paper, we propose an LLM-guided method PFQS (for Planning First, Question Second), which utilizes Llama 2 to generate... | Kunze Li, Yu Zhang |  |
| 1266 |  |  [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://doi.org/10.18653/v1/2024.findings-acl.281) |  | 0 | Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn’t previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if... | Yanming Liu, Xinyue Peng, Xuhong Zhang, Weihao Liu, Jianwei Yin, Jiannan Cao, Tianyu Du |  |
| 1267 |  |  [MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model](https://doi.org/10.18653/v1/2024.findings-acl.282) |  | 0 | Large Language Models (LLMs) often struggle with hallucinations and outdated information. To address this, Information Retrieval (IR) systems can be employed to augment LLMs with up-to-date knowledge. However, existing IR techniques contain deficiencies, posing a performance bottleneck. Given the extensive array of IR systems, combining diverse approaches presents a viable strategy. Nevertheless, prior attempts have yielded restricted efficacy. In this work, we propose an approach that... | Danupat Khamnuansin, Tawunrat Chalothorn, Ekapol Chuangsuwanich |  |
| 1268 |  |  [Chain-of-Question: A Progressive Question Decomposition Approach for Complex Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.283) |  | 0 | Complex KBQA leverages the knowledge base (KB) to answer complex natural questions involving complicated semantics like multi-hop reasoning. Existing methods involve a question decomposition process, i.e., breaking a complex question into several simpler sub-questions, to assist obtaining logical forms for querying the KB. However, existing question decomposition process derives all sub-questions directly according to the original question, resulting in limitations when one sub-question relies... | Yixing Peng, Quan Wang, Licheng Zhang, Yi Liu, Zhendong Mao |  |
| 1269 |  |  [Instruction Tuning with Retrieval-based Examples Ranking for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.284) |  | 0 | Aspect-based sentiment analysis (ABSA) identifies sentiment information related to specific aspects and provides deeper market insights to businesses and organizations. With the emergence of large language models (LMs), recent studies have proposed using fixed examples for instruction tuning to reformulate ABSA as a generation task. However, the performance is sensitive to the selection of in-context examples; several retrieval methods are based on surface similarity and are independent of the... | Guangmin Zheng, Jin Wang, LiangChih Yu, Xuejie Zhang |  |
| 1270 |  |  [Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation](https://doi.org/10.18653/v1/2024.findings-acl.285) |  | 0 | Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change. Simulating the response of the public and forecasting the potential impact has become increasingly important. However, existing methods for simulating such phenomena encounter challenges concerning their efficacy and efficiency in capturing the behaviors of social movement participants. In this paper, we introduce a hybrid framework for social media user simulation, wherein... | Xinyi Mou, Zhongyu Wei, Xuanjing Huang |  |
| 1271 |  |  [Incorporating Syntax and Lexical Knowledge to Multilingual Sentiment Classification on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.286) |  | 0 | This paper exploits a sentiment extractor supported by syntactic and lexical resources to enhance multilingual sentiment classification solved through the generative approach, without retraining LLMs. By adding external information of words and phrases that have positive/negative polarities, the multilingual sentiment classification error was reduced by up to 33 points, and the combination of two approaches performed best especially in high-performing pairs of LLMs and languages. | Hiroshi Kanayama, Yang Zhao, Ran Iwamoto, Takuya Ohko |  |
| 1272 |  |  [Locating and Extracting Relational Concepts in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.287) |  | 0 | Relational concepts are indeed foundational to the structure of knowledge representation, as they facilitate the association between various entity concepts, allowing us to express and comprehend complex world knowledge.By expressing relational concepts in natural language prompts, people can effortlessly interact with large language models (LLMs) and recall desired factual knowledge. However, the process of knowledge recall lacks interpretability, and representations of relational concepts... | Zijian Wang, Britney White, Chang Xu |  |
| 1273 |  |  [Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.288) |  | 0 | Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their superiority in terms of factuality, they do not consistently outperform the original retrieval-free Language Models (LMs). Our experiments reveal that this example-level performance inconsistency exists not only between retrieval-augmented and retrieval-free LM but also among different retrievers. To understand this phenomenon, we investigate the degeneration behavior of RALMs and theoretically decompose it into four... | Mingda Li, Xinyu Li, Yifan Chen, Wenfeng Xuan, Weinan Zhang |  |
| 1274 |  |  [SenticVec: Toward Robust and Human-Centric Neurosymbolic Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.289) |  | 0 | The success of state-of-the-art Natural Language Processing (NLP) systems heavily depends on deep neural networks, which excel in various tasks through strong data fitting and latent feature modeling abilities. However, certain challenges linked to deep neural networks and supervised deep learning deserve considerations, e.g., extensive computing resources, knowledge forgetting, etc. Previous research attempted to tackle these challenges individually through irrelative techniques. However, they... | Xulang Zhang, Rui Mao, Erik Cambria |  |
| 1275 |  |  [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.290) |  | 0 | Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs’ trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs’ trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that... | Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao |  |
| 1276 |  |  [Language Models can Evaluate Themselves via Probability Discrepancy](https://doi.org/10.18653/v1/2024.findings-acl.291) |  | 0 | In this paper, we begin by illustrating that, when presented with a query, Large Language Models (LLMs) capable of providing accurate responses tend to exhibit a more uniform probability distribution compared to their less proficient counterparts. Building upon this observation, we introduce a novel self-assessment criterion termed ProbDiff for evaluating the performance of diverse LLMs. This method eliminates the need for training an additional evaluation model or relying on external... | Tingyu Xia, Bowen Yu, Yuan Wu, Yi Chang, Chang Zhou |  |
| 1277 |  |  [Evaluating the Validity of Word-level Adversarial Attacks with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.292) |  | 0 | Deep neural networks exhibit vulnerability to word-level adversarial attacks in natural language processing. Most of these attack methods adopt synonymous substitutions to perturb original samples for crafting adversarial examples while attempting to maintain semantic consistency with the originals. Some of them claim that they could achieve over 90% attack success rate, thereby raising serious safety concerns. However, our investigation reveals that many purportedly successful adversarial... | Huichi Zhou, Zhaoyang Wang, Hongtao Wang, Dongping Chen, Wenhan Mu, Fangyuan Zhang |  |
| 1278 |  |  [On the Language Encoder of Contrastive Cross-modal Models](https://doi.org/10.18653/v1/2024.findings-acl.293) |  | 0 | Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder – the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found... | Mengjie Zhao, Junya Ono, Zhi Zhong, ChiehHsin Lai, Yuhta Takida, Naoki Murata, WeiHsiang Liao, Takashi Shibuya, Hiromi Wakaki, Yuki Mitsufuji |  |
| 1279 |  |  [Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World](https://doi.org/10.18653/v1/2024.findings-acl.294) |  | 0 | Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration with humans or other LLMs in equal roles, which involves intent understanding, task coordination, and communication. To test LLM’s ability to collaborate, we design a blocks-world environment, where two... | Guande Wu, Chen Zhao, Cláudio T. Silva, He He |  |
| 1280 |  |  [Anchor-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.295) |  | 0 | Large language models (LLMs) predominantly employ decoder-only transformer architectures, necessitating the retention of keys/values information for historical tokens to provide contextual information and avoid redundant computation. However, the substantial size and parameter volume of these LLMs require massive GPU memory. This memory demand increases with the length of the input text, leading to an urgent need for more efficient methods of information storage and processing. This study... | Jianhui Pang, Fanghua Ye, Derek F. Wong, Xin He, Wanshun Chen, Longyue Wang |  |
| 1281 |  |  [MLeVLM: Improve Multi-level Progressive Capabilities based on Multimodal Large Language Model for Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.296) |  | 0 | Medical visual question answering (MVQA) requires in-depth understanding of medical images and questions to provide reliable answers. We summarize multi-level progressive capabilities that models need to focus on in MVQA: recognition, details, diagnosis, knowledge, and reasoning. Existing MVQA models tend to ignore the above capabilities due to unspecific data and plain architecture. To address these issues, this paper proposes Multi-level Visual Language Model (MLeVLM) for MVQA. On the data... | Dexuan Xu, Yanyuan Chen, Jieyi Wang, Yue Huang, Hanpin Wang, Zhi Jin, Hongxing Wang, Weihua Yue, Jing He, Hang Li, Yu Huang |  |
| 1282 |  |  [Disentangling Length from Quality in Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.297) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has been a crucial component in the recent success of Large Language Models. However, RLHF is know to exploit biases in human preferences, such as verbosity. A well-formatted and eloquent answer is often more highly rated by users, even when it is less helpful and objective. A number of approaches have been developed to control those biases in the classical RLHF literature, but the problem remains relatively under-explored for Direct Alignment... | Ryan Park, Rafael Rafailov, Stefano Ermon, Chelsea Finn |  |
| 1283 |  |  [MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.298) |  | 0 | Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity knowledge largely unexplored. This gap presents a notable challenge, as FG entity recognition is pivotal for the practical deployment and effectiveness of MLLMs in diverse real-world scenarios. To bridge... | Jiaqi Li, Miaozeng Du, Chuanyi Zhang, Yongrui Chen, Nan Hu, Guilin Qi, Haiyun Jiang, Siyuan Cheng, Bozhong Tian |  |
| 1284 |  |  [Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise: A Case Study on Chinese Legal Domain](https://doi.org/10.18653/v1/2024.findings-acl.299) |  | 0 | While large language models (LLMs) like GPT-4 have recently demonstrated astonishing zero-shot capabilities in general domain tasks, they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the absence of training data that encompasses such a specific domain, preventing GPT-4 from acquiring in-domain knowledge. A pressing challenge is that it’s not plausible to continue training LLMs of the... | Zhen Wan, Yating Zhang, Yexiang Wang, Fei Cheng, Sadao Kurohashi |  |
| 1285 |  |  [MemeMQA: Multimodal Question Answering for Memes via Rationale-Based Inferencing](https://doi.org/10.18653/v1/2024.findings-acl.300) |  | 0 | Memes have evolved as a prevalent medium for diverse communication, ranging from humour to propaganda. With the rising popularity of image-focused content, there is a growing need to explore its potential harm from different aspects. Previous studies have analyzed memes in closed settings - detecting harm, applying semantic labels, and offering natural language explanations. To extend this research, we introduce MemeMQA, a multimodal question-answering framework aiming to solicit accurate... | Siddhant Agarwal, Shivam Sharma, Preslav Nakov, Tanmoy Chakraborty |  |
| 1286 |  |  [Improving Attributed Text Generation of Large Language Models via Preference Learning](https://doi.org/10.18653/v1/2024.findings-acl.301) |  | 0 | Large language models have been widely adopted in natural language processing, yet they face the challenge of generating unreliable content. Recent works aim to reduce misinformation and hallucinations by resorting to attribution as a means to provide evidence (i.e., citations). However, current attribution methods usually focus on the retrieval stage and automatic evaluation that neglect mirroring the citation mechanisms in human scholarly writing to bolster credibility. In this paper, we... | Dongfang Li, Zetian Sun, Baotian Hu, Zhenyu Liu, Xinshuo Hu, Xuebo Liu, Min Zhang |  |
| 1287 |  |  [KOMBO: Korean Character Representations Based on the Combination Rules of Subcharacters](https://doi.org/10.18653/v1/2024.findings-acl.302) |  | 0 | The Korean writing system, Hangeul, has a unique character representation rigidly following the invention principles recorded in Hunminjeongeum. However, existing pre-trained language models (PLMs) for Korean have overlooked these principles. In this paper, we introduce a novel framework for Korean PLMs called KOMBO, which firstly brings the invention principles of Hangeul to represent character. Our proposed method, KOMBO, exhibits notable experimental proficiency across diverse NLP tasks. In... | SungHo Kim, Juhyeong Park, Yeachan Kim, SangKeun Lee |  |
| 1288 |  |  [Tree-Planted Transformers: Unidirectional Transformer Language Models with Implicit Syntactic Supervision](https://doi.org/10.18653/v1/2024.findings-acl.303) |  | 0 | Syntactic Language Models (SLMs) can be trained efficiently to reach relatively high performance; however, they have trouble with inference efficiency due to the explicit generation of syntactic structures. In this paper, we propose a new method dubbed tree-planting: instead of explicitly generating syntactic structures, we “plant” trees into attention weights of unidirectional Transformer LMs to implicitly reflect syntactic structures of natural language. Specifically, unidirectional... | Ryo Yoshida, Taiga Someya, Yohei Oseki |  |
| 1289 |  |  [Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues](https://doi.org/10.18653/v1/2024.findings-acl.304) |  | 0 | With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM’s defensive strategies and obtain... | Zhiyuan Chang, Mingyang Li, Yi Liu, Junjie Wang, Qing Wang, Yang Liu |  |
| 1290 |  |  [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.305) |  | 0 | The development of large language models tailored for handling patients’ clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations.To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature.We then use these synthetic notes to train our specialized clinical large language model, Asclepius.While Asclepius is trained on synthetic... | Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im, Eunbyeol Cho, Seongsu Bae, Jungwoo Oh, Gyubok Lee, Jong Hak Moon, Seng Chan You, Seungjin Baek, Chang Hoon Han, Yoon Bin Jung, Yohan Jo, Edward Choi |  |
| 1291 |  |  [Extending Context Window of Large Language Models via Semantic Compression](https://doi.org/10.18653/v1/2024.findings-acl.306) |  | 0 | Transformer based Large Language Models (LLMs) often impose limitations on the length of the text input to ensure the generation of fluent and relevant responses due to the quadratic complexity. These constraints restrict their applicability in long text scenarios. In this paper, we propose a novel semantic compression method that enables generalization to texts that are 6-8 times longer without incurring significant computational costs or requiring fine-tuning. Our proposed framework draws... | Weizhi Fei, Xueyan Niu, Pingyi Zhou, Lu Hou, Bo Bai, Lei Deng, Wei Han |  |
| 1292 |  |  [Plausible Extractive Rationalization through Semi-Supervised Entailment Signal](https://doi.org/10.18653/v1/2024.findings-acl.307) |  | 0 | The increasing use of complex and opaque black box models requires the adoption of interpretable measures, one such option is extractive rationalizing models, which serve as a more interpretable alternative. These models, also known as Explain-Then-Predict models, employ an explainer model to extract rationales and subsequently condition the predictor with the extracted information. Their primary objective is to provide precise and faithful explanations, represented by the extracted rationales.... | Wei Jie Yeo, Ranjan Satapathy, Erik Cambria |  |
| 1293 |  |  [Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.308) |  | 0 | Building a reliable visual question answering (VQA) system across different languages is a challenging problem, primarily due to the lack of abundant samples for training. To address this challenge, recent studies have employed machine translation systems for the cross-lingual VQA task. This involves translating the evaluation samples into a source language (usually English) and using monolingual models (i.e., translate-test). However, our analysis reveals that translated texts contain unique... | ChaeHun Park, Koanho Lee, Hyesu Lim, Jaeseok Kim, Junmo Park, YuJung Heo, DuSeong Chang, Jaegul Choo |  |
| 1294 |  |  [Scented-EAE: Stage-Customized Entity Type Embedding for Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.309) |  | 0 | Existing methods for incorporating entities into EAE rely on prompts or NER. They typically fail to explicitly explore the role of entity types, which results in shallow argument comprehension and often encounter three issues: (1) weak semantic associations due to missing role-entity correspondence cues; (2) compromised semantic integrity from abandoning context after recognizing entities regardless of their types; (3) one-sided semantic understanding relying solely on argument role semantics.... | Yu Yang, Jinyu Guo, Kai Shuang, Chenrui Mao |  |
| 1295 |  |  [Fast Randomized Low-Rank Adaptation of Pre-trained Language Models with PAC Regularization](https://doi.org/10.18653/v1/2024.findings-acl.310) |  | 0 | Low-rank adaptation (LoRA) achieves parameter efficient fine-tuning for large language models (LLMs) by decomposing the model weight update into a pair of low-rank projection matrices. Yet, the memory overhead restricts it to scale up when the model size increases. We propose Randomized LoRA (RLoRA) which adopts Randomized Walsh-Hadamard Transform to achieve significant reduction in the size of trainable parameters compared to LoRA. At the same time, it allows a PAC-Bayes regularizer to be... | Zijian Lei, Dong Qian, William K. Cheung |  |
| 1296 |  |  [SDA: Semantic Discrepancy Alignment for Text-conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.311) |  | 0 | In the realm of text-conditioned image retrieval, models utilize a query composed of a reference image and modification text to retrieve corresponding images. Despite its significance, this task is fraught with challenges, including small-scale datasets due to labeling costs and the complexity of attributes in modification texts. These challenges often result in models learning a generalized representation of the query, thereby missing the semantic correlations of image and text attributes.In... | Yuchen Yang, Yu Wang, Yanfeng Wang |  |
| 1297 |  |  [Se²: Sequential Example Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.312) |  | 0 | The remarkable capability of large language models(LLMs) for in-context learning(ICL) needs to be activated by demonstration examples. Prior work has extensively explored the selection of examples for ICL, predominantly following the “select then organize” paradigm, such approaches often neglect the internal relationships between examples and exist an inconsistency between the training and inference. In this paper, we formulate the problem as a Sequential Selection problem and introduce Se2, a... | Haoyu Liu, Jianfeng Liu, Shaohan Huang, Yuefeng Zhan, Hao Sun, Weiwei Deng, Furu Wei, Qi Zhang |  |
| 1298 |  |  [Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding](https://doi.org/10.18653/v1/2024.findings-acl.313) |  | 0 | This research aims to accelerate the inference speed of large language models (LLMs) with billions of parameters. We propose Smart Parallel Auto-Correct dEcoding (SPACE), an approach designed for achieving lossless acceleration of LLMs. By integrating semi-autoregressive inference and speculative decoding capabilities, SPACE uniquely enables autoregressive LLMs to parallelize token generation and verification. This is realized through a specialized semi-autoregressive supervised fine-tuning... | Hanling Yi, Feng Lin, Hongbin Li, Peiyang Ning, Xiaotian Yu, Rong Xiao |  |
| 1299 |  |  [StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.314) |  | 0 | Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggle to discern whether a model genuinely possesses the required capabilities or merely memorizes/guesses the answers to specific questions. To this end, this paper proposes a novel evaluation framework referred to as StructEval. Starting from an atomic test objective, StructEval deepens and broadens the evaluation... | Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun |  |
| 1300 |  |  [Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching](https://doi.org/10.18653/v1/2024.findings-acl.315) |  | 0 | Protecting privacy leakage in large language models remains a paramount challenge. In this paper, we reveal Privacy Seesaw in LLM privacy safeguarding, a phenomenon where measures to secure specific private information inadvertently heighten exposure risks for other privacy. Through comprehensive analysis, we identify the amount of targeted privacy data and the volume of edited privacy neurons as the two central triggers to this issue. To mitigate privacy seesaw, we propose Augmented Privacy... | Xinwei Wu, Weilong Dong, Shaoyang Xu, Deyi Xiong |  |
| 1301 |  |  [Which Information Matters? Dissecting Human-written Multi-document Summaries with Partial Information Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.316) |  | 0 | Understanding the nature of high-quality summaries is crucial to further improve the performance of multi-document summarization. We propose an approach to characterize human-written summaries using partial information decomposition, which decomposes the mutual information provided by all source documents into union, redundancy, synergy, and unique information. Our empirical analysis on different MDS datasets shows that there is a direct dependency between the number of sources and their... | Laura Mascarell, Yan L'Homme, Majed El Helou |  |
| 1302 |  |  [BadActs: A Universal Backdoor Defense in the Activation Space](https://doi.org/10.18653/v1/2024.findings-acl.317) |  | 0 | Backdoor attacks pose an increasingly severe security threat to Deep Neural Networks (DNNs) during their development stage. In response, backdoor sample purification has emerged as a promising defense mechanism, aiming to eliminate backdoor triggers while preserving the integrity of the clean content in the samples. However, existing approaches have been predominantly focused on the word space, which are ineffective against feature-space triggers and significantly impair performance on clean... | Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu |  |
| 1303 |  |  [ReactXT: Understanding Molecular "Reaction-ship" via Reaction-Contextualized Molecule-Text Pretraining](https://doi.org/10.18653/v1/2024.findings-acl.318) |  | 0 | Molecule-text modeling, which aims to facilitate molecule-relevant tasks with a textual interface and textual knowledge, is an emerging research direction. Beyond single molecules, studying reaction-text modeling holds promise for helping the synthesis of new materials and drugs. However, previous works mostly neglect reaction-text modeling: they primarily focus on modeling individual molecule-text pairs or learning chemical reactions without texts in context. Additionally, one key task of... | Zhiyuan Liu, Yaorui Shi, An Zhang, Sihang Li, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, TatSeng Chua |  |
| 1304 |  |  [Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.319) |  | 0 | Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training (MMCAP) approach for generative Med-VQA, leveraging a knowledge graph sourced from medical image-caption datasets and the Unified Medical Language System. MMCAP advances the fusion of visual and textual medical knowledge via a graph attention network and a... | Quan Yan, Junwen Duan, Jianxin Wang |  |
| 1305 |  |  [Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques](https://doi.org/10.18653/v1/2024.findings-acl.320) |  | 0 | Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss functions that explicitly account for the ordinal nature of labels. However, with the advent of Pre-trained Language Models (PLMs), it became possible to tackle ordinality through the implicit semantics... | Siva Rajesh Kasa, Aniket Goel, Karan Gupta, Sumegh Roychowdhury, Pattisapu Priyatam, Anish Bhanushali, Prasanna Srinivasa Murthy |  |
| 1306 |  |  [Evaluating Large Language Models on Wikipedia-Style Survey Generation](https://doi.org/10.18653/v1/2024.findings-acl.321) |  | 0 | Educational materials such as survey articles in specialized fields like computer science traditionally require tremendous expert inputs and are therefore expensive to create and update. Recently, Large Language Models (LLMs) have achieved significant success across various general tasks. However, their effectiveness and limitations in the education domain are yet to be fully explored. In this work, we examine the proficiency of LLMs in generating succinct survey articles specific to the niche... | Fan Gao, Hang Jiang, Rui Yang, Qingcheng Zeng, Jinghui Lu, Moritz Blum, Tianwei She, Yuang Jiang, Irene Li |  |
| 1307 |  |  [The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse](https://doi.org/10.18653/v1/2024.findings-acl.322) |  | 0 | Although model editing has shown promise in revising knowledge in Large Language Models (LLMs), its impact on the inherent capabilities of LLMs is often overlooked. In this work, we reveal a critical phenomenon: even a single edit can trigger model collapse, manifesting as significant performance degradation in various benchmark tasks. However, benchmarking LLMs after each edit, while necessary to prevent such collapses, is impractically time-consuming and resource-intensive. To mitigate this,... | Wanli Yang, Fei Sun, Xinyu Ma, Xun Liu, Dawei Yin, Xueqi Cheng |  |
| 1308 |  |  [Can We Continually Edit Language Models? On the Knowledge Attenuation in Sequential Model Editing](https://doi.org/10.18653/v1/2024.findings-acl.323) |  | 0 | Model editing has become a promising method for precisely and effectively updating knowledge in language models. In this paper, we investigate knowledge attenuation, in which the retention of updated knowledge within the language model decreases as the number of edits increases after sequential editing. Through empirical study, we discovered that existing editing methods generally suffer from knowledge attenuation. We attribute this phenomenon to two aspects: (1) redundant parameters... | Qi Li, Xiaowen Chu |  |
| 1309 |  |  [Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation](https://doi.org/10.18653/v1/2024.findings-acl.324) |  | 0 | Large Language Models (LLMs) driven by In-Context Learning (ICL) have significantly improved the performance of text-to-SQL. Previous methods generally employ a two-stage reasoning framework, namely 1) schema linking and 2) logical synthesis, making the framework not only effective but also interpretable. Despite these advancements, the inherent bad nature of the generalization of LLMs often results in hallucinations, which limits the full potential of LLMs. In this work, we first identify and... | Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo, Chenhao Ma, Reynold Cheng |  |
| 1310 |  |  [Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.325) |  | 0 |  | Zhibin Lan, Liqiang Niu, Fandong Meng, Jie Zhou, Min Zhang, Jinsong Su |  |
| 1311 |  |  [StatBot.Swiss: Bilingual Open Data Exploration in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.326) |  | 0 | The potential for improvements brought by Large Language Models (LLMs) in Text-to-SQL systems is mostly assessed on monolingual English datasets. However, LLMs’ performance for other languages remains vastly unexplored. In this work, we release the StatBot.Swiss dataset, the first bilingual benchmark for evaluating Text-to-SQL systems based on real-world applications. The StatBot.Swiss dataset contains 455 natural language/SQL-pairs over 35 big databases with varying level of complexity for... | Farhad Nooralahzadeh, Yi Zhang, Ellery Smith, Sabine Maennel, Cyril MattheyDoret, Raphaël de Fondeville, Kurt Stockinger |  |
| 1312 |  |  [Subtle Signatures, Strong Shields: Advancing Robust and Imperceptible Watermarking in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.327) |  | 0 | The widespread adoption of Large Language Models (LLMs) has led to an increase in AI-generated text on the Internet, presenting a crucial challenge to differentiate AI-created content from human-written text. This challenge is critical to prevent issues of authenticity, trust, and potential copyright violations. Current research focuses on watermarking LLM-generated text, but traditional techniques struggle to balance robustness with text quality. We introduce a novel watermarking approach,... | Yubing Ren, Ping Guo, Yanan Cao, Wei Ma |  |
| 1313 |  |  [Thinking about how to extract: Energizing LLMs' emergence capabilities for document-level event argument extraction](https://doi.org/10.18653/v1/2024.findings-acl.328) |  | 0 | There are two key challenges remaining for the document-level event argument extraction (D-EAE) tasks: key feature forgetting and cross-event argument confusion. The emergence capability of large language models (LLMs) holds promise for solving the above two challenges. In this paper, we propose a document-level event argument extraction method based on guided summarization and reasoning (EAESR), which leverages the emergence capabilities of LLMs to highlight key event information and to... | Kai Shuang, Zhouji Zhouji, Qiwei Wang, Jinyu Guo |  |
| 1314 |  |  [Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning](https://doi.org/10.18653/v1/2024.findings-acl.329) |  | 0 | Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the burden of annotation, but meanwhile suffers from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, we argue that these teacher-student methods achieve limited performance because the poor calibration of the teacher network produces incorrectly pseudo-labeled samples, leading to error propagation.... | Shuzheng Si, Helan Hu, Haozhe Zhao, Shuang Zeng, Kaikai An, Zefan Cai, Baobao Chang |  |
| 1315 |  |  [Predicting Narratives of Climate Obstruction in Social Media Advertising](https://doi.org/10.18653/v1/2024.findings-acl.330) |  | 0 | Social media advertising offers a platform for fossil fuel value chain companies and their agents to reinforce their narratives, often emphasizing economic, labor market, and energy security benefits to promote oil and gas policy and products. Whether such narratives can be detected automatically and the extent to which the cost of human annotation can be reduced is our research question. We introduce a task of classifying narratives into seven categories, based on existing definitions and... | Harri Rowlands, Gaku Morio, Dylan Tanner, Christopher D. Manning |  |
| 1316 |  |  [SSS: Editing Factual Knowledge in Language Models towards Semantic Sparse Space](https://doi.org/10.18653/v1/2024.findings-acl.331) |  | 0 | Language Models (LMs) acquire factual knowledge during pre-training and store it in the parameters, which can be valuable for downstream tasks. As world evolves, some facts may be incorrectly induced or become obsolete over time. Various model editing methods have been proposed to modify specific examples in LMs. However, existing training-based methods still suffer from sub-optimal locality, where irrelevant neighborhood examples can be adversely influenced. Model’s gradients are still... | Huazheng Wang, Haifeng Sun, Jingyu Wang, Qi Qi, Zixuan Xia, Menghao Zhang, Jianxin Liao |  |
| 1317 |  |  [GeoHard: Towards Measuring Class-wise Hardness through Modelling Class Semantics](https://doi.org/10.18653/v1/2024.findings-acl.332) |  | 0 |  | Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl |  |
| 1318 |  |  [Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.333) |  | 0 | In this paper, we investigate the phenomena of “selection biases” in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option order and token usage, which significantly impact LLMs’ decision-making processes. We also quantify the impact of these biases through an extensive empirical analysis across multiple models and tasks. Furthermore, we propose mitigation strategies to enhance... | ShengLun Wei, ChengKuang Wu, HenHsen Huang, HsinHsi Chen |  |
| 1319 |  |  [ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic](https://doi.org/10.18653/v1/2024.findings-acl.334) |  | 0 | The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to the limited availability of relevant datasets. To bridge this gap, we present ArabicMMLU, the first multi-task language understanding benchmark for the Arabic language, sourced from school exams across... | Fajri Koto, Haonan Li, Sara Shatnawi, Jad Doughman, Abdelrahman Boda Sadallah, Aisha Alraeesi, Khalid Almubarak, Zaid Alyafeai, Neha Sengupta, Shady Shehata, Nizar Habash, Preslav Nakov, Timothy Baldwin |  |
| 1320 |  |  [On the Relationship Between RNN Hidden-State Vectors and Semantic Structures](https://doi.org/10.18653/v1/2024.findings-acl.335) |  | 0 | We examine the assumption that hidden-state vectors of recurrent neural networks (RNNs) tend to form clusters of semantically similar vectors, which we dub the clustering hypothesis. While this hypothesis has been assumed in RNN analyses in recent years, its validity has not been studied thoroughly on modern RNN architectures. We first consider RNNs that were trained to recognize regular languages. This enables us to draw on perfect ground-truth automata in our evaluation, against which we can... | Edi Muskardin, Martin Tappler, Ingo Pill, Bernhard K. Aichernig, Thomas Pock |  |
| 1321 |  |  [XMC-Agent : Dynamic Navigation over Scalable Hierarchical Index for Incremental Extreme Multi-label Classification](https://doi.org/10.18653/v1/2024.findings-acl.336) |  | 0 | The eXtreme Multi-label Classification (XMC) aims at accurately assigning large-scale labels to instances, and is challenging for learning, managing, and predicting over the large-scale and rapidly growing set of labels. Traditional XMC methods, like one-vs-all and tree-based methods struggle with the growing set of labels due to their static label assumptions, and embedding-based methods struggle with the complex mapping relationships due to their late-interaction paradigm. In this paper, we... | Yanjiang Liu, Tianyun Zhong, Yaojie Lu, Hongyu Lin, Ben He, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Zhongyi Liu, Xianpei Han, Le Sun |  |
| 1322 |  |  [Benchmarking Large Language Models on CFLUE - A Chinese Financial Language Understanding Evaluation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.337) |  | 0 | In light of recent breakthroughs in large language models (LLMs) that have revolutionized natural language processing (NLP), there is an urgent need for new benchmarks to keep pace with the fast development of LLMs. In this paper, we propose CFLUE, the Chinese Financial Language Understanding Evaluation benchmark, designed to assess the capability of LLMs across various dimensions. Specifically, CFLUE provides datasets tailored for both knowledge assessment and application assessment. In... | Jie Zhu, Junhui Li, Yalong Wen, Lifan Guo |  |
| 1323 |  |  [Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint](https://doi.org/10.18653/v1/2024.findings-acl.338) |  | 0 | Reinforcement learning (RL) has been widely used in training large language models (LLMs) for preventing unexpected outputs, e.g., reducing harmfulness and errors. However, existing RL methods mainly adopt instance-level reward, which cannot provide fine-grained supervision for complex reasoning tasks. As a result, the RL training cannot be fully aware of the specific part or step that actually leads to the incorrectness in model response. To address it, we propose a new RL method named RLMEC... | Zhipeng Chen, Kun Zhou, Xin Zhao, Junchen Wan, Fuzheng Zhang, Di Zhang, JiRong Wen |  |
| 1324 |  |  [Definition generation for lexical semantic change detection](https://doi.org/10.18653/v1/2024.findings-acl.339) |  | 0 | We use contextualized word definitions generated by large language models as semantic representations in the task of diachronic lexical semantic change detection (LSCD). In short, generated definitions are used as ‘senses’, and the change score of a target word is retrieved by comparing their distributions in two time periods under comparison. On the material of five datasets and three languages, we show that generated definitions are indeed specific and general enough to convey a signal... | Mariia Fedorova, Andrey Kutuzov, Yves Scherrer |  |
| 1325 |  |  [MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector](https://doi.org/10.18653/v1/2024.findings-acl.340) |  | 0 | Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the first highly multilingual audio-based dataset with toxicity labels which covers 14 different linguistic families. The dataset comprises 20,000 audio utterances for English and Spanish, and 4,000 for the... | Marta R. Costajussà, Mariano Coria Meglioli, Pierre Andrews, David Dale, Prangthip Hansanti, Elahe Kalbassi, Alexandre Mourachko, Christophe Ropers, Carleigh Wood |  |
| 1326 |  |  [Phased Instruction Fine-Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.341) |  | 0 | Instruction Fine-Tuning, a method enhancing pre-trained language models’ capabilities from mere next-word prediction to complex instruction following, often employs a one-off training approach on diverse instruction dataset. However, this method may not effectively enhance models’ adherence to instructions due to the simultaneous handling of varying instruction complexities. To address this, we propose a novel phased instruction fine-tuning (Phased IFT) method, grounded in the hypothesis of... | Wei Pang, Chuan Zhou, XiaoHua Zhou, Xiaojie Wang |  |
| 1327 |  |  [TOREE: Evaluating Topic Relevance of Student Essays for Chinese Primary and Middle School Education](https://doi.org/10.18653/v1/2024.findings-acl.342) |  | 0 | Topic relevance of an essay demands that the composition adheres to a clear theme and aligns well with the essay prompt requirements, a critical aspect of essay quality evaluation. However, existing research of Automatic Essay Scoring (AES) for Chinese essays has overlooked topic relevance and lacks detailed feedback, while Automatic Essay Comment Generation (AECG) faces much complexity and difficulty. Additionally, current Large Language Models, including GPT-4, often make incorrect judgments... | Xinlin Zhuang, Hongyi Wu, Xinshu Shen, Peimin Yu, Gaowei Yi, Xinhao Chen, Tu Hu, Yang Chen, Yupei Ren, Yadong Zhang, Youqi Song, Binxuan Liu, Man Lan |  |
| 1328 |  |  [Predicting the Unpredictable: Uncertainty-Aware Reasoning over Temporal Knowledge Graphs via Diffusion Process](https://doi.org/10.18653/v1/2024.findings-acl.343) |  | 0 | Temporal Knowledge Graph (TKG) reasoning seeks to predict future incomplete facts leveraging historical data. While existing approaches have shown effectiveness in addressing the task through various perspectives, such as graph learning and logic rules, they are limited in capturing the indeterminacy in future events, particularly in the case of rare/unseen facts. To tackle the highlighted issues, we introduce a novel approach by conceptualizing TKG reasoning as a sequence denoising process for... | Yuxiang Cai, Qiao Liu, Yanglei Gan, Changlin Li, Xueyi Liu, Run Lin, Da Luo, JiayeYang JiayeYang |  |
| 1329 |  |  [Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-acl.344) |  | 0 | The widespread use of Text-to-Image (T2I) models in content generation requires careful examination of their safety, including their robustness to adversarial attacks. Despite extensive research on adversarial attacks, the reasons for their effectiveness remain underexplored. This paper presents an empirical study on adversarial attacks against T2I models, focusing on analyzing factors associated with attack success rates (ASR). We introduce a new attack objective - entity swapping using... | Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, Yue Dong |  |
| 1330 |  |  [Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs](https://doi.org/10.18653/v1/2024.findings-acl.345) |  | 0 | Controlled Text Generation (CTG) aims to produce texts that exhibit specific desired attributes. In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG). This framework utilizes an attribute scorer to evaluate the attributes of sentences generated by LLMs and constructs dynamic attribute graphs. DATG modulates the occurrence of key attribute words and key anti-attribute words, achieving... | Xun Liang, Hanyu Wang, Shichao Song, Mengting Hu, Xunzhi Wang, Zhiyu Li, Feiyu Xiong, Bo Tang |  |
| 1331 |  |  [Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.346) |  | 0 | In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples are subsequently distilled into small language models to enhance their contextualization capability. Extensive evaluations show that COCONUT considerably improves commonsense reasoning performance... | JunHyung Park, Mingyu Lee, Junho Kim, SangKeun Lee |  |
| 1332 |  |  [Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge](https://doi.org/10.18653/v1/2024.findings-acl.347) |  | 0 | Recent research has explored methods for updating and modifying factual knowledge in large language models, often focusing on specific multi-layer perceptron blocks. This study expands on this work by examining the effectiveness of existing knowledge editing methods across languages and delving into the role of attention mechanisms in this process. Drawing from the insights gained, we propose Mass-Editing Memory with Attention in Transformers (MEMAT), a method that achieves significant... | Daniel Mela, Aitor GonzalezAgirre, Javier Hernando, Marta Villegas |  |
| 1333 |  |  [BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains](https://doi.org/10.18653/v1/2024.findings-acl.348) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges.In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further... | Yanis Labrak, Adrien Bazoge, Emmanuel Morin, PierreAntoine Gourraud, Mickael Rouvier, Richard Dufour |  |
| 1334 |  |  [All Languages Matter: On the Multilingual Safety of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.349) |  | 0 | Safety lies at the core of developing and deploying large language models (LLMs). However, previous safety benchmarks only concern the safety in one language, e.g. the majority language in the pretraining data such as English. In this work, we build the first multilingual safety benchmark for LLMs, XSafety, in response to the global deployment of LLMs in practice. XSafety covers 14 kinds of commonly used safety issues across 10 languages that span several language families. We utilize XSafety... | Wenxuan Wang, Zhaopeng Tu, Chang Chen, Youliang Yuan, Jentse Huang, Wenxiang Jiao, Michael R. Lyu |  |
| 1335 |  |  [LJPCheck: Functional Tests for Legal Judgment Prediction](https://doi.org/10.18653/v1/2024.findings-acl.350) |  | 0 | Legal Judgment Prediction (LJP) refers to the task of automatically predicting judgment results (e.g., charges, law articles and term of penalty) given the fact description of cases. While SOTA models have achieved high accuracy and F1 scores on public datasets, existing datasets fail to evaluate specific aspects of these models (e.g., legal fairness, which significantly impact their applications in real scenarios). Inspired by functional testing in software engineering, we introduce LJPCHECK,... | Yuan Zhang, Wanhong Huang, Yi Feng, Chuanyi Li, Zhiwei Fei, Jidong Ge, Bin Luo, Vincent Ng |  |
| 1336 |  |  [CMDL: A Large-Scale Chinese Multi-Defendant Legal Judgment Prediction Dataset](https://doi.org/10.18653/v1/2024.findings-acl.351) |  | 0 | Legal Judgment Prediction (LJP) has attracted significant attention in recent years. However, previous studies have primarily focused on cases involving only a single defendant, skipping multi-defendant cases due to complexity and difficulty. To advance research, we introduce CMDL, a large-scale real-world Chinese Multi-Defendant LJP dataset, which consists of over 393,945 cases with nearly 1.2 million defendants in total. For performance evaluation, we propose case-level evaluation metrics... | Wanhong Huang, Yi Feng, Chuanyi Li, Honghan Wu, Jidong Ge, Vincent Ng |  |
| 1337 |  |  [Model Editing by Standard Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.352) |  | 0 | Standard fine-tuning is considered not as effective as specialized methods for model editing due to its comparatively poor performance. However, it is simple, agnostic to the architectural details of the model being edited, and able to leverage advances in standard training techniques with no additional work (e.g., black-box PEFT for computational efficiency), making it an appealing choice for a model editor. In this work, we show that standard fine-tuning alone can yield competitive model... | Govind Krishnan Gangadhar, Karl Stratos |  |
| 1338 |  |  [Abstract Meaning Representation-Based Logic-Driven Data Augmentation for Logical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.353) |  | 0 | Combining large language models with logical reasoning enhances their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges when gathering reliable data from the web to build comprehensive training datasets, subsequently affecting performance on downstream tasks. To address this, we introduce a novel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the original text into an Abstract Meaning... | Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Gaël Gendron, Timothy Pistotti, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Paul Denny, Michael Witbrock, Jiamou Liu |  |
| 1339 |  |  [CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow](https://doi.org/10.18653/v1/2024.findings-acl.354) |  | 0 | We introduce a novel dataset tailored for code generation, aimed at aiding developers in common tasks. Our dataset provides examples that include a clarified intent, code snippets associated, and an average of three related unit tests. It encompasses a range of libraries such as Pandas, Numpy, and Regex, along with more than 70 standard libraries in Python code derived from Stack Overflow. Comprising 3,402 crafted examples by Python experts, our dataset is designed for both model finetuning and... | Nathanaël Beau, Benoît Crabbé |  |
| 1340 |  |  [ViHateT5: Enhancing Hate Speech Detection in Vietnamese With a Unified Text-to-Text Transformer Model](https://doi.org/10.18653/v1/2024.findings-acl.355) |  | 0 | Recent advancements in hate speech detection (HSD) in Vietnamese have made significant progress, primarily attributed to the emergence of transformer-based pre-trained language models, particularly those built on the BERT architecture. However, the necessity for specialized fine-tuned models has resulted in the complexity and fragmentation of developing a multitasking HSD system. Moreover, most current methodologies focus on fine-tuning general pre-trained models, primarily trained on formal... | Luan Thanh Nguyen |  |
| 1341 |  |  [Bias in News Summarization: Measures, Pitfalls and Corpora](https://doi.org/10.18653/v1/2024.findings-acl.356) |  | 0 | Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their content selection, faithfulness, grammaticality and coherence. However, it is well known that LLMs can reproduce and reinforce harmful social biases. This raises the question: Do biases affect model outputs in a constrained setting like summarization?To help answer this question, we first motivate and introduce a number of definitions for biased... | Julius Steen, Katja Markert |  |
| 1342 |  |  [When to Trust LLMs: Aligning Confidence with Response Quality](https://doi.org/10.18653/v1/2024.findings-acl.357) |  | 0 | Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods often express reliability by confidence level, however, their effectiveness is limited by the lack of objective guidance. To address this, we propose CONfidence-Quality-ORDer-preserving alignment approach... | Shuchang Tao, Liuyi Yao, Hanxing Ding, Yuexiang Xie, Qi Cao, Fei Sun, Jinyang Gao, Huawei Shen, Bolin Ding |  |
| 1343 |  |  [Zero-shot Cross-lingual Alignment for Embedding Initialization](https://doi.org/10.18653/v1/2024.findings-acl.358) |  | 0 | For multilingual training, we present CrossInit, an initialization method that initializes embeddings into similar geometrical structures across languages in an unsupervised manner. CrossInit leverages a common cognitive linguistic mechanism, Zipf’s law, which indicates that similar concepts across languages have similar word ranks or frequencies in their monolingual corpora. Instead of considering point-to-point alignments based on ranks, CrossInit considers the same span of consecutive ranks... | Xi Ai, Zhiyong Huang |  |
| 1344 |  |  [Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)](https://doi.org/10.18653/v1/2024.findings-acl.359) |  | 0 | Large Vision-Language Models (LVLMs) are an extension of Large Language Models (LLMs) that facilitate processing both image and text inputs, expanding AI capabilities. However, LVLMs struggle with object hallucinations due to their reliance on text cues and learned object co-occurrence biases. While most research quantifies these hallucinations, mitigation strategies are still lacking. Our study introduces a Language Contrastive Decoding (LCD) algorithm that adjusts LVLM outputs based on LLM... | Avshalom Manevich, Reut Tsarfaty |  |
| 1345 |  |  [It takes two to borrow: a donor and a recipient. Who's who?](https://doi.org/10.18653/v1/2024.findings-acl.360) |  | 0 | We address the open problem of automatically identifying the direction of lexical borrowing, given word pairs in the donor and recipient languages. We propose strong benchmarks for this task, by applying a set of machine learning models. We extract and publicly release a comprehensive borrowings dataset from the recent RoBoCoP cognates and borrowings database for five Romance languages. We experiment on this dataset with both graphic and phonetic representations and with different features,... | Liviu P. Dinu, Ana Sabina Uban, Anca Dinu, IoanBogdan Iordache, Simona Georgescu, Laurentiu Zoicas |  |
| 1346 |  |  [Advancing Post-OCR Correction: A Comparative Study of Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.361) |  | 0 | This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages computer vision feature detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several... | Shuhao Guan, Derek Greene |  |
| 1347 |  |  [GeoAgent: To Empower LLMs using Geospatial Tools for Address Standardization](https://doi.org/10.18653/v1/2024.findings-acl.362) |  | 0 | This paper presents a novel solution to tackle the challenges that posed by the abundance of non-standard addresses, which input by users in modern applications such as navigation maps, ride-hailing apps, food delivery platforms, and logistics services. These manually entered addresses often contain irregularities, such as missing information, spelling errors, colloquial descriptions, and directional offsets, which hinder address-related tasks like address matching and linking. To tackle these... | Chenghua Huang, Shisong Chen, Zhixu Li, Jianfeng Qu, Yanghua Xiao, Jiaxin Liu, Zhigang Chen |  |
| 1348 |  |  [HQP: A Human-Annotated Dataset for Detecting Online Propaganda](https://doi.org/10.18653/v1/2024.findings-acl.363) |  | 0 | Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present HQP: a novel dataset (N=30000) for detecting online propaganda with high-quality labels. To the best of our knowledge, HQP is the first large-scale dataset for detecting online... | Abdurahman Maarouf, Dominik Bär, Dominique Geissler, Stefan Feuerriegel |  |
| 1349 |  |  [Teaching Language Models to Self-Improve by Learning from Language Feedback](https://doi.org/10.18653/v1/2024.findings-acl.364) |  | 0 | Aligning Large Language Models (LLMs) with human intentions and values is crucial yet challenging. Current methods primarily rely on human preferences, which are costly and insufficient in capturing nuanced feedback expressed in natural language. In this paper, we present Self-Refinement Tuning (SRT), a method that leverages model feedback for alignment, thereby reducing reliance on human annotations. SRT uses a base language model (e.g., Tulu2) to generate initial responses, which are... | Chi Hu, Yimin Hu, Hang Cao, Tong Xiao, JingBo Zhu |  |
| 1350 |  |  [Exploring Spatial Schema Intuitions in Large Language and Vision Models](https://doi.org/10.18653/v1/2024.findings-acl.365) |  | 0 | Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action.Our investigation navigates the intriguing terrain of whether LLMs, despite their non-embodied nature, effectively capture implicit human intuitions about fundamental, spatial building blocks of language. We employ insights from spatial cognitive foundations... | Philipp Wicke, Lennart Wachowiak |  |
| 1351 |  |  [Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model](https://doi.org/10.18653/v1/2024.findings-acl.366) |  | 0 | The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot ones often yield suboptimal performance. Although the recent DetectGPT has shown promising detection performance, it suffers from significant inefficiency issues, as detecting a single candidate... | Yibo Miao, Hongcheng Gao, Hao Zhang, Zhijie Deng |  |
| 1352 |  |  [Decoding the Narratives: Analyzing Personal Drug Experiences Shared on Reddit](https://doi.org/10.18653/v1/2024.findings-acl.367) |  | 0 | Online communities such as drug-related subreddits serve as safe spaces for people who use drugs (PWUD), fostering discussions on substance use experiences, harm reduction, and addiction recovery. Users’ shared narratives on these forums provide insights into the likelihood of developing a substance use disorder (SUD) and recovery potential. Our study aims to develop a multi-level, multi-label classification model to analyze online user-generated texts about substance use experiences. For this... | Layla Bouzoubaa, Elham Aghakhani, Max Song, Quang Trinh, Rezvaneh (Shadi) Rezapour |  |
| 1353 |  |  [Unveiling the Art of Heading Design: A Harmonious Blend of Summarization, Neology, and Algorithm](https://doi.org/10.18653/v1/2024.findings-acl.368) |  | 0 | Crafting an appealing heading is crucial for attracting readers and marketing work or products. A popular way is to summarize the main idea with a refined description and a memorable acronym. However, there lacks a systematic study and a formal benchmark including datasets and metrics. Motivated by this absence, we introduce LOgogram, a novel benchmark comprising 6,653 paper abstracts with corresponding descriptions and acronyms. To measure the quality of heading generation, we propose a set of... | Shaobo Cui, Yiyang Feng, Yisong Mao, Yifan Hou, Boi Faltings |  |
| 1354 |  |  [Understanding Fine-grained Distortions in Reports of Scientific Findings](https://doi.org/10.18653/v1/2024.findings-acl.369) |  | 0 | Distorted science communication harms individuals and society as it can lead to unhealthy behavior change and decrease trust in scientific institutions. Given the rapidly increasing volume of science communication in recent years, a fine-grained understanding of how findings from scientific publications are reported to the general public, and methods to detect distortions from the original work automatically, are crucial. Prior work focused on individual aspects of distortions or worked with... | Amelie Wührl, Dustin Wright, Roman Klinger, Isabelle Augenstein |  |
| 1355 |  |  [MM-SOC: Benchmarking Multimodal Large Language Models in Social Media Platforms](https://doi.org/10.18653/v1/2024.findings-acl.370) |  | 0 | Social media platforms are hubs for multimodal information exchange, encompassing text, images, and videos, making it challenging for machines to comprehend the information or emotions associated with interactions in online spaces. Multimodal Large Language Models (MLLMs) have emerged as a promising solution to address these challenges, yet struggle with accurately interpreting human emotions and complex contents like misinformation. This paper introduces MM-Soc, a comprehensive benchmark... | Yiqiao Jin, Minje Choi, Gaurav Verma, Jindong Wang, Srijan Kumar |  |
| 1356 |  |  [Instances Need More Care: Rewriting Prompts for Instances with LLMs in the Loop Yields Better Zero-Shot Performance](https://doi.org/10.18653/v1/2024.findings-acl.371) |  | 0 | Large language models (LLMs) have revolutionized zero-shot task performance, mitigating the need for task-specific annotations while enhancing task generalizability. Despite its advancements, current methods using trigger phrases such as “Let’s think step by step” remain limited. This study introduces PRomPTed, an approach that optimizes the zero-shot prompts for individual task instances following an innovative manner of “LLMs in the loop”.Our comprehensive evaluation across 13 datasets and 10... | Saurabh Srivastava, Chengyue Huang, Weiguo Fan, Ziyu Yao |  |
| 1357 |  |  [Benchmarking Retrieval-Augmented Generation for Medicine](https://doi.org/10.18653/v1/2024.findings-acl.372) |  | 0 | While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted. However, a RAG system can involve multiple flexible components, and there is a lack of best practices regarding the optimal RAG setting for various medical purposes. To systematically evaluate such... | Guangzhi Xiong, Qiao Jin, Zhiyong Lu, Aidong Zhang |  |
| 1358 |  |  [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://doi.org/10.18653/v1/2024.findings-acl.373) |  | 0 | While LLMs demonstrate impressive capabilities in musical knowledge, we find that music reasoning is still an unsolved task.We introduce ChatMusician, an open-source large language model (LLM) that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2 on a text-compatible music representation, ABC notation, and the music is treated as a second language.ChatMusician can understand and generate music with a pure text tokenizer without external... | Ruibin Yuan, Hanfeng Lin, Yi Wang, Zeyue Tian, Shangda Wu, Tianhao Shen, Ge Zhang, Yuhang Wu, Cong Liu, Ziya Zhou, Liumeng Xue, Ziyang Ma, Qin Liu, Tianyu Zheng, Yizhi Li, Yinghao Ma, Yiming Liang, Xiaowei Chi, Ruibo Liu, Zili Wang, Chenghua Lin, Qifeng Liu, Tao Jiang, Wenhao Huang, Wenhu Chen, Jie Fu, Emmanouil Benetos, Gus Xia, Roger B. Dannenberg, Wei Xue, Shiyin Kang, Yike Guo |  |
| 1359 |  |  [Towards Robust Temporal Reasoning of Large Language Models via a Multi-Hop QA Dataset and Pseudo-Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.374) |  | 0 | Knowledge in the real world is being updated constantly. However, it is costly to frequently update large language models (LLMs). Therefore, it is crucial for LLMs to understand the concept of temporal knowledge. However, prior works on temporal question answering (TQA) did not emphasize multi-answer and multi-hop types of temporal reasoning. In this paper, we propose a complex temporal question-answering dataset Complex-TR that focuses on multi-answer and multi-hop temporal reasoning. Besides,... | Qingyu Tan, Hwee Tou Ng, Lidong Bing |  |
| 1360 |  |  [Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements](https://doi.org/10.18653/v1/2024.findings-acl.375) |  | 0 |  | Anton Voronov, Lena Wolf, Max Ryabinin |  |
| 1361 |  |  [Knowledge Graph-Enhanced Large Language Models via Path Selection](https://doi.org/10.18653/v1/2024.findings-acl.376) |  | 0 | Large Language Models (LLMs) have shown unprecedented performance in various real-world applications. However, they are known to generate factually inaccurate outputs, a.k.a. the hallucination problem. In recent years, incorporating external knowledge extracted from Knowledge Graphs (KGs) has become a promising strategy to improve the factual accuracy of LLM-generated outputs. Nevertheless, most existing explorations rely on LLMs themselves to perform KG knowledge extraction, which is highly... | Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li |  |
| 1362 |  |  [OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission Translation Errors Detection](https://doi.org/10.18653/v1/2024.findings-acl.377) |  | 0 | Recently, there has been considerable attention on detecting hallucinations and omissions in Machine Translation (MT) systems. The two dominant approaches to tackle this task involve analyzing the MT system’s internal states or relying on the output of external tools, such as sentence similarity or MT quality estimators. In this work, we introduce OTTAWA, a novel Optimal Transport (OT)-based word aligner specifically designed to enhance the detection of hallucinations and omissions in MT... | Chenyang Huang, Abbas Ghaddar, Ivan Kobyzev, Mehdi Rezagholizadeh, Osmar Zaïane, Boxing Chen |  |
| 1363 |  |  [ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.378) |  | 0 | In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically... | Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan |  |
| 1364 |  |  [Speech-based Slot Filling using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.379) |  | 0 | Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated prompt designs and noise-robust LoRA fine-tuning are proposed to improve the robustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a linearised knowledge injection (LKI) scheme is... | Guangzhi Sun, Shutong Feng, Dongcheng Jiang, Chao Zhang, Milica Gasic, Philip C. Woodland |  |
| 1365 |  |  [Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies](https://doi.org/10.18653/v1/2024.findings-acl.380) |  | 0 | As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how “surprised” an NLM model is at novel input. PPL has been widely used to understand the behavior of NLMs. Previous findings show that changes in PPL when masking attention layers in pre-trained... | Changye Li, Zhecheng Sheng, Trevor Cohen, Serguei Pakhomov |  |
| 1366 |  |  [HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.381) |  | 0 | While large language models (LLMs) excel in various natural language tasks in English, their performance in low-resource languages like Hebrew, especially for generative tasks such as abstractive summarization, remains unclear. The high morphological richness in Hebrew adds further challenges due to the ambiguity in sentence comprehension and the complexities in meaning construction.In this paper, we address this evaluation and resource gap by introducing HeSum, a novel benchmark dataset... | Tzuf PazArgaman, Itai Mondshine, Asaf Achi Mordechai, Reut Tsarfaty |  |
| 1367 |  |  [TRAM: Benchmarking Temporal Reasoning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.382) |  | 0 | Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate... | Yuqing Wang, Yun Zhao |  |
| 1368 |  |  [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.383) |  | 0 | This paper investigates the capabilities of Large Language Models (LLMs) in understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a new dataset with Known-Unknown Questions (KUQ) and establish a categorization framework to clarify the origins of uncertainty in such queries. Subsequently, we examine the performance... | Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, William Yang Wang |  |
| 1369 |  |  [Exploring Defeasibility in Causal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.384) |  | 0 | Defeasibility in causal reasoning implies that the causal relationship between cause and effect can be strengthened or weakened. Namely, the causal strength between cause and effect should increase or decrease with the incorporation of strengthening arguments (supporters) or weakening arguments (defeaters), respectively. However, existing works ignore defeasibility in causal reasoning and fail to evaluate existing causal strength metrics in defeasible settings. In this work, we present... | Shaobo Cui, Lazar Milikic, Yiyang Feng, Mete Ismayilzada, Debjit Paul, Antoine Bosselut, Boi Faltings |  |
| 1370 |  |  [Better Synthetic Data by Retrieving and Transforming Existing Datasets](https://doi.org/10.18653/v1/2024.findings-acl.385) |  | 0 | Despite recent advances in large language models, building dependable and deployable NLP models typically requires abundant, high-quality training data. However, task-specific data is not available for many use cases, and manually curating task-specific data is labor-intensive. Recent work has studied prompt-driven synthetic data generation using large language models, but these generated datasets tend to lack complexity and diversity. To address these limitations, we introduce a method,... | Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, Graham Neubig |  |
| 1371 |  |  [Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models](https://doi.org/10.18653/v1/2024.findings-acl.386) |  | 0 | In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to prefix language models (PrefixLMs). We attribute this phenomenon to the auto-regressive attention masks within CausalLMs, which restrict each token from accessing information from subsequent tokens.... | Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He |  |
| 1372 |  |  [Perspective Taking through Generating Responses to Conflict Situations](https://doi.org/10.18653/v1/2024.findings-acl.387) |  | 0 | Although language model performance across diverse tasks continues to improve, these models still struggle to understand and explain the beliefs of other people. This skill requires perspective-taking, the process of conceptualizing the point of view of another person. Perspective taking becomes challenging when the text reflects more personal and potentially more controversial beliefs.We explore this task through natural language generation of responses to conflict situations. We evaluate... | Joan Plepi, Charles Welch, Lucie Flek |  |
| 1373 |  |  [LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement](https://doi.org/10.18653/v1/2024.findings-acl.388) |  | 0 | Pretrained large language models (LLMs) are currently state-of-the-art for solving the vast majority of natural language processing tasks. While many real-world applications still require fine-tuning to reach satisfactory levels of performance, many of them are in the low-data regime, making fine-tuning challenging. To address this, we propose LLM2LLM, a targeted and iterative data augmentation strategy that uses a teacher LLM to enhance a small seed dataset by augmenting additional data that... | Nicholas Lee, Thanakul Wattanawong, Sehoon Kim, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipalli, Michael W. Mahoney, Kurt Keutzer, Amir Gholami |  |
| 1374 |  |  [The Power of Summary-Source Alignments](https://doi.org/10.18653/v1/2024.findings-acl.389) |  | 0 | Multi-document summarization (MDS) is a challenging task, often decomposed to subtasks of salience and redundancy detection, followed by text generation.In this context, alignment of corresponding sentences between a reference summary and its source documents has been leveraged to generate training data for some of the component tasks. Yet, this enabling alignment step has usually been applied heuristically on the sentence level on a limited number of subtasks.In this paper, we propose... | Ori Ernst, Ori Shapira, Aviv Slobodkin, Sharon Adar, Mohit Bansal, Jacob Goldberger, Ran Levy, Ido Dagan |  |
| 1375 |  |  [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.390) |  | 0 | Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive, especially as the number of tasks spanned by instruction datasets continues to increase. Active learning is effective in identifying useful subsets of samples to annotate from... | Gantavya Bhatt, Yifang Chen, Arnav Mohanty Das, Jifan Zhang, Sang T. Truong, Stephen Mussmann, Yinglun Zhu, Jeff A. Bilmes, Simon S. Du, Kevin G. Jamieson, Jordan T. Ash, Robert D. Nowak |  |
| 1376 |  |  [Learning Multimodal Contrast with Cross-modal Memory and Reinforced Contrast Recognition](https://doi.org/10.18653/v1/2024.findings-acl.391) |  | 0 | In many practical scenarios, contents from different modalities are not semantically aligned; for instance, visual and textual information may conflict with each other, resulting in non-compositional expression effects such as irony or humor. Effective modeling and smooth integration of multimodal information are crucial for achieving good understanding of the contrast across modalities. Being focusing on image-text matching, most current studies face challenges in identifying such contrast,... | Yuanhe Tian, Fei Xia, Yan Song |  |
| 1377 |  |  [Text Simplification via Adaptive Teaching](https://doi.org/10.18653/v1/2024.findings-acl.392) |  | 0 | Text simplification is the process of rewriting a piece of text using simpler vocabulary and grammatical structure in order to make the text more accessible and understandable for a larger audience. In this paper, we introduce a new text simplification model based on the notion of adaptive teaching using a teacher network and a text generation network. We name this new model Simplification via Adaptive Teaching (SAT). Our proposed model sets a new state-of-the-art performance in terms of... | Seyed Ali Bahrainian, Jonathan Dou, Carsten Eickhoff |  |
| 1378 |  |  [A multi-level multi-label text classification dataset of 19th century Ottoman and Russian literary and critical texts](https://doi.org/10.18653/v1/2024.findings-acl.393) |  | 0 | This paper introduces a multi-level, multi-label text classification dataset comprising over 3000 documents. The dataset features literary and critical texts from 19th-century Ottoman Turkish and Russian. It is the first study to apply large language models (LLMs) to this dataset, sourced from prominent literary periodicals of the era. The texts have been meticulously organized and labeled. This was done according to a taxonomic framework that takes into account both their structural and... | Gokcen Gokceoglu, Devrim Cavusoglu, Emre Akbas, Özen Nergis Dolcerocca |  |
| 1379 |  |  [It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment Analysis Performance](https://doi.org/10.18653/v1/2024.findings-acl.394) |  | 0 | Aspect-Based Sentiment Analysis (ABSA) involves extracting opinions from textual data about specific entities and their corresponding aspects through various complementary subtasks. Several prior research has focused on developing ad hoc designs of varying complexities for these subtasks. In this paper, we build upon the instruction tuned model proposed by Scaria et al. (2023), who present an instruction-based model with task descriptions followed by in-context examples on ABSA subtasks. We... | Laura Cabello, Uchenna Akujuobi |  |
| 1380 |  |  [Whose Emotions and Moral Sentiments do Language Models Reflect?](https://doi.org/10.18653/v1/2024.findings-acl.395) |  | 0 | Language models (LMs) are known to represent the perspectives of some social groups better than others, which may impact their performance, especially on subjective tasks such as content moderation and hate speech detection. To explore how LMs represent different perspectives, existing research focused on positional alignment, i.e., how closely the models mimic the opinions and stances of different groups, e.g., liberals or conservatives. However, human communication also encompasses emotional... | Zihao He, Siyi Guo, Ashwin Rao, Kristina Lerman |  |
| 1381 |  |  [LLM can Achieve Self-Regulation via Hyperparameter Aware Generation](https://doi.org/10.18653/v1/2024.findings-acl.396) |  | 0 | In the realm of Large Language Models (LLMs), users commonly employ diverse decoding strategies and adjust hyperparameters to control the generated text. However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves? The current decoding generation process often relies on empirical and heuristic manual adjustments to hyperparameters based on types of tasks and demands. However, this process is typically cumbersome,... | Siyin Wang, Shimin Li, Tianxiang Sun, Jinlan Fu, Qinyuan Cheng, Jiasheng Ye, Junjie Ye, Xipeng Qiu, Xuanjing Huang |  |
| 1382 |  |  [Forward-Backward Reasoning in Large Language Models for Mathematical Verification](https://doi.org/10.18653/v1/2024.findings-acl.397) |  | 0 | Self-Consistency samples diverse reasoning chains with answers and chooses the final answer by majority voting. It is based on forward reasoning and cannot further improve performance by sampling more reasoning chains when saturated. To further boost performance, we introduce backward reasoning to verify candidate answers. Specifically, for mathematical tasks, we mask a number in the question and ask the LLM to answer a backward question created by a simple template, i.e., to predict the masked... | Weisen Jiang, Han Shi, Longhui Yu, Zhengying Liu, Yu Zhang, Zhenguo Li, James T. Kwok |  |
| 1383 |  |  [Towards Uncertainty-Aware Language Agent](https://doi.org/10.18653/v1/2024.findings-acl.398) |  | 0 | While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our... | Jiuzhou Han, Wray L. Buntine, Ehsan Shareghi |  |
| 1384 |  |  [Detection and Positive Reconstruction of Cognitive Distortion Sentences: Mandarin Dataset and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.399) |  | 0 | This research introduces a Positive Reconstruction Framework based on positive psychology theory. Overcoming negative thoughts can be challenging, our objective is to address and reframe them through a positive reinterpretation. To tackle this challenge, a two-fold approach is necessary: identifying cognitive distortions and suggesting a positively reframed alternative while preserving the original thought’s meaning. Recent studies have investigated the application of Natural Language... | Shuya Lin, Yuxiong Wang, Jonathan Dong, Shiguang Ni |  |
| 1385 |  |  [PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.400) |  | 0 | Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pre-training data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework, Prompting with Iterative Verification (PiVe), to improve graph-based generative capability of LLMs. We show how a small language model could be trained to act as a verifier module for the output of an... | Jiuzhou Han, Nigel Collier, Wray L. Buntine, Ehsan Shareghi |  |
| 1386 |  |  [Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.401) |  | 0 | Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA,... | Yifu Gao, Linbo Qiao, Zhigang Kan, Zhihua Wen, Yongquan He, Dongsheng Li |  |
| 1387 |  |  [VISREAS: Complex Visual Reasoning with Unanswerable Questions](https://doi.org/10.18653/v1/2024.findings-acl.402) |  | 0 | Verifying a question’s validity before answering is crucial in real-world applications, where users may provide imperfect instructions. In this scenario, an ideal model should address the discrepancies in the query and convey them to the users rather than generating the best possible answer. Addressing this requirement, we introduce a new compositional visual question-answering dataset, VisReas, that consists of answerable and unanswerable visual queries formulated by traversing and perturbing... | Syeda Nahida Akter, Sangwu Lee, Yingshan Chang, Yonatan Bisk, Eric Nyberg |  |
| 1388 |  |  [A Unified Generative Framework for Bilingual Euphemism Detection and Identification](https://doi.org/10.18653/v1/2024.findings-acl.403) |  | 0 | Various euphemisms are emerging in social networks, attracting widespread attention from the natural language processing community. However, existing euphemism datasets are only domain-specific or language-specific. In addition, existing approaches to the study of euphemisms are one-sided. Either only the euphemism detection task or only the euphemism identification task is accomplished, lacking a unified framework. To this end, we construct a large-scale Bilingual Multi-category dataset of... | Yuxue Hu, Junsong Li, Tongguan Wang, Dongyu Su, Guixin Su, Ying Sha |  |
| 1389 |  |  [StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing](https://doi.org/10.18653/v1/2024.findings-acl.404) |  | 0 | Given a script, the challenge in Movie Dubbing (Visual Voice Cloning, V2C) is to generate speech that aligns well with the video in both time and emotion, based on the tone of a reference audio track. Existing state-of-the-art V2C models break the phonemes in the script according to the divisions between video frames, which solves the temporal alignment problem but leads to incomplete phoneme pronunciation and poor identity stability. To address this problem, we propose StyleDubber, which... | Gaoxiang Cong, Yuankai Qi, Liang Li, Amin Beheshti, Zhedong Zhang, Anton van den Hengel, MingHsuan Yang, Chenggang Yan, Qingming Huang |  |
| 1390 |  |  [ETAS: Zero-Shot Transformer Architecture Search via Network Trainability and Expressivity](https://doi.org/10.18653/v1/2024.findings-acl.405) |  | 0 | Transformer Architecture Search (TAS) methods aim to automate searching for the optimal Transformer architecture configurations for a given task. However, they are impeded by the prohibitive cost of evaluating Transformer architectures. Recently, several Zero-Shot TAS methods have been proposed to mitigate this problem by utilizing zero-cost proxies to evaluate Transformer architectures without training. Unfortunately, they are limited to specific computer vision or natural language processing... | Jiechao Yang, Yong Liu |  |
| 1391 |  |  [Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment](https://doi.org/10.18653/v1/2024.findings-acl.406) |  | 0 | Medical dialogue systems have attracted significant attention for their potential to act as medical assistants. Enabling these medical systems to emulate clinicians’ diagnostic reasoning process has been the long-standing research focus. Previous studies rudimentarily realized the simulation of clinicians’ diagnostic process by fine-tuning language models on high-quality dialogue datasets. Nonetheless, they overly focus on the outcomes of the clinician’s reasoning process while ignoring their... | Kaishuai Xu, Yi Cheng, Wenjun Hou, Qiaoyu Tan, Wenjie Li |  |
| 1392 |  |  [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.407) |  | 0 | This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath systemically organizes math problems under a hierarchy of math concepts, so that mathematical reasoning can be evaluated at different granularity with concept-wise accuracies. Based on our ConcepthMath, we... | Yanan Wu, Jie Liu, Xingyuan Bu, Jiaheng Liu, Zhanhui Zhou, Yuanxing Zhang, Chenchen Zhang, Zhiqi Bai, Haibin Chen, Tiezheng Ge, Wanli Ouyang, Wenbo Su, Bo Zheng |  |
| 1393 |  |  [REInstruct: Building Instruction Data from Unlabeled Corpus](https://doi.org/10.18653/v1/2024.findings-acl.408) |  | 0 | Manually annotating instruction data for large language models is difficult, costly, and hard to scale. Meanwhile, current automatic annotation methods typically rely on distilling synthetic data from proprietary LLMs, which not only limits the upper bound of the quality of the instruction data but also raises potential copyright issues. In this paper, we propose REInstruct, a simple and scalable method to automatically build instruction data from an unlabeled corpus without heavy reliance on... | Shu Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun |  |
| 1394 |  |  [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://doi.org/10.18653/v1/2024.findings-acl.409) |  | 0 | Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller models with the superior reasoning capabilities of their larger counterparts. In DSS, the distilled model acquires the ability to generate rationales and predict labels concurrently through a... | Xin Chen, Hanxian Huang, Yanjun Gao, Yi Wang, Jishen Zhao, Ke Ding |  |
| 1395 |  |  [PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning](https://doi.org/10.18653/v1/2024.findings-acl.410) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as an effective method for adapting pre-trained language models to various tasks efficiently. Recently, there has been a growing interest in transferring knowledge from one or multiple tasks to the downstream target task to achieve performance improvements. However, current approaches typically either train adapters on individual tasks or distill shared knowledge from source tasks, failing to fully exploit task-specific knowledge and the... | Zhisheng Lin, Han Fu, Chenghao Liu, Zhuo Li, Jianling Sun |  |
| 1396 |  |  [MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.411) |  | 0 | Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics. However, traditional math benchmarks like GSM8k offer a unidimensional perspective, which fall short in providing a holistic assessment of the LLMs’ math capabilities. To address this gap, we introduce MathBench, a new benchmark that rigorously assesses the mathematical capabilities of large language models. MathBench spans a wide range of mathematical disciplines, offering a detailed... | Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 1397 |  |  [Identifying Semantic Induction Heads to Understand In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.412) |  | 0 | Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to better understand the in-context learning of LLMs. Specifically, we investigate whether attention heads encode two types of relationships between tokens present in natural languages: the syntactic... | Jie Ren, Qipeng Guo, Hang Yan, Dongrui Liu, Quanshi Zhang, Xipeng Qiu, Dahua Lin |  |
| 1398 |  |  [Chinese Spelling Corrector Is Just a Language Learner](https://doi.org/10.18653/v1/2024.findings-acl.413) |  | 0 | This paper emphasizes Chinese spelling correction by means of self-supervised learning, which means there are no annotated errors within the training data. Our intuition is that humans are naturally good correctors with exposure to error-free sentences, which contrasts with current unsupervised methods that strongly rely on the usage of confusion sets to produce parallel sentences. In this paper, we demonstrate that learning a spelling correction model is identical to learning a language model... | Lai Jiang, Hongqiu Wu, Hai Zhao, Min Zhang |  |
| 1399 |  |  [Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.414) |  | 0 |  | Junfei Wu, Qiang Liu, Ding Wang, Jinghao Zhang, Shu Wu, Liang Wang, Tieniu Tan |  |
| 1400 |  |  [RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.415) |  | 0 | Adaptive retrieval-augmented generation (ARAG) aims to dynamically determine the necessity of retrieval for queries instead of retrieving indiscriminately to enhance the efficiency and relevance of the sourced information. However, previous works largely overlook the evaluation of ARAG approaches, leading to their effectiveness being understudied. This work presents a benchmark, RetrievalQA, comprising 1,271 short-form questions covering new world and long-tail knowledge. The knowledge... | Zihan Zhang, Meng Fang, Ling Chen |  |
| 1401 |  |  [LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.416) |  | 0 | We introduces \*\*\*LLaST\*\*\*, a framework for building high-performance Large Language model based Speech-to-text Translation systems. We address the limitations of end-to-end speech translation (E2E ST) models by exploring model architecture design and optimization techniques tailored for LLMs. Our approach includes LLM-based speech translation architecture design, ASR-augmented training, multilingual data augmentation, and dual-LoRA optimization. Our approach demonstrates superior... | Xi Chen, Songyang Zhang, Qibing Bai, Kai Chen, Satoshi Nakamura |  |
| 1402 |  |  [Plan, Generate and Complicate: Improving Low-resource Dialogue State Tracking via Easy-to-Difficult Zero-shot Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.417) |  | 0 | Data augmentation methods have been a promising direction to improve the performance of small models for low-resource dialogue state tracking. However, traditional methods rely on pre-defined user goals and neglect the importance of data complexity in this task. In this paper, we propose EDZ-DA, an Easy-to-Difficult Zero-shot Data Augmentation framework for low-resource dialogue state tracking that utilizes large language models to automatically catch the relationships of different domains and... | Ming Gu, Yan Yang |  |
| 1403 |  |  [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](https://doi.org/10.18653/v1/2024.findings-acl.418) |  | 0 | The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning. There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance to suffer from multi-task disturbance, and 2) the human annotation consistency rate is generally only 60% to 75%, causing training data to contain a lot of noise. To tackle these two challenges, we... | Shanghaoran Quan |  |
| 1404 |  |  [LEIA: Facilitating Cross-lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.419) |  | 0 | Adapting English-based large language models (LLMs) to other languages has become increasingly popular due to the efficiency and potential of cross-lingual transfer. However, existing language adaptation methods often overlook the benefits of cross-lingual supervision. In this study, we introduce LEIA, a language adaptation tuning method that utilizes Wikipedia entity names aligned across languages. This method involves augmenting the target language corpus with English entity names and... | Ikuya Yamada, Ryokan Ri |  |
| 1405 |  |  [Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective](https://doi.org/10.18653/v1/2024.findings-acl.420) |  | 0 | Code generation aims to understand the problem description and generate corresponding code snippets, where existing works generally decompose such complex tasks into intermediate steps by prompting strategies, such as Chain-of-Thought and its variants. While these studies have achieved some success, their effectiveness is highly dependent on the capabilities of advanced Large Language Models (LLMs) such as GPT-4, particularly in terms of API calls, which significantly limits their practical... | Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou |  |
| 1406 |  |  [Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration](https://doi.org/10.18653/v1/2024.findings-acl.421) |  | 0 | The proliferation of Large Language Models (LLMs) has led to an influx of AI-generated content (AIGC) on the internet, transforming the corpus of Information Retrieval (IR) systems from solely human-written to a coexistence with LLM-generated content. The impact of this surge in AIGC on IR systems remains an open question, with the primary challenge being the lack of a dedicated benchmark for researchers. In this paper, we introduce Cocktail, a comprehensive benchmark tailored for evaluating IR... | Sunhao Dai, Weihao Liu, Yuqi Zhou, Liang Pang, Rongju Ruan, Gang Wang, Zhenhua Dong, Jun Xu, JiRong Wen |  |
| 1407 |  |  [Continual Dialogue State Tracking via Reason-of-Select Distillation](https://doi.org/10.18653/v1/2024.findings-acl.422) |  | 0 | An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services, confronting catastrophic forgetting and a critical capability loss termed the “Value Selection Quandary”. To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel “meta-reasoning” capability. Meta-reasoning,... | Yujie Feng, Bo Liu, Xiaoyu Dong, Zexin Lu, LiMing Zhan, XiaoMing Wu, Albert Y. S. Lam |  |
| 1408 |  |  [Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text](https://doi.org/10.18653/v1/2024.findings-acl.423) |  | 0 | AI-generated text detection has attracted increasing attention as powerful language models approach human-level generation. Limited work is devoted to detecting (partially) AI-paraphrased texts. However, AI paraphrasing is commonly employed in various application scenarios for text refinement and diversity. To this end, we propose a novel detection framework, paraphrased text span detection (PTD), aiming to identify paraphrased text spans within a text. Different from text-level detection, PTD... | Yafu Li, Zhilin Wang, Leyang Cui, Wei Bi, Shuming Shi, Yue Zhang |  |
| 1409 |  |  [SoFA: Shielded On-the-fly Alignment via Priority Rule Following](https://doi.org/10.18653/v1/2024.findings-acl.424) |  | 0 | The alignment problem in Large Language Models (LLMs) involves adapting them to the broad spectrum of human values. This requirement challenges existing alignment methods due to diversity of preferences and regulatory standards. This paper introduces a novel alignment paradigm, priority rule following, which defines rules as the primary control mechanism in each dialog, prioritizing them over user instructions. Our preliminary analysis reveals that even the advanced LLMs, such as GPT-4, exhibit... | Xinyu Lu, Bowen Yu, Yaojie Lu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, Yongbin Li |  |
| 1410 |  |  [Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition](https://doi.org/10.18653/v1/2024.findings-acl.425) |  | 0 | Recent advances in LLMs have sparked a debate on whether they understand text. In this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. To substantiate this claim, we propose a thought experiment involving an open-source chatbot Z which excels on every possible benchmark, seemingly without subjective experience. We ask whether Z is capable of understanding, and show that... | Ariel Goldstein, Gabriel Stanovsky |  |
| 1411 |  |  [Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning](https://doi.org/10.18653/v1/2024.findings-acl.426) |  | 0 | Telling stories is an integral part of human communication which can evoke emotions and influence the affective states of the audience. Automatically modeling emotional trajectories in stories has thus attracted considerable scholarly interest. However, as most existing works have been limited to unsupervised dictionary-based approaches, there is no benchmark for this task. We address this gap by introducing continuous valence and arousal labels for an existing dataset of children’s stories... | Lukas Christ, Shahin Amiriparian, Manuel Milling, Ilhan Aslan, Björn W. Schuller |  |
| 1412 |  |  [RAP: Efficient Text-Video Retrieval with Sparse-and-Correlated Adapter](https://doi.org/10.18653/v1/2024.findings-acl.427) |  | 0 | Text-Video Retrieval (TVR) aims to align relevant video content with natural language queries. To date, most of the state-of-the-art TVR methods learn image-to-video transfer learning based on the large-scale pre-trained vision-language models (e.g., CLIP). However, fully fine-tuning these pre-trained models for TVR incurs prohibitively expensive computation cost. To this end, we propose to conduct efficient text-video Retrieval with a salient-and-correlated AdaPter (RAP), i.e., fine-tuning the... | Meng Cao, Haoran Tang, Jinfa Huang, Peng Jin, Can Zhang, Ruyang Liu, Long Chen, Xiaodan Liang, Li Yuan, Ge Li |  |
| 1413 |  |  [Benchmarking and Improving Long-Text Translation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.428) |  | 0 | Recent studies have illuminated the promising capabilities of large language models (LLMs) in handling long texts. However, their performance in machine translation (MT) of long documents remains underexplored. This paper aims to shed light on how LLMs navigate this complex task, offering a comprehensive evaluation of their capabilities and limitations in long-text MT. First, we collect and construct an instruction-based benchmark dataset, specifically designed for the finetuning and evaluation... | Longyue Wang, Zefeng Du, Wenxiang Jiao, Chenyang Lyu, Jianhui Pang, Leyang Cui, Kaiqiang Song, Derek F. Wong, Shuming Shi, Zhaopeng Tu |  |
| 1414 |  |  [Personalized Topic Selection Model for Topic-Grounded Dialogue](https://doi.org/10.18653/v1/2024.findings-acl.429) |  | 0 | Recently, the topic-grounded dialogue (TGD) system has become increasingly popular as its powerful capability to actively guide users to accomplish specific tasks through topic-guided conversations. Most existing works utilize side information (e.g. topics or personas) in isolation to enhance the topic selection ability. However, due to disregarding the noise within these auxiliary information sources and their mutual influence, current models tend to predict user-uninteresting and contextually... | Shixuan Fan, Wei Wei, Xiaofei Wen, XianLing Mao, Jixiong Chen, Dangyang Chen |  |
| 1415 |  |  [Debiasing In-Context Learning by Instructing LLMs How to Follow Demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.430) |  | 0 | In-context learning(ICL) has gained considerable attention due to its data efficiency and task adaptability. Unfortunately, ICL suffers from the demonstration bias, i.e., its performance and robustness are severely affected by the selection and ordering of demonstrations. In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be... | Lvxue Li, Jiaqi Chen, Xinyu Lu, Yaojie Lu, Hongyu Lin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Zhongyi Liu, Xianpei Han, Le Sun |  |
| 1416 |  |  [Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog Systems](https://doi.org/10.18653/v1/2024.findings-acl.431) |  | 0 | Creating effective and reliable task-oriented dialog systems (ToDSs) is challenging, not only because of the complex structure of these systems, but also due to the scarcity of training data, especially when several modules need to be trained separately, each one with its own input/output training examples. Data augmentation (DA), whereby synthetic training examples are added to the training data, has been successful in other NLP systems, but has not been explored as extensively in ToDSs. We... | Christos Vlachos, Themos Stafylakis, Ion Androutsopoulos |  |
| 1417 |  |  [MS2SL: Multimodal Spoken Data-Driven Continuous Sign Language Production](https://doi.org/10.18653/v1/2024.findings-acl.432) |  | 0 | Sign language understanding has made significant strides; however, there is still no viable solution for generating sign sequences directlyfrom entire spoken content, e.g., text or speech. In this paper, we propose a unified framework for continuous sign language production, easing communication between sign and non-sign language users. In particular, a sequence diffusion model, utilizing embeddings extracted from text or speech, is crafted to generate sign predictions step by step. Moreover,... | Jian Ma, Wenguan Wang, Yi Yang, Feng Zheng |  |
| 1418 |  |  [BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.433) |  | 0 | Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional domains. However, the vanilla Chain-of-Thought (CoT) prompting method faces challenges in effectively leveraging the unique strengths of visual and DSL representations, primarily due to their differing... | Xueliang Zhao, Xinting Huang, Tingchen Fu, Qintong Li, Shansan Gong, Lemao Liu, Wei Bi, Lingpeng Kong |  |
| 1419 |  |  [PartialFormer: Modeling Part Instead of Whole for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.434) |  | 0 | The design choices in Transformer feed-forward neural networks have resulted in significant computational and parameter overhead. In this work, we emphasize the importance of hidden dimensions in designing lightweight FFNs, a factor often overlooked in previous architectures. Guided by this principle, we introduce PartialFormer, a parameter-efficient Transformer architecture utilizing multiple smaller FFNs to reduce parameters and computation while maintaining essential hidden dimensions. These... | Tong Zheng, Bei Li, Huiwen Bao, Jiale Wang, Weiqiao Shan, Tong Xiao, JingBo Zhu |  |
| 1420 |  |  [Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with Extract-Then-Assign Strategy](https://doi.org/10.18653/v1/2024.findings-acl.435) |  | 0 | In the task of aspect sentiment quad prediction (ASQP), generative methods for predicting sentiment quads have shown promisingresults. However, they still suffer from imprecise predictions and limited interpretability, caused by data scarcity and inadequate modeling of the quadruplet composition process. In this paper, we propose Self-Consistent Reasoning-based Aspect sentiment quadruple Prediction (SCRAP), optimizing its model to generate reasonings and the corresponding sentiment quadruplets... | Jieyong Kim, Ryang Heo, Yongsik Seo, SeongKu Kang, Jinyoung Yeo, Dongha Lee |  |
| 1421 |  |  [PACE: Improving Prompt with Actor-Critic Editing for Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.436) |  | 0 | Large language models (LLMs) have showcased remarkable potential across various tasks by conditioning on prompts. However, the quality of different human-written prompts leads to substantial discrepancies in LLMs’ performance, and improving prompts usually necessitates considerable human effort and expertise. To this end, this paper proposes Prompt with Actor-Critic Editing (PACE) for LLMs to enable automatic prompt editing. Drawing inspiration from the actor-critic algorithm in reinforcement... | Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, Ge Li |  |
| 1422 |  |  [Penetrative AI: Making LLMs Comprehend the Physical World](https://doi.org/10.18653/v1/2024.findings-acl.437) |  | 0 | Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we... | Huatao Xu, Liying Han, Qirui Yang, Mo Li, Mani Srivastava |  |
| 1423 |  |  [The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis](https://doi.org/10.18653/v1/2024.findings-acl.438) |  | 0 | In-context learning is a popular inference strategy where large language models solve a task using only a few labeled demonstrations without needing any parameter updates. Although there have been extensive studies on English in-context learning, multilingual in-context learning remains under-explored, and we lack an in-depth understanding of the role of demonstrations in this context. To address this gap, we conduct a multidimensional analysis of multilingual in-context learning, experimenting... | Miaoran Zhang, Vagrant Gautam, Mingyang Wang, Jesujoba Alabi, Xiaoyu Shen, Dietrich Klakow, Marius Mosbach |  |
| 1424 |  |  [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](https://doi.org/10.18653/v1/2024.findings-acl.439) |  | 0 |  | Ming Dong, Yujing Chen, Miao Zhang, Hao Sun, Tingting He |  |
| 1425 |  |  [An Empirical Study of In-context Learning in LLMs for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.440) |  | 0 | Recent interest has surged in employing Large Language Models (LLMs) for machine translation (MT) via in-context learning (ICL) (Vilar et al., 2023). Most prior studies primarily focus on optimizing translation quality, with limited attention to understanding the specific aspects of ICL that influence the said quality. To this end, we perform the first of its kind, exhaustive study of in-context learning for machine translation (MT). We first establish that ICL is primarily example-driven and... | Pranjal A. Chitale, Jay P. Gala, Raj Dabre |  |
| 1426 |  |  ["My Answer is C": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models](https://doi.org/10.18653/v1/2024.findings-acl.441) |  | 0 | The open-ended nature of language generation makes the evaluation of autoregressive large language models (LLMs) challenging. One common evaluation approach uses multiple-choice questions to limit the response space. The model is then evaluated by ranking the candidate answers by the log probability of the first token prediction. However, first-tokens may not consistently reflect the final response output, due to model’s diverse response styles such as starting with “Sure” or refusing to... | Xinpeng Wang, Bolei Ma, Chengzhi Hu, Leon WeberGenzel, Paul Röttger, Frauke Kreuter, Dirk Hovy, Barbara Plank |  |
| 1427 |  |  [ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.442) |  | 0 | The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has achieved remarkable success in various natural language processing tasks. However, existing methodologies that integrate LLMs and KGs often navigate the task-solving process solely based on the LLM’s analysis of the question, overlooking the rich cognitive potential inherent in the vast knowledge encapsulated in KGs. To address this, we introduce Observation-Driven Agent (ODA), a novel AI agent framework tailored for... | Lei Sun, Zhengwei Tao, Youdi Li, Hiroshi Arakawa |  |
| 1428 |  |  [A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.443) |  | 0 | Large Language Models (LLMs) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques to align model outputs with societal values to curb the generation of malicious content. However, the phenomenon of “jailbreaking” — where carefully crafted prompts elicit harmful responses from... | Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, Stjepan Picek |  |
| 1429 |  |  [A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning](https://doi.org/10.18653/v1/2024.findings-acl.444) |  | 0 |  | Panagiotis Kaliosis, John Pavlopoulos, Foivos Charalampakos, Georgios Moschovis, Ion Androutsopoulos |  |
| 1430 |  |  [Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.445) |  | 0 | Aligned Large Language Models (LLMs) showcase remarkable versatility, capable of handling diverse real-world tasks. Meanwhile, aligned LLMs are also expected to exhibit speciality, excelling in specific applications. However, fine-tuning with extra data, a common practice to gain speciality, often leads to catastrophic forgetting (CF) of previously acquired versatility, hindering the model’s performance across diverse tasks. In response to this challenge, we propose CoFiTune, a coarse to fine... | Hengyuan Zhang, Yanru Wu, Dawei Li, Sak Yang, Rui Zhao, Yong Jiang, Fei Tan |  |
| 1431 |  |  [A Two-Agent Game for Zero-shot Relation Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.446) |  | 0 | Relation triplet extraction is a fundamental task in natural language processing that aims to identify semantic relationships between entities in text. It is particularly challenging in the zero-shot setting, i.e., zero-shot relation triplet extraction (ZeroRTE), where the relation sets between training and test are disjoint. Existing methods deal with this task by integrating relations into prompts, which may lack sufficient understanding of the unseen relations. To address these limitations,... | Ting Xu, Haiqin Yang, Fei Zhao, Zhen Wu, Xinyu Dai |  |
| 1432 |  |  [Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning](https://doi.org/10.18653/v1/2024.findings-acl.447) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as the predominant technique for fine-tuning in the era of large language models. However, existing PEFT methods still have inadequate training efficiency. Firstly, the utilization of large-scale foundation models during the training process is excessively redundant for certain fine-tuning tasks. Secondly, as the model size increases, the growth in trainable parameters of empirically added PEFT modules becomes non-negligible and redundant,... | Naibin Gu, Peng Fu, Xiyu Liu, Bowen Shen, Zheng Lin, Weiping Wang |  |
| 1433 |  |  [Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German](https://doi.org/10.18653/v1/2024.findings-acl.448) |  | 0 | The translation of gender-neutral person-referring terms (e.g.,the students) is often non-trivial.Translating from English into German poses an interesting case—in German, person-referring nouns are usually gender-specific, and if the gender of the referent(s) is unknown or diverse, the generic masculine (die Studenten (m.)) is commonly used. This solution, however, reduces the visibility of other genders, such as women and non-binary people. To counteract gender discrimination, a societal... | Manuel Lardelli, Giuseppe Attanasio, Anne Lauscher |  |
| 1434 |  |  [Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.449) |  | 0 |  | Shichao Sun, Ruifeng Yuan, Ziqiang Cao, Wenjie Li, Pengfei Liu |  |
| 1435 |  |  [Trust in Internal or External Knowledge? Generative Multi-Modal Entity Linking with Knowledge Retriever](https://doi.org/10.18653/v1/2024.findings-acl.450) |  | 0 | Multi-modal entity linking (MEL) is a challenging task that requires accurate prediction of entities within extensive search spaces, utilizing multi-modal contexts. Existing generative approaches struggle with the knowledge gap between visual entity information and the intrinsic parametric knowledge of LLMs. To address this knowledge gap, we introduce a novel approach called GELR, which incorporates a knowledge retriever to enhance visual entity information by leveraging external sources.... | Xinwei Long, Jiali Zeng, Fandong Meng, Jie Zhou, Bowen Zhou |  |
| 1436 |  |  [A Semantic Distance Metric Learning approach for Lexical Semantic Change Detection](https://doi.org/10.18653/v1/2024.findings-acl.451) |  | 0 | Detecting temporal semantic changes of words is an important task for various NLP applications that must make time-sensitive predictions.Lexical Semantic Change Detection (SCD) task involves predicting whether a given target word, w, changes its meaning between two different text corpora, C1 and C2.For this purpose, we propose a supervised two-staged SCD method that uses existing Word-in-Context (WiC) datasets.In the first stage, for a target word w, we learn two sense-aware encoders that... | Taichi Aida, Danushka Bollegala |  |
| 1437 |  |  [What Have We Achieved on Non-autoregressive Translation?](https://doi.org/10.18653/v1/2024.findings-acl.452) |  | 0 | Recent advances have made non-autoregressive (NAT) translation comparable to autoregressive methods (AT). However, their evaluation using BLEU has been shown to weakly correlate with human annotations. Limited research compares non-autoregressive translation and autoregressive translation comprehensively, leaving uncertainty about the true proximity of NAT to AT. To address this gap, we systematically evaluate four representative NAT methods across various dimensions, including human... | Yafu Li, Huajian Zhang, Jianhao Yan, Yongjing Yin, Yue Zhang |  |
| 1438 |  |  [From Zero to Hero: Cold-Start Anomaly Detection](https://doi.org/10.18653/v1/2024.findings-acl.453) |  | 0 |  | Tal Reiss, George Kour, Naama Zwerdling, Ateret AnabyTavor, Yedid Hoshen |  |
| 1439 |  |  [Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives](https://doi.org/10.18653/v1/2024.findings-acl.454) |  | 0 | Existing datasets for narrative understanding often fail to represent the complexity and uncertainty of relationships in real-life social scenarios. To address this gap, we introduce a new benchmark, Conan, designed for extracting and analysing intricate character relation graphs from detective narratives. Specifically, we designed hierarchical relationship categories and manually extracted and annotated role-oriented relationships from the perspectives of various characters, incorporating both... | Runcong Zhao, Qinglin Zhu, Hainiu Xu, Jiazheng Li, Yuxiang Zhou, Yulan He, Lin Gui |  |
| 1440 |  |  [DistillMIKE: Editing Distillation of Massive In-Context Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.455) |  | 0 | Among the recently emerged knowledge editing methods, in-context knowledge editing (IKE) has shown respectable abilities on knowledge editing in terms of generalization and specificity. Noting the promising advantages but unexplored issues of IKE, we propose \*\*DistillMIKE\*\* as a novel extension of IKE, i.e., editing \*\*distill\*\*ation of "\*\*M\*\*assive” \*\*I\*\*n-context \*\*K\*\*nowledge \*\*E\*\*diting in large language models (LLMs), mainly consisting of two expansions; 1) \*Massive... | Shanbao Qiao, Xuebing Liu, SeungHoon Na |  |
| 1441 |  |  [Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.456) |  | 0 | To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first drafts several future tokens efficiently and then verifies them in parallel. Unlike autoregressive decoding, Speculative Decoding facilitates the simultaneous decoding of multiple tokens per step, thereby accelerating inference. This paper presents a comprehensive... | Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu, Wenjie Li, Zhifang Sui |  |
| 1442 |  |  [Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.457) |  | 0 | Hierarchical text classification (HTC) is a challenging problem with two key issues: utilizing structural information and mitigating label imbalance. Recently, the unit-based approach generating unit-based feature representations has outperformed the global approach focusing on a global feature representation. Nevertheless, unit-based models using BCE and ZLPR losses still face static thresholding and label imbalance challenges. Those challenges become more critical in large-scale hierarchies.... | Gibaeg Kim, Sanghun Im, HeungSeon Oh |  |
| 1443 |  |  [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](https://doi.org/10.18653/v1/2024.findings-acl.458) |  | 0 | In the era of large language models, applying techniques such as Retrieval Augmented Generation can better address Open-Domain Question-Answering problems. Due to constraints including model sizes and computing resources, the length of context is often limited, and it becomes challenging to empower the model to cover overlong contexts while answering questions from open domains. This paper proposes a general and convenient method to cover longer contexts in Open-Domain Question-Answering tasks.... | Zhuo Chen, Xinyu Wang, Yong Jiang, Pengjun Xie, Fei Huang, Kewei Tu |  |
| 1444 |  |  [CICLe: Conformal In-Context Learning for Largescale Multi-Class Food Risk Classification](https://doi.org/10.18653/v1/2024.findings-acl.459) |  | 0 | Contaminated or adulterated food poses a substantial risk to human health. Given sets of labeled web texts for training, Machine Learning and Natural Language Processing can be applied to automatically detect such risks. We publish a dataset of 7,546 short texts describing public food recall announcements. Each text is manually labeled, on two granularity levels (coarse and fine), for food products and hazards that the recall corresponds to. We describe the dataset and benchmark naive,... | Korbinian Randl, John Pavlopoulos, Aron Henriksson, Tony Lindgren |  |
| 1445 |  |  [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](https://doi.org/10.18653/v1/2024.findings-acl.460) |  | 0 | Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outliers in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which are crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV... | Ruikang Liu, Haoli Bai, Haokun Lin, Yuening Li, Han Gao, Zhengzhuo Xu, Lu Hou, Jun Yao, Chun Yuan |  |
| 1446 |  |  [Learning Adverbs with Spectral Mixture Kernels](https://doi.org/10.18653/v1/2024.findings-acl.461) |  | 0 | For humans and robots to collaborate more in the real world, robots need to understand human intentions from the different manner of their behaviors. In our study, we focus on the meaning of adverbs which describe human motions. We propose a topic model, Hierarchical Dirichlet Process-Spectral Mixture Latent Dirichlet Allocation, which concurrently learns the relationship between those human motions and those adverbs by capturing the frequency kernels that represent motion characteristics and... | Tomoe Taniguchi, Daichi Mochihashi, Ichiro Kobayashi |  |
| 1447 |  |  [E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.462) |  | 0 | The rapid development of Large Language Models (LLMs) has led to their increasing utilization in Chinese K-12 education. Despite the growing integration of LLMs and education, the absence of a dedicated benchmark for evaluating LLMs within this domain presents a pressing concern. Consequently, there is an urgent need for a comprehensive natural language processing benchmark to precisely assess the capabilities of various LLMs in Chinese K-12 education. In response, we introduce E-EVAL, the... | Jinchang Hou, Chang Ao, Haihong Wu, Xiangtao Kong, Zhigang Zheng, Daijia Tang, Chengming Li, Xiping Hu, Ruifeng Xu, Shiwen Ni, Min Yang |  |
| 1448 |  |  [ChartAssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.463) |  | 0 | Charts play a vital role in data visualization, understanding data patterns, and informed decision-making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While vision-language models trained on chart data excel in comprehension, they struggle with generalization. To address these challenges, we propose ChartAssistant, a chart-based vision-language model for... | Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, Ping Luo |  |
| 1449 |  |  [Teaching Small Language Models to Reason for Knowledge-Intensive Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.464) |  | 0 | Large Language Models (LLMs) can teach small language models (SLMs) to solve complex reasoning tasks (e.g., mathematical question answering) by Chain-of-thought Distillation (CoTD). Specifically, CoTD fine-tunes SLMs by utilizing rationales generated from LLMs such as ChatGPT. However, CoTD has certain limitations that make it unsuitable for knowledge-intensive multi-hop question answering: 1) SLMs have a very limited capacity in memorizing required knowledge compared to LLMs. 2) SLMs do not... | Xiang Li, Shizhu He, Fangyu Lei, JunYang JunYang, Tianhuang Su, Kang Liu, Jun Zhao |  |
| 1450 |  |  [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://doi.org/10.18653/v1/2024.findings-acl.465) |  | 0 | We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences. The framework addresses the limitations of current alignment approaches, which often struggle with the inconsistency and sparsity of human supervision signals, by integrating holistic rewards with aspect-specific rewards. This integration enables more precise and consistent... | Yuhang Lai, Siyuan Wang, Shujun Liu, Xuanjing Huang, Zhongyu Wei |  |
| 1451 |  |  [LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting](https://doi.org/10.18653/v1/2024.findings-acl.466) |  | 0 | Time-series forecasting (TSF) finds broad applications in real-world scenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates strong zero-shot TSF capabilities while preserving computational efficiency. However, existing prompting methods oversimplify TSF as language next-token predictions, overlooking its dynamic nature and lack of integration with state-of-the-art prompt strategies such as Chain-of-Thought. Thus, we propose LSTPrompt, a novel approach for prompting LLMs in... | Haoxin Liu, Zhiyuan Zhao, Jindong Wang, Harshavardhan Kamarthi, B. Aditya Prakash |  |
| 1452 |  |  [Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.467) |  | 0 | Text classification is a crucial task encountered frequently in practical scenarios, yet it is still under-explored in the era of large language models (LLMs). This study shows that LLMs are vulnerable to changes in the number and arrangement of options in text classification. Our extensive empirical analyses reveal that the key bottleneck arises from ambiguous decision boundaries and inherent biases towards specific tokens and positions.To mitigate these issues, we make the first attempt and... | Zhenyi Lu, Jie Tian, Wei Wei, Xiaoye Qu, Yu Cheng, Wenfeng Xie, Dangyang Chen |  |
| 1453 |  |  [UOR: Universal Backdoor Attacks on Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.468) |  | 0 | Task-agnostic and transferable backdoors implanted in pre-trained language models (PLMs) pose a severe security threat as they can be inherited to any downstream task. However, existing methods rely on manual selection of triggers and backdoor representations, hindering their effectiveness and universality across different PLMs or usage paradigms. In this paper, we propose a new backdoor attack method called UOR, which overcomes these limitations by turning manual selection into automatic... | Wei Du, Peixuan Li, Haodong Zhao, Tianjie Ju, Ge Ren, Gongshen Liu |  |
| 1454 |  |  [Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences](https://doi.org/10.18653/v1/2024.findings-acl.469) |  | 0 | To date, most investigations on surprisal and entropy effects in reading have been conducted on the group level, disregarding individual differences. In this work, we revisit the predictive power (PP) of different LMs’ surprisal and entropy measures on data of human reading times as a measure of processing effort by incorporating information of language users’ cognitive capacities. To do so, we assess the PP of surprisal and entropy estimated from generative language models (LMs) on reading... | Patrick Haller, Lena S. Bolliger, Lena Ann Jäger |  |
| 1455 |  |  [The State of Relation Extraction Data Quality: Is Bigger Always Better?](https://doi.org/10.18653/v1/2024.findings-acl.470) |  | 0 | Relation extraction (RE) extracts structured tuples of relationships (e.g. friend, enemy) between entities (e.g. Sherlock Holmes, John Watson) from text, with exciting potential applications. Hundreds of RE papers have been published in recent years; do their evaluation practices inform these goals? We review recent surveys and a sample of recent RE methods papers, compiling 38 datasets currently being used. Unfortunately, many have frequent label errors, and ones with known problems continue... | Erica Cai, Brendan T. O'Connor |  |
| 1456 |  |  [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Queries](https://doi.org/10.18653/v1/2024.findings-acl.471) |  | 0 | Large language models (LLMs) have manifested strong ability to generate codes for productive activities. However, current benchmarks for code synthesis, such as HumanEval, MBPP, and DS-1000, are predominantly oriented towards introductory tasks on algorithm and data science, insufficiently satisfying challenging requirements prevalent in real-world coding. To fill this gap, we propose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror the complexity and variety of scenarios... | Shudan Zhang, Hanlin Zhao, Xiao Liu, Qinkai Zheng, Zehan Qi, Xiaotao Gu, Yuxiao Dong, Jie Tang |  |
| 1457 |  |  [LLMCrit: Teaching Large Language Models to Use Criteria](https://doi.org/10.18653/v1/2024.findings-acl.472) |  | 0 | Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, current research in this area tends to consider only a limited number of criteria, or only a limited number of quality assessment aspects. To fill this gap, we propose a general framework that enables large language models (LLMs) to use... | Weizhe Yuan, Pengfei Liu, Matthias Gallé |  |
| 1458 |  |  [Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.473) |  | 0 | The language ability of Large Language Models (LLMs) is often unbalanced towards English because of the imbalance in the distribution of the pre-training data. This disparity is demanded in further fine-tuning and affecting the cross-lingual abilities of LLMs. In this paper, we propose to empower Instruction-tuned LLMs (It-LLMs) in languages other than English by building semantic alignment between them. Hence, we propose CrossAlpaca, an It-LLM with cross-lingual Instruction-following and... | Leonardo Ranaldi, Giulia Pucci, André Freitas |  |
| 1459 |  |  [Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies](https://doi.org/10.18653/v1/2024.findings-acl.474) |  | 0 | Conceptual spaces represent entities in terms of their primitive semantic features. Such representations are highly valuable but they are notoriously difficult to learn, especially when it comes to modelling perceptual and subjective features. Distilling conceptual spaces from Large Language Models (LLMs) has recently emerged as a promising strategy, but existing work has been limited to probing pre-trained LLMs using relatively simple zero-shot strategies. We focus in particular on the task of... | Nitesh Kumar, Usashi Chatterjee, Steven Schockaert |  |
| 1460 |  |  [Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.475) |  | 0 | To achieve non-parametric NMT domain adaptation, k-Nearest-Neighbor Machine Translation (kNN-MT) constructs an external datastore to store domain-specific translation knowledge, which derives a kNN distribution to interpolate the prediction distribution of the NMT model via a linear interpolation coefficient 𝜆. Despite its success, kNN retrieval at each timestep leads to substantial time overhead. To address this issue, dominant studies resort to kNN-MT with adaptive retrieval (kNN-MT-AR),... | Yan Gao, Zhiwei Cao, Zhongjian Miao, Baosong Yang, Shiyu Liu, Min Zhang, Jinsong Su |  |
| 1461 |  |  [Symmetric Dot-Product Attention for Efficient Training of BERT Language Models](https://doi.org/10.18653/v1/2024.findings-acl.476) |  | 0 | Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing. Nowadays, to tackle increasingly more complex tasks, Transformer-based models are stretched to enormous sizes, requiring increasingly larger training datasets, and unsustainable amount of compute resources. The ubiquitous nature of the Transformer... | Martin Courtois, Malte Ostendorff, Leonhard Hennig, Georg Rehm |  |
| 1462 |  |  [Synthesizing Conversations from Unlabeled Documents using Automatic Response Segmentation](https://doi.org/10.18653/v1/2024.findings-acl.477) |  | 0 | In this study, we tackle the challenge of inadequate and costly training data that has hindered the development of conversational question answering (ConvQA) systems. Enterprises have a large corpus of diverse internal documents. Instead of relying on a searching engine, a more compelling approach for people to comprehend these documents is to create a dialogue system. In this paper, we propose a robust dialog synthesising method. We learn the segmentation of data for the dialog task instead of... | Fanyou Wu, Weijie Xu, Chandan K. Reddy, Srinivasan Sengamedu |  |
| 1463 |  |  [Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains](https://doi.org/10.18653/v1/2024.findings-acl.478) |  | 0 | Although large language models (LLMs) exhibit remarkable capacity to leverage in-context demonstrations, it is still unclear to what extent they can learn new facts or concept definitions via prompts. To address this question, we examine the capacity of instruction-tuned LLMs to follow in-context concept annotation guidelines for zero-shot sentence labeling tasks. We design guidelines that present different types of factual and counterfactual concept definitions, which are used as prompts for... | Marcio Fonseca, Shay B. Cohen |  |
| 1464 |  |  [Alignment-Based Decoding Policy for Low-Latency and Anticipation-Free Neural Japanese Input Method Editors](https://doi.org/10.18653/v1/2024.findings-acl.479) |  | 0 | Japanese input method editors (IMEs) are essential tools for inputting Japanese text using a limited set of characters such as the kana syllabary. However, despite their importance, the potential of newer attention-based encoder-decoder neural networks, such as Transformer, has not yet been fully explored for IMEs due to their high computational cost and low-quality intermediate output in simultaneous settings, leading to high latencies. In this work, we propose a simple decoding policy to... | Armin Sarhangzadeh, Taro Watanabe |  |
| 1465 |  |  [ECoK: Emotional Commonsense Knowledge Graph for Mining Emotional Gold](https://doi.org/10.18653/v1/2024.findings-acl.480) |  | 0 | The demand for understanding and expressing emotions in the field of natural language processing is growing rapidly. Knowledge graphs, as an important form of knowledge representation, have been widely utilized in various emotion-related tasks. However, existing knowledge graphs mainly focus on the representation and reasoning of general factual knowledge, while there are still significant deficiencies in the understanding and reasoning of emotional knowledge. In this work, we construct a... | Zhunheng Wang, Xiaoyi Liu, Mengting Hu, Rui Ying, Ming Jiang, Jianfeng Wu, Yalan Xie, Hang Gao, Renhong Cheng |  |
| 1466 |  |  [Deterministic Reversible Data Augmentation for Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.481) |  | 0 | Data augmentation is an effective way to diversify corpora in machine translation, but previous methods may introduce semantic inconsistency between original and augmented data because of irreversible operations and random subword sampling procedures. To generate both symbolically diverse and semantically consistent augmentation data, we propose Deterministic Reversible Data Augmentation (DRDA), a simple but effective data augmentation method for neural machine translation. DRDA adopts... | Jiashu Yao, Heyan Huang, Zeming Liu, Yuhang Guo |  |
| 1467 |  |  [Latent Learningscape Guided In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.482) |  | 0 | The growing interest in leveraging large language models is driven by their exceptional imitation and reasoning capabilities. In-context learning (ICL), a streamlined method, has shown potential in boosting these models’ performance without modifying their underlying parameters, especially when supplied with suitable demonstrations. However, existing methods mainly choose demonstrations by comparing surface-level semantic similarities (e.g., based on embedding) and fall short of identifying the... | Anlai Zhou, Sunshine Jiang, Yifei Liu, Yiquan Wu, Kun Kuang, Jun Xiao |  |
| 1468 |  |  [SMR: State Memory Replay for Long Sequence Modeling](https://doi.org/10.18653/v1/2024.findings-acl.483) |  | 0 | Despite the promising performance of state space models (SSMs) in long sequence modeling, limitations still exist. Advanced SSMs like S5 and S6 (Mamba) in addressing non-uniform sampling, their recursive structures impede efficient SSM computation via convolution. To overcome compatibility limitations in parallel convolutional computation, this paper proposes a novel non-recursive non-uniform sample processing strategy. Theoretical analysis of SSMs through the lens of Event-Triggered Control... | Biqing Qi, Junqi Gao, Kaiyan Zhang, Dong Li, Jianxing Liu, Ligang Wu, Bowen Zhou |  |
| 1469 |  |  [Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks](https://doi.org/10.18653/v1/2024.findings-acl.484) |  | 0 | Large language models (LLMs) are proficient at generating fluent text with minimal task-specific supervision. However, their ability to generate rationales for knowledge-intensive tasks (KITs) remains under-explored. Generating rationales for KIT solutions, such as commonsense multiple-choice QA, requires external knowledge to support predictions and refute alternate options. In this work, we consider the task of generating retrieval-augmented rationalization of KIT model predictions via... | Aditi Mishra, Sajjadur Rahman, Kushan Mitra, Hannah Kim, Estevam Hruschka |  |
| 1470 |  |  [Challenging Large Language Models with New Tasks: A Study on their Adaptability and Robustness](https://doi.org/10.18653/v1/2024.findings-acl.485) |  | 0 | Recent progress in large language models (LLMs) has marked a notable milestone in the field of artificial intelligence. The conventional evaluation of LLMs primarily relies on existing tasks and benchmarks, raising concerns about test set contamination and the genuine comprehension abilities of LLMs. To address these concerns, we propose to evaluate LLMs by designing new tasks, automatically generating evaluation datasets for the tasks, and conducting detailed error analyses to scrutinize LLMs’... | Chenxi Li, Yuanhe Tian, Zhaxi Zerong, Yan Song, Fei Xia |  |
| 1471 |  |  [Linear Cross-Lingual Mapping of Sentence Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.486) |  | 0 | Semantics of a sentence is defined with much less ambiguity than semantics of a single word, and we assume that it should be better preserved by translation to another language. If multilingual sentence embeddings intend to represent sentence semantics, then the similarity between embeddings of any two sentences must be invariant with respect to translation. Based on this suggestion, we consider a simple linear cross-lingual mapping as a possible improvement of the multilingual embeddings. We... | Oleg Vasilyev, Fumika Isono, John Bohannon |  |
| 1472 |  |  [ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Self-Refinement](https://doi.org/10.18653/v1/2024.findings-acl.487) |  | 0 | Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore open-source Large Language Models (LLMs) for DocEAE, and propose... | Xinliang Frederick Zhang, Carter Wood Blum, Temma Choji, Shalin Shah, Alakananda Vempala |  |
| 1473 |  |  [LLMs Beyond English: Scaling the Multilingual Capability of LLMs with Cross-Lingual Feedback](https://doi.org/10.18653/v1/2024.findings-acl.488) |  | 0 | To democratize large language models (LLMs) to most natural languages, it is imperative to make these models capable of understanding and generating texts in many languages, in particular low-resource ones. While recent multilingual LLMs demonstrate remarkable performance in such capabilities, these LLMs still support a limited number of human languages due to the lack of training data for low resource languages. Moreover, these LLMs are not yet aligned with human preference for downstream... | Wen Lai, Mohsen Mesgar, Alexander Fraser |  |
| 1474 |  |  [BASS: Batched Attention-optimized Speculative Sampling](https://doi.org/10.18653/v1/2024.findings-acl.489) |  | 0 | Speculative decoding has emerged as a powerful method to improve latency and throughput in hosting large language models. However, most existing implementations focus on generating a single sequence. Real-world generative AI applications often require multiple responses and how to perform speculative decoding in a batched setting while preserving its latency benefits poses non-trivial challenges. This paper describes a system of batched speculative decoding that sets a new state of the art in... | Haifeng Qian, Sujan Kumar Gonugondla, Sungsoo Ha, Mingyue Shang, Sanjay Krishna Gouda, Ramesh Nallapati, Sudipta Sengupta, Xiaofei Ma, Anoop Deoras |  |
| 1475 |  |  [Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games](https://doi.org/10.18653/v1/2024.findings-acl.490) |  | 0 | In this study, we explore the application of Large Language Models (LLMs) in Jubensha, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in Jubensha games.... | Dekun Wu, Haochen Shi, Zhiyuan Sun, Bang Liu |  |
| 1476 |  |  [It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.491) |  | 0 | Natural language processing has seen rapid progress over the past decade. Due to the speed of developments, some practices get established without proper evaluation. Considering one such case and focusing on reading comprehension, we ask our first research question: 1) How does the order of inputs – i.e., question and context – affect model performance? Additionally, given recent advancements in input emphasis, we ask a second research question: 2) Does emphasizing either the question, the... | Sagi Shaier, Lawrence Hunter, Katharina von der Wense |  |
| 1477 |  |  [Large Language Models Relearn Removed Concepts](https://doi.org/10.18653/v1/2024.findings-acl.492) |  | 0 | Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by tracking concept saliency and similarity in pruned neurons during retraining for named entity recognition tasks. Our findings reveal that models can quickly regain performance post-pruning by relocating... | Michelle Lo, Fazl Barez, Shay B. Cohen |  |
| 1478 |  |  [Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond](https://doi.org/10.18653/v1/2024.findings-acl.493) |  | 0 | Task embedding, a meta-learning technique that captures task-specific information, has gained popularity, especially in areas such as multi-task learning, model editing, and interpretability. However, it faces challenges with the emergence of prompt-guided Large Language Models (LLMs) operating in a gradient-free manner. Existing task embedding methods rely on fine-tuned, task-specific language models, which hinders the adaptability of task embeddings across diverse models, especially... | Xinyu Wang, Hainiu Xu, Lin Gui, Yulan He |  |
| 1479 |  |  [TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles](https://doi.org/10.18653/v1/2024.findings-acl.494) |  | 0 | In light of recent advances in large language models (LLMs), the expectations for the next generation of virtual assistants include enhanced naturalness and adaptability across diverse usage scenarios. However, the creation of high-quality annotated data for Task-Oriented Dialog (TOD) is recognized to be slow and costly. To address these challenges, we introduce Task-Oriented Automatic Dialogs (TOAD), a novel and scalable TOD dataset along with its automatic generation pipeline. The TOAD... | Yinhong Liu, Yimai Fang, David Vandyke, Nigel Collier |  |
| 1480 |  |  [Machine-Generated Text Localization](https://doi.org/10.18653/v1/2024.findings-acl.495) |  | 0 | Machine-Generated Text (MGT) detection aims to identify a piece of text as machine or human written. Prior work has primarily formulated MGT detection as a binary classification task over an entire document, with limited work exploring cases where only part of a document is machine generated. This paper provides the first in-depth study of MGT that localizes the portions of a document that were machine generated. Thus, if a bad actor were to change a key portion of a news article to spread... | Zhongping Zhang, Wenda Qin, Bryan A. Plummer |  |
| 1481 |  |  [BenchIE⌃FL: A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.496) |  | 0 | Open Information Extraction (OIE) is a field of natural language processing that aims to present textual information in a format that allows it to be organized, analyzed and reflected upon. Numerous OIE systems are developed, claiming ever-increasing performance, marking the need for objective benchmarks. BenchIE is the latest reference we know of. Despite being very well thought out, we noticed a number of issues we believe are limiting. Therefore, we propose BenchIE^FL, a new OIE benchmark... | Fabrice Lamarche, Philippe Langlais |  |
| 1482 |  |  [CausalCite: A Causal Formulation of Paper Citations](https://doi.org/10.18653/v1/2024.findings-acl.497) |  | 0 | Citation count of a paper is a commonly used proxy for evaluating the significance of a paper in the scientific community. Yet citation measures are widely criticized for failing to accurately reflect the true impact of a paper. Thus, we propose CausalCite, a new way to measure the significance of a paper by assessing the causal impact of the paper on its follow-up papers. CausalCite is based on a novel causal inference method, TextMatch, which adapts the traditional matching framework to... | Ishan Kumar, Zhijing Jin, Ehsan Mokhtarian, Siyuan Guo, Yuen Chen, Negar Kiyavash, Mrinmaya Sachan, Bernhard Schölkopf |  |
| 1483 |  |  [Question Translation Training for Better Multilingual Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.498) |  | 0 | Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training. This approach not only incurs high cost, but also results in poorly translated data due... | Wenhao Zhu, Shujian Huang, Fei Yuan, Shuaijie She, Jiajun Chen, Alexandra Birch |  |
| 1484 |  |  [Improving LLM Generations via Fine-Grained Self-Endorsement](https://doi.org/10.18653/v1/2024.findings-acl.499) |  | 0 | This work studies mitigating fact-conflicting hallucinations for large language model (LLM) at inference time.Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses.Compared with prior ensemble methods (e.g., self-consistency) that perform response-level selection, our approach can better alleviate hallucinations for knowledge-intensive tasks.Our approach can broadly benefit smaller and open-source LLMs as... | Ante Wang, Linfeng Song, Baolin Peng, Lifeng Jin, Ye Tian, Haitao Mi, Jinsong Su, Dong Yu |  |
| 1485 |  |  [Multi-Label Classification for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2024.findings-acl.500) |  | 0 | Discourse relations play a pivotal role in establishing coherence within textual content, uniting sentences and clauses into a cohesive narrative. The Penn Discourse Treebank (PDTB) stands as one of the most extensively utilized datasets in this domain. In PDTB-3, the annotators can assign multiple labels to an example, when they believe the simultaneous presence of multiple relations. Prior research in discourse relation recognition has treated these instances as separate examples during... | Wanqiu Long, Siddharth Narayanaswamy, Bonnie Webber |  |
| 1486 |  |  [StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code](https://doi.org/10.18653/v1/2024.findings-acl.501) |  | 0 | Code LLMs have the potential to make it easier for non-experts to understand and write code. However, current CodeLLM benchmarks rely on a single expert-written prompt per problem, making it hard to generalize their success to non-expert users. In this paper, we present a new natural-language-to-code benchmark of prompts written by a key population of non-experts: beginning programmers. StudentEval contains 1,749 prompts written by 80 students who have only completed one introductory Python... | Hannah McLean Babe, Sydney Nguyen, Yangtian Zi, Arjun Guha, Molly Q. Feldman, Carolyn Jane Anderson |  |
| 1487 |  |  [ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution](https://doi.org/10.18653/v1/2024.findings-acl.502) |  | 0 | Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task — language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems’ ability to generate not only... | Xuanming Zhang, Zixun Chen, Zhou Yu |  |
| 1488 |  |  [Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.503) |  | 0 | One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse.Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing algorithms proposed to generate diverse outputs are predominantly based on beam search or random sampling, thus their output quality is capped by these underlying decoding algorithms. In this paper, we... | Yuu Jinnai, Ukyo Honda, Tetsuro Morimura, Peinan Zhang |  |
| 1489 |  |  [GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages](https://doi.org/10.18653/v1/2024.findings-acl.504) |  | 0 | Neural Machine Translation (NMT) continues to improve in quality and adoption, yet the in advertent perpetuation of gender bias remains a significant concern. Despite numerous studies on gender bias in translations into English from weakly gendered-languages, there are no benchmarks for evaluating this phenomenon or for assessing mitigation strategies. To address this gap, we introduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus, that consists of human translations from... | Spencer Rarrick, Ranjita Naik, Sundar Poudel, Vishal Chowdhary |  |
| 1490 |  |  [Hyperparameter-Free Approach for Faster Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.505) |  | 0 | Minimum Bayes-Risk (MBR) decoding is shown to be a powerful alternative to beam search decoding for a wide range of text generation tasks. However, MBR requires a huge amount of time for inference to compute the MBR objective, which makes the method infeasible in many situations where response time is critical. Confidence-based pruning (CBP) (Cheng and Vlachos, 2023) has recently been proposed to reduce the inference time in machine translation tasks. Although it is shown to significantly... | Yuu Jinnai, Kaito Ariu |  |
| 1491 |  |  [Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.506) |  | 0 | In recent years, neural machine translation (NMT) has become widely used in everyday life. However, the current NMT lacks a mechanism to adjust the difficulty level of translations to match the user’s language level. Additionally, due to the bias in the training data for NMT, translations of simple source sentences are often produced with complex words. In particular, this could pose a problem for children, who may not be able to understand the meaning of the translations correctly. In this... | Masashi Oshika, Makoto Morishita, Tsutomu Hirao, Ryohei Sasano, Koichi Takeda |  |
| 1492 |  |  [Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining](https://doi.org/10.18653/v1/2024.findings-acl.507) |  | 0 | Large Language Models (LLMs) have shown human-like reasoning abilities but still face challenges in solving complex logical problems. Existing unidirectional chaining methods, such as forward chaining and backward chaining, suffer from issues like low prediction accuracy and efficiency. To address these, we propose a bidirectional chaining method, Bi-Chainer, which dynamically switches to depth-first reasoning in the opposite reasoning direction when it encounters multiple branching options... | Shuqi Liu, Bowei He, Linqi Song |  |
| 1493 |  |  [Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?](https://doi.org/10.18653/v1/2024.findings-acl.508) |  | 0 | In this work, we investigate the controllability of large language models (LLMs) on scientific summarization tasks. We identify key stylistic and content coverage factors that characterize different types of summaries such as paper reviews, abstracts, and lay summaries. By controlling stylistic features, we find that non-fine-tuned LLMs outperform humans in the MuP review generation task, both in terms of similarity to reference summaries and human preferences. Also, we show that we can improve... | Marcio Fonseca, Shay B. Cohen |  |
| 1494 |  |  [Knowledge Context Modeling with Pre-trained Language Models for Contrastive Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.509) |  | 0 | Text-based knowledge graph completion (KGC) methods utilize pre-trained language models for triple encoding and further fine-tune the model to achieve completion. Despite their excellent performance, they neglect the knowledge context in inferring process. Intuitively, knowledge contexts, which refer to the neighboring triples around the target triples, are important information for triple inferring, since they provide additional detailed information about the entities. To this end, we propose... | Guangqian Yang, Yi Liu, Lei Zhang, Licheng Zhang, Hongtao Xie, Zhendong Mao |  |
| 1495 |  |  [Stronger, Lighter, Better: Towards Life-Long Attribute Value Extraction for E-Commerce Products](https://doi.org/10.18653/v1/2024.findings-acl.510) |  | 0 | Attribute value extraction involves identifying the value spans of predetermined attributes in product texts. This area of research has traditionally operated under a closed-world assumption, focusing on products from a static set of categories and their associated attributes. However, products in e-commerce stores are ever-increasing and evolving, calling for life-long learning. If continuously trained on the fast-increasing products and attributes, most existing solutions not only struggle... | Tao Zhang, Chenwei Zhang, Xian Li, Jingbo Shang, Hoang Nguyen, Philip S. Yu |  |
| 1496 |  |  [Exploring Domain Robust Lightweight Reward Models based on Router Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.511) |  | 0 | Recent advancements in large language models have heavily relied on the large reward model from reinforcement learning from human feedback for fine-tuning. However, the use of a single reward model across various domains may not always be optimal, often requiring retraining from scratch when new domain data is introduced. To address these challenges, we explore the utilization of small language models operating in a domain-specific manner based on router mechanisms. Our three approaches are: 1)... | Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, YoonHyung Roh |  |
| 1497 |  |  [Generalized Category Discovery with Large Language Models in the Loop](https://doi.org/10.18653/v1/2024.findings-acl.512) |  | 0 | Generalized Category Discovery (GCD) is a crucial task that aims to recognize both known and novel categories from a set of unlabeled data by utilizing a few labeled data with only known categories. Due to the lack of supervision and category information, current methods usually perform poorly on novel categories and struggle to reveal semantic meanings of the discovered clusters, which limits their applications in the real world. To mitigate the above issues, we propose Loop, an end-to-end... | Wenbin An, Wenkai Shi, Feng Tian, Haonan Lin, Qianying Wang, Yaqiang Wu, Mingxiang Cai, Luyan Wang, Yan Chen, Haiping Zhu, Ping Chen |  |
| 1498 |  |  [VAEGPT-Sim: Improving Sentence Representation with Limited Corpus Using Gradually-Denoising VAE](https://doi.org/10.18653/v1/2024.findings-acl.513) |  | 0 | Text embedding requires a highly efficient method for training domain-specific models on limited data, as general models trained on large corpora lack universal applicability in highly specific fields. Therefore, we have introduced VAEGPT-Sim, an innovative model for generating synonyms that combines a denoising variational autoencoder with a target-specific discriminator to generate synonymous sentences that closely resemble human language. Even when trained with completely unsupervised... | Zhenyi Wang, Haiyan Ning, Qing Ling, Dan Wang |  |
| 1499 |  |  [PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion](https://doi.org/10.18653/v1/2024.findings-acl.514) |  | 0 | Recent evaluations of Large Language Models (LLMs) have centered around testing their zero-shot/few-shot capabilities for basic natural language tasks and their ability to translate instructions into tool APIs. However, the evaluation of LLMs utilizing complex tools to finish multi-turn, multi-modal instructions in a complex multi-modal environment has not been investigated. To address this gap, we introduce the PowerPoint Task Completion (PPTC) benchmark to assess LLMs’ ability to create and... | Yiduo Guo, Zekai Zhang, Yaobo Liang, Dongyan Zhao, Nan Duan |  |
| 1500 |  |  [Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.515) |  | 0 | For a LLM to be trustworthy, its confidence level should be well-calibrated with its actual performance. While it is now common sense that LLM performances are greatly impacted by prompts, the confidence calibration in prompting LLMs has yet to be thoroughly explored.In this paper, we explore how different prompting strategies influence LLM confidence calibration and how it could be improved. We conduct extensive experiments on six prompting methods in the question-answering context and we... | Xinran Zhao, Hongming Zhang, Xiaoman Pan, Wenlin Yao, Dong Yu, Tongshuang Wu, Jianshu Chen |  |
| 1501 |  |  [DB-LLM: Accurate Dual-Binarization for Efficient LLMs](https://doi.org/10.18653/v1/2024.findings-acl.516) |  | 0 | Large language models (LLMs) have significantly advanced the field of natural language processing, while the expensive memory and computation consumption impede their practical deployment. Quantization emerges as one of the most effective methods for improving the computational efficiency of LLMs. However, existing ultra-low-bit quantization always causes severe accuracy drops. In this paper, we empirically investigate the micro and macro characteristics of ultra-low bit quantization and... | Hong Chen, Chengtao Lv, Liang Ding, Haotong Qin, Xiabin Zhou, Yifu Ding, Xuebo Liu, Min Zhang, Jinyang Guo, Xianglong Liu, Dacheng Tao |  |
| 1502 |  |  [TempCompass: Do Video LLMs Really Understand Videos?](https://doi.org/10.18653/v1/2024.findings-acl.517) |  | 0 | Recently, there is a surge in interest surrounding video large language models (Video LLMs). However, existing benchmarks fail to provide a comprehensive feedback on the temporal perception ability of Video LLMs. On the one hand, most of them are unable to distinguish between different temporal aspects (e.g., speed, direction) and thus cannot reflect the nuanced performance on these specific aspects. On the other hand, they are limited in the diversity of task formats (e.g., only multi-choice... | Yuanxin Liu, Shicheng Li, Yi Liu, Yuxiang Wang, Shuhuai Ren, Lei Li, Sishuo Chen, Xu Sun, Lu Hou |  |
| 1503 |  |  ["Get Their Hands Dirty, Not Mine": On Researcher-Annotator Collaboration and the Agency of Annotators](https://doi.org/10.18653/v1/2024.findings-acl.518) |  | 0 | Annotation quality is often framed as post-hoc cleanup of annotator-caused issues. This position paper discusses whether, how, and why this narrative limits the scope of improving annotation. We call to consider annotation as a procedural collaboration, outlining three points in this direction:(1) An issue can be either annotator- or researcher-oriented, where one party is accountable and the other party may lack ability to fix it; (2) yet, they can co-occur or have similar consequences, and... | Shengqi Zhu, Jeffrey M. Rzeszotarski |  |
| 1504 |  |  [Teaching Large Language Models an Unseen Language on the Fly](https://doi.org/10.18653/v1/2024.findings-acl.519) |  | 0 | Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones, for which there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through prompting. To study this question, we collect a research suite for Zhuang, a language supported by no LLMs currently. We introduce DiPMT++, a framework for adapting LLMs to unseen languages by... | Chen Zhang, Xiao Liu, Jiuheng Lin, Yansong Feng |  |
| 1505 |  |  [Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.520) |  | 0 | Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks, such as machine translation, text summarization. Recent research (Kocmi and Federmann, 2023) has shown that utilizing LLMs for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conduct an investigation... | Qingyu Lu, Baopu Qiu, Liang Ding, Kanjian Zhang, Tom Kocmi, Dacheng Tao |  |
| 1506 |  |  [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.521) |  | 0 | The Large Vision-Language Models (LVLMs) have demonstrated great abilities in image perception and language understanding. However, existing datasets either focus solely on primary perception abilities and commonsense knowledge, or have a low level of text comprehension difficulty, which are insufficient to reflect the comprehensive capabilities of LVLMs, particularly in terms of Chinese language proficiency. We propose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance... | Yi Zong, Xipeng Qiu |  |
| 1507 |  |  [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](https://doi.org/10.18653/v1/2024.findings-acl.522) |  | 0 | We present DiffChat, a novel method to align Large Language Models (LLMs) to “chat” with prompt-as-input Text-to-Image Synthesis (TIS)models (e.g., Stable Diffusion) for interactive image creation. Given a raw prompt/image and a user-specified instruction, DiffChat can effectively make appropriate modifications and generate the target prompt, which can be leveraged to create the target image of high quality. To achieve this, we first collect an instruction-following prompt engineering dataset... | Jiapeng Wang, Chengyu Wang, Tingfeng Cao, Jun Huang, Lianwen Jin |  |
| 1508 |  |  [Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration](https://doi.org/10.18653/v1/2024.findings-acl.523) |  | 0 | We identify two crucial limitations in the evaluation of recent parallel-integrated method Parallel Context Windows (PCW), which extends the maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing window-wise attention and positional embedding techniques. We first show that a simple yet strong baseline, weighted sum ensemble, is missing for the in-context few-shot classification. Moreover, on more challenging Chain-of-Thought (CoT) reasoning (e.g., HotpotQA), PCW would... | Kejuan Yang, Xiao Liu, Kaiwen Men, Aohan Zeng, Yuxiao Dong, Jie Tang |  |
| 1509 |  |  [Rationales for Answers to Simple Math Word Problems Confuse Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.524) |  | 0 | Recently, large language models (LLMs) have demonstrated breakthrough mathematical problem-solving capabilities in grade school math word problems (MWP). For example, on the MWP benchmark GSM8K, the accuracy of GPT-3.5-Turbo and MetaMath-70B reaches 80.80% and 82.30%, respectively. One question arises, does it mean that LLMs have truly mastered related mathematical problem-solving abilities? In this paper, by presenting two types of benchmarks, where MCGSM8K aims at selecting one correct... | Yidan Zhang, Mingfeng Xue, Dayiheng Liu, Zhenan He |  |
| 1510 |  |  [ResLoRA: Identity Residual Mapping in Low-Rank Adaption](https://doi.org/10.18653/v1/2024.findings-acl.525) |  | 0 | As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs). However, updating the weights of LoRA blocks effectively and expeditiously is challenging due to the long calculation path in the original model. To address this, we propose ResLoRA, an improved framework of LoRA. By adding residual paths during training and using merging approaches to eliminate these extra paths during inference,... | Shuhua Shi, Shaohan Huang, Minghui Song, Zhoujun Li, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang |  |
| 1511 |  |  [Towards Objectively Benchmarking Social Intelligence of Language Agents at the Action Level](https://doi.org/10.18653/v1/2024.findings-acl.526) |  | 0 | Prominent large language models have exhibited human-level performance in many domains, even enabling the derived agents to simulate human and social interactions. While practical works have substantiated the practicability of grounding language agents in sandbox simulation or embodied simulators, current social intelligence benchmarks either stay at the language level or use subjective metrics. In pursuit of a more realistic and objective evaluation, we introduce the Social Tasks in Sandbox... | Chenxu Wang, Bin Dai, Huaping Liu, Baoyuan Wang |  |
| 1512 |  |  [Semantic Role Labeling from Chinese Speech via End-to-End Learning](https://doi.org/10.18653/v1/2024.findings-acl.527) |  | 0 | Semantic Role Labeling (SRL), crucial for understanding semantic relationships in sentences, has traditionally focused on text-based input. However, the increasing use of voice assistants and the need for hands-free interaction have highlighted the importance of SRL from speech.SRL from speech can be accomplished via a two-step pipeline directly: transcribing speech to text via Automatic Speech Recognition (ASR) and then applying text-based SRL, which could lead to error propagation and loss of... | Huiyao Chen, Xinxin Li, Meishan Zhang, Min Zhang |  |
| 1513 |  |  [MEEL: Multi-Modal Event Evolution Learning](https://doi.org/10.18653/v1/2024.findings-acl.528) |  | 0 | Multi-modal Event Reasoning (MMER) endeavors to endow machines with the ability to comprehend intricate event relations across diverse data modalities. MMER is fundamental and underlies a wide broad of applications. Despite extensive instruction fine-tuning, current multi-modal large language models still fall short in such ability. The disparity stems from that existing models are insufficient to capture underlying principles governing event evolution in various scenarios. In this paper, we... | Zhengwei Tao, Zhi Jin, Junqiang Huang, Xiancai Chen, Xiaoying Bai, Yifan Zhang, Chongyang Tao |  |
| 1514 |  |  [LLM-REDIAL: A Large-Scale Dataset for Conversational Recommender Systems Created from User Behaviors with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.529) |  | 0 | The large-scale conversational recommendation dataset is pivotal for the development of conversational recommender systems (CRS). Most existing CRS datasets suffers from the problems of data inextensibility and semantic inconsistency. To tackle these limitations and establish a benchmark in the conversational recommendation scenario, in this paper, we introduce the LLM-REDIAL dataset to facilitate the research in CRS. LLM-REDIAL is constructed by leveraging large language models (LLMs) to... | Tingting Liang, Chenxin Jin, Lingzhi Wang, Wenqi Fan, Congying Xia, Kai Chen, Yuyu Yin |  |
| 1515 |  |  [Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models](https://doi.org/10.18653/v1/2024.findings-acl.530) |  | 0 | LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks introducing LLM biases into consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been widely studied, especially for specific stereotypes (e.g., Asians are good at math). In this paper, we investigate bias along less-studied but still consequential, dimensions, such as age and beauty,... | Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim |  |
| 1516 |  |  [EVIT: Event-Oriented Instruction Tuning for Event Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.531) |  | 0 | Events refer to specific occurrences, incidents, or happenings that take place under a particular background. Event reasoning aims to infer events according to certain relations and predict future events. The cutting-edge techniques for event reasoning play a crucial role in various natural language processing applications. Large language models (LLMs) have made significant advancements in event reasoning owing to their wealth of knowledge and reasoning capabilities. However, smaller... | Zhengwei Tao, Xiancai Chen, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Yiwei Lou |  |
| 1517 |  |  [InstructCMP: Length Control in Sentence Compression through Instruction-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.532) |  | 0 | Extractive summarization can produce faithful summaries but often requires additional constraints such as a desired summary length. Traditional sentence compression models do not typically consider the constraints because of their restricted model abilities, which require model modifications for coping with them. To bridge this gap, we propose Instruction-based Compression (InstructCMP), an approach to the sentence compression task that can consider the length constraint through instructions by... | JuseonDo, Hidetaka Kamigaito, Manabu Okumura, Jingun Kwon |  |
| 1518 |  |  [SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation](https://doi.org/10.18653/v1/2024.findings-acl.533) |  | 0 | Citing pertinent literature is pivotal to writing and reviewing a scientific document. Existing techniques mainly focus on the local context or the global context for recommending citations but fail to consider the actual human citation behaviour. We propose SymTax, a three-stage recommendation architecture that considers both the local and the global context, and additionally the taxonomical representations of query-candidate tuples and the Symbiosis prevailing amongst them. SymTax learns to... | Karan Goyal, Mayank Goel, Vikram Goyal, Mukesh K. Mohania |  |
| 1519 |  |  [Assessing News Thumbnail Representativeness: Counterfactual text can enhance the cross-modal matching ability](https://doi.org/10.18653/v1/2024.findings-acl.534) |  | 0 | This paper addresses the critical challenge of assessing the representativeness of news thumbnail images, which often serve as the first visual engagement for readers when an article is disseminated on social media. We focus on whether a news image represents the actors discussed in the news text. To serve the challenge, we introduce NewsTT, a manually annotated dataset of 1000 news thumbnail images and text pairs. We found that the pretrained vision and language models, such as BLIP-2,... | Yejun Yoon, Seunghyun Yoon, Kunwoo Park |  |
| 1520 |  |  [Towards Better Question Generation in QA-based Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.535) |  | 0 | Event Extraction (EE) is an essential information extraction task that aims to extract event-related information from unstructured texts.The paradigm of this task has shifted from conventional classification-based methods to more contemporary question-answering-based (QA-based) approaches. However, in QA-based EE, the quality of the questions dramatically affects the extraction accuracy, and how to generate high-quality questions for QA-based EE remains a challenge. In this work, to tackle this... | Zijin Hong, Jian Liu |  |
| 1521 |  |  [Budget-Constrained Tool Learning with Planning](https://doi.org/10.18653/v1/2024.findings-acl.536) |  | 0 | Despite intensive efforts devoted to tool learning, the problem of budget-constrained tool learning, which focuses on resolving user queries within a specific budget constraint, has been widely overlooked. This paper proposes a novel method for budget-constrained tool learning. Our approach involves creating a preferable plan under the budget constraint before utilizing the tools. This plan outlines the feasible tools and the maximum number of times they can be employed, offering a... | Yuanhang Zheng, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu |  |
| 1522 |  |  [TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.537) |  | 0 | Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following. We introduce TextBind, an almost annotation-free framework... | Huayang Li, Siheng Li, Deng Cai, Longyue Wang, Lemao Liu, Taro Watanabe, Yujiu Yang, Shuming Shi |  |
| 1523 |  |  [The Critique of Critique](https://doi.org/10.18653/v1/2024.findings-acl.538) |  | 0 |  | Shichao Sun, Junlong Li, Weizhe Yuan, Ruifeng Yuan, Wenjie Li, Pengfei Liu |  |
| 1524 |  |  [CoCo-Agent: A Comprehensive Cognitive MLLM Agent for Smartphone GUI Automation](https://doi.org/10.18653/v1/2024.findings-acl.539) |  | 0 | Multimodal large language models (MLLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation.However, those GUI agents require comprehensive cognition including exhaustive perception and reliable action response.We propose a Comprehensive Cognitive LLM Agent, CoCo-Agent, with two novel approaches, comprehensive environment perception (CEP) and conditional action prediction... | Xinbei Ma, Zhuosheng Zhang, Hai Zhao |  |
| 1525 |  |  [FRVA: Fact-Retrieval and Verification Augmented Entailment Tree Generation for Explainable Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.540) |  | 0 | Structured entailment tree can exhibit the reasoning chains from knowledge facts to predicted answers, which is important for constructing an explainable question answering system. Existing works mainly include directly generating the entire tree and stepwise generating the proof steps. The stepwise methods can exploit combinatoriality and generalize to longer steps, but they have large fact search spaces and error accumulation problems resulting in the generation of invalid steps. In this... | Yue Fan, Hu Zhang, Ru Li, Yujie Wang, Hongye Tan, Jiye Liang |  |
| 1526 |  |  [P4: Plug-and-Play Discrete Prompting for Large Language Models Personalization](https://doi.org/10.18653/v1/2024.findings-acl.541) |  | 0 | Empowering Large Language Models (LLMs) with distinct human-like personality traits has become an innovative task for developing advanced dialog systems.Although LLMs demonstrate impressive capabilities in following instructions, directly prompting them to exhibit certain personalities through manually crafted instructions may result in sub-optimal performance.In this paper, we propose a plug-and-play prompting method to manipulate the LLMs’ personality traits.Specifically, we append discrete... | Yuansen Zhang, Xiao Wang, Tianze Chen, Jiayi Fu, Tao Gui, Qi Zhang |  |
| 1527 |  |  [Large Language Models Can Learn Representation in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.542) |  | 0 | One major challenge for Large Language Models (LLMs) is completing complex tasks involving multiple entities, such as tool APIs. To tackle this, one approach is to retrieve relevant entities to enhance LLMs in task completion. A crucial issue here is obtaining accurate natural language representations for each entity to aid in retriever precision. In this paper, we propose the Natural Language Representation Optimization Problem, which aims to refine entity descriptions for improved retrieval... | Yiduo Guo, Yaobo Liang, Dongyan Zhao, Nan Duan |  |
| 1528 |  |  [CTC-based Non-autoregressive Textless Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.543) |  | 0 | Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences. Recently, some research has turned to non-autoregressive (NAR) models to expedite decoding, yet the translation quality typically lags behind autoregressive (AR) models significantly. In this paper, we investigate the performance of CTC-based NAR models in S2ST, as these models have shown impressive results... | Qingkai Fang, Zhengrui Ma, Yan Zhou, Min Zhang, Yang Feng |  |
| 1529 |  |  [RRNorm: A Novel Framework for Chinese Disease Diagnoses Normalization via LLM-Driven Terminology Component Recognition and Reconstruction](https://doi.org/10.18653/v1/2024.findings-acl.544) |  | 0 | The Clinical Terminology Normalization aims at finding standard terms from a given termbase for mentions extracted from clinical texts. However, we found that extracted mentions suffer from the multi-implication problem, especially disease diagnoses. The reason for this is that physicians often use abbreviations, conjunctions, and juxtapositions when writing diagnoses, and it is difficult to manually decompose. To address this problem, we propose a Terminology Component Recognition and... | Yongqi Fan, Yansha Zhu, Kui Xue, Jingping Liu, Tong Ruan |  |
| 1530 |  |  [Unexpected Phenomenon: LLMs' Spurious Associations in Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.545) |  | 0 | Information extraction plays a critical role in natural language processing. When applying large language models (LLMs) to this domain, we discover an unexpected phenomenon: LLMs’ spurious associations. In tasks such as relation extraction, LLMs can accurately identify entity pairs, even if the given relation (label) is semantically unrelated to the pre-defined original one. To find these labels, we design two strategies in this study, including forward label extension and backward label... | Weiyan Zhang, Wanpeng Lu, Jiacheng Wang, Yating Wang, Lihan Chen, Haiyun Jiang, Jingping Liu, Tong Ruan |  |
| 1531 |  |  [AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought](https://doi.org/10.18653/v1/2024.findings-acl.546) |  | 0 | Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention.Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning knowledge from different languages. Despite achieving excellent performance, current methods still have two main challenges: (1) Manual language specification: They still highly rely on manually selecting the languages to integrate, severely affecting their... | Yongheng Zhang, Qiguang Chen, Min Li, Wanxiang Che, Libo Qin |  |
| 1532 |  |  [LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.547) |  | 0 | Multilingual neural machine translation models generally distinguish translation directions by the language tag (LT) in front of the source or target sentences. However, current LT strategies cannot indicate the desired target language as expected on zero-shot translation, i.e., the off-target issue. Our analysis reveals that the indication of the target language is sensitive to the placement of the target LT. For example, when placing the target LT on the decoder side, the indication would... | Zengkui Sun, Yijin Liu, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 1533 |  |  [Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data](https://doi.org/10.18653/v1/2024.findings-acl.548) |  | 0 | Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models’ capability in statistical and causal reasoning with real-world data. The benchmark comprises a carefully constructed dataset of 411 questions accompanied by data sheets from textbooks, online learning materials, and academic papers. To compare models’... | Xiao Liu, Zirui Wu, Xueqing Wu, Pan Lu, KaiWei Chang, Yansong Feng |  |
| 1534 |  |  [On the Vulnerability of Safety Alignment in Open-Access LLMs](https://doi.org/10.18653/v1/2024.findings-acl.549) |  | 0 | Large language models (LLMs) possess immense capabilities but are susceptible to malicious exploitation. To mitigate the risk, safety alignment is employed to align LLMs with ethical standards. However, safety-aligned LLMs may remain vulnerable to carefully crafted jailbreak attacks, but these attacks often face high rejection rates and limited harmfulness. In this paper, we expose the vulnerabilities of safety alignment in open-access LLMs, which can significantly enhance the success rate and... | Jingwei Yi, Rui Ye, Qisi Chen, Bin Zhu, Siheng Chen, Defu Lian, Guangzhong Sun, Xing Xie, Fangzhao Wu |  |
| 1535 |  |  [PEK: A Parameter-Efficient Framework for Knowledge-Grounded Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.550) |  | 0 | Pre-trained language models (PLMs) have shown great dialogue generation capability in different scenarios. However, the huge VRAM consumption when fine-tuning them is one of their drawbacks. PEFT approaches can significantly reduce the number of trainable parameters, which enables us to fine-tune larger dialogue generation models. However, the reduction in parameter quantity can diminish a PLM’s expressive capacity and affect the PLM’s learning from certain specific examples like... | Pan Yang, Dandan Song, Zhijing Wu, Yanru Zhou |  |
| 1536 |  |  [Evidence Retrieval is almost All You Need for Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.551) |  | 0 | Current fact verification methods generally follow the two-stage training paradigm: evidence retrieval and claim verification. While existing works focus on developing sophisticated claim verification modules, the fundamental importance of evidence retrieval is largely ignored. Existing approaches usually adopt the heuristic semantic similarity-based retrieval strategy, resulting in the task-irrelevant evidence and undesirable performance. In this paper, we concentrate on evidence retrieval and... | Liwen Zheng, Chaozhuo Li, Xi Zhang, Yuming Shang, Feiran Huang, Haoran Jia |  |
| 1537 |  |  [Outdated Issue Aware Decoding for Factual Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.552) |  | 0 | Recently, Knowledge Editing has received increasing attention, since it could update the specific knowledge from outdated ones in pretrained models without re-training. However, as pointed out by recent studies, existing related methods tend to merely memorize the superficial word composition of the edited knowledge, rather than truly learning and absorbing it. Consequently, on the reasoning questions, we discover that existing methods struggle to utilize the edited knowledge to reason the new... | Zengkui Sun, Yijin Liu, Jiaan Wang, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou |  |
| 1538 |  |  [Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness](https://doi.org/10.18653/v1/2024.findings-acl.553) |  | 0 | Dialects introduce syntactic and lexical variations in language that occur in regional or social groups. Most NLP methods are not sensitive to such variations. This may lead to unfair behavior of the methods, conveying negative bias towards dialect speakers. While previous work has studied dialect-related fairness for aspects like hate speech, other aspects of biased language, such as lewdness, remain fully unexplored. To fill this gap, we investigate performance disparities between dialects in... | Maximilian Spliethöver, Sai Nikhil Menon, Henning Wachsmuth |  |
| 1539 |  |  [DP-MLM: Differentially Private Text Rewriting Using Masked Language Models](https://doi.org/10.18653/v1/2024.findings-acl.554) |  | 0 |  | Stephen Meisenbacher, Maulik Chevli, Juraj Vladika, Florian Matthes |  |
| 1540 |  |  [Question-Instructed Visual Descriptions for Zero-Shot Video Answering](https://doi.org/10.18653/v1/2024.findings-acl.555) |  | 0 | We present Q-ViD, a simple approach for video question answering (video QA), that unlike prior methods, which are based on complex architectures, computationally expensive pipelines or use closed models like GPTs, Q-ViD relies on a single instruction-aware open vision-language model (InstructBLIP) to tackle videoQA using frame descriptions. Specifically, we create captioning instruction prompts that rely on the target questions about the videos and leverage InstructBLIP to obtain video frame... | David Mogrovejo, Thamar Solorio |  |
| 1541 |  |  [EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.556) |  | 0 | Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in accuracy improvement, let alone explainability, a critical capability of fact verification systems.Constructing an explainable fact verification system in a complex multi-hop scenario is consistently impeded by the absence of a relevant, high-quality dataset. Previous datasets either suffer from excessive simplification or fail to incorporate essential... | Huanhuan Ma, Weizhi Xu, Yifan Wei, Liuji Chen, Liang Wang, Qiang Liu, Shu Wu |  |
| 1542 |  |  [Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.557) |  | 0 | Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial and urgent problem.This paper first delivers three key observations: (1) the current agent training corpus is entangled with both formats following and agent reasoning, which significantly shifts from the distribution of its pre-training data; (2) LLMs exhibit... | Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Jiangning Liu, Dahua Lin, Kai Chen, Feng Zhao |  |
| 1543 |  |  [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](https://doi.org/10.18653/v1/2024.findings-acl.558) |  | 0 | Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factually correct, making it extremely hard for the users to spot them. Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. Here, we aim to bridge this gap. In particular, we... | Ekaterina Fadeeva, Aleksandr Rubashevskii, Artem Shelmanov, Sergey Petrakov, Haonan Li, Hamdy Mubarak, Evgenii Tsymbalov, Gleb Kuzmin, Alexander Panchenko, Timothy Baldwin, Preslav Nakov, Maxim Panov |  |
| 1544 |  |  [Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.559) |  | 0 | Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine... | Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Zhouhao Sun, Shi Jun, Ting Liu, Bing Qin |  |
| 1545 |  |  [Critical Learning Periods: Leveraging Early Training Dynamics for Efficient Data Pruning](https://doi.org/10.18653/v1/2024.findings-acl.560) |  | 0 | Neural Machine Translation models are extremely data and compute-hungry. However, not all datapoints contribute equally to model training and generalization. Data pruning to remove the low-value data points has the benefit of drastically reducing the compute budget without significantdrop in model performance. In this paper, we propose a new data pruning technique: CheckpointsAcross Time (CAT ), that leverages early model training dynamics to identify the most relevantdata points for model... | Everlyn Chimoto, Jay Gala, Orevaoghene Ahia, Julia Kreutzer, Bruce A. Bassett, Sara Hooker |  |
| 1546 |  |  [What Are You Token About? Differentiable Perturbed Top-k Token Selection for Scientific Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.561) |  | 0 | Scientific document summarization aims to condense complex and long articles in both technical and plain-language terms to facilitate the accessibility and dissemination of scientific findings. Existing datasets suffer from a deficiency in source heterogeneity, as their data predominantly stem from a single common resource, hindering effective model training and generalizability. First, we introduce SciLay, a novel dataset that includes documents from multiple natural science journals with... | Luca Ragazzi, Paolo Italiani, Gianluca Moro, Mattia Panni |  |
| 1547 |  |  [Description Boosting for Zero-Shot Entity and Relation Classification](https://doi.org/10.18653/v1/2024.findings-acl.562) |  | 0 | Zero-shot entity and relation classification models leverage available external information of unseen classes – e.g., textual descriptions – to annotate input text data. Thanks to the minimum data requirement, Zero-Shot Learning (ZSL) methods have high value in practice, especially in applications where labeled data is scarce. Even though recent research in ZSL has demonstrated significant results, our analysis reveals that those methods are sensitive to provided textual descriptions of... | Gabriele Picco, Leopold Fuchs, Marcos Martínez Galindo, Alberto Purpura, Vanessa López, Hoang Thanh Lam |  |
| 1548 |  |  [Domain-Aware k-Nearest-Neighbor Knowledge Distillation for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.563) |  | 0 | kNN-MT has utilized neighborhood knowledge for auxiliary decoding, significantly improving translation performance. Subsequently, kNN-KD transitions the use of neighborhood knowledge from the decoding phase to the training phase, to address the temporal and spatial inefficiencies inherent in kNN-MT. However, kNN-KD transfers all the kNN knowledge arbitrarily, which has the potential to restrict the learning of student models. In this paper, we propose a novel domain-aware kNN-KD method, which... | Zhexuan Wang, Shudong Liu, Xuebo Liu, Miao Zhang, Derek F. Wong, Min Zhang |  |
| 1549 |  |  [Beyond Single-Event Extraction: Towards Efficient Document-Level Multi-Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.564) |  | 0 | Recent mainstream event argument extraction methods process each event in isolation, resulting in inefficient inference and ignoring the correlations among multiple events. To address these limitations, here we propose a multiple-event argument extraction model DEEIA (Dependency-guided Encoding and Event-specific Information Aggregation), capable of extracting arguments from all events within a document simultaneously. The proposed DEEIA model employs a multi-event prompt mechanism, comprising... | Wanlong Liu, Li Zhou, Dingyi Zeng, Yichen Xiao, Shaohuan Cheng, Chen Zhang, Grandee Lee, Malu Zhang, Wenyu Chen |  |
| 1550 |  |  [Revisiting Interpolation Augmentation for Speech-to-Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.565) |  | 0 | Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization in other domains. Despite its potential, this technique’s application in S2T tasks has remained under-explored. In this paper, we delve into the utility of interpolation augmentation, guided by... | Chen Xu, Jie Wang, Xiaoqian Liu, Qian Dong, Chunliang Zhang, Tong Xiao, JingBo Zhu, Dapeng Man, Wu Yang |  |
| 1551 |  |  [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://doi.org/10.18653/v1/2024.findings-acl.566) |  | 0 | Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a... | Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Lijia Sun, Xibin Gao, Yi Zhang |  |
| 1552 |  |  [Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning](https://doi.org/10.18653/v1/2024.findings-acl.567) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of Large Language Models (LLMs) to various downstream applications. However, the effectiveness of the PEFT diminishes notably when downstream tasks require accurate learning of specific knowledge. In this paper, we adopt a semantic perspective to investigate this phenomenon, uncovering the reasons behind PEFT’s limitations in knowledge learning task. Our findings reveals that: (1) PEFT presents a notable risk of pushing... | Renzhi Wang, Piji Li |  |
| 1553 |  |  [Leveraging Collection-Wide Similarities for Unsupervised Document Structure Extraction](https://doi.org/10.18653/v1/2024.findings-acl.568) |  | 0 | Document collections of various domains, e.g., legal, medical, or financial, often share some underlying collection-wide structure, which captures information that can aid both human users and structure-aware models.We propose to identify the typical structure of document within a collection, which requires to capture recurring topics across the collection, while abstracting over arbitrary header paraphrases, and ground each topic to respective document locations. These requirements pose... | Gili Lior, Yoav Goldberg, Gabriel Stanovsky |  |
| 1554 |  |  [Enhancing Cross Text-Molecule Learning by Self-Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.569) |  | 0 | The development of Large Language Models (LLMs) has greatly advanced the field of drug discovery, with the belief that natural language can enhance human control over molecule design. However, the scarcity of high-quality labeled data remains a challenge for cross text-molecule learning. Existing datasets are limited due to the difficulty of collecting precise molecule-description pairs. Although recent efforts have utilized pseudo data generated by LLMs for augmentation, the lack of... | Yinuo Jiang, Xiang Zhuang, Keyan Ding, Qiang Zhang, Huajun Chen |  |
| 1555 |  |  [RePALM: Popular Quote Tweet Generation via Auto-Response Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.570) |  | 0 | A quote tweet enables users to share others’ content while adding their own commentary. In order to enhance public engagement through quote tweets, we investigate the task of generating popular quote tweets. This task aims to produce quote tweets that garner higher popularity, as indicated by increased likes, replies, and retweets. Despite the impressive language generation capabilities of large language models (LLMs), there has been limited research on how LLMs can effectively learn the... | Erxin Yu, Jing Li, Chunpu Xu |  |
| 1556 |  |  [On the Effect of (Near) Duplicate Subwords in Language Modelling](https://doi.org/10.18653/v1/2024.findings-acl.571) |  | 0 | Tokenisation is a core part of language models (LMs). It involves splitting a character sequence into subwords which are assigned random indices before being served to the LM. However, this process—while typically lossless—may lead to less efficient LM training, because it removes character-level information, thereby making it more difficult to generalise across similar subwords, such as \*now\* and \*Now\*. We refer to such subwords as \*\*near duplicates\*\*. In this paper, we study the... | Anton Schäfer, Thomas Hofmann, Imanol Schlag, Tiago Pimentel |  |
| 1557 |  |  [Do Pre-Trained Language Models Detect and Understand Semantic Underspecification? Ask the DUST!](https://doi.org/10.18653/v1/2024.findings-acl.572) |  | 0 | In everyday language use, speakers frequently utter and interpret sentences that are semantically underspecified, namely, whose content is insufficient to fully convey their message or interpret them univocally. For example, to interpret the underspecified sentence “Don’t spend too much”, which leaves implicit what (not) to spend, additional linguistic context or outside knowledge is needed. In this work, we propose a novel Dataset of semantically Underspecified Sentences grouped by Type (DUST)... | Frank Wildenburg, Michael Hanna, Sandro Pezzelle |  |
| 1558 |  |  [Visual Hallucinations of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.573) |  | 0 | Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines incorrect details about an image in visual question answering. Existing studies find VH instances only in existing image datasets, which results in biased understanding of MLLMs’ performance under VH due to limited diversity of such VH instances. In this work, we propose a tool called VHTest to generate a diverse set of VH instances. Specifically, VHTest finds some initial VH instances in existing image datasets (e.g.,... | Wen Huang, Hongbin Liu, Minxin Guo, Neil Gong |  |
| 1559 |  |  [SumSurvey: An Abstractive Dataset of Scientific Survey Papers for Long Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.574) |  | 0 | With the popularity of large language models (LLMs) and their ability to handle longer input documents, there is a growing need for high-quality long document summarization datasets. Although many models already support 16k input, current lengths of summarization datasets are inadequate, and salient information is not evenly distributed. To bridge these gaps, we collect a new summarization dataset called SumSurvey, consisting of more than 18k scientific survey papers. With an average document... | Ran Liu, Ming Liu, Min Yu, He Zhang, Jianguo Jiang, Gang Li, Weiqing Huang |  |
| 1560 |  |  [Pushing the Limits of Low-Resource NER Using LLM Artificial Data Generation](https://doi.org/10.18653/v1/2024.findings-acl.575) |  | 0 | Named Entity Recognition (NER) is an important task, but to achieve great performance, it is usually necessary to collect a large amount of labeled data, incurring high costs. In this paper, we propose using open-source Large Language Models (LLM) to generate NER data with only a few labeled examples, reducing the cost of human annotations. Our proposed method is very simple and can perform well using only a few labeled data points. Experimental results on diverse low-resource NER datasets show... | Joan Santoso, Patrick Sutanto, Billy Cahyadi, Esther Irawati Setiawan |  |
| 1561 |  |  [Understanding and Patching Compositional Reasoning in LLMs](https://doi.org/10.18653/v1/2024.findings-acl.576) |  | 0 | LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. Our research embarks on a quest to uncover the root causes of compositional reasoning failures of LLMs, uncovering that most of them stem from the improperly generated or leveraged implicit reasoning results. Inspired by our empirical findings, we resort to Logit Lens and an intervention experiment to dissect the inner hidden states of LLMs. This deep dive reveals that implicit reasoning... | Zhaoyi Li, Gangwei Jiang, Hong Xie, Linqi Song, Defu Lian, Ying Wei |  |
| 1562 |  |  [Bilingual Rhetorical Structure Parsing with Large Parallel Annotations](https://doi.org/10.18653/v1/2024.findings-acl.577) |  | 0 | Discourse parsing is a crucial task in natural language processing that aims to reveal the higher-level relations in a text. Despite growing interest in cross-lingual discourse parsing, challenges persist due to limited parallel data and inconsistencies in the Rhetorical Structure Theory (RST) application across languages and corpora. To address this, we introduce a parallel Russian annotation for the large and diverse English GUM RST corpus. Leveraging recent advances, our end-to-end RST... | Elena Chistova |  |
| 1563 |  |  [Book2Dial: Generating Teacher Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](https://doi.org/10.18653/v1/2024.findings-acl.578) |  | 0 | Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student interactions grounded in a set of textbooks. Our approaches capture a key aspect of learning interactions where curious students with partial knowledge interactively ask teachers questions about the material... | Junling Wang, Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Mrinmaya Sachan |  |
| 1564 |  |  [SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.579) |  | 0 |  | Wenxin Liang, Tingyu Zhang, Han Liu, Feng Zhang |  |
| 1565 |  |  [Automated Focused Feedback Generation for Scientific Writing Assistance](https://doi.org/10.18653/v1/2024.findings-acl.580) |  | 0 | Scientific writing is a challenging task, particularly for novice researchers who often rely on feedback from experienced peers. Recent work has primarily focused on improving surface form and style rather than manuscript content. In this paper, we propose a novel task: automated focused feedback generation for scientific writing assistance. We present SWIF2T: a Scientific WrIting Focused Feedback Tool. It is designed to generate specific, actionable and coherent comments, which identify... | Eric Chamoun, Michael Sejr Schlichtkrull, Andreas Vlachos |  |
| 1566 |  |  [FastGAS: Fast Graph-based Annotation Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.581) |  | 0 | In-context learning (ICL) empowers large language models (LLMs) to tackle new tasks by using a series of training instances as prompts. Since generating the prompts needs to sample from a vast pool of instances and annotate them (e.g., add labels in classification task), existing methods have proposed to select a subset of unlabeled examples for annotation, thus enhancing the quality of prompts and concurrently mitigating annotation costs. However, these methods often require a long time to... | Zihan Chen, Song Wang, Cong Shen, Jundong Li |  |
| 1567 |  |  [Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations](https://doi.org/10.18653/v1/2024.findings-acl.582) |  | 0 | Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly compatible with further tuning and compression. However, as the coarse-grained structured pruning poses large damage to the highly interconnected model, achieving a high compression ratio for scaled-up LLMs remains a challenge. In this paper, we introduce a... | Bowen Shen, Zheng Lin, Daren Zha, Wei Liu, Jian Luan, Bin Wang, Weiping Wang |  |
| 1568 |  |  [Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.583) |  | 0 | Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages. While byte-based tokenization addresses... | Langlin Huang, Yang Feng |  |
| 1569 |  |  [Deductive Closure Training of Language Models for Coherence, Accuracy, and Updatability](https://doi.org/10.18653/v1/2024.findings-acl.584) |  | 0 | While language models (LMs) can sometimes generate factually correct text and estimate truth values of individual claims, these generally do not reflect a globally coherent, manipulable model of the world. As a consequence, current LMs also generate incorrect or nonsensical content, and are difficult to edit and bring up to date. We present a method called Deductive Closure Training (DCT) that uses LMs themselves to identify implications of (and contradictions within) the text that they... | Afra Feyza Akyürek, Ekin Akyürek, Leshem Choshen, Derry Wijaya, Jacob Andreas |  |
| 1570 |  |  [Self-Supervised Singing Voice Pre-Training towards Speech-to-Singing Conversion](https://doi.org/10.18653/v1/2024.findings-acl.585) |  | 0 | Speech-to-singing voice conversion (STS) task always suffers from data scarcity, because it requires paired speech and singing data. Compounding this issue are the challenges of content-pitch alignment and the suboptimal quality of generated outputs, presenting significant hurdles in STS research. This paper presents SVPT, an STS approach boosted by a self-supervised singing voice pre-training model.We leverage spoken language model techniques to tackle the rhythm alignment problem and the... | Ruiqi Li, Rongjie Huang, Yongqi Wang, Zhiqing Hong, Zhou Zhao |  |
| 1571 |  |  [Evaluating Large Language Model Biases in Persona-Steered Generation](https://doi.org/10.18653/v1/2024.findings-acl.586) |  | 0 | The task of persona-steered text generation requires large language models (LLMs) to generate text that reflects the distribution of views that an individual fitting a persona could have. People have multifaceted personas, but prior work on bias in LLM-generated opinions has only explored multiple-choice settings or one-dimensional personas. We define an incongruous persona as a persona with multiple traits where one trait makes its other traits less likely in human survey data, e.g. political... | Andy Liu, Mona T. Diab, Daniel Fried |  |
| 1572 |  |  [Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization](https://doi.org/10.18653/v1/2024.findings-acl.587) |  | 0 | The rapid increase in multimedia data has spurred advancements in Multimodal Summarization with Multimodal Output (MSMO), which aims to produce a multimodal summary that integrates both text and relevant images. The inherent heterogeneity of content within multimodal inputs and outputs presents a significant challenge to the execution of MSMO. Traditional approaches typically adopt a holistic perspective on coarse image-text data or individual visual objects, overlooking the essential... | Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen |  |
| 1573 |  |  [CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.588) |  | 0 | It is imperative to ensure the stability of every prediction made by a language model; that is, a language’s prediction should remain consistent despite minor input variations, like word substitutions. In this paper, we investigate the problem of certifying a language model’s robustness against Universal Text Perturbations (UTPs), which have been widely used in universal adversarial attacks and backdoor attacks. Existing certified robustness based on random smoothing has shown considerable... | Qian Lou, Xin Liang, Jiaqi Xue, Yancheng Zhang, Rui Xie, Mengxin Zheng |  |
| 1574 |  |  [Recovering document annotations for sentence-level bitext](https://doi.org/10.18653/v1/2024.findings-acl.589) |  | 0 | In machine translation, historical models were incapable of handling longer contexts, so the lack of document-level datasets was less noticeable. Now, despite the emergence of long-sequence methods, we remain within a sentence-level paradigm and without data to adequately approach context-aware machine translation. Most large-scale datasets have been processed through a pipeline that discards document-level metadata. In this work, we reconstruct document-level information for three (ParaCrawl,... | Rachel Wicks, Matt Post, Philipp Koehn |  |
| 1575 |  |  [MetaPro 2.0: Computational Metaphor Processing on the Effectiveness of Anomalous Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.590) |  | 0 | Metaphor interpretation is a difficult task in natural language understanding. The development of relevant techniques in this domain is slow, mostly because of the lack of large annotated datasets and effective pre-trained language models (PLMs) for metaphor learning. Thus, we propose a large annotated dataset and a PLM for the metaphor interpretation task. Our foundation model is based on a novel anomalous language modeling (ALM) method, which we benchmark with comparable PLM baselines on the... | Rui Mao, Kai He, Claudia Ong, Qian Liu, Erik Cambria |  |
| 1576 |  |  [Boosting LLM Agents with Recursive Contemplation for Effective Deception Handling](https://doi.org/10.18653/v1/2024.findings-acl.591) |  | 0 | Recent advances in large language models (LLMs) have led to significant success in using LLMs as agents. Nevertheless, a common assumption that LLMs always process honest information neglects the widespread deceptive or misleading content in human and AI-generated material. This oversight might expose LLMs to malicious manipulations. To enhance LLMs’ ability to identify and counteract deceptive information, in this paper, inspired by humans’ recursive thinking and perspective-taking, we... | Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, Gao Huang |  |
| 1577 |  |  [Direct Preference Optimization with an Offset](https://doi.org/10.18653/v1/2024.findings-acl.592) |  | 0 | Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language model to increase the likelihood of a preferred response over a dispreferred response. However, not all preference pairs are equal. Sometimes, the preferred response is only slightly better than the... | Afra Amini, Tim Vieira, Ryan Cotterell |  |
| 1578 |  |  [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation](https://doi.org/10.18653/v1/2024.findings-acl.593) |  | 0 | Direct speech-to-speech translation achieves high-quality results through the introduction of discrete units obtained from self-supervised learning. However, talking head translation, converting audio-visual speech (i.e., talking head video) from one language into another, still confronts several challenges compared to audio speech: (1) Existing methods invariably rely on cascading, synthesizing via both audio and text, resulting in delays and cascading errors. (2) Talking head translation has... | Xize Cheng, Rongjie Huang, Linjun Li, Zehan Wang, Tao Jin, Aoxiong Yin, Feiyang Chen, Xinyu Duan, Baoxing Huai, Zhou Zhao |  |
| 1579 |  |  [More than Minorities and Majorities: Understanding Multilateral Bias in Language Generation](https://doi.org/10.18653/v1/2024.findings-acl.594) |  | 0 | Pretrained models learned from real corpora can often capture undesirable features, leading to bias issues against different demographic groups. Most existing studies on bias dataset construction or bias mitigation methods only focus on one demographic group pair to study a certain bias, e.g. black vs. white for racial bias. However, in real-world applications, there are more than two demographic groups that are at risk of the same bias. In this paper, we propose to analyze and reduce biases... | Jiaxu Zhao, Zijing Shi, Yitong Li, Yulong Pei, Ling Chen, Meng Fang, Mykola Pechenizkiy |  |
| 1580 |  |  [Fair Federated Learning with Biased Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.595) |  | 0 | Existing literature that integrates CLIP into federated learning (FL) largely ignores the inherent group unfairness within CLIP and its ethical implications on FL applications. Furthermore, such CLIP bias may be amplified in FL, due to the unique issue of data heterogeneity across clients. However, in identity-sensitive FL applications, model fairness (i.e., group fairness) is imperative for model development. Therefore, this work explores a critical question ignored by the existing literature:... | Huimin Zeng, Zhenrui Yue, Yang Zhang, Lanyu Shang, Dong Wang |  |
| 1581 |  |  [SpeechGuard: Exploring the Adversarial Robustness of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.596) |  | 0 | Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this work, we investigate the potential vulnerabilities of such instruction-following speech-language models to adversarial attacks and jailbreaking. Specifically, we design algorithms that can generate adversarial examples to jailbreak SLMs in both white-box and... | Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel GarciaRomero, Sundararajan Srinivasan, Kyu J. Han, Katrin Kirchhoff |  |
| 1582 |  |  [ACUEval: Fine-grained Hallucination Evaluation and Correction for Abstractive Summarization](https://doi.org/10.18653/v1/2024.findings-acl.597) |  | 0 | The impressive generation capabilities of large language models (LLMs) have made it harder to detect the subtle hallucinations they make in abstractive summarization, where generated summaries consist of a blend of correct and incorrect information w.r.t. a given document. Recently-proposed LLM-based evaluation metrics attempt to capture this, but still face challenges: (1) they are biased towards summaries generated from the same underlying LLM, and (2) they lack interpretability, offering... | David Wan, Koustuv Sinha, Srini Iyer, Asli Celikyilmaz, Mohit Bansal, Ramakanth Pasunuru |  |
| 1583 |  |  [An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.598) |  | 0 | Multimodal Large Language Models (MLLMs) fine-tuned with multimodal instruction-following data have demonstrated formidable capabilities in multimodal tasks. However, fine-tuning all parameters of MLLMs has become challenging due to the rapid growth of the overall model’s parameters. To address this issue, we study Parameter-Efficient Fine-Tuning (PEFT) methods for MLLMs. We aim to identify effective methods for enhancing performance in scenarios where only a limited number of parameters are... | Xiongtao Zhou, Jie He, Yuhua Ke, Guangyao Zhu, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 1584 |  |  [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](https://doi.org/10.18653/v1/2024.findings-acl.599) |  | 0 | Recently, there has been growing interest within the community regarding whether large language models are capable of planning or executing plans. However, most prior studies use LLMs to generate high-level plans for simplified scenarios lacking linguistic complexity and domain diversity, limiting analysis of their planning abilities. These setups constrain evaluation methods (e.g., predefined action space), architectural choices (e.g., only generative models), and overlook the linguistic... | Arda Uzunoglu, Gözde Gül Sahin, Abdulfattah Safa |  |
| 1585 |  |  [TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation](https://doi.org/10.18653/v1/2024.findings-acl.600) |  | 0 | The recent advances in natural language processing have predominantly favored well-resourced English-centric models, resulting in a significant gap with low-resource languages. In this work, we introduce TURNA, a language model developed for the low-resource language Turkish and is capable of both natural language understanding and generation tasks.TURNA is pretrained with an encoder-decoder architecture based on the unified framework UL2 with a diverse corpus that we specifically curated for... | Gökçe Uludogan, Zeynep Yirmibesoglu Balal, Salih Furkan Akkurt, Meliksah Türker, Onur Güngör, Susan Üsküdarli |  |
| 1586 |  |  [MELD-ST: An Emotion-aware Speech Translation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.601) |  | 0 | Emotion plays a crucial role in human conversation. This paper underscores the significance of considering emotion in speech translation. We present the MELD-ST dataset for the emotion-aware speech translation task, comprising English-to-Japanese and English-to-German language pairs. Each language pair includes about 10,000 utterances annotated with emotion labels from the MELD dataset. Baseline experiments using the SeamlessM4T model on the dataset indicate that fine-tuning with emotion labels... | Sirou Chen, Sakiko Yahata, Shuichiro Shimizu, Zhengdong Yang, Yihang Li, Chenhui Chu, Sadao Kurohashi |  |
| 1587 |  |  [Designing Informative Metrics for Few-Shot Example Selection](https://doi.org/10.18653/v1/2024.findings-acl.602) |  | 0 | Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the “best” examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach avoids the training of a dedicated model for selection of examples, and instead uses certain metrics to align the syntactico-semantic complexity of test sentences and examples. We use both sentence-... | Rishabh Adiga, Lakshmi Subramanian, Varun Chandrasekaran |  |
| 1588 |  |  [Chain-of-Quizzes: Pedagogy-inspired Example Selection in In-Context-Learning](https://doi.org/10.18653/v1/2024.findings-acl.603) |  | 0 | In-context learning (ICL) has emerged as a powerful tool for enhancing large language models (LLMs) in addressing downstream tasks. In this paper, we explore the vital task of example selection in ICL by mimicking the human learning process. We propose a Chain-of-Quizzes (CoQ) framework inspired by educational theories such as Bruner’s Spiral Learning and Mastery Learning theory. Specifically, our framework employs the LLMs to answer the quiz (question in the example) to sift ‘good’ examples,... | Yiquan Wu, Anlai Zhou, Yuhang Liu, Yifei Liu, Adam Jatowt, Weiming Lu, Jun Xiao, Kun Kuang |  |
| 1589 |  |  [It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.604) |  | 0 | Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This process of elimination (PoE), when used with COT, can enhance self-consistency, interpretability, and tasks such as medical diagnoses of exclusion. Thus, we propose PoE with COT, where LLMs must reason toward incorrect options on multiple-choice questions. We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to... | Nishant Balepur, Shramay Palta, Rachel Rudinger |  |
| 1590 |  |  [From Discrimination to Generation: Low-Resource Intent Detection with Language Model Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.605) |  | 0 | Intent detection aims to identify user goals from utterances, and is a ubiquitous step towards the satisfaction of user desired needs in many interaction systems. As dynamic and varied intents arise, models that are capable of identifying new intents promptly are required. However, existing studies usually fine-tune discriminative models on the specific defined intent classes, precluding them from being directly adopted to new intent domains. In this paper, we introduce a generative pre-trained... | Feng Zhang, Wei Chen, Fei Ding, Meng Gao, Tengjiao Wang, Jiahui Yao, Jiabin Zheng |  |
| 1591 |  |  [Efficient Continual Pre-training for Building Domain Specific Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.606) |  | 0 | Large language models (LLMs) have demonstrated remarkable open-domain capabilities. LLMs tailored for a domain are typically trained entirely on domain corpus to excel at handling domain-specific tasks. In this work, we explore an alternative strategy of continual pre-training as a means to develop domain-specific LLMs over an existing open-domain LLM. We introduce FinPythia-6.9B, developed through domain-adaptive continual pre-training on the financial domain.Continual pre-trained FinPythia... | Yong Xie, Karan Aggarwal, Aitzaz Ahmad |  |
| 1592 |  |  [Distantly-Supervised Joint Extraction with Noise-Robust Learning](https://doi.org/10.18653/v1/2024.findings-acl.607) |  | 0 | Joint entity and relation extraction is a process that identifies entity pairs and their relations using a single model. We focus on the problem of joint extraction in distantly-labeled data, whose labels are generated by aligning entity mentions with the corresponding entity and relation tags using a knowledge base (KB). One key challenge is the presence of noisy labels arising from both incorrect entity and relation annotations, which significantly impairs the quality of supervised learning.... | Yufei Li, Xiao Yu, Yanghong Guo, Yanchi Liu, Haifeng Chen, Cong Liu |  |
| 1593 |  |  [LLM Factoscope: Uncovering LLMs' Factual Discernment through Measuring Inner States](https://doi.org/10.18653/v1/2024.findings-acl.608) |  | 0 | Large Language Models (LLMs) have revolutionized various domains with extensive knowledge and creative capabilities. However, a critical issue with LLMs is their tendency to produce outputs that diverge from factual reality. This phenomenon is particularly concerning in sensitive applications such as medical consultation and legal advice, where accuracy is paramount. Inspired by human lie detectors using physiological responses, we introduce the LLM Factoscope, a novel Siamese network-based... | Jinwen He, Yujia Gong, Zijin Lin, Cheng'an Wei, Yue Zhao, Kai Chen |  |
| 1594 |  |  [DictLLM: Harnessing Key-Value Data Structures with Large Language Models for Enhanced Medical Diagnostics](https://doi.org/10.18653/v1/2024.findings-acl.609) |  | 0 | Structured data offers an efficient means of organizing information. Exsisting text-serialization based methods for processing structured data using large language models (LLMs) are not designed to explicitly capture the heterogeneity of structured data. Such methods are suboptimal for LLMs to process structured data, and may lead to large input token size and poor robustness to input perturbation. In this paper, we propose a novel framework called DictLLM, which is an efficient and effective... | YiQiu Guo, Yuchen Yang, Ya Zhang, Yu Wang, Yanfeng Wang |  |
| 1595 |  |  [imapScore: Medical Fact Evaluation Made Easy](https://doi.org/10.18653/v1/2024.findings-acl.610) |  | 0 | Automatic evaluation of natural language generation (NLG) tasks has gained extensive research interests, since it can rapidly assess the performance of large language models (LLMs). However, automatic NLG evaluation struggles with medical QA because it fails to focus on the crucial correctness of medical facts throughout the generated text. To address this, this paper introduces a new data structure, imap, designed to capture key information in questions and answers, enabling evaluators to... | Huimin Wang, Yutian Zhao, Xian Wu, Yefeng Zheng |  |
| 1596 |  |  [Making Harmful Behaviors Unlearnable for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.611) |  | 0 | Large language models (LLMs) have shown great potential to empower various domains and are often customized by fine-tuning for the requirements of different applications. However, the powerful learning ability of LLMs not only enables them to learn new tasks but also makes them vulnerable to learning undesired behaviors, such as harmfulness and hallucination, as the fine-tuning data often implicitly or explicitly contains such content. Can we fine-tune LLMs on harmful data without learning... | Xin Zhou, Yi Lu, Ruotian Ma, Yujian Wei, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 1597 |  |  [Debiasing Large Language Models with Structured Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.612) |  | 0 | Due to biases inherently present in data for pre-training, current pre-trained Large Language Models (LLMs) also ubiquitously manifest the same phenomena. Since the bias influences the output from the LLMs across various tasks, the widespread deployment of the LLMs is hampered. We propose a simple method that utilizes structured knowledge to alleviate this issue, aiming to reduce the bias embedded within the LLMs and ensuring they have an encompassing perspective when used in applications.... | Congda Ma, Tianyu Zhao, Manabu Okumura |  |
| 1598 |  |  [Contrastive Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.613) |  | 0 | Instruction tuning has been used as a promising approach to improve the performance of large language models (LLMs) on unseen tasks. However, current LLMs exhibit limited robustness to unseen instructions, generating inconsistent outputs when the same instruction is phrased with slightly varied forms or language styles. This behavior indicates LLMs’ lack of robustness to textual variations and generalizability to unseen instructions, potentially leading to trustworthiness issues. Accordingly,... | Tianyi Yan, Fei Wang, James Y. Huang, Wenxuan Zhou, Fan Yin, Aram Galstyan, Wenpeng Yin, Muhao Chen |  |
| 1599 |  |  [Bootstrapped Pre-training with Dynamic Identifier Prediction for Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.614) |  | 0 | Generative retrieval uses differentiable search indexes to directly generate relevant document identifiers in response to a query. Recent studies have highlighted the potential of a strong generative retrieval model, trained with carefully crafted pre-training tasks, to enhance downstream retrieval tasks via fine-tuning. However, the full power of pre-training for generative retrieval remains underexploited due to its reliance on pre-defined static document identifiers, which may not align with... | Yubao Tang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng |  |
| 1600 |  |  [Refining and Synthesis: A Simple yet Effective Data Augmentation Framework for Cross-Domain Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.615) |  | 0 | Aspect-based Sentiment Analysis (ABSA) is extensively researched in the NLP community, yet related models face challenges due to data sparsity when shifting to a new domain. Hence, data augmentation for cross-domain ABSA has attracted increasing attention in recent years. However, two key points have been neglected in prior studies: First, target domain unlabeled data are labeled with pseudo labels by the model trained in the source domain with little quality control, leading to inaccuracy and... | Haining Wang, Kang He, Bobo Li, Lei Chen, Fei Li, Xu Han, Chong Teng, Donghong Ji |  |
| 1601 |  |  [Codec-SUPERB: An In-Depth Analysis of Sound Codec Models](https://doi.org/10.18653/v1/2024.findings-acl.616) |  | 0 | The sound codec’s dual roles in minimizing data transmission latency and serving as tokenizers underscore its critical importance.Recent years have witnessed significant developments in codec models.The ideal sound codec should preserve content, paralinguistics, speakers, and audio information.However, the question of which codec achieves optimal sound information preservation remains unanswered, as in different papers, models are evaluated on their selected experimental settings.This study... | Haibin Wu, HoLam Chung, YiCheng Lin, YuanKuei Wu, Xuanjun Chen, YuChi Pai, HsiuHsuan Wang, KaiWei Chang, Alexander H. Liu, Hungyi Lee |  |
| 1602 |  |  [CACL: Community-Aware Heterogeneous Graph Contrastive Learning for Social Media Bot Detection](https://doi.org/10.18653/v1/2024.findings-acl.617) |  | 0 | Social media bot detection is increasingly crucial with the rise of social media platforms. Existing methods predominantly construct social networks as graph and utilize graph neural networks (GNNs) for bot detection. However, most of these methods focus on how to improve the performance of GNNs while neglecting the community structure within social networks. Moreover, GNNs based methods still face problems such as poor model generalization due to the relatively small scale of the dataset and... | Sirry Chen, Shuo Feng, Songsong Liang, ChenChen Zong, Jing Li, Piji Li |  |
| 1603 |  |  [Are Machines Better at Complex Reasoning? Unveiling Human-Machine Inference Gaps in Entailment Verification](https://doi.org/10.18653/v1/2024.findings-acl.618) |  | 0 | Making inferences in text comprehension to understand the meaning is essential in language processing. This work studies the entailment verification (EV) problem of complex, multi-sentence premises requiring a system to make multiple inferences implicitly. Modern applications of EV in detecting inconsistent model-generated rationales require complex multi-hop reasoning. However, current textual inference datasets mostly contain short-sentence premises that partially focus on this. To address... | Soumya Sanyal, Tianyi Xiao, Jiacheng Liu, Wenya Wang, Xiang Ren |  |
| 1604 |  |  [ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.619) |  | 0 | Charts provide visual representations of data and are widely used for analyzing information, addressing queries, and conveying insights to others. Various chart-related downstream tasks have emerged recently, such as question-answering and summarization. A common strategy to solve these tasks is to fine-tune various models originally trained on vision tasks language. However, such task-specific models are not capable of solving a wide range of chart-related tasks, constraining their real-world... | Ahmed Masry, Mehrad Shahmohammadi, Md. Rizwan Parvez, Enamul Hoque, Shafiq Joty |  |
| 1605 |  |  [Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.620) |  | 0 | The many-to-many multilingual neural machine translation can be regarded as the process of integrating semantic features from the source sentences and linguistic features from the target sentences. To enhance zero-shot translation, models need to share knowledge across languages, which can be achieved through auxiliary tasks for learning a universal representation or cross-lingual mapping. To this end, we propose to exploit both semantic and linguistic features between multiple languages to... | Mengyu Bu, Shuhao Gu, Yang Feng |  |
| 1606 |  |  [Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with Architecture-Routed Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.621) |  | 0 | Weight-sharing supernets are crucial for performance estimation in cutting-edge neural architecture search (NAS) frameworks. Despite their ability to generate diverse subnetworks without retraining, the quality of these subnetworks is not guaranteed due to weight sharing. In NLP tasks like machine translation and pre-trained language modeling, there is a significant performance gap between supernet and training from scratch for the same model architecture, necessitating retraining post optimal... | Ganesh Jawahar, Haichuan Yang, Yunyang Xiong, Zechun Liu, Dilin Wang, Fei Sun, Meng Li, Aasish Pappu, Barlas Oguz, Muhammad AbdulMageed, Laks V. S. Lakshmanan, Raghuraman Krishnamoorthi, Vikas Chandra |  |
| 1607 |  |  [SharedCon: Implicit Hate Speech Detection using Shared Semantics](https://doi.org/10.18653/v1/2024.findings-acl.622) |  | 0 | The ever-growing presence of hate speech on social network services and other online platforms not only fuels online harassment but also presents a growing challenge for hate speech detection. As this task is akin to binary classification, one of the promising approaches for hate speech detection is the utilization of contrastive learning. Recent studies suggest that classifying hateful posts in just a binary manner may not adequately address the nuanced task of detecting implicit hate speech.... | Hyeseon Ahn, Youngwook Kim, Jungin Kim, YoSub Han |  |
| 1608 |  |  [Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models](https://doi.org/10.18653/v1/2024.findings-acl.623) |  | 0 | Instruction-tuning language models has become a crucial step in aligning them for general use. Typically, this process involves extensive training on large datasets, incurring high training costs. In this paper, we introduce a novel training data selection based on the learning percentage of the samples. We assert that current language models possess the capability to autonomously select high-quality training data, leading to comparable or improved performance compared to training on the entire... | Dheeraj Mekala, Alex Nguyen, Jingbo Shang |  |
| 1609 |  |  [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.624) |  | 0 | Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess... | Qiusi Zhan, Zhixiang Liang, Zifan Ying, Daniel Kang |  |
| 1610 |  |  [Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.625) |  | 0 | Code Pre-trained Models (CodePTMs) based vulnerability detection have achieved promising results over recent years. However, these models struggle to generalize as they typically learn superficial mapping from source code to labels instead of understanding the root causes of code vulnerabilities, resulting in poor performance in real-world scenarios beyond the training instances. To tackle this challenge, we introduce VulLLM, a novel framework that integrates multi-task learning with Large... | Xiaohu Du, Ming Wen, Jiahao Zhu, Zifan Xie, Bin Ji, Huijun Liu, Xuanhua Shi, Hai Jin |  |
| 1611 |  |  [PPTSER: A Plug-and-Play Tag-guided Method for Few-shot Semantic Entity Recognition on Visually-rich Documents](https://doi.org/10.18653/v1/2024.findings-acl.626) |  | 0 | Visually-rich document information extraction (VIE) is a vital aspect of document understanding, wherein Semantic Entity Recognition (SER) plays a significant role. However, few-shot SER on visually-rich documents remains relatively unexplored despite its considerable potential for practical applications. To address this issue, we propose a simple yet effective Plug-and-Play Tag-guided method for few-shot Semantic Entity Recognition (PPTSER) on visually-rich documents. PPTSER is built upon... | Wenhui Liao, Jiapeng Wang, Zening Lin, Longfei Xiong, Lianwen Jin |  |
| 1612 |  |  [LLM Performance Predictors are good initializers for Architecture Search](https://doi.org/10.18653/v1/2024.findings-acl.627) |  | 0 | In this work, we utilize Large Language Models (LLMs) for a novel use case: constructing Performance Predictors (PP) that estimate the performance of specific deep neural network architectures on downstream tasks. We create PP prompts for LLMs, comprising (i) role descriptions, (ii) instructions for the LLM, (iii) hyperparameter definitions, and (iv) demonstrations presenting sample architectures with efficiency metrics and ‘training from scratch’ performance. In machine translation (MT) tasks,... | Ganesh Jawahar, Muhammad AbdulMageed, Laks V. S. Lakshmanan, Dujian Ding |  |
| 1613 |  |  [MODDP: A Multi-modal Open-domain Chinese Dataset for Dialogue Discourse Parsing](https://doi.org/10.18653/v1/2024.findings-acl.628) |  | 0 | Dialogue discourse parsing (DDP) aims to capture the relations between utterances in the dialogue. In everyday real-world scenarios, dialogues are typically multi-modal and cover open-domain topics. However, most existing widely used benchmark datasets for DDP contain only textual modality and are domain-specific. This makes it challenging to accurately and comprehensively understand the dialogue without multi-modal clues, and prevents them from capturing the discourse structures of the more... | Chen Gong, Dexin Kong, Suxian Zhao, Xingyu Li, Guohong Fu |  |
| 1614 |  |  [Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.629) |  | 0 | In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis situations. There is a recognized need for models capable of efficient analysis. While pre-trained language models have demonstrated their effectiveness broadly, there’s a noticeable gap in pre-trained... | Wei Zhai, Hongzhi Qi, Qing Zhao, Jianqiang Li, Ziqi Wang, Han Wang, Bing Yang, Guanghui Fu |  |
| 1615 |  |  [Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.630) |  | 0 | A single language model, even when aligned with labelers through reinforcement learning from human feedback (RLHF), may not suit all human preferences. Recent approaches therefore prefer customization, gathering multi-dimensional feedback, and creating distinct reward models for each dimension.Different language models are then optimized for various preferences using multi-objective RLHF (MORLHF) with varying reward weights.However, RL fine-tuning is unstable and resource-heavy, especially with... | Zhanhui Zhou, Jie Liu, Jing Shao, Xiangyu Yue, Chao Yang, Wanli Ouyang, Yu Qiao |  |
| 1616 |  |  [DORY: Deliberative Prompt Recovery for LLM](https://doi.org/10.18653/v1/2024.findings-acl.631) |  | 0 | Prompt recovery in large language models (LLMs) is crucial for understanding how LLMs work and addressing concerns regarding privacy, copyright, etc. The trend towards inference-only APIs complicates this task by restricting access to essential outputs for recovery. To tackle this challenge, we extract prompt-related information from limited outputs and identify a strong(negative) correlation between output probability-based uncertainty and the success of prompt recovery.This finding led to the... | Lirong Gao, Ru Peng, Yiming Zhang, Junbo Zhao |  |
| 1617 |  |  [STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.632) |  | 0 | Equipping a conversational search engine with strategies regarding when to ask clarification questions is becoming increasingly important across various domains. Attributing to the context understanding capability of LLMs and their access to domain-specific sources of knowledge, LLM-based clarification strategies feature rapid transfer to various domains in a post-hoc manner.However, they still struggle to deliver promising performance on unseen domains, struggling to achieve effective domain... | Yue Chen, Chen Huang, Yang Deng, Wenqiang Lei, Dingnan Jin, Jia Liu, TatSeng Chua |  |
| 1618 |  |  [Evaluating Robustness of Generative Search Engine on Adversarial Factoid Questions](https://doi.org/10.18653/v1/2024.findings-acl.633) |  | 0 | Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable part of a claim. To this end, we propose evaluating the robustness of generative search engines in the... | Xuming Hu, Xiaochuan Li, Junzhe Chen, Yinghui Li, Yangning Li, Xiaoguang Li, Yasheng Wang, Qun Liu, Lijie Wen, Philip S. Yu, Zhijiang Guo |  |
| 1619 |  |  [Automatic Engineering of Long Prompts](https://doi.org/10.18653/v1/2024.findings-acl.634) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities in solving complex open-domain tasks, guided by comprehensive instructions and demonstrations provided in the form of prompts. However, these prompts can be lengthy, often comprising hundreds of lines and thousands of tokens, and their design often requires considerable human effort. Recent research has explored automatic prompt engineering for short prompts, typically consisting of one or a few sentences. However, the... | ChoJui Hsieh, Si Si, Felix X. Yu, Inderjit S. Dhillon |  |
| 1620 |  |  [AS-ES Learning: Towards efficient CoT learning in small models](https://doi.org/10.18653/v1/2024.findings-acl.635) |  | 0 | Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs, especially when it comes to logical reasoning. Attempts have been made to induce such ability in small models as well by distilling from the data with CoT generated by Large Language Models (LLMs). However, existing methods often simply generate and incorporate more data from LLMs and fail to note the importance of efficiently utilizing existing CoT data. We here propose a new training paradigm AS-ES (Abstractive Segments -... | Nuwa Xi, Yuhan Chen, Sendong Zhao, Haochun Wang, GongZhang GongZhang, Bing Qin, Ting Liu |  |
| 1621 |  |  [II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.636) |  | 0 | Visual Question Answering (VQA) often involves diverse reasoning scenarios across Vision and Language (V&L). Most prior VQA studies, however, have merely focused on assessing the model’s overall accuracy without evaluating it on different reasoning cases. Furthermore, some recent works observe that conventional Chain-of-Thought (CoT) prompting fails to generate effective reasoning for VQA, especially for complex scenarios requiring multi-hop reasoning. In this paper, we propose II-MMR, a novel... | Jihyung Kil, Farideh Tavazoee, Dongyeop Kang, JooKyung Kim |  |
| 1622 |  |  [TAME-RD: Text Assisted Replication of Image Multi-Adjustments for Reverse Designing](https://doi.org/10.18653/v1/2024.findings-acl.637) |  | 0 | Given a source and its edited version performed based on human instructions in natural language, how do we extract the underlying edit operations, to automatically replicate similar edits on other images? This is the problem of reverse designing, and we present TAME-RD, a model to solve this problem. TAME-RD automatically learns from the complex interplay of image editing operations and the natural language instructions to learn fully specified edit operations. It predicts both the underlying... | Pooja Guhan, Uttaran Bhattacharya, Somdeb Sarkhel, Vahid Azizi, Xiang Chen, Saayan Mitra, Aniket Bera, Dinesh Manocha |  |
| 1623 |  |  [Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.638) |  | 0 | In this paper, by treating in-context learning (ICL) as a meta-optimization process, we explain why LLMs are sensitive to the order of ICL examples. This understanding leads us to the development of Batch-ICL, an effective, efficient, and order-agnostic inference algorithm for ICL. Differing from the standard N-shot learning approach, Batch-ICL employs N separate 1-shot forward computations and aggregates the resulting meta-gradients. These aggregated meta-gradients are then applied to the... | Kaiyi Zhang, Ang Lv, Yuhan Chen, Hansen Ha, Tao Xu, Rui Yan |  |
| 1624 |  |  [IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.639) |  | 0 | We present INDICVOICES, a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a median of 73 hours per language. Through this paper, we share our journey of capturing the cultural, linguistic and demographic diversity of India to create a one-of-its-kind inclusive and... | Tahir Javed, Janki Nawale, Eldho Ittan George, Sakshi Joshi, Kaushal Santosh Bhogale, Deovrat Mehendale, Ishvinder Virender Sethi, Aparna Ananthanarayanan, Hafsah Faquih, Pratiti Palit, Sneha Ravishankar, Saranya Sukumaran, Tripura Panchagnula, Sunjay Murali, Kunal Sharad Gandhi, Ambujavalli R, Manickam K. M, C. Venkata Vaijayanthi, Krishnan Srinivasa Raghavan Karunganni, Pratyush Kumar, Mitesh M. Khapra |  |
| 1625 |  |  [ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.640) |  | 0 | In our work, we explore the synergistic capabilities of pre-trained vision-and-language models (VLMs) and large language models (LLMs) on visual commonsense reasoning (VCR) problems. We find that VLMs and LLMs-based decision pipelines are good at different kinds of VCR problems. Pre-trained VLMs exhibit strong performance for problems involving understanding the literal visual content, which we noted as visual commonsense understanding (VCU). For problems where the goal is to infer conclusions... | Kaiwen Zhou, Kwonjoon Lee, Teruhisa Misu, Xin Wang |  |
| 1626 |  |  [Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.641) |  | 0 | In-context learning of large-language models (LLMs) has achieved remarkable success in the field of natural language processing, while extensive case studies reveal that the single-step chain-of-thought prompting approach faces challenges such as attention diffusion and inadequate performance in complex tasks like text-to-SQL. To improve the contextual learning capabilities of LLMs in text-to-SQL, a workflow paradigm method is proposed, aiming to enhance the attention and problem-solving scope... | Yuanzhen Xie, Xinzhou Jin, Tao Xie, Mingxiong Lin, Liang Chen, Chenyun Yu, Cheng Lei, Chengxiang Zhuo, Bo Hu, Zang Li |  |
| 1627 |  |  [Unveiling Opinion Evolution via Prompting and Diffusion for Short Video Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.642) |  | 0 | Short video fake news detection is crucial for combating the spread of misinformation. Current detection methods tend to aggregate features from individual modalities into multimodal features, overlooking the implicit opinions and the evolving nature of opinions across modalities. In this paper, we mine implicit opinions within short video news and promote the evolution of both explicit and implicit opinions across all modalities. Specifically, we design a prompt template to mine implicit... | Linlin Zong, Jiahui Zhou, Wenmin Lin, Xinyue Liu, Xianchao Zhang, Bo Xu |  |
| 1628 |  |  [iSign: A Benchmark for Indian Sign Language Processing](https://doi.org/10.18653/v1/2024.findings-acl.643) |  | 0 | Indian Sign Language has limited resources for developing machine learning and data-driven approaches for automated language processing. Though text/audio-based language processing techniques have shown colossal research interest and tremendous improvements in the last few years, Sign Languages still need to catch up due to the need for more resources. To bridge this gap, in this work, we propose iSign: a benchmark for Indian Sign Language (ISL) Processing. We make three primary contributions... | Abhinav Joshi, Romit Mohanty, Mounika Kanakanti, Andesha Mangla, Sudeep Choudhary, Monali Barbate, Ashutosh Modi |  |
| 1629 |  |  [Data Contamination Calibration for Black-box LLMs](https://doi.org/10.18653/v1/2024.findings-acl.644) |  | 0 | The rapid advancements of Large Language Models (LLMs) tightly associate with the expansion of the training data size. However, the unchecked ultra-large-scale training sets introduce a series of potential risks like data contamination, i.e. the benchmark data is used for training. In this work, we propose a holistic method named Polarized Augment Calibration (PAC) along with a new to-be-released dataset to detect the contaminated data and diminish the contamination effect. PAC extends the... | Wentao Ye, Jiaqi Hu, Liyao Li, Haobo Wang, Gang Chen, Junbo Zhao |  |
| 1630 |  |  [Truth-Aware Context Selection: Mitigating Hallucinations of Large Language Models Being Misled by Untruthful Contexts](https://doi.org/10.18653/v1/2024.findings-acl.645) |  | 0 | Although Large Language Models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by untruthful contexts provided by users or knowledge augmentation tools, leading to hallucinations. To alleviate LLMs from being misled by untruthful context and take advantage of knowledge augmentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to adaptively recognize and mask untruthful context from the inputs. TACS begins by performing truth... | Tian Yu, Shaolei Zhang, Yang Feng |  |
| 1631 |  |  [Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.646) |  | 0 | Large language models (LLMs) exhibit outstanding performance in machine translation via in-context learning. In contrast to sentence-level translation, document-level translation (DOCMT) by LLMs based on in-context learning faces two major challenges: firstly, document translations generated by LLMs are often incoherent; secondly, the length of demonstration for in-context learning is usually limited. To address these issues, we propose a Context-Aware Prompting method (CAP), which enables LLMs... | Menglong Cui, Jiangcun Du, Shaolin Zhu, Deyi Xiong |  |
| 1632 |  |  [Improving Grammatical Error Correction via Contextual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.647) |  | 0 | Nowadays, data augmentation through synthetic data has been widely used in the field of Grammatical Error Correction (GEC) to alleviate the problem of data scarcity. However, these synthetic data are mainly used in the pre-training phase rather than the data-limited fine tuning phase due to inconsistent error distribution and noisy labels. In this paper, we propose a synthetic data construction method based on contextual augmentation, which can ensure an efficient augmentation of the original... | Yixuan Wang, Baoxin Wang, Yijun Liu, Qingfu Zhu, Dayong Wu, Wanxiang Che |  |
| 1633 |  |  [RECOST: External Knowledge Guided Data-efficient Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.648) |  | 0 | In the current landscape of large language models (LLMs), the process of instruction tuning serves as an essential step. Considering the high computing power overhead, data-efficient instruction tuning was proposed to reduce the training data size in this process, aiming at selecting high-quality instructional data. Nevertheless, we argue that most current data-efficient instruction-tuning methods are highly dependent on the quality of the original instruction-tuning dataset. When it comes to... | Qi Zhang, Yiming Zhang, Haobo Wang, Junbo Zhao |  |
| 1634 |  |  [Understanding Cross-Lingual Alignment - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.649) |  | 0 | Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising insights from throughout the field. We present different understandings of cross-lingual alignment and their limitations. We provide a qualitative summary of results from a number of surveyed papers.... | Katharina Hämmerl, Jindrich Libovický, Alexander Fraser |  |
| 1635 |  |  [Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-acl.650) |  | 0 | Lifelong prompt tuning has significantly advanced parameter-efficient lifelong learning with its efficiency and minimal storage demands on various tasks.Our empirical studies, however, highlights certain transferability constraints in the current methodologies: a universal algorithm that guarantees consistent positive transfer across all tasks is currently unattainable, especially when dealing dissimilar tasks that may engender negative transfer.Identifying the misalignment between algorithm... | Chenyuan Wu, Gangwei Jiang, Defu Lian |  |
| 1636 |  |  [PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.651) |  | 0 | While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves fine-tuning them using corresponding datasets. However, this method can be both resource and time-intensive, and not applicable to closed-source commercial LLMs. In this paper, we propose Preference... | An Liu, Zonghan Yang, Zhenhe Zhang, Qingyuan Hu, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu |  |
| 1637 |  |  [Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction](https://doi.org/10.18653/v1/2024.findings-acl.652) |  | 0 | Advancements in AI and natural language processing have revolutionized machine-human language interactions, with question answering (QA) systems playing a pivotal role. The knowledge base question answering (KBQA) task, utilizing structured knowledge graphs (KG), allows for handling extensive knowledge-intensive questions. However, a significant gap exists in KBQA datasets, especially for low-resource languages. Many existing construction pipelines for these datasets are outdated and... | Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domogala, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz |  |
| 1638 |  |  [Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM](https://doi.org/10.18653/v1/2024.findings-acl.653) |  | 0 | Generating accurate SQL queries for user questions (text-to-SQL) has been a long-standing challenge since it requires a deep understanding of both the user’s question and the corresponding database schema in order to retrieve the desired content accurately. Existing methods rely on the comprehensive capability of large language models (LLMs) to generate the SQL. However, some necessary knowledge is not explicitly included in the database schema and user question or has been learned by LLMs.... | Zijin Hong, Zheng Yuan, Hao Chen, Qinggang Zhang, Feiran Huang, Xiao Huang |  |
| 1639 |  |  [Centroid-Based Efficient Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.654) |  | 0 | Minimum Bayes risk (MBR) decoding achieved state-of-the-art translation performance by using COMET, a neural metric that has a high correlation with human evaluation.However, MBR decoding requires quadratic time since it computes the expected score between a translation hypothesis and all reference translations.We propose centroid-based MBR (CBMBR) decoding to improve the speed of MBR decoding.Our method clusters the reference translations in the feature space, and then calculates the score... | Hiroyuki Deguchi, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe, Hideki Tanaka, Masao Utiyama |  |
| 1640 |  |  [Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration](https://doi.org/10.18653/v1/2024.findings-acl.655) |  | 0 | In this paper, we tackle the task of distractor generation (DG) for multiple-choice questions. Our study introduces two key designs. First, we propose the concept of retrieval augmented pretraining, which involves refining the language model pretraining to align it more closely with the downstream task of DG. Second, we explore the integration of knowledge graphs and language models to further enhance the performance of DG. Our study unveils promising directions for further development in DG by... | HanCheng Yu, YuAn Shih, KinMan Law, KaiYu Hsieh, YuChen Cheng, HsinChih Ho, ZihAn Lin, WenChuan Hsu, YaoChung Fan |  |
| 1641 |  |  [Exploiting Positional Bias for Query-Agnostic Generative Content in Search](https://doi.org/10.18653/v1/2024.findings-acl.656) |  | 0 | In recent years, research shows that neural ranking models (NRMs) substantially outperform their lexical counterparts in text retrieval. In traditional search pipelines, a combination of features leads to well-defined behaviour. However, as neural approaches become increasingly prevalent as the final scoring component of engines or as standalone systems, their robustness to malicious text and, more generally, semantic perturbation needs to be better understood. We posit that the transformer... | Andrew Parry, Sean MacAvaney, Debasis Ganguly |  |
| 1642 |  |  [ICC : Quantifying Image Caption Concreteness for Multimodal Dataset Curation](https://doi.org/10.18653/v1/2024.findings-acl.657) |  | 0 | Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we... | Moran Yanuka, Morris Alper, Hadar AverbuchElor, Raja Giryes |  |
| 1643 |  |  [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.658) |  | 0 | Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However, current investigations into this field lack a unified framework and mostly stay on the surface. Therefore, this paper provides an organization of relevant studies based on a generic workflow of synthetic... | Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, Haobo Wang |  |
| 1644 |  |  [When is a Language Process a Language Model?](https://doi.org/10.18653/v1/2024.findings-acl.659) |  | 0 | A language model may be viewed as a 𝛴-valued stochastic process for some alphabet 𝛴.However, in some pathological situations, such a stochastic process may “leak” probability mass onto the set of infinite strings and hence is not equivalent to the conventional view of a language model as a distribution over ordinary (finite) strings.Such ill-behaved language processes are referred to as \*non-tight\* in the literature.In this work, we study conditions of tightness through the lens of stochastic... | Li Du, Holden Lee, Jason Eisner, Ryan Cotterell |  |
| 1645 |  |  [Accelerating Multilingual Language Model for Excessively Tokenized Languages](https://doi.org/10.18653/v1/2024.findings-acl.660) |  | 0 | Recent advancements in large language models (LLMs) have remarkably enhanced performances on a variety of tasks in multiple languages. However, tokenizers in LLMs trained primarily on English-centric corpora often overly fragment a text into character or Unicode-level tokens in non-Roman alphabetic languages, leading to inefficient text generation.We introduce a simple yet effective framework to accelerate text generation in such languages. Our approach involves employing a new language model... | Jimin Hong, Gibbeum Lee, Jaewoong Cho |  |
| 1646 |  |  [Definition Generation for Automatically Induced Semantic Frame](https://doi.org/10.18653/v1/2024.findings-acl.661) |  | 0 | In a semantic frame resource such as FrameNet, the definition sentence of a frame is essential for humans to understand the meaning of the frame intuitively. Recently, several attempts have been made to induce semantic frames from large corpora, but the cost of creating the definition sentences for such frames is significant. In this paper, we address a new task of generating frame definitions from a set of frame-evoking words. Specifically, given a cluster of frame-evoking words and associated... | Yi Han, Ryohei Sasano, Koichi Takeda |  |
| 1647 |  |  [Distillation Enhanced Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.662) |  | 0 | Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generative language models, distinct from traditional sparse or dense retrieval methods. In this work, we identify a viable direction to further enhance generative retrieval via distillation and propose a feasible framework, named DGR. DGR utilizes sophisticated ranking models, such as the cross-encoder, in a teacher... | Yongqi Li, Zhen Zhang, Wenjie Wang, Liqiang Nie, Wenjie Li, TatSeng Chua |  |
| 1648 |  |  [ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos](https://doi.org/10.18653/v1/2024.findings-acl.663) |  | 0 | In an era of rapidly evolving internet technology, the surge in multimodal content, including videos, has expanded the horizons of online communication. However, the detection of toxic content in this diverse landscape, particularly in low-resource code-mixed languages, remains a critical challenge. While substantial research has addressed toxic content detection in textual data, the realm of video content, especially in non-English languages, has been relatively underexplored. This paper... | Krishanu Maity, Poornash Sangeetha, Sriparna Saha, Pushpak Bhattacharyya |  |
| 1649 |  |  [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.664) |  | 0 | Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status. To address this problem, we... | Zhicheng Guo, Sijie Cheng, Hao Wang, Shihao Liang, Yujia Qin, Peng Li, Zhiyuan Liu, Maosong Sun, Yang Liu |  |
| 1650 |  |  [Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence](https://doi.org/10.18653/v1/2024.findings-acl.665) |  | 0 | Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants. Previous works mainly focus on raising the emotion perception ability of them via naive fine-tuning on EI-related classification or regression tasks. However, this leads to the incomplete enhancement of EI and catastrophic forgetting of the... | Weixiang Zhao, Zhuojun Li, Shilong Wang, Yang Wang, Yulin Hu, Yanyan Zhao, Chen Wei, Bing Qin |  |
| 1651 |  |  [KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.666) |  | 0 | To reliably deploy Large Language Models (LLMs) in a specific country, they must possess an understanding of the nation’s culture and basic knowledge. To this end, we introduce National Alignment, which measures the alignment between an LLM and a targeted country from two aspects: social value alignment and common knowledge alignment. We constructed KorNAT, the first benchmark that measures national alignment between LLMs and South Korea. KorNat contains 4K and 6K multiple-choice questions for... | Jiyoung Lee, Minwoo Kim, Seungho Kim, Junghwan Kim, Seunghyun Won, Hwaran Lee, Edward Choi |  |
| 1652 |  |  [Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development](https://doi.org/10.18653/v1/2024.findings-acl.667) |  | 0 | The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance, enhancing patient safety by identifying potential risks associated with medications, facilitating early detection of adverse events, and guiding regulatory decision-making. Traditional ADE detection methods are reliable but slow, not easily adaptable to large-scale operations, and offer limited information. With the exponential increase in data sources like social media content, biomedical literature, and Electronic... | Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal |  |
| 1653 |  |  [Space Decomposition for Sentence Embedding](https://doi.org/10.18653/v1/2024.findings-acl.668) |  | 0 | Determining sentence pair similarity is crucial for various NLP tasks. A common technique to address this is typically evaluated on a continuous semantic textual similarity scale from 0 to 5. However, based on a linguistic observation in STS annotation guidelines, we found that the score in the range [4,5] indicates an upper-range sample, while the rest are lower-range samples. This necessitates a new approach to treating the upper-range and lower-range classes separately. In this paper, we... | Wuttikorn Ponwitayarat, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 1654 |  |  [Don't Augment, Rewrite? Assessing Abusive Language Detection with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.669) |  | 0 | Research on abusive language detection and content moderation is crucial to combat online harm. However, current limitations set by regulatory bodies and social media platforms can make it difficult to share collected data. We address this challenge by exploring the possibility to replace existing datasets in English for abusive language detection with synthetic data obtained by rewriting original texts with an instruction-based generative model.We show that such data can be effectively used to... | Camilla Casula, Elisa Leonardelli, Sara Tonelli |  |
| 1655 |  |  [Improving Low-Resource Machine Translation for Formosan Languages Using Bilingual Lexical Resources](https://doi.org/10.18653/v1/2024.findings-acl.670) |  | 0 | This paper investigates how machine translation for low-resource languages can be improved by incorporating information from bilingual lexicons during the training process for mainly translation between Mandarin and Formosan languages, which are all moribund or critically endangered, and we also show that our techniques work for translation between Spanish and Nahuatl, a language pair consisting of languages from completely different language families. About 70% of the approximately 7,000... | Francis Zheng, Edison MarreseTaylor, Yutaka Matsuo |  |
| 1656 |  |  [CMMLU: Measuring massive multitask language understanding in Chinese](https://doi.org/10.18653/v1/2024.findings-acl.671) |  | 0 | As the capabilities of large language models (LLMs) continue to advance, evaluating their performance is becoming more important and more challenging. This paper aims to address this issue for Mandarin Chinese in the form of CMMLU, a comprehensive Chinese benchmark that covers various subjects, including natural sciences, social sciences, engineering, and the humanities. We conduct a thorough evaluation of more than 20 contemporary multilingual and Chinese LLMs, assessing their performance... | Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, Timothy Baldwin |  |
| 1657 |  |  [Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.672) |  | 0 | Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging. It not only requires checking whether the VLM follows the given instruction but also verifying whether the text output is properly grounded on the given image. Inspired by the recent approach of evaluating LMs with LMs, in this work, we propose to evaluate VLMs with VLMs. For this purpose, we present a new feedback dataset called the Perception Collection, encompassing 15K customized score rubrics that... | Seongyun Lee, Seungone Kim, Sue Hyun Park, Geewook Kim, Minjoon Seo |  |
| 1658 |  |  [Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction](https://doi.org/10.18653/v1/2024.findings-acl.673) |  | 0 | The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual perspective of examiner regarding error identification and correction.From the examiner perspective, we define four evaluation tasks for error identification and correction along with a new dataset with... | Xiaoyuan Li, Wenjie Wang, Moxin Li, Junrong Guo, Yang Zhang, Fuli Feng |  |
| 1659 |  |  [Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.674) |  | 0 |  | Michele Mastromattei, Fabio Massimo Zanzotto |  |
| 1660 |  |  [When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.675) |  | 0 | Large Language Models (LLMs) have been found to have difficulty knowing they do not possess certain knowledge and tend to provide specious answers in such cases. Retrieval Augmentation (RA) has been extensively studied to mitigate LLMs’ hallucinations. However, due to the extra overhead and unassured quality of retrieval, it may not be optimal to conduct RA all the time. A straightforward idea is to only conduct retrieval when LLMs are uncertain about a question. This motivates us to enhance... | Shiyu Ni, Keping Bi, Jiafeng Guo, Xueqi Cheng |  |
| 1661 |  |  [Hybrid Alignment Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.676) |  | 0 | Alignment training is crucial for enabling large language models (LLMs) to cater to human intentions and preferences. It is typically performed based on two stages with different objectives: instruction-following alignment and human-preference alignment. However, aligning LLMs with these objectives in sequence suffers from an inherent problem: the objectives may conflict, and the LLMs cannot guarantee to simultaneously align with the instructions and human preferences well. To response to... | Chenglong Wang, Hang Zhou, Kaiyan Chang, Bei Li, Yongyu Mu, Tong Xiao, Tongran Liu, JingBo Zhu |  |
| 1662 |  |  [Graph-Structured Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.677) |  | 0 | Speculative decoding has emerged as a promising technique to accelerate the inference of Large Language Models (LLMs) by employing a small language model to draft a hypothesis sequence, which is then validated by the LLM. The effectiveness of this approach heavily relies on the balance between performance and efficiency of the draft model. In our research, we focus on enhancing the proportion of draft tokens that are accepted to the final output by generating multiple hypotheses instead of just... | Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan |  |
| 1663 |  |  [Duwak: Dual Watermarks in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.678) |  | 0 | As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with... | Chaoyi Zhu, Jeroen Galjaard, PinYu Chen, Lydia Y. Chen |  |
| 1664 |  |  [CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion](https://doi.org/10.18653/v1/2024.findings-acl.679) |  | 0 | The rapid advancement of Large Language Models (LLMs) has brought about remarkable generative capabilities but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel... | Qibing Ren, Chang Gao, Jing Shao, Junchi Yan, Xin Tan, Wai Lam, Lizhuang Ma |  |
| 1665 |  |  [Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training](https://doi.org/10.18653/v1/2024.findings-acl.680) |  | 0 | While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the “reversal curse”. It is a typical example that the model knows “A’s father is B”, but is unable to reason “B’s child is A”. This limitation poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models’ ability to comprehend and apply bidirectional reasoning. In this paper, we first conduct... | Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, Jiang Bian, Yujiu Yang |  |
| 1666 |  |  [wav2vec-S: Adapting Pre-trained Speech Models for Streaming](https://doi.org/10.18653/v1/2024.findings-acl.681) |  | 0 | Pre-trained speech models, such as wav2vec 2.0, have significantly advanced speech-related tasks, including speech recognition and translation. However, their applicability in streaming scenarios is limited because these models are trained on complete utterances, leading to a mismatch with incremental streaming inputs. This paper identifies three critical design aspects within the architecture of wav2vec 2.0 and proposes a novel model, wav2vec-S, which incorporates simple modifications to... | Biao Fu, Kai Fan, Minpeng Liao, Yidong Chen, Xiaodong Shi, Zhongqiang Huang |  |
| 1667 |  |  [Peering into the Mind of Language Models: An Approach for Attribution in Contextual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.682) |  | 0 | With the enhancement in the field of generative artificial intelligence (AI), contextual question answering has become extremely relevant. Attributing model generations to the input source document is essential to ensure trustworthiness and reliability. We observe that when large language models (LLMs) are used for contextual question answering, the output answer often consists of text copied verbatim from the input prompt which is linked together with “glue text” generated by the LLM.... | Anirudh Phukan, Shwetha Somasundaram, Apoorv Saxena, Koustava Goswami, Balaji Vasan Srinivasan |  |
| 1668 |  |  [TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification](https://doi.org/10.18653/v1/2024.findings-acl.683) |  | 0 | Large Language Model (LLM) services and models often come with legal rules on \*who\* can use them and \*how\* they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel fingerprinting problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method... | Martin Gubri, Dennis Ulmer, Hwaran Lee, Sangdoo Yun, Seong Joon Oh |  |
| 1669 |  |  [CLASP: Cross-modal Alignment Using Pre-trained Unimodal Models](https://doi.org/10.18653/v1/2024.findings-acl.684) |  | 0 | Recent advancements in joint speech-text pre-training have significantly advanced the processing of natural language. However, a key limitation is their reliance on parallel speech-text data, posing challenges due to data accessibility. Addressing this, our paper introduces an innovative framework for jointly performing speech and text processing without parallel corpora during pre-training but only downstream. Utilizing pre-trained unimodal models, we extract distinct representations for... | Jianing Zhou, Ziheng Zeng, Hongyu Gong, Suma Bhat |  |
| 1670 |  |  [TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind](https://doi.org/10.18653/v1/2024.findings-acl.685) |  | 0 | Theory of Mind (ToM)—the cognitive ability to reason about mental states of ourselves and others, is the foundation of social interaction. Although ToM comes naturally to humans, it poses a significant challenge to even the most advanced Large Language Models (LLMs). Due to the complex logical chains in ToM reasoning, especially in higher-order ToM questions, simply utilizing reasoning methods like Chain of Thought (CoT) will not improve the ToM capabilities of LLMs. We present TimeToM, which... | Guiyang Hou, Wenqi Zhang, Yongliang Shen, Linjuan Wu, Weiming Lu |  |
| 1671 |  |  [Identifying and Mitigating Annotation Bias in Natural Language Understanding using Causal Mediation Analysis](https://doi.org/10.18653/v1/2024.findings-acl.686) |  | 0 | NLU models have achieved promising results on standard benchmarks. Despite state-of-the-art accuracy, analysis reveals that many models make predictions using annotation bias rather than the properties we intend the model to learn. Consequently, these models perform poorly on out-of-distribution datasets. Recent advances in bias mitigation show that annotation bias can be alleviated through fine-tuning debiasing objectives. In this paper, we apply causal mediation analysis to gauge how much... | Sitiporn Sae Lim, Can Udomcharoenchaikit, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong |  |
| 1672 |  |  [Perturbed examples reveal invariances shared by language models](https://doi.org/10.18653/v1/2024.findings-acl.687) |  | 0 | The rapid growth in natural language processing (NLP) research has led to numerous new models, outpacing our understanding of how they compare to established ones. One major reason for this difficulty is saturating benchmarks, which may not well reflect differences in model performance in the wild. In this work, we introduce a novel framework to compare two NLP models by revealing their shared invariance to interpretable input perturbations targeting a specific linguistic capability. Via... | Ruchit Rawal, Mariya Toneva |  |
| 1673 |  |  [Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.688) |  | 0 | Stochastic sampling strategies such as top-k and top-p have been widely used in dialogue generation task. However, as an open-domain chatting system, there will be two different conversation scenarios, i.e. chit-chat and knowledge-based question answering. In the former situation, responses diversity is essential due to the one-to-many nature in dialogue. The latter, on the other hand, requires less randomness given that stochastic decoding strategy entails the risk of generating incorrect... | Yiwei Li, Fei Mi, Yitong Li, Yasheng Wang, Bin Sun, Shaoxiong Feng, Kan Li |  |
| 1674 |  |  [Discourse Structure-Aware Prefix for Generation-Based End-to-End Argumentation Mining](https://doi.org/10.18653/v1/2024.findings-acl.689) |  | 0 | End-to-end argumentation mining (AM) aims to extract the argumentation structure including argumentation components and their argumentation relations from text. Recent developments in end-to-end AM models have demonstrated significant progress by redefining the AM task as a sequence generation task, exhibiting simplicity and competitive performance. Nevertheless, these models overlook the integration of supplementary discourse structure information, a crucial factor for comprehending... | Yang Sun, Guanrong Chen, Caihua Yang, Jianzhu Bao, Bin Liang, Xi Zeng, Min Yang, Ruifeng Xu |  |
| 1675 |  |  [Poor-Supervised Evaluation for SuperLLM via Mutual Consistency](https://doi.org/10.18653/v1/2024.findings-acl.690) |  | 0 | The guidance from capability evaluations has greatly propelled the progress of human society and the development of Artificial Intelligence. However, as LLMs evolve, it becomes challenging to construct evaluation benchmark with accurate labels for SuperLLMs whose capabilities approach or even surpass those of humans. To credibly conduct poor-supervised evaluation without accurate labels, we first prove that the consistency between the model under evaluation and the reference model, when their... | Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Yao Hu, Kan Li |  |
| 1676 |  |  [Addressing Entity Translation Problem via Translation Difficulty and Context Diversity](https://doi.org/10.18653/v1/2024.findings-acl.691) |  | 0 | Neural machine translation (NMT) systems often produce inadequate translations for named entities. In this study, we conducted preliminary experiments to examine the factors affecting the translation accuracy of named entities, specifically focusing on their translation difficulty and context diversity. Based on our observations, we propose a novel data augmentation strategy to enhance the accuracy of named entity translation. The main concept behind our approach is to increase both the context... | Tian Liang, Xing Wang, Mingming Yang, Yujiu Yang, Shuming Shi, Zhaopeng Tu |  |
| 1677 |  |  [ADAM: Dense Retrieval Distillation with Adaptive Dark Examples](https://doi.org/10.18653/v1/2024.findings-acl.692) |  | 0 | To improve the performance of the dual-encoder retriever, one effective approach is knowledge distillation from the cross-encoder ranker. Existing works prepare training instances by pairing each query with one positive and a batch of negatives. However, most hard negatives mined by advanced dense retrieval methods are still too trivial for the teacher to distinguish, preventing the teacher from transferring abundant dark knowledge to the student through its soft label. To alleviate this issue,... | Chongyang Tao, Chang Liu, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, Daxin Jiang |  |
| 1678 |  |  [Instruction Position Matters in Sequence Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.693) |  | 0 | Large language models (LLMs) are capable of performing conditional sequence generation tasks, such as translation or summarization, through instruction fine-tuning. The fine-tuning data is generally sequentially concatenated from a specific task instruction, an input sentence, and the corresponding response. Considering the locality modeled by the self-attention mechanism of LLMs, these models face the risk of instruction forgetting when generating responses for long input sentences. To... | Yijin Liu, Xianfeng Zeng, Chenze Shao, Fandong Meng, Jie Zhou |  |
| 1679 |  |  [XMoE: Sparse Models with Fine-grained and Adaptive Expert Selection](https://doi.org/10.18653/v1/2024.findings-acl.694) |  | 0 | Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations by multiplying values by zero or low activation values. To address this issue, we present XMoE, a novel MoE designed to enhance both the efficacy and efficiency of sparse MoE models. XMoE leverages small experts and a... | Yuanhang Yang, Shiyi Qi, Wenchao Gu, Chaozheng Wang, Cuiyun Gao, Zenglin Xu |  |
| 1680 |  |  [BranchNorm: Robustly Scaling Extremely Deep Transformers](https://doi.org/10.18653/v1/2024.findings-acl.695) |  | 0 | Recently, DeepNorm scales Transformers into extremely deep (i.e., 1000 layers) and reveals the promising potential of deep scaling. To stabilize the training of deep models, DeepNorm attempts to constrain the model update to a constant value. Although applying such a constraint can benefit the early stage of model training, it may lead to undertrained models during the whole training procedure. In this paper, we propose BranchNorm, which dynamically rescales the non-residual branch of... | Yijin Liu, Xianfeng Zeng, Fandong Meng, Jie Zhou |  |
| 1681 |  |  [MusTQ: A Temporal Knowledge Graph Question Answering Dataset for Multi-Step Temporal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.696) |  | 0 | Question answering over temporal knowledge graphs (TKGQA) is an emerging topic, which has attracted increasing interest since it considers the dynamic knowledge in the world. Several datasets along with model developments are proposed in the TKGQA research field. However, existing studies generally focus on fact-centered reasoning, with limited attention to temporal reasoning. To tackle the intricate and comprehensive nature of temporal reasoning, we propose a new TKGQA dataset, MusTQ, which... | Tingyi Zhang, Jiaan Wang, Zhixu Li, Jianfeng Qu, An Liu, Zhigang Chen, Hongping Zhi |  |
| 1682 |  |  [Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.697) |  | 0 | Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an expansion of the long-standing “conversation forecasting” task: instead of just accuracy, evaluation is conducted with uncertainty-aware metrics, effectively enabling abstention on individual instances.... | Anthony Sicilia, Hyunwoo Kim, Khyathi Raghavi Chandu, Malihe Alikhani, Jack Hessel |  |
| 1683 |  |  [Knowledge Fusion By Evolving Weights of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.698) |  | 0 | Fine-tuning pre-trained language models, particularly large language models, demands extensive computing resources and can result in varying performance outcomes across different domains and datasets. This paper examines the approach of integrating multiple models from diverse training scenarios into a unified model. This unified model excels across various data domains and exhibits the ability to generalize well on out-of-domain data. We propose a knowledge fusion method named Evolver,... | Guodong Du, Jing Li, Hanting Liu, Runhua Jiang, Shuyang Yu, Yifei Guo, Sim Kuan Goh, HoKin Tang |  |
| 1684 |  |  [ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale](https://doi.org/10.18653/v1/2024.findings-acl.699) |  | 0 | Multi-task learning (MTL) has shown considerable practical benefits, particularly when using language models (LMs). While this is commonly achieved by learning tasks under a joint optimization procedure, some methods, such as AdapterFusion, divide the problem into two stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is leveraged for a target task. This separation of... | Markus Frohmann, Carolin Holtermann, Shahed Masoudian, Anne Lauscher, Navid Rekabsaz |  |
| 1685 |  |  [Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.700) |  | 0 | For dialogue systems, the utilization of multimodal dialogue responses, as opposed to relying solely on text-only responses, offers the capability to describe different concepts through various modalities. This enhances the effectiveness of communication and elevates the overall conversational experience. However, current methods for dialogue-to-image retrieval are constrained by the capabilities of the pre-trained vision language models (VLMs). They struggle to accurately extract key... | ChangSheng Kao, YunNung Chen |  |
| 1686 |  |  [MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization](https://doi.org/10.18653/v1/2024.findings-acl.701) |  | 0 | Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored. In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks. Leveraging the capabilities of both code LLMs and... | Zhiyu Yang, Zihan Zhou, Shuo Wang, Xin Cong, Xu Han, Yukun Yan, Zhenghao Liu, Zhixing Tan, Pengyuan Liu, Dong Yu, Zhiyuan Liu, Xiaodong Shi, Maosong Sun |  |
| 1687 |  |  [Continual Few-shot Relation Extraction via Adaptive Gradient Correction and Knowledge Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.702) |  | 0 | Continual few-shot relation extraction (CFRE) aims to continually learn new relations with limited samples. However, current methods neglect the instability of embeddings in the process of different task training, which leads to serious catastrophic forgetting. In this paper, we propose the concept of the following degree from the perspective of instability to analyze catastrophic forgetting and design a novel method based on adaptive gradient correction and knowledge decomposition to alleviate... | Jianpeng Hu, Chengxiang Tan, Jiacheng Xu, Xiangyun Kong |  |
| 1688 |  |  [CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.703) |  | 0 | What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity... | Linhao Yu, Yongqi Leng, Yufei Huang, Shang Wu, Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang Song, Tingting Cui, Xiaoqing Cheng, Liutao Liutao, Deyi Xiong |  |
| 1689 |  |  [Cache & Distil: Optimising API Calls to Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.704) |  | 0 | Large-scale deployment of generative AI tools often depends on costly API calls to a Large Language Model (LLM) to fulfil user queries, a process that also exposes the request stream to external providers. To curtail the frequency of these calls, one can employ a local smaller language model -a student- which is continuously trained on the responses of the LLM. This student gradually gains proficiency in independently handling an increasing number of user requests, a process we term neural... | Guillem Ramírez, Matthias Lindemann, Alexandra Birch, Ivan Titov |  |
| 1690 |  |  [Investigating the Impact of Model Instability on Explanations and Uncertainty](https://doi.org/10.18653/v1/2024.findings-acl.705) |  | 0 | Explainable AI methods facilitate the understanding of model behaviour, yet, small, imperceptible perturbations to inputs can vastly distort explanations. As these explanations are typically evaluated holistically, before model deployment, it is difficult to assess when a particular explanation is trustworthy. Some studies have tried to create confidence estimators for explanations, but none have investigated an existing link between uncertainty and explanation quality. We artificially simulate... | Sara Marjanovic, Isabelle Augenstein, Christina Lioma |  |
| 1691 |  |  [A Two-Stage Adaptation of Large Language Models for Text Ranking](https://doi.org/10.18653/v1/2024.findings-acl.706) |  | 0 | Text ranking is a critical task in information retrieval. Recent advances in pre-trained language models (PLMs), especially large language models (LLMs), present new opportunities for applying them to text ranking. While supervised fine-tuning (SFT) with ranking data has been widely explored to better align PLMs with text ranking goals, previous studies have focused primarily on encoder-only and encoder-decoder PLMs. Research on leveraging decoder-only LLMs for text ranking remains scarce. An... | Longhui Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang |  |
| 1692 |  |  [Fine-tuning with HED-IT: The impact of human post-editing for dialogical language models](https://doi.org/10.18653/v1/2024.findings-acl.707) |  | 0 | Automatic methods for generating and gathering linguistic data have proven effective for fine-tuning Language Models (LMs) in languages less resourced than English. Still, while there has been emphasis on data quantity, less attention has been given to its quality. In this work, we investigate the impact of human intervention on machine-generated data when fine-tuning dialogical models. In particular, we study (1) whether post-edited dialogues exhibit higher perceived quality compared to the... | Daniela Occhipinti, Michele Marchi, Irene Mondella, Huiyuan Lai, Felice Dell'Orletta, Malvina Nissim, Marco Guerini |  |
| 1693 |  |  [Analyze, Generate and Refine: Query Expansion with LLMs for Zero-Shot Open-Domain QA](https://doi.org/10.18653/v1/2024.findings-acl.708) |  | 0 | Query expansion (QE) is a critical component in the open-domain question answering (OpenQA) pipeline, enhancing the retrieval performance by broadening the scope of queries with additional relevant texts. However, existing methods like GAR and EAR rely heavily on supervised training and often struggle to maintain effectiveness across domains and datasets. Meanwhile, although large language models (LLMs) have demonstrated QE capability for information retrieval (IR) tasks, their application in... | Xinran Chen, Xuanang Chen, Ben He, Tengfei Wen, Le Sun |  |
| 1694 |  |  [On the Evaluation of Speech Foundation Models for Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.709) |  | 0 | The Spoken Language Understanding Evaluation (SLUE) suite of benchmark tasks was recently introduced to address the need for openresources and benchmarking of complex spoken language understanding (SLU) tasks, including both classification and sequence generation tasks, on natural speech. The benchmark has demonstrated preliminary success in using pre-trained speech foundation models (SFM) for these SLU tasks. However, the community still lacks a fine-grained understanding of the comparative... | Siddhant Arora, Ankita Pasad, ChungMing Chien, Jionghao Han, Roshan S. Sharma, Jeeweon Jung, Hira Dhamyal, William Chen, Suwon Shon, Hungyi Lee, Karen Livescu, Shinji Watanabe |  |
| 1695 |  |  [Towards Multiple References Era - Addressing Data Leakage and Limited Reference Diversity in Machine Translation Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.710) |  | 0 | Recent research has shown a weak correlation between n-gram-based metrics and human evaluations in machine translation task, particularly when evaluating large language models (LLMs). Additionally, the data leakage risk in LLMs may cause an overestimation problem when evaluating LLMs on downstream tasks. In this work, we identify the limited diversity of references as the primary cause for the inferior performance of n-gram-based metrics and the overestimation problem. To address this issue, we... | Xianfeng Zeng, Yijin Liu, Fandong Meng, Jie Zhou |  |
| 1696 |  |  [Prompting open-source and commercial language models for grammatical error correction of English learner text](https://doi.org/10.18653/v1/2024.findings-acl.711) |  | 0 | Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input sentences. We evaluate how well LLMs can perform at GEC by measuring their performance on established benchmark datasets. We go beyond previous studies, which only examined GPT\* models on a selection of... | Christopher Davis, Andrew Caines, Øistein E. Andersen, Shiva Taslimipoor, Helen Yannakoudakis, Zheng Yuan, Christopher Bryant, Marek Rei, Paula Buttery |  |
| 1697 |  |  [BATS: BenchmArking Text Simplicity 🦇](https://doi.org/10.18653/v1/2024.findings-acl.712) |  | 0 | Evaluation of text simplification currently focuses on the difference of a source text to its simplified variant. Datasets for this evaluation base on a specific topic and group of readers for which is simplified. The broad applicability of text simplification and specifics that come with intended target audiences (e.g., children compared to adult non-experts) are disregarded. An explainable assessment of the overall simplicity of text is missing. This work is BenchmArking Text Simplicity... | Christin Kreutz, Fabian Haak, Björn Engelmann, Philipp Schaer |  |
| 1698 |  |  [AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection](https://doi.org/10.18653/v1/2024.findings-acl.713) |  | 0 | Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently, such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian German dialect, comprising 4,562 user comments. In addition to binary offensiveness classification, we identify spans within each comment constituting vulgar language or representing targets of... | Pia Pachinger, Janis Goldzycher, Anna Maria Planitzer, Wojciech Kusa, Allan Hanbury, Julia Neidhardt |  |
| 1699 |  |  [Discovering influential text using convolutional neural networks](https://doi.org/10.18653/v1/2024.findings-acl.714) |  | 0 | Experimental methods for estimating the impacts of text on human evaluation have been widely used in the social sciences. However, researchers in experimental settings are usually limited to testing a small number of pre-specified text treatments. While efforts to mine unstructured texts for features that causally affect outcomes have been ongoing in recent years, these models have primarily focused on the topics or specific words of text, which may not always be the mechanism of the effect. We... | Megan Ayers, Luke Sanford, Margaret E. Roberts, Eddie Yang |  |
| 1700 |  |  [LC4EE: LLMs as Good Corrector for Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.715) |  | 0 | Event extraction (EE) is a critical task in natural language processing, yet deploying a practical EE system remains challenging. On one hand, powerful large language models (LLMs) currently show poor performance because EE task is more complex than other tasks. On the other hand, state-of-the-art (SOTA) small language models (SLMs) for EE tasks are typically developed through fine-tuning, lack flexibility, and have considerable room for improvement. We propose an approach,... | Mengna Zhu, Kaisheng Zeng, Jibing Wu, Lihua Liu, Hongbin Huang, Lei Hou, Juanzi Li |  |
| 1701 |  |  [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.716) |  | 0 | Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs’ training data, it could explicitly or implicitly include test data, leading to LLMs being more susceptible to data contamination. However, due to the opacity of training data, the black-box access of models, and the rapid growth of synthetic training data, detecting and mitigating data... | Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, Bin Gu, Mengfei Yang, Ge Li |  |
| 1702 |  |  [Efficient Training of Language Models with Compact and Consistent Next Token Distributions](https://doi.org/10.18653/v1/2024.findings-acl.717) |  | 0 | Maximizing the likelihood of the next token is an established, statistically sound objective for pre-training language models. In this paper we show that we can train better models faster by pre-aggregating the corpus with a collapsed n-gram distribution. Previous studies have proposed corpus-level n-gram statistics as a regularizer; however, the construction and querying of such n-grams, if done naively, prove to be costly and significantly impede training speed, thereby limiting their... | Ashutosh Sathe, Sunita Sarawagi |  |
| 1703 |  |  [Ancient Chinese Glyph Identification Powered by Radical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.718) |  | 0 | The ancestor of Chinese character – the ancient characters from about 1300 BC to 200 BC are not fixed in their writing glyphs. At the same or different points in time, one character can possess multiple glyphs that are different in shapes or radicals. Nearly half of ancient glyphs have not been deciphered yet. This paper proposes an innovative task of ancient Chinese glyph identification, which aims at inferring the Chinese character label for the unknown ancient Chinese glyphs which are not in... | Yang Chi, Fausto Giunchiglia, Chuntao Li, Hao Xu |  |
| 1704 |  |  [PUB: A Pragmatics Understanding Benchmark for Assessing LLMs' Pragmatics Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.719) |  | 0 | LLMs have demonstrated remarkable capability for understanding semantics, but their understanding of pragmatics is not well studied. To this end, we release a Pragmatics Understanding Benchmark (PUB) dataset consisting of fourteen tasks in four pragmatics phenomena, namely; Implicature, Presupposition, Reference, and Deixis. We curate high-quality test sets for each task, consisting of Multiple Choice Question Answers (MCQA). PUB includes a total of 28k data points, 6.1k are newly annotated. We... | Settaluri Lakshmi Sravanthi, Meet Doshi, Pavan Tankala, V. Rudra Murthy, Raj Dabre, Pushpak Bhattacharyya |  |
| 1705 |  |  [EmoTransKG: An Innovative Emotion Knowledge Graph to Reveal Emotion Transformation](https://doi.org/10.18653/v1/2024.findings-acl.720) |  | 0 | This paper introduces EmoTransKG, an innovative Emotion Knowledge Graph (EKG) that establishes connections and transformations between emotions across diverse open-textual events. Compared to existing EKGs, which primarily focus on linking emotion keywords to related terms or on assigning sentiment dimension ratings to emotion words by humans, EmoTransKG aims to represent the general knowledge involved in emotion transformation. Specifically, in conversations, successive emotions expressed by a... | Huan Zhao, Xupeng Zha, Zixing Zhang |  |
| 1706 |  |  [How Vocabulary Sharing Facilitates Multilingualism in LLaMA?](https://doi.org/10.18653/v1/2024.findings-acl.721) |  | 0 | Large Language Models (LLMs), often show strong performance on English tasks, while exhibiting limitations on other languages. What is an LLM’s multilingual capability when it is trained only on certain languages? The underlying mechanism remains unclear. This study endeavors to examine the multilingual capability of LLMs from the vocabulary sharing perspective by conducting an exhaustive analysis across 101 languages. Through the investigation of the performance gap before and after embedding... | Fei Yuan, Shuai Yuan, Zhiyong Wu, Lei Li |  |
| 1707 |  |  [Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model](https://doi.org/10.18653/v1/2024.findings-acl.722) |  | 0 | While supervised fine-tuning (SFT) has been a straightforward approach for tailoring the output of foundation large language model (LLM) to specific preferences, concerns have been raised about the depth of this alignment, with some critiques suggesting it is merely “superficial”. We critically examine this hypothesis within the scope of cross-lingual generation tasks, proposing that the effectiveness of SFT may be constrained by its reliance on prior tokens to guide cross-lingual generation.... | Runzhe Zhan, Xinyi Yang, Derek F. Wong, Lidia S. Chao, Yue Zhang |  |
| 1708 |  |  [Dual Prompt Tuning based Contrastive Learning for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.723) |  | 0 | Hierarchical text classification aims at categorizing texts into a multi-tiered tree-structured hierarchy of labels. Existing methods pay more attention to capture hierarchy-aware text feature by exploiting explicit parent-child relationships, while interactions between peer labels are rarely taken into account, resulting in severe label confusion within each layer. In this work, we propose a novel Dual Prompt Tuning (DPT) method, which emphasizes identifying discrimination among peer labels by... | Sishi Xiong, Yu Zhao, Jie Zhang, Mengxiang Li, Zhongjiang He, Xuelong Li, Shuangyong Song |  |
| 1709 |  |  [Probing the Emergence of Cross-lingual Alignment during LLM Training](https://doi.org/10.18653/v1/2024.findings-acl.724) |  | 0 | Multilingual Large Language Models (LLMs) achieve remarkable levels of zero-shot cross-lingual transfer performance. We speculate that this is predicated on their ability to align languages without explicit supervision from parallel sentences. While representations of translationally equivalent sentences in different languages are known to be similar after convergence, however, it remains unclear how such cross-lingual alignment emerges during pre-training of LLMs. Our study leverages intrinsic... | Hetong Wang, Pasquale Minervini, Edoardo M. Ponti |  |
| 1710 |  |  [STSPL-SSC: Semi-Supervised Few-Shot Short Text Clustering with Semantic text similarity Optimized Pseudo-Labels](https://doi.org/10.18653/v1/2024.findings-acl.725) |  | 0 | This study introduces the Semantic Textual Similarity Pseudo-Label Semi-Supervised Clustering (STSPL-SSC) framework. The STSPL-SSC framework is designed to tackle the prevalent issue of scarce labeled data by combining a Semantic Textual Similarity Pseudo-Label Generation process with a Robust Contrastive Learning module. The process begins with employing k-means clustering on embeddings for initial pseudo-Label allocation. Then we use a Semantic Text Similarity-enhanced module to supervise the... | Wenhua Nie, Lin Deng, ChangBo Liu, Jialing Wei, Ruitong Han, Haoran Zheng |  |
| 1711 |  |  [A Comprehensive Evaluation of Quantization Strategies for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.726) |  | 0 | Increasing the number of parameters in large language models (LLMs) usually improves performance in downstream tasks but raises compute and memory costs, making deployment difficult in resource-limited settings. Quantization techniques, which reduce the bits needed for model weights or activations with minimal performance loss, have become popular due to the rise of LLMs. However, most quantization studies use pre-trained LLMs, and the impact of quantization on instruction-tuned LLMs and the... | Renren Jin, Jiangcun Du, Wuwei Huang, Wei Liu, Jian Luan, Bin Wang, Deyi Xiong |  |
| 1712 |  |  [Exploiting Target Language Data for Neural Machine Translation Beyond Back Translation](https://doi.org/10.18653/v1/2024.findings-acl.727) |  | 0 | Neural Machine Translation (NMT) encounters challenges when translating in new domains and low-resource languages. To address these issues, researchers have proposed methods to integrate additional knowledge into NMT, such as translation memories (TMs). However, finding TMs that closely match the input sentence remains challenging, particularly in specific domains. On the other hand, monolingual data is widely accessible in most languages, and back-translation is seen as a promising approach... | Abudurexiti Reheman, Yingfeng Luo, Junhao Ruan, Chunliang Zhang, Anxiang Ma, Tong Xiao, JingBo Zhu |  |
| 1713 |  |  [Bayesian Prompt Ensembles: Model Uncertainty Estimation for Black-Box Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.728) |  | 0 | An important requirement for the reliable deployment of pre-trained large language models (LLMs) is the well-calibrated quantification of the uncertainty in their outputs. While the likelihood of predicting the next token is a practical surrogate of the data uncertainty learned during training, model uncertainty is challenging to estimate, i.e., due to lack of knowledge acquired during training. Prior efforts to quantify uncertainty of neural networks require specific architectures or... | Francesco Tonolini, Nikolaos Aletras, Jordan Massiah, Gabriella Kazai |  |
| 1714 |  |  [X-ACE: Explainable and Multi-factor Audio Captioning Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.729) |  | 0 | Automated audio captioning (AAC) aims to generate descriptions based on audio input, attracting exploration of emerging audio language models (ALMs). However, current evaluation metrics only provide a single score to assess the overall quality of captions without characterizing the nuanced difference by systematically going through an evaluation checklist. To this end, we propose the explainable and multi-factor audio captioning evaluation (X-ACE) paradigm. X-ACE identifies four main factors... | Qian Wang, JiaChen Gu, ZhenHua Ling |  |
| 1715 |  |  [Reasons to Reject? Aligning Language Models with Judgments](https://doi.org/10.18653/v1/2024.findings-acl.730) |  | 0 | As humans, we consistently interact with our peers and receive feedback in the form of natural language. This language feedback allows us to maintain appropriate behavior, and rectify potential errors. The question arises naturally: can we use language feedback to align large language models (LLMs)? In contrast to previous research that aligns LLMs with scalar rewards, we present the first systematic exploration of alignment through the lens of language feedback (i.e., judgment). We start with... | Weiwen Xu, Deng Cai, Zhisong Zhang, Wai Lam, Shuming Shi |  |
| 1716 |  |  [Decomposing Argumentative Essay Generation via Dialectical Planning of Complex Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.731) |  | 0 | Argumentative Essay Generation (AEG) is a challenging task in computational argumentation, where detailed logical reasoning and effective rhetorical skills are essential.Previous methods on argument generation typically involve planning prior to generation.However, the planning strategies in these methods overlook the exploration of the logical reasoning process.Inspired by argument structure-related theories, we propose an argumentative planning strategy for prompting large language models... | Yuhang He, Jianzhu Bao, Yang Sun, Bin Liang, Min Yang, Bing Qin, Ruifeng Xu |  |
| 1717 |  |  [Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition](https://doi.org/10.18653/v1/2024.findings-acl.732) |  | 0 | Recognizing fallacies is crucial for ensuring the quality and validity of arguments across various domains. However, computational fallacy recognition faces challenges due to the diverse genres, domains, and types of fallacies found in datasets. This leads to a highly multi-class, and even multi-label, setup with substantial class imbalance. In this study, we aim to enhance existing models for fallacy recognition by incorporating additional context and by leveraging large language models to... | Tariq Alhindi, Smaranda Muresan, Preslav Nakov |  |
| 1718 |  |  [Concept-aware Data Construction Improves In-context Learning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.733) |  | 0 | Many recent language models (LMs) are capable of in-context learning (ICL), manifested in the LMs’ ability to perform a new task solely from natural-language instruction. Previous work curating in-context learners assumes that ICL emerges from a vast over-parametrization or the scale of multi-task training. However, recent theoretical work attributes the ICL ability to concept-dependent training data and creates functional in-context learners even in small-scale, synthetic settings.In this... | Michal Stefánik, Marek Kadlcík, Petr Sojka |  |
| 1719 |  |  [Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis](https://doi.org/10.18653/v1/2024.findings-acl.734) |  | 0 | Supervised machine-learning models for predicting user behavior offer a challenging classification problem with lower average prediction performance scores than other text classification tasks. This study evaluates multi-task learning frameworks grounded in Cognitive Appraisal Theory to predict user behavior as a function of users’ self-expression and psychological attributes. Our experiments show that users’ language and traits improve predictions above and beyond models predicting only from... | Gerard Yeo, Shaz Furniturewala, Kokil Jaidka |  |
| 1720 |  |  [Non-Autoregressive Machine Translation as Constrained HMM](https://doi.org/10.18653/v1/2024.findings-acl.735) |  | 0 | In non-autoregressive translation (NAT), directed acyclic Transformers (DAT) have demonstrated their ability to achieve comparable performance to the autoregressive Transformers.In this paper, we first show that DAT is essentially a fully connected left-to-right Hidden Markov Model (HMM), with the source and target sequences being observations and the token positions being latent states.Even though generative models like HMM do not suffer from label bias in traditional task settings (e.g.,... | Haoran Li, Zhanming Jie, Wei Lu |  |
| 1721 |  |  [Multi-modal Stance Detection: New Datasets and Model](https://doi.org/10.18653/v1/2024.findings-acl.736) |  | 0 | Stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. Previous work on stance detection largely focused on pure texts. In this paper, we study multi-modal stance detection for tweets consisting of texts and images, which are prevalent in today’s fast-growing social media platforms where people often post multi-modal messages. To this end, we create five new multi-modal stance detection datasets of different... | Bin Liang, Ang Li, Jingqian Zhao, Lin Gui, Min Yang, Yue Yu, KamFai Wong, Ruifeng Xu |  |
| 1722 |  |  [Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression](https://doi.org/10.18653/v1/2024.findings-acl.737) |  | 0 | Large language models (LLMs) can generate long-form and coherent text, yet they often hallucinate facts, which undermines their reliability. To mitigate this issue, inference-time methods steer LLM representations toward the “truthful directions” previously learned for truth elicitation. However, applying these truthful directions with the same intensity fails to generalize across different query contexts. We propose LITO, a Learnable Intervention method for Truthfulness Optimization that... | Farima Fatahi Bayat, Xin Liu, H. V. Jagadish, Lu Wang |  |
| 1723 |  |  [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.738) |  | 0 | In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Initially, we outline general design... | Duzhen Zhang, Yahan Yu, Jiahua Dong, Chenxing Li, Dan Su, Chenhui Chu, Dong Yu |  |
| 1724 |  |  [CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.739) |  | 0 | The advancement of large language models (LLMs) has enhanced the ability to generalize across a wide range of unseen natural language processing (NLP) tasks through instruction-following.Yet, their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased evaluations from data leakage, casting doubt on their true generalizability to new linguistic territories. In response, we introduce the Chinese Instruction-Following Benchmark (\*\*CIF-Bench\*\*), designed... | Yizhi Li, Ge Zhang, Xingwei Qu, Jiali Li, Zhaoqun Li, Noah Wang, Hao Li, Ruibin Yuan, Yinghao Ma, Kai Zhang, Wangchunshu Zhou, Yiming Liang, Lei Zhang, Lei Ma, Jiajun Zhang, Zuowen Li, Wenhao Huang, Chenghua Lin, Jie Fu |  |
| 1725 |  |  [Countering Reward Over-Optimization in LLM with Demonstration-Guided Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.740) |  | 0 | While reinforcement learning (RL) has been proven essential for tuning large language models (LLMs), it can lead to reward over-optimization (ROO). Existing approaches address ROO by adding KL regularization, requiring computationally expensive hyperparameter tuning. Additionally, KL regularization focuses solely on regularizing the language policy, neglecting a potential source of regularization: the reward function itself. Inspired by demonstration-guided RL, we here introduce the Reward... | Mathieu Rita, Florian Strub, Rahma Chaabouni, Paul Michel, Emmanuel Dupoux, Olivier Pietquin |  |
| 1726 |  |  [Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss](https://doi.org/10.18653/v1/2024.findings-acl.741) |  | 0 | Accurately modeling idiomatic or non-compositional language has been a longstanding challenge in Natural Language Processing (NLP). This is partly because these expressions do not derive their meanings solely from their constituent words, but also due to the scarcity of relevant data resources, and their impact on the performance of downstream tasks such as machine translation and simplification. In this paper we propose an approach to model idiomaticity effectively using a triplet loss that... | Wei He, Marco Idiart, Carolina Scarton, Aline Villavicencio |  |
| 1727 |  |  [AdaLomo: Low-memory Optimization with Adaptive Learning Rate](https://doi.org/10.18653/v1/2024.findings-acl.742) |  | 0 | Large language models have achieved remarkable success, but their extensive parameter size necessitates substantial memory for training, thereby setting a high threshold. While the recently proposed low-memory optimization (LOMO) reduces memory footprint, its optimization technique, akin to stochastic gradient descent, is sensitive to hyper-parameters and exhibits suboptimal convergence, failing to match the performance of the prevailing optimizer for large language models, AdamW. Through... | Kai Lv, Hang Yan, Qipeng Guo, Haijun Lv, Xipeng Qiu |  |
| 1728 |  |  [Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks](https://doi.org/10.18653/v1/2024.findings-acl.743) |  | 0 | Current knowledge editing approaches struggle to effectively propagate updates to interconnected facts.In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel reasoning-based benchmark, ReCoE (Reasoning-based Counterfactual Editing dataset), which covers six common reasoning schemes in the real world. We conduct an extensive analysis of existing knowledge... | Wenyue Hua, Jiang Guo, Mingwen Dong, Henghui Zhu, Patrick Ng, Zhiguo Wang |  |
| 1729 |  |  [Exciting Mood Changes: A Time-aware Hierarchical Transformer for Change Detection Modelling](https://doi.org/10.18653/v1/2024.findings-acl.744) |  | 0 | Through the rise of social media platforms, longitudinal language modelling has received much attention over the latest years, especially in downstream tasks such as mental health monitoring of individuals where modelling linguistic content in a temporal fashion is crucial. A key limitation in existing work is how to effectively model temporal sequences within Transformer-based language models. In this work we address this challenge by introducing a novel approach for predicting ‘Moments of... | Anthony Hills, Talia Tseriotou, Xenia Miscouridou, Adam Tsakalidis, Maria Liakata |  |
| 1730 |  |  [CorNav: Autonomous Agent with Self-Corrected Planning for Zero-Shot Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.findings-acl.745) |  | 0 | Understanding and following natural language instructions while navigating through complex, real-world environments poses a significant challenge for general-purpose robots. These environments often include obstacles and pedestrians, making it essential for autonomous agents to possess the capability of self-corrected planning to adjust their actions based on feedback from the surroundings. However, the majority of existing vision-and-language navigation (VLN) methods primarily operate in less... | Xiwen Liang, Liang Ma, Shanshan Guo, Jianhua Han, Hang Xu, Shikui Ma, Xiaodan Liang |  |
| 1731 |  |  [SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.746) |  | 0 | Multi-modal information retrieval (MMIR) is a rapidly evolving field where significant progress has been made through advanced representation learning and cross-modality alignment research, particularly in image-text pairing.However, current benchmarks for evaluating MMIR performance on image-text pairings overlook the scientific domain, which has a notable gap with the generic data since the caption of scientific charts and tables usually describes the analysis of experimental results or... | Siwei Wu, Yizhi Li, Kang Zhu, Ge Zhang, Yiming Liang, Kaijing Ma, Chenghao Xiao, Haoran Zhang, Bohao Yang, Wenhu Chen, Wenhao Huang, Noura Al Moubayed, Jie Fu, Chenghua Lin |  |
| 1732 |  |  [Diving Deep into the Motion Representation of Video-Text Models](https://doi.org/10.18653/v1/2024.findings-acl.747) |  | 0 | Videos are more informative than images becausethey capture the dynamics of the scene.By representing motion in videos, we can capturedynamic activities. In this work, we introduceGPT-4 generated motion descriptions thatcapture fine-grained motion descriptions of activitiesand apply them to three action datasets.We evaluated several video-text models on thetask of retrieval of motion descriptions. Wefound that they fall far behind human expertperformance on two action datasets, raisingthe... | Chinmaya Devaraj, Cornelia Fermüller, Yiannis Aloimonos |  |
| 1733 |  |  [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation](https://doi.org/10.18653/v1/2024.findings-acl.748) |  | 0 | We introduce Bonito, an open-source model for conditional task generation that converts unannotated text into task-specific training datasets for instruction tuning. We aim to enable zero-shot task adaptation of large language models on users’ specialized, private data. We train Bonito by fine-tuning a pretrained large language model on a new large-scale dataset with 1.65M examples created by remixing existing instruction tuning datasets into meta-templates. The meta-templates for a dataset... | Nihal V. Nayak, Yiyang Nan, Avi Trost, Stephen H. Bach |  |
| 1734 |  |  [Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.749) |  | 0 | Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also often retain a large portion of the offensiveness of the original content, which raises questions on their overall usability. In this paper we aim to assist practitioners in developing usable paraphrasers by exploring In-Context... | Anirudh Som, Karan Sikka, Helen Gent, Ajay Divakaran, Andreas Kathol, Dimitra Vergyri |  |
| 1735 |  |  [Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse](https://doi.org/10.18653/v1/2024.findings-acl.750) |  | 0 | Whataboutism, a potent tool for disrupting narratives and sowing distrust, remains under-explored in quantitative NLP research. Moreover, past work has not distinguished its use as a strategy for misinformation and propaganda from its use as a tool for pragmatic and semantic framing. We introduce new datasets from Twitter/X and YouTube, revealing overlaps as well as distinctions between whataboutism, propaganda, and the tu quoque fallacy. Furthermore, drawing on recent work in linguistic... | Khiem Phi, Noushin Salek Faramarzi, Chenlu Wang, Ritwik Banerjee |  |
| 1736 |  |  [Epistemology of Language Models: Do Language Models Have Holistic Knowledge?](https://doi.org/10.18653/v1/2024.findings-acl.751) |  | 0 | This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as commonsense, general, and specific knowledge, each plays a specific role, serving as the foundation of our knowledge system and being difficult to revise. To assess these traits related to holism, we created a... | Minsu Kim, James Thorne |  |
| 1737 |  |  [Strong hallucinations from negation and how to fix them](https://doi.org/10.18653/v1/2024.findings-acl.752) |  | 0 | Despite great performance on many tasks, language models (LMs) still struggle with reasoning, sometimes providing responses that cannot possibly be true because they stem from logical incoherence. We call such responses strong hallucinations and prove that they follow from an LM’s computation of its internal representations for logical operators and outputs from those representations. Focusing on negation, we provide a novel solution in which negation is treated not as another element of a... | Swarnadeep Bhar, Nicholas Asher |  |
| 1738 |  |  [LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores](https://doi.org/10.18653/v1/2024.findings-acl.753) |  | 0 | Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for automated assessment of generation tasks. This paper investigates a pivotal question: Do language model-driven evaluation metrics inherently exhibit bias favoring texts generated by the same underlying... | Yiqi Liu, Nafise Sadat Moosavi, Chenghua Lin |  |
| 1739 |  |  [HelloFresh: LLM Evalutions on Streams of Real-World Human Editorial Actions across X Community Notes and Wikipedia edits](https://doi.org/10.18653/v1/2024.findings-acl.754) |  | 0 | Benchmarks have been essential for driving progress in machine learning. A better understanding of LLM capabilities on real world tasks is vital for safe development.Designing adequate LLM benchmarks is challenging: Data from real-world tasks is hard to collect, public availability of static evaluation data results in test data contamination and benchmark overfitting, and periodically generating new evaluation data is tedious and may result in temporally inconsistent results. We introduce... | Tim Franzmeyer, Aleksandar Shtedritski, Samuel Albanie, Philip Torr, João F. Henriques, Jakob N. Foerster |  |
| 1740 |  |  [Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies](https://doi.org/10.18653/v1/2024.findings-acl.755) |  | 0 | This study explores the sycophantic tendencies of Large Language Models (LLMs), where these models tend to provide answers that match what users want to hear, even if they are not entirely correct. The motivation behind this exploration stems from the common behavior observed in individuals searching the internet for facts with partial or misleading knowledge. Similar to using web search engines, users may recall fragments of misleading keywords and submit them to an LLM, hoping for a... | Aswin RRV, Nemika Tyagi, Md Nayem Uddin, Neeraj Varshney, Chitta Baral |  |
| 1741 |  |  [Empowering Large Language Models for Textual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.756) |  | 0 | With the capabilities of understanding and executing natural language instructions, Large language models (LLMs) can potentially act as a powerful tool for textual data augmentation. However, the quality of augmented data depends heavily on the augmentation instructions provided, and the effectiveness can fluctuate across different downstream tasks. While manually crafting and selecting instructions can offer some improvement, this approach faces scalability and consistency issues in practice... | Yichuan Li, Kaize Ding, Jianling Wang, Kyumin Lee |  |
| 1742 |  |  [Choose Your Transformer: Improved Transferability Estimation of Transformer Models on Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.757) |  | 0 | There currently exists a multitude of pre-trained transformer language models (LMs) that are readily available. From a practical perspective, this raises the question of which pre-trained LM will perform best if fine-tuned for a specific downstream NLP task. However, exhaustively fine-tuning all available LMs to determine the best-fitting model is computationally infeasible. To address this problem, we present an approach that inexpensively estimates a ranking of the expected performance of a... | Lukas Garbaciauskas, Max Ploner, Alan Akbik |  |
| 1743 |  |  [Argument-Aware Approach To Event Linking](https://doi.org/10.18653/v1/2024.findings-acl.758) |  | 0 | Event linking connects event mentions in text with relevant nodes in a knowledge base (KB). Prior research in event linking has mainly borrowed methods from entity linking, overlooking the distinct features of events. Compared to the extensively explored entity linking task, events have more complex structures and can be more effectively distinguished by examining their associated arguments. Moreover, the information-rich nature of events leads to the scarcity of event KBs. This emphasizes the... | IHung Hsu, Zihan Xue, Nilay Pochhi, Sahil Bansal, Prem Natarajan, Jayanth Srinivasa, Nanyun Peng |  |
| 1744 |  |  [CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation](https://doi.org/10.18653/v1/2024.findings-acl.759) |  | 0 | Grounded generation aims to equip language models (LMs) with the ability to produce more credible and accountable responses by accurately citing verifiable sources. However, existing methods, by either feeding LMs with raw or preprocessed materials, remain prone to errors. To address this, we introduce CaLM, a novel verification framework. CaLM leverages the insight that a robust grounded response should be consistent with information derived solely from its cited sources. Our framework... | IHung Hsu, Zifeng Wang, Long T. Le, Lesly Miculicich, Nanyun Peng, ChenYu Lee, Tomas Pfister |  |
| 1745 |  |  [TextEE: Benchmark, Reevaluation, Reflections, and Future Challenges in Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.760) |  | 0 | Event extraction has gained considerable interest due to its wide-ranging applications. However, recent studies draw attention to evaluation issues, suggesting that reported scores may not accurately reflect the true performance. In this work, we identify and address evaluation challenges, including inconsistency due to varying data assumptions or preprocessing steps, the insufficiency of current evaluation frameworks that may introduce dataset or data split bias, and the low reproducibility of... | KuanHao Huang, IHung Hsu, Tanmay Parekh, Zhiyu Xie, Zixuan Zhang, Prem Natarajan, KaiWei Chang, Nanyun Peng, Heng Ji |  |
| 1746 |  |  [Understanding the Impacts of Language Technologies' Performance Disparities on African American Language Speakers](https://doi.org/10.18653/v1/2024.findings-acl.761) |  | 0 | This paper examines the experiences of African American Language (AAL) speakers when using language technologies. Previous work has used quantitative methods to uncover performance disparities between AAL speakers and White Mainstream English speakers when using language technologies, but has not sought to understand the impacts of these performance disparities on AAL speakers. Through interviews with 19 AAL speakers, we focus on understanding such impacts in a contextualized and human-centered... | Jay Cunningham, Su Lin Blodgett, Michael Madaio, Hal Daumé III, Christina Harrington, Hanna M. Wallach |  |
| 1747 |  |  [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://doi.org/10.18653/v1/2024.findings-acl.762) |  | 0 | The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of open-source code systems designed for generating, executing, and iteratively refining code. Supported by Code Feedback, a dataset featuring 68K multi-turn interactions, OpenCodeInterpreter integrates... | Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen Lin, Jie Fu, Wenhu Chen, Xiang Yue |  |
| 1748 |  |  [Measuring and Addressing Indexical Bias in Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.763) |  | 0 | Information Retrieval (IR) systems are designed to deliver relevant content, but traditional systems may not optimize rankings for fairness, neutrality, or the balance of ideas. Consequently, IR can often introduce indexical biases, or biases in the positional order of documents. Although indexical bias can demonstrably affect people’s opinion, voting patterns, and other behaviors, these issues remain understudied as the field lacks reliable metrics and procedures for automatically measuring... | Caleb Ziems, William Held, Jane DwivediYu, Diyi Yang |  |
| 1749 |  |  [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://doi.org/10.18653/v1/2024.findings-acl.764) |  | 0 | Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, leading to inherent biases toward Western culture. This bias negatively impacts non-English languages such as Arabic and the unique culture of the Arab region. This paper addresses this limitation by introducing CIDAR, the first open Arabic instruction-tuning... | Zaid Alyafeai, Khalid Almubarak, Ahmed Ashraf, Deema Alnuhait, Saied Alshahrani, Gubran A. Q. Abdulrahman, Gamil Ahmed, Qais Gawah, Zead Saleh, Mustafa Ghaleb, Yousef Ali, Maged Saeed AlShaibani |  |
| 1750 |  |  [RadGraph-XL: A Large-Scale Expert-Annotated Dataset for Entity and Relation Extraction from Radiology Reports](https://doi.org/10.18653/v1/2024.findings-acl.765) |  | 0 | In order to enable extraction of structured clinical data from unstructured radiology reports, we introduce RadGraph-XL, a large-scale, expert-annotated dataset for clinical entity and relation extraction. RadGraph-XL consists of 2,300 radiology reports, which are annotated with over 410,000 entities and relations by board-certified radiologists. Whereas previous approaches focus solely on chest X-rays, RadGraph-XL includes data from four anatomy-modality pairs - chest CT, abdomen/pelvis CT,... | JeanBenoit Delbrouck, Pierre J. Chambon, Zhihong Chen, Maya Varma, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Tan Bui, Steven Quoc Hung Truong, Curtis P. Langlotz |  |
| 1751 |  |  [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.766) |  | 0 | Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging. Unfortunately, there’s currently no systematic method beyond manual tuning or relying on practitioners’ intuition. In this paper, we introduce SMART (Submodular data Mixture... | H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia, Ganesh Ramakrishnan |  |
| 1752 |  |  [Selective "Selective Prediction": Reducing Unnecessary Abstention in Vision-Language Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.767) |  | 0 | Selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain too frequently, even on many correct predictions. We introduce ReCoVERR, an inference-time algorithm to reduce the over-abstention of a selective vision-language system without increasing the error rate... | Tejas Srinivasan, Jack Hessel, Tanmay Gupta, Bill Yuchen Lin, Yejin Choi, Jesse Thomason, Khyathi Raghavi Chandu |  |
| 1753 |  |  [Language Model Priors and Data Augmentation Strategies for Low-resource Machine Translation: A Case Study Using Finnish to Northern Sámi](https://doi.org/10.18653/v1/2024.findings-acl.768) |  | 0 | We investigate ways of using monolingual data in both the source and target languages for improving low-resource machine translation. As a case study, we experiment with translation from Finnish to Northern Sámi.Our experiments show that while conventional backtranslation remains a strong contender, using synthetic target-side data when training backtranslation models can be helpful as well.We also show that monolingual data can be used to train a language model which can act as a regularizer... | Jonne Sälevä, Constantine Lignos |  |
| 1754 |  |  [Differentially Private Knowledge Distillation via Synthetic Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.769) |  | 0 | Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy puts pressure on practitioners to train LLMs with Differential Privacy (DP) on private data. Concurrently, the exponential growth in parameter size of LLMs necessitates model compression before deployment of LLMs on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade... | James Flemings, Murali Annavaram |  |
| 1755 |  |  [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](https://doi.org/10.18653/v1/2024.findings-acl.770) |  | 0 | Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on this task, we construct KIWI, a dataset of knowledge-intensive writing instructions in the scientific domain. Given a research question, an initial model-generated answer and a set of relevant... | Fangyuan Xu, Kyle Lo, Luca Soldaini, Bailey Kuehl, Eunsol Choi, David Wadden |  |
| 1756 |  |  [XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the Multilingual Generation of News Headlines and Tags](https://doi.org/10.18653/v1/2024.findings-acl.771) |  | 0 | Millions of news articles published online daily can overwhelm readers. Headlines and entity (topic) tags are essential for guiding readers to decide if the content is worth their time. While headline generation has been extensively studied, tag generation remains largely unexplored, yet it offers readers better access to topics of interest. The need for conciseness in capturing readers’ attention necessitates improved content selection strategies for identifying salient and relevant segments... | Faisal Tareque Shohan, Mir Tafseer Nayeem, Samsul Islam, Abu Ubaida Akash, Shafiq Joty |  |
| 1757 |  |  [InFoBench: Evaluating Instruction Following Ability in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.772) |  | 0 | This paper introduces the Decomposed Requirements Following Ratio (DRFR), a new metric for evaluating Large Language Models’ (LLMs) ability to follow instructions. Addressing a gap in current methodologies, DRFR breaks down complex instructions into simpler criteria, facilitating a detailed analysis of LLMs’ compliance with various aspects of tasks. Alongside this metric, we present InFoBench, a benchmark comprising 500 diverse instructions and 2,250 decomposed questions across multiple... | Yiwei Qin, Kaiqiang Song, Yebowen Hu, Wenlin Yao, Sangwoo Cho, Xiaoyang Wang, Xuansheng Wu, Fei Liu, Pengfei Liu, Dong Yu |  |
| 1758 |  |  [EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.773) |  | 0 | Large Language Models (LLMs) have achieved state-of-the-art performance in text re-ranking. This process includes queries and candidate passages in the prompts, utilizing pointwise, listwise, and pairwise prompting strategies. A limitation of these ranking strategies with LLMs is their cost: the process can become expensive due to API charges, which are based on the number of input and output tokens. We study how to maximize the re-ranking performance given a budget, by navigating the vast... | Muhammad Shihab Rashid, Jannat Ara Meem, Yue Dong, Vagelis Hristidis |  |
| 1759 |  |  [FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.774) |  | 0 | We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction fine-tuning, and RLAIF training by exploiting a large collection of textual and visual datasets we curate for this work. We also introduce an extensive benchmark featuring nine tasks and 25 datasets for... | Gagan Bhatia, El Moatez Billah Nagoudi, Hasan Cavusoglu, Muhammad AbdulMageed |  |
| 1760 |  |  [Aligning Large Multimodal Models with Factually Augmented RLHF](https://doi.org/10.18653/v1/2024.findings-acl.775) |  | 0 | Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in “hallucination”, generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the... | Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liangyan Gui, YuXiong Wang, Yiming Yang, Kurt Keutzer, Trevor Darrell |  |
| 1761 |  |  [The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness](https://doi.org/10.18653/v1/2024.findings-acl.776) |  | 0 | As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research. This has resulted in the development of various LLM defense strategies. Unfortunately, despite the shared goal of improving the safety of LLMs, the evaluation suites across various research works are disjoint and lack diverse inputs to ensure accurate and precise evaluation estimates. Furthermore, the important factor of... | Neeraj Varshney, Pavel Dolin, Agastya Seth, Chitta Baral |  |
| 1762 |  |  [PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering](https://doi.org/10.18653/v1/2024.findings-acl.777) |  | 0 | Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. ‘Who was the US president in 1970?’). Little work has studied questions whose temporal context is relative to the present time (e.g. ‘Who was the previous US president?’). We refer to this problem as Present-Anchored Temporal QA (PATQA). PATQA poses unique challenges: (1) large language models (LLMs) may have outdated knowledge, (2) complex temporal... | Jannat Ara Meem, Muhammad Shihab Rashid, Yue Dong, Vagelis Hristidis |  |
| 1763 |  |  [360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](https://doi.org/10.18653/v1/2024.findings-acl.778) |  | 0 |  | Shen Gao, Hao Li, Zhengliang Shi, Chengrui Huang, Quan Tu, Shuo Shang, Zhiliang Tian, Minlie Huang |  |
| 1764 |  |  [Extracting Polymer Nanocomposite Samples from Full-Length Documents](https://doi.org/10.18653/v1/2024.findings-acl.779) |  | 0 | This paper investigates the use of large language models (LLMs) for extracting sample lists of polymer nanocomposites (PNCs) from full-length materials science research papers. The challenge lies in the complex nature of PNC samples, which have numerous attributes scattered throughout the text. The complexity of annotating detailed information on PNCs limits the availability of data, making conventional document-level relation extraction techniques impractical due to the challenge in creating... | Ghazal Khalighinejad, Defne Circi, L. Catherine Brinson, Bhuwan Dhingra |  |
| 1765 |  |  [Leveraging LLM Reasoning Enhances Personalized Recommender Systems](https://doi.org/10.18653/v1/2024.findings-acl.780) |  | 0 |  | Alicia Tsai, Adam Kraft, Long Jin, Chenwei Cai, Anahita Hosseini, Taibai Xu, Zemin Zhang, Lichan Hong, Ed Huaihsin Chi, Xinyang Yi |  |
| 1766 |  |  [Toucan: Many-to-Many Translation for 150 African Language Pairs](https://doi.org/10.18653/v1/2024.findings-acl.781) |  | 0 | We address a notable gap in Natural Language Processing (NLP) by introducing a collection of resources designed to improve Machine Translation (MT) for low-resource languages, with a specific focus on African languages. First, We introduce two language models (LMs), Cheetah-1.2B and Cheetah-3.7B, with 1.2 billion and 3.7 billion parameters respectively. Next, we finetune the aforementioned models to create Toucan, an Afrocentric machine translation model designed to support 156 African language... | AbdelRahim A. Elmadany, Ife Adebara, Muhammad AbdulMageed |  |
| 1767 |  |  [Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.782) |  | 0 | We consider the task of building a dialogue system that can motivate users to adopt positive lifestyle changes, Motivational Interviewing (MI). Addressing such a task requires a system that could infer how to motivate the user effectively. We propose DIIR, a framework that is capable of learning and applying conversation strategies in the form of natural language inductive rules from expert demonstrations. Automatic and human evaluation on instruction-following large language models show... | Zhouhang Xie, Bodhisattwa Prasad Majumder, Mengjie Zhao, Yoshinori Maeda, Keiichi Yamada, Hiromi Wakaki, Julian J. McAuley |  |
| 1768 |  |  [Evaluating Structural Generalization in Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.783) |  | 0 | Compositional generalization refers to the ability to generalize to novel combinations of previously observed words and syntactic structures.Since it is regarded as a desired property of neural models, recent work has assessed compositional generalization in machine translation as well as semantic parsing.However, previous evaluations with machine translation have focused mostly on lexical generalization (i.e., generalization to unseen combinations of known words).Thus, it remains unclear to... | Ryoma Kumon, Daiki Matsuoka, Hitomi Yanaka |  |
| 1769 |  |  [Figuratively Speaking: Authorship Attribution via Multi-Task Figurative Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.784) |  | 0 | The identification of Figurative Language (FL) features in text is crucial for various Natural Language Processing (NLP) tasks, where understanding of the author’s intended meaning and its nuances is key for successful communication. At the same time, the use of a specific blend of various FL forms most accurately reflects a writer’s style, rather than the use of any single construct, such as just metaphors or irony. Thus, we postulate that FL features could play an important role in Authorship... | Gregorios A. Katsios, Ning Sa, Tomek Strzalkowski |  |
| 1770 |  |  [CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.785) |  | 0 | Recent large language models (LLMs) have shown indications of mathematical reasoning ability on challenging competition-level problems, especially with self-generated verbalizations of intermediate reasoning steps (i.e., chain-of-thought prompting). However, current evaluations mainly focus on the end-to-end final answer correctness, and it is unclear whether LLMs can make use of helpful side information such as problem-specific hints. In this paper, we propose a challenging benchmark dataset... | Yujun Mao, Yoon Kim, Yilun Zhou |  |
| 1771 |  |  [Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.786) |  | 0 | Contemporary translation engines based on the encoder-decoder framework have made significant strides in development.However, the emergence of Large Language Models (LLMs) has disrupted their position by presenting the potential for achieving superior translation quality.To uncover the circumstances in which LLMs excel and explore how their strengths can be harnessed to enhance translation quality,we first conduct a comprehensive analysis to assess the strengths and limitations of various... | Jiali Zeng, Fandong Meng, Yongjing Yin, Jie Zhou |  |
| 1772 |  |  [Integrating Pre-Trained Speech and Language Models for End-to-End Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.787) |  | 0 | Advances in machine learning have made it possible to perform various text and speech processing tasks, such as automatic speech recognition (ASR), in an end-to-end (E2E) manner. E2E approaches utilizing pre-trained models are gaining attention for conserving training data and resources. However, most of their applications in ASR involve only one of either a pre-trained speech or a language model. This paper proposes integrating a pre-trained speech representation model and a large language... | Yukiya Hono, Koh Mitsuda, Tianyu Zhao, Kentaro Mitsui, Toshiaki Wakatsuki, Kei Sawada |  |
| 1773 |  |  [Proving membership in LLM pretraining data via data watermarks](https://doi.org/10.18653/v1/2024.findings-acl.788) |  | 0 | Detecting whether copyright holders’ works were used in LLM pretraining is poised to be an important problem. This work proposes using data watermarks to enable principled detection with only black-box model access, provided that the rightholder contributed multiple training documents and watermarked them before public release. By applying a randomly sampled data watermark, detection can be framed as hypothesis testing, which provides guarantees on the false detection rate. We study two... | Johnny TianZheng Wei, Ryan Yixiang Wang, Robin Jia |  |
| 1774 |  |  [Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses](https://doi.org/10.18653/v1/2024.findings-acl.789) |  | 0 | Detecting hallucinations in large language model (LLM) outputs is pivotal, yet traditional fine-tuning for this classification task is impeded by the expensive and quickly outdated annotation process, especially across numerous vertical domains and in the face of rapid LLM advancements. In this study, we introduce an approach that automatically generates both faithful and hallucinated outputs by rewriting system responses. Experimental findings demonstrate that a T5-base model, fine-tuned on... | Dongxu Zhang, Varun Gangal, Barrett Martin Lattimer, Yi Yang |  |
| 1775 |  |  [SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC](https://doi.org/10.18653/v1/2024.findings-acl.790) |  | 0 |  | Jinglong Luo, Yehong Zhang, Zhuo Zhang, Jiaqi Zhang, Xin Mu, Hui Wang, Yue Yu, Zenglin Xu |  |
| 1776 |  |  [Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications](https://doi.org/10.18653/v1/2024.findings-acl.791) |  | 0 | With the proliferation of LLM-integrated applications such as GPT-s, millions are deployed, offering valuable services through proprietary instruction prompts. These systems, however, are prone to prompt extraction attacks through meticulously designed queries. To help mitigate this problem, we introduce the Raccoon benchmark which comprehensively evaluates a model’s susceptibility to prompt extraction attacks. Our novel evaluation method assesses models under both defenseless and defended... | Junlin Wang, Tianyi Yang, Roy Xie, Bhuwan Dhingra |  |
| 1777 |  |  [History-Aware Conversational Dense Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.792) |  | 0 | Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In particular, the search query should include the relevant information from the previous conversation turns.However, current approaches for conversational dense retrieval primarily rely on fine-tuning a... | Fengran Mo, Chen Qu, Kelong Mao, Tianyu Zhu, Zhan Su, Kaiyu Huang, JianYun Nie |  |
| 1778 |  |  [Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.793) |  | 0 | Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various downstream tasks. However, scaling them up is challenging because building large-scale MMKGs often introduces mismatched images (i.e., noise). Most entities in KGs belong to the long tail, meaning there are few images of them available online. This scarcity makes it difficult to determine whether a found image matches the entity. To address this, we draw on the Triangle of Reference Theory and suggest enhancing... | Yikai Zhang, Qianyu He, Xintao Wang, Siyu Yuan, Jiaqing Liang, Yanghua Xiao |  |
| 1779 |  |  [ZeroStance: Leveraging ChatGPT for Open-Domain Stance Detection via Dataset Generation](https://doi.org/10.18653/v1/2024.findings-acl.794) |  | 0 | Zero-shot stance detection that aims to detect the stance (typically against, favor, or neutral) towards unseen targets has attracted considerable attention. However, most previous studies only focus on targets from a single or limited text domains (e.g., financial domain), and thus zero-shot models cannot generalize well to unseen targets of diverse domains (e.g., political domain). In this paper, we consider a more realistic task, i.e., open-domain stance detection, which aims at training a... | Chenye Zhao, Yingjie Li, Cornelia Caragea, Yue Zhang |  |
| 1780 |  |  [Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.795) |  | 0 | Large language models (LLMs) are very proficient text generators. We leverage this capability of LLMs to generate task-specific data via zero-shot prompting and promote cross-lingual transfer for low-resource target languages. Given task-specific data in a source language and a teacher model trained on this data, we propose using this teacher to label LLM generations and employ a set of simple data selection strategies that use the teacher’s label probabilities. Our data selection strategies... | Barah Fazili, Ashish Agrawal, Preethi Jyothi |  |
| 1781 |  |  [Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.796) |  | 0 | Learning multi-task models for jointly detecting stance and verifying rumors poses challenges due to the need for training data of stance at post level and rumor veracity at claim level, which are difficult to obtain. To address this issue, we leverage large language models (LLMs) as the foundation annotators for the joint stance detection (SD) and rumor verification (RV) tasks, dubbed as JSDRV. We introduce a novel reinforcement tuning framework to enhance the joint predictive capabilities of... | Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, Bo Wang |  |
| 1782 |  |  [Exploring the Potential of Dense Information in Multimodal Alignment](https://doi.org/10.18653/v1/2024.findings-acl.797) |  | 0 | Despite the success of data augmentation in improving CLIP model, existing methods that utilize LLM or SAM to enrich the information in captions still suffer from several limitations, including insufficient detail and excessive hallucinations, ultimately resulting in compromised alignment and masking the true potential of dense information. This can lead to erroneous conclusions about CLIP’s ability to handle rich data, impeding the development of more effective models. To address the... | Zhiyuan Fan, Zhihong Chen, Benyou Wang |  |
| 1783 |  |  [Referral Augmentation for Zero-Shot Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.798) |  | 0 | We propose Referral-Augmented Retrieval (RAR), a simple technique that concatenates document indices with referrals: text from other documents that cite or link to the given document. We find that RAR provides significant performance gains for tasks across paper retrieval, entity retrieval, and open-domain question-answering in both zero-shot and in-domain (e.g., fine-tuned) settings. We examine how RAR provides especially strong improvements on more structured tasks, and can greatly outperform... | Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan |  |
| 1784 |  |  [InstructEval: Instruction-Tuned Text Evaluator from Human Preference](https://doi.org/10.18653/v1/2024.findings-acl.799) |  | 0 | This paper explores to construct a general text evaluator based on open-source Large Language Models (LLMs), a domain predominantly occupied by commercial counterparts such as GPT-4. Recognizing the limitations of open-source models like Llama in evaluative tasks, we introduce InstructEval, a general multi-aspect text evaluator developed through instruction tuning of open-source LLMs. To overcome the shortage of annotated resources for multi-aspect evaluations, InstructEval combines extensive... | Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li |  |
| 1785 |  |  [A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models](https://doi.org/10.18653/v1/2024.findings-acl.800) |  | 0 | Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done only after fine-tuning the models and ignoring the training data. In this paper, we want to prove that there is also a strong correlation between training data and model robustness. To this end, we extract 13 different features representing a wide range of input... | Cuong Dang, Dung D. Le, Thai Le |  |
| 1786 |  |  [InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment](https://doi.org/10.18653/v1/2024.findings-acl.801) |  | 0 | Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders.... | Jianing Wang, Junda Wu, Yupeng Hou, Yao Liu, Ming Gao, Julian J. McAuley |  |
| 1787 |  |  [RaDA: Retrieval-augmented Web Agent Planning with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.802) |  | 0 | Agents powered by large language models (LLMs) inherit important limitations, such as the restricted context length, dependency on human-engineered exemplars (e.g., for task decomposition), and insufficient generalization. To address these challenges, we propose RaDA, a novel planning method for Web agents that does not require manual exemplars, efficiently leverages the LLMs’ context, and enhances generalization. RaDA disentangles planning into two stages: for a new given task, during... | Minsoo Kim, Victor S. Bursztyn, Eunyee Koh, Shunan Guo, Seungwon Hwang |  |
| 1788 |  |  [Competition-Level Problems are Effective LLM Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.803) |  | 0 | Large language models (LLMs) have demonstrated impressive reasoning capabilities, yet there is ongoing debate about these abilities and the potential data contamination problem recently. This paper aims to evaluate the reasoning capacities of LLMs, specifically in solving recent competition-level programming problems in Codeforces, which are expert-crafted and unique, requiring deep understanding and robust reasoning skills. We first provide a comprehensive evaluation of GPT-4’s perceived... | Yiming Huang, Zhenghao Lin, Xiao Liu, Yeyun Gong, Shuai Lu, Fangyu Lei, Yaobo Liang, Yelong Shen, Chen Lin, Nan Duan, Weizhu Chen |  |
| 1789 |  |  [Large Language Models for Automated Open-domain Scientific Hypotheses Discovery](https://doi.org/10.18653/v1/2024.findings-acl.804) |  | 0 | Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are carefully manually handpicked sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses are mostly commonsense knowledge, making the task less challenging. In this work, we... | Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, Erik Cambria |  |
| 1790 |  |  [GRADUAL: Granularity-aware Dual Prototype Learning for Better Few-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.805) |  | 0 | Recent studies have shown that fusing text labels and context sentences is an effective method for learning prototype representations in few-shot relation extraction. However, the \*\*inconsistency of prototype representations\*\* across different few-shot tasks persists due to different context sentences for the same relation, even with the integration of text labels into prototype representations. Conversely, the text label for each relation is unique and consistent, 1)which prompts us to... | Zhiming Li, Yuchen Lyu |  |
| 1791 |  |  [Training a Better Chinese Spelling Correction Model via Prior-knowledge Guided Teacher](https://doi.org/10.18653/v1/2024.findings-acl.806) |  | 0 | Recent advancements in Chinese Spelling Correction (CSC) predominantly leverage pre-trained language models (PLMs). However, a notable challenge with fine-tuned PLM-based CSC models is their tendency to over-correct, leading to poor generalization for error patterns outside the standard distribution. To address this, we developed a teacher network guided by prior knowledge for distillation learning of CSC models. Unlike traditional teacher networks, which depend on task-related pre-training,... | Chi Wei, Shaobin Huang, Rongsheng Li, Naiyu Yan, Rui Wang |  |
| 1792 |  |  [The Revolution of Multimodal Large Language Models: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.807) |  | 0 | Connecting text and visual modalities plays an essential role in generative intelligence. For this reason, inspired by the success of large language models, significant research efforts are being devoted to the development of Multimodal Large Language Models (MLLMs). These models can seamlessly integrate visual and textual modalities, while providing a dialogue-based interface and instruction-following capabilities. In this paper, we provide a comprehensive review of recent visual-based MLLMs,... | Davide Caffagni, Federico Cocchi, Luca Barsellotti, Nicholas Moratelli, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara |  |
| 1793 |  |  [OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.808) |  | 0 | Advancing automated programming necessitates robust and comprehensive code generation benchmarks, yet current evaluation frameworks largely neglect object-oriented programming (OOP) in favour of functional programming (FP), e.g., HumanEval and MBPP. To address this, our study introduces a pioneering OOP-focused benchmark, featuring 431 Python programs that encompass essential OOP concepts and features like classes and encapsulation methods. We propose a novel evaluation metric, pass@o, tailored... | Shuai Wang, Liang Ding, Li Shen, Yong Luo, Bo Du, Dacheng Tao |  |
| 1794 |  |  [Code Needs Comments: Enhancing Code LLMs with Comment Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.809) |  | 0 | The programming skill is one crucial ability for Large Language Models (LLMs), necessitating a deep understanding of programming languages (PLs) and their correlation with natural languages (NLs). We examine the impact of pre-training data on code-focused LLMs’ performance by assessing the comment density as a measure of PL-NL alignment. Given the scarcity of code-comment aligned data in pre-training corpora, we introduce a novel data augmentation method that generates comments for existing... | Demin Song, Honglin Guo, Yunhua Zhou, Shuhao Xing, Yudong Wang, Zifan Song, Wenwei Zhang, Qipeng Guo, Hang Yan, Xipeng Qiu, Dahua Lin |  |
| 1795 |  |  [Efficient Domain Adaptation for Non-Autoregressive Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.810) |  | 0 | Domain adaptation remains a challenge in the realm of Neural Machine Translation (NMT), even in the era of large language models (LLMs). Existing non-parametric approaches like nearest neighbor machine translation have made small Autoregressive Translation (AT) models achieve efficient domain generalization and adaptation without updating parameters, but leaving the Non-Autoregressive Translation (NAT) counterparts under-explored. To fill this blank, we introduce Bi-kNN, an innovative and... | Wangjie You, Pei Guo, Juntao Li, Kehai Chen, Min Zhang |  |
| 1796 |  |  [Exploring Reversal Mathematical Reasoning Ability for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.811) |  | 0 | Large language models (LLMs) have presented remarkable capabilities in the wide range of natural language understanding and reasoning tasks. Despite their success, a few works indicate that LLMs suffer from the “reversal curse”, in which LLMs can’t employ the inverted structure “B is A” when they are trained based on “A is B”. To explore the effect of the “reversal curse” for LLMs on complex mathematical reasoning tasks, we present two reversal datasets upon GSM8K and MathQA and verify that... | Pei Guo, Wangjie You, Juntao Li, Bowen Yan, Min Zhang |  |
| 1797 |  |  [A Unified Joint Approach with Topological Context Learning and Rule Augmentation for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.812) |  | 0 | Knowledge graph completion (KGC) task is to infer the missing knowledge in the knowledge graph based on known factual triples. However, present KGC approaches still face the following two challenges. Those methods perform simple linear update on relation representation, and only local neighborhood information is aggregated, which makes it difficult to capture logic semantic between relations and global topological context information. To tackle the above challenges, we propose a unified joint... | Jingtao Guo, Chunxia Zhang, Lingxi Li, Xiaojun Xue, Zhendong Niu |  |
| 1798 |  |  [FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.813) |  | 0 | Since most large language models (LLMs) are trained once and never updated, they struggle to dynamically adapt to our ever-changing world. In this work, we present FreshQA, a dynamic QA benchmark that tests a model’s ability to answer questions that may require reasoning over up-to-date world knowledge. We develop a two-mode human evaluation procedure to measure both correctness and hallucination, which we use to benchmark both closed and open-source LLMs by collecting >50K human judgments. We... | Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry W. Wei, Jason Wei, Chris Tar, YunHsuan Sung, Denny Zhou, Quoc V. Le, Thang Luong |  |
| 1799 |  |  [ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.814) |  | 0 | With the development of instruction-tuned large language models (LLMs), improving the safety of LLMs has become more critical. However, the current approaches for aligning the LLMs output with expected safety usually require substantial training efforts, e.g., high-quality safety data and expensive computational resources, which are costly and inefficient. To this end, we present reverse prompt contrastive decoding (ROSE), a simple-yet-effective method to directly boost the safety of existing... | Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao |  |
| 1800 |  |  [CR-LLM: A Dataset and Optimization for Concept Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.815) |  | 0 | Concept reasoning is an important capability for models to understand the world. However, the existing datasets, such as concept extraction and concept generation, suffer from modeledge leakage and context leakage. To address these limitations, we construct a dataset of concept reasoning for large language models (CR-LLM) with modeledge leakage prevention and context leakage prevention, which consists of 2,167 samples and covers different concept types. In addition, we propose a hybrid... | Nianqi Li, Jingping Liu, Sihang Jiang, Haiyun Jiang, Yanghua Xiao, Jiaqing Liang, Zujie Liang, Feng Wei, Jinglei Chen, Zhenghong Hao, Bing Han |  |
| 1801 |  |  [DATA-CUBE: Data Curriculum for Instruction-based Sentence Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.816) |  | 0 | Recently, multi-task instruction tuning has been utilized to improve sentence representation learning (SRL). It enables SRL models to generate task-specific representations with the guidance of task instruction, thus exhibiting strong generalization ability on unseen tasks. However, these methods mostly neglect the potential interference problems across different tasks and instances, which may affect the training of the model.To address this issue, we propose a data curriculum method, namely... | Yingqian Min, Kun Zhou, Dawei Gao, Xin Zhao, He Hu, Yaliang Li |  |
| 1802 |  |  [Combating Label Sparsity in Short Text Topic Modeling via Nearest Neighbor Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.817) |  | 0 | Extracting semantic topics from short texts presents a significant challenge in the field of data mining. While efforts have been made to mitigate data sparsity issue, the limited length of short documents also results in the absence of semantically relevant words, causing biased evidence lower bound and incomplete labels for likelihood maximization. We refer to this issue as the label sparsity problem. To combat this problem, we propose kNNTM, a neural short text topic model that incorporates... | Yang Lin, Xinyu Ma, Xin Gao, Ruiqing Li, Yasha Wang, Xu Chu |  |
| 1803 |  |  [RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.818) |  | 0 | The application scope of large language models (LLMs) is increasingly expanding. In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback. Whether the model can appropriately respond to users’ refuting feedback and consistently follow through with execution has not been thoroughly analyzed. In light of this, this paper proposes a comprehensive benchmark, RefuteBench, covering tasks such as... | Jianhao Yan, Yun Luo, Yue Zhang |  |
| 1804 |  |  [Complex Logical Query Answering by Calibrating Knowledge Graph Completion Models](https://doi.org/10.18653/v1/2024.findings-acl.819) |  | 0 | Complex logical query answering (CLQA) is a challenging task that involves finding answer entities for complex logical queries over incomplete knowledge graphs (KGs). Previous research has explored the use of pre-trained knowledge graph completion (KGC) models, which can predict the missing facts in KGs, to answer complex logical queries. However, KGC models are typically evaluated using ranking evaluation metrics, which may result in values of predictions of KGC models that are not... | Changyi Xiao, Yixin Cao |  |
| 1805 |  |  [Argument-Based Sentiment Analysis on Forward-Looking Statements](https://doi.org/10.18653/v1/2024.findings-acl.820) |  | 0 | This paper introduces a novel approach to analyzing the forward-looking statements in equity research reports by integrating argument mining with sentiment analysis. Recognizing the limitations of traditional models in capturing the nuances of future-oriented analysis, we propose a refined categorization of argument units into claims, premises, and scenarios, coupled with a unique sentiment analysis framework. Furthermore, we incorporate a temporal dimension to categorize the anticipated impact... | ChinYi Lin, ChungChi Chen, HenHsen Huang, HsinHsi Chen |  |
| 1806 |  |  [Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.821) |  | 0 | Large language models (LLMs) have showcased their remarkable capabilities to handle various downstream tasks, including multilingual machine translation ability. Despite their impressive performance, decoder-only LLMs lack an explicit alignment between source and target contexts, leading to translation that may not faithfully represent the original content. To address this, we propose three learning strategies to encourage LLMs to pay more attention to the source context during translation: 1)... | Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang |  |
| 1807 |  |  [Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion](https://doi.org/10.18653/v1/2024.findings-acl.822) |  | 0 | Block Diagrams play an essential role in visualizing the relationships between components or systems. Generating summaries of block diagrams is important for document understanding or question answering (QA) tasks by providing concise overviews of complex systems. However, it’s a challenging task as it requires compressing complex relationships into informative descriptions. In this paper, we present “BlockNet”, a fusion framework that summarizes block diagrams by integrating local and global... | Shreyanshu Bhushan, EunSoo Jung, Minho Lee |  |
| 1808 |  |  [MultiSQL: A Schema-Integrated Context-Dependent Text2SQL Dataset with Diverse SQL Operations](https://doi.org/10.18653/v1/2024.findings-acl.823) |  | 0 | Text2SQL is a task that translates natural language into SQL statements. Context-dependent Text2SQL offers a more natural database interaction by simulating dialogues between users and databases, with CoSQL and SparC as representative datasets. Yet, these datasets struggle to accurately replicate real-world situations. To address this, we introduce MultiSQL, which extends them in three key aspects: (1) Diverse SQL Operations. We incorporate diverse SQL types such as Create, Update, and Insert... | Chunhui Li, Yifan Wang, Zhen Wu, Zhen Yu, Fei Zhao, Shujian Huang, Xinyu Dai |  |
| 1809 |  |  [Towards Demonstration-Aware Large Language Models for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.824) |  | 0 | Tuning-based large language models for machine translation (aka large translation model, LTM) have demonstrated significant performance in the field of machine translation. Despite their success, these models often face difficulties in leveraging demonstrations to further improve their performance. To tackle this challenge, we introduce a novel approach that integrates demonstration-aware training and inference strategies within the framework of tuning-based LTMs, hereby referred to as... | Chen Li, Meishan Zhang, Xuebo Liu, Zhaocong Li, Derek F. Wong, Min Zhang |  |
| 1810 |  |  [DADA: Distribution-Aware Domain Adaptation of PLMs for Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.825) |  | 0 | Pre-trained language models (PLMs) exhibit promise in retrieval tasks but struggle with out-of-domain data due to distribution shifts.Addressing this, generative domain adaptation (DA), known as GPL, tackles distribution shifts by generating pseudo queries and labels to train models for predicting query-document relationships in new domains.However, it overlooks the domain distribution, causing the model to struggle with aligning the distribution in the target domain.We, therefore, propose a... | Dohyeon Lee, Jongyoon Kim, Seungwon Hwang, Joonsuk Park |  |
| 1811 |  |  [LLMs cannot find reasoning errors, but can correct them given the error location](https://doi.org/10.18653/v1/2024.findings-acl.826) |  | 0 | While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023b; Madaan et al.,2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang et al., 2023). In this paper, we show that poor self-correction performance stems from LLMs’ inability tofind logical mistakes, rather than their ability to correct a known mistake. Firstly, we... | Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter Chen, Tony Mak |  |
| 1812 |  |  [Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL translation](https://doi.org/10.18653/v1/2024.findings-acl.827) |  | 0 | Understanding textual description to generate code seems to be an achieved capability of instruction-following Large Language Models (LLMs) in zero-shot scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and the related code. This effect is known as Data Contamination.In this study, we investigate the impact of Data Contamination on the performance of GPT-3.5 in the Text-to-SQL code-generating tasks. Hence,... | Federico Ranaldi, Elena Sofia Ruzzetti, Dario Onorati, Leonardo Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli, Fabio Massimo Zanzotto |  |
| 1813 |  |  [ChartCheck: Explainable Fact-Checking over Real-World Chart Images](https://doi.org/10.18653/v1/2024.findings-acl.828) |  | 0 | Whilst fact verification has attracted substantial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key information, but they can also be easily misused to spread misinformation and promote certain agendas. In this paper, we introduce ChartCheck, a novel, large-scale dataset for explainable fact-checking against... | Mubashara Akhtar, Nikesh Subedi, Vivek Gupta, Sahar Tahmasebi, Oana Cocarascu, Elena Simperl |  |
| 1814 |  |  [Real World Conversational Entity Linking Requires More Than Zero-Shots](https://doi.org/10.18653/v1/2024.findings-acl.829) |  | 0 | Entity linking (EL) in conversations faces notable challenges in practical applications, primarily due to scarcity of entity-annotated conversational datasets and sparse knowledge bases (KB) containing domain-specific, long-tail entities. We designed targeted evaluation scenarios to measure the efficacy of EL models under resource constraints. Our evaluation employs two KBs: Fandom, exemplifying real-world EL complexities, and the widely used Wikipedia. First, we assess EL models’ ability to... | Mohanna Hoveyda, Arjen P. de Vries, Faegheh Hasibi, Maarten de Rijke |  |
| 1815 |  |  [CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling](https://doi.org/10.18653/v1/2024.findings-acl.830) |  | 0 | Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting knowledge, resulting in LLMs lacking professional consulting competence. Moreover, how to automatically evaluate multi-turn dialogues within the counseling process remains an understudied area. To bridge the... | Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei Zhu, Di Yang, Jiahao Zhao, Guancheng Ye, Chengming Li, Xiping Hu |  |
| 1816 |  |  [Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech](https://doi.org/10.18653/v1/2024.findings-acl.831) |  | 0 | Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide world knowledge and improve performance on standard metrics. Interestingly, our study presents conflicting evidence for the role of the quality of KG tuples in generating implicit explanations.... | Neemesh Yadav, Sarah Masud, Vikram Goyal, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 1817 |  |  [TextGenSHAP: Scalable Post-Hoc Explanations in Text Generation with Long Documents](https://doi.org/10.18653/v1/2024.findings-acl.832) |  | 0 | Large language models (LLMs) have attracted great interest in many real-world applications; however, their “black-box” nature necessitates scalable and faithful explanations. Shapley values have matured as an explainability method for deep learning, but extending them to LLMs is difficult due to long input contexts and autoregressive output generation. We introduce , an efficient post-hoc explanation method incorporating LLM-specific techniques, which leads to significant runtime improvements:... | James Enouen, Hootan Nakhost, Sayna Ebrahimi, Sercan Ö. Arik, Yan Liu, Tomas Pfister |  |
| 1818 |  |  [Balanced Data Sampling for Language Model Training with Clustering](https://doi.org/10.18653/v1/2024.findings-acl.833) |  | 0 | Data plays a fundamental role in the training of Large Language Models (LLMs). While attention has been paid to the collection and composition of datasets, determining the data sampling strategy in training remains an open question. Most LLMs are trained with a simple strategy, random sampling. However, this sampling strategy ignores the unbalanced nature of training data distribution, which can be sub-optimal. In this paper, we propose ClusterClip Sampling to balance the text distribution of... | Yunfan Shao, Linyang Li, Zhaoye Fei, Hang Yan, Dahua Lin, Xipeng Qiu |  |
| 1819 |  |  [Length Generalization of Causal Transformers without Position Encoding](https://doi.org/10.18653/v1/2024.findings-acl.834) |  | 0 | Generalizing to longer sentences is important for recent Transformer-based language models. Besides algorithms manipulating explicit position features, the success of Transformers without position encodings (NoPE) provides a new way to overcome the challenge. In this paper, we study the length generalization property of NoPE. We find that although NoPE can extend to longer sequences than the commonly used explicit position encodings, it still has a limited context length. We identify a... | Jie Wang, Tao Ji, Yuanbin Wu, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang, Xiaoling Wang |  |
| 1820 |  |  [Unsupervised Sign Language Translation and Generation](https://doi.org/10.18653/v1/2024.findings-acl.835) |  | 0 | Motivated by the success of unsupervised neural machine translation (UNMT), we introduce an unsupervised sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data. USLNet comprises two main components: single-modality reconstruction modules (text and video) that rebuild the input from its noisy version in the same modality and cross-modality back-translation modules (text-video-text and... | Zhengsheng Guo, Zhiwei He, Wenxiang Jiao, Xing Wang, Rui Wang, Kehai Chen, Zhaopeng Tu, Yong Xu, Min Zhang |  |
| 1821 |  |  [Mitigating Data Scarcity in Semantic Parsing across Languages with the Multilingual Semantic Layer and its Dataset](https://doi.org/10.18653/v1/2024.findings-acl.836) |  | 0 | Data scarcity is a prevalent challenge in the era of Large Language Models (LLMs). The insatiable hunger of LLMs for large corpora becomes even more pronounced when dealing with non-English and low-resource languages. The issue is particularly exacerbated in Semantic Parsing (SP), i.e. the task of converting text into a formal representation. The complexity of semantic formalisms makes training human annotators and subsequent data annotation unfeasible on a large scale, especially across... | Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Karim Ghonim, Lu Xu, HeeSoo Choi, Alberte FernándezCastro, Roberto Navigli |  |
| 1822 |  |  [Efficient Sparse Attention needs Adaptive Token Release](https://doi.org/10.18653/v1/2024.findings-acl.837) |  | 0 |  | Chaoran Zhang, Lixin Zou, Dan Luo, Xiangyang Luo, Zihao Li, Min Tang, Chenliang Li |  |
| 1823 |  |  [Learning Fine-Grained Grounded Citations for Attributed Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.838) |  | 0 | Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations. Attributed LLMs, which augment generated text with in-line citations, demonstrate potential in mitigating hallucinations and improving verifiability. However, current approaches suffer from suboptimal citation quality due to their reliance on in-context learning. Furthermore, the practice of merely citing document identifiers complicates the process for users to... | Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin |  |
| 1824 |  |  [ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget](https://doi.org/10.18653/v1/2024.findings-acl.839) |  | 0 | Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in a wide range of applications. In this paper, we propose ReLiK, a Retriever-Reader architecture for both EL and RE, where, given an input text, the Retriever module undertakes the identification of candidate entities or relations that could potentially appear within the text. Subsequently, the Reader module is tasked to discern the pertinent retrieved entities... | Riccardo Orlando, PereLluís Huguet Cabot, Edoardo Barba, Roberto Navigli |  |
| 1825 |  |  [Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery](https://doi.org/10.18653/v1/2024.findings-acl.840) |  | 0 | In Conversational Intent Discovery (CID), Small Language Models (SLMs) struggle with overfitting to familiar intents and fail to label newly discovered ones. This issue stems from their limited grasp of semantic nuances and their intrinsically discriminative framework. Therefore, we propose Synergizing Large Language Models (LLMs) with pre-trained SLMs for CID (SynCID). It harnesses the profound semantic comprehension of LLMs alongside the operational agility of SLMs. By utilizing LLMs to... | Jinggui Liang, Lizi Liao, Hao Fei, Jing Jiang |  |
| 1826 |  |  [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](https://doi.org/10.18653/v1/2024.findings-acl.841) |  | 0 | Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In response to this issue, various approaches for the evaluation of consistency for summarization have emerged. Yet, these newly-introduced metrics face several limitations, including lack of... | Alessandro Scirè, Karim Ghonim, Roberto Navigli |  |
| 1827 |  |  [Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.842) |  | 0 | Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy generates some low-probability text, resulting in low-quality reasoning paths. As a consequence, it requires a relatively large sampling number to obtain good aggregation performance. In this paper, we propose an alternative strategy, self-para-consistency. It first... | Wenqing Chen, Weicheng Wang, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu |  |
| 1828 |  |  [Looking Right is Sometimes Right: Investigating the Capabilities of Decoder-only LLMs for Sequence Labeling](https://doi.org/10.18653/v1/2024.findings-acl.843) |  | 0 | Pre-trained language models based on masked language modeling (MLM) excel in natural language understanding (NLU) tasks. While fine-tuned MLM-based encoders consistently outperform causal language modeling decoders of comparable size, recent decoder-only large language models (LLMs) perform on par with smaller MLM-based encoders. Although their performance improves with scale, LLMs fall short of achieving state-of-the-art results in information extraction (IE) tasks, many of which are... | David Dukic, Jan Snajder |  |
| 1829 |  |  [mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans](https://doi.org/10.18653/v1/2024.findings-acl.844) |  | 0 | It is very challenging to curate a dataset for language-specific knowledge and common sense in order to evaluate natural language understanding capabilities of language models. Due to the limitation in the availability of annotators, most current multilingual datasets are created through translation, which cannot evaluate such language-specific aspects. Therefore, we propose Multilingual CommonsenseQA (mCSQA) based on the construction process of CSQA but leveraging language models for a more... | Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |  |
| 1830 |  |  [Dual-Stage Multi-Task Syntax-Oriented Pre-Training for Syntactically Controlled Paraphrase Generation](https://doi.org/10.18653/v1/2024.findings-acl.845) |  | 0 | Syntactically Controlled Paraphrase Generation (SCPG), which aims at generating sentences having syntactic structures resembling given exemplars, is attracting more research efforts in recent years. We took an empirical survey on previous SCPG datasets and methods and found three tacitly approved while seldom mentioned intrinsic shortcomings/trade-offs in terms of data obtaining, task formulation, and pre-training strategies. As a mitigation to these shortcomings, we proposed a novel Dual-Stage... | Hongxu Liu, Xiaojie Wang, Jiashen Sun, Ke Zeng, Guanglu Wan |  |
| 1831 |  |  [Demonstration Augmentation for Zero-shot In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.846) |  | 0 | Large Language Models (LLMs) have demonstrated an impressive capability known as In-context Learning (ICL), which enables them to acquire knowledge from textual demonstrations without the need for parameter updates.However, many studies have highlighted that the model’s performance is sensitive to the choice of demonstrations, presenting a significant challenge for practical applications where we lack prior knowledge of user queries.Consequently, we need to construct an extensive demonstration... | Yi Su, Yunpeng Tai, Yixin Ji, Juntao Li, Yan Bowen, Min Zhang |  |
| 1832 |  |  [Pushing the Limits of Zero-shot End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.847) |  | 0 | Data scarcity and the modality gap between the speech and text modalities are two major obstacles of end-to-end Speech Translation (ST) systems, thus hindering their performance. Prior work has attempted to mitigate these challenges by leveraging external MT data and optimizing distance metrics that bring closer the speech-text representations. However, achieving competitive results typically requires some ST data. For this reason, we introduce ZeroSwot, a method for zero-shot ST that bridges... | Ioannis Tsiamas, Gerard I. Gállego, José A. R. Fonollosa, Marta R. Costajussà |  |
| 1833 |  |  [NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.848) |  | 0 | Numeral systems and units of measurement are two conjoined topics in activities of human beings and have mutual effects with the languages expressing them. Currently, the evaluation of Large Language Models (LLMs) often involves mathematical reasoning, yet little attention is given to how minor changes in numbers or units can drastically alter the complexity of problems and the performance of LLMs. In this paper, we scrutinize existing LLMs on processing of numerals and units of measurement by... | Ancheng Xu, Minghuan Tan, Lei Wang, Min Yang, Ruifeng Xu |  |
| 1834 |  |  [On The Persona-based Summarization of Domain-Specific Documents](https://doi.org/10.18653/v1/2024.findings-acl.849) |  | 0 | In an ever-expanding world of domain-specific knowledge, the increasing complexity of consuming, and storing information necessitates the generation of summaries from large information repositories. However, every persona of a domain has different requirements of information and hence their summarization. For example, in the healthcare domain, a persona-based (such as Doctor, Nurse, Patient etc.) approach is imperative to deliver targeted medical information efficiently. Persona-based... | Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku |  |
| 1835 |  |  [Evaluating Large Language Models for Health-related Queries with Presuppositions](https://doi.org/10.18653/v1/2024.findings-acl.850) |  | 0 | As corporations rush to integrate large language models (LLMs) it is critical that they provide factually accurate information, that is robust to any presuppositions that a user may express. In this work, we introduce UPHILL, a dataset consisting of health-related queries with varying degrees of presuppositions. Using UPHILL, we evaluate the factual accuracy and consistency of InstructGPT, ChatGPT, GPT-4 and Bing Copilot models. We find that while model responses rarely contradict true health... | Navreet Kaur, Monojit Choudhury, Danish Pruthi |  |
| 1836 |  |  [Word Sense Linking: Disambiguating Outside the Sandbox](https://doi.org/10.18653/v1/2024.findings-acl.851) |  | 0 | Word Sense Disambiguation (WSD) is the task of associating a word in a given context with its most suitable meaning among a set of possible candidates. While the task has recently witnessed renewed interest, with systems achieving performances above the estimated inter-annotator agreement, at the time of writing it still struggles to find downstream applications. We argue that one of the reasons behind this is the difficulty of applying WSD to plain text. Indeed, in the standard formulation,... | Andrei Stefan Bejgu, Edoardo Barba, Luigi Procopio, Alberte FernándezCastro, Roberto Navigli |  |
| 1837 |  |  [Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.852) |  | 0 | Memorisation is a natural part of learning from real-world data: neural models pick up on atypical input-output combinations and store those training examples in their parameter space. That this happens is well-known, but how and where are questions that remain largely unanswered. Given a multi-layered neural model, where does memorisation occur in the millions of parameters?Related work reports conflicting findings: a dominant hypothesis based on image classification is that lower layers learn... | Verna Dankers, Ivan Titov |  |
| 1838 |  |  [Towards Multi-Relational Multi-Hop Reasoning over Dense Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.853) |  | 0 | Temporal knowledge graph reasoning has emerged as a crucial task for answering time-dependent questions within a knowledge graph (KG).Despite tremendous progress, the present research is impeded by the sparsity of a temporal KG and an over-reliance on simple single-relational reasoning patterns. To overcome these challenges, we introduce MulQuestions, a new temporal KG reasoning benchmark featuring over 200k entities and 960k questions designed to facilitate complex, multi-relational and... | Jian Liu, Zihe Liu, Xueqiang Lyu, Peng Jin, Jinan Xu |  |
| 1839 |  |  [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.854) |  | 0 | Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs. Previous studies have mainly concentrated on post-processing techniques for hallucination detection, which tend to be computationally intensive and limited in effectiveness due to their separation from... | Weihang Su, Changyue Wang, Qingyao Ai, Yiran Hu, Zhijing Wu, Yujia Zhou, Yiqun Liu |  |
| 1840 |  |  [Progressive Tuning: Towards Generic Sentiment Abilities for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.855) |  | 0 | Understanding sentiment is arguably an advanced and important capability of AI agents in the physical world. In previous works, many efforts have been devoted to individual sentiment subtasks, without considering interrelated sentiment knowledge among these subtasks. Although some recent works model multiple sentiment subtasks in a unified manner, they merely simply combine these subtasks without deeply exploring the hierarchical relationships among subtasks. In this paper, we introduce GSA-7B,... | Guiyang Hou, Yongliang Shen, Weiming Lu |  |
| 1841 |  |  [Fooling the Textual Fooler via Randomizing Latent Representations](https://doi.org/10.18653/v1/2024.findings-acl.856) |  | 0 | Despite outstanding performance in a variety of Natural Language Processing (NLP) tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Several attacks can even compromise the model without requiring access to the model architecture or model parameters (i.e., a blackbox setting), and thus are detrimental to existing NLP applications. To perform these attacks, the adversary queries the victim... | Duy C. Hoang, Nguyen HungQuang, Saurav Manchanda, Minlong Peng, KokSeng Wong, Khoa D. Doan |  |
| 1842 |  |  [Part-of-speech Tagging for Extremely Low-resource Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.857) |  | 0 | Modern natural language processing (NLP) systems thrive when given access to large datasets. However, a large fraction of the world’s languages are not privy to such benefits due to sparse documentation and inadequate digital representation. This is especially true for Indian regional languages. As a first step towards expanding the reach of NLP technologies to extremely low-resource Indian languages, we present a new parallel part-of-speech (POS) evaluation dataset for Angika, Magahi, Bhojpuri... | Sanjeev Kumar, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 1843 |  |  [FOCUS: Forging Originality through Contrastive Use in Self-Plagiarism for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.858) |  | 0 | Pre-trained Language Models (PLMs) have shown impressive results in various Natural Language Generation (NLG) tasks, such as powering chatbots and generating stories. However, an ethical concern arises due to their potential to produce verbatim copies of paragraphs from their training data. This is problematic as PLMs are trained on corpora constructed by human authors. As such, there is a pressing need for research to promote the generation of original content by these models. In this study,... | Kaixin Lan, Tao Fang, Derek F. Wong, Yabo Xu, Lidia S. Chao, Cecilia G. Zhao |  |
| 1844 |  |  [Amanda: Adaptively Modality-Balanced Domain Adaptation for Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2024.findings-acl.859) |  | 0 | This paper investigates unsupervised multimodal domain adaptation for multimodal emotion recognition, which is a solution for data scarcity yet remains under studied. Due to the varying distribution discrepancies of different modalities between source and target domains, the primary challenge lies in how to balance the domain alignment across modalities to guarantee they are all well aligned. To achieve this, we first develop our model based on the information bottleneck theory to learn optimal... | Xinxin Zhang, Jun Sun, Simin Hong, Taihao Li |  |
| 1845 |  |  [MedREQAL: Examining Medical Knowledge Recall of Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.860) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated an impressive ability to encode knowledge during pre-training on large text corpora. They can leverage this knowledge for downstream tasks like question answering (QA), even in complex areas involving health topics. Considering their high potential for facilitating clinical work in the future, understanding the quality of encoded medical knowledge and its recall in LLMs is an important step forward. In this study, we examine the... | Juraj Vladika, Phillip Schneider, Florian Matthes |  |
| 1846 |  |  [Deepfake Defense: Constructing and Evaluating a Specialized Urdu Deepfake Audio Dataset](https://doi.org/10.18653/v1/2024.findings-acl.861) |  | 0 | Deepfakes, particularly in the auditory domain, have become a significant threat, necessitating the development of robust countermeasures. This paper addresses the escalating challenges posed by deepfake attacks on Automatic Speaker Verification (ASV) systems. We present a novel Urdu deepfake audio dataset for deepfake detection, focusing on two spoofing attacks – Tacotron and VITS TTS. The dataset construction involves careful consideration of phonemic cover and balance and comparison with... | Sheza Munir, Wassay Sajjad, Mukeet Raza, Emaan Abbas, Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza |  |
| 1847 |  |  [Leveraging Entailment Judgements in Cross-Lingual Summarisation](https://doi.org/10.18653/v1/2024.findings-acl.862) |  | 0 | Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to include document-summary pairs where the reference summary is unfaithful to the corresponding document as it contains content not supported by the document (i.e., hallucinated content). This low data quality misleads model learning and obscures evaluation results. Automatic ways to assess hallucinations and improve training have been proposed for monolingual summarisation, predominantly in English. For CLS, we propose... | Huajian Zhang, Laura PerezBeltrachini |  |
| 1848 |  |  [Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.863) |  | 0 | In the field of information extraction (IE), tasks across a wide range of modalities and their combinations have been traditionally studied in isolation, leaving a gap in deeply recognizing and analyzing cross-modal information. To address this, this work for the first time introduces the concept of grounded Multimodal Universal Information Extraction (MUIE), providing a unified task framework to analyze any IE tasks over various modalities, along with their fine-grained groundings. To tackle... | Meishan Zhang, Hao Fei, Bin Wang, Shengqiong Wu, Yixin Cao, Fei Li, Min Zhang |  |
| 1849 |  |  [Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data](https://doi.org/10.18653/v1/2024.findings-acl.864) |  | 0 | The remarkable multimodal capabilities demonstrated by OpenAI’s GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions.Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these... | Yanda Li, Chi Zhang, Gang Yu, Wanqi Yang, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei |  |
| 1850 |  |  [Modeling Overregularization in Children with Small Language Models](https://doi.org/10.18653/v1/2024.findings-acl.865) |  | 0 | The imitation of the children’s language acquisition process has been explored to make language models (LMs) more efficient.In particular, errors caused by children’s regularization (so-called overregularization, e.g., using wroted for the past tense of write) have been widely studied to reveal the mechanisms of language acquisition. Existing research has analyzed regularization in language acquisition only by modeling word inflection directly, which is unnatural in light of human language... | Akari Haga, Saku Sugawara, Akiyo Fukatsu, Miyu Oba, Hiroki Ouchi, Taro Watanabe, Yohei Oseki |  |
| 1851 |  |  [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.866) |  | 0 | Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as BERT-like architectures. In this paper, we specifically investigate the bottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by probing its hidden states at the end of each layer... | Zhu Liu, Cunliang Kong, Ying Liu, Maosong Sun |  |
| 1852 |  |  [Harnessing Large Language Models as Post-hoc Correctors](https://doi.org/10.18653/v1/2024.findings-acl.867) |  | 0 | As Machine Learning (ML) models grow in size and demand higher-quality training data, the expenses associated with re-training and fine-tuning these models are escalating rapidly. Inspired by recent impressive achievements of Large Language Models (LLMs) in different fields, this paper delves into the question: can LLMs efficiently improve an ML’s performance at a minimal cost? We show that, through our proposed training-free framework LLMCorr, an LLM can work as a post-hoc corrector to propose... | Zhiqiang Zhong, Kuangyu Zhou, Davide Mottin |  |
| 1853 |  |  [Debatrix: Multi-dimensional Debate Judge with Iterative Chronological Analysis Based on LLM](https://doi.org/10.18653/v1/2024.findings-acl.868) |  | 0 | How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments.At the same time, current research mainly focuses on short dialogues, rarely touching upon the evaluation of an entire debate.In this paper, by leveraging Large Language Models (LLMs), we propose Debatrix, which makes the analysis and assessment... | Jingcong Liang, Rong Ye, Meng Han, Ruofei Lai, Xinyu Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 1854 |  |  [CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment](https://doi.org/10.18653/v1/2024.findings-acl.869) |  | 0 | Language models trained on large-scale corpus often generate harmful responses that are harmful and contrary to human values. A prevalent approach for human alignment is reinforcement learning from human feedback (RLHF), utilizing algorithms such as proximal policy optimization (PPO). However, these methods are often characterized by complexity, instability, and substantial resource consumption. Considering that existing large language models (LLMs) like ChatGPT are already relatively... | Jixiang Hong, Quan Tu, Changyu Chen, Gao Xing, Ji Zhang, Rui Yan |  |
| 1855 |  |  [Towards a new research agenda for multimodal enterprise document understanding: What are we missing?](https://doi.org/10.18653/v1/2024.findings-acl.870) |  | 0 | The field of multimodal document understanding has produced a suite of models that have achieved stellar performance across several tasks, even coming close to human performance on certain benchmarks. Nevertheless, the application of these models to real-world enterprise datasets remains constrained by a number of limitations. In this position paper, we discuss these limitations in the context of three key aspects of research: dataset curation, model development, and evaluation on downstream... | Armineh Nourbakhsh, Sameena Shah, Carolyn P. Rosé |  |
| 1856 |  |  [CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.871) |  | 0 | An important unexplored aspect in previous work on user satisfaction estimation for Task-Oriented Dialogue (TOD) systems is their evaluation in terms of robustness for the identification of user dissatisfaction: current benchmarks for user satisfaction estimation in TOD systems are highly skewed towards dialogues for which the user is satisfied. The effect of having a more balanced set of satisfaction labels on performance is unknown. However, balancing the data with more dissatisfactory... | Amin Abolghasemi, Zhaochun Ren, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke, Suzan Verberne |  |
| 1857 |  |  [Measuring Retrieval Complexity in Question Answering Systems](https://doi.org/10.18653/v1/2024.findings-acl.872) |  | 0 | In this paper, we investigate which questions are challenging for retrieval-based Question Answering (QA). We (i) propose retrieval complexity (RC), a novel metric conditioned on the completeness of retrieved documents, which measures the difficulty of answering questions, and (ii) propose an unsupervised pipeline to measure RC given an arbitrary retrieval system.Our proposed pipeline measures RC more accurately than alternative estimators, including LLMs, on six challenging QA benchmarks.... | Matteo Gabburo, Nicolaas Paul Jedema, Siddhant Garg, Leonardo F. R. Ribeiro, Alessandro Moschitti |  |
| 1858 |  |  [Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media](https://doi.org/10.18653/v1/2024.findings-acl.873) |  | 0 | We introduce a hybrid abstractive summarisation approach combining hierarchical VAEs with LLMs to produce clinically meaningful summaries from social media user timelines, appropriate for mental health monitoring. The summaries combine two different narrative points of view: (a) clinical insights in third person, generated by feeding into an LLM clinical expert-guided prompts, and importantly, (b) a temporally sensitive abstractive summary of the user’s timeline in first person, generated by a... | Jiayu Song, Jenny Chim, Adam Tsakalidis, Julia Ive, Dana AtzilSlonim, Maria Liakata |  |
| 1859 |  |  [PIXAR: Auto-Regressive Language Modeling in Pixel Space](https://doi.org/10.18653/v1/2024.findings-acl.874) |  | 0 | Recent work showed the possibility of building open-vocabulary large language models (LLMs) that directly operate on pixel representations. These models are implemented as autoencoders that reconstruct masked patches of rendered text.However, these pixel-based LLMs are limited to discriminative tasks (e.g., classification) and, similar to BERT, cannot be used to generate text.Therefore, they cannot be used for generative tasks such as free-form question answering. In this work, we introduce... | Yintao Tai, Xiyang Liao, Alessandro Suglia, Antonio Vergari |  |
| 1860 |  |  [Sparsity-Accelerated Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.875) |  | 0 | Large language models (LLMs) have demonstrated proficiency across various natural language processing (NLP) tasks but often require additional training, such as continual pre-training and supervised fine-tuning. However, the costs associated with this, primarily due to their large parameter count, remain high. This paper proposes leveraging sparsity in pre-trained LLMs to expedite this training process. By observing sparsity in activated neurons during forward iterations, we identify the... | Da Ma, Lu Chen, Pengyu Wang, Hongshen Xu, Hanqi Li, Liangtai Sun, Su Zhu, Shuai Fan, Kai Yu |  |
| 1861 |  |  [Preemptive Answer "Attacks" on Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.876) |  | 0 | Large language models (LLMs) showcase impressive reasoning capabilities when coupled with Chain-of-Thought (CoT) prompting. However, the robustness of this approach warrants further investigation. In this paper, we introduce a novel scenario termed preemptive answers, where the LLM obtains an answer before engaging in reasoning. This situation can arise inadvertently or induced by malicious users by prompt injection attacks. Experiments reveal that preemptive answers significantly impair the... | Rongwu Xu, Zehan Qi, Wei Xu |  |
| 1862 |  |  [Do Language Models Exhibit Human-like Structural Priming Effects?](https://doi.org/10.18653/v1/2024.findings-acl.877) |  | 0 | We explore which linguistic factors—at the sentence and token level—play an important role in influencing language model predictions, and investigate whether these are reflective of results found in humans and human corpora (Gries and Kootstra, 2017). We make use of the structural priming paradigm—where recent exposure to a structure facilitates processing of the same structure—to investigate where priming effects manifest, and what factors predict them. We find these effects can be explained... | Jaap Jumelet, Willem H. Zuidema, Arabella Sinclair |  |
| 1863 |  |  [RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.878) |  | 0 | The advent of Large Language Models (LLMs) has paved the way for complex tasks such as role-playing, which enhances user interactions by enabling models to imitate various characters. However, the closed-source nature of state-of-the-art LLMs and their general-purpose training limit role-playing optimization. In this paper, we introduce RoleLLM, a framework to benchmark, elicit, and enhance role-playing abilities in LLMs. RoleLLM comprises four stages: (1) Role Profile Construction for 100... | Noah Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhao Huang, Jie Fu, Junran Peng |  |
| 1864 |  |  [LangSuit·E: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments](https://doi.org/10.18653/v1/2024.findings-acl.879) |  | 0 | Recent advances in Large Language Models (LLMs) have shown inspiring achievements in constructing autonomous agents that rely onlanguage descriptions as inputs. However, it remains unclear how well LLMs can function as few-shot or zero-shot embodied agents in dynamic interactive environments. To address this gap, we introduce LangSuit·E, a versatile and simulation-free testbed featuring 6 representative embodied tasks in textual embodied worlds. Compared with previous LLM-based testbeds,... | Zixia Jia, Mengmeng Wang, Baichen Tong, SongChun Zhu, Zilong Zheng |  |
| 1865 |  |  [Views Are My Own, but Also Yours: Benchmarking Theory of Mind Using Common Ground](https://doi.org/10.18653/v1/2024.findings-acl.880) |  | 0 | Evaluating the theory of mind (ToM) capabilities of language models (LMs) has recently received a great deal of attention. However, many existing benchmarks rely on synthetic data, which risks misaligning the resulting experiments with human behavior. We introduce the first ToM dataset based on naturally occurring spoken dialogs, Common-ToM, and show that LMs struggle to demonstrate ToM. We then show that integrating a simple, explicit representation of beliefs improves LM performance on... | Adil Soubki, John Murzaku, Arash Yousefi Jordehi, Peter Zeng, Magdalena Markowska, Seyed Abolghasem Mirroshandel, Owen Rambow |  |
| 1866 |  |  [MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.881) |  | 0 | Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more... | Divyanshu Aggarwal, Ashutosh Sathe, Ishaan Watts, Sunayana Sitaram |  |
| 1867 |  |  [MoE-SLU: Towards ASR-Robust Spoken Language Understanding via Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.882) |  | 0 | As a crucial task in the task-oriented dialogue systems, spoken language understanding (SLU) has garnered increasing attention. However, errors from automatic speech recognition (ASR) often hinder the performance of understanding. To tackle this problem, we propose MoE-SLU, an ASR-Robust SLU framework based on the mixture-of-experts technique. Specifically, we first introduce three strategies to generate additional transcripts from clean transcripts. Then, we employ the mixture-of-experts... | Xuxin Cheng, Zhihong Zhu, Xianwei Zhuang, Zhanpeng Chen, Zhiqi Huang, Yuexian Zou |  |
| 1868 |  |  [Multi-Task Transfer Matters During Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.883) |  | 0 | Instruction-tuning trains a language model on hundreds of tasks jointly to improve a model’s ability to learn in-context;however, the mechanisms that drive in-context learning are poorly understood and, as a result, the role of instruction-tuning on in-context generalization is poorly understood as well.In this work, we study the impact of instruction-tuning on multi-task transfer: how well a model’s parameters adapt to an unseen task via fine-tuning.We find that instruction-tuning negatively... | David Mueller, Mark Dredze, Nicholas Andrews |  |
| 1869 |  |  [What Makes a Good Order of Examples in In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.884) |  | 0 | Although large language models (LLMs) have demonstrated impressive few-shot learning capabilities via in-context learning (ICL), ICL performance is known to be highly sensitive to the order of examples provided. To identify appropriate orders, recent studies propose heuristic methods to evaluate order performance using a set of unlabeled data. However, the requirement of in-domain data limits their utility in real-world scenarios where additional annotated data is challenging to acquire.... | Qi Guo, Leiyu Wang, Yidong Wang, Wei Ye, Shikun Zhang |  |
| 1870 |  |  [BloomVQA: Assessing Hierarchical Multi-modal Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.885) |  | 0 | We propose a novel VQA dataset, BloomVQA, to facilitate comprehensive evaluation of large vision-language models on comprehension tasks. Unlike current benchmarks that often focus on fact-based memorization and simple reasoning tasks without theoretical grounding, we collect multiple-choice samples based on picture stories that reflect different levels of comprehension, as laid out in Bloom’s Taxonomy, a classic framework for learning assessment widely adopted in education research. Our data... | Yunye Gong, Robik Shrestha, Jared Claypoole, Michael Cogswell, Arijit Ray, Christopher Kanan, Ajay Divakaran |  |
| 1871 |  |  [AttributionBench: How Hard is Automatic Attribution Evaluation?](https://doi.org/10.18653/v1/2024.findings-acl.886) |  | 0 | Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence. However, evaluating the answer’s attribution, i.e., whether every claim within the generated responses is fully supported by its cited evidence, remains an open problem. This verification, traditionally dependent on costly human evaluation, underscores the urgent need for automatic attribution evaluation methods. To bridge the gap in the absence of standardized... | Yifei Li, Xiang Yue, Zeyi Liao, Huan Sun |  |
| 1872 |  |  [Diffusion Guided Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.887) |  | 0 | Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language—ideally tailored towards each specific use case and target audience. For auto-regressive language models, existing guidance methods are prone to decoding errors that cascade during generation and degrade performance. In contrast, text diffusion models can easily be guided with, for example,... | Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger |  |
| 1873 |  |  [InstructEd: Soft-Instruction Tuning for Model Editing with Hops](https://doi.org/10.18653/v1/2024.findings-acl.888) |  | 0 | The task of model editing becomes popular for correcting inaccurate or outdated parametric knowledge in Large Language Models (LLMs). However, there are major limitations of state of the art (SOTA) model editing methods, including the excessive memorization issue caused by the direct editing methods, as well as the error propagation and knowledge conflict issues from the memory enhancement methods, resulting in hindering models’ \*portability\*, e.g., the ability to transfer the new knowledge... | Xiaoqi Han, Ru Li, Xiaoli Li, Jiye Liang, Zifang Zhang, Jeff Z. Pan |  |
| 1874 |  |  [TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2024.findings-acl.889) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) leverages human preference data to train language models to align more closely with human essence. These human preference data, however, are labeled at the sequence level, creating a mismatch between sequence-level preference labels and tokens, which are autoregressively generated from the language model. Although several recent approaches have tried to provide token-level (i.e., dense) rewards for each individual token, these typically rely on... | Eunseop Yoon, Hee Suk Yoon, SooHwan Eom, Gunsoo Han, Daniel Wontae Nam, Daejin Jo, KyoungWoon On, Mark HasegawaJohnson, Sungwoong Kim, Chang Dong Yoo |  |
| 1875 |  |  [Found in the middle: Calibrating Positional Attention Bias Improves Long Context Utilization](https://doi.org/10.18653/v1/2024.findings-acl.890) |  | 0 | Large language models (LLMs), even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon has been known as the lost-in-the-middle problem. In this work, we make three contributions. First, we set out to understand the factors that cause this phenomenon. In doing so, we establish a connection between lost-in-the-middle to LLMs’ intrinsic attention bias: LLMs exhibit an U-shaped attention bias where... | ChengYu Hsieh, YungSung Chuang, ChunLiang Li, Zifeng Wang, Long T. Le, Abhishek Kumar, James R. Glass, Alexander Ratner, ChenYu Lee, Ranjay Krishna, Tomas Pfister |  |
| 1876 |  |  [S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.891) |  | 0 | Traditional Dialogue State Tracking (DST) has focused on tracking preferences and intents in conversations centered around specific tasks (e.g. booking services). These conventional systems assume a relatively restricted conversation flow in which each turn gradually offers new information. However, advancements in Large Language Models (LLMs) have ushered in more versatile open-domain chat systems in which extended dialogue sessions encompassing numerous tasks and topics are common—in turn... | Sarkar Snigdha Sarathi Das, Chirag Shah, Mengting Wan, Jennifer Neville, Longqi Yang, Reid Andersen, Georg Buscher, Tara Safavi |  |
| 1877 |  |  [Set the Clock: Temporal Alignment of Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.892) |  | 0 | Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call “temporal alignment.” To do this, we first automatically construct a dataset containing 20K time-sensitive questions and their answers for each year from 2000 to 2023. Based on this dataset, we... | Bowen Zhao, Zander Brumbaugh, Yizhong Wang, Hannaneh Hajishirzi, Noah A. Smith |  |
| 1878 |  |  [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.893) |  | 0 | To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it’s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation... | Beyza Ermis, Luiza Pozzobon, Sara Hooker, Patrick Lewis |  |
| 1879 |  |  [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](https://doi.org/10.18653/v1/2024.findings-acl.894) |  | 0 | The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can... | Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu |  |
| 1880 |  |  [Enhancing Sentence Simplification in Portuguese: Leveraging Paraphrases, Context, and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.895) |  | 0 | Automatic text simplification focuses on transforming texts into a more comprehensible version without sacrificing their precision. However, automatic methods usually require (paired) datasets that can be rather scarce in languages other than English. This paper presents a new approach to automatic sentence simplification that leverages paraphrases, context, and linguistic attributes to overcome the absence of paired texts in Portuguese.We frame the simplification problem as a textual style... | Arthur Scalercio, Maria José Finatto, Aline Paes |  |
| 1881 |  |  [How Far can 100 Samples Go? Unlocking Zero-Shot Translation with Tiny Multi-Parallel Data](https://doi.org/10.18653/v1/2024.findings-acl.896) |  | 0 | Zero-shot translation aims to translate between language pairs not seen during training in Multilingual Machine Translation (MMT) and is widely considered an open problem. A common, albeit resource-consuming, solution is to add as many related translation directions as possible to the training corpus. In this paper, we show that for an English-centric model, surprisingly large zero-shot improvements can be achieved by simply fine-tuning with a very small amount of multi-parallel data. For... | Di Wu, Shaomu Tan, Yan Meng, David Stap, Christof Monz |  |
| 1882 |  |  [Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study on Two Materials Dataset](https://doi.org/10.18653/v1/2024.findings-acl.897) |  | 0 | We explore the ability of GPT-4 to perform ad-hoc schema-based information extraction from scientific literature. We assess specifically whether it can, with a basic one-shot prompting approach over the full text of the included manusciprts, replicate two existing material science datasets, one pertaining to multi-principal element alloys (MPEAs), and one to silicate diffusion. We collaborate with materials scientists to perform a detailed manual error analysis to assess where and why the model... | Satanu Ghosh, Neal R. Brodnik, Carolina Frey, Collin Holgate, Tresa M. Pollock, Samantha H. Daly, Samuel Carton |  |
| 1883 |  |  [Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction](https://doi.org/10.18653/v1/2024.findings-acl.898) |  | 0 | Neural parameterization has significantly advanced unsupervised grammar induction. However, training these models with a traditional likelihood loss for all possible parses exacerbates two issues: 1) \*structural optimization ambiguity\* that arbitrarily selects one among structurally ambiguous optimal grammars despite the specific preference of gold parses, and 2) \*structural simplicity bias\* that leads a model to underutilize rules to compose parse trees. These challenges subject... | Jinwook Park, Kangil Kim |  |
| 1884 |  |  [LMDX: Language Model-based Document Information Extraction and Localization](https://doi.org/10.18653/v1/2024.findings-acl.899) |  | 0 | Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art and exhibiting emergent capabilities across various tasks. However, their application in extracting information from visually rich documents, which is at the core of many document processing workflows and involving the extraction of key entities from semi-structured documents, has not yet been successful. The main obstacles to adopting LLMs for this task include the absence of layout... | Vincent Perot, Kai Kang, Florian Luisier, Guolong Su, Xiaoyu Sun, Ramya Sree Boppana, Zilong Wang, Zifeng Wang, Jiaqi Mu, Hao Zhang, ChenYu Lee, Nan Hua |  |
| 1885 |  |  [DBQR-QA: A Question Answering Dataset on a Hybrid of Database Querying and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.900) |  | 0 | This paper introduces the Database Querying and Reasoning Dataset for Question Answering (DBQR-QA), aimed at addressing the gap in current question-answering (QA) research by emphasizing the essential processes of database querying and reasoning to answer questions. Specifically designed to accommodate sequential questions and multi-hop queries, DBQR-QA more accurately mirrors the dynamics of real-world information retrieval and analysis, with a particular focus on the financial reports of US... | Rungsiman Nararatwong, ChungChi Chen, Natthawut Kertkeidkachorn, Hiroya Takamura, Ryutaro Ichise |  |
| 1886 |  |  [NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.901) |  | 0 | We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat embodies the principle that an ensemble of role-specific LLMs, through structured role-play and strategic prompting, can perform their assigned roles more effectively. The synergy among these role-playing LLMs results in a cohesive and efficient dialogue generation. Evaluation on MTS-dialogue, a benchmark dataset for patient-physician... | Junda Wang, Zonghai Yao, Zhichao Yang, Huixue Zhou, Rumeng Li, Xun Wang, Yucheng Xu, Hong Yu |  |
| 1887 |  |  [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://doi.org/10.18653/v1/2024.findings-acl.902) |  | 0 | Editing knowledge in large language models is an attractive capability that allows us to correct incorrectly learned facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same... | Akshat Gupta, Anurag Rao, Gopala Anumanchipalli |  |
| 1888 |  |  [3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding](https://doi.org/10.18653/v1/2024.findings-acl.903) |  | 0 | This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse... | Yihao Ding, Lorenzo Vaiani, Soyeon Caren Han, Jean Lee, Paolo Garza, Josiah Poon, Luca Cagliero |  |
| 1889 |  |  [Faithful Persona-based Conversational Dataset Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.904) |  | 0 | High-quality conversational datasets are essential for developing AI models that can communicate with users.One way to foster deeper interactions between a chatbot and its user is through \*personas\*, aspects of the user’s character that provide insights into their personality, motivations, and behaviors.Training Natural Language Processing (NLP) models on a diverse and comprehensive persona-based dataset can lead to conversational models that create a deeper connection with the user, and... | Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, Hakim Sidahmed |  |
| 1890 |  |  [Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.905) |  | 0 | Despite vision-language models’ (VLMs) remarkable capabilities as versatile visual assistants, two substantial challenges persist within the existing VLM frameworks: (1) lacking task diversity in pretraining and visual instruction tuning, and (2) annotation error and bias in GPT-4 synthesized instruction tuning data. Both challenges lead to issues such as poor generalizability, hallucination, and catastrophic forgetting. To address these challenges, we construct Vision-Flan, the most diverse... | Zhiyang Xu, Chao Feng, Rulin Shao, Trevor Ashby, Ying Shen, Di Jin, Yu Cheng, Qifan Wang, Lifu Huang |  |
| 1891 |  |  [TAXI: Evaluating Categorical Knowledge Editing for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.906) |  | 0 | Humans rarely learn one fact in isolation. Instead, learning a new fact induces knowledge of other facts about the world. For example, in learning a korat is a type of cat, you also infer it is a mammal and has claws, ensuring your model of the world is consistent. Knowledge editing aims to inject new facts into language models to improve their factuality, but current benchmarks fail to evaluate consistency, which is critical to ensure efficient, accurate, and generalizable edits. We manually... | Derek Powell, Walter Gerych, Thomas Hartvigsen |  |
| 1892 |  |  [Automatic Bug Detection in LLM-Powered Text-Based Games Using LLMs](https://doi.org/10.18653/v1/2024.findings-acl.907) |  | 0 | Advancements in large language models (LLMs) are revolutionizing interactive game design, enabling dynamic plotlines and interactions between players and non-player characters (NPCs). However, LLMs may exhibit flaws such as hallucinations, forgetfulness, or misinterpretations of prompts, causing logical inconsistencies and unexpected deviations from intended designs. Automated techniques for detecting such game bugs are still lacking. To address this, we propose a systematic LLM-based method... | Claire Jin, Sudha Rao, Xiangyu Peng, Portia Botchway, Jessica Quaye, Chris Brockett, Bill Dolan |  |
| 1893 |  |  [Embodied Language Learning: Opportunities, Challenges, and Future Directions](https://doi.org/10.18653/v1/2024.findings-acl.908) |  | 0 | While large language and vision-language models showcase impressive capabilities, they face a notable limitation: the inability to connect language with the physical world. To bridge this gap, research has focused on embodied language learning, where the language learner is situated in the world, perceives it, and interacts with it. This article explores the current standing of research in embodied language learning, highlighting opportunities and discussing common challenges. Lastly, it... | Nadine Amin, Julia Rayz |  |
| 1894 |  |  [Challenges to Evaluating the Generalization of Coreference Resolution Models: A Measurement Modeling Perspective](https://doi.org/10.18653/v1/2024.findings-acl.909) |  | 0 | It is increasingly common to evaluate the same coreference resolution (CR) model on multiple datasets. Do these multi-dataset evaluations allow us to draw meaningful conclusions about model generalization? Or, do they rather reflect the idiosyncrasies of a particular experimental setup (e.g., the specific datasets used)? To study this, we view evaluation through the lens of measurement modeling, a framework commonly used in the social sciences for analyzing the validity of measurements. By... | Ian Porada, Alexandra Olteanu, Kaheer Suleman, Adam Trischler, Jackie Chi Kit Cheung |  |
| 1895 |  |  [SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events](https://doi.org/10.18653/v1/2024.findings-acl.910) |  | 0 | Interpreting and assessing goal driven actions is vital to understanding and reasoning over complex events. It is important to be able to acquire the knowledge needed for this understanding, though doing so is challenging. We argue that such knowledge can be elicited through a participant achievement lens. We analyze a complex event in a narrative according to the intended achievements of the participants in that narrative, the likely future actions of the participants, and the likelihood of... | Sai Vallurupalli, Katrin Erk, Francis Ferraro |  |
| 1896 |  |  [SLIDE: A Framework Integrating Small and Large Language Models for Open-Domain Dialogues Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.911) |  | 0 | The long-standing one-to-many problem of gold standard responses in open-domain dialogue systems presents challenges for automatic evaluation metrics. Though prior works have demonstrated some success by applying powerful Large Language Models (LLMs), existing approaches still struggle with the one-to-many problem, and exhibit subpar performance in domain-specific scenarios. We assume the commonsense reasoning biases within LLMs may hinder their performance in domain-specific evaluations. To... | Kun Zhao, Bohao Yang, Chen Tang, Chenghua Lin, Liang Zhan |  |
| 1897 |  |  [Deep Exploration of Cross-Lingual Zero-Shot Generalization in Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.912) |  | 0 | Instruction tuning has emerged as a powerful technique, significantly boosting zero-shot performance on unseen tasks. While recent work has explored cross-lingual generalization by applying instruction tuning to multilingual models, previous studies have primarily focused on English, with a limited exploration of non-English tasks. For in-depth exploration of cross-lingual generalization in instruction tuning, we perform instruction tuning individually for two distinct language meta-datasets.... | Janghoon Han, Changho Lee, Joongbo Shin, Stanley Jungkyu Choi, Honglak Lee, Kyunghoon Bae |  |
| 1898 |  |  [What Makes Language Models Good-enough?](https://doi.org/10.18653/v1/2024.findings-acl.913) |  | 0 | Psycholinguistic research suggests that humans may build a representation of linguistic input that is ‘good-enough’ for the task at hand. This study examines what architectural features make language models learn human-like good-enough language processing. We focus on the number of layers and self-attention heads in Transformers. We create a good-enough language processing (GELP) evaluation dataset (7,680 examples), which is designed to test the effects of two plausibility types, eight... | Daiki Asami, Saku Sugawara |  |
| 1899 |  |  [Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction](https://doi.org/10.18653/v1/2024.findings-acl.914) |  | 0 | Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality corpora, due to the labor-intensive labeling of spelling errors in real-life human writing or typing scenarios. Two data augmentation methods are widely adopted: (1) \*Random Replacement\* with the guidance of confusion sets and (2) \*OCR/ASR-based Generation\* that simulates character misusing. However, both methods inevitably introduce noisy data (e.g., false spelling errors), potentially leading to over-correction. By... | Dingyao Yu, Yang An, Wei Ye, Xiongfeng Xiao, Shaoguang Mao, Tao Ge, Shikun Zhang |  |
| 1900 |  |  [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples](https://doi.org/10.18653/v1/2024.findings-acl.915) |  | 0 | We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two critical under- explored problems: the neglect of physically grounded reasoning (counting and position understanding) and the potential of using highly capable text and image generation models for semantic counterfactual fine-tuning. Our work pioneers an approach in addressing these gaps.We... | Jianrui Zhang, Mu Cai, Tengyang Xie, Yong Jae Lee |  |
| 1901 |  |  [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.916) |  | 0 | Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation with LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model... | Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, May Dongmei Wang, Wei Jin, Joyce C. Ho, Carl Yang |  |
| 1902 |  |  [Textless Acoustic Model with Self-Supervised Distillation for Noise-Robust Expressive Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.917) |  | 0 | In this paper, we propose a textless acoustic model with a self-supervised distillation strategy for noise-robust expressive speech-to-speech translation (S2ST).Recently proposed expressive S2ST systems have achieved impressive expressivity preservation performances by cascading unit-to-speech (U2S) generator to the speech-to-unit translation model. However, these systems are vulnerable to the presence of noise in input speech, which is an assumption in real-world translation scenarios. To... | MinJae Hwang, Ilia Kulikov, Benjamin N. Peloquin, Hongyu Gong, PengJen Chen, Ann Lee |  |
| 1903 |  |  [Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.918) |  | 0 | The integration of generative Large Language Models (LLMs) into various applications, including the legal domain, has been accelerated by their expansive and versatile nature. However, when facing a legal case, users without a legal background often struggle to formulate professional queries and may inadvertently overlook critical legal factors when presenting their case narrative to LLMs. To address this issue, we propose the Diagnostic Legal Large Language Model (D3LM), which utilizes... | Yang Wu, Chenghao Wang, Ece Gumusel, Xiaozhong Liu |  |
| 1904 |  |  [TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.919) |  | 0 | The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent reasoning processes, poor generalization abilities and inherent risks of integration with large language models (LLMs). To address this challenge, we propose TELLER, a novel framework for trustworthy fake... | Hui Liu, Wenya Wang, Haoru Li, Haoliang Li |  |
| 1905 |  |  [Verifiable Generation with Subsentence-Level Fine-Grained Citations](https://doi.org/10.18653/v1/2024.findings-acl.920) |  | 0 | Verifiable generation requires large language models (LLMs) to cite source documents supporting their outputs, thereby improve output transparency and trustworthiness. Yet, previous work mainly targets the generation of sentence-level citations, lacking specificity about which parts of a sentence are backed by the cited sources. This work studies verifiable generation with subsentence-level fine-grained citations for more precise location of generated content supported by the cited sources. We... | Shuyang Cao, Lu Wang |  |
| 1906 |  |  [Tailoring with Targeted Precision: Edit-Based Agents for Open-Domain Procedure Customization](https://doi.org/10.18653/v1/2024.findings-acl.921) |  | 0 | How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user’s specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM’s ability to perform such customization. Our approach is to test several simple multi-LLM-agent architectures for customization, as well as an end-to-end LLM, using a new evaluation set, called CustomPlans, of over 200 WikiHow procedures each with a customization... | Yash Kumar Lal, Li Zhang, Faeze Brahman, Bodhisattwa Prasad Majumder, Peter Clark, Niket Tandon |  |
| 1907 |  |  [A Meta-Learning Perspective on Transformers for Causal Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.922) |  | 0 | The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process that may happen within the Transformer. Further, from within the inner optimization, we discover and theoretically analyze a... | Xinbo Wu, Lav R. Varshney |  |
| 1908 |  |  [PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs](https://doi.org/10.18653/v1/2024.findings-acl.923) |  | 0 | Large Language Models (LLMs) have exhibited impressive capabilities in various tasks, yet their vast parameter sizes restrict their applicability in resource-constrained settings. Knowledge distillation (KD) offers a viable solution by transferring expertise from large teacher models to compact student models. However, traditional KD techniques face specific challenges when applied to LLMs, including restricted access to LLM outputs, significant teacher-student capacity gaps, and the inherited... | Rongzhi Zhang, Jiaming Shen, Tianqi Liu, Haorui Wang, Zhen Qin, Feng Han, Jialu Liu, Simon Baumgartner, Michael Bendersky, Chao Zhang |  |
| 1909 |  |  [Small Language Models Need Strong Verifiers to Self-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.924) |  | 0 | Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether small (≤ 13B) language models (LMs) have the ability of self-correction on reasoning tasks with minimal inputs from stronger LMs. We propose a novel pipeline that prompts smaller LMs to collect self-correction data that supports the training of self-refinement... | Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang |  |
| 1910 |  |  [Hire a Linguist!: Learning Endangered Languages in LLMs with In-Context Linguistic Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.925) |  | 0 | How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large corpus, have a grammar book or a dictionary. We propose LingoLLM, a training-free approach to enable an LLM to process unseen languages that hardly occur in its pre-training. Our key insight is to... | Kexun Zhang, Yee Man Choi, Zhenqiao Song, Taiqi He, William Yang Wang, Lei Li |  |
| 1911 |  |  [From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation](https://doi.org/10.18653/v1/2024.findings-acl.926) |  | 0 | We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end-users are not fully proficient, such as language learners. Using a novel framework, we evaluate the effectiveness of several key approaches for this task, including few-shot prompting, supervised finetuning, and reinforcement learning (RL), utilising both GPT-4 and open source alternatives like LLama2-7B and Mistral-7B.Our findings reveal a large performance gap... | Ali Malik, Stephen Mayhew, Christopher Piech, Klinton Bicknell |  |
| 1912 |  |  [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://doi.org/10.18653/v1/2024.findings-acl.927) |  | 0 | Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations.Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained... | Khaoula Chehbouni, Megha Roshan, Emmanuel Ma, Futian Andrew Wei, Afaf Taïk, Jackie Chi Kit Cheung, Golnoosh Farnadi |  |
| 1913 |  |  [CToolEval: A Chinese Benchmark for LLM-Powered Agent Evaluation in Real-World API Interactions](https://doi.org/10.18653/v1/2024.findings-acl.928) |  | 0 | Assessing the capabilities of large language models (LLMs) as agents in decision making and operational tasks is crucial for the development of LLM-as-agent service. We propose CToolEval, a benchmark designed to evaluate LLMs in the context of Chinese societal applications, featuring 398 APIs across 27 widely-used Apps (e.g., Apps for shopping, map, music, travel, etc.) that cover 14 domains. We further present an evaluation framework that simulates real-life scenarios, to facilitate the... | Zishan Guo, Yufei Huang, Deyi Xiong |  |
| 1914 |  |  [Token Alignment via Character Matching for Subword Completion](https://doi.org/10.18653/v1/2024.findings-acl.929) |  | 0 | Generative models, widely utilized in various applications, can often struggle with prompts corresponding to partial tokens. This struggle stems from tokenization, where partial tokens fall out of distribution during inference, leading to incorrect or nonsensical outputs. This paper examines a technique to alleviate the tokenization artifact on text completion in generative models, maintaining performance even in regular non-subword cases. The method, termed token alignment, involves... | Ben Athiwaratkun, Shiqi Wang, Mingyue Shang, Yuchen Tian, Zijian Wang, Sujan Kumar Gonugondla, Sanjay Krishna Gouda, Robert Kwiatkowski, Ramesh Nallapati, Parminder Bhatia, Bing Xiang |  |
| 1915 |  |  [Rethinking Efficient Multilingual Text Summarization Meta-Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.930) |  | 0 | Evaluating multilingual summarization evaluation metrics, i.e., meta-evaluation, is challenging because of the difficulty of human annotation collection. Therefore, we investigate an efficient multilingual meta-evaluation framework that uses machine translation systems to transform a monolingual meta-evaluation dataset into multilingual versions. To this end, we introduce a statistical test to verify the transformed dataset quality by checking the meta-evaluation result consistency on the... | Rilyn Han, Jiawen Chen, Yixin Liu, Arman Cohan |  |
| 1916 |  |  [emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation](https://doi.org/10.18653/v1/2024.findings-acl.931) |  | 0 | We propose emotion2vec, a universal speech emotion representation model. emotion2vec is pre-trained on open-source unlabeled emotion data through self-supervised online distillation, combining utterance-level loss and frame-level loss during pre-training. emotion2vec outperforms state-of-the-art pre-trained universal models and emotion specialist models by only training linear layers for the speech emotion recognition task on the mainstream IEMOCAP dataset. In addition, emotion2vec shows... | Ziyang Ma, Zhisheng Zheng, Jiaxin Ye, Jinchao Li, Zhifu Gao, Shiliang Zhang, Xie Chen |  |
| 1917 |  |  [Language-Informed Beam Search Decoding for Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.932) |  | 0 | Beam search decoding is the de-facto method for decoding auto-regressive Neural Machine Translation (NMT) models, including multilingual NMT where the target language is specified as an input. However, decoding multilingual NMT models commonly produces off-target translations – yielding translation outputs not in the intended language.In this paper, we first conduct an error analysis of off-target translations for a strong multilingual NMT model and identify how these decodings are produced... | Yilin Yang, Stefan Lee, Prasad Tadepalli |  |
| 1918 |  |  [RA-LoRA: Rank-Adaptive Parameter-Efficient Fine-Tuning for Accurate 2-bit Quantized Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.933) |  | 0 | Deploying large language models (LLMs) with their extensive parameters and high memory demands challenges computational efficiency, particularly in fine-tuning for specific applications with limited resources. Techniques like Low-Rank Adaptation (LoRA) help by training a smaller, modifiable extension of the base model to reduce memory usage. However, combining quantization with LoRA, especially in low-bit scenarios, can lead to performance losses due to quantization errors. Our innovative... | Minsoo Kim, Sihwa Lee, Wonyong Sung, Jungwook Choi |  |
| 1919 |  |  [The PGNSC Benchmark: How Do We Predict Where Information Spreads?](https://doi.org/10.18653/v1/2024.findings-acl.934) |  | 0 | Social networks have become ideal vehicles for news dissemination because posted content is easily able to reach users beyond a news outlet’s direct audience. Understanding how information is transmitted among communities of users is a critical step towards understanding the impact social networks have on real-world events. Two significant barriers in this vein of work are identifying user clusters and meaningfully characterizing these communities. Thus, we propose the PGNSC benchmark, which... | Alexander Taylor, Wei Wang |  |
| 1920 |  |  [STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.935) |  | 0 | Interactive fiction games have emerged as an important application to improve the generalization capabilities of language-based reinforcement learning (RL) agents. Existing environments for interactive fiction games are domain-specific or time-consuming to generate and do not train the RL agents to master a specific set of skills. In this work, we introduce an interactive environment for self-supervised RL, STARLING, for text-based games that bootstraps the text-based RL agents with... | Shreyas Basavatia, Keerthiram Murugesan, Shivam Ratnakar |  |
| 1921 |  |  [Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.936) |  | 0 |  | Dohyun Lee, Daniel Rim, Minseok Choi, Jaegul Choo |  |
| 1922 |  |  [Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.937) |  | 0 | Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs. However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text inaccurately represents the visual contents. To address this issue, this paper introduces the Instruction Contrastive Decoding (ICD) method, a novel approach designed to reduce hallucinations during LVLM... | Xintong Wang, Jingheng Pan, Liang Ding, Chris Biemann |  |
| 1923 |  |  [Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs](https://doi.org/10.18653/v1/2024.findings-acl.938) |  | 0 | Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs. In this study, we view partial code as implementation hints and fine-tune CodeLLMs to jointly rewrite and complete partial code into functional full programs. We explore two strategies: one-pass generation and multi-pass iterative refinement. We construct new... | Dingmin Wang, Jinman Zhao, Hengzhi Pei, Samson Tan, Sheng Zha |  |
| 1924 |  |  [A Critical Study of What Code-LLMs (Do Not) Learn](https://doi.org/10.18653/v1/2024.findings-acl.939) |  | 0 | Large Language Models trained on code corpora (code-LLMs) have demonstrated impressive performance in various coding assistance tasks. However, despite their increased size and training dataset, code-LLMs still have limitations such as suggesting codes with syntactic errors, variable misuse etc. Some studies argue that code-LLMs perform well on coding tasks because they use self-attention and hidden representations to encode relations among input tokens. However, previous works have not studied... | Abhinav Anand, Shweta Verma, Krishna Narasimhan, Mira Mezini |  |
| 1925 |  |  [Visual In-Context Learning for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.940) |  | 0 | In Large Visual Language Models (LVLMs), the efficacy of In-Context Learning (ICL) remains limited by challenges in cross-modal interactions and representation disparities. To overcome these challenges, we introduce a novel Visual In-Context Learning (VICL) method comprising Visual Demonstration Retrieval, Intent-Oriented Image Summarization, and Intent-Oriented Demonstration Composition. Our approach retrieves images via ”Retrieval & Rerank” paradigm, summarises images with task intent and... | Yucheng Zhou, Xiang Li, Qianning Wang, Jianbing Shen |  |
| 1926 |  |  [SCALE: Synergized Collaboration of Asymmetric Language Translation Engines](https://doi.org/10.18653/v1/2024.findings-acl.941) |  | 0 | In this paper, we introduce SCALE, a collaborative framework that connects a compact Specialized Translation Model (STM) and a general-purpose Large Language Model (LLM) as one unified translation engine. By introducing translation from STM into the triplet in-context demonstrations, SCALE unlocks refinement and pivoting ability of LLM, thus 1) mitigating language bias of LLMs and parallel data bias of STMs, 2) enhancing LLM speciality without sacrificing generality, and 3) facilitating... | Xin Cheng, Xun Wang, Tao Ge, SiQing Chen, Furu Wei, Dongyan Zhao, Rui Yan |  |
| 1927 |  |  [No perspective, no perception!! Perspective-aware Healthcare Answer Summarization](https://doi.org/10.18653/v1/2024.findings-acl.942) |  | 0 | Healthcare Community Question Answering (CQA) forums offer an accessible platform for individuals seeking information on various healthcare-related topics. People find such platforms suitable for self-disclosure, seeking medical opinions, finding simplified explanations for their medical conditions, and answering others’ questions. However, answers on these forums are typically diverse and prone to off-topic discussions. It can be challenging for readers to sift through numerous answers and... | Gauri Naik, Sharad Chandakacherla, Shweta Yadav, Md. Shad Akhtar |  |
| 1928 |  |  [Retrieval-Augmented Retrieval: Large Language Models are Strong Zero-Shot Retriever](https://doi.org/10.18653/v1/2024.findings-acl.943) |  | 0 | We propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Large language model as Retriever (LameR), is built upon no other neural models but an LLM in a retrieval-augmented retrieval fashion, while breaking brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers... | Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Yibin Lei, Tianyi Zhou, Michael Blumenstein, Daxin Jiang |  |
| 1929 |  |  [A Survey on Predicting the Factuality and the Bias of News Media](https://doi.org/10.18653/v1/2024.findings-acl.944) |  | 0 | The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim or article, either manually or automatically. An increasing number of scholars are focusing on a coarser granularity, aiming to profile entire news outlets, which allows fast identification of potential “fake news” by checking the reliability of their source. Source factuality is also an important element of systems for automatic fact-checking... | Preslav Nakov, Jisun An, Haewoon Kwak, Muhammad Arslan Manzoor, Zain Muhammad Mujahid, Husrev T. Sencar |  |
| 1930 |  |  [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://doi.org/10.18653/v1/2024.findings-acl.945) |  | 0 | Wavelet transforms, a powerful mathematical tool, have been widely used in different domains, including Signal and Image processing, to unravel intricate patterns, enhance data representation, and extract meaningful features from data. Tangible results from their application suggest that Wavelet transforms can be applied to NLP capturing a variety of linguistic and semantic properties.In this paper, we empirically leverage the application of Discrete Wavelet Transforms (DWT) to word and... | Rana Aref Salama, Abdou Youssef, Mona T. Diab |  |
| 1931 |  |  [Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.946) |  | 0 | Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural language processing, with numerous approaches aiming to answer First-Order Logic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g., beta distribution)-based methodologies have effectively addressed complex FOL queries. However, a common challenge across these methods lies in determining accurate geometric bounds or probability parameters for these queries. The challenge arises because existing... | Jeonghoon Kim, Heesoo Jung, Hyeju Jang, Hogun Park |  |
| 1932 |  |  [ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.947) |  | 0 | Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient strategy to harness LLMs with modest NER capabilities for producing superior NER datasets. Our approach diverges from the basic class-conditional prompts by instructing LLMs to self-reflect on the specific domain, thereby generating domain-relevant... | Yuzhao Heng, Chunyuan Deng, Yitong Li, Yue Yu, Yinghao Li, Rongzhi Zhang, Chao Zhang |  |
| 1933 |  |  [Defending LLMs against Jailbreaking Attacks via Backtranslation](https://doi.org/10.18653/v1/2024.findings-acl.948) |  | 0 | Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by “backtranslation”. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the... | Yihan Wang, Zhouxing Shi, Andrew Bai, ChoJui Hsieh |  |
| 1934 |  |  [A Large Collection of Model-generated Contradictory Responses for Consistency-aware Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.949) |  | 0 | Mitigating the generation of contradictory responses poses a substantial challenge in dialogue response generation. The quality and quantity of available contradictory response data play a vital role in suppressing these contradictions, offering two significant benefits. First, having access to large contradiction data enables a comprehensive examination of their characteristics. Second, data-driven methods to mitigate contradictions may be enhanced with large-scale contradiction data for... | Shiki Sato, Reina Akama, Jun Suzuki, Kentaro Inui |  |
| 1935 |  |  [Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset](https://doi.org/10.18653/v1/2024.findings-acl.950) |  | 0 | This paper explores the question of how accurately current large language models can perform logical reasoning in natural language, with an emphasis on whether these models exhibit reasoning biases similar to humans. Specifically, our study focuses on syllogistic reasoning, a form of deductive reasoning extensively studied in cognitive science as a natural form of human reasoning. We present a syllogism dataset called NeuBAROCO, which consists of syllogistic reasoning problems in English and... | Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada |  |
| 1936 |  |  [Unveiling the Spectrum of Data Contamination in Language Model: A Survey from Detection to Remediation](https://doi.org/10.18653/v1/2024.findings-acl.951) |  | 0 | Data contamination has garnered increased attention in the era of Large language models (LLMs) due to the reliance on extensive internet-derived training corpora. The issue of training corpus overlap with evaluation benchmarks—referred to as contamination—has been the focus of significant recent research. This body of work aims to identify contamination, understand its impacts, and explore mitigation strategies from diverse perspectives. However, comprehensive studies that provide a clear... | Chunyuan Deng, Yilun Zhao, Yuzhao Heng, Yitong Li, Jiannan Cao, Xiangru Tang, Arman Cohan |  |
| 1937 |  |  [DIMSIM: Distilled Multilingual Critics for Indic Text Simplification](https://doi.org/10.18653/v1/2024.findings-acl.952) |  | 0 | Self-correction techniques have recently emerged as a promising framework to improve the quality of responses generated by large language models (LLMs). Few-shot prompted LLMs act as critics to produce feedback for an input, which is further fed to a refiner (also an LLM) to produce an output. However, these critique-refine steps require multiple expensive LLM calls. To circumvent this large inference cost, we borrow inspiration from prior work on knowledge distillation and propose the use of... | Sneha Mondal, Ritika, Ashish Agrawal, Preethi Jyothi, Aravindan Raghuveer |  |
| 1938 |  |  [MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources](https://doi.org/10.18653/v1/2024.findings-acl.953) |  | 0 | Leveraging external knowledge is crucial for achieving high performance in knowledge-intensive tasks, such as question answering. The retrieve-and-read approach is widely adopted for integrating external knowledge into a language model. However, this approach suffers from increased computational cost and latency due to the long context length, which grows proportionally with the number of retrieved knowledge. Furthermore, existing retrieval-augmented models typically retrieve information from a... | Dongkyu Lee, Chandana Satya Prakash, Jack FitzGerald, Jens Lehmann |  |
| 1939 |  |  [Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.954) |  | 0 | Social bias is shaped by the accumulation of social perceptions towards targets across various demographic identities. To fully understand such social bias in large language models (LLMs), it is essential to consider the composite of social perceptions from diverse perspectives among identities. Previous studies have either evaluated biases in LLMs by indirectly assessing the presence of sentiments towards demographic identities in the generated text or measuring the degree of alignment with... | Jisu Shin, Hoyun Song, Huije Lee, Soyeong Jeong, Jong Park |  |
| 1940 |  |  [Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.findings-acl.955) |  | 0 | Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has emerged. However, the existing LLM-based model exhibits three shortcomings: (1) It only focuses on the first-order history for prediction while ignoring high-order historical information, resulting in... | Yuwei Xia, Ding Wang, Qiang Liu, Liang Wang, Shu Wu, Xiaoyu Zhang |  |
| 1941 |  |  [Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements](https://doi.org/10.18653/v1/2024.findings-acl.956) |  | 0 | Making LLMs speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. However, existing LLMs lack sufficient controllability to the stance of their generated content, which often contains inconsistent, neutral, or biased statements. In this paper, we improve the controllability of LLMs in generating statements supporting an argument the user defined in the... | Ming Li, Jiuhai Chen, Lichang Chen, Tianyi Zhou |  |
| 1942 |  |  [Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.findings-acl.957) |  | 0 | Detecting implicit hate speech that is not directly hateful remains a challenge. Recent research has attempted to detect implicit hate speech by applying contrastive learning to pre-trained language models such as BERT and RoBERTa, but the proposed models still do not have a significant advantage over cross-entropy loss-based learning. We found that contrastive learning based on randomly sampled batch data does not encourage the model to learn hard negative samples. In this work, we propose... | Jaehoon Kim, Seungwan Jin, Sohyun Park, Someen Park, Kyungsik Han |  |
| 1943 |  |  [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.958) |  | 0 | Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned. This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM’s reflection and introspection for improving existing... | Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, Tianyi Zhou |  |
| 1944 |  |  [Selective Prompting Tuning for Personalized Conversations with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.959) |  | 0 | In conversational AI, personalizing dialogues with persona profiles and contextual understanding is essential. Despite large language models’ (LLMs) improved response coherence, effective persona integration remains a challenge. In this work, we first study two common approaches for personalizing LLMs: textual prompting and direct fine-tuning. We observed that textual prompting often struggles to yield responses that are similar to the ground truths in datasets, while direct fine-tuning tends... | Qiushi Huang, Xubo Liu, Tom Ko, Bo Wu, Wenwu Wang, Yu Zhang, Lilian Tang |  |
| 1945 |  |  [Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models](https://doi.org/10.18653/v1/2024.findings-acl.960) |  | 0 | In the rapidly advancing field of artificial intelligence, the concept of ‘Red-Teaming’ or ‘Jailbreaking’ large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This paper investigates the intricate consequences of such modifications through model editing, uncovering a complex relationship between enhancing model accuracy and preserving its ethical integrity. Our... | Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria |  |
| 1946 |  |  [ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.961) |  | 0 | Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text. Despite the success of VLMs, they still significantly lag behind human performance in IRCD. The main challenges lie in aligning key contextual cues in two modalities, where these subtle cues are concealed in tiny areas of multiple contrastive images and within the complex linguistics of textual descriptions. This motivates us to... | Honglin Lin, Siyu Li, Guoshun Nan, Chaoyue Tang, Xueting Wang, Jingxin Xu, Yankai Rong, Zhouzhili Zhouzhili, Yutong Gao, Qimei Cui, Xiaofeng Tao |  |
| 1947 |  |  [PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns](https://doi.org/10.18653/v1/2024.findings-acl.962) |  | 0 | Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities. However, it is not clear how they can emulate the general intelligence and reasoning ability of humans. As recognizing patterns and abstracting concepts are key to general intelligence, we introduce PuzzleVQA, a collection of 2000 puzzle instances based on abstract patterns. With this dataset, we evaluate large multimodal models with abstract patterns based on... | Yew Ken Chia, Vernon Toh, Deepanway Ghosal, Lidong Bing, Soujanya Poria |  |
| 1948 |  |  [How Do Moral Emotions Shape Political Participation? A Cross-Cultural Analysis of Online Petitions Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.963) |  | 0 | Understanding the interplay between emotions in language and user behaviors is critical. We study how moral emotions shape the political participation of users based on cross-cultural online petition data. To quantify moral emotions, we employ a context-aware NLP model that is designed to capture the subtle nuances of emotions across cultures. For model training, we construct and share a moral emotion dataset comprising nearly 50,000 petition sentences in Korean and English each, along with... | Jaehong Kim, Chaeyoon Jeong, Seongchan Park, Meeyoung Cha, Wonjae Lee |  |
| 1949 |  |  [VillagerAgent: A Graph-Based Multi-Agent Framework for Coordinating Complex Task Dependencies in Minecraft](https://doi.org/10.18653/v1/2024.findings-acl.964) |  | 0 | In this paper, we aim to evaluate multi-agent systems against complex dependencies, including spatial, causal, and temporal constraints. First, we construct a new benchmark, named VillagerBench, within the Minecraft environment. VillagerBench comprises diverse tasks crafted to test various aspects of multi-agent collaboration, from workload distribution to dynamic adaptation and synchronized task execution. Second, we introduce a Directed Acyclic Graph Multi-Agent Framework (VillagerAgent) to... | Yubo Dong, Xukun Zhu, Zhengzhe Pan, Linchao Zhu, Yi Yang |  |
| 1950 |  |  [CF-TCIR: A Compositor-Free Framework for Hierarchical Text-Conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.965) |  | 0 | In text-conditioned image retrieval (TCIR), the combination of a reference image and modification text forms a query tuple, aiming to locate the most congruent target image within a dataset. The advantages of rich image semantic information and text flexibility are combined in this manner for more accurate retrieval. While traditional techniques often employ attention-driven compositors to craft a unified image-text representation, our paper introduces a compositor-free framework, CF-TCIR,... | Yuchen Yang, Yu Wang, Yanfeng Wang |  |
| 1951 |  |  [DMIN: A Discourse-specific Multi-granularity Integration Network for Conversational Aspect-based Sentiment Quadruple Analysis](https://doi.org/10.18653/v1/2024.findings-acl.966) |  | 0 | Conversational Aspect-based Sentiment Quadruple Analysis (DiaASQ) aims to extract fine-grained sentiment quadruples from dialogues. Previous research has primarily concentrated on enhancing token-level interactions, still lacking in sufficient modeling of the discourse structure information in dialogue. Firstly, it does not incorporate interactions among different utterances in the encoding stage, resulting in a limited token-level context understanding for subsequent modules. Secondly, it... | Peijie Huang, Xisheng Xiao, Yuhong Xu, Jiawei Chen |  |
| 1952 |  |  [Are Decoder-Only Language Models Better than Encoder-Only Language Models in Understanding Word Meaning?](https://doi.org/10.18653/v1/2024.findings-acl.967) |  | 0 | The natural language processing field has been evolving around language models for the past few years, from the usage of n-gram language models for re-ranking, to transfer learning with encoder-only (BERT-like) language models, and finally to large language models (LLMs) as general solvers. LLMs are dominated by the decoder-only type, and they are popular for their efficacy in numerous tasks. LLMs are regarded as having strong comprehension abilities and strong capabilities to solve new unseen... | Muhammad Reza Qorib, Geonsik Moon, Hwee Tou Ng |  |
| 1953 |  |  [FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.968) |  | 0 | To process contexts with unlimited length using Large Language Models (LLMs), recent studies explore hierarchically managing the long text. Only several text fragments are taken from the external memory and passed into the temporary working memory, i.e., LLM’s context window. However, existing approaches isolatedly handle the text fragments without considering their structural connections, thereby suffering limited capability on texts with intensive inter-relations, e.g., coherent stories and... | Xihang Yue, Linchao Zhu, Yi Yang |  |
| 1954 |  |  [On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations](https://doi.org/10.18653/v1/2024.findings-acl.969) |  | 0 | Driven by the demand for cross-sentence and large-scale relation extraction, document-level relation extraction (DocRE) has attracted increasing research interest. Despite the continuous improvement in performance, we find that existing DocRE models which initially perform well may make more mistakes when merely changing the entity names in the document, hindering the generalization to novel entity names. To this end, we systematically investigate the robustness of DocRE models to entity name... | Shiao Meng, Xuming Hu, Aiwei Liu, Fukun Ma, Yawen Yang, Shuang Li, Lijie Wen |  |
| 1955 |  |  [RESEMO: A Benchmark Chinese Dataset for Studying Responsive Emotion from Social Media Content](https://doi.org/10.18653/v1/2024.findings-acl.970) |  | 0 | On social media platforms, users’ emotions are triggered when they encounter particular content from other users,where such emotions are different from those that spontaneously emerged, owing to the “responsive” nature. Analyzing the aforementioned responsive emotions from user interactions is a task of significant importance for understanding human cognition, the mechanisms of emotion generation, and behavior on the Internet, etc. Performing the task with artificial intelligence generally... | Bo Hu, Meng Zhang, Chenfei Xie, Yuanhe Tian, Yan Song, Zhendong Mao |  |
| 1956 |  |  [EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records](https://doi.org/10.18653/v1/2024.findings-acl.971) |  | 0 | In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to address critical yet underexplored aspects in text-to-SQL parsing: interactivity, compositionality, and efficiency. To the best of our knowledge, EHR-SeqSQL is not only the largest but also the first medical text-to-SQL dataset benchmark to include sequential and contextual questions. We provide a data split and the new test set designed to... | Jaehee Ryu, Seonhee Cho, Gyubok Lee, Edward Choi |  |
| 1957 |  |  [KEEP CHATTING! An Attractive Dataset for Continuous Conversation Agents](https://doi.org/10.18653/v1/2024.findings-acl.972) |  | 0 | Ongoing chatting is an important step for conversational agents to build long-term connections with people. However, people tend to quickly lose interest in chatting if the conversational agent’s words are not engaging enough. In this paper, we present a novel task of increasing users’ willingness to continue talking to the agent.We collect a dataset named ContinuousChat by: (i) collecting personas and revising them, and then expanding the personas to detailed-personas through experiences,... | Yihe Wang, Jin Liu, Yao Wan, Yitong Li, Zifeng Liu, Weipeng Chen |  |
| 1958 |  |  [RePair: Automated Program Repair with Process-based Feedback](https://doi.org/10.18653/v1/2024.findings-acl.973) |  | 0 | The gap between the trepidation of program reliability and the expense of repairs underscore the indispensability for Automated Program Repair (APR). APR is instrumental in transforming vulnerable programs into more robust ones, bolstering program reliability while simultaneously diminishing the financial burden of manual repairs. Commercial-scale language models (LM) have taken APR to unprecedented levels. However, due to the limitations of model capabilities by parameters, a one-step... | Yuze Zhao, Zhenya Huang, Yixiao Ma, Rui Li, Kai Zhang, Hao Jiang, Qi Liu, Linbo Zhu, Yu Su |  |
| 1959 |  |  [Concise and Precise Context Compression for Tool-Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.974) |  | 0 | Through reading the documentation in the context, tool-using language models can dynamically extend their capability using external tools. The cost is that we have to input lengthy documentation every time the model needs to use the tool, occupying the input window as well as slowing down the decoding process.Given the progress in general-purpose compression, soft context compression is a suitable approach to alleviate the problem. However, when compressing tool documentation, existing methods... | Yang Xu, Yunlong Feng, Honglin Mu, Yutai Hou, Yitong Li, Xinghao Wang, Wanjun Zhong, Zhongyang Li, Dandan Tu, Qingfu Zhu, Min Zhang, Wanxiang Che |  |
| 1960 |  |  [MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries](https://doi.org/10.18653/v1/2024.findings-acl.975) |  | 0 | Medical decisions directly impact individuals’ health and well-being. Extracting decision spans from clinical notes plays a crucial role in understanding medical decision-making processes. In this paper, we develop a new dataset called “MedDec,” which contains clinical notes of eleven different phenotypes (diseases) annotated by ten types of medical decisions. We introduce the task of medical decision extraction, aiming to jointly extract and classify different types of medical decisions within... | Mohamed Elgaar, Jiali Cheng, Nidhi Vakil, Hadi Amiri, Leo Anthony Celi |  |

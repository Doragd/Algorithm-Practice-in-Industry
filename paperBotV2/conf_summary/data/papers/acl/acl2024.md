# ACL2024

## 会议论文列表

本会议共有 1960 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Feriji: A French-Zarma Parallel Corpus, Glossary & Translator](https://doi.org/10.18653/v1/2024.acl-srw.1) |  | 0 | Machine translation (MT) is a rapidly expanding field that has experienced significant advancements in recent years with the development of models capable of translating multiple languages with remarkable accuracy. However, the representation of African languages in this field still needs... | Christopher Homan, Elysabhete Amadou Ibrahim, Habibatou Abdoulaye Alfari, Mamadou Keita |  |
| 2 |  |  [Pragmatic inference of scalar implicature by LLMs](https://doi.org/10.18653/v1/2024.acl-srw.2) |  | 0 | This study investigates how Large Language Models (LLMs), particularly BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic inference of scalar implicature, such as some. Two sets of experiments were conducted using cosine similarity and next sentence/token prediction as... | Seong mook Kim, Yeeun Cho |  |
| 3 |  |  [Topic Modeling for Short Texts with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.3) |  | 0 | As conventional topic models rely on word co-occurrence to infer latent topics, topic modeling for short texts has been a long-standing challenge. Large Language Models (LLMs) can potentially overcome this challenge by contextually learning the meanings of words via pretraining. In this paper, we... | Hitomi Yanaka, Masaru Isonuma, Tomoki Doi |  |
| 4 |  |  [Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases](https://doi.org/10.18653/v1/2024.acl-srw.4) |  | 0 |  | Khatoon Khedri, Reza Rawassizadeh, Xiang Zhang |  |
| 5 |  |  [Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer](https://doi.org/10.18653/v1/2024.acl-srw.5) |  | 0 | Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer... | Jionghao Bai, Rongjie Huang, Ruiqi Li, Yongqi Wang, Zhiqing Hong, Zhou Zhao |  |
| 6 |  |  [InstructCoder: Instruction Tuning Large Language Models for Code Editing](https://doi.org/10.18653/v1/2024.acl-srw.6) |  | 0 |  | Hui Chen, James Xu Zhao, Junxian He, Kaixin Li, Michael Shieh, Qisheng Hu, Tiedong Liu, Yuxi Xie |  |
| 7 |  |  [BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization](https://doi.org/10.18653/v1/2024.acl-srw.7) |  | 0 | Large Language Models (LLMs) have become pivotal in advancing natural language processing, yet their potential to perpetuate biases poses significant concerns. This paper introduces a new framework employing Direct Preference Optimization (DPO) to mitigate gender, racial, and religious biases in... | Ahmed Allam |  |
| 8 |  |  [MoExtend: Tuning New Experts for Modality and Task Extension](https://doi.org/10.18653/v1/2024.acl-srw.8) |  | 0 |  | Marinka Zitnik, Pan Zhou, Shanghua Gao, Shanshan Zhong, Wushao Wen, Zhongzhan Huang |  |
| 9 |  |  [On the Interpretability of Deep Learning Models for Collaborative Argumentation Analysis in Classrooms](https://doi.org/10.18653/v1/2024.acl-srw.9) |  | 0 |  | Deliang Wang, Gaowei Chen |  |
| 10 |  |  [Document Alignment based on Overlapping Fixed-Length Segments](https://doi.org/10.18653/v1/2024.acl-srw.10) |  | 0 | Acquiring large-scale parallel corpora is crucial for NLP tasks such as Neural Machine Translation, and web crawling has become a popular methodology for this purpose. Previous studies have been conducted based on sentence-based segmentation (SBS) when aligning documents in various languages which... | Masaaki Nagata, Takehito Utsuro, Xiaotian Wang |  |
| 11 |  |  [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.acl-srw.11) |  | 0 |  | Akiko Aizawa, Enrico Benedetti, Florian Boudin |  |
| 12 |  |  [Z-coref: Thai Coreference and Zero Pronoun Resolution](https://doi.org/10.18653/v1/2024.acl-srw.12) |  | 0 |  | Poomphob Suwannapichat, Sansiri Tarnpradab, Santitham Promon |  |
| 13 |  |  [ReMAG-KR: Retrieval and Medically Assisted Generation with Knowledge Reduction for Medical Question Answering](https://doi.org/10.18653/v1/2024.acl-srw.13) |  | 0 | Large Language Models (LLMs) have significant potential for facilitating intelligent end-user applications in healthcare. However, hallucinations remain an inherent problem with LLMs, making it crucial to address this issue with extensive medical knowledge and data. In this work, we propose a... | Sidhaarth Murali, Sowmya S., Supreetha R. |  |
| 14 |  |  [Plot Retrieval as an Assessment of Abstract Semantic Association](https://doi.org/10.18653/v1/2024.acl-srw.14) |  | 0 |  | Fandong Meng, Huawei Shen, Jiangnan Li, Jie Zhou, Liang Pang, Mo Yu, Shicheng Xu, Xueqi Cheng |  |
| 15 |  |  [Demystifying Instruction Mixing for Fine-tuning Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.15) |  | 0 | Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP... | Chiyu Zhang, Haonan Li, Minghao Wu, Renxi Wang, Timothy Baldwin, Xudong Han, Yuxia Wang |  |
| 16 |  |  [Fine-Tuning ASR models for Very Low-Resource Languages: A Study on Mvskoke](https://doi.org/10.18653/v1/2024.acl-srw.16) |  | 0 | Recent advancements in multilingual models for automatic speech recognition (ASR) have been able to achieve a high accuracy for languages with extremely limited resources. This study examines ASR modeling for the Mvskoke language, an indigenous language of America. The parameter efficiency of... | GinaAnne Levow, Julia Mainzinger |  |
| 17 |  |  [Automating Qualitative Data Analysis with Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.17) |  | 0 | This PhD proposal aims to investigate ways of automating qualitative data analysis, specifically the thematic coding of texts. Despite existing methods vastly covered in literature, they mainly use Topic Modeling and other quantitative approaches which are far from resembling a human’s analysis... | Alexander Denzler, Angelina Parfenova, Jörgen Pfeffer |  |
| 18 |  |  [ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection](https://doi.org/10.18653/v1/2024.acl-srw.18) |  | 0 | Research on token-level reference-free hallucination detection has predominantly focused on English, primarily due to the scarcity of robust datasets in other languages. This has hindered systematic investigations into the effectiveness of cross-lingual transfer for this important NLP application.... | ChiaChien Hung, Goran Glavas, Janek Herrlein |  |
| 19 |  |  [Label-Aware Automatic Verbalizer for Few-Shot Text Classification in Mid-To-Low Resource Languages](https://doi.org/10.18653/v1/2024.acl-srw.19) |  | 0 | Prompt-based learning has shown its effectiveness in few-shot text classification. A key factor in its success is a verbalizer, which translates output from a language model into a predicted class. Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the... | Peerapon Vateekul, Piyawat Lertvittayakumjorn, Thanakorn Thaminkaew |  |
| 20 |  |  [Vector Spaces for Quantifying Disparity of Multiword Expressions in Annotated Text](https://doi.org/10.18653/v1/2024.acl-srw.20) |  | 0 | Multiword Expressions (MWEs) make a goodcase study for linguistic diversity due to theiridiosyncratic nature. Defining MWE canonicalforms as types, diversity may be measurednotably through disparity, based on pairwisedistances between types. To this aim, wetrain static MWE-aware word embeddings... | Agata Savary, Louis Estève, Thomas Lavergne |  |
| 21 |  |  [Narratives at Conflict: Computational Analysis of News Framing in Multilingual Disinformation Campaigns](https://doi.org/10.18653/v1/2024.acl-srw.21) |  | 0 | Any report frames issues to favor a particular interpretation by highlighting or excluding certain aspects of a story. Despite the widespread use of framing in disinformation, framing properties and detection methods remain underexplored outside the English-speaking world. We explore how... | Antonina Sinelnik, Dirk Hovy |  |
| 22 |  |  [Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data](https://doi.org/10.18653/v1/2024.acl-srw.22) |  | 0 | Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages. Automated scalable methods are necessary due to the impracticality of manual labeling. In this paper, we model... | Andreas Spitz, Julian Schelb, Roberto Ulloa |  |
| 23 |  |  [Knowledge Editing of Large Language Models Unconstrained by Word Order](https://doi.org/10.18653/v1/2024.acl-srw.23) |  | 0 | Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves. To address this issue, a method called local modification-based knowledge... | Eisaku Maeda, Jundai Suzuki, Masaki Shuzo, Ryoma Ishigaki |  |
| 24 |  |  [Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning](https://doi.org/10.18653/v1/2024.acl-srw.24) |  | 0 | Identifying beneficial tasks to transfer from is a critical step toward successful intermediate-task transfer learning. In this work, we experiment with 130 source-target task combinations and demonstrate that the transfer performance exhibits severe variance across different source tasks and... | Dietrich Klakow, Marius Mosbach, Miaoran Zhang, PinJie Lin |  |
| 25 |  |  [Does the structure of textual content have an impact on language models for automatic summarization?](https://doi.org/10.18653/v1/2024.acl-srw.25) |  | 0 | The processing of long sequences with models remains a subject in its own right, including automatic summary, despite recent improvements. In this work, we present experiments on the automatic summarization of scientific articles using BART models, taking into account textual information coming... | Cyril Grouin, Eve Sauvage, Lydia Ould Ouali, Sabrina Campano |  |
| 26 |  |  [Action Inference for Destination Prediction in Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-srw.26) |  | 0 | Vision-and-Language Navigation (VLN) encompasses interacting with autonomous vehicles using language and visual input from the perspective of mobility.Most of the previous work in this field focuses on spatial reasoning and the semantic grounding of visual information.However, reasoning based on... | Anirudh Reddy Kondapally, Hitomi Yanaka, Kentaro Yamada |  |
| 27 |  |  [A Computational Analysis and Exploration of Linguistic Borrowings in French Rap Lyrics](https://doi.org/10.18653/v1/2024.acl-srw.27) |  | 0 | In France, linguistic borrowings in the relatively conservative French language are an important site of cultural debate, and rap in particular is a hotspot for borrowings. In this work, we use computational methods to understand the factors that affect the prominence and prevalence of a borrowing.... | Lucas Zurbuchen, Rob Voigt |  |
| 28 |  |  [On Improving Repository-Level Code QA for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.28) |  | 0 | Large Language Models (LLMs) such as ChatGPT, GitHub Copilot, Llama, or Mistral assist programmers as copilots and knowledge sources to make the coding process faster and more efficient. This paper aims to improve the copilot performance by implementing different self-alignment processes and... | Chris Biemann, Florian Schneider, Irina Nikishina, Jan Strich |  |
| 29 |  |  [Compromesso! Italian Many-Shot Jailbreaks undermine the safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.29) |  | 0 | As diverse linguistic communities and users adopt Large Language Models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to align these models with safe and ethical guidelines, they can still be induced into unsafe behavior with jailbreaking, a technique in... | Dirk Hovy, Fabio Pernisi, Paul Röttger |  |
| 30 |  |  [Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.30) |  | 0 |  | Yunsoo Kim |  |
| 31 |  |  [ViMedAQA: A Vietnamese Medical Abstractive Question-Answering Dataset and Findings of Large Language Model](https://doi.org/10.18653/v1/2024.acl-srw.31) |  | 0 | Question answering involves creating answers to questions. With the growth of large language models, the ability of question-answering systems has dramatically improved. However, there is a lack of Vietnamese abstractive question-answering datasets, especially in the medical domain. Therefore, this... | Dien Dinh, Long Nguyen, MinhNam Tran, PhuVinh Nguyen |  |
| 32 |  |  [Rescue: Ranking LLM Responses with Partial Ordering to Improve Response Generation](https://doi.org/10.18653/v1/2024.acl-srw.32) |  | 0 | Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert-annotated data is costly for most tasks. In this paper,... | Fei Liu, Haoming Li, Qi Zhang, Rui Zheng, Tao Gui, Yikun Wang |  |
| 33 |  |  [Basreh or Basra? Geoparsing Historical Locations in the Svoboda Diaries](https://doi.org/10.18653/v1/2024.acl-srw.33) |  | 0 | Geoparsing, the task of assigning coordinates to locations extracted from free text, is invaluable in enabling us to place locations in time and space. In the historical domain, many geoparsing corpora are from large news collections. We examine the Svoboda Diaries, a small historical corpus... | Annie Chen, Camille Cole, Jolie Zhou |  |
| 34 |  |  [Homophone2Vec: Embedding Space Analysis for Empirical Evaluation of Phonological and Semantic Similarity](https://doi.org/10.18653/v1/2024.acl-srw.34) |  | 0 | This paper introduces a novel method for empirically evaluating the relationship between the phonological and semantic similarity of linguistic units using embedding spaces. Chinese character homophones are used as a proof-of-concept. We employ cosine similarity as a proxy for semantic similarity... | Anita Zheng, Joey Chuang, Sophie Wu |  |
| 35 |  |  [Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition](https://doi.org/10.18653/v1/2024.acl-srw.35) |  | 0 | Knowledge distillation allows smaller neural networks to emulate the performance of larger, teacher models with reduced computational demands. Traditional methods for Large Language Models (LLMs) often necessitate extensive fine-tuning, which limits their accessibility. To address this, we... | Ali Emami, Tyler McDonald |  |
| 36 |  |  [Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges](https://doi.org/10.18653/v1/2024.acl-srw.36) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply common sense. A relevant application is to use them for creating high-quality synthetic datasets for downstream tasks. In this work, we probe... | Aman Chadha, Arijit Ghosh Chowdhury, Houda Aynaou, Karthik Venkat Ramanan, Vinay Samuel |  |
| 37 |  |  [Automatic Derivation of Semantic Representations for Thai Serial Verb Constructions: A Grammar-Based Approach](https://doi.org/10.18653/v1/2024.acl-srw.37) |  | 0 | Deep semantic representations are useful for many NLU tasks (Droganova and Zeman 2019; Schuster and Manning-2016). Manual annotation to build these representations is time-consuming, and so automatic approaches are preferred (Droganova and Zeman 2019; Bender et al. 2015). This paper demonstrates... | Vipasha Bansal |  |
| 38 |  |  [Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai](https://doi.org/10.18653/v1/2024.acl-srw.38) |  | 0 |  | Can Udomcharoenchaikit, Parinthapat Pengpun, Peerat Limkonchotiwat, Weerayut Buaphet |  |
| 39 |  |  [Bridging Distribution Gap via Semantic Rewriting with LLMs to Enhance OOD Robustness](https://doi.org/10.18653/v1/2024.acl-srw.39) |  | 0 | This paper investigates the robustness of Large Language Models (LLMs) against Out-Of-Distribution (OOD) data within the context of sentiment analysis. Traditional fine-tuning approaches often fail to generalize effectively across different data distributions, limiting the practical deployment of... | Manas Madine |  |
| 40 |  |  [CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units](https://doi.org/10.18653/v1/2024.acl-srw.40) |  | 0 | Multilingual code-switching research is often hindered by the lack and linguistically biased status of available datasets. To expand language representation, we synthesize code-switching data by replacing intonation units detected through PSST, a speech segmentation model fine-tuned from OpenAI’s... | Yeeun Kang |  |
| 41 |  |  [An Analysis under a Unified Formulation of Learning Algorithms with Output Constraints](https://doi.org/10.18653/v1/2024.acl-srw.41) |  | 0 |  | JayYoon Lee, Mooho Song |  |
| 42 |  |  [Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation](https://doi.org/10.18653/v1/2024.acl-srw.42) |  | 0 | The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but... | Anya Belz, Cian Nolan, James O'Doherty, Yufang Hou |  |
| 43 |  |  [Improving Sentence Embeddings with Automatic Generation of Training Data Using Few-shot Examples](https://doi.org/10.18653/v1/2024.acl-srw.43) |  | 0 | Decoder-based large language models (LLMs) have shown high performance on many tasks in natural language processing. This is also true for sentence embedding learning, where a decoder-based model, PromptEOL, has achieved the best performance on semantic textual similarity (STS) tasks. However,... | Hayato Tsukagoshi, Koichi Takeda, Ryohei Sasano, Soma Sato |  |
| 44 |  |  [Curriculum Learning for Small Code Language Models](https://doi.org/10.18653/v1/2024.acl-srw.44) |  | 0 | Code language models have emerged as useful tools for various programming tasks, yet they often struggle when it comes to complex ones. In this paper, we explore the potential of curriculum learning in enhancing the performance of these models. While prior research has suggested that curriculum... | Kamel Mohammed Yamani, Lynda Said L'Hadj, Marwa Naïr, Riyadh Baghdadi |  |
| 45 |  |  [Question-Analysis Prompting Improves LLM Performance in Reasoning Tasks](https://doi.org/10.18653/v1/2024.acl-srw.45) |  | 0 | Although LLMs have the potential to transform many fields, they still underperform humans in reasoning tasks. Existing methods induce the model to produce step-by-step calculations, but this research explores the question: Does making the LLM analyze the question improve its performance? We propose... | Dharunish Yugeswardeenoo, Kevin Zhu, Sean O'Brien |  |
| 46 |  |  [An Individualized News Affective Response Dataset](https://doi.org/10.18653/v1/2024.acl-srw.46) |  | 0 |  | Nigel Collier, Tiancheng Hu |  |
| 47 |  |  [How Well Do Vision Models Encode Diagram Attributes?](https://doi.org/10.18653/v1/2024.acl-srw.47) |  | 0 |  | Haruto Yoshida, Itsumi Saito, Keisuke Sakaguchi, Keito Kudo, Kentaro Inui, Ryota Tanaka, Yoichi Aoki |  |
| 48 |  |  [CheckersGPT: Learning World Models through Language Modeling](https://doi.org/10.18653/v1/2024.acl-srw.48) |  | 0 | Although Large Language Models (LLMs) have been trained using just the next token prediction objective, these have shown impressive performance on various tasks. Consequently, it has attracted research interests in this regard. While one line of work in the past has suggested that LLMs learn... | Abhinav Joshi, Ashutosh Modi, Vaibhav Sharma |  |
| 49 |  |  [In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery](https://doi.org/10.18653/v1/2024.acl-srw.49) |  | 0 | State of the art Symbolic Regression (SR) methods currently build specialized models, while the application of Large Language Models (LLMs) remains largely unexplored. In this work, we introduce the first comprehensive framework that utilizes LLMs for the task of SR.We propose In-Context Symbolic... | Katsiaryna Haitsiukevich, Matteo Merler, Nicola Dainese, Pekka Marttinen |  |
| 50 |  |  [STEP: Staged Parameter-Efficient Pre-training for Large Language Models](https://doi.org/10.18653/v1/2024.acl-srw.50) |  | 0 | We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity,... | Jun Suzuki, Kazuki Yano, Takumi Ito |  |
| 51 |  |  [Can Language Models Serve as Text-Based World Simulators?](https://doi.org/10.18653/v1/2024.acl-short.1) |  | 0 | Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus... | Graham Todd, MarcAlexandre Côté, Peter A. Jansen, Peter Clark, Ruoyao Wang, Xingdi Yuan, Ziang Xiao |  |
| 52 |  |  [FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.2) |  | 0 | One type of question that is commonly found in day-to-day scenarios is “fan-out” questions, complex multi-hop, multi-document reasoning questions that require finding information about a large number of entities. However, there exist few resources to evaluate this type of question-answering... | Alyssa Hwang, Andrew Zhu, Chris CallisonBurch, Liam Dugan |  |
| 53 |  |  [Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance](https://doi.org/10.18653/v1/2024.acl-short.3) |  | 0 | This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity... | Cedric Lothritz, Jacques Klein, Tegawendé F. Bissyandé, Xunzhu Tang, Yewei Song |  |
| 54 |  |  [Resisting the Lure of the Skyline: Grounding Practices in Active Learning for Morphological Inflection](https://doi.org/10.18653/v1/2024.acl-short.4) |  | 0 | Active learning (AL) aims to lower the demand of annotation by selecting informative unannotated samples for the model building. In this paper, we explore the importance of conscious experimental design in the language documentation and description setting, particularly the distribution of the... | Mans Hulden, Michael Ginn, Miikka Silfverberg, Saliha Muradoglu |  |
| 55 |  |  [Speculative Contrastive Decoding](https://doi.org/10.18653/v1/2024.acl-short.5) |  | 0 | Large language models (LLMs) exhibit exceptional performance in language tasks, yet their auto-regressive inference is limited due to high computational requirements and is sub-optimal due to the exposure bias. Inspired by speculative decoding and contrastive decoding, we introduce Speculative... | Chang Zhou, Fei Huang, Hongyi Yuan, Keming Lu, Zheng Yuan |  |
| 56 |  |  [RDRec: Rationale Distillation for LLM-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.6) |  | 0 | Large language model (LLM)-based recommender models that bridge users and items through textual prompts for effective semantic reasoning have gained considerable attention. However, few methods consider the underlying rationales behind interactions, such as user preferences and item attributes,... | Fumiyo Fukumoto, Jin Cui, Xinfeng Wang, Yoshimi Suzuki |  |
| 57 |  |  [Isotropy, Clusters, and Classifiers](https://doi.org/10.18653/v1/2024.acl-short.7) |  | 0 | Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the... | Joseph Attieh, StigArne Grönroos, Timothee Mickus |  |
| 58 |  |  [Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks](https://doi.org/10.18653/v1/2024.acl-short.8) |  | 0 | The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate. We show that LLMs are frequently able to correctly and confidently predict the first digit of n-digit by m-digit multiplication tasks without using... | Andrew Gambardella, Yusuke Iwasawa, Yutaka Matsuo |  |
| 59 |  |  [Simpson's Paradox and the Accuracy-Fluency Tradeoff in Translation](https://doi.org/10.18653/v1/2024.acl-short.9) |  | 0 | A good translation should be faithful to the source and should respect the norms of the target language. We address a theoretical puzzle about the relationship between these objectives. On one hand, intuition and some prior work suggest that accuracy and fluency should trade off against each other,... | Charles Kemp, Ekaterina Vylomova, Trevor Cohn, Zheng Wei Lim |  |
| 60 |  |  [UltraSparseBERT: 99% Conditionally Sparse Language Modelling](https://doi.org/10.18653/v1/2024.acl-short.10) |  | 0 | We present UltraSparseBERT, a BERT variant that uses 0.3% of its neurons during inference while performing on par with similar BERT models. UltraSparseBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by reorganizing feedforward networks into fast... | Peter Belcak, Roger Wattenhofer |  |
| 61 |  |  [SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark](https://doi.org/10.18653/v1/2024.acl-short.11) |  | 0 | The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including... | Gang Liu, Jiajun Jiao, Jipeng Zhang, Kehan Guo, Renjie Pi, Taicheng Guo, Tianyu Yang, Xiangliang Zhang, Yujun Zhou, Zhenwen Liang |  |
| 62 |  |  [On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.12) |  | 0 | Retrieval augmented generation (RAG) exhibits outstanding performance in promoting the knowledge capabilities of large language models (LLMs) with retrieved documents related to user queries. However, RAG only focuses on improving the response quality of LLMs via enhancing queries indiscriminately... | Chengyu Wang, Dongyang Li, Hui Xue, Jun Huang, Junbing Yan, Longtao Huang, Taolin Zhang, Xiaofeng He |  |
| 63 |  |  [IEPile: Unearthing Large Scale Schema-Conditioned Information Extraction Corpus](https://doi.org/10.18653/v1/2024.acl-short.13) |  | 0 | Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE... | Hongbin Ye, Honghao Gui, Huajun Chen, Lei Liang, Lin Yuan, Mengshu Sun, Ningyu Zhang |  |
| 64 |  |  [Bi-Directional Multi-Granularity Generation Framework for Knowledge Graph-to-Text with Large Language Model](https://doi.org/10.18653/v1/2024.acl-short.14) |  | 0 | The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. Existing methods generate the whole target text based on all KG triples at once and may incorporate... | Chen Li, Dinghao Zhang, Dongyan Zhao, Haowei Du |  |
| 65 |  |  [Code-Switching Can be Better Aligners: Advancing Cross-Lingual SLU through Representation-Level and Prediction-Level Alignment](https://doi.org/10.18653/v1/2024.acl-short.15) |  | 0 | Zero-shot cross-lingual spoken language understanding (SLU) can promote the globalization application of dialog systems, which has attracted increasing attention. While current code-switching based cross-lingual SLU frameworks have shown promising results, they (i) predominantly utilize contrastive... | Xianwei Zhuang, Xuxin Cheng, Yuexian Zou, Zhanpeng Chen, Zhihong Zhu, Zhiqi Huang |  |
| 66 |  |  [AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://doi.org/10.18653/v1/2024.acl-short.16) |  | 0 | We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low-Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each... | Anni Li, Junrui Wan, Lianghao Jiang, Peter A. Beerel, Souvik Kundu, Zeyu Liu |  |
| 67 |  |  [DDPrompt: Differential Diversity Prompting in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.17) |  | 0 | Large Language Models (LLMs) have shown that their reasoning ability could be enhanced through approaches like Chain-of-Thought (CoT) prompting. However, these methods use single prompts for different types of questions and do not design appropriate prompts for questions with different... | Lin Mu, Peiquan Jin, Wenhao Zhang, Yiwen Zhang |  |
| 68 |  |  [Monotonic Representation of Numeric Attributes in Language Models](https://doi.org/10.18653/v1/2024.acl-short.18) |  | 0 | Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model’s internal representations is not understood well. Here, we introduce a method for finding and editing representations of... | Benjamin Heinzerling, Kentaro Inui |  |
| 69 |  |  [Two Issues with Chinese Spelling Correction and A Refinement Solution](https://doi.org/10.18653/v1/2024.acl-short.19) |  | 0 | The Chinese Spelling Correction (CSC) task aims to detect and correct misspelled characters in Chinese text, and has received lots of attention in the past few years. Most recent studies adopt a Transformer-based model and leverage different features of characters such as pronunciation, glyph and... | Changxuan Sun, Linlin She, Xuesong Lu |  |
| 70 |  |  [DynaSemble: Dynamic Ensembling of Textual and Structure-Based Models for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-short.20) |  | 0 | We consider two popular approaches to KnowledgeGraph Completion (KGC): textual modelsthat rely on textual entity descriptions, andstructure-based models that exploit the connectivitystructure of the Knowledge Graph(KG). Preliminary experiments show that theseapproaches have complementary... | Ananjan Nandi, Mausam, Navdeep Kaur, Parag Singla |  |
| 71 |  |  [Fine-Tuning Pre-Trained Language Models with Gaze Supervision](https://doi.org/10.18653/v1/2024.acl-short.21) |  | 0 | Human gaze data provide cognitive information that reflect human language comprehension and has been effectively integrated into a variety of natural language processing (NLP) tasks, demonstrating improved performance over corresponding plain text-based models. In this work, we propose to integrate... | David R. Reich, Lena A. Jäger, Paul Prasse, Shuwen Deng, Tobias Scheffer |  |
| 72 |  |  [Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech](https://doi.org/10.18653/v1/2024.acl-short.22) |  | 0 | Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task (Pupier et al. 2022), as a way of incorporating prosodic information in the parsing system and bypassing the limitations of a pipeline approach that would consist of... | Adrien Pupier, Benjamin Lecouteux, Jérôme Goulian, Maximin Coavoux |  |
| 73 |  |  [Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access](https://doi.org/10.18653/v1/2024.acl-short.23) |  | 0 | Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually... | Berkay Döner, Chris Wendler, Martin Josifoski, Robert West, Saibo Geng |  |
| 74 |  |  [On the Semantic Latent Space of Diffusion-Based Text-To-Speech Models](https://doi.org/10.18653/v1/2024.acl-short.24) |  | 0 | The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized... | Daniel Freedman, Ehud Rivlin, Miri VarshavskyHassid, Regev Cohen, Roy Hirsch, Tomer Golany |  |
| 75 |  |  [Learnable Privacy Neurons Localization in Language Models](https://doi.org/10.18653/v1/2024.acl-short.25) |  | 0 | Concerns regarding Large Language Models (LLMs) to memorize and disclose private information, particularly Personally Identifiable Information (PII), become prominent within the community. Many efforts have been made to mitigate the privacy risks.However, the mechanism through which LLMs memorize... | Ruizhe Chen, Tianxiang Hu, Yang Feng, Zuozhu Liu |  |
| 76 |  |  [Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs](https://doi.org/10.18653/v1/2024.acl-short.26) |  | 0 | Humans often express their communicative intents indirectly or non-literally, which requires their interlocutors—human or AI—to understand beyond the literal meaning of words. While most existing work has focused on discriminative evaluations, we present a new approach to generatively evaluate... | Akhila Yerukola, Daniel Fried, Maarten Sap, Saujas Vaduguru |  |
| 77 |  |  [Generating Harder Cross-document Event Coreference Resolution Datasets using Metaphoric Paraphrasing](https://doi.org/10.18653/v1/2024.acl-short.27) |  | 0 | The most popular Cross-Document Event Coreference Resolution (CDEC) datasets fail to convey the true difficulty of the task, due to the lack of lexical diversity between coreferring event triggers (words or phrases that refer to an event). Furthermore, there is a dearth of event datasets for... | George Baker, James H. Martin, Kevin Stowe, Shafiuddin Rehan Ahmed, Zhiyong Eric Wang |  |
| 78 |  |  [Soft Self-Consistency Improves Language Models Agents](https://doi.org/10.18653/v1/2024.acl-short.28) |  | 0 | Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current “sample and select” methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers,... | Archiki Prasad, Elias StengelEskin, Han Wang, Mohit Bansal |  |
| 79 |  |  [RecGPT: Generative Pre-training for Text-based Recommendation](https://doi.org/10.18653/v1/2024.acl-short.29) |  | 0 | We present the first domain-adapted and fully-trained large language model, RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for text-based recommendation. Experimental results on rating prediction and sequential recommendation tasks show that our model, RecGPT-7B-Instruct,... | Dat Quoc Nguyen, Hoang Ngo |  |
| 80 |  |  [MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations](https://doi.org/10.18653/v1/2024.acl-short.30) |  | 0 | Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a... | Chang Wei Tan, GiaBao Dinh Ho, Mahsa Salehi, Reza Haffari, Wray L. Buntine, Zahra Zamanzadeh Darban |  |
| 81 |  |  [What Does Parameter-free Probing Really Uncover?](https://doi.org/10.18653/v1/2024.acl-short.31) |  | 0 | Supervised approaches to probing large language models (LLMs) have been criticized of using pre-defined theory-laden target labels. As an alternative, parameter-free probing constructs structural representations bottom-up via information derived from the LLM alone. This has been suggested to... | Tommi BuderGröndahl |  |
| 82 |  |  [ATLAS: Improving Lay Summarisation with Attribute-based Control](https://doi.org/10.18653/v1/2024.acl-short.32) |  | 0 | Lay summarisation aims to produce summaries of scientific articles that are comprehensible to non-expert audiences. However, previous work assumes a one-size-fits-all approach, where the content and style of the produced summary are entirely dependent on the data used to train the model. In... | Carolina Scarton, Chenghua Lin, Tomas Goldsack, Zhihao Zhang |  |
| 83 |  |  [EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-short.33) |  | 0 | The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated, leaving the gap between current LVLMs and qualified embodied... | Binhao Wu, Mengfei Du, Xuanjing Huang, Zejun Li, Zhongyu Wei |  |
| 84 |  |  [Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark](https://doi.org/10.18653/v1/2024.acl-short.34) |  | 0 | Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of noise,... | Amin Ahmadi, Fredrik Gordh Riseby, Niklas Wretblad, Oskar Holmström, Rahul Biswas |  |
| 85 |  |  [Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-short.35) |  | 0 | This study investigates the existence of positional biases in Transformer-based language models for text representation learning, particularly in the context of web document retrieval. We build on previous research that demonstrated loss of information in the middle of input sequences for causal... | Bruno Martins, Chenyan Xiong, Jamie Callan, João Coelho, João Magalhães |  |
| 86 |  |  [That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses](https://doi.org/10.18653/v1/2024.acl-short.36) |  | 0 | The Uniform Information Density (UID) hypothesis posits that speakers optimize the communicative properties of their utterances by avoiding spikes in information, thereby maintaining a relatively uniform information profile over time. This paper investigates the impact of UID principles on... | Ella Rabinovich |  |
| 87 |  |  [Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?](https://doi.org/10.18653/v1/2024.acl-short.37) |  | 0 | We examine whether large language models (LLMs) exhibit race- and gender-based name discrimination in hiring decisions, similar to classic findings in the social sciences (Bertrand and Mullainathan, 2004). We design a series of templatic prompts to LLMs to write an email to a named job applicant... | Christabel Acquaye, Colin Wang, Haozhe An, Rachel Rudinger, Zongxia Li |  |
| 88 |  |  [Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster](https://doi.org/10.18653/v1/2024.acl-short.38) |  | 0 | Content moderators play a key role in keeping the conversation on social media healthy. While the high volume of content they need to judge represents a bottleneck to the moderation pipeline, no studies have explored how models could support them to make faster decisions. There is, by now, a vast... | Agostina Calabrese, Björn Ross, Francesco Barbieri, Leonardo Neves, Maarten W. Bos, Mirella Lapata, Neil Shah |  |
| 89 |  |  [Born Differently Makes a Difference: Counterfactual Study of Bias in Biography Generation from a Data-to-Text Perspective](https://doi.org/10.18653/v1/2024.acl-short.39) |  | 0 | How do personal attributes affect biography generation? Addressing this question requires an identical pair of biographies where only the personal attributes of interest are different. However, it is rare in the real world. To address this, we propose a counterfactual methodology from a... | Biaoyan Fang, Ritvik Dinesh, Sarvnaz Karimi, Xiang Dai |  |
| 90 |  |  [Sign Language Translation with Sentence Embedding Supervision](https://doi.org/10.18653/v1/2024.acl-short.40) |  | 0 | State-of-the-art sign language translation (SLT) systems facilitate the learning process through gloss annotations, either in an end2end manner or by involving an intermediate step. Unfortunately, gloss labelled sign language data is usually not available at scale and, when available, gloss... | Cristina EspañaBonet, Josef van Genabith, Yasser Hamidullah |  |
| 91 |  |  [STREAM: Simplified Topic Retrieval, Exploration, and Analysis Module](https://doi.org/10.18653/v1/2024.acl-short.41) |  | 0 | Topic modeling is a widely used technique to analyze large document corpora. With the ever-growing emergence of scientific contributions in the field, non-technical users may often use the simplest available software module, independent of whether there are potentially better models available. We... | Anton Thielmann, Arik Reuter, Benjamin Säfken, Christoph Weisser, Gillian Kant, Manish Kumar |  |
| 92 |  |  [DocFinQA: A Long-Context Financial Reasoning Dataset](https://doi.org/10.18653/v1/2024.acl-short.42) |  | 0 | For large language models (LLMs) to be effective in the financial domain – where each decision can have a significant impact – it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents spanning hundreds of pages, but most financial research... | Charles Lovering, Chris Tanner, Michael Krumdick, Rik KoncelKedziorski, Varshini Reddy, Viet Dac Lai |  |
| 93 |  |  [MaskLID: Code-Switching Language Identification through Iterative Masking](https://doi.org/10.18653/v1/2024.acl-short.43) |  | 0 | We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single... | Amir Hossein Kargaran, François Yvon, Hinrich Schütze |  |
| 94 |  |  [An Empirical Analysis on Large Language Models in Debate Evaluation](https://doi.org/10.18653/v1/2024.acl-short.44) |  | 0 | In this study, we investigate the capabilities and inherent biases of advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context of debate evaluation. We discover that LLM’s performance exceeds humans and surpasses the performance of state-of-the-art methods fine-tuned on... | Hangfeng He, Pinxin Liu, Xinyi Liu |  |
| 95 |  |  [Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains](https://doi.org/10.18653/v1/2024.acl-short.45) |  | 0 | We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain... | Anna Currey, Brian Thompson, Jenyuan Wang, Shuoyang Ding, Tatyana Badeka, Vilém Zouhar |  |
| 96 |  |  [IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages](https://doi.org/10.18653/v1/2024.acl-short.46) |  | 0 | In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include... | Ashutosh Sharma, Niyati Chhaya, Omar Khattab, Pushpak Bhattacharyya, Saiful Haq |  |
| 97 |  |  [AGR: Reinforced Causal Agent-Guided Self-explaining Rationalization](https://doi.org/10.18653/v1/2024.acl-short.47) |  | 0 | Most existing rationalization approaches are susceptible to degeneration accumulation due to a lack of effective control over the learning direction of the model during training. To address this issue, we propose a novel approach AGR (Agent-Guided Rationalization), guiding the next action of the... | Jiye Liang, Ru Li, Xiaoli Li, Yunxiao Zhao, Zhiqiang Wang |  |
| 98 |  |  [Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research](https://doi.org/10.18653/v1/2024.acl-short.48) |  | 0 | We analysed a sample of NLP research papers archived in ACL Anthology as an attempt to quantify the degree of openness and the benefit of such an open culture in the NLP community. We observe that papers published in different NLP venues show different patterns related to artefact reuse. We also... | Aloka Fernando, Dilith Jayakody, Nisansa de Silva, Surangika Ranathunga |  |
| 99 |  |  [The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-short.49) |  | 0 | In order to oversee advanced AI systems, it is important to understand their reasons for generating a given output. When prompted, large language models (LLMs) can provide natural language explanations or reasoning traces that sound plausible and receive high ratings from human annotators. However,... | María PérezOrtiz, Nicolas Heess, Noah Y. Siegel, OanaMaria Camburu |  |
| 100 |  |  [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](https://doi.org/10.18653/v1/2024.acl-short.50) |  | 0 | While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision & Language Large Language Models (VLLMs) can mimic this crucial feature of... | Alberto Testoni, Juell Sprott, Sandro Pezzelle |  |
| 101 |  |  [Are LLMs classical or nonmonotonic reasoners? Lessons from generics](https://doi.org/10.18653/v1/2024.acl-short.51) |  | 0 | Recent scholarship on reasoning in LLMs has supplied evidence of impressive performance and flexible adaptation to machine generated or human critique. Nonmonotonic reasoning, crucial to human cognition for navigating the real world, remains a challenging, yet understudied task. In this work, we... | Alina Leidinger, Ekaterina Shutova, Robert van Rooij |  |
| 102 |  |  [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](https://doi.org/10.18653/v1/2024.acl-short.52) |  | 0 | Large language models (LLMs) are highly capable at a variety of tasks given the right prompt, but writing one is still a difficult and tedious process. In this work, we introduce ConstitutionalExperts, a method for learning a prompt consisting of constitutional principles (i.e. rules), given a... | Ann Yuan, Ben Wedin, James Wexler, Nithum Thain, Savvas Petridis |  |
| 103 |  |  [Time Sensitive Knowledge Editing through Efficient Finetuning](https://doi.org/10.18653/v1/2024.acl-short.53) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capability in different tasks and are bringing transformative changes to many domains. However, keeping the knowledge in LLMs up-to-date remains a challenge once pretraining is complete. It is thus essential to design effective methods to... | Ali Mousavi, Armand Joulin, Benjamin Han, Edouard Grave, Kun Qian, Mostafa Arefiyan, Xiou Ge, Yunyao Li |  |
| 104 |  |  [PRewrite: Prompt Rewriting with Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-short.54) |  | 0 | Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a “trial and error” fashion that can be time consuming, ineffective, and sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the... | Michael Bendersky, Mingyang Zhang, Qiaozhu Mei, Spurthi Amba Hombaiah, Weize Kong |  |
| 105 |  |  [Paraphrasing in Affirmative Terms Improves Negation Understanding](https://doi.org/10.18653/v1/2024.acl-short.55) |  | 0 | Negation is a common linguistic phenomenon. Yet language models face challenges with negation in many natural language understanding tasks such as question answering and natural language inference. In this paper, we experiment with seamless strategies that incorporate affirmative interpretations... | Eduardo Blanco, MohammadHossein Rezaei |  |
| 106 |  |  [Exploring Conditional Variational Mechanism to Pinyin Input Method for Addressing One-to-Many Mappings in Low-Resource Scenarios](https://doi.org/10.18653/v1/2024.acl-short.56) |  | 0 | Pinyin input method engine (IME) refers to the transformation tool from pinyin sequence to Chinese characters, which is widely used on mobile phone applications. Due to the homophones, Pinyin IME suffers from the one-to-many mapping problem in the process of pinyin sequences to Chinese characters.... | Bin Sun, Fandong Meng, Hao Zhou, Jianfeng Li, Jie Zhou, Kan Li |  |
| 107 |  |  [Consistency Training by Synthetic Question Generation for Conversational Question Answering](https://doi.org/10.18653/v1/2024.acl-short.57) |  | 0 | Efficiently modeling historical information is a critical component in addressing user queries within a conversational question-answering (QA) context, as historical context plays a vital role in clarifying the user’s questions. However, irrelevant history induces noise in the reasoning process,... | Hamed Hematian Hemati, Hamid Beigy |  |
| 108 |  |  [How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?](https://doi.org/10.18653/v1/2024.acl-short.58) |  | 0 | While machine translation evaluation has been studied primarily for high-resource languages, there has been a recent interest in evaluation for low-resource languages due to the increasing availability of data and models. In this paper, we focus on a zero-shot evaluation setting focusing on... | Ananya Sai, Anoop Kunchukuttan, Anushka Singh, Mitesh M. Khapra, Raj Dabre, Ratish Puduppully |  |
| 109 |  |  [Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-short.59) |  | 0 | Large language models (LLMs) as listwise rerankers have shown impressive zero-shot capabilities in various passage ranking tasks. Despite their success, there is still a gap in existing literature on their effectiveness in reranking low-resource languages. To address this, we investigate how LLMs... | Akintunde Oladipo, Jimmy Lin, Mofetoluwa Adeyemi, Ronak Pradeep |  |
| 110 |  |  [Cross-Modal Projection in Multimodal LLMs Doesn't Really Project Visual Attributes to Textual Space](https://doi.org/10.18653/v1/2024.acl-short.60) |  | 0 | Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock... | Gaurav Verma, Jamelle WatsonDaniels, Kartik Sharma, Minje Choi, Sejoon Oh, Srijan Kumar |  |
| 111 |  |  [Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-short.61) |  | 0 | While the abundance of rich and vast datasets across numerous fields has facilitated the advancement of natural language processing, sectors in need of specialized data types continue to struggle with the challenge of finding quality data. Our study introduces a novel guidance data augmentation... | DuSeong Chang, Hyein Seo, Hyeonseok Kang, Jeesu Jung, Riwoo Chung, Sangkeun Jung |  |
| 112 |  |  [Aligning Large Language Models via Fine-grained Supervision](https://doi.org/10.18653/v1/2024.acl-short.62) |  | 0 | Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by... | Dehong Xu, Faisal Ladhak, Jaeyoung Do, Liang Qiu, Minseok Kim |  |
| 113 |  |  [Annotating FrameNet via Structure-Conditioned Language Generation](https://doi.org/10.18653/v1/2024.acl-short.63) |  | 0 | Despite the remarkable generative capabilities of language models in producing naturalistic language, their effectiveness on explicit manipulation and generation of linguistic structures remain understudied. In this paper, we investigate the task of generating new sentences preserving a given... | Swabha Swayamdipta, Xinyue Cui |  |
| 114 |  |  [DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms](https://doi.org/10.18653/v1/2024.acl-short.64) |  | 0 | Recently, large language models (LLMs) enhanced by self-reflection have achieved promising performance on machine transla004 tion. The key idea is guiding LLMs to generate translation with human-like feedback. However, existing self-reflection methods lack effective feedback information, limiting... | Andong Chen, Kehai Chen, Lianzhang Lou, Min Zhang, Muyun Yang, Tiejun Zhao, Xuefeng Bai, Yang Xiang |  |
| 115 |  |  [Towards Artwork Explanation in Large-scale Vision Language Models](https://doi.org/10.18653/v1/2024.acl-short.65) |  | 0 | Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships... | Hidetaka Kamigaito, Katsuhiko Hayashi, Kazuki Hayashi, Taro Watanabe, Yusuke Sakai |  |
| 116 |  |  [On the Hallucination in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-short.66) |  | 0 | It is widely known that hallucination is a critical issue in Simultaneous Machine Translation (SiMT) due to the absence of source-side information. While many efforts have been made to enhance performance for SiMT, few of them attempt to understand and analyze hallucination in SiMT.Therefore, we... | Kehai Chen, Lemao Liu, Meizhi Zhong, Min Zhang, Mingming Yang, Zhengshan Xue |  |
| 117 |  |  [Self-Augmented In-Context Learning for Unsupervised Word Translation](https://doi.org/10.18653/v1/2024.acl-short.67) |  | 0 | Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of ‘traditional’ mapping-based approaches in the unsupervised scenario where no seed... | Anna Korhonen, Ivan Vulic, Yaoyiran Li |  |
| 118 |  |  [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://doi.org/10.18653/v1/2024.acl-short.68) |  | 0 | We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy... | Bowen Jin, Carl Yang, Joyce C. Ho, May Dongmei Wang, Ran Xu, Wenqi Shi, Yuchen Zhuang, Yue Yu |  |
| 119 |  |  [Frontmatter](https://doi.org/10.18653/v1/2024.acl-long.0) |  | 0 |  |  |  |
| 120 |  |  [Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.1) |  | 0 | Finetuning large language models (LLMs) has been empirically effective on a variety of downstream tasks. Existing approaches to finetuning an LLM either focus on parameter-efficient finetuning, which only updates a small number of trainable parameters, or attempt to reduce the memory footprint... | Dan Zhao, Gabriele Oliaro, Qing Li, Xupeng Miao, Yong Jiang, Zhengxin Zhang, Zhihao Jia, Zhihao Zhang |  |
| 121 |  |  [Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances](https://doi.org/10.18653/v1/2024.acl-long.2) |  | 0 | Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions. Existing methods manifest limitations in leveraging nonverbal information for discerning complex semantics in unsupervised scenarios. This paper introduces a... | Fei Long, Hanlei Zhang, Hua Xu, Kai Gao, Xin Wang |  |
| 122 |  |  [MAGE: Machine-generated Text Detection in the Wild](https://doi.org/10.18653/v1/2024.acl-long.3) |  | 0 | Large language models (LLMs) have achieved human-level text generation, emphasizing the need for effective deepfake text detection to mitigate risks like the spread of fake news and plagiarism. Existing research has been constrained by evaluating detection methods o specific domains or particular... | Leyang Cui, Linyi Yang, Longyue Wang, Qintong Li, Shuming Shi, Wei Bi, Yafu Li, Yue Zhang, Zhilin Wang |  |
| 123 |  |  [PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models](https://doi.org/10.18653/v1/2024.acl-long.4) |  | 0 | The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model... | Chunkit Chan, Dadi Guo, Donghao Li, Duanyi Yao, Haoran Li, Qi Hu, Wei Fan, Xin Liu, Yangqiu Song, Yuan Yao |  |
| 124 |  |  [GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators](https://doi.org/10.18653/v1/2024.acl-long.5) |  | 0 | Recent advances in large language models (LLMs) have stepped forward the development of multilingual speech and machine translation by its reduced representation errors and incorporated external knowledge. However, both translation tasks typically utilize beam search decoding and top-1 hypothesis... | ChaoHan Huck Yang, Chen Chen, Dong Zhang, Engsiong Chng, Ruizhe Li, Yuchen Hu, Zhehuai Chen |  |
| 125 |  |  [Exploring Chain-of-Thought for Multi-modal Metaphor Detection](https://doi.org/10.18653/v1/2024.acl-long.6) |  | 0 | Metaphors are commonly found in advertising and internet memes. However, the free form of internet memes often leads to a lack of high-quality textual data. Metaphor detection demands a deep interpretation of both textual and visual elements, requiring extensive common-sense knowledge, which poses... | Shichen Li, Yanzhi Xu, Yueying Hua, Zhongqing Wang |  |
| 126 |  |  [BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation](https://doi.org/10.18653/v1/2024.acl-long.7) |  | 0 | The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges. Weight quantization has emerged as a widely embraced solution to reduce memory and computational demands. This paper introduces... | Dayou Du, Jiaqi Guo, Ningyi Xu, Shijie Cao, Ting Cao, Xiaowen Chu, Yijia Zhang |  |
| 127 |  |  [A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation](https://doi.org/10.18653/v1/2024.acl-long.8) |  | 0 | Temporal knowledge graph (TKG) reasoning has two settings: interpolation reasoning and extrapolation reasoning. Both of them draw plenty of research interest and have great significance. Methods of the former de-emphasize the temporal correlations among facts sequences, while methods of the latter... | Aiping Li, Han Yu, Kai Chen, Xin Song, Ye Wang, Yitong Li |  |
| 128 |  |  [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.9) |  | 0 | Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignore it or be misled by it. The key reason is that... | Fandong Meng, Huawei Shen, Jie Zhou, Liang Pang, Mo Yu, Shicheng Xu, Xueqi Cheng |  |
| 129 |  |  [CSCD-NS: a Chinese Spelling Check Dataset for Native Speakers](https://doi.org/10.18653/v1/2024.acl-long.10) |  | 0 | In this paper, we present CSCD-NS, the first Chinese spelling check (CSC) dataset designed for native speakers, containing 40,000 samples from a Chinese social platform. Compared with existing CSC datasets aimed at Chinese learners, CSCD-NS is ten times larger in scale and exhibits a distinct error... | Fandong Meng, Jie Zhou, Yong Hu |  |
| 130 |  |  [Evaluating Dynamic Topic Models](https://doi.org/10.18653/v1/2024.acl-long.11) |  | 0 | There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension... | Charu James, Marius Kloft, Mayank Nagda, Nooshin Haji Ghassemi, Sophie Fellenz |  |
| 131 |  |  [How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition](https://doi.org/10.18653/v1/2024.acl-long.12) |  | 0 | Large language models (LLMs) with enormous pre-training tokens and parameters emerge diverse abilities, including math reasoning, codegeneration, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). While the open-source community has explored ad-hoc SFT... | Chang Zhou, Chengpeng Li, Dayiheng Liu, Guanting Dong, Hongyi Yuan, Jingren Zhou, Keming Lu, Mingfeng Xue, Wei Wang, Zheng Yuan |  |
| 132 |  |  [Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification](https://doi.org/10.18653/v1/2024.acl-long.13) |  | 0 | In legal decisions, split votes (SV) occur when judges cannot reach a unanimous decision, posing a difficulty for lawyers who must navigate diverse legal arguments and opinions. In high-stakes domains, %as human-AI interaction systems become increasingly important, understanding the alignment of... | Barbara Plank, Matthias Grabmair, Oana Ichim, Shanshan Xu, T. Y. S. S. Santosh |  |
| 133 |  |  [Inference to the Best Explanation in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.14) |  | 0 | While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process is still poorly understood. This paper proposes IBE-Eval, a framework inspired by philosophical accounts on Inference to the Best Explanation (IBE) to advance the interpretation... | André Freitas, Dhairya Dalal, Marco Valentino, Paul Buitelaar |  |
| 134 |  |  [A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus](https://doi.org/10.18653/v1/2024.acl-long.15) |  | 0 | Natural language inference (NLI), the task of recognizing the entailment relationship in sentence pairs, is an actively studied topic serving as a proxy for natural language understanding. Despite the relevance of the task in building conversational agents and improving text classification, machine... | Cornelia Caragea, Eduard Poesina, Radu Tudor Ionescu |  |
| 135 |  |  [MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering](https://doi.org/10.18653/v1/2024.acl-long.16) |  | 0 | Recent advances in few-shot question answering (QA) mostly rely on the power of pre-trained large language models (LLMs) and fine-tuning in specific settings. Although the pre-training stage has already equipped LLMs with powerful reasoning capabilities, LLMs still need to be fine-tuned to adapt to... | ChoJui Hsieh, HsiangFu Yu, JyunYu Jiang, Wei Wang, WeiCheng Chang, Xiusi Chen |  |
| 136 |  |  [SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs](https://doi.org/10.18653/v1/2024.acl-long.17) |  | 0 | Large language models hold significant potential for integrating various data types, such as text documents and database records, for advanced analytics. However, blending text and numerical data presents substantial challenges. LLMs need to process and cross-reference entities and numbers, handle... | Dong Yu, Fei Liu, Hassan Foroosh, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Yebowen Hu |  |
| 137 |  |  [SciMON: Scientific Inspiration Machines Optimized for Novelty](https://doi.org/10.18653/v1/2024.acl-long.18) |  | 0 | We explore and enhance the ability of neural language models to generate novel scientific directions grounded in literature. Work on literature-based hypothesis generation has traditionally focused on binary link prediction—severely limiting the expressivity of hypotheses. This line of work also... | Doug Downey, Heng Ji, Qingyun Wang, Tom Hope |  |
| 138 |  |  [Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction](https://doi.org/10.18653/v1/2024.acl-long.19) |  | 0 | We introduce EVLGen, a streamlined framework designed for the pre-training of visually conditioned language generation models with high computational demands, utilizing frozen pre-trained large language models (LLMs). The conventional approach in vision-language pre-training (VLP) typically... | Chunhui Zhang, Hongxia Yang, Soroush Vosoughi, Tingkai Liu, Yiren Jian, Yunzhe Tao |  |
| 139 |  |  [Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.20) |  | 0 | As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models. We introduce the concept of Confidence-Probability... | Abhishek Kumar, Ali Emami, Jad Kabbara, Robert Morabito, Sanzhar Umbet |  |
| 140 |  |  [Retrieval-Augmented Multilingual Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.21) |  | 0 | Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time. Updating knowledge via fine-tuning is computationally resource-hungry and not reliable, and so knowledge editing (KE) has developed as an effective and economical alternative to... | Alexandra Birch, Barry Haddow, Weixuan Wang |  |
| 141 |  |  [Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge](https://doi.org/10.18653/v1/2024.acl-long.22) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable success in tasks like the Winograd Schema Challenge (WSC), showcasing advanced textual common-sense reasoning. However, applying this reasoning to multimodal domains, where understanding text and images together is essential, remains a... | Ali Emami, Brendan Park, Madeline Janecek, Naser EzzatiJivan, Yifeng Li |  |
| 142 |  |  [Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.23) |  | 0 | Research on Large Language Models (LLMs) has often neglected subtle biases that, although less apparent, can significantly influence the models’ outputs toward particular social narratives. This study addresses two such biases within LLMs: representative bias, which denotes a tendency of LLMs to... | Abhishek Kumar, Ali Emami, Sarfaroz Yunusov |  |
| 143 |  |  [Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News](https://doi.org/10.18653/v1/2024.acl-long.24) |  | 0 | The mainstream media has much leeway in what it chooses to cover and how it covers it. These choices have real-world consequences on what people know and their subsequent behaviors. However, the lack of objective measures to evaluate editorial choices makes research in this area particularly... | Alexandria Leto, Coen D. Needell, David Rothschild, Elliot Pickens, Maria Leonor Pacheco |  |
| 144 |  |  [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences](https://doi.org/10.18653/v1/2024.acl-long.25) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate... | Feihong He, Furong Huang, Fuxiao Liu, Gedas Bertasius, Hongjin Lu, Huaxiu Yao, Jaehong Yoon, Mohit Bansal, Taixi Lu, Xiaoyu Liu, Xiyao Wang, Yuancheng Xu, Yuhang Zhou |  |
| 145 |  |  [TTM-RE: Memory-Augmented Document-Level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.26) |  | 0 | Document-level relation extraction aims to categorize the association between any two entities within a document.We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels. For... | Chufan Gao, Jimeng Sun, Xuan Wang |  |
| 146 |  |  [Answer is All You Need: Instruction-following Text Embedding via Answering the Question](https://doi.org/10.18653/v1/2024.acl-long.27) |  | 0 | This work aims to build a text embedder that can capture characteristics of texts specified by user instructions clarifying the similarity criterion. While previous methods improve general task awareness by injecting the instruction information into encoding, they fail to be sensitive to clearer... | Gaowen Liu, Jayanth Srinivasa, Jingbo Shang, Letian Peng, Yuwei Zhang, Zihan Wang, Zilong Wang |  |
| 147 |  |  [Explore Spurious Correlations at the Concept Level in Language Models for Text Classification](https://doi.org/10.18653/v1/2024.acl-long.28) |  | 0 | Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label... | Bang An, Furong Huang, Paiheng Xu, Wei Ai, Xiaoyu Liu, Yuhang Zhou |  |
| 148 |  |  [Every Answer Matters: Evaluating Commonsense with Probabilistic Measures](https://doi.org/10.18653/v1/2024.acl-long.29) |  | 0 | Large language models have demonstrated impressive performance on commonsense tasks; however, these tasks are often posed as multiple-choice questions, allowing models to exploit systematic biases. Commonsense is also inherently probabilistic with multiple correct answers. The purpose of “boiling... | Andrew McCallum, Michael Boratko, Nalini Singh, Pranay Kumar Yelugam, Qi Cheng, Tim O'Gorman, Xiang Li |  |
| 149 |  |  [GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis](https://doi.org/10.18653/v1/2024.acl-long.30) |  | 0 | Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study,... | Minghong Fang, Neil Gong, Renjie Pi, Yueqi Xie |  |
| 150 |  |  [Pouring Your Heart Out: Investigating the Role of Figurative Language in Online Expressions of Empathy](https://doi.org/10.18653/v1/2024.acl-long.31) |  | 0 | Empathy is a social mechanism used to support and strengthen emotional connection with others, including in online communities. However, little is currently known about the nature of these online expressions, nor the particular factors that may lead to their improved detection. In this work, we... | Christina Wong, Gyeongeun Lee, Meghan Guo, Natalie Parde |  |
| 151 |  |  [An Information-Theoretic Approach to Analyze NLP Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.32) |  | 0 | Understanding the contribution of the inputs on the output is useful across many tasks. This work provides an information-theoretic framework to analyse the influence of inputs for text classification tasks. Natural language processing (NLP) tasks take either a single or multiple text elements to... | Luran Wang, Mark J. F. Gales, Vatsal Raina |  |
| 152 |  |  [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](https://doi.org/10.18653/v1/2024.acl-long.33) |  | 0 | Conversational systems often rely on embedding models for intent classification and intent clustering tasks. The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for... | Hang Su, Hwanjun Song, Igor Shalyminov, Saab Mansour, Sailik Sengupta, Siffi Singh, Yuwei Zhang |  |
| 153 |  |  [Wav2Gloss: Generating Interlinear Glossed Text from Speech](https://doi.org/10.18653/v1/2024.acl-long.34) |  | 0 | Thousands of the world’s languages are in danger of extinction—a tremendous threat to cultural identities and human language diversity. Interlinear Glossed Text (IGT) is a form of linguistic annotation that can support documentation and resource creation for these languages’ communities. IGT... | David R. Mortensen, Graham Neubig, Jiatong Shi, Kwanghee Choi, Lindia Tjuatja, Lori S. Levin, Nathaniel R. Robinson, Shinji Watanabe, Taiqi He |  |
| 154 |  |  [Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification](https://doi.org/10.18653/v1/2024.acl-long.35) |  | 0 | Is it possible accurately classify political relations within evolving event ontologies without extensive annotations? This study investigates zero-shot learning methods that use expert knowledge from existing annotation codebook, and evaluates the performance of advanced ChatGPT (GPT-3.5/4) and a... | Erick Skorupa Parolin, Javier Osorio, Latifur Khan, Patrick T. Brandt, Vito D'Orazio, Yibo Hu |  |
| 155 |  |  [SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.36) |  | 0 | Compositional generalization is an important ability of language models and has many different manifestations. For data-to-text generation, previous research on this ability is limited to a single manifestation called Systematicity and lacks consideration of large language models (LLMs), which... | Houfeng Wang, Ziyao Xu |  |
| 156 |  |  [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.37) |  | 0 | Embodied Instruction Following (EIF) is a crucial task in embodied learning, requiring agents to interact with their environment through egocentric observations to fulfill natural language instructions. Recent advancements have seen a surge in employing large language models (LLMs) within a... | Bang Liu, Haochen Shi, MarcAlexandre Côté, Xingdi Yuan, Zhiyuan Sun |  |
| 157 |  |  [Multimodal Instruction Tuning with Conditional Mixture of LoRA](https://doi.org/10.18653/v1/2024.acl-long.38) |  | 0 | Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in diverse tasks across different domains, with an increasing focus on improving their zero-shot generalization capabilities for unseen multimodal tasks. Multimodal instruction tuning has emerged as a successful... | Lifu Huang, Qifan Wang, Wenpeng Yin, Ying Shen, Yu Cheng, Zhiyang Xu |  |
| 158 |  |  [DocLens: Multi-aspect Fine-grained Medical Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.39) |  | 0 | Medical text generation aims to assist with administrative work and highlight salient information to support decision-making.To reflect the specific requirements of medical text, in this paper, we propose a set of metrics to evaluate the completeness, conciseness, and attribution of the generated... | Carolyn P. Rosé, Cliff Wong, Hao Cheng, Hoifung Poon, Pengfei Liu, Sheng Zhang, Tristan Naumann, Yiqing Xie, Zelalem Gero |  |
| 159 |  |  [FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability](https://doi.org/10.18653/v1/2024.acl-long.40) |  | 0 | This paper presents FoFo, a pioneering benchmark for evaluating large language models’ (LLMs) ability to follow complex, domain-specific formats, a crucial yet under-examined capability for their application as AI agents. Despite LLMs’ advancements, existing benchmarks fail to assess their... | Caiming Xiong, Chen Xing, Congying Xia, Jiangshu Du, Ran Xu, Wenpeng Yin, Xinyi Yang, Yihao Feng |  |
| 160 |  |  [Hyper-CL: Conditioning Sentence Representations with Hypernetworks](https://doi.org/10.18653/v1/2024.acl-long.41) |  | 0 | While the introduction of contrastive learning frameworks in sentence representation learning has significantly contributed to advancements in the field, it still remains unclear whether state-of-the-art sentence embeddings can capture the fine-grained semantics of sentences, particularly when... | Changhyeon Kim, Jii Cha, Taeuk Kim, Young Hyun Yoo |  |
| 161 |  |  [Analysis of Multi-Source Language Training in Cross-Lingual Transfer](https://doi.org/10.18653/v1/2024.acl-long.42) |  | 0 | The successful adaptation of multilingual language models (LMs) to a specific language-task pair critically depends on the availability of data tailored for that condition. While cross-lingual transfer (XLT) methods have contributed to addressing this data scarcity problem, there still exists... | Jihun Choi, Jinhyeon Kim, Seong Hoon Lim, Taejun Yun, Taeuk Kim |  |
| 162 |  |  [ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions](https://doi.org/10.18653/v1/2024.acl-long.43) |  | 0 | We present ABEX, a novel and effective generative data augmentation methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms of an input document – we first convert a document into its concise,... | Chandra Kiran Reddy Evuru, Dinesh Manocha, Ramaneswaran S., S. Sakshi, Sonal Kumar, Sreyan Ghosh, Utkarsh Tyagi |  |
| 163 |  |  [The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants](https://doi.org/10.18653/v1/2024.acl-long.44) |  | 0 | We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource... | Abhinandan Krishnan, Benjamin Muller, Davis Liang, Donald Husa, Lucas Bandarkar, Luke Zettlemoyer, Madian Khabsa, Mikel Artetxe, Naman Goyal, Satya Narayan Shukla |  |
| 164 |  |  [Learn from Failure: Fine-tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving](https://doi.org/10.18653/v1/2024.acl-long.45) |  | 0 | Recent advances in Automated Theorem Proving have shown the effectiveness of leveraging a (large) language model that generates tactics (i.e. proof steps) to search through proof states. The current model, while trained solely on successful proof paths, faces a discrepancy at the inference stage,... | Chenyang An, Emily First, Jiayun Zhang, Jingbo Shang, Letian Peng, Qihao Ye, Sorin Lerner, Zhibo Chen, Zihan Wang |  |
| 165 |  |  [Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach](https://doi.org/10.18653/v1/2024.acl-long.46) |  | 0 | In this paper, we primarily address the issue of dialogue-form context query within the interactive text-to-image retrieval task. Our methodology, PlugIR, actively utilizes the general instruction-following capability of LLMs in two ways. First, by reformulating the dialogue-form context, we... | Jihun Yi, Junsung Park, Saehyung Lee, Sangwon Yu, Sungroh Yoon |  |
| 166 |  |  [IMBUE: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction](https://doi.org/10.18653/v1/2024.acl-long.47) |  | 0 | Navigating certain communication situations can be challenging due to individuals’ lack of skills and the interference of strong emotions. However, effective learning opportunities are rarely accessible. In this work, we conduct a human-centered study that uses language models to simulate bespoke... | Adam S. Miner, Ashish Sharma, Christopher Michael Rytting, Inna W. Lin, Jina Suh, Tim Althoff |  |
| 167 |  |  [Token-wise Influential Training Data Retrieval for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.48) |  | 0 | Given a Large Language Model (LLM) generation, how can we identify which training data led to this generation? In this paper, we proposed RapidIn, a scalable framework adapting to LLMs for estimating the influence of each training data. The proposed framework consists of two stages: caching and... | Huawei Lin, Jikai Long, Weijie Zhao, Zhaozhuo Xu |  |
| 168 |  |  [Tree-of-Counterfactual Prompting for Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.49) |  | 0 | Stance detection enables the inference of attitudes from human communications. Automatic stance identification was mostly cast as a classification problem. However, stance decisions involve complex judgments, which can be nowadays generated by prompting Large Language Models (LLMs). In this paper... | Maxwell A. Weinzierl, Sanda M. Harabagiu |  |
| 169 |  |  [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://doi.org/10.18653/v1/2024.acl-long.50) |  | 0 | Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively... | Daniel Fried, Graham Neubig, Jing Yu Koh, Lawrence Jang, Ming Chong Lim, PoYu Huang, Robert Lo, Russ Salakhutdinov, Shuyan Zhou, Vikram Duvvur |  |
| 170 |  |  [FineSurE: Fine-grained Summarization Evaluation using LLMs](https://doi.org/10.18653/v1/2024.acl-long.51) |  | 0 | Automated evaluation is crucial for streamlining text summarization benchmarking and model development, given the costly and time-consuming nature of human evaluation. Traditional methods like ROUGE do not correlate well with human judgment, while recently proposed LLM-based metrics provide only... | Hang Su, Hwanjun Song, Igor Shalyminov, Jason Cai, Saab Mansour |  |
| 171 |  |  [Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback](https://doi.org/10.18653/v1/2024.acl-long.52) |  | 0 | Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). Previous approaches for VLMMs involve Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and additional learnable parameters. Here,... | Daechul Ahn, Dongyeop Kang, Jonghyun Choi, Youngjae Yu, Yura Choi |  |
| 172 |  |  [Prompt Refinement with Image Pivot for Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.53) |  | 0 | For text-to-image generation, automatically refining user-provided natural language prompts into the keyword-enriched prompts favored by systems is essential for the user experience. Such a prompt refinement process is analogous to translating the prompt from “user languages” into “system... | Jiaxin Mao, Jingtao Zhan, Qingyao Ai, Shaoping Ma, Tao Mei, Ting Yao, Yingwei Pan, Yiqun Liu |  |
| 173 |  |  [Striking Gold in Advertising: Standardization and Exploration of Ad Text Generation](https://doi.org/10.18653/v1/2024.acl-long.54) |  | 0 | In response to the limitations of manual ad creation, significant research has been conducted in the field of automatic ad text generation (ATG). However, the lack of comprehensive benchmarks and well-defined problem sets has made comparing different methods challenging. To tackle these challenges,... | Akihiko Kato, Masato Mita, Peinan Zhang, Soichiro Murakami |  |
| 174 |  |  [AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation](https://doi.org/10.18653/v1/2024.acl-long.55) |  | 0 | Abstraction ability is crucial in human intelligence, which can also benefit various tasks in NLP study. Existing work shows that LLMs are deficient in abstract ability, and how to improve it remains unexplored. In this work, we design the framework AbsInstruct to enhance LLMs’ abstraction ability... | Ginny Y. Wong, Hongming Zhang, Qing Zong, Sehyun Choi, Simon See, Tianqing Fang, Wei Fan, Xin Liu, Yangqiu Song, Zhaowei Wang |  |
| 175 |  |  [Reflect-RL: Two-Player Online RL Fine-Tuning for LMs](https://doi.org/10.18653/v1/2024.acl-long.56) |  | 0 | As language models (LMs) demonstrate their capabilities in various fields, their application to tasks requiring multi-round interactions has become increasingly popular. These tasks usually have complex dynamics, so supervised fine-tuning (SFT) on a limited offline dataset does not yield good... | Beibin Li, Runlong Zhou, Simon S. Du |  |
| 176 |  |  [Can ChatGPT's Performance be Improved on Verb Metaphor Detection Tasks? Bootstrapping and Combining Tacit Knowledge](https://doi.org/10.18653/v1/2024.acl-long.57) |  | 0 | Metaphors detection, as an important task in the field of NLP, has been receiving sustained academic attention in recent years. Current researches focus supervised metaphors detection systems, which usually require large-scale, high-quality labeled data support. The emerge of large language models... | Cheng Yang, Puli Chen, Qingbao Huang |  |
| 177 |  |  [Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.58) |  | 0 | The surge in Large Language Models (LLMs) has revolutionized natural language processing, but fine-tuning them for specific tasks often encounters challenges in balancing performance and preserving general instruction-following abilities. In this paper, we posit that the distribution gap between... | Han Wang, Haozhe Feng, Minfeng Zhu, Qian Liu, Tianyu Pang, Wei Chen, Zhaorui Yang |  |
| 178 |  |  [An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.acl-long.59) |  | 0 | Retrieval-augmented generation integrates the capabilities of large language models with relevant information retrieved from an extensive corpus, yet encounters challenges when confronted with real-world noisy data. One recent solution is to train a filter module to find relevant content but only... | Bing Qin, Haotian Wang, Jingchang Chen, Kun Zhu, Qianglong Chen, Weijiang Yu, Xiaocheng Feng, Xiyuan Du, Yuxuan Gu, Zheng Chu |  |
| 179 |  |  [RORA: Robust Free-Text Rationale Evaluation](https://doi.org/10.18653/v1/2024.acl-long.60) |  | 0 | Free-text rationales play a pivotal role in explainable NLP, bridging the knowledge and reasoning gaps behind a model’s decision-making. However, due to the diversity of potential reasoning paths and a corresponding lack of definitive ground truth, their evaluation remains a challenge. Existing... | Anqi Liu, Benjamin Van Durme, Daniel Khashabi, Hanjie Chen, Yining Lu, Zhengping Jiang |  |
| 180 |  |  [Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents](https://doi.org/10.18653/v1/2024.acl-long.61) |  | 0 | Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise... | Bingxiang He, Cheng Qian, Jia Deng, Jie Zhou, Maosong Sun, Xin Cong, Yankai Lin, Yujia Qin, Zhiyuan Liu, Zhong Zhang, Zhong Zhuang |  |
| 181 |  |  [InstructProtein: Aligning Human and Protein Language via Knowledge Instruction](https://doi.org/10.18653/v1/2024.acl-long.62) |  | 0 | Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in... | Huajun Chen, Keyan Ding, Ming Qin, Qiang Zhang, Xiang Zhuang, Xiaotong Li, Zeyuan Wang |  |
| 182 |  |  [ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.63) |  | 0 | In this position paper, we argue that human evaluation of generative large language models (LLMs) should be a multidisciplinary undertaking that draws upon the insights from disciplines such as user experience research and human behavioral psychology to ensure that the experimental design and... | Aparna Elangovan, Dan Roth, Lei Xu, Ling Liu, Sravan Babu Bodapati |  |
| 183 |  |  [Linguistically Conditioned Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.64) |  | 0 | Semantic textual similarity (STS) is a fundamental NLP task that measures the semantic similarity between a pair of sentences. In order to reduce the inherent ambiguity posed from the sentences, a recent work called Conditional STS (C-STS) has been proposed to measure the sentences’ similarity... | Bingyang Ye, James Pustejovsky, Jingxuan Tu, Keer Xu, Kyeongmin Rim, Liulu Yue |  |
| 184 |  |  [Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future](https://doi.org/10.18653/v1/2024.acl-long.65) |  | 0 | Reasoning, a fundamental cognitive process integral to human intelligence, has garnered substantial interest within artificial intelligence.Notably, recent studies have revealed that chain-of-thought prompting significantly enhances LLM’s reasoning capabilities, which attracts widespread attention... | Bing Qin, Haotian Wang, Jingchang Chen, Ming Liu, Qianglong Chen, Tao He, Ting Liu, Weihua Peng, Weijiang Yu, Zheng Chu |  |
| 185 |  |  [TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.66) |  | 0 | Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world.Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark.To address this, we propose TimeBench, a... | Bing Qin, Haotian Wang, Jingchang Chen, Ming Liu, Qianglong Chen, Weijiang Yu, Zheng Chu |  |
| 186 |  |  [BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.67) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning capabilities.Nevertheless, they still suffer from factual errors when tackling knowledge-intensive tasks.Retrieval-augmented reasoning represents a promising approach.However, significant challenges still persist, including inaccurate... | Bing Qin, Haotian Wang, Jingchang Chen, Kun Zhu, Ming Liu, Qianglong Chen, Weijiang Yu, Xiyuan Du, Zheng Chu |  |
| 187 |  |  [ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base](https://doi.org/10.18653/v1/2024.acl-long.68) |  | 0 | Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a... | Changzhi Sun, Deqing Yang, Jiangjie Chen, Jiaqing Liang, Siyu Yuan, Yanghua Xiao |  |
| 188 |  |  [TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation](https://doi.org/10.18653/v1/2024.acl-long.69) |  | 0 | A practical dialogue system requires the capacity for ongoing skill acquisition and adaptability to new tasks while preserving prior knowledge. However, current methods for Continual Dialogue State Tracking (DST), a crucial function of dialogue systems, struggle with the catastrophic forgetting... | Bo Liu, Guangyuan Shi, XiaoMing Wu, Xu Chu, Yongxin Xu, Yujie Feng |  |
| 189 |  |  [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://doi.org/10.18653/v1/2024.acl-long.70) |  | 0 | In the era of large language models, Mixture-of-Experts (MoE) is a promising architecture for managing computational costs when scaling up model parameters. However, conventional MoE architectures like GShard, which activate the top-K out of N experts, face challenges in ensuring expert... | Chenggang Zhao, Chengqi Deng, Chong Ruan, Damai Dai, Deli Chen, Fuli Luo, Huazuo Gao, Jiashi Li, Panpan Huang, R. X. Xu, Wangding Zeng, Wenfeng Liang, Xingkai Yu, Y. K. Li, Y. Wu, Zhenda Xie, Zhifang Sui |  |
| 190 |  |  [Grounding Language Model with Chunking-Free In-Context Retrieval](https://doi.org/10.18653/v1/2024.acl-long.71) |  | 0 | This paper presents a novel Chunking-Free In-Context (CFIC) retrieval approach, specifically tailored for Retrieval-Augmented Generation (RAG) systems. Traditional RAG systems often struggle with grounding responses using precise evidence text due to the challenges of processing lengthy documents... | Hongjin Qian, Kelong Mao, Yujia Zhou, Zheng Liu, Zhicheng Dou |  |
| 191 |  |  [Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation](https://doi.org/10.18653/v1/2024.acl-long.72) |  | 0 | Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains... | Jiaxin Bai, Tianshi Zheng, Xin Liu, Yangqiu Song, Yicheng Wang, Yue Guo |  |
| 192 |  |  [Active Prompting with Chain-of-Thought for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.73) |  | 0 | The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs’ ability to produce high-quality answers. In... | Pengcheng Wang, Rui Pan, Shizhe Diao, Tong Zhang, Xiang Liu, Yong Lin |  |
| 193 |  |  [EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs](https://doi.org/10.18653/v1/2024.acl-long.74) |  | 0 | We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample... | Bo Liu, Guangyuan Shi, Qijiong Liu, Xiangyu Zhao, XiaoMing Wu |  |
| 194 |  |  [Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search](https://doi.org/10.18653/v1/2024.acl-long.75) |  | 0 | In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the... | Haochen Li, Xin Zhou, Zhiqi Shen |  |
| 195 |  |  [A Multidimensional Framework for Evaluating Lexical Semantic Change with Social Science Applications](https://doi.org/10.18653/v1/2024.acl-long.76) |  | 0 | Historical linguists have identified multiple forms of lexical semantic change. We present a three-dimensional framework for integrating these forms and a unified computational methodology for evaluating them concurrently. The dimensions represent increases or decreases in semantic 1) sentiment... | Ekaterina Vylomova, Naomi Baes, Nick Haslam |  |
| 196 |  |  [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](https://doi.org/10.18653/v1/2024.acl-long.77) |  | 0 | Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model’s ability, which may not be feasible in real-world applications. When conducting continual learning based on a... | Ante Wang, Chengyi Yang, Jianheng Huang, Jinsong Su, Junfeng Yao, Leyang Cui, Linfeng Song, Xinting Liao |  |
| 197 |  |  [Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency](https://doi.org/10.18653/v1/2024.acl-long.78) |  | 0 | Large language models (LLMs) have exhibited remarkable ability in code generation. However, generating the correct solution in a single attempt still remains a challenge. Prior works utilize verification properties in software engineering to verify and re-rank solutions in a majority voting manner.... | Baizhou Huang, Nan Duan, Shuai Lu, Xiaojun Wan |  |
| 198 |  |  [Citation-Enhanced Generation for LLM-based Chatbots](https://doi.org/10.18653/v1/2024.acl-long.79) |  | 0 | Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability.... | Junkai Li, Weitao Li, Weizhi Ma, Yang Liu |  |
| 199 |  |  [Transitive Consistency Constrained Learning for Entity-to-Entity Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.80) |  | 0 | Entity-to-entity stance detection identifies the stance between a pair of entities with a directed link that indicates the source, target and polarity. It is a streamlined task without the complex dependency structure for structural sentiment analysis, while it is more informative compared to most... | Alexander Hauptmann, Eduard H. Hovy, Haoyang Wen |  |
| 200 |  |  [Feature-Adaptive and Data-Scalable In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.81) |  | 0 | In-context learning (ICL), which promotes inference with several demonstrations, has become a widespread paradigm to stimulate LLM capabilities for downstream tasks. Due to context length constraints, it cannot be further improved in spite of more training data, and general features directly from... | Guoqing Jin, Jiahao Li, Licheng Zhang, Quan Wang, Zhendong Mao |  |
| 201 |  |  [Probing the Multi-turn Planning Capabilities of LLMs via 20 Question Games](https://doi.org/10.18653/v1/2024.acl-long.82) |  | 0 | Large language models (LLMs) are effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification... | Jiarui Lu, Navdeep Jaitly, Yizhe Zhang |  |
| 202 |  |  [WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.83) |  | 0 | To mitigate the potential misuse of large language models (LLMs), recent research has developed watermarking algorithms, which restrict the generation process to leave an invisible trace for watermark detection. Due to the two-stage nature of the task, most studies evaluate the generation and... | Jifan Yu, Juanzi Li, Lei Hou, Shangqing Tu, Yuliang Sun, Yushi Bai |  |
| 203 |  |  [Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models](https://doi.org/10.18653/v1/2024.acl-long.84) |  | 0 | Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences. While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of... | Chao Lou, Kewei Tu, Yida Zhao |  |
| 204 |  |  [A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation](https://doi.org/10.18653/v1/2024.acl-long.85) |  | 0 | Simultaneous translation models play a crucial role in facilitating communication. However, existing research primarily focuses on text-to-text or speech-to-text models, necessitating additional cascade components to achieve speech-to-speech translation. These pipeline methods suffer from error... | Min Zhang, Qingkai Fang, Shaolei Zhang, Shoutao Guo, Yang Feng, Zhengrui Ma |  |
| 205 |  |  [Probing Language Models for Pre-training Data Detection](https://doi.org/10.18653/v1/2024.acl-long.86) |  | 0 | Large Language Models (LLMs) have shown their impressive capabilities, while also raising concerns about the data contamination problems due to privacy issues and leakage of benchmark datasets in the pre-training phase. Therefore, it is vital to detect the contamination by checking whether an LLM... | Bing Liu, Chuanyuan Tan, Haonan Lu, Tong Zhu, Wenliang Chen, Zhenhua Liu |  |
| 206 |  |  [Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.87) |  | 0 | The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for swift and precise analysis of complex events.We refer to the complex events composed of many news articles over an extended period as Temporal Complex Event (TCE). This paper proposes a... | Chenchen Ye, Lizi Liao, TatSeng Chua, Yixin Cao, Yunshan Ma, Zhihan Zhang |  |
| 207 |  |  [IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation](https://doi.org/10.18653/v1/2024.acl-long.88) |  | 0 | Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. Current language model agents mainly focus on reasonable behaviors from the level of individuals, and their behaviors might be hard to constraint on the level of the whole... | Kai Yu, LiMin Lin, Lu Chen, Senyu Han, Zhengshan Xu |  |
| 208 |  |  [Language Model Adaption for Reinforcement Learning with Natural Language Action Space](https://doi.org/10.18653/v1/2024.acl-long.89) |  | 0 | Reinforcement learning with natural language action space often suffers from the curse of dimensionality due to the combinatorial nature of the natural language. Previous research leverages pretrained language models to capture action semantics and reduce the size of the action space. However,... | Deheng Ye, Jiachen Li, Jiangxing Wang, Xiao Han, Zongqing Lu |  |
| 209 |  |  [Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues](https://doi.org/10.18653/v1/2024.acl-long.90) |  | 0 | We investigate intention detection in persuasive multi-turn dialogs employing the largest available Large Language Models (LLMs).Much of the prior research measures the intention detection capability of machine learning models without considering the conversational history.To evaluate LLMs’... | Hiromasa Sakurai, Yusuke Miyao |  |
| 210 |  |  [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://doi.org/10.18653/v1/2024.acl-long.91) |  | 0 | In long context scenarios, large language models (LLMs) face three main challenges: higher computational cost, performance reduction, and position bias. Research indicates that LLM performance hinges on the density and position of key information in the input prompt. Inspired by these findings, we... | ChinYew Lin, Dongsheng Li, Huiqiang Jiang, Lili Qiu, Qianhui Wu, Xufang Luo, Yuqing Yang |  |
| 211 |  |  [Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.92) |  | 0 | Persuasive dialogue requires multi-turn following and planning abilities to achieve the goal of persuading users, which is still challenging even for state-of-the-art large language models (LLMs). Previous works focus on retrieval-based models or generative models in a specific domain due to a lack... | Chuhao Jin, Huan Chen, Kening Ren, Lingzhen Kong, Ruihua Song, Xiting Wang |  |
| 212 |  |  [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://doi.org/10.18653/v1/2024.acl-long.93) |  | 0 | Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative... | Jimin Huang, Kailai Yang, Mengxi Xiao, Min Peng, Qianqian Xie, Weiguang Han, Zhicheng Liu, Ziyan Kuang |  |
| 213 |  |  [Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.94) |  | 0 | The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, in real-world applications, the presence of various missing modality cases often leads to a degradation in the model’s performance. In this work, we propose a novel... | Tao Jin, Zhou Zhao, Zirun Guo |  |
| 214 |  |  [An Effective Pronunciation Assessment Approach Leveraging Hierarchical Transformers and Pre-training Strategies](https://doi.org/10.18653/v1/2024.acl-long.95) |  | 0 | Automatic pronunciation assessment (APA) manages to quantify a second language (L2) learner’s pronunciation proficiency in a target language by providing fine-grained feedback with multiple pronunciation aspect scores at various linguistic levels. Most existing efforts on APA typically parallelize... | Berlin Chen, BiCheng Yan, HsinWei Wang, JiunTing Li, TienHong Lo, WeiCheng Chao, YiCheng Wang, YungChang Hsu |  |
| 215 |  |  [Detection-Correction Structure via General Language Model for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.acl-long.96) |  | 0 | Grammatical error correction (GEC) is a task dedicated to rectifying texts with minimal edits, which can be decoupled into two components: detection and correction. However, previous works have predominantly focused on direct correction, with no prior efforts to integrate both into a single model.... | Houfeng Wang, Wei Li |  |
| 216 |  |  [Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer](https://doi.org/10.18653/v1/2024.acl-long.97) |  | 0 | While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper, we introduce Generative Pre-trained Speech Transformer (GPST), a hierarchical transformer designed... | Dan Su, Dong Yu, Linli Xu, Liqiang He, Yongxin Zhu |  |
| 217 |  |  [Selene: Pioneering Automated Proof in Software Verification](https://doi.org/10.18653/v1/2024.acl-long.98) |  | 0 | Ensuring correctness is a pivotal aspect of software engineering. Among the various strategies available, software verification offers a definitive assurance of correctness. Nevertheless, writing verification proofs is resource-intensive and manpower-consuming, and there is a great need to automate... | Lichen Zhang, Nan Duan, Shuai Lu |  |
| 218 |  |  [Dissecting Human and LLM Preferences](https://doi.org/10.18653/v1/2024.acl-long.99) |  | 0 | As a relative quality comparison of model responses, human and Large Language Model (LLM) preferences serve as common alignment goals in model fine-tuning and criteria in evaluation. Yet, these preferences merely reflect broad tendencies, resulting in less explainable and controllable models with... | Fan Zhou, Hai Zhao, Junlong Li, Pengfei Liu, Shichao Sun, Yikai Zhang |  |
| 219 |  |  [UniCoder: Scaling Code Large Language Model via Universal Code](https://doi.org/10.18653/v1/2024.acl-long.100) |  | 0 | Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks.When applying LLMs for code generation, recent works mainly focus on directing the models to articulate intermediate... | Bing Wang, Hongcheng Guo, Jiaheng Liu, Jian Yang, Linzheng Chai, Liqun Yang, Tao Sun, Yuwei Yin, Zhoujun Li |  |
| 220 |  |  [AoE: Angle-optimized Embeddings for Semantic Textual Similarity](https://doi.org/10.18653/v1/2024.acl-long.101) |  | 0 | Text embedding is pivotal in semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. STS learning largely relies on the cosine function as the optimization objective to reflect semantic similarity. However, the cosine has saturation zones... | Jing Li, Xianming Li |  |
| 221 |  |  [InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews](https://doi.org/10.18653/v1/2024.acl-long.102) |  | 0 | Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether RPAs accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the... | Cheng Li, Haoran Guo, Jentse Huang, Jiangjie Chen, Quan Tu, Rui Xu, Siyu Yuan, Wei Wang, Xintao Wang, Yanghua Xiao, Yaying Fei, Yunze Xiao, Ziang Leng |  |
| 222 |  |  [Does DetectGPT Fully Utilize Perturbation? Bridging Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better](https://doi.org/10.18653/v1/2024.acl-long.103) |  | 0 | The burgeoning generative capabilities of large language models (LLMs) have raised growing concerns about abuse, demanding automatic machine-generated text detectors. DetectGPT, a zero-shot metric-based detector, first introduces perturbation and shows great performance improvement. However, in... | Chao Shen, Chengzhengxu Li, Shengchao Liu, Xiaoming Liu, Yichen Wang, Yu Lan, Zehua Cheng, Zhaohan Zhang |  |
| 223 |  |  [AFaCTA: Assisting the Annotation of Factual Claim Detection with Reliable LLM Annotators](https://doi.org/10.18653/v1/2024.acl-long.104) |  | 0 | With the rise of generative AI, automated fact-checking methods to combat misinformation are becoming more and more important. However, factual claim detection, the first step in a fact-checking pipeline, suffers from two key issues that limit its scalability and generalizability: (1) inconsistency... | Dominik Stammbach, Elliott Ash, Jingwei Ni, Markus Leippold, Minjing Shi, Mrinmaya Sachan |  |
| 224 |  |  [Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering](https://doi.org/10.18653/v1/2024.acl-long.105) |  | 0 | Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for various research and practical endeavors. One avenue in reaching this goal is basing the answers on reliable sources. However, this Evidence-Based QA has proven to work insufficiently with LLMs in... | Elliott Ash, Jingwei Ni, Markus Leippold, Mathias Kraus, Tobias Schimanski |  |
| 225 |  |  [LoRAMoE: Alleviating World Knowledge Forgetting in Large Language Models via MoE-Style Plugin](https://doi.org/10.18653/v1/2024.acl-long.106) |  | 0 | Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to align with human instructions and enhance their capabilities in downstream tasks. Substantially increasing instruction data is a direct solution to align the model with a broader range of downstream... | Enyu Zhou, Jiang Zhu, Limao Xiong, Qi Zhang, Rui Zheng, Shihan Dou, Shiliang Pu, Songyang Gao, Tao Gui, Wei Shen, Xiao Wang, Xiaoran Fan, Xuanjing Huang, Yan Liu, Yuhao Zhou, Zhiheng Xi |  |
| 226 |  |  [Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation](https://doi.org/10.18653/v1/2024.acl-long.107) |  | 0 | Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., ”hallucinations”, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this... | Baolin Peng, Haitao Mi, Helen Meng, Jingyan Zhou, Lifeng Jin, Linfeng Song, Xiaoying Zhang, Ye Tian |  |
| 227 |  |  [M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions](https://doi.org/10.18653/v1/2024.acl-long.108) |  | 0 | Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant memories from an external database. However, existing RAG methods typically organize all memories in a whole database, potentially limiting focus on crucial memories and introducing noise. In this... | Jieer Ouyang, Shu Xian Teo, Wei Shi, Yongjun Xu, Zheng Wang |  |
| 228 |  |  [AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension](https://doi.org/10.18653/v1/2024.acl-long.109) |  | 0 | Recently, instruction-following audio-language models have received broad attention for human-audio interaction. However, the absence of benchmarks capable of evaluating audio-centric interaction capabilities has impeded advancements in this field. Previous models primarily focus on assessing... | Chang Zhou, Jin Xu, Jingren Zhou, Qian Yang, Wenrui Liu, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Yunfei Chu, Zhou Zhao, Ziyue Jiang |  |
| 229 |  |  [Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies](https://doi.org/10.18653/v1/2024.acl-long.110) |  | 0 | Ten years ago a single metric, BLEU, governed progress in machine translation research. For better or worse, there is no such consensus today, and consequently it is difficult for researchers to develop and retain intuitions about metric deltas that drove earlier research and deployment decisions.... | Christian Federmann, Matt Post, Tom Kocmi, Vilém Zouhar |  |
| 230 |  |  [ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.111) |  | 0 | Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. This development underscores the urgent need for evaluating value orientations and understanding of LLMs to ensure their responsible integration into public-facing applications. This work... | Guojie Song, Hanjun Fang, Haoran Ye, Xin Zhang, Yuanyi Ren |  |
| 231 |  |  [DM-BLI: Dynamic Multiple Subspaces Alignment for Unsupervised Bilingual Lexicon Induction](https://doi.org/10.18653/v1/2024.acl-long.112) |  | 0 | Unsupervised bilingual lexicon induction (BLI) task aims to find word translations between languages and has achieved great success in similar language pairs. However, related works mostly rely on a single linear mapping for language alignment and fail on distant or low-resource language pairs,... | Ling Hu, Yuemei Xu |  |
| 232 |  |  [SparseFit: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.113) |  | 0 | Models that generate natural language explanations (NLEs) for their predictions have recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers at training time, which can be expensive and potentially infeasible for... | Jesus Solano, Mardhiyah Sanni, OanaMaria Camburu, Pasquale Minervini |  |
| 233 |  |  [Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation](https://doi.org/10.18653/v1/2024.acl-long.114) |  | 0 | The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper... | Bo Li, Chao Zhang, ChungCheng Chiu, Junwen Bai, Philip C. Woodland, Qiujia Li, Tara N. Sainath, Wen Wu |  |
| 234 |  |  [REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation](https://doi.org/10.18653/v1/2024.acl-long.115) |  | 0 | Open domain question answering (ODQA) aims to answer questions with knowledge from an external corpus. Fusion-in-Decoder (FiD) is an effective retrieval-augmented reader model to address this task. Given that FiD independently encodes passages, which overlooks the semantic relationships between... | Craig MacDonald, Jinyuan Fang, Zaiqiao Meng |  |
| 235 |  |  [Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks](https://doi.org/10.18653/v1/2024.acl-long.116) |  | 0 | Disentangled latent spaces usually have better semantic separability and geometrical properties, which leads to better interpretability and more controllable data generation. While this has been well investigated in Computer Vision, in tasks such as image disentanglement, in the NLP domain,... | André Freitas, Danilo S. Carvalho, Yingji Zhang |  |
| 236 |  |  [MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation](https://doi.org/10.18653/v1/2024.acl-long.117) |  | 0 | A story premise succinctly defines a story’s main idea, foundation, and trajectory. It serves as the initial trigger in automatic story generation. Existing sources of story premises are limited by a lack of diversity, uneven quality, and high costs that make them difficult to scale. In response,... | Pengfei Liu, Yan Ma, Yu Qiao |  |
| 237 |  |  [Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization](https://doi.org/10.18653/v1/2024.acl-long.118) |  | 0 | Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited set of labeled texts, alongside plenty of unlabeled texts that include both in-distribution and out-of-distribution examples. In this paper, we revisit the main challenge in OSTC, i.e., outlier... | Chunming Hu, Junchi Chen, Junfan Chen, Richong Zhang |  |
| 238 |  |  [ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages](https://doi.org/10.18653/v1/2024.acl-long.119) |  | 0 | Tool learning is widely acknowledged as a foundational approach or deploying large language models (LLMs) in real-world scenarios. While current research primarily emphasizes leveraging tools to augment LLMs, it frequently neglects emerging safety considerations tied to their application. To fill... | Caishuang Huang, Guanyu Li, Junjie Ye, Qi Zhang, Sixian Li, Songyang Gao, Tao Gui, Xuanjing Huang, Yilong Wu |  |
| 239 |  |  [A synthetic data approach for domain generalization of NLI models](https://doi.org/10.18653/v1/2024.acl-long.120) |  | 0 | Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfulness of model-generated text. There are several large scale NLI datasets today,... | Alex Fabrikant, Andrey Petrov, Annie Louis, Mohammad Javad Hosseini |  |
| 240 |  |  [Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild](https://doi.org/10.18653/v1/2024.acl-long.121) |  | 0 | The principle of continual relation extraction (CRE) involves adapting to emerging novel relations while preserving old knowledge. Existing CRE approaches excel in preserving old knowledge but falter when confronted with contaminated data streams, likely due to an artificial assumption of no... | Jingyi Liu, Qi Zhang, Rui Zheng, Tao Gui, Ting Wu, Xuanjing Huang |  |
| 241 |  |  [LRQuant: Learnable and Robust Post-Training Quantization for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.122) |  | 0 | Post-training quantization (PTQ) for large language models (LLMs) significantly accelerates model inference and relieves memory constraints, without incurring model training. A “smoothing paradigm” is commonly used in LLM quantization, which transfers the quantization difficulty of activation to... | Chao Zeng, Jiaqi Zhao, Liqiang Nie, Miao Zhang, Ming Wang, Xuebo Liu |  |
| 242 |  |  [VariErr NLI: Separating Annotation Error from Human Label Variation](https://doi.org/10.18653/v1/2024.acl-long.123) |  | 0 | Human label variation arises when annotators assign different labels to the same item for valid reasons, while annotation errors occur when labels are assigned for invalid reasons. These two issues are prevalent in NLP benchmarks, yet existing research has studied them in isolation. To the best of... | Barbara Plank, Leon WeberGenzel, MarieCatherine de Marneffe, Siyao Peng |  |
| 243 |  |  [Benchmarking Knowledge Boundary for Large Language Models: A Different Perspective on Model Evaluation](https://doi.org/10.18653/v1/2024.acl-long.124) |  | 0 | In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks.To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs.We... | Jie Ruan, Xiaojun Wan, Xu Zhang, Xunjian Yin |  |
| 244 |  |  [ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval](https://doi.org/10.18653/v1/2024.acl-long.125) |  | 0 | We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and... | Eunbi Choi, Hyeongu Yun, Jiyeon Kim, Seungwon Hwang, Soyoung Yoon, Yireun Kim |  |
| 245 |  |  [Exploring the Potential of Large Language Models in Computational Argumentation](https://doi.org/10.18653/v1/2024.acl-long.126) |  | 0 | Computational argumentation has become an essential tool in various domains, including law, public policy, and artificial intelligence. It is an emerging research field in natural language processing that attracts increasing attention. Research on computational argumentation mainly involves two... | Anh Tuan Luu, Guizhen Chen, Lidong Bing, Liying Cheng |  |
| 246 |  |  [TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks](https://doi.org/10.18653/v1/2024.acl-long.127) |  | 0 | In this paper, we explore the capabilities of LLMs in capturing lexical-semantic knowledge from WordNet on the example of the LLaMA-2-7b model and test it on multiple lexical semantic tasks. As the outcome of our experiments, we present TaxoLLaMA, the “all-in-one” model for taxonomy-related tasks,... | Alexander Panchenko, Alina Lobanova, Ekaterina Neminova, Irina Nikishina, Viktor Moskvoretskii |  |
| 247 |  |  [CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.128) |  | 0 | The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows the application of existing knowledge to unfamiliar scenarios. However, existing works tend to undervalue the step of instantiation and heavilyrely on pre-built concept... | Baixuan Xu, Cheng Jiayang, Chunkit Chan, Chunyang Li, Haochen Shi, Jiaxin Bai, Tianqing Fang, Weiqi Wang, Wenxuan Ding, Xin Liu, Yangqiu Song, Zhaowei Wang |  |
| 248 |  |  [MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter](https://doi.org/10.18653/v1/2024.acl-long.129) |  | 0 | Parameter-Efficient Fine-tuning (PEFT) facilitates the fine-tuning of Large Language Models (LLMs) under limited resources. However, the fine-tuning performance with PEFT on complex, knowledge-intensive tasks is limited due to the constrained model capacity, which originates from the limited number... | Jitai Hao, Pengjie Ren, Qi Meng, Weiwei Sun, Xin Xin, Zhaochun Ren, Zhumin Chen |  |
| 249 |  |  [Surgical Feature-Space Decomposition of LLMs: Why, When and How?](https://doi.org/10.18653/v1/2024.acl-long.130) |  | 0 | Low-rank approximations, of the weight and feature space can enhance the performance of deep learning models, whether in terms of improving generalization or reducing the latency of inference. However, there is no clear consensus yet on how, when and why these approximations are helpful for large... | Arnav Chavan, Deepak K. Gupta, Nahush Lele |  |
| 250 |  |  [Reasoning in Flux: Enhancing Large Language Models Reasoning through Uncertainty-aware Adaptive Guidance](https://doi.org/10.18653/v1/2024.acl-long.131) |  | 0 | Machine reasoning, which involves solving complex problems through step-by-step deduction and analysis, is a crucial indicator of the capabilities of Large Language Models (LLMs). However, as the complexity of tasks escalates, LLMs often encounter increasing errors in their multi-step reasoning... | Junqi Dai, Qinyuan Cheng, Qipeng Guo, Qiushi Sun, Xiaonan Li, Xipeng Qiu, Xuanjing Huang, Zhangyue Yin, Zhiyuan Zeng |  |
| 251 |  |  [Modality-Aware Integration with Large Language Models for Knowledge-Based Visual Question Answering](https://doi.org/10.18653/v1/2024.acl-long.132) |  | 0 | Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging... | Daochen Zha, Huachi Zhou, Junnan Dong, Pai Zheng, Qinggang Zhang, Xiao Huang |  |
| 252 |  |  [Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression](https://doi.org/10.18653/v1/2024.acl-long.133) |  | 0 | Key-value (KV) caching is an important technique to accelerate the inference of large language models (LLMs), but incurs significant memory overhead. To compress the size of KV cache, existing methods often compromise precision or require extra data for calibration, limiting their practicality in... | JiRong Wen, Peiyu Liu, Tao Wang, Xin Zhao, Yipeng Ma, ZeFeng Gao |  |
| 253 |  |  [VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.134) |  | 0 | Recent approaches in domain-specific named entity recognition (NER), such as biomedical NER, have shown remarkable advances. However, they still lack of faithfulness, producing erroneous predictions. We assume that knowledge of entities can be useful in verifying the correctness of the predictions.... | Dongha Lee, Hyungjoo Chae, Jinyoung Yeo, Kwangwook Seo, Seoyeon Kim |  |
| 254 |  |  [Making Long-Context Language Models Better Multi-Hop Reasoners](https://doi.org/10.18653/v1/2024.acl-long.135) |  | 0 | Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased performance in the presence of noisy contexts. In this paper,... | Liwei Wang, Michael R. Lyu, Shuo Liang, Yanyang Li |  |
| 255 |  |  [TransliCo: A Contrastive Learning Framework to Address the Script Barrier in Multilingual Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.136) |  | 0 | The world’s more than 7000 languages are written in at least 293 scripts. Due to various reasons, many closely related languages use different scripts, which poses a difficulty for multilingual pretrained language models (mPLMs) in learning crosslingual knowledge through lexical overlap. As a... | Chunlan Ma, Haotian Ye, Hinrich Schütze, Yihong Liu |  |
| 256 |  |  [Extreme Miscalibration and the Illusion of Adversarial Robustness](https://doi.org/10.18653/v1/2024.acl-long.137) |  | 0 | Deep learning-based Natural Language Processing (NLP) models are vulnerable to adversarial attacks, where small perturbations can cause a model to misclassify. Adversarial Training (AT) is often used to increase model robustness. However, we have discovered an intriguing phenomenon: deliberately or... | Aditya Rawal, George Karypis, Samson Tan, Sheng Zha, Volkan Cevher, Vyas Raina |  |
| 257 |  |  [HyCoRec: Hypergraph-Enhanced Multi-Preference Learning for Alleviating Matthew Effect in Conversational Recommendation](https://doi.org/10.18653/v1/2024.acl-long.138) |  | 0 | The Matthew effect is a notorious issue in Recommender Systems (RSs), i.e., the rich get richer and the poor get poorer, wherein popular items are overexposed while less popular ones are regularly ignored. Most methods examine Matthew effect in static or nearly-static recommendation scenarios.... | Guohua Wang, Jinghui Qin, Liang Lin, Mingjie Qian, Ruilin Xu, Yongsen Zheng, Ziliang Chen |  |
| 258 |  |  [Co-training for Low Resource Scientific Natural Language Inference](https://doi.org/10.18653/v1/2024.acl-long.139) |  | 0 | Scientific Natural Language Inference (NLI) is the task of predicting the semantic relation between a pair of sentences extracted from research articles. The automatic annotation method based on distant supervision for the training set of SciNLI, the first and most popular dataset for this task,... | Cornelia Caragea, Mobashir Sadat |  |
| 259 |  |  [RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.140) |  | 0 | Reinforcement Learning with Human Feedback (RLHF) is a methodology designed to align Large Language Models (LLMs) with human preferences, playing an important role in LLMs alignment. Despite its advantages, RLHF relies on human annotators to rank the text, which can introduce potential security... | Chaowei Xiao, Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik |  |
| 260 |  |  [Time is Encoded in the Weights of Finetuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.141) |  | 0 | We present time vectors, a simple tool to customize language models to new time periods. Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model. This vector specifies a direction... | Kai Nylund, Noah A. Smith, Suchin Gururangan |  |
| 261 |  |  [Long-Context Language Modeling with Parallel Context Encoding](https://doi.org/10.18653/v1/2024.acl-long.142) |  | 0 | Extending large language models (LLMs) to process longer inputs is crucial for a wide range of applications. However, the substantial computational cost of transformers and limited generalization of positional encoding restrict the size of their context window. We introduce Context Expansion with... | Danqi Chen, Howard Yen, Tianyu Gao |  |
| 262 |  |  [SirLLM: Streaming Infinite Retentive LLM](https://doi.org/10.18653/v1/2024.acl-long.143) |  | 0 | As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process inputs of any length and maintain a degree of memory becomes essential. However, the one-off input of overly long texts is limited, as studies have shown that when input lengths exceed the... | Hai Zhao, Yao Yao, Zuchao Li |  |
| 263 |  |  [IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models](https://doi.org/10.18653/v1/2024.acl-long.144) |  | 0 | Machine learning models have made incredible progress, but they still struggle when applied to examples from unseen domains. This study focuses on a specific problem of domain generalization, where a model is trained on one source domain and tested on multiple target domains that are unseen during... | Gholamreza Haffari, Haolan Zhan, Lizhen Qu, Tao Feng, Yuncheng Hua, Zhuang Li |  |
| 264 |  |  [Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale](https://doi.org/10.18653/v1/2024.acl-long.145) |  | 0 | A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner.We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained from scratch on raw texts with high parallelism. GPST... | Kewei Tu, Pengyu Ji, Qingyang Zhu, Wei Wu, Xiang Hu |  |
| 265 |  |  [MELA: Multilingual Evaluation of Linguistic Acceptability](https://doi.org/10.18653/v1/2024.acl-long.146) |  | 0 | In this work, we present the largest benchmark to date on linguistic acceptability: Multilingual Evaluation of Linguistic Acceptability—MELA, with 46K samples covering 10 languages from a diverse set of language families. We establish LLM baselines on this benchmark, and investigate cross-lingual... | Hai Hu, Junyu Mao, Rui Wang, Weifang Huang, Yikang Liu, Ziyin Zhang |  |
| 266 |  |  [CopyNE: Better Contextual ASR by Copying Named Entities](https://doi.org/10.18653/v1/2024.acl-long.147) |  | 0 | End-to-end automatic speech recognition (ASR) systems have made significant progress in general scenarios. However, it remains challenging to transcribe contextual named entities (NEs) in the contextual ASR scenario. Previous approaches have attempted to address this by utilizing the NE dictionary.... | Baoxing Huai, Min Zhang, Shilin Zhou, Yu Hong, Zhefeng Wang, Zhenghua Li |  |
| 267 |  |  [Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval](https://doi.org/10.18653/v1/2024.acl-long.148) |  | 0 | Retrieving relevant tables containing the necessary information to accurately answer a given question over tables is critical to open-domain question-answering (QA) systems. Previous methods assume the answer to such a question can be found either in a single table or multiple tables identified... | Dan Roth, Peter Baile Chen, Yi Zhang |  |
| 268 |  |  [Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation](https://doi.org/10.18653/v1/2024.acl-long.149) |  | 0 | Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem – that is, users can perform a... | Haonan Chen, Jiongnan Liu, Kelong Mao, Zhicheng Dou, Ziliang Zhao |  |
| 269 |  |  [ItD: Large Language Models Can Teach Themselves Induction through Deduction](https://doi.org/10.18653/v1/2024.acl-long.150) |  | 0 | Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, researchers have found that they still have limited ability to conduct induction. Recent works mainly adopt “post processes” paradigms to improve the performance of LLMs on... | Haotian Xu, Jun Zhao, Kang Liu, Pei Chen, Shizhu He, Wangtao Sun, Xuanqing Yu |  |
| 270 |  |  [MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.151) |  | 0 | Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and... | Aojun Zhou, Hongsheng Li, Houxing Ren, Junting Pan, Ke Wang, Mingjie Zhan, Weikang Shi, Zimu Lu |  |
| 271 |  |  [Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent](https://doi.org/10.18653/v1/2024.acl-long.152) |  | 0 | Task-oriented dialogue (TOD) systems are predominantly designed to be composed of several functional modules (e.g. dialogue state tracker, dialogue policy, natural language generation) whether they are pipeline or end-to-end architectures. However, this modular design not only heavily relies on... | Fanshu Sun, HengDa Xu, Heyan Huang, Puhai Yang, XianLing Mao |  |
| 272 |  |  [On Context Utilization in Summarization with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.153) |  | 0 | Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of... | Aixin Sun, Mathieu Ravaut, Nancy F. Chen, Shafiq Joty |  |
| 273 |  |  [INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.154) |  | 0 | Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While... | Binyu Xie, Chenghao Zhang, JiRong Wen, Peitian Zhang, Yifei Chen, Yutao Zhu, Zheng Liu, Zhicheng Dou |  |
| 274 |  |  [Enhancing In-Context Learning via Implicit Demonstration Augmentation](https://doi.org/10.18653/v1/2024.acl-long.155) |  | 0 | The emergence of in-context learning (ICL) enables large pre-trained language models (PLMs) to make predictions for unseen inputs without updating parameters. Despite its potential, ICL’s effectiveness heavily relies on the quality, quantity, and permutation of demonstrations, commonly leading to... | Chaoya Jiang, Rui Xie, Shikun Zhang, Wei Ye, Xiaoling Zhou, Yidong Wang, Zhemg Lee |  |
| 275 |  |  [PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA](https://doi.org/10.18653/v1/2024.acl-long.156) |  | 0 | With the rapid scaling of large language models (LLMs), serving numerouslow-rank adaptations (LoRAs) concurrently has become increasingly impractical,leading to unaffordable costs and necessitating more parameter-efficientfinetuning methods. In this work, we introduce Partially Rotation-enhanced... | Boyang Xue, Chuan Wu, Jiacheng Ye, Jiyue Jiang, Liheng Chen, Lingpeng Kong, Sheng Wang |  |
| 276 |  |  [Improving Event Definition Following For Zero-Shot Event Detection](https://doi.org/10.18653/v1/2024.acl-long.157) |  | 0 | Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations.In this work, we aim to improve zero-shot event... | Ashima Suvarna, Baobao Chang, Hritik Bansal, Mingyu Derek Ma, Nanyun Peng, P. Jeffrey Brantingham, PoNien Kung, Wei Wang, Zefan Cai |  |
| 277 |  |  [Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements](https://doi.org/10.18653/v1/2024.acl-long.158) |  | 0 | The current charge prediction datasets mostly focus on single-defendant criminal cases.However, real-world criminal cases usually involve multiple defendants whose criminal facts are intertwined. In an early attempt to fill this gap, we introduce a new benchmark that encompasses legal cases... | Erik Cambria, Hang Yu, Qi Xu, Qian Liu, Xiao Wei |  |
| 278 |  |  [Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding](https://doi.org/10.18653/v1/2024.acl-long.159) |  | 0 | Conversational dense retrieval has shown to be effective in conversational search. However, a major limitation of conversational dense retrieval is their lack of interpretability, hindering intuitive understanding of model behaviors for targeted improvements. This paper presents CONVINV, a simple... | Kelong Mao, Yiruo Cheng, Zhicheng Dou |  |
| 279 |  |  [Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks](https://doi.org/10.18653/v1/2024.acl-long.160) |  | 0 | The widespread use of large language models (LLMs) is increasing the demand for methods that detect machine-generated text to prevent misuse. The goal of our study is to stress test the detectors’ robustness to malicious attacks under realistic scenarios. We comprehensively study the robustness of... | Abe Bohan Hou, Chao Shen, Shangbin Feng, Tianxing He, Xiao Pu, Xiaoming Liu, Yichen Wang, Yulia Tsvetkov |  |
| 280 |  |  [Training Language Models to Generate Text with Citations via Fine-grained Rewards](https://doi.org/10.18653/v1/2024.acl-long.161) |  | 0 | While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to... | Chengyu Huang, Wenya Wang, Yushi Hu, Zeqiu Wu |  |
| 281 |  |  [Hypergraph based Understanding for Document Semantic Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.162) |  | 0 | Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus... | Hai Zhao, Haojun Ai, Ping Wang, Qiwei Li, Zuchao Li |  |
| 282 |  |  [GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers](https://doi.org/10.18653/v1/2024.acl-long.163) |  | 0 | Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One... | Leyang Cui, Lingpeng Kong, Qintong Li, Wei Bi, Xueliang Zhao |  |
| 283 |  |  [Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.164) |  | 0 | Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events. Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event... | Qingkai Min, Qipeng Guo, Songfang Huang, Xiangkun Hu, Yue Zhang, Zheng Zhang |  |
| 284 |  |  [AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning](https://doi.org/10.18653/v1/2024.acl-long.165) |  | 0 | Language agents have achieved considerable performance on various complex question-answering tasks by planning with external tools. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of... | Chengfei Lv, Huajun Chen, Ningyu Zhang, Runnan Fang, Shuofei Qiao, Wangchunshu Zhou, Yuchen Eleanor Jiang, Yujie Luo |  |
| 285 |  |  [ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks](https://doi.org/10.18653/v1/2024.acl-long.166) |  | 0 | This study investigates the challenges posed by the dynamic nature of legal multi-label text classification tasks, where legal concepts evolve over time. Existing models often overlook the temporal dimension in their training process, leading to suboptimal performance of those models over time, as... | Matthias Grabmair, T. Y. S. S. Santosh, TuanQuang Vuong |  |
| 286 |  |  [Virtual Compiler Is All You Need For Assembly Code Search](https://doi.org/10.18653/v1/2024.acl-long.167) |  | 0 | Assembly code search is vital for reducing the burden on reverse engineers, allowing them to quickly identify specific functions using natural language within vast binary programs.Despite its significance, this critical task is impeded by the complexities involved in building high-quality datasets.... | Chao Zhang, Hao Wang, Yuanda Wang, Zeyu Gao |  |
| 287 |  |  [MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.168) |  | 0 | Parameter-efficient fine-tuning (PEFT) is a popular method for tailoring pre-trained large language models (LLMs), especially as the models’ scale and the diversity of tasks increase. Low-rank adaptation (LoRA) is based on the idea that the adaptation process is intrinsically low-dimensional, i.e.,... | Chengshun Shi, Jiahuan Pei, Maarten de Rijke, Mengqi Zhang, Pengjie Ren, Shiguang Wu, Zhaochun Ren, Zhumin Chen |  |
| 288 |  |  [Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning](https://doi.org/10.18653/v1/2024.acl-long.169) |  | 0 | Large language models (LLMs) have demonstrated striking reasoning capability. Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples,... | Dawei Li, Fei Teng, Jingbo Shang, Sizhe Wang, Yongqi Tong, Yujia Wang |  |
| 289 |  |  [An Iterative Associative Memory Model for Empathetic Response Generation](https://doi.org/10.18653/v1/2024.acl-long.170) |  | 0 | Empathetic response generation aims to comprehend the cognitive and emotional states in dialogue utterances and generate proper responses. Psychological theories posit that comprehending emotional and cognitive states necessitates iteratively capturing and understanding associated words across... | Chao Chen, Haizhou Sun, Xiangwen Liao, Xiaofei Zhu, Yufeng Wang, Zhaochun Ren, Zhou Yang |  |
| 290 |  |  [Detoxifying Large Language Models via Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.171) |  | 0 | This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments with... | Huajun Chen, Jindong Wang, Linyi Yang, Mengru Wang, Ningyu Zhang, Qishen Zhang, Shumin Deng, Yunzhi Yao, Zekun Xi, Ziwen Xu |  |
| 291 |  |  [LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding](https://doi.org/10.18653/v1/2024.acl-long.172) |  | 0 | Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs, such as books, reports, and codebases. Recent works have proposed methods to... | Aohan Zeng, Hongchang Lyu, Jiajie Zhang, Jiankai Tang, Jie Tang, Juanzi Li, Lei Hou, Xiao Liu, Xin Lv, Yushi Bai, Yuxiao Dong, Zhengxiao Du, Zhidian Huang |  |
| 292 |  |  [Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.173) |  | 0 | Teachers are important to imparting knowledge and guiding learners, and the role of large language models (LLMs) as potential educators is emerging as an important area of study. Recognizing LLMs’ capability to generate educational content can lead to advances in automated and personalized... | Panjun Liu, Songzhou Yan, Yanghua Xiao, Yuyan Chen |  |
| 293 |  |  [UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages](https://doi.org/10.18653/v1/2024.acl-long.174) |  | 0 | In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a comprehensive approach developed to improve the effectiveness of Cross-Lingual Transfer Learning, particularly in languages with limited resources. Our approach tackles two essential... | Anh Tuan Luu, Khoi Le, Trinh Pham |  |
| 294 |  |  [VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval](https://doi.org/10.18653/v1/2024.acl-long.175) |  | 0 | Multi-modal retrieval becomes increasingly popular in practice. However, the existing retrievers are mostly text-oriented, which lack the capability to process visual information. Despite the presence of vision-language models like CLIP, the current methods are severely limited in representing the... | Bo Zhao, Junjie Zhou, Shitao Xiao, Yongping Xiong, Zheng Liu |  |
| 295 |  |  [Black-Box Prompt Optimization: Aligning Large Language Models without Model Training](https://doi.org/10.18653/v1/2024.acl-long.176) |  | 0 | Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them; that is, the alignment problem. To make LLMs better follow user instructions, existing alignment... | Hongning Wang, Jiale Cheng, Jie Tang, Kehan Zheng, Minlie Huang, Pei Ke, Xiao Liu, Yuxiao Dong |  |
| 296 |  |  [Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark](https://doi.org/10.18653/v1/2024.acl-long.177) |  | 0 | This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as vital tools for evaluating Large Language Models (LLMs) in Korean. Incorporating private test sets while mirroring the English Open LLM Leaderboard, we establish a robust evaluation framework that has been well integrated... | Chanjun Park, Dahyun Kim, Hwalsuk Lee, Hyeonwoo Kim, Sanghoon Kim, Seonghwan Cho, Sukyung Lee, Yungi Kim |  |
| 297 |  |  [Unified Hallucination Detection for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.178) |  | 0 | Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical... | Chenxi Wang, Huajun Chen, Jinjie Gu, Lei Liang, Ningyu Zhang, Qiang Li, Xiang Chen, Xiaoyan Yang, Yida Xue, Yue Shen |  |
| 298 |  |  [Empowering Character-level Text Infilling by Eliminating Sub-Tokens](https://doi.org/10.18653/v1/2024.acl-long.179) |  | 0 | In infilling tasks, sub-tokens, representing instances where a complete token is segmented into two parts, often emerge at the boundaries of prefixes, middles, and suffixes. Traditional methods focused on training models at the token level, leading to sub-optimal performance in character-level... | Hongsheng Li, Houxing Ren, Mingjie Zhan, Zhongyuan Wu |  |
| 299 |  |  [Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.180) |  | 0 | Retrieval augmentation is a promising approach to handle long-context language modeling. However, the existing retrieval methods usually work with the chunked context, which is prone to inferior quality of semantic representation and incomplete retrieval of useful information. In this work, we... | Jun Zhao, Kang Liu, Kun Luo, Shitao Xiao, Tong Zhou, Yubo Chen, Zheng Liu |  |
| 300 |  |  [GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?](https://doi.org/10.18653/v1/2024.acl-long.181) |  | 0 | In the real world, knowledge is constantly evolving, which can render existing knowledge-based datasets outdated. This unreliability highlights the critical need for continuous updates to ensure both accuracy and relevance in knowledge-intensive tasks. To address this, we propose GrowOVER-QA and... | Dayoon Ko, Gunhee Kim, Hahyeon Choi, Jinyoung Kim |  |
| 301 |  |  [Attribute First, then Generate: Locally-attributable Grounded Text Generation](https://doi.org/10.18653/v1/2024.acl-long.182) |  | 0 | Recent efforts to address hallucinations in Large Language Models (LLMs) have focused on attributed text generation, which supplements generated texts with citations of supporting sources for post-generation fact-checking and corrections. Yet, these citations often point to entire documents or... | Arie Cattan, Aviv Slobodkin, Eran Hirsch, Ido Dagan, Tal Schuster |  |
| 302 |  |  [T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text](https://doi.org/10.18653/v1/2024.acl-long.183) |  | 0 | In this work, we propose a two-stage sign language production (SLP) paradigm that first encodes sign language sequences into discrete codes and then autoregressively generates sign language from text based on the learned codebook. However, existing vector quantization (VQ) methods are fixed-length... | Aoxiong Yin, Haoyuan Li, Kai Shen, Siliang Tang, Yueting Zhuang |  |
| 303 |  |  [OceanGPT: A Large Language Model for Ocean Science Tasks](https://doi.org/10.18653/v1/2024.acl-long.184) |  | 0 | Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet’s surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other... | Daxiong Ji, Guozhou Zheng, Huajun Chen, Ningyu Zhang, Yida Xue, Yixin Ou, Zhen Bi |  |
| 304 |  |  [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://doi.org/10.18653/v1/2024.acl-long.185) |  | 0 | Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks.However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM... | Liang Pang, Min Lin, MinYen Kan, Qian Liu, Tongyao Zhu, Zhengbao Jiang |  |
| 305 |  |  [BIPED: Pedagogically Informed Tutoring System for ESL Education](https://doi.org/10.18653/v1/2024.acl-long.186) |  | 0 | Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English. Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to... | Kyuseok Kim, Minju Park, Seunghyun Lee, Sojung Kim, Soonwoo Kwon |  |
| 306 |  |  [Timeline-based Sentence Decomposition with In Context Learning for Temporal Fact Extraction](https://doi.org/10.18653/v1/2024.acl-long.187) |  | 0 | Facts extraction is pivotal for constructing knowledge graphs. Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction. In this paper, we specifically address the extraction of temporal facts from natural language text.... | Haoyuan Ouyang, Jianhao Chen, Junyang Ren, Wei Hu, Wentao Ding, Yuzhong Qu |  |
| 307 |  |  [Collaboration or Corporate Capture? Quantifying NLP's Reliance on Industry Artifacts and Contributions](https://doi.org/10.18653/v1/2024.acl-long.188) |  | 0 | Impressive performance of pre-trained models has garnered public attention and made news headlines in recent years. Almost always, these models are produced by or in collaboration with industry. Using them is critical for competing on natural language processing (NLP) benchmarks and correspondingly... | Catherine Stinson, Karen Rudie, Mohamed Abdalla, Will Aitken |  |
| 308 |  |  [Prompt Expansion for Adaptive Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.189) |  | 0 | Text-to-image generation models are powerful but difficult to use. Users craft specific prompts to get better images, though the images can be repetitive. This paper proposes the Prompt Expansion framework that helps users generate high-quality, diverse images with less effort. The Prompt Expansion... | Alexander Ku, Deepak Ramachandran, Peter Anderson, Siddhartha Datta |  |
| 309 |  |  [Progressively Modality Freezing for Multi-Modal Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.190) |  | 0 | Multi-Modal Entity Alignment aims to discover identical entities across heterogeneous knowledge graphs. While recent studies have delved into fusion paradigms to represent entities holistically, the elimination of features irrelevant to alignment and modal inconsistencies is overlooked, which are... | Jaein Kim, Junfan Chen, Richong Zhang, Xuefeng Zhang, Yani Huang |  |
| 310 |  |  [Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval](https://doi.org/10.18653/v1/2024.acl-long.191) |  | 0 | Dense retrieval calls for discriminative embeddings to represent the semantic relationship between query and document. It may benefit from the using of large language models (LLMs), given LLMs’ strong capability on semantic understanding. However, the LLMs are learned by auto-regression, whose... | Chaofan Li, Defu Lian, Shitao Xiao, Yingxia Shao, Zheng Liu |  |
| 311 |  |  [Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts](https://doi.org/10.18653/v1/2024.acl-long.192) |  | 0 | Large language models (LLMs) are known to effectively perform tasks by simply observing few exemplars. However, in low-resource languages, obtaining such hand-picked exemplars can still be challenging, where unsupervised techniques may be necessary. Moreover, competent generative capabilities of... | Lidong Bing, Mahani Aljunied, Shafiq Joty, XuanPhi Nguyen |  |
| 312 |  |  [Metaphor Understanding Challenge Dataset for LLMs](https://doi.org/10.18653/v1/2024.acl-long.193) |  | 0 | Metaphors in natural language are a reflection of fundamental cognitive processes such as analogical reasoning and categorisation, and are deeply rooted in everyday communication. Metaphor understanding is therefore an essential task for large language models (LLMs). We release the Metaphor... | Ekaterina Shutova, Martha Lewis, Rochelle Choenni, Xiaoyu Tong |  |
| 313 |  |  [A Multi-Task Embedder For Retrieval Augmented LLMs](https://doi.org/10.18653/v1/2024.acl-long.194) |  | 0 | LLMs confront inherent limitations in terms of its knowledge, memory, and action. The retrieval augmentation stands as a vital mechanism to address these limitations, which brings in useful information from external sources to augment the LLM. However, existing retrieval methods encounter two... | JianYun Nie, Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou |  |
| 314 |  |  [Language Models Don't Learn the Physical Manifestation of Language](https://doi.org/10.18653/v1/2024.acl-long.195) |  | 0 | We argue that language-only models don’t learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test.These tasks highlight a fundamental gap between human linguistic understanding and the... | Bruce W. Lee, Jaehyuk Lim |  |
| 315 |  |  [What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection](https://doi.org/10.18653/v1/2024.acl-long.196) |  | 0 | Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language... | Herun Wan, Minnan Luo, Ningnan Wang, Shangbin Feng, Yulia Tsvetkov, Zhaoxuan Tan |  |
| 316 |  |  [Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives](https://doi.org/10.18653/v1/2024.acl-long.197) |  | 0 | The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM’s response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM’s intrinsic... | Jun Wang, Linjuan Wu, Qiuying Peng, Weiming Lu, Wenqi Zhang, Yongliang Shen, Yueting Zhuang |  |
| 317 |  |  [Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty](https://doi.org/10.18653/v1/2024.acl-long.198) |  | 0 | As natural language becomes the default interface for human-AI interaction, there is a need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence in responses via natural language and how downstream users behave in... | Jena D. Hwang, Kaitlyn Zhou, Maarten Sap, Xiang Ren |  |
| 318 |  |  [Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources](https://doi.org/10.18653/v1/2024.acl-long.199) |  | 0 | Although pre-training has become a prevalent approach for addressing various biomedical tasks, the current efficacy of pre-trained models is hindered by their reliance on a limited scope of medical sources. This limitation results in data scarcity during pre-training and restricts the range of... | Cao Xiao, Fenglong Ma, Jiaqi Wang, Junyu Luo, Parminder Bhatia, Xiaochen Wang, Xiaokun Zhang, Yaqing Wang, Yuan Zhong |  |
| 319 |  |  [When Good and Reproducible Results are a Giant with Feet of Clay: The Importance of Software Quality in NLP](https://doi.org/10.18653/v1/2024.acl-long.200) |  | 0 | Despite its crucial role in research experiments, code correctness is often presumed solely based on the perceived quality of results. This assumption, however, comes with the risk of erroneous outcomes and, in turn, potentially misleading findings. To mitigate this risk, we posit that the current... | Andrea Pilzer, Marco Gaido, Matteo Negri, Sara Papi |  |
| 320 |  |  [SBAAM! Eliminating Transcript Dependency in Automatic Subtitling](https://doi.org/10.18653/v1/2024.acl-long.201) |  | 0 | Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three primary subtasks: translating spoken dialogue, segmenting translations into concise textual units, and estimating timestamps that govern their on-screen duration. Past attempts to automate... | Luisa Bentivogli, Marco Gaido, Matteo Negri, Mauro Cettolo, Sara Papi |  |
| 321 |  |  [StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection](https://doi.org/10.18653/v1/2024.acl-long.202) |  | 0 | Streaming speech-to-text translation (StreamST) is the task of automatically translating speech while incrementally receiving an audio stream. Unlike simultaneous ST (SimulST), which deals with pre-segmented speech, StreamST faces the challenges of handling continuous and unbounded audio streams.... | Luisa Bentivogli, Marco Gaido, Matteo Negri, Sara Papi |  |
| 322 |  |  [ARL2: Aligning Retrievers with Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](https://doi.org/10.18653/v1/2024.acl-long.203) |  | 0 | Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with... | Chao Zhang, Kuan Wang, Lingxi Zhang, Yue Yu |  |
| 323 |  |  [Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference](https://doi.org/10.18653/v1/2024.acl-long.204) |  | 0 | The customization of large language models (LLMs) for user-specified tasks gets important. However, maintaining all the customized LLMs on cloud servers incurs substantial memory and computational overheads, and uploading user data can also lead to privacy concerns. On-device LLMs can offer a... | Jihwan Bang, Juntae Lee, Kyuhong Shim, Seunghan Yang, Simyung Chang |  |
| 324 |  |  [FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model](https://doi.org/10.18653/v1/2024.acl-long.205) |  | 0 | Most existing image captioning evaluation metrics focus on assigning a single numerical score to a caption by comparing it with reference captions. However, these methods do not provide an explanation for the assigned score. Moreover, reference captions are expensive to acquire. In this paper, we... | Imseong Park, Myungjoo Kang, Yebin Lee |  |
| 325 |  |  [MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations](https://doi.org/10.18653/v1/2024.acl-long.206) |  | 0 | Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its context-dependent and often subtle nature. The detection of manipulative language is essential for protecting potential victims, yet the field of Natural Language Processing... | Ivory Yang, Saeed Hassanpour, Soroush Vosoughi, Yuxin Wang |  |
| 326 |  |  [MPCoder: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning](https://doi.org/10.18653/v1/2024.acl-long.207) |  | 0 | Large Language Models (LLMs) have demonstrated great potential for assisting developers in their daily development. However, most research focuses on generating correct code, how to use LLMs to generate personalized code has seldom been investigated. To bridge this gap, we proposed MPCoder... | Chang Yao, Jingyuan Chen, WenKang Han, Yuanying Yuanying, Zhenlong Dai, Zhipeng Gao |  |
| 327 |  |  [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://doi.org/10.18653/v1/2024.acl-long.208) |  | 0 | Large language models (LLMs) have become a dominant and important tool for NLP researchers in a wide range of tasks. Today, many researchers use LLMs in synthetic data generation, task evaluation, fine-tuning, distillation, and other model-in-the-loop research workflows. However, challenges arise... | Ajay Patel, Chris CallisonBurch, Colin Raffel |  |
| 328 |  |  [Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective](https://doi.org/10.18653/v1/2024.acl-long.209) |  | 0 | Neural Machine Translation (NMT) has made remarkable progress over the past years. However, under-translation and over-translation remain two challenging problems in state-of-the-art NMT systems. In this work, we conduct an in-depth analysis on the underlying cause of under-translation in NMT,... | Chenze Shao, Fandong Meng, Jiali Zeng, Jie Zhou |  |
| 329 |  |  [Identifying while Learning for Document Event Causality Identification](https://doi.org/10.18653/v1/2024.acl-long.210) |  | 0 | Event Causality Identification (ECI) aims to detect whether there exists a causal relation between two events in a document. Existing studies adopt a kind of \*identifying after learning\* paradigm, where events’ representations are first learned and then used for the identification. Furthermore,... | Bang Wang, Cheng Liu, Wei Xiang |  |
| 330 |  |  [OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems](https://doi.org/10.18653/v1/2024.acl-long.211) |  | 0 | Recent advancements have seen Large Language Models (LLMs) and Large Multimodal Models (LMMs) surpassing general human capabilities in various tasks, approaching the proficiency level of human experts across multiple domains. With traditional benchmarks becoming less challenging for these models,... | Chaoqun He, Jie Liu, Jinyi Hu, Junhao Shen, Lei Qi, Maosong Sun, Renjie Luo, Shengding Hu, Xu Han, Yujie Huang, Yuxiang Zhang, Yuzhuo Bai, Zhen Leng Thai, Zhiyuan Liu |  |
| 331 |  |  [Insert or Attach: Taxonomy Completion via Box Embedding](https://doi.org/10.18653/v1/2024.acl-long.212) |  | 0 | Taxonomy completion, enriching existing taxonomies by inserting new concepts as parents or attaching them as children, has gained significant interest. Previous approaches embed concepts as vectors in Euclidean space, which makes it difficult to model asymmetric relations in taxonomy. In addition,... | Jietian Guo, Shiliang Pu, Wei Xue, Weiming Lu, Wenqi Ren, Yongliang Shen |  |
| 332 |  |  [Semiparametric Token-Sequence Co-Supervision](https://doi.org/10.18653/v1/2024.acl-long.213) |  | 0 | In this work, we introduce a semiparametric token-sequence co-supervision training method. It trains a language model by simultaneously leveraging supervision from the traditional next token prediction loss which is calculated over the parametric token embedding space and the next sequence... | Doyoung Kim, Hyunji Lee, Jihoon Jun, Joel Jang, KyoungWoon On, Minjoon Seo, Se June Joo |  |
| 333 |  |  [Instruction Fusion: Advancing Prompt Evolution through Hybridization](https://doi.org/10.18653/v1/2024.acl-long.214) |  | 0 | The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code... | Di Niu, Jiuding Yang, Kaitong Yang, Weidong Guo, Xiangyang Li, Yu Xu, Zhuwei Rao |  |
| 334 |  |  [TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation](https://doi.org/10.18653/v1/2024.acl-long.215) |  | 0 | Despite remarkable advancements in emulating human-like behavior through Large Language Models (LLMs), current textual simulations do not adequately address the notion of time. To this end, we introduce TimeArena, a novel textual simulated environment that incorporates complex temporal dynamics and... | Caiyu Hu, Jiangjie Chen, Kyle Richardson, Siyu Yuan, Yanghua Xiao, Yikai Zhang |  |
| 335 |  |  [Exploring Memorization in Fine-tuned Language Models](https://doi.org/10.18653/v1/2024.acl-long.216) |  | 0 | Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is... | Dawei Yin, Han Xu, Jie Ren, Jiliang Tang, Pengfei He, Shenglai Zeng, Shuaiqiang Wang, Yaxin Li, Yiding Liu, Yue Xing |  |
| 336 |  |  [Towards Real-world Scenario: Imbalanced New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.217) |  | 0 | New Intent Discovery (NID) aims at detecting known and previously undefined categories of user intent by utilizing limited labeled and massive unlabeled data. Most prior works often operate under the unrealistic assumption that the distribution of both familiar and new intent classes is uniform,... | Chaoran Yan, Jiaheng Liu, Jian Yang, Jiaqi Bai, Shun Zhang, Tongliang Li, Ying Mo, Zhoujun Li |  |
| 337 |  |  [M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection](https://doi.org/10.18653/v1/2024.acl-long.218) |  | 0 | The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine... | Akim Tsvigun, Alham Fikri Aji, Artem Shelmanov, Giovanni Puccetti, Iryna Gurevych, Jinyan Su, Jonibek Mansurov, Nizar Habash, Osama Mohammed Afzal, Petar Ivanov, Preslav Nakov, Tarek Mahmoud, Thomas Arnold, Yuxia Wang |  |
| 338 |  |  [Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning Framework for Dialogue](https://doi.org/10.18653/v1/2024.acl-long.219) |  | 0 | Tuning language models for dialogue generation has been a prevalent paradigm for building capable dialogue agents. Yet, traditional tuning narrowly views dialogue generation as resembling other language generation tasks, ignoring the role disparities between two speakers and the multi-round... | Chak Tou Leong, Dongding Lin, Jian Wang, Jiashuo Wang, Wenjie Li, Xiaoyong Wei |  |
| 339 |  |  [SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training](https://doi.org/10.18653/v1/2024.acl-long.220) |  | 0 | The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and neglects the varying degrees of duplication. To... | Guohua Tang, Hanwen Liu, Kai Zhang, Lei Ding, Nan He, Weichen Xiong, Xiao Han, Yang Wei, Yi Liao |  |
| 340 |  |  [Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?](https://doi.org/10.18653/v1/2024.acl-long.221) |  | 0 | Building machines with commonsense has been a longstanding challenge in NLP due to the reporting bias of commonsense rules and the exposure bias of rule-based commonsense reasoning. In contrast, humans convey and pass down commonsense implicitly through stories. This paper investigates the inherent... | Ben He, Hongyu Lin, Le Sun, Ning Bian, Xianpei Han, Yaojie Lu |  |
| 341 |  |  [Learning Global Controller in Latent Space for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.222) |  | 0 | While large language models (LLMs) have showcased remarkable prowess in various natural language processing tasks, their training costs are exorbitant. Consequently, a plethora of parameter-efficient fine-tuning methods have emerged to tailor large models for downstream tasks, including low-rank... | Chang Zong, Jian Shao, Weiming Lu, Wenqi Zhang, Xiaoxia Cheng, Yongliang Shen, Yueting Zhuang, Zeqi Tan |  |
| 342 |  |  [CaMML: Context-Aware Multimodal Learner for Large Models](https://doi.org/10.18653/v1/2024.acl-long.223) |  | 0 | In this work, we introduce Context-Aware MultiModal Learner (CaMML), for tuning large multimodal models (LMMs). CaMML, a lightweight module, is crafted to seamlessly integrate multimodal contextual samples into large models, thereby empowering the model to derive knowledge from analogous,... | Bo Li, Boran Han, Shuai Zhang, Tong He, Yixin Chen |  |
| 343 |  |  [MAVEN-ARG: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation](https://doi.org/10.18653/v1/2024.acl-long.224) |  | 0 | Understanding events in texts is a core objective of natural language understanding, which requires detecting event occurrences, extracting event arguments, and analyzing inter-event relationships. However, due to the annotation challenges brought by task complexity, a large-scale dataset covering... | Hao Peng, Jianhui Chen, Jie Zhou, Juanzi Li, Kaisheng Zeng, Lei Hou, Ruobing Xie, Xiaozhi Wang, Xu Han, Yankai Lin, Yong Guan, Zhiyuan Liu |  |
| 344 |  |  [NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes](https://doi.org/10.18653/v1/2024.acl-long.225) |  | 0 | Complex reasoning ability is one of the most important features of Large Language Models (LLMs). Numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, they are inadequate in offering a rigorous evaluation and prone to the risk of overfitting, as these... | Haoyang Ling, Lingyao Li, Lizhou Fan, Wenyue Hua, Yongfeng Zhang |  |
| 345 |  |  [Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.226) |  | 0 | Text watermarking technology aims to tag and identify content produced by large language models (LLMs) to prevent misuse. In this study, we introduce the concept of cross-lingual consistency in text watermarking, which assesses the ability of text watermarks to maintain their effectiveness after... | Aiwei Liu, Binglin Zhou, Hongkun Hao, Rui Wang, Xing Wang, Zhaopeng Tu, Zhiwei He, Zhuosheng Zhang |  |
| 346 |  |  [Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors](https://doi.org/10.18653/v1/2024.acl-long.227) |  | 0 | Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it... | Alicja Chaszczewicz, Bruce A Arnow, Diyi Yang, Raj Sanjay Shah, Robert E. Kraut, Ryan Louie |  |
| 347 |  |  [In-context Mixing (ICM): Code-mixed Prompts for Multilingual LLMs](https://doi.org/10.18653/v1/2024.acl-long.228) |  | 0 | We introduce a simple and effective prompting technique called in-context mixing (ICM) for effective in-context learning (ICL) with multilingual large language models (MLLMs). With ICM, we modify the few-shot examples within ICL prompts to be intra-sententially code-mixed by randomly swapping... | Bhavani Shankar, Preethi Jyothi, Pushpak Bhattacharyya |  |
| 348 |  |  [Respond in my Language: Mitigating Language Inconsistency in Response Generation based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.229) |  | 0 | Large Language Models (LLMs) show strong instruction understanding ability across multiple languages. However, they are easily biased towards English in instruction tuning, and generate English responses even given non-English instructions. In this paper, we investigate the language inconsistent... | Dongdong Zhang, Furu Wei, Haoyang Huang, Liang Zhang, Qin Jin |  |
| 349 |  |  [Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries](https://doi.org/10.18653/v1/2024.acl-long.230) |  | 0 | This study investigates the privacy risks associated with text embeddings, focusing on the scenario where attackers cannot access the original embedding model. Contrary to previous research requiring direct model access, we explore a more realistic threat model by developing a transfer attack... | HongYi Lin, Hsiang Hsiao, ShouDe Lin, YuChe Tsai, YuHsiang Huang |  |
| 350 |  |  [Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding](https://doi.org/10.18653/v1/2024.acl-long.231) |  | 0 | Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF encounters numerous challenges, including the objective mismatch issue,... | Chengguo Yin, Honglin Han, Kuo Liao, Liqun Liu, Meng Zhao, Mengge Xue, Shuang Li, Zhenyu Hu |  |
| 351 |  |  [Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts](https://doi.org/10.18653/v1/2024.acl-long.232) |  | 0 | This study investigates the behaviors of Large Language Models (LLMs) when faced with conflicting prompts versus their internal memory. This will not only help to understand LLMs’ decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG).Drawing on... | Jiahao Ying, Kai Xiong, Long Cui, Yidong He, Yixin Cao, Yongbin Liu |  |
| 352 |  |  [CoCA: Fusing Position Embedding with Collinear Constrained Attention in Transformers for Long Context Window Extending](https://doi.org/10.18653/v1/2024.acl-long.233) |  | 0 | Self-attention and position embedding are two crucial modules in transformer-based Large Language Models (LLMs). However, the potential relationship between them is far from well studied, especially for long context window extending. In fact, anomalous behaviors that hinder long context... | Jianguo Li, Jing Ye, Qi Zhang, Shiyi Zhu, Siqiao Xue, Wei Jiang, Yifan Wu |  |
| 353 |  |  [InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification](https://doi.org/10.18653/v1/2024.acl-long.234) |  | 0 | Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs.... | Byron C. Wallace, Christin Seifert, Jan Trienes, Junyi Jessy Li, Jörg Schlötterer, Kyle Lo, Sebastian Joseph, Wei Xu |  |
| 354 |  |  [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](https://doi.org/10.18653/v1/2024.acl-long.235) |  | 0 | With the advancement of language models (LMs), their exposure to private data is increasingly inevitable, and their deployment (especially for smaller ones) on personal devices, such as PCs and smartphones, has become a prevailing trend. In contexts laden with user information, enabling models to... | Biqing Qi, Bowen Zhou, Ermo Hua, Jianyu Wang, Kaiyan Zhang, Ning Ding |  |
| 355 |  |  [DAPR: A Benchmark on Document-Aware Passage Retrieval](https://doi.org/10.18653/v1/2024.acl-long.236) |  | 0 | The work of neural retrieval so far focuses on ranking short texts and is challenged with long documents. There are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. Wikipedia articles, research papers, etc. We propose and name this task... | Iryna Gurevych, Kexin Wang, Nils Reimers |  |
| 356 |  |  [Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors](https://doi.org/10.18653/v1/2024.acl-long.237) |  | 0 | Multiple-Choice Questions (MCQs) constitute a critical area of research in the study of Large Language Models (LLMs). Previous works have investigated the selection bias problem in MCQs within few-shot scenarios, in which the LLM’s performance may be influenced by the presentation of answer... | Chengguo Yin, Honglin Han, Kuo Liao, Liqun Liu, Meng Zhao, Mengge Xue, Shuang Li, Zhenyu Hu |  |
| 357 |  |  [SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.238) |  | 0 | Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks across specialized domains, where the acquisition of precise and dependable knowledge is crucial. However, existing KG construction methods heavily rely on human intervention to attain qualified KGs, which severely hinders the... | Hanzhu Chen, Jie Wang, Jieping Ye, Qitan Lv, Xiaoqi Ni, Xu Shen |  |
| 358 |  |  [Uncertainty-Guided Modal Rebalance for Hateful Memes Detection](https://doi.org/10.18653/v1/2024.acl-long.239) |  | 0 | Hateful memes detection is a challenging multimodal understanding task that requires comprehensive learning of vision, language, and cross-modal interactions. Previous research has focused on developing effective fusion strategies for integrating hate information from different modalities. However,... | Chuanpeng Yang, Fuqing Zhu, Jizhong Han, Songlin Hu, Yaxin Liu |  |
| 359 |  |  [Missci: Reconstructing Fallacies in Misrepresented Science](https://doi.org/10.18653/v1/2024.acl-long.240) |  | 0 | Health-related misinformation on social networks can lead to poor decision-making and real-world dangers. Such misinformation often misrepresents scientific publications and cites them as “proof” to gain perceived credibility. To effectively counter such claims automatically, a system must explain... | Iryna Gurevych, Max Glockner, Preslav Nakov, Yufang Hou |  |
| 360 |  |  [Uncovering the Full Potential of Visual Grounding Methods in VQA](https://doi.org/10.18653/v1/2024.acl-long.241) |  | 0 | Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to improve VQA performance by strengthening a model’s reliance on question-relevant visual information. The presence of such relevant information in the visual input is typically assumed in training and testing. This... | Daniel Reich, Tanja Schultz |  |
| 361 |  |  [Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs](https://doi.org/10.18653/v1/2024.acl-long.242) |  | 0 | The integration of large language models (LLMs) and search engines represents a significant evolution in knowledge acquisition methodologies. However, determining the knowledge that an LLM already possesses and the knowledge that requires the help of a search engine remains an unresolved issue.... | JiRong Wen, Jiejun Tan, Kun Fang, Peidong Guo, Yutao Zhu, Zhicheng Dou |  |
| 362 |  |  [Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation](https://doi.org/10.18653/v1/2024.acl-long.243) |  | 0 | Generative AI systems have become ubiquitous for all kinds of modalities, which makes the issue of the evaluation of such models more pressing. One popular approach is preference ratings, where the generated outputs of different systems are shown to evaluators who choose their preferences. In... | Don Tuggener, Jan Deriu, Mark Cieliebak, Pius von Däniken |  |
| 363 |  |  [LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback](https://doi.org/10.18653/v1/2024.acl-long.244) |  | 0 | Ensuring that online discussions are civil and productive is a major challenge for social media platforms. Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review. However, this kind of post-hoc... | Alireza Bayat Makou, Gabriella Skitalinskaya, Henning Wachsmuth, Timon Ziegenbein |  |
| 364 |  |  [Graph Language Models](https://doi.org/10.18653/v1/2024.acl-long.245) |  | 0 | While Language Models (LMs) are the workhorses of NLP, their interplay with structured knowledge graphs (KGs) is still actively researched. Current methods for encoding such graphs typically either (i) linearize them for embedding with LMs – which underutilize structural information, or (ii) use... | Anette Frank, Moritz Plenz |  |
| 365 |  |  [Analyzing Semantic Change through Lexical Replacements](https://doi.org/10.18653/v1/2024.acl-long.246) |  | 0 | Modern language models are capable of contextualizing words based on their surrounding context. However, this capability is often compromised due to semantic change that leads to words being used in new, unexpected contexts not encountered during pre-training. In this paper, we model semantic... | Francesco Periti, Haim Dubossarsky, Nina Tahmasebi, Pierluigi Cassotti |  |
| 366 |  |  [Exploiting Intrinsic Multilateral Logical Rules for Weakly Supervised Natural Language Video Localization](https://doi.org/10.18653/v1/2024.acl-long.247) |  | 0 | Weakly supervised natural language video localization (WS-NLVL) aims to retrieve the moment corresponding to a language query in a video with only video-language pairs utilized during training. Despite great success, existing WS-NLVL methods seldomly consider the complex temporal relations... | Cheng Deng, Kun Wei, Xu Yang, Zhe Xu |  |
| 367 |  |  [Interpretability of Language Models via Task Spaces](https://doi.org/10.18653/v1/2024.acl-long.248) |  | 0 | The usual way to interpret language models (LMs) is to test their performance on different benchmarks and subsequently infer their internal processes.In this paper, we present an alternative approach, concentrating on the _quality_ of LM processing, with a focus on their language abilities.To this... | Dieuwke Hupkes, Elia Bruni, Jaap Jumelet, Lucas Weber |  |
| 368 |  |  [Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types](https://doi.org/10.18653/v1/2024.acl-long.249) |  | 0 | There is abundant evidence of the fact that the way words change their meaning can be classified in different types of change, highlighting the relationship between the old and new meanings (among which generalisation, specialisation and co-hyponymy transfer).In this paper, we present a way of... | Nina Tahmasebi, Pierluigi Cassotti, Stefano De Pascale |  |
| 369 |  |  [Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators](https://doi.org/10.18653/v1/2024.acl-long.250) |  | 0 | Large Language Models (LLMs) tend to be unreliable on fact-based answers.To address this problem, NLP researchers have proposed a range of techniques to estimate LLM’s confidence over facts. However, due to the lack of a systematic comparison, it is not clear how the different methods compare to... | Laura Aina, Lluís Màrquez, Matéo Mahaut, Momchil Hardalov, Paula Czarnowska, Thomas Müller |  |
| 370 |  |  [StepCoder: Improving Code Generation with Reinforcement Learning from Compiler Feedback](https://doi.org/10.18653/v1/2024.acl-long.251) |  | 0 | The advancement of large language models (LLMs) has significantly propelled the field of code generation. Previous work integrated reinforcement learning (RL) with compiler feedback for exploring the output space of LLMs to enhance code generation quality. However, the lengthy code generated by... | Caishuang Huang, Enyu Zhou, Haoxiang Jia, Junjie Shan, Limao Xiong, Qi Zhang, Rui Zheng, Shihan Dou, Tao Gui, Tao Ji, Xiao Wang, Xiaoran Fan, Xuanjing Huang, Yan Liu, Yuhao Zhou, Zhiheng Xi |  |
| 371 |  |  [One-Shot Learning as Instruction Data Prospector for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.252) |  | 0 | Contemporary practices in instruction tuning often hinge on enlarging data scaling without a clear strategy for ensuring data quality, inadvertently introducing noise that may compromise model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that... | Binyuan Hui, Fei Huang, Jiaxi Yang, Junhao Liu, Lei Zhang, LingHao Chen, Min Yang, Shuzheng Si, Tongliang Liu, Xiaobo Xia, Yongbin Li, Yunshui Li |  |
| 372 |  |  [Navigating the OverKill in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.253) |  | 0 | Large language models are meticulously aligned to be both helpful and harmless. However, recent research points to a potential overkill which means models may refuse to answer benign queries. In this paper, we investigate the factors for overkill by exploring how models handle and determine the... | Chenyu Shi, Dahua Lin, Qi Zhang, Qiming Ge, Songyang Gao, Tao Gui, Xianjun Yang, Xiao Wang, Xuanjing Huang, Xun Zhao |  |
| 373 |  |  [A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains](https://doi.org/10.18653/v1/2024.acl-long.254) |  | 0 | Prompting language models to provide step-by-step answers (e.g., “Chain-of-Thought”) is the prominent approach for complex reasoning tasks, where more accurate reasoning chains typically improve downstream task performance. Recent literature discusses automatic methods to verify reasoning to... | Alon Jacovi, Bernd Bohnet, Jonathan Herzig, Michael Collins, Michael Tseng, Mor Geva, Or Honovich, Roee Aharoni, Yonatan Bitton |  |
| 374 |  |  [Re3: A Holistic Framework and Dataset for Modeling Collaborative Document Revision](https://doi.org/10.18653/v1/2024.acl-long.255) |  | 0 | Collaborative review and revision of textual documents is the core of knowledge work and a promising target for empirical analysis and NLP assistance. Yet, a holistic framework that would allow modeling complex relationships between document revisions, reviews and author responses is lacking. To... | Ilia Kuznetsov, Iryna Gurevych, Qian Ruan |  |
| 375 |  |  [NextLevelBERT: Masked Language Modeling with Higher-Level Representations for Long Documents](https://doi.org/10.18653/v1/2024.acl-long.256) |  | 0 | While (large) language models have significantly improved over the last years, they still struggle to sensibly process long sequences found, e.g., in books, due to the quadratic scaling of the underlying attention mechanism. To address this, we propose NextLevelBERT, a Masked Language Model... | Christoph Hönes, Gerard de Melo, Maximilian Schall, Tamara Czinczoll |  |
| 376 |  |  [FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.257) |  | 0 | The ability to follow instructions is crucial for Large Language Models (LLMs) to handle various real-world applications. Existing benchmarks primarily focus on evaluating pure response quality, rather than assessing whether the response follows constraints stated in the instruction. To fill this... | Fei Mi, Liangyou Li, Lifeng Shang, Qun Liu, Wanjun Zhong, Wei Wang, Xin Jiang, Xingshan Zeng, Yufei Wang, Yuxin Jiang |  |
| 377 |  |  [Learning to Edit: Aligning LLMs with Knowledge Editing](https://doi.org/10.18653/v1/2024.acl-long.258) |  | 0 | Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated... | Chuhan Wu, Jiahui Gao, Liangyou Li, Lifeng Shang, Qun Liu, Ruiming Tang, Wanjun Zhong, Wei Wang, Xin Jiang, Xingshan Zeng, Yufei Wang, Yuxin Jiang |  |
| 378 |  |  [DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.259) |  | 0 | Code Large Language Models (Code LLMs) have demonstrated outstanding performance in code-related tasks. Various instruction finetuning approaches have been proposed to boost the code generation performance of pre-trained Code LLMs. In this paper, we introduce a diverse instruction model DolphCoder... | Guanting Dong, Jingang Wang, Keqing He, Mengdi Zhang, Muxi Diao, Pei Wang, Weihao Zeng, Weiran Xu, Xunliang Cai, Yejie Wang |  |
| 379 |  |  [When Only Time Will Tell: Interpreting How Transformers Process Local Ambiguities Through the Lens of Restart-Incrementality](https://doi.org/10.18653/v1/2024.acl-long.260) |  | 0 | Incremental models that process sentences one token at a time will sometimes encounter points where more than one interpretation is possible. Causal models are forced to output one interpretation and continue, whereas models that can revise may edit their previous output as the ambiguity is... | Brielen Madureira, David Schlangen, Patrick Kahardipraja |  |
| 380 |  |  [SpaRC and SpaRP: Spatial Reasoning Characterization and Path Generation for Understanding Spatial Reasoning Capability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.261) |  | 0 | Spatial reasoning is a crucial component of both biological and artificial intelligence. In this work, we present a comprehensive study of the capability of current state-of-the-art large language models (LLMs) on spatial reasoning. To support our study, we created and contribute a novel Spatial... | Iryna Gurevych, Md Imbesat Hassan Rizvi, Xiaodan Zhu |  |
| 381 |  |  [Planning Like Human: A Dual-process Framework for Dialogue Planning](https://doi.org/10.18653/v1/2024.acl-long.262) |  | 0 | In proactive dialogue, the challenge lies not just in generating responses but in steering conversations toward predetermined goals, a task where Large Language Models (LLMs) typically struggle due to their reactive nature. Traditional approaches to enhance dialogue planning in LLMs, ranging from... | Bing Qin, Lizi Liao, Ming Liu, Tao He, Yixin Cao, Yuanxing Liu, Zerui Chen |  |
| 382 |  |  [Spectral Filters, Dark Signals, and Attention Sinks](https://doi.org/10.18653/v1/2024.acl-long.263) |  | 0 | Projecting intermediate representations onto the vocabulary is an increasingly popular interpretation tool for transformer-based LLMs, also known as the logit lens (Nostalgebraist). We propose a quantitative extension to this approach and define spectral filters on intermediate representations... | Nicola Cancedda |  |
| 383 |  |  [DiffuCOMET: Contextual Commonsense Knowledge Diffusion](https://doi.org/10.18653/v1/2024.acl-long.264) |  | 0 | Inferring contextually-relevant and diverse commonsense to understand narratives remains challenging for knowledge models. In this work, we develop a series of knowledge models, DiffuCOMET, that leverage diffusion to learn to reconstruct the implicit semantic connections between narrative contexts... | Antoine Bosselut, Hiromi Wakaki, Mengjie Zhao, Mete Ismayilzada, Silin Gao, Yuki Mitsufuji |  |
| 384 |  |  [Systematic Task Exploration with LLMs: A Study in Citation Text Generation](https://doi.org/10.18653/v1/2024.acl-long.265) |  | 0 | Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language generation (NLG) tasks. Yet, this flexibility brings new challenges, as it introduces new degrees of freedom in formulating the task inputs and instructions and in evaluating... | Furkan Sahinuç, Ilia Kuznetsov, Iryna Gurevych, Yufang Hou |  |
| 385 |  |  [Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition](https://doi.org/10.18653/v1/2024.acl-long.266) |  | 0 | Recent work on dialogue-based collaborative plan acquisition (CPA) has suggested that Theory of Mind (ToM) modelling can improve missing knowledge prediction in settings with asymmetric skill-sets and knowledge. Although ToM was claimed to be important for effective collaboration, its real impact... | Adnen Abdessaied, Andreas Bulling, Constantin Ruhdorfer, Lei Shi, Matteo Bortoletto |  |
| 386 |  |  [Temporal Knowledge Question Answering via Abstract Reasoning Induction](https://doi.org/10.18653/v1/2024.acl-long.267) |  | 0 | In this study, we address the challenge of enhancing temporal knowledge reasoning in Large Language Models (LLMs). LLMs often struggle with this task, leading to the generation of inaccurate or misleading responses. This issue mainly arises from their limited ability to handle evolving factual... | Baotian Hu, Dongfang Li, Min Zhang, Xiang Zhao, Ziyang Chen |  |
| 387 |  |  [Who Wrote this Code? Watermarking for Code Generation](https://doi.org/10.18653/v1/2024.acl-long.268) |  | 0 | Since the remarkable generation performance of large language models raised ethical and legal concerns, approaches to detect machine-generated text by embedding watermarks are being developed.However, we discover that the existing works fail to function appropriately in code generation tasks due to... | Gunhee Kim, Hwaran Lee, Ilgee Hong, Jaewoo Ahn, Jamin Shin, Sangdoo Yun, Seokhee Hong, Taehyun Lee |  |
| 388 |  |  [MapCoder: Multi-Agent Code Generation for Competitive Problem Solving](https://doi.org/10.18653/v1/2024.acl-long.269) |  | 0 | Code synthesis, which requires a deep understanding of complex natural language (NL) problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. Thus, while large... | Md. Ashraful Islam, Md. Rizwan Parvez, Mohammed Eunus Ali |  |
| 389 |  |  [RelayAttention for Efficient Large Language Model Serving with Long System Prompts](https://doi.org/10.18653/v1/2024.acl-long.270) |  | 0 | A practical large language model (LLM) service may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across requests. However, the long system prompt causes throughput/latency bottlenecks as the cost of generating the next... | Lei Zhu, Rynson W. H. Lau, Wayne Zhang, Xinjiang Wang |  |
| 390 |  |  [Boosting Language Models Reasoning with Chain-of-Knowledge Prompting](https://doi.org/10.18653/v1/2024.acl-long.271) |  | 0 | Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like “Let’s think step by step” or multiple in-context exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate... | Jianing Wang, Ming Gao, Qiushi Sun, Xiang Li |  |
| 391 |  |  [Open Grounded Planning: Challenges and Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.272) |  | 0 | The emergence of large language models (LLMs) has increasingly drawn attention to the use of LLMs for human-like planning. Existing work on LLM-based planning either focuses on leveraging the inherent language generation capabilities of LLMs to produce free-style plans, or employs reinforcement... | Hongyu Lin, Le Sun, Shiguang Guo, Xianpei Han, Yaojie Lu, Ziliang Deng |  |
| 392 |  |  [LLM Knows Body Language, Too: Translating Speech Voices into Human Gestures](https://doi.org/10.18653/v1/2024.acl-long.273) |  | 0 | In response to the escalating demand for digital human representations, progress has been made in the generation of realistic human gestures from given speeches. Despite the remarkable achievements of recent research, the generation process frequently includes unintended, meaningless, or... | Cheng Deng, Chenghao Xu, Guangtao Lyu, Jiexi Yan, Muli Yang |  |
| 393 |  |  [QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction](https://doi.org/10.18653/v1/2024.acl-long.274) |  | 0 | Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which... | Chaoyun Zhang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiang Huang, Yong Xu, Yuzhong Qu |  |
| 394 |  |  [PITA: Prompting Task Interaction for Argumentation Mining](https://doi.org/10.18653/v1/2024.acl-long.275) |  | 0 | Argumentation mining (AM) aims to detect the arguments and their inherent relations from argumentative textual compositions. Generally, AM comprises three key challenging subtasks, including argument component type classification (ACTC), argumentative relation identification (ARI), and... | Bin Liang, Caihua Yang, Jianzhu Bao, Min Yang, Muyi Wang, Ruifeng Xu, Xiaoyan Zhao, Yang Sun |  |
| 395 |  |  [Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.276) |  | 0 | Large Language Models (LLMs) show promising results in language generation and instruction following but frequently “hallucinate”, making their outputs less reliable. Despite Uncertainty Quantification’s (UQ) potential solutions, implementing it accurately within LLMs is challenging. Our research... | Alex Zavalny, Bhavya Kailkhura, Chenan Wang, Hao Cheng, Jinhao Duan, Kaidi Xu, Renjing Xu, Shiqi Wang |  |
| 396 |  |  [Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations](https://doi.org/10.18653/v1/2024.acl-long.277) |  | 0 | Vision-and-language (VL) models with separate encoders for each modality (e.g., CLIP) have become the go-to models for zero-shot image classification and image-text retrieval. They are, however, mostly evaluated in English as multilingual benchmarks are limited in availability. We introduce... | Goran Glavas, Gregor Geigle, Radu Timofte |  |
| 397 |  |  [Estimating Agreement by Chance for Sequence Annotation](https://doi.org/10.18653/v1/2024.acl-long.278) |  | 0 | In the field of natural language processing, correction of performance assessment for chance agreement plays a crucial role in evaluating the reliability of annotations. However, there is a notable dearth of research focusing on chance correction for assessing the reliability of sequence annotation... | Ao Yuan, Carolyn P. Rosé, Chunxiao Zhou, Diya Li |  |
| 398 |  |  [Are Emergent Abilities in Large Language Models just In-Context Learning?](https://doi.org/10.18653/v1/2024.acl-long.279) |  | 0 | Large language models, comprising billions of parameters and pre-trained on extensive web-scale corpora, have been claimed to acquire certain capabilities without having been specifically trained on them. These capabilities, referred to as “emergent abilities,” have been a driving force in... | Harish Tayyar Madabushi, Irina Bigoulaeva, Iryna Gurevych, Rachneet Sachdeva, Sheng Lu |  |
| 399 |  |  [WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.280) |  | 0 | Recent work demonstrates that, after instruction tuning, Code Large Language Models (Code LLMs) can obtain impressive capabilities to address a wide range of code-related tasks. However, current instruction tuning methods for Code LLMs mainly focus on the traditional code generation task, resulting... | Can Xu, Ning Shang, Qiufeng Yin, Wenxiang Hu, Xin Zhang, Yangyu Huang, Yishujie Zhao, Zhaojian Yu |  |
| 400 |  |  [Eliciting Better Multilingual Structured Reasoning from LLMs through Code](https://doi.org/10.18653/v1/2024.acl-long.281) |  | 0 | The development of large language models (LLM) has shown progress on reasoning, though studies have largely considered either English or simple reasoning tasks. To address this, we introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across... | Bryan Li, Daniele Bonadiman, Nikolaos Pappas, Saab Mansour, Tamer Alkhouli |  |
| 401 |  |  [OLIVE: Object Level In-Context Visual Embeddings](https://doi.org/10.18653/v1/2024.acl-long.282) |  | 0 | Recent generalist vision-language models (VLMs) have demonstrated impressive reasoning capabilities across diverse multimodal tasks. However, these models still struggle with fine-grained object-level understanding and grounding. In terms of modeling, existing VLMs implicitly align text tokens with... | Junjie Hu, Timothy Ossowski |  |
| 402 |  |  [Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness](https://doi.org/10.18653/v1/2024.acl-long.283) |  | 0 | We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training... | Jiuhai Chen, Jonas Mueller |  |
| 403 |  |  [Marathon: A Race Through the Realm of Long Context with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.284) |  | 0 | With the advancement of large language models (LLMs) and the expansion of their context windows, existing long-context benchmarks fall short in effectively evaluating the models’ comprehension and reasoning abilities in extended texts. Moreover, conventional benchmarks relying on F1 metrics often... | Jiaxi Yang, Junhao Liu, Lei Zhang, Longze Chen, Min Yang, Run Luo, Yunshui Li, Ziqiang Liu |  |
| 404 |  |  [Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph](https://doi.org/10.18653/v1/2024.acl-long.285) |  | 0 | Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs). However, it can fall short in specific scenarios where simple customized methods excel. In this paper, we delve into the patent approval prediction task and unveil that simple... | Animesh Kumar, Beilei He, Feng Yao, Jingbo Shang, Kewen Zhao, Vish Krishnan, Xiaochen Gao |  |
| 405 |  |  [PCAD: Towards ASR-Robust Spoken Language Understanding via Prototype Calibration and Asymmetric Decoupling](https://doi.org/10.18653/v1/2024.acl-long.286) |  | 0 | Spoken language understanding (SLU) inevitably suffers from error propagation from automatic speech recognition (ASR) in actual scenarios. Some recent works attempt to alleviate this issue through contrastive learning. However, they (1) sample negative pairs incorrectly in pre-training; (2) only... | Liming Liang, Xianwei Zhuang, Xuxin Cheng, Yuexian Zou, Yuxin Xie, Zhichang Wang, Zhiqi Huang |  |
| 406 |  |  [Rethinking the Multimodal Correlation of Multimodal Sequential Learning via Generalizable Attentional Results Alignment](https://doi.org/10.18653/v1/2024.acl-long.287) |  | 0 | Transformer-based methods have gone mainstream in multimodal sequential learning. The intra and inter modality interactions are captured by the query-key associations of multi-head attention. In this way, the calculated multimodal contexts (attentional results) are expected to be relevant to the... | Linjun Li, Tao Jin, Wang Lin, Xize Cheng, Ye Wang, Zhou Zhao |  |
| 407 |  |  [UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation](https://doi.org/10.18653/v1/2024.acl-long.288) |  | 0 | Large language models (LLMs) produce hallucinated text, compromising their practical utility in professional contexts. To assess the reliability of LLMs, numerous initiatives have developed benchmark evaluations for hallucination phenomena. However, they often employ constrained generation... | Bo Tang, Cheng Peng, Dawei He, Feiyu Xiong, Haiying Deng, Shichao Song, Simin Niu, Xun Liang, Yezhaohui Wang, Zhiyu Li, Zhonghao Wang |  |
| 408 |  |  [PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers](https://doi.org/10.18653/v1/2024.acl-long.289) |  | 0 | Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We... | Bill Byrne, Jingbiao Mei, Jinghong Chen, Weizhe Lin |  |
| 409 |  |  [Triple-Encoders: Representations That Fire Together, Wire Together](https://doi.org/10.18653/v1/2024.acl-long.290) |  | 0 | Search-based dialog models typically re-encode the dialog history at every turn, incurring high cost.Curved Contrastive Learning, a representation learning method that encodes relative distances between utterances into the embedding space via a bi-encoder, has recently shown promising results for... | Florian Mai, Gerasimos Spanakis, Iryna Gurevych, JustusJonas Erker, Nils Reimers |  |
| 410 |  |  [Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.291) |  | 0 | Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in... | Bill Byrne, Jingbiao Mei, Jinghong Chen, Marcus Tomalin, Weizhe Lin |  |
| 411 |  |  [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://doi.org/10.18653/v1/2024.acl-long.292) |  | 0 | Large Language Models (LLMs) exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers... | Guiyang Hou, Hai Wu, Ke Tang, Mengna Wang, Peng Li, Weiming Lu, Wenqi Zhang, Yongliang Shen, Yueting Zhuang, Zeqi Tan |  |
| 412 |  |  [Your Transformer is Secretly Linear](https://doi.org/10.18653/v1/2024.acl-long.293) |  | 0 | This paper reveals a novel linear characteristic exclusive to transformer decoders, including models like GPT, LLaMA, OPT, BLOOM and others. We analyze embedding transformations between sequential layers, uncovering an almost perfect linear relationship (Procrustes similarity score of 0.99).... | Andrey Kuznetsov, Anton Razzhigaev, Denis Dimitrov, Elizaveta Goncharova, Ivan V. Oseledets, Matvey Mikhalchuk, Nikolai Gerasimenko |  |
| 413 |  |  [Noise Correction on Subjective Datasets](https://doi.org/10.18653/v1/2024.acl-long.294) |  | 0 | Incorporating every annotator’s perspective is crucial for unbiased data modeling. Annotator fatigue and changing opinions over time can distort dataset annotations. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction... | Uthman Jinadu, Yi Ding |  |
| 414 |  |  [Generative Explore-Exploit: Training-free Optimization of Generative Recommender Systems using LLM Optimizers](https://doi.org/10.18653/v1/2024.acl-long.295) |  | 0 | Recommender systems are widely used to suggest engaging content, and Large Language Models (LLMs) have given rise to generative recommenders. Such systems can directly generate items, including for open-set tasks like question suggestion. While the world knowledge of LLMs enables good... | Besnik Fetahu, Davis Yoshida, Giuseppe Castellucci, Jason Ingyu Choi, Lütfi Kerem Senel, Nikhita Vedula, Shervin Malmasi, Zhiyu Chen |  |
| 415 |  |  [Instruction-tuned Language Models are Better Knowledge Learners](https://doi.org/10.18653/v1/2024.acl-long.296) |  | 0 | In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by... | Chunting Zhou, Graham Neubig, Pedro Rodríguez, Srini Iyer, Weijia Shi, Wentau Yih, Xi Victoria Lin, Zhengbao Jiang, Zhiqing Sun |  |
| 416 |  |  [What Do Language Models Hear? Probing for Auditory Representations in Language Models](https://doi.org/10.18653/v1/2024.acl-long.297) |  | 0 | This work explores whether language models encode meaningfully grounded representations of sounds of objects. We learn a linear probe that retrieves the correct text representation of an object given a snippet of audio related to that object, where the sound representation is given by a pretrained... | Jerry Ngo, Yoon Kim |  |
| 417 |  |  [Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs](https://doi.org/10.18653/v1/2024.acl-long.298) |  | 0 | With the advent of large language models (LLM), the line between human-crafted and machine-generated texts has become increasingly blurred. This paper delves into the inquiry of identifying discernible and unique linguistic properties in texts that were written by humans, particularly uncovering... | Dongyeop Kang, Kwang Hee Lee, Preston Zhu, Vipul Raheja, Zae Myung Kim |  |
| 418 |  |  [Jailbreak Open-Sourced Large Language Models via Enforced Decoding](https://doi.org/10.18653/v1/2024.acl-long.299) |  | 0 | Large Language Models (LLMs) have achieved unprecedented performance in Natural Language Generation (NLG) tasks. However, many existing studies have shown that they could be misused to generate undesired content. In response, before releasing LLMs for public access, model developers usually align... | Bochuan Cao, Dinghao Wu, Hangfan Zhang, Huaisheng Zhu, Jinghui Chen, Jinyuan Jia, Lu Lin, Zhimeng Guo |  |
| 419 |  |  [NICE: To Optimize In-Context Examples or Not?](https://doi.org/10.18653/v1/2024.acl-long.300) |  | 0 | Recent work shows that in-context learning and optimization of in-context examples (ICE) can significantly improve the accuracy of large language models (LLMs) on a wide range of tasks, leading to an apparent consensus that ICE optimization is crucial for better performance. However, most of these... | Amit Deshpande, Amit Sharma, Pragya Srivastava, Satvik Golechha |  |
| 420 |  |  [CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation](https://doi.org/10.18653/v1/2024.acl-long.301) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable performance on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most... | Haitian Liu, Hari Sundaram, Li Zhu, Qian Chen, Shuiguang Deng, Tingyu Lin, Weishan Zhao, Weixiang Yan, Wen Wang, Yunkun Wang, Yunzhe Li |  |
| 421 |  |  [Digital Socrates: Evaluating LLMs through Explanation Critiques](https://doi.org/10.18653/v1/2024.acl-long.302) |  | 0 | While LLMs can provide reasoned explanations along with their answers, the nature and quality of those explanations are still poorly understood. In response, our goal is to define a detailed way of characterizing the explanation capabilities of modern models and to create a nuanced, interpretable... | Oyvind Tafjord, Peter Clark, Yuling Gu |  |
| 422 |  |  [SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://doi.org/10.18653/v1/2024.acl-long.303) |  | 0 | As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, which aim to provoke unintended and unsafe... | Bill Yuchen Lin, Fengqing Jiang, Jinyuan Jia, Luyao Niu, Radha Poovendran, Zhangchen Xu |  |
| 423 |  |  [Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?](https://doi.org/10.18653/v1/2024.acl-long.304) |  | 0 | Large language models (LLMs) are typically prompted to follow a single instruction per inference call. In this work, we analyze whether LLMs also hold the capability to handle multiple instructions simultaneously, denoted as Multi-Task Inference. For this purpose, we introduce the MTI Bench... | Guijin Son, Ilgyun Jeong, Sangdae Nam, Sangwon Baek, Seungone Kim |  |
| 424 |  |  [Experiential Co-Learning of Software-Developing Agents](https://doi.org/10.18653/v1/2024.acl-long.305) |  | 0 | Recent advancements in large language models (LLMs) have brought significant changes to various domains, especially through LLM-driven autonomous agents. A representative scenario is in software development, where LLM agents demonstrate efficient collaboration, task division, and assurance of... | Chen Qian, Cheng Yang, Jiahao Li, Maosong Sun, Wei Liu, Weize Chen, Xiaoyin Che, Xin Cong, Yifei Wang, Yufan Dang, Zhiyuan Liu, Zihao Xie |  |
| 425 |  |  [Learning Geometry-Aware Representations for New Intent Discovery](https://doi.org/10.18653/v1/2024.acl-long.306) |  | 0 | New intent discovery (NID) is an important problem for deploying practical dialogue systems, which trains intent classifiers on a semi-supervised corpus where unlabeled user utterances contain both known and novel intents. Most existing NID algorithms place hope on the sample similarity to cluster... | Gang Chen, Haobo Wang, Junbo Zhao, Kai Tang, Lei Feng, Runze Wu, Xiao Ding |  |
| 426 |  |  [Speaker Verification in Agent-generated Conversations](https://doi.org/10.18653/v1/2024.acl-long.307) |  | 0 | The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks. However, the... | EePeng Lim, Heyan Huang, Jing Jiang, Palakorn Achananuparp, Yizhe Yang |  |
| 427 |  |  [Benchmarking Data Science Agents](https://doi.org/10.18653/v1/2024.acl-long.308) |  | 0 | In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools of data science, presenting significant challenges even for specialists. Large Language Models (LLMs) have emerged as promising aids as data science agents, assisting humans in data... | Kan Ren, Nan Chen, Qiyang Jiang, Xingyu Han, Yuge Zhang, Yuqing Yang |  |
| 428 |  |  [Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.309) |  | 0 | Large language models (LLMs) demonstrate remarkable multilingual capabilities without being pre-trained on specially curated multilingual parallel corpora.It remains a challenging problem to explain the underlying mechanisms by which LLMs process multilingual texts.In this paper, we delve into the... | Dongdong Zhang, Furu Wei, Haoyang Huang, JiRong Wen, Tianyi Tang, Wenyang Luo, Xiaolei Wang, Xin Zhao |  |
| 429 |  |  [Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.310) |  | 0 | Recent advancements in Large Language Models (LLMs) have showcased their remarkable capabilities in text understanding and generation. However, even stronger LLMs are susceptible to acquiring erroneous or obsolete information from the training corpus. Direct secondary fine-tuning with data... | Chengming Li, Dingwei Chen, Min Yang, Ruifeng Xu, Shiwen Ni, Xiping Hu |  |
| 430 |  |  [A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques](https://doi.org/10.18653/v1/2024.acl-long.311) |  | 0 | Large language models are first pre-trained on trillions of tokens and then instruction-tuned or aligned to specific preferences. While pre-training remains out of reach for most researchers due to the compute required, fine-tuning has become affordable thanks to parameter-efficient methods such as... | Amal Zouaq, Matthew Riemer, Megh Thakkar, Payel Das, PinYu Chen, Quentin Fournier, Sarath Chandar |  |
| 431 |  |  [Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation](https://doi.org/10.18653/v1/2024.acl-long.312) |  | 0 | Zero-shot dialogue state tracking (DST) seeks to enable dialogue systems to transition to unfamiliar domains without manual annotation or extensive retraining. Prior research has approached this objective by embedding prompts into language models (LMs). Common methodologies include integrating... | Jin Wang, Xiang Luo, Xuejie Zhang, Zhiwen Tang |  |
| 432 |  |  [PRP-Graph: Pairwise Ranking Prompting to LLMs with Graph Aggregation for Effective Text Re-ranking](https://doi.org/10.18653/v1/2024.acl-long.313) |  | 0 | Pairwise Ranking Prompting (PRP) demonstrates impressive effectiveness in zero-shot document re-ranking tasks with large language models (LLMs). However, in the existing methods, PRP only outputs the same label for the comparison results of different confidence intervals without considering the... | Ben He, Jian Luo, Le Sun, Xuanang Chen |  |
| 433 |  |  [RepCodec: A Speech Representation Codec for Speech Tokenization](https://doi.org/10.18653/v1/2024.acl-long.314) |  | 0 | With recent rapid growth of large language models (LLMs), discrete speech tokenization has played an important role for injecting speech into LLMs. However, this discretization gives rise to a loss of information, consequently impairing overall performance. To improve the performance of these... | Chutong Meng, Tom Ko, Zhichao Huang |  |
| 434 |  |  [GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick](https://doi.org/10.18653/v1/2024.acl-long.315) |  | 0 | Large language models (LLMs) excellently generate human-like text, but also raise concerns about misuse in fake news and academic dishonesty. Decoding-based watermark, particularly the watermark based on the GumbelMax trick (GM watermark), is a standout solution for safeguarding machine-generated... | Jiangjie Chen, Jiayi Fu, Ruihan Yang, Xuandong Zhao, Yanghua Xiao, Yuansen Zhang |  |
| 435 |  |  [Event-Radar: Event-driven Multi-View Learning for Multimodal Fake News Detection](https://doi.org/10.18653/v1/2024.acl-long.316) |  | 0 | The swift detection of multimedia fake news has emerged as a crucial task in combating malicious propaganda and safeguarding the security of the online environment. While existing methods have achieved commendable results in modeling entity-level inconsistency, addressing event-level inconsistency... | Hao Guo, Minnan Luo, Xiang Zhao, Yiran Hao, Zhi Zeng, Zihan Ma |  |
| 436 |  |  [Fine-Grained Modeling of Narrative Context: A Coherence Perspective via Retrospective Questions](https://doi.org/10.18653/v1/2024.acl-long.317) |  | 0 | This work introduces an original and practical paradigm for narrative comprehension, stemming from the characteristics that individual passages within narratives tend to be more cohesively related than isolated.Complementary to the common end-to-end paradigm, we propose a fine-grained modeling of... | Jiangnan Li, Jie Zhou, Liyan Xu, Mo Yu |  |
| 437 |  |  [Stealthy Attack on Large Language Model based Recommendation](https://doi.org/10.18653/v1/2024.acl-long.318) |  | 0 | Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of... | Guibing Guo, Jinghao Zhang, Liang Wang, Qiang Liu, Shu Wu, Yuting Liu |  |
| 438 |  |  [Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.319) |  | 0 | The evaluation of summary quality encompasses diverse dimensions such as consistency, coherence, relevance, and fluency. However, existing summarization methods often target a specific dimension, facing challenges in generating well-balanced summaries across multiple dimensions. In this paper, we... | Gary Lee, Heejin Do, Jungseul Ok, Sangwon Ryu, Yunsu Kim |  |
| 439 |  |  [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://doi.org/10.18653/v1/2024.acl-long.320) |  | 0 | In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models insuch domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or... | Ang Lv, Changyu Chen, JiRong Wen, Rui Yan, TingEn Lin, Xin Gao, Xiting Wang, Yongbin Li, Yuchuan Wu |  |
| 440 |  |  [SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning](https://doi.org/10.18653/v1/2024.acl-long.321) |  | 0 | Elucidating the reasoning process with structured explanations from question to answer is crucial, as it significantly enhances the interpretability, traceability, and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricately... | Chao Yang, Fuying Ye, Guoxin Chen, Kexin Tang, Yiming Qian, Yu Qiao |  |
| 441 |  |  [Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning](https://doi.org/10.18653/v1/2024.acl-long.322) |  | 0 | Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization of cumbersome language models in real-world settings. However, as datasets in such environments often contain noisy labels that adversely affect performance, PEFT methods are inevitably exposed to noisy labels. Despite... | Junho Kim, SangKeun Lee, Yeachan Kim |  |
| 442 |  |  [SparseFlow: Accelerating Transformers by Sparsifying Information Flows](https://doi.org/10.18653/v1/2024.acl-long.323) |  | 0 | Transformers have become the de-facto standard for natural language processing. However, dense information flows within transformers pose significant challenges for real-time and resource-constrained devices, as computational complexity grows quadratically with sequence length. To counteract such... | SangKeun Lee, Yeachan Kim |  |
| 443 |  |  [ProtT3: Protein-to-Text Generation for Text-based Protein Understanding](https://doi.org/10.18653/v1/2024.acl-long.324) |  | 0 | Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models... | An Zhang, Enzhi Zhang, Hao Fei, Kenji Kawaguchi, TatSeng Chua, Xiang Wang, Zhiyuan Liu |  |
| 444 |  |  [KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.325) |  | 0 | Automatic evaluation methods for large language models (LLMs) are hindered by data contamination, leading to inflated assessments of their effectiveness. Existing strategies, which aim to detect contaminated texts, focus on quantifying contamination status instead of accurately gauging model... | Chang Gao, Jindong Wang, Shikun Zhang, Wei Ye, Wenjin Yao, Xing Xie, Yidong Wang, Yue Zhang, Zhuohao Yu |  |
| 445 |  |  [EmoBench: Evaluating the Emotional Intelligence of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.326) |  | 0 | Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on... | Alvionna S. Sunaryo, Jinfeng Zhou, June M. Liu, Minlie Huang, Rada Mihalcea, Sahand Sabour, Siyang Liu, Tatia M. C. Lee, Zheyuan Zhang |  |
| 446 |  |  [Are AI-Generated Text Detectors Robust to Adversarial Perturbations?](https://doi.org/10.18653/v1/2024.acl-long.327) |  | 0 | The widespread use of large language models (LLMs) has sparked concerns about the potential misuse of AI-generated text, as these models can produce content that closely resembles human-generated text. Current detectors for AI-generated text (AIGT) lack robustness against adversarial perturbations,... | Guanhua Huang, Mingze Wang, Yongjian You, Yuchen Zhang, Zhe Li, Zhouwang Yang |  |
| 447 |  |  [FinTextQA: A Dataset for Long-form Financial Question Answering](https://doi.org/10.18653/v1/2024.acl-long.328) |  | 0 | Accurate evaluation of financial question answering (QA) systems necessitates a comprehensive dataset encompassing diverse question types and contexts. However, current financial QA datasets lack scope diversity and question complexity. This work introduces FinTextQA, a novel dataset for long-form... | Bing Zhu, Jian Chen, Junwei Liang, Kehui Chen, Loh Xin, Peilin Zhou, Yining Hua, Ziyuan Li |  |
| 448 |  |  [On Measuring Faithfulness or Self-consistency of Natural Language Explanations](https://doi.org/10.18653/v1/2024.acl-long.329) |  | 0 | Large language models (LLMs) can explain their predictions through post-hoc or Chain-of-Thought (CoT) explanations. But an LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of... | Anette Frank, Letitia Parcalabescu |  |
| 449 |  |  [Learning or Self-aligning? Rethinking Instruction Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.330) |  | 0 | Instruction Fine-tuning (IFT) is a crucial phase in building large language models (LLMs). Previous works mainly focus on the IFT’s role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains... | Boxi Cao, Cao Liu, Guanglu Wan, Hongyu Lin, Ke Zeng, Le Sun, Mengjie Ren, Xianpei Han, Xunliang Cai |  |
| 450 |  |  [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?](https://doi.org/10.18653/v1/2024.acl-long.331) |  | 0 | Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our... | Hanghang Tong, Qineng Wang, Yangqiu Song, Ying Su, Zihao Wang |  |
| 451 |  |  [Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct LLM in Knowledge-based VQA](https://doi.org/10.18653/v1/2024.acl-long.332) |  | 0 | LLM has achieved impressive performance on multi-modal tasks, which have received ever-increasing research attention. Recent research focuses on improving prediction performance and reliability (e.g., addressing the hallucination problem). They often prepend relevant external knowledge to the input... | Jing Liu, Qunbo Wang, Ruyi Ji, Tianhao Peng, Wenjun Wu, Zechao Li |  |
| 452 |  |  [TasTe: Teaching Large Language Models to Translate through Self-Reflection](https://doi.org/10.18653/v1/2024.acl-long.333) |  | 0 | Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation. However, the existing approaches fail to yield... | Fandong Meng, Jiali Zeng, Jie Zhou, Min Zhang, Xuebo Liu, Yutong Wang |  |
| 453 |  |  [Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.334) |  | 0 | A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with fewer active parameters, but it is still hard to deploy them due to their immense parameter sizes.... | Aojun Zhou, Bo Zhang, Hongsheng Li, Junchi Yan, Qi Liu, Siyuan Huang, Xudong Lu, Yuhui Xu |  |
| 454 |  |  [UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion](https://doi.org/10.18653/v1/2024.acl-long.335) |  | 0 | Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents UNIMO-G, a simple... | Jiachen Liu, Wei Li, Xinyan Xiao, Xue Xu |  |
| 455 |  |  [The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities](https://doi.org/10.18653/v1/2024.acl-long.336) |  | 0 | Fine-tuning large language models (LLMs) for machine translation has shown improvements in overall translation quality. However, it is unclear what is the impact of fine-tuning on desirable LLM behaviors that are not present in neural machine translation models, such as steerability, inherent... | Bill Byrne, Christof Monz, David Stap, Eva Hasler, Ke Tran |  |
| 456 |  |  [Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?](https://doi.org/10.18653/v1/2024.acl-long.337) |  | 0 | While auxiliary information has become a key to enhancing Large Language Models (LLMs), relatively little is known about how LLMs merge these contexts, specifically contexts generated by LLMs and those retrieved from external sources.To investigate this, we formulate a systematic framework to... | Fei Sun, Hexiang Tan, Qi Cao, Wanli Yang, Xueqi Cheng, Yuanzhuo Wang |  |
| 457 |  |  [Unveiling Linguistic Regions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.338) |  | 0 | Large Language Models (LLMs) have demonstrated considerable cross-lingual alignment and generalization ability. Current research primarily focuses on improving LLMs’ cross-lingual generalization capabilities. However, there is still a lack of research on the intrinsic mechanisms of how LLMs achieve... | Jun Zhao, Qi Zhang, Tao Gui, Xuanjing Huang, Zhihao Zhang |  |
| 458 |  |  [Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment](https://doi.org/10.18653/v1/2024.acl-long.339) |  | 0 | A song is a combination of singing voice and accompaniment. However, existing works focus on singing voice synthesis and music generation independently. Little attention was paid to exploring song synthesis. In this work, we propose a novel task called Text-to-Song synthesis which incorporates both... | Fuming You, Rongjie Huang, Ruiqi Li, Xize Cheng, Yongqi Wang, Zhimeng Zhang, Zhiqing Hong, Zhou Zhao |  |
| 459 |  |  [FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection](https://doi.org/10.18653/v1/2024.acl-long.340) |  | 0 | Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models. State-of-the-art models typically incorporate the FiD framework, which is composed by a neural retriever alongside an... | Maosong Sun, Xu Han, Yufei Huang |  |
| 460 |  |  [Discursive Socratic Questioning: Evaluating the Faithfulness of Language Models' Understanding of Discourse Relations](https://doi.org/10.18653/v1/2024.acl-long.341) |  | 0 | While large language models have significantly enhanced the effectiveness of discourse relation classifications, it remains unclear whether their comprehension is faithful and reliable. We provide DiSQ, a new method for evaluating the faithfulness of understanding discourse based on question... | Hongfu Liu, MinYen Kan, Nancy F. Chen, Wenqiang Lei, Yisong Miao |  |
| 461 |  |  [An Open Multilingual System for Scoring Readability of Wikipedia](https://doi.org/10.18653/v1/2024.acl-long.342) |  | 0 | With over 60M articles, Wikipedia has become the largest platform for open and freely accessible knowledge. While it has more than 15B monthly visits, its content is believed to be inaccessible to many readers due to the lack of readability of its text. However, previous investigations of the... | Indira Sen, Martin Gerlach, Mykola Trokhymovych |  |
| 462 |  |  [Unlearning Traces the Influential Training Data of Language Models](https://doi.org/10.18653/v1/2024.acl-long.343) |  | 0 | Identifying the training datasets that influence a language model’s outputs is essential for minimizing the generation of harmful content and enhancing its performance. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to... | Ivan Titov, Masaru Isonuma |  |
| 463 |  |  [Exploring Alignment in Shared Cross-lingual Spaces](https://doi.org/10.18653/v1/2024.acl-long.344) |  | 0 | Despite their remarkable ability to capture linguistic nuances across diverse languages, questions persist regarding the degree of alignment between languages in multilingual embeddings. Drawing inspiration from research on high-dimensional representations in neural language models, we employ... | Ahmed Abdelali, Basel Mousi, Fahim Dalvi, Majd Hawasly, Nadir Durrani |  |
| 464 |  |  [Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.345) |  | 0 | This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in... | Jentse Huang, Jingyuan Huang, Michael R. Lyu, Ruyi Dai, Wenxiang Jiao, Wenxuan Wang, Zhaopeng Tu |  |
| 465 |  |  [Self-Evolving GPT: A Lifelong Autonomous Experiential Learner](https://doi.org/10.18653/v1/2024.acl-long.346) |  | 0 | To improve the performance of large language models (LLMs), researchers have explored providing LLMs with textual task-solving experience via prompts. However, they rely on manual efforts to acquire and apply such experience for each task, which is not feasible for the growing demand for LLMs and... | Bing Qin, Hepeng Wang, Jianbai Zhao, Jinglong Gao, Ting Liu, Xiao Ding, Yiming Cui |  |
| 466 |  |  [WRP: Weight Recover Prune for Structured Sparsity](https://doi.org/10.18653/v1/2024.acl-long.347) |  | 0 | As the scale of Large Language Models (LLMs) increases, it is necessary to compress the models to reduce the substantial demand on computational resources. Network pruning significantly reduces the model size by converting the weight matrix from dense to sparse data format. Current methodologies... | Xingjun Zhang, Zhendong Tan, Zheng Wei |  |
| 467 |  |  [Error-preserving Automatic Speech Recognition of Young English Learners' Language](https://doi.org/10.18653/v1/2024.acl-long.348) |  | 0 | One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. The recent advances in speech technology and natural language processing allow the creation of novel... | Jan Deriu, Janick Michot, Katsiaryna Mlynchyk, Luzia Sauer, Manuela Hürlimann, Mark Cieliebak |  |
| 468 |  |  [DiFiNet: Boundary-Aware Semantic Differentiation and Filtration Network for Nested Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.349) |  | 0 | Nested Named Entity Recognition (Nested NER) entails identifying and classifying entity spans within the text, including the detection of named entities that are embedded within external entities. Prior approaches primarily employ span-based techniques, utilizing the power of exhaustive searches to... | Changlin Li, Da Luo, JiayeYang JiayeYang, Qiao Liu, Run Lin, Xueyi Liu, Yanglei Gan, Yuxiang Cai |  |
| 469 |  |  [Legal Case Retrieval: A Survey of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.350) |  | 0 | Recent years have seen increasing attention on Legal Case Retrieval (LCR), a key task in the area of Legal AI that concerns the retrieval of cases from a large legal database of historical cases that are similar to a given query. This paper presents a survey of the major milestones made in LCR... | Chuanyi Li, Vincent Ng, Yi Feng |  |
| 470 |  |  [Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.351) |  | 0 | Compositional generalization, representing the model’s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive... | Defu Lian, Linqi Song, Quan Wang, Tianqi Zhong, Ying Wei, Zhaoyi Li, Zhendong Mao |  |
| 471 |  |  [LLaMA Pro: Progressive LLaMA with Block Expansion](https://doi.org/10.18653/v1/2024.acl-long.352) |  | 0 | Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLMs), e.g., from LLaMA to CodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with an expansion of Transformer blocks. We tune the expanded blocks using... | Chengyue Wu, Jiahao Wang, Ping Luo, Ye Feng, Ying Shan, Yixiao Ge, Yukang Gan, Zeyu Lu |  |
| 472 |  |  [Generating Contrastive Narratives Using the Brownian Bridge Process for Narrative Coherence Learning](https://doi.org/10.18653/v1/2024.acl-long.353) |  | 0 | A major challenge for narrative reasoning is to learn narrative coherence. Existing works mainly follow the contrastive learning paradigm. However, the negative samples in their methods can be easily distinguished, which makes their methods unsatisfactory. In this work, we devise two strategies for... | Feiteng Mu, Wenjie Li |  |
| 473 |  |  [A Causal Approach for Counterfactual Reasoning in Narratives](https://doi.org/10.18653/v1/2024.acl-long.354) |  | 0 | Counterfactual reasoning in narratives requires predicting how alternative conditions, contrary to what actually happened, might have resulted in different outcomes.One major challenge is to maintain the causality between the counterfactual condition and the generated counterfactual outcome. In... | Feiteng Mu, Wenjie Li |  |
| 474 |  |  [SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation](https://doi.org/10.18653/v1/2024.acl-long.355) |  | 0 | Strong inductive biases enable learning from little data and help generalization outside the training distribution. Popular neural architectures such as Transformers lack strong structural inductive biases for seq2seq NLP tasks on their own. Consequently, they struggle with systematic... | Alexander Koller, Ivan Titov, Matthias Lindemann |  |
| 475 |  |  [The Hidden Space of Transformer Language Adapters](https://doi.org/10.18653/v1/2024.acl-long.356) |  | 0 | We analyze the operation of transformer language adapters, which are small modules trained on top of a frozen language model to adapt its predictions to new target languages. We show that adapted predictions mostly evolve in the source language the model was trained on, while the target language... | Dietrich Klakow, Jesujoba Alabi, Marius Mosbach, Matan Eyal, Mor Geva |  |
| 476 |  |  [A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts](https://doi.org/10.18653/v1/2024.acl-long.357) |  | 0 | In the realm of text manipulation and linguistic transformation, the question of authorship has been a subject of fascination and philosophical inquiry. Much like the Ship of Theseus paradox, which ponders whether a ship remains the same when each of its original planks is replaced, our research... | Adaku Uchendu, Dominik Macko, Dongwon Lee, Ivan Srba, Nafis Irtiza Tripto, Róbert Móro, Saranya Venkatraman, Thai Le |  |
| 477 |  |  [Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations](https://doi.org/10.18653/v1/2024.acl-long.358) |  | 0 | In spoken dialogue, even if two current turns are the same sentence, their responses might still differ when they are spoken in different styles. The spoken styles, containing paralinguistic and prosodic information, mark the most significant difference between text and speech modality. When using... | ChengHan Chiang, GuanTing Lin, Hungyi Lee |  |
| 478 |  |  [RetinaQA: A Robust Knowledge Base Question Answering Model for both Answerable and Unanswerable Questions](https://doi.org/10.18653/v1/2024.acl-long.359) |  | 0 | An essential requirement for a real-world Knowledge Base Question Answering (KBQA) system is the ability to detect the answerability of questions when generating logical forms. However, state-of-the-art KBQA models assume all questions to be answerable. Recent research has found that such models,... | Indrajit Bhattacharya, Mausam, Prayushi Faldu |  |
| 479 |  |  [GroundingGPT: Language Enhanced Multi-modal Grounding Model](https://doi.org/10.18653/v1/2024.acl-long.360) |  | 0 | Multi-modal large language models (MLLMs) have demonstrated remarkable performance across various tasks. However, these models often prioritize capturing global information and overlook the importance of perceiving local information. This limitation hinders their ability to effectively understand... | Dong Zhang, Hang Song, Junting Pan, Qi Qi, Qi Xu, Ran Zhou, Tao Wang, Vu Tu, Yiqing Cai, Zefeng Li, Zhaowei Li, Zhida Huang |  |
| 480 |  |  [Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches](https://doi.org/10.18653/v1/2024.acl-long.361) |  | 0 | Automated Fact-Checking (AFC) is the automated verification of claim accuracy. AFC is crucial in discerning truth from misinformation, especially given the huge amounts of content are generated online daily. Current research focuses on predicting claim veracity through metadata analysis and... | Amine Trabelsi, Islam Eldifrawi, Shengrui Wang |  |
| 481 |  |  [Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages](https://doi.org/10.18653/v1/2024.acl-long.362) |  | 0 | Multilingual neural machine translation systems learn to map sentences of different languages into a common representation space. Intuitively, with a growing number of seen languages the encoder sentence representation grows more flexible and easily adaptable to new languages. In this work, we test... | Alexander Waibel, Carlos Mullov, NgocQuan Pham |  |
| 482 |  |  [SwapMoE: Serving Off-the-shelf MoE-based Large Language Models with Tunable Memory Budget](https://doi.org/10.18653/v1/2024.acl-long.363) |  | 0 | Mixture of experts (MoE) is a popular technique to improve capacity of Large Language Models (LLMs) with conditionally-activated parallel experts. However, serving MoE models on memory-constrained devices is challenging due to the large parameter size. Typical solutions such as memory swapping or... | Linghe Kong, Qingtian Feng, Rui Kong, Weijun Wang, Xiaozhou Ye, Ye Ouyang, Yuanchun Li, Yunxin Liu |  |
| 483 |  |  [PixT3: Pixel-based Table-To-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.364) |  | 0 | Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. A common feature across existing methods... | Eneko Agirre, Iñigo Alonso, Mirella Lapata |  |
| 484 |  |  [Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers](https://doi.org/10.18653/v1/2024.acl-long.365) |  | 0 | Factual questions typically can be answered correctly at different levels of granularity. For example, both “August 4, 1961” and “1961” are correct answers to the question “When was Barack Obama born?”. Standard question answering (QA) evaluation protocols, however, do not explicitly take this into... | Gal Yona, Mor Geva, Roee Aharoni |  |
| 485 |  |  [TAMS: Translation-Assisted Morphological Segmentation](https://doi.org/10.18653/v1/2024.acl-long.366) |  | 0 | Canonical morphological segmentation is the process of analyzing words into the standard (aka underlying) forms of their constituent morphemes.This is a core task in endangered language documentation, and NLP systems have the potential to dramatically speed up this process. In typical language... | Alexis Palmer, Ali Marashian, Enora Rice, Katharina von der Wense, Luke Gessler |  |
| 486 |  |  [XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval](https://doi.org/10.18653/v1/2024.acl-long.367) |  | 0 | Recently, pre-trained large language models (LLMs) have shown impressive abilities in generating codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been... | M. Saiful Bari, Md. Rizwan Parvez, Mohammad Abdullah Matin Khan, Shafiq Joty, Weishi Wang, Xuan Do Long |  |
| 487 |  |  [ProxyQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.368) |  | 0 | Large Language Models (LLMs) have succeeded remarkably in understanding long-form contents. However, exploring their capability for generating long-form contents, such as reports and articles, has been relatively unexplored and inadequately assessed by existing benchmarks. The prevalent evaluation... | Haochen Tan, Lifeng Shang, Linqi Song, Lu Xu, Qun Liu, Xiaoguang Li, Yasheng Wang, Yunlong Feng, Zhan Shi, Zhijiang Guo, Zhili Liu |  |
| 488 |  |  [A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia](https://doi.org/10.18653/v1/2024.acl-long.369) |  | 0 | Large language models (LLMs) have an impressive ability to draw on novel information supplied in their context. Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters, which... | Barun Patra, Emre Kiciman, Giovanni Monea, Hamid Palangi, Jason Eisner, Martin Josifoski, Maxime Peyrard, Robert West, Vishrav Chaudhary |  |
| 489 |  |  [Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA](https://doi.org/10.18653/v1/2024.acl-long.370) |  | 0 | Multipanel images, commonly seen as web screenshots, posters, etc., pervade our daily lives. These images, characterized by their composition of multiple subfigures in distinct layouts, effectively convey information to people. Toward building advanced multimodal AI applications, such as agents... | ChingChen Kuo, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, Xin Wang, Xinze Guan, Yang Zhao, Yue Fan |  |
| 490 |  |  [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.371) |  | 0 | The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in... | Dong Yu, Hongliang He, Hongming Zhang, Kaixin Ma, Wenhao Yu, Wenlin Yao, Yong Dai, Zhenzhong Lan |  |
| 491 |  |  [Translation-based Lexicalization Generation and Lexical Gap Detection: Application to Kinship Terms](https://doi.org/10.18653/v1/2024.acl-long.372) |  | 0 | Constructing lexicons with explicitly identified lexical gaps is a vital part of building multilingual lexical resources. Prior work has leveraged bilingual dictionaries and linguistic typologies for semi-automatic identification of lexical gaps. Instead, we propose a generally-applicable... | Bradley Hauer, Grzegorz Kondrak, Ning Shi, Senyu Li |  |
| 492 |  |  [Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations](https://doi.org/10.18653/v1/2024.acl-long.373) |  | 0 | We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to... | Carolyn P. Rosé, Divyanshu Sheth, Jiaxin Shi, Prakhar Gupta, Ritam Dutt, Zhen Wu |  |
| 493 |  |  [Robust Frame-Semantic Models with Lexical Unit Trees and Negative Samples](https://doi.org/10.18653/v1/2024.acl-long.374) |  | 0 | We present novel advancements in frame-semantic parsing, specifically focusing on target identification and frame identification. Our target identification model employs a novel prefix tree modification to enable robust support for multi-word lexical units, resulting in a coverage of 99.4% of the... | Chengkai Li, Jacob Daniel Devasier, Yogesh Gurjar |  |
| 494 |  |  [Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://doi.org/10.18653/v1/2024.acl-long.375) |  | 0 | Advancements in logical reasoning, utilizing LLMs to convert natural language into logical symbolism, combined with the use of external theorem provers, have repositioned the symbolic approach as a central point of interest. The main challenge within this paradigm lies in the LLMs’ capability to... | Ali Payani, Ehsan Shareghi, Faramarz Fekri, Siheng Xiong, Yuan Yang |  |
| 495 |  |  [Lightweight reranking for language model generations](https://doi.org/10.18653/v1/2024.acl-long.376) |  | 0 | Large Language Models (LLMs) can exhibit considerable variation in the quality of their sampled outputs. Reranking and selecting the best generation from the sampled set is a popular way of obtaining strong gains in generation quality. In this paper, we present a novel approach for reranking LLM... | Anoop Deoras, Bing Xiang, Siddhartha Jain, Xiaofei Ma |  |
| 496 |  |  [ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews](https://doi.org/10.18653/v1/2024.acl-long.377) |  | 0 | We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a dataset of review comments and their corresponding paper edits. The data is drawn from real reviewer-author interactions from computer science, and we provide labels linking each reviewer... | Alexis Ross, Bailey Kuehl, Doug Downey, Erin Bransom, Jonathan Bragg, Mike D'Arcy, Tom Hope |  |
| 497 |  |  [The Unreasonable Effectiveness of Easy Training Data for Hard Tasks](https://doi.org/10.18653/v1/2024.acl-long.378) |  | 0 | How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present... | Mohit Bansal, Peter Clark, Peter Hase, Sarah Wiegreffe |  |
| 498 |  |  [PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.379) |  | 0 | Instruction tuning has remarkably advanced large language models (LLMs) in understanding and responding to diverse human instructions. Despite the success in high-resource languages, its application in lower-resource ones faces challenges due to the imbalanced foundational abilities of LLMs across... | DongHo Lee, Francesco Barbieri, Meng Jiang, Mengzhao Jia, Wenhao Yu, Yuwei Fang, Zhihan Zhang |  |
| 499 |  |  [MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.380) |  | 0 | We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error propagation due to the autoregressive nature and... | Inderjeet Nair, Lu Wang |  |
| 500 |  |  [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs](https://doi.org/10.18653/v1/2024.acl-long.381) |  | 0 | Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning... | Justin ChihYao Chen, Mohit Bansal, Swarnadeep Saha |  |
| 501 |  |  [Mirror: Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning](https://doi.org/10.18653/v1/2024.acl-long.382) |  | 0 | While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs... | Hanqi Yan, Lin Gui, Qinglin Zhu, Xinyu Wang, Yulan He |  |
| 502 |  |  [Where Do People Tell Stories Online? Story Detection Across Online Communities](https://doi.org/10.18653/v1/2024.acl-long.383) |  | 0 | Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit... | Andrew Piper, Elliott Ash, Joel Mire, Maarten Sap, Maria Antoniak |  |
| 503 |  |  [Large Language Models Are No Longer Shallow Parsers](https://doi.org/10.18653/v1/2024.acl-long.384) |  | 0 | The development of large language models (LLMs) brings significant changes to the field of natural language processing (NLP), enabling remarkable performance in various high-level tasks, such as machine translation, question-answering, dialogue generation, etc., under end-to-end settings without... | Fei Xia, Yan Song, Yuanhe Tian |  |
| 504 |  |  [Dialogue Summarization with Mixture of Experts based on Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.385) |  | 0 | Dialogue summarization is an important task that requires to generate highlights for a conversation from different aspects (e.g., content of various speakers). While several studies successfully employ large language models (LLMs) and achieve satisfying results, they are limited by using one model... | Fei Xia, Yan Song, Yuanhe Tian |  |
| 505 |  |  [ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences](https://doi.org/10.18653/v1/2024.acl-long.386) |  | 0 | Recently, the increasing demand for superior medical services has highlighted the discrepancies in the medical infrastructure. With big data, especially texts, forming the foundation of medical services, there is an exigent need for effective natural language processing (NLP) solutions tailored to... | Jiaxing Zhang, Ruyi Gan, Yan Song, Yongdong Zhang, Yuanhe Tian |  |
| 506 |  |  [An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs](https://doi.org/10.18653/v1/2024.acl-long.387) |  | 0 | Large language models (LLMs) have shown strong arithmetic reasoning capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we have only a limited understanding of how they are processed by LLMs. To demystify it, prior work has primarily focused on ablating different components in... | Daking Rai, Ziyu Yao |  |
| 507 |  |  [Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling](https://doi.org/10.18653/v1/2024.acl-long.388) |  | 0 | Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of... | Alex Pentland, Daniel T. Kessler, Deb K. Roy, Eric Ma, Hang Jiang, Irene Li, Jad Kabbara, Robert Mahari, Tal August, Xiajie Zhang, Yoon Kim |  |
| 508 |  |  [Intrinsic Task-based Evaluation for Referring Expression Generation](https://doi.org/10.18653/v1/2024.acl-long.389) |  | 0 | Recently, a human evaluation study of Referring Expression Generation (REG) models had an unexpected conclusion: on WEBNLG, Referring Expressions (REs) generated by the state-of-the-art neural models were not only indistinguishable from the REs in WEBNLG but also from the REs generated by a simple... | Fahime Same, Guanyi Chen, Kees van Deemter |  |
| 509 |  |  [From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.390) |  | 0 | Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts, tracing the progression of events and topics over time. Prior research typically focuses on either event or topic timeline summarization, neglecting the potential synergy of these two... | Geonsik Moon, Hwee Tou Ng, Qisheng Hu |  |
| 510 |  |  [End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.391) |  | 0 | Document-level relation extraction (DocRE) aims to extract relations between entities in a whole document. One of the pivotal challenges of DocRE is to capture the intricate interdependencies between relations of entity pairs. Previous methods have shown that logical rules can explicitly help... | Hai Wan, Jianfeng Du, Kunxun Qi |  |
| 511 |  |  [Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?](https://doi.org/10.18653/v1/2024.acl-long.392) |  | 0 | Recently proposed two-pass direct speech-to-speech translation (S2ST) models decompose the task into speech-to-text translation (S2TT) and text-to-speech (TTS) within an end-to-end model, yielding promising results. However, the training of these models still relies on parallel speech data, which... | Min Zhang, Qingkai Fang, Shaolei Zhang, Yang Feng, Zhengrui Ma |  |
| 512 |  |  [Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder](https://doi.org/10.18653/v1/2024.acl-long.393) |  | 0 | Reconstructing natural language from non-invasive electroencephalography (EEG) holds great promise as a language decoding technology for brain-computer interfaces (BCIs). However, EEG-based language decoding is still in its nascent stages, facing several technical issues such as: 1) Absence of a... | Jiaqi Wang, Min Zhang, Xipeng Qiu, Zhengyu Ma, Zhenxi Song, Zhiguo Zhang |  |
| 513 |  |  [CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers](https://doi.org/10.18653/v1/2024.acl-long.394) |  | 0 | The fast-growing large scale language models are delivering unprecedented performance on almost all natural language processing tasks. However, the effectiveness of large language models are reliant on an exponentially increasing number of parameters. The overwhelming computation complexity incurs... | Han Zhao, Jiangangkong Jiangangkong, Longwei Zou, Qingyang Wang, Yangdong Deng, Yi Yang |  |
| 514 |  |  [Prompt Optimization via Adversarial In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.395) |  | 0 | We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompts for in-context learning (ICL). Inspired by adversarial learning, adv-ICL is implemented as a two-player game between a generator and discriminator, with LLMs acting as both. In each round, given an input... | Do Xuan Long, Hannah Brown, James Xu Zhao, Junxian He, Kenji Kawaguchi, Michael Shieh, Nancy F. Chen, Yiran Zhao, Yuxi Xie |  |
| 515 |  |  [StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion](https://doi.org/10.18653/v1/2024.acl-long.396) |  | 0 | Recent language model (LM) advancements have showcased impressive zero-shot voice conversion (VC) performance. However, existing LM-based VC models usually apply offline conversion from source semantics to acoustic features, demanding the complete source speech and limiting their deployment to... | Lei Xie, Xinsheng Wang, Yuanzhe Chen, Yuping Wang, Zhichao Wang |  |
| 516 |  |  [Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.397) |  | 0 | Multi-Hop Question Answering (MHQA) task presents a significant challenge for large language models (LLMs) due to the intensive knowledge required. Current solutions, like Retrieval-Augmented Generation, typically retrieve potential documents from an external corpus to read an answer. However, the... | Pengjie Ren, Shen Gao, Shuo Zhang, Weiwei Sun, Zhaochun Ren, Zhengliang Shi, Zhumin Chen |  |
| 517 |  |  [Multimodal Contextualized Semantic Parsing from Speech](https://doi.org/10.18653/v1/2024.acl-long.398) |  | 0 | We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents’ contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically... | David Harwath, Jordan Voas, Raymond Mooney |  |
| 518 |  |  [LaMP: When Large Language Models Meet Personalization](https://doi.org/10.18653/v1/2024.acl-long.399) |  | 0 | This paper highlights the importance of personalization in large language models and introduces the LaMP benchmark — a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and... | Alireza Salemi, Hamed Zamani, Michael Bendersky, Sheshera Mysore |  |
| 519 |  |  [AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters](https://doi.org/10.18653/v1/2024.acl-long.400) |  | 0 | Large language models’ (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage are under-scrutinized. In our work, we ground web text, which is a popular pretraining... | David Bamman, Emma Strubell, Jesse Dodge, Lauren F. Klein, Li Lucy, Luca Soldaini, Suchin Gururangan |  |
| 520 |  |  [MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.acl-long.401) |  | 0 | The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems. However, comprehensively evaluating the dialogue abilities of LLMs remains a challenge. Previous benchmarks have primarily focused on single-turn dialogues or provided coarse-grained and incomplete assessments of... | Bo Zheng, Ge Bai, Jiaheng Liu, Jie Liu, Tiezheng Ge, Wanli Ouyang, Wenbo Su, Xingyuan Bu, Yancheng He, Zhanhui Zhou, Zhuoran Lin |  |
| 521 |  |  [EFSA: Towards Event-Level Financial Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.402) |  | 0 | In this paper, we extend financial sentiment analysis (FSA) to event-level since events usually serve as the subject of the sentiment in financial text. Though extracting events from the financial text may be conducive to accurate sentiment predictions, it has specialized challenges due to the... | Dapeng Zhang, Guoxin Yu, Li Zeng, Qing He, Tianyu Chen, Xiang Ao, Yiming Zhang |  |
| 522 |  |  [What Evidence Do Language Models Find Convincing?](https://doi.org/10.18653/v1/2024.acl-long.403) |  | 0 | Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as “is aspartame linked to cancer”. To resolve these ambiguous queries, one must search through a large range of websites and consider “which, if any, of this evidence do I... | Alexander Wan, Dan Klein, Eric Wallace |  |
| 523 |  |  [Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.404) |  | 0 | Graph data organizes complex relationships and interactions between objects, facilitating advanced analysis and decision-making across different fields. In this paper, we propose a new paradigm for interactive and instructional graph data understanding and reasoning.Instead of adopting complex... | Haiyun Jiang, Jiafan Li, Jianwu Zhou, Jincheng Dai, Lemao Liu, Qihang Ai, Shuming Shi |  |
| 524 |  |  [LangBridge: Multilingual Reasoning Without Multilingual Supervision](https://doi.org/10.18653/v1/2024.acl-long.405) |  | 0 | We introduce LangBridge, a zero-shot approach to adapt language models for multilingual reasoning tasks without multilingual supervision. LangBridge operates by bridging two models, each specialized in different aspects: (1) one specialized in understanding multiple languages (e.g., mT5 encoder)... | Dongkeun Yoon, Joel Jang, Minjoon Seo, Seungone Kim, Sheikh Shafayat, Sungdong Kim |  |
| 525 |  |  [Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs](https://doi.org/10.18653/v1/2024.acl-long.406) |  | 0 | Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to... | Siyuan Wang, Xiang Ren, Yejin Choi, Zhongyu Wei |  |
| 526 |  |  [SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving](https://doi.org/10.18653/v1/2024.acl-long.407) |  | 0 | Large Language Models (LLMs) have driven substantial progress in artificial intelligence in recent years, exhibiting impressive capabilities across a wide range of tasks, including mathematical problem-solving. Inspired by the success of subgoal-based methods, we propose a novel framework called... | Lingpeng Kong, Wei Bi, Xinting Huang, Xueliang Zhao |  |
| 527 |  |  [Unlocking the Power of Large Language Models for Entity Alignment](https://doi.org/10.18653/v1/2024.acl-long.408) |  | 0 | Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in data-driven AI applications. Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of... | Chengjin Xu, Huawei Shen, Jian Guo, Wei Li, Xuhui Jiang, Yinghan Shen, Yuanzhuo Wang, Zhichao Shi, Zixuan Li |  |
| 528 |  |  [Trial and Error: Exploration-Based Trajectory Optimization of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.409) |  | 0 | Large Language Models (LLMs) have become integral components in various autonomous agent systems.In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous... | Bill Yuchen Lin, Da Yin, Jie Huang, Sujian Li, Xiang Yue, Yifan Song |  |
| 529 |  |  [ReFT: Reasoning with Reinforced Fine-Tuning](https://doi.org/10.18653/v1/2024.acl-long.410) |  | 0 | One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data.... | Hang Li, Luong Quoc Trung, Peng Sun, Xiaoran Jin, Xinbo Zhang, Zhanming Jie |  |
| 530 |  |  [Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension with Enhanced Visual Knowledge Alignment](https://doi.org/10.18653/v1/2024.acl-long.411) |  | 0 | Evaluating and Rethinking the current landscape of Large Multimodal Models (LMMs), we observe that widely-used visual-language projection approaches (e.g., Q-former or MLP) focus on the alignment of image-text descriptions yet ignore the visual knowledge-dimension alignment, i.e., connecting... | Baotian Hu, Haoyuan Shi, Min Zhang, Xinyu Chen, Yunxin Li |  |
| 531 |  |  [FreeCtrl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation](https://doi.org/10.18653/v1/2024.acl-long.412) |  | 0 | Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data... | Hanzhang Zhou, Kezhi Mao, Zijian Feng, Zixiao Zhu |  |
| 532 |  |  [HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition](https://doi.org/10.18653/v1/2024.acl-long.413) |  | 0 | Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval,... | Feng Sun, Furu Wei, Haizhen Huang, Qi Zhang, Shaohan Huang, Tianchi Yang, Weiwei Deng, Yuxuan Liu, Zihan Zhang |  |
| 533 |  |  [Conundrums in Cross-Prompt Automated Essay Scoring: Making Sense of the State of the Art](https://doi.org/10.18653/v1/2024.acl-long.414) |  | 0 | Cross-prompt automated essay scoring (AES), an under-investigated but challenging task that has gained increasing popularity in the AES community, aims to train an AES system that can generalize well to prompts that are unseen during model training. While recently-developed cross-prompt AES models... | Shengjie Li, Vincent Ng |  |
| 534 |  |  [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](https://doi.org/10.18653/v1/2024.acl-long.415) |  | 0 | Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes have been extensively researched in various NLP applications, there is a surprising gap for emotion analysis. However, emotion and gender are closely linked in societal... | Alba Cercas Curry, Amanda Cercas Curry, Dirk Hovy, Flor Miriam Plaza del Arco, Gavin Abercrombie |  |
| 535 |  |  [Label Augmentation for Zero-Shot Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.acl-long.416) |  | 0 | Hierarchical Text Classification poses the difficult challenge of classifying documents into multiple labels organized in a hierarchy. The vast majority of works aimed to address this problem relies on supervised methods which are difficult to implement due to the scarcity of labeled data in many... | Lorenzo Paletto, Roberto Esposito, Valerio Basile |  |
| 536 |  |  [STICKERCONV: Generating Multimodal Empathetic Responses from Scratch](https://doi.org/10.18653/v1/2024.acl-long.417) |  | 0 | Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which... | Daling Wang, Fanheng Kong, Kaisong Song, Lingshuai Wang, Peidong Wang, Shi Feng, Shuang Sun, Yifei Zhang, Yiqun Zhang |  |
| 537 |  |  [EIT: Enhanced Interactive Transformer](https://doi.org/10.18653/v1/2024.acl-long.418) |  | 0 | Two principles: the complementary principle and the consensus principle are widely acknowledged in the literature of multi-view learning. However, the current design of multi-head self-attention, an instance of multi-view learning, prioritizes the complementarity while ignoring the consensus. To... | Bei Li, Huiwen Bao, JingBo Zhu, Tong Xiao, Tong Zheng |  |
| 538 |  |  [MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs](https://doi.org/10.18653/v1/2024.acl-long.419) |  | 0 | Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is... | Baturalp Buyukates, Chenyang Tao, Dimitrios Dimitriadis, Duygu Nur Yaldiz, Salman Avestimehr, Yavuz Faruk Bakman |  |
| 539 |  |  [EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models](https://doi.org/10.18653/v1/2024.acl-long.420) |  | 0 | We introduce EXAMS-V, a new challenging multi-discipline multimodal multilingual exam benchmark for evaluating vision language models. It consists of 20,932 multiple-choice questions across 20 school disciplines covering natural science, social science, and other miscellaneous studies, e.g.,... | Dimitar Dimitrov, Haonan Li, Ivan Koychev, Preslav Nakov, Rocktim Jyoti Das, Simeon Emilov Hristov |  |
| 540 |  |  [Order-Agnostic Data Augmentation for Few-Shot Named Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.421) |  | 0 | Data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, existing NER DA techniques either perform rule-based manipulations on words that break the semantic coherence... | De Wen Soh, Huiming Wang, Lidong Bing, Liying Cheng, Wenxuan Zhang |  |
| 541 |  |  [Text Embedding Inversion Security for Multilingual Language Models](https://doi.org/10.18653/v1/2024.acl-long.422) |  | 0 | Textual data is often represented as real-numbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be susceptible to security breaches, as research shows that text can be... | Heather C. Lent, Johannes Bjerva, Yiyi Chen |  |
| 542 |  |  [Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment](https://doi.org/10.18653/v1/2024.acl-long.423) |  | 0 | Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and... | Bowen Yu, Chang Zhou, Jingren Zhou, Keming Lu |  |
| 543 |  |  [PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator](https://doi.org/10.18653/v1/2024.acl-long.424) |  | 0 | The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides made by leveraging real user and ChatGPT dialogues, as evidenced by Vicuna. However, due to challenges in gathering dialogues involving human participation, current endeavors... | Benyou Wang, Chuyi Kong, Feng Jiang, Xiang Wan, Yaxin Fan |  |
| 544 |  |  [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](https://doi.org/10.18653/v1/2024.acl-long.425) |  | 0 | The capability gap between open-source and closed-source large language models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we introduce a synthetic data approach that combines data produced by larger, more powerful models (strong models) with error information data generated by... | Binyuan Hui, Chang Zhou, Jian Yang, Jiaxi Yang, Junyang Lin, Min Yang |  |
| 545 |  |  [STRUCTSUM Generation for Faster Text Comprehension](https://doi.org/10.18653/v1/2024.acl-long.426) |  | 0 | We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly... | Andreea Marzoca, Francesco Piccinno, Parag Jain |  |
| 546 |  |  [Analysing The Impact of Sequence Composition on Language Model Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.427) |  | 0 | Most language model pre-training frameworks concatenate multiple documents into fixed-length sequences and use causal masking to compute the likelihood of each token given its context; this strategy is widely adopted due to its simplicity and efficiency. However, to this day, the influence of the... | Konrad Staniszewski, Pasquale Minervini, Piotr Milos, Szymon Tworkowski, Wei Liu, Yu Zhao, Yuanbin Qu, Yuxiang Wu |  |
| 547 |  |  [NACL: A General and Effective KV Cache Eviction Framework for LLM at Inference Time](https://doi.org/10.18653/v1/2024.acl-long.428) |  | 0 | Large Language Models (LLMs) have ignited an innovative surge of AI applications, marking a new era of exciting possibilities equipped with extended context windows. However, hosting these models is cost-prohibitive mainly due to the extensive memory consumption of KV Cache involving long-context... | Dianhai Yu, Guoxia Wang, Hua Wu, Junyuan Shang, Shiyao Cui, Shuohuan Wang, Tingwen Liu, Yilong Chen, Yu Sun, Zhenyu Zhang |  |
| 548 |  |  [SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network](https://doi.org/10.18653/v1/2024.acl-long.429) |  | 0 | Brain-inspired Spiking Neural Network (SNN) has demonstrated its effectiveness and efficiency in vision, natural language, and speech understanding tasks, indicating their capacity to “see”, “listen”, and “read”. In this paper, we design SpikeVoice, which performs high-quality Text-To-Speech (TTS)... | Bo Xu, Di Shang, Guoqi Li, Jiahong Zhang, Kexin Wang, Man Yao, Yong Ren |  |
| 549 |  |  [Context-aware Difference Distilling for Multi-change Captioning](https://doi.org/10.18653/v1/2024.acl-long.430) |  | 0 | Multi-change captioning aims to describe complex and coupled changes within an image pair in natural language. Compared with single-change captioning, this task requires the model to have higher-level cognition ability to reason an arbitrary number of changes. In this paper, we propose a novel... | Chenggang Yan, Li Su, Liang Li, Qingming Huang, Yunbin Tu, ZhengJun Zha |  |
| 550 |  |  [Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion](https://doi.org/10.18653/v1/2024.acl-long.431) |  | 0 | Recent years have witnessed the deployment of code language models (LMs) in various code intelligence tasks such as code completion. Yet, it is challenging for pre-trained LMs to generate correct completions in private repositories. Previous studies retrieve cross-file context based on import... | Wei Cheng, Wei Hu, Yuhan Wu |  |
| 551 |  |  [Chain-of-Exemplar: Enhancing Distractor Generation for Multimodal Educational Question Generation](https://doi.org/10.18653/v1/2024.acl-long.432) |  | 0 | Multiple-choice questions (MCQs) are important in enhancing concept learning and student engagement for educational purposes. Despite the multimodal nature of educational content, current methods focus mainly on text-based inputs and often neglect the integration of visual information. In this... | Haohao Luo, SeeKiong Ng, TatSeng Chua, Yang Deng, Ying Shen |  |
| 552 |  |  [LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification](https://doi.org/10.18653/v1/2024.acl-long.433) |  | 0 | With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly researched in various research areas. Recently, many attempts based on prompt-learning have been made to improve the performance of text classification. However, most of these methods are based on... | ChunLiu ChunLiu, Hongguang Zhang, Kainan Zhao, Lin Yang, Xinghai Ju |  |
| 553 |  |  [LEMON: Reviving Stronger and Smaller LMs from Larger LMs with Linear Parameter Fusion](https://doi.org/10.18653/v1/2024.acl-long.434) |  | 0 | In the new era of language models, small models (with billions of parameter sizes) are receiving increasing attention due to their flexibility and cost-effectiveness in deployment. However, limited by the model size, the performance of small models trained from scratch may often be unsatisfactory.... | Hua Wu, Junyuan Shang, Shiyao Cui, Shuohuan Wang, Tingwen Liu, Yilong Chen, Yu Sun, Zhenyu Zhang |  |
| 554 |  |  [Speech Sense Disambiguation: Tackling Homophone Ambiguity in End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.435) |  | 0 | End-to-end speech translation (ST) presents notable disambiguation challenges as it necessitates simultaneous cross-modal and cross-lingual transformations. While word sense disambiguation is an extensively investigated topic in textual machine translation, the exploration of disambiguation... | Dacheng Tao, Kehai Chen, Liang Ding, Min Zhang, Tengfei Yu, Xuebo Liu |  |
| 555 |  |  [To be Continuous, or to be Discrete, Those are Bits of Questions](https://doi.org/10.18653/v1/2024.acl-long.436) |  | 0 | Recently, binary representation has been proposed as a novel representation that lies between continuous and discrete representations. It exhibits considerable information-preserving capability when being used to replace continuous input vectors. In this paper, we investigate the feasibility of... | Masao Utiyama, Yiran Wang |  |
| 556 |  |  [Moûsai: Efficient Text-to-Music Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.437) |  | 0 | Recent years have seen the rapid development of large generative models for text; however, much less research has explored the connection between text and another “language” of communication – music. Music, much like text, can convey emotions, stories, and ideas, and has its own unique structure... | Bernhard Schölkopf, Flavio Schneider, Ojasv Kamal, Zhijing Jin |  |
| 557 |  |  [PokeMQA: Programmable knowledge editing for Multi-hop Question Answering](https://doi.org/10.18653/v1/2024.acl-long.438) |  | 0 | Multi-hop question answering (MQA) is one of the challenging tasks to evaluate machine’s comprehension and reasoning abilities, where large language models (LLMs) have widely achieved the human-comparable performance. Due to the dynamics of knowledge facts in real world, knowledge editing has been... | Hengrui Gu, Kaixiong Zhou, Ninghao Liu, Ruobing Wang, Xiaotian Han, Xin Wang |  |
| 558 |  |  [MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention](https://doi.org/10.18653/v1/2024.acl-long.439) |  | 0 | In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content,... | Aman Chadha, Konika Mandal, Prince Jha, Pushpak Bhattacharyya, Raghav Jain, Sriparna Saha |  |
| 559 |  |  [Efficient OCR for Building a Diverse Digital History](https://doi.org/10.18653/v1/2024.acl-long.440) |  | 0 | Many users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) – which jointly learns a vision and language model – is poorly... | Jacob Carlson, Melissa Dell, Tom Bryan |  |
| 560 |  |  [Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space](https://doi.org/10.18653/v1/2024.acl-long.441) |  | 0 | Despite the notable success of language models (LMs) in various natural language processing (NLP) tasks, the reliability of LMs is susceptible to backdoor attacks. Prior research attempts to mitigate backdoor learning while training the LMs on the poisoned dataset, yet struggles against complex... | Gongshen Liu, Pengzhou Cheng, Zhuosheng Zhang, Zongru Wu |  |
| 561 |  |  [ANAH: Analytical Annotation of Hallucinations in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.442) |  | 0 | Reducing the ‘hallucination' problem of Large Language Models (LLMs) is crucial for their wide applications. A comprehensive and fine-grained measurement of the hallucination is the first key step for the governance of this issue but is under-explored in the community.Thus, we present ANAH, a... | Chengqi Lyu, Dahua Lin, Kai Chen, Wenwei Zhang, Yuzhe Gu, Ziwei Ji |  |
| 562 |  |  [Aligning Large Language Models for Controllable Recommendations](https://doi.org/10.18653/v1/2024.acl-long.443) |  | 0 | Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems — systems that are conversational, explainable, and controllable. However, existing literature primarily... | Guanghua Li, Hao Liao, Jianxun Lian, Mingyang Zhou, Wei Zhang, Wensheng Lu, Xing Xie |  |
| 563 |  |  [Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods](https://doi.org/10.18653/v1/2024.acl-long.444) |  | 0 | Language Models (LMs) acquire parametric knowledge from their training process, embedding it within their weights. The increasing scalability of LMs, however, poses significant challenges for understanding a model’s inner workings and further for updating or correcting this embedded knowledge... | Haeun Yu, Isabelle Augenstein, Pepa Atanasova |  |
| 564 |  |  [Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://doi.org/10.18653/v1/2024.acl-long.445) |  | 0 | Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have... | Kai Lv, Qipeng Guo, Tengxiao Liu, Xipeng Qiu, Yuqing Yang |  |
| 565 |  |  [M³CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.446) |  | 0 | Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge from both textual and visual modalities for step-by-step reasoning, which gains increasing attention. Nevertheless, the current MCoT benchmark still faces some challenges: (1) absence of visual modal reasoning, (2)... | Jin Zhang, Libo Qin, Qiguang Chen, Wanxiang Che, Xiao Xu, Zhi Chen |  |
| 566 |  |  [Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.447) |  | 0 | Long-context modeling capabilities are important for large language models (LLMs) in various applications. However, directly training LLMs with long context windows is insufficient to enhance this capability since some training samples do not exhibit strong semantic dependencies across long... | Hao Sun, Longze Chen, Min Yang, Run Luo, Wanwei He, Yinhe Zheng, Yunshui Li, Ziqiang Liu |  |
| 567 |  |  [Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation](https://doi.org/10.18653/v1/2024.acl-long.448) |  | 0 | While the neural transducer is popular for online speech recognition, simultaneous speech translation (SST) requires both streaming and re-ordering capabilities. This paper presents the LS-Transducer-SST, a label-synchronous neural transducer for SST, which naturally possesses these two properties.... | Keqi Deng, Philip C. Woodland |  |
| 568 |  |  [Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL](https://doi.org/10.18653/v1/2024.acl-long.449) |  | 0 | With the advent of foundation models, prompt tuning has positioned itself as an important technique for directing model behaviors and eliciting desired responses. Prompt tuning regards selecting appropriate keywords included into the input, thereby adapting to the downstream task without adjusting... | Chuheng Zhang, Jiang Bian, KeeEung Kim, Lei Song, Li Zhao, Minchan Jeong, Sangmin Bae, Seonghyun Ban, Yunseon Choi |  |
| 569 |  |  [A Modular Approach for Multimodal Summarization of TV Shows](https://doi.org/10.18653/v1/2024.acl-long.450) |  | 0 | In this paper we address the task of summarizing television shows, which touches key areas in AI research: complex reasoning, multiple modalities, and long narratives. We present a modular approach where separate components perform specialized sub-tasks which we argue affords greater flexibility... | Louis Mahon, Mirella Lapata |  |
| 570 |  |  [Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities](https://doi.org/10.18653/v1/2024.acl-long.451) |  | 0 | Human interactions are deeply rooted in the interplay of thoughts, beliefs, and desires made possible by Theory of Mind (ToM): our cognitive ability to understand the mental states of ourselves and others. Although ToM may come naturally to us, emulating it presents a challenge to even the most... | Alex Wilf, LouisPhilippe Morency, Paul Pu Liang, Sihyun Shawn Lee |  |
| 571 |  |  [BizBench: A Quantitative Reasoning Benchmark for Business and Finance](https://doi.org/10.18653/v1/2024.acl-long.452) |  | 0 | Answering questions within business and finance requires reasoning, precision, and a wide-breadth of technical knowledge. Together, these requirements make this domain difficult for large language models (LLMs). We introduce BizBench, a benchmark for evaluating models’ ability to reason about... | Charles Lovering, Chris Tanner, Michael Krumdick, Rik KoncelKedziorski, Varshini Reddy, Viet Dac Lai |  |
| 572 |  |  [Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization](https://doi.org/10.18653/v1/2024.acl-long.453) |  | 0 | While image captioning is an essential field of vision language models (VLM), a lack of continuity between the learning objective and final performance metrics of VLMs complicates their training and optimization. Reinforcement learning (RL) can directly optimize such metrics, but it is accompanied... | Aiswariya Manoj Kumar, Haruki Sato, Hayato Tanoue, Hiroki Nishihara, Hiroki Takushima, Kazuya Ueki, Takayuki Hori, Takumi Takada, Yuma Suzuki |  |
| 573 |  |  [Deciphering Hate: Identifying Hateful Memes and Their Targets](https://doi.org/10.18653/v1/2024.acl-long.454) |  | 0 | Internet memes have become a powerful means for individuals to express emotions, thoughts, and perspectives on social media. While often considered as a source of humor and entertainment, memes can also disseminate hateful content targeting individuals or communities. Most existing research focuses... | Eftekhar Hossain, Mohammed Moshiul Hoque, Omar Sharif, Sarah Masud Preum |  |
| 574 |  |  [Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings](https://doi.org/10.18653/v1/2024.acl-long.455) |  | 0 | Transformers generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes structurally equivalent sentences using a... | Mohit Bansal, Xiang Zhou, Yichen Jiang |  |
| 575 |  |  [Label-Efficient Model Selection for Text Generation](https://doi.org/10.18653/v1/2024.acl-long.456) |  | 0 | Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models based on preference annotations. DiffUse... | Ariel Gera, Benjamin Sznajder, Eyal Shnarch, Leshem Choshen, Liat EinDor, Shir AshuryTahan |  |
| 576 |  |  [Machine Unlearning of Pre-trained Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.457) |  | 0 | This study investigates the concept of the ‘right to be forgotten’ within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models–a notably under-researched area. Our research delineates a comprehensive framework for... | Eli Chien, Jin Yao, Minxin Du, Tianhao Wang, Xiang Yue, Xinyao Niu, Zezhou Cheng |  |
| 577 |  |  [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://doi.org/10.18653/v1/2024.acl-long.458) |  | 0 | Interpretability research aims to bridge the gap between the empirical success and our scientific understanding of the inner workings of large language models (LLMs). However, most existing research in this area focused on analyzing a single mechanism, such as how models copy or recall factual... | Alberto Cazzaniga, Bernhard Schölkopf, Diego Doimo, Francesco Ortu, Mrinmaya Sachan, Zhijing Jin |  |
| 578 |  |  [FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence](https://doi.org/10.18653/v1/2024.acl-long.459) |  | 0 | Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing... | Byron C. Wallace, Hannah Louisa Göke, Jan Trienes, Junyi Jessy Li, Lily Chen, Monika Coers, Sebastian Joseph, Wei Xu |  |
| 579 |  |  [BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.460) |  | 0 | Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based elements, including aspect term, opinion term, aspect category, and sentiment polarity. In practice, unseen aspects, due to distinct data distribution, impose many challenges for a trained neural model. Motivated by this,... | Hang Gao, Mengting Hu, Renhong Cheng, Xiaoyi Liu, Yalan Xie, Yinhao Bai, Yuhua Zhao, Zhixin Han |  |
| 580 |  |  [Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack](https://doi.org/10.18653/v1/2024.acl-long.461) |  | 0 | Recent developments in balancing the usefulness and safety of Large Language Models (LLMs) have raised a critical question: Are mainstream NLP tasks adequately aligned with safety consideration? Our study, focusing on safety-sensitive documents obtained through adversarial attacks, reveals... | Cong Liu, Wen Xiao, Yu Fu, Yue Dong, Yufei Li |  |
| 581 |  |  [Speech language models lack important brain-relevant semantics](https://doi.org/10.18653/v1/2024.acl-long.462) |  | 0 | Despite known differences between reading and listening in the brain, recent work has shown that text-based language models predict both text-evoked and speech-evoked brain activity to an impressive degree. This poses the question of what types of information language models truly predict in the... | Emin Çelik, Fatma Deniz, Mariya Toneva, Subba Reddy Oota |  |
| 582 |  |  [DocLLM: A Layout-Aware Generative Language Model for Multimodal Document Understanding](https://doi.org/10.18653/v1/2024.acl-long.463) |  | 0 | Enterprise documents such as forms, receipts, reports, and other such records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we... | Armineh Nourbakhsh, Dongsheng Wang, Mathieu Sibue, Natraj Raman, Petr Babkin, Simerjot Kaur, Xiaomo Liu, Yulong Pei, Zhiqiang Ma |  |
| 583 |  |  [Bypassing LLM Watermarks with Color-Aware Substitutions](https://doi.org/10.18653/v1/2024.acl-long.464) |  | 0 | Watermarking approaches are proposed to identify if text being circulated is human- or large language model- (LLM) generated. The state-of-the-art watermarking strategy of Kirchenbauer et al. (2023a) biases the LLM to generate specific (“green”) tokens. However, determining the robustness of this... | Qilong Wu, Varun Chandrasekaran |  |
| 584 |  |  [Parallel Structures in Pre-training Data Yield In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.465) |  | 0 | Pre-trained language models (LMs) are capable of in-context learning (ICL): they can adapt to a task with only a few examples given in the prompt without any parameter update. However, it is unclear where this capability comes from as there is a stark distribution shift between pre-training text... | Chen Zhao, He He, Kathleen R. McKeown, Yanda Chen, Zhou Yu |  |
| 585 |  |  [OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.466) |  | 0 | Neural Theory-of-Mind (N-ToM), machine’s ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence... | Hainiu Xu, Jinhua Du, Lixing Zhu, Runcong Zhao, Yulan He |  |
| 586 |  |  [Towards Privacy-Aware Sign Language Translation at Scale](https://doi.org/10.18653/v1/2024.acl-long.467) |  | 0 | A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much of the sign language data currently available on the web cannot be used for training supervised models due to the lack of aligned captions. Furthermore, scaling SLT using large-scale web-scraped datasets... | Bowen Shi, Jean Maillard, Necati Cihan Camgöz, Phillip Rust, Skyler Wang |  |
| 587 |  |  [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://doi.org/10.18653/v1/2024.acl-long.468) |  | 0 | Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture... | Han Zhao, Haoxiang Wang, Rui Yang, Shizhe Diao, Shuang Qiu, Tong Zhang, Wei Xiong, Yong Lin |  |
| 588 |  |  [Towards Real-World Writing Assistance: A Chinese Character Checking Benchmark with Faked and Misspelled Characters](https://doi.org/10.18653/v1/2024.acl-long.469) |  | 0 | Writing assistance aims to improve the correctness and quality of input texts, with character checking being crucial in detecting and correcting wrong characters. In the real world where handwriting occupies the vast majority, characters that humans get wrong include faked characters (i.e., untrue... | HaiTao Zheng, Haojing Huang, Qingyu Zhou, Shaoshen Chen, Shirong Ma, Yangning Li, Ying Shen, Yinghui Li, Yong Jiang, Zhongli Li, Zishan Xu |  |
| 589 |  |  [RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations](https://doi.org/10.18653/v1/2024.acl-long.470) |  | 0 | Individual neurons participate in the representation of multiple high-level concepts. To what extent can different interpretability methods successfully disentangle these roles? To help address this question, we introduce RAVEL (Resolving Attribute-Value Entanglements in Language Models), a dataset... | Atticus Geiger, Christopher Potts, Jing Huang, Mor Geva, Zhengxuan Wu |  |
| 590 |  |  [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://doi.org/10.18653/v1/2024.acl-long.471) |  | 0 | Large language models (LLMs) are increasingly prevalent in conversational systems due to their advanced understanding and generative capabilities in general contexts. However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective... | Adithya Sagar, Mike Ross, Patrick Huber, Paul A. Crook, Seungwhan Moon, Xifeng Yan, Xin Dong, Zekun Li, Zhaojiang Lin, Zhiyu Chen |  |
| 591 |  |  [Faithful Chart Summarization with ChaTS-Pi](https://doi.org/10.18653/v1/2024.acl-long.472) |  | 0 | Chart-to-summary generation can help explore data, communicate insights, and help the visually impaired people. Multi-modal generative models have been used to produce fluent summaries, but they can suffer from factual and perceptual errors. In this work we present CHATS-CRITIC, a reference-free... | Fangyu Liu, Francesco Piccinno, Julian Eisenschlos, Syrine Krichene |  |
| 592 |  |  [Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation](https://doi.org/10.18653/v1/2024.acl-long.473) |  | 0 | Dialogue State Tracking (DST) is designed to monitor the evolving dialogue state in the conversations and plays a pivotal role in developing task-oriented dialogue systems. However, obtaining the annotated data for the DST task is usually a costly endeavor. In this paper, we focus on employing LLMs... | Cheng Niu, Juntong Song, Tong Zhang, Xingguang Wang, Xuxin Cheng |  |
| 593 |  |  [MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.474) |  | 0 | Fact-checking real-world claims often requires reviewing multiple multimodal documents in order to assess the claim’s truthfulness, a highly laborious and time-consuming task. In this paper, we present a summarization model crafted to generate claim-specific summaries useful for fact-checking from... | ChiaWei Tang, Chris Thomas, TingChih Chen |  |
| 594 |  |  [KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction](https://doi.org/10.18653/v1/2024.acl-long.475) |  | 0 |  | Jiafeng Guo, Long Bai, Miao Su, Pan Yang, Wei Li, Weicheng Ren, Wenxuan Liu, Xiang Li, Xiaolong Jin, Xueqi Cheng, Yantao Liu, Yidan Liu, Yucan Guo, Yutao Zeng, Yuxin Zuo, Zhilei Hu, Zixuan Li |  |
| 595 |  |  [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](https://doi.org/10.18653/v1/2024.acl-long.476) |  | 0 | Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. These challenges arise from the presence of implicit... | Jianwei Yin, Tianyu Du, Weihao Liu, Xinyue Peng, Xuhong Zhang, Yanming Liu |  |
| 596 |  |  [On the Multi-turn Instruction Following for Conversational Web Agents](https://doi.org/10.18653/v1/2024.acl-long.477) |  | 0 | Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to... | SeeKiong Ng, TatSeng Chua, Wenxuan Zhang, Xuan Zhang, Yang Deng, Yifei Yuan |  |
| 597 |  |  [Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](https://doi.org/10.18653/v1/2024.acl-long.478) |  | 0 | With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research hotspot in human-computer interaction.However, there is a scarcity of benchmarks available for LLM-based mobile agents.Benchmarking these agents generally faces three main challenges:(1) The... | Ang Li, Bin Wang, Hongda Sun, Jian Luan, Jianfeng Liu, Rui Yan, Shihan Deng, Shuo Shang, Tao Tan, Wei Liu, Weikai Xu |  |
| 598 |  |  [MC²: Towards Transparent and Culturally-Aware NLP for Minority Languages in China](https://doi.org/10.18653/v1/2024.acl-long.479) |  | 0 | Current large language models demonstrate deficiencies in understanding low-resource languages, particularly the minority languages in China. This limitation stems from the scarcity of available pre-training data. To address this accessibility challenge, we present MC2, a Multilingual Corpus of... | Chen Zhang, Jiuheng Lin, Mingxu Tao, Quzhe Huang, Yansong Feng, Zhibin Chen |  |
| 599 |  |  [Decoder-only Streaming Transformer for Simultaneous Translation](https://doi.org/10.18653/v1/2024.acl-long.480) |  | 0 | Simultaneous Machine Translation (SiMT) generates translation while reading source tokens, essentially producing the target prefix based on the source prefix. To achieve good performance, it leverages the relationship between source and target prefixes to exact a policy to guide the generation of... | Shaolei Zhang, Shoutao Guo, Yang Feng |  |
| 600 |  |  [Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization](https://doi.org/10.18653/v1/2024.acl-long.481) |  | 0 | While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of effort in defending against these attacks. We point out a pivotal factor contributing to the success of jailbreaks: the intrinsic conflict between the goals of... | Fei Mi, Hongning Wang, Junxiao Yang, Minlie Huang, Pei Ke, Zhexin Zhang |  |
| 601 |  |  [I am a Strange Dataset: Metalinguistic Tests for Language Models](https://doi.org/10.18653/v1/2024.acl-long.482) |  | 0 | Statements involving metalinguistic self-reference (“This paper has six sections.”) are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present “I am a Strange Dataset”, a new dataset for addressing this question. There are two subtasks:... | Christopher Potts, Douwe Kiela, Jared Moore, Miguel Monares, Tristan Thrush |  |
| 602 |  |  [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](https://doi.org/10.18653/v1/2024.acl-long.483) |  | 0 | Large Language Models (LLMs) sometimes suffer from producing hallucinations, especially LLMs may generate untruthful responses despite knowing the correct knowledge. Activating the truthfulness within LLM is the key to fully unlocking LLM’s knowledge potential. In this paper, we propose TruthX, an... | Shaolei Zhang, Tian Yu, Yang Feng |  |
| 603 |  |  [ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training](https://doi.org/10.18653/v1/2024.acl-long.484) |  | 0 | We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of... | Conghui He, Heqi Zheng, Heyan Huang, Jianan Zhao, Le Zhuo, Minghao Xu, Wentao Zhang, XianLing Mao, Zewen Chi |  |
| 604 |  |  [StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning](https://doi.org/10.18653/v1/2024.acl-long.485) |  | 0 | Simultaneous speech-to-speech translation (Simul-S2ST, a.k.a streaming speech translation) outputs target speech while receiving streaming speech inputs, which is critical for real-time communication. Beyond accomplishing translation between speech, Simul-S2ST requires a policy to control the model... | Min Zhang, Qingkai Fang, Shaolei Zhang, Shoutao Guo, Yang Feng, Zhengrui Ma |  |
| 605 |  |  [Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.486) |  | 0 | Recent work has showcased the powerful capability of large language models (LLMs) in recalling knowledge and reasoning. However, the reliability of LLMs in combining these two capabilities into reasoning through multi-hop facts has not been widely explored. This paper systematically investigates... | Gongshen Liu, Tianjie Ju, Wei Du, Xinwei Yuan, Yijin Chen, Yubin Zheng, Zhuosheng Zhang |  |
| 606 |  |  [Why Don't Prompt-Based Fairness Metrics Correlate?](https://doi.org/10.18653/v1/2024.acl-long.487) |  | 0 | The widespread use of large language models has brought up essential questions about the potential biases these models might learn. This led to the development of several metrics aimed at evaluating and mitigating these biases. In this paper, we first demonstrate that prompt-based fairness metrics... | Abdelrahman Zayed, Gonçalo Mordido, Ioana Baldini, Sarath Chandar |  |
| 607 |  |  [NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data](https://doi.org/10.18653/v1/2024.acl-long.488) |  | 0 | To address the global issue of online hate, hate speech detection (HSD) systems are typically developed on datasets from the United States, thereby failing to generalize to English dialects from the Majority World. Furthermore, HSD models are often evaluated on non-representative samples, raising... | Ibrahim Farouq, Karim Lasri, Lakshmi Subramanian, Manuel Tonneau, Pedro Vitor Quinta de Castro, Samuel Fraiberger, Víctor OrozcoOlvera |  |
| 608 |  |  [M³AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset](https://doi.org/10.18653/v1/2024.acl-long.489) |  | 0 | Publishing open-source academic video recordings is an emergent and prevalent approach to sharing knowledge online. Such videos carry rich multimodal information including speech, the facial and body movements of the speakers, as well as the texts and pictures in the slides and possibly even the... | Chao Zhang, Guangzhi Sun, Heyang Liu, Hongcheng Liu, Ji Wu, Wenyi Yu, Yanfeng Wang, Yu Wang, Zhe Chen |  |
| 609 |  |  [Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination](https://doi.org/10.18653/v1/2024.acl-long.490) |  | 0 | Instruction-following language models often show undesirable biases. These undesirable biases may be accelerated in the real-world usage of language models, where a wide range of instructions is used through zero-shot example prompting. To solve this problem, we first define the bias neuron, which... | Honglak Lee, Kyomin Jung, Nakyeong Yang, Stanley Jungkyu Choi, Taegwan Kang |  |
| 610 |  |  [Domain Adaptation for Subjective Induction Questions Answering on Products by Adversarial Disentangled Learning](https://doi.org/10.18653/v1/2024.acl-long.491) |  | 0 | This paper focuses on answering subjective questions about products. Different from the factoid question with a single answer span, this subjective one involves multiple viewpoints. For example, the question of ‘how the phone’s battery is?’ not only involves facts of battery capacity but also... | Huaijie Zhu, Jian Yin, Jianxing Yu, Libin Zheng, Qinliang Su, Yanghui Rao, Yufeng Zhang |  |
| 611 |  |  [Revisiting Demonstration Selection Strategies in In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.492) |  | 0 | Large language models (LLMs) have shown an impressive ability to perform a wide range of tasks using in-context learning (ICL), where a few examples are used to describe a task to the model. However, the performance of ICL varies significantly with the choice of demonstrations, and previous... | Dacheng Tao, Keqin Peng, Liang Ding, Min Zhang, Xuebo Liu, Yancheng Yuan, Yuanxin Ouyang |  |
| 612 |  |  [Multimodal Table Understanding](https://doi.org/10.18653/v1/2024.acl-long.493) |  | 0 | Although great progress has been made by previous table understanding methods including recent approaches based on large language models (LLMs), they rely heavily on the premise that given tables must be converted into a certain text sequence (such as Markdown or HTML) to serve as model input.... | Mingyu Zheng, Qiaoqiao She, Qingyi Si, Weiping Wang, Wenbin Jiang, Xinwei Feng, Zheng Lin |  |
| 613 |  |  [Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding](https://doi.org/10.18653/v1/2024.acl-long.494) |  | 0 | Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length,... | Guanhua He, Huang Lei, Jiaming Guo, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen, Xishan Zhang |  |
| 614 |  |  [Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning](https://doi.org/10.18653/v1/2024.acl-long.495) |  | 0 | Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled... | Avinash Kumar Singh, Biswajit Chatterjee, Indrajit Bhattacharya, Mausam, Mayur Patidar, Riya Sawhney |  |
| 615 |  |  [WatME: Towards Lossless Watermarking Through Lexical Redundancy](https://doi.org/10.18653/v1/2024.acl-long.496) |  | 0 | Text watermarking has emerged as a pivotal technique for identifying machine-generated text. However, existing methods often rely on arbitrary vocabulary partitioning during decoding to embed watermarks, which compromises the availability of suitable tokens and significantly degrades the quality of... | Deng Cai, KamFai Wong, Liang Chen, Peilin Zhao, Shuaiyi Li, Yang Deng, Yatao Bian |  |
| 616 |  |  [Text-like Encoding of Collaborative Information in Large Language Models for Recommendation](https://doi.org/10.18653/v1/2024.acl-long.497) |  | 0 | When adapting Large Language Models for Recommendation (LLMRec), it is crucial to integrate collaborative information. Existing methods achieve this by learning collaborative embeddings in LLMs’ latent space from scratch or by mapping from external models. However, they fail to represent the... | Fuli Feng, Keqin Bao, Ming Yan, Wenjie Wang, Xiangnan He, Yang Zhang |  |
| 617 |  |  [MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception](https://doi.org/10.18653/v1/2024.acl-long.498) |  | 0 | Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in visual perception and understanding. However, these models also suffer from hallucinations, which limit their reliability as AI systems. We believe that these hallucinations are partially... | Heyang Liu, Hongcheng Liu, Yanfeng Wang, Yu Wang, Yuhao Wang, Yusheng Liao |  |
| 618 |  |  [Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning](https://doi.org/10.18653/v1/2024.acl-long.499) |  | 0 | Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT). However, we find these CoT-like methods lead to a considerable number of originally correct answers turning wrong, which we define as the Toxic CoT problem. To... | Chenhao Wang, Daojian Zeng, Jiachun Li, Jun Zhao, Kang Liu, Pengfei Cao, Yubo Chen, Zhuoran Jin |  |
| 619 |  |  [Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation](https://doi.org/10.18653/v1/2024.acl-long.500) |  | 0 | Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects (e.g., “positive” from sentiment and “sport” from topic). Existing works neglect attribute correlations formed by the intertwining of different attributes. Particularly, the stereotype... | Wei Hu, Xiangrong Zhu, Xiangyu Liu, Yi Liu |  |
| 620 |  |  [Reward-based Input Construction for Cross-document Relation Extraction](https://doi.org/10.18653/v1/2024.acl-long.501) |  | 0 | Relation extraction (RE) is a fundamental task in natural language processing, aiming to identify relations between target entities in text. While many RE methods are designed for a single sentence or document, cross-document RE has emerged to address relations across multiple long documents. Given... | Byeonghu Na, IlChul Moon, Suhyeon Jo, Yeongmin Kim |  |
| 621 |  |  [Hyperspherical Multi-Prototype with Optimal Transport for Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.502) |  | 0 | Event Argument Extraction (EAE) aims to extract arguments for specified events from a text. Previous research has mainly focused on addressing long-distance dependencies of arguments, modeling co-occurrence relationships between roles and events, but overlooking potential inductive biases: (i)... | Guangjun Zhang, Hongye Tan, Hu Zhang, Jiye Liang, Ru Li, Yujie Wang |  |
| 622 |  |  [Understanding Retrieval Robustness for Retrieval-augmented Image Captioning](https://doi.org/10.18653/v1/2024.acl-long.503) |  | 0 | Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far... | Desmond Elliott, Jiaang Li, Raphael Tang, Rita Ramos, Wenyan Li |  |
| 623 |  |  [Semi-Supervised Spoken Language Glossification](https://doi.org/10.18653/v1/2024.acl-long.504) |  | 0 | Spoken language glossification (SLG) aims to translate the spoken language text into the sign language gloss, i.e., a written record of sign language. In this work, we present a framework named Semi-Supervised Spoken Language Glossification (S3LG) for SLG. To tackle the bottleneck of limited... | Hao Zhou, Houqiang Li, Huijie Yao, Wengang Zhou |  |
| 624 |  |  [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents](https://doi.org/10.18653/v1/2024.acl-long.505) |  | 0 | Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g.,... | Fangzhi Xu, Jianbing Zhang, Kanzhi Cheng, Qiushi Sun, Yantao Li, Yougang Chu, Zhiyong Wu |  |
| 625 |  |  [InterrogateLLM: Zero-Resource Hallucination Detection in LLM-Generated Answers](https://doi.org/10.18653/v1/2024.acl-long.506) |  | 0 | Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where... | Itzik Malkiel, Jonathan Weill, Noam Koenigstein, Oren Barkan, Royi Ronen, Yakir Yehuda |  |
| 626 |  |  [F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods](https://doi.org/10.18653/v1/2024.acl-long.507) |  | 0 | Large language models (LLMs) garner significant attention for their unprecedented performance, leading to an increasing number of researches evaluating LLMs. However, these evaluation benchmarks are limited to assessing the instruction-following capabilities, overlooking the fundamental abilities... | Dahua Lin, Hang Yan, Keyuchen Keyuchen, Peiji Li, Qipeng Guo, Shujie Wang, Xipeng Qiu, Xuanjing Huang, Yu Sun |  |
| 627 |  |  [Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning](https://doi.org/10.18653/v1/2024.acl-long.508) |  | 0 | Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their... | Barbara Plank, Philipp Mondorf |  |
| 628 |  |  [Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback](https://doi.org/10.18653/v1/2024.acl-long.509) |  | 0 | There is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences. We consider the setting of fairness in content moderation, in which human feedback is used to determine how two comments — referencing different... | Elliott Ash, Florian E. Dorner, Maria Lerner, Naman Goel |  |
| 629 |  |  [Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://doi.org/10.18653/v1/2024.acl-long.510) |  | 0 | In this paper, we present an innovative process-oriented math process reward model called Math-shepherd, which assigns a reward score to each step of math problem solutions. The training of Math-shepherd is achieved using automatically constructed process-wise supervision data, breaking the... | Damai Dai, Deli Chen, Lei Li, Peiyi Wang, Runxin Xu, Yifei Li, Yu Wu, Zhifang Sui, Zhihong Shao |  |
| 630 |  |  [Large Language Models are not Fair Evaluators](https://doi.org/10.18653/v1/2024.acl-long.511) |  | 0 | In this paper, we uncover a positional bias in the evaluation paradigm of adopting large language models (LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by... | Binghuai Lin, Dawei Zhu, Lei Li, Liang Chen, Lingpeng Kong, Peiyi Wang, Qi Liu, Tianyu Liu, Yunbo Cao, Zefan Cai, Zhifang Sui |  |
| 631 |  |  [Improving Large Language Models in Event Relation Logical Prediction](https://doi.org/10.18653/v1/2024.acl-long.512) |  | 0 | Event relations are crucial for narrative understanding and reasoning. Governed by nuanced logic, event relation extraction (ERE) is a challenging task that demands thorough semantic understanding and rigorous logical reasoning. In this paper, we conduct an in-depth investigation to systematically... | Dongsheng Li, Kaitao Song, Meiqi Chen, Yan Zhang, Yixin Cao, Yubo Ma |  |
| 632 |  |  [Synchronized Video Storytelling: Generating Video Narrations with Structured Storyline](https://doi.org/10.18653/v1/2024.acl-long.513) |  | 0 | Video storytelling is engaging multimedia content that utilizes video and its accompanying narration to share a story and attract the audience, where a key challenge is creating narrations for recorded visual scenes. Previous studies on dense video captioning and video story generation have made... | Biao Wang, Bo Zheng, Chunru Zhan, Dingyi Yang, Qin Jin, Tiezheng Ge, Ziheng Wang |  |
| 633 |  |  [Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation](https://doi.org/10.18653/v1/2024.acl-long.514) |  | 0 | Fine-grained vision-language models (VLM) have been widely used for inter-modality local alignment between the predefined fixed patches and textual words. However, in medical analysis, lesions exhibit varying sizes and positions, and using fixed patches may cause incomplete representations of... | Jiebo Luo, Jingyang Lin, Linlin Shen, Wenting Chen, Xiang Li, Yixuan Yuan |  |
| 634 |  |  [T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step](https://doi.org/10.18653/v1/2024.acl-long.515) |  | 0 | Large language models (LLMs) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models... | Dahua Lin, Feng Zhao, Jiangning Liu, Jingming Zhuo, Kai Chen, Kuikun Liu, Miao Zheng, Songyang Zhang, Weihua Du, Wenwei Zhang, Zehui Chen |  |
| 635 |  |  [Are LLM-based Evaluators Confusing NLG Quality Criteria?](https://doi.org/10.18653/v1/2024.acl-long.516) |  | 0 | Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and... | Mingqi Gao, Sen Hu, Teng Xu, Xiaojun Wan, Xinyu Hu, Yang Zhang, Yicheng Chen |  |
| 636 |  |  [Synergistic Interplay between Search and Large Language Models for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.517) |  | 0 | Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern retrieval models (RMs). The emergence of large language models (LLMs) has further revolutionized the IR field by... | Can Xu, Chongyang Tao, Daxin Jiang, Dongyan Zhao, Guodong Long, Jiazhan Feng, Tao Shen, Xiubo Geng |  |
| 637 |  |  [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://doi.org/10.18653/v1/2024.acl-long.518) |  | 0 | Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing. Current innovations, including State Space Models, were initially celebrated for surpassing Transformer performance on language modeling tasks.... | Alexey Gorbatovski, Boris Shaposhnikov, Daniil Gavrilov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina, Yaroslav Aksenov |  |
| 638 |  |  [Temperature-scaling surprisal estimates improve fit to human reading times - but does it do so for the "right reasons"?](https://doi.org/10.18653/v1/2024.acl-long.519) |  | 0 | A wide body of evidence shows that human language processing difficulty is predicted by the information-theoretic measure surprisal, a word’s negative log probability in context. However, it is still unclear how to best estimate these probabilities needed for predicting human processing difficulty... | Iza Skrjanec, Tong Liu, Vera Demberg |  |
| 639 |  |  [Beyond Recognising Entailment: Formalising Natural Language Inference from an Argumentative Perspective](https://doi.org/10.18653/v1/2024.acl-long.520) |  | 0 | In argumentation theory, argument schemes are a characterisation of stereotypical patterns of inference. There has been little work done to develop computational approaches to identify these schemes in natural language. Moreover, advancements in recognizing textual entailment lack a standardized... | Ameer SaadatYazdi, Nadin Kökciyan |  |
| 640 |  |  [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://doi.org/10.18653/v1/2024.acl-long.521) |  | 0 | We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM)... | Dong Zhang, Ge Zhang, Hang Yan, Jiasheng Ye, Jie Fu, Jun Zhan, Junqi Dai, Linyang Li, Ruibin Yuan, Tao Gui, Tianxiang Sun, Xin Zhang, Xipeng Qiu, YuGang Jiang, Yunhua Zhou, Zhigeng Liu |  |
| 641 |  |  [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](https://doi.org/10.18653/v1/2024.acl-long.522) |  | 0 | Social media abounds with multimodal sarcasm, and identifying sarcasm targets is particularly challenging due to the implicit incongruity not directly evident in the text and image modalities. Current methods for Multimodal Sarcasm Target Identification (MSTI) predominantly focus on superficial... | Guang Chen, Hongzhan Lin, Jing Ma, Mingfei Cheng, Zixin Chen, Ziyang Luo |  |
| 642 |  |  [Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation](https://doi.org/10.18653/v1/2024.acl-long.523) |  | 0 | Aligning large language models (LLMs) with human expectations without human-annotated preference data is an important problem. In this paper, we propose a method to evaluate the response preference by using the output probabilities of response pairs under contrastive prompt pairs, which could... | Aiwei Liu, Haoping Bai, Jiulong Shan, Lijie Wen, Meng Cao, Simon Wang, Xiang Kong, Zhiyun Lu |  |
| 643 |  |  [Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines](https://doi.org/10.18653/v1/2024.acl-long.524) |  | 0 | Text-to-image diffusion models (T2I) use a latent representation of a text prompt to guide the image generation process. However, the process by which the encoder produces the text representation is unknown. We propose the Diffusion Lens, a method for analyzing the text encoder of T2I models by... | Dana Arad, Hadas Orgad, Michael Toker, Mor Ventura, Yonatan Belinkov |  |
| 644 |  |  [Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.525) |  | 0 | Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training method, and evaluation benchmark. In... | Che Liu, Di Zhang, Fuzheng Zhang, Jinwen Huang, Kun Gai, Kun Zhou, Ruihua Song, Xin Zhao, Yuchong Sun |  |
| 645 |  |  [Robust Singing Voice Transcription Serves Synthesis](https://doi.org/10.18653/v1/2024.acl-long.526) |  | 0 | Note-level Automatic Singing Voice Transcription (AST) converts singing recordings into note sequences, facilitating the automatic annotation of singing datasets for Singing Voice Synthesis (SVS) applications. Current AST methods, however, struggle with accuracy and robustness when used for... | Rongjie Huang, Ruiqi Li, Yongqi Wang, Yu Zhang, Zhiqing Hong, Zhou Zhao |  |
| 646 |  |  [VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model](https://doi.org/10.18653/v1/2024.acl-long.527) |  | 0 | Security practitioners maintain vulnerability reports (e.g., GitHub Advisory) to help developers mitigate security risks. An important task for these databases is automatically extracting structured information mentioned in the report, e.g., the affected software packages, to accelerate the defense... | Guangtai Liang, Lin Li, Qianxiang Wang, Tao Xie, Tianyu Chen, Xueqing Liu, ZhuLiuchuan ZhuLiuchuan, Zongyang Li |  |
| 647 |  |  [Self-Modifying State Modeling for Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.528) |  | 0 | Simultaneous Machine Translation (SiMT) generates target outputs while receiving stream source inputs and requires a read/write policy to decide whether to wait for the next source token or generate a new target token, whose decisions form a decision path. Existing SiMT methods, which learn the... | Chengqing Zong, Donglei Yu, Xiaomian Kang, Yu Zhou, Yuchen Liu |  |
| 648 |  |  [MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.acl-long.529) |  | 0 | Embodied agents equipped with GPT as their brain have exhibited extraordinary decision-making and generalization abilities across various tasks. However, existing zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT-4 to select potential locations within localized... | Bingqian Lin, Jiaqi Chen, KwanYee Kenneth Wong, Ran Xu, Xiaodan Liang, Zhenhua Chai |  |
| 649 |  |  [BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.530) |  | 0 | With the prosperity of large language models (LLMs), powerful LLM-based intelligent agents have been developed to provide customized services with a set of user-defined tools. State-of-the-art methods for constructing LLM agents adopt trained LLMs and further fine-tune them on data for the agent... | Dizhan Xue, Shengjie Zhang, Shengsheng Qian, Yifei Wang |  |
| 650 |  |  [DetermLR: Augmenting LLM-based Logical Reasoning from Indeterminacy to Determinacy](https://doi.org/10.18653/v1/2024.acl-long.531) |  | 0 | Recent advances in large language models (LLMs) have revolutionized the landscape of reasoning tasks. To enhance the capabilities of LLMs to emulate human reasoning, prior studies have focused on modeling reasoning steps using various thought structures like chains, trees, or graphs. However,... | Bin Wang, Hongda Sun, JiRong Wen, Jian Luan, Rui Yan, Shuo Shang, Wei Liu, Weikai Xu |  |
| 651 |  |  [LePaRD: A Large-Scale Dataset of Judicial Citations to Precedent](https://doi.org/10.18653/v1/2024.acl-long.532) |  | 0 | We present the Legal Passage Retrieval Dataset, LePaRD. LePaRD contains millions of examples of U.S. federal judges citing precedent in context. The dataset aims to facilitate work on legal passage retrieval, a challenging practice-oriented legal retrieval and reasoning task. Legal passage... | Alex Pentland, Dominik Stammbach, Elliott Ash, Robert Mahari |  |
| 652 |  |  [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.533) |  | 0 | Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has... | Alessio Cocchieri, Alex Presepi, Giacomo Frisoni, Gianluca Moro, Zaiqiao Meng |  |
| 653 |  |  [MERA: A Comprehensive LLM Evaluation in Russian](https://doi.org/10.18653/v1/2024.acl-long.534) |  | 0 | Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). However, despite researchers’ attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still... | Albina Akhmetgareeva, Alena Fenogenova, Alexander Panchenko, Anastasia Kozlova, Anastasia Minaeva, Anton A. Emelyanov, Artem Chervyakov, Daniil Moskovskiy, Denis Dimitrov, Denis Shevelev, Elizaveta Goncharova, Katerina Kolomeytseva, Leonid Sinev, Maria Tikhonova, Nikita Martynov, Nikita Savushkin, Pavel Lebedev, Polina Mikhailova, Sergey Markov, Ulyana Isaeva |  |
| 654 |  |  [SC2: Towards Enhancing Content Preservation and Style Consistency in Long Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.535) |  | 0 | Text style transfer (TST) aims to vary the style polarity of text while preserving the semantic content. Although recent advancements have demonstrated remarkable progress in short TST, it remains a relatively straightforward task with limited practical applications. The more comprehensive long TST... | Cai Xu, Jie Zhao, Wei Zhao, Yue Jiang, Ziyu Guan |  |
| 655 |  |  [Dodo: Dynamic Contextual Compression for Decoder-only LMs](https://doi.org/10.18653/v1/2024.acl-long.536) |  | 0 | Transformer-based language models (LMs) are inefficient in long contexts. We propose Dodo, a solution for context compression. Instead of one vector per token in a standard transformer model, Dodo represents text with a dynamic number of hidden states at each layer, reducing the cost of... | Benjamin Van Durme, Corby Rosset, Ethan C. Chau, Guanghui Qin, Nikhil Rao |  |
| 656 |  |  [POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.537) |  | 0 | Low-resource languages (LRLs) face challenges in supervised neural machine translation (NMT) due to limited parallel data, prompting research in unsupervised NMT.Unsupervised NMT (UNMT), without requiring ground truth, provides solutions for LRL translations using synthetic pseudo-parallel data and... | Dongsheng Li, Haoqi Zheng, Liang Ding, Shilong Pan, Zhen Huang, Zhihua Wen, Zhiliang Tian |  |
| 657 |  |  [NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism](https://doi.org/10.18653/v1/2024.acl-long.538) |  | 0 | We present NewsBench, a novel evaluation framework to systematically assess the capabilities of Large Language Models (LLMs) for editorial capabilities in Chinese journalism. Our constructed benchmark dataset is focused on four facets of writing proficiency and six facets of safety adherence, and... | Bo Tang, Cheng Peng, Feiyu Xiong, Haiying Deng, Keming Mao, Miao Li, MingBin Chen, Pengyu Wang, ShengbinHou ShengbinHou, Yi Luo, Zhiyu Li |  |
| 658 |  |  [MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization](https://doi.org/10.18653/v1/2024.acl-long.539) |  | 0 | Intuitively, reasoning abilities are considered language-agnostic. However, existing LLMs exhibit inconsistent reasoning abilities across different languages, e.g., reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To... | Jiajun Chen, Shuaijie She, Shujian Huang, Wei Zou, Wenhao Zhu, Xiang Geng, Xiang Liu |  |
| 659 |  |  [Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training](https://doi.org/10.18653/v1/2024.acl-long.540) |  | 0 | Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to... | Feiteng Fang, Min Yang, Ruifeng Xu, Shiwen Ni, Xiaojun Chen, Yuelin Bai |  |
| 660 |  |  [Predicting Text Preference Via Structured Comparative Reasoning](https://doi.org/10.18653/v1/2024.acl-long.541) |  | 0 | Comparative reasoning plays a crucial role in predicting text preferences; however, large language models (LLMs) often demonstrate inconsistencies in their reasoning, leading to incorrect preference predictions. While approaches like Chain-of-Thought improve accuracy in many settings, they struggle... | Alexander M. Rush, Charumathi Lakshmanan, Jialu Liu, Jiaming Shen, Jing Nathan Yan, Justin T. Chiu, Michael Bendersky, Tianqi Liu, Yair Kurzion, Yue Yu, Zhen Qin |  |
| 661 |  |  [CoELM: Construction-Enhanced Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.542) |  | 0 | Recent studies have shown that integrating constructional information can improve the performance of pre-trained language models (PLMs) in natural language understanding. However, exploration into leveraging constructional information to enhance generative language models for natural language... | Jianhua Dai, Jiawei Peng, Lvxiaowei Xu, Ming Cai, Tianxiang Wang, Zhilin Gong |  |
| 662 |  |  [Uni-Dubbing: Zero-Shot Speech Synthesis from Visual Articulation](https://doi.org/10.18653/v1/2024.acl-long.543) |  | 0 | In the field of speech synthesis, there is a growing emphasis on employing multimodal speech to enhance robustness. A key challenge in this area is the scarcity of datasets that pair audio with corresponding video. We employ a methodology that incorporates modality alignment during the pre-training... | Jianqiao Hu, Jintao Tan, Lingyu Xiong, Mengjiao Lyu, Runlin Liu, Songju Lei, Tao Jin, Xiandong Li, Xize Cheng, Zhou Zhao |  |
| 663 |  |  [On the Impact of Calibration Data in Post-training Quantization and Pruning](https://doi.org/10.18653/v1/2024.acl-long.544) |  | 0 | Quantization and pruning form the foundation of compression for neural networks, enabling efficient inference for large language models (LLMs). Recently, various quantization and pruning techniques have demonstrated remarkable performance in a post-training setting. They rely upon calibration data,... | Miles Williams, Nikolaos Aletras |  |
| 664 |  |  [SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution](https://doi.org/10.18653/v1/2024.acl-long.545) |  | 0 | Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent... | Nishant Kumar, Prerna Agarwal, Srikanta Bedathur |  |
| 665 |  |  [Meta-Task Prompting Elicits Embeddings from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.546) |  | 0 | We introduce a new unsupervised text embedding method, Meta-Task Prompting with Explicit One-Word Limitation (MetaEOL), for generating high-quality sentence embeddings from Large Language Models (LLMs) without the need for model fine-tuning. Leveraging meta-task prompting, MetaEOL guides LLMs to... | Andrew Yates, Chongyang Tao, Di Wu, Tao Shen, Tianyi Zhou, Yibin Lei, Yu Cao |  |
| 666 |  |  [A Sentiment Consolidation Framework for Meta-Review Generation](https://doi.org/10.18653/v1/2024.acl-long.547) |  | 0 | Modern natural language generation systems with Large Language Models (LLMs) exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if they truly possess the capability of information consolidation to generate summaries, especially on documents with... | Eduard H. Hovy, Jey Han Lau, Miao Li |  |
| 667 |  |  [Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing](https://doi.org/10.18653/v1/2024.acl-long.548) |  | 0 | Structured Sentiment Analysis (SSA) was cast as a problem of bi-lexical dependency graph parsing by prior studies.Multiple formulations have been proposed to construct the graph, which share several intrinsic drawbacks:(1) The internal structures of spans are neglected, thus only the boundary... | Bobo Li, Chengjie Zhou, Chong Teng, Donghong Ji, Fei Li, Hao Fei |  |
| 668 |  |  [OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification](https://doi.org/10.18653/v1/2024.acl-long.549) |  | 0 | There has been an increasing interest in large speech models that can perform multiple tasks in a single model. Such models usually adopt an encoder-decoder or decoder-only architecture due to their popularity and good performance in many domains. However, autoregressive models can be slower during... | Muhammad Shakeel, Shinji Watanabe, Yifan Peng, Yui Sudo |  |
| 669 |  |  [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.550) |  | 0 | We study whether Large Language Models (LLMs) latently perform multi-hop reasoning with complex prompts such as “The mother of the singer of ‘Superstition’ is”. We look for evidence of a latent reasoning pathway where an LLM (1) latently identifies “the singer of ‘Superstition’” as Stevie Wonder,... | Elena Gribovskaya, Mor Geva, Nora Kassner, Sebastian Riedel, Sohee Yang |  |
| 670 |  |  [MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning](https://doi.org/10.18653/v1/2024.acl-long.551) |  | 0 | In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation... | Chang Zhou, Chengpeng Li, Chuanqi Tan, Guanting Dong, Hongyi Yuan, Jiancan Wu, Keming Lu, Xiang Wang, Zheng Yuan |  |
| 671 |  |  [Harnessing Toulmin's theory for zero-shot argument explication](https://doi.org/10.18653/v1/2024.acl-long.552) |  | 0 | To better analyze informal arguments on public forums, we propose the task of argument explication, which makes explicit a text’s argumentative structure and implicit reasoning by outputting triples of propositions ⟨claim, reason warrant⟩. The three slots, or argument components, are derived from... | Ankita Gupta, Brendan T. O'Connor, Ethan Zuckerman |  |
| 672 |  |  [BinaryAlign: Word Alignment as Binary Sequence Labeling](https://doi.org/10.18653/v1/2024.acl-long.553) |  | 0 | Real world deployments of word alignment are almost certain to cover both high and low resource languages. However, the state-of-the-art for this task recommends a different model class depending on the availability of gold alignment training data for a particular language pair. We propose... | Benjamin Swanson, Gaetan Latouche, MarcAndré Carbonneau |  |
| 673 |  |  [Quantifying the Persona Effect in LLM Simulations](https://doi.org/10.18653/v1/2024.acl-long.554) |  | 0 | Large language models (LLMs) have shown remarkable promise in simulating human language and behavior. This study investigates how integrating persona variables—demographic, social, and behavioral factors—impacts LLMs’ ability to simulate diverse perspectives. We find that persona variables account... | Nigel Collier, Tiancheng Hu |  |
| 674 |  |  [Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?](https://doi.org/10.18653/v1/2024.acl-long.555) |  | 0 | Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four... | Abhilasha Ravichander, Nishant Balepur, Rachel Rudinger |  |
| 675 |  |  [Retrieval Augmented Fact Verification by Synthesizing Contrastive Arguments](https://doi.org/10.18653/v1/2024.acl-long.556) |  | 0 | The rapid propagation of misinformation poses substantial risks to public interest. To combat misinformation, large language models (LLMs) are adapted to automatically verify claim credibility. Nevertheless, existing methods heavily rely on the embedded knowledge within LLMs and / or black-box APIs... | Dong Wang, Huimin Zeng, Lanyu Shang, Yang Zhang, Yifan Liu, Zhenrui Yue |  |
| 676 |  |  [SyllabusQA: A Course Logistics Question Answering Dataset](https://doi.org/10.18653/v1/2024.acl-long.557) |  | 0 | Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly... | Alexander Scarlatos, Andrew S. Lan, Nigel Fernandez |  |
| 677 |  |  [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.558) |  | 0 | Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address... | Jimeng Sun, Yilin Wen, Zifeng Wang |  |
| 678 |  |  [AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German Consumer Contracts](https://doi.org/10.18653/v1/2024.acl-long.559) |  | 0 | Legal tasks and datasets are often used as benchmarks for the capabilities of language models. However, openly available annotated datasets are rare. In this paper, we introduce AGB-DE, a corpus of 3,764 clauses from German consumer contracts that have been annotated and legally assessed by legal... | Daniel Braun, Florian Matthes |  |
| 679 |  |  [Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks](https://doi.org/10.18653/v1/2024.acl-long.560) |  | 0 | Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model’s average performance across the test prompts of a benchmark to evaluate the model’s performance. This is consistent with the assumption that the test prompts... | Charlotte Siska, James Bono, Katerina Marazopoulou, Melissa Ailem |  |
| 680 |  |  [Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning](https://doi.org/10.18653/v1/2024.acl-long.561) |  | 0 | We present a new method for large language models to solve compositional tasks. Although they have shown strong performance on traditional language understanding tasks, large language models struggle to solve compositional tasks, where the solution depends on solving smaller instances of the same... | Chenguang Wang, Dawn Song, Eric Pasewark, Kefei Duan, Kyle Montgomery |  |
| 681 |  |  [Bridging the Preference Gap between Retrievers and LLMs](https://doi.org/10.18653/v1/2024.acl-long.562) |  | 0 | Large Language Models (LLMs) have demonstrated superior results across a wide range of tasks, and Retrieval-augmented Generation (RAG) is an effective way to enhance the performance by locating relevant information and placing it into the context window of the LLM. However, the relationship between... | Cheng Li, Michael Bendersky, Mingyang Zhang, Qiaozhu Mei, Weize Kong, Zixuan Ke |  |
| 682 |  |  [Large Language Models Can Learn Temporal Reasoning](https://doi.org/10.18653/v1/2024.acl-long.563) |  | 0 | While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs... | Ali Payani, Faramarz Fekri, Ramana Kompella, Siheng Xiong |  |
| 683 |  |  [Learning Relational Decomposition of Queries for Question Answering from Tables](https://doi.org/10.18653/v1/2024.acl-long.564) |  | 0 | Table Question-Answering involves both understanding the natural language query and grounding it in the context of the input table to extract relevant information. In this context, many methods have highlighted the benefits of intermediate pre-training using SQL queries. However, while most... | Benjamin Piwowarski, Raphaël Mouravieff, Sylvain Lamprier |  |
| 684 |  |  [Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People](https://doi.org/10.18653/v1/2024.acl-long.565) |  | 0 | Conversational tones — the manners and attitudes in which speakers communicate — are essential to effective communication. As Large Language Models (LLMs) become increasingly popular, it is necessary to characterize the divergences in their conversational tones relative to humans. Prior research... | DunMing Huang, Ilia Sucholutsky, Nori Jacoby, Pol van Rijn, Raja Marjieh |  |
| 685 |  |  [Pareto Optimal Learning for Estimating Large Language Model Errors](https://doi.org/10.18653/v1/2024.acl-long.566) |  | 0 | Large Language Models (LLMs) have shown impressive abilities in many applications. When a concrete and precise answer is desired, it is important to have a quantitative estimation of the potential error rate. However, this can be challenging due to the text-in-text-out nature of the generative... | Hoifung Poon, Joseph Preston, Mu Wei, Theodore Zhao |  |
| 686 |  |  [Simul-LLM: A Framework for Exploring High-Quality Simultaneous Translation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.567) |  | 0 | Large language models (LLMs) with billions of parameters and pretrained on massive amounts of data are now capable of near or better than state-of-the-art performance in a variety of downstream natural language processing tasks. Neural machine translation (NMT) is one such task that LLMs have been... | Kazi Ahmed Asif Fuad, Lizhong Chen, Matthew Raffel, Max Wild, Victor Agostinelli |  |
| 687 |  |  [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM](https://doi.org/10.18653/v1/2024.acl-long.568) |  | 0 | Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with... | Bochuan Cao, Jinghui Chen, Lu Lin, Yuanpu Cao |  |
| 688 |  |  [Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.569) |  | 0 | This study explores the realm of knowledge base question answering (KBQA). KBQA is considered a challenging task, particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)-based methods require extensive data annotations, which result in... | Guanming Xiong, Junwei Bao, Wen Zhao |  |
| 689 |  |  [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](https://doi.org/10.18653/v1/2024.acl-long.570) |  | 0 | Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect... | Benjamin Van Durme, Boshi Wang, Hao Fang, Jason Eisner, Yu Su |  |
| 690 |  |  [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://doi.org/10.18653/v1/2024.acl-long.571) |  | 0 | The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the... | Hao Zhao, Huijia Wu, Jie Fu, Zhaofeng He, Zihan Qiu, Zili Wang |  |
| 691 |  |  [Aligning Large Language Models with Human Preferences through Representation Engineering](https://doi.org/10.18653/v1/2024.acl-long.572) |  | 0 | Aligning large language models (LLMs) with human preferences is crucial for enhancing their utility in terms of helpfulness, truthfulness, safety, harmlessness, and interestingness. Existing methods for achieving this alignment often involve employing reinforcement learning from human feedback... | Cenyuan Zhang, Changze Lv, Jianhao Zhu, Muling Wu, Tianlong Li, Wenhao Liu, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang, Zixuan Ling |  |
| 692 |  |  [CODIS: Benchmarking Context-dependent Visual Comprehension for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.573) |  | 0 | Multimodal large language models (MLLMs) have demonstrated promising results in a variety of tasks that combine vision and language. As these models become more integral to research and applications, conducting comprehensive evaluations of their capabilities has grown increasingly important.... | Chi Chen, Fuwen Luo, Maosong Sun, Ning Ma, Peng Li, Qidong Yan, Siyu Wang, Xiaolong Wang, Xiaoyue Mi, Yang Liu, Yingjie Li, Zhaolu Kang, Zihao Wan, Ziyue Wang |  |
| 693 |  |  [ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.574) |  | 0 | Human annotation is a time-consuming task that requires a significant amount of effort. To address this issue, interactive data annotation utilizes an annotation model to provide suggestions for humans to approve or correct. However, annotation models trained with limited labeled data are prone to... | Chen Huang, Ilija Ilievski, Jiancheng Lv, Wenqiang Lei, Yiping Jin |  |
| 694 |  |  [PolCLIP: A Unified Image-Text Word Sense Disambiguation Model via Generating Multimodal Complementary Representations](https://doi.org/10.18653/v1/2024.acl-long.575) |  | 0 | Word sense disambiguation (WSD) can be viewed as two subtasks: textual word sense disambiguation (Textual-WSD) and visual word sense disambiguation (Visual-WSD). They aim to identify the most semantically relevant senses or images to a given context containing ambiguous target words. However,... | Fu Lee Wang, Qihao Yang, Tianyong Hao, Xuelin Wang, Yong Li |  |
| 695 |  |  [Prompted Aspect Key Point Analysis for Quantitative Review Summarization](https://doi.org/10.18653/v1/2024.acl-long.576) |  | 0 | Key Point Analysis (KPA) aims for quantitative summarization that provides key points (KPs) as succinct textual summaries and quantities measuring their prevalence. KPA studies for arguments and reviews have been reported in the literature. A majority of KPA studies for reviews adopt supervised... | An Quang Tang, Erik Cambria, Minh Ngoc Dinh, Xiuzhen Zhang |  |
| 696 |  |  [Ask Again, Then Fail: Large Language Models' Vacillations in Judgment](https://doi.org/10.18653/v1/2024.acl-long.577) |  | 0 | We observe that current large language models often waver in their judgments when faced with follow-up questions, even if the original judgment was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this... | Qiming Xie, Rui Xia, Yi Feng, Zengzhi Wang |  |
| 697 |  |  [CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.578) |  | 0 | Large language models (LLMs) are increasingly used to meet user information needs, but their effectiveness in dealing with user queries that contain various types of ambiguity remains unknown, ultimately risking user trust and satisfaction. To this end, we introduce CLAMBER, a benchmark for... | Chen Huang, Dingnan Jin, Hongru Liang, Junhong Liu, Peixin Qin, TatSeng Chua, Tong Zhang, Wenqiang Lei, Yang Deng |  |
| 698 |  |  [Multimodal Reasoning with Multimodal Knowledge Graph](https://doi.org/10.18653/v1/2024.acl-long.579) |  | 0 | Multimodal reasoning with large language models (LLMs) often suffers from hallucinations and the presence of deficient or outdated knowledge within LLMs. Some approaches have sought to mitigate these issues by employing textual knowledge graphs, but their singular modality of knowledge limits... | Jing Li, Junlin Lee, Min Zhang, Yequan Wang |  |
| 699 |  |  [Confidence is not Timeless: Modeling Temporal Validity for Rule-based Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.acl-long.580) |  | 0 | Recently, Temporal Knowledge Graph Forecasting (TKGF) has emerged as a pivotal domain for forecasting future events. Unlike black-box neural network methods, rule-based approaches are lauded for their efficiency and interpretability. For this line of work, it is crucial to correctly estimate the... | Dangyang Chen, Rikui Huang, Shengzhe Zhang, Wei Wei, Xiaoye Qu, Yu Cheng |  |
| 700 |  |  [CARE: A Clue-guided Assistant for CSRs to Read User Manuals](https://doi.org/10.18653/v1/2024.acl-long.581) |  | 0 | It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don’t fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence,... | Dingnan Jin, Hongru Liang, Jia Liu, Weihong Du, Wenqiang Lei, Zujie Wen |  |
| 701 |  |  [Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning Processes](https://doi.org/10.18653/v1/2024.acl-long.582) |  | 0 | Numerical reasoning is an essential ability for NLP systems to handle numeric information. Recent research indicates that fine-tuning a small-scale model to learn generating reasoning processes alongside answers can significantly enhance performance. However, current methods have the limitation... | Dingzirui Wang, Longxu Dou, Qingfu Zhu, Wanxiang Che, Xuanliang Zhang |  |
| 702 |  |  [PAGED: A Benchmark for Procedural Graphs Extraction from Documents](https://doi.org/10.18653/v1/2024.acl-long.583) |  | 0 | Automatic extraction of procedural graphs from documents creates a low-cost way for users to easily understand a complex procedure by skimming visual graphs. Despite the progress in recent studies, it remains unanswered: whether the existing studies have well solved this task (Q1) and whether the... | Hongru Liang, Weihong Du, Wenqiang Lei, Wenrui Liao |  |
| 703 |  |  [Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors](https://doi.org/10.18653/v1/2024.acl-long.584) |  | 0 | With the launch of ChatGPT, large language models (LLMs) have attracted global attention. In the realm of article writing, LLMs have witnessed extensive utilization, giving rise to concerns related to intellectual property protection, personal privacy, and academic integrity. In response, AI-text... | Ben He, Le Sun, Ying Zhou |  |
| 704 |  |  [RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models](https://doi.org/10.18653/v1/2024.acl-long.585) |  | 0 | Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs). Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents. In order to develop effective hallucination... | Cheng Niu, Juno Zhu, Juntong Song, Kashun Shum, Randy Zhong, Siliang Xu, Tong Zhang, Yuanhao Wu |  |
| 705 |  |  [The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.586) |  | 0 | In the era of large language models (LLMs), hallucination (the tendency to generate factually incorrect content) poses great challenges to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the hallucination, three key questions should be well studied: how to detect... | JiRong Wen, JianYun Nie, Jie Chen, Junyi Li, Ruiyang Ren, Xiaoxue Cheng, Xin Zhao |  |
| 706 |  |  [Revisiting Knowledge Distillation for Autoregressive Language Models](https://doi.org/10.18653/v1/2024.acl-long.587) |  | 0 | Knowledge distillation (KD) is a common approach to compress a teacher model to reduce its inference cost and memory footprint, by training a smaller student model. However, in the context of autoregressive language models (LMs), we empirically find that larger teacher LMs might dramatically result... | Bo Du, Dacheng Tao, Juhua Liu, Li Shen, Liang Ding, Qihuang Zhong |  |
| 707 |  |  [Continual Learning with Semi-supervised Contrastive Distillation for Incremental Neural Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.588) |  | 0 | Incrementally expanding the capability of an existing translation model to solve new domain tasks over time is a fundamental and practical problem, which usually suffers from catastrophic forgetting. Generally, multi-domain learning can be seen as a good solution. However, there are two drawbacks:... | Fandong Meng, Jiaan Wang, Jie Zhou, Jinan Xu, Yufeng Chen, Yunlong Liang |  |
| 708 |  |  [Make-A-Voice: Revisiting Voice Large Language Models as Scalable Multilingual and Multitask Learners](https://doi.org/10.18653/v1/2024.acl-long.589) |  | 0 | Large language models (LLMs) have successfully served as a general-purpose interface across multiple tasks and languages, while the adaptation of voice LLMs is mostly designed for specific purposes (either single-task or monolingual), where the advantages of LLMs especially for low-resource... | Chao Weng, Chunlei Zhang, Dong Yu, Dongchao Yang, Jiatong Shi, Jinchuan Tian, Luping Liu, Rongjie Huang, Xuankai Chang, Yongqi Wang, Zehan Wang, Zhenhui Ye, Zhou Zhao, Ziyue Jiang |  |
| 709 |  |  [Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages](https://doi.org/10.18653/v1/2024.acl-long.590) |  | 0 | Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of chat vector to equip pre-trained language... | Hungyi Lee, KuangMing Chen, PinZu Li, Richard TzongHan Tsai, ShihCheng Huang, ShihKai Hsiao, YuChi Hsu, YuTung Lin |  |
| 710 |  |  [PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails](https://doi.org/10.18653/v1/2024.acl-long.591) |  | 0 | Large language models (LLMs) are typically aligned to be harmless to humans. Unfortunately, recent work has shown that such models are susceptible to automated jailbreak attacks that induce them to generate harmful content. More recent LLMs often incorporate an additional layer of defense, a Guard... | Ashish Hooda, Atul Prakash, Jihye Choi, Kassem Fawaz, Neal Mangaokar, Shreyas Chandrashekaran, Somesh Jha |  |
| 711 |  |  [Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLMs-Powered Assistance](https://doi.org/10.18653/v1/2024.acl-long.592) |  | 0 | Learning from noisy labels (LNL) is a challenge that arises in many real-world scenarios where collected training data can contain incorrect or corrupted labels. Most existing solutions identify noisy labels and adopt active learning to query human experts on them for denoising. In the era of large... | Bo Yuan, Wei Jiang, Yin Zhang, Yulin Chen |  |
| 712 |  |  [CLOMO: Counterfactual Logical Modification with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.593) |  | 0 | In this study, we delve into the realm of counterfactual reasoning capabilities of large language models (LLMs). Our primary objective is to cultivate the counterfactual thought processes within LLMs and rigorously assess these processes for their validity. Specifically, we introduce a novel task,... | Changshui Zhang, Dong Yu, Hongming Zhang, Linqi Song, Ruixin Hong, Wei Shao, Xiaodan Liang, Yinya Huang, Zhicheng Yang |  |
| 713 |  |  [Exploring Hybrid Question Answering via Program-based Prompting](https://doi.org/10.18653/v1/2024.acl-long.594) |  | 0 | Question answering over heterogeneous data requires reasoning over diverse sources of data, which is challenging due to the large scale of information and organic coupling of heterogeneous data. Various approaches have been proposed to address these challenges. One approach involves training... | Han Cui, Haofeng Wang, Qi Shi, Qingfu Zhu, Ting Liu, Wanxiang Che |  |
| 714 |  |  [IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages](https://doi.org/10.18653/v1/2024.acl-long.595) |  | 0 | As large language models (LLMs) see increasing adoption across the globe, it is imperative for LLMs to be representative of the linguistic diversity of the world. India is a linguistically diverse country of 1.4 Billion people. To facilitate research on multilingual LLM evaluation, we release... | Dinesh Tewari, Harman Singh, Nitish Gupta, Partha Talukdar, Shikhar Bharadwaj |  |
| 715 |  |  [Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.596) |  | 0 | Temporal knowledge graph completion aims to infer the missing facts in temporal knowledge graphs. Current approaches usually embed factual knowledge into continuous vector space and apply geometric operations to learn potential patterns in temporal knowledge graphs. However, these methods only... | Hang Gao, Jianfeng Wu, Linlin Zhang, Mengting Hu, Ming Jiang, Renhong Cheng, Rui Ying, Xiaoyi Liu, Yalan Xie, Zhunheng Wang |  |
| 716 |  |  [Uncertainty Aware Learning for Language Model Alignment](https://doi.org/10.18653/v1/2024.acl-long.597) |  | 0 | As instruction-tuned large language models (LLMs) evolve, aligning pretrained foundation models presents increasing challenges. Existing alignment strategies, which typically leverage diverse and high-quality data sources, often overlook the intrinsic uncertainty of tasks, learning all data samples... | Dacheng Tao, Dahua Lin, Liang Ding, Qi Zhang, Rui Zheng, Yikun Wang |  |
| 717 |  |  [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.598) |  | 0 | Accurate and interpretable user satisfaction estimation (USE) is critical for understanding, evaluating, and continuously improving conversational systems. Users express their satisfaction or dissatisfaction with diverse conversational patterns in both general-purpose (ChatGPT and Bing Copilot) and... | Brent J. Hecht, Deepak Gupta, Georg Buscher, Jack W. Stokes, Jaime Teevan, Jennifer Neville, Longqi Yang, Mengting Wan, Reid Andersen, Saurabh Tiwary, Scott Counts, Siddharth Suri, Sujay Kumar Jauhar, Tara Safavi, Xia Song, Xiaofeng Xu, YingChun Lin |  |
| 718 |  |  [Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey](https://doi.org/10.18653/v1/2024.acl-long.599) |  | 0 | Large Language Models (LLMs) demonstrate significant value in domain-specific applications, benefiting from their fundamental capabilities. Nevertheless, it is still unclear which fundamental capabilities contribute to success in specific domains. Moreover, the existing benchmark-based evaluation... | Bin Xu, Chong Feng, Heyan Huang, Huashan Sun, Jiawei Li, Ren Bowen, Xiaofeng Zhou, Xingpeng Si, Yang Gao, Yiguan Lin, Yinghao Li, Yixiao Wu, Yizhe Yang, Yu Bai, Yuhang Liu, Yuhao Ye |  |
| 719 |  |  [Measuring Political Bias in Large Language Models: What Is Said and How It Is Said](https://doi.org/10.18653/v1/2024.acl-long.600) |  | 0 | We propose to measure political bias in LLMs by analyzing both the content and style of their generated content regarding political issues. Existing benchmarks and measures focus on gender and racial biases. However, political bias exists in LLMs and can lead to polarization and other harms in... | Delong Chen, Nayeon Lee, Pascale Fung, Yejin Bang |  |
| 720 |  |  [Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use](https://doi.org/10.18653/v1/2024.acl-long.601) |  | 0 | In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in... | Ang Lv, Changyu Chen, Fei Huang, Rui Yan, TingEn Lin, Yongbin Li, Yuchuan Wu, Yuhan Chen |  |
| 721 |  |  [Layer-Condensed KV Cache for Efficient Inference of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.602) |  | 0 | Huge memory consumption has been a major bottleneck for deploying high-throughput large language models in real-world applications. In addition to the large number of parameters, the key-value (KV) cache for the attention mechanism in the transformer architecture consumes a significant amount of... | Haoyi Wu, Kewei Tu |  |
| 722 |  |  [Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages](https://doi.org/10.18653/v1/2024.acl-long.603) |  | 0 | While large language models (LLMs) have been pre-trained on multilingual corpora, their performance still lags behind in most languages compared to a few resource-rich languages. One common approach to mitigate this issue is to translate training data from resource-rich languages into other... | Maosong Sun, Peng Li, Shuo Wang, Xiaolong Wang, Yang Liu, Yile Wang, Yuanchi Zhang, Zijun Liu |  |
| 723 |  |  [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](https://doi.org/10.18653/v1/2024.acl-long.604) |  | 0 | We introduce CHARM, the first benchmark for comprehensively and in-depth evaluating the commonsense reasoning ability of large language models (LLMs) in Chinese, which covers both globally known and Chinese-specific commonsense. We evaluated 7 English and 12 Chinese-oriented LLMs on CHARM,... | Chenya Gu, Conghui He, Hang Yan, Jiang Wu, Jiaxing Sun, Songyang Zhang, Wei Li, Weiquan Huang |  |
| 724 |  |  [Browse and Concentrate: Comprehending Multimodal Content via Prior-LLM Context Fusion](https://doi.org/10.18653/v1/2024.acl-long.605) |  | 0 | With the bloom of Large Language Models (LLMs), Multimodal Large Language Models (MLLMs) that incorporate LLMs with pre-trained vision models have recently demonstrated impressive performance across diverse vision-language tasks. However, they fall short to comprehend context involving multiple... | Chi Chen, Fei Huang, Fuwen Luo, Ji Zhang, Maosong Sun, Ming Yan, Peng Li, Yang Liu, Yiqi Zhu, Ziyue Wang |  |
| 725 |  |  [Model Composition for Multimodal Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.606) |  | 0 | Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is... | Chi Chen, Fei Huang, Fuwen Luo, Ji Zhang, Maosong Sun, Ming Yan, Peng Li, Yang Liu, Yiyang Du, Zheng Fang, Ziyue Wang |  |
| 726 |  |  [Draft& Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.607) |  | 0 | We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower... | Gang Chen, Huan Li, Jue Wang, Jun Zhang, Ke Chen, Lidan Shou, Sharad Mehrotra |  |
| 727 |  |  [Soul-Mix: Enhancing Multimodal Machine Translation with Manifold Mixup](https://doi.org/10.18653/v1/2024.acl-long.608) |  | 0 | Multimodal machine translation (MMT) aims to improve the performance of machine translation with the help of visual information, which has received widespread attention recently. It has been verified that visual information brings greater performance gains when the textual information is limited.... | Hao An, Hongxiang Li, Xuxin Cheng, Yaowei Li, Yifei Xin, Yuexian Zou, Ziyu Yao |  |
| 728 |  |  [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.609) |  | 0 | The process of meaning composition, wherein smaller units like morphemes or words combine to form the meaning of phrases and sentences, is essential for human sentence comprehension. Despite extensive neurolinguistic research into the brain regions involved in meaning composition, a computational... | Changjiang Gao, Jiajun Chen, Jixing Li, Shujian Huang |  |
| 729 |  |  [MIST: Mutual Information Maximization for Short Text Clustering](https://doi.org/10.18653/v1/2024.acl-long.610) |  | 0 | Short text clustering poses substantial challenges due to the limited amount of information provided by each text sample. Previous efforts based on dense representations are still inadequate as texts are not sufficiently segregated in the embedding space before clustering. Even though the... | Can Udomcharoenchaikit, Krissanee Kamthawee, Sarana Nutanong |  |
| 730 |  |  [Self-chats from Large Language Models Make Small Emotional Support Chatbot Better](https://doi.org/10.18653/v1/2024.acl-long.611) |  | 0 | Large Language Models (LLMs) have shown strong generalization abilities to excel in various tasks, including emotion support conversations. However, deploying such LLMs like GPT-3 (175B parameters) is resource-intensive and challenging at scale. In this study, we utilize LLMs as “Counseling... | Libo Qin, Liqiang Nie, Lizi Liao, Yang Deng, Zhonghua Zheng |  |
| 731 |  |  [Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment](https://doi.org/10.18653/v1/2024.acl-long.612) |  | 0 | The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced techniques such as instruction tuning and reinforcement... | DuSeong Chang, Janghwan Lee, Jungwook Choi, Minsoo Kim, Seongmin Park, Sukjin Hong |  |
| 732 |  |  [Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.613) |  | 0 | Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit contextunderlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense infer-ences for contexts and questions... | Antoine Bosselut, Tianqing Fang, Yangqiu Song, Zeming Chen |  |
| 733 |  |  [An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing](https://doi.org/10.18653/v1/2024.acl-long.614) |  | 0 | We present Expert-Token-Routing, a unified generalist framework that facilitates seamless integration of multiple expert LLMs. Our framework represents expert LLMs as special expert tokens within the vocabulary of a meta LLM. The meta LLM can route to an expert LLM like generating new tokens.... | Fei Wu, Guoyin Wang, Hongxia Yang, Jianbo Yuan, Jing Su, Jingjing Xu, Tianjie Zhang, Xuanwen Huang, Xuwu Wang, Yang Yang, Ziwei Chai |  |
| 734 |  |  [Learning to Plan and Generate Text with Citations](https://doi.org/10.18653/v1/2024.acl-long.615) |  | 0 | The increasing demand for the deployment of LLMs in information-seeking scenarios has spurred efforts in creating verifiable systems, which generate responses to queries along with supporting evidence. In this paper, we explore the attribution capabilities of plan-based models which have been... | Constanza Fierro, Fantine Huot, Joshua Maynez, Mirella Lapata, Nicola De Cao, Reinald Kim Amplayo, Shashi Narayan |  |
| 735 |  |  [Exploring Precision and Recall to assess the quality and diversity of LLMs](https://doi.org/10.18653/v1/2024.acl-long.616) |  | 0 | We introduce a novel evaluation framework for Large Language Models (LLMs) such as Llama-2 and Mistral, focusing on importing Precision and Recall metrics from image generation to text generation. This approach allows for a nuanced assessment of the quality and diversity of generated text without... | Alexandre Allauzen, Alexandre Verine, Benjamin Négrevergne, Florian Le Bronnec, Yann Chevaleyre |  |
| 736 |  |  [Aligning Large Language Models by On-Policy Self-Judgment](https://doi.org/10.18653/v1/2024.acl-long.617) |  | 0 | Existing approaches for aligning large language models with human preferences face a trade-off that requires a separate reward model (RM) for on-policy learning. In this paper, we present a novel alignment framework, SELF-JUDGE that (1) does on-policy learning and 2) is parameter efficient, as it... | Ashkan Yousefpour, Kang Min Yoo, Minjoon Seo, Sangkyu Lee, Sungdong Kim, Youngjae Yu |  |
| 737 |  |  [IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning](https://doi.org/10.18653/v1/2024.acl-long.618) |  | 0 | Legal systems worldwide are inundated with exponential growth in cases and documents. There is an imminent need to develop NLP and ML techniques for automatically processing and understanding legal documents to streamline the legal system. However, evaluating and comparing various NLP models... | Abhinav Joshi, Akshat Sharma, Ashutosh Modi, Pawan Goyal, Saptarshi Ghosh, Shounak Paul |  |
| 738 |  |  [JumpCoder: Go Beyond Autoregressive Coder via Online Modification](https://doi.org/10.18653/v1/2024.acl-long.619) |  | 0 | While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often... | Hao Tian, Jianling Sun, Mouxiang Chen, Xiaoxue Ren, Zhongxin Liu |  |
| 739 |  |  [Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.acl-long.620) |  | 0 | Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the fine-tuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to... | Abinaya Mahendiran, Ahmet Üstün, Aisha Alaagib, Börje Karlsson, Daniel D'souza, Deividas Mataciunas, Dominik Krzeminski, Emad A. Alghamdi, Freddie Vargus, Hakimeh Fadaei, Herumb Shandilya, Ifeoma Okoh, Irem Ergün, Jay Patel, Joseph Wilson, Julia Kreutzer, Laura O'Mahony, Luisa Souza Moura, Marina Machado, Marzieh Fadaee, Max Bartolo, Mike Zhang, Minh Vu Chien, Niklas Muennighoff, Oshan Mudannayake, Ramith Hettiarachchi, Sara Hooker, Sebastian Gehrmann, Sebastian Ruder, Shivalika Singh, Surya Guthikonda, WeiYin Ko, Zaid Alyafeai |  |
| 740 |  |  [Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks](https://doi.org/10.18653/v1/2024.acl-long.621) |  | 0 | Large Language Models (LLMs) have transformed NLP with their remarkable In-context Learning (ICL) capabilities. Automated assistants based on LLMs are gaining popularity; however, adapting them to novel tasks is still challenging. While colossal models excel in zero-shot performance, their... | Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty |  |
| 741 |  |  [Split and Rephrase with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.622) |  | 0 | The Split and Rephrase (SPRP) task, which consists in splitting complex sentences into a sequence of shorter grammatical sentences, while preserving the original meaning, can facilitate the processing of complex texts for humans and machines alike. It is also a valuable testbed to evaluate natural... | David Ponce, Harritxu Gete, Jesus Calleja, Thierry Etchegoyhen |  |
| 742 |  |  [ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition](https://doi.org/10.18653/v1/2024.acl-long.623) |  | 0 | Self-attention is an essential component of large language models (LLM) but a significant source of inference latency for long sequences. In multi-tenant LLMs serving scenarios, the compute and memory operation cost of self-attention can be optimized by using the probability that multiple LLM... | Lu Ye, Yang Li, Yong Huang, Ze Tao |  |
| 743 |  |  [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.624) |  | 0 | Alignment has become a critical step for instruction-tuned Large Language Models (LLMs) to become helpful assistants. However, effective evaluation of alignment for emerging Chinese LLMs is still significantly lacking, calling for real-scenario grounded, open-ended, challenging and automatic... | Andrew Feng, Bosi Wen, Hongning Wang, Jiale Cheng, Jie Tang, Jing Zhang, Lichao Sun, Minlie Huang, Pei Ke, Shengyuan Wang, Weng Lam Tam, Xiao Liu, Xiaohan Zhang, Xiaotao Gu, Xuanyu Lei, Yifan Xu, Yue Huang, Yuxiao Dong |  |
| 744 |  |  [SAPT: A Shared Attention Framework for Parameter-Efficient Continual Learning of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.625) |  | 0 | The continual learning (CL) ability is vital for deploying large language models (LLMs) in the dynamic world. Existing methods devise the learning module to acquire task-specific knowledge with parameter-efficient tuning (PET) block and the selection module to pick out the corresponding one for the... | Bing Qin, Dongliang Xu, Qing Yang, Shilong Wang, Wanxiang Che, Weixiang Zhao, Xuanyu Zhang, Yanyan Zhao, Yulin Hu |  |
| 745 |  |  [DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution](https://doi.org/10.18653/v1/2024.acl-long.626) |  | 0 | Fine-tuning large-scale pre-trained models is inherently a resource-intensive task. While it can enhance the capabilities of the model, it also incurs substantial computational costs, posing challenges to the practical application of downstream tasks. Existing parameter-efficient fine-tuning (PEFT)... | Changhao Guan, Fengran Mo, Ganglin Bao, Jinan Xu, Kaiyu Huang, Yulong Mao |  |
| 746 |  |  [Cross-Lingual Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.627) |  | 0 | Knowledge editing aims to change language models’ performance on several special cases (i.e., editing scope) by infusing the corresponding expected knowledge into them. With the recent advancements in large language models (LLMs), knowledge editing has been shown as a promising technique to adapt... | Fandong Meng, Jiaan Wang, Jiarong Xu, Yunlong Liang, Yuxuan Cao, Zengkui Sun |  |
| 747 |  |  [Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques](https://doi.org/10.18653/v1/2024.acl-long.628) |  | 0 | Recent research on sequence labelling has been exploring different strategies to mitigate the lack of manually annotated data for the large majority of the world languages. Among others, the most successful approaches have been based on (i) the crosslingual transfer capabilities of multilingual... | Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri |  |
| 748 |  |  [Learning Task Decomposition to Assist Humans in Competitive Programming](https://doi.org/10.18653/v1/2024.acl-long.629) |  | 0 | When using language models (LMs) to solve complex problems, humans might struggle to understand the LM-generated solutions and repair the flawed ones. To assist humans in repairing them, we propose to automatically decompose complex solutions into multiple simpler pieces that correspond to specific... | Hongning Wang, Jiaxin Wen, Minlie Huang, Pei Ke, Ruiqi Zhong, Zhihong Shao |  |
| 749 |  |  [An Entropy-based Text Watermarking Detection Method](https://doi.org/10.18653/v1/2024.acl-long.630) |  | 0 | Text watermarking algorithms for large language models (LLMs) can effectively identify machine-generated texts by embedding and detecting hidden features in the text. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy... | Aiwei Liu, Dianzhi Yu, Irwin King, Jingjing Li, Yijian Lu |  |
| 750 |  |  [Enhancing Explainable Rating Prediction through Annotated Macro Concepts](https://doi.org/10.18653/v1/2024.acl-long.631) |  | 0 | Generating recommendation reasons for recommendation results is a long-standing problem because it is challenging to explain the underlying reasons for recommending an item based on user and item IDs. Existing models usually learn semantic embeddings for each user and item, and generate the reasons... | Fan Yang, Hao Chen, Huachi Zhou, Ninghao Liu, Shuang Zhou, Xiao Huang |  |
| 751 |  |  [How to Engage your Readers? Generating Guiding Questions to Promote Active Reading](https://doi.org/10.18653/v1/2024.acl-long.632) |  | 0 | Using questions in written text is an effective strategy to enhance readability. However, what makes an active reading question good, what the linguistic role of these questions is, and what is their impact on human reading remains understudied. We introduce GuidingQ, a dataset of 10K in-text... | Mrinmaya Sachan, Peng Cui, Vilém Zouhar, Xiaoyu Zhang |  |
| 752 |  |  [Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective](https://doi.org/10.18653/v1/2024.acl-long.633) |  | 0 | Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model’s ability to timely terminate generation,... | Liang Zhang, Qin Jin, Zihao Yue |  |
| 753 |  |  [Integrate the Essence and Eliminate the Dross: Fine-Grained Self-Consistency for Free-Form Language Generation](https://doi.org/10.18653/v1/2024.acl-long.634) |  | 0 | Self-consistency (SC), leveraging multiple samples from LLMs, shows significant gains on various reasoning tasks but struggles with free-form generation due to the difficulty of aggregating answers. Its variants, UCS and USC, rely on sample selection or voting mechanisms to improve output quality.... | Boyuan Pan, Heda Wang, Kan Li, Peiwen Yuan, Shaoxiong Feng, Xinglin Wang, Yao Hu, Yiwei Li |  |
| 754 |  |  [More frequent verbs are associated with more diverse valency frames: Efficient principles at the lexicon-grammar interface](https://doi.org/10.18653/v1/2024.acl-long.635) |  | 0 | A substantial body of work has provided evidence that the lexicons of natural languages are organized to support efficient communication. However, existing work has largely focused on word-internal properties, such as Zipf’s observation that more frequent words are optimized in form to minimize... | Lucia Donatelli, Michael Hahn, Siyu Tao |  |
| 755 |  |  [Quantifying Generalizations: Exploring the Divide Between Human and LLMs' Sensitivity to Quantification](https://doi.org/10.18653/v1/2024.acl-long.636) |  | 0 | Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., “Birds fly”), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the... | Claudia Collacciani, Giulia Rambelli, Marianna Bolognesi |  |
| 756 |  |  [Can Large Language Models Interpret Noun-Noun Compounds? A Linguistically-Motivated Study on Lexicalized and Novel Compounds](https://doi.org/10.18653/v1/2024.acl-long.637) |  | 0 | Noun-noun compounds interpretation is the task where a model is given one of such constructions, and it is asked to provide a paraphrase, making the semantic relation between the nouns explicit, as in carrot cake is “a cake made of carrots.” Such a task requires the ability to understand the... | Claudia Collacciani, Emmanuele Chersoni, Giulia Rambelli, Marianna Bolognesi |  |
| 757 |  |  [CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation](https://doi.org/10.18653/v1/2024.acl-long.638) |  | 0 | Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in... | Quan Tu, Rui Yan, Shilong Fan, Shuo Shang, Tianhao Shen, Xin Gao, Zihang Tian |  |
| 758 |  |  [Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond](https://doi.org/10.18653/v1/2024.acl-long.639) |  | 0 | The recent advancements in generative language models have demonstrated their ability to memorize knowledge from documents and recall knowledge to respond to user queries effectively. Building upon this capability, we propose to enable multimodal large language models (MLLMs) to memorize and recall... | Leigang Qu, Liqiang Nie, TatSeng Chua, Wenjie Li, Wenjie Wang, Yongqi Li |  |
| 759 |  |  [Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.acl-long.640) |  | 0 | Aspect Sentiment Quad Prediction (ASQP) aims to predict all quads (aspect term, aspect category, opinion term, sentiment polarity) for a given review, which is the most representative and challenging task in aspect-based sentiment analysis. A key challenge in the ASQP task is the scarcity of... | Jie Zeng, Ruifeng Xu, Shiwei Chen, Weiming Hu, Yice Zhang, Ziyi Wang |  |
| 760 |  |  [Learning to Generate Answers with Citations via Factual Consistency Models](https://doi.org/10.18653/v1/2024.acl-long.641) |  | 0 | Large Language Models (LLMs) frequently hallucinate, impeding their reliability in mission-critical situations. One approach to address this issue is to provide citations to relevant sources alongside generated content, enhancing the verifiability of generations. However, citing passages accurately... | George Karypis, Rami Aly, Samson Tan, Zhiqiang Tang |  |
| 761 |  |  [Improving Text Embeddings with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.642) |  | 0 | In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by... | Furu Wei, Liang Wang, Linjun Yang, Nan Yang, Rangan Majumder, Xiaolong Huang |  |
| 762 |  |  [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.643) |  | 0 | Teaching small-scale language models to perform math reasoning is a valuable yet challenging task. Besides obtaining labeled data from human experts, one of the most common ways to collect high-quality data is by sampling from a larger and more powerful language model. Although previous works have... | Shichen Li, Tianduo Wang, Wei Lu |  |
| 763 |  |  [UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset](https://doi.org/10.18653/v1/2024.acl-long.644) |  | 0 | Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual abilities.In this work, we therefore construct an open-source... | Haoyu Wang, Liner Yang, Maosong Sun, Ning Ding, Shuo Wang, Xu Han, Xujia Wang, Yukun Yan, Yuzhuang Xu, Zhenghao Liu, Zhiyu Yang, Zhiyuan Liu |  |
| 764 |  |  [Document-level Claim Extraction and Decontextualisation for Fact-Checking](https://doi.org/10.18653/v1/2024.acl-long.645) |  | 0 | Selecting which claims to check is a time-consuming task for human fact-checkers, especially from documents consisting of multiple sentences and containing multiple claims. However, existing claim extraction approaches focus more on identifying and extracting claims from individual sentences, e.g.,... | Andreas Vlachos, Michael Sejr Schlichtkrull, Zhenyun Deng |  |
| 765 |  |  [PairCFR: Enhancing Model Training on Paired Counterfactually Augmented Data through Contrastive Learning](https://doi.org/10.18653/v1/2024.acl-long.646) |  | 0 | Counterfactually Augmented Data (CAD) involves creating new data samples by applying minimal yet sufficient modifications to flip the label of existing data samples to other classes. Training with CAD enhances model robustness against spurious features that happen to correlate with labels by... | Chunyan Miao, Xiaoqi Qiu, Xu Guo, Yongjie Wang, Yu Yue, Yuhong Feng, Zhiwei Zeng |  |
| 766 |  |  [LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2024.acl-long.647) |  | 0 | In this study, we explore in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting tailored for the EAE task. Specifically, we hypothesize... | Hanzhang Zhou, Hui Lu, Junlang Qian, Kezhi Mao, Zijian Feng, Zixiao Zhu |  |
| 767 |  |  [Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.648) |  | 0 | Though advanced in understanding visual information with human languages, Large Vision-Language Models (LVLMs) still suffer from multimodal hallucinations. A natural concern is that during multimodal interaction, the generated hallucinations could influence the LVLMs’ subsequent generation. Thus,... | Bing Qin, Lei Huang, Liang Zhao, Qiming Li, Weihong Zhong, Weitao Ma, Xiaocheng Feng, Yuan Xu, Yuxuan Gu |  |
| 768 |  |  [mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models](https://doi.org/10.18653/v1/2024.acl-long.649) |  | 0 | Large language models (LLMs) with Chain-of-thought (CoT) have recently emerged as a powerful technique for eliciting reasoning to improve various downstream tasks. As most research mainly focuses on English, with few explorations in a multilingual context, the question of how reliable this... | Huiyuan Lai, Malvina Nissim |  |
| 769 |  |  [GunStance: Stance Detection for Gun Control and Gun Regulation](https://doi.org/10.18653/v1/2024.acl-long.650) |  | 0 | The debate surrounding gun control and gun regulation in the United States has intensified in the wake of numerous mass shooting events. As perspectives on this matter vary, it becomes increasingly important to comprehend individuals’ positions. Stance detection, the task of determining an author’s... | Cornelia Caragea, Doina Caragea, Iustin Sirbu, Nikesh Gyawali, Sarthak Khanal, Tiberiu Sosea, Traian Rebedea |  |
| 770 |  |  [Beyond Traditional Benchmarks: Analyzing Behaviors of Open LLMs on Data-to-Text Generation](https://doi.org/10.18653/v1/2024.acl-long.651) |  | 0 | We analyze the behaviors of open large language models (LLMs) on the task of data-to-text (D2T) generation, i.e., generating coherent and relevant text from structured data. To avoid the issue of LLM training data contamination with standard benchmarks, we design Quintd - a tool for collecting... | Ondrej Dusek, Zdenek Kasner |  |
| 771 |  |  [Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.acl-long.652) |  | 0 | The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue... | ChangTien Lu, Jianfeng He, Min Zhang, Taoran Ji |  |
| 772 |  |  [Don't Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation](https://doi.org/10.18653/v1/2024.acl-long.653) |  | 0 | Neural machine translation systems estimate probabilities of target sentences given source sentences, yet these estimates may not align with human preferences. This work introduces QE-fusion, a method that synthesizes translations using a quality estimation metric (QE), which correlates better with... | Andrei PopescuBelis, Giorgos Vernikos |  |
| 773 |  |  [Generating and Evaluating Plausible Explanations for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.acl-long.654) |  | 0 | Explanations for AI should aid human users, yet this ultimate goal remains under-explored. This paper aims to bridge this gap by investigating the specific explanatory needs of human users in the context of Knowledge Graph Completion (KGC) systems. In contrast to the prevailing approaches that... | Antonio Di Mauro, Carolin Lawrence, Timo Sztyler, Wiem Ben Rim, Zhao Xu |  |
| 774 |  |  [One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation](https://doi.org/10.18653/v1/2024.acl-long.655) |  | 0 | Evaluation of opinion summaries using conventional reference-based metrics often fails to provide a comprehensive assessment and exhibits limited correlation with human judgments. While Large Language Models (LLMs) have shown promise as reference-free metrics for NLG evaluation, their potential... | Amey Patil, Muthusamy Chelliah, Nikesh Garera, Pushpak Bhattacharyya, Rupasai Rangaraju, Sankara Sri Raghava Ravindra Muddu, Sudhanshu Singh, Suman Banerjee, Swaprava Nath, Swaroop Nath, Tejpalsingh Siledar |  |
| 775 |  |  [LANDeRMT: Dectecting and Routing Language-Aware Neurons for Selectively Finetuning LLMs to Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.656) |  | 0 | Recent advancements in large language models (LLMs) have shown promising results in multilingual translation even with limited bilingual supervision. The major challenges are catastrophic forgetting and parameter interference for finetuning LLMs when provided parallel training data. To address... | Bo Li, Deyi Xiong, Leiyu Pan, Shaolin Zhu |  |
| 776 |  |  [A Joint Coreference-Aware Approach to Document-Level Target Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.657) |  | 0 | Most existing work on aspect-based sentiment analysis (ABSA) focuses on the sentence level, while research at the document level has not received enough attention. Compared to sentence-level ABSA, the document-level ABSA is not only more practical but also requires holistic document-level... | Heqing Ma, Hongjie Cai, Jianfei Yu, Rui Xia |  |
| 777 |  |  [VisDiaHalBench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.658) |  | 0 | Despite the significant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hallucination problem, where the LVLMs’ response contains descriptions of non-existent objects. Although various benchmarks have been proposed to investigate this problem,... | Junhao Cheng, Liang Lin, Qingxing Cao, Xiaodan Liang |  |
| 778 |  |  [AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints](https://doi.org/10.18653/v1/2024.acl-long.659) |  | 0 | Accurate representation of procedures in restricted scenarios, such as non-standardized scientific experiments, requires precise depiction of constraints. Unfortunately, Domain-specific Language (DSL), as an effective tool to express constraints structurally, often requires case-by-case... | Fanxu Meng, Haofei Hou, Lecheng Ruan, Qining Wang, Xiang Wei, YuZhe Shi, Zhangqian Bi |  |
| 779 |  |  [Multipath parsing in the brain](https://doi.org/10.18653/v1/2024.acl-long.660) |  | 0 | Humans understand sentences word-by-word, in the order that they hear them. This incrementality entails resolving temporary ambiguities about syntactic relationships. We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency... | Berta Franzluebbers, Donald Dunagan, Jan Buys, John T. Hale, Milos Stanojevic |  |
| 780 |  |  [Search-Adaptor: Embedding Customization for Information Retrieval](https://doi.org/10.18653/v1/2024.acl-long.661) |  | 0 | Embeddings extracted by pre-trained Large Language Models (LLMs) have significant potential to improve information retrieval and search. Beyond the zero-shot setup in which they are being conventionally used, being able to take advantage of the information from the relevant query-corpus paired data... | Jinsung Yoon, Sercan Ö. Arik, Tomas Pfister, Yanfei Chen |  |
| 781 |  |  [Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs](https://doi.org/10.18653/v1/2024.acl-long.662) |  | 0 | AI alignment in the shape of Reinforcement Learning from Human Feedback (RLHF) is increasingly treated as a crucial ingredient for high performance large language models. Proximal Policy Optimization (PPO) has been installed by the seminal literature as the standard method for the RL part of RLHF.... | Ahmet Üstün, Arash Ahmadian, Chris Cremer, Julia Kreutzer, Marzieh Fadaee, Matthias Gallé, Olivier Pietquin, Sara Hooker |  |
| 782 |  |  [VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation](https://doi.org/10.18653/v1/2024.acl-long.663) |  | 0 | In the rapidly advancing field of conditional image generation research, challenges such as limited explainability lie in effectively evaluating the performance and capabilities of various models. This paper introduces VIEScore, a Visual Instruction-guided Explainable metric for evaluating any... | Cong Wei, Dongfu Jiang, Max Ku, Wenhu Chen, Xiang Yue |  |
| 783 |  |  [Tree Transformer's Disambiguation Ability of Prepositional Phrase Attachment and Garden Path Effects](https://doi.org/10.18653/v1/2024.acl-long.664) |  | 0 | This work studies two types of ambiguity in natural language: prepositional phrase (PP) attachment ambiguity, and garden path constructions. Due to the different nature of these ambiguities – one being structural, the other incremental in nature – we pretrain and evaluate the Tree Transformer of... | Gijs Wijnholds, Lingling Zhou, Suzan Verberne |  |
| 784 |  |  [Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs](https://doi.org/10.18653/v1/2024.acl-long.665) |  | 0 | Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot... | Anil Ramakrishna, Aram Galstyan, Charith Peris, Elan Markowitz, Jwala Dhamala, KaiWei Chang, Ninareh Mehrabi, Rahul Gupta |  |
| 785 |  |  [Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.666) |  | 0 | We present the structured average intersection-over-union ratio (STRUCT-IOU), an evaluation metric that compares a constituency parse tree over automatically recognized spoken word boundaries with the ground-truth parse tree over written words. To compute the metric, we (1) project the ground-truth... | Freda Shi, Karen Livescu, Kevin Gimpel |  |
| 786 |  |  [ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.acl-long.667) |  | 0 | Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap,... | Akshita Jha, Chandan K. Reddy, Remi Denton, Rida Qadri, Sarah Laszlo, Shachi Dave, Sunipa Dev, Vinodkumar Prabhakaran |  |
| 787 |  |  [Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking](https://doi.org/10.18653/v1/2024.acl-long.668) |  | 0 | This paper proposes PiNose, which trains a probing model on offline self-consistency checking results, thereby circumventing the need for human-annotated data and achieving transferability across diverse data distributions. As the consistency check process is offline, PiNose reduces the... | Jie Tang, Jifan Yu, Jing Zhang, Juanzi Li, Kaifeng Yun, Xiaokang Zhang, Zijun Yao |  |
| 788 |  |  [What Do Language Models Learn in Context? The Structured Task Hypothesis](https://doi.org/10.18653/v1/2024.acl-long.669) |  | 0 | Large language models (LLMs) exhibit an intriguing ability to learn a novel task from in-context examples presented in a demonstration, termed in-context learning (ICL). Understandably, a swath of research has been dedicated to uncovering the theories underpinning ICL. One popular hypothesis... | Jiaoda Li, Mrinmaya Sachan, Ryan Cotterell, Yifan Hou |  |
| 789 |  |  [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://doi.org/10.18653/v1/2024.acl-long.670) |  | 0 | Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce Lumos, one of the first frameworks for training open-source... | Abhilasha Ravichander, Bill Yuchen Lin, Da Yin, Faeze Brahman, KaiWei Chang, Khyathi Raghavi Chandu, Yejin Choi |  |
| 790 |  |  [Investigating Cultural Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.671) |  | 0 | The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology. Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the... | Badr AlKhamissi, Mai Alkhamissi, Mona T. Diab, Muhammad N. ElNokrashy |  |
| 791 |  |  [More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play](https://doi.org/10.18653/v1/2024.acl-long.672) |  | 0 | The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy AI, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics,... | Brandon M. Stewart, Denis Peskoff, Feng Gu, Jonathan K. Kummerfeld, Jonathan May, Jordan L. BoydGraber, Ulf Hermjakob, Wichayaporn Wongkamjan, Yanze Wang |  |
| 792 |  |  [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://doi.org/10.18653/v1/2024.acl-long.673) |  | 0 | We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token... | Abdelrahman Mohamed, David Harwath, PoYao Huang, Puyuan Peng, ShangWen Li |  |
| 793 |  |  [RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors](https://doi.org/10.18653/v1/2024.acl-long.674) |  | 0 | Many commercial and open-source models claim to detect machine-generated text with extremely high accuracy (99% or more). However, very few of these detectors are evaluated on shared benchmark datasets and even when they are, the datasets used for evaluation are insufficiently challenging—lacking... | Alyssa Hwang, Andrew Zhu, Chris CallisonBurch, Daphne Ippolito, Filip Trhlík, Hainiu Xu, Josh Magnus Ludan, Liam Dugan |  |
| 794 |  |  [Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles](https://doi.org/10.18653/v1/2024.acl-long.675) |  | 0 | A dog whistle is a form of coded communication that carries a secondary meaning to specific audiences and is often weaponized for racial and socioeconomic discrimination. Dog whistling historically originated from United States politics, but in recent years has taken root in social media as a means... | Caleb Ziems, David Muchlinski, Diyi Yang, Julia Kruk, Michela Marchini, Rijul Magu |  |
| 795 |  |  [On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.acl-long.676) |  | 0 | The performance of modern language models (LMs) has been improved by chain-of-thought (CoT) reasoning, i.e., the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that CoT reasoning extends an LM’s computational... | Alexandra Butoi, Anej Svete, Franz Nowak, Ryan Cotterell |  |
| 796 |  |  [Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends](https://doi.org/10.18653/v1/2024.acl-long.677) |  | 0 | Recent advancements in large language models (LLMs) have significantly advanced the capabilities of summarization systems.However, they continue to face a persistent challenge: hallucination. While prior work has extensively examined LLMs in news domains, evaluation of dialogue summarization has... | Elisa Ferracane, Sanjana Ramprasad, Zachary C. Lipton |  |
| 797 |  |  [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://doi.org/10.18653/v1/2024.acl-long.678) |  | 0 | Large language models (LLMs) are central to modern natural language processing, delivering exceptional performance in various tasks. However, their substantial computational and memory requirements present challenges, especially for devices with limited DRAM capacity. This paper tackles the... | Dmitry Belenko, Iman Mirzadeh, Keivan Alizadeh, Mehrdad Farajtabar, Minsik Cho, Mohammad Rastegari, S. Khatamifard |  |
| 798 |  |  [Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models](https://doi.org/10.18653/v1/2024.acl-long.679) |  | 0 | Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the under-explored field of video-based conversation by introducing Video-ChatGPT. It is a... | Fahad Khan, Hanoona Abdul Rasheed, Muhammad Maaz, Salman Khan |  |
| 799 |  |  [To Distill or Not to Distill? On the Robustness of Robust Knowledge Distillation](https://doi.org/10.18653/v1/2024.acl-long.680) |  | 0 | Arabic is known to present unique challengesfor Automatic Speech Recognition (ASR). Onone hand, its rich linguistic diversity andwide range of dialects complicate the de-velopment of robust, inclusive models. Onthe other, current multilingual ASR modelsare compute-intensive and lack proper... | Abdul Waheed, Karima Kadaoui, Muhammad AbdulMageed |  |
| 800 |  |  [LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding](https://doi.org/10.18653/v1/2024.acl-long.681) |  | 0 | We present LayerSkip, an end-to-end solution to speed-up inference of large language models (LLMs). First, during training we apply layer dropout, with low dropout rates for earlier layers and higher dropout rates for later layers, and an early exit loss where all transformer layers share the same... | Ahmed A Aly, Ahmed Roman, Akshat Shrivastava, Anas Mahmoud, Basil Hosmer, Beidi Chen, Bilge Acun, Bram Wasti, CaroleJean Wu, Diana Liskovich, Liangzhen Lai, Mostafa Elhoushi, Saurabh Agarwal |  |
| 801 |  |  [Classist Tools: Social Class Correlates with Performance in NLP](https://doi.org/10.18653/v1/2024.acl-long.682) |  | 0 | The field of sociolinguistics has studied factors affecting language use for the last century. Labov (1964) and Bernstein (1960) showed that socioeconomic class strongly influences our accents, syntax and lexicon. However, despite growing concerns surrounding fairness and bias in Natural Language... | Amanda Cercas Curry, Dirk Hovy, Giuseppe Attanasio, Zeerak Talat |  |
| 802 |  |  [ActionIE: Action Extraction from Scientific Literature with Programming Languages](https://doi.org/10.18653/v1/2024.acl-long.683) |  | 0 | Extraction of experimental procedures from human language in scientific literature and patents into actionable sequences in robotics language holds immense significance in scientific domains. Such an action extraction task is particularly challenging given the intricate details and... | Hao Peng, Heng Ji, Jiawei Han, Ming Zhong, Qirong Ho, Siru Ouyang, Tingfeng Luo, Xianrui Zhong, Yufeng Du |  |
| 803 |  |  [A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech](https://doi.org/10.18653/v1/2024.acl-long.684) |  | 0 | Violence-provoking speech – speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of... | Binny Mathew, Gaurav Verma, Jiawei Zhou, Jordan Kraemer, Munmun De Choudhury, Rynaa Grover, Srijan Kumar |  |
| 804 |  |  [Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs](https://doi.org/10.18653/v1/2024.acl-long.685) |  | 0 | The growing popularity of Large Language Models has sparked interest in context compression for Large Language Models (LLMs). However, the performance of previous methods degrades dramatically as compression ratios increase, sometimes even falling to the closed-book level. This decline can be... | Jinsong Su, Luyang Huang, Ningxin Peng, Qian Cao, Shanbo Cheng, Yu Lu, Zhiwei Cao |  |
| 805 |  |  [COSMIC: Mutual Information for Task-Agnostic Summarization Evaluation](https://doi.org/10.18653/v1/2024.acl-long.686) |  | 0 | Assessing the quality of summarizers poses significant challenges—gold summaries are hard to obtain and their suitability depends on the use context of the summarization system. Who is the user of the system, and what do they intend to do with the summary? In response, we propose a novel... | Jackie Chi Kit Cheung, Maxime Darrin, Pablo Piantanida, Philippe Formont |  |
| 806 |  |  [EUROPA: A Legal Multilingual Keyphrase Generation Dataset](https://doi.org/10.18653/v1/2024.acl-long.687) |  | 0 | Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a novel dataset for multilingual keyphrase generation in the legal domain. It is derived from... | David AlfonsoHermelo, Frédéric Piedboeuf, Guillaume Le Berre, Olivier Salaün, Philippe Langlais |  |
| 807 |  |  [GLIMPSE: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews](https://doi.org/10.18653/v1/2024.acl-long.688) |  | 0 | Scientific peer review is essential for the quality of academic publications. However, the increasing number of paper submissions to conferences has strained the reviewing process. This surge poses a burden on area chairs who have to carefully read an ever-growing volume of reviews and discern each... | Ines Arous, Jackie Chi Kit Cheung, Maxime Darrin, Pablo Piantanida |  |
| 808 |  |  [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](https://doi.org/10.18653/v1/2024.acl-long.689) |  | 0 | Multimodal large language models (MLLMs) have proven effective in a wide range of tasks that require complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, the success of MLLMs remains relatively limited to... | Abdelrahman Mohamed, El Moatez Billah Nagoudi, Fakhraddin Alwajih, Gagan Bhatia, Muhammad AbdulMageed |  |
| 809 |  |  [Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks](https://doi.org/10.18653/v1/2024.acl-long.690) |  | 0 | Multistep instructions, such as recipes and how-to guides, greatly benefit from visual aids, such as a series of images that accompany the instruction steps. While Large Language Models (LLMs) have become adept at generating coherent textual steps, Large Vision/Language Models (LVLMs) are less... | Diogo GlóriaSilva, Idan Szpektor, João Bordalo, João Magalhães, Michal Yarom, Rodrigo Valerio, Vasco Ramos, Yonatan Bitton |  |
| 810 |  |  [Cheetah: Natural Language Generation for 517 African Languages](https://doi.org/10.18653/v1/2024.acl-long.691) |  | 0 | Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language... | AbdelRahim A. Elmadany, Ife Adebara, Muhammad AbdulMageed |  |
| 811 |  |  [TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table QA by Content Planning and Execution-based Reasoning](https://doi.org/10.18653/v1/2024.acl-long.692) |  | 0 | Long-form Table Question Answering (LFTQA) requires systems to generate paragraph long and complex answers to questions over tabular data. While Large language models based systems have made significant progress, it often hallucinates, especially when the task involves complex reasoning over... | Arman Cohan, Chen Zhao, Lyuhao Chen, Yilun Zhao |  |
| 812 |  |  [KnowledgeFMath: A Knowledge-Intensive Math Reasoning Dataset in Finance Domains](https://doi.org/10.18653/v1/2024.acl-long.693) |  | 0 | We introduce FinanceMath, a novel benchmark designed to evaluate LLMs' capabilities in solving knowledge-intensive math reasoning problems. Compared to prior works, this study features three core advancements. First, FinanceMath includes 1,200 problems with a hybrid of textual and tabular content.... | Arman Cohan, Chen Zhao, Hongjun Liu, Rui Zhang, Yilun Zhao, Yitao Long |  |
| 813 |  |  [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://doi.org/10.18653/v1/2024.acl-long.694) |  | 0 | There is a growing need for Large Language Models (LLMs) to effectively use tools and external Application Programming Interfaces (APIs) to plan and complete tasks. As such, there is tremendous interest in methods that can acquire sufficient quantities of train and test data that involve calls to... | Asim Munawar, Ibrahim Abdelaziz, Kinjal Basu, Luis A. Lastras, Maxwell Crouse, Pavan Kapanipathi, Sadhana Kumaravel, Soham Dan, Subhajit Chaudhury, Vernon Austel, Vinod Muthusamy |  |
| 814 |  |  [LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks](https://doi.org/10.18653/v1/2024.acl-long.695) |  | 0 | LoRA employs lightweight modules to customize large language models (LLMs) for each downstream task or domain, where different learned additional modules represent diverse skills. Combining existing LoRAs to address new tasks can enhance the reusability of learned LoRAs, particularly beneficial for... | Bowen Ping, Hanqing Wang, Maosong Sun, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu |  |
| 815 |  |  [Harder Task Needs More Experts: Dynamic Routing in MoE Models](https://doi.org/10.18653/v1/2024.acl-long.696) |  | 0 | In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike existing MoE approaches that rely on fixed TopK... | Chen Zhang, Kun Xu, Liwei Chen, Mingxu Tao, Nan Zhuang, Quzhe Huang, Songfang Huang, Yang Jin, Yansong Feng, Zhenwei An |  |
| 816 |  |  [XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception](https://doi.org/10.18653/v1/2024.acl-long.697) |  | 0 | Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is only available in limited amounts and for fewer... | Bowen Shi, Changhan Wang, HyoJung Han, Juan Pino, Marine Carpuat, Mohamed Anwar, WeiNing Hsu |  |
| 817 |  |  [SOTOPIA-π: Interactive Learning of Socially Intelligent Language Agents](https://doi.org/10.18653/v1/2024.acl-long.698) |  | 0 | Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-π, that improves the social intelligence of... | Graham Neubig, Hao Zhu, Haofei Yu, Maarten Sap, Ruiyi Wang, Wenxin Zhang, Yonatan Bisk, Zhengyang Qi |  |
| 818 |  |  [\mathcal XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts](https://doi.org/10.18653/v1/2024.acl-long.699) |  | 0 | We introduce XFT, a simple yet powerful training scheme, by simply merging upcycled Mixture-of-Experts (MoE) to unleash the performance limit of instruction-tuned code Large Language Models (LLMs). While vanilla sparse upcycling fails to improve instruction tuning, XFT introduces a shared expert... | Jiawei Liu, Lingming Zhang, Yifeng Ding, Yuxiang Wei |  |
| 819 |  |  [Generalizability of Mixture of Domain-Specific Adapters from the Lens of Signed Weight Directions and its Application to Effective Model Pruning](https://doi.org/10.18653/v1/2024.acl-long.700) |  | 0 | Several parameter-efficient fine-tuning methods based on adapters have been proposed as a streamlined approach to incorporate not only a single specialized knowledge into existing Pre-Trained Language Models (PLMs) but also multiple of them at once. Recent works such as AdapterSoup propose to mix... | Thai Le, Tuc Nguyen |  |
| 820 |  |  [Learning to Decode Collaboratively with Multiple Language Models](https://doi.org/10.18653/v1/2024.acl-long.701) |  | 0 | We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level. We model the decision of which LLM generates the next token as a latent variable. By optimizing the marginal likelihood of a training set under our latent variable... | Bailin Wang, David A. Sontag, Hunter Lang, Yoon Kim, Zejiang Shen |  |
| 821 |  |  [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.702) |  | 0 | Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs).There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to... | Qingyao Ai, Weihang Su, Yichen Tang, Yiqun Liu, Zhijing Wu |  |
| 822 |  |  [Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?](https://doi.org/10.18653/v1/2024.acl-long.703) |  | 0 | Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world. Current temporal reasoning datasets are limited to questions about single or isolated events, falling short in mirroring the realistic temporal characteristics involving concurrent nature and intricate... | Jun Zhang, Juntao Li, Min Zhang, Pan Zhou, Tong Zhu, Xiaoye Qu, Yan Bowen, Yu Cheng, Zhaochen Su |  |
| 823 |  |  [CritiqueLLM: Towards an Informative Critique Generation Model for Evaluation of Large Language Model Generation](https://doi.org/10.18653/v1/2024.acl-long.704) |  | 0 | Since the natural language processing (NLP) community started to make large language models (LLMs) act as a critic to evaluate the quality of generated texts, most of the existing works train a critique generation model on the evaluation data labeled by GPT-4’s direct prompting. We observe that... | Andrew Feng, Aohan Zeng, Bosi Wen, Hongning Wang, Jiale Cheng, Jie Tang, Minlie Huang, Pei Ke, Shengyuan Wang, Xiao Liu, Xuanyu Lei, Yuxiao Dong |  |
| 824 |  |  [LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments](https://doi.org/10.18653/v1/2024.acl-long.705) |  | 0 | Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence. However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent... | Junzhe Chen, Lijie Wen, Shiyu Huang, Shuodi Liu, WeiWei Tu, Xuming Hu, Zhaofeng He |  |
| 825 |  |  [Small But Funny: A Feedback-Driven Approach to Humor Distillation](https://doi.org/10.18653/v1/2024.acl-long.706) |  | 0 | The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing. Consequently, distillation through imitation of teacher responses has emerged as a popular technique to... | Akshat Shrivastava, Arash Einolghozati, Patrick Huber, Sahithya Ravi, Vered Shwartz |  |
| 826 |  |  [Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.707) |  | 0 | Although Large Language Models (LLMs) demonstrate remarkable ability in processing and generating human-like text, they do have limitations when it comes to comprehending and expressing world knowledge that extends beyond the boundaries of natural language(e.g., chemical molecular formula).... | Fangzhi Xu, Fei Yuan, Jun Liu, Qika Lin, Qiushi Sun, Shuai Yuan, Siyu Ren, Yu Qiao, Zhiyong Wu |  |
| 827 |  |  [From Sights to Insights: Towards Summarization of Multimodal Clinical Documents](https://doi.org/10.18653/v1/2024.acl-long.708) |  | 0 | The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective... | Abhisek Tiwari, Akash Ghosh, Jatin Salve, Mohit Tomar, Setu Sinha, Sriparna Saha |  |
| 828 |  |  [When Phrases Meet Probabilities: Enabling Open Relation Extraction with Cooperating Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.709) |  | 0 | Current clustering-based open relation extraction (OpenRE) methods usually apply clustering algorithms on top of pre-trained language models. However, this practice has three drawbacks. First, embeddings from language models are high-dimensional and anisotropic, so using simple metrics to calculate... | Jiaxin Wang, Jun Liu, Lingling Zhang, Liwei Kang, Wee Sun Lee, Yujie Zhong |  |
| 829 |  |  [Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation](https://doi.org/10.18653/v1/2024.acl-long.710) |  | 0 | The latest generative large language models (LLMs) have found their application in data augmentation tasks, where small numbers of text samples are LLM-paraphrased and then used to fine-tune downstream models. However, more research is needed to assess how different prompts, seed data selection... | Branislav Pecher, Ivan Srba, Jakub Simko, Ján Cegin, Mária Bieliková, Peter Brusilovsky |  |
| 830 |  |  [Beyond Orthography: Automatic Recovery of Short Vowels and Dialectal Sounds in Arabic](https://doi.org/10.18653/v1/2024.acl-long.711) |  | 0 | This paper presents a novel Dialectal Sound and Vowelization Recovery framework, designed to recognize borrowed and dialectal sounds within phonologically diverse and dialect-rich languages, that extends beyond its standard orthographic sound sets. The proposed framework utilized quantized sequence... | Ahmed Ali, Hamdy Mubarak, Shammur Absar Chowdhury, Yassine El Kheir |  |
| 831 |  |  [Document-Level Machine Translation with Large-Scale Public Parallel Corpora](https://doi.org/10.18653/v1/2024.acl-long.712) |  | 0 | Despite the fact that document-level machine translation has inherent advantages over sentence-level machine translation due to additional information available to a model from document context, most translation systems continue to operate at a sentence level. This is primarily due to the severe... | Alexandra Birch, Kenneth Heafield, Proyag Pal |  |
| 832 |  |  [Bridging the Empirical-Theoretical Gap in Neural Network Formal Language Learning Using Minimum Description Length](https://doi.org/10.18653/v1/2024.acl-long.713) |  | 0 | Neural networks offer good approximation to many tasks but consistently fail to reach perfect generalization, even when theoretical work shows that such perfect solutions can be expressed by certain architectures. Using the task of formal language learning, we focus on one simple formal language... | Emmanuel Chemla, Nur Geffen Lan, Roni Katzir |  |
| 833 |  |  [Context versus Prior Knowledge in Language Models](https://doi.org/10.18653/v1/2024.acl-long.714) |  | 0 | To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different questions and contexts: models will rely more on prior... | Aaron Schein, Jennifer C. White, Kevin Du, Niklas Stoehr, Ryan Cotterell, Vésteinn Snæbjarnarson |  |
| 834 |  |  [Word Matters: What Influences Domain Adaptation in Summarization?](https://doi.org/10.18653/v1/2024.acl-long.715) |  | 0 | Domain adaptation aims to enable Large Language Models (LLMs) to generalize domain datasets unseen effectively during the training phase. However, factors such as the size of the model parameters and the scale of training data are general influencers and do not reflect the nuances of domain... | Heyan Huang, Siyu Miao, Yang Gao, Yinghao Li |  |
| 835 |  |  [Visualization Recommendation with Prompt-based Reprogramming of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.716) |  | 0 | Visualization recommendations, which aim to automatically match proper visual charts for specific data tables, can significantly simplify the data analysis process. Traditional approaches in this domain have primarily relied on rule-based or machine learning-based methodologies. These methods often... | Derong Xu, Enhong Chen, Jingbo Zhou, Tong Xu, Wei Chen, Xinhang Li |  |
| 836 |  |  [HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs](https://doi.org/10.18653/v1/2024.acl-long.717) |  | 0 | Given unstructured text, Large Language Models (LLMs) are adept at answering simple (single-hop) questions. However, as the complexity of the questions increase, the performance of LLMs degrade. We believe this is due to the overhead associated with understanding the complex question followed by... | A. P. Prathosh, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, Pranoy Panda |  |
| 837 |  |  [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](https://doi.org/10.18653/v1/2024.acl-long.718) |  | 0 | When a teacher provides examples for a student to study, these examples must be informative, enabling a student to progress from their current state toward a target concept or skill. Good teachers must therefore simultaneously infer what students already know and adapt their teaching to students’... | Alexis Ross, Jacob Andreas |  |
| 838 |  |  [Bridging Word-Pair and Token-Level Metaphor Detection with Explainable Domain Mining](https://doi.org/10.18653/v1/2024.acl-long.719) |  | 0 | Metaphor detection aims to identify whether a linguistic expression in text is metaphorical or literal. Most existing research tackles this problem either using word-pair or token-level information as input, and thus treats word-pair and token-level metaphor detection as distinct subtasks.... | Nan Xu, Ruike Zhang, Wenji Mao, Yuan Tian |  |
| 839 |  |  [Faithful Logical Reasoning via Symbolic Chain-of-Thought](https://doi.org/10.18653/v1/2024.acl-long.720) |  | 0 | While the recent Chain-of-Thought (CoT) technique enhances the reasoning ability of large language models (LLMs) with the theory of mind, it might still struggle in handling logical reasoning that relies much on symbolic expressions and rigid deducing rules. To strengthen the logical reasoning... | Hao Fei, Jundong Xu, Liangming Pan, MongLi Lee, Qian Liu, Wynne Hsu |  |
| 840 |  |  [S²GSL: Incorporating Segment to Syntactic Enhanced Graph Structure Learning for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.acl-long.721) |  | 0 | Previous graph-based approaches in Aspect-based Sentiment Analysis(ABSA) have demonstrated impressive performance by utilizing graph neural networks and attention mechanisms to learn structures of static dependency trees and dynamic latent trees. However, incorporating both semantic and syntactic... | Bingfeng Chen, Boyan Xu, Qihan Ouyang, Ruichu Cai, Yongqi Luo, Zhifeng Hao |  |
| 841 |  |  [Maverick: Efficient and Accurate Coreference Resolution Defying Recent Trends](https://doi.org/10.18653/v1/2024.acl-long.722) |  | 0 | Large autoregressive generative models have emerged as the cornerstone for achieving the highest performance across several Natural Language Processing tasks. However, the urge to attain superior results has, at times, led to the premature replacement of carefully designed task-specific approaches... | Edoardo Barba, Giuliano Martinelli, Roberto Navigli |  |
| 842 |  |  [ESCoT: Towards Interpretable Emotional Support Dialogue Systems](https://doi.org/10.18653/v1/2024.acl-long.723) |  | 0 | Understanding the reason for emotional support response is crucial for establishing connections between users and emotional support dialogue systems. Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable... | Jinming Zhao, Li Zhou, Qin Jin, Tenggan Zhang, Xinjie Zhang |  |
| 843 |  |  [PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering](https://doi.org/10.18653/v1/2024.acl-long.724) |  | 0 | Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure... | Fangzhi Xu, Jiawei Han, Jun Liu, Qika Lin, Tianzhe Zhao |  |
| 844 |  |  [WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection](https://doi.org/10.18653/v1/2024.acl-long.725) |  | 0 | Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern... | Anudeex Shetty, Ke He, Qiongkai Xu, Yue Teng |  |
| 845 |  |  [Advancing Parameter Efficiency in Fine-tuning via Representation Editing](https://doi.org/10.18653/v1/2024.acl-long.726) |  | 0 | Parameter Efficient Fine-Tuning (PEFT) has gained significant attention for its ability to achieve competitive results while updating only a small subset of trainable parameters. Despite the promising performance of current PEFT methods, they present challenges in hyperparameter selection, such as... | Cenyuan Zhang, Changze Lv, Jianhao Zhu, Muling Wu, Tianlong Li, Wenhao Liu, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang, Zixuan Ling |  |
| 846 |  |  [Context Consistency between Training and Inference in Simultaneous Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.727) |  | 0 | Simultaneous Machine Translation (SiMT) aims to yield a real-time partial translation with a monotonically growing source-side context.However, there is a counterintuitive phenomenon about the context usage between training and inference: \*e.g.\*, in wait-k inference, model consistently trained... | Kehai Chen, Lemao Liu, Meizhi Zhong, Min Zhang, Mingming Yang |  |
| 847 |  |  [Using Natural Language Explanations to Improve Robustness of In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.728) |  | 0 | Recent studies demonstrated that large language models (LLMs) can excel in many tasks via in-context learning (ICL). However, recentworks show that ICL-prompted models tend to produce inaccurate results when presented with adversarial inputs. In this work, we investigate whether augmenting ICL with... | OanaMaria Camburu, Pasquale Minervini, Pontus Stenetorp, Xuanli He, Yuxiang Wu |  |
| 848 |  |  [Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers](https://doi.org/10.18653/v1/2024.acl-long.729) |  | 0 | Although dominant in natural language processing, transformer-based models still struggle with long-sequence processing, due to the computational costs of their self-attention operations, which increase exponentially as the length of the input sequence grows. To address this challenge, we propose a... | Jiawen Xie, Nan Du, Pengyu Cheng, Xiao Liang, Yong Dai |  |
| 849 |  |  [ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.730) |  | 0 | This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g.,... | Hojae Han, Jaejin Kim, Jaeseok Yoo, Seungwon Hwang, Youngwon Lee |  |
| 850 |  |  [Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels](https://doi.org/10.18653/v1/2024.acl-long.731) |  | 0 | Traditional supervised learning heavily relies on human-annotated datasets, especially in data-hungry neural approaches. However, various tasks, especially multi-label tasks like document-level relation extraction, pose challenges in fully manual annotation due to the specific domain knowledge and... | Anji Liu, Junpeng Li, Shichuan Zhang, Zilong Zheng, Zixia Jia |  |
| 851 |  |  [MULFE: A Multi-Level Benchmark for Free Text Model Editing](https://doi.org/10.18653/v1/2024.acl-long.732) |  | 0 | Adjusting the outdated behaviors of large langugae models (LLMs) after deployment remains a significant challenge. It motivates the model editing research, which is however mainly explored in a restricted task form with triple-based edit requests. Recent works have initiated a transition to a more... | Chenhao Wang, Daojian Zeng, Jun Zhao, Kang Liu, Pengfei Cao, Yubo Chen, Zhuoran Jin |  |
| 852 |  |  [MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech](https://doi.org/10.18653/v1/2024.acl-long.733) |  | 0 | Zero-shot text-to-speech (TTS) has gained significant attention due to its powerful voice cloning capabilities, requiring only a few seconds of unseen speaker voice prompts. However, all previous work has been developed for cloud-based systems. Taking autoregressive models as an example, although... | Hanting Wang, Jialong Zuo, Shengpeng Ji, Zhou Zhao, Ziyue Jiang |  |
| 853 |  |  [Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation](https://doi.org/10.18653/v1/2024.acl-long.734) |  | 0 | Embodied AI aims to develop robots that can understand and execute human language instructions, as well as communicate in natural languages. On this front, we study the task of generating highly detailed navigational instructions for the embodied robots to follow. Although recent studies have... | David Suter, Jumana AbuKhalaf, Martin Masek, Muraleekrishna Gopinathan |  |
| 854 |  |  [HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position](https://doi.org/10.18653/v1/2024.acl-long.735) |  | 0 | Addressing the limitation of context length in large language models for code-related tasks is the primary focus of this paper. Existing LLMs are constrained by their pre-trained context lengths, leading to performance issues in handling long complex code sequences. Inspired by how human... | Ge Li, Huangzhao Zhang, Kechi Zhang, Zhi Jin |  |
| 855 |  |  [Never Lost in the Middle: Mastering Long-Context Question Answering with Position-Agnostic Decompositional Training](https://doi.org/10.18653/v1/2024.acl-long.736) |  | 0 | While large language models (LLMs) are equipped with longer text input capabilities than before, they are struggling to seek correct information in long contexts. The “lost in the middle” problem challenges most LLMs, referring to the dramatic decline in accuracy when correct information is located... | Enming Zhang, Hao Wang, Jiaxing Zhang, Junqing He, Kunhao Pan, LiuYiBo LiuYiBo, Qianguosun Qianguosun, Xiaoqun Dong, Yuxin Liang, Zhuoyang Song |  |
| 856 |  |  [CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges](https://doi.org/10.18653/v1/2024.acl-long.737) |  | 0 | Large Language Models (LLMs) have shown promise in automated code generation but typically excel only in simpler tasks such as generating standalone code units. However, real-world software development often involves complex code repositories with complex dependencies and extensive documentation.... | Ge Li, Jia Li, Kechi Zhang, Xianjie Shi, Zhi Jin |  |
| 857 |  |  [When is Tree Search Useful for LLM Planning? It Depends on the Discriminator](https://doi.org/10.18653/v1/2024.acl-long.738) |  | 0 | In this paper, we examine how large language models (LLMs) solve multi-step problems under a language agent framework with three components: a generator, a discriminator, and a planning method. We investigate the practical utility of two advanced planning methods, iterative correction and tree... | Ali Payani, Huan Sun, Michael White, Raymond J. Mooney, Yu Su, Ziru Chen |  |
| 858 |  |  [LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.739) |  | 0 | Recently developed large language models (LLMs) have been shown to perform remarkably well on a wide range of language understanding tasks. But, can they really “reason” over the natural language? This question has been receiving significant research attention and many reasoning skills such as... | Arindam Mitra, Chitta Baral, Man Luo, Mihir Parmar, Mutsumi Nakamura, Neeraj Varshney, Nisarg Patel, Santosh Mashetty |  |
| 859 |  |  [Meta-Tuning LLMs to Leverage Lexical Knowledge for Generalizable Language Style Understanding](https://doi.org/10.18653/v1/2024.acl-long.740) |  | 0 | Language style is often used by writers to convey their intentions, identities, and mastery of language. In this paper, we show that current large language models struggle to capture some language styles without fine-tuning. To address this challenge, we investigate whether LLMs can be meta-trained... | Alan Ritter, Ruohao Guo, Wei Xu |  |
| 860 |  |  [Reducing Privacy Risks in Online Self-Disclosures with Language Models](https://doi.org/10.18653/v1/2024.acl-long.741) |  | 0 | Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure... | Alan Ritter, Anubha Kabra, Isadora Krsek, Sauvik Das, Tarek Naous, Wei Xu, Yao Dou |  |
| 861 |  |  [Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.742) |  | 0 | Memory Editing (ME) has emerged as an efficient method to modify erroneous facts or inject new facts into Large Language Models (LLMs). Two mainstream ME methods exist: parameter-modifying ME and parameter-preserving ME (integrating extra modules while preserving original parameters). Regrettably,... | Hongxuan Li, Lifu Huang, Mohammad Beigi, Qifan Wang, Wenpeng Yin, Yufan Zhou, Yuxiang Zhang, Zihao Lin |  |
| 862 |  |  [REFINESUMM: Self-Refining MLLM for Generating a Multimodal Summarization Dataset](https://doi.org/10.18653/v1/2024.acl-long.743) |  | 0 | Multimodal Large Language Models (MLLMs) excel at synthesizing key information from diverse sources. However, generating accurate and faithful multimodal summaries is challenging, primarily due to the lack of appropriate multimodal datasets for fine-tuning that meaningfully integrate textual and... | Leonardo F. R. Ribeiro, Markus Dreyer, Mengwen Liu, Mohit Bansal, Vaidehi Patil |  |
| 863 |  |  [When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards](https://doi.org/10.18653/v1/2024.acl-long.744) |  | 0 | Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value — we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance... | Areeb Alowisheq, Faisal Mirza, Haidar Khan, Hisham Abdullah Alyahya, M. Saiful Bari, Nora AlTwairesh, Norah Alzahrani, Nouf Alotaibi, Shaykhah Alsubaie, Sultan Alrashed, Yazeed Alnumay, Yousef Almushayqih |  |
| 864 |  |  [LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts](https://doi.org/10.18653/v1/2024.acl-long.745) |  | 0 | This paper introduces a framework for the automated evaluation of natural language texts. A manually constructed rubric describes how to assess multiple dimensions of interest. To evaluate a text, a large language model (LLM) is prompted with each rubric question and produces a distribution over... | Benjamin Van Durme, Chris Kedzie, Corby Rosset, Helia Hashemi, Jason Eisner |  |
| 865 |  |  [LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition](https://doi.org/10.18653/v1/2024.acl-long.746) |  | 0 | Discourse Entity (DE) recognition is the task of identifying novel and known entities introduced within a text. While previous work has found that large language models have basic, if imperfect, DE recognition abilities (Schuster and Linzen, 2022), it remains largely unassessed which of the... | Robert Frank, Xiaomeng Zhu |  |
| 866 |  |  [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.747) |  | 0 | Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term... | Adyasha Maharana, DongHo Lee, Francesco Barbieri, Mohit Bansal, Sergey Tulyakov, Yuwei Fang |  |
| 867 |  |  [Prototypical Reward Network for Data-Efficient RLHF](https://doi.org/10.18653/v1/2024.acl-long.748) |  | 0 | The reward model for Reinforcement Learning from Human Feedback (RLHF) has proven effective in fine-tuning Large Language Models (LLMs). Notably, collecting human feedback for RLHF can be resource-intensive and lead to scalability issues for LLMs and complex tasks. Our proposed framework Proto-RM... | Changyu Chen, Jinghan Zhang, Kunpeng Liu, Xinhao Zhang, Xiting Wang, Yiqiao Jin |  |
| 868 |  |  [NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms](https://doi.org/10.18653/v1/2024.acl-long.749) |  | 0 | The performance of Large Language Models (LLMs) degrades from the temporal drift between data used for model training and newer text seen during inference. One understudied avenue of language change causing data drift is the emergence of neologisms – new word forms – over time. We create a diverse... | Alan Ritter, Jonathan Zheng, Wei Xu |  |
| 869 |  |  [Impacts of Misspelled Queries on Translation and Product Search](https://doi.org/10.18653/v1/2024.acl-long.750) |  | 0 | Machine translation is used in e-commerce to translate second-language queries into the primary language of the store, to be matched by the search system against the product catalog. However, many queries contain spelling mistakes. We first present an analysis of the spelling-robustness of a... | Greg Hanneman, Natawut Monaikul, Taichi Nakatani |  |
| 870 |  |  [Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs](https://doi.org/10.18653/v1/2024.acl-long.751) |  | 0 | Large Language Models (LLMs) have shown remarkable capabilities in tasks such as summarization, arithmetic reasoning, and question answering. However, they encounter significant challenges in the domain of moral reasoning and ethical decision-making, especially in complex scenarios with multiple... | Bilgehan Sel, Kun Zhou, Ming Jin, Mohammad Kachuee, Priya Shanmugasundaram, Ruoxi Jia |  |
| 871 |  |  [The MERSA Dataset and a Transformer-Based Approach for Speech Emotion Recognition](https://doi.org/10.18653/v1/2024.acl-long.752) |  | 0 | Research in the field of speech emotion recognition (SER) relies on the availability of comprehensive datasets to make it possible to design accurate emotion detection models. This study introduces the Multimodal Emotion Recognition and Sentiment Analysis (MERSA) dataset, which includes both... | Christian Poellabauer, Enshi Zhang, Rafael Trujillo |  |
| 872 |  |  [Transparent and Scrutable Recommendations Using Natural Language User Profiles](https://doi.org/10.18653/v1/2024.acl-long.753) |  | 0 | Recent state-of-the-art recommender systems predominantly rely on either implicit or explicit feedback from users to suggest new items. While effective in recommending novel options, many recommender systems often use uninterpretable embeddings to represent user preferences. This lack of... | Aldo Lipani, Hossein A. Rahmani, Jerome Ramos, Xi Wang, Xiao Fu |  |
| 873 |  |  [Fora: A corpus and framework for the study of facilitated dialogue](https://doi.org/10.18653/v1/2024.acl-long.754) |  | 0 | Facilitated dialogue is increasingly popular as a method of civic engagement and as a method for gathering social insight, but resources for its study are scant. We present Fora, a unique collection of annotated facilitated dialogues. We compile 262 facilitated conversations that were hosted with... | Deb Roy, Hope Schroeder, Jad Kabbara |  |
| 874 |  |  [Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning](https://doi.org/10.18653/v1/2024.acl-long.755) |  | 0 | Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks with a few demonstration examples via in-context learning. Common strategies to boost such “in-context” learning ability are to ensemble multiple model decoded results and require the... | Chao Zhang, Jialu Liu, Jiaming Shen, Jing Nathan Yan, Michael Bendersky, Tianqi Liu, Yue Yu, Zhen Qin |  |
| 875 |  |  [What is the Best Way for ChatGPT to Translate Poetry?](https://doi.org/10.18653/v1/2024.acl-long.756) |  | 0 | Machine translation (MT) has historically faced significant challenges when applied to literary works, particularly in the domain of poetry translation. The advent of Large Language Models such as ChatGPT holds potential for innovation in this field. This study examines ChatGPT’s capabilities in... | Derek F. Wong, Jingming Yao, Lidia S. Chao, Shanshan Wang |  |
| 876 |  |  [Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.757) |  | 0 | Large language models are trained on massive scrapes of the web, which are often unstructured, noisy, and poorly phrased. Current scaling laws show that learning from such data requires an abundance of both compute and data, which grows with the size of the model being trained. This is infeasible... | David Grangier, Navdeep Jaitly, Pratyush Maini, Richard He Bai, Skyler Seto, Yizhe Zhang |  |
| 877 |  |  [DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention](https://doi.org/10.18653/v1/2024.acl-long.758) |  | 0 | Large language models (LLMs) often require task-relevant knowledge to augment their internal knowledge through prompts. However, simply injecting external knowledge into prompts does not guarantee that LLMs can identify and use relevant information in the prompts to conduct chain-of-thought... | Anup B. Rao, Haoliang Wang, Julian J. McAuley, Junda Wu, Ryan A. Rossi, Sungchul Kim, Tong Yu, Xiang Chen |  |
| 878 |  |  [Representation Learning with Conditional Information Flow Maximization](https://doi.org/10.18653/v1/2024.acl-long.759) |  | 0 | This paper proposes an information-theoretic representation learning framework, named conditional information flow maximization, to extract noise-invariant sufficient representations for the input data and target task. It promotes the learned representations have good feature uniformity and... | Dou Hu, Lingwei Wei, Songlin Hu, Wei Zhou |  |
| 879 |  |  [GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction](https://doi.org/10.18653/v1/2024.acl-long.760) |  | 0 | Social biases in LLMs are usually measured via bias benchmark datasets. Current benchmarks have limitations in scope, grounding, quality, and human effort required. Previous work has shown success with a community-sourced, rather than crowd-sourced, approach to benchmark development. However, this... | Jennifer A. Thompson, Jonathan May, Virginia K. Felkner |  |
| 880 |  |  [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](https://doi.org/10.18653/v1/2024.acl-long.761) |  | 0 | While large language models have achieved remarkable performance on various code generation benchmarks, there have been growing concerns regarding potential contamination of these benchmarks as they may be leaked into pretraining and finetuning data. While recent work has investigated contamination... | Ansong Ni, Arman Cohan, Martin Riddell |  |
| 881 |  |  [Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic](https://doi.org/10.18653/v1/2024.acl-long.762) |  | 0 | We propose RESTA to perform LLM realignment towards safety, which gets compromised due to downstream task fine-tuning. RESTA stands for REstoring Safety through Task Arithmetic. At its core, it involves a simple arithmetic addition of a safety vector to the weights of the compromised model. We... | Do Duc Anh, Rishabh Bhardwaj, Soujanya Poria |  |
| 882 |  |  [Tracking the Newsworthiness of Public Documents](https://doi.org/10.18653/v1/2024.acl-long.763) |  | 0 | Journalists regularly make decisions on whether or not to report stories, based on “news values”. In this work, we wish to explicitly model these decisions to explore _when_ and _why_ certain stories get press attention. This is challenging because very few labelled links between source documents... | Alexander Spangher, Ben Welsh, Emilio Ferrara, Jonathan May, Nanyun Peng, Serdar Tumgoren |  |
| 883 |  |  [EWEK-QA : Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems](https://doi.org/10.18653/v1/2024.acl-long.764) |  | 0 | The emerging citation-based QA systems are gaining more attention especially in generative AI search applications. The importance of extracted knowledge provided to these systems is vital from both accuracy (completeness of information) and efficiency (extracting the information in a timely... | Abbas Ghaddar, Boxing Chen, David AlfonsoHermelo, Jianye Hao, Jimmy Lin, Khalil Bibi, Mahdi Biparva, Mehdi Rezagholizadeh, Mohammad Ali Alomrani, Mohammad Dehghan, Prasanna Parthasarathi, Qun Liu, Sunyam Bagga, Xiaoguang Li, Yingxue Zhang |  |
| 884 |  |  [Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models](https://doi.org/10.18653/v1/2024.acl-long.765) |  | 0 | Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer from degradation, as VQA datasets lack the diversity and... | Rongyu Lin, Shengzhi Li, Shichao Pei |  |
| 885 |  |  [Multistage Collaborative Knowledge Distillation from a Large Language Model for Semi-Supervised Sequence Generation](https://doi.org/10.18653/v1/2024.acl-long.766) |  | 0 | We study semi-supervised sequence generation tasks, where the few labeled examples are too scarce to finetune a model, and meanwhile, few-shot prompted large language models (LLMs) exhibit room for improvement. In this paper, we present the discovery that a student model distilled from a few-shot... | Andrew Drozdov, Andrew McCallum, Benjamin Rozonoyer, JayYoon Lee, Jiachen Zhao, Md. Arafat Sultan, Mohit Iyyer, Wenlong Zhao |  |
| 886 |  |  [Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor](https://doi.org/10.18653/v1/2024.acl-long.767) |  | 0 | Controlled text generation, aiming to ensure that language models produce text containing only the desired domain or corpus attributes, is immensely crucial in the practical application of language models. Existing methods, however, are inapplicable to black-box models or suffer a significant... | Changmin Lee, Hojin Lee, Sangwon Yu, Sungroh Yoon |  |
| 887 |  |  [LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP](https://doi.org/10.18653/v1/2024.acl-long.768) |  | 0 | Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor-intensive process that requires... | Aditi Agarwal, Danlu Chen, Freda Shi, Jacobo Myerston, Taylor BergKirkpatrick |  |
| 888 |  |  [Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning](https://doi.org/10.18653/v1/2024.acl-long.769) |  | 0 | Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the... | Hongyu Zhao, Jianzong Wang, Ming Li, Ning Cheng, Shwai He, Tianyi Zhou, Yong Zhang, Zhitao Li |  |
| 889 |  |  [Confabulation: The Surprising Value of Large Language Model Hallucinations](https://doi.org/10.18653/v1/2024.acl-long.770) |  | 0 | This paper presents a systematic defense of large language model (LLM) hallucinations or ‘confabulations’ as a potential resource instead of a categorically negative pitfall. The standard view is that confabulations are inherently problematic and AI research should eliminate this flaw. In this... | Eamon Duede, Peiqi Sui, Richard Jean So, Sophie Wu |  |
| 890 |  |  [IAPT: Instance-Aware Prompt Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.771) |  | 0 | Soft prompt tuning is a widely studied parameter-efficient fine-tuning method. However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance. As a result, soft prompt tuning is less considered than Low-rank adaptation (LoRA) in the... | Aaron Xuxiang Tian, Congrui Yin, Guotong Xie, Wei Zhu, Xiaoling Wang, Yuan Ni |  |
| 891 |  |  [DeVAn: Dense Video Annotation for Video-Language Models](https://doi.org/10.18653/v1/2024.acl-long.772) |  | 0 | We present a novel human annotated dataset for evaluating the ability for visual-language models to generate both short and long descriptions for real-world video clips, termed DeVAn (Dense Video Annotation). The dataset contains 8.5K YouTube video clips of 20-60 seconds in duration and covers a... | Ding Zhou, Haogeng Liu, Hongxia Yang, Huaibo Huang, Qihang Fan, Ran He, Tingkai Liu, Yunzhe Tao |  |
| 892 |  |  [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://doi.org/10.18653/v1/2024.acl-long.773) |  | 0 | Most traditional AI safety research views models as machines and centers on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. Observing this, we shift... | Diyi Yang, Hongpeng Lin, Jingwen Zhang, Ruoxi Jia, Weiyan Shi, Yi Zeng |  |
| 893 |  |  [The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models](https://doi.org/10.18653/v1/2024.acl-long.774) |  | 0 | Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that... | Adithya Bhaskar, Dan Friedman, Danqi Chen |  |
| 894 |  |  [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.acl-long.775) |  | 0 | Large vision-language models (LVLMs) excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains.To fill... | Lei Li, Lingpeng Kong, Peiyi Wang, Qi Liu, Runxin Xu, Xiachong Feng, Yuqi Wang |  |
| 895 |  |  [L-Eval: Instituting Standardized Evaluation for Long Context Language Models](https://doi.org/10.18653/v1/2024.acl-long.776) |  | 0 | Recently, there has been growing interest in long-context scaling of large language models (LLMs). To facilitate research in this field, we propose L-Eval to institute a more standardized evaluation for Long-Context Language Models (LCLMs) addressing two key aspects: dataset construction and... | Chenxin An, Jun Zhang, Lingpeng Kong, Ming Zhong, Mukai Li, Shansan Gong, Xingjian Zhao, Xipeng Qiu |  |
| 896 |  |  [DIALECTBENCH: An NLP Benchmark for Dialects, Varieties, and Closely-Related Languages](https://doi.org/10.18653/v1/2024.acl-long.777) |  | 0 | Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks... | Aarohi Srivastava, Antonios Anastasopoulos, David Chiang, Fahim Faisal, Kabir Ahuja, Orevaoghene Ahia, Yulia Tsvetkov |  |
| 897 |  |  [Causal-Guided Active Learning for Debiasing Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.778) |  | 0 | Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs. However, due to the diversity of dataset biases and the... | Bing Qin, Kaitao Qiu, Li Du, Ting Liu, Xiao Ding, Yang Zhao, Yixuan Ma, Zhouhao Sun |  |
| 898 |  |  [PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.779) |  | 0 | Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to... | Gao Huang, Honghui Chen, Qisen Yang, Shenzhi Wang, Shiji Song, Wenhao Huang, Xin Gao, Yifan Pu, Zekun Wang |  |
| 899 |  |  [Towards Better Understanding of Contrastive Sentence Representation Learning: A Unified Paradigm for Gradient](https://doi.org/10.18653/v1/2024.acl-long.780) |  | 0 | Sentence Representation Learning (SRL) is a crucial task in Natural Language Processing (NLP), where contrastive Self-Supervised Learning (SSL) is currently a mainstream approach. However, the reasons behind its remarkable effectiveness remain unclear. Specifically, many studies have investigated... | Mingxin Li, Richong Zhang, Zhijie Nie |  |
| 900 |  |  [Emergent Word Order Universals from Cognitively-Motivated Language Models](https://doi.org/10.18653/v1/2024.acl-long.781) |  | 0 | The world’s languages exhibit certain so-called typological or implicational universals; for example, Subject-Object-Verb (SOV) languages typically use postpositions. Explaining the source of such biases is a key goal of linguistics.We study word-order universals through a computational simulation... | Ryo Ueda, Ryo Yoshida, Tatsuki Kuribayashi, Ted Briscoe, Timothy Baldwin, Yohei Oseki |  |
| 901 |  |  [Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View](https://doi.org/10.18653/v1/2024.acl-long.782) |  | 0 | As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: \*Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?\* This paper probes... | Bryan Hooi, Jintian Zhang, Ningyu Zhang, Ruibo Liu, Shumin Deng, Xin Xu |  |
| 902 |  |  [MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin](https://doi.org/10.18653/v1/2024.acl-long.783) |  | 0 | This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL), which learns an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap... | Chenyan Xiong, Ge Yu, Sen Mei, Tianshuo Zhou, Xinze Li, Yu Gu, Zhenghao Liu, Zhiyuan Liu |  |
| 903 |  |  [Distributional Inclusion Hypothesis and Quantifications: Probing for Hypernymy in Functional Distributional Semantics](https://doi.org/10.18653/v1/2024.acl-long.784) |  | 0 | Functional Distributional Semantics (FDS) models the meaning of words by truth-conditional functions. This provides a natural representation for hypernymy but no guarantee that it can be learnt when FDS models are trained on a corpus. In this paper, we probe into FDS models and study the... | Chun Hei Lo, Guy Emerson, Hong Cheng, Wai Lam |  |
| 904 |  |  [CausalGym: Benchmarking causal interpretability methods on linguistic tasks](https://doi.org/10.18653/v1/2024.acl-long.785) |  | 0 | Language models (LMs) have proven to be powerful tools for psycholinguistic research, but most prior work has focused on purely behavioural measures (e.g., surprisal comparisons). At the same time, research in model interpretability has begun to illuminate the abstract causal mechanisms shaping LM... | Aryaman Arora, Christopher Potts, Dan Jurafsky |  |
| 905 |  |  [Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration](https://doi.org/10.18653/v1/2024.acl-long.786) |  | 0 | Despite efforts to expand the knowledge of large language models (LLMs), knowledge gaps—missing or outdated information in LLMs—might always persist given the evolving nature of knowledge. In this work, we study approaches to identify LLM knowledge gaps and abstain from answering questions when... | Shangbin Feng, Vidhisha Balachandran, Weijia Shi, Wenxuan Ding, Yike Wang, Yulia Tsvetkov |  |
| 906 |  |  [Mission: Impossible Language Models](https://doi.org/10.18653/v1/2024.acl-long.787) |  | 0 | Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic... | Christopher Potts, Isabel Papadimitriou, Julie Kallini, Kyle Mahowald, Richard Futrell |  |
| 907 |  |  [Semisupervised Neural Proto-Language Reconstruction](https://doi.org/10.18653/v1/2024.acl-long.788) |  | 0 | Existing work implementing comparative reconstruction of ancestral languages (proto-languages) has usually required full supervision. However, historical reconstruction models are only of practical value if they can be trained with a limited amount of labeled data. We propose a semisupervised... | David R. Mortensen, Liang Lu, Peirong Xie |  |
| 908 |  |  [Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?](https://doi.org/10.18653/v1/2024.acl-long.789) |  | 0 | The field of natural language processing (NLP) has recently witnessed a transformative shift with the emergence of foundation models, particularly Large Language Models (LLMs) that have revolutionized text-based NLP. This paradigm has extended to other modalities, including speech, where... | Luisa Bentivogli, Marco Gaido, Matteo Negri, Sara Papi |  |
| 909 |  |  [Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?](https://doi.org/10.18653/v1/2024.acl-long.790) |  | 0 | Reference summaries for abstractive speech summarization require human annotation, which can be performed by listening to an audio recording or by reading textual transcripts of the recording. In this paper, we examine whether summaries based on annotators listening to the recordings differ from... | Bhiksha Raj, Hira Dhamyal, Mark Lindsey, Roshan Sharma, Suwon Shon |  |
| 910 |  |  [D2LLM: Decomposed and Distilled Large Language Models for Semantic Search](https://doi.org/10.18653/v1/2024.acl-long.791) |  | 0 | The key challenge in semantic search is to create models that are both accurate and efficient in pinpointing relevant sentences for queries. While BERT-style bi-encoders excel in efficiency with pre-computed embeddings, they often miss subtle nuances in search tasks. Conversely, GPT-style LLMs with... | Hang Yu, Jianguo Li, Jun Wang, Wei Zhang, Zihan Liao |  |
| 911 |  |  [Arabic Diacritics in the Wild: Exploiting Opportunities for Improved Diacritization](https://doi.org/10.18653/v1/2024.acl-long.792) |  | 0 | The widespread absence of diacritical marks in Arabic text poses a significant challenge for Arabic natural language processing (NLP). This paper explores instances of naturally occurring diacritics, referred to as “diacritics in the wild,” to unveil patterns and latent information across six... | Go Inoue, Mhd Tameem Kabbani, Nizar Habash, Ossama Obeid, Salman Elgamal |  |
| 912 |  |  [Disinformation Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.793) |  | 0 | Automated disinformation generation is often listed as one of the risks of large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for democratic societies around the world. This paper presents a comprehensive... | Dominik Macko, Ivan Srba, Ivan Vykopal, Matús Pikuliak, Mária Bieliková, Róbert Móro |  |
| 913 |  |  [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://doi.org/10.18653/v1/2024.acl-long.794) |  | 0 | Incremental Learning (IL) has been a long-standing problem in both vision and Natural Language Processing (NLP) communities.In recent years, as Pre-trained Language Models (PLMs) have achieved remarkable progress in various NLP downstream tasks, utilizing PLMs as backbones has become a common... | Junhao Zheng, Qianli Ma, Shengjie Qiu |  |
| 914 |  |  [How to Handle Different Types of Out-of-Distribution Scenarios in Computational Argumentation? A Comprehensive and Fine-Grained Field Study](https://doi.org/10.18653/v1/2024.acl-long.795) |  | 0 | The advent of pre-trained Language Models (LMs) has markedly advanced natural language processing, but their efficacy in out-of-distribution (OOD) scenarios remains a significant challenge. Computational argumentation (CA), modeling human argumentation processes, is a field notably impacted by... | Andreas Waldis, Iryna Gurevych, Yufang Hou |  |
| 915 |  |  [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](https://doi.org/10.18653/v1/2024.acl-long.796) |  | 0 | Large language models (LLMs) show remarkable human-like capability in various domains and languages. To bridge this quality gap, we introduce Cendol, a collection of Indonesian LLMs encompassing both decoder-only and encoder-decoder architectures across a range of model sizes. We highlight Cendol’s... | Alham Fikri Aji, Ayu Purwarianti, Bryan Wilie, Dea Annisayanti Putri, Emmanuel Dave, Fajri Koto, Genta Indra Winata, Holy Lovenia, Jhonson Lee, Muhammad Ihza Mahendra, Nuur Shadieq, Pascale Fung, Rifki Afina Putri, Salsabil Maulana Akbar, Samuel Cahyawijaya, Tjeng Wawan Cenggoro |  |
| 916 |  |  [Must NLP be Extractive?](https://doi.org/10.18653/v1/2024.acl-long.797) |  | 0 | How do we roll out language technologies across a world with 7,000 languages? In one story, we scale the successes of NLP further into ‘low-resource’ languages, doing ever more with less. However, this approach does not recognise the fact that, beyond the 500 institutional languages, the remaining... | Steven Bird |  |
| 917 |  |  [Spiral of Silence: How is Large Language Model Killing Information Retrieval? - A Case Study on Open Domain Question Answering](https://doi.org/10.18653/v1/2024.acl-long.798) |  | 0 | The practice of Retrieval-Augmented Generation (RAG), which integrates Large Language Models (LLMs) with retrieval systems, has become increasingly prevalent. However, the repercussions of LLM-derived content infiltrating the web and influencing the retrieval-generation feedback loop are largely... | Ben He, Boxi Cao, Hongyu Lin, Le Sun, Tianshu Wang, Xianpei Han, Xiaoyang Chen, Yingfei Sun |  |
| 918 |  |  [Latxa: An Open Language Model and Evaluation Suite for Basque](https://doi.org/10.18653/v1/2024.acl-long.799) |  | 0 | We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we... | Aitor Ormazabal, Aitor Soroa, Eneko Agirre, German Rigau, Itziar Aldabe, Julen Etxaniz, Mikel Artetxe, Naiara Miguel, Oscar Sainz |  |
| 919 |  |  [Why are Sensitive Functions Hard for Transformers?](https://doi.org/10.18653/v1/2024.acl-long.800) |  | 0 | Empirical studies have identified a range of learnability biases and limitations of transformers, such as a persistent difficulty in learning to compute simple formal languages such as PARITY, and a bias towards low-degree functions. However, theoretical understanding remains limited, with existing... | Mark Rofin, Michael Hahn |  |
| 920 |  |  [Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction](https://doi.org/10.18653/v1/2024.acl-long.801) |  | 0 | Large Language Model (LLM)-enhanced agents become increasingly prevalent in Human-AI communication, offering vast potential from entertainment to professional domains. However, current multi-modal dialogue systems overlook the acoustic information present in speech, which is crucial for... | Bing Liu, Deqiang Jiang, Haoqiu Yan, Haoyu Cao, Kai Zheng, Linli Xu, Yongxin Zhu |  |
| 921 |  |  [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://doi.org/10.18653/v1/2024.acl-long.802) |  | 0 | Code generation has fast become one of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs, such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation,... | Goran Glavas, Indraneil Paul, Iryna Gurevych |  |
| 922 |  |  [The Echoes of Multilinguality: Tracing Cultural Value Shifts during Language Model Fine-tuning](https://doi.org/10.18653/v1/2024.acl-long.803) |  | 0 | Texts written in different languages reflect different culturally-dependent beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are jointly trained on a concatenation of text in multiple languages, to encode different cultural values for each language. Yet, as the... | Anne Lauscher, Ekaterina Shutova, Rochelle Choenni |  |
| 923 |  |  [MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual Language Modeling](https://doi.org/10.18653/v1/2024.acl-long.804) |  | 0 | A major consideration in multilingual language modeling is how to best represent languages with diverse vocabularies and scripts.Although contemporary text encoding methods cover most of the world’s writing systems, they exhibit bias towards the high-resource languages of the Global West. As a... | Hila Gonen, Luke Zettlemoyer, Orevaoghene Ahia, Terra Blevins, Tomasz Limisiewicz |  |
| 924 |  |  [MultiLegalPile: A 689GB Multilingual Legal Corpus](https://doi.org/10.18653/v1/2024.acl-long.805) |  | 0 | Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, few datasets are available for specialized critical domains such as law and the available ones are often small and only in English. To fill this gap, we curate and release MultiLegalPile, a 689GB... | Daniel E. Ho, Ilias Chalkidis, Joel Niklaus, Matthias Stürmer, Veton Matoshi |  |
| 925 |  |  [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](https://doi.org/10.18653/v1/2024.acl-long.806) |  | 0 | Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we... | Chang Wang, Dezhang Yuan, Haolin Deng, Jin Ma, Jun Gao, Junlang Zhan, Ruifeng Xu, Tianhua Zhou, Xin Li |  |
| 926 |  |  [What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages](https://doi.org/10.18653/v1/2024.acl-long.807) |  | 0 | What can large language models learn? By definition, language models (LM) are distributionsover strings. Therefore, an intuitive way of addressing the above question is to formalize it as a matter of learnability of classes of distributions over strings. While prior work in this direction focused... | Anej Svete, Eleanor Chodroff, Franz Nowak, Isabelle Augenstein, Josef Valvoda, Nadav Borenstein, Robin Chan, Ryan Cotterell |  |
| 927 |  |  [Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous Constituency Parsing](https://doi.org/10.18653/v1/2024.acl-long.808) |  | 0 | We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model in the literature. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and... | Behzad Shayegh, Lili Mou, Yuqiao Wen |  |
| 928 |  |  [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs](https://doi.org/10.18653/v1/2024.acl-long.809) |  | 0 | Safety is critical to the usage of large language models (LLMs). Multiple techniques such as data filtering and supervised fine-tuning have been developed to strengthen LLM safety. However, currently known techniques presume that corpora used for safety alignment of LLMs are solely interpreted by... | Bhaskar Ramasubramanian, Bo Li, Fengqing Jiang, Luyao Niu, Radha Poovendran, Zhangchen Xu, Zhen Xiang |  |
| 929 |  |  [ChatDev: Communicative Agents for Software Development](https://doi.org/10.18653/v1/2024.acl-long.810) |  | 0 | Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique... | Chen Qian, Cheng Yang, Dahai Li, Hongzhang Liu, Jiahao Li, Juyuan Xu, Maosong Sun, Nuo Chen, Wei Liu, Weize Chen, Xin Cong, Yufan Dang, Yusheng Su, Zhiyuan Liu |  |
| 930 |  |  [Disentangled Learning with Synthetic Parallel Data for Text Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.811) |  | 0 | Text style transfer (TST) is an important task in natural language generation, which aims to transfer the text style (e.g., sentiment) while keeping its semantic information. Due to the absence of parallel datasets for supervision, most existing studies have been conducted in an unsupervised... | Benfeng Xu, Jingxuan Han, Licheng Zhang, Quan Wang, Zhendong Mao, Zikang Guo |  |
| 931 |  |  [PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](https://doi.org/10.18653/v1/2024.acl-long.812) |  | 0 | Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with... | Feng Zhao, Hongzhi Gao, Huchuan Lu, Jing Shao, Lijun Li, Lijun Wang, Yongting Zhang, Yu Qiao, Zaibin Zhang |  |
| 932 |  |  [Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation](https://doi.org/10.18653/v1/2024.acl-long.813) |  | 0 | Emotional Support Conversation (ESC) is a task aimed at alleviating individuals’ emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently,... | Dongha Lee, Dongjin Kang, Hyunsouk Cho, Jinyoung Yeo, Seungjun Moon, Sunghwan Kim, Taeyoon Kwon, Youngjae Yu |  |
| 933 |  |  [ınftyBench: Extending Long Context Evaluation Beyond 100K Tokens](https://doi.org/10.18653/v1/2024.acl-long.814) |  | 0 | Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a... | Junhao Chen, Maosong Sun, Moo Khai Hao, Shengding Hu, Shuo Wang, Xinrong Zhang, Xu Han, Yingfa Chen, Zhen Leng Thai, Zhiyuan Liu, Zihang Xu |  |
| 934 |  |  [Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models](https://doi.org/10.18653/v1/2024.acl-long.815) |  | 0 | Efforts to apply transformer-based language models (TLMs) to the problem of reasoning in natural language have enjoyed ever-increasing success in recent years. The most fundamental task in this area to which nearly all others can be reduced is that of determining satisfiability. However, from a... | Ian PrattHartmann, Riza BatistaNavarro, Tharindu Madusanka |  |
| 935 |  |  [Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.816) |  | 0 | Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are... | Dirk Hovy, Hannah Kirk, Hinrich Schütze, Musashi Hinck, Paul Röttger, Valentin Hofmann, Valentina Pyatkin |  |
| 936 |  |  [AI 'News' Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian](https://doi.org/10.18653/v1/2024.acl-long.817) |  | 0 | Large Language Models (LLMs) are increasingly used as ‘content farm’ models (CFMs), to generate synthetic text that could pass for real news articles. This is already happening even for languages that do not have high-quality monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on... | Andrea Esuli, Anna Rogers, Chiara Alzetta, Felice Dell'Orletta, Giovanni Puccetti |  |
| 937 |  |  [Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.818) |  | 0 | This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA... | Alon Jacoby, Mosh Levy, Yoav Goldberg |  |
| 938 |  |  [Disambiguate Words like Composing Them: A Morphology-Informed Approach to Enhance Chinese Word Sense Disambiguation](https://doi.org/10.18653/v1/2024.acl-long.819) |  | 0 | In parataxis languages like Chinese, word meanings are highly correlated with morphological knowledge, which can help to disambiguate word senses. However, in-depth exploration of morphological knowledge in previous word sense disambiguation (WSD) methods is still lacking due to the absence of... | Hansi Wang, Qiliang Liang, Yang Liu, Yaqi Yin, Yue Wang |  |
| 939 |  |  [Do Llamas Work in English? On the Latent Language of Multilingual Transformers](https://doi.org/10.18653/v1/2024.acl-long.820) |  | 0 | We ask whether multilingual language models trained on unbalanced, English-dominated corpora use English as an internal pivot language—-a question of key importance for understanding how language models function and the origins of linguistic bias. Focusing on the Llama-2 family of transformer... | Chris Wendler, Giovanni Monea, Robert West, Veniamin Veselovsky |  |
| 940 |  |  [G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation](https://doi.org/10.18653/v1/2024.acl-long.821) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable abilities in general scenarios. Instruction finetuning empowers them to align with humans in various tasks. Nevertheless, the Diversity and Quality of the instruction data remain two main challenges for instruction finetuning. With regard to... | Liyan Kang, Luyang Huang, Shanbo Cheng, Xingyuan Pan, Yu Lu, Zhicheng Liu |  |
| 941 |  |  [Media Framing: A typology and Survey of Computational Approaches Across Disciplines](https://doi.org/10.18653/v1/2024.acl-long.822) |  | 0 | Framing studies how individuals and societies make sense of the world, by communicating or representing complex issues through schema of interpretation. The framing of information in the mass media influences our interpretation of facts and corresponding decisions, so detecting and analysing it is... | Lea Frermann, Shima Khanehzar, Yulia Otmakhova |  |
| 942 |  |  [SPZ: A Semantic Perturbation-based Data Augmentation Method with Zonal-Mixing for Alzheimer's Disease Detection](https://doi.org/10.18653/v1/2024.acl-long.823) |  | 0 | Alzheimer’s Disease (AD), characterized by significant cognitive and functional impairment, necessitates the development of early detection techniques. Traditional diagnostic practices, such as cognitive assessments and biomarker analysis, are often invasive and costly. Deep learning-based... | Cheng Huang, Fangfang Li, Jie Yin, Puzhen Su |  |
| 943 |  |  [Calibrating Large Language Models Using Their Generations Only](https://doi.org/10.18653/v1/2024.acl-long.824) |  | 0 | As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model’s confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs—especially when the only... | Dennis Ulmer, Hwaran Lee, Martin Gubri, Sangdoo Yun, Seong Joon Oh |  |
| 944 |  |  [Iterative Forward Tuning Boosts In-Context Learning in Language Models](https://doi.org/10.18653/v1/2024.acl-long.825) |  | 0 | Despite the advancements in in-context learning (ICL) for large language models (LLMs), current research centers on specific prompt engineering, such as demonstration selection, with the expectation that a single iteration of demonstrations processing can generalize effectively to a given test... | Bailin Wang, Binhua Li, Binyuan Hui, Bowen Li, Fei Huang, Jiaxi Yang, Min Yang, Yongbin Li |  |
| 945 |  |  [Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement](https://doi.org/10.18653/v1/2024.acl-long.826) |  | 0 | Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM’s bias in evaluating their own output. In this paper, we formally define LLM’s self-bias – the tendency to... | Guanglei Zhu, Lei Li, Liangming Pan, Wenda Xu, William Wang, Xuandong Zhao |  |
| 946 |  |  [Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't](https://doi.org/10.18653/v1/2024.acl-long.827) |  | 0 | We investigate what linguistic factors affect the performance of Automatic Speech Recognition (ASR) models. We hypothesize that orthographic and phonological complexities both degrade accuracy. To examine this, we fine-tune the multilingual self-supervised pretrained model Wav2Vec2-XLSR-53 on 25... | Chihiro Taguchi, David Chiang |  |
| 947 |  |  [Steering Llama 2 via Contrastive Activation Addition](https://doi.org/10.18653/v1/2024.acl-long.828) |  | 0 | We introduce Contrastive Activation Addition (CAA), a method for steering language models by modifying their activations during forward passes. CAA computes “steering vectors” by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular... | Alexander Matt Turner, Evan Hubinger, Julian Schulz, Meg Tong, Nick Gabrieli, Nina Rimsky |  |
| 948 |  |  [EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities](https://doi.org/10.18653/v1/2024.acl-long.829) |  | 0 | The advent of artificial intelligence has led to a growing emphasis on data-driven modeling in macroeconomics, with agent-based modeling (ABM) emerging as a prominent bottom-up simulation paradigm. In ABM, agents (\*e.g.\*, households, firms) interact within a macroeconomic environment,... | Chen Gao, Mingyu Li, Nian Li, Qingmin Liao, Yong Li |  |
| 949 |  |  [SafetyBench: Evaluating the Safety of Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.830) |  | 0 | With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety... | Chong Long, Jie Tang, Leqi Lei, Lindong Wu, Minlie Huang, Rui Sun, Xiao Liu, Xuanyu Lei, Yongkang Huang, Zhexin Zhang |  |
| 950 |  |  [Deciphering Oracle Bone Language with Diffusion Models](https://doi.org/10.18653/v1/2024.acl-long.831) |  | 0 | Originating from China’s Shang Dynasty approximately 3,000 years ago, the Oracle Bone Script (OBS) is a cornerstone in the annals of linguistic history, predating many established writing systems. Despite the discovery of thousands of inscriptions, a vast expanse of OBS remains undeciphered,... | Haisu Guan, Huanxin Yang, Lianwen Jin, Shengwei Han, Xiang Bai, Xinyu Wang, Yongge Liu, Yuliang Liu |  |
| 951 |  |  [M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.832) |  | 0 | Managing long sequences has become an important and necessary feature for large language models (LLMs). However, assessing their ability to handle long contexts remains a challenge. This paper introduces M4LE, a Multi-ability, Multi-range, Multi-task, Multi-domain benchmark for Long-context... | KamFai Wong, Liangyou Li, Lifeng Shang, Qun Liu, WaiChung Kwan, Xingshan Zeng, Yufei Wang, Yusen Sun, Yuxin Jiang |  |
| 952 |  |  [RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models via Romanization](https://doi.org/10.18653/v1/2024.acl-long.833) |  | 0 | This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Roman scripts. We propose an approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens... | Anoop Kunchukuttan, Aswanth M., Jaavid Aktar Husain, Jay Gala, Raj Dabre, Ratish Puduppully, Thanmay Jayakumar |  |
| 953 |  |  [Causal Estimation of Memorisation Profiles](https://doi.org/10.18653/v1/2024.acl-long.834) |  | 0 | Understanding memorisation in language models has practical and societal implications, e.g., studying models’ training dynamics or preventing copyright infringements.Prior work defines memorisation as the causal effect of training with an instance on the model’s ability to predict that instance.... | Andreas Vlachos, Clara Meister, Pietro Lesci, Thomas Hofmann, Tiago Pimentel |  |
| 954 |  |  [CHECKWHY: Causal Fact Verification via Argument Structure](https://doi.org/10.18653/v1/2024.acl-long.835) |  | 0 | With the growing complexity of fact verification tasks, the concern with “thoughtful” reasoning capabilities is increasing. However, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. In this... | Deyu Zhou, Haiyang Zhu, Jiasheng Si, Wenpeng Lu, Yibo Zhao, Yingjie Zhu |  |
| 955 |  |  [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://doi.org/10.18653/v1/2024.acl-long.836) |  | 0 | Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However,... | Christian Tomani, Colin Cherry, Daniel Cremers, David Vilar, Mara Finkelstein, Markus Freitag, Subhajit Naskar, Xavier Garcia |  |
| 956 |  |  [On Efficient and Statistical Quality Estimation for Data Annotation](https://doi.org/10.18653/v1/2024.acl-long.837) |  | 0 | Annotated datasets are an essential ingredient to train, evaluate, compare and productionalize supervised machine learning models. It is therefore imperative that annotations are of high quality. For their creation, good quality management and thereby reliable quality estimates are needed. Then, if... | JanChristoph Klie, Juan Haladjian, Marc Kirchner, Rahul Nair |  |
| 957 |  |  [EZ-STANCE: A Large Dataset for English Zero-Shot Stance Detection](https://doi.org/10.18653/v1/2024.acl-long.838) |  | 0 | Zero-shot stance detection (ZSSD) aims to determine whether the author of a text is in favor, against, or neutral toward a target that is unseen during training. In this paper, we present EZ-STANCE, a large English ZSSD dataset with 47,316 annotated text-target pairs. In contrast to VAST, which is... | Chenye Zhao, Cornelia Caragea |  |
| 958 |  |  [American Sign Language Handshapes Reflect Pressures for Communicative Efficiency](https://doi.org/10.18653/v1/2024.acl-long.839) |  | 0 | Communicative efficiency is a key topic in linguistics and cognitive psychology, with many studies demonstrating how the pressure to communicate with minimal effort guides the form of natural language. However, this phenomenon is rarely explored in signed languages. This paper shows how handshapes... | Dan Klein, Kayo Yin, Terry Regier |  |
| 959 |  |  [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://doi.org/10.18653/v1/2024.acl-long.840) |  | 0 | Information about pretraining corpora used to train the current best-performing language models is seldom discussed: commercial models rarely detail their data, and even open models are often released without accompanying training data or recipes to reproduce them. As a result, it is challenging to... | Aakanksha Naik, Abhilasha Ravichander, Akshita Bhagia, Ananya Harsh Jha, Ben Bogin, Crystal Nam, David Atkinson, Dirk Groeneveld, Dustin Schwenk, Emma Strubell, Hannaneh Hajishirzi, Ian Magnusson, Iz Beltagy, Jacob Morrison, Jennifer Dumas, Jesse Dodge, Khyathi Raghavi Chandu, Kyle Lo, Kyle Richardson, Li Lucy, Luca Soldaini, Luke Zettlemoyer, Matthew E. Peters, Nathan Lambert, Niklas Muennighoff, Nishant Subramani, Noah A. Smith, Oyvind Tafjord, Pete Walsh, Rodney Kinney, Russell Authur, Sachin Kumar, Valentin Hofmann, Xinxi Lyu, Yanai Elazar, Zejiang Shen |  |
| 960 |  |  [OLMo: Accelerating the Science of Language Models](https://doi.org/10.18653/v1/2024.acl-long.841) |  | 0 | Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and... | Aakanksha Naik, Abhilasha Ravichander, Akshita Bhagia, Ananya Harsh Jha, Arman Cohan, Crystal Nam, David Atkinson, Dirk Groeneveld, Dustin Schwenk, Emma Strubell, Evan Pete Walsh, Hamish Ivison, Hannaneh Hajishirzi, Ian Magnusson, Iz Beltagy, Jack Hessel, Jacob Morrison, Jennifer Dumas, Jesse Dodge, Khyathi Raghavi Chandu, Kyle Lo, Kyle Richardson, Luca Soldaini, Luke Zettlemoyer, Matthew E. Peters, Mitchell Wortsman, Nathan Lambert, Niklas Muennighoff, Nishant Subramani, Noah A. Smith, Oyvind Tafjord, Pradeep Dasigi, Rodney Kinney, Russell Authur, Saurabh Shah, Shane Arora, Tushar Khot, Valentina Pyatkin, Will Smith, William Merrill, Yanai Elazar, Yizhong Wang, Yuling Gu |  |
| 961 |  |  [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://doi.org/10.18653/v1/2024.acl-long.842) |  | 0 | Large language models (LLMs) undergo safety alignment to ensure safe conversations with humans. However, this paper introduces a training-free attack method capable of reversing safety alignment, converting the outcomes of stronger alignment into greater potential for harm by accessing only LLM... | Chao Yang, Jiaheng Liu, Jie Liu, Wanli Ouyang, Yu Qiao, Zhanhui Zhou, Zhichen Dong |  |
| 962 |  |  [IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for Indian Languages](https://doi.org/10.18653/v1/2024.acl-long.843) |  | 0 | Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the... | Ananth Sankar, Anoop Kunchukuttan, Mitesh M. Khapra, Mohammed Safi Ur Rahman Khan, Pratyush Kumar, Priyam Mehta, Raj Dabre, Sparsh Jain, Sumanth Doddapaneni, Suriyaprasaad B, Umashankar Kumaravelan, Varun Balan G |  |
| 963 |  |  [Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.844) |  | 0 | Large Language Models (LLMs) have achieved remarkable performance in objective tasks such as open-domain question answering and mathematical reasoning, which can often be solved through recalling learned factual knowledge or chain-of-thought style reasoning. However, we find that the performance of... | Fuwen Luo, Maosong Sun, Peng Li, Xiaolong Wang, Yang Liu, Yile Wang, Yuanchi Zhang |  |
| 964 |  |  [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://doi.org/10.18653/v1/2024.acl-long.845) |  | 0 | Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows... | Ahmet Üstün, Amr Kayid, Daniel D'souza, Freddie Vargus, Gbemileke Onilude, HuiLee Ooi, Julia Kreutzer, Marzieh Fadaee, Neel Bhandari, Niklas Muennighoff, Phil Blunsom, Sara Hooker, Shayne Longpre, Shivalika Singh, Viraat Aryabumi, WeiYin Ko, Zheng Xin Yong |  |
| 965 |  |  [BatchEval: Towards Human-like Text Evaluation](https://doi.org/10.18653/v1/2024.acl-long.846) |  | 0 | Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior... | Boyuan Pan, Heda Wang, Kan Li, Peiwen Yuan, Shaoxiong Feng, Xinglin Wang, Yao Hu, Yiwei Li |  |
| 966 |  |  [ToMBench: Benchmarking Theory of Mind in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.847) |  | 0 | Theory of Mind (ToM) is the cognitive capability to perceive and ascribe mental states to oneself and others. Recent research has sparked a debate over whether large language models (LLMs) exhibit a form of ToM. However, existing ToM evaluations are hindered by challenges such as constrained scope,... | Bosi Wen, Gongyao Jiang, Guanqun Bi, Jincenzi Wu, Jinfeng Zhou, Mengting Hu, Minlie Huang, Yaru Cao, Yunghwei Lai, Zexuan Xiong, Zhuang Chen |  |
| 967 |  |  [COKE: A Cognitive Knowledge Graph for Machine Theory of Mind](https://doi.org/10.18653/v1/2024.acl-long.848) |  | 0 | Theory of mind (ToM) refers to humans’ ability to understand and infer the desires, beliefs, and intentions of others. The acquisition of ToM plays a key role in humans’ social cognition and interpersonal relations. Though indispensable for social intelligence, ToM is still lacking for modern AI... | Helen Meng, Jiawen Deng, Jincenzi Wu, Minlie Huang, Sahand Sabour, Zhuang Chen |  |
| 968 |  |  [MultiPICo: Multilingual Perspectivist Irony Corpus](https://doi.org/10.18653/v1/2024.acl-long.849) |  | 0 | Recently, several scholars have contributed to the growth of a new theoretical framework in NLP called perspectivism. This approach aimsto leverage data annotated by different individuals to model diverse perspectives that affect their opinions on subjective phenomena such as irony. In this... | Alessandro Pedrani, Antonio Uva, Chiara Rubagotti, Cristina Bosco, Davide Bernardi, Erhan Sezerer, Silvia Casola, Simona Frenda, Soda Marem Lo, Valerio Basile, Viviana Patti |  |
| 969 |  |  [AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents](https://doi.org/10.18653/v1/2024.acl-long.850) |  | 0 | Autonomous agents that address day-to-day digital tasks (e.g., ordering groceries for a household), must not only operate multiple apps (e.g., notes, messaging, shopping app) via APIs, but also generate rich code with complex control flow in an iterative manner based on their interaction with the... | Ashish Sabharwal, Edward Li, Harsh Trivedi, Mareike Hartmann, Niranjan Balasubramanian, Ruskin Manku, Shashank Gupta, Tushar Khot, Vinty Dong |  |
| 970 |  |  [MMToM-QA: Multimodal Theory of Mind Question Answering](https://doi.org/10.18653/v1/2024.acl-long.851) |  | 0 | Theory of Mind (ToM), the ability to understand people’s mental states, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM... | Antonio Torralba, Chuanyang Jin, Jiannan Xiang, Jing Cao, Joshua B. Tenenbaum, Tianmin Shu, Tomer D. Ullman, YenLing Kuo, Yutong Wu, Zhiting Hu |  |
| 971 |  |  [DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents](https://doi.org/10.18653/v1/2024.acl-long.852) |  | 0 | Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems. However, the degree to which these numerical reasoning skills are effective in real-world scenarios, particularly in expert domains, is still largely unexplored. This paper introduces DocMath-Eval, a... | Arman Cohan, Hongjun Liu, Linyong Nan, Lyuhao Chen, Rui Zhang, Ryo Kamoi, Xiangru Tang, Yilun Zhao, Yitao Long, Yixin Liu |  |
| 972 |  |  [Unintended Impacts of LLM Alignment on Global Representation](https://doi.org/10.18653/v1/2024.acl-long.853) |  | 0 | Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on... | Diyi Yang, Michael J. Ryan, William Held |  |
| 973 |  |  [ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer](https://doi.org/10.18653/v1/2024.acl-long.854) |  | 0 | While state-of-the-art large language models (LLMs) can excel at adapting text from one style to another, current work does not address the explainability of style transfer models. Recent work has explored generating textual explanations from larger teacher models and distilling them into smaller... | Arkadiy Saakyan, Smaranda Muresan |  |
| 974 |  |  [MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy](https://doi.org/10.18653/v1/2024.acl-long.855) |  | 0 | It has been widely observed that exact or approximate MAP (mode-seeking) decoding from natural language generation (NLG) models consistently leads to degenerate outputs (Holtzman et al., 2019; Stahlberg and Byrne, 2019). Prior work has attributed this behavior to either a fundamental and... | Davis Yoshida, Kartik Goyal, Kevin Gimpel |  |
| 975 |  |  [Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!](https://doi.org/10.18653/v1/2024.acl-long.856) |  | 0 | Annually, at the Conference of Machine Translation (WMT), the Metrics Shared Task organizers conduct the meta-evaluation of Machine Translation (MT) metrics, ranking them according to their correlation with human judgments. Their results guide researchers toward enhancing the next generation of... | Alessandro Scirè, Edoardo Barba, Lorenzo Proietti, Roberto Navigli, Stefano Perrella |  |
| 976 |  |  [NounAtlas: Filling the Gap in Nominal Semantic Role Labeling](https://doi.org/10.18653/v1/2024.acl-long.857) |  | 0 | Despite significant advances in Semantic Role Labeling (SRL), much work in this field has been carried out with a focus on verbal predicates, with the research on nominal SRL lagging behind. In many contexts, however, nominal predicates are often as informative as verbal ones, thus needing proper... | Alessandro Scirè, Dennis Rotondi, Marco Pinto, Pasquale Silvestri, Roberto Navigli, Simone Ciciliano |  |
| 977 |  |  [The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation](https://doi.org/10.18653/v1/2024.acl-long.858) |  | 0 | Large language models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive... | Brian S. Lin, Han Qiu, Rongwu Xu, Shujian Yang, Tianqi Zhang, Tianwei Zhang, Wei Xu, Weiyan Shi, Zhixuan Fang |  |
| 978 |  |  [LooGLE: Can Long-Context Language Models Understand Long Contexts?](https://doi.org/10.18653/v1/2024.acl-long.859) |  | 0 | Large language models (LLMs) are typically limited to processing texts within context window size, which has spurred significant research efforts into enhancing LLMs’ long-context understanding as well as developing high-quality benchmarks to evaluate the ability. However, prior datasets suffer... | Jiaqi Li, Mengmeng Wang, Muhan Zhang, Zilong Zheng |  |
| 979 |  |  [Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation](https://doi.org/10.18653/v1/2024.acl-long.860) |  | 0 | In this paper, we introduce a novel Face-to-Face spoken dialogue model. It processes audio-visual speech from user input and generates audio-visual speech as the response, marking the initial step towards creating an avatar chatbot system without relying on intermediate text. To this end, we newly... | Chae Won Kim, Hyeongseop Rha, Jeong Hun Yeo, Joanna Hong, Minsu Kim, Se Jin Park, Yong Man Ro |  |
| 980 |  |  [ECBD: Evidence-Centered Benchmark Design for NLP](https://doi.org/10.18653/v1/2024.acl-long.861) |  | 0 | Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually... | Alexandra Olteanu, Jackie C. K. Cheung, Su Lin Blodgett, Vera Liao, Yu Lu Liu, Ziang Xiao |  |
| 981 |  |  [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://doi.org/10.18653/v1/2024.acl-long.862) |  | 0 | As the reach of large language models (LMs) expands globally, their ability to cater to diverse cultural contexts becomes crucial. Despite advancements in multilingual capabilities, models are not designed with appropriate cultural nuances. In this paper, we show that multilingual and Arabic... | Alan Ritter, Michael J. Ryan, Tarek Naous, Wei Xu |  |
| 982 |  |  [Explicating the Implicit: Argument Detection Beyond Sentence Boundaries](https://doi.org/10.18653/v1/2024.acl-long.863) |  | 0 | Detecting semantic arguments of a predicate word has been conventionally modeled as a sentence-level task. The typical reader, however, perfectly interprets predicate-argument relations in a much wider context than just the sentence where the predicate was evoked. In this work, we reformulate the... | Arie Cattan, Aviv Slobodkin, Ayal Klein, Eran Hirsch, Ido Dagan, Paul Roit, Valentina Pyatkin |  |
| 983 |  |  [Word Embeddings Are Steers for Language Models](https://doi.org/10.18653/v1/2024.acl-long.864) |  | 0 | Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically... | Chenkai Sun, Chi Han, Heng Ji, Jialiang Xu, Manling Li, Nan Jiang, Tarek F. Abdelzaher, Yi Fung |  |
| 984 |  |  [Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024](https://aclanthology.org/volumes/2024.findings-acl/) |  | 0 |  | Andre Martins, LunWei Ku, Vivek Srikumar |  |
| 985 |  |  [Frontmatter](https://aclanthology.org/2024.findings-acl.0) |  | 0 |  |  |  |
| 986 |  |  [Controllable Data Augmentation for Few-Shot Text Mining with Chain-of-Thought Attribute Manipulation](https://doi.org/10.18653/v1/2024.findings-acl.1) |  | 0 | Prompting large language models (LLMs) for data augmentation has recently become a common practice in few-shot NLP tasks. In this paper, we propose Chain-of-Thought Attribute Manipulation (CoTAM), a novel approach that generates new data from existing examples by only tweaking in the user-provided,... | Jingbo Shang, Letian Peng, Yuwei Zhang |  |
| 987 |  |  [Match More, Extract Better! Hybrid Matching Model for Open Domain Web Keyphrase Extraction](https://doi.org/10.18653/v1/2024.findings-acl.2) |  | 0 | Keyphrase extraction aims to automatically extract salient phrases representing the critical information in the source document. Identifying salient phrases is challenging because there is a lot of noisy information in the document, leading to wrong extraction. To address this issue, in this paper,... | Liping Jing, Mingyang Song, Yi Feng |  |
| 988 |  |  [AFPQ: Asymmetric Floating Point Quantization for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.3) |  | 0 | Large language models (LLMs) show great performance in various tasks, but face deployment challenges from limited memory capacity and bandwidth.Low-bit weight quantization can save memory and accelerate inference.Although floating-point (FP) formats show good performance in LLM quantization, they... | Dayou Du, Jianyu Wei, Ningyi Xu, Shijie Cao, Sicheng Zhang, Ting Cao, Yijia Zhang |  |
| 989 |  |  [End-to-End Emotion Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.4) |  | 0 | Emotion detection is the task of automatically associating one or more emotions with a text. The emotions are experienced, targeted, and caused by different semantic constituents. Therefore, it is necessary to incorporate these semantic constituents into the process of emotion detection. In this... | Guodong Zhou, Xiaotong Jiang, Zhongqing Wang |  |
| 990 |  |  [Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System](https://doi.org/10.18653/v1/2024.findings-acl.5) |  | 0 | Intelligent task-oriented dialogue systems (ToDs) are expected to continuously acquire new knowledge, also known as Continual Learning (CL), which is crucial to fit ever-changing user needs. However, catastrophic forgetting dramatically degrades the model performance in face of a long streamed... | Chen Chen, Chengwei Qin, Qiang Zhang, Ruizhe Li, Yuanyuan Chen, Yuchen Hu |  |
| 991 |  |  [Unveiling Imitation Learning: Exploring the impact of Data Falsity to Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.6) |  | 0 | Many recent studies endeavor to improve open-sourced language models through imitation learning, re-training on the synthetic instruction data from state-of-the-art proprietary models like ChatGPT and GPT-4.However, the innate nature of synthetic data inherently contains noisy data, giving rise to... | Hyunsoo Cho |  |
| 992 |  |  [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://doi.org/10.18653/v1/2024.findings-acl.7) |  | 0 | While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these... | Alex Gu, Armando SolarLezama, Celine Lee, Koushik Sen, Naman Jain, Theo Olausson, WenDing Li |  |
| 993 |  |  [CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support](https://doi.org/10.18653/v1/2024.findings-acl.8) |  | 0 | Literature review requires researchers to synthesize a large amount of information and is increasingly challenging as the scientific literature expands. In this work, we investigate the potential of LLMs for producing hierarchical organizations of scientific studies to assist researchers with... | Aakanksha Naik, Bailey Kuehl, ChaoChun Hsu, Chenhao Tan, David Wadden, Erin Bransom, Jenna Sparks, Lucy Lu Wang |  |
| 994 |  |  [Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.9) |  | 0 | With the recent advances of large language models (LLMs), it is no longer infeasible to build an automated debate system that helps people to synthesise persuasive arguments. Previous work attempted this task by integrating multiple components. In our work, we introduce an argument mining dataset... | Goran Nenadic, Hao Li, Iqra Zahid, Jiayan Zeng, Riza BatistaNavarro, Tharindu Madusanka, Viktor Schlegel, Xiaochi Wang, Xinran He, Yizhi Li, Yuping Wu |  |
| 995 |  |  [A Grounded Preference Model for LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.10) |  | 0 | Despite LLMs’ recent advancements, they still suffer from factual inconsistency and hallucination. An often-opted remedy is retrieval-augmented generation – however, there is no guarantee that the model will strictly adhere to retrieved grounding. Fundamentally, LLMs need to be aligned to be more... | Asaf Yehudai, Asim Munawar, Guangxuan Xu, Radu Florian, Ramón Fernandez Astudillo, Sarathkrishna Swaminathan, Subhajit Chaudhury, Tahira Naseem |  |
| 996 |  |  [Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](https://doi.org/10.18653/v1/2024.findings-acl.11) |  | 0 | Large language models (LLMs), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment LLMs with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains,... | Bowen Jin, Chulin Xie, Jiawei Han, Jiawei Zhang, Kashob Kumar Roy, Ruirui Li, Suhang Wang, Xianfeng Tang, Yu Meng, Yu Zhang, Zheng Li |  |
| 997 |  |  [Text2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.12) |  | 0 | The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE, Text2DB, that emphasizes the... | Heng Ji, Jiawei Han, Sha Li, Sizhe Zhou, Yizhu Jiao |  |
| 998 |  |  [How Important is a Language Model for Low-resource ASR?](https://doi.org/10.18653/v1/2024.findings-acl.13) |  | 0 | N-gram language models (LMs) are the innovation that first made large-vocabulary continuous automatic speech recognition (ASR) viable. With neural end-to-end ASR architectures, however, LMs have become an afterthought. While the effect on accuracy may be negligible for English and Mandarin,... | Emily Prud'hommeaux, Nitin Venkateswaran, Zoey Liu, Éric Le Ferrand |  |
| 999 |  |  [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](https://doi.org/10.18653/v1/2024.findings-acl.14) |  | 0 | Large language models (LLMs) are typically trained on general source data forvarious domains, but a recent surge in domain-specific LLMs has shown theirpotential to outperform general-purpose models in domain-specific tasks (e.g.,biomedicine). Although domain-specific pre-training enhances... | ChenYu Leong, Joel Hestness, Mahmoud Salem, Sean Lie, Shreyas Saxena, Vithursan Thangarasa |  |
| 1000 |  |  [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.15) |  | 0 | Today’s most accurate language models are trained on orders of magnitude more language data than human language learners receive— but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs’ representations and predictions more accurate (and... | Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas |  |
| 1001 |  |  [P-TA: Using Proximal Policy Optimization to Enhance Tabular Data Augmentation via Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.16) |  | 0 | A multitude of industries depend on accurate and reasonable tabular data augmentation for their business processes. Contemporary methodologies in generating tabular data revolve around utilizing Generative Adversarial Networks (GAN) or fine-tuning Large Language Models (LLM). However, GAN-based... | Chenchen Yuan, Felix Steinbauer, Gjergji Kasneci, Shuo Yang, Yao Rong |  |
| 1002 |  |  [Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.17) |  | 0 | There is increasing interest in distilling task-specific knowledge from large language models (LLM) to smaller student models.Nonetheless, LLM distillation presents a dual challenge: 1) there is a high cost associated with querying the teacher LLM, such as GPT-4, for gathering an ample number of... | Wei Ai, Yuhang Zhou |  |
| 1003 |  |  [Small Models are Valuable Plug-ins for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.18) |  | 0 | Large language models (LLMs) such as GPT-3 and GPT-4 are powerful but their weights are often publicly unavailable and their immense sizes make the models difficult to be tuned with common hardware. As a result, effectively tuning these models with large-scale supervised data can be challenging. As... | Canwen Xu, Chenguang Zhu, Julian J. McAuley, Shuohang Wang, Yang Liu, Yichong Xu |  |
| 1004 |  |  [Are self-explanations from Large Language Models faithful?](https://doi.org/10.18653/v1/2024.findings-acl.19) |  | 0 | Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it’s important to measure if... | Andreas Madsen, Sarath Chandar, Siva Reddy |  |
| 1005 |  |  [ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction](https://doi.org/10.18653/v1/2024.findings-acl.20) |  | 0 | Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains. To address these limitations, we present... | Cornelia Caragea, Henry Peng Zou, Liancheng Fang, Philip S. Yu, Vinay Samuel, Weizhi Zhang, Yue Zhou, Zihe Song |  |
| 1006 |  |  [Prompt Engineering a Prompt Engineer](https://doi.org/10.18653/v1/2024.findings-acl.21) |  | 0 | Prompt engineering is a challenging yet crucial task for optimizing the performance of large language models on customized tasks. It requires complex reasoning to examine the model’s errors, hypothesize what is missing or misleading in the current prompt, and communicate the task with clarity.... | Fereshte Khani, Mohamed Ahmed, Qinyuan Ye, Reid Pryzant |  |
| 1007 |  |  [ASPIRE: Language-Guided Data Augmentation for Improving Robustness Against Spurious Correlations](https://doi.org/10.18653/v1/2024.findings-acl.22) |  | 0 | Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. This paper presents... | Chandra Kiran Reddy Evuru, Dinesh Manocha, S. Sakshi, Sanjoy Chowdhury, Sonal Kumar, Sreyan Ghosh, Utkarsh Tyagi |  |
| 1008 |  |  [Tables as Texts or Images: Evaluating the Table Reasoning Ability of LLMs and MLLMs](https://doi.org/10.18653/v1/2024.findings-acl.23) |  | 0 | Tables contrast with unstructured text data by its structure to organize the information.In this paper, we investigate the efficiency of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related... | Aman Sikka, Lin Ma, Naihao Deng, Rada Mihalcea, Ruiqi He, Yue Zhang, Yulong Chen, Zhenjie Sun |  |
| 1009 |  |  [Biasly: An Expert-Annotated Dataset for Subtle Misogyny Detection and Mitigation](https://doi.org/10.18653/v1/2024.findings-acl.24) |  | 0 | Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles,... | Allison Cohen, Anna Richter, Brooklyn Sheppard, Carolyne Pelletier, Elizabeth Allyn Smith, Ioana Baldini, Tamara Kneese, Yue Dong |  |
| 1010 |  |  [BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra](https://doi.org/10.18653/v1/2024.findings-acl.25) |  | 0 | Many existing end-to-end systems for hybrid question answering tasks can often be boiled down to a “prompt-and-pray” paradigm, where the user has limited control and insight into the intermediate reasoning steps used to achieve the final result. Additionally, due to the context size limitation of... | Liang Wang, Parag Dakle, Parker Glenn, Preethi Raghavan |  |
| 1011 |  |  [LLM-QAT: Data-Free Quantization Aware Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.26) |  | 0 | Several post-training quantization methods have been applied to large language models (LLMs), and have been shown to perform well down to 8-bits. We find that these methods break down at lower bit precision, and investigate quantization-aware training for LLMs (LLM-QAT) to push quantization levels... | Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Raghuraman Krishnamoorthi, Vikas Chandra, Yangyang Shi, Yashar Mehdad, Zechun Liu |  |
| 1012 |  |  [InfiMM: Advancing Multimodal Understanding with an Open-Sourced Visual Language Model](https://doi.org/10.18653/v1/2024.findings-acl.27) |  | 0 | In this work, we present InfiMM, an advanced Multimodal Large Language Model that adapts to intricate vision-language tasks. InfiMM, inspired by the Flamingo architecture, distinguishes itself through the utilization of large-scale training data, comprehensive training strategies, and diverse large... | Bohan Zhai, Haogeng Liu, Hongxia Yang, Jianbo Yuan, Quanzeng You, Ran He, Wentao Chen, Xiaotian Han, Yiqi Wang, Yiren Jian, Yongfei Liu, Yunzhe Tao |  |
| 1013 |  |  [Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution](https://doi.org/10.18653/v1/2024.findings-acl.28) |  | 0 | Although achieving great success, Large Language Models (LLMs) usually suffer from unreliable hallucinations. Although language attribution can be a potential solution, there are no suitable benchmarks and evaluation metrics to attribute LLMs to structured knowledge. In this paper, we define a new... | Aixin Sun, Liangming Pan, Xinze Li, Yixin Cao, Yubo Ma |  |
| 1014 |  |  [Benchmarking Cognitive Biases in Large Language Models as Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.29) |  | 0 | Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 16 LLMs encompassing four different size ranges and evaluate their output responses by preference ranking from the other LLMs as... | Dongyeop Kang, Jong Inn Park, Minhwa Lee, Ryan Koo, Vipul Raheja, Zae Myung Kim |  |
| 1015 |  |  [X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions](https://doi.org/10.18653/v1/2024.findings-acl.30) |  | 0 | Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples into these languages can be a solution but unreliable,... | Chengqing Zong, Chong Li, Jiajun Zhang, Jinliang Lu, Shaonan Wang, Wen Yang |  |
| 1016 |  |  [Muffin: Mitigating Unhelpfulness in Emotional Support Conversations with Multifaceted AI Feedback](https://doi.org/10.18653/v1/2024.findings-acl.31) |  | 0 |  | Chak Tou Leong, Chunpu Xu, Jiashuo Wang, Jing Li, Wenjie Li |  |
| 1017 |  |  [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.32) |  | 0 | This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce... | Bang Liu, Ivan Kobyzev, Mehdi Rezagholizadeh, Peng Lu, Suyuchen Wang |  |
| 1018 |  |  [MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.33) |  | 0 | Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we... | Anni Zou, Arman Cohan, Mark Gerstein, Xiangru Tang, Xingyao Zhang, Yilun Zhao, Zhuosheng Zhang, Ziming Li |  |
| 1019 |  |  [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.34) |  | 0 | Neural-symbolic methods have demonstrated efficiency in enhancing the reasoning abilities of large language models (LLMs). However, existing methods mainly rely on syntactically mapping natural languages to complete formal languages like Python and SQL. Those methods require that reasoning tasks be... | Baosong Yang, Pei Zhang, Rui Wang, Yiming Wang, Zhuosheng Zhang |  |
| 1020 |  |  [DPDLLM: A Black-box Framework for Detecting Pre-training Data from Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.35) |  | 0 | The success of large language models (LLM) benefits from large-scale model parameters and large amounts of pre-training data. However, the textual data for training LLM can not be confirmed to be legal because they are crawled from different web sites. For example, there are copyrighted articles,... | Baohang Zhou, Hongru Wang, KamFai Wong, Kehui Song, Lingzhi Wang, Xuhui Sui, Ying Zhang, Zezhong Wang |  |
| 1021 |  |  [PACIT: Unlocking the Power of Examples for Better In-Context Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.36) |  | 0 | Instruction tuning enhances the instruction following ability of large language models by finetuning with supervised instruction data. Previous work proposes in-context instruction tuning (ICIT) where specific positive or negative examples are incorporated into the prompt for better performance. In... | Guanhua Chen, Tianci Xue, Yixia Li, Yun Chen, Ziqi Wang |  |
| 1022 |  |  [Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.37) |  | 0 | Recent advances in large language models (LLMs) have promoted generative error correction (GER) for automatic speech recognition (ASR), which aims to predict the ground-truth transcription from the decoded N-best hypotheses. Thanks to the strong language generation ability of LLMs and rich... | Chen Chen, Chengwei Qin, Engsiong Chng, Qiushi Zhu, Ruizhe Li, Yuchen Hu |  |
| 1023 |  |  [Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing](https://doi.org/10.18653/v1/2024.findings-acl.38) |  | 0 | Cross-document Relation Extraction aims to predict the relation between target entities located in different documents. In this regard, the dominant models commonly retain useful information for relation prediction via bridge entities, which allows the model to elaborately capture the intrinsic... | Chengyi Yang, Hao Yue, Jinsong Su, Junfeng Yao, Liang Zhang, Shaopeng Lai |  |
| 1024 |  |  [Large Language Models can Share Images, Too!](https://doi.org/10.18653/v1/2024.findings-acl.39) |  | 0 | This paper explores the image-sharing capability of Large Language Models (LLMs), such as GPT-4 and LLaMA 2, in a zero-shot setting. To facilitate a comprehensive evaluation of LLMs, we introduce the photochatplus dataset, which includes enriched annotations (ie intent, triggering sentence, image... | Dokyong Lee, HoJin Choi, Jonghwan Hyeon, JooWon Sung, YoungJun Lee |  |
| 1025 |  |  [CodeM: Less Data Yields More Versatility via Ability Matrix](https://doi.org/10.18653/v1/2024.findings-acl.40) |  | 0 | In the era of code large language models (code LLMs), data engineering plays a pivotal role during the instruction fine-tuning phase. To train a versatile model, previous efforts devote tremendous efforts into crafting instruction data covering all the downstream scenarios. Nonetheless, this will... | Ailun Yu, Bei Guan, Bo Shen, Daoguang Zan, Lizhen Cui, Qianxiang Wang, Shaoxin Lin, Wei Liu, Weihua Luo, Yafen Yao, Yan Liu, Yongji Wang, Yongshun Gong |  |
| 1026 |  |  [Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning](https://doi.org/10.18653/v1/2024.findings-acl.41) |  | 0 | Advances in large vision-language models (LVLMs) have led to significant progress in generating natural language descriptions for visual contents. These powerful models are known for producing texts that are factually inconsistent with the visual input. While some efforts mitigate such... | Heng Ji, Hou Pong Chan, KungHsiang Huang, Lingyu Zhang, Mingyang Zhou, ShihFu Chang, Yi Fung, Zhenhailong Wang |  |
| 1027 |  |  [BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs via Key Supporting Evidence](https://doi.org/10.18653/v1/2024.findings-acl.42) |  | 0 | Retrieval-augmented large language models (LLMs) have demonstrated efficacy in knowledge-intensive tasks such as open-domain QA, addressing inherent challenges in knowledge update and factual inadequacy.However, inconsistencies between retrieval knowledge and the necessary knowledge for LLMs,... | Jiajie Jin, Yujia Zhou, Yutao Zhu, Zhicheng Dou |  |
| 1028 |  |  [Beyond Literal Descriptions: Understanding and Locating Open-World Objects Aligned with Human Intentions](https://doi.org/10.18653/v1/2024.findings-acl.43) |  | 0 | Visual grounding (VG) aims at locating the foreground entities that match the given natural language expression. Previous datasets and methods for classic VG task mainly rely on the prior assumption that the given expression must literally refer to the target object, which greatly impedes the... | Jing Liu, Wenxuan Wang, Xingjian He, Xinlong Wang, Yichen Yan, Yisi Zhang, Zijia Zhao |  |
| 1029 |  |  [Incremental Sequence Labeling: A Tale of Two Shifts](https://doi.org/10.18653/v1/2024.findings-acl.44) |  | 0 | The incremental sequence labeling task involves continuously learning new classes over time while retaining knowledge of the previous ones. Our investigation identifies two significant semantic shifts: E2O (where the model mislabels an old entity as a non-entity) and O2E (where the model labels a... | Junhao Zheng, Qianli Ma, Shengjie Qiu, Yicheng Luo, Zhen Liu |  |
| 1030 |  |  [How Proficient Are Large Language Models in Formal Languages? An In-Depth Insight for Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.45) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions based on facts in knowledge bases. A typical approach to KBQA is semantic parsing, which translates a question into an executable logical form in a formal language. Recent works leverage the capabilities of large... | Jiaxin Shi, Jinxin Liu, Juanzi Li, Lei Hou, Linmei Hu, Lunyiu Nie, Shulin Cao, Tingjian Zhang |  |
| 1031 |  |  [MELOV: Multimodal Entity Linking with Optimized Visual Features in Latent Space](https://doi.org/10.18653/v1/2024.findings-acl.46) |  | 0 | Multimodal entity linking (MEL), which aligns ambiguous mentions within multimodal contexts to referent entities from multimodal knowledge bases, is essential for many natural language processing applications. Previous MEL methods mainly focus on exploring complex multimodal interaction mechanisms... | Baohang Zhou, Kehui Song, Xiaojie Yuan, Xuhui Sui, Ying Zhang, Yu Zhao |  |
| 1032 |  |  [Unsupervised Distractor Generation via Large Language Model Distilling and Counterfactual Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.47) |  | 0 | Within the context of reading comprehension, the task of Distractor Generation (DG) aims to generate several incorrect options to confuse readers. In recent years, the emergence of Large Language Models (LLMs) provides a potential for unsupervised DG without expensive human-annotated distractor... | Fanyi Qu, Hao Sun, Yunfang Wu |  |
| 1033 |  |  [Conversational Question Answering with Language Models Generated Reformulations over Knowledge Graph](https://doi.org/10.18653/v1/2024.findings-acl.48) |  | 0 | Conversational question answering (ConvQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to... | Blaine Hill, Boxin Du, Fei Wang, Hanghang Tong, Lihui Liu |  |
| 1034 |  |  [Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step by Step](https://doi.org/10.18653/v1/2024.findings-acl.49) |  | 0 | Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an... | Jingbo Shang, Li Zhong, Zilong Wang |  |
| 1035 |  |  [Effective In-Context Example Selection through Data Compression](https://doi.org/10.18653/v1/2024.findings-acl.50) |  | 0 | In-context learning has been extensively validated in large language models. However, the mechanism and selection strategy for in-context example selection, which is a crucial ingredient in this approach, lacks systematic and in-depth research. In this paper, we propose a data compression approach... | Haoyu Wang, Jun Xu, Kepu Zhang, Xiao Zhang, Zhongxiang Sun |  |
| 1036 |  |  [Are U a Joke Master? Pun Generation via Multi-Stage Curriculum Learning towards a Humor LLM](https://doi.org/10.18653/v1/2024.findings-acl.51) |  | 0 | Although large language models (LLMs) acquire extensive world knowledge and some reasoning abilities, their proficiency in generating humorous sentences remains a challenge. Previous research has demonstrated that the humor generation capabilities of ChatGPT are confined to producing merely 25... | Aimin Zhou, Chong Yang, Li Cai, Man Lan, Tu Hu, Xin Lu, Xinhao Chen, Xinlin Zhuang, Xuan Lin, Yang Chen |  |
| 1037 |  |  [Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.52) |  | 0 | Deploying large language models (LLMs) to real scenarios for domain-specific question answering (QA) is a key thrust for LLM applications, which poses numerous challenges, especially in ensuring that responses are both accommodating to user requirements and appropriately leveraging domain-specific... | Fangming Li, Huajun Chen, Wen Zhang, Yanxi Lu, Yichi Zhang, Yin Fang, Zhuo Chen |  |
| 1038 |  |  [MARIO: MAth Reasoning with code Interpreter Output - A Reproducible Pipeline](https://doi.org/10.18653/v1/2024.findings-acl.53) |  | 0 | Large language models (LLMs) have significantly improved in understanding natural language but still lack in mathematical reasoning, a hurdle on the path to true artificial general intelligence. The training of large language models, based on next-token prediction, struggles to capture the precise... | Chengxi Li, Jing Wu, Kai Fan, Minpeng Liao, Wei Luo |  |
| 1039 |  |  [DiffusPoll: Conditional Text Diffusion Model for Poll Generation](https://doi.org/10.18653/v1/2024.findings-acl.54) |  | 0 | Online social media platforms often gather user feedback through polls to enhance user engagement. Automatically generating polls from social media and its context can decrease the labor expenses of media workers and enhance workplace productivity. However, on social media platforms, there are... | Le Cheng, Shuangyin Li |  |
| 1040 |  |  [Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.55) |  | 0 | While large language models (LLMs) have shown excellent capabilities in language understanding, text generation and many other tasks, they still struggle in complex multi-step reasoning problems such as mathematical reasoning. In this paper, through a newly proposed arithmetical puzzle problem, we... | Chen Ye, Haolong Li, Jie Chen, Yinqi Zhang, Yu Ma |  |
| 1041 |  |  [Implanting LLM's Knowledge via Reading Comprehension Tree for Toxicity Detection](https://doi.org/10.18653/v1/2024.findings-acl.56) |  | 0 | Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs... | Hankun Kang, Tieyun Qian |  |
| 1042 |  |  [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://doi.org/10.18653/v1/2024.findings-acl.57) |  | 0 | This paper focuses on task-agnostic prompt compression for better generalizability and efficiency. Considering the redundancy in natural language, existing approaches compress prompts by removing tokens or lexical units according to their information entropy obtained from a causal language model... | ChinYew Lin, Dongmei Zhang, H. Vicky Zhao, Huiqiang Jiang, Jue Zhang, Lili Qiu, Menglin Xia, Qianhui Wu, Qingwei Lin, Victor Rühle, Xufang Luo, Yuqing Yang, Zhuoshi Pan |  |
| 1043 |  |  [EconNLI: Evaluating Large Language Models on Economics Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.58) |  | 0 | Large Language Models (LLMs) are widely used for writing economic analysis reports or providing financial advice, but their ability to understand economic knowledge and reason about potential results of specific economic events lacks systematic evaluation. To address this gap, we propose a new... | Yi Yang, Yue Guo |  |
| 1044 |  |  [Better Late Than Never: Model-Agnostic Hallucination Post-Processing Framework Towards Clinical Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.59) |  | 0 | Clinical text summarization has proven successful in generating concise and coherent summaries. However, these summaries may include unintended text with hallucinations, which can mislead clinicians and patients. Existing methods for mitigating hallucinations can be categorized into task-specific... | Chunyuan Deng, Hui Zhao, Songda Li, Yake Niu, Yunqi Zhang |  |
| 1045 |  |  [Finding and Editing Multi-Modal Neurons in Pre-Trained Transformers](https://doi.org/10.18653/v1/2024.findings-acl.60) |  | 0 | Understanding the internal mechanisms by which multi-modal large language models (LLMs) interpret different modalities and integrate cross-modal representations is becoming increasingly critical for continuous improvements in both academia and industry. In this paper, we propose a novel method to... | Haowen Pan, Meng Wang, Xiaozhi Wang, Xun Yang, Yixin Cao |  |
| 1046 |  |  [Realistic Evaluation of Toxicity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.61) |  | 0 | Large language models (LLMs) have become integral to our professional workflows and daily lives. Nevertheless, these machine companions of ours have a critical flaw: the huge amount of data which endows them with vast and diverse knowledge, also exposes them to the inevitable toxicity and bias.... | Linh Ngo Van, ThanhThien Le, Thien Huu Nguyen, Tinh Son Luong |  |
| 1047 |  |  [Controllable Text Generation with Residual Memory Transformer](https://doi.org/10.18653/v1/2024.findings-acl.62) |  | 0 | Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have brought great success in text generation. However, it is still an open challenge to effectively control the generation process of a CLM while balancing the flexibility, control granularity, and generation efficiency. In this... | Dawei Song, Haiming Wu, Hanqing Zhang, Si Sun |  |
| 1048 |  |  [Prompt-Based Length Controlled Generation with Multiple Control Types](https://doi.org/10.18653/v1/2024.findings-acl.63) |  | 0 | Large language models (LLMs) have attracted great attention given their strong performance on a wide range of NLP tasks. In practice, users often expect generated texts to fall within a specific length range, making length controlled generation an important topic, especially for GPT-style models.... | Lifeng Shang, Qun Liu, Renlong Jie, Xiaojun Meng, Xin Jiang |  |
| 1049 |  |  [PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain](https://doi.org/10.18653/v1/2024.findings-acl.64) |  | 0 | We present PCA-Bench, a multimodal decision-making benchmark for evaluating the integrated capabilities of Multimodal Large Language Models (MLLMs). Departing from previous benchmarks focusing on simplistic tasks and individual model capability, PCA-Bench introduces three complex scenarios:... | Baobao Chang, Haozhe Zhao, Liang Chen, Peiyi Wang, Shuhuai Ren, Tianyu Liu, Xiangdi Meng, Yichi Zhang, Yuchi Wang, Zefan Cai |  |
| 1050 |  |  [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.65) |  | 0 | Conversational recommender systems are an emerging area that has garnered increasing interest in the community, especially with the advancements in large language models (LLMs) that enable sophisticated handling of conversational input. Despite the progress, the field still has many aspects left to... | Beongwoo Kwak, Dongha Lee, Hana Kim, Jinyoung Yeo, Minjin Kim, Minju Kim, SeongKu Kang, Youngjae Yu |  |
| 1051 |  |  [CoLLaVO: Crayon Large Language and Vision mOdel](https://doi.org/10.18653/v1/2024.findings-acl.66) |  | 0 | The remarkable success of Large Language Models (LLMs) and instruction tuning drives the evolution of Vision Language Models (VLMs) towards a versatile general-purpose model. Yet, it remains unexplored whether current VLMs genuinely possess quality object-level image understanding capabilities... | Beomchan Park, ByungKwan Lee, Chae Won Kim, Yong Man Ro |  |
| 1052 |  |  [Modelling Variability in Human Annotator Simulation](https://doi.org/10.18653/v1/2024.findings-acl.67) |  | 0 | Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation tasks such as data annotation and system assessment. It is important to incorporate the variability present in human evaluation into HAS, since it helps capture diverse subjective interpretations and... | Chao Zhang, Philip C. Woodland, Wen Wu, Wenlin Chen |  |
| 1053 |  |  [BEnQA: A Question Answering Benchmark for Bengali and English](https://doi.org/10.18653/v1/2024.findings-acl.68) |  | 0 | In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with different types of questions, including factual,... | Alice Oh, H. M. Quamran Hasan, James Thorne, Minhajur Rahman Chowdhury Mahim, Rifki Afina Putri, Sheikh Shafayat |  |
| 1054 |  |  [MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.69) |  | 0 |  | Jiafeng Guo, Keping Bi, Wanqing Cui, Xueqi Cheng |  |
| 1055 |  |  [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.70) |  | 0 | Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within... | Hongbang Yuan, Huaijun Li, Jiexin Xu, Jun Zhao, Kang Liu, Pengfei Cao, Xiaojian Jiang, Yubo Chen, Zhuoran Jin |  |
| 1056 |  |  [BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning](https://doi.org/10.18653/v1/2024.findings-acl.71) |  | 0 | Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding... | Jinhua Zhu, Kaiyuan Gao, Lijun Wu, Qizhi Pei, Rui Yan, Shufang Xie, Tao Qin, Xiaozhuan Liang, Yin Fang |  |
| 1057 |  |  [SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.72) |  | 0 | Fine-tuning all parameters of large language models (LLMs) necessitates substantial computational power and extended time. Latest advancements in parameter-efficient fine-tuning (PEFT) techniques, such as Adapter tuning and LoRA, allow for adjustments to only a minor fraction of the parameters of... | Jie Zhang, Yuan Fang, Zhihao Wen |  |
| 1058 |  |  [GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving](https://doi.org/10.18653/v1/2024.findings-acl.73) |  | 0 | Recent advancements in large language models (LLMs) and multi-modal models (MMs) have demonstrated their remarkable capabilities in problem-solving. Yet, their proficiency in tackling geometry math problems, which necessitates an integrated understanding of both textual and visual information, has... | ChengLin Liu, Fei Yin, Jiaxin Zhang, MingLiang Zhang, Yashar Moshfeghi, Zhongzhi Li |  |
| 1059 |  |  [Boosting Textural NER with Synthetic Image and Instructive Alignment](https://doi.org/10.18653/v1/2024.findings-acl.74) |  | 0 | Named entity recognition (NER) is a pivotal task reliant on textual data, often impeding the disambiguation of entities due to the absence of context. To tackle this challenge, conventional methods often incorporate images crawled from the internet as auxiliary information. However, the images... | Dong Nie, Guozheng Li, Hang Zhang, Jiahao Wang, Jiajun Liu, Peng Wang, Wenjun Ke, Ziyu Shang |  |
| 1060 |  |  [Neurons in Large Language Models: Dead, N-gram, Positional](https://doi.org/10.18653/v1/2024.findings-acl.75) |  | 0 | We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the... | Christoforos Nalmpantis, Elena Voita, Javier Ferrando |  |
| 1061 |  |  [LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.76) |  | 0 | Grounded Multimodal Named Entity Recognition (GMNER) is a nascent multimodal task that aims to identify named entities, entity types and their corresponding visual regions. GMNER task exhibits two challenging properties: 1) The weak correlation between image-text pairs in social media results in a... | Di Sun, Gang Pan, Han Li, Jiahao Wang, Jinyuan Li, Wenkun Zhang, Zan Wang |  |
| 1062 |  |  [Learning Job Title Representation from Job Description Aggregation Network](https://doi.org/10.18653/v1/2024.findings-acl.77) |  | 0 | Learning job title representation is a vital process for developing automatic human resource tools. To do so, existing methods primarily rely on learning the title representation through skills extracted from the job description, neglecting the rich and diverse content within. Thus, we propose an... | Attapol Rutherford, Chawan Piansaddhayanon, Ekapol Chuangsuwanich, Napat Laosaengpha, Thanit Tativannarat |  |
| 1063 |  |  [FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts](https://doi.org/10.18653/v1/2024.findings-acl.78) |  | 0 | Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of visual question-answering multimodal language models in reasoning with... | Dan Roth, Pranshu Pandya, Purvi Chaurasia, Shubhankar Singh, Vatsal Gupta, Vivek Gupta, Yerram Varun |  |
| 1064 |  |  [Flexible Weight Tuning and Weight Fusion Strategies for Continual Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.79) |  | 0 | Continual Named Entity Recognition (CNER) is dedicated to sequentially learning new entity types while mitigating catastrophic forgetting of old entity types. Traditional CNER approaches commonly employ knowledge distillation to retain old knowledge within the current model. However, because only... | Chenhui Chu, Duzhen Zhang, Xiuyi Chen, Yahan Yu |  |
| 1065 |  |  [Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.80) |  | 0 | The automatic evaluation of natural language generation (NLG) systems presents a long-lasting challenge. Recent studies have highlighted various neural metrics that align well with human evaluations. Yet, the robustness of these evaluators against adversarial perturbations remains largely... | Chen Zhang, Danqing Luo, Haizhou Li, Luis Fernando D'Haro, Robby T. Tan, Yiming Chen |  |
| 1066 |  |  [Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.81) |  | 0 | Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities and versatility in NLP tasks, however they sometimes fail to maintain crucial invariances for specific tasks. One example is permutation sensitivity, where LLMs’ outputs may significantly vary depending on the order of... | Adian Liusie, Mark J. F. Gales, Yassir Fathullah |  |
| 1067 |  |  [Uncovering Limitations of Large Language Models in Information Seeking from Tables](https://doi.org/10.18653/v1/2024.findings-acl.82) |  | 0 | Tables are recognized for their high information density and widespread usage, serving as essential sources of information. Seeking information from tables (TIS) is a crucial capability for Large Language Models (LLMs), serving as the foundation of knowledge-based Q&A systems. However, this field... | Chaoxu Pang, Chunhao Yang, Ping Luo, Yixuan Cao |  |
| 1068 |  |  [An Ensemble-of-Experts Framework for Rehearsal-free Continual Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.83) |  | 0 | Continual relation extraction (CRE) aims to continuously learn relations in new tasks without forgetting old relations in previous tasks.Current CRE methods are all rehearsal-based which need to store samples and thus may encounter privacy and security issues.This paper targets rehearsal-free... | Shen Zhou, Tieyun Qian, Xin Miao, Yongqi Li |  |
| 1069 |  |  [Temporal Validity Change Prediction](https://doi.org/10.18653/v1/2024.findings-acl.84) |  | 0 | Temporal validity is an important property of text that has many downstream applications, such as recommender systems, conversational AI, and user status tracking. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, many data... | Adam Jatowt, Georg Wenzel |  |
| 1070 |  |  [RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.85) |  | 0 | Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter-efficient fine-tuning methods that optimize input prompts or adjust a small number of model parameters (e.g LoRA). In this study, we explore... | Alona Fyshe, Saeed Najafi |  |
| 1071 |  |  [Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.86) |  | 0 | Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e. sets of concepts which share some property... | Hanane Kteich, Na Li, Steven Schockaert, Usashi Chatterjee, Zied Bouraoui |  |
| 1072 |  |  [Revisiting Multimodal Transformers for Tabular Data with Text Fields](https://doi.org/10.18653/v1/2024.findings-acl.87) |  | 0 | Tabular data with text fields can be leveraged in applications such as financial risk assessment or medical diagnosis prediction. When employing multimodal approaches to make predictions based on these modalities, it is crucial to make the most appropriate modeling choices in terms of numerical... | Thomas Bonnier |  |
| 1073 |  |  [An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla](https://doi.org/10.18653/v1/2024.findings-acl.88) |  | 0 | Pretrained language models inherently exhibit various social biases, prompting a crucial examination of their social impact across various linguistic contexts due to their widespread usage. Previous studies have provided numerous methods for intrinsic bias measurements, predominantly focused on... | Abhik Bhattacharjee, Ayan Antik Khan, Jayanta Sadhu, Rifat Shahriyar |  |
| 1074 |  |  [ConTempo: A Unified Temporally Contrastive Framework for Temporal Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.89) |  | 0 | The task of temporal relation extraction (TRE) involves identifying and extracting temporal relations between events from narratives. We identify two primary issues with TRE systems. First, by formulating TRE as a simple text classification task where every temporal relation is independent, it is... | Gerald Penn, Jingcheng Niu, Saifei Liao, Simon de Montigny, Victoria Ng |  |
| 1075 |  |  [CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.90) |  | 0 | In this work, we dive deep into one of the popular knowledge-grounded dialogue benchmarks that focus on faithfulness, FaithDial. We show that a significant portion of the FaithDial data contains annotation artifacts, which may bias models towards completely ignoring the conversation history. We... | Abbas Ghaddar, Boxing Chen, David AlfonsoHermelo, Mehdi Rezagholizadeh, Philippe Langlais, Prasanna Parthasarathi |  |
| 1076 |  |  [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.91) |  | 0 | The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs’ abilities to critique and rectify their... | Haowei Liu, Ruilin Luo, Tian Liang, Yujiu Yang, Zhibin Gou, Zicheng Lin |  |
| 1077 |  |  [DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.92) |  | 0 | Recently, while large language models (LLMs) have demonstrated impressive results, they still suffer from hallucination, i.e., the generation of false information. Model editing is the task of fixing factual mistakes in LLMs; yet, most previous works treat it as a one-time task, paying little... | Chengyu Wang, Dongyang Li, Hui Xue', Jun Huang, Longtao Huang, Qizhou Chen, Taolin Zhang, Xiaofeng He |  |
| 1078 |  |  [Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.93) |  | 0 | Generic text summarization approaches often fail to address the specific intent and needs of individual users. Recently, scholarly attention has turned to the development of summarization methods that are more closely tailored and controlled to align with specific objectives and user needs. Despite... | Ashok Urlana, Pruthwik Mishra, Rahul Mishra, Tathagato Roy |  |
| 1079 |  |  [Benchmarking Large Language Models on Communicative Medical Coaching: A Dataset and a Novel System](https://doi.org/10.18653/v1/2024.findings-acl.94) |  | 0 | Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors,... | Hao Wang, Hengguan Huang, Hongfu Liu, Songtao Wang, Ye Wang |  |
| 1080 |  |  [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://doi.org/10.18653/v1/2024.findings-acl.95) |  | 0 | This paper introduce a novel thought prompting approach called ”Everything of Thoughts” (XoT) for Large Language Models (LLMs) to defy the law of ”Penrose triangle” of existing thought paradigms, to achieve three key perspectives in thought generation simultaneously: performance, efficiency, and... | Chaoyun Zhang, Dongmei Zhang, Lu Wang, Minghua Ma, Qingwei Lin, Ruomeng Ding, Saravan Rajmohan, Si Qin, Wei Zhang, Yong Xu |  |
| 1081 |  |  [SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources with Retrieval and Semantic Parsing](https://doi.org/10.18653/v1/2024.findings-acl.96) |  | 0 | We introduce SPAGHETTI: Semantic Parsing Augmented Generation for Hybrid English information from Text Tables and Infoboxes, a hybrid question-answering (QA) pipeline that utilizes information from heterogeneous knowledge sources, including knowledge base, text, tables, and infoboxes. Our... | Farhad Ghassemi, Heidi C. Zhang, Jialiang Xu, Monica S. Lam, Shicheng Liu, Sina J. Semnani |  |
| 1082 |  |  [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.97) |  | 0 | In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of LLMs on DA,... | Anh Tuan Luu, Bosheng Ding, Chengwei Qin, Guizhen Chen, Junjie Hu, Ruochen Zhao, Shafiq Joty, Tianze Luo, Wenhan Xia, Xinze Li |  |
| 1083 |  |  [k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text](https://doi.org/10.18653/v1/2024.findings-acl.98) |  | 0 | Recent watermarked generation algorithms inject detectable signatures during language generation to facilitate post-hoc detection. While token-level watermarks are vulnerable to paraphrase attacks, SemStamp (Hou et al., 2023) applies watermark on the semantic representation of sentences and... | Abe Bohan Hou, Daniel Khashabi, Jingyu Zhang, Tianxing He, Yichen Wang |  |
| 1084 |  |  [ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.99) |  | 0 | This paper introduces the ColorSwap dataset, designed to assess and improve the proficiency of multimodal models in matching objects with their colors. The dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000 examples. Each example includes a caption-image pair, along with a... | Agam Bhatia, Ishan Gaur, Jirayu Burapacheep, Tristan Thrush |  |
| 1085 |  |  [Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers](https://doi.org/10.18653/v1/2024.findings-acl.100) |  | 0 | Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that... | Jinyue Yuan, Salman Avestimehr, Tuo Zhang |  |
| 1086 |  |  [CeeBERT: Cross-Domain Inference in Early Exit BERT](https://doi.org/10.18653/v1/2024.findings-acl.101) |  | 0 | Pre-trained Language Models (PLMs), like BERT, with self-supervision objectives exhibit remarkable performance and generalization across various tasks. However, they suffer in inference latency due to their large size. To address this issue, side branches are attached at intermediate layers,... | Divya Jyoti Bajpai, Manjesh K. Hanawal |  |
| 1087 |  |  [UNIWIZ: A Unified Large Language Model Orchestrated Wizard for Safe Knowledge Grounded Conversations](https://doi.org/10.18653/v1/2024.findings-acl.102) |  | 0 | Large Language Models (LLMs) have made significant progress in integrating safety and knowledge alignment. However, adversarial actors can manipulate these models into generating unsafe responses, and excessive safety alignment can lead to unintended hallucinations. To address these challenges, we... | Rohini K. Srihari, Souvik Das |  |
| 1088 |  |  [A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism](https://doi.org/10.18653/v1/2024.findings-acl.103) |  | 0 | We show that content on the web is often translated into many languages, and the low quality of these multi-way translations indicates they were likely created using Machine Translation (MT). Multi-way parallel, machine generated content not only dominates the translations in lower resource... | Brian Thompson, Marcello Federico, Mehak Preet Dhaliwal, Peter Frisch, Tobias Domhan |  |
| 1089 |  |  [RankMean: Module-Level Importance Score for Merging Fine-tuned LLM Models](https://doi.org/10.18653/v1/2024.findings-acl.104) |  | 0 | Traditionally, developing new language models (LMs) capable of addressing multiple tasks involves fine-tuning pre-trained LMs using a wide collection of datasets, a process that often incurs significant computational expenses. Model merging emerges as a cost-effective alternative, allowing the... | Bhavya Kailkhura, Brian Gallagher, Gabriel J. Perin, Shusen Liu, Xuxi Chen, Zhangyang Wang |  |
| 1090 |  |  [VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.105) |  | 0 | Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability. A comprehensive quantitative evaluation is necessary to identify and understand the extent of hallucinations in these... | Haoyi Qiu, Nanyun Peng, Wenbo Hu, ZiYi Dou |  |
| 1091 |  |  [Cyclical Contrastive Learning Based on Geodesic for Zero-shot Cross-lingual Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.106) |  | 0 | Owing to the scarcity of labeled training data, Spoken Language Understanding (SLU) is still a challenging task in low-resource languages. Therefore, zero-shot cross-lingual SLU attracts more and more attention. Contrastive learning is widely applied to explicitly align representations of similar... | Bang Yang, Hongxiang Li, Xianwei Zhuang, Xuxin Cheng, Yuexian Zou, Zhihong Zhu |  |
| 1092 |  |  [Towards Safer Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.107) |  | 0 | The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with... | Guangyao Dou, Meng Jiang, Yijun Tian, Zhaoxuan Tan, Zheyuan Liu |  |
| 1093 |  |  [The Impact of Reasoning Step Length on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.108) |  | 0 | Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical... | Dong Shu, Haiyan Zhao, Mengnan Du, Mingyu Jin, Qinkai Yu, Wenyue Hua, Yanda Meng, Yongfeng Zhang |  |
| 1094 |  |  [Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness](https://doi.org/10.18653/v1/2024.findings-acl.109) |  | 0 | While task-agnostic debiasing provides notable generalizability and reduced reliance on downstream data, its impact on language modeling ability and the risk of relearning social biases from downstream task-specific data remain as the two most significant challenges when debiasing Pretrained... | Avrajit Ghosh, Bidhan Bashyal, Guangliang Liu, Kristen Marie Johnson, Milad Afshari, Rongrong Wang, Xitong Zhang, Zhiyu Xue |  |
| 1095 |  |  [SKGSum: Structured Knowledge-Guided Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.110) |  | 0 | A summary structure is inherent to certain types of texts according to the Genre Theory of Linguistics. Such structures aid readers in efficiently locating information within summaries. However, most existing automatic summarization methods overlook the importance of summary structure, resulting in... | Benjamin Liu, Jiamou Liu, Kaiqi Zhao, Qiqi Wang, Robert Amor, Ruofan Wang, Xianda Zheng, Zijian Huang |  |
| 1096 |  |  [Chinese Spoken Named Entity Recognition in Real-world Scenarios: Dataset and Approaches](https://doi.org/10.18653/v1/2024.findings-acl.111) |  | 0 | Spoken Named Entity Recognition (NER) aims to extract entities from speech. The extracted entities can help voice assistants better understand user’s questions and instructions. However, current Chinese Spoken NER datasets are laboratory-controlled data that are collected by reading existing texts... | Chen Gong, Lei Zhang, Min Zhang, Shilin Zhou, Yu Hong, Zhenghua Li |  |
| 1097 |  |  [DEBATE: Devil's Advocate-Based Assessment and Text Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.112) |  | 0 | As natural language generation (NLG) models have become prevalent, systematically assessing the quality of machine-generated texts has become increasingly important. Recent studies introduce LLM-based evaluators that operate as reference-free metrics, demonstrating their capability to adeptly... | Alex Kim, Keonwoo Kim, Sangwon Yoon |  |
| 1098 |  |  [Can Large Multimodal Models Uncover Deep Semantics Behind Images?](https://doi.org/10.18653/v1/2024.findings-acl.113) |  | 0 | Understanding the deep semantics of images is essential in the era dominated by social media. However, current research works primarily on the superficial description of images, revealing a notable deficiency in the systematic investigation of the inherent deep semantics. In this work, we introduce... | Heming Xia, Qingxiu Dong, Yixin Yang, Zheng Li, Zhifang Sui |  |
| 1099 |  |  [Harvesting Events from Multiple Sources: Towards a Cross-Document Event Extraction Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.114) |  | 0 | Document-level event extraction aims to extract structured event information from unstructured text. However, a single document often contains limited event information and the roles of different event arguments may be biased due to the influence of the information source.This paper addresses the... | Bobo Li, Chong Teng, Donghong Ji, Fei Li, Jun Zhou, Qiang Gao, Zixiang Meng |  |
| 1100 |  |  [A Graph per Persona: Reasoning about Subjective Natural Language Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.115) |  | 0 | Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the... | Dan Gutfreund, Eunjeong Hwang, Vered Shwartz, Veronika Thost |  |
| 1101 |  |  [MolTC: Towards Molecular Relational Modeling In Language Models](https://doi.org/10.18653/v1/2024.findings-acl.116) |  | 0 | Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities,... | Chang Wu, Junfeng Fang, Kun Wang, Shuai Zhang, Sihang Li, Wenjie Du, Xiang Wang, Zhengyi Yang, Zhiyuan Liu |  |
| 1102 |  |  [KPEval: Towards Fine-Grained Semantic-Based Keyphrase Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.117) |  | 0 | Despite the significant advancements in keyphrase extraction and keyphrase generation methods, the predominant approach for evaluation mainly relies on exact matching with human references. This scheme fails to recognize systems that generate keyphrases semantically equivalent to the references or... | Da Yin, Di Wu, KaiWei Chang |  |
| 1103 |  |  [Learning Low-dimensional Multi-domain Knowledge Graph Embedding via Dual Archimedean Spirals](https://doi.org/10.18653/v1/2024.findings-acl.118) |  | 0 | Knowledge graph embedding (KGE) is extensively employed for link prediction by representing entities and relations as low-dimensional vectors. In real-world scenarios, knowledge graphs (KGs) usually encompass diverse domains, which poses challenges to KG representations. However, existing KGE... | Fujun Zhang, Guanglai Gao, Jiang Li, Xiangdong Su |  |
| 1104 |  |  [LoRA Meets Dropout under a Unified Framework](https://doi.org/10.18653/v1/2024.findings-acl.119) |  | 0 | With the remarkable capabilities, large language models (LLMs) have emergedas essential elements in numerous NLP applications, while parameter-efficientfinetuning, especially LoRA, has gained popularity as a lightweight approachfor model customization. Meanwhile, various dropout methods, initially... | Boyang Xue, Chuan Wu, Jiyue Jiang, Liheng Chen, Lingpeng Kong, Sheng Wang |  |
| 1105 |  |  [Enhancing Text-to-SQL Parsing through Question Rewriting and Execution-Guided Refinement](https://doi.org/10.18653/v1/2024.findings-acl.120) |  | 0 | Large Language Model (LLM)-based approach has become the mainstream for Text-to-SQL task and achieves remarkable performance. In this paper, we augment the existing prompt engineering methods by exploiting the database content and execution feedback. Specifically, we introduce DART-SQL, which... | Chuanyi Liu, Cuiyun Gao, Jichuan Zeng, Jiyu Guo, Peiyi Han, Ruiqi Wang, Wenxin Mao |  |
| 1106 |  |  [The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.121) |  | 0 | Large language models often necessitate grounding on external knowledge to generate faithful and reliable answers. Yet even with the correct groundings in the reference, they can ignore them and rely on wrong groundings or their inherent biases to hallucinate when users, being largely unaware of... | Junzhou Zhao, Liangming Pan, Shuo Zhang, William Yang Wang |  |
| 1107 |  |  [ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.122) |  | 0 | Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of... | Anh Tuan Luu, Chenghao Ma, Guanting Dong, Haihong E, Haoran Luo, Meina Song, Shiyao Peng, Wei Lin, Wentai Zhang, Yifan Zhu, Yikai Guo, Zichen Tang |  |
| 1108 |  |  [Achilles-Bench: A Challenging Benchmark for Low-Resource Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.123) |  | 0 | With promising yet saturated results in high-resource settings, low-resource datasets have gradually become crucial benchmarks (e.g., BigBench Hard, superGLUE) for evaluating the learning ability of advanced neural networks. In this work, we find that there exists a set of “hard examples” in... | Chang Ma, Jingjing Xu, Lingpeng Kong, Qingxiu Dong, Yudong Wang, Zhifang Sui |  |
| 1109 |  |  [INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair](https://doi.org/10.18653/v1/2024.findings-acl.124) |  | 0 | This paper introduces INTERVENOR (INTERactiVE chaiN Of Repair), a system designed to emulate the interactive code repair processes observed in humans, encompassing both code diagnosis and code repair. INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair... | Ganqu Cui, Ge Yu, Hanbin Wang, Ning Ding, Shuo Wang, Zhenghao Liu, Zhiyuan Liu |  |
| 1110 |  |  [SocialBench: Sociality Evaluation of Role-Playing Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.125) |  | 0 | Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge and... | Chenliang Li, Fei Huang, Gao Xing, Hehong Chen, Hongzhan Chen, Ji Zhang, Ming Yan, Weizhou Shen, Wenshen Xu, Xiaojun Quan |  |
| 1111 |  |  [From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications](https://doi.org/10.18653/v1/2024.findings-acl.126) |  | 0 | Evaluating large language models (LLMs) is fundamental, particularly in the context of practical applications. Conventional evaluation methods, typically designed primarily for LLM development, yield numerical scores that ignore the user experience. Therefore, our study shifts the focus from... | Jiawei Liu, Lizhi Qing, Qikai Cheng, Wei Lu, Xiaozhong Liu, Yangyang Kang, Yongqiang Ma, Yue Zhang |  |
| 1112 |  |  [Context-Aware Tracking and Dynamic Introduction for Incomplete Utterance Rewriting in Extended Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.findings-acl.127) |  | 0 | Incomplete utterance rewriting (IUR) aims to reconstruct the utterance with omitted information and pronouns to be standalone and complete based on the context. The existing works predominantly focus on simple ellipsis and coreference problems in brief multi-turn dialogues. But in actual scenarios:... | DaqianLi DaqianLi, Liubin Wang, Qian Zhu, Qiuhui Shi, Xinnan Guo, Xuan Lin, Yongrui Chen |  |
| 1113 |  |  [EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.128) |  | 0 | Emotional intelligence in large language models (LLMs) is of great importance in Natural Language Processing. However, the previous research mainly focus on basic sentiment analysis tasks, such as emotion recognition, which is not enough to evaluate LLMs’ overall emotional intelligence. Therefore,... | Sijia Liu, Songzhou Yan, Yanghua Xiao, Yueze Li, Yuyan Chen |  |
| 1114 |  |  [Plum: Prompt Learning using Metaheuristics](https://doi.org/10.18653/v1/2024.findings-acl.129) |  | 0 | Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering... | Jipeng Zhang, Kashun Shum, Renjie Pi, Rui Pan, Shizhe Diao, Shuo Xing, Tong Zhang, Wenhe Sun, Xiang Liu |  |
| 1115 |  |  [HOTVCOM: Generating Buzzworthy Comments for Videos](https://doi.org/10.18653/v1/2024.findings-acl.130) |  | 0 | In the era of social media video platforms, popular “hot-comments” play a crucial role in attracting user impressions of short-form videos, making them vital for marketing and branding purpose. However, existing research predominantly focuses on generating descriptive comments or “danmaku” in... | Jiyuan Jia, Qingpei Guo, Songzhou Yan, Yanghua Xiao, Yuyan Chen, Zhixu Li |  |
| 1116 |  |  [Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?](https://doi.org/10.18653/v1/2024.findings-acl.131) |  | 0 | The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs’... | Jiaqing Liang, Sijia Liu, Songzhou Yan, Yanghua Xiao, Yueze Li, Yuyan Chen |  |
| 1117 |  |  [Distilling Robustness into Natural Language Inference Models with Domain-Targeted Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.132) |  | 0 | Knowledge distillation optimises a smaller student model to behave similarly to a larger teacher model, retaining some of the performance benefits. While this method can improve results on in-distribution examples, it does not necessarily generalise to out-of-distribution (OOD) settings. We... | Joe Stacey, Marek Rei |  |
| 1118 |  |  [Into the Unknown: Generating Geospatial Descriptions for New Environments](https://doi.org/10.18653/v1/2024.findings-acl.133) |  | 0 | Similar to vision-and-language navigation (VLN) tasks that focus on bridging the gap between vision and language for embodied navigation, the new Rendezvous (RVS) task requires reasoning over allocentric spatial relationships using non-sequential navigation instructions and maps. However,... | Jason Baldridge, John Palowitch, Reut Tsarfaty, Sayali Kulkarni, Tzuf PazArgaman |  |
| 1119 |  |  [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.134) |  | 0 | Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability... | Avi Caciularu, Idan Szpektor, Kris Cao, Matan Eyal, Omer Goldman, Reut Tsarfaty |  |
| 1120 |  |  [Length-aware Byte Pair Encoding for Mitigating Over-segmentation in Korean Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.135) |  | 0 | Byte Pair Encoding is an effective approach in machine translation across several languages. However, our analysis indicates that BPE is prone to over-segmentation in the morphologically rich language, Korean, which can erode word semantics and lead to semantic confusion during training. This... | Chanjun Park, Heuiseok Lim, Hyeonseok Moon, Hyunwoong Ko, Jaehyung Seo, Jungseob Lee, Seungjun Lee, Seungyoon Lee, Sugyeong Eo |  |
| 1121 |  |  [Multilingual Instruction Tuning With Just a Pinch of Multilinguality](https://doi.org/10.18653/v1/2024.findings-acl.136) |  | 0 | As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across... | Idan Szpektor, Jonathan Herzig, Matan Eyal, Reut Tsarfaty, Roee Aharoni, Uri Shaham |  |
| 1122 |  |  [M3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation](https://doi.org/10.18653/v1/2024.findings-acl.137) |  | 0 | In this paper, we introduce a new embedding model called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It provides a uniform support for the semantic retrieval of more than 100 working languages. It can simultaneously... | Defu Lian, Jianlyu Chen, Kun Luo, Peitian Zhang, Shitao Xiao, Zheng Liu |  |
| 1123 |  |  [Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback](https://doi.org/10.18653/v1/2024.findings-acl.138) |  | 0 | Large Language Models (LLMs) have shown remarkable progress in automated code generation. Yet, LLM-generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must... | Batu Guan, Fangxin Lu, Hai Jin, Hongyu Zhang, Xuanhua Shi, Yao Wan, Yulei Sui, Zhangqian Bi, Zheng Wang, Zili Zhang |  |
| 1124 |  |  [An Element is Worth a Thousand Words: Enhancing Legal Case Retrieval by Incorporating Legal Elements](https://doi.org/10.18653/v1/2024.findings-acl.139) |  | 0 | Legal case retrieval plays an important role in promoting judicial justice and fairness. One of its greatest challenges is that the definition of relevance goes far beyond the common semantic relevance as in ad-hoc retrieval. In this paper, we reveal that the legal elements, which typically... | Chenlong Deng, Kelong Mao, Peitian Zhang, Yujia Zhou, Zhicheng Dou |  |
| 1125 |  |  [SoMeLVLM: A Large Vision Language Model for Social Media Processing](https://doi.org/10.18653/v1/2024.findings-acl.140) |  | 0 | The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks... | Hanjia Lyu, Haoyu Kuang, Jiebo Luo, Kun Wu, Siming Chen, Xinnong Zhang, Xinyi Mou, Xuanjing Huang, Zhongyu Wei |  |
| 1126 |  |  [KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.141) |  | 0 | The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs against socially acceptable commonsense standards in... | Chanjun Park, Heuiseok Lim, Jaehyung Seo, Jaewook Lee, Seongtae Hong, Seungjun Lee |  |
| 1127 |  |  [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.142) |  | 0 | Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at... | Amit Dhurandhar, Aurélie C. Lozano, Georgios Kollias, Payel Das, Ronny Luss, Soham Dan, Tejaswini Pedapati |  |
| 1128 |  |  [Ranking Large Language Models without Ground Truth](https://doi.org/10.18653/v1/2024.findings-acl.143) |  | 0 | Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In... | Amit Dhurandhar, Elizabeth Daly, Karthikeyan Natesan Ramamurthy, Moninder Singh, Rahul Nair |  |
| 1129 |  |  [Integrating Physician Diagnostic Logic into Large Language Models: Preference Learning from Process Feedback](https://doi.org/10.18653/v1/2024.findings-acl.144) |  | 0 | The utilization of large language models for medical dialogue generation has attracted considerable attention due to its potential to enhance response richness and coherence. While previous studies have made strides in optimizing model performance, there is a pressing need to bolster the model’s... | Chengfeng Dou, Haiyan Zhao, Wenpin Jiao, Ying Zhang, Yongqiang Zhao, Zhengwei Tao, Zhi Jin |  |
| 1130 |  |  [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://doi.org/10.18653/v1/2024.findings-acl.145) |  | 0 | The pre-trained language models are continually fine-tuned to better support downstream applications. However, this operation may result in significant performance degeneration on general tasks beyond the targeted domain. To overcome this problem, we propose LM-Cocktail which enables the fine-tuned... | Peitian Zhang, Shitao Xiao, Xingrun Xing, Zheng Liu |  |
| 1131 |  |  [Episodic Memory Retrieval from LLMs: A Neuromorphic Mechanism to Generate Commonsense Counterfactuals for Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.146) |  | 0 | Large language models (LLMs) have achieved satisfactory performance in counterfactual generation. However, confined by the stochastic generation process of LLMs, there often are misalignments between LLMs and humans which hinder LLMs from handling complex tasks like relation extraction. As a... | Shen Zhou, Tieyun Qian, Xin Miao, Yongqi Li |  |
| 1132 |  |  [SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages](https://doi.org/10.18653/v1/2024.findings-acl.147) |  | 0 | Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader... | Abinew Ali Ayele, Alham Fikri Aji, Chris Biemann, Christine de Kock, Genet Shanko Dekebo, Genta Indra Winata, Gopichand Kanumolu, Hailegnaw Getaneh Tilaye, Ibrahim Said Ahmad, Idris Abdulmumin, Krishnapriya Vishnubhotla, Lokesh Madasu, Manish Shrivastava, Meriem Beloucif, Mohamed Abdalla, Nedjma Ousidhoum, Nirmal Surange, Oumaima Hourrane, Pavan Baswani, Saif M. Mohammad, Samuel Rutunda, Sanchit Ahuja, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad, Sofia Bourhim, Thamar Solorio, Vladimir Araujo |  |
| 1133 |  |  [Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector](https://doi.org/10.18653/v1/2024.findings-acl.148) |  | 0 | Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models,... | Haihui Yang, Xiaojun Quan |  |
| 1134 |  |  [VISPool: Enhancing Transformer Encoders with Vector Visibility Graph Neural Networks](https://doi.org/10.18653/v1/2024.findings-acl.149) |  | 0 | The emergence of transformers has revolutionized natural language processing (NLP), as evidenced in various NLP tasks. While graph neural networks (GNNs) show recent promise in NLP, they are not standalone replacements for transformers. Rather, recent research explores combining transformers and... | Arda C. Aras, Aykut Koç, Tuna Alikasifoglu |  |
| 1135 |  |  [The Emotion Dynamics of Literary Novels](https://doi.org/10.18653/v1/2024.findings-acl.150) |  | 0 | Stories are rich in the emotions they exhibit in their narratives and evoke in the readers. The emotional journeys of the various characters within a story are central to their appeal. Computational analysis of the emotions of novels, however, has rarely examined the variation in the emotional... | Adam Hammond, Graeme Hirst, Krishnapriya Vishnubhotla, Saif M. Mohammad |  |
| 1136 |  |  [Accurate and Nuanced Open-QA Evaluation Through Textual Entailment](https://doi.org/10.18653/v1/2024.findings-acl.151) |  | 0 | Open-domain question answering (Open-QA) is a common task for evaluating large language models (LLMs). However, current Open-QA evaluations are criticized for the ambiguity in questions and the lack of semantic understanding in evaluators. Complex evaluators, powered by foundation models or LLMs... | Denilson Barbosa, Peiran Yao |  |
| 1137 |  |  [Dictionary-Aided Translation for Handling Multi-Word Expressions in Low-Resource Languages](https://doi.org/10.18653/v1/2024.findings-acl.152) |  | 0 | Multi-word expressions (MWEs) present unique challenges in natural language processing (NLP), particularly within the context of translation systems, due to their inherent scarcity, non-compositional nature, and other distinct lexical and morphosyntactic characteristics, issues that are exacerbated... | Antonios Anastasopoulos, Antonios Dimakis, Stella Markantonatou |  |
| 1138 |  |  [LANS: A Layout-Aware Neural Solver for Plane Geometry Problem](https://doi.org/10.18653/v1/2024.findings-acl.153) |  | 0 | Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion, and reasoning. Existing neural solvers take GPS as a vision-language task but are short in the representation of geometry diagrams that carry rich and complex layout information.... | ChengLin Liu, Fei Yin, MingLiang Zhang, Zhongzhi Li |  |
| 1139 |  |  [Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.154) |  | 0 | We propose Knowledge Crosswords, a geometric knowledge reasoning benchmark consisting of incomplete knowledge networks bounded by structured factual constraints, where LLMs are tasked with inferring the missing facts to meet all constraints. The novel setting of geometric knowledge reasoning... | Shangbin Feng, Tianxing He, Vidhisha Balachandran, Wenxuan Ding, Yuhan Liu, Yulia Tsvetkov, Zhaoxuan Tan |  |
| 1140 |  |  [DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection](https://doi.org/10.18653/v1/2024.findings-acl.155) |  | 0 | Large language models are limited by challenges in factuality and hallucinations to be directly employed off-the-shelf for judging the veracity of news articles, where factual accuracy is paramount. In this work, we propose DELL that identifies three key stages in misinformation detection where... | Heng Wang, Herun Wan, Minnan Luo, Shangbin Feng, Yulia Tsvetkov, Zhaoxuan Tan |  |
| 1141 |  |  [The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts](https://doi.org/10.18653/v1/2024.findings-acl.156) |  | 0 | As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to... | Boyuan Zheng, Daniel Khashabi, Haoran Xu, Jingyu Zhang, Lingfeng Shen, Philipp Koehn, Sihao Chen, Weiting Tan, Yunmo Chen |  |
| 1142 |  |  [Self-Specialization: Uncovering Latent Expertise within Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.157) |  | 0 | Recent works have demonstrated the effectiveness of self-alignment in which a large language model is aligned to follow general instructions using instructional data generated from the model itself starting from a handful of human-written seeds. Instead of general alignment, in this work, we focus... | Alan Ritter, David D. Cox, Hongyin Luo, Jacob A. Hansen, James R. Glass, Junmo Kang, Leonid Karlinsky, Rogério Feris, Yada Zhu |  |
| 1143 |  |  [FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion](https://doi.org/10.18653/v1/2024.findings-acl.158) |  | 0 | Taxonomy Expansion, which relies on modeling concepts and concept relations, can be formulated as a set representation learning task. The generalization of set, fuzzy set, incorporates uncertainty and measures the information within a semantic concept, making it suitable for concept modeling.... | Fred Xu, Shichang Zhang, Song Jiang, Xiao Luo, Yizhou Sun, Yuanzhou Chen, Zijie Huang |  |
| 1144 |  |  [Chain of Logic: Rule-Based Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.159) |  | 0 | Rule-based reasoning, a fundamental type of legal reasoning, enables us to draw conclusions by accurately applying a rule to a set of facts. We explore causal language models as rule-based reasoners, specifically with respect to compositional rules - rules consisting of multiple elements which form... | Joe Barrow, Kristian J. Hammond, Rajiv Jain, Sergio Servantez |  |
| 1145 |  |  [Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations](https://doi.org/10.18653/v1/2024.findings-acl.160) |  | 0 | Long-form generations from large language models (LLMs) contain a mix of factual and non-factual claims, making evaluating factuality difficult.Prior works evaluate the factuality of a long paragraph by decomposing it into multiple facts, verifying those facts independently, and aggregating the... | ChengHan Chiang, Hungyi Lee |  |
| 1146 |  |  [Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment](https://doi.org/10.18653/v1/2024.findings-acl.161) |  | 0 | Do LMs infer the semantics of text from co-occurrence patterns in their training data? Merrill et al. (2022) argue that, in theory, sentence co-occurrence probabilities predicted by an optimal LM should reflect the entailment relationship of the constituent sentences, but it is unclear whether... | Norihito Naka, Tal Linzen, William Merrill, Yoon Kim, Zhaofeng Wu |  |
| 1147 |  |  [Simulated Misinformation Susceptibility (SMISTS): Enhancing Misinformation Research with Large Language Model Simulations](https://doi.org/10.18653/v1/2024.findings-acl.162) |  | 0 | Psychological inoculation, a strategy designed to build resistance against persuasive misinformation, has shown efficacy in curbing its spread and mitigating its adverse effects at early stages. Despite its effectiveness, the design and optimization of these inoculations typically demand... | Aram Moossavi, Chunyuan Deng, Diyi Yang, Lili Wang, Soroush Vosoughi, Weicheng Ma |  |
| 1148 |  |  [Social Intelligence Data Infrastructure: Structuring the Present and Navigating the Future](https://doi.org/10.18653/v1/2024.findings-acl.163) |  | 0 | As Natural Language Processing (NLP) systems become increasingly integrated into human social life, these technologies will need to increasingly rely on social intelligence. Although there are many valuable datasets that benchmark isolated dimensions of social intelligence, there does not yet exist... | Caleb Ziems, Diyi Yang, Minzhi Li, Weiyan Shi |  |
| 1149 |  |  [Selective Prefix Tuning for Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.164) |  | 0 | The prevalent approach for optimizing pre-trained language models in downstream tasks is fine-tuning. However, it is both time-consuming and memory-inefficient. In response, a more efficient method called Prefix Tuning, which insert learnable vectors into each Transformer layers, has been proposed... | Hai Zhao, Hongyi Zhang, Ping Wang, Zuchao Li |  |
| 1150 |  |  [MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization](https://doi.org/10.18653/v1/2024.findings-acl.165) |  | 0 | The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We... | Soroush Vosoughi, Xiaobo Guo |  |
| 1151 |  |  [Non-compositional Expression Generation and its Continual Learning](https://doi.org/10.18653/v1/2024.findings-acl.166) |  | 0 | Non-compositional expressions are an integral part of natural language and their meanings cannot be directly derived from the meanings of their component words. Recent work has shown how their processing remains a challenge for pre-trained language models. Here we consider the fact that prior... | Jianing Zhou, Suma Bhat |  |
| 1152 |  |  [Medical Dialogue System: A Survey of Categories, Methods, Evaluation and Challenges](https://doi.org/10.18653/v1/2024.findings-acl.167) |  | 0 | This paper surveys and organizes research works of medical dialog systems, which is an important yet challenging task. Although these systems have been surveyed in the medical community from an application perspective, a systematic review from a rigorous technical perspective has to date remained... | Hongru Wang, Jie Xu, Li Du, Shaoting Zhang, Tong Ruan, Xiaofan Zhang, Xiaoming Shi, Yuhang Guo, Yuxuan Wang, Zeming Liu |  |
| 1153 |  |  [Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.168) |  | 0 | Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this... | Dinh Phung, Fatemeh Shiri, Gholamreza Haffari, Linhao Luo, Thi Nguyen, ThuyTrang Vu, YuanFang Li |  |
| 1154 |  |  [Comprehensive Abstractive Comment Summarization with Dynamic Clustering and Chain of Thought](https://doi.org/10.18653/v1/2024.findings-acl.169) |  | 0 | Real-world news comments pose a significant challenge due to their noisy and ambiguous nature, which complicates their modeling for clustering and summarization tasks. Most previous research has predominantly focused on extractive summarization methods within specific constraints. This paper... | AiTi Aw, Bowei Zou, Jacintha Yi, Longyin Zhang |  |
| 1155 |  |  [Self-Supervised Position Debiasing for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.170) |  | 0 | Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Previous works have proven that LLMs are prone to exhibit... | Mengqi Zhang, Pengjie Ren, Zhaochun Ren, Zheng Chen, Zhongkun Liu, Zhumin Chen |  |
| 1156 |  |  [HyperCL: A Contrastive Learning Framework for Hyper-Relational Knowledge Graph Embedding with Hierarchical Ontology](https://doi.org/10.18653/v1/2024.findings-acl.171) |  | 0 |  | Dingqi Yang, Weijian Yu, Xin Jing, Yuhuan Lu |  |
| 1157 |  |  [Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection](https://doi.org/10.18653/v1/2024.findings-acl.172) |  | 0 | Multifaceted ideology detection (MID) aims to detect the ideological leanings of texts towards multiple facets. Previous studies on ideology detection mainly focus on one generic facet and ignore label semantics and explanatory descriptions of ideologies, which are a kind of instructive information... | Bang Wang, Han Xu, Minghua Xu, Songtao Liu, Wei Xiang |  |
| 1158 |  |  [Character-Level Chinese Dependency Parsing via Modeling Latent Intra-Word Structure](https://doi.org/10.18653/v1/2024.findings-acl.173) |  | 0 | Revealing the syntactic structure of sentences in Chinese poses significant challenges for word-level parsers due to the absence of clear word boundaries. To facilitate a transition from word-level to character-level Chinese dependency parsing, this paper proposes modeling latent internal... | Yang Hou, Zhenghua Li |  |
| 1159 |  |  [AlignRE: An Encoding and Semantic Alignment Approach for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.174) |  | 0 | Zero-shot Relation Extraction (ZSRE) aims to predict unseen relations between entity pairs from input sentences. Existing prototype-based ZSRE methods encode relation descriptions into prototype embeddings and predict by measuring the similarity between sentence embeddings and prototype embeddings.... | Fu Zhang, Jingwei Cheng, Zehan Li |  |
| 1160 |  |  [Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction](https://doi.org/10.18653/v1/2024.findings-acl.175) |  | 0 | Supervised fine-tuning (SFT) on instruction-following corpus is a crucial approach toward the alignment of large language models (LLMs). However, the performance of LLMs on standard knowledge and reasoning benchmarks tends to suffer from deterioration at the latter stage of the SFT process, echoing... | Deng Cai, Lemao Liu, Rui Yan, Shuming Shi, Tingchen Fu |  |
| 1161 |  |  [Efficient Knowledge Infusion via KG-LLM Alignment](https://doi.org/10.18653/v1/2024.findings-acl.176) |  | 0 | To tackle the problem of domain-specific knowledge scarcity within large language models (LLMs), knowledge graph-retrievalaugmented method has been proven to be an effective and efficient technique for knowledge infusion. However, existing approaches face two primary challenges: knowledge mismatch... | Hui Cai, Jun Xu, Ling Zhong, Mengshu Sun, Rui Sun, Shuhan Luo, Zhiqiang Zhang, Zhouyu Jiang |  |
| 1162 |  |  [Towards Precise Localization of Critical Errors in Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.177) |  | 0 | The advent of large language models has experienced a remarkable improvement in the field of machine translation. However, machine translation is still vulnerable to critical meaning deviations, which may incur catastrophic issues in social or ethical contexts. In particular, existing critical... | Dahyun Jung, Heuiseok Lim, Sugyeong Eo |  |
| 1163 |  |  [LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.178) |  | 0 | Large Language Models (LLMs), such as LLaMA and T5, have shown exceptional performance across various tasks through fine-tuning. Although low-rank adaption (LoRA) has emerged to cheaply fine-tune these LLMs on downstream tasks, their deployment is still hindered by the vast model scale and... | Bohan Zhuang, Chunhua Shen, Hao Chen, Linlin Ou, Mingyang Zhang, Xinyi Yu, Zhen Yang |  |
| 1164 |  |  [Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.179) |  | 0 | The recent advancements in large language models (LLMs) have been extraordinary, yet the escalating inference costs associated with them present challenges in real-world applications. To address these challenges, we propose a novel approach called Early-exiting Speculative Decoding (EESD) with... | Jiahao Liu, Jingang Wang, Qifan Wang, Xunliang Cai |  |
| 1165 |  |  [Towards Better Utilization of Multi-Reference Training Data for Chinese Grammatical Error Correction](https://doi.org/10.18653/v1/2024.findings-acl.180) |  | 0 | For the grammatical error correction (GEC) task, there usually exist multiple correction ways for an erroneous input sentence, leading to multiple references. Observing the high proportion of multi-reference instances in Chinese GEC training data, we target a systematic study on how to better... | Bo Zhang, Chen Li, Haochen Jiang, Ji Zhang, Yumeng Liu, Zhenghua Li |  |
| 1166 |  |  [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://doi.org/10.18653/v1/2024.findings-acl.181) |  | 0 | Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs... | Aohan Zeng, Bowen Wang, Jie Tang, Mingdao Liu, Rui Lu, Xiao Liu, Yuxiao Dong |  |
| 1167 |  |  [Transition-based Opinion Generation for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.182) |  | 0 | Recently, the use of pre-trained generation models for extracting sentiment elements has resulted in significant advancements in aspect-based sentiment analysis benchmarks. However, these approaches often overlook the importance of explicitly modeling structure among sentiment elements. To address... | Guodong Zhou, Tianlai Ma, Zhongqing Wang |  |
| 1168 |  |  [Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion](https://doi.org/10.18653/v1/2024.findings-acl.183) |  | 0 | Dynamic topic models track the evolution of topics in sequential documents, which have derived various applications like trend analysis. However, existing models suffer from repetitive topic and unassociated topic issues, failing to reveal the evolution and hindering further applications. To... | Anh Tuan Luu, Liangming Pan, Thong Nguyen, Xiaobao Wu, Xinshuai Dong |  |
| 1169 |  |  [A Chinese Dataset for Evaluating the Safeguards in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.184) |  | 0 | Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks. Previous studies have proposed comprehensive taxonomies of LLM risks, as well as corresponding prompts that can be used to examine LLM safety. However, the focus has... | Angela Zhao, Haonan Li, Preslav Nakov, Shom Lin, Timothy Baldwin, Xudong Han, Yuxia Wang, Zenan Zhai, Zhenxuan Zhang |  |
| 1170 |  |  [LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction](https://doi.org/10.18653/v1/2024.findings-acl.185) |  | 0 | Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting... | Hiroki Sakaji, Kiyoshi Izumi, Meiyun Wang |  |
| 1171 |  |  [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://doi.org/10.18653/v1/2024.findings-acl.186) |  | 0 | Autonomous graphical user interface (GUI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To... | Aston Zhang, Zhuosheng Zhang |  |
| 1172 |  |  [SP³: Enhancing Structured Pruning via PCA Projection](https://doi.org/10.18653/v1/2024.findings-acl.187) |  | 0 |  | Chen Zhao, Cuiping Li, Hong Chen, Jing Zhang, Xiaodong Chen, Yuxuan Hu, Zhe Zhao |  |
| 1173 |  |  [GENDEX: Generative Data Augmentation Strategy Leveraging External Data for Abstractive Dialogue Summarization](https://doi.org/10.18653/v1/2024.findings-acl.188) |  | 0 | With the proliferation of digital communication, dialogue summarization has become increasingly important. However, it still faces a shortage of data. To address this issue, we developed \*\*Gen\*\*erative \*\*D\*\*ata Augmentation Strategy Leveraging \*\*Ex\*\*ternal Data for Abstractive Dialogue... | Dongha Choi, Hongseok Choi, Hyunju Lee, Sangwon Park |  |
| 1174 |  |  [Concept-Best-Matching: Evaluating Compositionality In Emergent Communication](https://doi.org/10.18653/v1/2024.findings-acl.189) |  | 0 | Artificial agents that learn to communicate in order to accomplish a given task acquire communication protocols that are typically opaque to a human. A large body of work has attempted to evaluate the emergent communication via various evaluation measures, with \*\*compositionality\*\* featuring as... | Boaz Carmeli, Ron Meir, Yonatan Belinkov |  |
| 1175 |  |  [A Tale of Two Revisions: Summarizing Changes Across Document Versions](https://doi.org/10.18653/v1/2024.findings-acl.190) |  | 0 | Document revision is a crucial aspect of the writing process, particularly in collaborative environments where multiple authors contribute simultaneously. However, current tools lack an efficient way to provide a comprehensive overview of changes between versions, leading to difficulties in... | Apoorv Saxena, Natwar Modani, T. Y. S. S. Santosh |  |
| 1176 |  |  [Refine, Align, and Aggregate: Multi-view Linguistic Features Enhancement for Aspect Sentiment Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.191) |  | 0 | Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplets of aspect terms, their associated sentiment and opinion terms. Previous works based on different modeling paradigms have achieved promising results. However, these methods struggle to comprehensively explore the various... | Guixin Su, Mingmin Wu, Tongguan Wang, Ying Sha, Yongcheng Zhang, Yuxue Hu, Zhongqiang Huang |  |
| 1177 |  |  [Pro-Woman, Anti-Man? Identifying Gender Bias in Stance Detection](https://doi.org/10.18653/v1/2024.findings-acl.192) |  | 0 | Gender bias has been widely observed in NLP models, which has the potential to perpetuate harmful stereotypes and discrimination. In this paper, we construct a dataset GenderStance of 36k samples to measure gender bias in stance detection, determining whether models consistently predict the same... | Yingjie Li, Yue Zhang |  |
| 1178 |  |  [Likelihood-based Mitigation of Evaluation Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.193) |  | 0 | Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics.However, the likelihood, a measure of LLM’s plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure.It is therefore... | Masahiro Kaneko, Masanari Ohi, Mengsay Loem, Naoaki Okazaki, Ryuto Koike |  |
| 1179 |  |  [The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.194) |  | 0 | Benchmark plays a pivotal role in assessing the advancements of large language models (LLMs). While numerous benchmarks have been proposed to evaluate LLMs’ capabilities, there is a notable absence of a dedicated benchmark for assessing their musical abilities. To address this gap, we present... | Chenchong Chenchong, Hai Zhao, Jiajia Li, Lu Yang, Mingni Tang, Ping Wang, Zuchao Li |  |
| 1180 |  |  [PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference](https://doi.org/10.18653/v1/2024.findings-acl.195) |  | 0 | Large Language Models (LLMs) have shown remarkable comprehension abilities but face challenges in GPU memory usage during inference, hindering their scalability for real-time applications like chatbots. To accelerate inference, we store computed keys and values (KV cache) in the GPU memory.... | Dongjie Yang, Hai Zhao, Shilin Zhang, Xiaodong Han, Yan Gao, Yao Hu |  |
| 1181 |  |  [From Role-Play to Drama-Interaction: An LLM Solution](https://doi.org/10.18653/v1/2024.findings-acl.196) |  | 0 | Drama is a form of storytelling inspired by human creativity, proceeding with a predefined storyline, carrying emotions and thoughts.This paper introduces LLM-based interactive drama, which endows traditional drama with an unprecedented immersion, where a person is allowed to walk into it and... | Hai Zhao, Hongqiu Wu, Lai Jiang, Min Zhang, Weiqi Wu, Xingyuan Liu |  |
| 1182 |  |  [TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.197) |  | 0 | While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users’ narrative... | Gunhee Kim, Hwaran Lee, Jaewoo Ahn, JinHwa Kim, Junyoung Lim, Sangdoo Yun, Taehyun Lee |  |
| 1183 |  |  [Red Teaming Visual Language Models](https://doi.org/10.18653/v1/2024.findings-acl.198) |  | 0 | VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar... | Lei Li, Masood Ahmed, Mukai Li, Qi Liu, Yuwei Yin, Zhenguang Liu |  |
| 1184 |  |  [Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach](https://doi.org/10.18653/v1/2024.findings-acl.199) |  | 0 | A Large Language Model (LLM) tends to generate inconsistent and sometimes contradictory outputs when presented with a prompt that has equivalent semantics but is expressed differently from the original prompt. To achieve semantic consistency of an LLM, one of the key approaches is to finetune the... | Dapeng Chen, Jingyuan Yang, Rongjun Li, Wei Peng, Yajing Sun, Zhiyong Feng |  |
| 1185 |  |  [Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments](https://doi.org/10.18653/v1/2024.findings-acl.200) |  | 0 | In embodied instruction-following (EIF), the integration of pretrained language models (LMs) as task planners emerges as a significant branch, where tasks are planned at the skill level by prompting LMs with pretrained skills and user instructions. However, grounding these pretrained skills in... | Honguk Woo, Moontae Lee, Sangwoo Shin, Seunghyun Kim, Youngsoo Jang |  |
| 1186 |  |  [LIRE: listwise reward enhancement for preference alignment](https://doi.org/10.18653/v1/2024.findings-acl.201) |  | 0 | Recently, tremendous strides have been made to align the generation of Large Language Models (LLMs) with human values to mitigate toxic or unhelpful content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves effective and is widely adopted by researchers. However, implementing... | Junbo Guo, Lei Zhang, Mingye Zhu, Yi Liu, Zhendong Mao |  |
| 1187 |  |  [See It All: Contextualized Late Aggregation for 3D Dense Captioning](https://doi.org/10.18653/v1/2024.findings-acl.202) |  | 0 | 3D dense captioning is a task to localize objects in a 3D scene and generate descriptive sentences for each object. Recent approaches in 3D dense captioning have adopted transformer encoder-decoder frameworks from object detection to build an end-to-end pipeline without hand-crafted components.... | Bumsoo Kim, Gunhee Kim, Hyung Lim, Minjung Kim, Seung Hwan Kim, Soonyoung Lee |  |
| 1188 |  |  [DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.203) |  | 0 | Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning autonomous language agents in various real-life applications. To improve the neural-symbolic reasoning capabilities of language agents powered by Large Language Models (LLMs) in KGQA, we propose the... | Haishuo Fang, Iryna Gurevych, Xiaodan Zhu |  |
| 1189 |  |  [GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment](https://doi.org/10.18653/v1/2024.findings-acl.204) |  | 0 | The burgeoning size of Large Language Models (LLMs) has led to enhanced capabilities in generating responses, albeit at the expense of increased inference times and elevated resource demands. Existing methods of acceleration, predominantly hinged on knowledge distillation, generally necessitate... | Hai Zhao, Yao Yao, Zuchao Li |  |
| 1190 |  |  [Compositional Generalization with Grounded Language Models](https://doi.org/10.18653/v1/2024.findings-acl.205) |  | 0 | Grounded language models use external sources of information, such as knowledge graphs, to meet some of the general challenges associated with pre-training. By extending previous work on compositional generalization in semantic parsing, we allow for a controlled evaluation of the degree to which... | Egor V. Kostylev, Erik Velldal, Lilja Øvrelid, Lucas Georges Gabriel Charpentier, Sondre Wold, Étienne Simon |  |
| 1191 |  |  [Rethinking Negative Instances for Generative Named Entity Recognition](https://doi.org/10.18653/v1/2024.findings-acl.206) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric... | Juntao Li, Min Zhang, Pinzheng Wang, Yan Bowen, Yuyang Ding, Zecheng Tang |  |
| 1192 |  |  [WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.207) |  | 0 | Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. This study reveals a... | Chenhui Hu, Jun Zhao, Kang Liu, Pengfei Cao, Yubo Chen |  |
| 1193 |  |  [DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference](https://doi.org/10.18653/v1/2024.findings-acl.208) |  | 0 | Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have... | Deyu Zhou, Guoqiang Xu, Jialong Wu, Linhai Zhang |  |
| 1194 |  |  [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.209) |  | 0 | Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning... | Deyu Zhou, Guoqiang Xu, Jialong Wu, Linhai Zhang |  |
| 1195 |  |  [How Much Does Nonverbal Communication Conform to Entropy Rate Constancy?: A Case Study on Listener Gaze in Interaction](https://doi.org/10.18653/v1/2024.findings-acl.210) |  | 0 | According to the Entropy Rate Constancy (ERC) principle, the information density of a text is approximately constant over its length. Whether this principle also applies to nonverbal communication signals is still under investigation. We perform empirical analyses of video-recorded dialogue data... | Gabriel Skantze, Hendrik Buschmeier, Yang Xu, Yu Wang |  |
| 1196 |  |  [Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.211) |  | 0 | This study investigates how Large Language Models (LLMs) leverage source and reference data in machine translation evaluation task, aiming to better understand the mechanisms behind their remarkable performance in this task.We design the controlled experiments across various input modes and model... | Jiajun Chen, Shujian Huang, Xiang Geng, Xu Huang, Yichao Du, Zhirui Zhang |  |
| 1197 |  |  [Chain-of-Verification Reduces Hallucination in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.212) |  | 0 | Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method... | Asli Celikyilmaz, Jason Weston, Jing Xu, Mojtaba Komeili, Roberta Raileanu, Shehzaad Dhuliawala, Xian Li |  |
| 1198 |  |  [Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method](https://doi.org/10.18653/v1/2024.findings-acl.213) |  | 0 | Bargaining is an important and unique part of negotiation between humans. As LLM-driven agents learn to negotiate and act like real humans, how to evaluate agents’ bargaining abilities remains an open problem.For the first time, we formally described the Bargaining task as an asymmetric incomplete... | Rui Wang, Tian Xia, Tong Ren, Yang Yang, Yibo Miao, Zhiwei He, Zhuosheng Zhang |  |
| 1199 |  |  [DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories](https://doi.org/10.18653/v1/2024.findings-acl.214) |  | 0 | How to evaluate the coding abilities of Large Language Models (LLMs) remains an open question. We find that existing benchmarks are poorly aligned with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs.To address the knowledge gap, we propose a new benchmark... | Bin Gu, Binhua Li, Fei Huang, Ge Li, Hao Zhu, Huanyu Liu, Jia Li, Jiazheng Ding, Kaibo Liu, Lanshen Wang, Lecheng Wang, Mengfei Yang, Xuanming Zhang, Yihong Dong, Yongbin Li, Yongmin Li, Yunfei Zhao, Yuqi Zhu, Zheng Fang, Zhi Jin |  |
| 1200 |  |  [LPNL: Scalable Link Prediction with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.215) |  | 0 | Exploring the application of large language models (LLMs) to graph learning is an emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to graph learning with LLMs. This work focuses on the link prediction task and introduces \*\*LPNL\*\*... | Baolong Bi, Lingrui Mei, Shenghua Liu, Xueqi Cheng, Yiwei Wang |  |
| 1201 |  |  [Aligning Speech Segments Beyond Pure Semantics](https://doi.org/10.18653/v1/2024.findings-acl.216) |  | 0 | Multilingual parallel data for speech-to-speech translation is scarce and expensive to create from scratch. This is all the more true for expressive speech translation, which aims at preserving not only the semantics, but also the overall prosody (e.g. style, emotion, rate-of-speech). Existing... | Alexandre Mourachko, Artyom Kozhevnikov, Holger Schwenk, Kevin Heffernan, Loïc Barrault |  |
| 1202 |  |  [Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives](https://doi.org/10.18653/v1/2024.findings-acl.217) |  | 0 | Humans use multiple senses to comprehend the environment. Vision and language are two of the most vital senses since they allow us to easily communicate our thoughts and perceive the world around us. There has been a lot of interest in creating video-language understanding systems with human-like... | Anh Tuan Luu, CongDuy Nguyen, Jay Zhangjie Wu, Junbin Xiao, Leigang Qu, SeeKiong Ng, Thong Nguyen, Yi Bin, Yicong Li |  |
| 1203 |  |  [Generative Input: Towards Next-Generation Input Methods Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.218) |  | 0 | Since the release of ChatGPT, generative models have achieved tremendous success and become the de facto approach for various NLP tasks. However, its application in the field of input methods remains under-explored. Many neural network approaches have been applied to the construction of Chinese... | Enhong Chen, Keyu Ding, Yongcan Wang, Zhenzhen Jia, Zihang Xu |  |
| 1204 |  |  [A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential](https://doi.org/10.18653/v1/2024.findings-acl.219) |  | 0 | Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, “generate-then-read” pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although... | Bo Wang, Jiahao Ying, Peng Zhou, Wei Tang, Yixin Cao, Yong Liao, Yuyue Zhao |  |
| 1205 |  |  [Functional Overlap Reranking for Neural Code Generation](https://doi.org/10.18653/v1/2024.findings-acl.220) |  | 0 | Code Large Language Models (CodeLLMs) have ushered in a new era in code generation advancements. However, selecting the best code solutions from all possible CodeLLM outputs remains a challenge. Previous methods often overlooked the intricate functional similarities and interactions between... | Hung To, Minh Nguyen, Nghi Bui |  |
| 1206 |  |  [Adversarial Preference Optimization: Enhancing Your Alignment via RM-LLM Game](https://doi.org/10.18653/v1/2024.findings-acl.221) |  | 0 | Human preference alignment is essential to improve the interaction quality of large language models (LLMs). Existing alignment methods depend on manually annotated preference data to guide the LLM optimization directions. However, continuously updating LLMs for alignment raises a distribution gap... | Jian Li, Nan Du, Peixin Cao, Pengyu Cheng, Tianhao Hu, Xiaolong Li, Yifan Yang, Yong Dai |  |
| 1207 |  |  [Pinpointing Diffusion Grid Noise to Enhance Aspect Sentiment Quad Prediction](https://doi.org/10.18653/v1/2024.findings-acl.222) |  | 0 | Aspect sentiment quad prediction (ASQP) has garnered significant attention in aspect-based sentiment analysis (ABSA). Current ASQP research primarily relies on pre-trained generative language models to produce templated sequences, often complemented by grid-based auxiliary methods. Despite these... | Chenwei Zhang, Linan Zhu, Xiangfan Chen, Xiangjie Kong, Xiaolei Guo, Zehai Zhou, Zhechao Zhu |  |
| 1208 |  |  [Continual Contrastive Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.223) |  | 0 | Recently, neural networks have shown impressive progress across diverse fields, with speech processing being no exception. However, recent breakthroughs in this area require extensive offline training using large datasets and tremendous computing resources. Unfortunately, these models struggle to... | Alessio Brutti, Bhiksha Raj, Daniele Falavigna, Enrico Fini, Muqiao Yang, Umberto Cappellazzo |  |
| 1209 |  |  [LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.224) |  | 0 | Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and... | Kai Wang, Siqiang Luo, Yuwei Xu, Zhiyong Wu |  |
| 1210 |  |  [Unsupervised Parsing by Searching for Frequent Word Sequences among Sentences with Equivalent Predicate-Argument Structures](https://doi.org/10.18653/v1/2024.findings-acl.225) |  | 0 | Unsupervised constituency parsing focuses on identifying word sequences that form a syntactic unit (i.e., constituents) in target sentences. Linguists identify the constituent by evaluating a set of Predicate-Argument Structure (PAS) equivalent sentences where we find the constituent appears more... | Danushka Bollegala, Junjie Chen, Xiangheng He, Yusuke Miyao |  |
| 1211 |  |  [Data-Centric Explainable Debiasing for Improving Fairness in Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.226) |  | 0 | Human-like social bias of pre-trained language models (PLMs) on downstream tasks have attracted increasing attention. The potential flaws in the training data are the main factor that causes unfairness in PLMs. Existing data-centric debiasing strategies mainly leverage explicit bias words (defined... | Mengnan Du, Rui Song, Xin Wang, Ying Wang, Yingji Li |  |
| 1212 |  |  [Knowledge-Driven Cross-Document Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.227) |  | 0 | Relation extraction (RE) is a well-known NLP application often treated as a sentence or document-level task. However, a handful of recent efforts explore it across documents or in the cross-document setting (CrossDocRE). This is distinct from the single document case because different documents... | Kuldeep Singh, Monika Jain, Raghava Mutharaju, Ramakanth Kavuluru |  |
| 1213 |  |  [Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.228) |  | 0 | Recent research in dialogue systems focuses on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users complete specific tasks, while open-domain systems aim to create engaging conversations. However, user intents often emerge during interactions. A... | Wen Chang, YunNung Chen |  |
| 1214 |  |  [KG-Adapter: Enabling Knowledge Graph Integration in Large Language Models through Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.229) |  | 0 | Although large language models (LLMs) show remarkable capabilities and generalizability across various tasks, they are criticized for lack of expertise. One promising solution is to combine knowledge graphs (KGs) with LLMs, and recent studies focus on integrating KGs into LLMs through prompt-based... | Caixia Yuan, Chen Wei, Huixing Jiang, Shiyu Tian, Tianze Xu, Xiaojie Wang, Yangyang Luo |  |
| 1215 |  |  [Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.230) |  | 0 | Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local optimality. To address this shortcoming, ensemble-optimization tries to... | Di Zhang, Fuzheng Zhang, JiaYi Fu, Junchen Wan, Kun Gai, Lei Lin, Pengli Liu, Qingyang Li, Yan Gong, Zhongyuan Wang |  |
| 1216 |  |  [Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.231) |  | 0 | Large Language Models (LLMs), excel in natural language understanding, but their capability for complex mathematical reasoning with a hybrid of structured tables and unstructured text remain uncertain. This study explores LLMs’ mathematical reasoning on four financial tabular question-answering... | Dan Roth, Manuj Malik, Pragya Srivastava, Tanuja Ganu, Vivek Gupta |  |
| 1217 |  |  [Improving In-Context Learning with Prediction Feedback for Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.232) |  | 0 | Large language models (LLMs) have achieved promising results in sentiment analysis through the in-context learning (ICL) paradigm. However, their ability to distinguish subtle sentiments still remains a challenge. Inspired by the human ability to adjust understanding via feedback, this paper... | Bing Qin, Hongling Xu, Min Yang, Qianlong Wang, Ruifeng Xu, Xi Zeng, Yice Zhang |  |
| 1218 |  |  [Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model](https://doi.org/10.18653/v1/2024.findings-acl.233) |  | 0 | Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into symbol-based and neural-based models. Symbol-based models are interpretable but inefficient, while... | Caihong Sun, JiRong Wen, Ran Song, Wei Xu, Zhengtao Yu, Zhiwei Li |  |
| 1219 |  |  [Discerning and Resolving Knowledge Conflicts through Adaptive Decoding with Contextual Information-Entropy Constraint](https://doi.org/10.18653/v1/2024.findings-acl.234) |  | 0 | Large language models (LLMs) internalize enormous parametric knowledge during pre-training. Concurrently, realistic applications necessitate external contextual knowledge to aid models on the underlying tasks. This raises a crucial dilemma known as knowledge conflicts, where the contextual... | Jun Zhao, Kang Liu, Shengping Liu, Xiaowei Yuan, Yequan Wang, Zhao Yang |  |
| 1220 |  |  [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.235) |  | 0 | In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose SALAD-Bench, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench... | Bowen Dong, Dahua Lin, Jing Shao, Lijun Li, Ruohui Wang, Wangmeng Zuo, Xuhao Hu, Yu Qiao |  |
| 1221 |  |  [Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation](https://doi.org/10.18653/v1/2024.findings-acl.236) |  | 0 | Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality factual statements from free-text radiology reports... | Alvaro Soto, Denis Parra, Pablo Messina, René Vidal, Vladimir Araujo |  |
| 1222 |  |  [GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network](https://doi.org/10.18653/v1/2024.findings-acl.237) |  | 0 | Large Language Models (LLMs) exhibit strong In-Context Learning (ICL) capabilities when prompts with demonstrations are used. However, fine-tuning still remains crucial to further enhance their adaptability. Prompt-based fine-tuning proves to be an effective fine-tuning method in low-data... | Ercong Nie, Helmut Schmid, Hinrich Schütze, Michael Färber, Shuzhou Yuan |  |
| 1223 |  |  [M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.238) |  | 0 | There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it... | Abhinav Ramesh Kashyap, Anand Subramanian, Stefan Winkler, ThanhTung Nguyen, Vijay Prakash Dwivedi, Viktor Schlegel |  |
| 1224 |  |  [MovieSum: An Abstractive Summarization Dataset for Movie Screenplays](https://doi.org/10.18653/v1/2024.findings-acl.239) |  | 0 | Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore,... | Frank Keller, Rohit Saxena |  |
| 1225 |  |  [Autonomous Workflow for Multimodal Fine-Grained Training Assistants Towards Mixed Reality](https://doi.org/10.18653/v1/2024.findings-acl.240) |  | 0 | Autonomous artificial intelligence (AI) agents have emerged as promising protocols for automatically understanding the language-based environment, particularly with the exponential development of large language models (LLMs). However, a fine-grained, comprehensive understanding of multimodal... | Di Wang, Fanghua Ye, Haochen Huang, Irene Viola, Jiahuan Pei, Junxiao Wang, Moonisa Ahsan, Pablo César, Pengjie Ren, Yao Sai, Yiming Jiang, Zhumin Chen |  |
| 1226 |  |  [Perceptions of Language Technology Failures from South Asian English Speakers](https://doi.org/10.18653/v1/2024.findings-acl.241) |  | 0 | English NLP systems have empirically worse performance for dialects other than Standard American English (SAmE). However, how these discrepancies impact use of language technology by speakers of non-SAmE global Englishes is not well understood. We focus on reducing this gap for South Asian... | Diyi Yang, Faye Holt, William Held |  |
| 1227 |  |  [A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task](https://doi.org/10.18653/v1/2024.findings-acl.242) |  | 0 | Transformers demonstrate impressive performance on a range of reasoning benchmarks. To evaluate the degree to which these abilities are a result of actual reasoning, existing work has focused on developing sophisticated benchmarks for behavioral studies. However, these studies do not provide... | Abhay Sheshadri, Christian Bartelt, Jannik Brinkmann, Paul Swoboda, Victor Levoso |  |
| 1228 |  |  [Optimal Transport Guided Correlation Assignment for Multimodal Entity Linking](https://doi.org/10.18653/v1/2024.findings-acl.243) |  | 0 | Multimodal entity linking (MEL) aims to link ambiguous mentions in multimodal contexts to entities in a multimodal knowledge graph. A pivotal challenge is to fully leverage multi-element correlations between mentions and entities to bridge modality gap and enable fine-grained semantic matching.... | Chuang Zhang, Jiawei Sheng, Liangyunzhi Liangyunzhi, Siqi Wang, Tingwen Liu, Wenyuan Zhang, Zefeng Zhang |  |
| 1229 |  |  [On Efficiently Representing Regular Languages as RNNs](https://doi.org/10.18653/v1/2024.findings-acl.244) |  | 0 | Recent work by Hewitt et al. (2020) provides an interpretation of the empirical success of recurrent neural networks (RNNs) as language models (LMs). It shows that RNNs can efficiently represent bounded hierarchical structures that are prevalent in human language.This suggests that RNNs’ success... | Anej Svete, Robin Chan, Ryan Cotterell |  |
| 1230 |  |  [A Survey on Modelling Morality for Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.245) |  | 0 | In this survey, we provide a systematic review of recent work on modelling morality in text, an area of research that has garnered increasing attention in recent years. Our survey is motivated by the importance of modelling decisions on the created resources, the models trained on these resources... | Ines Rehbein, Ines Reinig, Maria Becker, Simone Paolo Ponzetto |  |
| 1231 |  |  [Your Vision-Language Model Itself Is a Strong Filter: Towards High-Quality Instruction Tuning with Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.246) |  | 0 | Data selection in instruction tuning emerges as a pivotal process for acquiring high-quality data and training instruction-following large language models (LLMs), but it is still a new and unexplored research area for vision-language models (VLMs). Existing data selection approaches on LLMs either... | Chenxi Liu, Guodong Liu, Heng Huang, Junfeng Guo, Lichang Chen, Qi He, Ruibo Chen, Tianyi Xiong, Yihan Wu |  |
| 1232 |  |  [DebugBench: Evaluating Debugging Capability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.247) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs’ debugging ability are significantly limited by the risk of... | Haotian Hui, Maosong Sun, Runchu Tian, Weichuan Liu, Xin Cong, Yankai Lin, Yesai Wu, Yining Ye, Yinxu Pan, Yujia Qin, Zhiyuan Liu |  |
| 1233 |  |  [POP-CEE: Position-oriented Prompt-tuning Model for Causal Emotion Entailment](https://doi.org/10.18653/v1/2024.findings-acl.248) |  | 0 | The objective of the Causal Emotion Entailment (CEE) task is to identify the causes of the target emotional utterances in a given conversation. Most existing studies have focused on a fine-tuning paradigm based on a pretrained model, e.g., the BERT model. However, there are gaps between the... | Hao Xu, Xue Gu, Yujie Zhao, Zhihan Zhou |  |
| 1234 |  |  [Context Length Extension via Generalized Extrapolation Scale](https://doi.org/10.18653/v1/2024.findings-acl.249) |  | 0 |  | Huaping Zhang, Linhan Li |  |
| 1235 |  |  [Selectively Answering Visual Questions](https://doi.org/10.18653/v1/2024.findings-acl.250) |  | 0 | Recently, large multi-modal models (LMMs) have emerged with the capacity to perform vision tasks such as captioning and visual question answering (VQA) with unprecedented accuracy. Applications such as helping the blind or visually impaired have a critical need for precise answers. It is specially... | Guido Ivetta, Hernán Maina, Julian Eisenschlos, Luciana Benotti |  |
| 1236 |  |  [Wav2SQL: Direct Generalizable Speech-To-SQL Parsing](https://doi.org/10.18653/v1/2024.findings-acl.251) |  | 0 | We release a multi-accent dataset and propose speech-programming and gradient reversal classifier to improve the generalization.Abstract: Speech-to-SQL (S2SQL) aims to convert spoken questions into SQL queries given relational databases, which has been traditionally implemented in a cascaded manner... | Gang Sun, Huadai Liu, Jinzheng He, Ran Shen, Rongjie Huang, Xize Cheng, Zhou Zhao |  |
| 1237 |  |  [E2-LLM: Efficient and Extreme Length Extension of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.252) |  | 0 | Training Large Language Models (LLMs) to process extensive context lengths incurs prohibitive computational costs. Prevailing techniques for extending context capabilities in LLMs typically require not only additional training procedures but also access to datasets with long context (e.g.,... | Bo Zheng, Chenchen Zhang, Ge Zhang, Haoran Que, Jiaheng Liu, Jiakai Wang, Jie Fu, Tiezheng Ge, Wenbo Su, Wenhu Chen, Yu Zhang, Yuanxing Zhang, Yukang Chen, Zhiqi Bai |  |
| 1238 |  |  [Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality](https://doi.org/10.18653/v1/2024.findings-acl.253) |  | 0 | People tend to use language to mention surprising properties of events: for example, when a banana is blue, we are more likely to mention color than when it is yellow. This fact is taken to suggest that yellowness is somehow a typical feature of bananas, and blueness is exceptional. Similar to how... | Adina Williams, Da Ju, Karen Ullrich |  |
| 1239 |  |  [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](https://doi.org/10.18653/v1/2024.findings-acl.254) |  | 0 | Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally... | Chaoyun Zhang, Dongmei Zhang, Fangkai Yang, Ling Chen, Qi Zhang, Qingwei Lin, Saravan Rajmohan, Sitao Cheng, Xiang Huang, Xiaoting Qin, Yong Xu, Ziyuan Zhuang |  |
| 1240 |  |  [Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts](https://doi.org/10.18653/v1/2024.findings-acl.255) |  | 0 | In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of legal proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce Prediction with Explanation (PredEx), the largest expert-annotated dataset... | Anurag Sharma, Arnab Bhattacharya, Danush Khanna, Kripabandhu Ghosh, Noel Shallum, Shubham Kumar Nigam |  |
| 1241 |  |  [RulE: Knowledge Graph Reasoning with Rule Embedding](https://doi.org/10.18653/v1/2024.findings-acl.256) |  | 0 | Knowledge graph reasoning is an important problem for knowledge graphs. In this paper, we propose a novel and principled framework called RulE (stands for Rule Embedding) to effectively leverage logical rules to enhance KG reasoning. Unlike knowledge graph embedding methods, RulE learns rule... | Muhan Zhang, SongChun Zhu, Xiaojuan Tang, Yitao Liang |  |
| 1242 |  |  [Multi-Objective Linguistic Control of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.257) |  | 0 | Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, prefer to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple... | Dang Nguyen, Jiuhai Chen, Tianyi Zhou |  |
| 1243 |  |  [Evaluating the Smooth Control of Attribute Intensity in Text Generation with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.258) |  | 0 | Controlling the attribute intensity of text generation is crucial across scenarios (e.g., writing conciseness, chatting emotion, and explanation clarity). The remarkable capabilities of large language models (LLMs) have revolutionized text generation, prompting us to explore such smooth control of... | Chengyu Dong, Feng Yao, Jingbo Shang, Shang Zhou, Zihan Wang |  |
| 1244 |  |  [Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios](https://doi.org/10.18653/v1/2024.findings-acl.259) |  | 0 | The recent trend of using Large Language Models (LLMs) as tool agents in real-world applications underscores the necessity for comprehensive evaluations of their capabilities, particularly in complex scenarios involving planning, creating, and using tools. However, existing benchmarks typically... | Jiahui Gao, Jianqiao Lu, Lifeng Shang, Qi Zhu, Qun Liu, Ruifeng Xu, Shijue Huang, Wanjun Zhong, Weiwen Liu, Xin Jiang, Xingshan Zeng, Yasheng Wang, Yutai Hou |  |
| 1245 |  |  [Do Androids Know They're Only Dreaming of Electric Sheep?](https://doi.org/10.18653/v1/2024.findings-acl.260) |  | 0 | We design probes trained on the internal representations of a transformer language model to predict its hallucinatory behavior on three grounded generation tasks. To train the probes, we annotate for span-level hallucination on both sampled (organic) and manually edited (synthetic) reference... | Benjamin Van Durme, Chris Kedzie, Jason Eisner, Sky CHWang |  |
| 1246 |  |  [URG: A Unified Ranking and Generation Method for Ensembling Language Models](https://doi.org/10.18653/v1/2024.findings-acl.261) |  | 0 | Prior research endeavors of the ensemble Large Language Models (LLMs) achieved great success by employing an individual language model (LM) rank before the text generation. However, the use of an individual LM ranker faces two primary challenges: (1) The time-intensive nature of the ranking... | Bo Lv, Chen Tang, Ping Luo, Xin Liu, Yanan Zhang, Yue Yu |  |
| 1247 |  |  [Multi-Modal Retrieval For Large Language Model Based Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.262) |  | 0 | Retrieval is a widely adopted approach for improving language models leveraging external information. As the field moves towards multi-modal large language models, it is important to extend the pure text based methods to incorporate other modalities in retrieval as well for applications across the... | Aditya Gourav, Ankur Gandhe, Ariya Rastrow, Grant P. Strimel, Ivan Bulyko, Jari Kolehmainen, Prashanth Gurunath Shivakumar, Yile Gu |  |
| 1248 |  |  [LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.263) |  | 0 | Low-Rank Adaptation (LoRA) provides an effective yet efficient solution for fine-tuning large language models (LLMs). The modular and plug-and-play nature of LoRA enables the integration of diverse domain-specific LoRAs to enhance the capabilities of LLMs. Previous research on exploiting multiple... | Fei Wu, Guoyin Wang, Hongxia Yang, Kun Kuang, Leilei Gan, Wangchunshu Zhou, Ziyu Zhao |  |
| 1249 |  |  [ELAD: Explanation-Guided Large Language Models Active Distillation](https://doi.org/10.18653/v1/2024.findings-acl.264) |  | 0 | The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences. Traditional distillation methods, which transfer the capabilities of LLMs to smaller models, often fail to determine whether the... | Bo Pan, Chen Ling, Liang Zhao, Yifei Zhang, Yuntong Hu |  |
| 1250 |  |  [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](https://doi.org/10.18653/v1/2024.findings-acl.265) |  | 0 | Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen).... | Anne Lauscher, Carolin Holtermann, Paul Röttger, Timm Dill |  |
| 1251 |  |  [Semantics or spelling? Probing contextual word embeddings with orthographic noise](https://doi.org/10.18653/v1/2024.findings-acl.266) |  | 0 | Pretrained language model (PLM) hidden states are frequently employed as contextual word embeddings (CWE): high-dimensional representations that encode semantic information given linguistic context. Across many areas of computational linguistics research, similarity between CWEs is interpreted as... | Jacob Matthews, John Starr, Marten van Schijndel |  |
| 1252 |  |  [The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)](https://doi.org/10.18653/v1/2024.findings-acl.267) |  | 0 | Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model generation with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could... | Dawei Yin, Han Xu, Jiankun Zhang, Jie Ren, Jiliang Tang, Pengfei He, Shenglai Zeng, Shuaiqiang Wang, Yi Chang, Yiding Liu, Yue Xing |  |
| 1253 |  |  [EmpathicStories++: A Multimodal Dataset for Empathy Towards Personal Experiences](https://doi.org/10.18653/v1/2024.findings-acl.268) |  | 0 | Modeling empathy is a complex endeavor that is rooted in interpersonal and experiential dimensions of human interaction, and remains an open problem within AI. Existing empathy datasets fall short in capturing the richness of empathy responses, often being confined to in-lab or acted scenarios,... | Cynthia Breazeal, Hae Won Park, Jocelyn Shen, Mohit Hulse, Sharifa Alghowinem, Wazeer Zulfikar, Yubin Kim |  |
| 1254 |  |  [MRL Parsing Without Tears: The Case of Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.269) |  | 0 | Syntactic parsing remains a critical tool for relation extraction and information extraction, especially in resource-scarce languages where LLMs are lacking. Yet in morphologically rich languages (MRLs), where parsers need to identify multiple lexical units in each token, existing systems suffer in... | Avi Shmidman, Moshe Koppel, Reut Tsarfaty, Shaltiel Shmidman |  |
| 1255 |  |  [SyntaxShap: Syntax-aware Explainability Method for Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.270) |  | 0 | To harness the power of large language models in safety-critical domains, we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods... | Kenza Amara, Mennatallah ElAssady, Rita Sevastjanova |  |
| 1256 |  |  [Automated Detection and Analysis of Data Practices Using A Real-World Corpus](https://doi.org/10.18653/v1/2024.findings-acl.271) |  | 0 | Privacy policies are crucial for informing users about data practices, yet their length and complexity often deter users from reading them. In this paper, we propose an automated approach to identify and visualize data practices within privacy policies at different levels of detail. Leveraging... | C. Lee Giles, Florian Schaub, Maria Badillo, Mukund Srinath, Pranav Narayanan Venkit, Shomir Wilson |  |
| 1257 |  |  [Enhancing Hyperbolic Knowledge Graph Embeddings via Lorentz Transformations](https://doi.org/10.18653/v1/2024.findings-acl.272) |  | 0 | Knowledge Graph Embedding (KGE) is a powerful technique for predicting missing links in Knowledge Graphs (KGs) by learning the entities and relations. Hyperbolic space has emerged as a promising embedding space for KGs due to its ability to represent hierarchical data. Nevertheless, most existing... | Hao Yang, Huiyuan Chen, Mahashweta Das, Minghua Xu, Xiran Fan, Yuzhong Chen |  |
| 1258 |  |  [Tell Me What's Next: Textual Foresight for Generic UI Representations](https://doi.org/10.18653/v1/2024.findings-acl.273) |  | 0 | Mobile app user interfaces (UIs) are rich with action, text, structure, and image content that can be utilized to learn generic UI representations for tasks like automating user commands, summarizing content, and evaluating the accessibility of user interfaces. Prior work has learned strong visual... | Andrea Burns, Bryan A. Plummer, Kate Saenko |  |
| 1259 |  |  [Probing the Uniquely Identifiable Linguistic Patterns of Conversational AI Agents](https://doi.org/10.18653/v1/2024.findings-acl.274) |  | 0 | The proliferation of Conversational AI agents (CAAs) has emphasised the need to distinguish between human and machine-generated texts, with implications spanning digital forensics and cybersecurity. While prior research primarily focussed on distinguishing human from machine-generated text, our... | Iqra Zahid, Riza BatistaNavarro, Tharindu Madusanka, Youcheng Sun |  |
| 1260 |  |  [The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance](https://doi.org/10.18653/v1/2024.findings-acl.275) |  | 0 | Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or “prompting,” practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of... | Abel Salinas, Fred Morstatter |  |
| 1261 |  |  [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](https://doi.org/10.18653/v1/2024.findings-acl.276) |  | 0 | In recent years, few-shot and zero-shot learning, which learn to predict labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat frequent-shot (freq-shot; labels with abundant instances), few-shot, and zero-shot learning as distinct... | Hanzi Xu, Lifu Huang, Muhao Chen, Slobodan Vucetic, Wenpeng Yin |  |
| 1262 |  |  [SPIN: Sparsifying and Integrating Internal Neurons in Large Language Models for Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.277) |  | 0 | Among the many tasks that Large Language Models (LLMs) have revolutionized is text classification. Current text classification paradigms, however, rely solely on the output of the final layer in the LLM, with the rich information contained in internal neurons largely untapped. In this study, we... | Ashton Anderson, Daniel Matter, Difan Jiao, Jürgen Pfeffer, Yilun Liu, Zhenwei Tang |  |
| 1263 |  |  [Decomposing Co-occurrence Matrices into Interpretable Components as Formal Concepts](https://doi.org/10.18653/v1/2024.findings-acl.278) |  | 0 | This study addresses the interpretability of word representations through an investigation of a count-based co-occurrence matrix. Employing the mathematical methodology of Formal Concept Analysis, we reveal an underlying structure that is amenable to human interpretation. Furthermore, we unveil the... | Akihiro Maeda, Shohei Hidaka, Takuma Torii |  |
| 1264 |  |  [Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification](https://doi.org/10.18653/v1/2024.findings-acl.279) |  | 0 | Radiology reports are highly technical documents aimed primarily at doctor-doctor communication. There has been an increasing interest in sharing those reports with patients, necessitating providing them patient-friendly simplifications of the original reports. This study explores the suitability... | Santhosh Cherian, Slobodan Vucetic, Ziyu Yang |  |
| 1265 |  |  [Planning First, Question Second: An LLM-Guided Method for Controllable Question Generation](https://doi.org/10.18653/v1/2024.findings-acl.280) |  | 0 | In the field of education, for better assessment of students’ abilities, generated questions often need to meet experts’ requirements, indicating the need for controllable question generation (CQG). However, current CQG methods mainly focus on difficulty control, neglecting the control of question... | Kunze Li, Yu Zhang |  |
| 1266 |  |  [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://doi.org/10.18653/v1/2024.findings-acl.281) |  | 0 | Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external... | Jiannan Cao, Jianwei Yin, Tianyu Du, Weihao Liu, Xinyue Peng, Xuhong Zhang, Yanming Liu |  |
| 1267 |  |  [MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model](https://doi.org/10.18653/v1/2024.findings-acl.282) |  | 0 | Large Language Models (LLMs) often struggle with hallucinations and outdated information. To address this, Information Retrieval (IR) systems can be employed to augment LLMs with up-to-date knowledge. However, existing IR techniques contain deficiencies, posing a performance bottleneck. Given the... | Danupat Khamnuansin, Ekapol Chuangsuwanich, Tawunrat Chalothorn |  |
| 1268 |  |  [Chain-of-Question: A Progressive Question Decomposition Approach for Complex Knowledge Base Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.283) |  | 0 | Complex KBQA leverages the knowledge base (KB) to answer complex natural questions involving complicated semantics like multi-hop reasoning. Existing methods involve a question decomposition process, i.e., breaking a complex question into several simpler sub-questions, to assist obtaining logical... | Licheng Zhang, Quan Wang, Yi Liu, Yixing Peng, Zhendong Mao |  |
| 1269 |  |  [Instruction Tuning with Retrieval-based Examples Ranking for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.284) |  | 0 | Aspect-based sentiment analysis (ABSA) identifies sentiment information related to specific aspects and provides deeper market insights to businesses and organizations. With the emergence of large language models (LMs), recent studies have proposed using fixed examples for instruction tuning to... | Guangmin Zheng, Jin Wang, LiangChih Yu, Xuejie Zhang |  |
| 1270 |  |  [Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation](https://doi.org/10.18653/v1/2024.findings-acl.285) |  | 0 | Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change. Simulating the response of the public and forecasting the potential impact has become increasingly important. However, existing methods for simulating such phenomena encounter... | Xinyi Mou, Xuanjing Huang, Zhongyu Wei |  |
| 1271 |  |  [Incorporating Syntax and Lexical Knowledge to Multilingual Sentiment Classification on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.286) |  | 0 | This paper exploits a sentiment extractor supported by syntactic and lexical resources to enhance multilingual sentiment classification solved through the generative approach, without retraining LLMs. By adding external information of words and phrases that have positive/negative polarities, the... | Hiroshi Kanayama, Ran Iwamoto, Takuya Ohko, Yang Zhao |  |
| 1272 |  |  [Locating and Extracting Relational Concepts in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.287) |  | 0 | Relational concepts are indeed foundational to the structure of knowledge representation, as they facilitate the association between various entity concepts, allowing us to express and comprehend complex world knowledge.By expressing relational concepts in natural language prompts, people can... | Britney White, Chang Xu, Zijian Wang |  |
| 1273 |  |  [Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.288) |  | 0 | Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their superiority in terms of factuality, they do not consistently outperform the original retrieval-free Language Models (LMs). Our experiments reveal that this example-level performance inconsistency exists not only between... | Mingda Li, Weinan Zhang, Wenfeng Xuan, Xinyu Li, Yifan Chen |  |
| 1274 |  |  [SenticVec: Toward Robust and Human-Centric Neurosymbolic Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.289) |  | 0 | The success of state-of-the-art Natural Language Processing (NLP) systems heavily depends on deep neural networks, which excel in various tasks through strong data fitting and latent feature modeling abilities. However, certain challenges linked to deep neural networks and supervised deep learning... | Erik Cambria, Rui Mao, Xulang Zhang |  |
| 1275 |  |  [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.290) |  | 0 | Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs’ trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs’ trustworthiness... | Chen Qian, Dongrui Liu, Jie Zhang, Jing Shao, Wei Yao, Yong Liu, Yu Qiao, Zhenfei Yin |  |
| 1276 |  |  [Language Models can Evaluate Themselves via Probability Discrepancy](https://doi.org/10.18653/v1/2024.findings-acl.291) |  | 0 | In this paper, we begin by illustrating that, when presented with a query, Large Language Models (LLMs) capable of providing accurate responses tend to exhibit a more uniform probability distribution compared to their less proficient counterparts. Building upon this observation, we introduce a... | Bowen Yu, Chang Zhou, Tingyu Xia, Yi Chang, Yuan Wu |  |
| 1277 |  |  [Evaluating the Validity of Word-level Adversarial Attacks with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.292) |  | 0 | Deep neural networks exhibit vulnerability to word-level adversarial attacks in natural language processing. Most of these attack methods adopt synonymous substitutions to perturb original samples for crafting adversarial examples while attempting to maintain semantic consistency with the... | Dongping Chen, Fangyuan Zhang, Hongtao Wang, Huichi Zhou, Wenhan Mu, Zhaoyang Wang |  |
| 1278 |  |  [On the Language Encoder of Contrastive Cross-modal Models](https://doi.org/10.18653/v1/2024.findings-acl.293) |  | 0 | Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder – the central component of encoding natural language descriptions of image/audio into... | ChiehHsin Lai, Hiromi Wakaki, Junya Ono, Mengjie Zhao, Naoki Murata, Takashi Shibuya, WeiHsiang Liao, Yuhta Takida, Yuki Mitsufuji, Zhi Zhong |  |
| 1279 |  |  [Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World](https://doi.org/10.18653/v1/2024.findings-acl.294) |  | 0 | Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration... | Chen Zhao, Cláudio T. Silva, Guande Wu, He He |  |
| 1280 |  |  [Anchor-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.295) |  | 0 | Large language models (LLMs) predominantly employ decoder-only transformer architectures, necessitating the retention of keys/values information for historical tokens to provide contextual information and avoid redundant computation. However, the substantial size and parameter volume of these LLMs... | Derek F. Wong, Fanghua Ye, Jianhui Pang, Longyue Wang, Wanshun Chen, Xin He |  |
| 1281 |  |  [MLeVLM: Improve Multi-level Progressive Capabilities based on Multimodal Large Language Model for Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.296) |  | 0 | Medical visual question answering (MVQA) requires in-depth understanding of medical images and questions to provide reliable answers. We summarize multi-level progressive capabilities that models need to focus on in MVQA: recognition, details, diagnosis, knowledge, and reasoning. Existing MVQA... | Dexuan Xu, Hang Li, Hanpin Wang, Hongxing Wang, Jieyi Wang, Jing He, Weihua Yue, Yanyuan Chen, Yu Huang, Yue Huang, Zhi Jin |  |
| 1282 |  |  [Disentangling Length from Quality in Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.297) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) has been a crucial component in the recent success of Large Language Models. However, RLHF is know to exploit biases in human preferences, such as verbosity. A well-formatted and eloquent answer is often more highly rated by users, even when it is... | Chelsea Finn, Rafael Rafailov, Ryan Park, Stefano Ermon |  |
| 1283 |  |  [MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.298) |  | 0 | Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity... | Bozhong Tian, Chuanyi Zhang, Guilin Qi, Haiyun Jiang, Jiaqi Li, Miaozeng Du, Nan Hu, Siyuan Cheng, Yongrui Chen |  |
| 1284 |  |  [Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise: A Case Study on Chinese Legal Domain](https://doi.org/10.18653/v1/2024.findings-acl.299) |  | 0 | While large language models (LLMs) like GPT-4 have recently demonstrated astonishing zero-shot capabilities in general domain tasks, they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the... | Fei Cheng, Sadao Kurohashi, Yating Zhang, Yexiang Wang, Zhen Wan |  |
| 1285 |  |  [MemeMQA: Multimodal Question Answering for Memes via Rationale-Based Inferencing](https://doi.org/10.18653/v1/2024.findings-acl.300) |  | 0 | Memes have evolved as a prevalent medium for diverse communication, ranging from humour to propaganda. With the rising popularity of image-focused content, there is a growing need to explore its potential harm from different aspects. Previous studies have analyzed memes in closed settings -... | Preslav Nakov, Shivam Sharma, Siddhant Agarwal, Tanmoy Chakraborty |  |
| 1286 |  |  [Improving Attributed Text Generation of Large Language Models via Preference Learning](https://doi.org/10.18653/v1/2024.findings-acl.301) |  | 0 | Large language models have been widely adopted in natural language processing, yet they face the challenge of generating unreliable content. Recent works aim to reduce misinformation and hallucinations by resorting to attribution as a means to provide evidence (i.e., citations). However, current... | Baotian Hu, Dongfang Li, Min Zhang, Xinshuo Hu, Xuebo Liu, Zetian Sun, Zhenyu Liu |  |
| 1287 |  |  [KOMBO: Korean Character Representations Based on the Combination Rules of Subcharacters](https://doi.org/10.18653/v1/2024.findings-acl.302) |  | 0 | The Korean writing system, Hangeul, has a unique character representation rigidly following the invention principles recorded in Hunminjeongeum. However, existing pre-trained language models (PLMs) for Korean have overlooked these principles. In this paper, we introduce a novel framework for Korean... | Juhyeong Park, SangKeun Lee, SungHo Kim, Yeachan Kim |  |
| 1288 |  |  [Tree-Planted Transformers: Unidirectional Transformer Language Models with Implicit Syntactic Supervision](https://doi.org/10.18653/v1/2024.findings-acl.303) |  | 0 | Syntactic Language Models (SLMs) can be trained efficiently to reach relatively high performance; however, they have trouble with inference efficiency due to the explicit generation of syntactic structures. In this paper, we propose a new method dubbed tree-planting: instead of explicitly... | Ryo Yoshida, Taiga Someya, Yohei Oseki |  |
| 1289 |  |  [Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues](https://doi.org/10.18653/v1/2024.findings-acl.304) |  | 0 | With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of... | Junjie Wang, Mingyang Li, Qing Wang, Yang Liu, Yi Liu, Zhiyuan Chang |  |
| 1290 |  |  [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.305) |  | 0 | The development of large language models tailored for handling patients’ clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations.To address these challenges, we first create synthetic large-scale clinical notes using publicly... | Chang Hoon Han, Edward Choi, Eunbyeol Cho, Gyubok Lee, Jiyoun Kim, Jong Hak Moon, Jungwoo Oh, Junu Kim, Seng Chan You, Seongsu Bae, Seungjin Baek, Sujeong Im, Sunjun Kweon, Yohan Jo, Yoon Bin Jung |  |
| 1291 |  |  [Extending Context Window of Large Language Models via Semantic Compression](https://doi.org/10.18653/v1/2024.findings-acl.306) |  | 0 | Transformer based Large Language Models (LLMs) often impose limitations on the length of the text input to ensure the generation of fluent and relevant responses due to the quadratic complexity. These constraints restrict their applicability in long text scenarios. In this paper, we propose a novel... | Bo Bai, Lei Deng, Lu Hou, Pingyi Zhou, Wei Han, Weizhi Fei, Xueyan Niu |  |
| 1292 |  |  [Plausible Extractive Rationalization through Semi-Supervised Entailment Signal](https://doi.org/10.18653/v1/2024.findings-acl.307) |  | 0 | The increasing use of complex and opaque black box models requires the adoption of interpretable measures, one such option is extractive rationalizing models, which serve as a more interpretable alternative. These models, also known as Explain-Then-Predict models, employ an explainer model to... | Erik Cambria, Ranjan Satapathy, Wei Jie Yeo |  |
| 1293 |  |  [Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.308) |  | 0 | Building a reliable visual question answering (VQA) system across different languages is a challenging problem, primarily due to the lack of abundant samples for training. To address this challenge, recent studies have employed machine translation systems for the cross-lingual VQA task. This... | ChaeHun Park, DuSeong Chang, Hyesu Lim, Jaegul Choo, Jaeseok Kim, Junmo Park, Koanho Lee, YuJung Heo |  |
| 1294 |  |  [Scented-EAE: Stage-Customized Entity Type Embedding for Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.309) |  | 0 | Existing methods for incorporating entities into EAE rely on prompts or NER. They typically fail to explicitly explore the role of entity types, which results in shallow argument comprehension and often encounter three issues: (1) weak semantic associations due to missing role-entity correspondence... | Chenrui Mao, Jinyu Guo, Kai Shuang, Yu Yang |  |
| 1295 |  |  [Fast Randomized Low-Rank Adaptation of Pre-trained Language Models with PAC Regularization](https://doi.org/10.18653/v1/2024.findings-acl.310) |  | 0 | Low-rank adaptation (LoRA) achieves parameter efficient fine-tuning for large language models (LLMs) by decomposing the model weight update into a pair of low-rank projection matrices. Yet, the memory overhead restricts it to scale up when the model size increases. We propose Randomized LoRA... | Dong Qian, William K. Cheung, Zijian Lei |  |
| 1296 |  |  [SDA: Semantic Discrepancy Alignment for Text-conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.311) |  | 0 | In the realm of text-conditioned image retrieval, models utilize a query composed of a reference image and modification text to retrieve corresponding images. Despite its significance, this task is fraught with challenges, including small-scale datasets due to labeling costs and the complexity of... | Yanfeng Wang, Yu Wang, Yuchen Yang |  |
| 1297 |  |  [Se²: Sequential Example Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.312) |  | 0 | The remarkable capability of large language models(LLMs) for in-context learning(ICL) needs to be activated by demonstration examples. Prior work has extensively explored the selection of examples for ICL, predominantly following the “select then organize” paradigm, such approaches often neglect... | Furu Wei, Hao Sun, Haoyu Liu, Jianfeng Liu, Qi Zhang, Shaohan Huang, Weiwei Deng, Yuefeng Zhan |  |
| 1298 |  |  [Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding](https://doi.org/10.18653/v1/2024.findings-acl.313) |  | 0 | This research aims to accelerate the inference speed of large language models (LLMs) with billions of parameters. We propose Smart Parallel Auto-Correct dEcoding (SPACE), an approach designed for achieving lossless acceleration of LLMs. By integrating semi-autoregressive inference and speculative... | Feng Lin, Hanling Yi, Hongbin Li, Peiyang Ning, Rong Xiao, Xiaotian Yu |  |
| 1299 |  |  [StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.314) |  | 0 | Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggle to discern whether a model genuinely possesses the required capabilities or merely memorizes/guesses the... | Boxi Cao, Feng Zhang, Hongyu Lin, Junfeng Zhan, Le Sun, Mengjie Ren, Xianpei Han |  |
| 1300 |  |  [Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching](https://doi.org/10.18653/v1/2024.findings-acl.315) |  | 0 | Protecting privacy leakage in large language models remains a paramount challenge. In this paper, we reveal Privacy Seesaw in LLM privacy safeguarding, a phenomenon where measures to secure specific private information inadvertently heighten exposure risks for other privacy. Through comprehensive... | Deyi Xiong, Shaoyang Xu, Weilong Dong, Xinwei Wu |  |
| 1301 |  |  [Which Information Matters? Dissecting Human-written Multi-document Summaries with Partial Information Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.316) |  | 0 | Understanding the nature of high-quality summaries is crucial to further improve the performance of multi-document summarization. We propose an approach to characterize human-written summaries using partial information decomposition, which decomposes the mutual information provided by all source... | Laura Mascarell, Majed El Helou, Yan L'Homme |  |
| 1302 |  |  [BadActs: A Universal Backdoor Defense in the Activation Space](https://doi.org/10.18653/v1/2024.findings-acl.317) |  | 0 | Backdoor attacks pose an increasingly severe security threat to Deep Neural Networks (DNNs) during their development stage. In response, backdoor sample purification has emerged as a promising defense mechanism, aiming to eliminate backdoor triggers while preserving the integrity of the clean... | Baolei Zhang, Biao Yi, Sishuo Chen, Tong Li, Yiming Li, Zheli Liu |  |
| 1303 |  |  [ReactXT: Understanding Molecular "Reaction-ship" via Reaction-Contextualized Molecule-Text Pretraining](https://doi.org/10.18653/v1/2024.findings-acl.318) |  | 0 | Molecule-text modeling, which aims to facilitate molecule-relevant tasks with a textual interface and textual knowledge, is an emerging research direction. Beyond single molecules, studying reaction-text modeling holds promise for helping the synthesis of new materials and drugs. However, previous... | An Zhang, Enzhi Zhang, Kenji Kawaguchi, Sihang Li, TatSeng Chua, Xiang Wang, Yaorui Shi, Zhiyuan Liu |  |
| 1304 |  |  [Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.319) |  | 0 | Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training (MMCAP) approach for generative Med-VQA, leveraging a knowledge... | Jianxin Wang, Junwen Duan, Quan Yan |  |
| 1305 |  |  [Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques](https://doi.org/10.18653/v1/2024.findings-acl.320) |  | 0 | Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss... | Aniket Goel, Anish Bhanushali, Karan Gupta, Pattisapu Priyatam, Prasanna Srinivasa Murthy, Siva Rajesh Kasa, Sumegh Roychowdhury |  |
| 1306 |  |  [Evaluating Large Language Models on Wikipedia-Style Survey Generation](https://doi.org/10.18653/v1/2024.findings-acl.321) |  | 0 | Educational materials such as survey articles in specialized fields like computer science traditionally require tremendous expert inputs and are therefore expensive to create and update. Recently, Large Language Models (LLMs) have achieved significant success across various general tasks. However,... | Fan Gao, Hang Jiang, Irene Li, Jinghui Lu, Moritz Blum, Qingcheng Zeng, Rui Yang, Tianwei She, Yuang Jiang |  |
| 1307 |  |  [The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse](https://doi.org/10.18653/v1/2024.findings-acl.322) |  | 0 | Although model editing has shown promise in revising knowledge in Large Language Models (LLMs), its impact on the inherent capabilities of LLMs is often overlooked. In this work, we reveal a critical phenomenon: even a single edit can trigger model collapse, manifesting as significant performance... | Dawei Yin, Fei Sun, Wanli Yang, Xinyu Ma, Xueqi Cheng, Xun Liu |  |
| 1308 |  |  [Can We Continually Edit Language Models? On the Knowledge Attenuation in Sequential Model Editing](https://doi.org/10.18653/v1/2024.findings-acl.323) |  | 0 | Model editing has become a promising method for precisely and effectively updating knowledge in language models. In this paper, we investigate knowledge attenuation, in which the retention of updated knowledge within the language model decreases as the number of edits increases after sequential... | Qi Li, Xiaowen Chu |  |
| 1309 |  |  [Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation](https://doi.org/10.18653/v1/2024.findings-acl.324) |  | 0 | Large Language Models (LLMs) driven by In-Context Learning (ICL) have significantly improved the performance of text-to-SQL. Previous methods generally employ a two-stage reasoning framework, namely 1) schema linking and 2) logical synthesis, making the framework not only effective but also... | Bowen Li, Bowen Qin, Chenhao Ma, Ge Qu, Jinyang Li, Nan Huo, Reynold Cheng |  |
| 1310 |  |  [Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.325) |  | 0 |  | Fandong Meng, Jie Zhou, Jinsong Su, Liqiang Niu, Min Zhang, Zhibin Lan |  |
| 1311 |  |  [StatBot.Swiss: Bilingual Open Data Exploration in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.326) |  | 0 | The potential for improvements brought by Large Language Models (LLMs) in Text-to-SQL systems is mostly assessed on monolingual English datasets. However, LLMs’ performance for other languages remains vastly unexplored. In this work, we release the StatBot.Swiss dataset, the first bilingual... | Cyril MattheyDoret, Ellery Smith, Farhad Nooralahzadeh, Kurt Stockinger, Raphaël de Fondeville, Sabine Maennel, Yi Zhang |  |
| 1312 |  |  [Subtle Signatures, Strong Shields: Advancing Robust and Imperceptible Watermarking in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.327) |  | 0 | The widespread adoption of Large Language Models (LLMs) has led to an increase in AI-generated text on the Internet, presenting a crucial challenge to differentiate AI-created content from human-written text. This challenge is critical to prevent issues of authenticity, trust, and potential... | Ping Guo, Wei Ma, Yanan Cao, Yubing Ren |  |
| 1313 |  |  [Thinking about how to extract: Energizing LLMs' emergence capabilities for document-level event argument extraction](https://doi.org/10.18653/v1/2024.findings-acl.328) |  | 0 | There are two key challenges remaining for the document-level event argument extraction (D-EAE) tasks: key feature forgetting and cross-event argument confusion. The emergence capability of large language models (LLMs) holds promise for solving the above two challenges. In this paper, we propose a... | Jinyu Guo, Kai Shuang, Qiwei Wang, Zhouji Zhouji |  |
| 1314 |  |  [Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning](https://doi.org/10.18653/v1/2024.findings-acl.329) |  | 0 | Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the burden of annotation, but meanwhile suffers from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, we... | Baobao Chang, Haozhe Zhao, Helan Hu, Kaikai An, Shuang Zeng, Shuzheng Si, Zefan Cai |  |
| 1315 |  |  [Predicting Narratives of Climate Obstruction in Social Media Advertising](https://doi.org/10.18653/v1/2024.findings-acl.330) |  | 0 | Social media advertising offers a platform for fossil fuel value chain companies and their agents to reinforce their narratives, often emphasizing economic, labor market, and energy security benefits to promote oil and gas policy and products. Whether such narratives can be detected automatically... | Christopher D. Manning, Dylan Tanner, Gaku Morio, Harri Rowlands |  |
| 1316 |  |  [SSS: Editing Factual Knowledge in Language Models towards Semantic Sparse Space](https://doi.org/10.18653/v1/2024.findings-acl.331) |  | 0 | Language Models (LMs) acquire factual knowledge during pre-training and store it in the parameters, which can be valuable for downstream tasks. As world evolves, some facts may be incorrectly induced or become obsolete over time. Various model editing methods have been proposed to modify specific... | Haifeng Sun, Huazheng Wang, Jianxin Liao, Jingyu Wang, Menghao Zhang, Qi Qi, Zixuan Xia |  |
| 1317 |  |  [GeoHard: Towards Measuring Class-wise Hardness through Modelling Class Semantics](https://doi.org/10.18653/v1/2024.findings-acl.332) |  | 0 |  | Fengyu Cai, Heinz Koeppl, Hongming Zhang, Iryna Gurevych, Xinran Zhao |  |
| 1318 |  |  [Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.333) |  | 0 | In this paper, we investigate the phenomena of “selection biases” in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option order and token usage, which significantly impact LLMs’... | ChengKuang Wu, HenHsen Huang, HsinHsi Chen, ShengLun Wei |  |
| 1319 |  |  [ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic](https://doi.org/10.18653/v1/2024.findings-acl.334) |  | 0 | The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to... | Abdelrahman Boda Sadallah, Aisha Alraeesi, Fajri Koto, Haonan Li, Jad Doughman, Khalid Almubarak, Neha Sengupta, Nizar Habash, Preslav Nakov, Sara Shatnawi, Shady Shehata, Timothy Baldwin, Zaid Alyafeai |  |
| 1320 |  |  [On the Relationship Between RNN Hidden-State Vectors and Semantic Structures](https://doi.org/10.18653/v1/2024.findings-acl.335) |  | 0 | We examine the assumption that hidden-state vectors of recurrent neural networks (RNNs) tend to form clusters of semantically similar vectors, which we dub the clustering hypothesis. While this hypothesis has been assumed in RNN analyses in recent years, its validity has not been studied thoroughly... | Bernhard K. Aichernig, Edi Muskardin, Ingo Pill, Martin Tappler, Thomas Pock |  |
| 1321 |  |  [XMC-Agent : Dynamic Navigation over Scalable Hierarchical Index for Incremental Extreme Multi-label Classification](https://doi.org/10.18653/v1/2024.findings-acl.336) |  | 0 | The eXtreme Multi-label Classification (XMC) aims at accurately assigning large-scale labels to instances, and is challenging for learning, managing, and predicting over the large-scale and rapidly growing set of labels. Traditional XMC methods, like one-vs-all and tree-based methods struggle with... | Ben He, Hongyu Lin, Huijia Zhu, Le Sun, Shuheng Zhou, Tianyun Zhong, Weiqiang Wang, Xianpei Han, Yanjiang Liu, Yaojie Lu, Zhongyi Liu |  |
| 1322 |  |  [Benchmarking Large Language Models on CFLUE - A Chinese Financial Language Understanding Evaluation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.337) |  | 0 | In light of recent breakthroughs in large language models (LLMs) that have revolutionized natural language processing (NLP), there is an urgent need for new benchmarks to keep pace with the fast development of LLMs. In this paper, we propose CFLUE, the Chinese Financial Language Understanding... | Jie Zhu, Junhui Li, Lifan Guo, Yalong Wen |  |
| 1323 |  |  [Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint](https://doi.org/10.18653/v1/2024.findings-acl.338) |  | 0 | Reinforcement learning (RL) has been widely used in training large language models (LLMs) for preventing unexpected outputs, e.g., reducing harmfulness and errors. However, existing RL methods mainly adopt instance-level reward, which cannot provide fine-grained supervision for complex reasoning... | Di Zhang, Fuzheng Zhang, JiRong Wen, Junchen Wan, Kun Zhou, Xin Zhao, Zhipeng Chen |  |
| 1324 |  |  [Definition generation for lexical semantic change detection](https://doi.org/10.18653/v1/2024.findings-acl.339) |  | 0 | We use contextualized word definitions generated by large language models as semantic representations in the task of diachronic lexical semantic change detection (LSCD). In short, generated definitions are used as ‘senses’, and the change score of a target word is retrieved by comparing their... | Andrey Kutuzov, Mariia Fedorova, Yves Scherrer |  |
| 1325 |  |  [MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector](https://doi.org/10.18653/v1/2024.findings-acl.340) |  | 0 | Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the... | Alexandre Mourachko, Carleigh Wood, Christophe Ropers, David Dale, Elahe Kalbassi, Mariano Coria Meglioli, Marta R. Costajussà, Pierre Andrews, Prangthip Hansanti |  |
| 1326 |  |  [Phased Instruction Fine-Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.341) |  | 0 | Instruction Fine-Tuning, a method enhancing pre-trained language models’ capabilities from mere next-word prediction to complex instruction following, often employs a one-off training approach on diverse instruction dataset. However, this method may not effectively enhance models’ adherence to... | Chuan Zhou, Wei Pang, XiaoHua Zhou, Xiaojie Wang |  |
| 1327 |  |  [TOREE: Evaluating Topic Relevance of Student Essays for Chinese Primary and Middle School Education](https://doi.org/10.18653/v1/2024.findings-acl.342) |  | 0 | Topic relevance of an essay demands that the composition adheres to a clear theme and aligns well with the essay prompt requirements, a critical aspect of essay quality evaluation. However, existing research of Automatic Essay Scoring (AES) for Chinese essays has overlooked topic relevance and... | Binxuan Liu, Gaowei Yi, Hongyi Wu, Man Lan, Peimin Yu, Tu Hu, Xinhao Chen, Xinlin Zhuang, Xinshu Shen, Yadong Zhang, Yang Chen, Youqi Song, Yupei Ren |  |
| 1328 |  |  [Predicting the Unpredictable: Uncertainty-Aware Reasoning over Temporal Knowledge Graphs via Diffusion Process](https://doi.org/10.18653/v1/2024.findings-acl.343) |  | 0 | Temporal Knowledge Graph (TKG) reasoning seeks to predict future incomplete facts leveraging historical data. While existing approaches have shown effectiveness in addressing the task through various perspectives, such as graph learning and logic rules, they are limited in capturing the... | Changlin Li, Da Luo, JiayeYang JiayeYang, Qiao Liu, Run Lin, Xueyi Liu, Yanglei Gan, Yuxiang Cai |  |
| 1329 |  |  [Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-acl.344) |  | 0 | The widespread use of Text-to-Image (T2I) models in content generation requires careful examination of their safety, including their robustness to adversarial attacks. Despite extensive research on adversarial attacks, the reasons for their effectiveness remain underexplored. This paper presents an... | Greg Ver Steeg, Haz Sameen Shahgir, Xianghao Kong, Yue Dong |  |
| 1330 |  |  [Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs](https://doi.org/10.18653/v1/2024.findings-acl.345) |  | 0 | Controlled Text Generation (CTG) aims to produce texts that exhibit specific desired attributes. In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG). This framework utilizes an attribute scorer... | Bo Tang, Feiyu Xiong, Hanyu Wang, Mengting Hu, Shichao Song, Xun Liang, Xunzhi Wang, Zhiyu Li |  |
| 1331 |  |  [Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.346) |  | 0 | In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples... | JunHyung Park, Junho Kim, Mingyu Lee, SangKeun Lee |  |
| 1332 |  |  [Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge](https://doi.org/10.18653/v1/2024.findings-acl.347) |  | 0 | Recent research has explored methods for updating and modifying factual knowledge in large language models, often focusing on specific multi-layer perceptron blocks. This study expands on this work by examining the effectiveness of existing knowledge editing methods across languages and delving... | Aitor GonzalezAgirre, Daniel Mela, Javier Hernando, Marta Villegas |  |
| 1333 |  |  [BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains](https://doi.org/10.18653/v1/2024.findings-acl.348) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the... | Adrien Bazoge, Emmanuel Morin, Mickael Rouvier, PierreAntoine Gourraud, Richard Dufour, Yanis Labrak |  |
| 1334 |  |  [All Languages Matter: On the Multilingual Safety of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.349) |  | 0 | Safety lies at the core of developing and deploying large language models (LLMs). However, previous safety benchmarks only concern the safety in one language, e.g. the majority language in the pretraining data such as English. In this work, we build the first multilingual safety benchmark for LLMs,... | Chang Chen, Jentse Huang, Michael R. Lyu, Wenxiang Jiao, Wenxuan Wang, Youliang Yuan, Zhaopeng Tu |  |
| 1335 |  |  [LJPCheck: Functional Tests for Legal Judgment Prediction](https://doi.org/10.18653/v1/2024.findings-acl.350) |  | 0 | Legal Judgment Prediction (LJP) refers to the task of automatically predicting judgment results (e.g., charges, law articles and term of penalty) given the fact description of cases. While SOTA models have achieved high accuracy and F1 scores on public datasets, existing datasets fail to evaluate... | Bin Luo, Chuanyi Li, Jidong Ge, Vincent Ng, Wanhong Huang, Yi Feng, Yuan Zhang, Zhiwei Fei |  |
| 1336 |  |  [CMDL: A Large-Scale Chinese Multi-Defendant Legal Judgment Prediction Dataset](https://doi.org/10.18653/v1/2024.findings-acl.351) |  | 0 | Legal Judgment Prediction (LJP) has attracted significant attention in recent years. However, previous studies have primarily focused on cases involving only a single defendant, skipping multi-defendant cases due to complexity and difficulty. To advance research, we introduce CMDL, a large-scale... | Chuanyi Li, Honghan Wu, Jidong Ge, Vincent Ng, Wanhong Huang, Yi Feng |  |
| 1337 |  |  [Model Editing by Standard Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.352) |  | 0 | Standard fine-tuning is considered not as effective as specialized methods for model editing due to its comparatively poor performance. However, it is simple, agnostic to the architectural details of the model being edited, and able to leverage advances in standard training techniques with no... | Govind Krishnan Gangadhar, Karl Stratos |  |
| 1338 |  |  [Abstract Meaning Representation-Based Logic-Driven Data Augmentation for Logical Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.353) |  | 0 | Combining large language models with logical reasoning enhances their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges when gathering reliable data from the web to build comprehensive training datasets,... | Alex Yuxuan Peng, Gaël Gendron, Jiamou Liu, Michael Witbrock, Nathan Young, Neset Tan, Paul Denny, Qiming Bao, Timothy Pistotti, Wanjun Zhong, Yang Chen, Yonghua Zhu, Zhenyun Deng |  |
| 1339 |  |  [CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow](https://doi.org/10.18653/v1/2024.findings-acl.354) |  | 0 | We introduce a novel dataset tailored for code generation, aimed at aiding developers in common tasks. Our dataset provides examples that include a clarified intent, code snippets associated, and an average of three related unit tests. It encompasses a range of libraries such as Pandas, Numpy, and... | Benoît Crabbé, Nathanaël Beau |  |
| 1340 |  |  [ViHateT5: Enhancing Hate Speech Detection in Vietnamese With a Unified Text-to-Text Transformer Model](https://doi.org/10.18653/v1/2024.findings-acl.355) |  | 0 | Recent advancements in hate speech detection (HSD) in Vietnamese have made significant progress, primarily attributed to the emergence of transformer-based pre-trained language models, particularly those built on the BERT architecture. However, the necessity for specialized fine-tuned models has... | Luan Thanh Nguyen |  |
| 1341 |  |  [Bias in News Summarization: Measures, Pitfalls and Corpora](https://doi.org/10.18653/v1/2024.findings-acl.356) |  | 0 | Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their content selection, faithfulness, grammaticality and coherence. However, it is well known that LLMs can reproduce and reinforce harmful social biases. This... | Julius Steen, Katja Markert |  |
| 1342 |  |  [When to Trust LLMs: Aligning Confidence with Response Quality](https://doi.org/10.18653/v1/2024.findings-acl.357) |  | 0 | Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods often... | Bolin Ding, Fei Sun, Hanxing Ding, Huawei Shen, Jinyang Gao, Liuyi Yao, Qi Cao, Shuchang Tao, Yuexiang Xie |  |
| 1343 |  |  [Zero-shot Cross-lingual Alignment for Embedding Initialization](https://doi.org/10.18653/v1/2024.findings-acl.358) |  | 0 | For multilingual training, we present CrossInit, an initialization method that initializes embeddings into similar geometrical structures across languages in an unsupervised manner. CrossInit leverages a common cognitive linguistic mechanism, Zipf’s law, which indicates that similar concepts across... | Xi Ai, Zhiyong Huang |  |
| 1344 |  |  [Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)](https://doi.org/10.18653/v1/2024.findings-acl.359) |  | 0 | Large Vision-Language Models (LVLMs) are an extension of Large Language Models (LLMs) that facilitate processing both image and text inputs, expanding AI capabilities. However, LVLMs struggle with object hallucinations due to their reliance on text cues and learned object co-occurrence biases.... | Avshalom Manevich, Reut Tsarfaty |  |
| 1345 |  |  [It takes two to borrow: a donor and a recipient. Who's who?](https://doi.org/10.18653/v1/2024.findings-acl.360) |  | 0 | We address the open problem of automatically identifying the direction of lexical borrowing, given word pairs in the donor and recipient languages. We propose strong benchmarks for this task, by applying a set of machine learning models. We extract and publicly release a comprehensive borrowings... | Ana Sabina Uban, Anca Dinu, IoanBogdan Iordache, Laurentiu Zoicas, Liviu P. Dinu, Simona Georgescu |  |
| 1346 |  |  [Advancing Post-OCR Correction: A Comparative Study of Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.361) |  | 0 | This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages... | Derek Greene, Shuhao Guan |  |
| 1347 |  |  [GeoAgent: To Empower LLMs using Geospatial Tools for Address Standardization](https://doi.org/10.18653/v1/2024.findings-acl.362) |  | 0 | This paper presents a novel solution to tackle the challenges that posed by the abundance of non-standard addresses, which input by users in modern applications such as navigation maps, ride-hailing apps, food delivery platforms, and logistics services. These manually entered addresses often... | Chenghua Huang, Jianfeng Qu, Jiaxin Liu, Shisong Chen, Yanghua Xiao, Zhigang Chen, Zhixu Li |  |
| 1348 |  |  [HQP: A Human-Annotated Dataset for Detecting Online Propaganda](https://doi.org/10.18653/v1/2024.findings-acl.363) |  | 0 | Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following... | Abdurahman Maarouf, Dominik Bär, Dominique Geissler, Stefan Feuerriegel |  |
| 1349 |  |  [Teaching Language Models to Self-Improve by Learning from Language Feedback](https://doi.org/10.18653/v1/2024.findings-acl.364) |  | 0 | Aligning Large Language Models (LLMs) with human intentions and values is crucial yet challenging. Current methods primarily rely on human preferences, which are costly and insufficient in capturing nuanced feedback expressed in natural language. In this paper, we present Self-Refinement Tuning... | Chi Hu, Hang Cao, JingBo Zhu, Tong Xiao, Yimin Hu |  |
| 1350 |  |  [Exploring Spatial Schema Intuitions in Large Language and Vision Models](https://doi.org/10.18653/v1/2024.findings-acl.365) |  | 0 | Despite the ubiquity of large language models (LLMs) in AI research, the question of embodiment in LLMs remains underexplored, distinguishing them from embodied systems in robotics where sensory perception directly informs physical action.Our investigation navigates the intriguing terrain of... | Lennart Wachowiak, Philipp Wicke |  |
| 1351 |  |  [Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model](https://doi.org/10.18653/v1/2024.findings-acl.366) |  | 0 | The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot... | Hao Zhang, Hongcheng Gao, Yibo Miao, Zhijie Deng |  |
| 1352 |  |  [Decoding the Narratives: Analyzing Personal Drug Experiences Shared on Reddit](https://doi.org/10.18653/v1/2024.findings-acl.367) |  | 0 | Online communities such as drug-related subreddits serve as safe spaces for people who use drugs (PWUD), fostering discussions on substance use experiences, harm reduction, and addiction recovery. Users’ shared narratives on these forums provide insights into the likelihood of developing a... | Elham Aghakhani, Layla Bouzoubaa, Max Song, Quang Trinh, Rezvaneh (Shadi) Rezapour |  |
| 1353 |  |  [Unveiling the Art of Heading Design: A Harmonious Blend of Summarization, Neology, and Algorithm](https://doi.org/10.18653/v1/2024.findings-acl.368) |  | 0 | Crafting an appealing heading is crucial for attracting readers and marketing work or products. A popular way is to summarize the main idea with a refined description and a memorable acronym. However, there lacks a systematic study and a formal benchmark including datasets and metrics. Motivated by... | Boi Faltings, Shaobo Cui, Yifan Hou, Yisong Mao, Yiyang Feng |  |
| 1354 |  |  [Understanding Fine-grained Distortions in Reports of Scientific Findings](https://doi.org/10.18653/v1/2024.findings-acl.369) |  | 0 | Distorted science communication harms individuals and society as it can lead to unhealthy behavior change and decrease trust in scientific institutions. Given the rapidly increasing volume of science communication in recent years, a fine-grained understanding of how findings from scientific... | Amelie Wührl, Dustin Wright, Isabelle Augenstein, Roman Klinger |  |
| 1355 |  |  [MM-SOC: Benchmarking Multimodal Large Language Models in Social Media Platforms](https://doi.org/10.18653/v1/2024.findings-acl.370) |  | 0 | Social media platforms are hubs for multimodal information exchange, encompassing text, images, and videos, making it challenging for machines to comprehend the information or emotions associated with interactions in online spaces. Multimodal Large Language Models (MLLMs) have emerged as a... | Gaurav Verma, Jindong Wang, Minje Choi, Srijan Kumar, Yiqiao Jin |  |
| 1356 |  |  [Instances Need More Care: Rewriting Prompts for Instances with LLMs in the Loop Yields Better Zero-Shot Performance](https://doi.org/10.18653/v1/2024.findings-acl.371) |  | 0 | Large language models (LLMs) have revolutionized zero-shot task performance, mitigating the need for task-specific annotations while enhancing task generalizability. Despite its advancements, current methods using trigger phrases such as “Let’s think step by step” remain limited. This study... | Chengyue Huang, Saurabh Srivastava, Weiguo Fan, Ziyu Yao |  |
| 1357 |  |  [Benchmarking Retrieval-Augmented Generation for Medicine](https://doi.org/10.18653/v1/2024.findings-acl.372) |  | 0 | While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted.... | Aidong Zhang, Guangzhi Xiong, Qiao Jin, Zhiyong Lu |  |
| 1358 |  |  [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://doi.org/10.18653/v1/2024.findings-acl.373) |  | 0 | While LLMs demonstrate impressive capabilities in musical knowledge, we find that music reasoning is still an unsolved task.We introduce ChatMusician, an open-source large language model (LLM) that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2... | Chenghua Lin, Cong Liu, Emmanouil Benetos, Ge Zhang, Gus Xia, Hanfeng Lin, Jie Fu, Liumeng Xue, Qifeng Liu, Qin Liu, Roger B. Dannenberg, Ruibin Yuan, Ruibo Liu, Shangda Wu, Shiyin Kang, Tao Jiang, Tianhao Shen, Tianyu Zheng, Wei Xue, Wenhao Huang, Wenhu Chen, Xiaowei Chi, Yi Wang, Yike Guo, Yiming Liang, Yinghao Ma, Yizhi Li, Yuhang Wu, Zeyue Tian, Zili Wang, Ziya Zhou, Ziyang Ma |  |
| 1359 |  |  [Towards Robust Temporal Reasoning of Large Language Models via a Multi-Hop QA Dataset and Pseudo-Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.374) |  | 0 | Knowledge in the real world is being updated constantly. However, it is costly to frequently update large language models (LLMs). Therefore, it is crucial for LLMs to understand the concept of temporal knowledge. However, prior works on temporal question answering (TQA) did not emphasize... | Hwee Tou Ng, Lidong Bing, Qingyu Tan |  |
| 1360 |  |  [Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements](https://doi.org/10.18653/v1/2024.findings-acl.375) |  | 0 |  | Anton Voronov, Lena Wolf, Max Ryabinin |  |
| 1361 |  |  [Knowledge Graph-Enhanced Large Language Models via Path Selection](https://doi.org/10.18653/v1/2024.findings-acl.376) |  | 0 | Large Language Models (LLMs) have shown unprecedented performance in various real-world applications. However, they are known to generate factually inaccurate outputs, a.k.a. the hallucination problem. In recent years, incorporating external knowledge extracted from Knowledge Graphs (KGs) has... | Haochen Liu, Jundong Li, Song Wang, Yaochen Zhu, Yushun Dong |  |
| 1362 |  |  [OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission Translation Errors Detection](https://doi.org/10.18653/v1/2024.findings-acl.377) |  | 0 | Recently, there has been considerable attention on detecting hallucinations and omissions in Machine Translation (MT) systems. The two dominant approaches to tackle this task involve analyzing the MT system’s internal states or relying on the output of external tools, such as sentence similarity or... | Abbas Ghaddar, Boxing Chen, Chenyang Huang, Ivan Kobyzev, Mehdi Rezagholizadeh, Osmar Zaïane |  |
| 1363 |  |  [ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.378) |  | 0 | In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we... | Chengbao Liu, Jie Tan, Jingwei Li, Kang Liu, Wangtao Sun, Xuanqing Yu |  |
| 1364 |  |  [Speech-based Slot Filling using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.379) |  | 0 | Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated... | Chao Zhang, Dongcheng Jiang, Guangzhi Sun, Milica Gasic, Philip C. Woodland, Shutong Feng |  |
| 1365 |  |  [Too Big to Fail: Larger Language Models are Disproportionately Resilient to Induction of Dementia-Related Linguistic Anomalies](https://doi.org/10.18653/v1/2024.findings-acl.380) |  | 0 | As artificial neural networks grow in complexity, understanding their inner workings becomes increasingly challenging, which is particularly important in healthcare applications. The intrinsic evaluation metrics of autoregressive neural language models (NLMs), perplexity (PPL), can reflect how... | Changye Li, Serguei Pakhomov, Trevor Cohen, Zhecheng Sheng |  |
| 1366 |  |  [HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew](https://doi.org/10.18653/v1/2024.findings-acl.381) |  | 0 | While large language models (LLMs) excel in various natural language tasks in English, their performance in low-resource languages like Hebrew, especially for generative tasks such as abstractive summarization, remains unclear. The high morphological richness in Hebrew adds further challenges due... | Asaf Achi Mordechai, Itai Mondshine, Reut Tsarfaty, Tzuf PazArgaman |  |
| 1367 |  |  [TRAM: Benchmarking Temporal Reasoning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.382) |  | 0 | Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper,... | Yun Zhao, Yuqing Wang |  |
| 1368 |  |  [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.383) |  | 0 | This paper investigates the capabilities of Large Language Models (LLMs) in understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our... | Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, William Yang Wang |  |
| 1369 |  |  [Exploring Defeasibility in Causal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.384) |  | 0 | Defeasibility in causal reasoning implies that the causal relationship between cause and effect can be strengthened or weakened. Namely, the causal strength between cause and effect should increase or decrease with the incorporation of strengthening arguments (supporters) or weakening arguments... | Antoine Bosselut, Boi Faltings, Debjit Paul, Lazar Milikic, Mete Ismayilzada, Shaobo Cui, Yiyang Feng |  |
| 1370 |  |  [Better Synthetic Data by Retrieving and Transforming Existing Datasets](https://doi.org/10.18653/v1/2024.findings-acl.385) |  | 0 | Despite recent advances in large language models, building dependable and deployable NLP models typically requires abundant, high-quality training data. However, task-specific data is not available for many use cases, and manually curating task-specific data is labor-intensive. Recent work has... | Graham Neubig, Ritu Gala, Saumya Gandhi, Tongshuang Wu, Vijay Viswanathan |  |
| 1371 |  |  [Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models](https://doi.org/10.18653/v1/2024.findings-acl.386) |  | 0 | In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to... | Hanqi Yan, Lin Gui, Yanzheng Xiang, Yulan He |  |
| 1372 |  |  [Perspective Taking through Generating Responses to Conflict Situations](https://doi.org/10.18653/v1/2024.findings-acl.387) |  | 0 | Although language model performance across diverse tasks continues to improve, these models still struggle to understand and explain the beliefs of other people. This skill requires perspective-taking, the process of conceptualizing the point of view of another person. Perspective taking becomes... | Charles Welch, Joan Plepi, Lucie Flek |  |
| 1373 |  |  [LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement](https://doi.org/10.18653/v1/2024.findings-acl.388) |  | 0 | Pretrained large language models (LLMs) are currently state-of-the-art for solving the vast majority of natural language processing tasks. While many real-world applications still require fine-tuning to reach satisfactory levels of performance, many of them are in the low-data regime, making... | Amir Gholami, Gopala Anumanchipalli, Karttikeya Mangalam, Kurt Keutzer, Michael W. Mahoney, Nicholas Lee, Sehoon Kim, Sheng Shen, Thanakul Wattanawong |  |
| 1374 |  |  [The Power of Summary-Source Alignments](https://doi.org/10.18653/v1/2024.findings-acl.389) |  | 0 | Multi-document summarization (MDS) is a challenging task, often decomposed to subtasks of salience and redundancy detection, followed by text generation.In this context, alignment of corresponding sentences between a reference summary and its source documents has been leveraged to generate training... | Aviv Slobodkin, Ido Dagan, Jacob Goldberger, Mohit Bansal, Ori Ernst, Ori Shapira, Ran Levy, Sharon Adar |  |
| 1375 |  |  [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.390) |  | 0 | Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming... | Arnav Mohanty Das, Gantavya Bhatt, Jeff A. Bilmes, Jifan Zhang, Jordan T. Ash, Kevin G. Jamieson, Robert D. Nowak, Sang T. Truong, Simon S. Du, Stephen Mussmann, Yifang Chen, Yinglun Zhu |  |
| 1376 |  |  [Learning Multimodal Contrast with Cross-modal Memory and Reinforced Contrast Recognition](https://doi.org/10.18653/v1/2024.findings-acl.391) |  | 0 | In many practical scenarios, contents from different modalities are not semantically aligned; for instance, visual and textual information may conflict with each other, resulting in non-compositional expression effects such as irony or humor. Effective modeling and smooth integration of multimodal... | Fei Xia, Yan Song, Yuanhe Tian |  |
| 1377 |  |  [Text Simplification via Adaptive Teaching](https://doi.org/10.18653/v1/2024.findings-acl.392) |  | 0 | Text simplification is the process of rewriting a piece of text using simpler vocabulary and grammatical structure in order to make the text more accessible and understandable for a larger audience. In this paper, we introduce a new text simplification model based on the notion of adaptive teaching... | Carsten Eickhoff, Jonathan Dou, Seyed Ali Bahrainian |  |
| 1378 |  |  [A multi-level multi-label text classification dataset of 19th century Ottoman and Russian literary and critical texts](https://doi.org/10.18653/v1/2024.findings-acl.393) |  | 0 | This paper introduces a multi-level, multi-label text classification dataset comprising over 3000 documents. The dataset features literary and critical texts from 19th-century Ottoman Turkish and Russian. It is the first study to apply large language models (LLMs) to this dataset, sourced from... | Devrim Cavusoglu, Emre Akbas, Gokcen Gokceoglu, Özen Nergis Dolcerocca |  |
| 1379 |  |  [It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment Analysis Performance](https://doi.org/10.18653/v1/2024.findings-acl.394) |  | 0 | Aspect-Based Sentiment Analysis (ABSA) involves extracting opinions from textual data about specific entities and their corresponding aspects through various complementary subtasks. Several prior research has focused on developing ad hoc designs of varying complexities for these subtasks. In this... | Laura Cabello, Uchenna Akujuobi |  |
| 1380 |  |  [Whose Emotions and Moral Sentiments do Language Models Reflect?](https://doi.org/10.18653/v1/2024.findings-acl.395) |  | 0 | Language models (LMs) are known to represent the perspectives of some social groups better than others, which may impact their performance, especially on subjective tasks such as content moderation and hate speech detection. To explore how LMs represent different perspectives, existing research... | Ashwin Rao, Kristina Lerman, Siyi Guo, Zihao He |  |
| 1381 |  |  [LLM can Achieve Self-Regulation via Hyperparameter Aware Generation](https://doi.org/10.18653/v1/2024.findings-acl.396) |  | 0 | In the realm of Large Language Models (LLMs), users commonly employ diverse decoding strategies and adjust hyperparameters to control the generated text. However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves? The... | Jiasheng Ye, Jinlan Fu, Junjie Ye, Qinyuan Cheng, Shimin Li, Siyin Wang, Tianxiang Sun, Xipeng Qiu, Xuanjing Huang |  |
| 1382 |  |  [Forward-Backward Reasoning in Large Language Models for Mathematical Verification](https://doi.org/10.18653/v1/2024.findings-acl.397) |  | 0 | Self-Consistency samples diverse reasoning chains with answers and chooses the final answer by majority voting. It is based on forward reasoning and cannot further improve performance by sampling more reasoning chains when saturated. To further boost performance, we introduce backward reasoning to... | Han Shi, James T. Kwok, Longhui Yu, Weisen Jiang, Yu Zhang, Zhenguo Li, Zhengying Liu |  |
| 1383 |  |  [Towards Uncertainty-Aware Language Agent](https://doi.org/10.18653/v1/2024.findings-acl.398) |  | 0 | While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware... | Ehsan Shareghi, Jiuzhou Han, Wray L. Buntine |  |
| 1384 |  |  [Detection and Positive Reconstruction of Cognitive Distortion Sentences: Mandarin Dataset and Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.399) |  | 0 | This research introduces a Positive Reconstruction Framework based on positive psychology theory. Overcoming negative thoughts can be challenging, our objective is to address and reframe them through a positive reinterpretation. To tackle this challenge, a two-fold approach is necessary:... | Jonathan Dong, Shiguang Ni, Shuya Lin, Yuxiong Wang |  |
| 1385 |  |  [PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.400) |  | 0 | Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pre-training data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework,... | Ehsan Shareghi, Jiuzhou Han, Nigel Collier, Wray L. Buntine |  |
| 1386 |  |  [Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.401) |  | 0 | Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over... | Dongsheng Li, Linbo Qiao, Yifu Gao, Yongquan He, Zhigang Kan, Zhihua Wen |  |
| 1387 |  |  [VISREAS: Complex Visual Reasoning with Unanswerable Questions](https://doi.org/10.18653/v1/2024.findings-acl.402) |  | 0 | Verifying a question’s validity before answering is crucial in real-world applications, where users may provide imperfect instructions. In this scenario, an ideal model should address the discrepancies in the query and convey them to the users rather than generating the best possible answer.... | Eric Nyberg, Sangwu Lee, Syeda Nahida Akter, Yingshan Chang, Yonatan Bisk |  |
| 1388 |  |  [A Unified Generative Framework for Bilingual Euphemism Detection and Identification](https://doi.org/10.18653/v1/2024.findings-acl.403) |  | 0 | Various euphemisms are emerging in social networks, attracting widespread attention from the natural language processing community. However, existing euphemism datasets are only domain-specific or language-specific. In addition, existing approaches to the study of euphemisms are one-sided. Either... | Dongyu Su, Guixin Su, Junsong Li, Tongguan Wang, Ying Sha, Yuxue Hu |  |
| 1389 |  |  [StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing](https://doi.org/10.18653/v1/2024.findings-acl.404) |  | 0 | Given a script, the challenge in Movie Dubbing (Visual Voice Cloning, V2C) is to generate speech that aligns well with the video in both time and emotion, based on the tone of a reference audio track. Existing state-of-the-art V2C models break the phonemes in the script according to the divisions... | Amin Beheshti, Anton van den Hengel, Chenggang Yan, Gaoxiang Cong, Liang Li, MingHsuan Yang, Qingming Huang, Yuankai Qi, Zhedong Zhang |  |
| 1390 |  |  [ETAS: Zero-Shot Transformer Architecture Search via Network Trainability and Expressivity](https://doi.org/10.18653/v1/2024.findings-acl.405) |  | 0 | Transformer Architecture Search (TAS) methods aim to automate searching for the optimal Transformer architecture configurations for a given task. However, they are impeded by the prohibitive cost of evaluating Transformer architectures. Recently, several Zero-Shot TAS methods have been proposed to... | Jiechao Yang, Yong Liu |  |
| 1391 |  |  [Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment](https://doi.org/10.18653/v1/2024.findings-acl.406) |  | 0 | Medical dialogue systems have attracted significant attention for their potential to act as medical assistants. Enabling these medical systems to emulate clinicians’ diagnostic reasoning process has been the long-standing research focus. Previous studies rudimentarily realized the simulation of... | Kaishuai Xu, Qiaoyu Tan, Wenjie Li, Wenjun Hou, Yi Cheng |  |
| 1392 |  |  [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.407) |  | 0 | This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath... | Bo Zheng, Chenchen Zhang, Haibin Chen, Jiaheng Liu, Jie Liu, Tiezheng Ge, Wanli Ouyang, Wenbo Su, Xingyuan Bu, Yanan Wu, Yuanxing Zhang, Zhanhui Zhou, Zhiqi Bai |  |
| 1393 |  |  [REInstruct: Building Instruction Data from Unlabeled Corpus](https://doi.org/10.18653/v1/2024.findings-acl.408) |  | 0 | Manually annotating instruction data for large language models is difficult, costly, and hard to scale. Meanwhile, current automatic annotation methods typically rely on distilling synthetic data from proprietary LLMs, which not only limits the upper bound of the quality of the instruction data but... | Hongyu Lin, Le Sun, Shu Chen, Xianpei Han, Xinyan Guan, Yaojie Lu |  |
| 1394 |  |  [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://doi.org/10.18653/v1/2024.findings-acl.409) |  | 0 | Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller... | Hanxian Huang, Jishen Zhao, Ke Ding, Xin Chen, Yanjun Gao, Yi Wang |  |
| 1395 |  |  [PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning](https://doi.org/10.18653/v1/2024.findings-acl.410) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as an effective method for adapting pre-trained language models to various tasks efficiently. Recently, there has been a growing interest in transferring knowledge from one or multiple tasks to the downstream target task to achieve performance... | Chenghao Liu, Han Fu, Jianling Sun, Zhisheng Lin, Zhuo Li |  |
| 1396 |  |  [MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.411) |  | 0 | Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics. However, traditional math benchmarks like GSM8k offer a unidimensional perspective, which fall short in providing a holistic assessment of the LLMs’ math capabilities. To address this gap, we... | Dahua Lin, Fengzhe Zhou, Haodong Duan, Hongwei Liu, Kai Chen, Songyang Zhang, Wenwei Zhang, Yuxuan Qiao, Zhiwei Fei, Zilong Zheng |  |
| 1397 |  |  [Identifying Semantic Induction Heads to Understand In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.412) |  | 0 | Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to... | Dahua Lin, Dongrui Liu, Hang Yan, Jie Ren, Qipeng Guo, Quanshi Zhang, Xipeng Qiu |  |
| 1398 |  |  [Chinese Spelling Corrector Is Just a Language Learner](https://doi.org/10.18653/v1/2024.findings-acl.413) |  | 0 | This paper emphasizes Chinese spelling correction by means of self-supervised learning, which means there are no annotated errors within the training data. Our intuition is that humans are naturally good correctors with exposure to error-free sentences, which contrasts with current unsupervised... | Hai Zhao, Hongqiu Wu, Lai Jiang, Min Zhang |  |
| 1399 |  |  [Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.414) |  | 0 |  | Ding Wang, Jinghao Zhang, Junfei Wu, Liang Wang, Qiang Liu, Shu Wu, Tieniu Tan |  |
| 1400 |  |  [RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.415) |  | 0 | Adaptive retrieval-augmented generation (ARAG) aims to dynamically determine the necessity of retrieval for queries instead of retrieving indiscriminately to enhance the efficiency and relevance of the sourced information. However, previous works largely overlook the evaluation of ARAG approaches,... | Ling Chen, Meng Fang, Zihan Zhang |  |
| 1401 |  |  [LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.416) |  | 0 | We introduces \*\*\*LLaST\*\*\*, a framework for building high-performance Large Language model based Speech-to-text Translation systems. We address the limitations of end-to-end speech translation (E2E ST) models by exploring model architecture design and optimization techniques tailored for LLMs.... | Kai Chen, Qibing Bai, Satoshi Nakamura, Songyang Zhang, Xi Chen |  |
| 1402 |  |  [Plan, Generate and Complicate: Improving Low-resource Dialogue State Tracking via Easy-to-Difficult Zero-shot Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.417) |  | 0 | Data augmentation methods have been a promising direction to improve the performance of small models for low-resource dialogue state tracking. However, traditional methods rely on pre-defined user goals and neglect the importance of data complexity in this task. In this paper, we propose EDZ-DA, an... | Ming Gu, Yan Yang |  |
| 1403 |  |  [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](https://doi.org/10.18653/v1/2024.findings-acl.418) |  | 0 | The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning. There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance... | Shanghaoran Quan |  |
| 1404 |  |  [LEIA: Facilitating Cross-lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.419) |  | 0 | Adapting English-based large language models (LLMs) to other languages has become increasingly popular due to the efficiency and potential of cross-lingual transfer. However, existing language adaptation methods often overlook the benefits of cross-lingual supervision. In this study, we introduce... | Ikuya Yamada, Ryokan Ri |  |
| 1405 |  |  [Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective](https://doi.org/10.18653/v1/2024.findings-acl.420) |  | 0 | Code generation aims to understand the problem description and generate corresponding code snippets, where existing works generally decompose such complex tasks into intermediate steps by prompting strategies, such as Chain-of-Thought and its variants. While these studies have achieved some... | Fandong Meng, Jie Zhou, Jinan Xu, Yijie Chen, Yijin Liu, Yufeng Chen |  |
| 1406 |  |  [Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration](https://doi.org/10.18653/v1/2024.findings-acl.421) |  | 0 | The proliferation of Large Language Models (LLMs) has led to an influx of AI-generated content (AIGC) on the internet, transforming the corpus of Information Retrieval (IR) systems from solely human-written to a coexistence with LLM-generated content. The impact of this surge in AIGC on IR systems... | Gang Wang, JiRong Wen, Jun Xu, Liang Pang, Rongju Ruan, Sunhao Dai, Weihao Liu, Yuqi Zhou, Zhenhua Dong |  |
| 1407 |  |  [Continual Dialogue State Tracking via Reason-of-Select Distillation](https://doi.org/10.18653/v1/2024.findings-acl.422) |  | 0 | An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services, confronting catastrophic forgetting and a critical capability loss termed the... | Albert Y. S. Lam, Bo Liu, LiMing Zhan, XiaoMing Wu, Xiaoyu Dong, Yujie Feng, Zexin Lu |  |
| 1408 |  |  [Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text](https://doi.org/10.18653/v1/2024.findings-acl.423) |  | 0 | AI-generated text detection has attracted increasing attention as powerful language models approach human-level generation. Limited work is devoted to detecting (partially) AI-paraphrased texts. However, AI paraphrasing is commonly employed in various application scenarios for text refinement and... | Leyang Cui, Shuming Shi, Wei Bi, Yafu Li, Yue Zhang, Zhilin Wang |  |
| 1409 |  |  [SoFA: Shielded On-the-fly Alignment via Priority Rule Following](https://doi.org/10.18653/v1/2024.findings-acl.424) |  | 0 | The alignment problem in Large Language Models (LLMs) involves adapting them to the broad spectrum of human values. This requirement challenges existing alignment methods due to diversity of preferences and regulatory standards. This paper introduces a novel alignment paradigm, priority rule... | Bowen Yu, Haiyang Yu, Hongyu Lin, Le Sun, Xianpei Han, Xinyu Lu, Yaojie Lu, Yongbin Li |  |
| 1410 |  |  [Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition](https://doi.org/10.18653/v1/2024.findings-acl.425) |  | 0 | Recent advances in LLMs have sparked a debate on whether they understand text. In this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. To substantiate this claim, we propose a... | Ariel Goldstein, Gabriel Stanovsky |  |
| 1411 |  |  [Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning](https://doi.org/10.18653/v1/2024.findings-acl.426) |  | 0 | Telling stories is an integral part of human communication which can evoke emotions and influence the affective states of the audience. Automatically modeling emotional trajectories in stories has thus attracted considerable scholarly interest. However, as most existing works have been limited to... | Björn W. Schuller, Ilhan Aslan, Lukas Christ, Manuel Milling, Shahin Amiriparian |  |
| 1412 |  |  [RAP: Efficient Text-Video Retrieval with Sparse-and-Correlated Adapter](https://doi.org/10.18653/v1/2024.findings-acl.427) |  | 0 | Text-Video Retrieval (TVR) aims to align relevant video content with natural language queries. To date, most of the state-of-the-art TVR methods learn image-to-video transfer learning based on the large-scale pre-trained vision-language models (e.g., CLIP). However, fully fine-tuning these... | Can Zhang, Ge Li, Haoran Tang, Jinfa Huang, Li Yuan, Long Chen, Meng Cao, Peng Jin, Ruyang Liu, Xiaodan Liang |  |
| 1413 |  |  [Benchmarking and Improving Long-Text Translation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.428) |  | 0 | Recent studies have illuminated the promising capabilities of large language models (LLMs) in handling long texts. However, their performance in machine translation (MT) of long documents remains underexplored. This paper aims to shed light on how LLMs navigate this complex task, offering a... | Chenyang Lyu, Derek F. Wong, Jianhui Pang, Kaiqiang Song, Leyang Cui, Longyue Wang, Shuming Shi, Wenxiang Jiao, Zefeng Du, Zhaopeng Tu |  |
| 1414 |  |  [Personalized Topic Selection Model for Topic-Grounded Dialogue](https://doi.org/10.18653/v1/2024.findings-acl.429) |  | 0 | Recently, the topic-grounded dialogue (TGD) system has become increasingly popular as its powerful capability to actively guide users to accomplish specific tasks through topic-guided conversations. Most existing works utilize side information (e.g. topics or personas) in isolation to enhance the... | Dangyang Chen, Jixiong Chen, Shixuan Fan, Wei Wei, XianLing Mao, Xiaofei Wen |  |
| 1415 |  |  [Debiasing In-Context Learning by Instructing LLMs How to Follow Demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.430) |  | 0 | In-context learning(ICL) has gained considerable attention due to its data efficiency and task adaptability. Unfortunately, ICL suffers from the demonstration bias, i.e., its performance and robustness are severely affected by the selection and ordering of demonstrations. In this paper, we identify... | Hongyu Lin, Huijia Zhu, Jiaqi Chen, Le Sun, Lvxue Li, Shuheng Zhou, Weiqiang Wang, Xianpei Han, Xinyu Lu, Yaojie Lu, Zhongyi Liu |  |
| 1416 |  |  [Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog Systems](https://doi.org/10.18653/v1/2024.findings-acl.431) |  | 0 | Creating effective and reliable task-oriented dialog systems (ToDSs) is challenging, not only because of the complex structure of these systems, but also due to the scarcity of training data, especially when several modules need to be trained separately, each one with its own input/output training... | Christos Vlachos, Ion Androutsopoulos, Themos Stafylakis |  |
| 1417 |  |  [MS2SL: Multimodal Spoken Data-Driven Continuous Sign Language Production](https://doi.org/10.18653/v1/2024.findings-acl.432) |  | 0 | Sign language understanding has made significant strides; however, there is still no viable solution for generating sign sequences directlyfrom entire spoken content, e.g., text or speech. In this paper, we propose a unified framework for continuous sign language production, easing communication... | Feng Zheng, Jian Ma, Wenguan Wang, Yi Yang |  |
| 1418 |  |  [BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.433) |  | 0 | Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional... | Lemao Liu, Lingpeng Kong, Qintong Li, Shansan Gong, Tingchen Fu, Wei Bi, Xinting Huang, Xueliang Zhao |  |
| 1419 |  |  [PartialFormer: Modeling Part Instead of Whole for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.434) |  | 0 | The design choices in Transformer feed-forward neural networks have resulted in significant computational and parameter overhead. In this work, we emphasize the importance of hidden dimensions in designing lightweight FFNs, a factor often overlooked in previous architectures. Guided by this... | Bei Li, Huiwen Bao, Jiale Wang, JingBo Zhu, Tong Xiao, Tong Zheng, Weiqiao Shan |  |
| 1420 |  |  [Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with Extract-Then-Assign Strategy](https://doi.org/10.18653/v1/2024.findings-acl.435) |  | 0 | In the task of aspect sentiment quad prediction (ASQP), generative methods for predicting sentiment quads have shown promisingresults. However, they still suffer from imprecise predictions and limited interpretability, caused by data scarcity and inadequate modeling of the quadruplet composition... | Dongha Lee, Jieyong Kim, Jinyoung Yeo, Ryang Heo, SeongKu Kang, Yongsik Seo |  |
| 1421 |  |  [PACE: Improving Prompt with Actor-Critic Editing for Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.436) |  | 0 | Large language models (LLMs) have showcased remarkable potential across various tasks by conditioning on prompts. However, the quality of different human-written prompts leads to substantial discrepancies in LLMs’ performance, and improving prompts usually necessitates considerable human effort and... | Ge Li, Kangcheng Luo, Xue Jiang, Yihong Dong, Zhi Jin |  |
| 1422 |  |  [Penetrative AI: Making LLMs Comprehend the Physical World](https://doi.org/10.18653/v1/2024.findings-acl.437) |  | 0 | Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real... | Huatao Xu, Liying Han, Mani Srivastava, Mo Li, Qirui Yang |  |
| 1423 |  |  [The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis](https://doi.org/10.18653/v1/2024.findings-acl.438) |  | 0 | In-context learning is a popular inference strategy where large language models solve a task using only a few labeled demonstrations without needing any parameter updates. Although there have been extensive studies on English in-context learning, multilingual in-context learning remains... | Dietrich Klakow, Jesujoba Alabi, Marius Mosbach, Miaoran Zhang, Mingyang Wang, Vagrant Gautam, Xiaoyu Shen |  |
| 1424 |  |  [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](https://doi.org/10.18653/v1/2024.findings-acl.439) |  | 0 |  | Hao Sun, Miao Zhang, Ming Dong, Tingting He, Yujing Chen |  |
| 1425 |  |  [An Empirical Study of In-context Learning in LLMs for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.440) |  | 0 | Recent interest has surged in employing Large Language Models (LLMs) for machine translation (MT) via in-context learning (ICL) (Vilar et al., 2023). Most prior studies primarily focus on optimizing translation quality, with limited attention to understanding the specific aspects of ICL that... | Jay P. Gala, Pranjal A. Chitale, Raj Dabre |  |
| 1426 |  |  ["My Answer is C": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models](https://doi.org/10.18653/v1/2024.findings-acl.441) |  | 0 | The open-ended nature of language generation makes the evaluation of autoregressive large language models (LLMs) challenging. One common evaluation approach uses multiple-choice questions to limit the response space. The model is then evaluated by ranking the candidate answers by the log... | Barbara Plank, Bolei Ma, Chengzhi Hu, Dirk Hovy, Frauke Kreuter, Leon WeberGenzel, Paul Röttger, Xinpeng Wang |  |
| 1427 |  |  [ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.442) |  | 0 | The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has achieved remarkable success in various natural language processing tasks. However, existing methodologies that integrate LLMs and KGs often navigate the task-solving process solely based on the LLM’s analysis of the... | Hiroshi Arakawa, Lei Sun, Youdi Li, Zhengwei Tao |  |
| 1428 |  |  [A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.443) |  | 0 | Large Language Models (LLMs) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques... | Gelei Deng, Stjepan Picek, Yi Liu, Yuekang Li, Zihao Xu |  |
| 1429 |  |  [A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning](https://doi.org/10.18653/v1/2024.findings-acl.444) |  | 0 |  | Foivos Charalampakos, Georgios Moschovis, Ion Androutsopoulos, John Pavlopoulos, Panagiotis Kaliosis |  |
| 1430 |  |  [Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.445) |  | 0 | Aligned Large Language Models (LLMs) showcase remarkable versatility, capable of handling diverse real-world tasks. Meanwhile, aligned LLMs are also expected to exhibit speciality, excelling in specific applications. However, fine-tuning with extra data, a common practice to gain speciality, often... | Dawei Li, Fei Tan, Hengyuan Zhang, Rui Zhao, Sak Yang, Yanru Wu, Yong Jiang |  |
| 1431 |  |  [A Two-Agent Game for Zero-shot Relation Triplet Extraction](https://doi.org/10.18653/v1/2024.findings-acl.446) |  | 0 | Relation triplet extraction is a fundamental task in natural language processing that aims to identify semantic relationships between entities in text. It is particularly challenging in the zero-shot setting, i.e., zero-shot relation triplet extraction (ZeroRTE), where the relation sets between... | Fei Zhao, Haiqin Yang, Ting Xu, Xinyu Dai, Zhen Wu |  |
| 1432 |  |  [Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning](https://doi.org/10.18653/v1/2024.findings-acl.447) |  | 0 | Parameter-efficient fine-tuning (PEFT) has emerged as the predominant technique for fine-tuning in the era of large language models. However, existing PEFT methods still have inadequate training efficiency. Firstly, the utilization of large-scale foundation models during the training process is... | Bowen Shen, Naibin Gu, Peng Fu, Weiping Wang, Xiyu Liu, Zheng Lin |  |
| 1433 |  |  [Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German](https://doi.org/10.18653/v1/2024.findings-acl.448) |  | 0 | The translation of gender-neutral person-referring terms (e.g.,the students) is often non-trivial.Translating from English into German poses an interesting case—in German, person-referring nouns are usually gender-specific, and if the gender of the referent(s) is unknown or diverse, the generic... | Anne Lauscher, Giuseppe Attanasio, Manuel Lardelli |  |
| 1434 |  |  [Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization](https://doi.org/10.18653/v1/2024.findings-acl.449) |  | 0 |  | Pengfei Liu, Ruifeng Yuan, Shichao Sun, Wenjie Li, Ziqiang Cao |  |
| 1435 |  |  [Trust in Internal or External Knowledge? Generative Multi-Modal Entity Linking with Knowledge Retriever](https://doi.org/10.18653/v1/2024.findings-acl.450) |  | 0 | Multi-modal entity linking (MEL) is a challenging task that requires accurate prediction of entities within extensive search spaces, utilizing multi-modal contexts. Existing generative approaches struggle with the knowledge gap between visual entity information and the intrinsic parametric... | Bowen Zhou, Fandong Meng, Jiali Zeng, Jie Zhou, Xinwei Long |  |
| 1436 |  |  [A Semantic Distance Metric Learning approach for Lexical Semantic Change Detection](https://doi.org/10.18653/v1/2024.findings-acl.451) |  | 0 | Detecting temporal semantic changes of words is an important task for various NLP applications that must make time-sensitive predictions.Lexical Semantic Change Detection (SCD) task involves predicting whether a given target word, w, changes its meaning between two different text corpora, C1 and... | Danushka Bollegala, Taichi Aida |  |
| 1437 |  |  [What Have We Achieved on Non-autoregressive Translation?](https://doi.org/10.18653/v1/2024.findings-acl.452) |  | 0 | Recent advances have made non-autoregressive (NAT) translation comparable to autoregressive methods (AT). However, their evaluation using BLEU has been shown to weakly correlate with human annotations. Limited research compares non-autoregressive translation and autoregressive translation... | Huajian Zhang, Jianhao Yan, Yafu Li, Yongjing Yin, Yue Zhang |  |
| 1438 |  |  [From Zero to Hero: Cold-Start Anomaly Detection](https://doi.org/10.18653/v1/2024.findings-acl.453) |  | 0 |  | Ateret AnabyTavor, George Kour, Naama Zwerdling, Tal Reiss, Yedid Hoshen |  |
| 1439 |  |  [Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives](https://doi.org/10.18653/v1/2024.findings-acl.454) |  | 0 | Existing datasets for narrative understanding often fail to represent the complexity and uncertainty of relationships in real-life social scenarios. To address this gap, we introduce a new benchmark, Conan, designed for extracting and analysing intricate character relation graphs from detective... | Hainiu Xu, Jiazheng Li, Lin Gui, Qinglin Zhu, Runcong Zhao, Yulan He, Yuxiang Zhou |  |
| 1440 |  |  [DistillMIKE: Editing Distillation of Massive In-Context Knowledge Editing in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.455) |  | 0 | Among the recently emerged knowledge editing methods, in-context knowledge editing (IKE) has shown respectable abilities on knowledge editing in terms of generalization and specificity. Noting the promising advantages but unexplored issues of IKE, we propose \*\*DistillMIKE\*\* as a novel extension... | SeungHoon Na, Shanbao Qiao, Xuebing Liu |  |
| 1441 |  |  [Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.456) |  | 0 | To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first drafts several future tokens efficiently and then verifies them in... | Heming Xia, Peiyi Wang, Qingxiu Dong, Tao Ge, Tianyu Liu, Wenjie Li, Yongqi Li, Zhe Yang, Zhifang Sui |  |
| 1442 |  |  [Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.457) |  | 0 | Hierarchical text classification (HTC) is a challenging problem with two key issues: utilizing structural information and mitigating label imbalance. Recently, the unit-based approach generating unit-based feature representations has outperformed the global approach focusing on a global feature... | Gibaeg Kim, HeungSeon Oh, Sanghun Im |  |
| 1443 |  |  [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](https://doi.org/10.18653/v1/2024.findings-acl.458) |  | 0 | In the era of large language models, applying techniques such as Retrieval Augmented Generation can better address Open-Domain Question-Answering problems. Due to constraints including model sizes and computing resources, the length of context is often limited, and it becomes challenging to empower... | Fei Huang, Kewei Tu, Pengjun Xie, Xinyu Wang, Yong Jiang, Zhuo Chen |  |
| 1444 |  |  [CICLe: Conformal In-Context Learning for Largescale Multi-Class Food Risk Classification](https://doi.org/10.18653/v1/2024.findings-acl.459) |  | 0 | Contaminated or adulterated food poses a substantial risk to human health. Given sets of labeled web texts for training, Machine Learning and Natural Language Processing can be applied to automatically detect such risks. We publish a dataset of 7,546 short texts describing public food recall... | Aron Henriksson, John Pavlopoulos, Korbinian Randl, Tony Lindgren |  |
| 1445 |  |  [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](https://doi.org/10.18653/v1/2024.findings-acl.460) |  | 0 | Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outliers in LLMs. Such outliers are found to... | Chun Yuan, Han Gao, Haokun Lin, Haoli Bai, Jun Yao, Lu Hou, Ruikang Liu, Yuening Li, Zhengzhuo Xu |  |
| 1446 |  |  [Learning Adverbs with Spectral Mixture Kernels](https://doi.org/10.18653/v1/2024.findings-acl.461) |  | 0 | For humans and robots to collaborate more in the real world, robots need to understand human intentions from the different manner of their behaviors. In our study, we focus on the meaning of adverbs which describe human motions. We propose a topic model, Hierarchical Dirichlet Process-Spectral... | Daichi Mochihashi, Ichiro Kobayashi, Tomoe Taniguchi |  |
| 1447 |  |  [E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.462) |  | 0 | The rapid development of Large Language Models (LLMs) has led to their increasing utilization in Chinese K-12 education. Despite the growing integration of LLMs and education, the absence of a dedicated benchmark for evaluating LLMs within this domain presents a pressing concern. Consequently,... | Chang Ao, Chengming Li, Daijia Tang, Haihong Wu, Jinchang Hou, Min Yang, Ruifeng Xu, Shiwen Ni, Xiangtao Kong, Xiping Hu, Zhigang Zheng |  |
| 1448 |  |  [ChartAssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.463) |  | 0 | Charts play a vital role in data visualization, understanding data patterns, and informed decision-making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While... | Fanqing Meng, Kaipeng Zhang, Peng Gao, Ping Luo, Quanfeng Lu, Wenqi Shao, Yu Qiao |  |
| 1449 |  |  [Teaching Small Language Models to Reason for Knowledge-Intensive Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.464) |  | 0 | Large Language Models (LLMs) can teach small language models (SLMs) to solve complex reasoning tasks (e.g., mathematical question answering) by Chain-of-thought Distillation (CoTD). Specifically, CoTD fine-tunes SLMs by utilizing rationales generated from LLMs such as ChatGPT. However, CoTD has... | Fangyu Lei, Jun Zhao, JunYang JunYang, Kang Liu, Shizhu He, Tianhuang Su, Xiang Li |  |
| 1450 |  |  [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://doi.org/10.18653/v1/2024.findings-acl.465) |  | 0 | We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences. The framework addresses the limitations of current alignment approaches,... | Shujun Liu, Siyuan Wang, Xuanjing Huang, Yuhang Lai, Zhongyu Wei |  |
| 1451 |  |  [LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting](https://doi.org/10.18653/v1/2024.findings-acl.466) |  | 0 | Time-series forecasting (TSF) finds broad applications in real-world scenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates strong zero-shot TSF capabilities while preserving computational efficiency. However, existing prompting methods oversimplify TSF as language next-token... | B. Aditya Prakash, Haoxin Liu, Harshavardhan Kamarthi, Jindong Wang, Zhiyuan Zhao |  |
| 1452 |  |  [Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.467) |  | 0 | Text classification is a crucial task encountered frequently in practical scenarios, yet it is still under-explored in the era of large language models (LLMs). This study shows that LLMs are vulnerable to changes in the number and arrangement of options in text classification. Our extensive... | Dangyang Chen, Jie Tian, Wei Wei, Wenfeng Xie, Xiaoye Qu, Yu Cheng, Zhenyi Lu |  |
| 1453 |  |  [UOR: Universal Backdoor Attacks on Pre-trained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.468) |  | 0 | Task-agnostic and transferable backdoors implanted in pre-trained language models (PLMs) pose a severe security threat as they can be inherited to any downstream task. However, existing methods rely on manual selection of triggers and backdoor representations, hindering their effectiveness and... | Ge Ren, Gongshen Liu, Haodong Zhao, Peixuan Li, Tianjie Ju, Wei Du |  |
| 1454 |  |  [Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences](https://doi.org/10.18653/v1/2024.findings-acl.469) |  | 0 | To date, most investigations on surprisal and entropy effects in reading have been conducted on the group level, disregarding individual differences. In this work, we revisit the predictive power (PP) of different LMs’ surprisal and entropy measures on data of human reading times as a measure of... | Lena Ann Jäger, Lena S. Bolliger, Patrick Haller |  |
| 1455 |  |  [The State of Relation Extraction Data Quality: Is Bigger Always Better?](https://doi.org/10.18653/v1/2024.findings-acl.470) |  | 0 | Relation extraction (RE) extracts structured tuples of relationships (e.g. friend, enemy) between entities (e.g. Sherlock Holmes, John Watson) from text, with exciting potential applications. Hundreds of RE papers have been published in recent years; do their evaluation practices inform these... | Brendan T. O'Connor, Erica Cai |  |
| 1456 |  |  [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Queries](https://doi.org/10.18653/v1/2024.findings-acl.471) |  | 0 | Large language models (LLMs) have manifested strong ability to generate codes for productive activities. However, current benchmarks for code synthesis, such as HumanEval, MBPP, and DS-1000, are predominantly oriented towards introductory tasks on algorithm and data science, insufficiently... | Hanlin Zhao, Jie Tang, Qinkai Zheng, Shudan Zhang, Xiao Liu, Xiaotao Gu, Yuxiao Dong, Zehan Qi |  |
| 1457 |  |  [LLMCrit: Teaching Large Language Models to Use Criteria](https://doi.org/10.18653/v1/2024.findings-acl.472) |  | 0 | Humans follow criteria when they execute tasks, and these criteria are directly used to assess the quality of task completion. Therefore, having models learn to use criteria to provide feedback can help humans or models to perform tasks better. However, current research in this area tends to... | Matthias Gallé, Pengfei Liu, Weizhe Yuan |  |
| 1458 |  |  [Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations](https://doi.org/10.18653/v1/2024.findings-acl.473) |  | 0 | The language ability of Large Language Models (LLMs) is often unbalanced towards English because of the imbalance in the distribution of the pre-training data. This disparity is demanded in further fine-tuning and affecting the cross-lingual abilities of LLMs. In this paper, we propose to empower... | André Freitas, Giulia Pucci, Leonardo Ranaldi |  |
| 1459 |  |  [Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies](https://doi.org/10.18653/v1/2024.findings-acl.474) |  | 0 | Conceptual spaces represent entities in terms of their primitive semantic features. Such representations are highly valuable but they are notoriously difficult to learn, especially when it comes to modelling perceptual and subjective features. Distilling conceptual spaces from Large Language Models... | Nitesh Kumar, Steven Schockaert, Usashi Chatterjee |  |
| 1460 |  |  [Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.475) |  | 0 | To achieve non-parametric NMT domain adaptation, k-Nearest-Neighbor Machine Translation (kNN-MT) constructs an external datastore to store domain-specific translation knowledge, which derives a kNN distribution to interpolate the prediction distribution of the NMT model via a linear interpolation... | Baosong Yang, Jinsong Su, Min Zhang, Shiyu Liu, Yan Gao, Zhiwei Cao, Zhongjian Miao |  |
| 1461 |  |  [Symmetric Dot-Product Attention for Efficient Training of BERT Language Models](https://doi.org/10.18653/v1/2024.findings-acl.476) |  | 0 | Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing. Nowadays, to tackle increasingly more complex... | Georg Rehm, Leonhard Hennig, Malte Ostendorff, Martin Courtois |  |
| 1462 |  |  [Synthesizing Conversations from Unlabeled Documents using Automatic Response Segmentation](https://doi.org/10.18653/v1/2024.findings-acl.477) |  | 0 | In this study, we tackle the challenge of inadequate and costly training data that has hindered the development of conversational question answering (ConvQA) systems. Enterprises have a large corpus of diverse internal documents. Instead of relying on a searching engine, a more compelling approach... | Chandan K. Reddy, Fanyou Wu, Srinivasan Sengamedu, Weijie Xu |  |
| 1463 |  |  [Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains](https://doi.org/10.18653/v1/2024.findings-acl.478) |  | 0 | Although large language models (LLMs) exhibit remarkable capacity to leverage in-context demonstrations, it is still unclear to what extent they can learn new facts or concept definitions via prompts. To address this question, we examine the capacity of instruction-tuned LLMs to follow in-context... | Marcio Fonseca, Shay B. Cohen |  |
| 1464 |  |  [Alignment-Based Decoding Policy for Low-Latency and Anticipation-Free Neural Japanese Input Method Editors](https://doi.org/10.18653/v1/2024.findings-acl.479) |  | 0 | Japanese input method editors (IMEs) are essential tools for inputting Japanese text using a limited set of characters such as the kana syllabary. However, despite their importance, the potential of newer attention-based encoder-decoder neural networks, such as Transformer, has not yet been fully... | Armin Sarhangzadeh, Taro Watanabe |  |
| 1465 |  |  [ECoK: Emotional Commonsense Knowledge Graph for Mining Emotional Gold](https://doi.org/10.18653/v1/2024.findings-acl.480) |  | 0 | The demand for understanding and expressing emotions in the field of natural language processing is growing rapidly. Knowledge graphs, as an important form of knowledge representation, have been widely utilized in various emotion-related tasks. However, existing knowledge graphs mainly focus on the... | Hang Gao, Jianfeng Wu, Mengting Hu, Ming Jiang, Renhong Cheng, Rui Ying, Xiaoyi Liu, Yalan Xie, Zhunheng Wang |  |
| 1466 |  |  [Deterministic Reversible Data Augmentation for Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.481) |  | 0 | Data augmentation is an effective way to diversify corpora in machine translation, but previous methods may introduce semantic inconsistency between original and augmented data because of irreversible operations and random subword sampling procedures. To generate both symbolically diverse and... | Heyan Huang, Jiashu Yao, Yuhang Guo, Zeming Liu |  |
| 1467 |  |  [Latent Learningscape Guided In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.482) |  | 0 | The growing interest in leveraging large language models is driven by their exceptional imitation and reasoning capabilities. In-context learning (ICL), a streamlined method, has shown potential in boosting these models’ performance without modifying their underlying parameters, especially when... | Anlai Zhou, Jun Xiao, Kun Kuang, Sunshine Jiang, Yifei Liu, Yiquan Wu |  |
| 1468 |  |  [SMR: State Memory Replay for Long Sequence Modeling](https://doi.org/10.18653/v1/2024.findings-acl.483) |  | 0 | Despite the promising performance of state space models (SSMs) in long sequence modeling, limitations still exist. Advanced SSMs like S5 and S6 (Mamba) in addressing non-uniform sampling, their recursive structures impede efficient SSM computation via convolution. To overcome compatibility... | Biqing Qi, Bowen Zhou, Dong Li, Jianxing Liu, Junqi Gao, Kaiyan Zhang, Ligang Wu |  |
| 1469 |  |  [Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks](https://doi.org/10.18653/v1/2024.findings-acl.484) |  | 0 | Large language models (LLMs) are proficient at generating fluent text with minimal task-specific supervision. However, their ability to generate rationales for knowledge-intensive tasks (KITs) remains under-explored. Generating rationales for KIT solutions, such as commonsense multiple-choice QA,... | Aditi Mishra, Estevam Hruschka, Hannah Kim, Kushan Mitra, Sajjadur Rahman |  |
| 1470 |  |  [Challenging Large Language Models with New Tasks: A Study on their Adaptability and Robustness](https://doi.org/10.18653/v1/2024.findings-acl.485) |  | 0 | Recent progress in large language models (LLMs) has marked a notable milestone in the field of artificial intelligence. The conventional evaluation of LLMs primarily relies on existing tasks and benchmarks, raising concerns about test set contamination and the genuine comprehension abilities of... | Chenxi Li, Fei Xia, Yan Song, Yuanhe Tian, Zhaxi Zerong |  |
| 1471 |  |  [Linear Cross-Lingual Mapping of Sentence Embeddings](https://doi.org/10.18653/v1/2024.findings-acl.486) |  | 0 | Semantics of a sentence is defined with much less ambiguity than semantics of a single word, and we assume that it should be better preserved by translation to another language. If multilingual sentence embeddings intend to represent sentence semantics, then the similarity between embeddings of any... | Fumika Isono, John Bohannon, Oleg Vasilyev |  |
| 1472 |  |  [ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Self-Refinement](https://doi.org/10.18653/v1/2024.findings-acl.487) |  | 0 | Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a... | Alakananda Vempala, Carter Wood Blum, Shalin Shah, Temma Choji, Xinliang Frederick Zhang |  |
| 1473 |  |  [LLMs Beyond English: Scaling the Multilingual Capability of LLMs with Cross-Lingual Feedback](https://doi.org/10.18653/v1/2024.findings-acl.488) |  | 0 | To democratize large language models (LLMs) to most natural languages, it is imperative to make these models capable of understanding and generating texts in many languages, in particular low-resource ones. While recent multilingual LLMs demonstrate remarkable performance in such capabilities,... | Alexander Fraser, Mohsen Mesgar, Wen Lai |  |
| 1474 |  |  [BASS: Batched Attention-optimized Speculative Sampling](https://doi.org/10.18653/v1/2024.findings-acl.489) |  | 0 | Speculative decoding has emerged as a powerful method to improve latency and throughput in hosting large language models. However, most existing implementations focus on generating a single sequence. Real-world generative AI applications often require multiple responses and how to perform... | Anoop Deoras, Haifeng Qian, Mingyue Shang, Ramesh Nallapati, Sanjay Krishna Gouda, Sudipta Sengupta, Sujan Kumar Gonugondla, Sungsoo Ha, Xiaofei Ma |  |
| 1475 |  |  [Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games](https://doi.org/10.18653/v1/2024.findings-acl.490) |  | 0 | In this study, we explore the application of Large Language Models (LLMs) in Jubensha, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to... | Bang Liu, Dekun Wu, Haochen Shi, Zhiyuan Sun |  |
| 1476 |  |  [It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.491) |  | 0 | Natural language processing has seen rapid progress over the past decade. Due to the speed of developments, some practices get established without proper evaluation. Considering one such case and focusing on reading comprehension, we ask our first research question: 1) How does the order of inputs... | Katharina von der Wense, Lawrence Hunter, Sagi Shaier |  |
| 1477 |  |  [Large Language Models Relearn Removed Concepts](https://doi.org/10.18653/v1/2024.findings-acl.492) |  | 0 | Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by... | Fazl Barez, Michelle Lo, Shay B. Cohen |  |
| 1478 |  |  [Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond](https://doi.org/10.18653/v1/2024.findings-acl.493) |  | 0 | Task embedding, a meta-learning technique that captures task-specific information, has gained popularity, especially in areas such as multi-task learning, model editing, and interpretability. However, it faces challenges with the emergence of prompt-guided Large Language Models (LLMs) operating in... | Hainiu Xu, Lin Gui, Xinyu Wang, Yulan He |  |
| 1479 |  |  [TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles](https://doi.org/10.18653/v1/2024.findings-acl.494) |  | 0 | In light of recent advances in large language models (LLMs), the expectations for the next generation of virtual assistants include enhanced naturalness and adaptability across diverse usage scenarios. However, the creation of high-quality annotated data for Task-Oriented Dialog (TOD) is recognized... | David Vandyke, Nigel Collier, Yimai Fang, Yinhong Liu |  |
| 1480 |  |  [Machine-Generated Text Localization](https://doi.org/10.18653/v1/2024.findings-acl.495) |  | 0 | Machine-Generated Text (MGT) detection aims to identify a piece of text as machine or human written. Prior work has primarily formulated MGT detection as a binary classification task over an entire document, with limited work exploring cases where only part of a document is machine generated. This... | Bryan A. Plummer, Wenda Qin, Zhongping Zhang |  |
| 1481 |  |  [BenchIE⌃FL: A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark](https://doi.org/10.18653/v1/2024.findings-acl.496) |  | 0 | Open Information Extraction (OIE) is a field of natural language processing that aims to present textual information in a format that allows it to be organized, analyzed and reflected upon. Numerous OIE systems are developed, claiming ever-increasing performance, marking the need for objective... | Fabrice Lamarche, Philippe Langlais |  |
| 1482 |  |  [CausalCite: A Causal Formulation of Paper Citations](https://doi.org/10.18653/v1/2024.findings-acl.497) |  | 0 | Citation count of a paper is a commonly used proxy for evaluating the significance of a paper in the scientific community. Yet citation measures are widely criticized for failing to accurately reflect the true impact of a paper. Thus, we propose CausalCite, a new way to measure the significance of... | Bernhard Schölkopf, Ehsan Mokhtarian, Ishan Kumar, Mrinmaya Sachan, Negar Kiyavash, Siyuan Guo, Yuen Chen, Zhijing Jin |  |
| 1483 |  |  [Question Translation Training for Better Multilingual Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.498) |  | 0 | Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into... | Alexandra Birch, Fei Yuan, Jiajun Chen, Shuaijie She, Shujian Huang, Wenhao Zhu |  |
| 1484 |  |  [Improving LLM Generations via Fine-Grained Self-Endorsement](https://doi.org/10.18653/v1/2024.findings-acl.499) |  | 0 | This work studies mitigating fact-conflicting hallucinations for large language model (LLM) at inference time.Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses.Compared with prior ensemble methods (e.g.,... | Ante Wang, Baolin Peng, Dong Yu, Haitao Mi, Jinsong Su, Lifeng Jin, Linfeng Song, Ye Tian |  |
| 1485 |  |  [Multi-Label Classification for Implicit Discourse Relation Recognition](https://doi.org/10.18653/v1/2024.findings-acl.500) |  | 0 | Discourse relations play a pivotal role in establishing coherence within textual content, uniting sentences and clauses into a cohesive narrative. The Penn Discourse Treebank (PDTB) stands as one of the most extensively utilized datasets in this domain. In PDTB-3, the annotators can assign multiple... | Bonnie Webber, Siddharth Narayanaswamy, Wanqiu Long |  |
| 1486 |  |  [StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code](https://doi.org/10.18653/v1/2024.findings-acl.501) |  | 0 | Code LLMs have the potential to make it easier for non-experts to understand and write code. However, current CodeLLM benchmarks rely on a single expert-written prompt per problem, making it hard to generalize their success to non-expert users. In this paper, we present a new... | Arjun Guha, Carolyn Jane Anderson, Hannah McLean Babe, Molly Q. Feldman, Sydney Nguyen, Yangtian Zi |  |
| 1487 |  |  [ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution](https://doi.org/10.18653/v1/2024.findings-acl.502) |  | 0 | Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing.... | Xuanming Zhang, Zhou Yu, Zixun Chen |  |
| 1488 |  |  [Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.503) |  | 0 | One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse.Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing... | Peinan Zhang, Tetsuro Morimura, Ukyo Honda, Yuu Jinnai |  |
| 1489 |  |  [GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages](https://doi.org/10.18653/v1/2024.findings-acl.504) |  | 0 | Neural Machine Translation (NMT) continues to improve in quality and adoption, yet the in advertent perpetuation of gender bias remains a significant concern. Despite numerous studies on gender bias in translations into English from weakly gendered-languages, there are no benchmarks for evaluating... | Ranjita Naik, Spencer Rarrick, Sundar Poudel, Vishal Chowdhary |  |
| 1490 |  |  [Hyperparameter-Free Approach for Faster Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.505) |  | 0 | Minimum Bayes-Risk (MBR) decoding is shown to be a powerful alternative to beam search decoding for a wide range of text generation tasks. However, MBR requires a huge amount of time for inference to compute the MBR objective, which makes the method infeasible in many situations where response time... | Kaito Ariu, Yuu Jinnai |  |
| 1491 |  |  [Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.506) |  | 0 | In recent years, neural machine translation (NMT) has become widely used in everyday life. However, the current NMT lacks a mechanism to adjust the difficulty level of translations to match the user’s language level. Additionally, due to the bias in the training data for NMT, translations of simple... | Koichi Takeda, Makoto Morishita, Masashi Oshika, Ryohei Sasano, Tsutomu Hirao |  |
| 1492 |  |  [Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining](https://doi.org/10.18653/v1/2024.findings-acl.507) |  | 0 | Large Language Models (LLMs) have shown human-like reasoning abilities but still face challenges in solving complex logical problems. Existing unidirectional chaining methods, such as forward chaining and backward chaining, suffer from issues like low prediction accuracy and efficiency. To address... | Bowei He, Linqi Song, Shuqi Liu |  |
| 1493 |  |  [Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?](https://doi.org/10.18653/v1/2024.findings-acl.508) |  | 0 | In this work, we investigate the controllability of large language models (LLMs) on scientific summarization tasks. We identify key stylistic and content coverage factors that characterize different types of summaries such as paper reviews, abstracts, and lay summaries. By controlling stylistic... | Marcio Fonseca, Shay B. Cohen |  |
| 1494 |  |  [Knowledge Context Modeling with Pre-trained Language Models for Contrastive Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.509) |  | 0 | Text-based knowledge graph completion (KGC) methods utilize pre-trained language models for triple encoding and further fine-tune the model to achieve completion. Despite their excellent performance, they neglect the knowledge context in inferring process. Intuitively, knowledge contexts, which... | Guangqian Yang, Hongtao Xie, Lei Zhang, Licheng Zhang, Yi Liu, Zhendong Mao |  |
| 1495 |  |  [Stronger, Lighter, Better: Towards Life-Long Attribute Value Extraction for E-Commerce Products](https://doi.org/10.18653/v1/2024.findings-acl.510) |  | 0 | Attribute value extraction involves identifying the value spans of predetermined attributes in product texts. This area of research has traditionally operated under a closed-world assumption, focusing on products from a static set of categories and their associated attributes. However, products in... | Chenwei Zhang, Hoang Nguyen, Jingbo Shang, Philip S. Yu, Tao Zhang, Xian Li |  |
| 1496 |  |  [Exploring Domain Robust Lightweight Reward Models based on Router Mechanism](https://doi.org/10.18653/v1/2024.findings-acl.511) |  | 0 | Recent advancements in large language models have heavily relied on the large reward model from reinforcement learning from human feedback for fine-tuning. However, the use of a single reward model across various domains may not always be optimal, often requiring retraining from scratch when new... | Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, YoonHyung Roh |  |
| 1497 |  |  [Generalized Category Discovery with Large Language Models in the Loop](https://doi.org/10.18653/v1/2024.findings-acl.512) |  | 0 | Generalized Category Discovery (GCD) is a crucial task that aims to recognize both known and novel categories from a set of unlabeled data by utilizing a few labeled data with only known categories. Due to the lack of supervision and category information, current methods usually perform poorly on... | Feng Tian, Haiping Zhu, Haonan Lin, Luyan Wang, Mingxiang Cai, Ping Chen, Qianying Wang, Wenbin An, Wenkai Shi, Yan Chen, Yaqiang Wu |  |
| 1498 |  |  [VAEGPT-Sim: Improving Sentence Representation with Limited Corpus Using Gradually-Denoising VAE](https://doi.org/10.18653/v1/2024.findings-acl.513) |  | 0 | Text embedding requires a highly efficient method for training domain-specific models on limited data, as general models trained on large corpora lack universal applicability in highly specific fields. Therefore, we have introduced VAEGPT-Sim, an innovative model for generating synonyms that... | Dan Wang, Haiyan Ning, Qing Ling, Zhenyi Wang |  |
| 1499 |  |  [PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion](https://doi.org/10.18653/v1/2024.findings-acl.514) |  | 0 | Recent evaluations of Large Language Models (LLMs) have centered around testing their zero-shot/few-shot capabilities for basic natural language tasks and their ability to translate instructions into tool APIs. However, the evaluation of LLMs utilizing complex tools to finish multi-turn,... | Dongyan Zhao, Nan Duan, Yaobo Liang, Yiduo Guo, Zekai Zhang |  |
| 1500 |  |  [Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.515) |  | 0 | For a LLM to be trustworthy, its confidence level should be well-calibrated with its actual performance. While it is now common sense that LLM performances are greatly impacted by prompts, the confidence calibration in prompting LLMs has yet to be thoroughly explored.In this paper, we explore how... | Dong Yu, Hongming Zhang, Jianshu Chen, Tongshuang Wu, Wenlin Yao, Xiaoman Pan, Xinran Zhao |  |
| 1501 |  |  [DB-LLM: Accurate Dual-Binarization for Efficient LLMs](https://doi.org/10.18653/v1/2024.findings-acl.516) |  | 0 | Large language models (LLMs) have significantly advanced the field of natural language processing, while the expensive memory and computation consumption impede their practical deployment. Quantization emerges as one of the most effective methods for improving the computational efficiency of LLMs.... | Chengtao Lv, Dacheng Tao, Haotong Qin, Hong Chen, Jinyang Guo, Liang Ding, Min Zhang, Xiabin Zhou, Xianglong Liu, Xuebo Liu, Yifu Ding |  |
| 1502 |  |  [TempCompass: Do Video LLMs Really Understand Videos?](https://doi.org/10.18653/v1/2024.findings-acl.517) |  | 0 | Recently, there is a surge in interest surrounding video large language models (Video LLMs). However, existing benchmarks fail to provide a comprehensive feedback on the temporal perception ability of Video LLMs. On the one hand, most of them are unable to distinguish between different temporal... | Lei Li, Lu Hou, Shicheng Li, Shuhuai Ren, Sishuo Chen, Xu Sun, Yi Liu, Yuanxin Liu, Yuxiang Wang |  |
| 1503 |  |  ["Get Their Hands Dirty, Not Mine": On Researcher-Annotator Collaboration and the Agency of Annotators](https://doi.org/10.18653/v1/2024.findings-acl.518) |  | 0 | Annotation quality is often framed as post-hoc cleanup of annotator-caused issues. This position paper discusses whether, how, and why this narrative limits the scope of improving annotation. We call to consider annotation as a procedural collaboration, outlining three points in this direction:(1)... | Jeffrey M. Rzeszotarski, Shengqi Zhu |  |
| 1504 |  |  [Teaching Large Language Models an Unseen Language on the Fly](https://doi.org/10.18653/v1/2024.findings-acl.519) |  | 0 | Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones, for which there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through... | Chen Zhang, Jiuheng Lin, Xiao Liu, Yansong Feng |  |
| 1505 |  |  [Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.520) |  | 0 | Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks, such as machine translation, text summarization. Recent research (Kocmi and Federmann, 2023) has shown that utilizing LLMs for assessing the quality of machine translation (MT)... | Baopu Qiu, Dacheng Tao, Kanjian Zhang, Liang Ding, Qingyu Lu, Tom Kocmi |  |
| 1506 |  |  [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.521) |  | 0 | The Large Vision-Language Models (LVLMs) have demonstrated great abilities in image perception and language understanding. However, existing datasets either focus solely on primary perception abilities and commonsense knowledge, or have a low level of text comprehension difficulty, which are... | Xipeng Qiu, Yi Zong |  |
| 1507 |  |  [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](https://doi.org/10.18653/v1/2024.findings-acl.522) |  | 0 | We present DiffChat, a novel method to align Large Language Models (LLMs) to “chat” with prompt-as-input Text-to-Image Synthesis (TIS)models (e.g., Stable Diffusion) for interactive image creation. Given a raw prompt/image and a user-specified instruction, DiffChat can effectively make appropriate... | Chengyu Wang, Jiapeng Wang, Jun Huang, Lianwen Jin, Tingfeng Cao |  |
| 1508 |  |  [Revisiting Parallel Context Windows: A Frustratingly Simple Alternative and Chain-of-Thought Deterioration](https://doi.org/10.18653/v1/2024.findings-acl.523) |  | 0 | We identify two crucial limitations in the evaluation of recent parallel-integrated method Parallel Context Windows (PCW), which extends the maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing window-wise attention and positional embedding techniques. We first show that... | Aohan Zeng, Jie Tang, Kaiwen Men, Kejuan Yang, Xiao Liu, Yuxiao Dong |  |
| 1509 |  |  [Rationales for Answers to Simple Math Word Problems Confuse Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.524) |  | 0 | Recently, large language models (LLMs) have demonstrated breakthrough mathematical problem-solving capabilities in grade school math word problems (MWP). For example, on the MWP benchmark GSM8K, the accuracy of GPT-3.5-Turbo and MetaMath-70B reaches 80.80% and 82.30%, respectively. One question... | Dayiheng Liu, Mingfeng Xue, Yidan Zhang, Zhenan He |  |
| 1510 |  |  [ResLoRA: Identity Residual Mapping in Low-Rank Adaption](https://doi.org/10.18653/v1/2024.findings-acl.525) |  | 0 | As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs). However, updating the weights of LoRA blocks effectively and expeditiously is challenging due to the long calculation path in the... | Feng Sun, Furu Wei, Haizhen Huang, Minghui Song, Qi Zhang, Shaohan Huang, Shuhua Shi, Weiwei Deng, Zhoujun Li, Zihan Zhang |  |
| 1511 |  |  [Towards Objectively Benchmarking Social Intelligence of Language Agents at the Action Level](https://doi.org/10.18653/v1/2024.findings-acl.526) |  | 0 | Prominent large language models have exhibited human-level performance in many domains, even enabling the derived agents to simulate human and social interactions. While practical works have substantiated the practicability of grounding language agents in sandbox simulation or embodied simulators,... | Baoyuan Wang, Bin Dai, Chenxu Wang, Huaping Liu |  |
| 1512 |  |  [Semantic Role Labeling from Chinese Speech via End-to-End Learning](https://doi.org/10.18653/v1/2024.findings-acl.527) |  | 0 | Semantic Role Labeling (SRL), crucial for understanding semantic relationships in sentences, has traditionally focused on text-based input. However, the increasing use of voice assistants and the need for hands-free interaction have highlighted the importance of SRL from speech.SRL from speech can... | Huiyao Chen, Meishan Zhang, Min Zhang, Xinxin Li |  |
| 1513 |  |  [MEEL: Multi-Modal Event Evolution Learning](https://doi.org/10.18653/v1/2024.findings-acl.528) |  | 0 | Multi-modal Event Reasoning (MMER) endeavors to endow machines with the ability to comprehend intricate event relations across diverse data modalities. MMER is fundamental and underlies a wide broad of applications. Despite extensive instruction fine-tuning, current multi-modal large language... | Chongyang Tao, Junqiang Huang, Xiancai Chen, Xiaoying Bai, Yifan Zhang, Zhengwei Tao, Zhi Jin |  |
| 1514 |  |  [LLM-REDIAL: A Large-Scale Dataset for Conversational Recommender Systems Created from User Behaviors with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.529) |  | 0 | The large-scale conversational recommendation dataset is pivotal for the development of conversational recommender systems (CRS). Most existing CRS datasets suffers from the problems of data inextensibility and semantic inconsistency. To tackle these limitations and establish a benchmark in the... | Chenxin Jin, Congying Xia, Kai Chen, Lingzhi Wang, Tingting Liang, Wenqi Fan, Yuyu Yin |  |
| 1515 |  |  [Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models](https://doi.org/10.18653/v1/2024.findings-acl.530) |  | 0 | LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks introducing LLM biases into consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been... | Gene Louis Kim, Mahammed Kamruzzaman, Md. Minul Islam Shovon |  |
| 1516 |  |  [EVIT: Event-Oriented Instruction Tuning for Event Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.531) |  | 0 | Events refer to specific occurrences, incidents, or happenings that take place under a particular background. Event reasoning aims to infer events according to certain relations and predict future events. The cutting-edge techniques for event reasoning play a crucial role in various natural... | Haiyan Zhao, Xiancai Chen, Xiaoying Bai, Yiwei Lou, Zhengwei Tao, Zhi Jin |  |
| 1517 |  |  [InstructCMP: Length Control in Sentence Compression through Instruction-based Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.532) |  | 0 | Extractive summarization can produce faithful summaries but often requires additional constraints such as a desired summary length. Traditional sentence compression models do not typically consider the constraints because of their restricted model abilities, which require model modifications for... | Hidetaka Kamigaito, Jingun Kwon, JuseonDo, Manabu Okumura |  |
| 1518 |  |  [SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation](https://doi.org/10.18653/v1/2024.findings-acl.533) |  | 0 | Citing pertinent literature is pivotal to writing and reviewing a scientific document. Existing techniques mainly focus on the local context or the global context for recommending citations but fail to consider the actual human citation behaviour. We propose SymTax, a three-stage recommendation... | Karan Goyal, Mayank Goel, Mukesh K. Mohania, Vikram Goyal |  |
| 1519 |  |  [Assessing News Thumbnail Representativeness: Counterfactual text can enhance the cross-modal matching ability](https://doi.org/10.18653/v1/2024.findings-acl.534) |  | 0 | This paper addresses the critical challenge of assessing the representativeness of news thumbnail images, which often serve as the first visual engagement for readers when an article is disseminated on social media. We focus on whether a news image represents the actors discussed in the news text.... | Kunwoo Park, Seunghyun Yoon, Yejun Yoon |  |
| 1520 |  |  [Towards Better Question Generation in QA-based Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.535) |  | 0 | Event Extraction (EE) is an essential information extraction task that aims to extract event-related information from unstructured texts.The paradigm of this task has shifted from conventional classification-based methods to more contemporary question-answering-based (QA-based) approaches. However,... | Jian Liu, Zijin Hong |  |
| 1521 |  |  [Budget-Constrained Tool Learning with Planning](https://doi.org/10.18653/v1/2024.findings-acl.536) |  | 0 | Despite intensive efforts devoted to tool learning, the problem of budget-constrained tool learning, which focuses on resolving user queries within a specific budget constraint, has been widely overlooked. This paper proposes a novel method for budget-constrained tool learning. Our approach... | Fei Huang, Ji Zhang, Ming Yan, Peng Li, Yang Liu, Yuanhang Zheng |  |
| 1522 |  |  [TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild](https://doi.org/10.18653/v1/2024.findings-acl.537) |  | 0 | Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality... | Deng Cai, Huayang Li, Lemao Liu, Longyue Wang, Shuming Shi, Siheng Li, Taro Watanabe, Yujiu Yang |  |
| 1523 |  |  [The Critique of Critique](https://doi.org/10.18653/v1/2024.findings-acl.538) |  | 0 |  | Junlong Li, Pengfei Liu, Ruifeng Yuan, Shichao Sun, Weizhe Yuan, Wenjie Li |  |
| 1524 |  |  [CoCo-Agent: A Comprehensive Cognitive MLLM Agent for Smartphone GUI Automation](https://doi.org/10.18653/v1/2024.findings-acl.539) |  | 0 | Multimodal large language models (MLLMs) have shown remarkable potential as human-like autonomous language agents to interact with real-world environments, especially for graphical user interface (GUI) automation.However, those GUI agents require comprehensive cognition including exhaustive... | Hai Zhao, Xinbei Ma, Zhuosheng Zhang |  |
| 1525 |  |  [FRVA: Fact-Retrieval and Verification Augmented Entailment Tree Generation for Explainable Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.540) |  | 0 | Structured entailment tree can exhibit the reasoning chains from knowledge facts to predicted answers, which is important for constructing an explainable question answering system. Existing works mainly include directly generating the entire tree and stepwise generating the proof steps. The... | Hongye Tan, Hu Zhang, Jiye Liang, Ru Li, Yue Fan, Yujie Wang |  |
| 1526 |  |  [P4: Plug-and-Play Discrete Prompting for Large Language Models Personalization](https://doi.org/10.18653/v1/2024.findings-acl.541) |  | 0 | Empowering Large Language Models (LLMs) with distinct human-like personality traits has become an innovative task for developing advanced dialog systems.Although LLMs demonstrate impressive capabilities in following instructions, directly prompting them to exhibit certain personalities through... | Jiayi Fu, Qi Zhang, Tao Gui, Tianze Chen, Xiao Wang, Yuansen Zhang |  |
| 1527 |  |  [Large Language Models Can Learn Representation in Natural Language](https://doi.org/10.18653/v1/2024.findings-acl.542) |  | 0 | One major challenge for Large Language Models (LLMs) is completing complex tasks involving multiple entities, such as tool APIs. To tackle this, one approach is to retrieve relevant entities to enhance LLMs in task completion. A crucial issue here is obtaining accurate natural language... | Dongyan Zhao, Nan Duan, Yaobo Liang, Yiduo Guo |  |
| 1528 |  |  [CTC-based Non-autoregressive Textless Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.543) |  | 0 | Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences. Recently, some research has turned to non-autoregressive (NAR) models to expedite decoding, yet the... | Min Zhang, Qingkai Fang, Yan Zhou, Yang Feng, Zhengrui Ma |  |
| 1529 |  |  [RRNorm: A Novel Framework for Chinese Disease Diagnoses Normalization via LLM-Driven Terminology Component Recognition and Reconstruction](https://doi.org/10.18653/v1/2024.findings-acl.544) |  | 0 | The Clinical Terminology Normalization aims at finding standard terms from a given termbase for mentions extracted from clinical texts. However, we found that extracted mentions suffer from the multi-implication problem, especially disease diagnoses. The reason for this is that physicians often use... | Jingping Liu, Kui Xue, Tong Ruan, Yansha Zhu, Yongqi Fan |  |
| 1530 |  |  [Unexpected Phenomenon: LLMs' Spurious Associations in Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.545) |  | 0 | Information extraction plays a critical role in natural language processing. When applying large language models (LLMs) to this domain, we discover an unexpected phenomenon: LLMs’ spurious associations. In tasks such as relation extraction, LLMs can accurately identify entity pairs, even if the... | Haiyun Jiang, Jiacheng Wang, Jingping Liu, Lihan Chen, Tong Ruan, Wanpeng Lu, Weiyan Zhang, Yating Wang |  |
| 1531 |  |  [AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought](https://doi.org/10.18653/v1/2024.findings-acl.546) |  | 0 | Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention.Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning knowledge from different languages. Despite achieving... | Libo Qin, Min Li, Qiguang Chen, Wanxiang Che, Yongheng Zhang |  |
| 1532 |  |  [LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.547) |  | 0 | Multilingual neural machine translation models generally distinguish translation directions by the language tag (LT) in front of the source or target sentences. However, current LT strategies cannot indicate the desired target language as expected on zero-shot translation, i.e., the off-target... | Fandong Meng, Jie Zhou, Jinan Xu, Yijin Liu, Yufeng Chen, Zengkui Sun |  |
| 1533 |  |  [Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data](https://doi.org/10.18653/v1/2024.findings-acl.548) |  | 0 | Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models’ capability in statistical and causal reasoning with... | KaiWei Chang, Pan Lu, Xiao Liu, Xueqing Wu, Yansong Feng, Zirui Wu |  |
| 1534 |  |  [On the Vulnerability of Safety Alignment in Open-Access LLMs](https://doi.org/10.18653/v1/2024.findings-acl.549) |  | 0 | Large language models (LLMs) possess immense capabilities but are susceptible to malicious exploitation. To mitigate the risk, safety alignment is employed to align LLMs with ethical standards. However, safety-aligned LLMs may remain vulnerable to carefully crafted jailbreak attacks, but these... | Bin Zhu, Defu Lian, Fangzhao Wu, Guangzhong Sun, Jingwei Yi, Qisi Chen, Rui Ye, Siheng Chen, Xing Xie |  |
| 1535 |  |  [PEK: A Parameter-Efficient Framework for Knowledge-Grounded Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.550) |  | 0 | Pre-trained language models (PLMs) have shown great dialogue generation capability in different scenarios. However, the huge VRAM consumption when fine-tuning them is one of their drawbacks. PEFT approaches can significantly reduce the number of trainable parameters, which enables us to fine-tune... | Dandan Song, Pan Yang, Yanru Zhou, Zhijing Wu |  |
| 1536 |  |  [Evidence Retrieval is almost All You Need for Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.551) |  | 0 | Current fact verification methods generally follow the two-stage training paradigm: evidence retrieval and claim verification. While existing works focus on developing sophisticated claim verification modules, the fundamental importance of evidence retrieval is largely ignored. Existing approaches... | Chaozhuo Li, Feiran Huang, Haoran Jia, Liwen Zheng, Xi Zhang, Yuming Shang |  |
| 1537 |  |  [Outdated Issue Aware Decoding for Factual Knowledge Editing](https://doi.org/10.18653/v1/2024.findings-acl.552) |  | 0 | Recently, Knowledge Editing has received increasing attention, since it could update the specific knowledge from outdated ones in pretrained models without re-training. However, as pointed out by recent studies, existing related methods tend to merely memorize the superficial word composition of... | Fandong Meng, Jiaan Wang, Jie Zhou, Jinan Xu, Yijin Liu, Yufeng Chen, Zengkui Sun |  |
| 1538 |  |  [Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness](https://doi.org/10.18653/v1/2024.findings-acl.553) |  | 0 | Dialects introduce syntactic and lexical variations in language that occur in regional or social groups. Most NLP methods are not sensitive to such variations. This may lead to unfair behavior of the methods, conveying negative bias towards dialect speakers. While previous work has studied... | Henning Wachsmuth, Maximilian Spliethöver, Sai Nikhil Menon |  |
| 1539 |  |  [DP-MLM: Differentially Private Text Rewriting Using Masked Language Models](https://doi.org/10.18653/v1/2024.findings-acl.554) |  | 0 |  | Florian Matthes, Juraj Vladika, Maulik Chevli, Stephen Meisenbacher |  |
| 1540 |  |  [Question-Instructed Visual Descriptions for Zero-Shot Video Answering](https://doi.org/10.18653/v1/2024.findings-acl.555) |  | 0 | We present Q-ViD, a simple approach for video question answering (video QA), that unlike prior methods, which are based on complex architectures, computationally expensive pipelines or use closed models like GPTs, Q-ViD relies on a single instruction-aware open vision-language model (InstructBLIP)... | David Mogrovejo, Thamar Solorio |  |
| 1541 |  |  [EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification](https://doi.org/10.18653/v1/2024.findings-acl.556) |  | 0 | Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in accuracy improvement, let alone explainability, a critical capability of fact verification systems.Constructing an explainable fact verification system in... | Huanhuan Ma, Liang Wang, Liuji Chen, Qiang Liu, Shu Wu, Weizhi Xu, Yifan Wei |  |
| 1542 |  |  [Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.557) |  | 0 | Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial and urgent problem.This paper first delivers three key... | Dahua Lin, Feng Zhao, Jiangning Liu, Kai Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Zehui Chen |  |
| 1543 |  |  [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](https://doi.org/10.18653/v1/2024.findings-acl.558) |  | 0 | Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factually correct, making it... | Aleksandr Rubashevskii, Alexander Panchenko, Artem Shelmanov, Ekaterina Fadeeva, Evgenii Tsymbalov, Gleb Kuzmin, Hamdy Mubarak, Haonan Li, Maxim Panov, Preslav Nakov, Sergey Petrakov, Timothy Baldwin |  |
| 1544 |  |  [Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning](https://doi.org/10.18653/v1/2024.findings-acl.559) |  | 0 | Through pretraining on a corpus with various sources, Large Language Models (LLMs) have gained impressive performance. However, the impact of each component of the pretraining corpus remains opaque. As a result, the organization of the pretraining corpus is still empirical and may deviate from the... | Bing Qin, Kai Xiong, Li Du, Shi Jun, Ting Liu, Xiao Ding, Yang Zhao, Zhouhao Sun |  |
| 1545 |  |  [Critical Learning Periods: Leveraging Early Training Dynamics for Efficient Data Pruning](https://doi.org/10.18653/v1/2024.findings-acl.560) |  | 0 | Neural Machine Translation models are extremely data and compute-hungry. However, not all datapoints contribute equally to model training and generalization. Data pruning to remove the low-value data points has the benefit of drastically reducing the compute budget without significantdrop in model... | Bruce A. Bassett, Everlyn Chimoto, Jay Gala, Julia Kreutzer, Orevaoghene Ahia, Sara Hooker |  |
| 1546 |  |  [What Are You Token About? Differentiable Perturbed Top-k Token Selection for Scientific Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.561) |  | 0 | Scientific document summarization aims to condense complex and long articles in both technical and plain-language terms to facilitate the accessibility and dissemination of scientific findings. Existing datasets suffer from a deficiency in source heterogeneity, as their data predominantly stem from... | Gianluca Moro, Luca Ragazzi, Mattia Panni, Paolo Italiani |  |
| 1547 |  |  [Description Boosting for Zero-Shot Entity and Relation Classification](https://doi.org/10.18653/v1/2024.findings-acl.562) |  | 0 | Zero-shot entity and relation classification models leverage available external information of unseen classes – e.g., textual descriptions – to annotate input text data. Thanks to the minimum data requirement, Zero-Shot Learning (ZSL) methods have high value in practice, especially in applications... | Alberto Purpura, Gabriele Picco, Hoang Thanh Lam, Leopold Fuchs, Marcos Martínez Galindo, Vanessa López |  |
| 1548 |  |  [Domain-Aware k-Nearest-Neighbor Knowledge Distillation for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.563) |  | 0 | kNN-MT has utilized neighborhood knowledge for auxiliary decoding, significantly improving translation performance. Subsequently, kNN-KD transitions the use of neighborhood knowledge from the decoding phase to the training phase, to address the temporal and spatial inefficiencies inherent in... | Derek F. Wong, Miao Zhang, Min Zhang, Shudong Liu, Xuebo Liu, Zhexuan Wang |  |
| 1549 |  |  [Beyond Single-Event Extraction: Towards Efficient Document-Level Multi-Event Argument Extraction](https://doi.org/10.18653/v1/2024.findings-acl.564) |  | 0 | Recent mainstream event argument extraction methods process each event in isolation, resulting in inefficient inference and ignoring the correlations among multiple events. To address these limitations, here we propose a multiple-event argument extraction model DEEIA (Dependency-guided Encoding and... | Chen Zhang, Dingyi Zeng, Grandee Lee, Li Zhou, Malu Zhang, Shaohuan Cheng, Wanlong Liu, Wenyu Chen, Yichen Xiao |  |
| 1550 |  |  [Revisiting Interpolation Augmentation for Speech-to-Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.565) |  | 0 | Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization... | Chen Xu, Chunliang Zhang, Dapeng Man, Jie Wang, JingBo Zhu, Qian Dong, Tong Xiao, Wu Yang, Xiaoqian Liu |  |
| 1551 |  |  [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk](https://doi.org/10.18653/v1/2024.findings-acl.566) |  | 0 | Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do... | Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Lijia Sun, Xibin Gao, Yi Zhang |  |
| 1552 |  |  [Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning](https://doi.org/10.18653/v1/2024.findings-acl.567) |  | 0 | Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of Large Language Models (LLMs) to various downstream applications. However, the effectiveness of the PEFT diminishes notably when downstream tasks require accurate learning of specific knowledge. In this paper, we adopt a... | Piji Li, Renzhi Wang |  |
| 1553 |  |  [Leveraging Collection-Wide Similarities for Unsupervised Document Structure Extraction](https://doi.org/10.18653/v1/2024.findings-acl.568) |  | 0 | Document collections of various domains, e.g., legal, medical, or financial, often share some underlying collection-wide structure, which captures information that can aid both human users and structure-aware models.We propose to identify the typical structure of document within a collection, which... | Gabriel Stanovsky, Gili Lior, Yoav Goldberg |  |
| 1554 |  |  [Enhancing Cross Text-Molecule Learning by Self-Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.569) |  | 0 | The development of Large Language Models (LLMs) has greatly advanced the field of drug discovery, with the belief that natural language can enhance human control over molecule design. However, the scarcity of high-quality labeled data remains a challenge for cross text-molecule learning. Existing... | Huajun Chen, Keyan Ding, Qiang Zhang, Xiang Zhuang, Yinuo Jiang |  |
| 1555 |  |  [RePALM: Popular Quote Tweet Generation via Auto-Response Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.570) |  | 0 | A quote tweet enables users to share others’ content while adding their own commentary. In order to enhance public engagement through quote tweets, we investigate the task of generating popular quote tweets. This task aims to produce quote tweets that garner higher popularity, as indicated by... | Chunpu Xu, Erxin Yu, Jing Li |  |
| 1556 |  |  [On the Effect of (Near) Duplicate Subwords in Language Modelling](https://doi.org/10.18653/v1/2024.findings-acl.571) |  | 0 | Tokenisation is a core part of language models (LMs). It involves splitting a character sequence into subwords which are assigned random indices before being served to the LM. However, this process—while typically lossless—may lead to less efficient LM training, because it removes character-level... | Anton Schäfer, Imanol Schlag, Thomas Hofmann, Tiago Pimentel |  |
| 1557 |  |  [Do Pre-Trained Language Models Detect and Understand Semantic Underspecification? Ask the DUST!](https://doi.org/10.18653/v1/2024.findings-acl.572) |  | 0 | In everyday language use, speakers frequently utter and interpret sentences that are semantically underspecified, namely, whose content is insufficient to fully convey their message or interpret them univocally. For example, to interpret the underspecified sentence “Don’t spend too much”, which... | Frank Wildenburg, Michael Hanna, Sandro Pezzelle |  |
| 1558 |  |  [Visual Hallucinations of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.573) |  | 0 | Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines incorrect details about an image in visual question answering. Existing studies find VH instances only in existing image datasets, which results in biased understanding of MLLMs’ performance under VH due to limited diversity of... | Hongbin Liu, Minxin Guo, Neil Gong, Wen Huang |  |
| 1559 |  |  [SumSurvey: An Abstractive Dataset of Scientific Survey Papers for Long Document Summarization](https://doi.org/10.18653/v1/2024.findings-acl.574) |  | 0 | With the popularity of large language models (LLMs) and their ability to handle longer input documents, there is a growing need for high-quality long document summarization datasets. Although many models already support 16k input, current lengths of summarization datasets are inadequate, and... | Gang Li, He Zhang, Jianguo Jiang, Min Yu, Ming Liu, Ran Liu, Weiqing Huang |  |
| 1560 |  |  [Pushing the Limits of Low-Resource NER Using LLM Artificial Data Generation](https://doi.org/10.18653/v1/2024.findings-acl.575) |  | 0 | Named Entity Recognition (NER) is an important task, but to achieve great performance, it is usually necessary to collect a large amount of labeled data, incurring high costs. In this paper, we propose using open-source Large Language Models (LLM) to generate NER data with only a few labeled... | Billy Cahyadi, Esther Irawati Setiawan, Joan Santoso, Patrick Sutanto |  |
| 1561 |  |  [Understanding and Patching Compositional Reasoning in LLMs](https://doi.org/10.18653/v1/2024.findings-acl.576) |  | 0 | LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. Our research embarks on a quest to uncover the root causes of compositional reasoning failures of LLMs, uncovering that most of them stem from the improperly generated or leveraged implicit... | Defu Lian, Gangwei Jiang, Hong Xie, Linqi Song, Ying Wei, Zhaoyi Li |  |
| 1562 |  |  [Bilingual Rhetorical Structure Parsing with Large Parallel Annotations](https://doi.org/10.18653/v1/2024.findings-acl.577) |  | 0 | Discourse parsing is a crucial task in natural language processing that aims to reveal the higher-level relations in a text. Despite growing interest in cross-lingual discourse parsing, challenges persist due to limited parallel data and inconsistencies in the Rhetorical Structure Theory (RST)... | Elena Chistova |  |
| 1563 |  |  [Book2Dial: Generating Teacher Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](https://doi.org/10.18653/v1/2024.findings-acl.578) |  | 0 | Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student... | Jakub Macina, Junling Wang, Mrinmaya Sachan, Nico Daheim, Sankalan Pal Chowdhury |  |
| 1564 |  |  [SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.579) |  | 0 |  | Feng Zhang, Han Liu, Tingyu Zhang, Wenxin Liang |  |
| 1565 |  |  [Automated Focused Feedback Generation for Scientific Writing Assistance](https://doi.org/10.18653/v1/2024.findings-acl.580) |  | 0 | Scientific writing is a challenging task, particularly for novice researchers who often rely on feedback from experienced peers. Recent work has primarily focused on improving surface form and style rather than manuscript content. In this paper, we propose a novel task: automated focused feedback... | Andreas Vlachos, Eric Chamoun, Michael Sejr Schlichtkrull |  |
| 1566 |  |  [FastGAS: Fast Graph-based Annotation Selection for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.581) |  | 0 | In-context learning (ICL) empowers large language models (LLMs) to tackle new tasks by using a series of training instances as prompts. Since generating the prompts needs to sample from a vast pool of instances and annotate them (e.g., add labels in classification task), existing methods have... | Cong Shen, Jundong Li, Song Wang, Zihan Chen |  |
| 1567 |  |  [Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations](https://doi.org/10.18653/v1/2024.findings-acl.582) |  | 0 | Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly compatible with further tuning and compression. However, as the... | Bin Wang, Bowen Shen, Daren Zha, Jian Luan, Wei Liu, Weiping Wang, Zheng Lin |  |
| 1568 |  |  [Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.583) |  | 0 | Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual... | Langlin Huang, Yang Feng |  |
| 1569 |  |  [Deductive Closure Training of Language Models for Coherence, Accuracy, and Updatability](https://doi.org/10.18653/v1/2024.findings-acl.584) |  | 0 | While language models (LMs) can sometimes generate factually correct text and estimate truth values of individual claims, these generally do not reflect a globally coherent, manipulable model of the world. As a consequence, current LMs also generate incorrect or nonsensical content, and are... | Afra Feyza Akyürek, Derry Wijaya, Ekin Akyürek, Jacob Andreas, Leshem Choshen |  |
| 1570 |  |  [Self-Supervised Singing Voice Pre-Training towards Speech-to-Singing Conversion](https://doi.org/10.18653/v1/2024.findings-acl.585) |  | 0 | Speech-to-singing voice conversion (STS) task always suffers from data scarcity, because it requires paired speech and singing data. Compounding this issue are the challenges of content-pitch alignment and the suboptimal quality of generated outputs, presenting significant hurdles in STS research.... | Rongjie Huang, Ruiqi Li, Yongqi Wang, Zhiqing Hong, Zhou Zhao |  |
| 1571 |  |  [Evaluating Large Language Model Biases in Persona-Steered Generation](https://doi.org/10.18653/v1/2024.findings-acl.586) |  | 0 | The task of persona-steered text generation requires large language models (LLMs) to generate text that reflects the distribution of views that an individual fitting a persona could have. People have multifaceted personas, but prior work on bias in LLM-generated opinions has only explored... | Andy Liu, Daniel Fried, Mona T. Diab |  |
| 1572 |  |  [Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization](https://doi.org/10.18653/v1/2024.findings-acl.587) |  | 0 | The rapid increase in multimedia data has spurred advancements in Multimodal Summarization with Multimodal Output (MSMO), which aims to produce a multimodal summary that integrates both text and relevant images. The inherent heterogeneity of content within multimodal inputs and outputs presents a... | Enhong Chen, Kai Zhang, Qi Liu, Shiwei Wu, Xukai Liu, Yanghai Zhang, Ye Liu |  |
| 1573 |  |  [CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.588) |  | 0 | It is imperative to ensure the stability of every prediction made by a language model; that is, a language’s prediction should remain consistent despite minor input variations, like word substitutions. In this paper, we investigate the problem of certifying a language model’s robustness against... | Jiaqi Xue, Mengxin Zheng, Qian Lou, Rui Xie, Xin Liang, Yancheng Zhang |  |
| 1574 |  |  [Recovering document annotations for sentence-level bitext](https://doi.org/10.18653/v1/2024.findings-acl.589) |  | 0 | In machine translation, historical models were incapable of handling longer contexts, so the lack of document-level datasets was less noticeable. Now, despite the emergence of long-sequence methods, we remain within a sentence-level paradigm and without data to adequately approach context-aware... | Matt Post, Philipp Koehn, Rachel Wicks |  |
| 1575 |  |  [MetaPro 2.0: Computational Metaphor Processing on the Effectiveness of Anomalous Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.590) |  | 0 | Metaphor interpretation is a difficult task in natural language understanding. The development of relevant techniques in this domain is slow, mostly because of the lack of large annotated datasets and effective pre-trained language models (PLMs) for metaphor learning. Thus, we propose a large... | Claudia Ong, Erik Cambria, Kai He, Qian Liu, Rui Mao |  |
| 1576 |  |  [Boosting LLM Agents with Recursive Contemplation for Effective Deception Handling](https://doi.org/10.18653/v1/2024.findings-acl.591) |  | 0 | Recent advances in large language models (LLMs) have led to significant success in using LLMs as agents. Nevertheless, a common assumption that LLMs always process honest information neglects the widespread deceptive or misleading content in human and AI-generated material. This oversight might... | Andrew Zhao, Chang Liu, Chaofei Wang, Gao Huang, Qisen Yang, Shenzhi Wang, Shiji Song, Shuo Chen, Siyuan Qi, Zilong Zheng |  |
| 1577 |  |  [Direct Preference Optimization with an Offset](https://doi.org/10.18653/v1/2024.findings-acl.592) |  | 0 | Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language... | Afra Amini, Ryan Cotterell, Tim Vieira |  |
| 1578 |  |  [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation](https://doi.org/10.18653/v1/2024.findings-acl.593) |  | 0 | Direct speech-to-speech translation achieves high-quality results through the introduction of discrete units obtained from self-supervised learning. However, talking head translation, converting audio-visual speech (i.e., talking head video) from one language into another, still confronts several... | Aoxiong Yin, Baoxing Huai, Feiyang Chen, Linjun Li, Rongjie Huang, Tao Jin, Xinyu Duan, Xize Cheng, Zehan Wang, Zhou Zhao |  |
| 1579 |  |  [More than Minorities and Majorities: Understanding Multilateral Bias in Language Generation](https://doi.org/10.18653/v1/2024.findings-acl.594) |  | 0 | Pretrained models learned from real corpora can often capture undesirable features, leading to bias issues against different demographic groups. Most existing studies on bias dataset construction or bias mitigation methods only focus on one demographic group pair to study a certain bias, e.g. black... | Jiaxu Zhao, Ling Chen, Meng Fang, Mykola Pechenizkiy, Yitong Li, Yulong Pei, Zijing Shi |  |
| 1580 |  |  [Fair Federated Learning with Biased Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.595) |  | 0 | Existing literature that integrates CLIP into federated learning (FL) largely ignores the inherent group unfairness within CLIP and its ethical implications on FL applications. Furthermore, such CLIP bias may be amplified in FL, due to the unique issue of data heterogeneity across clients. However,... | Dong Wang, Huimin Zeng, Lanyu Shang, Yang Zhang, Zhenrui Yue |  |
| 1581 |  |  [SpeechGuard: Exploring the Adversarial Robustness of Multi-modal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.596) |  | 0 | Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this work, we investigate the potential vulnerabilities of such... | Anshu Bhatia, Daniel GarciaRomero, Goeric Huybrechts, Karel Mundnich, Katrin Kirchhoff, Kyu J. Han, Nilaksh Das, Raghuveer Peri, Sai Muralidhar Jayanthi, Saket Dingliwal, Srikanth Ronanki, Srikanth Vishnubhotla, Sundararajan Srinivasan, Zejiang Hou |  |
| 1582 |  |  [ACUEval: Fine-grained Hallucination Evaluation and Correction for Abstractive Summarization](https://doi.org/10.18653/v1/2024.findings-acl.597) |  | 0 | The impressive generation capabilities of large language models (LLMs) have made it harder to detect the subtle hallucinations they make in abstractive summarization, where generated summaries consist of a blend of correct and incorrect information w.r.t. a given document. Recently-proposed... | Asli Celikyilmaz, David Wan, Koustuv Sinha, Mohit Bansal, Ramakanth Pasunuru, Srini Iyer |  |
| 1583 |  |  [An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.598) |  | 0 | Multimodal Large Language Models (MLLMs) fine-tuned with multimodal instruction-following data have demonstrated formidable capabilities in multimodal tasks. However, fine-tuning all parameters of MLLMs has become challenging due to the rapid growth of the overall model’s parameters. To address... | Guangyao Zhu, Jeff Z. Pan, Jie He, Víctor GutiérrezBasulto, Xiongtao Zhou, Yuhua Ke |  |
| 1584 |  |  [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](https://doi.org/10.18653/v1/2024.findings-acl.599) |  | 0 | Recently, there has been growing interest within the community regarding whether large language models are capable of planning or executing plans. However, most prior studies use LLMs to generate high-level plans for simplified scenarios lacking linguistic complexity and domain diversity, limiting... | Abdulfattah Safa, Arda Uzunoglu, Gözde Gül Sahin |  |
| 1585 |  |  [TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation](https://doi.org/10.18653/v1/2024.findings-acl.600) |  | 0 | The recent advances in natural language processing have predominantly favored well-resourced English-centric models, resulting in a significant gap with low-resource languages. In this work, we introduce TURNA, a language model developed for the low-resource language Turkish and is capable of both... | Gökçe Uludogan, Meliksah Türker, Onur Güngör, Salih Furkan Akkurt, Susan Üsküdarli, Zeynep Yirmibesoglu Balal |  |
| 1586 |  |  [MELD-ST: An Emotion-aware Speech Translation Dataset](https://doi.org/10.18653/v1/2024.findings-acl.601) |  | 0 | Emotion plays a crucial role in human conversation. This paper underscores the significance of considering emotion in speech translation. We present the MELD-ST dataset for the emotion-aware speech translation task, comprising English-to-Japanese and English-to-German language pairs. Each language... | Chenhui Chu, Sadao Kurohashi, Sakiko Yahata, Shuichiro Shimizu, Sirou Chen, Yihang Li, Zhengdong Yang |  |
| 1587 |  |  [Designing Informative Metrics for Few-Shot Example Selection](https://doi.org/10.18653/v1/2024.findings-acl.602) |  | 0 | Pretrained language models (PLMs) have shown remarkable few-shot learning capabilities when provided with properly formatted examples. However, selecting the “best” examples remains an open challenge. We propose a complexity-based prompt selection approach for sequence tagging tasks. This approach... | Lakshmi Subramanian, Rishabh Adiga, Varun Chandrasekaran |  |
| 1588 |  |  [Chain-of-Quizzes: Pedagogy-inspired Example Selection in In-Context-Learning](https://doi.org/10.18653/v1/2024.findings-acl.603) |  | 0 | In-context learning (ICL) has emerged as a powerful tool for enhancing large language models (LLMs) in addressing downstream tasks. In this paper, we explore the vital task of example selection in ICL by mimicking the human learning process. We propose a Chain-of-Quizzes (CoQ) framework inspired by... | Adam Jatowt, Anlai Zhou, Jun Xiao, Kun Kuang, Weiming Lu, Yifei Liu, Yiquan Wu, Yuhang Liu |  |
| 1589 |  |  [It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.604) |  | 0 | Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This process of elimination (PoE), when used with COT, can enhance self-consistency, interpretability, and tasks such as... | Nishant Balepur, Rachel Rudinger, Shramay Palta |  |
| 1590 |  |  [From Discrimination to Generation: Low-Resource Intent Detection with Language Model Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.605) |  | 0 | Intent detection aims to identify user goals from utterances, and is a ubiquitous step towards the satisfaction of user desired needs in many interaction systems. As dynamic and varied intents arise, models that are capable of identifying new intents promptly are required. However, existing studies... | Fei Ding, Feng Zhang, Jiabin Zheng, Jiahui Yao, Meng Gao, Tengjiao Wang, Wei Chen |  |
| 1591 |  |  [Efficient Continual Pre-training for Building Domain Specific Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.606) |  | 0 | Large language models (LLMs) have demonstrated remarkable open-domain capabilities. LLMs tailored for a domain are typically trained entirely on domain corpus to excel at handling domain-specific tasks. In this work, we explore an alternative strategy of continual pre-training as a means to develop... | Aitzaz Ahmad, Karan Aggarwal, Yong Xie |  |
| 1592 |  |  [Distantly-Supervised Joint Extraction with Noise-Robust Learning](https://doi.org/10.18653/v1/2024.findings-acl.607) |  | 0 | Joint entity and relation extraction is a process that identifies entity pairs and their relations using a single model. We focus on the problem of joint extraction in distantly-labeled data, whose labels are generated by aligning entity mentions with the corresponding entity and relation tags... | Cong Liu, Haifeng Chen, Xiao Yu, Yanchi Liu, Yanghong Guo, Yufei Li |  |
| 1593 |  |  [LLM Factoscope: Uncovering LLMs' Factual Discernment through Measuring Inner States](https://doi.org/10.18653/v1/2024.findings-acl.608) |  | 0 | Large Language Models (LLMs) have revolutionized various domains with extensive knowledge and creative capabilities. However, a critical issue with LLMs is their tendency to produce outputs that diverge from factual reality. This phenomenon is particularly concerning in sensitive applications such... | Cheng'an Wei, Jinwen He, Kai Chen, Yue Zhao, Yujia Gong, Zijin Lin |  |
| 1594 |  |  [DictLLM: Harnessing Key-Value Data Structures with Large Language Models for Enhanced Medical Diagnostics](https://doi.org/10.18653/v1/2024.findings-acl.609) |  | 0 | Structured data offers an efficient means of organizing information. Exsisting text-serialization based methods for processing structured data using large language models (LLMs) are not designed to explicitly capture the heterogeneity of structured data. Such methods are suboptimal for LLMs to... | Ya Zhang, Yanfeng Wang, YiQiu Guo, Yu Wang, Yuchen Yang |  |
| 1595 |  |  [imapScore: Medical Fact Evaluation Made Easy](https://doi.org/10.18653/v1/2024.findings-acl.610) |  | 0 | Automatic evaluation of natural language generation (NLG) tasks has gained extensive research interests, since it can rapidly assess the performance of large language models (LLMs). However, automatic NLG evaluation struggles with medical QA because it fails to focus on the crucial correctness of... | Huimin Wang, Xian Wu, Yefeng Zheng, Yutian Zhao |  |
| 1596 |  |  [Making Harmful Behaviors Unlearnable for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.611) |  | 0 | Large language models (LLMs) have shown great potential to empower various domains and are often customized by fine-tuning for the requirements of different applications. However, the powerful learning ability of LLMs not only enables them to learn new tasks but also makes them vulnerable to... | Qi Zhang, Ruotian Ma, Tao Gui, Xin Zhou, Xuanjing Huang, Yi Lu, Yujian Wei |  |
| 1597 |  |  [Debiasing Large Language Models with Structured Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.612) |  | 0 | Due to biases inherently present in data for pre-training, current pre-trained Large Language Models (LLMs) also ubiquitously manifest the same phenomena. Since the bias influences the output from the LLMs across various tasks, the widespread deployment of the LLMs is hampered. We propose a simple... | Congda Ma, Manabu Okumura, Tianyu Zhao |  |
| 1598 |  |  [Contrastive Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.613) |  | 0 | Instruction tuning has been used as a promising approach to improve the performance of large language models (LLMs) on unseen tasks. However, current LLMs exhibit limited robustness to unseen instructions, generating inconsistent outputs when the same instruction is phrased with slightly varied... | Aram Galstyan, Fan Yin, Fei Wang, James Y. Huang, Muhao Chen, Tianyi Yan, Wenpeng Yin, Wenxuan Zhou |  |
| 1599 |  |  [Bootstrapped Pre-training with Dynamic Identifier Prediction for Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.614) |  | 0 | Generative retrieval uses differentiable search indexes to directly generate relevant document identifiers in response to a query. Recent studies have highlighted the potential of a strong generative retrieval model, trained with carefully crafted pre-training tasks, to enhance downstream retrieval... | Jiafeng Guo, Maarten de Rijke, Ruqing Zhang, Xueqi Cheng, Yixing Fan, Yubao Tang |  |
| 1600 |  |  [Refining and Synthesis: A Simple yet Effective Data Augmentation Framework for Cross-Domain Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-acl.615) |  | 0 | Aspect-based Sentiment Analysis (ABSA) is extensively researched in the NLP community, yet related models face challenges due to data sparsity when shifting to a new domain. Hence, data augmentation for cross-domain ABSA has attracted increasing attention in recent years. However, two key points... | Bobo Li, Chong Teng, Donghong Ji, Fei Li, Haining Wang, Kang He, Lei Chen, Xu Han |  |
| 1601 |  |  [Codec-SUPERB: An In-Depth Analysis of Sound Codec Models](https://doi.org/10.18653/v1/2024.findings-acl.616) |  | 0 | The sound codec’s dual roles in minimizing data transmission latency and serving as tokenizers underscore its critical importance.Recent years have witnessed significant developments in codec models.The ideal sound codec should preserve content, paralinguistics, speakers, and audio... | Alexander H. Liu, Haibin Wu, HoLam Chung, HsiuHsuan Wang, Hungyi Lee, KaiWei Chang, Xuanjun Chen, YiCheng Lin, YuChi Pai, YuanKuei Wu |  |
| 1602 |  |  [CACL: Community-Aware Heterogeneous Graph Contrastive Learning for Social Media Bot Detection](https://doi.org/10.18653/v1/2024.findings-acl.617) |  | 0 | Social media bot detection is increasingly crucial with the rise of social media platforms. Existing methods predominantly construct social networks as graph and utilize graph neural networks (GNNs) for bot detection. However, most of these methods focus on how to improve the performance of GNNs... | ChenChen Zong, Jing Li, Piji Li, Shuo Feng, Sirry Chen, Songsong Liang |  |
| 1603 |  |  [Are Machines Better at Complex Reasoning? Unveiling Human-Machine Inference Gaps in Entailment Verification](https://doi.org/10.18653/v1/2024.findings-acl.618) |  | 0 | Making inferences in text comprehension to understand the meaning is essential in language processing. This work studies the entailment verification (EV) problem of complex, multi-sentence premises requiring a system to make multiple inferences implicitly. Modern applications of EV in detecting... | Jiacheng Liu, Soumya Sanyal, Tianyi Xiao, Wenya Wang, Xiang Ren |  |
| 1604 |  |  [ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.619) |  | 0 | Charts provide visual representations of data and are widely used for analyzing information, addressing queries, and conveying insights to others. Various chart-related downstream tasks have emerged recently, such as question-answering and summarization. A common strategy to solve these tasks is to... | Ahmed Masry, Enamul Hoque, Md. Rizwan Parvez, Mehrad Shahmohammadi, Shafiq Joty |  |
| 1605 |  |  [Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.620) |  | 0 | The many-to-many multilingual neural machine translation can be regarded as the process of integrating semantic features from the source sentences and linguistic features from the target sentences. To enhance zero-shot translation, models need to share knowledge across languages, which can be... | Mengyu Bu, Shuhao Gu, Yang Feng |  |
| 1606 |  |  [Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with Architecture-Routed Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.621) |  | 0 | Weight-sharing supernets are crucial for performance estimation in cutting-edge neural architecture search (NAS) frameworks. Despite their ability to generate diverse subnetworks without retraining, the quality of these subnetworks is not guaranteed due to weight sharing. In NLP tasks like machine... | Aasish Pappu, Barlas Oguz, Dilin Wang, Fei Sun, Ganesh Jawahar, Haichuan Yang, Laks V. S. Lakshmanan, Meng Li, Muhammad AbdulMageed, Raghuraman Krishnamoorthi, Vikas Chandra, Yunyang Xiong, Zechun Liu |  |
| 1607 |  |  [SharedCon: Implicit Hate Speech Detection using Shared Semantics](https://doi.org/10.18653/v1/2024.findings-acl.622) |  | 0 | The ever-growing presence of hate speech on social network services and other online platforms not only fuels online harassment but also presents a growing challenge for hate speech detection. As this task is akin to binary classification, one of the promising approaches for hate speech detection... | Hyeseon Ahn, Jungin Kim, YoSub Han, Youngwook Kim |  |
| 1608 |  |  [Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models](https://doi.org/10.18653/v1/2024.findings-acl.623) |  | 0 | Instruction-tuning language models has become a crucial step in aligning them for general use. Typically, this process involves extensive training on large datasets, incurring high training costs. In this paper, we introduce a novel training data selection based on the learning percentage of the... | Alex Nguyen, Dheeraj Mekala, Jingbo Shang |  |
| 1609 |  |  [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://doi.org/10.18653/v1/2024.findings-acl.624) |  | 0 | Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the... | Daniel Kang, Qiusi Zhan, Zhixiang Liang, Zifan Ying |  |
| 1610 |  |  [Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.625) |  | 0 | Code Pre-trained Models (CodePTMs) based vulnerability detection have achieved promising results over recent years. However, these models struggle to generalize as they typically learn superficial mapping from source code to labels instead of understanding the root causes of code vulnerabilities,... | Bin Ji, Hai Jin, Huijun Liu, Jiahao Zhu, Ming Wen, Xiaohu Du, Xuanhua Shi, Zifan Xie |  |
| 1611 |  |  [PPTSER: A Plug-and-Play Tag-guided Method for Few-shot Semantic Entity Recognition on Visually-rich Documents](https://doi.org/10.18653/v1/2024.findings-acl.626) |  | 0 | Visually-rich document information extraction (VIE) is a vital aspect of document understanding, wherein Semantic Entity Recognition (SER) plays a significant role. However, few-shot SER on visually-rich documents remains relatively unexplored despite its considerable potential for practical... | Jiapeng Wang, Lianwen Jin, Longfei Xiong, Wenhui Liao, Zening Lin |  |
| 1612 |  |  [LLM Performance Predictors are good initializers for Architecture Search](https://doi.org/10.18653/v1/2024.findings-acl.627) |  | 0 | In this work, we utilize Large Language Models (LLMs) for a novel use case: constructing Performance Predictors (PP) that estimate the performance of specific deep neural network architectures on downstream tasks. We create PP prompts for LLMs, comprising (i) role descriptions, (ii) instructions... | Dujian Ding, Ganesh Jawahar, Laks V. S. Lakshmanan, Muhammad AbdulMageed |  |
| 1613 |  |  [MODDP: A Multi-modal Open-domain Chinese Dataset for Dialogue Discourse Parsing](https://doi.org/10.18653/v1/2024.findings-acl.628) |  | 0 | Dialogue discourse parsing (DDP) aims to capture the relations between utterances in the dialogue. In everyday real-world scenarios, dialogues are typically multi-modal and cover open-domain topics. However, most existing widely used benchmark datasets for DDP contain only textual modality and are... | Chen Gong, Dexin Kong, Guohong Fu, Suxian Zhao, Xingyu Li |  |
| 1614 |  |  [Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health Text Analysis](https://doi.org/10.18653/v1/2024.findings-acl.629) |  | 0 | In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis... | Bing Yang, Guanghui Fu, Han Wang, Hongzhi Qi, Jianqiang Li, Qing Zhao, Wei Zhai, Ziqi Wang |  |
| 1615 |  |  [Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct Preference Optimization](https://doi.org/10.18653/v1/2024.findings-acl.630) |  | 0 | A single language model, even when aligned with labelers through reinforcement learning from human feedback (RLHF), may not suit all human preferences. Recent approaches therefore prefer customization, gathering multi-dimensional feedback, and creating distinct reward models for each... | Chao Yang, Jie Liu, Jing Shao, Wanli Ouyang, Xiangyu Yue, Yu Qiao, Zhanhui Zhou |  |
| 1616 |  |  [DORY: Deliberative Prompt Recovery for LLM](https://doi.org/10.18653/v1/2024.findings-acl.631) |  | 0 | Prompt recovery in large language models (LLMs) is crucial for understanding how LLMs work and addressing concerns regarding privacy, copyright, etc. The trend towards inference-only APIs complicates this task by restricting access to essential outputs for recovery. To tackle this challenge, we... | Junbo Zhao, Lirong Gao, Ru Peng, Yiming Zhang |  |
| 1617 |  |  [STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents](https://doi.org/10.18653/v1/2024.findings-acl.632) |  | 0 | Equipping a conversational search engine with strategies regarding when to ask clarification questions is becoming increasingly important across various domains. Attributing to the context understanding capability of LLMs and their access to domain-specific sources of knowledge, LLM-based... | Chen Huang, Dingnan Jin, Jia Liu, TatSeng Chua, Wenqiang Lei, Yang Deng, Yue Chen |  |
| 1618 |  |  [Evaluating Robustness of Generative Search Engine on Adversarial Factoid Questions](https://doi.org/10.18653/v1/2024.findings-acl.633) |  | 0 | Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns,... | Junzhe Chen, Lijie Wen, Philip S. Yu, Qun Liu, Xiaochuan Li, Xiaoguang Li, Xuming Hu, Yangning Li, Yasheng Wang, Yinghui Li, Zhijiang Guo |  |
| 1619 |  |  [Automatic Engineering of Long Prompts](https://doi.org/10.18653/v1/2024.findings-acl.634) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities in solving complex open-domain tasks, guided by comprehensive instructions and demonstrations provided in the form of prompts. However, these prompts can be lengthy, often comprising hundreds of lines and thousands of tokens,... | ChoJui Hsieh, Felix X. Yu, Inderjit S. Dhillon, Si Si |  |
| 1620 |  |  [AS-ES Learning: Towards efficient CoT learning in small models](https://doi.org/10.18653/v1/2024.findings-acl.635) |  | 0 | Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs, especially when it comes to logical reasoning. Attempts have been made to induce such ability in small models as well by distilling from the data with CoT generated by Large Language Models (LLMs). However, existing methods often... | Bing Qin, GongZhang GongZhang, Haochun Wang, Nuwa Xi, Sendong Zhao, Ting Liu, Yuhan Chen |  |
| 1621 |  |  [II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.636) |  | 0 | Visual Question Answering (VQA) often involves diverse reasoning scenarios across Vision and Language (V&L). Most prior VQA studies, however, have merely focused on assessing the model’s overall accuracy without evaluating it on different reasoning cases. Furthermore, some recent works observe that... | Dongyeop Kang, Farideh Tavazoee, Jihyung Kil, JooKyung Kim |  |
| 1622 |  |  [TAME-RD: Text Assisted Replication of Image Multi-Adjustments for Reverse Designing](https://doi.org/10.18653/v1/2024.findings-acl.637) |  | 0 | Given a source and its edited version performed based on human instructions in natural language, how do we extract the underlying edit operations, to automatically replicate similar edits on other images? This is the problem of reverse designing, and we present TAME-RD, a model to solve this... | Aniket Bera, Dinesh Manocha, Pooja Guhan, Saayan Mitra, Somdeb Sarkhel, Uttaran Bhattacharya, Vahid Azizi, Xiang Chen |  |
| 1623 |  |  [Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.638) |  | 0 | In this paper, by treating in-context learning (ICL) as a meta-optimization process, we explain why LLMs are sensitive to the order of ICL examples. This understanding leads us to the development of Batch-ICL, an effective, efficient, and order-agnostic inference algorithm for ICL. Differing from... | Ang Lv, Hansen Ha, Kaiyi Zhang, Rui Yan, Tao Xu, Yuhan Chen |  |
| 1624 |  |  [IndicVoices: Towards building an Inclusive Multilingual Speech Dataset for Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.639) |  | 0 | We present INDICVOICES, a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a... | Ambujavalli R, Aparna Ananthanarayanan, C. Venkata Vaijayanthi, Deovrat Mehendale, Eldho Ittan George, Hafsah Faquih, Ishvinder Virender Sethi, Janki Nawale, Kaushal Santosh Bhogale, Krishnan Srinivasa Raghavan Karunganni, Kunal Sharad Gandhi, Manickam K. M, Mitesh M. Khapra, Pratiti Palit, Pratyush Kumar, Sakshi Joshi, Saranya Sukumaran, Sneha Ravishankar, Sunjay Murali, Tahir Javed, Tripura Panchagnula |  |
| 1625 |  |  [ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.640) |  | 0 | In our work, we explore the synergistic capabilities of pre-trained vision-and-language models (VLMs) and large language models (LLMs) on visual commonsense reasoning (VCR) problems. We find that VLMs and LLMs-based decision pipelines are good at different kinds of VCR problems. Pre-trained VLMs... | Kaiwen Zhou, Kwonjoon Lee, Teruhisa Misu, Xin Wang |  |
| 1626 |  |  [Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm](https://doi.org/10.18653/v1/2024.findings-acl.641) |  | 0 | In-context learning of large-language models (LLMs) has achieved remarkable success in the field of natural language processing, while extensive case studies reveal that the single-step chain-of-thought prompting approach faces challenges such as attention diffusion and inadequate performance in... | Bo Hu, Cheng Lei, Chengxiang Zhuo, Chenyun Yu, Liang Chen, Mingxiong Lin, Tao Xie, Xinzhou Jin, Yuanzhen Xie, Zang Li |  |
| 1627 |  |  [Unveiling Opinion Evolution via Prompting and Diffusion for Short Video Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.642) |  | 0 | Short video fake news detection is crucial for combating the spread of misinformation. Current detection methods tend to aggregate features from individual modalities into multimodal features, overlooking the implicit opinions and the evolving nature of opinions across modalities. In this paper, we... | Bo Xu, Jiahui Zhou, Linlin Zong, Wenmin Lin, Xianchao Zhang, Xinyue Liu |  |
| 1628 |  |  [iSign: A Benchmark for Indian Sign Language Processing](https://doi.org/10.18653/v1/2024.findings-acl.643) |  | 0 | Indian Sign Language has limited resources for developing machine learning and data-driven approaches for automated language processing. Though text/audio-based language processing techniques have shown colossal research interest and tremendous improvements in the last few years, Sign Languages... | Abhinav Joshi, Andesha Mangla, Ashutosh Modi, Monali Barbate, Mounika Kanakanti, Romit Mohanty, Sudeep Choudhary |  |
| 1629 |  |  [Data Contamination Calibration for Black-box LLMs](https://doi.org/10.18653/v1/2024.findings-acl.644) |  | 0 | The rapid advancements of Large Language Models (LLMs) tightly associate with the expansion of the training data size. However, the unchecked ultra-large-scale training sets introduce a series of potential risks like data contamination, i.e. the benchmark data is used for training. In this work, we... | Gang Chen, Haobo Wang, Jiaqi Hu, Junbo Zhao, Liyao Li, Wentao Ye |  |
| 1630 |  |  [Truth-Aware Context Selection: Mitigating Hallucinations of Large Language Models Being Misled by Untruthful Contexts](https://doi.org/10.18653/v1/2024.findings-acl.645) |  | 0 | Although Large Language Models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by untruthful contexts provided by users or knowledge augmentation tools, leading to hallucinations. To alleviate LLMs from being misled by untruthful context and take advantage... | Shaolei Zhang, Tian Yu, Yang Feng |  |
| 1631 |  |  [Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.646) |  | 0 | Large language models (LLMs) exhibit outstanding performance in machine translation via in-context learning. In contrast to sentence-level translation, document-level translation (DOCMT) by LLMs based on in-context learning faces two major challenges: firstly, document translations generated by... | Deyi Xiong, Jiangcun Du, Menglong Cui, Shaolin Zhu |  |
| 1632 |  |  [Improving Grammatical Error Correction via Contextual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.647) |  | 0 | Nowadays, data augmentation through synthetic data has been widely used in the field of Grammatical Error Correction (GEC) to alleviate the problem of data scarcity. However, these synthetic data are mainly used in the pre-training phase rather than the data-limited fine tuning phase due to... | Baoxin Wang, Dayong Wu, Qingfu Zhu, Wanxiang Che, Yijun Liu, Yixuan Wang |  |
| 1633 |  |  [RECOST: External Knowledge Guided Data-efficient Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.648) |  | 0 | In the current landscape of large language models (LLMs), the process of instruction tuning serves as an essential step. Considering the high computing power overhead, data-efficient instruction tuning was proposed to reduce the training data size in this process, aiming at selecting high-quality... | Haobo Wang, Junbo Zhao, Qi Zhang, Yiming Zhang |  |
| 1634 |  |  [Understanding Cross-Lingual Alignment - A Survey](https://doi.org/10.18653/v1/2024.findings-acl.649) |  | 0 | Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising... | Alexander Fraser, Jindrich Libovický, Katharina Hämmerl |  |
| 1635 |  |  [Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-acl.650) |  | 0 | Lifelong prompt tuning has significantly advanced parameter-efficient lifelong learning with its efficiency and minimal storage demands on various tasks.Our empirical studies, however, highlights certain transferability constraints in the current methodologies: a universal algorithm that guarantees... | Chenyuan Wu, Defu Lian, Gangwei Jiang |  |
| 1636 |  |  [PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.651) |  | 0 | While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves... | An Liu, Fei Huang, Ji Zhang, Ming Yan, Peng Li, Qingyuan Hu, Yang Liu, Zhenhe Zhang, Zonghan Yang |  |
| 1637 |  |  [Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction](https://doi.org/10.18653/v1/2024.findings-acl.652) |  | 0 | Advancements in AI and natural language processing have revolutionized machine-human language interactions, with question answering (QA) systems playing a pivotal role. The knowledge base question answering (KBQA) task, utilizing structured knowledge graphs (KG), allows for handling extensive... | Albert Sawczyn, Aleksandra Domogala, Katsiaryna Viarenich, Konrad Wojtasik, Maciej Piasecki, Marcin Oleksy, Tomasz Kajdanowicz |  |
| 1638 |  |  [Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM](https://doi.org/10.18653/v1/2024.findings-acl.653) |  | 0 | Generating accurate SQL queries for user questions (text-to-SQL) has been a long-standing challenge since it requires a deep understanding of both the user’s question and the corresponding database schema in order to retrieve the desired content accurately. Existing methods rely on the... | Feiran Huang, Hao Chen, Qinggang Zhang, Xiao Huang, Zheng Yuan, Zijin Hong |  |
| 1639 |  |  [Centroid-Based Efficient Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.findings-acl.654) |  | 0 | Minimum Bayes risk (MBR) decoding achieved state-of-the-art translation performance by using COMET, a neural metric that has a high correlation with human evaluation.However, MBR decoding requires quadratic time since it computes the expected score between a translation hypothesis and all reference... | Hideki Tanaka, Hidetaka Kamigaito, Hiroyuki Deguchi, Masao Utiyama, Taro Watanabe, Yusuke Sakai |  |
| 1640 |  |  [Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration](https://doi.org/10.18653/v1/2024.findings-acl.655) |  | 0 | In this paper, we tackle the task of distractor generation (DG) for multiple-choice questions. Our study introduces two key designs. First, we propose the concept of retrieval augmented pretraining, which involves refining the language model pretraining to align it more closely with the downstream... | HanCheng Yu, HsinChih Ho, KaiYu Hsieh, KinMan Law, WenChuan Hsu, YaoChung Fan, YuAn Shih, YuChen Cheng, ZihAn Lin |  |
| 1641 |  |  [Exploiting Positional Bias for Query-Agnostic Generative Content in Search](https://doi.org/10.18653/v1/2024.findings-acl.656) |  | 0 | In recent years, research shows that neural ranking models (NRMs) substantially outperform their lexical counterparts in text retrieval. In traditional search pipelines, a combination of features leads to well-defined behaviour. However, as neural approaches become increasingly prevalent as the... | Andrew Parry, Debasis Ganguly, Sean MacAvaney |  |
| 1642 |  |  [ICC : Quantifying Image Caption Concreteness for Multimodal Dataset Curation](https://doi.org/10.18653/v1/2024.findings-acl.657) |  | 0 | Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly... | Hadar AverbuchElor, Moran Yanuka, Morris Alper, Raja Giryes |  |
| 1643 |  |  [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.658) |  | 0 | Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However,... | Gang Chen, Haobo Wang, Junbo Zhao, Lin Long, Rui Wang, Ruixuan Xiao, Xiao Ding |  |
| 1644 |  |  [When is a Language Process a Language Model?](https://doi.org/10.18653/v1/2024.findings-acl.659) |  | 0 | A language model may be viewed as a 𝛴-valued stochastic process for some alphabet 𝛴.However, in some pathological situations, such a stochastic process may “leak” probability mass onto the set of infinite strings and hence is not equivalent to the conventional view of a language model as a... | Holden Lee, Jason Eisner, Li Du, Ryan Cotterell |  |
| 1645 |  |  [Accelerating Multilingual Language Model for Excessively Tokenized Languages](https://doi.org/10.18653/v1/2024.findings-acl.660) |  | 0 | Recent advancements in large language models (LLMs) have remarkably enhanced performances on a variety of tasks in multiple languages. However, tokenizers in LLMs trained primarily on English-centric corpora often overly fragment a text into character or Unicode-level tokens in non-Roman alphabetic... | Gibbeum Lee, Jaewoong Cho, Jimin Hong |  |
| 1646 |  |  [Definition Generation for Automatically Induced Semantic Frame](https://doi.org/10.18653/v1/2024.findings-acl.661) |  | 0 | In a semantic frame resource such as FrameNet, the definition sentence of a frame is essential for humans to understand the meaning of the frame intuitively. Recently, several attempts have been made to induce semantic frames from large corpora, but the cost of creating the definition sentences for... | Koichi Takeda, Ryohei Sasano, Yi Han |  |
| 1647 |  |  [Distillation Enhanced Generative Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.662) |  | 0 | Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generative language models, distinct from traditional sparse or dense retrieval methods. In this work, we identify a... | Liqiang Nie, TatSeng Chua, Wenjie Li, Wenjie Wang, Yongqi Li, Zhen Zhang |  |
| 1648 |  |  [ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos](https://doi.org/10.18653/v1/2024.findings-acl.663) |  | 0 | In an era of rapidly evolving internet technology, the surge in multimodal content, including videos, has expanded the horizons of online communication. However, the detection of toxic content in this diverse landscape, particularly in low-resource code-mixed languages, remains a critical... | Krishanu Maity, Poornash Sangeetha, Pushpak Bhattacharyya, Sriparna Saha |  |
| 1649 |  |  [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.664) |  | 0 | Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable... | Hao Wang, Maosong Sun, Peng Li, Shihao Liang, Sijie Cheng, Yang Liu, Yujia Qin, Zhicheng Guo, Zhiyuan Liu |  |
| 1650 |  |  [Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence](https://doi.org/10.18653/v1/2024.findings-acl.665) |  | 0 | Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants. Previous works mainly focus on raising... | Bing Qin, Chen Wei, Shilong Wang, Weixiang Zhao, Yang Wang, Yanyan Zhao, Yulin Hu, Zhuojun Li |  |
| 1651 |  |  [KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge](https://doi.org/10.18653/v1/2024.findings-acl.666) |  | 0 | To reliably deploy Large Language Models (LLMs) in a specific country, they must possess an understanding of the nation’s culture and basic knowledge. To this end, we introduce National Alignment, which measures the alignment between an LLM and a targeted country from two aspects: social value... | Edward Choi, Hwaran Lee, Jiyoung Lee, Junghwan Kim, Minwoo Kim, Seungho Kim, Seunghyun Won |  |
| 1652 |  |  [Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development](https://doi.org/10.18653/v1/2024.findings-acl.667) |  | 0 | The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance, enhancing patient safety by identifying potential risks associated with medications, facilitating early detection of adverse events, and guiding regulatory decision-making. Traditional ADE detection methods are reliable but... | Aman Chadha, Ayush Kumar Singh, Pranab Sahoo, Samrat Mondal, Sriparna Saha |  |
| 1653 |  |  [Space Decomposition for Sentence Embedding](https://doi.org/10.18653/v1/2024.findings-acl.668) |  | 0 | Determining sentence pair similarity is crucial for various NLP tasks. A common technique to address this is typically evaluated on a continuous semantic textual similarity scale from 0 to 5. However, based on a linguistic observation in STS annotation guidelines, we found that the score in the... | Ekapol Chuangsuwanich, Peerat Limkonchotiwat, Sarana Nutanong, Wuttikorn Ponwitayarat |  |
| 1654 |  |  [Don't Augment, Rewrite? Assessing Abusive Language Detection with Synthetic Data](https://doi.org/10.18653/v1/2024.findings-acl.669) |  | 0 | Research on abusive language detection and content moderation is crucial to combat online harm. However, current limitations set by regulatory bodies and social media platforms can make it difficult to share collected data. We address this challenge by exploring the possibility to replace existing... | Camilla Casula, Elisa Leonardelli, Sara Tonelli |  |
| 1655 |  |  [Improving Low-Resource Machine Translation for Formosan Languages Using Bilingual Lexical Resources](https://doi.org/10.18653/v1/2024.findings-acl.670) |  | 0 | This paper investigates how machine translation for low-resource languages can be improved by incorporating information from bilingual lexicons during the training process for mainly translation between Mandarin and Formosan languages, which are all moribund or critically endangered, and we also... | Edison MarreseTaylor, Francis Zheng, Yutaka Matsuo |  |
| 1656 |  |  [CMMLU: Measuring massive multitask language understanding in Chinese](https://doi.org/10.18653/v1/2024.findings-acl.671) |  | 0 | As the capabilities of large language models (LLMs) continue to advance, evaluating their performance is becoming more important and more challenging. This paper aims to address this issue for Mandarin Chinese in the form of CMMLU, a comprehensive Chinese benchmark that covers various subjects,... | Fajri Koto, Hai Zhao, Haonan Li, Nan Duan, Timothy Baldwin, Yeyun Gong, Yifei Yang, Yixuan Zhang |  |
| 1657 |  |  [Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.672) |  | 0 | Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging. It not only requires checking whether the VLM follows the given instruction but also verifying whether the text output is properly grounded on the given image. Inspired by the recent approach of evaluating LMs... | Geewook Kim, Minjoon Seo, Seongyun Lee, Seungone Kim, Sue Hyun Park |  |
| 1658 |  |  [Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction](https://doi.org/10.18653/v1/2024.findings-acl.673) |  | 0 | The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual... | Fuli Feng, Junrong Guo, Moxin Li, Wenjie Wang, Xiaoyuan Li, Yang Zhang |  |
| 1659 |  |  [Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.674) |  | 0 |  | Fabio Massimo Zanzotto, Michele Mastromattei |  |
| 1660 |  |  [When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.675) |  | 0 | Large Language Models (LLMs) have been found to have difficulty knowing they do not possess certain knowledge and tend to provide specious answers in such cases. Retrieval Augmentation (RA) has been extensively studied to mitigate LLMs’ hallucinations. However, due to the extra overhead and... | Jiafeng Guo, Keping Bi, Shiyu Ni, Xueqi Cheng |  |
| 1661 |  |  [Hybrid Alignment Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.676) |  | 0 | Alignment training is crucial for enabling large language models (LLMs) to cater to human intentions and preferences. It is typically performed based on two stages with different objectives: instruction-following alignment and human-preference alignment. However, aligning LLMs with these objectives... | Bei Li, Chenglong Wang, Hang Zhou, JingBo Zhu, Kaiyan Chang, Tong Xiao, Tongran Liu, Yongyu Mu |  |
| 1662 |  |  [Graph-Structured Speculative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.677) |  | 0 | Speculative decoding has emerged as a promising technique to accelerate the inference of Large Language Models (LLMs) by employing a small language model to draft a hypothesis sequence, which is then validated by the LLM. The effectiveness of this approach heavily relies on the balance between... | Dongyan Zhao, Jiahao Liu, Jingang Wang, Pengfei Wu, Rui Yan, Xunliang Cai, Zhuocheng Gong, Ziyue Wang |  |
| 1663 |  |  [Duwak: Dual Watermarks in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.678) |  | 0 | As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable... | Chaoyi Zhu, Jeroen Galjaard, Lydia Y. Chen, PinYu Chen |  |
| 1664 |  |  [CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion](https://doi.org/10.18653/v1/2024.findings-acl.679) |  | 0 | The rapid advancement of Large Language Models (LLMs) has brought about remarkable generative capabilities but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods... | Chang Gao, Jing Shao, Junchi Yan, Lizhuang Ma, Qibing Ren, Wai Lam, Xin Tan |  |
| 1665 |  |  [Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training](https://doi.org/10.18653/v1/2024.findings-acl.680) |  | 0 | While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the “reversal curse”. It is a typical example that the model knows “A’s father is B”, but is unable to reason “B’s child is A”. This limitation poses a... | Jiang Bian, Junliang Guo, Qingyan Guo, Rui Wang, Xu Tan, Yujiu Yang |  |
| 1666 |  |  [wav2vec-S: Adapting Pre-trained Speech Models for Streaming](https://doi.org/10.18653/v1/2024.findings-acl.681) |  | 0 | Pre-trained speech models, such as wav2vec 2.0, have significantly advanced speech-related tasks, including speech recognition and translation. However, their applicability in streaming scenarios is limited because these models are trained on complete utterances, leading to a mismatch with... | Biao Fu, Kai Fan, Minpeng Liao, Xiaodong Shi, Yidong Chen, Zhongqiang Huang |  |
| 1667 |  |  [Peering into the Mind of Language Models: An Approach for Attribution in Contextual Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.682) |  | 0 | With the enhancement in the field of generative artificial intelligence (AI), contextual question answering has become extremely relevant. Attributing model generations to the input source document is essential to ensure trustworthiness and reliability. We observe that when large language models... | Anirudh Phukan, Apoorv Saxena, Balaji Vasan Srinivasan, Koustava Goswami, Shwetha Somasundaram |  |
| 1668 |  |  [TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification](https://doi.org/10.18653/v1/2024.findings-acl.683) |  | 0 | Large Language Model (LLM) services and models often come with legal rules on \*who\* can use them and \*how\* they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe... | Dennis Ulmer, Hwaran Lee, Martin Gubri, Sangdoo Yun, Seong Joon Oh |  |
| 1669 |  |  [CLASP: Cross-modal Alignment Using Pre-trained Unimodal Models](https://doi.org/10.18653/v1/2024.findings-acl.684) |  | 0 | Recent advancements in joint speech-text pre-training have significantly advanced the processing of natural language. However, a key limitation is their reliance on parallel speech-text data, posing challenges due to data accessibility. Addressing this, our paper introduces an innovative framework... | Hongyu Gong, Jianing Zhou, Suma Bhat, Ziheng Zeng |  |
| 1670 |  |  [TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind](https://doi.org/10.18653/v1/2024.findings-acl.685) |  | 0 | Theory of Mind (ToM)—the cognitive ability to reason about mental states of ourselves and others, is the foundation of social interaction. Although ToM comes naturally to humans, it poses a significant challenge to even the most advanced Large Language Models (LLMs). Due to the complex logical... | Guiyang Hou, Linjuan Wu, Weiming Lu, Wenqi Zhang, Yongliang Shen |  |
| 1671 |  |  [Identifying and Mitigating Annotation Bias in Natural Language Understanding using Causal Mediation Analysis](https://doi.org/10.18653/v1/2024.findings-acl.686) |  | 0 | NLU models have achieved promising results on standard benchmarks. Despite state-of-the-art accuracy, analysis reveals that many models make predictions using annotation bias rather than the properties we intend the model to learn. Consequently, these models perform poorly on out-of-distribution... | Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Peerat Limkonchotiwat, Sarana Nutanong, Sitiporn Sae Lim |  |
| 1672 |  |  [Perturbed examples reveal invariances shared by language models](https://doi.org/10.18653/v1/2024.findings-acl.687) |  | 0 | The rapid growth in natural language processing (NLP) research has led to numerous new models, outpacing our understanding of how they compare to established ones. One major reason for this difficulty is saturating benchmarks, which may not well reflect differences in model performance in the wild.... | Mariya Toneva, Ruchit Rawal |  |
| 1673 |  |  [Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation](https://doi.org/10.18653/v1/2024.findings-acl.688) |  | 0 | Stochastic sampling strategies such as top-k and top-p have been widely used in dialogue generation task. However, as an open-domain chatting system, there will be two different conversation scenarios, i.e. chit-chat and knowledge-based question answering. In the former situation, responses... | Bin Sun, Fei Mi, Kan Li, Shaoxiong Feng, Yasheng Wang, Yitong Li, Yiwei Li |  |
| 1674 |  |  [Discourse Structure-Aware Prefix for Generation-Based End-to-End Argumentation Mining](https://doi.org/10.18653/v1/2024.findings-acl.689) |  | 0 | End-to-end argumentation mining (AM) aims to extract the argumentation structure including argumentation components and their argumentation relations from text. Recent developments in end-to-end AM models have demonstrated significant progress by redefining the AM task as a sequence generation... | Bin Liang, Caihua Yang, Guanrong Chen, Jianzhu Bao, Min Yang, Ruifeng Xu, Xi Zeng, Yang Sun |  |
| 1675 |  |  [Poor-Supervised Evaluation for SuperLLM via Mutual Consistency](https://doi.org/10.18653/v1/2024.findings-acl.690) |  | 0 | The guidance from capability evaluations has greatly propelled the progress of human society and the development of Artificial Intelligence. However, as LLMs evolve, it becomes challenging to construct evaluation benchmark with accurate labels for SuperLLMs whose capabilities approach or even... | Boyuan Pan, Heda Wang, Kan Li, Peiwen Yuan, Shaoxiong Feng, Xinglin Wang, Yao Hu, Yiwei Li |  |
| 1676 |  |  [Addressing Entity Translation Problem via Translation Difficulty and Context Diversity](https://doi.org/10.18653/v1/2024.findings-acl.691) |  | 0 | Neural machine translation (NMT) systems often produce inadequate translations for named entities. In this study, we conducted preliminary experiments to examine the factors affecting the translation accuracy of named entities, specifically focusing on their translation difficulty and context... | Mingming Yang, Shuming Shi, Tian Liang, Xing Wang, Yujiu Yang, Zhaopeng Tu |  |
| 1677 |  |  [ADAM: Dense Retrieval Distillation with Adaptive Dark Examples](https://doi.org/10.18653/v1/2024.findings-acl.692) |  | 0 | To improve the performance of the dual-encoder retriever, one effective approach is knowledge distillation from the cross-encoder ranker. Existing works prepare training instances by pairing each query with one positive and a batch of negatives. However, most hard negatives mined by advanced dense... | Binxing Jiao, Can Xu, Chang Liu, Chongyang Tao, Daxin Jiang, Tao Shen, Xiubo Geng |  |
| 1678 |  |  [Instruction Position Matters in Sequence Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.693) |  | 0 | Large language models (LLMs) are capable of performing conditional sequence generation tasks, such as translation or summarization, through instruction fine-tuning. The fine-tuning data is generally sequentially concatenated from a specific task instruction, an input sentence, and the corresponding... | Chenze Shao, Fandong Meng, Jie Zhou, Xianfeng Zeng, Yijin Liu |  |
| 1679 |  |  [XMoE: Sparse Models with Fine-grained and Adaptive Expert Selection](https://doi.org/10.18653/v1/2024.findings-acl.694) |  | 0 | Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations by multiplying values... | Chaozheng Wang, Cuiyun Gao, Shiyi Qi, Wenchao Gu, Yuanhang Yang, Zenglin Xu |  |
| 1680 |  |  [BranchNorm: Robustly Scaling Extremely Deep Transformers](https://doi.org/10.18653/v1/2024.findings-acl.695) |  | 0 | Recently, DeepNorm scales Transformers into extremely deep (i.e., 1000 layers) and reveals the promising potential of deep scaling. To stabilize the training of deep models, DeepNorm attempts to constrain the model update to a constant value. Although applying such a constraint can benefit the... | Fandong Meng, Jie Zhou, Xianfeng Zeng, Yijin Liu |  |
| 1681 |  |  [MusTQ: A Temporal Knowledge Graph Question Answering Dataset for Multi-Step Temporal Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.696) |  | 0 | Question answering over temporal knowledge graphs (TKGQA) is an emerging topic, which has attracted increasing interest since it considers the dynamic knowledge in the world. Several datasets along with model developments are proposed in the TKGQA research field. However, existing studies generally... | An Liu, Hongping Zhi, Jiaan Wang, Jianfeng Qu, Tingyi Zhang, Zhigang Chen, Zhixu Li |  |
| 1682 |  |  [Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.697) |  | 0 | Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an... | Anthony Sicilia, Hyunwoo Kim, Jack Hessel, Khyathi Raghavi Chandu, Malihe Alikhani |  |
| 1683 |  |  [Knowledge Fusion By Evolving Weights of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.698) |  | 0 | Fine-tuning pre-trained language models, particularly large language models, demands extensive computing resources and can result in varying performance outcomes across different domains and datasets. This paper examines the approach of integrating multiple models from diverse training scenarios... | Guodong Du, Hanting Liu, HoKin Tang, Jing Li, Runhua Jiang, Shuyang Yu, Sim Kuan Goh, Yifei Guo |  |
| 1684 |  |  [ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale](https://doi.org/10.18653/v1/2024.findings-acl.699) |  | 0 | Multi-task learning (MTL) has shown considerable practical benefits, particularly when using language models (LMs). While this is commonly achieved by learning tasks under a joint optimization procedure, some methods, such as AdapterFusion, divide the problem into two stages: (i) task learning,... | Anne Lauscher, Carolin Holtermann, Markus Frohmann, Navid Rekabsaz, Shahed Masoudian |  |
| 1685 |  |  [Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.700) |  | 0 | For dialogue systems, the utilization of multimodal dialogue responses, as opposed to relying solely on text-only responses, offers the capability to describe different concepts through various modalities. This enhances the effectiveness of communication and elevates the overall conversational... | ChangSheng Kao, YunNung Chen |  |
| 1686 |  |  [MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization](https://doi.org/10.18653/v1/2024.findings-acl.701) |  | 0 | Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather... | Dong Yu, Maosong Sun, Pengyuan Liu, Shuo Wang, Xiaodong Shi, Xin Cong, Xu Han, Yukun Yan, Zhenghao Liu, Zhixing Tan, Zhiyu Yang, Zhiyuan Liu, Zihan Zhou |  |
| 1687 |  |  [Continual Few-shot Relation Extraction via Adaptive Gradient Correction and Knowledge Decomposition](https://doi.org/10.18653/v1/2024.findings-acl.702) |  | 0 | Continual few-shot relation extraction (CFRE) aims to continually learn new relations with limited samples. However, current methods neglect the instability of embeddings in the process of different task training, which leads to serious catastrophic forgetting. In this paper, we propose the concept... | Chengxiang Tan, Jiacheng Xu, Jianpeng Hu, Xiangyun Kong |  |
| 1688 |  |  [CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.703) |  | 0 | What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the... | Deyi Xiong, Haixin Liu, Jiahui Zhao, Jinwang Song, Linhao Yu, Liutao Liutao, Shang Wu, Tingting Cui, Xiaoqing Cheng, Xinmeng Ji, Yongqi Leng, Yufei Huang |  |
| 1689 |  |  [Cache & Distil: Optimising API Calls to Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.704) |  | 0 | Large-scale deployment of generative AI tools often depends on costly API calls to a Large Language Model (LLM) to fulfil user queries, a process that also exposes the request stream to external providers. To curtail the frequency of these calls, one can employ a local smaller language model -a... | Alexandra Birch, Guillem Ramírez, Ivan Titov, Matthias Lindemann |  |
| 1690 |  |  [Investigating the Impact of Model Instability on Explanations and Uncertainty](https://doi.org/10.18653/v1/2024.findings-acl.705) |  | 0 | Explainable AI methods facilitate the understanding of model behaviour, yet, small, imperceptible perturbations to inputs can vastly distort explanations. As these explanations are typically evaluated holistically, before model deployment, it is difficult to assess when a particular explanation is... | Christina Lioma, Isabelle Augenstein, Sara Marjanovic |  |
| 1691 |  |  [A Two-Stage Adaptation of Large Language Models for Text Ranking](https://doi.org/10.18653/v1/2024.findings-acl.706) |  | 0 | Text ranking is a critical task in information retrieval. Recent advances in pre-trained language models (PLMs), especially large language models (LLMs), present new opportunities for applying them to text ranking. While supervised fine-tuning (SFT) with ranking data has been widely explored to... | Dingkun Long, Longhui Zhang, Meishan Zhang, Min Zhang, Pengjun Xie, Yanzhao Zhang |  |
| 1692 |  |  [Fine-tuning with HED-IT: The impact of human post-editing for dialogical language models](https://doi.org/10.18653/v1/2024.findings-acl.707) |  | 0 | Automatic methods for generating and gathering linguistic data have proven effective for fine-tuning Language Models (LMs) in languages less resourced than English. Still, while there has been emphasis on data quantity, less attention has been given to its quality. In this work, we investigate the... | Daniela Occhipinti, Felice Dell'Orletta, Huiyuan Lai, Irene Mondella, Malvina Nissim, Marco Guerini, Michele Marchi |  |
| 1693 |  |  [Analyze, Generate and Refine: Query Expansion with LLMs for Zero-Shot Open-Domain QA](https://doi.org/10.18653/v1/2024.findings-acl.708) |  | 0 | Query expansion (QE) is a critical component in the open-domain question answering (OpenQA) pipeline, enhancing the retrieval performance by broadening the scope of queries with additional relevant texts. However, existing methods like GAR and EAR rely heavily on supervised training and often... | Ben He, Le Sun, Tengfei Wen, Xinran Chen, Xuanang Chen |  |
| 1694 |  |  [On the Evaluation of Speech Foundation Models for Spoken Language Understanding](https://doi.org/10.18653/v1/2024.findings-acl.709) |  | 0 | The Spoken Language Understanding Evaluation (SLUE) suite of benchmark tasks was recently introduced to address the need for openresources and benchmarking of complex spoken language understanding (SLU) tasks, including both classification and sequence generation tasks, on natural speech. The... | Ankita Pasad, ChungMing Chien, Hira Dhamyal, Hungyi Lee, Jeeweon Jung, Jionghao Han, Karen Livescu, Roshan S. Sharma, Shinji Watanabe, Siddhant Arora, Suwon Shon, William Chen |  |
| 1695 |  |  [Towards Multiple References Era - Addressing Data Leakage and Limited Reference Diversity in Machine Translation Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.710) |  | 0 | Recent research has shown a weak correlation between n-gram-based metrics and human evaluations in machine translation task, particularly when evaluating large language models (LLMs). Additionally, the data leakage risk in LLMs may cause an overestimation problem when evaluating LLMs on downstream... | Fandong Meng, Jie Zhou, Xianfeng Zeng, Yijin Liu |  |
| 1696 |  |  [Prompting open-source and commercial language models for grammatical error correction of English learner text](https://doi.org/10.18653/v1/2024.findings-acl.711) |  | 0 | Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input... | Andrew Caines, Christopher Bryant, Christopher Davis, Helen Yannakoudakis, Marek Rei, Paula Buttery, Shiva Taslimipoor, Zheng Yuan, Øistein E. Andersen |  |
| 1697 |  |  [BATS: BenchmArking Text Simplicity 🦇](https://doi.org/10.18653/v1/2024.findings-acl.712) |  | 0 | Evaluation of text simplification currently focuses on the difference of a source text to its simplified variant. Datasets for this evaluation base on a specific topic and group of readers for which is simplified. The broad applicability of text simplification and specifics that come with intended... | Björn Engelmann, Christin Kreutz, Fabian Haak, Philipp Schaer |  |
| 1698 |  |  [AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection](https://doi.org/10.18653/v1/2024.findings-acl.713) |  | 0 | Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently, such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian... | Allan Hanbury, Anna Maria Planitzer, Janis Goldzycher, Julia Neidhardt, Pia Pachinger, Wojciech Kusa |  |
| 1699 |  |  [Discovering influential text using convolutional neural networks](https://doi.org/10.18653/v1/2024.findings-acl.714) |  | 0 | Experimental methods for estimating the impacts of text on human evaluation have been widely used in the social sciences. However, researchers in experimental settings are usually limited to testing a small number of pre-specified text treatments. While efforts to mine unstructured texts for... | Eddie Yang, Luke Sanford, Margaret E. Roberts, Megan Ayers |  |
| 1700 |  |  [LC4EE: LLMs as Good Corrector for Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.715) |  | 0 | Event extraction (EE) is a critical task in natural language processing, yet deploying a practical EE system remains challenging. On one hand, powerful large language models (LLMs) currently show poor performance because EE task is more complex than other tasks. On the other hand, state-of-the-art... | Hongbin Huang, Jibing Wu, Juanzi Li, Kaisheng Zeng, Lei Hou, Lihua Liu, Mengna Zhu |  |
| 1701 |  |  [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.716) |  | 0 | Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs’ training data, it could explicitly or implicitly include test data, leading to LLMs being... | Bin Gu, Ge Li, Huanyu Liu, Mengfei Yang, Xue Jiang, Yihong Dong, Zhi Jin |  |
| 1702 |  |  [Efficient Training of Language Models with Compact and Consistent Next Token Distributions](https://doi.org/10.18653/v1/2024.findings-acl.717) |  | 0 | Maximizing the likelihood of the next token is an established, statistically sound objective for pre-training language models. In this paper we show that we can train better models faster by pre-aggregating the corpus with a collapsed n-gram distribution. Previous studies have proposed corpus-level... | Ashutosh Sathe, Sunita Sarawagi |  |
| 1703 |  |  [Ancient Chinese Glyph Identification Powered by Radical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.718) |  | 0 | The ancestor of Chinese character – the ancient characters from about 1300 BC to 200 BC are not fixed in their writing glyphs. At the same or different points in time, one character can possess multiple glyphs that are different in shapes or radicals. Nearly half of ancient glyphs have not been... | Chuntao Li, Fausto Giunchiglia, Hao Xu, Yang Chi |  |
| 1704 |  |  [PUB: A Pragmatics Understanding Benchmark for Assessing LLMs' Pragmatics Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.719) |  | 0 | LLMs have demonstrated remarkable capability for understanding semantics, but their understanding of pragmatics is not well studied. To this end, we release a Pragmatics Understanding Benchmark (PUB) dataset consisting of fourteen tasks in four pragmatics phenomena, namely; Implicature,... | Meet Doshi, Pavan Tankala, Pushpak Bhattacharyya, Raj Dabre, Settaluri Lakshmi Sravanthi, V. Rudra Murthy |  |
| 1705 |  |  [EmoTransKG: An Innovative Emotion Knowledge Graph to Reveal Emotion Transformation](https://doi.org/10.18653/v1/2024.findings-acl.720) |  | 0 | This paper introduces EmoTransKG, an innovative Emotion Knowledge Graph (EKG) that establishes connections and transformations between emotions across diverse open-textual events. Compared to existing EKGs, which primarily focus on linking emotion keywords to related terms or on assigning sentiment... | Huan Zhao, Xupeng Zha, Zixing Zhang |  |
| 1706 |  |  [How Vocabulary Sharing Facilitates Multilingualism in LLaMA?](https://doi.org/10.18653/v1/2024.findings-acl.721) |  | 0 | Large Language Models (LLMs), often show strong performance on English tasks, while exhibiting limitations on other languages. What is an LLM’s multilingual capability when it is trained only on certain languages? The underlying mechanism remains unclear. This study endeavors to examine the... | Fei Yuan, Lei Li, Shuai Yuan, Zhiyong Wu |  |
| 1707 |  |  [Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model](https://doi.org/10.18653/v1/2024.findings-acl.722) |  | 0 | While supervised fine-tuning (SFT) has been a straightforward approach for tailoring the output of foundation large language model (LLM) to specific preferences, concerns have been raised about the depth of this alignment, with some critiques suggesting it is merely “superficial”. We critically... | Derek F. Wong, Lidia S. Chao, Runzhe Zhan, Xinyi Yang, Yue Zhang |  |
| 1708 |  |  [Dual Prompt Tuning based Contrastive Learning for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.findings-acl.723) |  | 0 | Hierarchical text classification aims at categorizing texts into a multi-tiered tree-structured hierarchy of labels. Existing methods pay more attention to capture hierarchy-aware text feature by exploiting explicit parent-child relationships, while interactions between peer labels are rarely taken... | Jie Zhang, Mengxiang Li, Shuangyong Song, Sishi Xiong, Xuelong Li, Yu Zhao, Zhongjiang He |  |
| 1709 |  |  [Probing the Emergence of Cross-lingual Alignment during LLM Training](https://doi.org/10.18653/v1/2024.findings-acl.724) |  | 0 | Multilingual Large Language Models (LLMs) achieve remarkable levels of zero-shot cross-lingual transfer performance. We speculate that this is predicated on their ability to align languages without explicit supervision from parallel sentences. While representations of translationally equivalent... | Edoardo M. Ponti, Hetong Wang, Pasquale Minervini |  |
| 1710 |  |  [STSPL-SSC: Semi-Supervised Few-Shot Short Text Clustering with Semantic text similarity Optimized Pseudo-Labels](https://doi.org/10.18653/v1/2024.findings-acl.725) |  | 0 | This study introduces the Semantic Textual Similarity Pseudo-Label Semi-Supervised Clustering (STSPL-SSC) framework. The STSPL-SSC framework is designed to tackle the prevalent issue of scarce labeled data by combining a Semantic Textual Similarity Pseudo-Label Generation process with a Robust... | ChangBo Liu, Haoran Zheng, Jialing Wei, Lin Deng, Ruitong Han, Wenhua Nie |  |
| 1711 |  |  [A Comprehensive Evaluation of Quantization Strategies for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.726) |  | 0 | Increasing the number of parameters in large language models (LLMs) usually improves performance in downstream tasks but raises compute and memory costs, making deployment difficult in resource-limited settings. Quantization techniques, which reduce the bits needed for model weights or activations... | Bin Wang, Deyi Xiong, Jian Luan, Jiangcun Du, Renren Jin, Wei Liu, Wuwei Huang |  |
| 1712 |  |  [Exploiting Target Language Data for Neural Machine Translation Beyond Back Translation](https://doi.org/10.18653/v1/2024.findings-acl.727) |  | 0 | Neural Machine Translation (NMT) encounters challenges when translating in new domains and low-resource languages. To address these issues, researchers have proposed methods to integrate additional knowledge into NMT, such as translation memories (TMs). However, finding TMs that closely match the... | Abudurexiti Reheman, Anxiang Ma, Chunliang Zhang, JingBo Zhu, Junhao Ruan, Tong Xiao, Yingfeng Luo |  |
| 1713 |  |  [Bayesian Prompt Ensembles: Model Uncertainty Estimation for Black-Box Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.728) |  | 0 | An important requirement for the reliable deployment of pre-trained large language models (LLMs) is the well-calibrated quantification of the uncertainty in their outputs. While the likelihood of predicting the next token is a practical surrogate of the data uncertainty learned during training,... | Francesco Tonolini, Gabriella Kazai, Jordan Massiah, Nikolaos Aletras |  |
| 1714 |  |  [X-ACE: Explainable and Multi-factor Audio Captioning Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.729) |  | 0 | Automated audio captioning (AAC) aims to generate descriptions based on audio input, attracting exploration of emerging audio language models (ALMs). However, current evaluation metrics only provide a single score to assess the overall quality of captions without characterizing the nuanced... | JiaChen Gu, Qian Wang, ZhenHua Ling |  |
| 1715 |  |  [Reasons to Reject? Aligning Language Models with Judgments](https://doi.org/10.18653/v1/2024.findings-acl.730) |  | 0 | As humans, we consistently interact with our peers and receive feedback in the form of natural language. This language feedback allows us to maintain appropriate behavior, and rectify potential errors. The question arises naturally: can we use language feedback to align large language models... | Deng Cai, Shuming Shi, Wai Lam, Weiwen Xu, Zhisong Zhang |  |
| 1716 |  |  [Decomposing Argumentative Essay Generation via Dialectical Planning of Complex Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.731) |  | 0 | Argumentative Essay Generation (AEG) is a challenging task in computational argumentation, where detailed logical reasoning and effective rhetorical skills are essential.Previous methods on argument generation typically involve planning prior to generation.However, the planning strategies in these... | Bin Liang, Bing Qin, Jianzhu Bao, Min Yang, Ruifeng Xu, Yang Sun, Yuhang He |  |
| 1717 |  |  [Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition](https://doi.org/10.18653/v1/2024.findings-acl.732) |  | 0 | Recognizing fallacies is crucial for ensuring the quality and validity of arguments across various domains. However, computational fallacy recognition faces challenges due to the diverse genres, domains, and types of fallacies found in datasets. This leads to a highly multi-class, and even... | Preslav Nakov, Smaranda Muresan, Tariq Alhindi |  |
| 1718 |  |  [Concept-aware Data Construction Improves In-context Learning of Language Models](https://doi.org/10.18653/v1/2024.findings-acl.733) |  | 0 | Many recent language models (LMs) are capable of in-context learning (ICL), manifested in the LMs’ ability to perform a new task solely from natural-language instruction. Previous work curating in-context learners assumes that ICL emerges from a vast over-parametrization or the scale of multi-task... | Marek Kadlcík, Michal Stefánik, Petr Sojka |  |
| 1719 |  |  [Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis](https://doi.org/10.18653/v1/2024.findings-acl.734) |  | 0 | Supervised machine-learning models for predicting user behavior offer a challenging classification problem with lower average prediction performance scores than other text classification tasks. This study evaluates multi-task learning frameworks grounded in Cognitive Appraisal Theory to predict... | Gerard Yeo, Kokil Jaidka, Shaz Furniturewala |  |
| 1720 |  |  [Non-Autoregressive Machine Translation as Constrained HMM](https://doi.org/10.18653/v1/2024.findings-acl.735) |  | 0 | In non-autoregressive translation (NAT), directed acyclic Transformers (DAT) have demonstrated their ability to achieve comparable performance to the autoregressive Transformers.In this paper, we first show that DAT is essentially a fully connected left-to-right Hidden Markov Model (HMM), with the... | Haoran Li, Wei Lu, Zhanming Jie |  |
| 1721 |  |  [Multi-modal Stance Detection: New Datasets and Model](https://doi.org/10.18653/v1/2024.findings-acl.736) |  | 0 | Stance detection is a challenging task that aims to identify public opinion from social media platforms with respect to specific targets. Previous work on stance detection largely focused on pure texts. In this paper, we study multi-modal stance detection for tweets consisting of texts and images,... | Ang Li, Bin Liang, Jingqian Zhao, KamFai Wong, Lin Gui, Min Yang, Ruifeng Xu, Yue Yu |  |
| 1722 |  |  [Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression](https://doi.org/10.18653/v1/2024.findings-acl.737) |  | 0 | Large language models (LLMs) can generate long-form and coherent text, yet they often hallucinate facts, which undermines their reliability. To mitigate this issue, inference-time methods steer LLM representations toward the “truthful directions” previously learned for truth elicitation. However,... | Farima Fatahi Bayat, H. V. Jagadish, Lu Wang, Xin Liu |  |
| 1723 |  |  [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.738) |  | 0 | In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities... | Chenhui Chu, Chenxing Li, Dan Su, Dong Yu, Duzhen Zhang, Jiahua Dong, Yahan Yu |  |
| 1724 |  |  [CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.739) |  | 0 | The advancement of large language models (LLMs) has enhanced the ability to generalize across a wide range of unseen natural language processing (NLP) tasks through instruction-following.Yet, their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased... | Chenghua Lin, Ge Zhang, Hao Li, Jiajun Zhang, Jiali Li, Jie Fu, Kai Zhang, Lei Ma, Lei Zhang, Noah Wang, Ruibin Yuan, Wangchunshu Zhou, Wenhao Huang, Xingwei Qu, Yiming Liang, Yinghao Ma, Yizhi Li, Zhaoqun Li, Zuowen Li |  |
| 1725 |  |  [Countering Reward Over-Optimization in LLM with Demonstration-Guided Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.740) |  | 0 | While reinforcement learning (RL) has been proven essential for tuning large language models (LLMs), it can lead to reward over-optimization (ROO). Existing approaches address ROO by adding KL regularization, requiring computationally expensive hyperparameter tuning. Additionally, KL regularization... | Emmanuel Dupoux, Florian Strub, Mathieu Rita, Olivier Pietquin, Paul Michel, Rahma Chaabouni |  |
| 1726 |  |  [Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss](https://doi.org/10.18653/v1/2024.findings-acl.741) |  | 0 | Accurately modeling idiomatic or non-compositional language has been a longstanding challenge in Natural Language Processing (NLP). This is partly because these expressions do not derive their meanings solely from their constituent words, but also due to the scarcity of relevant data resources, and... | Aline Villavicencio, Carolina Scarton, Marco Idiart, Wei He |  |
| 1727 |  |  [AdaLomo: Low-memory Optimization with Adaptive Learning Rate](https://doi.org/10.18653/v1/2024.findings-acl.742) |  | 0 | Large language models have achieved remarkable success, but their extensive parameter size necessitates substantial memory for training, thereby setting a high threshold. While the recently proposed low-memory optimization (LOMO) reduces memory footprint, its optimization technique, akin to... | Haijun Lv, Hang Yan, Kai Lv, Qipeng Guo, Xipeng Qiu |  |
| 1728 |  |  [Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks](https://doi.org/10.18653/v1/2024.findings-acl.743) |  | 0 | Current knowledge editing approaches struggle to effectively propagate updates to interconnected facts.In this work, we delve into the barriers that hinder the appropriate propagation of updated knowledge within these models for accurate reasoning. To support our analysis, we introduce a novel... | Henghui Zhu, Jiang Guo, Mingwen Dong, Patrick Ng, Wenyue Hua, Zhiguo Wang |  |
| 1729 |  |  [Exciting Mood Changes: A Time-aware Hierarchical Transformer for Change Detection Modelling](https://doi.org/10.18653/v1/2024.findings-acl.744) |  | 0 | Through the rise of social media platforms, longitudinal language modelling has received much attention over the latest years, especially in downstream tasks such as mental health monitoring of individuals where modelling linguistic content in a temporal fashion is crucial. A key limitation in... | Adam Tsakalidis, Anthony Hills, Maria Liakata, Talia Tseriotou, Xenia Miscouridou |  |
| 1730 |  |  [CorNav: Autonomous Agent with Self-Corrected Planning for Zero-Shot Vision-and-Language Navigation](https://doi.org/10.18653/v1/2024.findings-acl.745) |  | 0 | Understanding and following natural language instructions while navigating through complex, real-world environments poses a significant challenge for general-purpose robots. These environments often include obstacles and pedestrians, making it essential for autonomous agents to possess the... | Hang Xu, Jianhua Han, Liang Ma, Shanshan Guo, Shikui Ma, Xiaodan Liang, Xiwen Liang |  |
| 1731 |  |  [SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.746) |  | 0 | Multi-modal information retrieval (MMIR) is a rapidly evolving field where significant progress has been made through advanced representation learning and cross-modality alignment research, particularly in image-text pairing.However, current benchmarks for evaluating MMIR performance on image-text... | Bohao Yang, Chenghao Xiao, Chenghua Lin, Ge Zhang, Haoran Zhang, Jie Fu, Kaijing Ma, Kang Zhu, Noura Al Moubayed, Siwei Wu, Wenhao Huang, Wenhu Chen, Yiming Liang, Yizhi Li |  |
| 1732 |  |  [Diving Deep into the Motion Representation of Video-Text Models](https://doi.org/10.18653/v1/2024.findings-acl.747) |  | 0 | Videos are more informative than images becausethey capture the dynamics of the scene.By representing motion in videos, we can capturedynamic activities. In this work, we introduceGPT-4 generated motion descriptions thatcapture fine-grained motion descriptions of activitiesand apply them to three... | Chinmaya Devaraj, Cornelia Fermüller, Yiannis Aloimonos |  |
| 1733 |  |  [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation](https://doi.org/10.18653/v1/2024.findings-acl.748) |  | 0 | We introduce Bonito, an open-source model for conditional task generation that converts unannotated text into task-specific training datasets for instruction tuning. We aim to enable zero-shot task adaptation of large language models on users’ specialized, private data. We train Bonito by... | Avi Trost, Nihal V. Nayak, Stephen H. Bach, Yiyang Nan |  |
| 1734 |  |  [Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.749) |  | 0 | Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also often retain a large portion of... | Ajay Divakaran, Andreas Kathol, Anirudh Som, Dimitra Vergyri, Helen Gent, Karan Sikka |  |
| 1735 |  |  [Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse](https://doi.org/10.18653/v1/2024.findings-acl.750) |  | 0 | Whataboutism, a potent tool for disrupting narratives and sowing distrust, remains under-explored in quantitative NLP research. Moreover, past work has not distinguished its use as a strategy for misinformation and propaganda from its use as a tool for pragmatic and semantic framing. We introduce... | Chenlu Wang, Khiem Phi, Noushin Salek Faramarzi, Ritwik Banerjee |  |
| 1736 |  |  [Epistemology of Language Models: Do Language Models Have Holistic Knowledge?](https://doi.org/10.18653/v1/2024.findings-acl.751) |  | 0 | This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as... | James Thorne, Minsu Kim |  |
| 1737 |  |  [Strong hallucinations from negation and how to fix them](https://doi.org/10.18653/v1/2024.findings-acl.752) |  | 0 | Despite great performance on many tasks, language models (LMs) still struggle with reasoning, sometimes providing responses that cannot possibly be true because they stem from logical incoherence. We call such responses strong hallucinations and prove that they follow from an LM’s computation of... | Nicholas Asher, Swarnadeep Bhar |  |
| 1738 |  |  [LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores](https://doi.org/10.18653/v1/2024.findings-acl.753) |  | 0 | Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for... | Chenghua Lin, Nafise Sadat Moosavi, Yiqi Liu |  |
| 1739 |  |  [HelloFresh: LLM Evalutions on Streams of Real-World Human Editorial Actions across X Community Notes and Wikipedia edits](https://doi.org/10.18653/v1/2024.findings-acl.754) |  | 0 | Benchmarks have been essential for driving progress in machine learning. A better understanding of LLM capabilities on real world tasks is vital for safe development.Designing adequate LLM benchmarks is challenging: Data from real-world tasks is hard to collect, public availability of static... | Aleksandar Shtedritski, Jakob N. Foerster, João F. Henriques, Philip Torr, Samuel Albanie, Tim Franzmeyer |  |
| 1740 |  |  [Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies](https://doi.org/10.18653/v1/2024.findings-acl.755) |  | 0 | This study explores the sycophantic tendencies of Large Language Models (LLMs), where these models tend to provide answers that match what users want to hear, even if they are not entirely correct. The motivation behind this exploration stems from the common behavior observed in individuals... | Aswin RRV, Chitta Baral, Md Nayem Uddin, Neeraj Varshney, Nemika Tyagi |  |
| 1741 |  |  [Empowering Large Language Models for Textual Data Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.756) |  | 0 | With the capabilities of understanding and executing natural language instructions, Large language models (LLMs) can potentially act as a powerful tool for textual data augmentation. However, the quality of augmented data depends heavily on the augmentation instructions provided, and the... | Jianling Wang, Kaize Ding, Kyumin Lee, Yichuan Li |  |
| 1742 |  |  [Choose Your Transformer: Improved Transferability Estimation of Transformer Models on Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.757) |  | 0 | There currently exists a multitude of pre-trained transformer language models (LMs) that are readily available. From a practical perspective, this raises the question of which pre-trained LM will perform best if fine-tuned for a specific downstream NLP task. However, exhaustively fine-tuning all... | Alan Akbik, Lukas Garbaciauskas, Max Ploner |  |
| 1743 |  |  [Argument-Aware Approach To Event Linking](https://doi.org/10.18653/v1/2024.findings-acl.758) |  | 0 | Event linking connects event mentions in text with relevant nodes in a knowledge base (KB). Prior research in event linking has mainly borrowed methods from entity linking, overlooking the distinct features of events. Compared to the extensively explored entity linking task, events have more... | IHung Hsu, Jayanth Srinivasa, Nanyun Peng, Nilay Pochhi, Prem Natarajan, Sahil Bansal, Zihan Xue |  |
| 1744 |  |  [CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation](https://doi.org/10.18653/v1/2024.findings-acl.759) |  | 0 | Grounded generation aims to equip language models (LMs) with the ability to produce more credible and accountable responses by accurately citing verifiable sources. However, existing methods, by either feeding LMs with raw or preprocessed materials, remain prone to errors. To address this, we... | ChenYu Lee, IHung Hsu, Lesly Miculicich, Long T. Le, Nanyun Peng, Tomas Pfister, Zifeng Wang |  |
| 1745 |  |  [TextEE: Benchmark, Reevaluation, Reflections, and Future Challenges in Event Extraction](https://doi.org/10.18653/v1/2024.findings-acl.760) |  | 0 | Event extraction has gained considerable interest due to its wide-ranging applications. However, recent studies draw attention to evaluation issues, suggesting that reported scores may not accurately reflect the true performance. In this work, we identify and address evaluation challenges,... | Heng Ji, IHung Hsu, KaiWei Chang, KuanHao Huang, Nanyun Peng, Prem Natarajan, Tanmay Parekh, Zhiyu Xie, Zixuan Zhang |  |
| 1746 |  |  [Understanding the Impacts of Language Technologies' Performance Disparities on African American Language Speakers](https://doi.org/10.18653/v1/2024.findings-acl.761) |  | 0 | This paper examines the experiences of African American Language (AAL) speakers when using language technologies. Previous work has used quantitative methods to uncover performance disparities between AAL speakers and White Mainstream English speakers when using language technologies, but has not... | Christina Harrington, Hal Daumé III, Hanna M. Wallach, Jay Cunningham, Michael Madaio, Su Lin Blodgett |  |
| 1747 |  |  [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://doi.org/10.18653/v1/2024.findings-acl.762) |  | 0 | The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of... | Bill Yuchen Lin, Ge Zhang, Jie Fu, Tianhao Shen, Tianyu Zheng, Wenhu Chen, Xiang Yue, Xueling Liu |  |
| 1748 |  |  [Measuring and Addressing Indexical Bias in Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.763) |  | 0 | Information Retrieval (IR) systems are designed to deliver relevant content, but traditional systems may not optimize rankings for fairness, neutrality, or the balance of ideas. Consequently, IR can often introduce indexical biases, or biases in the positional order of documents. Although indexical... | Caleb Ziems, Diyi Yang, Jane DwivediYu, William Held |  |
| 1749 |  |  [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://doi.org/10.18653/v1/2024.findings-acl.764) |  | 0 | Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, leading to inherent biases toward Western culture. This bias... | Ahmed Ashraf, Deema Alnuhait, Gamil Ahmed, Gubran A. Q. Abdulrahman, Khalid Almubarak, Maged Saeed AlShaibani, Mustafa Ghaleb, Qais Gawah, Saied Alshahrani, Yousef Ali, Zaid Alyafeai, Zead Saleh |  |
| 1750 |  |  [RadGraph-XL: A Large-Scale Expert-Annotated Dataset for Entity and Relation Extraction from Radiology Reports](https://doi.org/10.18653/v1/2024.findings-acl.765) |  | 0 | In order to enable extraction of structured clinical data from unstructured radiology reports, we introduce RadGraph-XL, a large-scale, expert-annotated dataset for clinical entity and relation extraction. RadGraph-XL consists of 2,300 radiology reports, which are annotated with over 410,000... | Andrew Johnston, Curtis P. Langlotz, Dave Van Veen, JeanBenoit Delbrouck, Louis Blankemeier, Maya Varma, Pierre J. Chambon, Steven Quoc Hung Truong, Tan Bui, Zhihong Chen |  |
| 1751 |  |  [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.766) |  | 0 | Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance... | Ganesh Ramakrishnan, H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia |  |
| 1752 |  |  [Selective "Selective Prediction": Reducing Unnecessary Abstention in Vision-Language Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.767) |  | 0 | Selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain... | Bill Yuchen Lin, Jack Hessel, Jesse Thomason, Khyathi Raghavi Chandu, Tanmay Gupta, Tejas Srinivasan, Yejin Choi |  |
| 1753 |  |  [Language Model Priors and Data Augmentation Strategies for Low-resource Machine Translation: A Case Study Using Finnish to Northern Sámi](https://doi.org/10.18653/v1/2024.findings-acl.768) |  | 0 | We investigate ways of using monolingual data in both the source and target languages for improving low-resource machine translation. As a case study, we experiment with translation from Finnish to Northern Sámi.Our experiments show that while conventional backtranslation remains a strong... | Constantine Lignos, Jonne Sälevä |  |
| 1754 |  |  [Differentially Private Knowledge Distillation via Synthetic Text Generation](https://doi.org/10.18653/v1/2024.findings-acl.769) |  | 0 | Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy puts pressure on practitioners to train LLMs with Differential Privacy (DP) on private data. Concurrently, the exponential growth in parameter... | James Flemings, Murali Annavaram |  |
| 1755 |  |  [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](https://doi.org/10.18653/v1/2024.findings-acl.770) |  | 0 | Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on... | Bailey Kuehl, David Wadden, Eunsol Choi, Fangyuan Xu, Kyle Lo, Luca Soldaini |  |
| 1756 |  |  [XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the Multilingual Generation of News Headlines and Tags](https://doi.org/10.18653/v1/2024.findings-acl.771) |  | 0 | Millions of news articles published online daily can overwhelm readers. Headlines and entity (topic) tags are essential for guiding readers to decide if the content is worth their time. While headline generation has been extensively studied, tag generation remains largely unexplored, yet it offers... | Abu Ubaida Akash, Faisal Tareque Shohan, Mir Tafseer Nayeem, Samsul Islam, Shafiq Joty |  |
| 1757 |  |  [InFoBench: Evaluating Instruction Following Ability in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.772) |  | 0 | This paper introduces the Decomposed Requirements Following Ratio (DRFR), a new metric for evaluating Large Language Models’ (LLMs) ability to follow instructions. Addressing a gap in current methodologies, DRFR breaks down complex instructions into simpler criteria, facilitating a detailed... | Dong Yu, Fei Liu, Kaiqiang Song, Pengfei Liu, Sangwoo Cho, Wenlin Yao, Xiaoyang Wang, Xuansheng Wu, Yebowen Hu, Yiwei Qin |  |
| 1758 |  |  [EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.773) |  | 0 | Large Language Models (LLMs) have achieved state-of-the-art performance in text re-ranking. This process includes queries and candidate passages in the prompts, utilizing pointwise, listwise, and pairwise prompting strategies. A limitation of these ranking strategies with LLMs is their cost: the... | Jannat Ara Meem, Muhammad Shihab Rashid, Vagelis Hristidis, Yue Dong |  |
| 1759 |  |  [FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.774) |  | 0 | We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction... | El Moatez Billah Nagoudi, Gagan Bhatia, Hasan Cavusoglu, Muhammad AbdulMageed |  |
| 1760 |  |  [Aligning Large Multimodal Models with Factually Augmented RLHF](https://doi.org/10.18653/v1/2024.findings-acl.775) |  | 0 | Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in “hallucination”, generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement... | Chuang Gan, Chunyuan Li, Haotian Liu, Kurt Keutzer, Liangyan Gui, Sheng Shen, Shengcao Cao, Trevor Darrell, Yikang Shen, Yiming Yang, YuXiong Wang, Zhiqing Sun |  |
| 1761 |  |  [The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness](https://doi.org/10.18653/v1/2024.findings-acl.776) |  | 0 | As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research. This has resulted in the development of various LLM defense strategies. Unfortunately, despite the shared goal of improving the... | Agastya Seth, Chitta Baral, Neeraj Varshney, Pavel Dolin |  |
| 1762 |  |  [PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering](https://doi.org/10.18653/v1/2024.findings-acl.777) |  | 0 | Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. ‘Who was the US president in 1970?’). Little work has studied questions whose temporal context is relative to the present time (e.g. ‘Who was the previous US... | Jannat Ara Meem, Muhammad Shihab Rashid, Vagelis Hristidis, Yue Dong |  |
| 1763 |  |  [360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](https://doi.org/10.18653/v1/2024.findings-acl.778) |  | 0 |  | Chengrui Huang, Hao Li, Minlie Huang, Quan Tu, Shen Gao, Shuo Shang, Zhengliang Shi, Zhiliang Tian |  |
| 1764 |  |  [Extracting Polymer Nanocomposite Samples from Full-Length Documents](https://doi.org/10.18653/v1/2024.findings-acl.779) |  | 0 | This paper investigates the use of large language models (LLMs) for extracting sample lists of polymer nanocomposites (PNCs) from full-length materials science research papers. The challenge lies in the complex nature of PNC samples, which have numerous attributes scattered throughout the text. The... | Bhuwan Dhingra, Defne Circi, Ghazal Khalighinejad, L. Catherine Brinson |  |
| 1765 |  |  [Leveraging LLM Reasoning Enhances Personalized Recommender Systems](https://doi.org/10.18653/v1/2024.findings-acl.780) |  | 0 |  | Adam Kraft, Alicia Tsai, Anahita Hosseini, Chenwei Cai, Ed Huaihsin Chi, Lichan Hong, Long Jin, Taibai Xu, Xinyang Yi, Zemin Zhang |  |
| 1766 |  |  [Toucan: Many-to-Many Translation for 150 African Language Pairs](https://doi.org/10.18653/v1/2024.findings-acl.781) |  | 0 | We address a notable gap in Natural Language Processing (NLP) by introducing a collection of resources designed to improve Machine Translation (MT) for low-resource languages, with a specific focus on African languages. First, We introduce two language models (LMs), Cheetah-1.2B and Cheetah-3.7B,... | AbdelRahim A. Elmadany, Ife Adebara, Muhammad AbdulMageed |  |
| 1767 |  |  [Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.782) |  | 0 | We consider the task of building a dialogue system that can motivate users to adopt positive lifestyle changes, Motivational Interviewing (MI). Addressing such a task requires a system that could infer how to motivate the user effectively. We propose DIIR, a framework that is capable of learning... | Bodhisattwa Prasad Majumder, Hiromi Wakaki, Julian J. McAuley, Keiichi Yamada, Mengjie Zhao, Yoshinori Maeda, Zhouhang Xie |  |
| 1768 |  |  [Evaluating Structural Generalization in Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.783) |  | 0 | Compositional generalization refers to the ability to generalize to novel combinations of previously observed words and syntactic structures.Since it is regarded as a desired property of neural models, recent work has assessed compositional generalization in machine translation as well as semantic... | Daiki Matsuoka, Hitomi Yanaka, Ryoma Kumon |  |
| 1769 |  |  [Figuratively Speaking: Authorship Attribution via Multi-Task Figurative Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.784) |  | 0 | The identification of Figurative Language (FL) features in text is crucial for various Natural Language Processing (NLP) tasks, where understanding of the author’s intended meaning and its nuances is key for successful communication. At the same time, the use of a specific blend of various FL forms... | Gregorios A. Katsios, Ning Sa, Tomek Strzalkowski |  |
| 1770 |  |  [CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities](https://doi.org/10.18653/v1/2024.findings-acl.785) |  | 0 | Recent large language models (LLMs) have shown indications of mathematical reasoning ability on challenging competition-level problems, especially with self-generated verbalizations of intermediate reasoning steps (i.e., chain-of-thought prompting). However, current evaluations mainly focus on the... | Yilun Zhou, Yoon Kim, Yujun Mao |  |
| 1771 |  |  [Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding](https://doi.org/10.18653/v1/2024.findings-acl.786) |  | 0 | Contemporary translation engines based on the encoder-decoder framework have made significant strides in development.However, the emergence of Large Language Models (LLMs) has disrupted their position by presenting the potential for achieving superior translation quality.To uncover the... | Fandong Meng, Jiali Zeng, Jie Zhou, Yongjing Yin |  |
| 1772 |  |  [Integrating Pre-Trained Speech and Language Models for End-to-End Speech Recognition](https://doi.org/10.18653/v1/2024.findings-acl.787) |  | 0 | Advances in machine learning have made it possible to perform various text and speech processing tasks, such as automatic speech recognition (ASR), in an end-to-end (E2E) manner. E2E approaches utilizing pre-trained models are gaining attention for conserving training data and resources. However,... | Kei Sawada, Kentaro Mitsui, Koh Mitsuda, Tianyu Zhao, Toshiaki Wakatsuki, Yukiya Hono |  |
| 1773 |  |  [Proving membership in LLM pretraining data via data watermarks](https://doi.org/10.18653/v1/2024.findings-acl.788) |  | 0 | Detecting whether copyright holders’ works were used in LLM pretraining is poised to be an important problem. This work proposes using data watermarks to enable principled detection with only black-box model access, provided that the rightholder contributed multiple training documents and... | Johnny TianZheng Wei, Robin Jia, Ryan Yixiang Wang |  |
| 1774 |  |  [Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses](https://doi.org/10.18653/v1/2024.findings-acl.789) |  | 0 | Detecting hallucinations in large language model (LLM) outputs is pivotal, yet traditional fine-tuning for this classification task is impeded by the expensive and quickly outdated annotation process, especially across numerous vertical domains and in the face of rapid LLM advancements. In this... | Barrett Martin Lattimer, Dongxu Zhang, Varun Gangal, Yi Yang |  |
| 1775 |  |  [SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC](https://doi.org/10.18653/v1/2024.findings-acl.790) |  | 0 |  | Hui Wang, Jiaqi Zhang, Jinglong Luo, Xin Mu, Yehong Zhang, Yue Yu, Zenglin Xu, Zhuo Zhang |  |
| 1776 |  |  [Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications](https://doi.org/10.18653/v1/2024.findings-acl.791) |  | 0 | With the proliferation of LLM-integrated applications such as GPT-s, millions are deployed, offering valuable services through proprietary instruction prompts. These systems, however, are prone to prompt extraction attacks through meticulously designed queries. To help mitigate this problem, we... | Bhuwan Dhingra, Junlin Wang, Roy Xie, Tianyi Yang |  |
| 1777 |  |  [History-Aware Conversational Dense Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.792) |  | 0 | Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In... | Chen Qu, Fengran Mo, JianYun Nie, Kaiyu Huang, Kelong Mao, Tianyu Zhu, Zhan Su |  |
| 1778 |  |  [Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.793) |  | 0 | Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various downstream tasks. However, scaling them up is challenging because building large-scale MMKGs often introduces mismatched images (i.e., noise). Most entities in KGs belong to the long tail, meaning there are few images of them... | Jiaqing Liang, Qianyu He, Siyu Yuan, Xintao Wang, Yanghua Xiao, Yikai Zhang |  |
| 1779 |  |  [ZeroStance: Leveraging ChatGPT for Open-Domain Stance Detection via Dataset Generation](https://doi.org/10.18653/v1/2024.findings-acl.794) |  | 0 | Zero-shot stance detection that aims to detect the stance (typically against, favor, or neutral) towards unseen targets has attracted considerable attention. However, most previous studies only focus on targets from a single or limited text domains (e.g., financial domain), and thus zero-shot... | Chenye Zhao, Cornelia Caragea, Yingjie Li, Yue Zhang |  |
| 1780 |  |  [Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection](https://doi.org/10.18653/v1/2024.findings-acl.795) |  | 0 | Large language models (LLMs) are very proficient text generators. We leverage this capability of LLMs to generate task-specific data via zero-shot prompting and promote cross-lingual transfer for low-resource target languages. Given task-specific data in a source language and a teacher model... | Ashish Agrawal, Barah Fazili, Preethi Jyothi |  |
| 1781 |  |  [Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.796) |  | 0 | Learning multi-task models for jointly detecting stance and verifying rumors poses challenges due to the need for training data of stance at post level and rumor veracity at claim level, which are difficult to obtain. To address this issue, we leverage large language models (LLMs) as the foundation... | Bo Wang, Hongzhan Lin, Jing Ma, Ruichao Yang, Wei Gao |  |
| 1782 |  |  [Exploring the Potential of Dense Information in Multimodal Alignment](https://doi.org/10.18653/v1/2024.findings-acl.797) |  | 0 | Despite the success of data augmentation in improving CLIP model, existing methods that utilize LLM or SAM to enrich the information in captions still suffer from several limitations, including insufficient detail and excessive hallucinations, ultimately resulting in compromised alignment and... | Benyou Wang, Zhihong Chen, Zhiyuan Fan |  |
| 1783 |  |  [Referral Augmentation for Zero-Shot Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.798) |  | 0 | We propose Referral-Augmented Retrieval (RAR), a simple technique that concatenates document indices with referrals: text from other documents that cite or link to the given document. We find that RAR provides significant performance gains for tasks across paper retrieval, entity retrieval, and... | John Yang, Karthik Narasimhan, Michael Tang, Shunyu Yao |  |
| 1784 |  |  [InstructEval: Instruction-Tuned Text Evaluator from Human Preference](https://doi.org/10.18653/v1/2024.findings-acl.799) |  | 0 | This paper explores to construct a general text evaluator based on open-source Large Language Models (LLMs), a domain predominantly occupied by commercial counterparts such as GPT-4. Recognizing the limitations of open-source models like Llama in evaluative tasks, we introduce InstructEval, a... | Jiachen Liu, Sujian Li, Wei Li, Wenhao Wu, Xinyan Xiao |  |
| 1785 |  |  [A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models](https://doi.org/10.18653/v1/2024.findings-acl.800) |  | 0 | Existing works have shown that fine-tuned textual transformer models achieve state-of-the-art prediction performances but are also vulnerable to adversarial text perturbations. Traditional adversarial evaluation is often done only after fine-tuning the models and ignoring the training data. In this... | Cuong Dang, Dung D. Le, Thai Le |  |
| 1786 |  |  [InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment](https://doi.org/10.18653/v1/2024.findings-acl.801) |  | 0 | Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment.... | Jianing Wang, Julian J. McAuley, Junda Wu, Ming Gao, Yao Liu, Yupeng Hou |  |
| 1787 |  |  [RaDA: Retrieval-augmented Web Agent Planning with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.802) |  | 0 | Agents powered by large language models (LLMs) inherit important limitations, such as the restricted context length, dependency on human-engineered exemplars (e.g., for task decomposition), and insufficient generalization. To address these challenges, we propose RaDA, a novel planning method for... | Eunyee Koh, Minsoo Kim, Seungwon Hwang, Shunan Guo, Victor S. Bursztyn |  |
| 1788 |  |  [Competition-Level Problems are Effective LLM Evaluators](https://doi.org/10.18653/v1/2024.findings-acl.803) |  | 0 | Large language models (LLMs) have demonstrated impressive reasoning capabilities, yet there is ongoing debate about these abilities and the potential data contamination problem recently. This paper aims to evaluate the reasoning capacities of LLMs, specifically in solving recent competition-level... | Chen Lin, Fangyu Lei, Nan Duan, Shuai Lu, Weizhu Chen, Xiao Liu, Yaobo Liang, Yelong Shen, Yeyun Gong, Yiming Huang, Zhenghao Lin |  |
| 1789 |  |  [Large Language Models for Automated Open-domain Scientific Hypotheses Discovery](https://doi.org/10.18653/v1/2024.findings-acl.804) |  | 0 | Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are... | Erik Cambria, Jie Zheng, Junxian Li, Soujanya Poria, Xinya Du, Zonglin Yang |  |
| 1790 |  |  [GRADUAL: Granularity-aware Dual Prototype Learning for Better Few-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.findings-acl.805) |  | 0 | Recent studies have shown that fusing text labels and context sentences is an effective method for learning prototype representations in few-shot relation extraction. However, the \*\*inconsistency of prototype representations\*\* across different few-shot tasks persists due to different context... | Yuchen Lyu, Zhiming Li |  |
| 1791 |  |  [Training a Better Chinese Spelling Correction Model via Prior-knowledge Guided Teacher](https://doi.org/10.18653/v1/2024.findings-acl.806) |  | 0 | Recent advancements in Chinese Spelling Correction (CSC) predominantly leverage pre-trained language models (PLMs). However, a notable challenge with fine-tuned PLM-based CSC models is their tendency to over-correct, leading to poor generalization for error patterns outside the standard... | Chi Wei, Naiyu Yan, Rongsheng Li, Rui Wang, Shaobin Huang |  |
| 1792 |  |  [The Revolution of Multimodal Large Language Models: A Survey](https://doi.org/10.18653/v1/2024.findings-acl.807) |  | 0 | Connecting text and visual modalities plays an essential role in generative intelligence. For this reason, inspired by the success of large language models, significant research efforts are being devoted to the development of Multimodal Large Language Models (MLLMs). These models can seamlessly... | Davide Caffagni, Federico Cocchi, Lorenzo Baraldi, Luca Barsellotti, Marcella Cornia, Nicholas Moratelli, Rita Cucchiara, Sara Sarto |  |
| 1793 |  |  [OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.808) |  | 0 | Advancing automated programming necessitates robust and comprehensive code generation benchmarks, yet current evaluation frameworks largely neglect object-oriented programming (OOP) in favour of functional programming (FP), e.g., HumanEval and MBPP. To address this, our study introduces a... | Bo Du, Dacheng Tao, Li Shen, Liang Ding, Shuai Wang, Yong Luo |  |
| 1794 |  |  [Code Needs Comments: Enhancing Code LLMs with Comment Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.809) |  | 0 | The programming skill is one crucial ability for Large Language Models (LLMs), necessitating a deep understanding of programming languages (PLs) and their correlation with natural languages (NLs). We examine the impact of pre-training data on code-focused LLMs’ performance by assessing the comment... | Dahua Lin, Demin Song, Hang Yan, Honglin Guo, Qipeng Guo, Shuhao Xing, Wenwei Zhang, Xipeng Qiu, Yudong Wang, Yunhua Zhou, Zifan Song |  |
| 1795 |  |  [Efficient Domain Adaptation for Non-Autoregressive Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.810) |  | 0 | Domain adaptation remains a challenge in the realm of Neural Machine Translation (NMT), even in the era of large language models (LLMs). Existing non-parametric approaches like nearest neighbor machine translation have made small Autoregressive Translation (AT) models achieve efficient domain... | Juntao Li, Kehai Chen, Min Zhang, Pei Guo, Wangjie You |  |
| 1796 |  |  [Exploring Reversal Mathematical Reasoning Ability for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.811) |  | 0 | Large language models (LLMs) have presented remarkable capabilities in the wide range of natural language understanding and reasoning tasks. Despite their success, a few works indicate that LLMs suffer from the “reversal curse”, in which LLMs can’t employ the inverted structure “B is A” when they... | Bowen Yan, Juntao Li, Min Zhang, Pei Guo, Wangjie You |  |
| 1797 |  |  [A Unified Joint Approach with Topological Context Learning and Rule Augmentation for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-acl.812) |  | 0 | Knowledge graph completion (KGC) task is to infer the missing knowledge in the knowledge graph based on known factual triples. However, present KGC approaches still face the following two challenges. Those methods perform simple linear update on relation representation, and only local neighborhood... | Chunxia Zhang, Jingtao Guo, Lingxi Li, Xiaojun Xue, Zhendong Niu |  |
| 1798 |  |  [FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.813) |  | 0 | Since most large language models (LLMs) are trained once and never updated, they struggle to dynamically adapt to our ever-changing world. In this work, we present FreshQA, a dynamic QA benchmark that tests a model’s ability to answer questions that may require reasoning over up-to-date world... | Chris Tar, Denny Zhou, Jason Wei, Jerry W. Wei, Mohit Iyyer, Noah Constant, Quoc V. Le, Thang Luong, Tu Vu, Xuezhi Wang, YunHsuan Sung |  |
| 1799 |  |  [ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.814) |  | 0 | With the development of instruction-tuned large language models (LLMs), improving the safety of LLMs has become more critical. However, the current approaches for aligning the LLMs output with expected safety usually require substantial training efforts, e.g., high-quality safety data and expensive... | Bo Du, Dacheng Tao, Juhua Liu, Liang Ding, Qihuang Zhong |  |
| 1800 |  |  [CR-LLM: A Dataset and Optimization for Concept Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.815) |  | 0 | Concept reasoning is an important capability for models to understand the world. However, the existing datasets, such as concept extraction and concept generation, suffer from modeledge leakage and context leakage. To address these limitations, we construct a dataset of concept reasoning for large... | Bing Han, Feng Wei, Haiyun Jiang, Jiaqing Liang, Jinglei Chen, Jingping Liu, Nianqi Li, Sihang Jiang, Yanghua Xiao, Zhenghong Hao, Zujie Liang |  |
| 1801 |  |  [DATA-CUBE: Data Curriculum for Instruction-based Sentence Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.816) |  | 0 | Recently, multi-task instruction tuning has been utilized to improve sentence representation learning (SRL). It enables SRL models to generate task-specific representations with the guidance of task instruction, thus exhibiting strong generalization ability on unseen tasks. However, these methods... | Dawei Gao, He Hu, Kun Zhou, Xin Zhao, Yaliang Li, Yingqian Min |  |
| 1802 |  |  [Combating Label Sparsity in Short Text Topic Modeling via Nearest Neighbor Augmentation](https://doi.org/10.18653/v1/2024.findings-acl.817) |  | 0 | Extracting semantic topics from short texts presents a significant challenge in the field of data mining. While efforts have been made to mitigate data sparsity issue, the limited length of short documents also results in the absence of semantically relevant words, causing biased evidence lower... | Ruiqing Li, Xin Gao, Xinyu Ma, Xu Chu, Yang Lin, Yasha Wang |  |
| 1803 |  |  [RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.818) |  | 0 | The application scope of large language models (LLMs) is increasingly expanding. In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback. Whether the model can appropriately respond to users’... | Jianhao Yan, Yue Zhang, Yun Luo |  |
| 1804 |  |  [Complex Logical Query Answering by Calibrating Knowledge Graph Completion Models](https://doi.org/10.18653/v1/2024.findings-acl.819) |  | 0 | Complex logical query answering (CLQA) is a challenging task that involves finding answer entities for complex logical queries over incomplete knowledge graphs (KGs). Previous research has explored the use of pre-trained knowledge graph completion (KGC) models, which can predict the missing facts... | Changyi Xiao, Yixin Cao |  |
| 1805 |  |  [Argument-Based Sentiment Analysis on Forward-Looking Statements](https://doi.org/10.18653/v1/2024.findings-acl.820) |  | 0 | This paper introduces a novel approach to analyzing the forward-looking statements in equity research reports by integrating argument mining with sentiment analysis. Recognizing the limitations of traditional models in capturing the nuances of future-oriented analysis, we propose a refined... | ChinYi Lin, ChungChi Chen, HenHsen Huang, HsinHsi Chen |  |
| 1806 |  |  [Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model](https://doi.org/10.18653/v1/2024.findings-acl.821) |  | 0 | Large language models (LLMs) have showcased their remarkable capabilities to handle various downstream tasks, including multilingual machine translation ability. Despite their impressive performance, decoder-only LLMs lack an explicit alignment between source and target contexts, leading to... | Hongbin Zhang, Kehai Chen, Min Zhang, Xuefeng Bai, Yang Xiang |  |
| 1807 |  |  [Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion](https://doi.org/10.18653/v1/2024.findings-acl.822) |  | 0 | Block Diagrams play an essential role in visualizing the relationships between components or systems. Generating summaries of block diagrams is important for document understanding or question answering (QA) tasks by providing concise overviews of complex systems. However, it’s a challenging task... | EunSoo Jung, Minho Lee, Shreyanshu Bhushan |  |
| 1808 |  |  [MultiSQL: A Schema-Integrated Context-Dependent Text2SQL Dataset with Diverse SQL Operations](https://doi.org/10.18653/v1/2024.findings-acl.823) |  | 0 | Text2SQL is a task that translates natural language into SQL statements. Context-dependent Text2SQL offers a more natural database interaction by simulating dialogues between users and databases, with CoSQL and SparC as representative datasets. Yet, these datasets struggle to accurately replicate... | Chunhui Li, Fei Zhao, Shujian Huang, Xinyu Dai, Yifan Wang, Zhen Wu, Zhen Yu |  |
| 1809 |  |  [Towards Demonstration-Aware Large Language Models for Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.824) |  | 0 | Tuning-based large language models for machine translation (aka large translation model, LTM) have demonstrated significant performance in the field of machine translation. Despite their success, these models often face difficulties in leveraging demonstrations to further improve their performance.... | Chen Li, Derek F. Wong, Meishan Zhang, Min Zhang, Xuebo Liu, Zhaocong Li |  |
| 1810 |  |  [DADA: Distribution-Aware Domain Adaptation of PLMs for Information Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.825) |  | 0 | Pre-trained language models (PLMs) exhibit promise in retrieval tasks but struggle with out-of-domain data due to distribution shifts.Addressing this, generative domain adaptation (DA), known as GPL, tackles distribution shifts by generating pseudo queries and labels to train models for predicting... | Dohyeon Lee, Jongyoon Kim, Joonsuk Park, Seungwon Hwang |  |
| 1811 |  |  [LLMs cannot find reasoning errors, but can correct them given the error location](https://doi.org/10.18653/v1/2024.findings-acl.826) |  | 0 | While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023b; Madaan et al.,2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang... | Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, Victor Carbune |  |
| 1812 |  |  [Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL translation](https://doi.org/10.18653/v1/2024.findings-acl.827) |  | 0 | Understanding textual description to generate code seems to be an achieved capability of instruction-following Large Language Models (LLMs) in zero-shot scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and... | Andrea Favalli, Cristina Giannone, Dario Onorati, Elena Sofia Ruzzetti, Fabio Massimo Zanzotto, Federico Ranaldi, Leonardo Ranaldi, Raniero Romagnoli |  |
| 1813 |  |  [ChartCheck: Explainable Fact-Checking over Real-World Chart Images](https://doi.org/10.18653/v1/2024.findings-acl.828) |  | 0 | Whilst fact verification has attracted substantial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key... | Elena Simperl, Mubashara Akhtar, Nikesh Subedi, Oana Cocarascu, Sahar Tahmasebi, Vivek Gupta |  |
| 1814 |  |  [Real World Conversational Entity Linking Requires More Than Zero-Shots](https://doi.org/10.18653/v1/2024.findings-acl.829) |  | 0 | Entity linking (EL) in conversations faces notable challenges in practical applications, primarily due to scarcity of entity-annotated conversational datasets and sparse knowledge bases (KB) containing domain-specific, long-tail entities. We designed targeted evaluation scenarios to measure the... | Arjen P. de Vries, Faegheh Hasibi, Maarten de Rijke, Mohanna Hoveyda |  |
| 1815 |  |  [CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling](https://doi.org/10.18653/v1/2024.findings-acl.830) |  | 0 | Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting... | Chengming Li, Chenhao Zhang, Di Yang, Guancheng Ye, Jiahao Zhao, Jingwei Zhu, Min Yang, Minghuan Tan, Renhao Li, Xiping Hu |  |
| 1816 |  |  [Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech](https://doi.org/10.18653/v1/2024.findings-acl.831) |  | 0 | Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide... | Md. Shad Akhtar, Neemesh Yadav, Sarah Masud, Tanmoy Chakraborty, Vikram Goyal |  |
| 1817 |  |  [TextGenSHAP: Scalable Post-Hoc Explanations in Text Generation with Long Documents](https://doi.org/10.18653/v1/2024.findings-acl.832) |  | 0 | Large language models (LLMs) have attracted great interest in many real-world applications; however, their “black-box” nature necessitates scalable and faithful explanations. Shapley values have matured as an explainability method for deep learning, but extending them to LLMs is difficult due to... | Hootan Nakhost, James Enouen, Sayna Ebrahimi, Sercan Ö. Arik, Tomas Pfister, Yan Liu |  |
| 1818 |  |  [Balanced Data Sampling for Language Model Training with Clustering](https://doi.org/10.18653/v1/2024.findings-acl.833) |  | 0 | Data plays a fundamental role in the training of Large Language Models (LLMs). While attention has been paid to the collection and composition of datasets, determining the data sampling strategy in training remains an open question. Most LLMs are trained with a simple strategy, random sampling.... | Dahua Lin, Hang Yan, Linyang Li, Xipeng Qiu, Yunfan Shao, Zhaoye Fei |  |
| 1819 |  |  [Length Generalization of Causal Transformers without Position Encoding](https://doi.org/10.18653/v1/2024.findings-acl.834) |  | 0 | Generalizing to longer sentences is important for recent Transformer-based language models. Besides algorithms manipulating explicit position features, the success of Transformers without position encodings (NoPE) provides a new way to overcome the challenge. In this paper, we study the length... | Hang Yan, Jie Wang, Qi Zhang, Tao Gui, Tao Ji, Xiaoling Wang, Xuanjing Huang, Yuanbin Wu |  |
| 1820 |  |  [Unsupervised Sign Language Translation and Generation](https://doi.org/10.18653/v1/2024.findings-acl.835) |  | 0 | Motivated by the success of unsupervised neural machine translation (UNMT), we introduce an unsupervised sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data. USLNet comprises two main... | Kehai Chen, Min Zhang, Rui Wang, Wenxiang Jiao, Xing Wang, Yong Xu, Zhaopeng Tu, Zhengsheng Guo, Zhiwei He |  |
| 1821 |  |  [Mitigating Data Scarcity in Semantic Parsing across Languages with the Multilingual Semantic Layer and its Dataset](https://doi.org/10.18653/v1/2024.findings-acl.836) |  | 0 | Data scarcity is a prevalent challenge in the era of Large Language Models (LLMs). The insatiable hunger of LLMs for large corpora becomes even more pronounced when dealing with non-English and low-resource languages. The issue is particularly exacerbated in Semantic Parsing (SP), i.e. the task of... | Abelardo Carlos Martinez Lorenzo, Alberte FernándezCastro, HeeSoo Choi, Karim Ghonim, Lu Xu, PereLluís Huguet Cabot, Roberto Navigli |  |
| 1822 |  |  [Efficient Sparse Attention needs Adaptive Token Release](https://doi.org/10.18653/v1/2024.findings-acl.837) |  | 0 |  | Chaoran Zhang, Chenliang Li, Dan Luo, Lixin Zou, Min Tang, Xiangyang Luo, Zihao Li |  |
| 1823 |  |  [Learning Fine-Grained Grounded Citations for Attributed Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.838) |  | 0 | Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations. Attributed LLMs, which augment generated text with in-line citations, demonstrate potential in mitigating hallucinations and improving verifiability. However, current... | Bing Qin, Dandan Tu, Duyu Tang, Lei Huang, Weihong Zhong, Weihua Peng, Weijiang Yu, Weitao Ma, Xiachong Feng, Xiaocheng Feng, Yuxuan Gu |  |
| 1824 |  |  [ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget](https://doi.org/10.18653/v1/2024.findings-acl.839) |  | 0 | Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in a wide range of applications. In this paper, we propose ReLiK, a Retriever-Reader architecture for both EL and RE, where, given an input text, the Retriever... | Edoardo Barba, PereLluís Huguet Cabot, Riccardo Orlando, Roberto Navigli |  |
| 1825 |  |  [Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery](https://doi.org/10.18653/v1/2024.findings-acl.840) |  | 0 | In Conversational Intent Discovery (CID), Small Language Models (SLMs) struggle with overfitting to familiar intents and fail to label newly discovered ones. This issue stems from their limited grasp of semantic nuances and their intrinsically discriminative framework. Therefore, we propose... | Hao Fei, Jing Jiang, Jinggui Liang, Lizi Liao |  |
| 1826 |  |  [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](https://doi.org/10.18653/v1/2024.findings-acl.841) |  | 0 | Recent advancements in text summarization, particularly with the advent of Large Language Models (LLMs), have shown remarkable performance. However, a notable challenge persists as a substantial number of automatically-generated summaries exhibit factual inconsistencies, such as hallucinations. In... | Alessandro Scirè, Karim Ghonim, Roberto Navigli |  |
| 1827 |  |  [Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.842) |  | 0 | Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy generates some low-probability text, resulting in low-quality... | Kui Ren, Weicheng Wang, Wenqing Chen, Zhichao Lu, Zhixuan Chu, Zibin Zheng |  |
| 1828 |  |  [Looking Right is Sometimes Right: Investigating the Capabilities of Decoder-only LLMs for Sequence Labeling](https://doi.org/10.18653/v1/2024.findings-acl.843) |  | 0 | Pre-trained language models based on masked language modeling (MLM) excel in natural language understanding (NLU) tasks. While fine-tuned MLM-based encoders consistently outperform causal language modeling decoders of comparable size, recent decoder-only large language models (LLMs) perform on par... | David Dukic, Jan Snajder |  |
| 1829 |  |  [mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans](https://doi.org/10.18653/v1/2024.findings-acl.844) |  | 0 | It is very challenging to curate a dataset for language-specific knowledge and common sense in order to evaluate natural language understanding capabilities of language models. Due to the limitation in the availability of annotators, most current multilingual datasets are created through... | Hidetaka Kamigaito, Taro Watanabe, Yusuke Sakai |  |
| 1830 |  |  [Dual-Stage Multi-Task Syntax-Oriented Pre-Training for Syntactically Controlled Paraphrase Generation](https://doi.org/10.18653/v1/2024.findings-acl.845) |  | 0 | Syntactically Controlled Paraphrase Generation (SCPG), which aims at generating sentences having syntactic structures resembling given exemplars, is attracting more research efforts in recent years. We took an empirical survey on previous SCPG datasets and methods and found three tacitly approved... | Guanglu Wan, Hongxu Liu, Jiashen Sun, Ke Zeng, Xiaojie Wang |  |
| 1831 |  |  [Demonstration Augmentation for Zero-shot In-context Learning](https://doi.org/10.18653/v1/2024.findings-acl.846) |  | 0 | Large Language Models (LLMs) have demonstrated an impressive capability known as In-context Learning (ICL), which enables them to acquire knowledge from textual demonstrations without the need for parameter updates.However, many studies have highlighted that the model’s performance is sensitive to... | Juntao Li, Min Zhang, Yan Bowen, Yi Su, Yixin Ji, Yunpeng Tai |  |
| 1832 |  |  [Pushing the Limits of Zero-shot End-to-End Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.847) |  | 0 | Data scarcity and the modality gap between the speech and text modalities are two major obstacles of end-to-end Speech Translation (ST) systems, thus hindering their performance. Prior work has attempted to mitigate these challenges by leveraging external MT data and optimizing distance metrics... | Gerard I. Gállego, Ioannis Tsiamas, José A. R. Fonollosa, Marta R. Costajussà |  |
| 1833 |  |  [NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.848) |  | 0 | Numeral systems and units of measurement are two conjoined topics in activities of human beings and have mutual effects with the languages expressing them. Currently, the evaluation of Large Language Models (LLMs) often involves mathematical reasoning, yet little attention is given to how minor... | Ancheng Xu, Lei Wang, Min Yang, Minghuan Tan, Ruifeng Xu |  |
| 1834 |  |  [On The Persona-based Summarization of Domain-Specific Documents](https://doi.org/10.18653/v1/2024.findings-acl.849) |  | 0 | In an ever-expanding world of domain-specific knowledge, the increasing complexity of consuming, and storing information necessitates the generation of summaries from large information repositories. However, every persona of a domain has different requirements of information and hence their... | Ankan Mullick, Ayan Kumar Bhowmick, Niloy Ganguly, Pawan Goyal, Prasenjit Dey, Ravi Kokku, Rounak Saha, Sombit Bose |  |
| 1835 |  |  [Evaluating Large Language Models for Health-related Queries with Presuppositions](https://doi.org/10.18653/v1/2024.findings-acl.850) |  | 0 | As corporations rush to integrate large language models (LLMs) it is critical that they provide factually accurate information, that is robust to any presuppositions that a user may express. In this work, we introduce UPHILL, a dataset consisting of health-related queries with varying degrees of... | Danish Pruthi, Monojit Choudhury, Navreet Kaur |  |
| 1836 |  |  [Word Sense Linking: Disambiguating Outside the Sandbox](https://doi.org/10.18653/v1/2024.findings-acl.851) |  | 0 | Word Sense Disambiguation (WSD) is the task of associating a word in a given context with its most suitable meaning among a set of possible candidates. While the task has recently witnessed renewed interest, with systems achieving performances above the estimated inter-annotator agreement, at the... | Alberte FernándezCastro, Andrei Stefan Bejgu, Edoardo Barba, Luigi Procopio, Roberto Navigli |  |
| 1837 |  |  [Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks](https://doi.org/10.18653/v1/2024.findings-acl.852) |  | 0 | Memorisation is a natural part of learning from real-world data: neural models pick up on atypical input-output combinations and store those training examples in their parameter space. That this happens is well-known, but how and where are questions that remain largely unanswered. Given a... | Ivan Titov, Verna Dankers |  |
| 1838 |  |  [Towards Multi-Relational Multi-Hop Reasoning over Dense Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2024.findings-acl.853) |  | 0 | Temporal knowledge graph reasoning has emerged as a crucial task for answering time-dependent questions within a knowledge graph (KG).Despite tremendous progress, the present research is impeded by the sparsity of a temporal KG and an over-reliance on simple single-relational reasoning patterns. To... | Jian Liu, Jinan Xu, Peng Jin, Xueqiang Lyu, Zihe Liu |  |
| 1839 |  |  [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.854) |  | 0 | Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs.... | Changyue Wang, Qingyao Ai, Weihang Su, Yiqun Liu, Yiran Hu, Yujia Zhou, Zhijing Wu |  |
| 1840 |  |  [Progressive Tuning: Towards Generic Sentiment Abilities for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.855) |  | 0 | Understanding sentiment is arguably an advanced and important capability of AI agents in the physical world. In previous works, many efforts have been devoted to individual sentiment subtasks, without considering interrelated sentiment knowledge among these subtasks. Although some recent works... | Guiyang Hou, Weiming Lu, Yongliang Shen |  |
| 1841 |  |  [Fooling the Textual Fooler via Randomizing Latent Representations](https://doi.org/10.18653/v1/2024.findings-acl.856) |  | 0 | Despite outstanding performance in a variety of Natural Language Processing (NLP) tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Several attacks can even compromise the model without... | Duy C. Hoang, Khoa D. Doan, KokSeng Wong, Minlong Peng, Nguyen HungQuang, Saurav Manchanda |  |
| 1842 |  |  [Part-of-speech Tagging for Extremely Low-resource Indian Languages](https://doi.org/10.18653/v1/2024.findings-acl.857) |  | 0 | Modern natural language processing (NLP) systems thrive when given access to large datasets. However, a large fraction of the world’s languages are not privy to such benefits due to sparse documentation and inadequate digital representation. This is especially true for Indian regional languages. As... | Preethi Jyothi, Pushpak Bhattacharyya, Sanjeev Kumar |  |
| 1843 |  |  [FOCUS: Forging Originality through Contrastive Use in Self-Plagiarism for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.858) |  | 0 | Pre-trained Language Models (PLMs) have shown impressive results in various Natural Language Generation (NLG) tasks, such as powering chatbots and generating stories. However, an ethical concern arises due to their potential to produce verbatim copies of paragraphs from their training data. This is... | Cecilia G. Zhao, Derek F. Wong, Kaixin Lan, Lidia S. Chao, Tao Fang, Yabo Xu |  |
| 1844 |  |  [Amanda: Adaptively Modality-Balanced Domain Adaptation for Multimodal Emotion Recognition](https://doi.org/10.18653/v1/2024.findings-acl.859) |  | 0 | This paper investigates unsupervised multimodal domain adaptation for multimodal emotion recognition, which is a solution for data scarcity yet remains under studied. Due to the varying distribution discrepancies of different modalities between source and target domains, the primary challenge lies... | Jun Sun, Simin Hong, Taihao Li, Xinxin Zhang |  |
| 1845 |  |  [MedREQAL: Examining Medical Knowledge Recall of Large Language Models via Question Answering](https://doi.org/10.18653/v1/2024.findings-acl.860) |  | 0 | In recent years, Large Language Models (LLMs) have demonstrated an impressive ability to encode knowledge during pre-training on large text corpora. They can leverage this knowledge for downstream tasks like question answering (QA), even in complex areas involving health topics. Considering their... | Florian Matthes, Juraj Vladika, Phillip Schneider |  |
| 1846 |  |  [Deepfake Defense: Constructing and Evaluating a Specialized Urdu Deepfake Audio Dataset](https://doi.org/10.18653/v1/2024.findings-acl.861) |  | 0 | Deepfakes, particularly in the auditory domain, have become a significant threat, necessitating the development of robust countermeasures. This paper addresses the escalating challenges posed by deepfake attacks on Automatic Speaker Verification (ASV) systems. We present a novel Urdu deepfake audio... | Abdul Hameed Azeemi, Agha Ali Raza, Emaan Abbas, Ihsan Ayyub Qazi, Mukeet Raza, Sheza Munir, Wassay Sajjad |  |
| 1847 |  |  [Leveraging Entailment Judgements in Cross-Lingual Summarisation](https://doi.org/10.18653/v1/2024.findings-acl.862) |  | 0 | Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to include document-summary pairs where the reference summary is unfaithful to the corresponding document as it contains content not supported by the document (i.e., hallucinated content). This low data quality misleads... | Huajian Zhang, Laura PerezBeltrachini |  |
| 1848 |  |  [Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction](https://doi.org/10.18653/v1/2024.findings-acl.863) |  | 0 | In the field of information extraction (IE), tasks across a wide range of modalities and their combinations have been traditionally studied in isolation, leaving a gap in deeply recognizing and analyzing cross-modal information. To address this, this work for the first time introduces the concept... | Bin Wang, Fei Li, Hao Fei, Meishan Zhang, Min Zhang, Shengqiong Wu, Yixin Cao |  |
| 1849 |  |  [Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data](https://doi.org/10.18653/v1/2024.findings-acl.864) |  | 0 | The remarkable multimodal capabilities demonstrated by OpenAI’s GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human... | Bin Fu, Chi Zhang, Chunhua Shen, Gang Yu, Guosheng Lin, Ling Chen, Wanqi Yang, Yanda Li, Yunchao Wei, Zhibin Wang |  |
| 1850 |  |  [Modeling Overregularization in Children with Small Language Models](https://doi.org/10.18653/v1/2024.findings-acl.865) |  | 0 | The imitation of the children’s language acquisition process has been explored to make language models (LMs) more efficient.In particular, errors caused by children’s regularization (so-called overregularization, e.g., using wroted for the past tense of write) have been widely studied to reveal the... | Akari Haga, Akiyo Fukatsu, Hiroki Ouchi, Miyu Oba, Saku Sugawara, Taro Watanabe, Yohei Oseki |  |
| 1851 |  |  [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](https://doi.org/10.18653/v1/2024.findings-acl.866) |  | 0 | Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as... | Cunliang Kong, Maosong Sun, Ying Liu, Zhu Liu |  |
| 1852 |  |  [Harnessing Large Language Models as Post-hoc Correctors](https://doi.org/10.18653/v1/2024.findings-acl.867) |  | 0 | As Machine Learning (ML) models grow in size and demand higher-quality training data, the expenses associated with re-training and fine-tuning these models are escalating rapidly. Inspired by recent impressive achievements of Large Language Models (LLMs) in different fields, this paper delves into... | Davide Mottin, Kuangyu Zhou, Zhiqiang Zhong |  |
| 1853 |  |  [Debatrix: Multi-dimensional Debate Judge with Iterative Chronological Analysis Based on LLM](https://doi.org/10.18653/v1/2024.findings-acl.868) |  | 0 | How can we construct an automated debate judge to evaluate an extensive, vibrant, multi-turn debate? This task is challenging, as judging a debate involves grappling with lengthy texts, intricate argument relationships, and multi-dimensional assessments.At the same time, current research mainly... | Jingcong Liang, Meng Han, Rong Ye, Ruofei Lai, Xinyu Zhang, Xuanjing Huang, Zhongyu Wei |  |
| 1854 |  |  [CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment](https://doi.org/10.18653/v1/2024.findings-acl.869) |  | 0 | Language models trained on large-scale corpus often generate harmful responses that are harmful and contrary to human values. A prevalent approach for human alignment is reinforcement learning from human feedback (RLHF), utilizing algorithms such as proximal policy optimization (PPO). However,... | Changyu Chen, Gao Xing, Ji Zhang, Jixiang Hong, Quan Tu, Rui Yan |  |
| 1855 |  |  [Towards a new research agenda for multimodal enterprise document understanding: What are we missing?](https://doi.org/10.18653/v1/2024.findings-acl.870) |  | 0 | The field of multimodal document understanding has produced a suite of models that have achieved stellar performance across several tasks, even coming close to human performance on certain benchmarks. Nevertheless, the application of these models to real-world enterprise datasets remains... | Armineh Nourbakhsh, Carolyn P. Rosé, Sameena Shah |  |
| 1856 |  |  [CAUSE: Counterfactual Assessment of User Satisfaction Estimation in Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.871) |  | 0 | An important unexplored aspect in previous work on user satisfaction estimation for Task-Oriented Dialogue (TOD) systems is their evaluation in terms of robustness for the identification of user dissatisfaction: current benchmarks for user satisfaction estimation in TOD systems are highly skewed... | Amin Abolghasemi, Arian Askari, Maarten de Rijke, Mohammad Aliannejadi, Suzan Verberne, Zhaochun Ren |  |
| 1857 |  |  [Measuring Retrieval Complexity in Question Answering Systems](https://doi.org/10.18653/v1/2024.findings-acl.872) |  | 0 | In this paper, we investigate which questions are challenging for retrieval-based Question Answering (QA). We (i) propose retrieval complexity (RC), a novel metric conditioned on the completeness of retrieved documents, which measures the difficulty of answering questions, and (ii) propose an... | Alessandro Moschitti, Leonardo F. R. Ribeiro, Matteo Gabburo, Nicolaas Paul Jedema, Siddhant Garg |  |
| 1858 |  |  [Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media](https://doi.org/10.18653/v1/2024.findings-acl.873) |  | 0 | We introduce a hybrid abstractive summarisation approach combining hierarchical VAEs with LLMs to produce clinically meaningful summaries from social media user timelines, appropriate for mental health monitoring. The summaries combine two different narrative points of view: (a) clinical insights... | Adam Tsakalidis, Dana AtzilSlonim, Jenny Chim, Jiayu Song, Julia Ive, Maria Liakata |  |
| 1859 |  |  [PIXAR: Auto-Regressive Language Modeling in Pixel Space](https://doi.org/10.18653/v1/2024.findings-acl.874) |  | 0 | Recent work showed the possibility of building open-vocabulary large language models (LLMs) that directly operate on pixel representations. These models are implemented as autoencoders that reconstruct masked patches of rendered text.However, these pixel-based LLMs are limited to discriminative... | Alessandro Suglia, Antonio Vergari, Xiyang Liao, Yintao Tai |  |
| 1860 |  |  [Sparsity-Accelerated Training for Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.875) |  | 0 | Large language models (LLMs) have demonstrated proficiency across various natural language processing (NLP) tasks but often require additional training, such as continual pre-training and supervised fine-tuning. However, the costs associated with this, primarily due to their large parameter count,... | Da Ma, Hanqi Li, Hongshen Xu, Kai Yu, Liangtai Sun, Lu Chen, Pengyu Wang, Shuai Fan, Su Zhu |  |
| 1861 |  |  [Preemptive Answer "Attacks" on Chain-of-Thought Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.876) |  | 0 | Large language models (LLMs) showcase impressive reasoning capabilities when coupled with Chain-of-Thought (CoT) prompting. However, the robustness of this approach warrants further investigation. In this paper, we introduce a novel scenario termed preemptive answers, where the LLM obtains an... | Rongwu Xu, Wei Xu, Zehan Qi |  |
| 1862 |  |  [Do Language Models Exhibit Human-like Structural Priming Effects?](https://doi.org/10.18653/v1/2024.findings-acl.877) |  | 0 | We explore which linguistic factors—at the sentence and token level—play an important role in influencing language model predictions, and investigate whether these are reflective of results found in humans and human corpora (Gries and Kootstra, 2017). We make use of the structural priming... | Arabella Sinclair, Jaap Jumelet, Willem H. Zuidema |  |
| 1863 |  |  [RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.878) |  | 0 | The advent of Large Language Models (LLMs) has paved the way for complex tasks such as role-playing, which enhances user interactions by enabling models to imitate various characters. However, the closed-source nature of state-of-the-art LLMs and their general-purpose training limit role-playing... | Haoran Que, Hongcheng Guo, Jiaheng Liu, Jian Yang, Jie Fu, Junran Peng, Ke Xu, Man Zhang, Noah Wang, Ruitong Gan, Wangchunshu Zhou, Wanli Ouyang, Wenhao Huang, Yuhan Wu, Zehao Ni, Zhaoxiang Zhang, Zhongyuan Peng |  |
| 1864 |  |  [LangSuit·E: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments](https://doi.org/10.18653/v1/2024.findings-acl.879) |  | 0 | Recent advances in Large Language Models (LLMs) have shown inspiring achievements in constructing autonomous agents that rely onlanguage descriptions as inputs. However, it remains unclear how well LLMs can function as few-shot or zero-shot embodied agents in dynamic interactive environments. To... | Baichen Tong, Mengmeng Wang, SongChun Zhu, Zilong Zheng, Zixia Jia |  |
| 1865 |  |  [Views Are My Own, but Also Yours: Benchmarking Theory of Mind Using Common Ground](https://doi.org/10.18653/v1/2024.findings-acl.880) |  | 0 | Evaluating the theory of mind (ToM) capabilities of language models (LMs) has recently received a great deal of attention. However, many existing benchmarks rely on synthetic data, which risks misaligning the resulting experiments with human behavior. We introduce the first ToM dataset based on... | Adil Soubki, Arash Yousefi Jordehi, John Murzaku, Magdalena Markowska, Owen Rambow, Peter Zeng, Seyed Abolghasem Mirroshandel |  |
| 1866 |  |  [MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.881) |  | 0 | Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other... | Ashutosh Sathe, Divyanshu Aggarwal, Ishaan Watts, Sunayana Sitaram |  |
| 1867 |  |  [MoE-SLU: Towards ASR-Robust Spoken Language Understanding via Mixture-of-Experts](https://doi.org/10.18653/v1/2024.findings-acl.882) |  | 0 | As a crucial task in the task-oriented dialogue systems, spoken language understanding (SLU) has garnered increasing attention. However, errors from automatic speech recognition (ASR) often hinder the performance of understanding. To tackle this problem, we propose MoE-SLU, an ASR-Robust SLU... | Xianwei Zhuang, Xuxin Cheng, Yuexian Zou, Zhanpeng Chen, Zhihong Zhu, Zhiqi Huang |  |
| 1868 |  |  [Multi-Task Transfer Matters During Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.883) |  | 0 | Instruction-tuning trains a language model on hundreds of tasks jointly to improve a model’s ability to learn in-context;however, the mechanisms that drive in-context learning are poorly understood and, as a result, the role of instruction-tuning on in-context generalization is poorly understood as... | David Mueller, Mark Dredze, Nicholas Andrews |  |
| 1869 |  |  [What Makes a Good Order of Examples in In-Context Learning](https://doi.org/10.18653/v1/2024.findings-acl.884) |  | 0 | Although large language models (LLMs) have demonstrated impressive few-shot learning capabilities via in-context learning (ICL), ICL performance is known to be highly sensitive to the order of examples provided. To identify appropriate orders, recent studies propose heuristic methods to evaluate... | Leiyu Wang, Qi Guo, Shikun Zhang, Wei Ye, Yidong Wang |  |
| 1870 |  |  [BloomVQA: Assessing Hierarchical Multi-modal Comprehension](https://doi.org/10.18653/v1/2024.findings-acl.885) |  | 0 | We propose a novel VQA dataset, BloomVQA, to facilitate comprehensive evaluation of large vision-language models on comprehension tasks. Unlike current benchmarks that often focus on fact-based memorization and simple reasoning tasks without theoretical grounding, we collect multiple-choice samples... | Ajay Divakaran, Arijit Ray, Christopher Kanan, Jared Claypoole, Michael Cogswell, Robik Shrestha, Yunye Gong |  |
| 1871 |  |  [AttributionBench: How Hard is Automatic Attribution Evaluation?](https://doi.org/10.18653/v1/2024.findings-acl.886) |  | 0 | Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence. However, evaluating the answer’s attribution, i.e., whether every claim within the generated responses is fully supported by its cited evidence, remains an open problem.... | Huan Sun, Xiang Yue, Yifei Li, Zeyi Liao |  |
| 1872 |  |  [Diffusion Guided Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.887) |  | 0 | Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language—ideally tailored towards each specific use case and target audience. For auto-regressive... | Justin Lovelace, Kilian Q. Weinberger, Varsha Kishore, Yiwei Chen |  |
| 1873 |  |  [InstructEd: Soft-Instruction Tuning for Model Editing with Hops](https://doi.org/10.18653/v1/2024.findings-acl.888) |  | 0 | The task of model editing becomes popular for correcting inaccurate or outdated parametric knowledge in Large Language Models (LLMs). However, there are major limitations of state of the art (SOTA) model editing methods, including the excessive memorization issue caused by the direct editing... | Jeff Z. Pan, Jiye Liang, Ru Li, Xiaoli Li, Xiaoqi Han, Zifang Zhang |  |
| 1874 |  |  [TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback](https://doi.org/10.18653/v1/2024.findings-acl.889) |  | 0 | Reinforcement Learning from Human Feedback (RLHF) leverages human preference data to train language models to align more closely with human essence. These human preference data, however, are labeled at the sequence level, creating a mismatch between sequence-level preference labels and tokens,... | Chang Dong Yoo, Daejin Jo, Daniel Wontae Nam, Eunseop Yoon, Gunsoo Han, Hee Suk Yoon, KyoungWoon On, Mark HasegawaJohnson, SooHwan Eom, Sungwoong Kim |  |
| 1875 |  |  [Found in the middle: Calibrating Positional Attention Bias Improves Long Context Utilization](https://doi.org/10.18653/v1/2024.findings-acl.890) |  | 0 | Large language models (LLMs), even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon has been known as the lost-in-the-middle problem. In this work, we make three contributions. First, we set out... | Abhishek Kumar, Alexander Ratner, ChenYu Lee, ChengYu Hsieh, ChunLiang Li, James R. Glass, Long T. Le, Ranjay Krishna, Tomas Pfister, YungSung Chuang, Zifeng Wang |  |
| 1876 |  |  [S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs](https://doi.org/10.18653/v1/2024.findings-acl.891) |  | 0 | Traditional Dialogue State Tracking (DST) has focused on tracking preferences and intents in conversations centered around specific tasks (e.g. booking services). These conventional systems assume a relatively restricted conversation flow in which each turn gradually offers new information.... | Chirag Shah, Georg Buscher, Jennifer Neville, Longqi Yang, Mengting Wan, Reid Andersen, Sarkar Snigdha Sarathi Das, Tara Safavi |  |
| 1877 |  |  [Set the Clock: Temporal Alignment of Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-acl.892) |  | 0 | Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call... | Bowen Zhao, Hannaneh Hajishirzi, Noah A. Smith, Yizhong Wang, Zander Brumbaugh |  |
| 1878 |  |  [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.893) |  | 0 | To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it’s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity... | Beyza Ermis, Luiza Pozzobon, Patrick Lewis, Sara Hooker |  |
| 1879 |  |  [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](https://doi.org/10.18653/v1/2024.findings-acl.894) |  | 0 | The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are... | Ansh Arora, Mark Dras, Maximilian Mozes, Qiongkai Xu, Srinibas Swain, Xuanli He |  |
| 1880 |  |  [Enhancing Sentence Simplification in Portuguese: Leveraging Paraphrases, Context, and Linguistic Features](https://doi.org/10.18653/v1/2024.findings-acl.895) |  | 0 | Automatic text simplification focuses on transforming texts into a more comprehensible version without sacrificing their precision. However, automatic methods usually require (paired) datasets that can be rather scarce in languages other than English. This paper presents a new approach to automatic... | Aline Paes, Arthur Scalercio, Maria José Finatto |  |
| 1881 |  |  [How Far can 100 Samples Go? Unlocking Zero-Shot Translation with Tiny Multi-Parallel Data](https://doi.org/10.18653/v1/2024.findings-acl.896) |  | 0 | Zero-shot translation aims to translate between language pairs not seen during training in Multilingual Machine Translation (MMT) and is widely considered an open problem. A common, albeit resource-consuming, solution is to add as many related translation directions as possible to the training... | Christof Monz, David Stap, Di Wu, Shaomu Tan, Yan Meng |  |
| 1882 |  |  [Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study on Two Materials Dataset](https://doi.org/10.18653/v1/2024.findings-acl.897) |  | 0 | We explore the ability of GPT-4 to perform ad-hoc schema-based information extraction from scientific literature. We assess specifically whether it can, with a basic one-shot prompting approach over the full text of the included manusciprts, replicate two existing material science datasets, one... | Carolina Frey, Collin Holgate, Neal R. Brodnik, Samantha H. Daly, Samuel Carton, Satanu Ghosh, Tresa M. Pollock |  |
| 1883 |  |  [Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction](https://doi.org/10.18653/v1/2024.findings-acl.898) |  | 0 | Neural parameterization has significantly advanced unsupervised grammar induction. However, training these models with a traditional likelihood loss for all possible parses exacerbates two issues: 1) \*structural optimization ambiguity\* that arbitrarily selects one among structurally ambiguous... | Jinwook Park, Kangil Kim |  |
| 1884 |  |  [LMDX: Language Model-based Document Information Extraction and Localization](https://doi.org/10.18653/v1/2024.findings-acl.899) |  | 0 | Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art and exhibiting emergent capabilities across various tasks. However, their application in extracting information from visually rich documents, which is at the core of many document... | ChenYu Lee, Florian Luisier, Guolong Su, Hao Zhang, Jiaqi Mu, Kai Kang, Nan Hua, Ramya Sree Boppana, Vincent Perot, Xiaoyu Sun, Zifeng Wang, Zilong Wang |  |
| 1885 |  |  [DBQR-QA: A Question Answering Dataset on a Hybrid of Database Querying and Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.900) |  | 0 | This paper introduces the Database Querying and Reasoning Dataset for Question Answering (DBQR-QA), aimed at addressing the gap in current question-answering (QA) research by emphasizing the essential processes of database querying and reasoning to answer questions. Specifically designed to... | ChungChi Chen, Hiroya Takamura, Natthawut Kertkeidkachorn, Rungsiman Nararatwong, Ryutaro Ichise |  |
| 1886 |  |  [NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes](https://doi.org/10.18653/v1/2024.findings-acl.901) |  | 0 | We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat embodies the principle that an ensemble of role-specific LLMs, through structured role-play and strategic prompting, can perform their assigned... | Hong Yu, Huixue Zhou, Junda Wang, Rumeng Li, Xun Wang, Yucheng Xu, Zhichao Yang, Zonghai Yao |  |
| 1887 |  |  [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://doi.org/10.18653/v1/2024.findings-acl.902) |  | 0 | Editing knowledge in large language models is an attractive capability that allows us to correct incorrectly learned facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated... | Akshat Gupta, Anurag Rao, Gopala Anumanchipalli |  |
| 1888 |  |  [3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding](https://doi.org/10.18653/v1/2024.findings-acl.903) |  | 0 | This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation... | Jean Lee, Josiah Poon, Lorenzo Vaiani, Luca Cagliero, Paolo Garza, Soyeon Caren Han, Yihao Ding |  |
| 1889 |  |  [Faithful Persona-based Conversational Dataset Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.904) |  | 0 | High-quality conversational datasets are essential for developing AI models that can communicate with users.One way to foster deeper interactions between a chatbot and its user is through \*personas\*, aspects of the user’s character that provide insights into their personality, motivations, and... | Hakim Sidahmed, Jay Pujara, Pegah Jandaghi, XiangHai Sheng, Xinyi Bai |  |
| 1890 |  |  [Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.905) |  | 0 | Despite vision-language models’ (VLMs) remarkable capabilities as versatile visual assistants, two substantial challenges persist within the existing VLM frameworks: (1) lacking task diversity in pretraining and visual instruction tuning, and (2) annotation error and bias in GPT-4 synthesized... | Chao Feng, Di Jin, Lifu Huang, Qifan Wang, Rulin Shao, Trevor Ashby, Ying Shen, Yu Cheng, Zhiyang Xu |  |
| 1891 |  |  [TAXI: Evaluating Categorical Knowledge Editing for Language Models](https://doi.org/10.18653/v1/2024.findings-acl.906) |  | 0 | Humans rarely learn one fact in isolation. Instead, learning a new fact induces knowledge of other facts about the world. For example, in learning a korat is a type of cat, you also infer it is a mammal and has claws, ensuring your model of the world is consistent. Knowledge editing aims to inject... | Derek Powell, Thomas Hartvigsen, Walter Gerych |  |
| 1892 |  |  [Automatic Bug Detection in LLM-Powered Text-Based Games Using LLMs](https://doi.org/10.18653/v1/2024.findings-acl.907) |  | 0 | Advancements in large language models (LLMs) are revolutionizing interactive game design, enabling dynamic plotlines and interactions between players and non-player characters (NPCs). However, LLMs may exhibit flaws such as hallucinations, forgetfulness, or misinterpretations of prompts, causing... | Bill Dolan, Chris Brockett, Claire Jin, Jessica Quaye, Portia Botchway, Sudha Rao, Xiangyu Peng |  |
| 1893 |  |  [Embodied Language Learning: Opportunities, Challenges, and Future Directions](https://doi.org/10.18653/v1/2024.findings-acl.908) |  | 0 | While large language and vision-language models showcase impressive capabilities, they face a notable limitation: the inability to connect language with the physical world. To bridge this gap, research has focused on embodied language learning, where the language learner is situated in the world,... | Julia Rayz, Nadine Amin |  |
| 1894 |  |  [Challenges to Evaluating the Generalization of Coreference Resolution Models: A Measurement Modeling Perspective](https://doi.org/10.18653/v1/2024.findings-acl.909) |  | 0 | It is increasingly common to evaluate the same coreference resolution (CR) model on multiple datasets. Do these multi-dataset evaluations allow us to draw meaningful conclusions about model generalization? Or, do they rather reflect the idiosyncrasies of a particular experimental setup (e.g., the... | Adam Trischler, Alexandra Olteanu, Ian Porada, Jackie Chi Kit Cheung, Kaheer Suleman |  |
| 1895 |  |  [SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events](https://doi.org/10.18653/v1/2024.findings-acl.910) |  | 0 | Interpreting and assessing goal driven actions is vital to understanding and reasoning over complex events. It is important to be able to acquire the knowledge needed for this understanding, though doing so is challenging. We argue that such knowledge can be elicited through a participant... | Francis Ferraro, Katrin Erk, Sai Vallurupalli |  |
| 1896 |  |  [SLIDE: A Framework Integrating Small and Large Language Models for Open-Domain Dialogues Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.911) |  | 0 | The long-standing one-to-many problem of gold standard responses in open-domain dialogue systems presents challenges for automatic evaluation metrics. Though prior works have demonstrated some success by applying powerful Large Language Models (LLMs), existing approaches still struggle with the... | Bohao Yang, Chen Tang, Chenghua Lin, Kun Zhao, Liang Zhan |  |
| 1897 |  |  [Deep Exploration of Cross-Lingual Zero-Shot Generalization in Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-acl.912) |  | 0 | Instruction tuning has emerged as a powerful technique, significantly boosting zero-shot performance on unseen tasks. While recent work has explored cross-lingual generalization by applying instruction tuning to multilingual models, previous studies have primarily focused on English, with a limited... | Changho Lee, Honglak Lee, Janghoon Han, Joongbo Shin, Kyunghoon Bae, Stanley Jungkyu Choi |  |
| 1898 |  |  [What Makes Language Models Good-enough?](https://doi.org/10.18653/v1/2024.findings-acl.913) |  | 0 | Psycholinguistic research suggests that humans may build a representation of linguistic input that is ‘good-enough’ for the task at hand. This study examines what architectural features make language models learn human-like good-enough language processing. We focus on the number of layers and... | Daiki Asami, Saku Sugawara |  |
| 1899 |  |  [Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction](https://doi.org/10.18653/v1/2024.findings-acl.914) |  | 0 | Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality corpora, due to the labor-intensive labeling of spelling errors in real-life human writing or typing scenarios. Two data augmentation methods are widely adopted: (1) \*Random Replacement\* with the guidance of confusion sets... | Dingyao Yu, Shaoguang Mao, Shikun Zhang, Tao Ge, Wei Ye, Xiongfeng Xiao, Yang An |  |
| 1900 |  |  [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples](https://doi.org/10.18653/v1/2024.findings-acl.915) |  | 0 | We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two critical under- explored problems: the neglect of physically grounded reasoning (counting... | Jianrui Zhang, Mu Cai, Tengyang Xie, Yong Jae Lee |  |
| 1901 |  |  [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.916) |  | 0 | Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this... | Carl Yang, Hejie Cui, Joyce C. Ho, May Dongmei Wang, Ran Xu, Wei Jin, Wenqi Shi, Xuan Kan, Yuchen Zhuang, Yue Yu |  |
| 1902 |  |  [Textless Acoustic Model with Self-Supervised Distillation for Noise-Robust Expressive Speech-to-Speech Translation](https://doi.org/10.18653/v1/2024.findings-acl.917) |  | 0 | In this paper, we propose a textless acoustic model with a self-supervised distillation strategy for noise-robust expressive speech-to-speech translation (S2ST).Recently proposed expressive S2ST systems have achieved impressive expressivity preservation performances by cascading unit-to-speech... | Ann Lee, Benjamin N. Peloquin, Hongyu Gong, Ilia Kulikov, MinJae Hwang, PengJen Chen |  |
| 1903 |  |  [Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-acl.918) |  | 0 | The integration of generative Large Language Models (LLMs) into various applications, including the legal domain, has been accelerated by their expansive and versatile nature. However, when facing a legal case, users without a legal background often struggle to formulate professional queries and... | Chenghao Wang, Ece Gumusel, Xiaozhong Liu, Yang Wu |  |
| 1904 |  |  [TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection](https://doi.org/10.18653/v1/2024.findings-acl.919) |  | 0 | The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent... | Haoliang Li, Haoru Li, Hui Liu, Wenya Wang |  |
| 1905 |  |  [Verifiable Generation with Subsentence-Level Fine-Grained Citations](https://doi.org/10.18653/v1/2024.findings-acl.920) |  | 0 | Verifiable generation requires large language models (LLMs) to cite source documents supporting their outputs, thereby improve output transparency and trustworthiness. Yet, previous work mainly targets the generation of sentence-level citations, lacking specificity about which parts of a sentence... | Lu Wang, Shuyang Cao |  |
| 1906 |  |  [Tailoring with Targeted Precision: Edit-Based Agents for Open-Domain Procedure Customization](https://doi.org/10.18653/v1/2024.findings-acl.921) |  | 0 | How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user’s specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM’s ability to perform such customization. Our approach is to test... | Bodhisattwa Prasad Majumder, Faeze Brahman, Li Zhang, Niket Tandon, Peter Clark, Yash Kumar Lal |  |
| 1907 |  |  [A Meta-Learning Perspective on Transformers for Causal Language Modeling](https://doi.org/10.18653/v1/2024.findings-acl.922) |  | 0 | The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal... | Lav R. Varshney, Xinbo Wu |  |
| 1908 |  |  [PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs](https://doi.org/10.18653/v1/2024.findings-acl.923) |  | 0 | Large Language Models (LLMs) have exhibited impressive capabilities in various tasks, yet their vast parameter sizes restrict their applicability in resource-constrained settings. Knowledge distillation (KD) offers a viable solution by transferring expertise from large teacher models to compact... | Chao Zhang, Feng Han, Haorui Wang, Jialu Liu, Jiaming Shen, Michael Bendersky, Rongzhi Zhang, Simon Baumgartner, Tianqi Liu, Zhen Qin |  |
| 1909 |  |  [Small Language Models Need Strong Verifiers to Self-Correct Reasoning](https://doi.org/10.18653/v1/2024.findings-acl.924) |  | 0 | Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether small (≤ 13B) language models (LMs) have the ability of... | Honglak Lee, Jaekyeom Kim, Lajanugen Logeswaran, Lu Wang, Moontae Lee, Muhammad Khalifa, Yunxiang Zhang |  |
| 1910 |  |  [Hire a Linguist!: Learning Endangered Languages in LLMs with In-Context Linguistic Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.925) |  | 0 | How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large... | Kexun Zhang, Lei Li, Taiqi He, William Yang Wang, Yee Man Choi, Zhenqiao Song |  |
| 1911 |  |  [From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation](https://doi.org/10.18653/v1/2024.findings-acl.926) |  | 0 | We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end-users are not fully proficient, such as language learners. Using a novel framework, we evaluate the effectiveness of several key approaches for this task, including... | Ali Malik, Christopher Piech, Klinton Bicknell, Stephen Mayhew |  |
| 1912 |  |  [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://doi.org/10.18653/v1/2024.findings-acl.927) |  | 0 | Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations.Despite growing mitigation... | Afaf Taïk, Emmanuel Ma, Futian Andrew Wei, Golnoosh Farnadi, Jackie Chi Kit Cheung, Khaoula Chehbouni, Megha Roshan |  |
| 1913 |  |  [CToolEval: A Chinese Benchmark for LLM-Powered Agent Evaluation in Real-World API Interactions](https://doi.org/10.18653/v1/2024.findings-acl.928) |  | 0 | Assessing the capabilities of large language models (LLMs) as agents in decision making and operational tasks is crucial for the development of LLM-as-agent service. We propose CToolEval, a benchmark designed to evaluate LLMs in the context of Chinese societal applications, featuring 398 APIs... | Deyi Xiong, Yufei Huang, Zishan Guo |  |
| 1914 |  |  [Token Alignment via Character Matching for Subword Completion](https://doi.org/10.18653/v1/2024.findings-acl.929) |  | 0 | Generative models, widely utilized in various applications, can often struggle with prompts corresponding to partial tokens. This struggle stems from tokenization, where partial tokens fall out of distribution during inference, leading to incorrect or nonsensical outputs. This paper examines a... | Ben Athiwaratkun, Bing Xiang, Mingyue Shang, Parminder Bhatia, Ramesh Nallapati, Robert Kwiatkowski, Sanjay Krishna Gouda, Shiqi Wang, Sujan Kumar Gonugondla, Yuchen Tian, Zijian Wang |  |
| 1915 |  |  [Rethinking Efficient Multilingual Text Summarization Meta-Evaluation](https://doi.org/10.18653/v1/2024.findings-acl.930) |  | 0 | Evaluating multilingual summarization evaluation metrics, i.e., meta-evaluation, is challenging because of the difficulty of human annotation collection. Therefore, we investigate an efficient multilingual meta-evaluation framework that uses machine translation systems to transform a monolingual... | Arman Cohan, Jiawen Chen, Rilyn Han, Yixin Liu |  |
| 1916 |  |  [emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation](https://doi.org/10.18653/v1/2024.findings-acl.931) |  | 0 | We propose emotion2vec, a universal speech emotion representation model. emotion2vec is pre-trained on open-source unlabeled emotion data through self-supervised online distillation, combining utterance-level loss and frame-level loss during pre-training. emotion2vec outperforms state-of-the-art... | Jiaxin Ye, Jinchao Li, Shiliang Zhang, Xie Chen, Zhifu Gao, Zhisheng Zheng, Ziyang Ma |  |
| 1917 |  |  [Language-Informed Beam Search Decoding for Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.findings-acl.932) |  | 0 | Beam search decoding is the de-facto method for decoding auto-regressive Neural Machine Translation (NMT) models, including multilingual NMT where the target language is specified as an input. However, decoding multilingual NMT models commonly produces off-target translations – yielding translation... | Prasad Tadepalli, Stefan Lee, Yilin Yang |  |
| 1918 |  |  [RA-LoRA: Rank-Adaptive Parameter-Efficient Fine-Tuning for Accurate 2-bit Quantized Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.933) |  | 0 | Deploying large language models (LLMs) with their extensive parameters and high memory demands challenges computational efficiency, particularly in fine-tuning for specific applications with limited resources. Techniques like Low-Rank Adaptation (LoRA) help by training a smaller, modifiable... | Jungwook Choi, Minsoo Kim, Sihwa Lee, Wonyong Sung |  |
| 1919 |  |  [The PGNSC Benchmark: How Do We Predict Where Information Spreads?](https://doi.org/10.18653/v1/2024.findings-acl.934) |  | 0 | Social networks have become ideal vehicles for news dissemination because posted content is easily able to reach users beyond a news outlet’s direct audience. Understanding how information is transmitted among communities of users is a critical step towards understanding the impact social networks... | Alexander Taylor, Wei Wang |  |
| 1920 |  |  [STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.935) |  | 0 | Interactive fiction games have emerged as an important application to improve the generalization capabilities of language-based reinforcement learning (RL) agents. Existing environments for interactive fiction games are domain-specific or time-consuming to generate and do not train the RL agents to... | Keerthiram Murugesan, Shivam Ratnakar, Shreyas Basavatia |  |
| 1921 |  |  [Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models](https://doi.org/10.18653/v1/2024.findings-acl.936) |  | 0 |  | Daniel Rim, Dohyun Lee, Jaegul Choo, Minseok Choi |  |
| 1922 |  |  [Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://doi.org/10.18653/v1/2024.findings-acl.937) |  | 0 | Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs. However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text... | Chris Biemann, Jingheng Pan, Liang Ding, Xintong Wang |  |
| 1923 |  |  [Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs](https://doi.org/10.18653/v1/2024.findings-acl.938) |  | 0 | Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs. In this study, we view partial code as implementation hints and... | Dingmin Wang, Hengzhi Pei, Jinman Zhao, Samson Tan, Sheng Zha |  |
| 1924 |  |  [A Critical Study of What Code-LLMs (Do Not) Learn](https://doi.org/10.18653/v1/2024.findings-acl.939) |  | 0 | Large Language Models trained on code corpora (code-LLMs) have demonstrated impressive performance in various coding assistance tasks. However, despite their increased size and training dataset, code-LLMs still have limitations such as suggesting codes with syntactic errors, variable misuse etc.... | Abhinav Anand, Krishna Narasimhan, Mira Mezini, Shweta Verma |  |
| 1925 |  |  [Visual In-Context Learning for Large Vision-Language Models](https://doi.org/10.18653/v1/2024.findings-acl.940) |  | 0 | In Large Visual Language Models (LVLMs), the efficacy of In-Context Learning (ICL) remains limited by challenges in cross-modal interactions and representation disparities. To overcome these challenges, we introduce a novel Visual In-Context Learning (VICL) method comprising Visual Demonstration... | Jianbing Shen, Qianning Wang, Xiang Li, Yucheng Zhou |  |
| 1926 |  |  [SCALE: Synergized Collaboration of Asymmetric Language Translation Engines](https://doi.org/10.18653/v1/2024.findings-acl.941) |  | 0 | In this paper, we introduce SCALE, a collaborative framework that connects a compact Specialized Translation Model (STM) and a general-purpose Large Language Model (LLM) as one unified translation engine. By introducing translation from STM into the triplet in-context demonstrations, SCALE unlocks... | Dongyan Zhao, Furu Wei, Rui Yan, SiQing Chen, Tao Ge, Xin Cheng, Xun Wang |  |
| 1927 |  |  [No perspective, no perception!! Perspective-aware Healthcare Answer Summarization](https://doi.org/10.18653/v1/2024.findings-acl.942) |  | 0 | Healthcare Community Question Answering (CQA) forums offer an accessible platform for individuals seeking information on various healthcare-related topics. People find such platforms suitable for self-disclosure, seeking medical opinions, finding simplified explanations for their medical... | Gauri Naik, Md. Shad Akhtar, Sharad Chandakacherla, Shweta Yadav |  |
| 1928 |  |  [Retrieval-Augmented Retrieval: Large Language Models are Strong Zero-Shot Retriever](https://doi.org/10.18653/v1/2024.findings-acl.943) |  | 0 | We propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Large language model as Retriever (LameR), is built upon no other neural models but an LLM in a retrieval-augmented retrieval fashion, while breaking brute-force... | Chongyang Tao, Daxin Jiang, Guodong Long, Michael Blumenstein, Tao Shen, Tianyi Zhou, Xiubo Geng, Yibin Lei |  |
| 1929 |  |  [A Survey on Predicting the Factuality and the Bias of News Media](https://doi.org/10.18653/v1/2024.findings-acl.944) |  | 0 | The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim or article, either manually or automatically. An increasing number of scholars are focusing on a coarser granularity, aiming to profile entire... | Haewoon Kwak, Husrev T. Sencar, Jisun An, Muhammad Arslan Manzoor, Preslav Nakov, Zain Muhammad Mujahid |  |
| 1930 |  |  [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://doi.org/10.18653/v1/2024.findings-acl.945) |  | 0 | Wavelet transforms, a powerful mathematical tool, have been widely used in different domains, including Signal and Image processing, to unravel intricate patterns, enhance data representation, and extract meaningful features from data. Tangible results from their application suggest that Wavelet... | Abdou Youssef, Mona T. Diab, Rana Aref Salama |  |
| 1931 |  |  [Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning](https://doi.org/10.18653/v1/2024.findings-acl.946) |  | 0 | Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural language processing, with numerous approaches aiming to answer First-Order Logic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g., beta distribution)-based methodologies have effectively addressed... | Heesoo Jung, Hogun Park, Hyeju Jang, Jeonghoon Kim |  |
| 1932 |  |  [ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.947) |  | 0 | Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient strategy to harness LLMs with modest NER... | Chao Zhang, Chunyuan Deng, Rongzhi Zhang, Yinghao Li, Yitong Li, Yue Yu, Yuzhao Heng |  |
| 1933 |  |  [Defending LLMs against Jailbreaking Attacks via Backtranslation](https://doi.org/10.18653/v1/2024.findings-acl.948) |  | 0 | Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by... | Andrew Bai, ChoJui Hsieh, Yihan Wang, Zhouxing Shi |  |
| 1934 |  |  [A Large Collection of Model-generated Contradictory Responses for Consistency-aware Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-acl.949) |  | 0 | Mitigating the generation of contradictory responses poses a substantial challenge in dialogue response generation. The quality and quantity of available contradictory response data play a vital role in suppressing these contradictions, offering two significant benefits. First, having access to... | Jun Suzuki, Kentaro Inui, Reina Akama, Shiki Sato |  |
| 1935 |  |  [Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset](https://doi.org/10.18653/v1/2024.findings-acl.950) |  | 0 | This paper explores the question of how accurately current large language models can perform logical reasoning in natural language, with an emphasis on whether these models exhibit reasoning biases similar to humans. Specifically, our study focuses on syllogistic reasoning, a form of deductive... | Hirohiko Abe, Kentaro Ozeki, Koji Mineshima, Mitsuhiro Okada, Risako Ando, Takanobu Morishita |  |
| 1936 |  |  [Unveiling the Spectrum of Data Contamination in Language Model: A Survey from Detection to Remediation](https://doi.org/10.18653/v1/2024.findings-acl.951) |  | 0 | Data contamination has garnered increased attention in the era of Large language models (LLMs) due to the reliance on extensive internet-derived training corpora. The issue of training corpus overlap with evaluation benchmarks—referred to as contamination—has been the focus of significant recent... | Arman Cohan, Chunyuan Deng, Jiannan Cao, Xiangru Tang, Yilun Zhao, Yitong Li, Yuzhao Heng |  |
| 1937 |  |  [DIMSIM: Distilled Multilingual Critics for Indic Text Simplification](https://doi.org/10.18653/v1/2024.findings-acl.952) |  | 0 | Self-correction techniques have recently emerged as a promising framework to improve the quality of responses generated by large language models (LLMs). Few-shot prompted LLMs act as critics to produce feedback for an input, which is further fed to a refiner (also an LLM) to produce an output.... | Aravindan Raghuveer, Ashish Agrawal, Preethi Jyothi, Ritika, Sneha Mondal |  |
| 1938 |  |  [MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources](https://doi.org/10.18653/v1/2024.findings-acl.953) |  | 0 | Leveraging external knowledge is crucial for achieving high performance in knowledge-intensive tasks, such as question answering. The retrieve-and-read approach is widely adopted for integrating external knowledge into a language model. However, this approach suffers from increased computational... | Chandana Satya Prakash, Dongkyu Lee, Jack FitzGerald, Jens Lehmann |  |
| 1939 |  |  [Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.954) |  | 0 | Social bias is shaped by the accumulation of social perceptions towards targets across various demographic identities. To fully understand such social bias in large language models (LLMs), it is essential to consider the composite of social perceptions from diverse perspectives among identities.... | Hoyun Song, Huije Lee, Jisu Shin, Jong Park, Soyeong Jeong |  |
| 1940 |  |  [Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting](https://doi.org/10.18653/v1/2024.findings-acl.955) |  | 0 | Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has... | Ding Wang, Liang Wang, Qiang Liu, Shu Wu, Xiaoyu Zhang, Yuwei Xia |  |
| 1941 |  |  [Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements](https://doi.org/10.18653/v1/2024.findings-acl.956) |  | 0 | Making LLMs speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. However, existing LLMs lack sufficient controllability to the stance of their generated... | Jiuhai Chen, Lichang Chen, Ming Li, Tianyi Zhou |  |
| 1942 |  |  [Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection](https://doi.org/10.18653/v1/2024.findings-acl.957) |  | 0 | Detecting implicit hate speech that is not directly hateful remains a challenge. Recent research has attempted to detect implicit hate speech by applying contrastive learning to pre-trained language models such as BERT and RoBERTa, but the proposed models still do not have a significant advantage... | Jaehoon Kim, Kyungsik Han, Seungwan Jin, Sohyun Park, Someen Park |  |
| 1943 |  |  [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://doi.org/10.18653/v1/2024.findings-acl.958) |  | 0 | Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the... | Jiuhai Chen, Jiuxiang Gu, Lichang Chen, Ming Li, Shwai He, Tianyi Zhou |  |
| 1944 |  |  [Selective Prompting Tuning for Personalized Conversations with LLMs](https://doi.org/10.18653/v1/2024.findings-acl.959) |  | 0 | In conversational AI, personalizing dialogues with persona profiles and contextual understanding is essential. Despite large language models’ (LLMs) improved response coherence, effective persona integration remains a challenge. In this work, we first study two common approaches for personalizing... | Bo Wu, Lilian Tang, Qiushi Huang, Tom Ko, Wenwu Wang, Xubo Liu, Yu Zhang |  |
| 1945 |  |  [Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models](https://doi.org/10.18653/v1/2024.findings-acl.960) |  | 0 | In the rapidly advancing field of artificial intelligence, the concept of ‘Red-Teaming’ or ‘Jailbreaking’ large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This... | Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria |  |
| 1946 |  |  [ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions](https://doi.org/10.18653/v1/2024.findings-acl.961) |  | 0 | Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text. Despite the success of VLMs, they still significantly lag behind human performance in IRCD. The main challenges lie in aligning key... | Chaoyue Tang, Guoshun Nan, Honglin Lin, Jingxin Xu, Qimei Cui, Siyu Li, Xiaofeng Tao, Xueting Wang, Yankai Rong, Yutong Gao, Zhouzhili Zhouzhili |  |
| 1947 |  |  [PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns](https://doi.org/10.18653/v1/2024.findings-acl.962) |  | 0 | Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities. However, it is not clear how they can emulate the general intelligence and reasoning ability of humans. As recognizing patterns and abstracting concepts are key to... | Deepanway Ghosal, Lidong Bing, Soujanya Poria, Vernon Toh, Yew Ken Chia |  |
| 1948 |  |  [How Do Moral Emotions Shape Political Participation? A Cross-Cultural Analysis of Online Petitions Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.963) |  | 0 | Understanding the interplay between emotions in language and user behaviors is critical. We study how moral emotions shape the political participation of users based on cross-cultural online petition data. To quantify moral emotions, we employ a context-aware NLP model that is designed to capture... | Chaeyoon Jeong, Jaehong Kim, Meeyoung Cha, Seongchan Park, Wonjae Lee |  |
| 1949 |  |  [VillagerAgent: A Graph-Based Multi-Agent Framework for Coordinating Complex Task Dependencies in Minecraft](https://doi.org/10.18653/v1/2024.findings-acl.964) |  | 0 | In this paper, we aim to evaluate multi-agent systems against complex dependencies, including spatial, causal, and temporal constraints. First, we construct a new benchmark, named VillagerBench, within the Minecraft environment. VillagerBench comprises diverse tasks crafted to test various aspects... | Linchao Zhu, Xukun Zhu, Yi Yang, Yubo Dong, Zhengzhe Pan |  |
| 1950 |  |  [CF-TCIR: A Compositor-Free Framework for Hierarchical Text-Conditioned Image Retrieval](https://doi.org/10.18653/v1/2024.findings-acl.965) |  | 0 | In text-conditioned image retrieval (TCIR), the combination of a reference image and modification text forms a query tuple, aiming to locate the most congruent target image within a dataset. The advantages of rich image semantic information and text flexibility are combined in this manner for more... | Yanfeng Wang, Yu Wang, Yuchen Yang |  |
| 1951 |  |  [DMIN: A Discourse-specific Multi-granularity Integration Network for Conversational Aspect-based Sentiment Quadruple Analysis](https://doi.org/10.18653/v1/2024.findings-acl.966) |  | 0 | Conversational Aspect-based Sentiment Quadruple Analysis (DiaASQ) aims to extract fine-grained sentiment quadruples from dialogues. Previous research has primarily concentrated on enhancing token-level interactions, still lacking in sufficient modeling of the discourse structure information in... | Jiawei Chen, Peijie Huang, Xisheng Xiao, Yuhong Xu |  |
| 1952 |  |  [Are Decoder-Only Language Models Better than Encoder-Only Language Models in Understanding Word Meaning?](https://doi.org/10.18653/v1/2024.findings-acl.967) |  | 0 | The natural language processing field has been evolving around language models for the past few years, from the usage of n-gram language models for re-ranking, to transfer learning with encoder-only (BERT-like) language models, and finally to large language models (LLMs) as general solvers. LLMs... | Geonsik Moon, Hwee Tou Ng, Muhammad Reza Qorib |  |
| 1953 |  |  [FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models](https://doi.org/10.18653/v1/2024.findings-acl.968) |  | 0 | To process contexts with unlimited length using Large Language Models (LLMs), recent studies explore hierarchically managing the long text. Only several text fragments are taken from the external memory and passed into the temporary working memory, i.e., LLM’s context window. However, existing... | Linchao Zhu, Xihang Yue, Yi Yang |  |
| 1954 |  |  [On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations](https://doi.org/10.18653/v1/2024.findings-acl.969) |  | 0 | Driven by the demand for cross-sentence and large-scale relation extraction, document-level relation extraction (DocRE) has attracted increasing research interest. Despite the continuous improvement in performance, we find that existing DocRE models which initially perform well may make more... | Aiwei Liu, Fukun Ma, Lijie Wen, Shiao Meng, Shuang Li, Xuming Hu, Yawen Yang |  |
| 1955 |  |  [RESEMO: A Benchmark Chinese Dataset for Studying Responsive Emotion from Social Media Content](https://doi.org/10.18653/v1/2024.findings-acl.970) |  | 0 | On social media platforms, users’ emotions are triggered when they encounter particular content from other users,where such emotions are different from those that spontaneously emerged, owing to the “responsive” nature. Analyzing the aforementioned responsive emotions from user interactions is a... | Bo Hu, Chenfei Xie, Meng Zhang, Yan Song, Yuanhe Tian, Zhendong Mao |  |
| 1956 |  |  [EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records](https://doi.org/10.18653/v1/2024.findings-acl.971) |  | 0 | In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to address critical yet underexplored aspects in text-to-SQL parsing: interactivity, compositionality, and efficiency. To the best of our knowledge,... | Edward Choi, Gyubok Lee, Jaehee Ryu, Seonhee Cho |  |
| 1957 |  |  [KEEP CHATTING! An Attractive Dataset for Continuous Conversation Agents](https://doi.org/10.18653/v1/2024.findings-acl.972) |  | 0 | Ongoing chatting is an important step for conversational agents to build long-term connections with people. However, people tend to quickly lose interest in chatting if the conversational agent’s words are not engaging enough. In this paper, we present a novel task of increasing users’ willingness... | Jin Liu, Weipeng Chen, Yao Wan, Yihe Wang, Yitong Li, Zifeng Liu |  |
| 1958 |  |  [RePair: Automated Program Repair with Process-based Feedback](https://doi.org/10.18653/v1/2024.findings-acl.973) |  | 0 | The gap between the trepidation of program reliability and the expense of repairs underscore the indispensability for Automated Program Repair (APR). APR is instrumental in transforming vulnerable programs into more robust ones, bolstering program reliability while simultaneously diminishing the... | Hao Jiang, Kai Zhang, Linbo Zhu, Qi Liu, Rui Li, Yixiao Ma, Yu Su, Yuze Zhao, Zhenya Huang |  |
| 1959 |  |  [Concise and Precise Context Compression for Tool-Using Language Models](https://doi.org/10.18653/v1/2024.findings-acl.974) |  | 0 | Through reading the documentation in the context, tool-using language models can dynamically extend their capability using external tools. The cost is that we have to input lengthy documentation every time the model needs to use the tool, occupying the input window as well as slowing down the... | Dandan Tu, Honglin Mu, Min Zhang, Qingfu Zhu, Wanjun Zhong, Wanxiang Che, Xinghao Wang, Yang Xu, Yitong Li, Yunlong Feng, Yutai Hou, Zhongyang Li |  |
| 1960 |  |  [MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries](https://doi.org/10.18653/v1/2024.findings-acl.975) |  | 0 | Medical decisions directly impact individuals’ health and well-being. Extracting decision spans from clinical notes plays a crucial role in understanding medical decision-making processes. In this paper, we develop a new dataset called “MedDec,” which contains clinical notes of eleven different... | Hadi Amiri, Jiali Cheng, Leo Anthony Celi, Mohamed Elgaar, Nidhi Vakil |  |
